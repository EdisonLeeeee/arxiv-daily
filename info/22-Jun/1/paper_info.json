[
  {
    "id": "arXiv:2205.15304",
    "title": "Improvements to Supervised EM Learning of Shared Kernel Models by  Feature Space Partitioning",
    "abstract": "Expectation maximisation (EM) is usually thought of as an unsupervised\nlearning method for estimating the parameters of a mixture distribution,\nhowever it can also be used for supervised learning when class labels are\navailable. As such, EM has been applied to train neural nets including the\nprobabilistic radial basis function (PRBF) network or shared kernel (SK) model.\nThis paper addresses two major shortcomings of previous work in this area: the\nlack of rigour in the derivation of the EM training algorithm; and the\ncomputational complexity of the technique, which has limited it to low\ndimensional data sets. We first present a detailed derivation of EM for the\nGaussian shared kernel model PRBF classifier, making use of data association\ntheory to obtain the complete data likelihood, Baum's auxiliary function (the\nE-step) and its subsequent maximisation (M-step). To reduce complexity of the\nresulting SKEM algorithm, we partition the feature space into $R$\nnon-overlapping subsets of variables. The resulting product decomposition of\nthe joint data likelihood, which is exact when the feature partitions are\nindependent, allows the SKEM to be implemented in parallel and at $R^2$ times\nlower complexity. The operation of the partitioned SKEM algorithm is\ndemonstrated on the MNIST data set and compared with its non-partitioned\ncounterpart. It eventuates that improved performance at reduced complexity is\nachievable. Comparisons with standard classification algorithms are provided on\na number of other benchmark data sets.",
    "descriptor": "\nComments: 29 pages, 5 figures, 1 table. arXiv admin note: text overlap with arXiv:2205.09041\n",
    "authors": [
      "Graham W. Pulford"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.15304"
  },
  {
    "id": "arXiv:2205.15305",
    "title": "A Design Space for Explainable Ranking and Ranking Models",
    "abstract": "Item ranking systems support users in multi-criteria decision-making tasks.\nUsers need to trust rankings and ranking algorithms to reflect user preferences\nnicely while avoiding systematic errors and biases. However, today only few\napproaches help end users, model developers, and analysts to explain rankings.\nWe report on the study of explanation approaches from the perspectives of\nrecommender systems, explainable AI, and visualization research and propose the\nfirst cross-domain design space for explainers of item rankings. In addition,\nwe leverage the descriptive power of the design space to characterize a)\nexisting explainers and b) three main user groups involved in ranking\nexplanation tasks. The generative power of the design space is a means for\nfuture designers and developers to create more target-oriented solutions in\nthis only weakly exploited space.",
    "descriptor": "\nComments: Poster abstract submitted to EuroVIS 2022\n",
    "authors": [
      "I. Al Hazwani",
      "J. Schmid",
      "M. Sachdeva",
      "J. Bernard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2205.15305"
  },
  {
    "id": "arXiv:2205.15306",
    "title": "How to Compose Shortest Paths",
    "abstract": "The composition problem for shortest paths asks the following: given shortest\npaths on weighted graphs M and N which share a common boundary, find the\nshortest paths on their union. This problem is a crucial step in any algorithm\nwhich uses the divide and conquer method to find shortest paths. This extended\nabstract details how this problem may be understood categorically. Finding\nshortest paths is represented by a functor and the composition problem asks to\nfind the value of this functor on a pushout using the values of the functor on\nthe components. Furthermore, we present an algorithm which solves the\ncomposition problem for shortest paths. When implemented in Python, this\nalgorithm reduces the computation time for finding shortest paths by relying on\nprecompilation.",
    "descriptor": "\nComments: 3 pages, 2 pictures\n",
    "authors": [
      "Jade Master"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2205.15306"
  },
  {
    "id": "arXiv:2205.15307",
    "title": "A Unified Weight Initialization Paradigm for Tensorial Convolutional  Neural Networks",
    "abstract": "Tensorial Convolutional Neural Networks (TCNNs) have attracted much research\nattention for their power in reducing model parameters or enhancing the\ngeneralization ability. However, exploration of TCNNs is hindered even from\nweight initialization methods. To be specific, general initialization methods,\nsuch as Xavier or Kaiming initialization, usually fail to generate appropriate\nweights for TCNNs. Meanwhile, although there are ad-hoc approaches for specific\narchitectures (e.g., Tensor Ring Nets), they are not applicable to TCNNs with\nother tensor decomposition methods (e.g., CP or Tucker decomposition). To\naddress this problem, we propose a universal weight initialization paradigm,\nwhich generalizes Xavier and Kaiming methods and can be widely applicable to\narbitrary TCNNs. Specifically, we first present the Reproducing Transformation\nto convert the backward process in TCNNs to an equivalent convolution process.\nThen, based on the convolution operators in the forward and backward processes,\nwe build a unified paradigm to control the variance of features and gradients\nin TCNNs. Thus, we can derive fan-in and fan-out initialization for various\nTCNNs. We demonstrate that our paradigm can stabilize the training of TCNNs,\nleading to faster convergence and better results.",
    "descriptor": "\nComments: Accepted in ICML 2022\n",
    "authors": [
      "Yu Pan",
      "Zeyong Su",
      "Ao Liu",
      "Jingquan Wang",
      "Nannan Li",
      "Zenglin Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.15307"
  },
  {
    "id": "arXiv:2205.15308",
    "title": "Parameter-Efficient and Student-Friendly Knowledge Distillation",
    "abstract": "Knowledge distillation (KD) has been extensively employed to transfer the\nknowledge from a large teacher model to the smaller students, where the\nparameters of the teacher are fixed (or partially) during training. Recent\nstudies show that this mode may cause difficulties in knowledge transfer due to\nthe mismatched model capacities. To alleviate the mismatch problem,\nteacher-student joint training methods, e.g., online distillation, have been\nproposed, but it always requires expensive computational cost. In this paper,\nwe present a parameter-efficient and student-friendly knowledge distillation\nmethod, namely PESF-KD, to achieve efficient and sufficient knowledge transfer\nby updating relatively few partial parameters. Technically, we first\nmathematically formulate the mismatch as the sharpness gap between their\npredictive distributions, where we show such a gap can be narrowed with the\nappropriate smoothness of the soft label. Then, we introduce an adapter module\nfor the teacher and only update the adapter to obtain soft labels with\nappropriate smoothness. Experiments on a variety of benchmarks show that\nPESF-KD can significantly reduce the training cost while obtaining competitive\nresults compared to advanced online distillation methods. Code will be released\nupon acceptance.",
    "descriptor": "",
    "authors": [
      "Jun Rao",
      "Xv Meng",
      "Liang Ding",
      "Shuhan Qi",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15308"
  },
  {
    "id": "arXiv:2205.15311",
    "title": "Biological Evolution and Genetic Algorithms: Exploring the Space of  Abstract Tile Self-Assembly",
    "abstract": "A physically-motivated genetic algorithm (GA) and full enumeration for a\ntile-based model of self-assembly (JaTAM) is implemented using a graphics\nprocessing unit (GPU). We observe performance gains with respect to\nstate-of-the-art implementations on CPU of factor 7.7 for the GA and 2.9 for\nJaTAM. The correctness of our GA implementation is demonstrated using a\ntest-bed fitness function, and our JaTAM implementation is verified by\nclassifying a well-known search space $S_{2,8}$ based on two tile types. The\nperformance gains achieved allow for the classification of a larger search\nspace $S^{32}_{3,8}$ based on three tile types. The prevalence of structures\nbased on two tile types demonstrates that simple organisms emerge preferrably\neven in complex ecosystems. The modularity of the largest structures found\nmotivates the assumption that to first order, $S_{2,8}$ forms the building\nblocks of $S_{3,8}$. We conclude that GPUs may play an important role in future\nstudies of evolutionary dynamics.",
    "descriptor": "\nComments: MPhys Thesis, 2012. Awarded University of Oxford Tessella Prize\n",
    "authors": [
      "Christian Schroeder de Witt"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Biological Physics (physics.bio-ph)"
    ],
    "url": "https://arxiv.org/abs/2205.15311"
  },
  {
    "id": "arXiv:2205.15312",
    "title": "Mean Field inference of CRFs based on GAT",
    "abstract": "In this paper we propose an improved mean-field inference algorithm for the\nfully connected paired CRFs model. The improved method Message Passing\noperation is changed from the original linear convolution to the present graph\nattention operation, while the process of the inference algorithm is turned\ninto the forward process of the GAT model. Combined with the mean-field\ninferred label distribution, it is equivalent to the output of a classifier\nwith only unary potential. To this end, we propose a graph attention network\nmodel with residual structure, and the model approach is applicable to all\nsequence annotation tasks, such as pixel-level image semantic segmentation\ntasks as well as text annotation tasks.",
    "descriptor": "",
    "authors": [
      "LingHong Xing",
      "XiangXiang Ma",
      "GuangSheng Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.15312"
  },
  {
    "id": "arXiv:2205.15317",
    "title": "Chefs' Random Tables: Non-Trigonometric Random Features",
    "abstract": "We introduce chefs' random tables (CRTs), a new class of non-trigonometric\nrandom features (RFs) to approximate Gaussian and softmax kernels. CRTs are an\nalternative to standard random kitchen sink (RKS) methods, which inherently\nrely on the trigonometric maps. We present variants of CRTs where RFs are\npositive, a key requirement for applications in recent low-rank Transformers.\nFurther variance reduction is possible by leveraging statistics which are\nsimple to compute. One instantiation of CRTs, the optimal positive random\nfeatures (OPRFs), is to our knowledge the first RF method for unbiased softmax\nkernel estimation with positive and bounded RFs, resulting in exponentially\nsmall tails and much lower variance than its counterparts. As we show,\northogonal random features applied in OPRFs provide additional variance\nreduction for any dimensionality $d$ (not only asymptotically for sufficiently\nlarge $d$, as for RKS). We test CRTs on many tasks ranging from non-parametric\nclassification to training Transformers for text, speech and image data,\nobtaining new state-of-the-art results for low-rank text Transformers, while\nproviding linear space and time complexity.",
    "descriptor": "",
    "authors": [
      "Valerii Likhosherstov",
      "Krzysztof Choromanski",
      "Avinava Dubey",
      "Frederick Liu",
      "Tamas Sarlos",
      "Adrian Weller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.15317"
  },
  {
    "id": "arXiv:2205.15319",
    "title": "Learning Adaptive Propagation for Knowledge Graph Reasoning",
    "abstract": "Due to the success of Graph Neural Networks (GNNs) in learning from\ngraph-structured data, various GNN-based methods have been introduced to learn\nfrom knowledge graphs (KGs). In this paper, to reveal the key factors\nunderneath existing GNN-based methods, we revisit exemplar works from the lens\nof the propagation path. We find that the answer entity can be close to queried\none, but the information dependency can be long. Thus, better reasoning\nperformance can be obtained by exploring longer propagation paths. However,\nidentifying such a long-range dependency in KG is hard since the number of\ninvolved entities grows exponentially. This motivates us to learn an adaptive\npropagation path that filters out irrelevant entities while preserving\npromising targets during the propagation. First, we design an incremental\nsampling mechanism where the close and promising target can be preserved.\nSecond, we design a learning-based sampling distribution to identify the\ntargets with fewer involved entities. In this way, GNN can go deeper to capture\nlong-range information. Extensive experiments show that our method is efficient\nand achieves state-of-the-art performances in both transductive and inductive\nreasoning settings, benefiting from the deeper propagation.",
    "descriptor": "\nComments: under review\n",
    "authors": [
      "Yongqi Zhang",
      "Zhanke Zhou",
      "Quanming Yao",
      "Xiaowen Chu",
      "Bo Han"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.15319"
  },
  {
    "id": "arXiv:2205.15322",
    "title": "Superposing Many Tickets into One: A Performance Booster for Sparse  Neural Network Training",
    "abstract": "Recent works on sparse neural network training (sparse training) have shown\nthat a compelling trade-off between performance and efficiency can be achieved\nby training intrinsically sparse neural networks from scratch. Existing sparse\ntraining methods usually strive to find the best sparse subnetwork possible in\none single run, without involving any expensive dense or pre-training steps.\nFor instance, dynamic sparse training (DST), as one of the most prominent\ndirections, is capable of reaching a competitive performance of dense training\nby iteratively evolving the sparse topology during the course of training. In\nthis paper, we argue that it is better to allocate the limited resources to\ncreate multiple low-loss sparse subnetworks and superpose them into a stronger\none, instead of allocating all resources entirely to find an individual\nsubnetwork. To achieve this, two desiderata are required: (1) efficiently\nproducing many low-loss subnetworks, the so-called cheap tickets, within one\ntraining process limited to the standard training time used in dense training;\n(2) effectively superposing these cheap tickets into one stronger subnetwork\nwithout going over the constrained parameter budget. To corroborate our\nconjecture, we present a novel sparse training approach, termed\n\\textbf{Sup-tickets}, which can satisfy the above two desiderata concurrently\nin a single sparse-to-sparse training process. Across various modern\narchitectures on CIFAR-10/100 and ImageNet, we show that Sup-tickets integrates\nseamlessly with the existing sparse training methods and demonstrates\nconsistent performance improvement.",
    "descriptor": "\nComments: 17 pages, 5 figures, accepted by the 38th Conference on Uncertainty in Artificial Intelligence (UAI)\n",
    "authors": [
      "Lu Yin",
      "Vlado Menkovski",
      "Meng Fang",
      "Tianjin Huang",
      "Yulong Pei",
      "Mykola Pechenizkiy",
      "Decebal Constantin Mocanu",
      "Shiwei Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.15322"
  },
  {
    "id": "arXiv:2205.15354",
    "title": "Fast Computation of Electrostatic Potentials for Piecewise Constant  Conductivities",
    "abstract": "We present a novel numerical method for solving the elliptic partial\ndifferential equation problem for the electrostatic potential with piecewise\nconstant conductivity. We employ an integral equation approach for which we\nderive a system of well-conditioned integral equations by representing the\nsolution as a sum of single layer potentials. The kernel of the resulting\nintegral operator is smooth provided that the layers are well-separated. The\nfast multiple method is used to accelerate the generalized minimal residual\nmethod solution of the integral equations. For efficiency, we adapt the grid of\nthe Nystr\\\"{o}m method based on the spectral resolution of the layer charge\ndensity. Additionally, we present a method for evaluating the solution that is\nefficient and accurate throughout the domain, circumventing the\nclose-evaluation problem. To support the design choices of the numerical\nmethod, we derive regularity estimates with bounds explicitly in terms of the\nconductivities and the geometries of the boundaries between their regions. The\nresulting method is fast and accurate for solving for the electrostatic\npotential in media with piecewise constant conductivities.",
    "descriptor": "\nComments: 24 pages, 8 figures; 5 page supplement with 1 figure\n",
    "authors": [
      "Kyle Bower",
      "Kirill Serkh",
      "Spyros Alexakis",
      "Adam R Stinchcombe"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.15354"
  },
  {
    "id": "arXiv:2205.15357",
    "title": "Searching for the Essence of Adversarial Perturbations",
    "abstract": "Neural networks have achieved the state-of-the-art performance on various\nmachine learning fields, yet the incorporation of malicious perturbations with\ninput data (adversarial example) is able to fool neural networks' predictions.\nThis would lead to potential risks in real-world applications, for example,\nauto piloting and facial recognition. However, the reason for the existence of\nadversarial examples remains controversial. Here we demonstrate that\nadversarial perturbations contain human-recognizable information, which is the\nkey conspirator responsible for a neural network's erroneous prediction. This\nconcept of human-recognizable information allows us to explain key features\nrelated to adversarial perturbations, which include the existence of\nadversarial examples, the transferability among different neural networks, and\nthe increased neural network interpretability for adversarial training. Two\nunique properties in adversarial perturbations that fool neural networks are\nuncovered: masking and generation. A special class, the complementary class, is\nidentified when neural networks classify input images. The human-recognizable\ninformation contained in adversarial perturbations allows researchers to gain\ninsight on the working principles of neural networks and may lead to develop\ntechniques that detect/defense adversarial attacks.",
    "descriptor": "",
    "authors": [
      "Dennis Y. Menn",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2205.15357"
  },
  {
    "id": "arXiv:2205.15359",
    "title": "CTR: Checkpoint, Transfer, and Restore for Secure Enclaves",
    "abstract": "Hardware-based Trusted Execution Environments (TEEs) are becoming\nincreasingly prevalent in cloud computing, forming the basis for confidential\ncomputing. However, the security goals of TEEs sometimes conflict with existing\ncloud functionality, such as VM or process migration, because TEE memory cannot\nbe read by the hypervisor, OS, or other software on the platform. Whilst some\nnewer TEE architectures support migration of entire protected VMs, there is\ncurrently no practical solution for migrating individual processes containing\nin-process TEEs. The inability to migrate such processes leads to operational\ninefficiencies or even data loss if the host platform must be urgently\nrestarted.\nWe present CTR, a software-only design to retrofit migration functionality\ninto existing TEE architectures, whilst maintaining their expected security\nguarantees. Our design allows TEEs to be interrupted and migrated at arbitrary\npoints in their execution, thus maintaining compatibility with existing VM and\nprocess migration techniques. By cooperatively involving the TEE in the\nmigration process, our design also allows application developers to specify\nstateful migration-related policies, such as limiting the number of times a\nparticular TEE may be migrated. Our prototype implementation for Intel SGX\ndemonstrates that migration latency increases linearly with the size of the TEE\nmemory and is dominated by TEE system operations.",
    "descriptor": "",
    "authors": [
      "Yoshimichi Nakatsuka",
      "Ercan Ozturk",
      "Alex Shamis",
      "Andrew Paverd",
      "Peter Pietzuch"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.15359"
  },
  {
    "id": "arXiv:2205.15360",
    "title": "Revisiting Audio Pattern Recognition for Asthma Medication Adherence:  Evaluation with the RDA Benchmark Suite",
    "abstract": "Asthma is a common, usually long-term respiratory disease with negative\nimpact on society and the economy worldwide. Treatment involves using medical\ndevices (inhalers) that distribute medication to the airways, and its\nefficiency depends on the precision of the inhalation technique. Health\nmonitoring systems equipped with sensors and embedded with sound signal\ndetection enable the recognition of drug actuation and could be powerful tools\nfor reliable audio content analysis. This paper revisits audio pattern\nrecognition and machine learning techniques for asthma medication adherence\nassessment and presents the Respiratory and Drug Actuation (RDA)\nSuite(https://gitlab.com/vvr/monitoring-medication-adherence/rda-benchmark) for\nbenchmarking and further research. The RDA Suite includes a set of tools for\naudio processing, feature extraction and classification and is provided along\nwith a dataset consisting of respiratory and drug actuation sounds. The\nclassification models in RDA are implemented based on conventional and advanced\nmachine learning and deep network architectures. This study provides a\ncomparative evaluation of the implemented approaches, examines potential\nimprovements and discusses challenges and future tendencies.",
    "descriptor": "",
    "authors": [
      "Nikos D. Fakotakis",
      "Stavros Nousias",
      "Gerasimos Arvanitis",
      "Evangelia I. Zacharaki",
      "Konstantinos Moustakas"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)",
      "General Literature (cs.GL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2205.15360"
  },
  {
    "id": "arXiv:2205.15361",
    "title": "TubeFormer-DeepLab: Video Mask Transformer",
    "abstract": "We present TubeFormer-DeepLab, the first attempt to tackle multiple core\nvideo segmentation tasks in a unified manner. Different video segmentation\ntasks (e.g., video semantic/instance/panoptic segmentation) are usually\nconsidered as distinct problems. State-of-the-art models adopted in the\nseparate communities have diverged, and radically different approaches dominate\nin each task. By contrast, we make a crucial observation that video\nsegmentation tasks could be generally formulated as the problem of assigning\ndifferent predicted labels to video tubes (where a tube is obtained by linking\nsegmentation masks along the time axis) and the labels may encode different\nvalues depending on the target task. The observation motivates us to develop\nTubeFormer-DeepLab, a simple and effective video mask transformer model that is\nwidely applicable to multiple video segmentation tasks. TubeFormer-DeepLab\ndirectly predicts video tubes with task-specific labels (either pure semantic\ncategories, or both semantic categories and instance identities), which not\nonly significantly simplifies video segmentation models, but also advances\nstate-of-the-art results on multiple video segmentation benchmarks",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Dahun Kim",
      "Jun Xie",
      "Huiyu Wang",
      "Siyuan Qiao",
      "Qihang Yu",
      "Hong-Seok Kim",
      "Hartwig Adam",
      "In So Kweon",
      "Liang-Chieh Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15361"
  },
  {
    "id": "arXiv:2205.15367",
    "title": "Non-Markovian Reward Modelling from Trajectory Labels via Interpretable  Multiple Instance Learning",
    "abstract": "We generalise the problem of reward modelling (RM) for reinforcement learning\n(RL) to handle non-Markovian rewards. Existing work assumes that human\nevaluators observe each step in a trajectory independently when providing\nfeedback on agent behaviour. In this work, we remove this assumption, extending\nRM to include hidden state information that captures temporal dependencies in\nhuman assessment of trajectories. We then show how RM can be approached as a\nmultiple instance learning (MIL) problem, and develop new MIL models that are\nable to capture the time dependencies in labelled trajectories. We demonstrate\non a range of RL tasks that our novel MIL models can reconstruct reward\nfunctions to a high level of accuracy, and that they provide interpretable\nlearnt hidden information that can be used to train high-performing agent\npolicies.",
    "descriptor": "\nComments: 20 pages (9 main content; 2 references; 9 appendix). 11 figures (8 main content; 3 appendix)\n",
    "authors": [
      "Joseph Early",
      "Tom Bewley",
      "Christine Evers",
      "Sarvapali Ramchurn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.15367"
  },
  {
    "id": "arXiv:2205.15370",
    "title": "Guided-TTS 2: A Diffusion Model for High-quality Adaptive Text-to-Speech  with Untranscribed Data",
    "abstract": "We propose Guided-TTS 2, a diffusion-based generative model for high-quality\nadaptive TTS using untranscribed data. Guided-TTS 2 combines a\nspeaker-conditional diffusion model with a speaker-dependent phoneme classifier\nfor adaptive text-to-speech. We train the speaker-conditional diffusion model\non large-scale untranscribed datasets for a classifier-free guidance method and\nfurther fine-tune the diffusion model on the reference speech of the target\nspeaker for adaptation, which only takes 40 seconds. We demonstrate that\nGuided-TTS 2 shows comparable performance to high-quality single-speaker TTS\nbaselines in terms of speech quality and speaker similarity with only a\nten-second untranscribed data. We further show that Guided-TTS 2 outperforms\nadaptive TTS baselines on multi-speaker datasets even with a zero-shot\nadaptation setting. Guided-TTS 2 can adapt to a wide range of voices only using\nuntranscribed speech, which enables adaptive TTS with the voice of non-human\ncharacters such as Gollum in \\textit{\"The Lord of the Rings\"}.",
    "descriptor": "",
    "authors": [
      "Sungwon Kim",
      "Heeseung Kim",
      "Sungroh Yoon"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2205.15370"
  },
  {
    "id": "arXiv:2205.15372",
    "title": "Optimistic Whittle Index Policy: Online Learning for Restless Bandits",
    "abstract": "Restless multi-armed bandits (RMABs) extend multi-armed bandits to allow for\nstateful arms, where the state of each arm evolves restlessly with different\ntransitions depending on whether that arm is pulled. However, solving RMABs\nrequires information on transition dynamics, which is often not available\nupfront. To plan in RMAB settings with unknown transitions, we propose the\nfirst online learning algorithm based on the Whittle index policy, using an\nupper confidence bound (UCB) approach to learn transition dynamics.\nSpecifically, we formulate a bilinear program to compute the optimistic Whittle\nindex from the confidence bounds in transition dynamics. Our algorithm,\nUCWhittle, achieves sublinear $O(\\sqrt{T \\log T})$ frequentist regret to solve\nRMABs with unknown transitions. Empirically, we demonstrate that UCWhittle\nleverages the structure of RMABs and the Whittle index policy solution to\nachieve better performance than existing online learning baselines across three\ndomains, including on real-world maternal and childcare data aimed at reducing\nmaternal mortality.",
    "descriptor": "",
    "authors": [
      "Kai Wang",
      "Lily Xu",
      "Aparna Taneja",
      "Milind Tambe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15372"
  },
  {
    "id": "arXiv:2205.15376",
    "title": "Reinforcement Learning with a Terminator",
    "abstract": "We present the problem of reinforcement learning with exogenous termination.\nWe define the Termination Markov Decision Process (TerMDP), an extension of the\nMDP framework, in which episodes may be interrupted by an external\nnon-Markovian observer. This formulation accounts for numerous real-world\nsituations, such as a human interrupting an autonomous driving agent for\nreasons of discomfort. We learn the parameters of the TerMDP and leverage the\nstructure of the estimation problem to provide state-wise confidence bounds. We\nuse these to construct a provably-efficient algorithm, which accounts for\ntermination, and bound its regret. Motivated by our theoretical analysis, we\ndesign and implement a scalable approach, which combines optimism (w.r.t.\ntermination) and a dynamic discount factor, incorporating the termination\nprobability. We deploy our method on high-dimensional driving and MinAtar\nbenchmarks. Additionally, we test our approach on human data in a driving\nsetting. Our results demonstrate fast convergence and significant improvement\nover various baseline approaches.",
    "descriptor": "",
    "authors": [
      "Guy Tennenholtz",
      "Nadav Merlis",
      "Lior Shani",
      "Shie Mannor",
      "Uri Shalit",
      "Gal Chechik",
      "Assaf Hallak",
      "Gal Dalal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.15376"
  },
  {
    "id": "arXiv:2205.15379",
    "title": "Truly Deterministic Policy Optimization",
    "abstract": "In this paper, we present a policy gradient method that avoids exploratory\nnoise injection and performs policy search over the deterministic landscape. By\navoiding noise injection all sources of estimation variance can be eliminated\nin systems with deterministic dynamics (up to the initial state distribution).\nSince deterministic policy regularization is impossible using traditional\nnon-metric measures such as the KL divergence, we derive a Wasserstein-based\nquadratic model for our purposes. We state conditions on the system model under\nwhich it is possible to establish a monotonic policy improvement guarantee,\npropose a surrogate function for policy gradient estimation, and show that it\nis possible to compute exact advantage estimates if both the state transition\nmodel and the policy are deterministic. Finally, we describe two novel robotic\ncontrol environments -- one with non-local rewards in the frequency domain and\nthe other with a long horizon (8000 time-steps) -- for which our policy\ngradient method (TDPO) significantly outperforms existing methods (PPO, TRPO,\nDDPG, and TD3). Our implementation with all the experimental settings is\navailable at https://github.com/ehsansaleh/code_tdpo",
    "descriptor": "",
    "authors": [
      "Ehsan Saleh",
      "Saba Ghaffari",
      "Timothy Bretl",
      "Matthew West"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.15379"
  },
  {
    "id": "arXiv:2205.15386",
    "title": "Dictionary Learning with Accumulator Neurons",
    "abstract": "The Locally Competitive Algorithm (LCA) uses local competition between\nnon-spiking leaky integrator neurons to infer sparse representations, allowing\nfor potentially real-time execution on massively parallel neuromorphic\narchitectures such as Intel's Loihi processor. Here, we focus on the problem of\ninferring sparse representations from streaming video using dictionaries of\nspatiotemporal features optimized in an unsupervised manner for sparse\nreconstruction. Non-spiking LCA has previously been used to achieve\nunsupervised learning of spatiotemporal dictionaries composed of convolutional\nkernels from raw, unlabeled video. We demonstrate how unsupervised dictionary\nlearning with spiking LCA (\\hbox{S-LCA}) can be efficiently implemented using\naccumulator neurons, which combine a conventional leaky-integrate-and-fire\n(\\hbox{LIF}) spike generator with an additional state variable that is used to\nminimize the difference between the integrated input and the spiking output. We\ndemonstrate dictionary learning across a wide range of dynamical regimes, from\ngraded to intermittent spiking, for inferring sparse representations of both\nstatic images drawn from the CIFAR database as well as video frames captured\nfrom a DVS camera. On a classification task that requires identification of the\nsuite from a deck of cards being rapidly flipped through as viewed by a DVS\ncamera, we find essentially no degradation in performance as the LCA model used\nto infer sparse spatiotemporal representations migrates from graded to spiking.\nWe conclude that accumulator neurons are likely to provide a powerful enabling\ncomponent of future neuromorphic hardware for implementing online unsupervised\nlearning of spatiotemporal dictionaries optimized for sparse reconstruction of\nstreaming video from event based DVS cameras.",
    "descriptor": "",
    "authors": [
      "Gavin Parpart",
      "Carlos Gonzalez",
      "Terrence C. Stewart",
      "Edward Kim",
      "Jocelyn Rego",
      "Andrew O'Brien",
      "Steven Nesbit",
      "Garrett T. Kenyon",
      "Yijing Watkins"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15386"
  },
  {
    "id": "arXiv:2205.15389",
    "title": "Attention Flows for General Transformers",
    "abstract": "In this paper, we study the computation of how much an input token in a\nTransformer model influences its prediction. We formalize a method to construct\na flow network out of the attention values of encoder-only Transformer models\nand extend it to general Transformer architectures including an auto-regressive\ndecoder. We show that running a maxflow algorithm on the flow network\nconstruction yields Shapley values, which determine the impact of a player in\ncooperative game theory. By interpreting the input tokens in the flow network\nas players, we can compute their influence on the total attention flow leading\nto the decoder's decision. Additionally, we provide a library that computes and\nvisualizes the attention flow of arbitrary Transformer models. We show the\nusefulness of our implementation on various models trained on natural language\nprocessing and reasoning tasks.",
    "descriptor": "",
    "authors": [
      "Niklas Metzger",
      "Christopher Hahn",
      "Julian Siber",
      "Frederik Schmitt",
      "Bernd Finkbeiner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15389"
  },
  {
    "id": "arXiv:2205.15394",
    "title": "Diverse Representation via Computational Participatory Elections --  Lessons from a Case Study",
    "abstract": "Elections are the central institution of democratic processes, and often the\nelected body -- in either public or private governance -- is a committee of\nindividuals. To ensure the legitimacy of elected bodies, the electoral\nprocesses should guarantee that diverse groups are represented, in particular\nmembers of groups that are marginalized due to gender, ethnicity, or other\nsocially salient attributes. To address this challenge of representation, we\nhave designed a novel participatory electoral process coined the Representation\nPact, implemented with the support of a computational system. That process\nexplicitly enables voters to flexibly decide on representation criteria in a\nfirst round, and then lets them vote for candidates in a second round. After\nthe two rounds, a counting method is applied, which selects the committee of\ncandidates that maximizes the number of votes received in the second round,\nconditioned on satisfying the criteria provided in the first round. With the\nhelp of a detailed use case that applied this process in a primary election of\n96 representatives in Switzerland, we explain how this method contributes to\nfairness in political elections by achieving a better \"descriptive\nrepresentation\". Further, based on this use case, we identify lessons learnt\nthat are applicable to participatory computational systems used in societal or\npolitical contexts. Good practices are identified and presented.",
    "descriptor": "",
    "authors": [
      "Florian Ev\u00e9quoz",
      "Johan Rochel",
      "Vijay Keswani",
      "L. Elisa Celis"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2205.15394"
  },
  {
    "id": "arXiv:2205.15397",
    "title": "Minimax Optimal Online Imitation Learning via Replay Estimation",
    "abstract": "Online imitation learning is the problem of how best to mimic expert\ndemonstrations, given access to the environment or an accurate simulator. Prior\nwork has shown that in the infinite sample regime, exact moment matching\nachieves value equivalence to the expert policy. However, in the finite sample\nregime, even if one has no optimization error, empirical variance can lead to a\nperformance gap that scales with $H^2 / N$ for behavioral cloning and $H /\n\\sqrt{N}$ for online moment matching, where $H$ is the horizon and $N$ is the\nsize of the expert dataset. We introduce the technique of replay estimation to\nreduce this empirical variance: by repeatedly executing cached expert actions\nin a stochastic simulator, we compute a smoother expert visitation distribution\nestimate to match. In the presence of general function approximation, we prove\na meta theorem reducing the performance gap of our approach to the parameter\nestimation error for offline classification (i.e. learning the expert policy).\nIn the tabular setting or with linear function approximation, our meta theorem\nshows that the performance gap incurred by our approach achieves the optimal\n$\\widetilde{O} \\left( \\min({H^{3/2}} / {N}, {H} / {\\sqrt{N}} \\right)$\ndependency, under significantly weaker assumptions compared to prior work. We\nimplement multiple instantiations of our approach on several continuous control\ntasks and find that we are able to significantly improve policy performance\nacross a variety of dataset sizes.",
    "descriptor": "",
    "authors": [
      "Gokul Swamy",
      "Nived Rajaraman",
      "Matthew Peng",
      "Sanjiban Choudhury",
      "J. Andrew Bagnell",
      "Zhiwei Steven Wu",
      "Jiantao Jiao",
      "Kannan Ramchandran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.15397"
  },
  {
    "id": "arXiv:2205.15399",
    "title": "Variable-Length Coding for Binary-Input Channels With Limited Stop  Feedback",
    "abstract": "This paper focuses on the numerical evaluation of the maximal achievable rate\nof variable-length stop-feedback (VLSF) codes with $m$ decoding times at a\ngiven message size and error probability for binary-input additive white\nGaussian noise channel, binary symmetric channel, and binary erasure channel\n(BEC). Leveraging the Edgeworth and Petrov expansions, we develop tight\napproximations to the tail probability of length-$n$ cumulative information\ndensity that are accurate for any blocklength $n$. We reduce Yavas \\emph{et\nal.}'s non-asymptotic achievability bound on VLSF codes with $m$ decoding times\nto an integer program of minimizing the upper bound on the average blocklength\nsubject to the average error probability, minimum gap, and integer constraints.\nWe develop two distinct methods to solve this program. Numerical evaluations\nshow that Polyanskiy's achievability bound for VLSF codes, which assumes $m =\n\\infty$, can be approached with a relatively small $m$ in all of the three\nchannels. For BEC, we consider systematic transmission followed by random\nlinear fountain coding. This allows us to obtain a new achievability bound\nstronger than a previously known bound and new VLSF codes whose rate further\noutperforms Polyanskiy's bound.",
    "descriptor": "\nComments: 18 pages, 12 figures; submitted to IEEE Transactions on Information Theory. An earlier version of this work was accepted for presentation at ISIT 2022\n",
    "authors": [
      "Hengjie Yang",
      "Recep Can Yavas",
      "Victoria Kostina",
      "Richard D. Wesel"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.15399"
  },
  {
    "id": "arXiv:2205.15400",
    "title": "Designing Rewards for Fast Learning",
    "abstract": "To convey desired behavior to a Reinforcement Learning (RL) agent, a designer\nmust choose a reward function for the environment, arguably the most important\nknob designers have in interacting with RL agents. Although many reward\nfunctions induce the same optimal behavior (Ng et al., 1999), in practice, some\nof them result in faster learning than others. In this paper, we look at how\nreward-design choices impact learning speed and seek to identify principles of\ngood reward design that quickly induce target behavior. This\nreward-identification problem is framed as an optimization problem: Firstly, we\nadvocate choosing state-based rewards that maximize the action gap, making\noptimal actions easy to distinguish from suboptimal ones. Secondly, we propose\nminimizing a measure of the horizon, something we call the \"subjective\ndiscount\", over which rewards need to be optimized to encourage agents to make\noptimal decisions with less lookahead. To solve this optimization problem, we\npropose a linear-programming based algorithm that efficiently finds a reward\nfunction that maximizes action gap and minimizes subjective discount. We test\nthe rewards generated with the algorithm in tabular environments with\nQ-Learning, and empirically show they lead to faster learning. Although we only\nfocus on Q-Learning because it is perhaps the simplest and most well understood\nRL algorithm, preliminary results with R-max (Brafman and Tennenholtz, 2000)\nsuggest our results are much more general. Our experiments support three\nprinciples of reward design: 1) consistent with existing results, penalizing\neach step taken induces faster learning than rewarding the goal. 2) When\nrewarding subgoals along the target trajectory, rewards should gradually\nincrease as the goal gets closer. 3) Dense reward that's nonzero on every state\nis only good if designed carefully.",
    "descriptor": "\nComments: To appear at the 5th Multidisciplinary Conference on Reinforcement Learning and Decision Making (RLDM2022)\n",
    "authors": [
      "Henry Sowerby",
      "Zhiyuan Zhou",
      "Michael L. Littman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.15400"
  },
  {
    "id": "arXiv:2205.15401",
    "title": "VoGE: A Differentiable Volume Renderer using Gaussian Ellipsoids for  Analysis-by-Synthesis",
    "abstract": "Differentiable rendering allows the application of computer graphics on\nvision tasks, e.g. object pose and shape fitting, via analysis-by-synthesis,\nwhere gradients at occluded regions are important when inverting the rendering\nprocess. To obtain those gradients, state-of-the-art (SoTA) differentiable\nrenderers use rasterization to collect a set of nearest components for each\npixel and aggregate them based on the viewing distance. In this paper, we\npropose VoGE, which uses ray tracing to capture nearest components with their\nvolume density distributions on the rays and aggregates via integral of the\nvolume densities based on Gaussian ellipsoids, which brings more efficient and\nstable gradients. To efficiently render via VoGE, we propose an approximate\nclose-form solution for the volume density aggregation and a coarse-to-fine\nrendering strategy. Finally, we provide a CUDA implementation of VoGE, which\ngives a competitive rendering speed in comparison to PyTorch3D. Quantitative\nand qualitative experiment results show VoGE outperforms SoTA counterparts when\napplied to various vision tasks,e.g., object pose estimation, shape/texture\nfitting, and occlusion reasoning. The VoGE library and demos are available at\nhttps://github.com/Angtian/VoGE.",
    "descriptor": "",
    "authors": [
      "Angtian Wang",
      "Peng Wang",
      "Jian Sun",
      "Adam Kortylewski",
      "Alan Yuille"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15401"
  },
  {
    "id": "arXiv:2205.15403",
    "title": "Neural Optimal Transport with General Cost Functionals",
    "abstract": "We present a novel neural-networks-based algorithm to compute optimal\ntransport (OT) plans and maps for general cost functionals. The algorithm is\nbased on a saddle point reformulation of the OT problem and generalizes prior\nOT methods for weak and strong cost functionals. As an application, we\nconstruct a functional to map data distributions with preserving the class-wise\nstructure of data.",
    "descriptor": "",
    "authors": [
      "Arip Asadulaev",
      "Alexander Korotin",
      "Vage Egiazarian",
      "Evgeny Burnaev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15403"
  },
  {
    "id": "arXiv:2205.15404",
    "title": "Gator: Customizable Channel Pruning of Neural Networks with Gating",
    "abstract": "The rise of neural network (NN) applications has prompted an increased\ninterest in compression, with a particular focus on channel pruning, which does\nnot require any additional hardware. Most pruning methods employ either\nsingle-layer operations or global schemes to determine which channels to remove\nfollowed by fine-tuning of the network. In this paper we present Gator, a\nchannel-pruning method which temporarily adds learned gating mechanisms for\npruning of individual channels, and which is trained with an additional\nauxiliary loss, aimed at reducing the computational cost due to memory,\n(theoretical) speedup (in terms of FLOPs), and practical, hardware-specific\nspeedup. Gator introduces a new formulation of dependencies between NN layers\nwhich, in contrast to most previous methods, enables pruning of non-sequential\nparts, such as layers on ResNet's highway, and even removing entire ResNet\nblocks. Gator's pruning for ResNet-50 trained on ImageNet produces\nstate-of-the-art (SOTA) results, such as 50% FLOPs reduction with only\n0.4%-drop in top-5 accuracy. Also, Gator outperforms previous pruning models,\nin terms of GPU latency by running 1.4 times faster. Furthermore, Gator\nachieves improved top-5 accuracy results, compared to MobileNetV2 and\nSqueezeNet, for similar runtimes. The source code of this work is available at:\nhttps://github.com/EliPassov/gator.",
    "descriptor": "\nComments: 14 pages, 3 figures. The version that appeared in ICANN is an earlier version\n",
    "authors": [
      "Eli Passov",
      "Eli O. David",
      "Nathan S. Netanyahu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15404"
  },
  {
    "id": "arXiv:2205.15406",
    "title": "From Explanation to Recommendation: Ethical Standards for Algorithmic  Recourse",
    "abstract": "People are increasingly subject to algorithmic decisions, and it is generally\nagreed that end-users should be provided an explanation or rationale for these\ndecisions. There are different purposes that explanations can have, such as\nincreasing user trust in the system or allowing users to contest the decision.\nOne specific purpose that is gaining more traction is algorithmic recourse. We\nfirst propose that recourse should be viewed as a recommendation problem, not\nan explanation problem. Then, we argue that the capability approach provides\nplausible and fruitful ethical standards for recourse. We illustrate by\nconsidering the case of diversity constraints on algorithmic recourse. Finally,\nwe discuss the significance and implications of adopting the capability\napproach for algorithmic recourse research.",
    "descriptor": "\nComments: 11 pages, 3 figures, to be published in Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society\n",
    "authors": [
      "Emily Sullivan",
      "Philippe Verreault-Julien"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2205.15406"
  },
  {
    "id": "arXiv:2205.15407",
    "title": "Grid HTM: Hierarchical Temporal Memory for Anomaly Detection in Videos",
    "abstract": "The interest for video anomaly detection systems has gained traction for the\npast few years. The current approaches use deep learning to perform anomaly\ndetection in videos, but this approach has multiple problems. For starters,\ndeep learning in general has issues with noise, concept drift, explainability,\nand training data volumes. Additionally, anomaly detection in itself is a\ncomplex task and faces challenges such as unknowness, heterogeneity, and class\nimbalance. Anomaly detection using deep learning is therefore mainly\nconstrained to generative models such as generative adversarial networks and\nautoencoders due to their unsupervised nature, but even they suffer from\ngeneral deep learning issues and are hard to train properly. In this paper, we\nexplore the capabilities of the Hierarchical Temporal Memory (HTM) algorithm to\nperform anomaly detection in videos, as it has favorable properties such as\nnoise tolerance and online learning which combats concept drift. We introduce a\nnovel version of HTM, namely, Grid HTM, which is an HTM-based architecture\nspecifically for anomaly detection in complex videos such as surveillance\nfootage.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Vladimir Monakhov",
      "Vajira Thambawita",
      "P\u00e5l Halvorsen",
      "Michael A. Riegler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15407"
  },
  {
    "id": "arXiv:2205.15409",
    "title": "Painful intelligence: What AI can tell us about human suffering",
    "abstract": "This book uses the modern theory of artificial intelligence (AI) to\nunderstand human suffering or mental pain. Both humans and sophisticated AI\nagents process information about the world in order to achieve goals and obtain\nrewards, which is why AI can be used as a model of the human brain and mind.\nThis book intends to make the theory accessible to a relatively general\naudience, requiring only some relevant scientific background. The book starts\nwith the assumption that suffering is mainly caused by frustration. Frustration\nmeans the failure of an agent (whether AI or human) to achieve a goal or a\nreward it wanted or expected. Frustration is inevitable because of the\noverwhelming complexity of the world, limited computational resources, and\nscarcity of good data. In particular, such limitations imply that an agent\nacting in the real world must cope with uncontrollability, unpredictability,\nand uncertainty, which all lead to frustration. Fundamental in such modelling\nis the idea of learning, or adaptation to the environment. While AI uses\nmachine learning, humans and animals adapt by a combination of evolutionary\nmechanisms and ordinary learning. Even frustration is fundamentally an error\nsignal that the system uses for learning. This book explores various aspects\nand limitations of learning algorithms and their implications regarding\nsuffering. At the end of the book, the computational theory is used to derive\nvarious interventions or training methods that will reduce suffering in humans.\nThe amount of frustration is expressed by a simple equation which indicates how\nit can be reduced. The ensuing interventions are very similar to those proposed\nby Buddhist and Stoic philosophy, and include mindfulness meditation.\nTherefore, this book can be interpreted as an exposition of a computational\ntheory justifying why such philosophies and meditation reduce human suffering.",
    "descriptor": "\nComments: Book with 231 pages\n",
    "authors": [
      "Aapo Hyv\u00e4rinen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2205.15409"
  },
  {
    "id": "arXiv:2205.15410",
    "title": "LiDAR-aid Inertial Poser: Large-scale Human Motion Capture by Sparse  Inertial and LiDAR Sensors",
    "abstract": "We propose a multi-sensor fusion method for capturing challenging 3D human\nmotions with accurate consecutive local poses and global trajectories in\nlarge-scale scenarios, only using a single LiDAR and 4 IMUs. Specifically, to\nfully utilize the global geometry information captured by LiDAR and local\ndynamic motions captured by IMUs, we design a two-stage pose estimator in a\ncoarse-to-fine manner, where point clouds provide the coarse body shape and IMU\nmeasurements optimize the local actions. Furthermore, considering the\ntranslation deviation caused by the view-dependent partial point cloud, we\npropose a pose-guided translation corrector. It predicts the offset between\ncaptured points and the real root locations, which makes the consecutive\nmovements and trajectories more precise and natural. Extensive quantitative and\nqualitative experiments demonstrate the capability of our approach for\ncompelling motion capture in large-scale scenarios, which outperforms other\nmethods by an obvious margin. We will release our code and captured dataset to\nstimulate future research.",
    "descriptor": "",
    "authors": [
      "Chengfeng Zhao",
      "Yiming Ren",
      "Yannan He",
      "Peishan Cong",
      "Han Liang",
      "Jingyi Yu",
      "Lan Xu",
      "Yuexin Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15410"
  },
  {
    "id": "arXiv:2205.15412",
    "title": "Asynchronous Deterministic Leader Election in Three-Dimensional  Programmable Matter",
    "abstract": "Over three decades of scientific endeavors to realize programmable matter, a\nsubstance that can change its physical properties based on user input or\nresponses to its environment, there have been many advances in both the\nengineering of modular robotic systems and the corresponding algorithmic theory\nof collective behavior. However, while the design of modular robots routinely\naddresses the challenges of realistic three-dimensional (3D) space, algorithmic\ntheory remains largely focused on 2D abstractions such as planes and planar\ngraphs. In this work, we present the 3D geometric space variant for the\nwell-established amoebot model of programmable matter, using the face-centered\ncubic (FCC) lattice to represent space and define local spatial orientations.\nWe then give a distributed algorithm for the classical problem of leader\nelection that can be applied to 2D or 3D geometric amoebot systems, proving\nthat it deterministically elects exactly one leader in $\\mathcal{O}(n)$ rounds\nunder an unfair sequential adversary, where $n$ is the number of amoebots in\nthe system. We conclude by demonstrating how this algorithm can be transformed\nusing the concurrency control framework for amoebot algorithms (DISC 2021) to\nobtain the first known amoebot algorithm, both in 2D and 3D space, to solve\nleader election under an unfair asynchronous adversary.",
    "descriptor": "\nComments: 16 pages, 4 figures, 2 tables\n",
    "authors": [
      "Joseph L. Briones",
      "Tishya Chhabra",
      "Joshua J. Daymude",
      "Andr\u00e9a W. Richa"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.15412"
  },
  {
    "id": "arXiv:2205.15414",
    "title": "A portfolio-based analysis method for competition results",
    "abstract": "Competitions such as the MiniZinc Challenges or the SAT competitions have\nbeen very useful sources for comparing performance of different solving\napproaches and for advancing the state-of-the-arts of the fields. Traditional\ncompetition setting often focuses on producing a ranking between solvers based\non their average performance across a wide range of benchmark problems and\ninstances. While this is a sensible way to assess the relative performance of\nsolvers, such ranking does not necessarily reflect the full potential of a\nsolver, especially when we want to utilise a portfolio of solvers instead of a\nsingle one for solving a new problem. In this paper, I will describe a\nportfolio-based analysis method which can give complementary insights into the\nperformance of participating solvers in a competition. The method is\ndemonstrated on the results of the MiniZinc Challenges and new insights gained\nfrom the portfolio viewpoint are presented.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Nguyen Dang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.15414"
  },
  {
    "id": "arXiv:2205.15416",
    "title": "Distributed Ledger Technology based Integrated Healthcare Solution for  Bangladesh",
    "abstract": "Healthcare data is sensitive and requires great protection. Encrypted\nelectronic health records (EHRs) contain personal and sensitive data such as\nnames and addresses. Having access to patient data benefits all of them. This\npaper proposes a blockchain-based distributed healthcare application platform\nfor Bangladeshi public and private healthcare providers. Using data\nimmutability and smart contracts, the suggested application framework allows\nusers to create safe digital agreements for commerce or collaboration. Thus,\nall enterprises may securely collaborate using the same blockchain network,\ngaining data openness and read/write capacity. The proposed application\nconsists of various application interfaces for various system users. For data\nintegrity, privacy, permission and service availability, the proposed solution\nleverages Hyperledger fabric and Blockchain as a Service. Everyone will also\nhave their own profile in the portal. A unique identity for each person and the\ninstallation of digital information centres across the country have greatly\neased the process. It will collect systematic health data from each person\nwhich will be beneficial for research institutes and health-related\norganisations. A national data warehouse in Bangladesh is feasible for this\napplication and It is also possible to keep a clean health sector by analysing\ndata stored in this warehouse and conducting various purification algorithms\nusing technologies like Data Science. Given that Bangladesh has both public and\nprivate health care, a straightforward digital strategy for all organisations\nis essential.",
    "descriptor": "\nComments: 21 pages, 16 figures, 4 tables\n",
    "authors": [
      "Md. Ariful Islam",
      "Md. Antonin Islam",
      "Md. Amzad Hossain Jacky",
      "Md. Al-Amin",
      "M. Saef Ullah Miah",
      "Md Muhidul Islam Khan",
      "Md. Iqbal Hossain"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2205.15416"
  },
  {
    "id": "arXiv:2205.15419",
    "title": "Fooling SHAP with Stealthily Biased Sampling",
    "abstract": "SHAP explanations aim at identifying which features contribute the most to\nthe difference in model prediction at a specific input versus a background\ndistribution. Recent studies have shown that they can be manipulated by\nmalicious adversaries to produce arbitrary desired explanations. However,\nexisting attacks focus solely on altering the black-box model itself. In this\npaper, we propose a complementary family of attacks that leave the model intact\nand manipulate SHAP explanations using stealthily biased sampling of the data\npoints used to approximate expectations w.r.t the background distribution. In\nthe context of fairness audit, we show that our attack can reduce the\nimportance of a sensitive feature when explaining the difference in outcomes\nbetween groups, while remaining undetected. These results highlight the\nmanipulability of SHAP explanations and encourage auditors to treat post-hoc\nexplanations with skepticism.",
    "descriptor": "",
    "authors": [
      "Gabriel Laberge",
      "Ulrich A\u00efvodji",
      "Satoshi Hara"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15419"
  },
  {
    "id": "arXiv:2205.15424",
    "title": "Connecting adversarial attacks and optimal transport for domain  adaptation",
    "abstract": "We present a novel algorithm for domain adaptation using optimal transport.\nIn domain adaptation, the goal is to adapt a classifier trained on the source\ndomain samples to the target domain. In our method, we use optimal transport to\nmap target samples to the domain named source fiction. This domain differs from\nthe source but is accurately classified by the source domain classifier. Our\nmain idea is to generate a source fiction by c-cyclically monotone\ntransformation over the target domain. If samples with the same labels in two\ndomains are c-cyclically monotone, the optimal transport map between these\ndomains preserves the class-wise structure, which is the main goal of domain\nadaptation. To generate a source fiction domain, we propose an algorithm that\nis based on our finding that adversarial attacks are a c-cyclically monotone\ntransformation of the dataset. We conduct experiments on Digits and Modern\nOffice-31 datasets and achieve improvement in performance for simple discrete\noptimal transport solvers for all adaptation tasks.",
    "descriptor": "",
    "authors": [
      "Arip Asadulaev",
      "Vitaly Shutov",
      "Alexander Korotin",
      "Alexander Panfilov",
      "Andrey Filchenkov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15424"
  },
  {
    "id": "arXiv:2205.15425",
    "title": "Edge coloring of graphs of signed class 1 and 2",
    "abstract": "Recently, Behr introduced a notion of the chromatic index of signed graphs\nand proved that for every signed graph $(G$, $\\sigma)$ it holds that \\[\n\\Delta(G)\\leq\\chi'(G\\text{, }\\sigma)\\leq\\Delta(G)+1\\text{,} \\] where\n$\\Delta(G)$ is the maximum degree of $G$ and $\\chi'$ denotes its chromatic\nindex.\nIn general, the chromatic index of $(G$, $\\sigma)$ depends on both the\nunderlying graph $G$ and the signature $\\sigma$. In the paper we study graphs\n$G$ for which $\\chi'(G$, $\\sigma)$ does not depend on $\\sigma$. To this aim we\nintroduce two new classes of graphs, namely $1^\\pm$ and $2^\\pm$, such that\ngraph $G$ is of class $1^\\pm$ (respectively, $2^\\pm$) if and only if $\\chi'(G$,\n$\\sigma)=\\Delta(G)$ (respectively, $\\chi'(G$, $\\sigma)=\\Delta(G)+1$) for all\npossible signatures $\\sigma$. We prove that all wheels, necklaces, complete\nbipartite graphs $K_{r,t}$ with $r\\neq t$ and almost all cacti graphs are of\nclass $1^\\pm$. Moreover, we give sufficient and necessary conditions for a\ngraph to be of class $2^\\pm$, i.e. we show that these graphs must have odd\nmaximum degree and give examples of such graphs with arbitrary odd maximum\ndegree bigger that $1$.",
    "descriptor": "",
    "authors": [
      "Robert Janczewski",
      "Krzysztof Turowski",
      "Bart\u0142omiej Wr\u00f3blewski"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2205.15425"
  },
  {
    "id": "arXiv:2205.15426",
    "title": "Fitting and recognition of geometric primitives in segmented 3D point  clouds using a localized voting procedure",
    "abstract": "The automatic creation of geometric models from point clouds has numerous\napplications in CAD (e.g., reverse engineering, manufacturing, assembling) and,\nmore in general, in shape modelling and processing. Given a segmented point\ncloud representing a man-made object, we propose a method for recognizing\nsimple geometric primitives and their interrelationships. Our approach is based\non the Hough transform (HT) for its ability to deal with noise, missing parts\nand outliers. In our method we introduce a novel technique for processing\nsegmented point clouds that, through a voting procedure, is able to provide an\ninitial estimate of the geometric parameters characterizing each primitive\ntype. By using these estimates, we localize the search of the optimal solution\nin a dimensionally-reduced parameter space thus making it efficient to extend\nthe HT to more primitives than those that are generally found in the\nliterature, i.e. planes and spheres. Then, we extract a number of geometric\ndescriptors that uniquely characterize a segment, and, on the basis of these\ndescriptors, we show how to aggregate parts of primitives (segments).\nExperiments on both synthetic and industrial scans reveal the robustness of the\nprimitive fitting method and its effectiveness for inferring relations among\nsegments.",
    "descriptor": "",
    "authors": [
      "Andrea Raffo",
      "Chiara Romanengo",
      "Bianca Falcidieno",
      "Silvia Biasotti"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computational Geometry (cs.CG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.15426"
  },
  {
    "id": "arXiv:2205.15428",
    "title": "Segmentation Consistency Training: Out-of-Distribution Generalization  for Medical Image Segmentation",
    "abstract": "Generalizability is seen as one of the major challenges in deep learning, in\nparticular in the domain of medical imaging, where a change of hospital or in\nimaging routines can lead to a complete failure of a model. To tackle this, we\nintroduce Consistency Training, a training procedure and alternative to data\naugmentation based on maximizing models' prediction consistency across\naugmented and unaugmented data in order to facilitate better\nout-of-distribution generalization. To this end, we develop a novel\nregion-based segmentation loss function called Segmentation Inconsistency Loss\n(SIL), which considers the differences between pairs of augmented and\nunaugmented predictions and labels. We demonstrate that Consistency Training\noutperforms conventional data augmentation on several out-of-distribution\ndatasets on polyp segmentation, a popular medical task.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Birk Torpmann-Hagen",
      "Vajira Thambawita",
      "Kyrre Glette",
      "P\u00e5l Halvorsen",
      "Michael A. Riegler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15428"
  },
  {
    "id": "arXiv:2205.15430",
    "title": "Eigenvalue Bounds for Saddle-Point Systems with Singular Leading Blocks",
    "abstract": "We derive bounds on the eigenvalues of saddle-point matrices with singular\nleading blocks. The technique of proof is based on augmentation. Our bounds\ndepend on the principal angles between the ranges or kernels of the matrix\nblocks. Numerical experiments validate our analytical findings.",
    "descriptor": "",
    "authors": [
      "Susanne Bradley",
      "Chen Greif"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.15430"
  },
  {
    "id": "arXiv:2205.15434",
    "title": "Learning Risk-Averse Equilibria in Multi-Agent Systems",
    "abstract": "In multi-agent systems, intelligent agents are tasked with making decisions\nthat have optimal outcomes when the actions of the other agents are as\nexpected, whilst also being prepared for unexpected behaviour. In this work, we\nintroduce a new risk-averse solution concept that allows the learner to\naccommodate unexpected actions by finding the minimum variance strategy given\nany level of expected return. We prove the existence of such a risk-averse\nequilibrium, and propose one fictitious-play type learning algorithm for\nsmaller games that enjoys provable convergence guarantees in certain games\nclasses (e.g., zero-sum or potential). Furthermore, we propose an approximation\nmethod for larger games based on iterative population-based training that\ngenerates a population of risk-averse agents. Empirically, our equilibrium is\nshown to be able to reduce the reward variance, specifically in the sense that\noff-equilibrium behaviour has a far smaller impact on our risk-averse agents in\ncomparison to playing other equilibrium solutions. Importantly, we show that\nour population of agents that approximate a risk-averse equilibrium is\nparticularly effective in the presence of unseen opposing populations,\nespecially in the case of guaranteeing a minimal level of performance which is\ncritical to safety-aware multi-agent systems.",
    "descriptor": "",
    "authors": [
      "Oliver Slumbers",
      "David Henry Mguni",
      "Stephen McAleer",
      "Jun Wang",
      "Yaodong Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2205.15434"
  },
  {
    "id": "arXiv:2205.15436",
    "title": "Fairness in the First Stage of Two-Stage Recommender Systems",
    "abstract": "Many large-scale recommender systems consist of two stages, where the first\nstage focuses on efficiently generating a small subset of promising candidates\nfrom a huge pool of items for the second-stage model to curate final\nrecommendations from. In this paper, we investigate how to ensure groups\nfairness to the items in this two-stage paradigm. In particular, we find that\nexisting first-stage recommenders might select an irrecoverably unfair set of\ncandidates such that there is no hope for the second-stage recommender to\ndeliver fair recommendations. To this end, we propose two threshold-policy\nselection rules that, given any relevance model of queries and items and a\npoint-wise lower confidence bound on the expected number of relevant items for\neach policy, find near-optimal sets of candidates that contain enough relevant\nitems in expectation from each group of items. To instantiate the rules, we\ndemonstrate how to derive such confidence bounds from potentially partial and\nbiased user feedback data, which are abundant in many large-scale recommender\nsystems. In addition, we provide both finite-sample and asymptotic analysis of\nhow close the two threshold selection rules are to the optimal thresholds.\nBeyond this theoretical analysis, we show empirically that these two rules can\nconsistently select enough relevant items from each group while minimizing the\nsize of the candidate sets for a wide range of settings.",
    "descriptor": "",
    "authors": [
      "Lequn Wang",
      "Thorsten Joachims"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15436"
  },
  {
    "id": "arXiv:2205.15437",
    "title": "FBM: Fast-Bit Allocation for Mixed-Precision Quantization",
    "abstract": "Quantized neural networks are well known for reducing latency, power\nconsumption, and model size without significant degradation in accuracy, making\nthem highly applicable for systems with limited resources and low power\nrequirements.\nMixed precision quantization offers better utilization of customized hardware\nthat supports arithmetic operations at different bitwidths. Existing\nmixed-precision schemes rely on having a high exploration space, resulting in a\nlarge carbon footprint. In addition, these bit allocation strategies mostly\ninduce constraints on the model size rather than utilizing the performance of\nneural network deployment on specific hardware. Our work proposes Fast-Bit\nAllocation for Mixed-Precision Quantization (FBM), which finds an optimal\nbitwidth allocation by measuring desired behaviors through a simulation of a\nspecific device, or even on a physical one.\nWhile dynamic transitions of bit allocation in mixed precision quantization\nwith ultra-low bitwidth are known to suffer from performance degradation, we\npresent a fast recovery solution from such transitions.\nA comprehensive evaluation of the proposed method on CIFAR-10 and ImageNet\ndemonstrates our method's superiority over current state-of-the-art schemes in\nterms of the trade-off between neural network accuracy and hardware efficiency.\nOur source code, experimental settings and quantized models are available at\nhttps://github.com/RamorayDrake/FBM/",
    "descriptor": "",
    "authors": [
      "Moshe Kimhi",
      "Tal Rozen",
      "Tal Kopetz",
      "Olya Sirkin",
      "Avi Mendelson",
      "Chaim Baskin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15437"
  },
  {
    "id": "arXiv:2205.15442",
    "title": "Exploring Advances in Transformers and CNN for Skin Lesion Diagnosis on  Small Datasets",
    "abstract": "Skin cancer is one of the most common types of cancer in the world. Different\ncomputer-aided diagnosis systems have been proposed to tackle skin lesion\ndiagnosis, most of them based in deep convolutional neural networks. However,\nrecent advances in computer vision achieved state-of-art results in many tasks,\nnotably Transformer-based networks. We explore and evaluate advances in\ncomputer vision architectures, training methods and multimodal feature fusion\nfor skin lesion diagnosis task. Experiments show that PiT ($0.800 \\pm 0.006$),\nCoaT ($0.780 \\pm 0.024$) and ViT ($0.771 \\pm 0.018$) backbone models with\nMetaBlock fusion achieved state-of-art results for balanced accuracy metric in\nPAD-UFES-20 dataset.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Leandro M. de Lima",
      "Renato A. Krohling"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15442"
  },
  {
    "id": "arXiv:2205.15443",
    "title": "Dynamic Walking with Footstep Adaptation on the MIT Humanoid via Linear  Model Predictive Control",
    "abstract": "This paper proposes a model predictive control (MPC) framework for realizing\ndynamic walking gaits on the MIT Humanoid. In addition to adapting footstep\nlocation and timing online, the proposed method can reason about varying\nheight, contact wrench, torso rotation, kinematic limit and negotiating uneven\nterrains. Specifically, a linear MPC (LMPC) optimizes for the desired footstep\nlocation by linearizing the single rigid body dynamics with respect to the\ncurrent footstep location. A low-level task-space controller tracks the\npredicted state and control trajectories from the LMPC to leverage the\nfull-body dynamics. Finally, an adaptive gait frequency scheme is employed to\nmodify the step frequency and enhance the robustness of the walking controller.\nBoth LMPC and task-space control can be efficiently solved as quadratic\nprograms (QP), and thus amenable for real-time applications. Simulation studies\nwhere the MIT Humanoid traverses a wave field and recovers from impulsive\ndisturbances validated the proposed approach.",
    "descriptor": "",
    "authors": [
      "Yanran Ding",
      "Charles Khazoom",
      "Matthew Chignoli",
      "Sangbae Kim"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.15443"
  },
  {
    "id": "arXiv:2205.15444",
    "title": "Integrity Authentication in Tree Models",
    "abstract": "Tree models are very widely used in practice of machine learning and data\nmining. In this paper, we study the problem of model integrity authentication\nin tree models. In general, the task of model integrity authentication is the\ndesign \\& implementation of mechanisms for checking/detecting whether the model\ndeployed for the end-users has been tampered with or compromised, e.g.,\nmalicious modifications on the model. We propose an authentication framework\nthat enables the model builders/distributors to embed a signature to the tree\nmodel and authenticate the existence of the signature by only making a small\nnumber of black-box queries to the model. To the best of our knowledge, this is\nthe first study of signature embedding on tree models. Our proposed method\nsimply locates a collection of leaves and modifies their prediction values,\nwhich does not require any training/testing data nor any re-training. The\nexperiments on a large number of public classification datasets confirm that\nthe proposed signature embedding process has a high success rate while only\nintroducing a minimal prediction accuracy loss.",
    "descriptor": "",
    "authors": [
      "Weijie Zhao",
      "Yingjie Lao",
      "Ping Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.15444"
  },
  {
    "id": "arXiv:2205.15445",
    "title": "Continual Object Detection: A review of definitions, strategies, and  challenges",
    "abstract": "The field of Continual Learning investigates the ability to learn consecutive\ntasks without losing performance on those previously learned. Its focus has\nbeen mainly on incremental classification tasks. We believe that research in\ncontinual object detection deserves even more attention due to its vast range\nof applications in robotics and autonomous vehicles. This scenario is more\ncomplex than conventional classification given the occurrence of instances of\nclasses that are unknown at the time, but can appear in subsequent tasks as a\nnew class to be learned, resulting in missing annotations and conflicts with\nthe background label. In this review, we analyze the current strategies\nproposed to tackle the problem of class-incremental object detection. Our main\ncontributions are: (1) a short and systematic review of the methods that\npropose solutions to traditional incremental object detection scenarios; (2) A\ncomprehensive evaluation of the existing approaches using a new metric to\nquantify the stability and plasticity of each technique in a standard way; (3)\nan overview of the current trends within continual object detection and a\ndiscussion of possible future research directions.",
    "descriptor": "",
    "authors": [
      "Angelo G. Menezes",
      "Gustavo de Moura",
      "C\u00e9zanne Alves",
      "Andr\u00e9 C. P. L. F. de Carvalho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.15445"
  },
  {
    "id": "arXiv:2205.15448",
    "title": "HeatER: An Efficient and Unified Network for Human Reconstruction via  Heatmap-based TransformER",
    "abstract": "Recently, vision transformers have shown great success in 2D human pose\nestimation (2D HPE), 3D human pose estimation (3D HPE), and human mesh\nreconstruction (HMR) tasks. In these tasks, heatmap representations of the\nhuman structural information are often extracted first from the image by a CNN,\nand then further processed with a transformer architecture to provide the final\nHPE or HMR estimation. However, existing transformer architectures are not able\nto process these heatmap inputs directly, forcing an unnatural flattening of\nthe features prior to input. Furthermore, much of the performance benefit in\nrecent HPE and HMR methods has come at the cost of ever-increasing computation\nand memory needs. Therefore, to simultaneously address these problems, we\npropose HeatER, a novel transformer design which preserves the inherent\nstructure of heatmap representations when modeling attention while reducing the\nmemory and computational costs. Taking advantage of HeatER, we build a unified\nand efficient network for 2D HPE, 3D HPE, and HMR tasks. A heatmap\nreconstruction module is applied to improve the robustness of the estimated\nhuman pose and mesh. Extensive experiments demonstrate the effectiveness of\nHeatER on various human pose and mesh datasets. For instance, HeatER\noutperforms the SOTA method MeshGraphormer by requiring 5% of Params and 16% of\nMACs on Human3.6M and 3DPW datasets. Code will be publicly available.",
    "descriptor": "",
    "authors": [
      "Ce Zheng",
      "Matias Mendieta",
      "Taojiannan Yang",
      "Chen Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2205.15448"
  },
  {
    "id": "arXiv:2205.15449",
    "title": "Posterior and Computational Uncertainty in Gaussian Processes",
    "abstract": "Gaussian processes scale prohibitively with the size of the dataset. In\nresponse, many approximation methods have been developed, which inevitably\nintroduce approximation error. This additional source of uncertainty, due to\nlimited computation, is entirely ignored when using the approximate posterior.\nTherefore in practice, GP models are often as much about the approximation\nmethod as they are about the data. Here, we develop a new class of methods that\nprovides consistent estimation of the combined uncertainty arising from both\nthe finite number of data observed and the finite amount of computation\nexpended. The most common GP approximations map to an instance in this class,\nsuch as methods based on the Cholesky factorization, conjugate gradients, and\ninducing points. For any method in this class, we prove (i) convergence of its\nposterior mean in the associated RKHS, (ii) decomposability of its combined\nposterior covariance into mathematical and computational covariances, and (iii)\nthat the combined variance is a tight worst-case bound for the squared error\nbetween the method's posterior mean and the latent function. Finally, we\nempirically demonstrate the consequences of ignoring computational uncertainty\nand show how implicitly modeling it improves generalization performance on\nbenchmark datasets.",
    "descriptor": "",
    "authors": [
      "Jonathan Wenger",
      "Geoff Pleiss",
      "Marvin Pf\u00f6rtner",
      "Philipp Hennig",
      "John P. Cunningham"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.15449"
  },
  {
    "id": "arXiv:2205.15452",
    "title": "MVMO: A Multi-Object Dataset for Wide Baseline Multi-View Semantic  Segmentation",
    "abstract": "We present MVMO (Multi-View, Multi-Object dataset): a synthetic dataset of\n116,000 scenes containing randomly placed objects of 10 distinct classes and\ncaptured from 25 camera locations in the upper hemisphere. MVMO comprises\nphotorealistic, path-traced image renders, together with semantic segmentation\nground truth for every view. Unlike existing multi-view datasets, MVMO features\nwide baselines between cameras and high density of objects, which lead to large\ndisparities, heavy occlusions and view-dependent object appearance. Single view\nsemantic segmentation is hindered by self and inter-object occlusions that\ncould benefit from additional viewpoints. Therefore, we expect that MVMO will\npropel research in multi-view semantic segmentation and cross-view semantic\ntransfer. We also provide baselines that show that new research is needed in\nsuch fields to exploit the complementary information of multi-view setups.",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Aitor Alvarez-Gila",
      "Joost van de Weijer",
      "Yaxing Wang",
      "Estibaliz Garrote"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15452"
  },
  {
    "id": "arXiv:2205.15455",
    "title": "GLDQN: Explicitly Parameterized Quantile Reinforcement Learning for  Waste Reduction",
    "abstract": "We study the problem of restocking a grocery store's inventory with\nperishable items over time, from a distributional point of view. The objective\nis to maximize sales while minimizing waste, with uncertainty about the actual\nconsumption by costumers. This problem is of a high relevance today, given the\ngrowing demand for food and the impact of food waste on the environment, the\neconomy, and purchasing power. We frame inventory restocking as a new\nreinforcement learning task that exhibits stochastic behavior conditioned on\nthe agent's actions, making the environment partially observable. We introduce\na new reinforcement learning environment based on real grocery store data and\nexpert knowledge. This environment is highly stochastic, and presents a unique\nchallenge for reinforcement learning practitioners. We show that uncertainty\nabout the future behavior of the environment is not handled well by classical\nsupply chain algorithms, and that distributional approaches are a good way to\naccount for the uncertainty. We also present GLDQN, a new distributional\nreinforcement learning algorithm that learns a generalized lambda distribution\nover the reward space. We show that GLDQN outperforms other distributional\nreinforcement learning approaches in our partially observable environments, in\nboth overall reward and generated waste.",
    "descriptor": "\nComments: 10 pages, 1 figure, 2 tables\n",
    "authors": [
      "Sami Jullien",
      "Mozhdeh Ariannezhad",
      "Paul Groth",
      "Maarten de Rijke"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.15455"
  },
  {
    "id": "arXiv:2205.15456",
    "title": "Registering Image Volumes using 3D SIFT and Discrete SP-Symmetry",
    "abstract": "This paper proposes to extend local image features in 3D to include\ninvariance to discrete symmetry including inversion of spatial axes and image\ncontrast. A binary feature sign $s \\in \\{-1,+1\\}$ is defined as the sign of the\nLaplacian operator $\\nabla^2$, and used to obtain a descriptor that is\ninvariant to image sign inversion $s \\rightarrow -s$ and 3D parity transforms\n$(x,y,z)\\rightarrow(-x,-y,-z)$, i.e. SP-invariant or SP-symmetric. SP-symmetry\napplies to arbitrary scalar image fields $I: R^3 \\rightarrow R^1$ mapping 3D\ncoordinates $(x,y,z) \\in R^3$ to scalar intensity $I(x,y,z) \\in R^1$,\ngeneralizing the well-known charge conjugation and parity symmetry\n(CP-symmetry) applying to elementary charged particles. Feature orientation is\nmodeled as a set of discrete states corresponding to potential axis\nreflections, independently of image contrast inversion. Two primary axis\nvectors are derived from image observations and potentially subject to\nreflection, and a third axis is an axial vector defined by the right-hand rule.\nAugmenting local feature properties with sign in addition to standard\n(location, scale, orientation) geometry leads to descriptors that are invariant\nto coordinate reflections and intensity contrast inversion. Feature properties\nare factored in to probabilistic point-based registration as symmetric kernels,\nbased on a model of binary feature correspondence. Experiments using the\nwell-known coherent point drift (CPD) algorithm demonstrate that SIFT-CPD\nkernels achieve the most accurate and rapid registration of the human brain and\nCT chest, including multiple MRI modalities of differing intensity contrast,\nand abnormal local variations such as tumors or occlusions. SIFT-CPD image\nregistration is invariant to global scaling, rotation and translation and image\nintensity inversions of the input data.",
    "descriptor": "\nComments: 12 pages, 9 figures\n",
    "authors": [
      "Laurent Chauvin",
      "William Wells III",
      "Matthew Toews"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15456"
  },
  {
    "id": "arXiv:2205.15462",
    "title": "A Unifying Framework for Causal Explanation of Sequential Decision  Making",
    "abstract": "We present a novel framework for causal explanations of stochastic,\nsequential decision-making systems. Building on the well-studied structural\ncausal model paradigm for causal reasoning, we show how to identify\nsemantically distinct types of explanations for agent actions using a single\nunified approach. We provide results on the generality of this framework, run\ntime bounds, and offer several approximate techniques. Finally, we discuss\nseveral qualitative scenarios that illustrate the framework's flexibility and\nefficacy.",
    "descriptor": "\nComments: 9 pages, 4 figures, conference\n",
    "authors": [
      "Samer B. Nashed",
      "Saaduddin Mahmud",
      "Claudia V. Goldman",
      "Shlomo Zilberstein"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2205.15462"
  },
  {
    "id": "arXiv:2205.15463",
    "title": "Few-Shot Diffusion Models",
    "abstract": "Denoising diffusion probabilistic models (DDPM) are powerful hierarchical\nlatent variable models with remarkable sample generation quality and training\nstability. These properties can be attributed to parameter sharing in the\ngenerative hierarchy, as well as a parameter-free diffusion-based inference\nprocedure. In this paper, we present Few-Shot Diffusion Models (FSDM), a\nframework for few-shot generation leveraging conditional DDPMs. FSDMs are\ntrained to adapt the generative process conditioned on a small set of images\nfrom a given class by aggregating image patch information using a set-based\nVision Transformer (ViT). At test time, the model is able to generate samples\nfrom previously unseen classes conditioned on as few as 5 samples from that\nclass. We empirically show that FSDM can perform few-shot generation and\ntransfer to new datasets. We benchmark variants of our method on complex vision\ndatasets for few-shot learning and compare to unconditional and conditional\nDDPM baselines. Additionally, we show how conditioning the model on patch-based\ninput set information improves training convergence.",
    "descriptor": "",
    "authors": [
      "Giorgio Giannone",
      "Didrik Nielsen",
      "Ole Winther"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.15463"
  },
  {
    "id": "arXiv:2205.15465",
    "title": "Analyzing Modality Robustness in Multimodal Sentiment Analysis",
    "abstract": "Building robust multimodal models are crucial for achieving reliable\ndeployment in the wild. Despite its importance, less attention has been paid to\nidentifying and improving the robustness of Multimodal Sentiment Analysis (MSA)\nmodels. In this work, we hope to address that by (i) Proposing simple\ndiagnostic checks for modality robustness in a trained multimodal model. Using\nthese checks, we find MSA models to be highly sensitive to a single modality,\nwhich creates issues in their robustness; (ii) We analyze well-known robust\ntraining strategies to alleviate the issues. Critically, we observe that\nrobustness can be achieved without compromising on the original performance. We\nhope our extensive study-performed across five models and two benchmark\ndatasets-and proposed procedures would make robustness an integral component in\nMSA research. Our diagnostic checks and robust training solutions are simple to\nimplement and available at https://github. com/declare-lab/MSA-Robustness.",
    "descriptor": "\nComments: NAACL 2022\n",
    "authors": [
      "Devamanyu Hazarika",
      "Yingting Li",
      "Bo Cheng",
      "Shuai Zhao",
      "Roger Zimmermann",
      "Soujanya Poria"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.15465"
  },
  {
    "id": "arXiv:2205.15466",
    "title": "Data Banzhaf: A Data Valuation Framework with Maximal Robustness to  Learning Stochasticity",
    "abstract": "This paper studies the robustness of data valuation to noisy model\nperformance scores. Particularly, we find that the inherent randomness of the\nwidely used stochastic gradient descent can cause existing data value notions\n(e.g., the Shapley value and the Leave-one-out error) to produce inconsistent\ndata value rankings across different runs. To address this challenge, we first\npose a formal framework within which one can measure the robustness of a data\nvalue notion. We show that the Banzhaf value, a value notion originated from\ncooperative game theory literature, achieves the maximal robustness among all\nsemivalues -- a class of value notions that satisfy crucial properties entailed\nby ML applications. We propose an algorithm to efficiently estimate the Banzhaf\nvalue based on the Maximum Sample Reuse (MSR) principle. We derive the lower\nbound sample complexity for Banzhaf value approximation, and we show that our\nMSR algorithm's sample complexity nearly matches the lower bound. Our\nevaluation demonstrates that the Banzhaf value outperforms the existing\nsemivalue-based data value notions on several downstream ML tasks such as\nlearning with weighted samples and noisy label detection. Overall, our study\nsuggests that when the underlying ML algorithm is stochastic, the Banzhaf value\nis a promising alternative to the semivalue-based data value schemes given its\ncomputational advantage and ability to robustly differentiate data quality.",
    "descriptor": "",
    "authors": [
      "Tianhao Wang",
      "Ruoxi Jia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.15466"
  },
  {
    "id": "arXiv:2205.15469",
    "title": "GCoNet+: A Stronger Group Collaborative Co-Salient Object Detector",
    "abstract": "In this paper, we present a novel end-to-end group collaborative learning\nnetwork, termed GCoNet+, which can effectively and efficiently (250 fps)\nidentify co-salient objects in natural scenes. The proposed GCoNet+ achieves\nthe new state-of-the-art performance for co-salient object detection (CoSOD)\nthrough mining consensus representations based on the following two essential\ncriteria: 1) intra-group compactness to better formulate the consistency among\nco-salient objects by capturing their inherent shared attributes using our\nnovel group affinity module (GAM); 2) inter-group separability to effectively\nsuppress the influence of noisy objects on the output by introducing our new\ngroup collaborating module (GCM) conditioning on the inconsistent consensus. To\nfurther improve the accuracy, we design a series of simple yet effective\ncomponents as follows: i) a recurrent auxiliary classification module (RACM)\npromoting the model learning at the semantic level; ii) a confidence\nenhancement module (CEM) helping the model to improve the quality of the final\npredictions; and iii) a group-based symmetric triplet (GST) loss guiding the\nmodel to learn more discriminative features. Extensive experiments on three\nchallenging benchmarks, i.e., CoCA, CoSOD3k, and CoSal2015, demonstrate that\nour GCoNet+ outperforms the existing 12 cutting-edge models. Code has been\nreleased at https://github.com/ZhengPeng7/GCoNet_plus.",
    "descriptor": "",
    "authors": [
      "Peng Zheng",
      "Huazhu Fu",
      "Deng-Ping Fan",
      "Qi Fan",
      "Jie Qin",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15469"
  },
  {
    "id": "arXiv:2205.15473",
    "title": "Free-Space Ellipsoid Graphs for Multi-Agent Target Monitoring",
    "abstract": "We apply a novel framework for decomposing and reasoning about free space in\nan environment to a multi-agent persistent monitoring problem. Our\ndecomposition method represents free space as a collection of ellipsoids\nassociated with a weighted connectivity graph. The same ellipsoids used for\nreasoning about connectivity and distance during high level planning can be\nused as state constraints in a Model Predictive Control algorithm to enforce\ncollision-free motion. This structure allows for streamlined implementation in\ndistributed multi-agent tasks in 2D and 3D environments. We illustrate its\neffectiveness for a team of tracking agents tasked with monitoring a group of\ntarget agents. Our algorithm uses the ellipsoid decomposition as a primitive\nfor the coordination, path planning, and control of the tracking agents.\nSimulations with four tracking agents monitoring fifteen dynamic targets in\nobstacle-rich environments demonstrate the performance of our algorithm.",
    "descriptor": "\nComments: IEEE Intl. Conf. on Robotics and Automation (ICRA) 2022\n",
    "authors": [
      "Aaron Ray",
      "Alyssa Pierson",
      "Daniela Rus"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.15473"
  },
  {
    "id": "arXiv:2205.15476",
    "title": "Augmenting Scientific Creativity with an Analogical Search Engine",
    "abstract": "Analogies have been central to creative problem-solving throughout the\nhistory of science and technology. As the number of scientific papers continues\nto increase exponentially, there is a growing opportunity for finding diverse\nsolutions to existing problems. However, realizing this potential requires the\ndevelopment of a means for searching through a large corpus that goes beyond\nsurface matches and simple keywords. Here we contribute the first end-to-end\nsystem for analogical search on scientific papers and evaluate its\neffectiveness with scientists' own problems. Using a human-in-the-loop AI\nsystem as a probe we find that our system facilitates creative ideation, and\nthat ideation success is mediated by an intermediate level of matching on the\nproblem abstraction (i.e., high versus low). We also demonstrate a fully\nautomated AI search engine that achieves a similar accuracy with the\nhuman-in-the-loop system. We conclude with design implications for enabling\nautomated analogical inspiration engines to accelerate scientific innovation.",
    "descriptor": "",
    "authors": [
      "Hyeonsu B. Kang",
      "Xin Qian",
      "Tom Hope",
      "Dafna Shahaf",
      "Joel Chan",
      "Aniket Kittur"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2205.15476"
  },
  {
    "id": "arXiv:2205.15477",
    "title": "Introduction of a tree-based technique for efficient and real-time label  retrieval in the object tracking system",
    "abstract": "This paper addresses the issue of the real-time tracking quality of moving\nobjects in large-scale video surveillance systems. During the tracking process,\nthe system assigns an identifier or label to each tracked object to distinguish\nit from other objects. In such a mission, it is essential to keep this\nidentifier for the same objects, whatever the area, the time of their\nappearance, or the detecting camera. This is to conserve as much information\nabout the tracking object as possible, decrease the number of ID switching\n(ID-Sw), and increase the quality of object tracking. To accomplish object\nlabeling, a massive amount of data collected by the cameras must be searched to\nretrieve the most similar (nearest neighbor) object identifier. Although this\ntask is simple, it becomes very complex in large-scale video surveillance\nnetworks, where the data becomes very large. In this case, the label retrieval\ntime increases significantly with this increase, which negatively affects the\nperformance of the real-time tracking system. To avoid such problems, we\npropose a new solution to automatically label multiple objects for efficient\nreal-time tracking using the indexing mechanism. This mechanism organizes the\nmetadata of the objects extracted during the detection and tracking phase in an\nAdaptive BCCF-tree. The main advantage of this structure is: its ability to\nindex massive metadata generated by multi-cameras, its logarithmic search\ncomplexity, which implicitly reduces the search response time, and its quality\nof research results, which ensure coherent labeling of the tracked objects. The\nsystem load is distributed through a new Internet of Video Things\ninfrastructure-based architecture to improve data processing and real-time\nobject tracking performance. The experimental evaluation was conducted on a\npublicly available dataset generated by multi-camera containing different crowd\nactivities.",
    "descriptor": "\nComments: 29 pages, 15 figures, 6 tables\n",
    "authors": [
      "Ala-Eddine Benrazek",
      "Zineddine Kouahla",
      "Brahim Farou",
      "Hamid Seridi",
      "Imane Allele"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Information Retrieval (cs.IR)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2205.15477"
  },
  {
    "id": "arXiv:2205.15479",
    "title": "Learning to Represent Programs with Code Hierarchies",
    "abstract": "When used to process source code, graph neural networks have been shown to\nproduce impressive results for a wide range of software engineering tasks.\nExisting techniques, however, still have two issues: (1) long-term dependency\nand (2) different code components are treated as equals when they should not\nbe. To address these issues, we propose a method for representing code as a\nhierarchy (Code Hierarchy), in which different code components are represented\nseparately at various levels of granularity. Then, to process each level of\nrepresentation, we design a novel network architecture, HIRGAST, which combines\nthe strengths of Heterogeneous Graph Transformer Networks and Tree-based\nConvolutional Neural Networks to learn Abstract Syntax Trees enriched with code\ndependency information. We also propose a novel pretraining objective called\nMissing Subtree Prediction to complement our Code Hierarchy. The evaluation\nresults show that our method significantly outperforms other baselines in three\ndownstream tasks: any-code completion, code classification, and code clone\ndetection.",
    "descriptor": "",
    "authors": [
      "Minh Nguyen",
      "Nghi D. Q. Bui"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2205.15479"
  },
  {
    "id": "arXiv:2205.15480",
    "title": "Post-hoc Concept Bottleneck Models",
    "abstract": "Concept Bottleneck Models (CBMs) map the inputs onto a set of interpretable\nconcepts (``the bottleneck'') and use the concepts to make predictions. A\nconcept bottleneck enhances interpretability since it can be investigated to\nunderstand what concepts the model \"sees\" in an input and which of these\nconcepts are deemed important. However, CBMs are restrictive in practice as\nthey require concept labels in the training data to learn the bottleneck and do\nnot leverage strong pretrained models. Moreover, CBMs often do not match the\naccuracy of an unrestricted neural network, reducing the incentive to deploy\nthem in practice. In this work, we address the limitations of CBMs by\nintroducing Post-hoc Concept Bottleneck models (PCBMs). We show that we can\nturn any neural network into a PCBM without sacrificing model performance while\nstill retaining interpretability benefits. When concept annotation is not\navailable on the training data, we show that PCBM can transfer concepts from\nother datasets or from natural language descriptions of concepts. PCBM also\nenables users to quickly debug and update the model to reduce spurious\ncorrelations and improve generalization to new (potentially different) data.\nThrough a model-editing user study, we show that editing PCBMs via\nconcept-level feedback can provide significant performance gains without using\nany data from the target domain or model retraining.",
    "descriptor": "\nComments: An earlier version was published in the ICLR 2022 PAIR2Struct Workshop\n",
    "authors": [
      "Mert Yuksekgonul",
      "Maggie Wang",
      "James Zou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.15480"
  },
  {
    "id": "arXiv:2205.15483",
    "title": "Multi-robot Task Assignment for Aerial Tracking with Viewpoint  Constraints",
    "abstract": "We address the problem of assigning a team of drones to autonomously capture\na set desired shots of a dynamic target in the presence of obstacles. We\npresent a two-stage planning pipeline that generates offline an assignment of\ndrone to shots and locally optimizes online the viewpoint. Given desired shot\nparameters, the high-level planner uses a visibility heuristic to predict good\ntimes for capturing each shot and uses an Integer Linear Program to compute\ndrone assignments. An online Model Predictive Control algorithm uses the\nassignments as reference to capture the shots. The algorithm is validated in\nhardware with a pair of drones and a remote controlled car.",
    "descriptor": "",
    "authors": [
      "Aaron Ray",
      "Alyssa Pierson",
      "Hai Zhu",
      "Javier Alonso-Mora",
      "Daniela Rus"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.15483"
  },
  {
    "id": "arXiv:2205.15485",
    "title": "FinBERT-MRC: financial named entity recognition using BERT under the  machine reading comprehension paradigm",
    "abstract": "Financial named entity recognition (FinNER) from literature is a challenging\ntask in the field of financial text information extraction, which aims to\nextract a large amount of financial knowledge from unstructured texts. It is\nwidely accepted to use sequence tagging frameworks to implement FinNER tasks.\nHowever, such sequence tagging models cannot fully take advantage of the\nsemantic information in the texts. Instead, we formulate the FinNER task as a\nmachine reading comprehension (MRC) problem and propose a new model termed\nFinBERT-MRC. This formulation introduces significant prior information by\nutilizing well-designed queries, and extracts start index and end index of\ntarget entities without decoding modules such as conditional random fields\n(CRF). We conduct experiments on a publicly available Chinese financial dataset\nChFinAnn and a real-word bussiness dataset AdminPunish. FinBERT-MRC model\nachieves average F1 scores of 92.78% and 96.80% on the two datasets,\nrespectively, with average F1 gains +3.94% and +0.89% over some sequence\ntagging models including BiLSTM-CRF, BERT-Tagger, and BERT-CRF. The source code\nis available at https://github.com/zyz0000/FinBERT-MRC.",
    "descriptor": "",
    "authors": [
      "Yuzhe Zhang",
      "Hong Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.15485"
  },
  {
    "id": "arXiv:2205.15489",
    "title": "Computational Reproducibility Within Prognostics and Health Management",
    "abstract": "Scientific research frequently involves the use of computational tools and\nmethods. Providing thorough documentation, open-source code, and data -- the\ncreation of reproducible computational research -- helps others understand a\nresearcher's work. Here, we explore computational reproducibility, broadly, and\nfrom within the field of prognostics and health management (PHM). The adoption\nof reproducible computational research practices remains low across scientific\ndisciplines and within PHM. Our text mining of more than 300 articles, from\npublications engaged in PHM research, showed that fewer than 4% of researchers\nmade their code and data available to others. Although challenges remain, there\nare also clear opportunities, and benefits, for engaging in reproducible\ncomputational research. Highlighting an opportunity, we introduce an\nopen-source software tool, called PyPHM, to assist PHM researchers in accessing\nand preprocessing common industrial datasets.",
    "descriptor": "\nComments: Submitted to 2022 PHM Society Conference for possible publication. For associated code, see this https URL and this https URL\n",
    "authors": [
      "Tim von Hahn",
      "Chris K. Mechefske"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2205.15489"
  },
  {
    "id": "arXiv:2205.15492",
    "title": "Sepsis Prediction with Temporal Convolutional Networks",
    "abstract": "We design and implement a temporal convolutional network model to predict\nsepsis onset. Our model is trained on data extracted from MIMIC III database,\nbased on a retrospective analysis of patients admitted to intensive care unit\nwho did not fall under the definition of sepsis at the time of admission.\nBenchmarked with several machine learning models, our model is superior on this\nbinary classification task, demonstrates the prediction power of convolutional\nnetworks for temporal patterns, also shows the significant impact of having\nlonger look back time on sepsis prediction.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2010.01197\n",
    "authors": [
      "Xing Wang",
      "Yuntian He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15492"
  },
  {
    "id": "arXiv:2205.15494",
    "title": "Certifying Some Distributional Fairness with Subpopulation Decomposition",
    "abstract": "Extensive efforts have been made to understand and improve the fairness of\nmachine learning models based on observational metrics, especially in\nhigh-stakes domains such as medical insurance, education, and hiring decisions.\nHowever, there is a lack of certified fairness considering the end-to-end\nperformance of an ML model. In this paper, we first formulate the certified\nfairness of an ML model trained on a given data distribution as an optimization\nproblem based on the model performance loss bound on a fairness constrained\ndistribution, which is within bounded distributional distance with the training\ndistribution. We then propose a general fairness certification framework and\ninstantiate it for both sensitive shifting and general shifting scenarios. In\nparticular, we propose to solve the optimization problem by decomposing the\noriginal data distribution into analytical subpopulations and proving the\nconvexity of the subproblems to solve them. We evaluate our certified fairness\non six real-world datasets and show that our certification is tight in the\nsensitive shifting scenario and provides non-trivial certification under\ngeneral shifting. Our framework is flexible to integrate additional\nnon-skewness constraints and we show that it provides even tighter\ncertification under different real-world scenarios. We also compare our\ncertified fairness bound with adapted existing distributional robustness bounds\non Gaussian data and demonstrate that our method is significantly tighter.",
    "descriptor": "\nComments: 35 pages, 13 figures\n",
    "authors": [
      "Mintong Kang",
      "Linyi Li",
      "Maurice Weber",
      "Yang Liu",
      "Ce Zhang",
      "Bo Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2205.15494"
  },
  {
    "id": "arXiv:2205.15495",
    "title": "Joint Spatial-Temporal and Appearance Modeling with Transformer for  Multiple Object Tracking",
    "abstract": "The recent trend in multiple object tracking (MOT) is heading towards\nleveraging deep learning to boost the tracking performance. In this paper, we\npropose a novel solution named TransSTAM, which leverages Transformer to\neffectively model both the appearance features of each object and the\nspatial-temporal relationships among objects. TransSTAM consists of two major\nparts: (1) The encoder utilizes the powerful self-attention mechanism of\nTransformer to learn discriminative features for each tracklet; (2) The decoder\nadopts the standard cross-attention mechanism to model the affinities between\nthe tracklets and the detections by taking both spatial-temporal and appearance\nfeatures into account. TransSTAM has two major advantages: (1) It is solely\nbased on the encoder-decoder architecture and enjoys a compact network design,\nhence being computationally efficient; (2) It can effectively learn\nspatial-temporal and appearance features within one model, hence achieving\nbetter tracking accuracy. The proposed method is evaluated on multiple public\nbenchmarks including MOT16, MOT17, and MOT20, and it achieves a clear\nperformance improvement in both IDF1 and HOTA with respect to previous\nstate-of-the-art approaches on all the benchmarks. Our code is available at\n\\url{https://github.com/icicle4/TranSTAM}.",
    "descriptor": "",
    "authors": [
      "Peng Dai",
      "Yiqiang Feng",
      "Renliang Weng",
      "Changshui Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15495"
  },
  {
    "id": "arXiv:2205.15496",
    "title": "Towards Lifelong Federated Learning in Autonomous Mobile Robots with  Continuous Sim-to-Real Transfer",
    "abstract": "The role of deep learning (DL) in robotics has significantly deepened over\nthe last decade. Intelligent robotic systems today are highly connected systems\nthat rely on DL for a variety of perception, control, and other tasks. At the\nsame time, autonomous robots are being increasingly deployed as part of fleets,\nwith collaboration among robots becoming a more relevant factor. From the\nperspective of collaborative learning, federated learning (FL) enables\ncontinuous training of models in a distributed, privacy-preserving way. This\npaper focuses on vision-based obstacle avoidance for mobile robot navigation.\nOn this basis, we explore the potential of FL for distributed systems of mobile\nrobots enabling continuous learning via the engagement of robots in both\nsimulated and real-world scenarios. We extend previous works by studying the\nperformance of different image classifiers for FL, compared to centralized,\ncloud-based learning with a priori aggregated data. We also introduce an\napproach to continuous learning from mobile robots with extended sensor suites\nable to provide automatically labeled data while they are completing other\ntasks. We show that higher accuracies can be achieved by training the models in\nboth simulation and reality, enabling continuous updates to deployed models.",
    "descriptor": "",
    "authors": [
      "Xianjia Yu",
      "Jorge Pena Queralta",
      "Tomi Westerlund"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.15496"
  },
  {
    "id": "arXiv:2205.15501",
    "title": "Multi-Entanglement Routing Design over Quantum Networks",
    "abstract": "Quantum networks are considered as a promising future platform for quantum\ninformation exchange and quantum applications, which have capabilities far\nbeyond the traditional communication networks. Remote quantum entanglement is\nan essential component of a quantum network. How to efficiently design a\nmulti-routing entanglement protocol is a fundamental yet challenging problem.\nIn this paper, we study a quantum entanglement routing problem to\nsimultaneously maximize the number of quantum-user pairs and their expected\nthroughput. Our approach is to formulate the problem as two sequential integer\nprogramming steps. We propose efficient entanglement routing algorithms for the\ntwo integer programming steps and analyze their time complexity and performance\nbounds. Results of evaluation highlight that our approach outperforms existing\nsolutions in both served quantum-user pairs numbers and the network expected\nthroughput.",
    "descriptor": "",
    "authors": [
      "Yiming Zeng",
      "Jiarui Zhang",
      "Ji Liu",
      "Zhenhua Liu",
      "Yuanyuan Yang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2205.15501"
  },
  {
    "id": "arXiv:2205.15503",
    "title": "Leveraging Pre-Trained Language Models to Streamline Natural Language  Interaction for Self-Tracking",
    "abstract": "Current natural language interaction for self-tracking tools largely depends\non bespoke implementation optimized for a specific tracking theme and data\nformat, which is neither generalizable nor scalable to a tremendous design\nspace of self-tracking. However, training machine learning models in the\ncontext of self-tracking is challenging due to the wide variety of tracking\ntopics and data formats. In this paper, we propose a novel NLP task for\nself-tracking that extracts close- and open-ended information from a\nretrospective activity log described as a plain text, and a domain-agnostic,\nGPT-3-based NLU framework that performs this task. The framework augments the\nprompt using synthetic samples to transform the task into 10-shot learning, to\naddress a cold-start problem in bootstrapping a new tracking topic. Our\npreliminary evaluation suggests that our approach significantly outperforms the\nbaseline QA models. Going further, we discuss future application domains toward\nwhich the NLP and HCI researchers can collaborate.",
    "descriptor": "\nComments: Accepted to NAACL '22 2nd Workshop on Bridging Human-Computer Interaction and Natural Language Processing. 10 pages including appendix, 2 figures, and 1 table\n",
    "authors": [
      "Young-Ho Kim",
      "Sungdong Kim",
      "Minsuk Chang",
      "Sang-Woo Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2205.15503"
  },
  {
    "id": "arXiv:2205.15504",
    "title": "Stepping beyond your comfort zone: Diffusion-based network analytics for  knowledge trajectory recommendation",
    "abstract": "Interest in tracing the research interests of scientific researchers is\nrising, and particularly that of predicting a researcher's knowledge\ntrajectories beyond their current foci into potential\ninter-/cross-/multi-disciplinary interactions. Hence, in this study, we present\na method of diffusion-based network analytics for knowledge trajectory\nrecommendation. The method begins by constructing a heterogeneous bibliometric\nnetwork consisting of a co-topic layer and a co-authorship layer. A novel link\nprediction approach with a diffusion strategy is then used to reflect\nreal-world academic activity, such as knowledge sharing between co-authors or\ndiffusing between similar research topics. This strategy differentiates the\ninteractions occurring between homogeneous and heterogeneous nodes and weights\nthe strengths of these interactions. Two sets of experiments - one with a local\ndataset and another with a global dataset - demonstrate that the proposed\nmethod is prior to selected baselines. In addition, to further examine the\nreliability of our method, we conducted a case study on recommending knowledge\ntrajectories of selected information scientists and their research groups. The\nresults demonstrate the empirical insights our method yields for individual\nresearchers, communities, and research institutions in the information science\ndiscipline.",
    "descriptor": "",
    "authors": [
      "Yi Zhang",
      "Mengjia Wu",
      "Jie Lu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2205.15504"
  },
  {
    "id": "arXiv:2205.15505",
    "title": "DNA Pattern Matching Acceleration with Analog Resistive CAM",
    "abstract": "DNA pattern matching is essential for many widely used bioinformatics\napplications. Disease diagnosis is one of these applications, since analyzing\nchanges in DNA sequences can increase our understanding of possible genetic\ndiseases. The remarkable growth in the size of DNA datasets has resulted in\nchallenges in discovering DNA patterns efficiently in terms of run time and\npower consumption. In this paper, we propose an efficient hardware and software\ncodesign that determines the chance of the occurrence of repeat-expansion\ndiseases using DNA pattern matching. The proposed design parallelizes the DNA\npattern matching task using associative memory realized with analog\ncontent-addressable memory and implements an algorithm that returns the maximum\nnumber of consecutive occurrences of a specific pattern within a DNA sequence.\nWe fully implement all the required hardware circuits with PTM 45-nm\ntechnology, and we evaluate the proposed architecture on a practical human DNA\ndataset. The results show that our design is energy-efficient and significantly\naccelerates the DNA pattern matching task compared to previous approaches\ndescribed in the literature.",
    "descriptor": "",
    "authors": [
      "Jinane Bazzi",
      "Jana Sweidan",
      "Mohammed E. Fouda",
      "Rouwaida Kanj",
      "Ahmed M. Eltawil"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Emerging Technologies (cs.ET)",
      "Genomics (q-bio.GN)"
    ],
    "url": "https://arxiv.org/abs/2205.15505"
  },
  {
    "id": "arXiv:2205.15508",
    "title": "Rethinking Graph Neural Networks for Anomaly Detection",
    "abstract": "Graph Neural Networks (GNNs) are widely applied for graph anomaly detection.\nAs one of the key components for GNN design is to select a tailored spectral\nfilter, we take the first step towards analyzing anomalies via the lens of the\ngraph spectrum. Our crucial observation is the existence of anomalies will lead\nto the `right-shift' phenomenon, that is, the spectral energy distribution\nconcentrates less on low frequencies and more on high frequencies. This fact\nmotivates us to propose the Beta Wavelet Graph Neural Network (BWGNN). Indeed,\nBWGNN has spectral and spatial localized band-pass filters to better handle the\n`right-shift' phenomenon in anomalies. We demonstrate the effectiveness of\nBWGNN on four large-scale anomaly detection datasets. Our code and data are\nreleased at https://github.com/squareRoot3/Rethinking-Anomaly-Detection",
    "descriptor": "\nComments: Accepted by ICML 2022. Our code and data are released at this https URL\n",
    "authors": [
      "Jianheng Tang",
      "Jiajin Li",
      "Ziqi Gao",
      "Jia Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.15508"
  },
  {
    "id": "arXiv:2205.15509",
    "title": "ADAPT: Vision-Language Navigation with Modality-Aligned Action Prompts",
    "abstract": "Vision-Language Navigation (VLN) is a challenging task that requires an\nembodied agent to perform action-level modality alignment, i.e., make\ninstruction-asked actions sequentially in complex visual environments. Most\nexisting VLN agents learn the instruction-path data directly and cannot\nsufficiently explore action-level alignment knowledge inside the multi-modal\ninputs. In this paper, we propose modAlity-aligneD Action PrompTs (ADAPT),\nwhich provides the VLN agent with action prompts to enable the explicit\nlearning of action-level modality alignment to pursue successful navigation.\nSpecifically, an action prompt is defined as a modality-aligned pair of an\nimage sub-prompt and a text sub-prompt, where the former is a single-view\nobservation and the latter is a phrase like ''walk past the chair''. When\nstarting navigation, the instruction-related action prompt set is retrieved\nfrom a pre-built action prompt base and passed through a prompt encoder to\nobtain the prompt feature. Then the prompt feature is concatenated with the\noriginal instruction feature and fed to a multi-layer transformer for action\nprediction. To collect high-quality action prompts into the prompt base, we use\nthe Contrastive Language-Image Pretraining (CLIP) model which has powerful\ncross-modality alignment ability. A modality alignment loss and a sequential\nconsistency loss are further introduced to enhance the alignment of the action\nprompt and enforce the agent to focus on the related prompt sequentially.\nExperimental results on both R2R and RxR show the superiority of ADAPT over\nstate-of-the-art methods.",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Bingqian Lin",
      "Yi Zhu",
      "Zicong Chen",
      "Xiwen Liang",
      "Jianzhuang Liu",
      "Xiaodan Liang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.15509"
  },
  {
    "id": "arXiv:2205.15511",
    "title": "Enhancing Event-Level Sentiment Analysis with Structured Arguments",
    "abstract": "Previous studies about event-level sentiment analysis (SA) usually model the\nevent as a topic, a category or target terms, while the structured arguments\n(e.g., subject, object, time and location) that have potential effects on the\nsentiment are not well studied. In this paper, we redefine the task as\nstructured event-level SA and propose an End-to-End Event-level Sentiment\nAnalysis ($\\textit{E}^{3}\\textit{SA}$) approach to solve this issue.\nSpecifically, we explicitly extract and model the event structure information\nfor enhancing event-level SA. Extensive experiments demonstrate the great\nadvantages of our proposed approach over the state-of-the-art methods. Noting\nthe lack of the dataset, we also release a large-scale real-world dataset with\nevent arguments and sentiment labelling for promoting more\nresearches\\footnote{The dataset is available at\nhttps://github.com/zhangqi-here/E3SA}.",
    "descriptor": "",
    "authors": [
      "Qi Zhang",
      "Jie Zhou",
      "Qin Chen",
      "Qinchun Bai",
      "Liang He"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.15511"
  },
  {
    "id": "arXiv:2205.15512",
    "title": "Nearly Minimax Optimal Offline Reinforcement Learning with Linear  Function Approximation: Single-Agent MDP and Markov Game",
    "abstract": "Offline reinforcement learning (RL) aims at learning an optimal strategy\nusing a pre-collected dataset without further interactions with the\nenvironment. While various algorithms have been proposed for offline RL in the\nprevious literature, the minimax optimal performance has only been (nearly)\nachieved for tabular Markov decision processes (MDPs). In this paper, we focus\non offline RL with linear function approximation and propose two new\nalgorithms, SPEVI+ and SPMVI+, for single-agent MDPs and two-player zero-sum\nMarkov games (MGs), respectively. The proposed algorithms feature carefully\ncrafted data splitting mechanisms and novel variance-reduction pessimistic\nestimators. Theoretical analysis demonstrates that they are capable of matching\nthe performance lower bounds up to logarithmic factors. As a byproduct, a new\nperformance lower bound is established for MGs, which tightens the existing\nresults. To the best of our knowledge, these are the first computationally\nefficient and nearly minimax optimal algorithms for offline single-agent MDPs\nand MGs with linear function approximation.",
    "descriptor": "",
    "authors": [
      "Wei Xiong",
      "Han Zhong",
      "Chengshuai Shi",
      "Cong Shen",
      "Liwei Wang",
      "Tong Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.15512"
  },
  {
    "id": "arXiv:2205.15513",
    "title": "A Unified Framework for Emotion Identification and Generation in  Dialogues",
    "abstract": "Social chatbots have gained immense popularity, and their appeal lies not\njust in their capacity to respond to the diverse requests from users, but also\nin the ability to develop an emotional connection with users. To further\ndevelop and promote social chatbots, we need to concentrate on increasing user\ninteraction and take into account both the intellectual and emotional quotient\nin the conversational agents. In this paper, we propose a multi-task framework\nthat jointly identifies the emotion of a given dialogue and generates response\nin accordance to the identified emotion. We employ a BERT based network for\ncreating an empathetic system and use a mixed objective function that trains\nthe end-to-end network with both the classification and generation loss.\nExperimental results show that our proposed framework outperforms current\nstate-of-the-art models",
    "descriptor": "",
    "authors": [
      "Avinash Madasu",
      "Mauajama Firdaus",
      "Asif Eqbal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.15513"
  },
  {
    "id": "arXiv:2205.15514",
    "title": "A Knowledge-Enhanced Adversarial Model for Cross-lingual Structured  Sentiment Analysis",
    "abstract": "Structured sentiment analysis, which aims to extract the complex semantic\nstructures such as holders, expressions, targets, and polarities, has obtained\nwidespread attention from both industry and academia. Unfortunately, the\nexisting structured sentiment analysis datasets refer to a few languages and\nare relatively small, limiting neural network models' performance. In this\npaper, we focus on the cross-lingual structured sentiment analysis task, which\naims to transfer the knowledge from the source language to the target one.\nNotably, we propose a Knowledge-Enhanced Adversarial Model (\\texttt{KEAM}) with\nboth implicit distributed and explicit structural knowledge to enhance the\ncross-lingual transfer. First, we design an adversarial embedding adapter for\nlearning an informative and robust representation by capturing implicit\nsemantic information from diverse multi-lingual embeddings adaptively. Then, we\npropose a syntax GCN encoder to transfer the explicit semantic information\n(e.g., universal dependency tree) among multiple languages. We conduct\nexperiments on five datasets and compare \\texttt{KEAM} with both the supervised\nand unsupervised methods. The extensive experimental results show that our\n\\texttt{KEAM} model outperforms all the unsupervised baselines in various\nmetrics.",
    "descriptor": "",
    "authors": [
      "Qi Zhang",
      "Jie Zhou",
      "Qin Chen",
      "Qingchun Bai",
      "Jun Xiao",
      "Liang He"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.15514"
  },
  {
    "id": "arXiv:2205.15516",
    "title": "Multi-Scan Multi-Sensor Multi-Object State Estimation",
    "abstract": "If computational tractability were not an issue, multi-object estimation\nshould integrate all measurements from multiple sensors across multiple scans.\nIn this article, we propose an efficient numerical solution to the multi-scan\nmulti-sensor multi-object estimation problem by computing the (labeled)\nmulti-sensor multi-object posterior density. Minimizing the $L_{1}$-norm error\nfrom the exact posterior density requires solving large-scale multi-dimensional\nassignment problems that are NP-hard. An efficient multi-dimensional assignment\nalgorithm is developed based on Gibbs sampling, together with convergence\nanalysis. The resulting multi-scan multi-sensor multi-object estimation\nalgorithm can be applied either offline in one batch or recursively. The\nefficacy of the algorithm is demonstrated using numerical experiments with a\nsimulated dataset.",
    "descriptor": "",
    "authors": [
      "D. Moratuwage",
      "B.-N. Vo",
      "B.-T. Vo",
      "C. Shim"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2205.15516"
  },
  {
    "id": "arXiv:2205.15517",
    "title": "IDE-3D: Interactive Disentangled Editing for High-Resolution 3D-aware  Portrait Synthesis",
    "abstract": "Existing 3D-aware facial generation methods face a dilemma in quality versus\neditability: they either generate editable results in low resolution or\nhigh-quality ones with no editing flexibility. In this work, we propose a new\napproach that brings the best of both worlds together. Our system consists of\nthree major components: (1) a 3D-semantics-aware generative model that produces\nview-consistent, disentangled face images and semantic masks; (2) a hybrid GAN\ninversion approach that initialize the latent codes from the semantic and\ntexture encoder, and further optimized them for faithful reconstruction; and\n(3) a canonical editor that enables efficient manipulation of semantic masks in\ncanonical view and product high-quality editing results. Our approach is\ncompetent for many applications, e.g. free-view face drawing, editing, and\nstyle control. Both quantitative and qualitative results show that our method\nreaches the state-of-the-art in terms of photorealism, faithfulness, and\nefficiency.",
    "descriptor": "\nComments: Project Page: this https URL\n",
    "authors": [
      "Jingxiang Sun",
      "Xuan Wang",
      "Yichun Shi",
      "Lizhen Wang",
      "Jue Wang",
      "Yebin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15517"
  },
  {
    "id": "arXiv:2205.15518",
    "title": "On Forward Kinematics of a 3SPR Parallel Manipulator",
    "abstract": "In this paper, a new numerical method to solve the forward kinematics (FK) of\na parallel manipulator with three-limb spherical-prismatic-revolute (3SPR)\nstructure is presented. Unlike the existing numerical approaches that rely on\ncomputation of the manipulator's Jacobian matrix and its inverse at each\niteration, the proposed algorithm requires much less computations to estimate\nthe FK parameters. A cost function is introduced that measures the difference\nof the estimates from the actual FK values. At each iteration, the problem is\ndecomposed into two steps. First, the estimates of the platform orientation\nfrom the heave estimates are obtained. Then, heave estimates are updated by\nmoving in the gradient direction of the proposed cost function. To validate the\nperformance of the proposed algorithm, it is compared against a Jacobian-based\n(JB) approach for a 3SPR parallel manipulator.",
    "descriptor": "",
    "authors": [
      "Masoud Roudneshin",
      "Kamran Ghaffari",
      "Amir G. Aghdam"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.15518"
  },
  {
    "id": "arXiv:2205.15519",
    "title": "Vector-wise Joint Diagonalization of Almost Commuting Matrices",
    "abstract": "This work aims to numerically construct exactly commuting matrices close to\ngiven almost commuting ones, which is equivalent to the joint approximate\ndiagonalization problem. We first prove that almost commuting matrices\ngenerically has approximate common eigenvectors that are almost orthogonal to\neach other. Based on this key observation, we propose a fast and robust\nvector-wise joint diagonalization (VJD) algorithm, which constructs the\northogonal similarity transform by sequentially finding these approximate\ncommon eigenvectors. In doing so, we consider sub-optimization problems over\nthe unit sphere, for which we present a Riemannian quasi-Newton method with\nrigorous convergence analysis. We also discuss the numerical stability of the\nproposed VJD algorithm. Numerical examples with applications in independent\ncomponent analysis are provided to reveal the relation with Huaxin Lin's\ntheorem and to demonstrate that our method compares favorably with the\nstate-of-the-art Jacobi-type joint diagonalization algorithm.",
    "descriptor": "",
    "authors": [
      "Bowen Li",
      "Jianfeng Lu",
      "Ziang Yu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.15519"
  },
  {
    "id": "arXiv:2205.15523",
    "title": "Variational Transfer Learning using Cross-Domain Latent Modulation",
    "abstract": "To successfully apply trained neural network models to new domains, powerful\ntransfer learning solutions are essential. We propose to introduce a novel\ncross-domain latent modulation mechanism to a variational autoencoder framework\nso as to achieve effective transfer learning. Our key idea is to procure deep\nrepresentations from one data domain and use it to influence the\nreparameterization of the latent variable of another domain. Specifically, deep\nrepresentations of the source and target domains are first extracted by a\nunified inference model and aligned by employing gradient reversal. The learned\ndeep representations are then cross-modulated to the latent encoding of the\nalternative domain, where consistency constraints are also applied. In the\nempirical validation that includes a number of transfer learning benchmark\ntasks for unsupervised domain adaptation and image-to-image translation, our\nmodel demonstrates competitive performance, which is also supported by evidence\nobtained from visualization.",
    "descriptor": "\nComments: Under review. arXiv admin note: substantial text overlap with arXiv:2012.11727\n",
    "authors": [
      "Jinyong Hou",
      "Jeremiah D. Deng",
      "Stephen Cranefield",
      "Xuejie Din"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15523"
  },
  {
    "id": "arXiv:2205.15524",
    "title": "Symmetrized two-scale finite element discretizations for partial  differential equations with symmetric solutions",
    "abstract": "In this paper, a symmetrized two-scale finite element method is proposed for\na class of partial differential equations with symmetric solutions. With this\nmethod, the finite element approximation on a fine tensor product grid is\nreduced to the finite element approximations on a much coarse grid and a\nunivariant fine grid. It is shown by both theory and numerics including\nelectronic structure calculations that the resulting approximation still\nmaintains an asymptotically optimal accuracy. Consequently the symmetrized\ntwo-scale finite element method reduces computational cost significantly.",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Pengyu Hou",
      "Fang Liu",
      "Aihui Zhou"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.15524"
  },
  {
    "id": "arXiv:2205.15530",
    "title": "Pseudo-Data based Self-Supervised Federated Learning for Classification  of Histopathological Images",
    "abstract": "Computer-aided diagnosis (CAD) can help pathologists improve diagnostic\naccuracy together with consistency and repeatability for cancers. However, the\nCAD models trained with the histopathological images only from a single center\n(hospital) generally suffer from the generalization problem due to the\nstraining inconsistencies among different centers. In this work, we propose a\npseudo-data based self-supervised federated learning (FL) framework, named\nSSL-FT-BT, to improve both the diagnostic accuracy and generalization of CAD\nmodels. Specifically, the pseudo histopathological images are generated from\neach center, which contains inherent and specific properties corresponding to\nthe real images in this center, but does not include the privacy information.\nThese pseudo images are then shared in the central server for self-supervised\nlearning (SSL). A multi-task SSL is then designed to fully learn both the\ncenter-specific information and common inherent representation according to the\ndata characteristics. Moreover, a novel Barlow Twins based FL (FL-BT) algorithm\nis proposed to improve the local training for the CAD model in each center by\nconducting contrastive learning, which benefits the optimization of the global\nmodel in the FL procedure. The experimental results on three public\nhistopathological image datasets indicate the effectiveness of the proposed\nSSL-FL-BT on both diagnostic accuracy and generalization.",
    "descriptor": "",
    "authors": [
      "Jun Shi",
      "Yuanming Zhang",
      "Zheng Li",
      "Xiangmin Han",
      "Saisai Ding",
      "Jun Wang",
      "Shihui Ying"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15530"
  },
  {
    "id": "arXiv:2205.15531",
    "title": "itKD: Interchange Transfer-based Knowledge Distillation for 3D Object  Detection",
    "abstract": "Recently, point-cloud based 3D object detectors have achieved remarkable\nprogress. However, most studies are limited to the development of deep learning\narchitectures for improving only their accuracy. In this paper, we propose an\nautoencoder-style framework comprising channel-wise compression and\ndecompression via interchange transfer for knowledge distillation. To learn the\nmap-view feature of a teacher network, the features from a teacher and student\nnetwork are independently passed through the shared autoencoder; here, we use a\ncompressed representation loss that binds the channel-wised compression\nknowledge from both the networks as a kind of regularization. The decompressed\nfeatures are transferred in opposite directions to reduce the gap in the\ninterchange reconstructions. Lastly, we present an attentive head loss for\nmatching the pivotal detection information drawn by the multi-head\nself-attention mechanism. Through extensive experiments, we verify that our\nmethod can learn the lightweight model that is well-aligned with the 3D point\ncloud detection task and we demonstrate its superiority using the well-known\npublic datasets Waymo and nuScenes.",
    "descriptor": "\nComments: 12 pages, 2 figures, 8 tables\n",
    "authors": [
      "Hyeon Cho",
      "Junyong Choi",
      "Geonwoo Baek",
      "Wonjun Hwang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15531"
  },
  {
    "id": "arXiv:2205.15532",
    "title": "Dataset Bias in Android Malware Detection",
    "abstract": "Researchers have proposed kinds of malware detection methods to solve the\nexplosive mobile security threats. We argue that the experiment results are\ninflated due to the research bias introduced by the variability of malware\ndataset. We explore the impact of bias in Android malware detection in three\naspects, the method used to flag the ground truth, the distribution of malware\nfamilies in the dataset, and the methods to use the dataset. We implement a set\nof experiments of different VT thresholds and find that the methods used to\nflag the malware data affect the malware detection performance directly. We\nfurther compare the impact of malware family types and composition on malware\ndetection in detail. The superiority of each approach is different under\nvarious combinations of malware families. Through our extensive experiments, we\nshowed that the methods to use the dataset can have a misleading impact on\nevaluation, and the performance difference can be up to over 40%. We argue that\nthese research biases observed in this paper should be carefully\ncontrolled/eliminated to enforce a fair comparison of malware detection\ntechniques. Providing reasonable and explainable results is better than only\nreporting a high detection accuracy with vague dataset and experimental\nsettings.",
    "descriptor": "",
    "authors": [
      "Yan Lin",
      "Tianming Liu",
      "Wei Liu",
      "Zhigaoyuan Wang",
      "Li Li",
      "Guoai Xu",
      "Haoyu Wang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2205.15532"
  },
  {
    "id": "arXiv:2205.15534",
    "title": "Gluing Neural Networks Symbolically Through Hyperdimensional Computing",
    "abstract": "Hyperdimensional Computing affords simple, yet powerful operations to create\nlong Hyperdimensional Vectors (hypervectors) that can efficiently encode\ninformation, be used for learning, and are dynamic enough to be modified on the\nfly. In this paper, we explore the notion of using binary hypervectors to\ndirectly encode the final, classifying output signals of neural networks in\norder to fuse differing networks together at the symbolic level. This allows\nmultiple neural networks to work together to solve a problem, with little\nadditional overhead. Output signals just before classification are encoded as\nhypervectors and bundled together through consensus summation to train a\nclassification hypervector. This process can be performed iteratively and even\non single neural networks by instead making a consensus of multiple\nclassification hypervectors. We find that this outperforms the state of the\nart, or is on a par with it, while using very little overhead, as hypervector\noperations are extremely fast and efficient in comparison to the neural\nnetworks. This consensus process can learn online and even grow or lose models\nin real time. Hypervectors act as memories that can be stored, and even further\nbundled together over time, affording life long learning capabilities.\nAdditionally, this consensus structure inherits the benefits of\nHyperdimensional Computing, without sacrificing the performance of modern\nMachine Learning. This technique can be extrapolated to virtually any neural\nmodel, and requires little modification to employ - one simply requires\nrecording the output signals of networks when presented with a testing example.",
    "descriptor": "\nComments: 10 pages, 3 figures, 6 tables, accepted to IJCNN 2022 / IEEE WCCI 2022\n",
    "authors": [
      "Peter Sutor",
      "Dehao Yuan",
      "Douglas Summers-Stay",
      "Cornelia Fermuller",
      "Yiannis Aloimonos"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15534"
  },
  {
    "id": "arXiv:2205.15535",
    "title": "Do Customized Android Frameworks Keep Pace with Android?",
    "abstract": "To satisfy varying customer needs, device vendors and OS providers often rely\non the open-source nature of the Android OS and offer customized versions of\nthe Android OS. When a new version of the Android OS is released, device\nvendors and OS providers need to merge the changes from the Android OS into\ntheir customizations to account for its bug fixes, security patches, and new\nfeatures. Because developers of customized OSs might have made changes to code\nlocations that were also modified by the developers of the Android OS, the\nmerge task can be characterized by conflicts, which can be time-consuming and\nerror-prone to resolve.\nTo provide more insight into this critical aspect of the Android ecosystem,\nwe present an empirical study that investigates how eight open-source\ncustomizations of the Android OS merge the changes from the Android OS into\ntheir projects. The study analyzes how often the developers from the customized\nOSs merge changes from the Android OS, how often the developers experience\ntextual merge conflicts, and the characteristics of these conflicts.\nFurthermore, to analyze the effect of the conflicts, the study also analyzes\nhow the conflicts can affect a randomly selected sample of 1,000 apps. After\nanalyzing 1,148 merge operations, we identified that developers perform these\noperations for 9.7\\% of the released versions of the Android OS, developers\nwill encounter at least one conflict in 41.3\\% of the merge operations, 58.1\\%\nof the conflicts required developers to change the customized OSs, and 64.4\\%\nof the apps considered use at least one method affected by a conflict. In\naddition to detailing our results, the paper also discusses the implications of\nour findings and provides insights for researchers and practitioners working\nwith Android and its customizations.",
    "descriptor": "",
    "authors": [
      "Pei Liu",
      "Mattia Fazzini",
      "John Grundy",
      "Li Li"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2205.15535"
  },
  {
    "id": "arXiv:2205.15536",
    "title": "DeepDefacer: Automatic Removal of Facial Features via U-Net Image  Segmentation",
    "abstract": "Recent advancements in the field of magnetic resonance imaging (MRI) have\nenabled large-scale collaboration among clinicians and researchers for\nneuroimaging tasks. However, researchers are often forced to use outdated and\nslow software to anonymize MRI images for publication. These programs\nspecifically perform expensive mathematical operations over 3D images that\nrapidly slow down anonymization speed as an image's volume increases in size.\nIn this paper, we introduce DeepDefacer, an application of deep learning to MRI\nanonymization that uses a streamlined 3D U-Net network to mask facial regions\nin MRI images with a significant increase in speed over traditional\nde-identification software. We train DeepDefacer on MRI images from the Brain\nDevelopment Organization (IXI) and International Consortium for Brain Mapping\n(ICBM) and quantitatively evaluate our model against a baseline 3D U-Net model\nwith regards to Dice, recall, and precision scores. We also evaluate\nDeepDefacer against Pydeface, a traditional defacing application, with regards\nto speed on a range of CPU and GPU devices and qualitatively evaluate our\nmodel's defaced output versus the ground truth images produced by Pydeface. We\nprovide a link to a PyPi program at the end of this manuscript to encourage\nfurther research into the application of deep learning to MRI anonymization.",
    "descriptor": "",
    "authors": [
      "Anish Khazane",
      "Julien Hoachuck",
      "Krzysztof J. Gorgolewski",
      "Russell A. Poldrack"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2205.15536"
  },
  {
    "id": "arXiv:2205.15540",
    "title": "MACE: An Efficient Model-Agnostic Framework for Counterfactual  Explanation",
    "abstract": "Counterfactual explanation is an important Explainable AI technique to\nexplain machine learning predictions. Despite being studied actively, existing\noptimization-based methods often assume that the underlying machine-learning\nmodel is differentiable and treat categorical attributes as continuous ones,\nwhich restricts their real-world applications when categorical attributes have\nmany different values or the model is non-differentiable. To make\ncounterfactual explanation suitable for real-world applications, we propose a\nnovel framework of Model-Agnostic Counterfactual Explanation (MACE), which\nadopts a newly designed pipeline that can efficiently handle non-differentiable\nmachine-learning models on a large number of feature values. in our MACE\napproach, we propose a novel RL-based method for finding good counterfactual\nexamples and a gradient-less descent method for improving proximity.\nExperiments on public datasets validate the effectiveness with better validity,\nsparsity and proximity.",
    "descriptor": "\nComments: 9 pages, 2 figures\n",
    "authors": [
      "Wenzhuo Yang",
      "Jia Li",
      "Caiming Xiong",
      "Steven C.H. Hoi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15540"
  },
  {
    "id": "arXiv:2205.15544",
    "title": "Refining Low-Resource Unsupervised Translation by Language  Disentanglement of Multilingual Model",
    "abstract": "Numerous recent work on unsupervised machine translation (UMT) implies that\ncompetent unsupervised translations of low-resource and unrelated languages,\nsuch as Nepali or Sinhala, are only possible if the model is trained in a\nmassive multilingual environment, where theses low-resource languages are mixed\nwith high-resource counterparts. Nonetheless, while the high-resource languages\ngreatly help kick-start the target low-resource translation tasks, the language\ndiscrepancy between them may hinder their further improvement. In this work, we\npropose a simple refinement procedure to disentangle languages from a\npre-trained multilingual UMT model for it to focus on only the target\nlow-resource task. Our method achieves the state of the art in the fully\nunsupervised translation tasks of English to Nepali, Sinhala, Gujarati,\nLatvian, Estonian and Kazakh, with BLEU score gains of 3.5, 3.5, 3.3, 4.1, 4.2,\nand 3.3, respectively. Our codebase is available at\nhttps://github.com/nxphi47/refine_unsup_multilingual_mt",
    "descriptor": "",
    "authors": [
      "Xuan-Phi Nguyen",
      "Shafiq Joty",
      "Wu Kui",
      "Ai Ti Aw"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.15544"
  },
  {
    "id": "arXiv:2205.15545",
    "title": "Rethinking Block Storage Encryption with Virtual Disks",
    "abstract": "Disk encryption today uses standard encryption methods that are length\npreserving and do not require storing any additional information with an\nencrypted disk sector. This significantly simplifies disk encryption management\nas the disk mapping does not change with encryption. On the other hand, it\nforces the encryption to be deterministic when data is being overwritten and it\ndisallows integrity mechanisms, thus lowering security guarantees. Moreover,\nbecause the most widely used standard encryption methods (like AES-XTS) work at\nsmall sub-blocks of no more than 32 bytes, deterministic overwrites form an\neven greater security risk. Overall, today's standard practice forfeits some\nsecurity for ease of management and performance considerations. This\nshortcoming is further amplified in a virtual disk setting that supports\nversioning and snapshots so that overwritten data remains accessible.\nIn this work, we address these concerns and stipulate that especially with\nvirtual disks, there is motivation and potential to improve security at the\nexpense of a small performance overhead. Specifically, adding per-sector\nmetadata to a virtual disk allows running encryption with a random\ninitialization vector (IV) as well as potentially adding integrity mechanisms.\nWe explore how best to implement additional per-sector information in Ceph RBD,\na popular open-source distributed block storage with client-side encryption. We\nimplement and evaluate several approaches and show that one can run AES-XTS\nencryption with a random IV at a manageable overhead ranging from 1\\%--22\\%,\ndepending on the IO size.",
    "descriptor": "",
    "authors": [
      "Danny Harnik",
      "Oded Naor",
      "Effi Ofer",
      "Or Ozery"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2205.15545"
  },
  {
    "id": "arXiv:2205.15546",
    "title": "Identifying and Characterizing Silently-Evolved Methods in the Android  API",
    "abstract": "With over 500,000 commits and more than 700 contributors, the Android\nplatform is undoubtedly one of the largest industrial-scale software projects.\nThis project provides the Android API, and developers heavily rely on this API\nto develop their Android apps. Unfortunately, because the Android platform and\nits API evolve at an extremely rapid pace, app developers need to continually\nmonitor API changes to avoid compatibility issues in their apps (\\ie issues\nthat prevent apps from working as expected when running on newer versions of\nthe API). Despite a large number of studies on compatibility issues in the\nAndroid API, the research community has not yet investigated issues related to\nsilently-evolved methods (SEMs). These methods are functions whose behavior\nmight have changed but the corresponding documentation did not change\naccordingly. Because app developers rely on the provided documentation to\nevolve their apps, changes to methods that are not suitably documented may lead\nto unexpected failures in the apps using these methods.\nTo shed light on this type of issue, we conducted a large-scale empirical\nstudy in which we identified and characterized SEMs across ten versions of the\nAndroid API. In the study, we identified SEMs, characterized the nature of the\nchanges, and analyzed the impact of SEMs on a set of 1,000 real-world Android\napps. Our experimental results show that SEMs do exist in the Android API, and\nthat 957 of the apps we considered use at least one SEM. Based on these\nresults, we argue that the Android platform developers should take actions to\navoid introducing SEMs, especially those involving semantic changes. This\nsituation highlights the need for automated techniques and tools to help\nAndroid practitioners in this task.",
    "descriptor": "",
    "authors": [
      "Pei Liu",
      "Li Li",
      "Yichun Yan",
      "Mattia Fazzini",
      "John Grundy"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2205.15546"
  },
  {
    "id": "arXiv:2205.15547",
    "title": "Discovery of Keys for Graphs [Extended Version]",
    "abstract": "Keys for graphs uses the topology and value constraints needed to uniquely\nidentify entities in a graph database. They have been studied to support object\nidentification, knowledge fusion, data deduplication, and social network\nreconciliation. In this paper, we present our algorithm to mine keys over\ngraphs. Our algorithm discovers keys in a graph via frequent subgraph\nexpansion. We present two properties that define a meaningful key, including\nminimality and support. Lastly, using real-world graphs, we experimentally\nverify the efficiency of our algorithm on real world graphs.",
    "descriptor": "",
    "authors": [
      "Morteza Alipourlangouri",
      "Fei Chiang"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2205.15547"
  },
  {
    "id": "arXiv:2205.15550",
    "title": "A Multi-level Supervised Contrastive Learning Framework for Low-Resource  Natural Language Inference",
    "abstract": "Natural Language Inference (NLI) is a growingly essential task in natural\nlanguage understanding, which requires inferring the relationship between the\nsentence pairs (premise and hypothesis). Recently, low-resource natural\nlanguage inference has gained increasing attention, due to significant savings\nin manual annotation costs and a better fit with real-world scenarios. Existing\nworks fail to characterize discriminative representations between different\nclasses with limited training data, which may cause faults in label prediction.\nHere we propose a multi-level supervised contrastive learning framework named\nMultiSCL for low-resource natural language inference. MultiSCL leverages a\nsentence-level and pair-level contrastive learning objective to discriminate\nbetween different classes of sentence pairs by bringing those in one class\ntogether and pushing away those in different classes. MultiSCL adopts a data\naugmentation module that generates different views for input samples to better\nlearn the latent representation. The pair-level representation is obtained from\na cross attention module. We conduct extensive experiments on two public NLI\ndatasets in low-resource settings, and the accuracy of MultiSCL exceeds other\nmodels by 3.1% on average. Moreover, our method outperforms the previous\nstate-of-the-art method on cross-domain tasks of text classification.",
    "descriptor": "",
    "authors": [
      "Shu'ang Li",
      "Xuming Hu",
      "Li Lin",
      "Aiwei Liu",
      "Lijie Wen",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.15550"
  },
  {
    "id": "arXiv:2205.15553",
    "title": "Mask2Hand: Learning to Predict the 3D Hand Pose and Shape from Shadow",
    "abstract": "We present a self-trainable method, Mask2Hand, which learns to solve the\nchallenging task of predicting 3D hand pose and shape from a 2D binary mask of\nhand silhouette/shadow without additional manually-annotated data. Given the\nintrinsic camera parameters and the parametric hand model in the camera space,\nwe adopt the differentiable rendering technique to project 3D estimations onto\nthe 2D binary silhouette space. By applying a tailored combination of losses\nbetween the rendered silhouette and the input binary mask, we are able to\nintegrate the self-guidance mechanism into our end-to-end optimization process\nfor constraining global mesh registration and hand pose estimation. The\nexperiments show that our method, which takes a single binary mask as the\ninput, can achieve comparable prediction accuracy on both unaligned and aligned\nsettings as state-of-the-art methods that require RGB or depth inputs.",
    "descriptor": "",
    "authors": [
      "Li-Jen Chang",
      "Yu-Cheng Liao",
      "Chia-Hui Lin",
      "Hwann-Tzong Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15553"
  },
  {
    "id": "arXiv:2205.15555",
    "title": "Graph-level Neural Networks: Current Progress and Future Directions",
    "abstract": "Graph-structured data consisting of objects (i.e., nodes) and relationships\namong objects (i.e., edges) are ubiquitous. Graph-level learning is a matter of\nstudying a collection of graphs instead of a single graph. Traditional\ngraph-level learning methods used to be the mainstream. However, with the\nincreasing scale and complexity of graphs, Graph-level Neural Networks (GLNNs,\ndeep learning-based graph-level learning methods) have been attractive due to\ntheir superiority in modeling high-dimensional data. Thus, a survey on GLNNs is\nnecessary. To frame this survey, we propose a systematic taxonomy covering\nGLNNs upon deep neural networks, graph neural networks, and graph pooling. The\nrepresentative and state-of-the-art models in each category are focused on this\nsurvey. We also investigate the reproducibility, benchmarks, and new graph\ndatasets of GLNNs. Finally, we conclude future directions to further push\nforward GLNNs. The repository of this survey is available at\nhttps://github.com/GeZhangMQ/Awesome-Graph-level-Neural-Networks.",
    "descriptor": "",
    "authors": [
      "Ge Zhang",
      "Jia Wu",
      "Jian Yang",
      "Shan Xue",
      "Wenbin Hu",
      "Chuan Zhou",
      "Hao Peng",
      "Quan Z. Sheng",
      "Charu Aggarwal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15555"
  },
  {
    "id": "arXiv:2205.15556",
    "title": "Optimal Cloud Network Control with Strict Latency Constraints",
    "abstract": "The timely delivery of resource-intensive and latency-sensitive services\n(e.g., industrial automation, augmented reality) over distributed computing\nnetworks (e.g., mobile edge computing) is drawing increasing attention.\nMotivated by the insufficiency of average delay performance guarantees provided\nby existing studies, we focus on the critical goal of delivering next\ngeneration real-time services ahead of corresponding deadlines on a per-packet\nbasis, while minimizing overall cloud network resource cost. We introduce a\nnovel queuing system that is able to track data packets' lifetime and formalize\nthe optimal cloud network control problem with strict deadline constraints.\nAfter illustrating the main challenges in delivering packets to their\ndestinations before getting dropped due to lifetime expiry, we construct an\nequivalent formulation, where relaxed flow conservation allows leveraging\nLyapunov optimization to derive a provably near-optimal fully distributed\nalgorithm for the original problem. Numerical results validate the theoretical\nanalysis and show the superior performance of the proposed control policy\ncompared with state-of-the-art cloud network control.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2205.02427\n",
    "authors": [
      "Yang Cai",
      "Jaime Llorca",
      "Antonia M. Tulino",
      "Andreas F. Molisch"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.15556"
  },
  {
    "id": "arXiv:2205.15557",
    "title": "Optimal Multicast Service Chain Control: Packet Processing, Routing, and  Duplication",
    "abstract": "Distributed computing (cloud) networks, e.g., mobile edge computing (MEC),\nare playing an increasingly important role in the efficient hosting, running,\nand delivery of real-time stream-processing applications such as industrial\nautomation, immersive video, and augmented reality. While such applications\nrequire timely processing of real-time streams that are simultaneously useful\nfor multiple users/devices, existing technologies lack efficient mechanisms to\nhandle their increasingly multicast nature, leading to unnecessary traffic\nredundancy and associated network congestion. In this paper, we address the\ndesign of distributed packet processing, routing, and duplication policies for\noptimal control of multicast stream-processing services. We present a\ncharacterization of the enlarged capacity region that results from efficient\npacket duplication, and design the first fully distributed multicast traffic\nmanagement policy that stabilizes any input rate in the interior of the\ncapacity region while minimizing overall operational cost. Numerical results\ndemonstrate the effectiveness of the proposed policy to achieve throughput- and\ncost-optimal delivery of stream-processing services over distributed computing\nnetworks.",
    "descriptor": "",
    "authors": [
      "Yang Cai",
      "Jaime Llorca",
      "Antonia M. Tulino",
      "Andreas F. Molisch"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.15557"
  },
  {
    "id": "arXiv:2205.15561",
    "title": "Automatically Detecting API-induced Compatibility Issues in Android  Apps: A Comparative Analysis (Replicability Study)",
    "abstract": "Fragmentation is a serious problem in the Android ecosystem. This problem is\nmainly caused by the fast evolution of the system itself and the various\ncustomizations independently maintained by different smartphone manufacturers.\nMany efforts have attempted to mitigate its impact via approaches to\nautomatically pinpoint compatibility issues in Android apps. Unfortunately, at\nthis stage, it is still unknown if this objective has been fulfilled, and the\nexisting approaches can indeed be replicated and reliably leveraged to pinpoint\ncompatibility issues in the wild. We, therefore, propose to fill this gap by\nfirst conducting a literature review within this topic to identify all the\navailable approaches. Among the nine identified approaches, we then try our\nbest to reproduce them based on their original datasets. After that, we go one\nstep further to empirically compare those approaches against common datasets\nwith real-world apps containing compatibility issues. Experimental results show\nthat existing tools can indeed be reproduced, but their capabilities are quite\ndistinct, as confirmed by the fact that there is only a small overlap of the\nresults reported by the selected tools. This evidence suggests that more\nefforts should be spent by our community to achieve sound compatibility issues\ndetection.",
    "descriptor": "",
    "authors": [
      "Pei Liu",
      "Yanjie Zhao",
      "Haipeng Cai",
      "Mattia Fazzini",
      "John Grundy",
      "Li Li"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2205.15561"
  },
  {
    "id": "arXiv:2205.15562",
    "title": "iFS-RCNN: An Incremental Few-shot Instance Segmenter",
    "abstract": "This paper addresses incremental few-shot instance segmentation, where a few\nexamples of new object classes arrive when access to training examples of old\nclasses is not available anymore, and the goal is to perform well on both old\nand new classes. We make two contributions by extending the common Mask-RCNN\nframework in its second stage -- namely, we specify a new object class\nclassifier based on the probit function and a new uncertainty-guided\nbounding-box predictor. The former leverages Bayesian learning to address a\npaucity of training examples of new classes. The latter learns not only to\npredict object bounding boxes but also to estimate the uncertainty of the\nprediction as guidance for bounding box refinement. We also specify two new\nloss functions in terms of the estimated object-class distribution and\nbounding-box uncertainty. Our contributions produce significant performance\ngains on the COCO dataset over the state of the art -- specifically, the gain\nof +6 on the new classes and +16 on the old classes in the AP instance\nsegmentation metric. Furthermore, we are the first to evaluate the incremental\nfew-shot setting on the more challenging LVIS dataset.",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Khoi Nguyen",
      "Sinisa Todorovic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15562"
  },
  {
    "id": "arXiv:2205.15564",
    "title": "Secure Federated Clustering",
    "abstract": "We consider a foundational unsupervised learning task of $k$-means data\nclustering, in a federated learning (FL) setting consisting of a central server\nand many distributed clients. We develop SecFC, which is a secure federated\nclustering algorithm that simultaneously achieves 1) universal performance: no\nperformance loss compared with clustering over centralized data, regardless of\ndata distribution across clients; 2) data privacy: each client's private data\nand the cluster centers are not leaked to other clients and the server. In\nSecFC, the clients perform Lagrange encoding on their local data and share the\ncoded data in an information-theoretically private manner; then leveraging the\nalgebraic structure of the coding, the FL network exactly executes the Lloyd's\n$k$-means heuristic over the coded data to obtain the final clustering.\nExperiment results on synthetic and real datasets demonstrate the universally\nsuperior performance of SecFC for different data distributions across clients,\nand its computational practicality for various combinations of system\nparameters. Finally, we propose an extension of SecFC to further provide\nmembership privacy for all data points.",
    "descriptor": "",
    "authors": [
      "Songze Li",
      "Sizai Hou",
      "Baturalp Buyukates",
      "Salman Avestimehr"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.15564"
  },
  {
    "id": "arXiv:2205.15565",
    "title": "Sub-Image Histogram Equalization using Coot Optimization Algorithm for  Segmentation and Parameter Selection",
    "abstract": "Contrast enhancement is very important in terms of assessing images in an\nobjective way. Contrast enhancement is also significant for various algorithms\nincluding supervised and unsupervised algorithms for accurate classification of\nsamples. Some contrast enhancement algorithms solve this problem by addressing\nthe low contrast issue. Mean and variance based sub-image histogram\nequalization (MVSIHE) algorithm is one of these contrast enhancements methods\nproposed in the literature. It has different parameters which need to be tuned\nin order to achieve optimum results. With this motivation, in this study, we\nemployed one of the most recent optimization algorithms, namely, coot\noptimization algorithm (COA) for selecting appropriate parameters for the\nMVSIHE algorithm. Blind/referenceless image spatial quality evaluator (BRISQUE)\nand natural image quality evaluator (NIQE) metrics are used for evaluating\nfitness of the coot swarm population. The results show that the proposed method\ncan be used in the field of biomedical image processing.",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Emre Can Kuran",
      "Umut Kuran",
      "Mehmet Bilal Er"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2205.15565"
  },
  {
    "id": "arXiv:2205.15567",
    "title": "Few-Shot Unlearning by Model Inversion",
    "abstract": "We consider the problem of machine unlearning to erase a target dataset,\nwhich causes an unwanted behavior, from the trained model when the training\ndataset is not given. Previous works have assumed that the target dataset\nindicates all the training data imposing the unwanted behavior. However, it is\noften infeasible to obtain such a complete indication. We hence address a\npractical scenario of unlearning provided a few samples of target data,\nso-called few-shot unlearning. To this end, we devise a straightforward\nframework, including a new model inversion technique to retrieve the training\ndata from the model, followed by filtering out samples similar to the target\nsamples and then relearning. We demonstrate that our method using only a subset\nof target data can outperform the state-of-the-art methods with a full\nindication of target data.",
    "descriptor": "",
    "authors": [
      "Youngsik Yoon",
      "Jinhwan Nam",
      "Hyojeong Yun",
      "Dongwoo Kim",
      "Jungseul Ok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15567"
  },
  {
    "id": "arXiv:2205.15568",
    "title": "HW-Aware Initialization of DNN Auto-Tuning to Improve Exploration Time  and Robustness",
    "abstract": "The process of optimizing the latency of DNN operators with ML models and\nhardware-in-the-loop, called auto-tuning, has established itself as a pervasive\nmethod for the deployment of neural networks. From a search space of\nloop-optimizations, the candidate providing the best performance has to be\nselected. Performance of individual configurations is evaluated through\nhardware measurements. The combinatorial explosion of possible configurations,\ntogether with the cost of hardware evaluation makes exhaustive explorations of\nthe search space infeasible in practice. Machine Learning methods, like random\nforests or reinforcement learning are used to aid in the selection of\ncandidates for hardware evaluation. For general purpose hardware like x86 and\nGPGPU architectures impressive performance gains can be achieved, compared to\nhand-optimized libraries like cuDNN. The method is also useful in the space of\nhardware accelerators with less wide-spread adoption, where a high-performance\nlibrary is not always available. However, hardware accelerators are often less\nflexible with respect to their programming which leads to operator\nconfigurations not executable on the hardware target. This work evaluates how\nthese invalid configurations affect the auto-tuning process and its underlying\nperformance prediction model for the VTA hardware. From these results, a\nvalidity-driven initialization method for AutoTVM is developed, only requiring\n41.6% of the necessary hardware measurements to find the best solution, while\nimproving search robustness.",
    "descriptor": "",
    "authors": [
      "Dennis Rieber",
      "Moritz Reiber",
      "Oliver Bringmann",
      "Holger Fr\u00f6ning"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2205.15568"
  },
  {
    "id": "arXiv:2205.15569",
    "title": "GSR: A Generalized Symbolic Regression Approach",
    "abstract": "Identifying the mathematical relationships that best describe a dataset\nremains a very challenging problem in machine learning, and is known as\nSymbolic Regression (SR). In contrast to neural networks which are often\ntreated as black boxes, SR attempts to gain insight into the underlying\nrelationships between the independent variables and the target variable of a\ngiven dataset by assembling analytical functions. In this paper, we present\nGSR, a Generalized Symbolic Regression approach, by modifying the conventional\nSR optimization problem formulation, while keeping the main SR objective\nintact. In GSR, we infer mathematical relationships between the independent\nvariables and some transformation of the target variable. We constrain our\nsearch space to a weighted sum of basis functions, and propose a genetic\nprogramming approach with a matrix-based encoding scheme. We show that our GSR\nmethod outperforms several state-of-the-art methods on the well-known SR\nbenchmark problem sets. Finally, we highlight the strengths of GSR by\nintroducing SymSet, a new SR benchmark set which is more challenging relative\nto the existing benchmarks.",
    "descriptor": "",
    "authors": [
      "Tony Tohme",
      "Dehong Liu",
      "Kamal Youcef-Toumi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2205.15569"
  },
  {
    "id": "arXiv:2205.15571",
    "title": "Hierarchical Spherical CNNs with Lifting-based Adaptive Wavelets for  Pooling and Unpooling",
    "abstract": "Pooling and unpooling are two essential operations in constructing\nhierarchical spherical convolutional neural networks (HS-CNNs) for\ncomprehensive feature learning in the spherical domain. Most existing models\nemploy downsampling-based pooling, which will inevitably incur information loss\nand cannot adapt to different spherical signals and tasks. Besides, the\npreserved information after pooling cannot be well restored by the subsequent\nunpooling to characterize the desirable features for a task. In this paper, we\npropose a novel framework of HS-CNNs with a lifting structure to learn adaptive\nspherical wavelets for pooling and unpooling, dubbed LiftHS-CNN, which ensures\na more efficient hierarchical feature learning for both image- and pixel-level\ntasks. Specifically, adaptive spherical wavelets are learned with a lifting\nstructure that consists of trainable lifting operators (i.e., update and\npredict operators). With this learnable lifting structure, we can adaptively\npartition a signal into two sub-bands containing low- and high-frequency\ncomponents, respectively, and thus generate a better down-scaled representation\nfor pooling by preserving more information in the low-frequency sub-band. The\nupdate and predict operators are parameterized with graph-based attention to\njointly consider the signal's characteristics and the underlying geometries. We\nfurther show that particular properties are promised by the learned wavelets,\nensuring the spatial-frequency localization for better exploiting the signal's\ncorrelation in both spatial and frequency domains. We then propose an unpooling\noperation that is invertible to the lifting-based pooling, where an inverse\nwavelet transform is performed by using the learned lifting operators to\nrestore an up-scaled representation. Extensive empirical evaluations on various\nspherical domain tasks validate the superiority of the proposed LiftHS-CNN.",
    "descriptor": "",
    "authors": [
      "Mingxing Xu",
      "Chenglin Li",
      "Wenrui Dai",
      "Siheng Chen",
      "Junni Zou",
      "Pascal Frossard",
      "Hongkai Xiong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.15571"
  },
  {
    "id": "arXiv:2205.15572",
    "title": "3PSDF: Three-Pole Signed Distance Function for Learning Surfaces with  Arbitrary Topologies",
    "abstract": "Recent advances in learning 3D shapes using neural implicit functions have\nachieved impressive results by breaking the previous barrier of resolution and\ndiversity for varying topologies. However, most of such approaches are limited\nto closed surfaces as they require the space to be divided into inside and\noutside. More recent works based on unsigned distance function have been\nproposed to handle complex geometry containing both the open and closed\nsurfaces. Nonetheless, as their direct outputs are point clouds, robustly\nobtaining high-quality meshing results from discrete points remains an open\nquestion. We present a novel learnable implicit representation, called the\nthree-pole signed distance function (3PSDF), that can represent non-watertight\n3D shapes with arbitrary topologies while supporting easy field-to-mesh\nconversion using the classic Marching Cubes algorithm. The key to our method is\nthe introduction of a new sign, the NULL sign, in addition to the conventional\nin and out labels. The existence of the null sign could stop the formation of a\nclosed isosurface derived from the bisector of the in/out regions. Further, we\npropose a dedicated learning framework to effectively learn 3PSDF without\nworrying about the vanishing gradient due to the null labels. Experimental\nresults show that our approach outperforms the previous state-of-the-art\nmethods in a wide range of benchmarks both quantitatively and qualitatively.",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Weikai Chen",
      "Cheng Lin",
      "Weiyang Li",
      "Bo Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2205.15572"
  },
  {
    "id": "arXiv:2205.15573",
    "title": "Text/Speech-Driven Full-Body Animation",
    "abstract": "Due to the increasing demand in films and games, synthesizing 3D avatar\nanimation has attracted much attention recently. In this work, we present a\nproduction-ready text/speech-driven full-body animation synthesis system. Given\nthe text and corresponding speech, our system synthesizes face and body\nanimations simultaneously, which are then skinned and rendered to obtain a\nvideo stream output. We adopt a learning-based approach for synthesizing facial\nanimation and a graph-based approach to animate the body, which generates\nhigh-quality avatar animation efficiently and robustly. Our results demonstrate\nthe generated avatar animations are realistic, diverse and highly\ntext/speech-correlated.",
    "descriptor": "\nComments: IJCAI-2022 demo track, video see this https URL\n",
    "authors": [
      "Wenlin Zhuang",
      "Jinwei Qi",
      "Peng Zhang",
      "Bang Zhang",
      "Ping Tan"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2205.15573"
  },
  {
    "id": "arXiv:2205.15575",
    "title": "hmBERT: Historical Multilingual Language Models for Named Entity  Recognition",
    "abstract": "Compared to standard Named Entity Recognition (NER), identifying persons,\nlocations, and organizations in historical texts forms a big challenge. To\nobtain machine-readable corpora, the historical text is usually scanned and\noptical character recognition (OCR) needs to be performed. As a result, the\nhistorical corpora contain errors. Also, entities like location or organization\ncan change over time, which poses another challenge. Overall historical texts\ncome with several peculiarities that differ greatly from modern texts and large\nlabeled corpora for training a neural tagger are hardly available for this\ndomain. In this work, we tackle NER for historical German, English, French,\nSwedish, and Finnish by training large historical language models. We\ncircumvent the need for labeled data by using unlabeled data for pretraining a\nlanguage model. hmBERT, a historical multilingual BERT-based language model is\nproposed, with different sizes of it being publicly released. Furthermore, we\nevaluate the capability of hmBERT by solving downstream NER as part of this\nyear's HIPE-2022 shared task and provide detailed analysis and insights. For\nthe Multilingual Classical Commentary coarse-grained NER challenge, our tagger\nHISTeria outperforms the other teams' models for two out of three languages.",
    "descriptor": "\nComments: Submitted HIPE-2022 Working Note Paper for CLEF 2022 (Conference and Labs of the Evaluation Forum (CLEF 2022))\n",
    "authors": [
      "Stefan Schweter",
      "Luisa M\u00e4rz",
      "Katharina Schmid",
      "Erion \u00c7ano"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.15575"
  },
  {
    "id": "arXiv:2205.15577",
    "title": "MontageGAN: Generation and Assembly of Multiple Components by GANs",
    "abstract": "A multi-layer image is more valuable than a single-layer image from a graphic\ndesigner's perspective. However, most of the proposed image generation methods\nso far focus on single-layer images. In this paper, we propose MontageGAN,\nwhich is a Generative Adversarial Networks (GAN) framework for generating\nmulti-layer images. Our method utilized a two-step approach consisting of local\nGANs and global GAN. Each local GAN learns to generate a specific image layer,\nand the global GAN learns the placement of each generated image layer. Through\nour experiments, we show the ability of our method to generate multi-layer\nimages and estimate the placement of the generated image layers.",
    "descriptor": "\nComments: Accepted at ICPR2022\n",
    "authors": [
      "Chean Fei Shee",
      "Seiichi Uchida"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2205.15577"
  },
  {
    "id": "arXiv:2205.15580",
    "title": "A Computation and Communication Efficient Method for Distributed  Nonconvex Problems in the Partial Participation Setting",
    "abstract": "We present a new method that includes three key components of distributed\noptimization and federated learning: variance reduction of stochastic\ngradients, compressed communication, and partial participation. We prove that\nthe new method has optimal oracle complexity and state-of-the-art communication\ncomplexity in the partial participation setting. Moreover, we observe that \"1 +\n1 + 1 is not 3\": by mixing variance reduction of stochastic gradients with\ncompressed communication and partial participation, we do not obtain a fully\nsynergetic effect. We explain the nature of this phenomenon, argue that this is\nto be expected, and propose possible workarounds.",
    "descriptor": "",
    "authors": [
      "Alexander Tyurin",
      "Peter Richt\u00e1rik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2205.15580"
  },
  {
    "id": "arXiv:2205.15582",
    "title": "An Effective Fusion Method to Enhance the Robustness of CNN",
    "abstract": "With the development of technology rapidly, applications of convolutional\nneural networks have improved the convenience of our life. However, in image\nclassification field, it has been found that when some perturbations are added\nto images, the CNN would misclassify it. Thus various defense methods have been\nproposed. The previous approach only considered how to incorporate modules in\nthe network to improve robustness, but did not focus on the way the modules\nwere incorporated. In this paper, we design a new fusion method to enhance the\nrobustness of CNN. We use a dot product-based approach to add the denoising\nmodule to ResNet18 and the attention mechanism to further improve the\nrobustness of the model. The experimental results on CIFAR10 have shown that\nour method is effective and better than the state-of-the-art methods under the\nattack of FGSM and PGD.",
    "descriptor": "",
    "authors": [
      "Yating Ma",
      "Zhichao Lian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15582"
  },
  {
    "id": "arXiv:2205.15585",
    "title": "Decomposing NeRF for Editing via Feature Field Distillation",
    "abstract": "Emerging neural radiance fields (NeRF) are a promising scene representation\nfor computer graphics, enabling high-quality 3D reconstruction and novel view\nsynthesis from image observations. However, editing a scene represented by a\nNeRF is challenging, as the underlying connectionist representations such as\nMLPs or voxel grids are not object-centric or compositional. In particular, it\nhas been difficult to selectively edit specific regions or objects. In this\nwork, we tackle the problem of semantic scene decomposition of NeRFs to enable\nquery-based local editing of the represented 3D scenes. We propose to distill\nthe knowledge of off-the-shelf, self-supervised 2D image feature extractors\nsuch as CLIP-LSeg or DINO into a 3D feature field optimized in parallel to the\nradiance field. Given a user-specified query of various modalities such as\ntext, an image patch, or a point-and-click selection, 3D feature fields\nsemantically decompose 3D space without the need for re-training and enable us\nto semantically select and edit regions in the radiance field. Our experiments\nvalidate that the distilled feature fields (DFFs) can transfer recent progress\nin 2D vision and language foundation models to 3D scene representations,\nenabling convincing 3D segmentation and selective editing of emerging neural\ngraphics representations.",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Sosuke Kobayashi",
      "Eiichi Matsumoto",
      "Vincent Sitzmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2205.15585"
  },
  {
    "id": "arXiv:2205.15592",
    "title": "Semantic Autoencoder and Its Potential Usage for Adversarial Attack",
    "abstract": "Autoencoder can give rise to an appropriate latent representation of the\ninput data, however, the representation which is solely based on the intrinsic\nproperty of the input data, is usually inferior to express some semantic\ninformation. A typical case is the potential incapability of forming a clear\nboundary upon clustering of these representations. By encoding the latent\nrepresentation that not only depends on the content of the input data, but also\nthe semantic of the input data, such as label information, we propose an\nenhanced autoencoder architecture named semantic autoencoder. Experiments of\nrepresentation distribution via t-SNE shows a clear distinction between these\ntwo types of encoders and confirm the supremacy of the semantic one, whilst the\ndecoded samples of these two types of autoencoders exhibit faint dissimilarity\neither objectively or subjectively. Based on this observation, we consider\nadversarial attacks to learning algorithms that rely on the latent\nrepresentation obtained via autoencoders. It turns out that latent contents of\nadversarial samples constructed from semantic encoder with deliberate wrong\nlabel information exhibit different distribution compared with that of the\noriginal input data, while both of these samples manifest very marginal\ndifference. This new way of attack set up by our work is worthy of attention\ndue to the necessity to secure the widespread deep learning applications.",
    "descriptor": "",
    "authors": [
      "Yurui Ming",
      "Cuihuan Du",
      "Chin-Teng Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.15592"
  },
  {
    "id": "arXiv:2205.15595",
    "title": "Novel View Synthesis for High-fidelity Headshot Scenes",
    "abstract": "Rendering scenes with a high-quality human face from arbitrary viewpoints is\na practical and useful technique for many real-world applications. Recently,\nNeural Radiance Fields (NeRF), a rendering technique that uses neural networks\nto approximate classical ray tracing, have been considered as one of the\npromising approaches for synthesizing novel views from a sparse set of images.\nWe find that NeRF can render new views while maintaining geometric consistency,\nbut it does not properly maintain skin details, such as moles and pores. These\ndetails are important particularly for faces because when we look at an image\nof a face, we are much more sensitive to details than when we look at other\nobjects. On the other hand, 3D Morpable Models (3DMMs) based on traditional\nmeshes and textures can perform well in terms of skin detail despite that it\nhas less precise geometry and cannot cover the head and the entire scene with\nbackground. Based on these observations, we propose a method to use both NeRF\nand 3DMM to synthesize a high-fidelity novel view of a scene with a face. Our\nmethod learns a Generative Adversarial Network (GAN) to mix a NeRF-synthesized\nimage and a 3DMM-rendered image and produces a photorealistic scene with a face\npreserving the skin details. Experiments with various real-world scenes\ndemonstrate the effectiveness of our approach. The code will be available on\nhttps://github.com/showlab/headshot .",
    "descriptor": "",
    "authors": [
      "Satoshi Tsutsui",
      "Weijia Mao",
      "Sijing Lin",
      "Yunyi Zhu",
      "Murong Ma",
      "Mike Zheng Shou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15595"
  },
  {
    "id": "arXiv:2205.15598",
    "title": "Individual health-disease phase diagrams for disease prevention based on  machine learning",
    "abstract": "Early disease detection and prevention methods based on effective\ninterventions are gaining attention. Machine learning technology has enabled\nprecise disease prediction by capturing individual differences in multivariate\ndata. Progress in precision medicine has revealed that substantial\nheterogeneity exists in health data at the individual level and that complex\nhealth factors are involved in the development of chronic diseases. However, it\nremains a challenge to identify individual physiological state changes in\ncross-disease onset processes because of the complex relationships among\nmultiple biomarkers. Here, we present the health-disease phase diagram (HDPD),\nwhich represents a personal health state by visualizing the boundary values of\nmultiple biomarkers that fluctuate early in the disease progression process. In\nHDPDs, future onset predictions are represented by perturbing multiple\nbiomarker values while accounting for dependencies among variables. We\nconstructed HDPDs for 11 non-communicable diseases (NCDs) from a longitudinal\nhealth checkup cohort of 3,238 individuals, comprising 3,215 measurement items\nand genetic data. Improvement of biomarker values to the non-onset region in\nHDPD significantly prevented future disease onset in 7 out of 11 NCDs. Our\nresults demonstrate that HDPDs can represent individual physiological states in\nthe onset process and be used as intervention goals for disease prevention.",
    "descriptor": "",
    "authors": [
      "Kazuki Nakamura",
      "Eiichiro Uchino",
      "Noriaki Sato",
      "Ayano Araki",
      "Kei Terayama",
      "Ryosuke Kojima",
      "Koichi Murashita",
      "Ken Itoh",
      "Tatsuya Mikami",
      "Yoshinori Tamada",
      "Yasushi Okuno"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.15598"
  },
  {
    "id": "arXiv:2205.15599",
    "title": "Preparing an Endangered Language for the Digital Age: The Case of  Judeo-Spanish",
    "abstract": "We develop machine translation and speech synthesis systems to complement the\nefforts of revitalizing Judeo-Spanish, the exiled language of Sephardic Jews,\nwhich survived for centuries, but now faces the threat of extinction in the\ndigital age. Building on resources created by the Sephardic community of Turkey\nand elsewhere, we create corpora and tools that would help preserve this\nlanguage for future generations. For machine translation, we first develop a\nSpanish to Judeo-Spanish rule-based machine translation system, in order to\ngenerate large volumes of synthetic parallel data in the relevant language\npairs: Turkish, English and Spanish. Then, we train baseline neural machine\ntranslation engines using this synthetic data and authentic parallel data\ncreated from translations by the Sephardic community. For text-to-speech\nsynthesis, we present a 3.5 hour single speaker speech corpus for building a\nneural speech synthesis engine. Resources, model weights and online inference\nengines are shared publicly.",
    "descriptor": "",
    "authors": [
      "Alp \u00d6ktem",
      "Rodolfo Zevallos",
      "Yasmin Moslem",
      "G\u00fcne\u015f \u00d6zt\u00fcrk",
      "Karen \u015earhon"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.15599"
  },
  {
    "id": "arXiv:2205.15606",
    "title": "Zero-Emission Delivery for Logistics and Transportation: Challenges,  Research Issues, and Opportunities",
    "abstract": "Greenhouse gas, produced from various industries such as Power,\nManufacturing, Transport, Chemical, or Agriculture, is the major source of\nglobal warming. While the transport industry is among the top three major\ncontributors, accounting for 16.2% of global emissions. To counter this, many\ncountries are responding actively to achieve net or absolute zero-emission\ngoals by replacing fossil fuel with renewable energy sources. In response to\nthis initiative, this chapter provides a systematic review of the use of\nzero-emission vehicles for a specific use case of package delivery. It first\ncompares different green delivery systems that use unmanned aerial vehicles,\nelectric vehicles, and fuel-cell trucks for certain weight categories.\nSpecifically, a coordination of unmanned aerial vehicle and ground-based\nelectric truck envisions a new paradigm of ground-based zero-emission vehicles\nwhere unmanned aerial vehicles can fly in the air beyond the visual line of\nsight empowered by future-generation wireless technologies. The integration of\nzero-emission vehicles for package delivery will encounter many challenges in\nanalyzing, modelling, planning, and designing a green logistics system. This\nchapter investigates these challenges in the adoption of zero-emission vehicles\nwith the existing research issues from a technical, environmental, economic,\nand political point of view. In addition, this study also sheds a new research\nperspective on artificial intelligence and integrated solutions for\nzero-emission deliveries.",
    "descriptor": "\nComments: 20 pages, 9 figures\n",
    "authors": [
      "J. Bukhari",
      "A.G. Somanagoudar",
      "L. Hou",
      "O. Herrera",
      "W. Merida"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2205.15606"
  },
  {
    "id": "arXiv:2205.15608",
    "title": "Weakly-supervised Action Transition Learning for Stochastic Human Motion  Prediction",
    "abstract": "We introduce the task of action-driven stochastic human motion prediction,\nwhich aims to predict multiple plausible future motions given a sequence of\naction labels and a short motion history. This differs from existing works,\nwhich predict motions that either do not respect any specific action category,\nor follow a single action label. In particular, addressing this task requires\ntackling two challenges: The transitions between the different actions must be\nsmooth; the length of the predicted motion depends on the action sequence and\nvaries significantly across samples. As we cannot realistically expect training\ndata to cover sufficiently diverse action transitions and motion lengths, we\npropose an effective training strategy consisting of combining multiple motions\nfrom different actions and introducing a weak form of supervision to encourage\nsmooth transitions. We then design a VAE-based model conditioned on both the\nobserved motion and the action label sequence, allowing us to generate multiple\nplausible future motions of varying length. We illustrate the generality of our\napproach by exploring its use with two different temporal encoding models,\nnamely RNNs and Transformers. Our approach outperforms baseline models\nconstructed by adapting state-of-the-art single action-conditioned motion\ngeneration methods and stochastic human motion prediction approaches to our new\ntask of action-driven stochastic motion prediction. Our code is available at\nhttps://github.com/wei-mao-2019/WAT.",
    "descriptor": "\nComments: CVPR2022 (Oral)\n",
    "authors": [
      "Wei Mao",
      "Miaomiao Liu",
      "Mathieu Salzmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.15608"
  },
  {
    "id": "arXiv:2205.15609",
    "title": "Bag of Tricks for Domain Adaptive Multi-Object Tracking",
    "abstract": "In this paper, SIA_Track is presented which is developed by a research team\nfrom SI Analytics. The proposed method was built from pre-existing detector and\ntracker under the tracking-by-detection paradigm. The tracker we used is an\nonline tracker that merely links newly received detections with existing\ntracks. The core part of our method is training procedure of the object\ndetector where synthetic and unlabeled real data were only used for training.\nTo maximize the performance on real data, we first propose to use\npseudo-labeling that generates imperfect labels for real data using a model\ntrained with synthetic dataset. After that model soups scheme was applied to\naggregate weights produced during iterative pseudo-labeling. Besides,\ncross-domain mixed sampling also helped to increase detection performance on\nreal data. Our method, SIA_Track, takes the first place on MOTSynth2MOT17 track\nat BMTT 2022 challenge. The code is available on\nhttps://github.com/SIAnalytics/BMTT2022_SIA_track.",
    "descriptor": "\nComments: This technical paper contains a brief overview of the proposed method, SIA_Track, which wins the MOTSynth2MOT17 track at BMTT 2022 challenge\n",
    "authors": [
      "Minseok Seo",
      "Jeongwon Ryu",
      "Kwangjin Yoon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15609"
  },
  {
    "id": "arXiv:2205.15612",
    "title": "GlanceNets: Interpretabile, Leak-proof Concept-based Models",
    "abstract": "There is growing interest in concept-based models (CBMs) that combine\nhigh-performance and interpretability by acquiring and reasoning with a\nvocabulary of high-level concepts. A key requirement is that the concepts be\ninterpretable. Existing CBMs tackle this desideratum using a variety of\nheuristics based on unclear notions of interpretability, and fail to acquire\nconcepts with the intended semantics. We address this by providing a clear\ndefinition of interpretability in terms of alignment between the model's\nrepresentation and an underlying data generation process, and introduce\nGlanceNets, a new CBM that exploits techniques from disentangled representation\nlearning and open-set recognition to achieve alignment, thus improving the\ninterpretability of the learned concepts. We show that GlanceNets, paired with\nconcept-level supervision, achieve better alignment than state-of-the-art\napproaches while preventing spurious information from unintendedly leaking into\nthe learned concepts.",
    "descriptor": "",
    "authors": [
      "Emanuele Marconato",
      "Andrea Passerini",
      "Stefano Teso"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15612"
  },
  {
    "id": "arXiv:2205.15614",
    "title": "Communication-Efficient Distributionally Robust Decentralized Learning",
    "abstract": "Decentralized learning algorithms empower interconnected edge devices to\nshare data and computational resources to collaboratively train a machine\nlearning model without the aid of a central coordinator (e.g. an orchestrating\nbasestation). In the case of heterogeneous data distributions at the network\ndevices, collaboration can yield predictors with unsatisfactory performance for\na subset of the devices. For this reason, in this work we consider the\nformulation of a distributionally robust decentralized learning task and we\npropose a decentralized single loop gradient descent/ascent algorithm (AD-GDA)\nto solve the underlying minimax optimization problem. We render our algorithm\ncommunication efficient by employing a compressed consensus scheme and we\nprovide convergence guarantees for smooth convex and non-convex loss functions.\nFinally, we corroborate the theoretical findings with empirical evidence of the\nability of the proposed algorithm in providing unbiased predictors over a\nnetwork of collaborating devices with highly heterogeneous data distributions.",
    "descriptor": "\nComments: Manuscript submitted for publication\n",
    "authors": [
      "Matteo Zecchin",
      "Marios Kountouris",
      "David Gesbert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.15614"
  },
  {
    "id": "arXiv:2205.15615",
    "title": "Fundamental CRB-Rate Tradeoff in Multi-antenna Multicast Channel with  ISAC",
    "abstract": "This paper studies the multi-antenna multicast channel with integrated\nsensing and communication (ISAC), in which a multi-antenna base station (BS)\nsends common messages to a set of single-antenna communication users (CUs) and\nsimultaneously estimates the parameters of an extended target via radar\nsensing. We investigate the fundamental performance limits of this ISAC system,\nin terms of the achievable rate for communication and the estimation\nCram\\'er-Rao bound (CRB) for sensing. First, we derive the optimal transmit\ncovariance in semi-closed form to balance the CRB-rate (C-R) tradeoff, and\naccordingly characterize the outer bound of a so-called C-R region. It is shown\nthat the optimal transmit covariance should be of full rank, consisting of both\ninformation-carrying and dedicated sensing signals in general. Next, we\nconsider a practical joint information and sensing beamforming design, and\npropose an efficient approach to optimize the joint beamforming for balancing\nthe C-R tradeoff. Numerical results are presented to show the C-R region\nachieved by the optimal transmit covariance and the joint beamforming, as\ncompared to other benchmark schemes.",
    "descriptor": "\nComments: conference\n",
    "authors": [
      "Zixiang Ren",
      "Xianxin Song",
      "Yuan Fang",
      "Ling Qiu",
      "Jie Xu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.15615"
  },
  {
    "id": "arXiv:2205.15617",
    "title": "Optimizing Intermediate Representations of Generative Models for Phase  Retrieval",
    "abstract": "Phase retrieval is the problem of reconstructing images from magnitude-only\nmeasurements. In many real-world applications the problem is underdetermined.\nWhen training data is available, generative models are a new idea to constrain\nthe solution set. However, not all possible solutions are within the range of\nthe generator. Instead, they are represented with some error. To reduce this\nrepresentation error in the context of phase retrieval, we first leverage a\nnovel variation of intermediate layer optimization (ILO) to extend the range of\nthe generator while still producing images consistent with the training data.\nSecond, we introduce new initialization schemes that further improve the\nquality of the reconstruction. With extensive experiments on Fourier and\nGaussian phase retrieval problems and thorough ablation studies, we can show\nthe benefits of our modified ILO and the new initialization schemes.",
    "descriptor": "\nComments: First two authors contributed equally\n",
    "authors": [
      "Tobias Uelwer",
      "Sebastian Konietzny",
      "Stefan Harmeling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2205.15617"
  },
  {
    "id": "arXiv:2205.15618",
    "title": "Local discontinuous Galerkin method for the Backward Feynman-Kac  Equation",
    "abstract": "Anomalous diffusions are ubiquitous in nature, whose functional distributions\nare governed by the backward Feynman-Kac equation. In this paper, the local\ndiscontinuous Galerkin (LDG) method is used to solve the 2D backward\nFeynman-Kac equation in a rectangular domain. The spatial semi-discrete LDG\nscheme of the equivalent form (obtained by Laplace transform) of the original\nequation is established. After discussing the properties of the fractional\nsubstantial calculus, the stability and optimal convergence rates $O(h^{k+1})$\nof the semi-discrete scheme are proved by choosing an appropriate generalized\nnumerical flux. The $L1$ scheme on the graded meshes is used to deal with the\nweak singularity of the solution near the initial time. Based on the\ntheoretical results of a semi-discrete scheme, we investigate the stability and\nconvergence of the fully discrete scheme, which shows the optimal convergence\nrates $O(h^{k+1}+\\tau^{\\min\\{2-\\alpha,\\gamma\\delta\\}})$. Numerical experiments\nare carried out to show the efficiency and accuracy of the proposed scheme. In\naddition, we also verify the effect of the central numerical flux on the\nconvergence rates and the condition number of the coefficient matrix.",
    "descriptor": "\nComments: 34 pages\n",
    "authors": [
      "Dong Liu",
      "Weihua Deng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.15618"
  },
  {
    "id": "arXiv:2205.15619",
    "title": "Meta-ticket: Finding optimal subnetworks for few-shot learning within  randomly initialized neural networks",
    "abstract": "Few-shot learning for neural networks (NNs) is an important problem that aims\nto train NNs with a few data. The main challenge is how to avoid overfitting\nsince over-parameterized NNs can easily overfit to such small dataset. Previous\nwork (e.g. MAML by Finn et al. 2017) tackles this challenge by meta-learning,\nwhich learns how to learn from a few data by using various tasks. On the other\nhand, one conventional approach to avoid overfitting is restricting hypothesis\nspaces by endowing sparse NN structures like convolution layers in computer\nvision. However, although such manually-designed sparse structures are\nsample-efficient for sufficiently large datasets, they are still insufficient\nfor few-shot learning. Then the following questions naturally arise: (1) Can we\nfind sparse structures effective for few-shot learning by meta-learning? (2)\nWhat benefits will it bring in terms of meta-generalization? In this work, we\npropose a novel meta-learning approach, called Meta-ticket, to find optimal\nsparse subnetworks for few-shot learning within randomly initialized NNs. We\nempirically validated that Meta-ticket successfully discover sparse subnetworks\nthat can learn specialized features for each given task. Due to this task-wise\nadaptation ability, Meta-ticket achieves superior meta-generalization compared\nto MAML-based methods especially with large NNs.",
    "descriptor": "\nComments: Code will be available at this https URL\n",
    "authors": [
      "Daiki Chijiwa",
      "Shin'ya Yamaguchi",
      "Atsutoshi Kumagai",
      "Yasutoshi Ida"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.15619"
  },
  {
    "id": "arXiv:2205.15623",
    "title": "k-Means Maximum Entropy Exploration",
    "abstract": "Exploration in high-dimensional, continuous spaces with sparse rewards is an\nopen problem in reinforcement learning. Artificial curiosity algorithms address\nthis by creating rewards that lead to exploration. Given a reinforcement\nlearning algorithm capable of maximizing rewards, the problem reduces to\nfinding an optimization objective consistent with exploration. Maximum entropy\nexploration uses the entropy of the state visitation distribution as such an\nobjective. However, efficiently estimating the entropy of the state visitation\ndistribution is challenging in high-dimensional, continuous spaces. We\nintroduce an artificial curiosity algorithm based on lower bounding an\napproximation to the entropy of the state visitation distribution. The bound\nrelies on a result for non-parametric density estimation in arbitrary\ndimensions using k-means. We show that our approach is both computationally\nefficient and competitive on benchmarks for exploration in high-dimensional,\ncontinuous spaces, especially on tasks where reinforcement learning algorithms\nare unable to find rewards.",
    "descriptor": "",
    "authors": [
      "Alexander Nedergaard",
      "Matthew Cook"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15623"
  },
  {
    "id": "arXiv:2205.15624",
    "title": "Scalable Distributional Robustness in a Class of Non Convex Optimization  with Guarantees",
    "abstract": "Distributionally robust optimization (DRO) has shown lot of promise in\nproviding robustness in learning as well as sample based optimization problems.\nWe endeavor to provide DRO solutions for a class of sum of fractionals,\nnon-convex optimization which is used for decision making in prominent areas\nsuch as facility location and security games. In contrast to previous work, we\nfind it more tractable to optimize the equivalent variance regularized form of\nDRO rather than the minimax form. We transform the variance regularized form to\na mixed-integer second order cone program (MISOCP), which, while guaranteeing\nnear global optimality, does not scale enough to solve problems with real world\ndata-sets. We further propose two abstraction approaches based on clustering\nand stratified sampling to increase scalability, which we then use for real\nworld data-sets. Importantly, we provide near global optimality guarantees for\nour approach and show experimentally that our solution quality is better than\nthe locally optimal ones achieved by state-of-the-art gradient-based methods.\nWe experimentally compare our different approaches and baselines, and reveal\nnuanced properties of a DRO solution.",
    "descriptor": "\nComments: 24 pages, 3 figures, 5 tables\n",
    "authors": [
      "Avinandan Bose",
      "Arunesh Sinha",
      "Tien Mai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2205.15624"
  },
  {
    "id": "arXiv:2205.15626",
    "title": "A Reduced Basis Method for Darcy flow systems that ensures local mass  conservation by using exact discrete complexes",
    "abstract": "A solution technique is proposed for flows in porous media that guarantees\nlocal conservation of mass. We first compute a flux field to balance the mass\nsource and then exploit exact co-chain complexes to generate a solenoidal\ncorrection. A reduced basis method based on proper orthogonal decomposition is\nemployed to construct the correction and we show that mass balance is ensured\nregardless of the quality of the reduced basis approximation. The method is\ndirectly applicable to mixed finite and virtual element methods, among other\nstructure-preserving discretization techniques, and we present the extension to\nDarcy flow in fractured porous media.",
    "descriptor": "",
    "authors": [
      "Wietse M. Boon",
      "Alessio Fumagalli"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.15626"
  },
  {
    "id": "arXiv:2205.15627",
    "title": "APPReddit: a Corpus of Reddit Posts Annotated for Appraisal",
    "abstract": "Despite the large number of computational resources for emotion recognition,\nthere is a lack of data sets relying on appraisal models. According to\nAppraisal theories, emotions are the outcome of a multi-dimensional evaluation\nof events. In this paper, we present APPReddit, the first corpus of\nnon-experimental data annotated according to this theory. After describing its\ndevelopment, we compare our resource with enISEAR, a corpus of events created\nin an experimental setting and annotated for appraisal. Results show that the\ntwo corpora can be mapped notwithstanding different typologies of data and\nannotations schemes. A SVM model trained on APPReddit predicts four appraisal\ndimensions without significant loss. Merging both corpora in a single training\nset increases the prediction of 3 out of 4 dimensions. Such findings pave the\nway to a better performing classification model for appraisal prediction.",
    "descriptor": "",
    "authors": [
      "Marco Antonio Stranisci",
      "Simona Frenda",
      "Eleonora Ceccaldi",
      "Valerio Basile",
      "Rossana Damiano",
      "Viviana Patti"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.15627"
  },
  {
    "id": "arXiv:2205.15628",
    "title": "Seniorities and Minimal Clearing in Financial Network Games",
    "abstract": "Financial network games model payment incentives in the context of networked\nliabilities. In this paper, we advance the understanding of incentives in\nfinancial networks in two important directions: minimal clearing (arising,\ne.g., as a result of sequential execution of payments) and seniorities (i.e.,\npriorities over debt contracts). We distinguish between priorities that are\nchosen endogenously or exogenously. For endogenous priorities and standard\n(maximal) clearing, the games exhibit a coalitional form of weak acyclicity. A\nstrong equilibrium exists and can be reached after a polynomial number of\ndeviations. Moreover, there is a strong equilibrium that is optimal for a wide\nvariety of social welfare functions. In contrast, for minimal clearing there\nare games in which no optimal strategy profile exists, even for standard\nutilitarian social welfare. Perhaps surprisingly, a strong equilibrium still\nexists and, for a wide range of strategies, can be reached after a polynomial\nnumber of deviations. In contrast, for exogenous priorities, equilibria can be\nabsent and equilibrium existence is NP-hard to decide, for both minimal and\nmaximal clearing.",
    "descriptor": "",
    "authors": [
      "Martin Hoefer",
      "Lisa Wilhelmi"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2205.15628"
  },
  {
    "id": "arXiv:2205.15630",
    "title": "Privacy Leakage in Discrete Time Updating Systems",
    "abstract": "A source generates time-stamped update packets that are sent to a server and\nthen forwarded to a monitor. This occurs in the presence of an adversary that\ncan infer information about the source by observing the output process of the\nserver. The server wishes to release updates in a timely way to the monitor but\nalso wishes to minimize the information leaked to the adversary. We analyze the\ntrade-off between the age of information (AoI) and the maximal leakage for\nsystems in which the source generates updates as a Bernoulli process. For a\ntime slotted system in which sending an update requires one slot, we consider\nthree server policies: (1) Memoryless with Bernoulli Thinning (MBT): arriving\nupdates are queued with some probability and head-of-line update is released\nafter a geometric holding time; (2) Deterministic Accumulate-and-Dump (DAD):\nthe most recently generated update (if any) is released after a fixed time; (3)\nRandom Accumulate-and-Dump (RAD): the most recently generated update (if any)\nis released after a geometric waiting time. We show that for the same maximal\nleakage rate, the DAD policy achieves lower age compared to the other two\npolicies but is restricted to discrete age-leakage operating points.",
    "descriptor": "",
    "authors": [
      "Nitya Sathyavageesran",
      "Roy D. Yates",
      "Anand D. Sarwate",
      "Narayan Mandayam"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.15630"
  },
  {
    "id": "arXiv:2205.15631",
    "title": "Computational and Descriptional Power of Nondeterministic Iterated  Uniform Finite-State Transducers",
    "abstract": "An iterated uniform finite-state transducer (IUFST) runs the same\nlength-preserving transduction, starting with a sweep on the input string and\nthen iteratively sweeping on the output of the previous sweep. The IUFST\naccepts the input string by halting in an accepting state at the end of a\nsweep. We consider both the deterministic (IUFST) and nondeterministic (NIUFST)\nversion of this device. We show that constant sweep bounded IUFSTs and NIUFSTs\naccept all and only regular languages. We study the state complexity of\nremoving nondeterminism as well as sweeps on constant sweep bounded NIUFSTs,\nthe descriptional power of constant sweep bounded IUFSTs and NIUFSTs with\nrespect to classical models of finite-state automata, and the computational\ncomplexity of several decidability questions. Then, we focus on non-constant\nsweep bounded devices, proving the existence of a proper infinite nonregular\nlanguage hierarchy depending on the sweep complexity both in the deterministic\nand nondeterministic case. Though NIUFSTss are \"one-way\" devices we show that\nthey characterize the class of context-sensitive languages, that is, the\ncomplexity class DSpace(lin). Finally, we show that the nondeterministic\ndevices are more powerful than their deterministic variant for a sublinear\nnumber of sweeps that is at least logarithmic.",
    "descriptor": "",
    "authors": [
      "Martin Kutrib",
      "Andreas Malcher",
      "Carlo Mereghetti",
      "Beatrice Palano"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2205.15631"
  },
  {
    "id": "arXiv:2205.15638",
    "title": "Differentiable Invariant Causal Discovery",
    "abstract": "Learning causal structure from observational data is a fundamental challenge\nin machine learning. The majority of commonly used differentiable causal\ndiscovery methods are non-identifiable, turning this problem into a continuous\noptimization task prone to data biases. In many real-life situations, data is\ncollected from different environments, in which the functional relations remain\nconsistent across environments, while the distribution of additive noises may\nvary. This paper proposes Differentiable Invariant Causal Discovery (DICD),\nutilizing the multi-environment information based on a differentiable framework\nto avoid learning spurious edges and wrong causal directions. Specifically,\nDICD aims to discover the environment-invariant causation while removing the\nenvironment-dependent correlation. We further formulate the constraint that\nenforces the target structure equation model to maintain optimal across the\nenvironments. Theoretical guarantees for the identifiability of proposed DICD\nare provided under mild conditions with enough environments. Extensive\nexperiments on synthetic and real-world datasets verify that DICD outperforms\nstate-of-the-art causal discovery methods up to 36% in SHD. Our code will be\nopen-sourced upon acceptance.",
    "descriptor": "\nComments: 22 pages, 6 figures\n",
    "authors": [
      "Yu Wang",
      "An Zhang",
      "Xiang Wang",
      "Xiangnan He",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2205.15638"
  },
  {
    "id": "arXiv:2205.15639",
    "title": "Adaptive fuzzy control of electrohydraulic servosystems",
    "abstract": "Electrohydraulic servosystems are widely employed in industrial applications\nsuch as robotic manipulators, active suspensions, precision machine tools and\naerospace systems. They provide many advantages over electric motors, including\nhigh force to weight ratio, fast response time and compact size. However,\nprecise control of electrohydraulic actuated systems, due to their inherent\nnonlinear characteristics, cannot be easily obtained with conventional linear\ncontrollers. Most flow control valves can also exhibit some hard nonlinearities\nsuch as dead-zone due to valve spool overlap. This work describes the\ndevelopment of an adaptive fuzzy controller for electrohydraulic actuated\nsystems with unknown dead-zone. The stability properties of the closed-loop\nsystems was proven using Lyapunov stability theory and Barbalat's lemma.\nNumerical results are presented in order to demonstrate the control system\nperformance.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2205.13343, arXiv:2205.13669\n",
    "authors": [
      "Wallace Moreira Bessa",
      "Max Suell Dutra",
      "Edwin Kreuzer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2205.15639"
  },
  {
    "id": "arXiv:2205.15642",
    "title": "How Should IRSs Scale to Harden Multi-Antenna Channels?",
    "abstract": "This work extends the concept of channel hardening to multi-antenna systems\nthat are aided by intelligent reflecting surfaces (IRSs). For fading links\nbetween a multi-antenna transmitter and a single-antenna receiver, we derive an\naccurate approximation for the distribution of the input-output mutual\ninformation when the number of reflecting elements grows large. The asymptotic\nresults demonstrate that by increasing the number of elements on the IRS, the\nend-to-end channel hardens as long as the physical dimensions of the IRS grow\nas well. The growth rate however need not to be of a specific order and can be\nsignificantly sub-linear. The validity of the analytical result is confirmed by\nnumerical experiments.",
    "descriptor": "\nComments: Accepted for presentation at 2022 IEEE Sensor Array and Multichannel Signal Processing Workshop (SAM ) in Trondheim, Norway; 5 pages and 2 figures. arXiv admin note: text overlap with arXiv:2203.11592\n",
    "authors": [
      "Ali Bereyhi",
      "Saba Asaad",
      "Chongjun Ouyang",
      "Ralf R. M\u00fcller",
      "Rafael F. Schaefer",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.15642"
  },
  {
    "id": "arXiv:2205.15648",
    "title": "Reliable and Efficient Broadcast Routing Using Multipoint Relays Over  VANET For Vehicle Platooning",
    "abstract": "In this paper, we design and implement a reliable broadcast algorithm over a\nVANET for supporting multi-hop forwarding of vehicle sensor and control packets\nthat will enable vehicles to platoon with each other in order to form a road\ntrain behind the lead truck. In particular, we use multipoint relays (MPRs) for\npacket transmission, which leads to more efficient communication in a VANET. We\nevaluate the performance based on simulation by running a platooning simulation\napplication program, and show that with MPRs, the communication in the VANET to\nform a road train is more efficient and reliable.",
    "descriptor": "",
    "authors": [
      "Xing Wang",
      "Alvin Lim"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2205.15648"
  },
  {
    "id": "arXiv:2205.15650",
    "title": "Robust finite element discretizations for a simplified Galbrun's  equation",
    "abstract": "Driven by the challenging task of finding robust discretization methods for\nGalbrun's equation, we investigate conditions for stability and different\naspects of robustness for different finite element schemes on a simplified\nversion of the equations. The considered PDE is a second order indefinite\nvector-PDE which remains if only the highest order terms of Galbrun's equation\nare taken into account. A key property for stability is a Helmholtz-type\ndecomposition which results in a strong connection between stable\ndiscretizations for Galbrun's equation and Stokes and nearly incompressible\nlinear elasticity problems.",
    "descriptor": "\nComments: 12 pages, 3 figures\n",
    "authors": [
      "Tilman Alem\u00e1n",
      "Martin Halla",
      "Christoph Lehrenfeld",
      "Paul Stocker"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.15650"
  },
  {
    "id": "arXiv:2205.15653",
    "title": "Label-Enhanced Graph Neural Network for Semi-supervised Node  Classification",
    "abstract": "Graph Neural Networks (GNNs) have been widely applied in the semi-supervised\nnode classification task, where a key point lies in how to sufficiently\nleverage the limited but valuable label information. Most of the classical GNNs\nsolely use the known labels for computing the classification loss at the\noutput. In recent years, several methods have been designed to additionally\nutilize the labels at the input. One part of the methods augment the node\nfeatures via concatenating or adding them with the one-hot encodings of labels,\nwhile other methods optimize the graph structure by assuming neighboring nodes\ntend to have the same label. To bring into full play the rich information of\nlabels, in this paper, we present a label-enhanced learning framework for GNNs,\nwhich first models each label as a virtual center for intra-class nodes and\nthen jointly learns the representations of both nodes and labels. Our approach\ncould not only smooth the representations of nodes belonging to the same class,\nbut also explicitly encode the label semantics into the learning process of\nGNNs. Moreover, a training node selection technique is provided to eliminate\nthe potential label leakage issue and guarantee the model generalization\nability. Finally, an adaptive self-training strategy is proposed to iteratively\nenlarge the training set with more reliable pseudo labels and distinguish the\nimportance of each pseudo-labeled node during the model training process.\nExperimental results on both real-world and synthetic datasets demonstrate our\napproach can not only consistently outperform the state-of-the-arts, but also\neffectively smooth the representations of intra-class nodes.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Le Yu",
      "Leilei Sun",
      "Bowen Du",
      "Tongyu Zhu",
      "Weifeng Lv"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15653"
  },
  {
    "id": "arXiv:2205.15656",
    "title": "Sample-Efficient, Exploration-Based Policy Optimisation for Routing  Problems",
    "abstract": "Model-free deep-reinforcement-based learning algorithms have been applied to\na range of\nCOPs~\\cite{bello2016neural}~\\cite{kool2018attention}~\\cite{nazari2018reinforcement}.\nHowever, these approaches suffer from two key challenges when applied to\ncombinatorial problems: insufficient exploration and the requirement of many\ntraining examples of the search space to achieve reasonable performance.\nCombinatorial optimisation can be complex, characterised by search spaces with\nmany optimas and large spaces to search and learn. Therefore, a new method is\nneeded to find good solutions that are more efficient by being more sample\nefficient. This paper presents a new reinforcement learning approach that is\nbased on entropy. In addition, we design an off-policy-based reinforcement\nlearning technique that maximises the expected return and improves the sample\nefficiency to achieve faster learning during training time. We systematically\nevaluate our approach on a range of route optimisation tasks typically used to\nevaluate learning-based optimisation, such as the such as the Travelling\nSalesman problems (TSP), Capacitated Vehicle Routing Problem (CVRP). In this\npaper, we show that our model can generalise to various route problems, such as\nthe split-delivery VRP (SDVRP), and compare the performance of our method with\nthat of current state-of-the-art approaches. The Empirical results show that\nthe proposed method can improve on state-of-the-art methods in terms of\nsolution quality and computation time and generalise to problems of different\nsizes.",
    "descriptor": "",
    "authors": [
      "Nasrin Sultana",
      "Jeffrey Chan",
      "Tabinda Sarwar",
      "A. K. Qin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15656"
  },
  {
    "id": "arXiv:2205.15657",
    "title": "Structure of Ego-alter relationships of Politicians in Twitter",
    "abstract": "We analyze the ego-alter Twitter networks of 300 Italian MPs and 18 European\nleaders, and of about 14,000 generic users. We find structural properties\ntypical of social environments, meaning that Twitter activity is controlled by\nconstraints that are similar to those shaping conventional social\nrelationships. However, the evolution of ego-alter ties is very dynamic, which\nsuggests that they are not entirely used for social interaction, but for public\nsignaling and self-promotion. From this standpoint, the behavior of EU leaders\nis much more evident, while Italian MPs are in between them and generic users.\nWe find that politicians, more than generic users, create relationships as a\nside effect of tweeting on discussion topics, rather than by contacting\nspecific alters.",
    "descriptor": "",
    "authors": [
      "Valerio Arnaboldi",
      "Andrea Passarella",
      "Marco Conti",
      "Robin Dunbar"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2205.15657"
  },
  {
    "id": "arXiv:2205.15658",
    "title": "Contrastive Centroid Supervision Alleviates Domain Shift in Medical  Image Classification",
    "abstract": "Deep learning based medical imaging classification models usually suffer from\nthe domain shift problem, where the classification performance drops when\ntraining data and real-world data differ in imaging equipment manufacturer,\nimage acquisition protocol, patient populations, etc. We propose Feature\nCentroid Contrast Learning (FCCL), which can improve target domain\nclassification performance by extra supervision during training with\ncontrastive loss between instance and class centroid. Compared with current\nunsupervised domain adaptation and domain generalization methods, FCCL performs\nbetter while only requires labeled image data from a single source domain and\nno target domain. We verify through extensive experiments that FCCL can achieve\nsuperior performance on at least three imaging modalities, i.e. fundus\nphotographs, dermatoscopic images, and H & E tissue images.",
    "descriptor": "",
    "authors": [
      "Wenshuo Zhou",
      "Dalu Yang",
      "Binghong Wu",
      "Yehui Yang",
      "Junde Wu",
      "Xiaorong Wang",
      "Lei Wang",
      "Haifeng Huang",
      "Yanwu Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15658"
  },
  {
    "id": "arXiv:2205.15659",
    "title": "The CLRS Algorithmic Reasoning Benchmark",
    "abstract": "Learning representations of algorithms is an emerging area of machine\nlearning, seeking to bridge concepts from neural networks with classical\nalgorithms. Several important works have investigated whether neural networks\ncan effectively reason like algorithms, typically by learning to execute them.\nThe common trend in the area, however, is to generate targeted kinds of\nalgorithmic data to evaluate specific hypotheses, making results hard to\ntransfer across publications, and increasing the barrier of entry. To\nconsolidate progress and work towards unified evaluation, we propose the CLRS\nAlgorithmic Reasoning Benchmark, covering classical algorithms from the\nIntroduction to Algorithms textbook. Our benchmark spans a variety of\nalgorithmic reasoning procedures, including sorting, searching, dynamic\nprogramming, graph algorithms, string algorithms and geometric algorithms. We\nperform extensive experiments to demonstrate how several popular algorithmic\nreasoning baselines perform on these tasks, and consequently, highlight links\nto several open challenges. Our library is readily available at\nhttps://github.com/deepmind/clrs.",
    "descriptor": "\nComments: To appear in ICML 2021. 19 pages, 4 figures\n",
    "authors": [
      "Petar Veli\u010dkovi\u0107",
      "Adri\u00e0 Puigdom\u00e8nech Badia",
      "David Budden",
      "Razvan Pascanu",
      "Andrea Banino",
      "Misha Dashevskiy",
      "Raia Hadsell",
      "Charles Blundell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.15659"
  },
  {
    "id": "arXiv:2205.15661",
    "title": "NEWTS: A Corpus for News Topic-Focused Summarization",
    "abstract": "Text summarization models are approaching human levels of fidelity. Existing\nbenchmarking corpora provide concordant pairs of full and abridged versions of\nWeb, news or, professional content. To date, all summarization datasets operate\nunder a one-size-fits-all paradigm that may not reflect the full range of\norganic summarization needs. Several recently proposed models (e.g., plug and\nplay language models) have the capacity to condition the generated summaries on\na desired range of themes. These capacities remain largely unused and\nunevaluated as there is no dedicated dataset that would support the task of\ntopic-focused summarization.\nThis paper introduces the first topical summarization corpus NEWTS, based on\nthe well-known CNN/Dailymail dataset, and annotated via online crowd-sourcing.\nEach source article is paired with two reference summaries, each focusing on a\ndifferent theme of the source document. We evaluate a representative range of\nexisting techniques and analyze the effectiveness of different prompting\nmethods.",
    "descriptor": "",
    "authors": [
      "Seyed Ali Bahrainian",
      "Sheridan Feucht",
      "Carsten Eickhoff"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.15661"
  },
  {
    "id": "arXiv:2205.15663",
    "title": "Multi-task Optimization Based Co-training for Electricity Consumption  Prediction",
    "abstract": "Real-world electricity consumption prediction may involve different tasks,\ne.g., prediction for different time steps ahead or different geo-locations.\nThese tasks are often solved independently without utilizing some common\nproblem-solving knowledge that could be extracted and shared among these tasks\nto augment the performance of solving each task. In this work, we propose a\nmulti-task optimization (MTO) based co-training (MTO-CT) framework, where the\nmodels for solving different tasks are co-trained via an MTO paradigm in which\nsolving each task may benefit from the knowledge gained from when solving some\nother tasks to help its solving process. MTO-CT leverages long short-term\nmemory (LSTM) based model as the predictor where the knowledge is represented\nvia connection weights and biases. In MTO-CT, an inter-task knowledge transfer\nmodule is designed to transfer knowledge between different tasks, where the\nmost helpful source tasks are selected by using the probability matching and\nstochastic universal selection, and evolutionary operations like mutation and\ncrossover are performed for reusing the knowledge from selected source tasks in\na target task. We use electricity consumption data from five states in\nAustralia to design two sets of tasks at different scales: a) one-step ahead\nprediction for each state (five tasks) and b) 6-step, 12-step, 18-step, and\n24-step ahead prediction for each state (20 tasks). The performance of MTO-CT\nis evaluated on solving each of these two sets of tasks in comparison to\nsolving each task in the set independently without knowledge sharing under the\nsame settings, which demonstrates the superiority of MTO-CT in terms of\nprediction accuracy.",
    "descriptor": "\nComments: accepted by the 2022 IEEE International Joint Conference on Neural Networks (IJCNN 2022)\n",
    "authors": [
      "Hui Song",
      "A. K. Qin",
      "Chenggang Yan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2205.15663"
  },
  {
    "id": "arXiv:2205.15667",
    "title": "ViT-BEVSeg: A Hierarchical Transformer Network for Monocular  Birds-Eye-View Segmentation",
    "abstract": "Generating a detailed near-field perceptual model of the environment is an\nimportant and challenging problem in both self-driving vehicles and autonomous\nmobile robotics. A Bird Eye View (BEV) map, providing a panoptic\nrepresentation, is a commonly used approach that provides a simplified 2D\nrepresentation of the vehicle surroundings with accurate semantic level\nsegmentation for many downstream tasks. Current state-of-the art approaches to\ngenerate BEV-maps employ a Convolutional Neural Network (CNN) backbone to\ncreate feature-maps which are passed through a spatial transformer to project\nthe derived features onto the BEV coordinate frame. In this paper, we evaluate\nthe use of vision transformers (ViT) as a backbone architecture to generate BEV\nmaps. Our network architecture, ViT-BEVSeg, employs standard vision\ntransformers to generate a multi-scale representation of the input image. The\nresulting representation is then provided as an input to a spatial transformer\ndecoder module which outputs segmentation maps in the BEV grid. We evaluate our\napproach on the nuScenes dataset demonstrating a considerable improvement in\nthe performance relative to state-of-the-art approaches.",
    "descriptor": "\nComments: Accepted for 2022 IEEE World Congress on Computational Intelligence (Track: IJCNN)\n",
    "authors": [
      "Pramit Dutta",
      "Ganesh Sistu",
      "Senthil Yogamani",
      "Edgar Galv\u00e1n",
      "John McDonald"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15667"
  },
  {
    "id": "arXiv:2205.15668",
    "title": "On the Steady-State Behavior of Finite-Control-Set MPC with an  Application to High-Precision Power Amplifiers",
    "abstract": "Motivated by increasing precision requirements for switched power amplifiers,\nthis paper addresses the problem of model predictive control (MPC) design for\ndiscrete-time linear systems with a finite control set (FCS). Typically,\nexisting solutions for FCS-MPC penalize the output tracking error and the\ncontrol input rate of change, which can lead to arbitrary switching among the\navailable discrete control inputs and unpredictable steady-state behavior. To\nimprove the steady-state behavior of FCS-MPC, in this paper we design a cost\nfunction that penalizes the tracking error with respect to a state and input\nsteady-state limit cycle. We prove that if a suitable terminal cost is added to\nthe FCS-MPC algorithm convergence to the limit cycle is ensured. The developed\nmethodology is validated in direct switching control of a power amplifier for\nhigh-precision motion systems, where it significantly improves the steady-state\noutput current ripple.",
    "descriptor": "",
    "authors": [
      "Duo Xu",
      "Sander Damsma",
      "Mircea Lazar"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.15668"
  },
  {
    "id": "arXiv:2205.15670",
    "title": "REF: A Rapid Exploration Framework for Deploying Autonomous MAVs in  Unknown Environments",
    "abstract": "Exploration and mapping of unknown environments is a fundamental task in\napplications for autonomous robots. In this article, we present a complete\nframework for deploying MAVs in autonomous exploration missions in unknown\nsubterranean areas. The main motive of exploration algorithms is to depict the\nnext best frontier for the robot such that new ground can be covered in a fast,\nsafe yet efficient manner. The proposed framework uses a novel frontier\nselection method that also contributes to the safe navigation of autonomous\nrobots in obstructed areas such as subterranean caves, mines, and urban areas.\nThe framework presented in this work bifurcates the exploration problem in\nlocal and global exploration. The proposed exploration framework is also\nadaptable according to computational resources available onboard the robot\nwhich means the trade-off between the speed of exploration and the quality of\nthe map can be made. Such capability allows the proposed framework to be\ndeployed in a subterranean exploration, mapping as well as in fast search and\nrescue scenarios. The overall system is considered a low-complexity and\nbaseline solution for navigation and object localization in tunnel-like\nenvironments. The performance of the proposed framework is evaluated in\ndetailed simulation studies with comparisons made against a high-level\nexploration-planning framework developed for the DARPA Sub-T challenge as it\nwill be presented in this article.",
    "descriptor": "",
    "authors": [
      "Akash Patel",
      "Bj\u00f6rn Lindqvist",
      "Christoforos Kanellakis",
      "Ali-akbar Agha-mohammadi",
      "George Nikolakopoulos"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.15670"
  },
  {
    "id": "arXiv:2205.15674",
    "title": "Generalised Implicit Neural Representations",
    "abstract": "We consider the problem of learning implicit neural representations (INRs)\nfor signals on non-Euclidean domains. In the Euclidean case, INRs are trained\non a discrete sampling of a signal over a regular lattice. Here, we assume that\nthe continuous signal exists on some unknown topological space from which we\nsample a discrete graph. In the absence of a coordinate system to identify the\nsampled nodes, we propose approximating their location with a spectral\nembedding of the graph. This allows us to train INRs without knowing the\nunderlying continuous domain, which is the case for most graph signals in\nnature, while also making the INRs equivariant under the symmetry group of the\ndomain. We show experiments with our method on various real-world signals on\nnon-Euclidean domains.",
    "descriptor": "",
    "authors": [
      "Daniele Grattarola",
      "Pierre Vandergheynst"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.15674"
  },
  {
    "id": "arXiv:2205.15677",
    "title": "Augmentation-Aware Self-Supervision for Data-Efficient GAN Training",
    "abstract": "Training generative adversarial networks (GANs) with limited data is valuable\nbut challenging because discriminators are prone to over-fitting in such\nsituations. Recently proposed differentiable data augmentation techniques for\ndiscriminators demonstrate improved data efficiency of training GANs. However,\nthe naive data augmentation introduces undesired invariance to augmentation\ninto the discriminator. The invariance may degrade the representation learning\nability of the discriminator, thereby affecting the generative modeling\nperformance of the generator. To mitigate the invariance while inheriting the\nbenefits of data augmentation, we propose a novel augmentation-aware\nself-supervised discriminator that predicts the parameter of augmentation given\nthe augmented and original data. Moreover, the prediction task is required to\ndistinguishable between real data and generated data since they are different\nduring training. We further encourage the generator to learn from the proposed\ndiscriminator by generating augmentation-predictable real data. We compare the\nproposed method with state-of-the-arts across the class-conditional BigGAN and\nunconditional StyleGAN2 architectures on CIFAR-10/100 and several low-shot\ndatasets, respectively. Experimental results show a significantly improved\ngeneration performance of our method over competing methods for training\ndata-efficient GANs.",
    "descriptor": "",
    "authors": [
      "Liang Hou",
      "Qi Cao",
      "Huawei Shen",
      "Siyuan Pan",
      "Xiaoshuang Li",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15677"
  },
  {
    "id": "arXiv:2205.15678",
    "title": "Automatic Relation-aware Graph Network Proliferation",
    "abstract": "Graph neural architecture search has sparked much attention as Graph Neural\nNetworks (GNNs) have shown powerful reasoning capability in many relational\ntasks. However, the currently used graph search space overemphasizes learning\nnode features and neglects mining hierarchical relational information.\nMoreover, due to diverse mechanisms in the message passing, the graph search\nspace is much larger than that of CNNs. This hinders the straightforward\napplication of classical search strategies for exploring complicated graph\nsearch space. We propose Automatic Relation-aware Graph Network Proliferation\n(ARGNP) for efficiently searching GNNs with a relation-guided message passing\nmechanism. Specifically, we first devise a novel dual relation-aware graph\nsearch space that comprises both node and relation learning operations. These\noperations can extract hierarchical node/relational information and provide\nanisotropic guidance for message passing on a graph. Second, analogous to cell\nproliferation, we design a network proliferation search paradigm to\nprogressively determine the GNN architectures by iteratively performing network\ndivision and differentiation. The experiments on six datasets for four graph\nlearning tasks demonstrate that GNNs produced by our method are superior to the\ncurrent state-of-the-art hand-crafted and search-based GNNs. Codes are\navailable at https://github.com/phython96/ARGNP.",
    "descriptor": "\nComments: Accepted by CVPR2022 (Oral)\n",
    "authors": [
      "Shaofei Cai",
      "Liang Li",
      "Xinzhe Han",
      "Jiebo Luo",
      "Zheng-Jun Zha",
      "Qingming Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15678"
  },
  {
    "id": "arXiv:2205.15683",
    "title": "Why are NLP Models Fumbling at Elementary Math? A Survey of Deep  Learning based Word Problem Solvers",
    "abstract": "From the latter half of the last decade, there has been a growing interest in\ndeveloping algorithms for automatically solving mathematical word problems\n(MWP). It is a challenging and unique task that demands blending surface level\ntext pattern recognition with mathematical reasoning. In spite of extensive\nresearch, we are still miles away from building robust representations of\nelementary math word problems and effective solutions for the general task. In\nthis paper, we critically examine the various models that have been developed\nfor solving word problems, their pros and cons and the challenges ahead. In the\nlast two years, a lot of deep learning models have recorded competing results\non benchmark datasets, making a critical and conceptual analysis of literature\nhighly useful at this juncture. We take a step back and analyse why, in spite\nof this abundance in scholarly interest, the predominantly used experiment and\ndataset designs continue to be a stumbling block. From the vantage point of\nhaving analyzed the literature closely, we also endeavour to provide a road-map\nfor future math word problem research.",
    "descriptor": "",
    "authors": [
      "Sowmya S Sundaram",
      "Sairam Gurajada",
      "Marco Fisichella",
      "Deepak P",
      "Savitha Sam Abraham"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.15683"
  },
  {
    "id": "arXiv:2205.15688",
    "title": "Self-Supervised Learning for Building Damage Assessment from Large-scale  xBD Satellite Imagery Benchmark Datasets",
    "abstract": "In the field of post-disaster assessment, for timely and accurate rescue and\nlocalization after a disaster, people need to know the location of damaged\nbuildings. In deep learning, some scholars have proposed methods to make\nautomatic and highly accurate building damage assessments by remote sensing\nimages, which are proved to be more efficient than assessment by domain\nexperts. However, due to the lack of a large amount of labeled data, these\nkinds of tasks can suffer from being able to do an accurate assessment, as the\nefficiency of deep learning models relies highly on labeled data. Although\nexisting semi-supervised and unsupervised studies have made breakthroughs in\nthis area, none of them has completely solved this problem. Therefore, we\npropose adopting a self-supervised comparative learning approach to address the\ntask without the requirement of labeled data. We constructed a novel asymmetric\ntwin network architecture and tested its performance on the xBD dataset.\nExperiment results of our model show the improvement compared to baseline and\ncommonly used methods. We also demonstrated the potential of self-supervised\nmethods for building damage recognition awareness.",
    "descriptor": "\nComments: 14 pages, 7 figures, DEXA 2022\n",
    "authors": [
      "Zaishuo Xia",
      "Zelin Li",
      "Yanbing Bai",
      "Jinze Yu",
      "Bruno Adriano"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.15688"
  },
  {
    "id": "arXiv:2205.15691",
    "title": "Fast-Spanning Ant Colony Optimisation (FaSACO) for Mobile Robot Coverage  Path Planning",
    "abstract": "Coverage path planning acts as a key component for applications such as\nmobile robot vacuum cleaners and hospital disinfecting robots. However, the\ncoverage path planning problem remains a challenge due to its NP-hard nature.\nBio-inspired algorithms such as Ant Colony Optimisation (ACO) have been\nexploited to solve the problem because they can utilise heuristic information\nto mitigate the path planning complexity. This paper proposes a new variant of\nACO - the Fast-Spanning Ant Colony Optimisation (FaSACO), where ants can\nexplore the environment with various velocities. By doing so, ants with higher\nvelocities can find targets or obstacles faster and keep lower velocity ants\ninformed by communicating such information via trail pheromones. This mechanism\nensures the optimal path is found while reducing the overall path planning\ntime. Experimental results show that FaSACO is $19.3-32.3\\%$ more efficient\nthan ACO, and re-covers $6.9-12.5\\%$ fewer cells than ACO. This makes FaSACO\nmore appealing in real-time and energy-limited applications.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Christopher Carr",
      "Peng Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.15691"
  },
  {
    "id": "arXiv:2205.15694",
    "title": "Data-driven Reference Trajectory Optimization for Precision Motion  Systems",
    "abstract": "We propose an optimization-based method to improve contour tracking\nperformance on precision motion stages by modifying the reference trajectory,\nwithout changing the built-in low-level controller. The position of the\nprecision motion stage is predicted with data-driven models. First, a linear\nlow-fidelity model is used to optimize traversal time, by changing the path\nvelocity and acceleration profiles. Second, a non-linear high-fidelity model is\nused to refine the previously found time-optimal solution. We experimentally\ndemonstrate that the method is capable of improving the productivity vs.\naccuracy trade-off for a high precision motion stage. Given the data-based\nnature of the models used, we claim that the method can easily be adapted to a\nwide family of precision motion systems.",
    "descriptor": "\nComments: 14 pages, 17 figures\n",
    "authors": [
      "Samuel Balula",
      "Dominic Liao-McPherson",
      "Alisa Rupenyan",
      "John Lygeros"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.15694"
  },
  {
    "id": "arXiv:2205.15695",
    "title": "Static Scheduling with Predictions Learned through Efficient Exploration",
    "abstract": "A popular approach to go beyond the worst-case analysis of online algorithms\nis to assume the existence of predictions that can be leveraged to improve\nperformances. Those predictions are usually given by some external sources that\ncannot be fully trusted. Instead, we argue that trustful predictions can be\nbuilt by algorithms, while they run. We investigate this idea in the\nillustrative context of static scheduling with exponential job sizes. Indeed,\nwe prove that algorithms agnostic to this structure do not perform better than\nin the worst case. In contrast, when the expected job sizes are known, we show\nthat the best algorithm using this information, called\nFollow-The-Perfect-Prediction (FTPP), exhibits much better performances. Then,\nwe introduce two adaptive explore-then-commit types of algorithms: they both\nfirst (partially) learn expected job sizes and then follow FTPP once their\nself-predictions are confident enough. On the one hand, ETCU explores in\n\"series\", by completing jobs sequentially to acquire information. On the other\nhand, ETCRR, inspired by the optimal worst-case algorithm Round-Robin (RR),\nexplores efficiently in \"parallel\". We prove that both of them asymptotically\nreach the performances of FTPP, with a faster rate for ETCRR. Those findings\nare empirically evaluated on synthetic data.",
    "descriptor": "",
    "authors": [
      "Hugo Richard",
      "Flore Sentenac",
      "Corentin Odic",
      "Mathieu Molina",
      "Vianney Perchet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.15695"
  },
  {
    "id": "arXiv:2205.15696",
    "title": "An Informational Space Based Semantic Analysis for Scientific Texts",
    "abstract": "One major problem in Natural Language Processing is the automatic analysis\nand representation of human language. Human language is ambiguous and deeper\nunderstanding of semantics and creating human-to-machine interaction have\nrequired an effort in creating the schemes for act of communication and\nbuilding common-sense knowledge bases for the 'meaning' in texts. This paper\nintroduces computational methods for semantic analysis and the quantifying the\nmeaning of short scientific texts. Computational methods extracting semantic\nfeature are used to analyse the relations between texts of messages and\n'representations of situations' for a newly created large collection of\nscientific texts, Leicester Scientific Corpus. The representation of\nscientific-specific meaning is standardised by replacing the situation\nrepresentations, rather than psychological properties, with the vectors of some\nattributes: a list of scientific subject categories that the text belongs to.\nFirst, this paper introduces 'Meaning Space' in which the informational\nrepresentation of the meaning is extracted from the occurrence of the word in\ntexts across the scientific categories, i.e., the meaning of a word is\nrepresented by a vector of Relative Information Gain about the subject\ncategories. Then, the meaning space is statistically analysed for Leicester\nScientific Dictionary-Core and we investigate 'Principal Components of the\nMeaning' to describe the adequate dimensions of the meaning. The research in\nthis paper conducts the base for the geometric representation of the meaning of\ntexts.",
    "descriptor": "\nComments: 19 pages. arXiv admin note: substantial text overlap with arXiv:2009.08859, arXiv:2004.13717\n",
    "authors": [
      "Neslihan Suzen",
      "Alexander N. Gorban",
      "Jeremy Levesley",
      "Evgeny M. Mirkes"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.15696"
  },
  {
    "id": "arXiv:2205.15701",
    "title": "Provable General Function Class Representation Learning in Multitask  Bandits and MDPs",
    "abstract": "While multitask representation learning has become a popular approach in\nreinforcement learning (RL) to boost the sample efficiency, the theoretical\nunderstanding of why and how it works is still limited. Most previous\nanalytical works could only assume that the representation function is already\nknown to the agent or from linear function class, since analyzing general\nfunction class representation encounters non-trivial technical obstacles such\nas generalization guarantee, formulation of confidence bound in abstract\nfunction space, etc. However, linear-case analysis heavily relies on the\nparticularity of linear function class, while real-world practice usually\nadopts general non-linear representation functions like neural networks. This\nsignificantly reduces its applicability. In this work, we extend the analysis\nto general function class representations. Specifically, we consider an agent\nplaying $M$ contextual bandits (or MDPs) concurrently and extracting a shared\nrepresentation function $\\phi$ from a specific function class $\\Phi$ using our\nproposed Generalized Functional Upper Confidence Bound algorithm (GFUCB). We\ntheoretically validate the benefit of multitask representation learning within\ngeneral function class for bandits and linear MDP for the first time. Lastly,\nwe conduct experiments to demonstrate the effectiveness of our algorithm with\nneural net representation.",
    "descriptor": "",
    "authors": [
      "Rui Lu",
      "Andrew Zhao",
      "Simon S. Du",
      "Gao Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.15701"
  },
  {
    "id": "arXiv:2205.15702",
    "title": "New theoretical insights in the decomposition and time-frequency  representation of nonstationary signals: the IMFogram algorithm",
    "abstract": "The analysis of the time-frequency content of a signal is a classical problem\nin signal processing, with a broad number of applications in real life. Many\ndifferent approaches have been developed over the decades, which provide\nalternative time-frequency representations of a signal each with its advantages\nand limitations. In this work, following the success of nonlinear methods for\nthe decomposition of signals into intrinsic mode functions (IMFs), we first\nprovide more theoretical insights into the so-called Iterative Filtering\ndecomposition algorithm, proving an energy conservation result for the derived\ndecompositions. Furthermore, we present a new time-frequency representation\nmethod based on the IMF decomposition of a signal, which is called IMFogram. We\nprove theoretical results regarding this method, including its convergence to\nthe spectrogram representation for a certain class of signals, and we present a\nfew examples of applications, comparing results with some of the most well know\napproaches available in the literature.",
    "descriptor": "",
    "authors": [
      "Antonio Cicone",
      "Wing Suet Li",
      "Haomin Zhou"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.15702"
  },
  {
    "id": "arXiv:2205.15703",
    "title": "Lessons Learned from Data-Driven Building Control Experiments:  Contrasting Gaussian Process-based MPC, Bilevel DeePC, and Deep Reinforcement  Learning",
    "abstract": "This manuscript offers the perspective of experimentalists on a number of\nmodern data-driven techniques: model predictive control relying on Gaussian\nprocesses, adaptive data-driven control based on behavioral theory, and deep\nreinforcement learning. These techniques are compared in terms of data\nrequirements, ease of use, computational burden, and robustness in the context\nof real-world applications. Our remarks and observations stem from a number of\nexperimental investigations carried out in the field of building control in\ndiverse environments, from lecture halls and apartment spaces to a hospital\nsurgery center. The final goal is to support others in identifying what\ntechnique is best suited to tackle their own problems.",
    "descriptor": "",
    "authors": [
      "Loris Di Natale",
      "Yingzhao Lian",
      "Emilio T. Maddalena",
      "Jicheng Shi",
      "Colin N. Jones"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15703"
  },
  {
    "id": "arXiv:2205.15704",
    "title": "Mitigating Dataset Bias by Using Per-sample Gradient",
    "abstract": "The performance of deep neural networks is strongly influenced by the\ntraining dataset setup. In particular, when attributes having a strong\ncorrelation with the target attribute are present, the trained model can\nprovide unintended prejudgments and show significant inference errors (i.e.,\nthe dataset bias problem). Various methods have been proposed to mitigate\ndataset bias, and their emphasis is on weakly correlated samples, called\nbias-conflicting samples. These methods are based on explicit bias labels\ninvolving human or empirical correlation metrics (e.g., training loss).\nHowever, such metrics require human costs or have insufficient theoretical\nexplanation. In this study, we propose a debiasing algorithm, called PGD\n(Per-sample Gradient-based Debiasing), that comprises three steps: (1) training\na model on uniform batch sampling, (2) setting the importance of each sample in\nproportion to the norm of the sample gradient, and (3) training the model using\nimportance-batch sampling, whose probability is obtained in step (2). Compared\nwith existing baselines for various synthetic and real-world datasets, the\nproposed method showed state-of-the-art accuracy for a the classification task.\nFurthermore, we describe theoretical understandings about how PGD can mitigate\ndataset bias.",
    "descriptor": "\nComments: 28 pages, 9 figures\n",
    "authors": [
      "Sumyeong Ahn",
      "Seongyoon Kim",
      "Se-young Yun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15704"
  },
  {
    "id": "arXiv:2205.15707",
    "title": "CALEB: A Conditional Adversarial Learning Framework to Enhance Bot  Detection",
    "abstract": "The high growth of Online Social Networks (OSNs) over the last few years has\nallowed automated accounts, known as social bots, to gain ground. As\nhighlighted by other researchers, most of these bots have malicious purposes\nand tend to mimic human behavior, posing high-level security threats on OSN\nplatforms. Moreover, recent studies have shown that social bots evolve over\ntime by reforming and reinventing unforeseen and sophisticated characteristics,\nmaking them capable of evading the current machine learning state-of-the-art\nbot detection systems. This work is motivated by the critical need to establish\nadaptive bot detection methods in order to proactively capture unseen evolved\nbots towards healthier OSNs interactions. In contrast with most earlier\nsupervised ML approaches which are limited by the inability to effectively\ndetect new types of bots, this paper proposes CALEB, a robust end-to-end\nproactive framework based on the Conditional Generative Adversarial Network\n(CGAN) and its extension, Auxiliary Classifier GAN (AC-GAN), to simulate bot\nevolution by creating realistic synthetic instances of different bot types.\nThese simulated evolved bots augment existing bot datasets and therefore\nenhance the detection of emerging generations of bots before they even appear!\nFurthermore, we show that our augmentation approach overpasses other earlier\naugmentation techniques which fail at simulating evolving bots. Extensive\nexperimentation on well established public bot datasets, show that our approach\noffers a performance boost of up to 10% regarding the detection of new unseen\nbots. Finally, the use of the AC-GAN Discriminator as a bot detector, has\noutperformed former ML approaches, showcasing the efficiency of our end to end\nframework.",
    "descriptor": "",
    "authors": [
      "George Dialektakis",
      "Ilias Dimitriadis",
      "Athena Vakali"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2205.15707"
  },
  {
    "id": "arXiv:2205.15710",
    "title": "Coverage Probability of STAR-RIS assisted Massive MIMO systems with  Correlation and Phase Errors",
    "abstract": "In this paper, we investigate a simultaneous transmitting and reflecting\nreconfigurable intelligent surface (STAR-RIS) assisting a massive\nmultiple-input multiple-output (mMIMO) system. In particular, we derive a\nclosed-form expression for the coverage probability of a STAR-RIS assisted\nmMIMO system while accounting for correlated fading and phase-shift errors.\nNotably, the phase configuration takes place at every several coherence\nintervals by optimizing the coverage probability since the latter depends on\nstatistical channel state information (CSI) in terms of large-scale statistics.\nAs a result, we achieve a reduced complexity and overhead for the optimization\nof passive beamforming, which are increased in the case of STAR-RIS networks\nwith instantaneous CSI. Numerical results corroborate our analysis, shed light\non interesting properties such as the impact of the number of RIS elements and\nthe effect of phase errors, along with affirming the superiority of STAR-RIS\nagainst reflective-only RIS.",
    "descriptor": "\nComments: accepted in IEEE WCL\n",
    "authors": [
      "Anastasios Papazafeiropoulos",
      "Zaid Abdullah",
      "Pandelis Kourtessis",
      "Steven Kisseleff",
      "Ioannis Krikidis"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.15710"
  },
  {
    "id": "arXiv:2205.15712",
    "title": "Multilingual Transformers for Product Matching -- Experiments and a New  Benchmark in Polish",
    "abstract": "Product matching corresponds to the task of matching identical products\nacross different data sources. It typically employs available product features\nwhich, apart from being multimodal, i.e., comprised of various data types,\nmight be non-homogeneous and incomplete. The paper shows that pre-trained,\nmultilingual Transformer models, after fine-tuning, are suitable for solving\nthe product matching problem using textual features both in English and Polish\nlanguages. We tested multilingual mBERT and XLM-RoBERTa models in English on\nWeb Data Commons - training dataset and gold standard for large-scale product\nmatching. The obtained results show that these models perform similarly to the\nlatest solutions tested on this set, and in some cases, the results were even\nbetter.\nAdditionally, we prepared a new dataset -- ProductMatch.pl -- that is\nentirely in Polish and based on offers in selected categories obtained from\nseveral online stores for the research purpose. It is the first open dataset\nfor product matching tasks in Polish, which allows comparing the effectiveness\nof the pre-trained models. Thus, we also showed the baseline results obtained\nby the fine-tuned mBERT and XLM-RoBERTa models on the Polish datasets.",
    "descriptor": "\nComments: 11 pages, 5 figures\n",
    "authors": [
      "Micha\u0142 Mo{\u017c}d{\u017c}onek",
      "Anna Wr\u00f3blewska",
      "Sergiy Tkachuk",
      "Szymon \u0141ukasik"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15712"
  },
  {
    "id": "arXiv:2205.15713",
    "title": "Don't Forget Cheap Training Signals Before Building Unsupervised  Bilingual Word Embeddings",
    "abstract": "Bilingual Word Embeddings (BWEs) are one of the cornerstones of cross-lingual\ntransfer of NLP models. They can be built using only monolingual corpora\nwithout supervision leading to numerous works focusing on unsupervised BWEs.\nHowever, most of the current approaches to build unsupervised BWEs do not\ncompare their results with methods based on easy-to-access cross-lingual\nsignals. In this paper, we argue that such signals should always be considered\nwhen developing unsupervised BWE methods. The two approaches we find most\neffective are: 1) using identical words as seed lexicons (which unsupervised\napproaches incorrectly assume are not available for orthographically distinct\nlanguage pairs) and 2) combining such lexicons with pairs extracted by matching\nromanized versions of words with an edit distance threshold. We experiment on\nthirteen non-Latin languages (and English) and show that such cheap signals\nwork well and that they outperform using more complex unsupervised methods on\ndistant language pairs such as Chinese, Japanese, Kannada, Tamil, and Thai. In\naddition, they are even competitive with the use of high-quality lexicons in\nsupervised approaches. Our results show that these training signals should not\nbe neglected when building BWEs, even for distant languages.",
    "descriptor": "\nComments: BUCC@LREC 2022\n",
    "authors": [
      "Silvia Severini",
      "Viktor Hangya",
      "Masoud Jalili Sabet",
      "Alexander Fraser",
      "Hinrich Sch\u00fctze"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.15713"
  },
  {
    "id": "arXiv:2205.15714",
    "title": "Attribute Exploration with Multiple Contradicting Partial Experts",
    "abstract": "Attribute exploration is a method from Formal Concept Analysis (FCA) that\nhelps a domain expert discover structural dependencies in knowledge domains\nwhich can be represented as formal contexts (cross tables of objects and\nattributes). In this paper we present an extension of attribute exploration\nthat allows for a group of domain experts and explores their shared views. Each\nexpert has their own view of the domain and the views of multiple experts may\ncontain contradicting information.",
    "descriptor": "\nComments: 22 pages (14 pages + 8 pages appendix)\n",
    "authors": [
      "Maximilian Felde",
      "Gerd Stumme"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.15714"
  },
  {
    "id": "arXiv:2205.15716",
    "title": "Multi-Agent Learning of Numerical Methods for Hyperbolic PDEs with  Factored Dec-MDP",
    "abstract": "Factored decentralized Markov decision process (Dec-MDP) is a framework for\nmodeling sequential decision making problems in multi-agent systems. In this\npaper, we formalize the learning of numerical methods for hyperbolic partial\ndifferential equations (PDEs), specifically the Weighted Essentially\nNon-Oscillatory (WENO) scheme, as a factored Dec-MDP problem. We show that\ndifferent reward formulations lead to either reinforcement learning (RL) or\nbehavior cloning, and a homogeneous policy could be learned for all agents\nunder the RL formulation with a policy gradient algorithm. Because the trained\nagents only act on their local observations, the multi-agent system can be used\nas a general numerical method for hyperbolic PDEs and generalize to different\nspatial discretizations, episode lengths, dimensions, and even equation types.",
    "descriptor": "\nComments: Submitted to 20th International Conference on Practical Applications of Agents and Multi-Agent Systems (PAAMS 2022)\n",
    "authors": [
      "Yiwei Fu",
      "Dheeraj S.K. Kapilavai",
      "Elliot Way"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2205.15716"
  },
  {
    "id": "arXiv:2205.15721",
    "title": "One Loss for Quantization: Deep Hashing with Discrete Wasserstein  Distributional Matching",
    "abstract": "Image hashing is a principled approximate nearest neighbor approach to find\nsimilar items to a query in a large collection of images. Hashing aims to learn\na binary-output function that maps an image to a binary vector. For optimal\nretrieval performance, producing balanced hash codes with low-quantization\nerror to bridge the gap between the learning stage's continuous relaxation and\nthe inference stage's discrete quantization is important. However, in the\nexisting deep supervised hashing methods, coding balance and low-quantization\nerror are difficult to achieve and involve several losses. We argue that this\nis because the existing quantization approaches in these methods are\nheuristically constructed and not effective to achieve these objectives. This\npaper considers an alternative approach to learning the quantization\nconstraints. The task of learning balanced codes with low quantization error is\nre-formulated as matching the learned distribution of the continuous codes to a\npre-defined discrete, uniform distribution. This is equivalent to minimizing\nthe distance between two distributions. We then propose a computationally\nefficient distributional distance by leveraging the discrete property of the\nhash functions. This distributional distance is a valid distance and enjoys\nlower time and sample complexities. The proposed single-loss quantization\nobjective can be integrated into any existing supervised hashing method to\nimprove code balance and quantization error. Experiments confirm that the\nproposed approach substantially improves the performance of several\nrepresentative hashing~methods.",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Khoa D. Doan",
      "Peng Yang",
      "Ping Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15721"
  },
  {
    "id": "arXiv:2205.15723",
    "title": "DeVRF: Fast Deformable Voxel Radiance Fields for Dynamic Scenes",
    "abstract": "Modeling dynamic scenes is important for many applications such as virtual\nreality and telepresence. Despite achieving unprecedented fidelity for novel\nview synthesis in dynamic scenes, existing methods based on Neural Radiance\nFields (NeRF) suffer from slow convergence (i.e., model training time measured\nin days). In this paper, we present DeVRF, a novel representation to accelerate\nlearning dynamic radiance fields. The core of DeVRF is to model both the 3D\ncanonical space and 4D deformation field of a dynamic, non-rigid scene with\nexplicit and discrete voxel-based representations. However, it is quite\nchallenging to train such a representation which has a large number of model\nparameters, often resulting in overfitting issues. To overcome this challenge,\nwe devise a novel static-to-dynamic learning paradigm together with a new data\ncapture setup that is convenient to deploy in practice. This paradigm unlocks\nefficient learning of deformable radiance fields via utilizing the 3D\nvolumetric canonical space learnt from multi-view static images to ease the\nlearning of 4D voxel deformation field with only few-view dynamic sequences. To\nfurther improve the efficiency of our DeVRF and its synthesized novel view's\nquality, we conduct thorough explorations and identify a set of strategies. We\nevaluate DeVRF on both synthetic and real-world dynamic scenes with different\ntypes of deformation. Experiments demonstrate that DeVRF achieves two orders of\nmagnitude speedup (100x faster) with on-par high-fidelity results compared to\nthe previous state-of-the-art approaches. The code and dataset will be released\nin https://github.com/showlab/DeVRF.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Jia-Wei Liu",
      "Yan-Pei Cao",
      "Weijia Mao",
      "Wenqiao Zhang",
      "David Junhao Zhang",
      "Jussi Keppo",
      "Ying Shan",
      "Xiaohu Qie",
      "Mike Zheng Shou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15723"
  },
  {
    "id": "arXiv:2205.15730",
    "title": "Transformers for Multi-Object Tracking on Point Clouds",
    "abstract": "We present TransMOT, a novel transformer-based end-to-end trainable online\ntracker and detector for point cloud data. The model utilizes a cross- and a\nself-attention mechanism and is applicable to lidar data in an automotive\ncontext, as well as other data types, such as radar. Both track management and\nthe detection of new tracks are performed by the same transformer decoder\nmodule and the tracker state is encoded in feature space. With this approach,\nwe make use of the rich latent space of the detector for tracking rather than\nrelying on low-dimensional bounding boxes. Still, we are able to retain some of\nthe desirable properties of traditional Kalman-filter based approaches, such as\nan ability to handle sensor input at arbitrary timesteps or to compensate frame\nskips. This is possible due to a novel module that transforms the track\ninformation from one frame to the next on feature-level and thereby fulfills a\nsimilar task as the prediction step of a Kalman filter. Results are presented\non the challenging real-world dataset nuScenes, where the proposed model\noutperforms its Kalman filter-based tracking baseline.",
    "descriptor": "\nComments: Accepted for publication at the 2022 33rd IEEE Intelligent Vehicles Symposium (IV 2022), June 5-9, 2022, in Aachen, Germany\n",
    "authors": [
      "Felicia Ruppel",
      "Florian Faion",
      "Claudius Gl\u00e4ser",
      "Klaus Dietmayer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15730"
  },
  {
    "id": "arXiv:2205.15731",
    "title": "ViNNPruner: Visual Interactive Pruning for Deep Learning",
    "abstract": "Neural networks grow vastly in size to tackle more sophisticated tasks. In\nmany cases, such large networks are not deployable on particular hardware and\nneed to be reduced in size. Pruning techniques help to shrink deep neural\nnetworks to smaller sizes by only decreasing their performance as little as\npossible. However, such pruning algorithms are often hard to understand by\napplying them and do not include domain knowledge which can potentially be bad\nfor user goals. We propose ViNNPruner, a visual interactive pruning application\nthat implements state-of-the-art pruning algorithms and the option for users to\ndo manual pruning based on their knowledge. We show how the application\nfacilitates gaining insights into automatic pruning algorithms and\nsemi-automatically pruning oversized networks to make them more efficient using\ninteractive visualizations.",
    "descriptor": "\nComments: MLVis Short Paper; 4 pages, 1 page references, 3 figures\n",
    "authors": [
      "Udo Schlegel",
      "Samuel Schiegg",
      "Daniel A. Keim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2205.15731"
  },
  {
    "id": "arXiv:2205.15733",
    "title": "Template based Graph Neural Network with Optimal Transport Distances",
    "abstract": "Current Graph Neural Networks (GNN) architectures generally rely on two\nimportant components: node features embedding through message passing, and\naggregation with a specialized form of pooling. The structural (or topological)\ninformation is implicitly taken into account in these two steps. We propose in\nthis work a novel point of view, which places distances to some learnable graph\ntemplates at the core of the graph representation. This distance embedding is\nconstructed thanks to an optimal transport distance: the Fused\nGromov-Wasserstein (FGW) distance, which encodes simultaneously feature and\nstructure dissimilarities by solving a soft graph-matching problem. We\npostulate that the vector of FGW distances to a set of template graphs has a\nstrong discriminative power, which is then fed to a non-linear classifier for\nfinal predictions. Distance embedding can be seen as a new layer, and can\nleverage on existing message passing techniques to promote sensible feature\nrepresentations. Interestingly enough, in our work the optimal set of template\ngraphs is also learnt in an end-to-end fashion by differentiating through this\nlayer. After describing the corresponding learning procedure, we empirically\nvalidate our claim on several synthetic and real life graph classification\ndatasets, where our method is competitive or surpasses kernel and GNN\nstate-of-the-art approaches. We complete our experiments by an ablation study\nand a sensitivity analysis to parameters.",
    "descriptor": "\nComments: Preprint under review\n",
    "authors": [
      "C\u00e9dric Vincent-Cuaz",
      "R\u00e9mi Flamary",
      "Marco Corneli",
      "Titouan Vayer",
      "Nicolas Courty"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15733"
  },
  {
    "id": "arXiv:2205.15737",
    "title": "A Compensation Mechanism for EV Flexibility Services using Discrete  Utility Functions",
    "abstract": "Compensation mechanisms are used to counterbalance the discomfort suffered by\nusers due to quality service issues. Such mechanisms are currently used for\ndifferent purposes in the electrical power and energy sector, e.g., power\nquality and reliability. This paper proposes a compensation mechanism using EV\nflexibility management of a set of charging sessions managed by a charging\npoint operator (CPO). Users' preferences and bilateral agreements with the CPO\nare modelled via discrete utility functions for the energy not served. A\nmathematical proof of the proposed compensation mechanism is given and applied\nto a test scenario using historical data from an office building with a parking\nlot in the Netherlands. Synthetic data for 400 charging sessions was generated\nusing multivariate elliptical copulas to capture the complex dependency\nstructures in EV charging data. Numerical results validate the usefulness of\nthe proposed compensation mechanism as an attractive measure both for the CPO\nand the users in case of energy not served.",
    "descriptor": "",
    "authors": [
      "Juan S. Giraldo",
      "Nataly Banol Arias",
      "Edgar Mauricio Salazar Duque",
      "Gerwin Hoogsteen",
      "Johann L. Hurink"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.15737"
  },
  {
    "id": "arXiv:2205.15743",
    "title": "Mixture GAN For Modulation Classification Resiliency Against Adversarial  Attacks",
    "abstract": "Automatic modulation classification (AMC) using the Deep Neural Network (DNN)\napproach outperforms the traditional classification techniques, even in the\npresence of challenging wireless channel environments. However, the adversarial\nattacks cause the loss of accuracy for the DNN-based AMC by injecting a\nwell-designed perturbation to the wireless channels. In this paper, we propose\na novel generative adversarial network (GAN)-based countermeasure approach to\nsafeguard the DNN-based AMC systems against adversarial attack examples.\nGAN-based aims to eliminate the adversarial attack examples before feeding to\nthe DNN-based classifier. Specifically, we have shown the resiliency of our\nproposed defense GAN against the Fast-Gradient Sign method (FGSM) algorithm as\none of the most potent kinds of attack algorithms to craft the perturbed\nsignals. The existing defense-GAN has been designed for image classification\nand does not work in our case where the above-mentioned communication system is\nconsidered. Thus, our proposed countermeasure approach deploys GANs with a\nmixture of generators to overcome the mode collapsing problem in a typical GAN\nfacing radio signal classification problem. Simulation results show the\neffectiveness of our proposed defense GAN so that it could enhance the accuracy\nof the DNN-based AMC under adversarial attacks to 81%, approximately.",
    "descriptor": "",
    "authors": [
      "Eyad Shtaiwi",
      "Ahmed El Ouadrhiri",
      "Majid Moradikia",
      "Salma Sultana",
      "Ahmed Abdelhadi",
      "Zhu Han"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2205.15743"
  },
  {
    "id": "arXiv:2205.15744",
    "title": "EMS: Efficient and Effective Massively Multilingual Sentence  Representation Learning",
    "abstract": "Massively multilingual sentence representation models, e.g., LASER,\nSBERT-distill, and LaBSE, help significantly improve cross-lingual downstream\ntasks. However, multiple training procedures, the use of a large amount of\ndata, or inefficient model architectures result in heavy computation to train a\nnew model according to our preferred languages and domains. To resolve this\nissue, we introduce efficient and effective massively multilingual sentence\nrepresentation learning (EMS), using cross-lingual sentence reconstruction\n(XTR) and sentence-level contrastive learning as training objectives. Compared\nwith related studies, the proposed model can be efficiently trained using\nsignificantly fewer parallel sentences and GPU computation resources without\ndepending on large-scale pre-trained models. Empirical results show that the\nproposed model significantly yields better or comparable results with regard to\nbi-text mining, zero-shot cross-lingual genre classification, and sentiment\nclassification. Ablative analyses demonstrate the effectiveness of each\ncomponent of the proposed model. We release the codes for model training and\nthe EMS pre-trained model, which supports 62 languages\n(https://github.com/Mao-KU/EMS).",
    "descriptor": "\nComments: This work is an extension of arXiv:2105.13856. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Zhuoyuan Mao",
      "Chenhui Chu",
      "Sadao Kurohashi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.15744"
  },
  {
    "id": "arXiv:2205.15745",
    "title": "HyperMAML: Few-Shot Adaptation of Deep Models with Hypernetworks",
    "abstract": "The aim of Few-Shot learning methods is to train models which can easily\nadapt to previously unseen tasks, based on small amounts of data. One of the\nmost popular and elegant Few-Shot learning approaches is Model-Agnostic\nMeta-Learning (MAML). The main idea behind this method is to learn the general\nweights of the meta-model, which are further adapted to specific problems in a\nsmall number of gradient steps. However, the model's main limitation lies in\nthe fact that the update procedure is realized by gradient-based optimisation.\nIn consequence, MAML cannot always modify weights to the essential level in one\nor even a few gradient iterations. On the other hand, using many gradient steps\nresults in a complex and time-consuming optimization procedure, which is hard\nto train in practice, and may lead to overfitting. In this paper, we propose\nHyperMAML, a novel generalization of MAML, where the training of the update\nprocedure is also part of the model. Namely, in HyperMAML, instead of updating\nthe weights with gradient descent, we use for this purpose a trainable\nHypernetwork. Consequently, in this framework, the model can generate\nsignificant updates whose range is not limited to a fixed number of gradient\nsteps. Experiments show that HyperMAML consistently outperforms MAML and\nperforms comparably to other state-of-the-art techniques in a number of\nstandard Few-Shot learning benchmarks.",
    "descriptor": "",
    "authors": [
      "M. Przewi\u0119\u017alikowski",
      "P. Przybysz",
      "J. Tabor",
      "M. Zi\u0119ba",
      "P. Spurek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.15745"
  },
  {
    "id": "arXiv:2205.15746",
    "title": "Omni-Granular Ego-Semantic Propagation for Self-Supervised Graph  Representation Learning",
    "abstract": "Unsupervised/self-supervised graph representation learning is critical for\ndownstream node- and graph-level classification tasks. Global structure of\ngraphs helps discriminating representations and existing methods mainly utilize\nthe global structure by imposing additional supervisions. However, their global\nsemantics are usually invariant for all nodes/graphs and they fail to\nexplicitly embed the global semantics to enrich the representations. In this\npaper, we propose Omni-Granular Ego-Semantic Propagation for Self-Supervised\nGraph Representation Learning (OEPG). Specifically, we introduce\ninstance-adaptive global-aware ego-semantic descriptors, leveraging the first-\nand second-order feature differences between each node/graph and hierarchical\nglobal clusters of the entire graph dataset. The descriptors can be explicitly\nintegrated into local graph convolution as new neighbor nodes. Besides, we\ndesign an omni-granular normalization on the whole scales and hierarchies of\nthe ego-semantic to assign attentional weight to each descriptor from an\nomni-granular perspective. Specialized pretext tasks and cross-iteration\nmomentum update are further developed for local-global mutual adaptation. In\ndownstream tasks, OEPG consistently achieves the best performance with a 2%~6%\naccuracy gain on multiple datasets cross scales and domains. Notably, OEPG also\ngeneralizes to quantity- and topology-imbalance scenarios.",
    "descriptor": "\nComments: Accepted by ICML 2022\n",
    "authors": [
      "Ling Yang",
      "Shenda Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15746"
  },
  {
    "id": "arXiv:2205.15749",
    "title": "Non-Iterative Recovery from Nonlinear Observations using Generative  Models",
    "abstract": "In this paper, we aim to estimate the direction of an underlying signal from\nits nonlinear observations following the semi-parametric single index model\n(SIM). Unlike conventional compressed sensing where the signal is assumed to be\nsparse, we assume that the signal lies in the range of an $L$-Lipschitz\ncontinuous generative model with bounded $k$-dimensional inputs. This is mainly\nmotivated by the tremendous success of deep generative models in various real\napplications. Our reconstruction method is non-iterative (though approximating\nthe projection step may use an iterative procedure) and highly efficient, and\nit is shown to attain the near-optimal statistical rate of order $\\sqrt{(k \\log\nL)/m}$, where $m$ is the number of measurements. We consider two specific\ninstances of the SIM, namely noisy $1$-bit and cubic measurement models, and\nperform experiments on image datasets to demonstrate the efficacy of our\nmethod. In particular, for the noisy $1$-bit measurement model, we show that\nour non-iterative method significantly outperforms a state-of-the-art iterative\nmethod in terms of both accuracy and efficiency.",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Jiulong Liu",
      "Zhaoqiang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15749"
  },
  {
    "id": "arXiv:2205.15750",
    "title": "Variable importance without impossible data",
    "abstract": "The most popular methods for measuring importance of the variables in a black\nbox prediction algorithm make use of synthetic inputs that combine predictor\nvariables from multiple subjects. These inputs can be unlikely, physically\nimpossible, or even logically impossible. As a result, the predictions for such\ncases can be based on data very unlike any the black box was trained on. We\nthink that users cannot trust an explanation of the decision of a prediction\nalgorithm when the explanation uses such values. Instead we advocate a method\ncalled Cohort Shapley that is grounded in economic game theory and unlike most\nother game theoretic methods, it uses only actually observed data to quantify\nvariable importance. Cohort Shapley works by narrowing the cohort of subjects\njudged to be similar to a target subject on one or more features. A feature is\nimportant if using it to narrow the cohort makes a large difference to the\ncohort mean. We illustrate it on an algorithmic fairness problem where it is\nessential to attribute importance to protected variables that the model was not\ntrained on. For every subject and every predictor variable, we can compute the\nimportance of that predictor to the subject's predicted response or to their\nactual response. These values can be aggregated, for example over all Black\nsubjects, and we propose a Bayesian bootstrap to quantify uncertainty in both\nindividual and aggregate Shapley values.",
    "descriptor": "",
    "authors": [
      "Masayoshi Mase",
      "Art B. Owen",
      "Benjamin B. Seiler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Econometrics (econ.EM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.15750"
  },
  {
    "id": "arXiv:2205.15752",
    "title": "Hierarchies of Reward Machines",
    "abstract": "Reward machines (RMs) are a recent formalism for representing the reward\nfunction of a reinforcement learning task through a finite-state machine whose\nedges encode landmarks of the task using high-level events. The structure of\nRMs enables the decomposition of a task into simpler and independently solvable\nsubtasks that help tackle long-horizon and/or sparse reward tasks. We propose a\nformalism for further abstracting the subtask structure by endowing an RM with\nthe ability to call other RMs, thus composing a hierarchy of RMs (HRM). We\nexploit HRMs by treating each call to an RM as an independently solvable\nsubtask using the options framework, and describe a curriculum-based method to\ninduce HRMs from example traces observed by the agent. Our experiments reveal\nthat exploiting a handcrafted HRM leads to faster convergence than with a flat\nHRM, and that learning an HRM is more scalable than learning an equivalent flat\nHRM.",
    "descriptor": "",
    "authors": [
      "Daniel Furelos-Blanco",
      "Mark Law",
      "Anders Jonsson",
      "Krysia Broda",
      "Alessandra Russo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.15752"
  },
  {
    "id": "arXiv:2205.15757",
    "title": "Dropbear: Machine Learning Marketplaces made Trustworthy with Byzantine  Model Agreement",
    "abstract": "Marketplaces for machine learning (ML) models are emerging as a way for\norganizations to monetize models. They allow model owners to retain control\nover hosted models by using cloud resources to execute ML inference requests\nfor a fee, preserving model confidentiality. Clients that rely on hosted models\nrequire trustworthy inference results, even when models are managed by third\nparties. While the resilience and robustness of inference results can be\nimproved by combining multiple independent models, such support is unavailable\nin today's marketplaces.\nWe describe Dropbear, the first ML model marketplace that provides clients\nwith strong integrity guarantees by combining results from multiple models in a\ntrustworthy fashion. Dropbear replicates inference computation across a model\ngroup, which consists of multiple cloud-based GPU nodes belonging to different\nmodel owners. Clients receive inference certificates that prove agreement using\na Byzantine consensus protocol, even under model heterogeneity and concurrent\nmodel updates. To improve performance, Dropbear batches inference and consensus\noperations separately: it first performs the inference computation across a\nmodel group, before ordering requests and model updates. Despite its strong\nintegrity guarantees, Dropbear's performance matches that of state-of-the-art\nML inference systems: deployed across 3 cloud sites, it handles 800 requests/s\nwith ImageNet models.",
    "descriptor": "",
    "authors": [
      "Alex Shamis",
      "Peter Pietzuch",
      "Antoine Delignat-Lavaud",
      "Andrew Paverd",
      "Manuel Costa"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.15757"
  },
  {
    "id": "arXiv:2205.15759",
    "title": "Hierarchically Constrained Adaptive Ad Exposure in Feeds",
    "abstract": "A contemporary feed application usually provides blended results of organic\nitems and sponsored items~(ads) to users. Conventionally, ads are exposed at\nfixed positions. Such a static exposure strategy is inefficient due to ignoring\nusers' personalized preferences towards ads. To this end, adaptive ad exposure\nhas become an appealing strategy to boost the overall performance of the feed.\nHowever, existing approaches to implementing the adaptive ad exposure still\nsuffer from several limitations: 1) they usually fall into sub-optimal\nsolutions because of only focusing on request-level optimization without\nconsideration of the long-term application-level performance and constraints,\n2) they neglect the necessity of keeping the game-theoretical properties of ad\nauctions, which may lead to anarchy in bidding, and 3) they can hardly be\ndeployed in large-scale applications due to high computational complexity. In\nthis paper, we focus on long-term performance optimization under hierarchical\nconstraints in feeds and formulate the adaptive ad exposure as a Dynamic\nKnapsack Problem. We propose an effective approach: Hierarchically Constrained\nAdaptive Ad Exposure~(HCA2E). We present that HCA2E possesses desired\ngame-theoretical properties, computational efficiency, and performance\nrobustness. Comprehensive offline and online experiments on a leading\ne-commerce application demonstrate the significant performance superiority of\nHCA2E over representative baselines. HCA2E has also been deployed on this\napplication to serve millions of daily users.",
    "descriptor": "",
    "authors": [
      "Dagui Chen",
      "Qi Yan",
      "Chunjie Chen",
      "Zhenzhe Zheng",
      "Yangsu Liu",
      "Zhenjia Ma",
      "Chuan Yu",
      "Jian Xu",
      "Bo Zheng"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2205.15759"
  },
  {
    "id": "arXiv:2205.15760",
    "title": "Optimized Distortion and Proportional Fairness in Voting",
    "abstract": "A voting rule decides on a probability distribution over a set of $m$\nalternatives, based on rankings of those alternatives provided by agents. We\nassume that agents have cardinal utility functions over the alternatives, but\nvoting rules have access to only the rankings induced by these utilities. We\nevaluate how well voting rules do on measures of social welfare and of\nproportional fairness, computed based on the hidden utility functions.\nIn particular, we study the distortion of voting rules, which is a worst-case\nmeasure. It is an approximation ratio comparing the utilitarian social welfare\nof the optimum outcome to the welfare of the outcome selected by the voting\nrule, in the worst case over possible input profiles and utility functions that\nare consistent with the input. The literature has studied distortion with\nunit-sum utility functions, and left a small asymptotic gap in the best\npossible distortion. Using tools from the theory of fair multi-winner\nelections, we propose the first voting rule which achieves the optimal\ndistortion $\\Theta(\\sqrt{m})$ for unit-sum utilities. Our voting rule also\nachieves optimum $\\Theta(\\sqrt{m})$ distortion for unit-range and approval\nutilities.\nWe then take a similar worst-case approach to a quantitative measure of the\nfairness of a voting rule, called proportional fairness. Informally, it\nmeasures whether the influence of cohesive groups of agents on the voting\noutcome is proportional to the group size. We show that there is a voting rule\nwhich, without knowledge of the utilities, can achieve an $O(\\log\nm)$-approximation to proportional fairness, the best possible approximation. As\na consequence of its proportional fairness, we show that this voting rule\nachieves $O(\\log m)$ distortion with respect to Nash welfare, and provides an\n$O(\\log m)$-approximation to the core, making it interesting for applications\nin participatory budgeting.",
    "descriptor": "\nComments: 34 pages including appendix, accepted at ACM EC 2022\n",
    "authors": [
      "Soroush Ebadian",
      "Anson Kahng",
      "Nisarg Shah",
      "Dominik Peters"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2205.15760"
  },
  {
    "id": "arXiv:2205.15761",
    "title": "Investigating the Role of Image Retrieval for Visual Localization -- An  exhaustive benchmark",
    "abstract": "Visual localization, i.e., camera pose estimation in a known scene, is a core\ncomponent of technologies such as autonomous driving and augmented reality.\nState-of-the-art localization approaches often rely on image retrieval\ntechniques for one of two purposes: (1) provide an approximate pose estimate or\n(2) determine which parts of the scene are potentially visible in a given query\nimage. It is common practice to use state-of-the-art image retrieval algorithms\nfor both of them. These algorithms are often trained for the goal of retrieving\nthe same landmark under a large range of viewpoint changes which often differs\nfrom the requirements of visual localization. In order to investigate the\nconsequences for visual localization, this paper focuses on understanding the\nrole of image retrieval for multiple visual localization paradigms. First, we\nintroduce a novel benchmark setup and compare state-of-the-art retrieval\nrepresentations on multiple datasets using localization performance as metric.\nSecond, we investigate several definitions of \"ground truth\" for image\nretrieval. Using these definitions as upper bounds for the visual localization\nparadigms, we show that there is still sgnificant room for improvement. Third,\nusing these tools and in-depth analysis, we show that retrieval performance on\nclassical landmark retrieval or place recognition tasks correlates only for\nsome but not all paradigms to localization performance. Finally, we analyze the\neffects of blur and dynamic scenes in the images. We conclude that there is a\nneed for retrieval approaches specifically designed for localization paradigms.\nOur benchmark and evaluation protocols are available at\nhttps://github.com/naver/kapture-localization.",
    "descriptor": "\nComments: International Journal of Computer Vision (2022). arXiv admin note: text overlap with arXiv:2011.11946\n",
    "authors": [
      "Martin Humenberger",
      "Yohann Cabon",
      "No\u00e9 Pion",
      "Philippe Weinzaepfel",
      "Donghwan Lee",
      "Nicolas Gu\u00e9rin",
      "Torsten Sattler",
      "Gabriela Csurka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15761"
  },
  {
    "id": "arXiv:2205.15762",
    "title": "Knowledge Enhanced Neural Networks for relational domains",
    "abstract": "In the recent past, there has been a growing interest in Neural-Symbolic\nIntegration frameworks, i.e., hybrid systems that integrate connectionist and\nsymbolic approaches to obtain the best of both worlds. In this work we focus on\na specific method, KENN (Knowledge Enhanced Neural Networks), a Neural-Symbolic\narchitecture that injects prior logical knowledge into a neural network by\nadding on its top a residual layer that modifies the initial predictions\naccordingly to the knowledge. Among the advantages of this strategy, there is\nthe inclusion of clause weights, learnable parameters that represent the\nstrength of the clauses, meaning that the model can learn the impact of each\nrule on the final predictions. As a special case, if the training data\ncontradicts a constraint, KENN learns to ignore it, making the system robust to\nthe presence of wrong knowledge. In this paper, we propose an extension of KENN\nfor relational data. One of the main advantages of KENN resides in its\nscalability, thanks to a flexible treatment of dependencies between the rules\nobtained by stacking multiple logical layers. We show experimentally the\nefficacy of this strategy. The results show that KENN is capable of increasing\nthe performances of the underlying neural network, obtaining better or\ncomparable accuracies in respect to other two related methods that combine\nlearning with logic, requiring significantly less time for learning.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2009.06087\n",
    "authors": [
      "Alessandro Daniele",
      "Luciano Serafini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2205.15762"
  },
  {
    "id": "arXiv:2205.15763",
    "title": "Exact Feature Collisions in Neural Networks",
    "abstract": "Predictions made by deep neural networks were shown to be highly sensitive to\nsmall changes made in the input space where such maliciously crafted data\npoints containing small perturbations are being referred to as adversarial\nexamples. On the other hand, recent research suggests that the same networks\ncan also be extremely insensitive to changes of large magnitude, where\npredictions of two largely different data points can be mapped to approximately\nthe same output. In such cases, features of two data points are said to\napproximately collide, thus leading to the largely similar predictions. Our\nresults improve and extend the work of Li et al.(2019), laying out theoretical\ngrounds for the data points that have colluding features from the perspective\nof weights of neural networks, revealing that neural networks not only suffer\nfrom features that approximately collide but also suffer from features that\nexactly collide. We identify the necessary conditions for the existence of such\nscenarios, hereby investigating a large number of DNNs that have been used to\nsolve various computer vision problems. Furthermore, we propose the Null-space\nsearch, a numerical approach that does not rely on heuristics, to create data\npoints with colliding features for any input and for any task, including, but\nnot limited to, classification, localization, and segmentation.",
    "descriptor": "",
    "authors": [
      "Utku Ozbulak",
      "Manvel Gasparyan",
      "Shodhan Rao",
      "Wesley De Neve",
      "Arnout Van Messem"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15763"
  },
  {
    "id": "arXiv:2205.15764",
    "title": "SymFormer: End-to-end symbolic regression using transformer-based  architecture",
    "abstract": "Novel view synthesis is a long-standing problem. In this work, we consider a\nvariant of the problem where we are given only a few context views sparsely\ncovering a scene or an object. The goal is to predict novel viewpoints in the\nscene, which requires learning priors. The current state of the art is based on\nNeural Radiance Fields (NeRFs), and while achieving impressive results, the\nmethods suffer from long training times as they require evaluating thousands of\n3D point samples via a deep neural network for each image. We propose a 2D-only\nmethod that maps multiple context views and a query pose to a new image in a\nsingle pass of a neural network. Our model uses a two-stage architecture\nconsisting of a codebook and a transformer model. The codebook is used to embed\nindividual images into a smaller latent space, and the transformer solves the\nview synthesis task in this more compact space. To train our model efficiently,\nwe introduce a novel branching attention mechanism that allows us to use the\nsame model not only for neural rendering but also for camera pose estimation.\nExperimental results on real-world scenes show that our approach is competitive\ncompared to NeRF-based methods while not reasoning in 3D, and it is faster to\ntrain.",
    "descriptor": "",
    "authors": [
      "Vastl",
      "Martin",
      "Kulh\u00e1nek",
      "Jon\u00e1\u0161",
      "Kubal\u00edk",
      "Ji\u0159\u00ed",
      "Derner",
      "Erik",
      "Babu\u0161ka",
      "Robert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2205.15764"
  },
  {
    "id": "arXiv:2205.15765",
    "title": "Strategic Classification with Graph Neural Networks",
    "abstract": "Strategic classification studies learning in settings where users can modify\ntheir features to obtain favorable predictions. Most current works focus on\nsimple classifiers that trigger independent user responses. Here we examine the\nimplications of learning with more elaborate models that break the independence\nassumption. Motivated by the idea that applications of strategic classification\nare often social in nature, we focus on \\emph{graph neural networks}, which\nmake use of social relations between users to improve predictions. Using a\ngraph for learning introduces inter-user dependencies in prediction; our key\npoint is that strategic users can exploit these to promote their goals. As we\nshow through analysis and simulation, this can work either against the system\n-- or for it. Based on this, we propose a differentiable framework for\nstrategically-robust learning of graph-based classifiers. Experiments on\nseveral real networked datasets demonstrate the utility of our approach.",
    "descriptor": "",
    "authors": [
      "Itay Eilat",
      "Ben Finkelshtein",
      "Chaim Baskin",
      "Nir Rosenfeld"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15765"
  },
  {
    "id": "arXiv:2205.15767",
    "title": "Quality Characteristics of a Software Platform for Human-AI Teaming in  Smart Manufacturing",
    "abstract": "As AI-enabled software systems become more prevalent in smart manufacturing,\ntheir role shifts from a reactive to a proactive one that provides\ncontext-specific support to machine operators. In the context of an\ninternational research project, we develop an AI-based software platform that\nshall facilitate the collaboration between human operators and manufacturing\nmachines. We conducted 14 structured interviews with stakeholders of the\nprospective software platform in order to determine the individual relevance of\nselected quality characteristics for human-AI teaming in smart manufacturing.\nThese characteristics include the ISO 25010:2011 standard for software quality\nand AI-specific quality characteristics such as trustworthiness, explicability,\nand auditability. The interviewees rated trustworthiness, functional\nsuitability, reliability, and security as the most important quality\ncharacteristics for this context, and portability, compatibility, and\nmaintainability as the least important. Also, we observed agreement regarding\nthe relevance of the quality characteristics among interviewees having the same\nrole. On the other hand, the relevance of each quality characteristics varied\ndepending on the concrete use case of the prospective software platform. The\ninterviewees also were asked about the key success factors related to human-AI\nteaming in smart manufacturing. They identified improving the production cycle,\nincreasing operator efficiency, reducing scrap, and reducing ergonomic risks as\nkey success criteria. In this paper, we also discuss metrics for measuring the\nfulfillment of these quality characteristics, which we intend to operationalize\nand monitor during operation of the prospective software platform.",
    "descriptor": "\nComments: Preprint: to appear in QUATIC'22 International Conference on the Quality of Information and Communications Technology\n",
    "authors": [
      "Philipp Haindl",
      "Thomas Hoch",
      "Javier Dominguez",
      "Julen Aperribai",
      "Nazim Kemal Ure",
      "Mehmet Tun\u00e7el"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2205.15767"
  },
  {
    "id": "arXiv:2205.15768",
    "title": "SAMURAI: Shape And Material from Unconstrained Real-world Arbitrary  Image collections",
    "abstract": "Inverse rendering of an object under entirely unknown capture conditions is a\nfundamental challenge in computer vision and graphics. Neural approaches such\nas NeRF have achieved photorealistic results on novel view synthesis, but they\nrequire known camera poses. Solving this problem with unknown camera poses is\nhighly challenging as it requires joint optimization over shape, radiance, and\npose. This problem is exacerbated when the input images are captured in the\nwild with varying backgrounds and illuminations. Standard pose estimation\ntechniques fail in such image collections in the wild due to very few estimated\ncorrespondences across images. Furthermore, NeRF cannot relight a scene under\nany illumination, as it operates on radiance (the product of reflectance and\nillumination). We propose a joint optimization framework to estimate the shape,\nBRDF, and per-image camera pose and illumination. Our method works on\nin-the-wild online image collections of an object and produces relightable 3D\nassets for several use-cases such as AR/VR. To our knowledge, our method is the\nfirst to tackle this severely unconstrained task with minimal user interaction.\nProject page: https://markboss.me/publication/2022-samurai/ Video:\nhttps://youtu.be/LlYuGDjXp-8",
    "descriptor": "",
    "authors": [
      "Mark Boss",
      "Andreas Engelhardt",
      "Abhishek Kar",
      "Yuanzhen Li",
      "Deqing Sun",
      "Jonathan T. Barron",
      "Hendrik P. A. Lensch",
      "Varun Jampani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15768"
  },
  {
    "id": "arXiv:2205.15769",
    "title": "Concept-level Debugging of Part-Prototype Networks",
    "abstract": "Part-prototype Networks (ProtoPNets) are concept-based classifiers designed\nto achieve the same performance as black-box models without compromising\ntransparency. ProtoPNets compute predictions based on similarity to\nclass-specific part-prototypes learned to recognize parts of training examples,\nmaking it easy to faithfully determine what examples are responsible for any\ntarget prediction and why. However, like other models, they are prone to\npicking up confounds and shortcuts from the data, thus suffering from\ncompromised prediction accuracy and limited generalization. We propose\nProtoPDebug, an effective concept-level debugger for ProtoPNets in which a\nhuman supervisor, guided by the model's explanations, supplies feedback in the\nform of what part-prototypes must be forgotten or kept, and the model is\nfine-tuned to align with this supervision. An extensive empirical evaluation on\nsynthetic and real-world data shows that ProtoPDebug outperforms\nstate-of-the-art debuggers for a fraction of the annotation cost.",
    "descriptor": "",
    "authors": [
      "Andrea Bontempelli",
      "Stefano Teso",
      "Fausto Giunchiglia",
      "Andrea Passerini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15769"
  },
  {
    "id": "arXiv:2205.15770",
    "title": "Matrix-free Monolithic Multigrid Methods for Stokes and Generalized  Stokes Problems",
    "abstract": "We consider the widely used continuous $\\mathcal{Q}_{k}$-$\\mathcal{Q}_{k-1}$\nquadrilateral or hexahedral Taylor-Hood elements for the finite element\ndiscretization of the Stokes and generalized Stokes systems in two and three\nspatial dimensions. For the fast solution of the corresponding symmetric, but\nindefinite system of finite element equations, we propose and analyze\nmatrix-free monolithic geometric multigrid solvers that are based on\nappropriately scaled Chebyshev-Jacobi smoothers. The analysis is based on\nresults by Sch\\\"oberl and Zulehner (2003). We present and discuss several\nnumerical results for typical benchmark problems.",
    "descriptor": "",
    "authors": [
      "Daniel Jodlbauer",
      "Ulrich Langer",
      "Thomas Wick",
      "Walter Zulehner"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.15770"
  },
  {
    "id": "arXiv:2205.15780",
    "title": "A Replication Study on Predicting Metamorphic Relations at Unit Testing  Level",
    "abstract": "Metamorphic Testing (MT) addresses the test oracle problem by examining the\nrelations between inputs and outputs of test executions. Such relations are\nknown as Metamorphic Relations (MRs). In current practice, identifying and\nselecting suitable MRs is usually a challenging manual task, requiring a\nthorough grasp of the SUT and its application domain. Thus, Kanewala et al.\nproposed the Predicting Metamorphic Relations (PMR) approach to automatically\nsuggest MRs from a list of six pre-defined MRs for testing newly developed\nmethods. PMR is based on a classification model trained on features extracted\nfrom the control-flow graph (CFG) of 100 Java methods. In our replication\nstudy, we explore the generalizability of PMR. First, we rebuild the entire\npreprocessing and training pipeline and repeat the original study in a close\nreplication to verify the reported results and establish the basis for further\nexperiments. Second, we perform a conceptual replication to explore the\nreusability of the PMR model trained on CFGs from Java methods in the first\nstep for functionally identical methods implemented in Python and C++. Finally,\nwe retrain the model on the CFGs from the Python and C++ methods to investigate\nthe dependence on programming language and implementation details. We were able\nto successfully replicate the original study achieving comparable results for\nthe Java methods set. However, the prediction performance of the Java-based\nclassifiers significantly decreases when applied to functionally equivalent\nPython and C++ methods despite using only CFG features to abstract from\nlanguage details. Since the performance improved again when the classifiers\nwere retrained on the CFGs of the methods written in Python and C++, we\nconclude that the PMR approach can be generalized, but only when classifiers\nare developed starting from code artefacts in the used programming language.",
    "descriptor": "\nComments: 11 pages, 10 tables, 2 figures\n",
    "authors": [
      "Alejandra Duque-Torres",
      "Dietmar Pfahl",
      "Rudolf Ramler",
      "Claus Klammer"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2205.15780"
  },
  {
    "id": "arXiv:2205.15781",
    "title": "Co-Training for Unsupervised Domain Adaptation of Semantic Segmentation  Models",
    "abstract": "Semantic image segmentation is addressed by training deep models. Since\nsupervised training draws to a curse of human-based image labeling, using\nsynthetic images with automatically generated ground truth together with\nunlabeled real-world images is a promising alternative. This implies to address\nan unsupervised domain adaptation (UDA) problem. In this paper, we proposed a\nnew co-training process for synth-to-real UDA of semantic segmentation models.\nFirst, we design a self-training procedure which provides two initial models.\nThen, we keep training these models in a collaborative manner for obtaining the\nfinal model. The overall process treats the deep models as black boxes and\ndrives their collaboration at the level of pseudo-labeled target images, {\\ie},\nneither modifying loss functions is required, nor explicit feature alignment.\nWe test our proposal on standard synthetic and real-world datasets. Our\nco-training shows improvements of 15-20 percentage points of mIoU over\nbaselines, so establishing new state-of-the-art results.",
    "descriptor": "",
    "authors": [
      "Jose L. G\u00f3mez",
      "Gabriel Villalonga",
      "Antonio M. L\u00f3pez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15781"
  },
  {
    "id": "arXiv:2205.15783",
    "title": "Benchmarks for infinite medium, time dependent transport problems with  isotropic scattering",
    "abstract": "The widely used AZURV1 transport benchmarks package provides a suite of\nsolutions to isotropic scattering transport problems with a variety of initial\nconditions (Ganapol 2001). Most of these solutions have an initial condition\nthat is a Dirac delta function in space; as a result these benchmarks are\nchallenging problems to use for verification tests in computer codes.\nNevertheless, approximating a delta function in simulation often leads to low\norders of convergence and the inability to test the convergence of high-order\nnumerical methods. While there are examples in the literature of integration of\nthese solutions as Green's functions for the transport operator to produce\nresults for more easily simulated sources, they are limited in scope and\nbriefly explained. For a sampling of initial conditions and sources, we present\nsolutions for the uncollided and collided scalar flux to facilitate accurate\ntesting of source treatment in numerical solvers. The solution for the\nuncollided scalar flux is found in analytic form for some sources. Since\nintegrating the Green's functions is often nontrivial, discussion of\nintegration difficulty and workarounds to find convergent integrals is\nincluded. Additionally, our uncollided solutions can be used as source terms in\nverification studies, in a similar way to the method of manufactured solutions.",
    "descriptor": "",
    "authors": [
      "William Bennett",
      "Ryan G. McClarren"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2205.15783"
  },
  {
    "id": "arXiv:2205.15792",
    "title": "A Survey of Deep Fake Detection for Trial Courts",
    "abstract": "Recently, image manipulation has achieved rapid growth due to the advancement\nof sophisticated image editing tools. A recent surge of generated fake imagery\nand videos using neural networks is DeepFake. DeepFake algorithms can create\nfake images and videos that humans cannot distinguish from authentic ones.\n(GANs) have been extensively used for creating realistic images without\naccessing the original images. Therefore, it is become essential to detect fake\nvideos to avoid spreading false information. This paper presents a survey of\nmethods used to detect DeepFakes and datasets available for detecting DeepFakes\nin the literature to date. We present extensive discussions and research trends\nrelated to DeepFake technologies.",
    "descriptor": "\nComments: 12 Pages, 1 Table\n",
    "authors": [
      "Naciye Celebi",
      "Qingzhong Liu",
      "Muhammed Karatoprak"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.15792"
  },
  {
    "id": "arXiv:2205.15795",
    "title": "A Meta Reinforcement Learning Approach for Predictive Autoscaling in the  Cloud",
    "abstract": "Predictive autoscaling (autoscaling with workload forecasting) is an\nimportant mechanism that supports autonomous adjustment of computing resources\nin accordance with fluctuating workload demands in the Cloud. In recent works,\nReinforcement Learning (RL) has been introduced as a promising approach to\nlearn the resource management policies to guide the scaling actions under the\ndynamic and uncertain cloud environment. However, RL methods face the following\nchallenges in steering predictive autoscaling, such as lack of accuracy in\ndecision-making, inefficient sampling and significant variability in workload\npatterns that may cause policies to fail at test time. To this end, we propose\nan end-to-end predictive meta model-based RL algorithm, aiming to optimally\nallocate resource to maintain a stable CPU utilization level, which\nincorporates a specially-designed deep periodic workload prediction model as\nthe input and embeds the Neural Process to guide the learning of the optimal\nscaling actions over numerous application services in the Cloud. Our algorithm\nnot only ensures the predictability and accuracy of the scaling strategy, but\nalso enables the scaling decisions to adapt to the changing workloads with high\nsample efficiency. Our method has achieved significant performance improvement\ncompared to the existing algorithms and has been deployed online at Alipay,\nsupporting the autoscaling of applications for the world-leading payment\nplatform.",
    "descriptor": "\nComments: Accepted by KDD'22 Applied Research Track\n",
    "authors": [
      "Siqiao Xue",
      "Chao Qu",
      "Xiaoming Shi",
      "Cong Liao",
      "Shiyi Zhu",
      "Xiaoyu Tan",
      "Lintao Ma",
      "Shiyu Wang",
      "Shijun Wang",
      "Yun Hu",
      "Lei Lei",
      "Yangfei Zheng",
      "Jianguo Li",
      "James Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15795"
  },
  {
    "id": "arXiv:2205.15802",
    "title": "AdaTask: Adaptive Multitask Online Learning",
    "abstract": "We introduce and analyze AdaTask, a multitask online learning algorithm that\nadapts to the unknown structure of the tasks. When the $N$ tasks are\nstochastically activated, we show that the regret of AdaTask is better, by a\nfactor that can be as large as $\\sqrt{N}$, than the regret achieved by running\n$N$ independent algorithms, one for each task. AdaTask can be seen as a\ncomparator-adaptive version of Follow-the-Regularized-Leader with a Mahalanobis\nnorm potential. Through a variational formulation of this potential, our\nanalysis reveals how AdaTask jointly learns the tasks and their structure.\nExperiments supporting our findings are presented.",
    "descriptor": "",
    "authors": [
      "Pierre Laforgue",
      "Andrea Della Vecchia",
      "Nicol\u00f2 Cesa-Bianchi",
      "Lorenzo Rosasco"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15802"
  },
  {
    "id": "arXiv:2205.15804",
    "title": "Deformation of the myocardium during CPR",
    "abstract": "Cardiopulmonary resuscitation (CPR) is an emergency procedure performed on\npatients during cardiac and respiratory arrest. This procedure externally\nactivates the cardiac and respiratory systems via the delivery of chest\ncompression and artificial ventilation. As the main purpose of CPR is to\nrecirculate the blood flow, prediction of the myocardium behavior has great\nimportance. This prediction allows us to have a better understanding of the\nneeded force to recirculate blood without hurting the heart. Finite element\nmethod offer the possibility of noninvasive quantification of myocardial\ndeformation. This method is attractive to use for the assessment of myocardial\nfunction. To investigate the behavior of the heart wall, a 3D model of thoracic\norgans has been prepared using medical images. In this study, to simulate the\nbehavior of different organs, Code-Aster open software is used. For every\norgan, the material properties are defined. The most important parameters in\nthe study are displacement, normal stress, and Von-Mises stress in the\nmyocardium. Using these parameters, displacement and stress distribution have\nbeen predicted. Effects of the applied force on the chest during CPR and\ndeformation of the myocardium have been predicted by the finite element model.\nA linear deformation is observable for each organ during force application.\nBesides, the final location of the heart and ribs and also involved parameters\nin predicting myocardium deformation are extracted from the model simulations.\nThis finite element model enables us to have a good vision of the deformation\nof the myocardium during CPR. Using this method, it is possible to predict the\ndeformation of every part of the heart, especially right and left ventricles.",
    "descriptor": "\nComments: 9 pages, 9 figures, 1 table\n",
    "authors": [
      "Jafar Moradicheghamahi",
      "Gerard Fortuny",
      "Josep M. L\u00f3pez",
      "Joan Herrero",
      "Dolors Puigjaner"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2205.15804"
  },
  {
    "id": "arXiv:2205.15805",
    "title": "Collaborative Sensing in Perceptive Mobile Networks: Opportunities and  Challenges",
    "abstract": "With the development of innovative applications that demand accurate\nenvironment information, e.g., autonomous driving, sensing becomes an important\nrequirement for future wireless networks. To this end, integrated sensing and\ncommunication (ISAC) provides a promising platform to exploit the synergy\nbetween sensing and communication, where perceptive mobile networks (PMNs) were\nproposed to add accurate sensing capability to existing wireless networks. The\nwell-developed cellular networks offer exciting opportunities for sensing,\nincluding large coverage, strong computation and communication power, and most\nimportantly networked sensing, where the perspectives from multiple sensing\nnodes can be collaboratively utilized for sensing the same target. However,\nPMNs also face big challenges such as the inherent interference between sensing\nand communication, the complex sensing environment, and the tracking of\nhigh-speed targets by cellular networks. This paper provides a comprehensive\nreview on the design of PMNs, covering the popular network architectures,\nsensing protocols, standing research problems, and available solutions. Several\nfuture research directions that are critical for the development of PMNs are\nalso discussed.",
    "descriptor": "",
    "authors": [
      "Lei Xie",
      "S.H. Song",
      "Yonina C. Eldar",
      "Khaled B. Letaief"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.15805"
  },
  {
    "id": "arXiv:2205.15812",
    "title": "GateNLP-UShef at SemEval-2022 Task 8: Entity-Enriched Siamese  Transformer for Multilingual News Article Similarity",
    "abstract": "This paper describes the second-placed system on the leaderboard of\nSemEval-2022 Task 8: Multilingual News Article Similarity. We propose an\nentity-enriched Siamese Transformer which computes news article similarity\nbased on different sub-dimensions, such as the shared narrative, entities,\nlocation and time of the event discussed in the news article. Our system\nexploits a Siamese network architecture using a Transformer encoder to learn\ndocument-level representations for the purpose of capturing the narrative\ntogether with the auxiliary entity-based features extracted from the news\narticles. The intuition behind using all these features together is to capture\nthe similarity between news articles at different granularity levels and to\nassess the extent to which different news outlets write about \"the same\nevents\". Our experimental results and detailed ablation study demonstrate the\neffectiveness and the validity of our proposed method.",
    "descriptor": "\nComments: SemEval-2022 Task 8: Multilingual News Article Similarity (co-located with NAACL 2022)\n",
    "authors": [
      "Iknoor Singh",
      "Yue Li",
      "Melissa Thong",
      "Carolina Scarton"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2205.15812"
  },
  {
    "id": "arXiv:2205.15813",
    "title": "A Coxeter type classification of Dynkin type $\\mathbb{A}_n$ non-negative  posets",
    "abstract": "We continue the Coxeter spectral analysis of finite connected posets $I$ that\nare non-negative in the sense that their symmetric Gram matrix\n$G_I:=\\frac{1}{2}(C_I + C_I^{tr})\\in\\mathbb{M}_{n}(\\mathbb{Q})$ is positive\nsemi-definite of rank $n-\\mathbf{crk}_I\\geq 0$, where\n$C_I\\in\\mathbb{M}_n(\\mathbb{Z})$ is the incidence matrix of $I$ encoding the\nrelation $\\preceq_I$. We extend the results of Fundam. Inform., 139.4(2015),\n347--367] and give a complete Coxeter spectral classification of finite\nconnected posets $I$ of Dynkin type $\\mathbb{A}_m$.\nWe show that such posets $I$, with $|I|>1$, yield exactly\n$\\lfloor\\frac{n}{2}\\rfloor$ Coxeter types, one of which describes the positive\n(i.e., $\\mathbf{crk}_I=0$) ones. We give an exact description and calculate the\nnumber of posets of every type. Moreover, we prove that, given a pair of such\nposets $I$ and $J$, the incidence matrices $C_I$ and $C_J$ are\n$\\mathbb{Z}$-congruent if and only if $\\mathbf{specc}_I = \\mathbf{specc}_J$,\nand present deterministic algorithms that calculate a $\\mathbb{Z}$-invertible\nmatrix defining such a $\\mathbb{Z}$-congruence in a polynomial time.",
    "descriptor": "",
    "authors": [
      "M. G\u0105siorek"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2205.15813"
  },
  {
    "id": "arXiv:2205.15814",
    "title": "Contrasting quadratic assignments for set-based representation learning",
    "abstract": "The standard approach to contrastive learning is to maximize the agreement\nbetween different views of the data. The views are ordered in pairs, such that\nthey are either positive, encoding different views of the same object, or\nnegative, corresponding to views of different objects. The supervisory signal\ncomes from maximizing the total similarity over positive pairs, while the\nnegative pairs are needed to avoid collapse. In this work, we note that the\napproach of considering individual pairs cannot account for both intra-set and\ninter-set similarities when the sets are formed from the views of the data. It\nthus limits the information content of the supervisory signal available to\ntrain representations. We propose to go beyond contrasting individual pairs of\nobjects by focusing on contrasting objects as sets. For this, we use\ncombinatorial quadratic assignment theory designed to evaluate set and graph\nsimilarities and derive set-contrastive objective as a regularizer for\ncontrastive learning methods. We conduct experiments and demonstrate that our\nmethod improves learned representations for the tasks of metric learning and\nself-supervised classification.",
    "descriptor": "",
    "authors": [
      "Artem Moskalev",
      "Ivan Sosnovik",
      "Volker Fischer",
      "Arnold Smeulders"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15814"
  },
  {
    "id": "arXiv:2205.15819",
    "title": "Do self-supervised speech models develop human-like perception biases?",
    "abstract": "Self-supervised models for speech processing form representational spaces\nwithout using any external labels. Increasingly, they appear to be a feasible\nway of at least partially eliminating costly manual annotations, a problem of\nparticular concern for low-resource languages. But what kind of\nrepresentational spaces do these models construct? Human perception specializes\nto the sounds of listeners' native languages. Does the same thing happen in\nself-supervised models? We examine the representational spaces of three kinds\nof state-of-the-art self-supervised models: wav2vec 2.0, HuBERT and contrastive\npredictive coding (CPC), and compare them with the perceptual spaces of\nFrench-speaking and English-speaking human listeners, both globally and taking\naccount of the behavioural differences between the two language groups. We show\nthat the CPC model shows a small native language effect, but that wav2vec 2.0\nand HuBERT seem to develop a universal speech perception space which is not\nlanguage specific. A comparison against the predictions of supervised phone\nrecognisers suggests that all three self-supervised models capture relatively\nfine-grained perceptual phenomena, while supervised models are better at\ncapturing coarser, phone-level, effects of listeners' native language, on\nperception.",
    "descriptor": "",
    "authors": [
      "Juliette Millet",
      "Ewan Dunbar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2205.15819"
  },
  {
    "id": "arXiv:2205.15821",
    "title": "Unsupervised Image Representation Learning with Deep Latent Particles",
    "abstract": "We propose a new representation of visual data that disentangles object\nposition from appearance. Our method, termed Deep Latent Particles (DLP),\ndecomposes the visual input into low-dimensional latent ``particles'', where\neach particle is described by its spatial location and features of its\nsurrounding region. To drive learning of such representations, we follow a\nVAE-based approach and introduce a prior for particle positions based on a\nspatial-softmax architecture, and a modification of the evidence lower bound\nloss inspired by the Chamfer distance between particles. We demonstrate that\nour DLP representations are useful for downstream tasks such as unsupervised\nkeypoint (KP) detection, image manipulation, and video prediction for scenes\ncomposed of multiple dynamic objects. In addition, we show that our\nprobabilistic interpretation of the problem naturally provides uncertainty\nestimates for particle locations, which can be used for model selection, among\nother tasks. Videos and code are available:\nhttps://taldatech.github.io/deep-latent-particles-web/",
    "descriptor": "\nComments: ICML 2022. Project webpage and code: this https URL\n",
    "authors": [
      "Tal Daniel",
      "Aviv Tamar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15821"
  },
  {
    "id": "arXiv:2205.15823",
    "title": "Predicting non-native speech perception using the Perceptual  Assimilation Model and state-of-the-art acoustic models",
    "abstract": "Our native language influences the way we perceive speech sounds, affecting\nour ability to discriminate non-native sounds. We compare two ideas about the\ninfluence of the native language on speech perception: the Perceptual\nAssimilation Model, which appeals to a mental classification of sounds into\nnative phoneme categories, versus the idea that rich, fine-grained phonetic\nrepresentations tuned to the statistics of the native language, are sufficient.\nWe operationalize this idea using representations from two state-of-the-art\nspeech models, a Dirichlet process Gaussian mixture model and the more recent\nwav2vec 2.0 model. We present a new, open dataset of French- and\nEnglish-speaking participants' speech perception behaviour for 61 vowel sounds\nfrom six languages. We show that phoneme assimilation is a better predictor\nthan fine-grained phonetic modelling, both for the discrimination behaviour as\na whole, and for predicting differences in discriminability associated with\ndifferences in native language background. We also show that wav2vec 2.0, while\nnot good at capturing the effects of native language on speech perception, is\ncomplementary to information about native phoneme assimilation, and provides a\ngood model of low-level phonetic representations, supporting the idea that both\ncategorical and fine-grained perception are used during speech perception.",
    "descriptor": "",
    "authors": [
      "Juliette Millet",
      "Ioana Chitoran",
      "Ewan Dunbar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2205.15823"
  },
  {
    "id": "arXiv:2205.15824",
    "title": "Graph Backup: Data Efficient Backup Exploiting Markovian Transitions",
    "abstract": "The successes of deep Reinforcement Learning (RL) are limited to settings\nwhere we have a large stream of online experiences, but applying RL in the\ndata-efficient setting with limited access to online interactions is still\nchallenging. A key to data-efficient RL is good value estimation, but current\nmethods in this space fail to fully utilise the structure of the trajectory\ndata gathered from the environment. In this paper, we treat the transition data\nof the MDP as a graph, and define a novel backup operator, Graph Backup, which\nexploits this graph structure for better value estimation. Compared to\nmulti-step backup methods such as $n$-step $Q$-Learning and TD($\\lambda$),\nGraph Backup can perform counterfactual credit assignment and gives stable\nvalue estimates for a state regardless of which trajectory the state is sampled\nfrom. Our method, when combined with popular value-based methods, provides\nimproved performance over one-step and multi-step methods on a suite of\ndata-efficient RL benchmarks including MiniGrid, Minatar and Atari100K. We\nfurther analyse the reasons for this performance boost through a novel\nvisualisation of the transition graphs of Atari games.",
    "descriptor": "",
    "authors": [
      "Zhengyao Jiang",
      "Tianjun Zhang",
      "Robert Kirk",
      "Tim Rockt\u00e4schel",
      "Edward Grefenstette"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15824"
  },
  {
    "id": "arXiv:2205.15827",
    "title": "Robust Anytime Learning of Markov Decision Processes",
    "abstract": "Markov decision processes (MDPs) are formal models commonly used in\nsequential decision-making. MDPs capture the stochasticity that may arise, for\ninstance, from imprecise actuators via probabilities in the transition\nfunction. However, in data-driven applications, deriving precise probabilities\nfrom (limited) data introduces statistical errors that may lead to unexpected\nor undesirable outcomes. Uncertain MDPs (uMDPs) do not require precise\nprobabilities but instead use so-called uncertainty sets in the transitions,\naccounting for such limited data. Tools from the formal verification community\nefficiently compute robust policies that provably adhere to formal\nspecifications, like safety constraints, under the worst-case instance in the\nuncertainty set. We continuously learn the transition probabilities of an MDP\nin a robust anytime-learning approach that combines a dedicated Bayesian\ninference scheme with the computation of robust policies. In particular, our\nmethod (1) approximates probabilities as intervals, (2) adapts to new data that\nmay be inconsistent with an intermediate model, and (3) may be stopped at any\ntime to compute a robust policy on the uMDP that faithfully captures the data\nso far. We show the effectiveness of our approach and compare it to robust\npolicies computed on uMDPs learned by the UCRL2 reinforcement learning\nalgorithm in an experimental evaluation on several benchmarks.",
    "descriptor": "",
    "authors": [
      "Marnix Suilen",
      "Thiago D. Sim\u00e3o",
      "Nils Jansen",
      "David Parker"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15827"
  },
  {
    "id": "arXiv:2205.15831",
    "title": "Wideband Time Frequency Coding",
    "abstract": "In the wideband regime, the performance of many of the popular modulation\nschemes such as code division multiple access and orthogonal frequency division\nmultiplexing falls quickly without channel state information. Obtaining the\namount of channel information required for these techniques to work is costly\nand difficult, which suggests the need for schemes which can perform well\nwithout channel state information. In this work, we present one such scheme,\ncalled wideband time frequency coding, which achieves rates on the order of the\nadditive white Gaussian noise capacity without requiring any channel state\ninformation. Wideband time frequency coding combines impulsive frequency shift\nkeying with pulse position modulation, which allows for information to be\nencoded in both the transmitted frequency and the transmission time period. On\nthe detection side, we propose a non-coherent decoder based on a square-law\ndetector, akin to the optimal decoder for frequency shift keying based signals.\nThe impacts of various parameters on the symbol error probability and capacity\nof wideband time frequency coding are investigated, and the results show that\nit is robust to shadowing and highly fading channels. When compared to other\nmodulation schemes such as code division multiple access, orthogonal frequency\ndivision multiplexing, pulse position modulation, and impulsive frequency shift\nkeying without channel state information, wideband time frequency coding\nachieves higher rates in the wideband regime, and performs comparably in\nsmaller bandwidths.",
    "descriptor": "",
    "authors": [
      "Kathleen Yang",
      "Salman Salamatian",
      "Rafael G. L . D'Oliveira",
      "Muriel Medard"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.15831"
  },
  {
    "id": "arXiv:2205.15833",
    "title": "Sharing Construction Safety Inspection Experiences and Site-Specific  Knowledge through XR-Augmented Visual Assistance",
    "abstract": "Early identification of on-site hazards is crucial for accident prevention in\nthe construction industry. Currently, the construction industry relies on\nexperienced safety advisors (SAs) to identify site hazards and generate\nmitigation measures to guide field workers. However, more than half of the site\nhazards remain unrecognized due to the lack of field experience or\nsite-specific knowledge of some SAs. To address these limitations, this study\nproposed an Extended Reality (XR)-augmented visual assistance framework,\nincluding Virtual Reality (VR) and Augmented Reality (AR), that enables\ncapturing and transferring subconscious inspection strategies between workers\nor workers/machines for a construction safety inspection. The purpose is to\nenhance SA's training and real-time situational awareness for identifying\non-site hazards while reducing their mental workloads.",
    "descriptor": "",
    "authors": [
      "Pengkun Liu",
      "Jinding Xing",
      "Ruoxin Xiong",
      "Pingbo Tang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2205.15833"
  },
  {
    "id": "arXiv:2205.15835",
    "title": "Using Source Code Metrics for Predicting Metamorphic Relations at Method  Level",
    "abstract": "Metamorphic testing (TM) examines the relations between inputs and outputs of\ntest runs. These relations are known as metamorphic relations (MR). Currently,\nMRs are handpicked and require in-depth knowledge of the System Under Test\n(SUT), as well as its problem domain. As a result, the identification and\nselection of high-quality MRs is a challenge. \\citeauthor{PMR1} suggested the\nPredicting Metamorphic Relations (PMR) approach for automatic prediction of\napplicable MRs picked from a predefined list. PMR is based on a Support Vector\nMachine (SVM) model using features derived from the Control Flow Graphs (CFGs)\nof 100 Java methods. The original study of \\citeauthor{PMR1} showed encouraging\nresults, but developing classification models from CFG-related features is\ncostly. In this paper, we aim at developing a PMR approach that is less costly\nwithout losing performance. We complement the original PMR approach by\nconsidering other than CFG-related features. We define 21 features that can be\ndirectly extracted from source code and build several classifiers, including\nSVM models. Our results indicate that using the original CFG-based method-level\nfeatures, in particular for a SVM with random walk kernel (RWK), achieve better\npredictions in terms of AUC-ROC for most of the candidate MRs than our models.\nHowever, for one of the candidate MRs, using source code features achieved the\nbest AUC-ROC result (greater than 0.8).",
    "descriptor": "\nComments: 8 pages, 6 tables, 3 figures\n",
    "authors": [
      "Alejandra Duque-Torres",
      "Dietmar Pfahl",
      "Claus Klammer",
      "Stefan Fischer"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2205.15835"
  },
  {
    "id": "arXiv:2205.15836",
    "title": "Surface Analysis with Vision Transformers",
    "abstract": "The extension of convolutional neural networks (CNNs) to non-Euclidean\ngeometries has led to multiple frameworks for studying manifolds. Many of those\nmethods have shown design limitations resulting in poor modelling of long-range\nassociations, as the generalisation of convolutions to irregular surfaces is\nnon-trivial. Recent state-of-the-art performance of Vision Transformers (ViTs)\ndemonstrates that a general-purpose architecture, which implements\nself-attention, could replace the local feature learning operations of CNNs.\nMotivated by the success of attention-modelling in computer vision, we extend\nViTs to surfaces by reformulating the task of surface learning as a\nsequence-to-sequence problem and propose a patching mechanism for surface\nmeshes. We validate the performance of the proposed Surface Vision Transformer\n(SiT) on two brain age prediction tasks in the developing Human Connectome\nProject (dHCP) dataset and investigate the impact of pre-training on model\nperformance. Experiments show that the SiT outperforms many surface CNNs, while\nindicating some evidence of general transformation invariance. Code available\nat https://github.com/metrics-lab/surface-vision-transformers",
    "descriptor": "\nComments: 7 pages, 1 figure, accepted to Transformers for Vision (T4V) workshop at CVPR 2022. arXiv admin note: substantial text overlap with arXiv:2204.03408, arXiv:2203.16414\n",
    "authors": [
      "Simon Dahan",
      "Logan Z. J. Williams",
      "Abdulah Fawaz",
      "Daniel Rueckert",
      "Emma C. Robinson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2205.15836"
  },
  {
    "id": "arXiv:2205.15837",
    "title": "A sharp $\u03b1$-robust $L1$ scheme on graded meshes for two-dimensional  time tempered fractional Fokker-Planck equation",
    "abstract": "In this paper, we are concerned with the numerical solution for the\ntwo-dimensional time fractional Fokker-Planck equation with tempered fractional\nderivative of order $\\alpha$. Although some of its variants are considered in\nmany recent numerical analysis papers, there are still some significant\ndifferences. Here we first provide the regularity estimates of the solution.\nAnd then a modified $L$1 scheme inspired by the middle rectangle quadrature\nformula on graded meshes is employed to compensate for the singularity of the\nsolution at $t\\rightarrow 0^{+}$, while the five-point difference scheme is\nused in space. Stability and convergence are proved in the sence of\n$L^{\\infty}$ norm, then a sharp error estimate\n$\\mathscr{O}(\\tau^{\\min\\{2-\\alpha, r\\alpha\\}})$ is derived on graded meshes.\nFurthermore, unlike the bounds proved in the previous works, the constant\nmultipliers in our analysis do not blow up as the Caputo fractional derivative\n$\\alpha$ approaches the classical value of 1. Finally, we perform the numerical\nexperiments to verify the effectiveness and convergence order of the presented\nalgorithms.",
    "descriptor": "",
    "authors": [
      "Can Wang",
      "Weihua Deng",
      "Xiangong Tang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.15837"
  },
  {
    "id": "arXiv:2205.15838",
    "title": "D$^2$NeRF: Self-Supervised Decoupling of Dynamic and Static Objects from  a Monocular Video",
    "abstract": "Given a monocular video, segmenting and decoupling dynamic objects while\nrecovering the static environment is a widely studied problem in machine\nintelligence. Existing solutions usually approach this problem in the image\ndomain, limiting their performance and understanding of the environment. We\nintroduce Decoupled Dynamic Neural Radiance Field (D$^2$NeRF), a\nself-supervised approach that takes a monocular video and learns a 3D scene\nrepresentation which decouples moving objects, including their shadows, from\nthe static background. Our method represents the moving objects and the static\nbackground by two separate neural radiance fields with only one allowing for\ntemporal changes. A naive implementation of this approach leads to the dynamic\ncomponent taking over the static one as the representation of the former is\ninherently more general and prone to overfitting. To this end, we propose a\nnovel loss to promote correct separation of phenomena. We further propose a\nshadow field network to detect and decouple dynamically moving shadows. We\nintroduce a new dataset containing various dynamic objects and shadows and\ndemonstrate that our method can achieve better performance than\nstate-of-the-art approaches in decoupling dynamic and static 3D objects,\nocclusion and shadow removal, and image segmentation for moving objects.",
    "descriptor": "",
    "authors": [
      "Tianhao Wu",
      "Fangcheng Zhong",
      "Andrea Tagliasacchi",
      "Forrester Cole",
      "Cengiz Oztireli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15838"
  },
  {
    "id": "arXiv:2205.15846",
    "title": "SaccadeNet: Towards Real-time Saccade Prediction for Virtual Reality  Infinite Walking",
    "abstract": "Modern Redirected Walking (RDW) techniques significantly outperform classical\nsolutions. Nevertheless, they are often limited by their heavy reliance on\neye-tracking hardware embedded within the VR headset to reveal redirection\nopportunities.\nWe propose a novel RDW technique that leverages the temporary blindness\ninduced due to saccades for redirection. However, unlike the state-of-the-art,\nour approach does not impose additional eye-tracking hardware requirements.\nInstead, SaccadeNet, a deep neural network, is trained on head rotation data to\npredict saccades in real-time during an apparent head rotation. Rigid\ntransformations are then applied to the virtual environment for redirection\nduring the onset duration of these saccades. However, SaccadeNet is only\neffective when combined with moderate cognitive workload that elicits repeated\nhead rotations.\nWe present three user studies. The relationship between head and gaze\ndirections is confirmed in the first user study, followed by the training data\ncollection in our second user study. Then, after some fine-tuning experiments,\nthe performance of our RDW technique is evaluated in a third user study.\nFinally, we present the results demonstrating the efficacy of our approach. It\nallowed users to walk up a straight virtual distance of at least 38 meters from\nwithin a $3.5 x 3.5m^2$ of the physical tracked space. Moreover, our system\nunlocks saccadic redirection on widely used consumer-grade hardware without\neye-tracking.",
    "descriptor": "\nComments: redirected walking, virtual reality\n",
    "authors": [
      "Yashas Joshi",
      "Charalambos Poullis"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2205.15846"
  },
  {
    "id": "arXiv:2205.15848",
    "title": "Geo-Neus: Geometry-Consistent Neural Implicit Surfaces Learning for  Multi-view Reconstruction",
    "abstract": "Recently, neural implicit surfaces learning by volume rendering has become\npopular for multi-view reconstruction. However, one key challenge remains:\nexisting approaches lack explicit multi-view geometry constraints, hence\nusually fail to generate geometry consistent surface reconstruction. To address\nthis challenge, we propose geometry-consistent neural implicit surfaces\nlearning for multi-view reconstruction. We theoretically analyze that there\nexists a gap between the volume rendering integral and point-based signed\ndistance function (SDF) modeling. To bridge this gap, we directly locate the\nzero-level set of SDF networks and explicitly perform multi-view geometry\noptimization by leveraging the sparse geometry from structure from motion (SFM)\nand photometric consistency in multi-view stereo. This makes our SDF\noptimization unbiased and allows the multi-view geometry constraints to focus\non the true surface optimization. Extensive experiments show that our proposed\nmethod achieves high-quality surface reconstruction in both complex thin\nstructures and large smooth regions, thus outperforming the state-of-the-arts\nby a large margin.",
    "descriptor": "",
    "authors": [
      "Qiancheng Fu",
      "Qingshan Xu",
      "Yew-Soon Ong",
      "Wenbing Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2205.15848"
  },
  {
    "id": "arXiv:2205.15850",
    "title": "LEXpander: applying colexification networks to automated lexicon  expansion",
    "abstract": "Recent approaches to text analysis from social media and other corpora rely\non word lists to detect topics, measure meaning, or to select relevant\ndocuments. These lists are often generated by applying computational lexicon\nexpansion methods to small, manually-curated sets of root words. Despite the\nwide use of this approach, we still lack an exhaustive comparative analysis of\nthe performance of lexicon expansion methods and how they can be improved with\nadditional linguistic data. In this work, we present LEXpander, a method for\nlexicon expansion that leverages novel data on colexification, i.e. semantic\nnetworks connecting words based on shared concepts and translations to other\nlanguages. We evaluate LEXpander in a benchmark including widely used methods\nfor lexicon expansion based on various word embedding models and synonym\nnetworks. We find that LEXpander outperforms existing approaches in terms of\nboth precision and the trade-off between precision and recall of generated word\nlists in a variety of tests. Our benchmark includes several linguistic\ncategories and sentiment variables in English and German. We also show that the\nexpanded word lists constitute a high-performing text analysis method in\napplication cases to various corpora. This way, LEXpander poses a systematic\nautomated solution to expand short lists of words into exhaustive and accurate\nword lists that can closely approximate word lists generated by experts in\npsychology and linguistics.",
    "descriptor": "\nComments: 41 pages, 5 figures\n",
    "authors": [
      "Anna Di Natale",
      "David Garcia"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.15850"
  },
  {
    "id": "arXiv:2205.15856",
    "title": "coVariance Neural Networks",
    "abstract": "Graph neural networks (GNN) are an effective framework that exploit\ninter-relationships within graph-structured data for learning. Principal\ncomponent analysis (PCA) involves the projection of data on the eigenspace of\nthe covariance matrix and draws similarities with the graph convolutional\nfilters in GNNs. Motivated by this observation, we propose a GNN architecture,\ncalled coVariance neural network (VNN), that operates on sample covariance\nmatrices as graphs. We theoretically establish the stability of VNNs to\nperturbations in the covariance matrix, thus, implying an advantage over\nstandard PCA-based data analysis approaches that are prone to instability due\nto principal components associated with close eigenvalues. Our experiments on\nreal-world datasets validate our theoretical results and show that VNN\nperformance is indeed more stable than PCA-based statistical approaches.\nMoreover, our experiments on multi-resolution datasets also demonstrate that\nVNNs are amenable to transferability of performance over covariance matrices of\ndifferent dimensions; a feature that is infeasible for PCA-based approaches.",
    "descriptor": "",
    "authors": [
      "Saurabh Sihag",
      "Gonzalo Mateos",
      "Corey McMillan",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.15856"
  },
  {
    "id": "arXiv:2205.15858",
    "title": "Automatic Diagnosis of Schizophrenia and Attention Deficit Hyperactivity  Disorder in rs-fMRI Modality using Convolutional Autoencoder Model and  Interval Type-2 Fuzzy Regression",
    "abstract": "Nowadays, many people worldwide suffer from brain disorders, and their health\nis in danger. So far, numerous methods have been proposed for the diagnosis of\nSchizophrenia (SZ) and attention deficit hyperactivity disorder (ADHD), among\nwhich functional magnetic resonance imaging (fMRI) modalities are known as a\npopular method among physicians. This paper presents an SZ and ADHD intelligent\ndetection method of resting-state fMRI (rs-fMRI) modality using a new deep\nlearning (DL) method. The University of California Los Angeles (UCLA) dataset,\nwhich contains the rs-fMRI modalities of SZ and ADHD patients, has been used\nfor experiments. The FMRIB software library (FSL) toolbox first performed\npreprocessing on rs-fMRI data. Then, a convolutional Autoencoder (CNN-AE) model\nwith the proposed number of layers is used to extract features from rs-fMRI\ndata. In the classification step, a new fuzzy method called interval type-2\nfuzzy regression (IT2FR) is introduced and then optimized by genetic algorithm\n(GA), particle swarm optimization (PSO), and gray wolf optimization (GWO)\ntechniques. Also, the results of IT2FR methods are compared with multilayer\nperceptron (MLP), k-nearest neighbors (KNN), support vector machine (SVM),\nrandom forest (RF), decision tree (DT), and adaptive neuro-fuzzy inference\nsystem (ANFIS) methods. The experiment results show that the IT2FR method with\nthe GWO optimization algorithm has achieved satisfactory results compared to\nother classifier methods. Finally, the proposed classification technique was\nable to provide 72.71% accuracy.",
    "descriptor": "",
    "authors": [
      "Afshin Shoeibi",
      "Navid Ghassemi",
      "Marjane Khodatars",
      "Parisa Moridian",
      "Abbas Khosravi",
      "Assef Zare",
      "Juan M. Gorriz",
      "Amir Hossein Chale-Chale",
      "Ali Khadem",
      "U. Rajendra Acharya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15858"
  },
  {
    "id": "arXiv:2205.15859",
    "title": "Learning Generalizable Risk-Sensitive Policies to Coordinate in  Decentralized Multi-Agent General-Sum Games",
    "abstract": "While various multi-agent reinforcement learning methods have been proposed\nin cooperative settings, few works investigate how self-interested learning\nagents achieve mutual coordination in decentralized general-sum games and\ngeneralize pre-trained policies to non-cooperative opponents during execution.\nIn this paper, we present a generalizable and sample efficient algorithm for\nmulti-agent coordination in decentralized general-sum games without any access\nto other agents' rewards or observations. Specifically, we first learn the\ndistributions over the return of individuals and estimate a dynamic\nrisk-seeking bonus to encourage agents to discover risky coordination\nstrategies. Furthermore, to avoid overfitting opponents' coordination\nstrategies during training, we propose an auxiliary opponent modeling task so\nthat agents can infer their opponents' type and dynamically alter corresponding\nstrategies during execution. Empirically, we show that agents trained via our\nmethod can achieve mutual coordination during training and avoid being\nexploited by non-cooperative opponents during execution, which outperforms\nother baseline methods and reaches the state-of-the-art.",
    "descriptor": "",
    "authors": [
      "Ziyi Liu",
      "Xian Guo",
      "Yongchun Fang"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2205.15859"
  },
  {
    "id": "arXiv:2205.15860",
    "title": "A Reduction to Binary Approach for Debiasing Multiclass Datasets",
    "abstract": "We propose a novel reduction-to-binary (R2B) approach that enforces\ndemographic parity for multiclass classification with non-binary sensitive\nattributes via a reduction to a sequence of binary debiasing tasks. We prove\nthat R2B satisfies optimality and bias guarantees and demonstrate empirically\nthat it can lead to an improvement over two baselines: (1) treating multiclass\nproblems as multi-label by debiasing labels independently and (2) transforming\nthe features instead of the labels. Surprisingly, we also demonstrate that\nindependent label debiasing yields competitive results in most (but not all)\nsettings. We validate these conclusions on synthetic and real-world datasets\nfrom social science, computer vision, and healthcare.",
    "descriptor": "\nComments: 18 pages, 5 figures\n",
    "authors": [
      "Ibrahim Alabdulmohsin",
      "Jessica Schrouff",
      "Oluwasanmi Koyejo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15860"
  },
  {
    "id": "arXiv:2205.15862",
    "title": "Snapture -- A Novel Neural Architecture for Combined Static and Dynamic  Hand Gesture Recognition",
    "abstract": "As robots are expected to get more involved in people's everyday lives,\nframeworks that enable intuitive user interfaces are in demand. Hand gesture\nrecognition systems provide a natural way of communication and, thus, are an\nintegral part of seamless Human-Robot Interaction (HRI). Recent years have\nwitnessed an immense evolution of computational models powered by deep\nlearning. However, state-of-the-art models fall short in expanding across\ndifferent gesture domains, such as emblems and co-speech. In this paper, we\npropose a novel hybrid hand gesture recognition system. Our architecture\nenables learning both static and dynamic gestures: by capturing a so-called\n\"snapshot\" of the gesture performance at its peak, we integrate the hand pose\nalong with the dynamic movement. Moreover, we present a method for analyzing\nthe motion profile of a gesture to uncover its dynamic characteristics and\nwhich allows regulating a static channel based on the amount of motion. Our\nevaluation demonstrates the superiority of our approach on two gesture\nbenchmarks compared to a CNNLSTM baseline. We also provide an analysis on a\ngesture class basis that unveils the potential of our Snapture architecture for\nperformance improvements. Thanks to its modular implementation, our framework\nallows the integration of other multimodal data like facial expressions and\nhead tracking, which are important cues in HRI scenarios, into one\narchitecture. Thus, our work contributes both to gesture recognition research\nand machine learning applications for non-verbal communication with robots.",
    "descriptor": "",
    "authors": [
      "Hassan Ali",
      "Doreen Jirak",
      "Stefan Wermter"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15862"
  },
  {
    "id": "arXiv:2205.15863",
    "title": "Justifying Social-Choice Mechanism Outcome for Improving Participant  Satisfaction",
    "abstract": "In many social-choice mechanisms the resulting choice is not the most\npreferred one for some of the participants, thus the need for methods to\njustify the choice made in a way that improves the acceptance and satisfaction\nof said participants. One natural method for providing such explanations is to\nask people to provide them, e.g., through crowdsourcing, and choosing the most\nconvincing arguments among those received. In this paper we propose the use of\nan alternative approach, one that automatically generates explanations based on\ndesirable mechanism features found in theoretical mechanism design literature.\nWe test the effectiveness of both of the methods through a series of extensive\nexperiments conducted with over 600 participants in ranked voting, a classic\nsocial choice mechanism. The analysis of the results reveals that explanations\nindeed affect both average satisfaction from and acceptance of the outcome in\nsuch settings. In particular, explanations are shown to have a positive effect\non satisfaction and acceptance when the outcome (the winning candidate in our\ncase) is the least desirable choice for the participant. A comparative analysis\nreveals that the automatically generated explanations result in similar levels\nof satisfaction from and acceptance of an outcome as with the more costly\nalternative of crowdsourced explanations, hence eliminating the need to keep\nhumans in the loop. Furthermore, the automatically generated explanations\nsignificantly reduce participants' belief that a different winner should have\nbeen elected compared to crowdsourced explanations.",
    "descriptor": "",
    "authors": [
      "Sharadhi Alape Suryanarayana",
      "David Sarne",
      "Sarit Kraus"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2205.15863"
  },
  {
    "id": "arXiv:2205.15864",
    "title": "Braille Letter Reading: A Benchmark for Spatio-Temporal Pattern  Recognition on Neuromorphic Hardware",
    "abstract": "Spatio-temporal pattern recognition is a fundamental ability of the brain\nwhich is required for numerous real-world applications. Recent deep learning\napproaches have reached outstanding accuracy in such tasks, but their\nimplementation on conventional embedded solutions is still very computationally\nand energy expensive. Tactile sensing in robotic applications is a\nrepresentative example where real-time processing and energy-efficiency are\nrequired. Following a brain-inspired computing approach, we propose a new\nbenchmark for spatio-temporal tactile pattern recognition at the edge through\nbraille letters reading. We recorded a new braille letters dataset based on the\ncapacitive tactile sensors/fingertip of the iCub robot, then we investigated\nthe importance of temporal information and the impact of event-based encoding\nfor spike-based/event-based computation. Afterwards, we trained and compared\nfeed-forward and recurrent spiking neural networks (SNNs) offline using\nback-propagation through time with surrogate gradients, then we deployed them\non the Intel Loihi neuromorphic chip for fast and efficient inference. We\nconfronted our approach to standard classifiers, in particular to a Long\nShort-Term Memory (LSTM) deployed on the embedded Nvidia Jetson GPU in terms of\nclassification accuracy, power/energy consumption and computational delay. Our\nresults show that the LSTM outperforms the recurrent SNN in terms of accuracy\nby 14%. However, the recurrent SNN on Loihi is 237 times more energy-efficient\nthan the LSTM on Jetson, requiring an average power of only 31mW. This work\nproposes a new benchmark for tactile sensing and highlights the challenges and\nopportunities of event-based encoding, neuromorphic hardware and spike-based\ncomputing for spatio-temporal pattern recognition at the edge.",
    "descriptor": "\nComments: 20 pages, submitted to Frontiers in Neuroscience - Neuromorphic Engineering\n",
    "authors": [
      "Simon F Muller-Cleve",
      "Vittorio Fra",
      "Lyes Khacef",
      "Alejandro Pequeno-Zurro",
      "Daniel Klepatsch",
      "Evelina Forno",
      "Diego G Ivanovich",
      "Shavika Rastogi",
      "Gianvito Urgese",
      "Friedemann Zenke",
      "Chiara Bartolozzi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.15864"
  },
  {
    "id": "arXiv:2205.15865",
    "title": "A Review of Mobile Mapping Systems: From Sensors to Applications",
    "abstract": "The evolution of mobile mapping systems (MMSs) has gained more attention in\nthe past few decades. MMSs have been widely used to provide valuable assets in\ndifferent applications. This has been facilitated by the wide availability of\nlow-cost sensors, the advances in computational resources, the maturity of the\nmapping algorithms, and the need for accurate and on-demand geographic\ninformation system (GIS) data and digital maps. Many MMSs combine hybrid\nsensors to provide a more informative, robust, and stable solution by\ncomplementing each other. In this paper, we present a comprehensive review of\nthe modern MMSs by focusing on 1) the types of sensors and platforms, where we\ndiscuss their capabilities, limitations, and also provide a comprehensive\noverview of recent MMS technologies available in the market, 2) highlighting\nthe general workflow to process any MMS data, 3) identifying the different use\ncases of mobile mapping technology by reviewing some of the common\napplications, and 4) presenting a discussion on the benefits, challenges, and\nshare our views on the potential research directions.",
    "descriptor": "\nComments: 5 tables\n",
    "authors": [
      "Mostafa Elhashash",
      "Hessah Albanwan",
      "Rongjun Qin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15865"
  },
  {
    "id": "arXiv:2205.15867",
    "title": "Median Pixel Difference Convolutional Network for Robust Face  Recognition",
    "abstract": "Face recognition is one of the most active tasks in computer vision and has\nbeen widely used in the real world. With great advances made in convolutional\nneural networks (CNN), lots of face recognition algorithms have achieved high\naccuracy on various face datasets. However, existing face recognition\nalgorithms based on CNNs are vulnerable to noise. Noise corrupted image\npatterns could lead to false activations, significantly decreasing face\nrecognition accuracy in noisy situations. To equip CNNs with built-in\nrobustness to noise of different levels, we proposed a Median Pixel Difference\nConvolutional Network (MeDiNet) by replacing some traditional convolutional\nlayers with the proposed novel Median Pixel Difference Convolutional Layer\n(MeDiConv) layer. The proposed MeDiNet integrates the idea of traditional\nmultiscale median filtering with deep CNNs. The MeDiNet is tested on the four\nface datasets (LFW, CA-LFW, CP-LFW, and YTF) with versatile settings on blur\nkernels, noise intensities, scales, and JPEG quality factors. Extensive\nexperiments show that our MeDiNet can effectively remove noisy pixels in the\nfeature map and suppress the negative impact of noise, leading to achieving\nlimited accuracy loss under these practical noises compared with the standard\nCNN under clean conditions.",
    "descriptor": "\nComments: Accepted by BMVC2021\n",
    "authors": [
      "Jiehua Zhang",
      "Zhuo Su",
      "Li Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2205.15867"
  },
  {
    "id": "arXiv:2205.15868",
    "title": "CogVideo: Large-scale Pretraining for Text-to-Video Generation via  Transformers",
    "abstract": "Large-scale pretrained transformers have created milestones in text (GPT-3)\nand text-to-image (DALL-E and CogView) generation. Its application to video\ngeneration is still facing many challenges: The potential huge computation cost\nmakes the training from scratch unaffordable; The scarcity and weak relevance\nof text-video datasets hinder the model understanding complex movement\nsemantics. In this work, we present 9B-parameter transformer CogVideo, trained\nby inheriting a pretrained text-to-image model, CogView2. We also propose\nmulti-frame-rate hierarchical training strategy to better align text and video\nclips. As (probably) the first open-source large-scale pretrained text-to-video\nmodel, CogVideo outperforms all publicly available models at a large margin in\nmachine and human evaluations.",
    "descriptor": "",
    "authors": [
      "Wenyi Hong",
      "Ming Ding",
      "Wendi Zheng",
      "Xinghan Liu",
      "Jie Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15868"
  },
  {
    "id": "arXiv:2205.15869",
    "title": "3D-model ShapeNet Core Classification using Meta-Semantic Learning",
    "abstract": "Understanding 3D point cloud models for learning purposes has become an\nimperative challenge for real-world identification such as autonomous driving\nsystems. A wide variety of solutions using deep learning have been proposed for\npoint cloud segmentation, object detection, and classification. These methods,\nhowever, often require a considerable number of model parameters and are\ncomputationally expensive. We study a semantic dimension of given 3D data\npoints and propose an efficient method called Meta-Semantic Learning\n(Meta-SeL). Meta-SeL is an integrated framework that leverages two input 3D\nlocal points (input 3D models and part-segmentation labels), providing a time\nand cost-efficient, and precise projection model for a number of 3D recognition\ntasks. The results indicate that Meta-SeL yields competitive performance in\ncomparison with other complex state-of-the-art work. Moreover, being random\nshuffle invariant, Meta-SeL is resilient to translation as well as jittering\nnoise.",
    "descriptor": "\nComments: The 6th International Conference on Applied Cognitive Computing\n",
    "authors": [
      "Farid Ghareh Mohammadi",
      "Cheng Chen",
      "Farzan Shenavarmasouleh",
      "M. Hadi Amini",
      "Beshoy Morkos",
      "Hamid R. Arabnia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.15869"
  },
  {
    "id": "arXiv:2205.15870",
    "title": "FaIRCoP: Facial Image Retrieval using Contrastive Personalization",
    "abstract": "Retrieving facial images from attributes plays a vital role in various\nsystems such as face recognition and suspect identification. Compared to other\nimage retrieval tasks, facial image retrieval is more challenging due to the\nhigh subjectivity involved in describing a person's facial features. Existing\nmethods do so by comparing specific characteristics from the user's mental\nimage against the suggested images via high-level supervision such as using\nnatural language. In contrast, we propose a method that uses a relatively\nsimpler form of binary supervision by utilizing the user's feedback to label\nimages as either similar or dissimilar to the target image. Such supervision\nenables us to exploit the contrastive learning paradigm for encapsulating each\nuser's personalized notion of similarity. For this, we propose a novel loss\nfunction optimized online via user feedback. We validate the efficacy of our\nproposed approach using a carefully designed testbed to simulate user feedback\nand a large-scale user study. Our experiments demonstrate that our method\niteratively improves personalization, leading to faster convergence and\nenhanced recommendation relevance, thereby, improving user satisfaction. Our\nproposed framework is also equipped with a user-friendly web interface with a\nreal-time experience for facial image retrieval.",
    "descriptor": "",
    "authors": [
      "Devansh Gupta",
      "Aditya Saini",
      "Drishti Bhasin",
      "Sarthak Bhagat",
      "Shagun Uppal",
      "Rishi Raj Jain",
      "Ponnurangam Kumaraguru",
      "Rajiv Ratn Shah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.15870"
  },
  {
    "id": "arXiv:2205.15874",
    "title": "On Maximizing Sums of Non-monotone Submodular and Linear Functions",
    "abstract": "We study the problem of Regularized Unconstrained Submodular Maximization\n(RegularizedUSM) as defined by Bodek and Feldman [BF22]. In this problem, you\nare given a non-monotone non-negative submodular function $f:2^{\\mathcal N}\\to\n\\mathbb R_{\\ge 0}$ and a linear function $\\ell:2^{\\mathcal N}\\to \\mathbb R$\nover the same ground set $\\mathcal N$, and the objective is to output a set\n$T\\subseteq \\mathcal N$ approximately maximizing the sum $f(T)+\\ell(T)$.\nSpecifically, an algorithm is said to provide an $(\\alpha,\\beta)$-approximation\nfor RegularizedUSM if it outputs a set $T$ such that $\\mathbb\nE[f(T)+\\ell(T)]\\ge \\max_{S\\subseteq \\mathcal N}[\\alpha \\cdot f(S)+\\beta\\cdot\n\\ell(S)]$. We also study the setting where $S$ and $T$ are subject to a matroid\nconstraint, which we refer to as Regularized Constrained Submodular\nMaximization (RegularizedCSM).\nFor both RegularizedUSM and RegularizedCSM, we provide improved\n$(\\alpha,\\beta)$-approximation algorithms for the cases of non-positive $\\ell$,\nnon-negative $\\ell$, and unconstrained $\\ell$. In particular, for the case of\nunconstrained $\\ell$, we are the first to provide nontrivial\n$(\\alpha,\\beta)$-approximations for RegularizedCSM, and the $\\alpha$ we obtain\nfor RegularizedUSM is superior to that of [BF22] for all $\\beta\\in (0,1)$.\nIn addition to approximation algorithms, we provide improved\ninapproximability results for all of the aforementioned cases. In particular,\nwe show that the $\\alpha$ our algorithm obtains for RegularizedCSM with\nunconstrained $\\ell$ is tight for $\\beta\\ge \\frac{e}{e+1}$. We also show\n0.478-inapproximability for maximizing a submodular function where $S$ and $T$\nare subject to a cardinality constraint, improving the long-standing\n0.491-inapproximability result due to Gharan and Vondrak [GV10].",
    "descriptor": "\nComments: 38 pages, 5 figures\n",
    "authors": [
      "Benjamin Qi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2205.15874"
  },
  {
    "id": "arXiv:2205.15875",
    "title": "SOM-CPC: Unsupervised Contrastive Learning with Self-Organizing Maps for  Structured Representations of High-Rate Time Series",
    "abstract": "Continuous monitoring with an ever-increasing number of sensors has become\nubiquitous across many application domains. Acquired data are typically\nhigh-dimensional and difficult to interpret, but they are also hypothesized to\nlie on a lower-dimensional manifold. Many deep learning (DL) models aim to\nidentify this manifold, but do not promote structure nor interpretability. We\npropose the SOM-CPC model, which jointly optimizes Contrastive Predictive\nCoding (CPC), and a Self-Organizing Map (SOM) to find such an organized\nmanifold. We address a largely unexplored and challenging set of scenarios\ncomprising high-rate time series, and show on synthetic and real-life medical\nand audio data that SOM-CPC outperforms strong baseline models that combine DL\nwith SOMs. SOM-CPC has great potential to expose latent patterns in high-rate\ndata streams, and may therefore contribute to a better understanding of many\ndifferent processes and systems.",
    "descriptor": "",
    "authors": [
      "Iris A.M. Huijben",
      "Arthur A. Nijdam",
      "Sebastiaan Overeem",
      "Merel M. van Gilst",
      "Ruud J.G. van Sloun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2205.15875"
  },
  {
    "id": "arXiv:2205.15879",
    "title": "Simplex Neural Population Learning: Any-Mixture Bayes-Optimality in  Symmetric Zero-sum Games",
    "abstract": "Learning to play optimally against any mixture over a diverse set of\nstrategies is of important practical interests in competitive games. In this\npaper, we propose simplex-NeuPL that satisfies two desiderata simultaneously:\ni) learning a population of strategically diverse basis policies, represented\nby a single conditional network; ii) using the same network, learn\nbest-responses to any mixture over the simplex of basis policies. We show that\nthe resulting conditional policies incorporate prior information about their\nopponents effectively, enabling near optimal returns against arbitrary mixture\npolicies in a game with tractable best-responses. We verify that such policies\nbehave Bayes-optimally under uncertainty and offer insights in using this\nflexibility at test time. Finally, we offer evidence that learning\nbest-responses to any mixture policies is an effective auxiliary task for\nstrategic exploration, which, by itself, can lead to more performant\npopulations.",
    "descriptor": "",
    "authors": [
      "Siqi Liu",
      "Marc Lanctot",
      "Luke Marris",
      "Nicolas Heess"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15879"
  },
  {
    "id": "arXiv:2205.15882",
    "title": "Compressed Hierarchical Representations for Multi-Task Learning and Task  Clustering",
    "abstract": "In this paper, we frame homogeneous-feature multi-task learning (MTL) as a\nhierarchical representation learning problem, with one task-agnostic and\nmultiple task-specific latent representations. Drawing inspiration from the\ninformation bottleneck principle and assuming an additive independent noise\nmodel between the task-agnostic and task-specific latent representations, we\nlimit the information contained in each task-specific representation. It is\nshown that our resulting representations yield competitive performance for\nseveral MTL benchmarks. Furthermore, for certain setups, we show that the\ntrained parameters of the additive noise model are closely related to the\nsimilarity of different tasks. This indicates that our approach yields a\ntask-agnostic representation that is disentangled in the sense that its\nindividual dimensions may be interpretable from a task-specific perspective.",
    "descriptor": "\nComments: Accepted by the 2022 International Joint Conference on Neural Networks (IJCNN 2022)\n",
    "authors": [
      "Jo\u00e3o Machado de Freitas",
      "Sebastian Berg",
      "Bernhard C. Geiger",
      "Manfred M\u00fccke"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15882"
  },
  {
    "id": "arXiv:2205.15884",
    "title": "An Effective and Efficient Evolutionary Algorithm for Many-Objective  Optimization",
    "abstract": "In evolutionary multi-objective optimization, effectiveness refers to how an\nevolutionary algorithm performs in terms of converging its solutions into the\nPareto front and also diversifying them over the front. This is not an easy\njob, particularly for optimization problems with more than three objectives,\ndubbed many-objective optimization problems. In such problems, classic\nPareto-based algorithms fail to provide sufficient selection pressure towards\nthe Pareto front, whilst recently developed algorithms, such as\ndecomposition-based ones, may struggle to maintain a set of well-distributed\nsolutions on certain problems (e.g., those with irregular Pareto fronts).\nAnother issue in some many-objective optimizers is rapidly increasing\ncomputational requirement with the number of objectives, such as\nhypervolume-based algorithms and shift-based density estimation (SDE) methods.\nIn this paper, we aim to address this problem and develop an effective and\nefficient evolutionary algorithm (E3A) that can handle various many-objective\nproblems. In E3A, inspired by SDE, a novel population maintenance method is\nproposed. We conduct extensive experiments and show that E3A performs better\nthan 11 state-of-the-art many-objective evolutionary algorithms in quickly\nfinding a set of well-converged and well-diversified solutions.",
    "descriptor": "\nComments: 22 pages, 5 figures\n",
    "authors": [
      "Yani Xue",
      "Miqing Li",
      "Xiaohui Liu"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2205.15884"
  },
  {
    "id": "arXiv:2205.15891",
    "title": "One Policy is Enough: Parallel Exploration with a Single Policy is  Minimax Optimal for Reward-Free Reinforcement Learning",
    "abstract": "While parallelism has been extensively used in Reinforcement Learning (RL),\nthe quantitative effects of parallel exploration are not well understood\ntheoretically. We study the benefits of simple parallel exploration for\nreward-free RL for linear Markov decision processes (MDPs) and two-player\nzero-sum Markov games (MGs). In contrast to the existing literature focused on\napproaches that encourage agents to explore over a diverse set of policies, we\nshow that using a single policy to guide exploration across all agents is\nsufficient to obtain an almost-linear speedup in all cases compared to their\nfully sequential counterpart. Further, we show that this simple procedure is\nminimax optimal up to logarithmic factors in the reward-free setting for both\nlinear MDPs and two-player zero-sum MGs. From a practical perspective, our\npaper shows that a single policy is sufficient and provably optimal for\nincorporating parallelism during the exploration phase.",
    "descriptor": "",
    "authors": [
      "Pedro Cisneros-Velarde",
      "Boxiang Lyu",
      "Sanmi Koyejo",
      "Mladen Kolar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.15891"
  },
  {
    "id": "arXiv:2205.15894",
    "title": "VQ-AR: Vector Quantized Autoregressive Probabilistic Time Series  Forecasting",
    "abstract": "Time series models aim for accurate predictions of the future given the past,\nwhere the forecasts are used for important downstream tasks like business\ndecision making. In practice, deep learning based time series models come in\nmany forms, but at a high level learn some continuous representation of the\npast and use it to output point or probabilistic forecasts. In this paper, we\nintroduce a novel autoregressive architecture, VQ-AR, which instead learns a\n\\emph{discrete} set of representations that are used to predict the future.\nExtensive empirical comparison with other competitive deep learning models\nshows that surprisingly such a discrete set of representations gives\nstate-of-the-art or equivalent results on a wide variety of time series\ndatasets. We also highlight the shortcomings of this approach, explore its\nzero-shot generalization capabilities, and present an ablation study on the\nnumber of representations. The full source code of the method will be available\nat the time of publication with the hope that researchers can further\ninvestigate this important but overlooked inductive bias for the time series\ndomain.",
    "descriptor": "",
    "authors": [
      "Kashif Rasul",
      "Young-Jin Park",
      "Max Nihl\u00e9n Ramstr\u00f6m",
      "Kyung-Min Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.15894"
  },
  {
    "id": "arXiv:2205.15895",
    "title": "From Keypoints to Object Landmarks via Self-Training Correspondence: A  novel approach to Unsupervised Landmark Discovery",
    "abstract": "This paper proposes a novel paradigm for the unsupervised learning of object\nlandmark detectors. Contrary to existing methods that build on auxiliary tasks\nsuch as image generation or equivariance, we propose a self-training approach\nwhere, departing from generic keypoints, a landmark detector and descriptor is\ntrained to improve itself, tuning the keypoints into distinctive landmarks. To\nthis end, we propose an iterative algorithm that alternates between producing\nnew pseudo-labels through feature clustering and learning distinctive features\nfor each pseudo-class through contrastive learning. With a shared backbone for\nthe landmark detector and descriptor, the keypoint locations progressively\nconverge to stable landmarks, filtering those less stable. Compared to previous\nworks, our approach can learn points that are more flexible in terms of\ncapturing large viewpoint changes. We validate our method on a variety of\ndifficult datasets, including LS3D, BBCPose, Human3.6M and PennAction,\nachieving new state of the art results.",
    "descriptor": "",
    "authors": [
      "Dimitrios Mallis",
      "Enrique Sanchez",
      "Matt Bell",
      "Georgios Tzimiropoulos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15895"
  },
  {
    "id": "arXiv:2205.15896",
    "title": "FedWalk: Communication Efficient Federated Unsupervised Node Embedding  with Differential Privacy",
    "abstract": "Node embedding aims to map nodes in the complex graph into low-dimensional\nrepresentations. The real-world large-scale graphs and difficulties of labeling\nmotivate wide studies of unsupervised node embedding problems. Nevertheless,\nprevious effort mostly operates in a centralized setting where a complete graph\nis given. With the growing awareness of data privacy, data holders who are only\naware of one vertex and its neighbours demand greater privacy protection. In\nthis paper, we introduce FedWalk, a random-walk-based unsupervised node\nembedding algorithm that operates in such a node-level visibility graph with\nraw graph information remaining locally. FedWalk is designed to offer\ncentralized competitive graph representation capability with data privacy\nprotection and great communication efficiency. FedWalk instantiates the\nprevalent federated paradigm and contains three modules. We first design a\nhierarchical clustering tree (HCT) constructor to extract the structural\nfeature of each node. A dynamic time wrapping algorithm seamlessly handles the\nstructural heterogeneity across different nodes. Based on the constructed HCT,\nwe then design a random walk generator, wherein a sequence encoder is designed\nto preserve privacy and a two-hop neighbor predictor is designed to save\ncommunication cost. The generated random walks are then used to update node\nembedding based on a SkipGram model. Extensive experiments on two large graphs\ndemonstrate that Fed-Walk achieves competitive representativeness as a\ncentralized node embedding algorithm does with only up to 1.8% Micro-F1 score\nand 4.4% Marco-F1 score loss while reducing about 6.7 times of inter-device\ncommunication per walk.",
    "descriptor": "\nComments: 10 pages, 8 figures, to be published in the Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining\n",
    "authors": [
      "Qiying Pan",
      "Yifei Zhu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15896"
  },
  {
    "id": "arXiv:2205.15904",
    "title": "Synthesizing Configuration Tactics for Exercising Hidden Options in  Serverless Systems",
    "abstract": "A proper configuration of an information system can ensure accuracy and\nefficiency, among other system objectives. Conversely, a poor configuration can\nhave a significant negative impact on the system's performance, reliability,\nand cost. Serverless systems in particular, which are comprised of many\nfunctions and managed services, can quickly risky the danger of\nmisconfiguration, with many provider- and platform-specific, often\nintransparent and 'hidden' settings. In this paper, we argue to pay close\nattention to the configuration of serverless systems to exercise options with\nknown accuracy, cost and time. Based on a literature study and long-term\nserverless systems development experience, we present nine tactics to unlock\npotentially neglected and unknown options in serverless systems.",
    "descriptor": "",
    "authors": [
      "J\u00f6rn Kuhlenkamp",
      "Sebastian Werner",
      "Chin Hong Tran",
      "Stefan Tai"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2205.15904"
  },
  {
    "id": "arXiv:2205.15906",
    "title": "SAR Despeckling Using Overcomplete Convolutional Networks",
    "abstract": "Synthetic Aperture Radar (SAR) despeckling is an important problem in remote\nsensing as speckle degrades SAR images, affecting downstream tasks like\ndetection and segmentation. Recent studies show that convolutional neural\nnetworks(CNNs) outperform classical despeckling methods. Traditional CNNs try\nto increase the receptive field size as the network goes deeper, thus\nextracting global features. However,speckle is relatively small, and increasing\nreceptive field does not help in extracting speckle features. This study\nemploys an overcomplete CNN architecture to focus on learning low-level\nfeatures by restricting the receptive field. The proposed network consists of\nan overcomplete branch to focus on the local structures and an undercomplete\nbranch that focuses on the global structures. We show that the proposed network\nimproves despeckling performance compared to recent despeckling methods on\nsynthetic and real SAR images.",
    "descriptor": "\nComments: Accepted to International Geoscience and Remote Sensing Symposium (IGARSS), 2022. Our code is available at this https URL\n",
    "authors": [
      "Malsha V. Perera",
      "Wele Gedara Chaminda Bandara",
      "Jeya Maria Jose Valanarasu",
      "Vishal M. Patel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2205.15906"
  },
  {
    "id": "arXiv:2205.15908",
    "title": "Computational Wavelet Method for Multidimensional Integro-Partial  Differential Equation of Distributed Order",
    "abstract": "This article provides an effective computational algorithm based on Legendre\nwavelet (LW) and standard tau approach to approximate the solution of\nmulti-dimensional distributed order time-space fractional weakly singular\nintegro-partial differential equation (DOT-SFWSIPDE). To the best of our\nunderstanding, the proposed computational algorithm is new and has not been\npreviously applied for solving DOT-SFWSIPDE. The matrix representation of\ndistributed order fractional derivatives, integer order derivatives and weakly\nsingular kernel associated with the integral based on LWare established to find\nthe numerical solutions of the proposed DOT-SFWSIPDE. Moreover, the association\nof standard tau rule and Legendre-Gauss quadrature (LGQ) techniques along with\nconstructed matrix representation of differential and integral operators\ndiminish DOT-SFWSIPDE into system of linear algebraic equations. Error bounds,\nconvergence analysis, numerical algorithms and also error estimation of the\nDOT-SFWSIPDE are regorously investigated. For the reliability of the proposed\ncomputational algorithm, numerous test examples has been incorporated in the\nmanuscript to ensure the robustness and theoretical results of proposed\ntechnique.",
    "descriptor": "\nComments: No comments\n",
    "authors": [
      "Yashveer Kuma",
      "Somveer Singh",
      "Reshma Singh",
      "Vineet Kumar Singh"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.15908"
  },
  {
    "id": "arXiv:2205.15912",
    "title": "Efficient Algorithms for Sorting in Trees",
    "abstract": "Sorting is a foundational problem in computer science that is typically\nemployed on sequences or total orders. More recently, a more general form of\nsorting on partially ordered sets (or posets), where some pairs of elements are\nincomparable, has been studied. General poset sorting algorithms have a\nlower-bound query complexity of $\\Omega(wn + n \\log n)$, where $w$ is the width\nof the poset.\nWe consider the problem of sorting in trees, a particular case of partial\norders, and parametrize the complexity with respect to $d$, the maximum degree\nof an element in the tree, as $d$ is usually much smaller than $w$ in trees.\nFor example, in complete binary trees, $d = \\Theta(1), w = \\Theta(n)$. We\npresent a randomized algorithm for sorting a tree poset in worst-case expected\n$O(dn\\log n)$ query and time complexity. This improves the previous upper bound\nof $O(dn \\log^2 n)$. Our algorithm is the first to be optimal for\nbounded-degree trees. We also provide a new lower bound of $\\Omega(dn + n \\log\nn)$ for the worst-case query complexity of sorting a tree poset. Finally, we\npresent the first deterministic algorithm for sorting tree posets that has\nlower total complexity than existing algorithms for sorting general partial\norders.",
    "descriptor": "",
    "authors": [
      "Jishnu Roychoudhury",
      "Jatin Yadav"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2205.15912"
  },
  {
    "id": "arXiv:2205.15913",
    "title": "Enhanced Teaching-Learning-based Optimization for 3D Path Planning of  Multicopter UAVs",
    "abstract": "This paper introduces a new path planning algorithm for unmanned aerial\nvehicles (UAVs) based on the teaching-learning-based optimization (TLBO)\ntechnique. We first define an objective function that incorporates requirements\non the path length and constraints on the movement and safe operation of UAVs\nto convert the path planning into an optimization problem. The optimization\nalgorithm named Multi-subject TLBO is then proposed to minimize the formulated\nobjective function. The algorithm is developed based on TLBO but enhanced with\nnew operations including mutation, elite selection and multi-subject training\nto improve the solution quality and speed up the convergence rate. Comparison\nwith state-of-the-art algorithms and experiments with real UAVs have been\nconducted to evaluate the performance of the proposed algorithm. The results\nconfirm its validity and effectiveness in generating optimal, collision-free\nand flyable paths for UAVs in complex operating environments.",
    "descriptor": "\nComments: Proceedings of the International Conference on Advanced Mechanical Engineering, Automation, and Sustainable Development 2021 (AMAS2021)\n",
    "authors": [
      "Van Truong Hoang",
      "Manh Duong Phung"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.15913"
  },
  {
    "id": "arXiv:2205.15915",
    "title": "IFCIL: An Information Flow Configuration Language for SELinux (Extended  Version)",
    "abstract": "Security Enhanced Linux (SELinux) is a security architecture for Linux\nimplementing mandatory access control. It has been used in numerous\nsecurity-critical contexts ranging from servers to mobile devices. But this is\nchallenging as SELinux security policies are difficult to write, understand,\nand maintain. Recently, the intermediate language CIL was introduced to foster\nthe development of high-level policy languages and to write structured\nconfigurations. However, CIL lacks mechanisms for ensuring that the resulting\nconfigurations obey desired information flow policies. To remedy this, we\npropose IFCIL, a backward compatible extension of CIL for specifying\nfine-grained information flow requirements for CIL configurations. Using IFCIL,\nadministrators can express, e.g., confidentiality, integrity, and\nnon-interference properties. We also provide a tool to statically verify these\nrequirements.",
    "descriptor": "\nComments: Extended version of the paper \"IFCIL: An Information Flow Configuration Language for SELinux\"\n",
    "authors": [
      "Lorenzo Ceragioli",
      "Letterio Galletta",
      "Pierpaolo Degano",
      "David Basin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.15915"
  },
  {
    "id": "arXiv:2205.15917",
    "title": "Concrete categories and higher-order recursion (With applications  including probability, differentiability, and full abstraction)",
    "abstract": "We study concrete sheaf models for a call-by-value higher-order language with\nrecursion. Our family of sheaf models is a generalization of many examples from\nthe literature, such as models for probabilistic and differentiable\nprogramming, and fully abstract logical relations models. We treat recursion in\nthe spirit of synthetic domain theory. We provide a general construction of a\nlifting monad starting from a class of admissible monomorphisms in the site of\nthe sheaf category. In this way, we obtain a family of models parametrized by a\nconcrete site and a class of monomorphisms, for which we prove a general\ncomputational adequacy theorem.",
    "descriptor": "",
    "authors": [
      "Cristina Matache",
      "Sean Moss",
      "Sam Staton"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2205.15917"
  },
  {
    "id": "arXiv:2205.15918",
    "title": "Interactive Query Clarification and Refinement via User Simulation",
    "abstract": "When users initiate search sessions, their queries are often unclear or might\nlack of context; this resulting in inefficient document ranking. Multiple\napproaches have been proposed by the Information Retrieval community to add\ncontext and retrieve documents aligned with users' intents. While some work\nfocus on query disambiguation using users' browsing history, a recent line of\nwork proposes to interact with users by asking clarification questions or/and\nproposing clarification panels. However, these approaches count either a\nlimited number (i.e., 1) of interactions with user or log-based interactions.\nIn this paper, we propose and evaluate a fully simulated query clarification\nframework allowing multi-turn interactions between IR systems and user agents.",
    "descriptor": "",
    "authors": [
      "Pierre Erbacher",
      "Ludovic Denoyer",
      "Laure Soulier"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2205.15918"
  },
  {
    "id": "arXiv:2205.15921",
    "title": "Online Meta-Learning in Adversarial Multi-Armed Bandits",
    "abstract": "We study meta-learning for adversarial multi-armed bandits. We consider the\nonline-within-online setup, in which a player (learner) encounters a sequence\nof multi-armed bandit episodes. The player's performance is measured as regret\nagainst the best arm in each episode, according to the losses generated by an\nadversary. The difficulty of the problem depends on the empirical distribution\nof the per-episode best arm chosen by the adversary. We present an algorithm\nthat can leverage the non-uniformity in this empirical distribution, and derive\nproblem-dependent regret bounds. This solution comprises an inner learner that\nplays each episode separately, and an outer learner that updates the\nhyper-parameters of the inner algorithm between the episodes. In the case where\nthe best arm distribution is far from uniform, it improves upon the best bound\nthat can be achieved by any online algorithm executed on each episode\nindividually without meta-learning.",
    "descriptor": "\nComments: Submitted to NeurIPS 2022. An older version was rejected from ICML 2022\n",
    "authors": [
      "Ilya Osadchiy",
      "Kfir Y. Levy",
      "Ron Meir"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.15921"
  },
  {
    "id": "arXiv:2205.15924",
    "title": "Continuous Temporal Graph Networks for Event-Based Graph Data",
    "abstract": "There has been an increasing interest in modeling continuous-time dynamics of\ntemporal graph data. Previous methods encode time-evolving relational\ninformation into a low-dimensional representation by specifying discrete layers\nof neural networks, while real-world dynamic graphs often vary continuously\nover time. Hence, we propose Continuous Temporal Graph Networks (CTGNs) to\ncapture the continuous dynamics of temporal graph data. We use both the link\nstarting timestamps and link duration as evolving information to model the\ncontinuous dynamics of nodes. The key idea is to use neural ordinary\ndifferential equations (ODE) to characterize the continuous dynamics of node\nrepresentations over dynamic graphs. We parameterize ordinary differential\nequations using a novel graph neural network. The existing dynamic graph\nnetworks can be considered as a specific discretization of CTGNs. Experiment\nresults on both transductive and inductive tasks demonstrate the effectiveness\nof our proposed approach over competitive baselines.",
    "descriptor": "",
    "authors": [
      "Jin Guo",
      "Zhen Han",
      "Zhou Su",
      "Jiliang Li",
      "Volker Tresp",
      "Yuyi Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15924"
  },
  {
    "id": "arXiv:2205.15930",
    "title": "Uzbek Sentiment Analysis based on local Restaurant Reviews",
    "abstract": "Extracting useful information for sentiment analysis and classification\nproblems from a big amount of user-generated feedback, such as restaurant\nreviews, is a crucial task of natural language processing, which is not only\nfor customer satisfaction where it can give personalized services, but can also\ninfluence the further development of a company. In this paper, we present a\nwork done on collecting restaurant reviews data as a sentiment analysis dataset\nfor the Uzbek language, a member of the Turkic family which is heavily affected\nby the low-resource constraint, and provide some further analysis of the novel\ndataset by evaluation using different techniques, from logistic regression\nbased models, to support vector machines, and even deep learning models, such\nas recurrent neural networks, as well as convolutional neural networks. The\npaper includes detailed information on how the data was collected, how it was\npre-processed for better quality optimization, as well as experimental setups\nfor the evaluation process. The overall evaluation results indicate that by\nperforming pre-processing steps, such as stemming for agglutinative languages,\nthe system yields better results, eventually achieving 91% accuracy result in\nthe best performing model",
    "descriptor": "\nComments: The International Conference on Agglutinative Language Technologies as a challenge of Natural Language Processing (ALTNLP) 2022, Koper, Slovenia\n",
    "authors": [
      "Sanatbek Matlatipov",
      "Hulkar Rahimboeva",
      "Jaloliddin Rajabov",
      "Elmurod Kuriyozov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.15930"
  },
  {
    "id": "arXiv:2205.15931",
    "title": "The Environmental Discontinuity Hypothesis for Down-Sampled Lexicase  Selection",
    "abstract": "Down-sampling training data has long been shown to improve the generalization\nperformance of a wide range of machine learning systems. Recently,\ndown-sampling has proved effective in genetic programming (GP) runs that\nutilize the lexicase parent selection technique. Although this down-sampling\nprocedure has been shown to significantly improve performance across a variety\nof problems, it does not seem to do so due to encouraging adaptability through\nenvironmental change. We hypothesize that the random sampling that is performed\nevery generation causes discontinuities that result in the population being\nunable to adapt to the shifting environment. We investigate modifications to\ndown-sampled lexicase selection in hopes of promoting incremental environmental\nchange to scaffold evolution by reducing the amount of jarring discontinuities\nbetween the environments of successive generations. In our empirical studies,\nwe find that forcing incremental environmental change is not significantly\nbetter for evolving solutions to program synthesis problems than simple random\ndown-sampling. In response to this, we attempt to exacerbate the hypothesized\nprevalence of discontinuities by using only disjoint down-samples to see if it\nhinders performance. We find that this also does not significantly differ from\nthe performance of regular random down-sampling. These negative results raise\nnew questions about the ways in which the composition of sub-samples, which may\ninclude synonymous cases, may be expected to influence the performance of\nmachine learning systems that use down-sampling.",
    "descriptor": "\nComments: Accepted to The 2022 Conference on Artificial Life - Why it Didn't Work-Shop. 10 pages\n",
    "authors": [
      "Ryan Boldi",
      "Thomas Helmuth",
      "Lee Spector"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2205.15931"
  },
  {
    "id": "arXiv:2205.15934",
    "title": "A Competitive Method for Dog Nose-print Re-identification",
    "abstract": "Vision-based pattern identification (such as face, fingerprint, iris etc.)\nhas been successfully applied in human biometrics for a long history. However,\ndog nose-print authentication is a challenging problem since the lack of a\nlarge amount of labeled data. For that, this paper presents our proposed\nmethods for dog nose-print authentication (Re-ID) task in CVPR 2022 pet\nbiometric challenge. First, considering the problem that each class only with\nfew samples in the training set, we propose an automatic offline data\naugmentation strategy. Then, for the difference in sample styles between the\ntraining and test datasets, we employ joint cross-entropy, triplet and\npair-wise circle losses function for network optimization. Finally, with\nmultiple models ensembled adopted, our methods achieve 86.67\\% AUC on the test\nset. Codes are available at https://github.com/muzishen/Pet-ReID-IMAG.",
    "descriptor": "\nComments: Technique report of 3rd solution to 2022 Pet Biometric Challenge (CVPRW)\n",
    "authors": [
      "Fei Shen",
      "Zhe Wang",
      "Zijun Wang",
      "Xiaode Fu",
      "Jiayi Chen",
      "Xiaoyu Du"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.15934"
  },
  {
    "id": "arXiv:2205.15935",
    "title": "Inducing bias is simpler than you think",
    "abstract": "Machine learning may be oblivious to human bias but it is not immune to its\nperpetuation. Marginalisation and iniquitous group representation are often\ntraceable in the very data used for training, and may be reflected or even\nenhanced by the learning models. To counter this, some of the model accuracy\ncan be traded off for a secondary objective that helps prevent a specific type\nof bias. Multiple notions of fairness have been proposed to this end but recent\nstudies show that some fairness criteria often stand in mutual competition.\nIn the present work, we introduce a solvable high-dimensional model of data\nimbalance, where parametric control over the many bias-inducing factors allows\nfor an extensive exploration of the bias inheritance mechanism. Through the\ntools of statistical physics, we analytically characterise the typical\nbehaviour of learning models trained in our synthetic framework and find\nsimilar unfairness behaviours as those observed on more realistic data.\nHowever, we also identify a positive transfer effect between the different\nsubpopulations within the data. This suggests that mixing data with different\nstatistical properties could be helpful, provided the learning model is made\naware of this structure.\nFinally, we analyse the issue of bias mitigation: by reweighing the various\nterms in the training loss, we indirectly minimise standard unfairness metrics\nand highlight their incompatibilities. Leveraging the insights on positive\ntransfer, we also propose a theory-informed mitigation strategy, based on the\nintroduction of coupled learning models. By allowing each model to specialise\non a different community within the data, we find that multiple fairness\ncriteria and high accuracy can be achieved simultaneously.",
    "descriptor": "\nComments: 9 pages, 7 figures + appendix\n",
    "authors": [
      "Stefano Sarao Mannelli",
      "Federica Gerace",
      "Negar Rostamzadeh",
      "Luca Saglietti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.15935"
  },
  {
    "id": "arXiv:2205.15936",
    "title": "Skeleton-based Action Recognition via Temporal-Channel Aggregation",
    "abstract": "Skeleton-based action recognition methods are limited by the semantic\nextraction of spatio-temporal skeletal maps. However, current methods have\ndifficulty in effectively combining features from both temporal and spatial\ngraph dimensions and tend to be thick on one side and thin on the other. In\nthis paper, we propose a Temporal-Channel Aggregation Graph Convolutional\nNetworks (TCA-GCN) to learn spatial and temporal topologies dynamically and\nefficiently aggregate topological features in different temporal and channel\ndimensions for skeleton-based action recognition. We use the Temporal\nAggregation module to learn temporal dimensional features and the Channel\nAggregation module to efficiently combine spatial dynamic topological features\nlearned using Channel-wise with temporal dynamic topological features. In\naddition, we extract multi-scale skeletal features on temporal modeling and\nfuse them with priori skeletal knowledge with an attention mechanism. Extensive\nexperiments show that our model results outperform state-of-the-art methods on\nthe NTU RGB+D, NTU RGB+D 120, and NW-UCLA datasets.",
    "descriptor": "",
    "authors": [
      "Shengqin Wang",
      "Yongji Zhang",
      "Fenglin Wei",
      "Kai Wang",
      "Minghao Zhao",
      "Yu Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15936"
  },
  {
    "id": "arXiv:2205.15938",
    "title": "Voxel Field Fusion for 3D Object Detection",
    "abstract": "In this work, we present a conceptually simple yet effective framework for\ncross-modality 3D object detection, named voxel field fusion. The proposed\napproach aims to maintain cross-modality consistency by representing and fusing\naugmented image features as a ray in the voxel field. To this end, the\nlearnable sampler is first designed to sample vital features from the image\nplane that are projected to the voxel grid in a point-to-ray manner, which\nmaintains the consistency in feature representation with spatial context. In\naddition, ray-wise fusion is conducted to fuse features with the supplemental\ncontext in the constructed voxel field. We further develop mixed augmentor to\nalign feature-variant transformations, which bridges the modality gap in data\naugmentation. The proposed framework is demonstrated to achieve consistent\ngains in various benchmarks and outperforms previous fusion-based methods on\nKITTI and nuScenes datasets. Code is made available at\nhttps://github.com/dvlab-research/VFF.",
    "descriptor": "\nComments: Accepted to CVPR2022\n",
    "authors": [
      "Yanwei Li",
      "Xiaojuan Qi",
      "Yukang Chen",
      "Liwei Wang",
      "Zeming Li",
      "Jian Sun",
      "Jiaya Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15938"
  },
  {
    "id": "arXiv:2205.15943",
    "title": "Conspiracy Brokers: Understanding the Monetization of YouTube Conspiracy  Theories",
    "abstract": "Conspiracy theories are increasingly a subject of research interest as\nsociety grapples with their rapid growth in areas such as politics or public\nhealth. Previous work has established YouTube as one of the most popular sites\nfor people to host and discuss different theories. In this paper, we present an\nanalysis of monetization methods of conspiracy theorist YouTube creators and\nthe types of advertisers potentially targeting this content. We collect 184,218\nad impressions from 6,347 unique advertisers found on conspiracy-focused\nchannels and mainstream YouTube content. We classify the ads into business\ncategories and compare their prevalence between conspiracy and mainstream\ncontent. We also identify common offsite monetization methods. In comparison\nwith mainstream content, conspiracy videos had similar levels of ads from\nwell-known brands, but an almost eleven times higher prevalence of likely\npredatory or deceptive ads. Additionally, we found that conspiracy channels\nwere more than twice as likely as mainstream channels to use offsite\nmonetization methods, and 53% of the demonetized channels we observed were\nlinking to third-party sites for alternative monetization opportunities. Our\nresults indicate that conspiracy theorists on YouTube had many potential\navenues to generate revenue, and that predatory ads were more frequently served\nfor conspiracy videos.",
    "descriptor": "",
    "authors": [
      "Cameron Ballard",
      "Ian Goldstein",
      "Pulak Mehta",
      "Genesis Smothers",
      "Kejsi Take",
      "Victoria Zhong",
      "Rachel Greenstadt",
      "Tobias Lauinger",
      "Damon McCoy"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2205.15943"
  },
  {
    "id": "arXiv:2205.15944",
    "title": "Hide and Seek: on the Stealthiness of Attacks against Deep Learning  Systems",
    "abstract": "With the growing popularity of artificial intelligence and machine learning,\na wide spectrum of attacks against deep learning models have been proposed in\nthe literature. Both the evasion attacks and the poisoning attacks attempt to\nutilize adversarially altered samples to fool the victim model to misclassify\nthe adversarial sample. While such attacks claim to be or are expected to be\nstealthy, i.e., imperceptible to human eyes, such claims are rarely evaluated.\nIn this paper, we present the first large-scale study on the stealthiness of\nadversarial samples used in the attacks against deep learning. We have\nimplemented 20 representative adversarial ML attacks on six popular\nbenchmarking datasets. We evaluate the stealthiness of the attack samples using\ntwo complementary approaches: (1) a numerical study that adopts 24 metrics for\nimage similarity or quality assessment; and (2) a user study of 3 sets of\nquestionnaires that has collected 20,000+ annotations from 1,000+ responses.\nOur results show that the majority of the existing attacks introduce\nnonnegligible perturbations that are not stealthy to human eyes. We further\nanalyze the factors that contribute to attack stealthiness. We further examine\nthe correlation between the numerical analysis and the user studies, and\ndemonstrate that some image quality metrics may provide useful guidance in\nattack designs, while there is still a significant gap between assessed image\nquality and visual stealthiness of attacks.",
    "descriptor": "",
    "authors": [
      "Zeyan Liu",
      "Fengjun Li",
      "Jingqiang Lin",
      "Zhu Li",
      "Bo Luo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15944"
  },
  {
    "id": "arXiv:2205.15947",
    "title": "Evaluating Robustness to Dataset Shift via Parametric Robustness Sets",
    "abstract": "We give a method for proactively identifying small, plausible shifts in\ndistribution which lead to large differences in model performance. To ensure\nthat these shifts are plausible, we parameterize them in terms of interpretable\nchanges in causal mechanisms of observed variables. This defines a parametric\nrobustness set of plausible distributions and a corresponding worst-case loss.\nWhile the loss under an individual parametric shift can be estimated via\nreweighting techniques such as importance sampling, the resulting worst-case\noptimization problem is non-convex, and the estimate may suffer from large\nvariance. For small shifts, however, we can construct a local second-order\napproximation to the loss under shift and cast the problem of finding a\nworst-case shift as a particular non-convex quadratic optimization problem, for\nwhich efficient algorithms are available. We demonstrate that this second-order\napproximation can be estimated directly for shifts in conditional exponential\nfamily models, and we bound the approximation error. We apply our approach to a\ncomputer vision task (classifying gender from images), revealing sensitivity to\nshifts in non-causal attributes.",
    "descriptor": "\nComments: Equal Contribution by NT/MO, order determined by coin flip\n",
    "authors": [
      "Nikolaj Thams",
      "Michael Oberst",
      "David Sontag"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.15947"
  },
  {
    "id": "arXiv:2205.15948",
    "title": "Two-Dimensional Quantum Material Identification via Self-Attention and  Soft-labeling in Deep Learning",
    "abstract": "In quantum machine field, detecting two-dimensional (2D) materials in Silicon\nchips is one of the most critical problems. Instance segmentation can be\nconsidered as a potential approach to solve this problem. However, similar to\nother deep learning methods, the instance segmentation requires a large scale\ntraining dataset and high quality annotation in order to achieve a considerable\nperformance. In practice, preparing the training dataset is a challenge since\nannotators have to deal with a large image, e.g 2K resolution, and extremely\ndense objects in this problem. In this work, we present a novel method to\ntackle the problem of missing annotation in instance segmentation in 2D quantum\nmaterial identification. We propose a new mechanism for automatically detecting\nfalse negative objects and an attention based loss strategy to reduce the\nnegative impact of these objects contributing to the overall loss function. We\nexperiment on the 2D material detection datasets, and the experiments show our\nmethod outperforms previous works.",
    "descriptor": "",
    "authors": [
      "Xuan Bac Nguyen",
      "Apoorva Bisht",
      "Hugh Churchill",
      "Khoa Luu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.15948"
  },
  {
    "id": "arXiv:2205.15951",
    "title": "Hollywood Identity Bias Dataset: A Context Oriented Bias Analysis of  Movie Dialogues",
    "abstract": "Movies reflect society and also hold power to transform opinions. Social\nbiases and stereotypes present in movies can cause extensive damage due to\ntheir reach. These biases are not always found to be the need of storyline but\ncan creep in as the author's bias. Movie production houses would prefer to\nascertain that the bias present in a script is the story's demand. Today, when\ndeep learning models can give human-level accuracy in multiple tasks, having an\nAI solution to identify the biases present in the script at the writing stage\ncan help them avoid the inconvenience of stalled release, lawsuits, etc. Since\nAI solutions are data intensive and there exists no domain specific data to\naddress the problem of biases in scripts, we introduce a new dataset of movie\nscripts that are annotated for identity bias. The dataset contains dialogue\nturns annotated for (i) bias labels for seven categories, viz., gender,\nrace/ethnicity, religion, age, occupation, LGBTQ, and other, which contains\nbiases like body shaming, personality bias, etc. (ii) labels for sensitivity,\nstereotype, sentiment, emotion, emotion intensity, (iii) all labels annotated\nwith context awareness, (iv) target groups and reason for bias labels and (v)\nexpert-driven group-validation process for high quality annotations. We also\nreport various baseline performances for bias identification and category\ndetection on our dataset.",
    "descriptor": "",
    "authors": [
      "Sandhya Singh",
      "Prapti Roy",
      "Nihar Sahoo",
      "Niteesh Mallela",
      "Himanshu Gupta",
      "Pushpak Bhattacharyya",
      "Milind Savagaonkar",
      "Nidhi",
      "Roshni Ramnani",
      "Anutosh Maitra",
      "Shubhashis Sengupta"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15951"
  },
  {
    "id": "arXiv:2205.15952",
    "title": "Knowledge Graph -- Deep Learning: A Case Study in Question Answering in  Aviation Safety Domain",
    "abstract": "In the commercial aviation domain, there are a large number of documents,\nlike, accident reports (NTSB, ASRS) and regulatory directives (ADs). There is a\nneed for a system to access these diverse repositories efficiently in order to\nservice needs in the aviation industry, like maintenance, compliance, and\nsafety. In this paper, we propose a Knowledge Graph (KG) guided Deep Learning\n(DL) based Question Answering (QA) system for aviation safety. We construct a\nKnowledge Graph from Aircraft Accident reports and contribute this resource to\nthe community of researchers. The efficacy of this resource is tested and\nproved by the aforesaid QA system. Natural Language Queries constructed from\nthe documents mentioned above are converted into SPARQL (the interface language\nof the RDF graph database) queries and answered. On the DL side, we have two\ndifferent QA models: (i) BERT QA which is a pipeline of Passage Retrieval\n(Sentence-BERT based) and Question Answering (BERT based), and (ii) the\nrecently released GPT-3. We evaluate our system on a set of queries created\nfrom the accident reports. Our combined QA system achieves 9.3% increase in\naccuracy over GPT-3 and 40.3% increase over BERT QA. Thus, we infer that KG-DL\nperforms better than either singly.",
    "descriptor": "",
    "authors": [
      "Ankush Agarwal",
      "Raj Gite",
      "Shreya Laddha",
      "Pushpak Bhattacharyya",
      "Satyanarayan Kar",
      "Asif Ekbal",
      "Prabhjit Thind",
      "Rajesh Zele",
      "Ravi Shankar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15952"
  },
  {
    "id": "arXiv:2205.15953",
    "title": "Timing is Everything: Learning to Act Selectively with Costly Actions  and Budgetary Constraints",
    "abstract": "Many real-world settings involve costs for performing actions; transaction\ncosts in financial systems and fuel costs being common examples. In these\nsettings, performing actions at each time step quickly accumulates costs\nleading to vastly suboptimal outcomes. Additionally, repeatedly acting produces\nwear and tear and ultimately, damage. Determining when to act is crucial for\nachieving successful outcomes and yet, the challenge of efficiently learning to\nbehave optimally when actions incur minimally bounded costs remains unresolved.\nIn this paper, we introduce a reinforcement learning (RL) framework named\nLearnable Impulse Control Reinforcement Algorithm (LICRA), for learning to\noptimally select both when to act and which actions to take when actions incur\ncosts. At the core of LICRA is a nested structure that combines RL and a form\nof policy known as impulse control which learns to maximise objectives when\nactions incur costs. We prove that LICRA, which seamlessly adopts any RL\nmethod, converges to policies that optimally select when to perform actions and\ntheir optimal magnitudes. We then augment LICRA to handle problems in which the\nagent can perform at most $k<\\infty$ actions and more generally, faces a budget\nconstraint. We show LICRA learns the optimal value function and ensures budget\nconstraints are satisfied almost surely. We demonstrate empirically LICRA's\nsuperior performance against benchmark RL methods in OpenAI gym's Lunar Lander\nand in Highway environments and a variant of the Merton portfolio problem\nwithin finance.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2112.02618, arXiv:2103.09159, arXiv:2205.15064\n",
    "authors": [
      "David Mguni",
      "Aivar Sootla",
      "Juliusz Ziomek",
      "Oliver Slumbers",
      "Zipeng Dai",
      "Kun Shao",
      "Jun Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15953"
  },
  {
    "id": "arXiv:2205.15954",
    "title": "Indirect Point Cloud Registration: Aligning Distance Fields using a  Pseudo Third Point Ses",
    "abstract": "In recent years, implicit functions have drawn attention in the field of 3D\nreconstruction and have successfully been applied with Deep Learning. However,\nfor incremental reconstruction, implicit function-based registrations have been\nrarely explored. Inspired by the high precision of deep learning global feature\nregistration, we propose to combine this with distance fields. We generalize\nthe algorithm to a non-Deep Learning setting while retaining the accuracy. Our\nalgorithm is more accurate than conventional models while, without any\ntraining, it achieves a competitive performance and faster speed, compared to\nDeep Learning-based registration models. The implementation is available on\ngithub for the research community.",
    "descriptor": "\nComments: Accpted to RAL2022, code at this https URL\n",
    "authors": [
      "Yijun Yuan",
      "Andreas Nuechter"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.15954"
  },
  {
    "id": "arXiv:2205.15955",
    "title": "CropMix: Sampling a Rich Input Distribution via Multi-Scale Cropping",
    "abstract": "We present a simple method, CropMix, for the purpose of producing a rich\ninput distribution from the original dataset distribution. Unlike single random\ncropping, which may inadvertently capture only limited information, or\nirrelevant information, like pure background, unrelated objects, etc, we crop\nan image multiple times using distinct crop scales, thereby ensuring that\nmulti-scale information is captured. The new input distribution, serving as\ntraining data, useful for a number of vision tasks, is then formed by simply\nmixing multiple cropped views. We first demonstrate that CropMix can be\nseamlessly applied to virtually any training recipe and neural network\narchitecture performing classification tasks. CropMix is shown to improve the\nperformance of image classifiers on several benchmark tasks across-the-board\nwithout sacrificing computational simplicity and efficiency. Moreover, we show\nthat CropMix is of benefit to both contrastive learning and masked image\nmodeling towards more powerful representations, where preferable results are\nachieved when learned representations are transferred to downstream tasks. Code\nis available at GitHub.",
    "descriptor": "\nComments: Code: this https URL\n",
    "authors": [
      "Junlin Han",
      "Lars Petersson",
      "Hongdong Li",
      "Ian Reid"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2205.15955"
  },
  {
    "id": "arXiv:2205.15958",
    "title": "The dynamics of online polarization",
    "abstract": "Several studies pointed out that users seek the information they like the\nmost, filter out dissenting information, and join groups of like-minded users\naround shared narratives. Feed algorithms may burst such a configuration toward\npolarization, thus influencing how information (and misinformation) spreads\nonline. However, despite the extensive evidence and data about polarized\nopinion spaces and echo chambers, the interplay between human and algorithmic\nfactors in shaping these phenomena remains unclear. In this work, we propose an\nopinion dynamic model mimicking human attitudes and algorithmic features. We\nquantitatively assess the adherence of the model's prediction to empirical data\nand compare the model performances with other state-of-the-art models. We\nfinally provide a synthetic description of social media platforms regarding the\nmodel's parameters space that may be used to fine-tune feed algorithms to\neventually smooth extreme polarization.",
    "descriptor": "",
    "authors": [
      "Carlo Michele Valensise",
      "Matteo Cinelli",
      "Walter Quattrociocchi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2205.15958"
  },
  {
    "id": "arXiv:2205.15960",
    "title": "NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local  Languages",
    "abstract": "Natural language processing (NLP) has a significant impact on society via\ntechnologies such as machine translation and search engines. Despite its\nsuccess, NLP technology is only widely available for high-resource languages\nsuch as English and Chinese, while it remains inaccessible to many languages\ndue to the unavailability of data resources and benchmarks. In this work, we\nfocus on developing resources for languages in Indonesia. Despite being the\nsecond most linguistically diverse country, most languages in Indonesia are\ncategorized as endangered and some are even extinct. We develop the first-ever\nparallel resource for 10 low-resource languages in Indonesia. Our resource\nincludes datasets, a multi-task benchmark, and lexicons, as well as a parallel\nIndonesian-English dataset. We provide extensive analyses and describe the\nchallenges when creating such resources. We hope that our work can spark NLP\nresearch on Indonesian and other underrepresented languages.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Genta Indra Winata",
      "Alham Fikri Aji",
      "Samuel Cahyawijaya",
      "Rahmad Mahendra",
      "Fajri Koto",
      "Ade Romadhony",
      "Kemal Kurniawan",
      "David Moeljadi",
      "Radityo Eko Prasojo",
      "Pascale Fung",
      "Timothy Baldwin",
      "Jey Han Lau",
      "Rico Sennrich",
      "Sebastian Ruder"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.15960"
  },
  {
    "id": "arXiv:2205.15967",
    "title": "You Can't Count on Luck: Why Decision Transformers Fail in Stochastic  Environments",
    "abstract": "Recently, methods such as Decision Transformer that reduce reinforcement\nlearning to a prediction task and solve it via supervised learning (RvS) have\nbecome popular due to their simplicity, robustness to hyperparameters, and\nstrong overall performance on offline RL tasks. However, simply conditioning a\nprobabilistic model on a desired return and taking the predicted action can\nfail dramatically in stochastic environments since trajectories that result in\na return may have only achieved that return due to luck. In this work, we\ndescribe the limitations of RvS approaches in stochastic environments and\npropose a solution. Rather than simply conditioning on the return of a single\ntrajectory as is standard practice, our proposed method, ESPER, learns to\ncluster trajectories and conditions on average cluster returns, which are\nindependent from environment stochasticity. Doing so allows ESPER to achieve\nstrong alignment between target return and expected performance in real\nenvironments. We demonstrate this in several challenging stochastic offline-RL\ntasks including the challenging puzzle game 2048, and Connect Four playing\nagainst a stochastic opponent. In all tested domains, ESPER achieves\nsignificantly better alignment between the target return and achieved return\nthan simply conditioning on returns. ESPER also achieves higher maximum\nperformance than even the value-based baselines.",
    "descriptor": "",
    "authors": [
      "Keiran Paster",
      "Sheila McIlraith",
      "Jimmy Ba"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.15967"
  },
  {
    "id": "arXiv:2205.15970",
    "title": "FedHarmony: Unlearning Scanner Bias with Distributed Data",
    "abstract": "The ability to combine data across scanners and studies is vital for\nneuroimaging, to increase both statistical power and the representation of\nbiological variability. However, combining datasets across sites leads to two\nchallenges: first, an increase in undesirable non-biological variance due to\nscanner and acquisition differences - the harmonisation problem - and second,\ndata privacy concerns due to the inherently personal nature of medical imaging\ndata, meaning that sharing them across sites may risk violation of privacy\nlaws. To overcome these restrictions, we propose FedHarmony: a harmonisation\nframework operating in the federated learning paradigm. We show that to remove\nthe scanner-specific effects, we only need to share the mean and standard\ndeviation of the learned features, helping to protect individual subjects'\nprivacy. We demonstrate our approach across a range of realistic data\nscenarios, using real multi-site data from the ABIDE dataset, thus showing the\npotential utility of our method for MRI harmonisation across studies. Our code\nis available at https://github.com/nkdinsdale/FedHarmony.",
    "descriptor": "\nComments: Accepted to MICCAI 2022, Code available at: this https URL\n",
    "authors": [
      "Nicola K Dinsdale",
      "Mark Jenkinson",
      "Ana IL Namburete"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15970"
  },
  {
    "id": "arXiv:2205.15972",
    "title": "K-Detector: Identifying Duplicate Crash Failures in Large-Scale Software  Delivery",
    "abstract": "After a developer submits code, corresponding test cases arise to ensure the\nquality of software delivery. Test failures would occur during this period,\nsuch as crash, error, and timeout. Since it takes time for developers to\nresolve them, many duplicate failures will happen during this period. In the\ndelivery practice of SAP HANA, crash triaging is considered as the most\ntime-consuming task. If duplicate crash failures can be automatically\nidentified, the degree of automation will be significantly enhanced. To find\nsuch duplicates, we propose a training-based mathematical model that utilizes\ncomponent information of SAP HANA to achieve better crash similarity\ncomparison. We implement our approach in a tool named Knowledge-based Detector\n(K-Detector), which is verified by 11,208 samples and performs 0.986 in AUC.\nFurthermore, we apply K-Detector to the production environment, and it can save\n97% human efforts in crash triage as statistics.",
    "descriptor": "",
    "authors": [
      "Hao Yang",
      "Yang Xu",
      "Yong Li",
      "Hyun-Deok Choi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2205.15972"
  },
  {
    "id": "arXiv:2205.15979",
    "title": "TUM Autonomous Motorsport: An Autonomous Racing Software for the Indy  Autonomous Challenge",
    "abstract": "For decades, motorsport has been an incubator for innovations in the\nautomotive sector and brought forth systems like disk brakes or rearview\nmirrors. Autonomous racing series such as Roborace, F1Tenth, or the Indy\nAutonomous Challenge (IAC) are envisioned as playing a similar role within the\nautonomous vehicle sector, serving as a proving ground for new technology at\nthe limits of the autonomous systems capabilities. This paper outlines the\nsoftware stack and approach of the TUM Autonomous Motorsport team for their\nparticipation in the Indy Autonomous Challenge, which holds two competitions: A\nsingle-vehicle competition on the Indianapolis Motor Speedway and a passing\ncompetition at the Las Vegas Motor Speedway. Nine university teams used an\nidentical vehicle platform: A modified Indy Lights chassis equipped with\nsensors, a computing platform, and actuators. All the teams developed different\nalgorithms for object detection, localization, planning, prediction, and\ncontrol of the race cars. The team from TUM placed first in Indianapolis and\nsecured second place in Las Vegas. During the final of the passing competition,\nthe TUM team reached speeds and accelerations close to the limit of the\nvehicle, peaking at around 270 km/h and 28 ms2. This paper will present details\nof the vehicle hardware platform, the developed algorithms, and the workflow to\ntest and enhance the software applied during the two-year project. We derive\ndeep insights into the autonomous vehicle's behavior at high speed and high\nacceleration by providing a detailed competition analysis. Based on this, we\ndeduce a list of lessons learned and provide insights on promising areas of\nfuture work based on the real-world evaluation of the displayed concepts.",
    "descriptor": "\nComments: 37 pages, 18 figures, 2 tables\n",
    "authors": [
      "Johannes Betz",
      "Tobias Betz",
      "Felix Fent",
      "Maximilian Geisslinger",
      "Alexander Heilmeier",
      "Leonhard Hermansdorfer",
      "Thomas Herrmann",
      "Sebastian Huch",
      "Phillip Karle",
      "Markus Lienkamp",
      "Boris Lohmann",
      "Felix Nobis",
      "Levent \u00d6gretmen",
      "Matthias Rowold",
      "Florian Sauerbeck",
      "Tim Stahl",
      "Rainer Trauth",
      "Frederik Werner",
      "Alexander Wischnewski"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2205.15979"
  },
  {
    "id": "arXiv:2205.15982",
    "title": "Testing Research Software: A Survey",
    "abstract": "Background: Research software plays an important role in solving real-life\nproblems, empowering scientific innovations, and handling emergency situations.\nTherefore, the correctness and trustworthiness of research software are of\nabsolute importance. Software testing is an important activity for identifying\nproblematic code and helping to produce high-quality software. However, testing\nof research software is difficult due to the complexity of the underlying\nscience, relatively unknown results from scientific algorithms, and the culture\nof the research software community. Aims: The goal of this paper is to better\nunderstand current testing practices, identify challenges, and provide\nrecommendations on how to improve the testing process for research software\ndevelopment. Method: We surveyed members of the research software developer\ncommunity to collect information regarding their knowledge about and use of\nsoftware testing in their projects. Results: We analysed 120 responses and\nidentified that even though research software developers report they have an\naverage level of knowledge about software testing, they still find it difficult\ndue to the numerous challenges involved. However, there are a number of ways,\nsuch as proper training, that can improve the testing process for research\nsoftware. Conclusions: Testing can be challenging for any type of software.\nThis difficulty is especially present in the development of research software,\nwhere software engineering activities are typically given less attention. To\nproduce trustworthy results from research software, there is a need for a\nculture change so that testing is valued and teams devote appropriate effort to\nwriting and executing tests.",
    "descriptor": "\nComments: Accepted for publication in Empirical Software Engineering\n",
    "authors": [
      "Nasir U. Eisty",
      "Jeffrey C. Carver"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2205.15982"
  },
  {
    "id": "arXiv:2205.15987",
    "title": "Semi-Supervised Cross-Silo Advertising with Partial Knowledge Transfer",
    "abstract": "As an emerging secure learning paradigm in leveraging cross-agency private\ndata, vertical federated learning (VFL) is expected to improve advertising\nmodels by enabling the joint learning of complementary user attributes\nprivately owned by the advertiser and the publisher. However, there are two key\nchallenges in applying it to advertising systems: a) the limited scale of\nlabeled overlapping samples, and b) the high cost of real-time cross-agency\nserving. In this paper, we propose a semi-supervised split distillation\nframework VFed-SSD to alleviate the two limitations. We identify that: i) there\nare massive unlabeled overlapped data available in advertising systems, and ii)\nwe can keep a balance between model performance and inference cost by\ndecomposing the federated model. Specifically, we develop a self-supervised\ntask Matched Pair Detection (MPD) to exploit the vertically partitioned\nunlabeled data and propose the Split Knowledge Distillation (SplitKD) schema to\navoid cross-agency serving. Empirical studies on three industrial datasets\nexhibit the effectiveness of our methods, with the median AUC over all datasets\nimproved by 0.86% and 2.6% in the local deployment mode and the federated\ndeployment mode respectively. Overall, our framework provides an efficient\nfederation-enhanced solution for real-time display advertising with minimal\ndeploying cost and significant performance lift.",
    "descriptor": "\nComments: 6 pages, 3 figures, 3 tables\n",
    "authors": [
      "Wenjie Li",
      "Qiaolin Xia",
      "Junfeng Deng",
      "Hao Cheng",
      "Jiangming Liu",
      "Kouying Xue",
      "Yong Cheng",
      "Shu-Tao Xia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2205.15987"
  },
  {
    "id": "arXiv:2205.15990",
    "title": "Correlation versus RMSE Loss Functions in Symbolic Regression Tasks",
    "abstract": "The use of correlation as a fitness function is explored in symbolic\nregression tasks and the performance is compared against the typical RMSE\nfitness function. Using correlation with an alignment step to conclude the\nevolution led to significant performance gains over RMSE as a fitness function.\nUsing correlation as a fitness function led to solutions being found in fewer\ngenerations compared to RMSE, as well it was found that fewer data points were\nneeded in the training set to discover the correct equations. The Feynman\nSymbolic Regression Benchmark as well as several other old and recent GP\nbenchmark problems were used to evaluate performance.",
    "descriptor": "\nComments: Submitted to the GPTP conference\n",
    "authors": [
      "Nathan Haut",
      "Wolfgang Banzhaf",
      "Bill Punch"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2205.15990"
  },
  {
    "id": "arXiv:2205.15992",
    "title": "Private Federated Submodel Learning with Sparsification",
    "abstract": "We investigate the problem of private read update write (PRUW) in federated\nsubmodel learning (FSL) with sparsification. In FSL, a machine learning model\nis divided into multiple submodels, where each user updates only the submodel\nthat is relevant to the user's local data. PRUW is the process of privately\nperforming FSL by reading from and writing to the required submodel without\nrevealing the submodel index, or the values of updates to the databases.\nSparsification is a widely used concept in learning, where the users update\nonly a small fraction of parameters to reduce the communication cost. Revealing\nthe coordinates of these selected (sparse) updates leaks privacy of the user.\nWe show how PRUW in FSL can be performed with sparsification. We propose a\nnovel scheme which privately reads from and writes to arbitrary parameters of\nany given submodel, without revealing the submodel index, values of updates, or\nthe coordinates of the sparse updates, to databases. The proposed scheme\nachieves significantly lower reading and writing costs compared to what is\nachieved without sparsification.",
    "descriptor": "",
    "authors": [
      "Sajani Vithana",
      "Sennur Ulukus"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.15992"
  },
  {
    "id": "arXiv:2205.15994",
    "title": "A Multi-Head Convolutional Neural Network Based Non-Intrusive Load  Monitoring Algorithm Under Dynamic Grid Voltage Conditions",
    "abstract": "In recent times, non-intrusive load monitoring (NILM) has emerged as an\nimportant tool for distribution-level energy management systems owing to its\npotential for energy conservation and management. However, load monitoring in\nsmart building environments is challenging due to high variability of real-time\nload and varied load composition. Furthermore, as the volume and dimensionality\nof smart meters data increases, accuracy and computational time are key\nconcerning factors. In view of these challenges, this paper proposes an\nimproved NILM technique using multi-head (Mh-Net) convolutional neural network\n(CNN) under dynamic grid voltage conditions. An attention layer is introduced\ninto the proposed CNN model, which helps in improving estimation accuracy of\nappliance power consumption. The performance of the developed model has been\nverified on an experimental laboratory setup for multiple appliance sets with\nvaried power consumption levels, under dynamic grid voltages. Moreover, the\neffectiveness of the proposed model has been verified on widely used UK-DALE\ndata, and its performance has been compared with existing NILM techniques.\nResults depict that the proposed model accurately identifies appliances, power\nconsumptions and their time-of-use even during practical dynamic grid voltage\nconditions.",
    "descriptor": "",
    "authors": [
      "Himanshu Grover",
      "Lokesh Panwar",
      "Ashu Verma",
      "B. K. Panigrahi",
      "T. S. Bhatti"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.15994"
  },
  {
    "id": "arXiv:2205.15996",
    "title": "Text2Human: Text-Driven Controllable Human Image Generation",
    "abstract": "Generating high-quality and diverse human images is an important yet\nchallenging task in vision and graphics. However, existing generative models\noften fall short under the high diversity of clothing shapes and textures.\nFurthermore, the generation process is even desired to be intuitively\ncontrollable for layman users. In this work, we present a text-driven\ncontrollable framework, Text2Human, for a high-quality and diverse human\ngeneration. We synthesize full-body human images starting from a given human\npose with two dedicated steps. 1) With some texts describing the shapes of\nclothes, the given human pose is first translated to a human parsing map. 2)\nThe final human image is then generated by providing the system with more\nattributes about the textures of clothes. Specifically, to model the diversity\nof clothing textures, we build a hierarchical texture-aware codebook that\nstores multi-scale neural representations for each type of texture. The\ncodebook at the coarse level includes the structural representations of\ntextures, while the codebook at the fine level focuses on the details of\ntextures. To make use of the learned hierarchical codebook to synthesize\ndesired images, a diffusion-based transformer sampler with mixture of experts\nis firstly employed to sample indices from the coarsest level of the codebook,\nwhich then is used to predict the indices of the codebook at finer levels. The\npredicted indices at different levels are translated to human images by the\ndecoder learned accompanied with hierarchical codebooks. The use of\nmixture-of-experts allows for the generated image conditioned on the\nfine-grained text input. The prediction for finer level indices refines the\nquality of clothing textures. Extensive quantitative and qualitative\nevaluations demonstrate that our proposed framework can generate more diverse\nand realistic human images compared to state-of-the-art methods.",
    "descriptor": "\nComments: SIGGRAPH 2022; Project Page: this https URL, Codes available at this https URL\n",
    "authors": [
      "Yuming Jiang",
      "Shuai Yang",
      "Haonan Qiu",
      "Wayne Wu",
      "Chen Change Loy",
      "Ziwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15996"
  },
  {
    "id": "arXiv:2205.15997",
    "title": "TransFuser: Imitation with Transformer-Based Sensor Fusion for  Autonomous Driving",
    "abstract": "How should we integrate representations from complementary sensors for\nautonomous driving? Geometry-based fusion has shown promise for perception\n(e.g. object detection, motion forecasting). However, in the context of\nend-to-end driving, we find that imitation learning based on existing sensor\nfusion methods underperforms in complex driving scenarios with a high density\nof dynamic agents. Therefore, we propose TransFuser, a mechanism to integrate\nimage and LiDAR representations using self-attention. Our approach uses\ntransformer modules at multiple resolutions to fuse perspective view and bird's\neye view feature maps. We experimentally validate its efficacy on a challenging\nnew benchmark with long routes and dense traffic, as well as the official\nleaderboard of the CARLA urban driving simulator. At the time of submission,\nTransFuser outperforms all prior work on the CARLA leaderboard in terms of\ndriving score by a large margin. Compared to geometry-based fusion, TransFuser\nreduces the average collisions per kilometer by 48%.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2104.09224\n",
    "authors": [
      "Kashyap Chitta",
      "Aditya Prakash",
      "Bernhard Jaeger",
      "Zehao Yu",
      "Katrin Renz",
      "Andreas Geiger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.15997"
  },
  {
    "id": "arXiv:2205.15999",
    "title": "Cascade Luminance and Chrominance for Image Retouching: More Like Artist",
    "abstract": "Photo retouching aims to adjust the luminance, contrast, and saturation of\nthe image to make it more human aesthetically desirable. However, artists'\nactions in photo retouching are difficult to quantitatively analyze. By\ninvestigating their retouching behaviors, we propose a two-stage network that\nbrightens images first and then enriches them in the chrominance plane. Six\npieces of useful information from image EXIF are picked as the network's\ncondition input. Additionally, hue palette loss is added to make the image more\nvibrant. Based on the above three aspects, Luminance-Chrominance Cascading\nNet(LCCNet) makes the machine learning problem of mimicking artists in photo\nretouching more reasonable. Experiments show that our method is effective on\nthe benchmark MIT-Adobe FiveK dataset, and achieves state-of-the-art\nperformance for both quantitative and qualitative evaluation.",
    "descriptor": "",
    "authors": [
      "Hailong Ma",
      "Sibo Feng",
      "Xi Xiao",
      "Chenyu Dong",
      "Xingyue Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15999"
  },
  {
    "id": "arXiv:2205.16001",
    "title": "Cluster-based Evaluation of Automatically Generated Text",
    "abstract": "While probabilistic language generators have improved dramatically over the\nlast few years, the automatic evaluation metrics used to assess them have not\nkept pace with this progress. In the domain of language generation, a good\nmetric must correlate highly with human judgements. Yet, with few exceptions,\nthere is a lack of such metrics in the literature. In this work, we analyse the\ngeneral paradigm of language generator evaluation. We first discuss the\ncomputational and qualitative issues with using automatic evaluation metrics\nthat operate on probability distributions over strings, the backbone of most\nlanguage generators. We then propose the use of distributions over clusters\ninstead, where we cluster strings based on their text embeddings (obtained from\na pretrained language model). While we find the biases introduced by this\nsubstitution to be quite strong, we observe that, empirically, this methodology\nleads to metric estimators with higher correlation with human judgements, while\nsimultaneously reducing estimator variance. We finish the paper with a probing\nanalysis, which leads us to conclude that -- by encoding syntactic- and\ncoherence-level features of text, while ignoring surface-level features --\nthese clusters may simply be better equipped to evaluate state-of-the-art\nlanguage models.",
    "descriptor": "\nComments: Tiago Pimentel and Clara Meister contributed equally to this work\n",
    "authors": [
      "Tiago Pimentel",
      "Clara Meister",
      "Ryan Cotterell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.16001"
  },
  {
    "id": "arXiv:2205.16003",
    "title": "Learning (Very) Simple Generative Models Is Hard",
    "abstract": "Motivated by the recent empirical successes of deep generative models, we\nstudy the computational complexity of the following unsupervised learning\nproblem. For an unknown neural network $F:\\mathbb{R}^d\\to\\mathbb{R}^{d'}$, let\n$D$ be the distribution over $\\mathbb{R}^{d'}$ given by pushing the standard\nGaussian $\\mathcal{N}(0,\\textrm{Id}_d)$ through $F$. Given i.i.d. samples from\n$D$, the goal is to output any distribution close to $D$ in statistical\ndistance. We show under the statistical query (SQ) model that no\npolynomial-time algorithm can solve this problem even when the output\ncoordinates of $F$ are one-hidden-layer ReLU networks with $\\log(d)$ neurons.\nPreviously, the best lower bounds for this problem simply followed from lower\nbounds for supervised learning and required at least two hidden layers and\n$\\mathrm{poly}(d)$ neurons [Daniely-Vardi '21, Chen-Gollakota-Klivans-Meka\n'22]. The key ingredient in our proof is an ODE-based construction of a\ncompactly supported, piecewise-linear function $f$ with polynomially-bounded\nslopes such that the pushforward of $\\mathcal{N}(0,1)$ under $f$ matches all\nlow-degree moments of $\\mathcal{N}(0,1)$.",
    "descriptor": "\nComments: 24 pages, 2 figures\n",
    "authors": [
      "Sitan Chen",
      "Jerry Li",
      "Yuanzhi Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.16003"
  },
  {
    "id": "arXiv:2205.16004",
    "title": "What Knowledge Gets Distilled in Knowledge Distillation?",
    "abstract": "Knowledge distillation aims to transfer useful information from a teacher\nnetwork to a student network, with the primary goal of improving the student's\nperformance for the task at hand. Over the years, there has a been a deluge of\nnovel techniques and use cases of knowledge distillation. Yet, despite the\nvarious improvements, there seems to be a glaring gap in the community's\nfundamental understanding of the process. Specifically, what is the knowledge\nthat gets distilled in knowledge distillation? In other words, in what ways\ndoes the student become similar to the teacher? Does it start to localize\nobjects in the same way? Does it get fooled by the same adversarial samples?\nDoes its data invariance properties become similar? Our work presents a\ncomprehensive study to try to answer these questions and more. Our results,\nusing image classification as a case study and three state-of-the-art knowledge\ndistillation techniques, show that knowledge distillation methods can indeed\nindirectly distill other kinds of properties beyond improving task performance.\nBy exploring these questions, we hope for our work to provide a clearer picture\nof what happens during knowledge distillation.",
    "descriptor": "",
    "authors": [
      "Utkarsh Ojha",
      "Yuheng Li",
      "Yong Jae Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.16004"
  },
  {
    "id": "arXiv:2205.16005",
    "title": "Neural Retriever and Go Beyond: A Thesis Proposal",
    "abstract": "Information Retriever (IR) aims to find the relevant documents (e.g.\nsnippets, passages, and articles) to a given query at large scale. IR plays an\nimportant role in many tasks such as open domain question answering and\ndialogue systems, where external knowledge is needed. In the past, searching\nalgorithms based on term matching have been widely used. Recently, neural-based\nalgorithms (termed as neural retrievers) have gained more attention which can\nmitigate the limitations of traditional methods. Regardless of the success\nachieved by neural retrievers, they still face many challenges, e.g. suffering\nfrom a small amount of training data and failing to answer simple\nentity-centric questions. Furthermore, most of the existing neural retrievers\nare developed for pure-text query. This prevents them from handling\nmulti-modality queries (i.e. the query is composed of textual description and\nimages). This proposal has two goals. First, we introduce methods to address\nthe abovementioned issues of neural retrievers from three angles, new model\narchitectures, IR-oriented pretraining tasks, and generating large scale\ntraining data. Second, we identify the future research direction and propose\npotential corresponding solution.",
    "descriptor": "\nComments: Accepted to NAACL 2022 SRW\n",
    "authors": [
      "Man Luo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2205.16005"
  },
  {
    "id": "arXiv:2205.16007",
    "title": "Improved Vector Quantized Diffusion Models",
    "abstract": "Vector quantized diffusion (VQ-Diffusion) is a powerful generative model for\ntext-to-image synthesis, but sometimes can still generate low-quality samples\nor weakly correlated images with text input. We find these issues are mainly\ndue to the flawed sampling strategy. In this paper, we propose two important\ntechniques to further improve the sample quality of VQ-Diffusion. 1) We explore\nclassifier-free guidance sampling for discrete denoising diffusion model and\npropose a more general and effective implementation of classifier-free\nguidance. 2) We present a high-quality inference strategy to alleviate the\njoint distribution issue in VQ-Diffusion. Finally, we conduct experiments on\nvarious datasets to validate their effectiveness and show that the improved\nVQ-Diffusion suppresses the vanilla version by large margins. We achieve an\n8.44 FID score on MSCOCO, surpassing VQ-Diffusion by 5.42 FID score. When\ntrained on ImageNet, we dramatically improve the FID score from 11.89 to 4.83,\ndemonstrating the superiority of our proposed techniques.",
    "descriptor": "",
    "authors": [
      "Zhicong Tang",
      "Shuyang Gu",
      "Jianmin Bao",
      "Dong Chen",
      "Fang Wen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.16007"
  },
  {
    "id": "arXiv:2205.16008",
    "title": "More Stiffness with Less Fiber: End-to-End Fiber Path Optimization for  3D-Printed Composites",
    "abstract": "In 3D printing, stiff fibers (e.g., carbon fiber) can reinforce thermoplastic\npolymers with limited stiffness. However, existing commercial digital\nmanufacturing software only provides a few simple fiber layout algorithms,\nwhich solely use the geometry of the shape. In this work, we build an automated\nfiber path planning algorithm that maximizes the stiffness of a 3D print given\nspecified external loads. We formalize this as an optimization problem: an\nobjective function is designed to measure the stiffness of the object while\nregularizing certain properties of fiber paths (e.g., smoothness). To\ninitialize each fiber path, we use finite element analysis to calculate the\nstress field on the object and greedily \"walk\" in the direction of the stress\nfield. We then apply a gradient-based optimization algorithm that uses the\nadjoint method to calculate the gradient of stiffness with respect to fiber\nlayout. We compare our approach, in both simulation and real-world experiments,\nto three baselines: (1) concentric fiber rings generated by Eiger, a leading\ndigital manufacturing software package developed by Markforged, (2) greedy\nextraction on the simulated stress field (i.e., our method without\noptimization), and (3) the greedy algorithm on a fiber orientation field\ncalculated by smoothing the simulated stress fields. The results show that\nobjects with fiber paths generated by our algorithm achieve greater stiffness\nwhile using less fiber than the baselines--our algorithm improves the Pareto\nfrontier of object stiffness as a function of fiber usage. Ablation studies\nshow that the smoothing regularizer is needed for feasible fiber paths and\nstability of optimization, and multi-resolution optimization help reduce the\nrunning time compared to single-resolution optimization.",
    "descriptor": "\nComments: 12 pages, 18 figures\n",
    "authors": [
      "Xingyuan Sun",
      "Geoffrey Roeder",
      "Tianju Xue",
      "Ryan P. Adams",
      "Szymon Rusinkiewicz"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2205.16008"
  },
  {
    "id": "arXiv:2205.15320",
    "title": "Payday loans -- blessing or growth suppressor? Machine Learning Analysis",
    "abstract": "The upsurge of real estate involves a variety of factors that have got\ninfluenced by many domains. Indeed, the unrecognized sector that would affect\nthe economy for which regulatory proposals are being drafted to keep this in\ncontrol is the payday loans. This research paper revolves around the impact of\npayday loans in the real estate market. The research paper draws a first-hand\nexperience of obtaining the index for the concentration of real estate in an\narea of reference by virtue of payday loans in Toronto, Ontario in particular,\nwhich sets out an ideology to create, evaluate and demonstrate the scenario\nthrough research analysis. The purpose of this indexing via payday loans is the\nbasic - debt: income ratio which states that when the income of the person\nbound to pay the interest of payday loans increases, his debt goes down\nmarginally which hence infers that the person invests in fixed assets like real\nestate which hikes up its growth.",
    "descriptor": "\nComments: 8 pages, 8 figures\n",
    "authors": [
      "Rohith Mahadevan",
      "Sam Richard",
      "Kishore Harshan Kumar",
      "Jeevitha Murugan",
      "Santhosh Kannan",
      "Saaisri",
      "Tarun",
      "Raja CSP Raman"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15320"
  },
  {
    "id": "arXiv:2205.15346",
    "title": "$TimeEvolver$: A Program for Time Evolution With Improved Error Bound",
    "abstract": "We present $TimeEvolver$, a program for computing time evolution in a generic\nquantum system. It relies on well-known Krylov subspace techniques to tackle\nthe problem of multiplying the exponential of a large sparse matrix $i H$,\nwhere $H$ is the Hamiltonian, with an initial vector $v$. The fact that $H$ is\nHermitian makes it possible to provide an easily computable bound on the\naccuracy of the Krylov approximation. Apart from effects of numerical roundoff,\nthe resulting a posteriori error bound is rigorous, which represents a crucial\nnovelty as compared to existing software packages such as $Expokit$ (R. Sidje,\nACM Trans. Math. Softw. 24 (1) 1998). On a standard notebook, $TimeEvolver$\nallows to compute time evolution with adjustable precision in Hilbert spaces of\ndimension greater than $10^6$. Additionally, we provide routines for deriving\nthe matrix $H$ from a more abstract representation of the Hamiltonian operator.",
    "descriptor": "\nComments: 18 pages, 4 figures\n",
    "authors": [
      "Marco Michel",
      "Sebastian Zell"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "High Energy Physics - Theory (hep-th)",
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2205.15346"
  },
  {
    "id": "arXiv:2205.15364",
    "title": "Associative Learning Mechanism for Drug-Target Interaction Prediction",
    "abstract": "As a necessary process in drug development, finding a drug compound that can\nselectively bind to a specific protein is highly challenging and costly.\nDrug-target affinity (DTA), which represents the strength of drug-target\ninteraction (DTI), has played an important role in the DTI prediction task over\nthe past decade. Although deep learning has been applied to DTA-related\nresearch, existing solutions ignore fundamental correlations between molecular\nsubstructures in molecular representation learning of drug compound\nmolecules/protein targets. Moreover, traditional methods lack the\ninterpretability of the DTA prediction process. This results in missing feature\ninformation of intermolecular interactions, thereby affecting prediction\nperformance. Therefore, this paper proposes a DTA prediction method with\ninteractive learning and an autoencoder mechanism. The proposed model enhances\nthe corresponding ability to capture the feature information of a single\nmolecular sequence by the drug/protein molecular representation learning module\nand supplements the information interaction between molecular sequence pairs by\nthe interactive information learning module. The DTA value prediction module\nfuses the drug-target pair interaction information to output the predicted\nvalue of DTA. Additionally, this paper theoretically proves that the proposed\nmethod maximizes evidence lower bound (ELBO) for the joint distribution of the\nDTA prediction model, which enhances the consistency of the probability\ndistribution between the actual value and the predicted value. The experimental\nresults confirm mutual transformer-drug target affinity (MT-DTA) achieves\nbetter performance than other comparative methods.",
    "descriptor": "",
    "authors": [
      "Zhiqin Zhu",
      "Zheng Yao",
      "Guanqiu Qi",
      "Neal Mazur",
      "Baisheng Cong"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15364"
  },
  {
    "id": "arXiv:2205.15368",
    "title": "Infinite-dimensional optimization and Bayesian nonparametric learning of  stochastic differential equations",
    "abstract": "The paper has two major themes. The first part of the paper establishes\ncertain general results for infinite-dimensional optimization problems on\nHilbert spaces. These results cover the classical representer theorem and many\nof its variants as special cases and offer a wider scope of applications. The\nsecond part of the paper then develops a systematic approach for learning the\ndrift function of a stochastic differential equation by integrating the results\nof the first part with Bayesian hierarchical framework. Importantly, our\nBaysian approach incorporates low-cost sparse learning through proper use of\nshrinkage priors while allowing proper quantification of uncertainty through\nposterior distributions. Several examples at the end illustrate the accuracy of\nour learning scheme.",
    "descriptor": "\nComments: 32 pages, 4 figures\n",
    "authors": [
      "Arnab Ganguly",
      "Riten Mitra",
      "Jinpu Zhou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2205.15368"
  },
  {
    "id": "arXiv:2205.15371",
    "title": "Optimal and Adaptive Monteiro-Svaiter Acceleration",
    "abstract": "We develop a variant of the Monteiro-Svaiter (MS) acceleration framework that\nremoves the need to solve an expensive implicit equation at every iteration.\nConsequently, for any $p\\ge 2$ we improve the complexity of convex optimization\nwith Lipschitz $p$th derivative by a logarithmic factor, matching a lower\nbound. We also introduce an MS subproblem solver that requires no knowledge of\nproblem parameters, and implement it as either a second- or first-order method\nby solving linear systems or applying MinRes, respectively. On logistic\nregression our method outperforms previous second-order momentum methods, but\nunder-performs Newton's method; simply iterating our first-order adaptive\nsubproblem solver performs comparably to L-BFGS.",
    "descriptor": "",
    "authors": [
      "Yair Carmon",
      "Danielle Hausler",
      "Arun Jambulapati",
      "Yujia Jin",
      "Aaron Sidford"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2205.15371"
  },
  {
    "id": "arXiv:2205.15395",
    "title": "A hybrid approach to seismic deblending: when physics meets  self-supervision",
    "abstract": "To limit the time, cost, and environmental impact associated with the\nacquisition of seismic data, in recent decades considerable effort has been put\ninto so-called simultaneous shooting acquisitions, where seismic sources are\nfired at short time intervals between each other. As a consequence, waves\noriginating from consecutive shots are entangled within the seismic recordings,\nyielding so-called blended data. For processing and imaging purposes, the data\ngenerated by each individual shot must be retrieved. This process, called\ndeblending, is achieved by solving an inverse problem which is heavily\nunderdetermined. Conventional approaches rely on transformations that render\nthe blending noise into burst-like noise, whilst preserving the signal of\ninterest. Compressed sensing type regularization is then applied, where\nsparsity in some domain is assumed for the signal of interest. The domain of\nchoice depends on the geometry of the acquisition and the properties of seismic\ndata within the chosen domain. In this work, we introduce a new concept that\nconsists of embedding a self-supervised denoising network into the\nPlug-and-Play (PnP) framework. A novel network is introduced whose design\nextends the blind-spot network architecture of [28 ] for partially coherent\nnoise (i.e., correlated in time). The network is then trained directly on the\nnoisy input data at each step of the PnP algorithm. By leveraging both the\nunderlying physics of the problem and the great denoising capabilities of our\nblind-spot network, the proposed algorithm is shown to outperform an\nindustry-standard method whilst being comparable in terms of computational\ncost. Moreover, being independent on the acquisition geometry, our method can\nbe easily applied to both marine and land data without any significant\nmodification.",
    "descriptor": "\nComments: 21 pages, 15 figures\n",
    "authors": [
      "Nick Luiken",
      "Matteo Ravasi",
      "Claire E. Birnie"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.15395"
  },
  {
    "id": "arXiv:2205.15402",
    "title": "A generalization of cellular automata over groups",
    "abstract": "Let $G$ be a group and let $A$ be a finite set with at least two elements. A\ncellular automaton (CA) over $A^G$ is a function $\\tau : A^G \\to A^G$ defined\nvia a finite memory set $S \\subseteq G$ and a local function $\\mu :A^S \\to A$.\nThe goal of this paper is to introduce the definition of a generalized cellular\nautomaton (GCA) $\\tau : A^G \\to A^H$, where $H$ is another arbitrary group, via\na group homomorphism $\\phi : H \\to G$. Our definition preserves the essence of\nCA, as we prove analogous versions of three key results in the theory of CA: a\ngeneralized Curtis-Hedlund Theorem for GCA, a Theorem of Composition for GCA,\nand a Theorem of Invertibility for GCA. When $G=H$, we prove that the group of\ninvertible GCA over $A^G$ is isomorphic to a semidirect product of\n$\\text{Aut}(G)^{op}$ and the group of invertible CA. Finally, we apply our\nresults to study automorphisms of the monoid $\\text{CA}(G;A)$ consisting of all\nCA over $A^G$. In particular, we show that every $\\phi \\in \\text{Aut}(G)$\ndefines an automorphism of $\\text{CA}(G;A)$ via conjugation by the invertible\nGCA defined by $\\phi$, and that, when $G$ is abelian, $\\text{Aut}(G)$ is\nembedded in the outer automorphism group of $\\text{CA}(G;A)$.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "A. Castillo-Ramirez",
      "M. Sanchez-Alvarez",
      "A. Vazquez-Aceves",
      "A. Zaldivar-Corichi"
    ],
    "subjectives": [
      "Group Theory (math.GR)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2205.15402"
  },
  {
    "id": "arXiv:2205.15413",
    "title": "PolypConnect: Image inpainting for generating realistic gastrointestinal  tract images with polyps",
    "abstract": "Early identification of a polyp in the lower gastrointestinal (GI) tract can\nlead to prevention of life-threatening colorectal cancer. Developing\ncomputer-aided diagnosis (CAD) systems to detect polyps can improve detection\naccuracy and efficiency and save the time of the domain experts called\nendoscopists. Lack of annotated data is a common challenge when building CAD\nsystems. Generating synthetic medical data is an active research area to\novercome the problem of having relatively few true positive cases in the\nmedical domain. To be able to efficiently train machine learning (ML) models,\nwhich are the core of CAD systems, a considerable amount of data should be\nused. In this respect, we propose the PolypConnect pipeline, which can convert\nnon-polyp images into polyp images to increase the size of training datasets\nfor training. We present the whole pipeline with quantitative and qualitative\nevaluations involving endoscopists. The polyp segmentation model trained using\nsynthetic data, and real data shows a 5.1% improvement of mean intersection\nover union (mIOU), compared to the model trained only using real data. The\ncodes of all the experiments are available on GitHub to reproduce the results.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Jan Andre Fagereng",
      "Vajira Thambawita",
      "Andrea M. Stor\u00e5s",
      "Sravanthi Parasa",
      "Thomas de Lange",
      "P\u00e5l Halvorsen",
      "Michael A. Riegler"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15413"
  },
  {
    "id": "arXiv:2205.15439",
    "title": "StyleTTS: A Style-Based Generative Model for Natural and Diverse  Text-to-Speech Synthesis",
    "abstract": "Text-to-Speech (TTS) has recently seen great progress in synthesizing\nhigh-quality speech owing to the rapid development of parallel TTS systems, but\nproducing speech with naturalistic prosodic variations, speaking styles and\nemotional tones remains challenging. Moreover, since duration and speech are\ngenerated separately, parallel TTS models still have problems finding the best\nmonotonic alignments that are crucial for naturalistic speech synthesis. Here,\nwe propose StyleTTS, a style-based generative model for parallel TTS that can\nsynthesize diverse speech with natural prosody from a reference speech\nutterance. With novel Transferable Monotonic Aligner (TMA) and\nduration-invariant data augmentation schemes, our method significantly\noutperforms state-of-the-art models on both single and multi-speaker datasets\nin subjective tests of speech naturalness and speaker similarity. Through\nself-supervised learning of the speaking styles, our model can synthesize\nspeech with the same prosodic and emotional tone as any given reference speech\nwithout the need for explicitly labeling these categories.",
    "descriptor": "",
    "authors": [
      "Yinghao Aaron Li",
      "Cong Han",
      "Nima Mesgarani"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2205.15439"
  },
  {
    "id": "arXiv:2205.15440",
    "title": "Lithium-Ion Battery Charging Schedule Optimization to Balance Battery  Usage and Degradation",
    "abstract": "This work optimizes a lithium-ion battery charging schedule while considering\na joint revenue and battery degradation model. The study extends the work of\nMeheswari et. al. to encourage battery usage/charging at optimal intervals\ndepending on energy cost forecasts. This paper utilizes central difference\nNesterov momentum gradient descent to come to optimal charging strategies and\ndeal with the non-linearities of the battery degradation model. This\noptimization strategy is tested against constant, random varied price forecasts\nand a novel Gaussian process cost forecasting model. Contrary to many other\npapers regarding battery charging, formulating schedule optimization as a\nmultivariate optimization problem provides meaningful insight to the inherent\nbalance between these two competing objectives.",
    "descriptor": "\nComments: 8 pages, 14 figures\n",
    "authors": [
      "Jacob Azoulay",
      "Nico Carballal"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2205.15440"
  },
  {
    "id": "arXiv:2205.15447",
    "title": "Holistic Generalized Linear Models",
    "abstract": "Holistic linear regression extends the classical best subset selection\nproblem by adding additional constraints designed to improve the model quality.\nThese constraints include sparsity-inducing constraints, sign-coherence\nconstraints and linear constraints. The $\\textsf{R}$ package $\\texttt{holiglm}$\nprovides functionality to model and fit holistic generalized linear models. By\nmaking use of state-of-the-art conic mixed-integer solvers, the package can\nreliably solve GLMs for Gaussian, binomial and Poisson responses with a\nmultitude of holistic constraints. The high-level interface simplifies the\nconstraint specification and can be used as a drop-in replacement for the\n$\\texttt{stats::glm()}$ function.",
    "descriptor": "\nComments: 34 pages, 2 figures, 4 tables\n",
    "authors": [
      "Benjamin Schwendinger",
      "Florian Schwendinger",
      "Laura Vana"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Mathematical Software (cs.MS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2205.15447"
  },
  {
    "id": "arXiv:2205.15458",
    "title": "Bayesian Active Learning for Scanning Probe Microscopy: from Gaussian  Processes to Hypothesis Learning",
    "abstract": "Recent progress in machine learning methods, and the emerging availability of\nprogrammable interfaces for scanning probe microscopes (SPMs), have propelled\nautomated and autonomous microscopies to the forefront of attention of the\nscientific community. However, enabling automated microscopy requires the\ndevelopment of task-specific machine learning methods, understanding the\ninterplay between physics discovery and machine learning, and fully defined\ndiscovery workflows. This, in turn, requires balancing the physical intuition\nand prior knowledge of the domain scientist with rewards that define\nexperimental goals and machine learning algorithms that can translate these to\nspecific experimental protocols. Here, we discuss the basic principles of\nBayesian active learning and illustrate its applications for SPM. We progress\nfrom the Gaussian Process as a simple data-driven method and Bayesian inference\nfor physical models as an extension of physics-based functional fits to more\ncomplex deep kernel learning methods, structured Gaussian Processes, and\nhypothesis learning. These frameworks allow for the use of prior data, the\ndiscovery of specific functionalities as encoded in spectral data, and\nexploration of physical laws manifesting during the experiment. The discussed\nframework can be universally applied to all techniques combining imaging and\nspectroscopy, SPM methods, nanoindentation, electron microscopy and\nspectroscopy, and chemical imaging methods, and can be particularly impactful\nfor destructive or irreversible measurements.",
    "descriptor": "\nComments: 39 pages, 10 figures\n",
    "authors": [
      "Maxim Ziatdinov",
      "Yongtao Liu",
      "Kyle Kelley",
      "Rama Vasudevan",
      "Sergei V. Kalinin"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15458"
  },
  {
    "id": "arXiv:2205.15460",
    "title": "Critic Sequential Monte Carlo",
    "abstract": "We introduce CriticSMC, a new algorithm for planning as inference built from\na novel composition of sequential Monte Carlo with learned soft-Q function\nheuristic factors. This algorithm is structured so as to allow using large\nnumbers of putative particles leading to efficient utilization of computational\nresource and effective discovery of high reward trajectories even in\nenvironments with difficult reward surfaces such as those arising from hard\nconstraints. Relative to prior art our approach is notably still compatible\nwith model-free reinforcement learning in the sense that the implicit policy we\nproduce can be used at test time in the absence of a world model. Our\nexperiments on self-driving car collision avoidance in simulation demonstrate\nimprovements against baselines in terms of infraction minimization relative to\ncomputational effort while maintaining diversity and realism of found\ntrajectories.",
    "descriptor": "\nComments: 20 pages, 3 figures\n",
    "authors": [
      "Vasileios Lioutas",
      "Jonathan Wilder Lavington",
      "Justice Sefas",
      "Matthew Niedoba",
      "Yunpeng Liu",
      "Berend Zwartsenberg",
      "Setareh Dabiri",
      "Frank Wood",
      "Adam Scibior"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15460"
  },
  {
    "id": "arXiv:2205.15498",
    "title": "Hadamard matrices related to a certain series of ternary self-dual codes",
    "abstract": "In 2013, Nebe and Villar gave a series of ternary self-dual codes of length\n$2(p+1)$ for a prime $p$ congruent to $5$ modulo $8$. As a consequence, the\nthird ternary extremal self-dual code of length $60$ was found. We show that\nthe ternary self-dual code contains codewords which form a Hadamard matrix of\norder $2(p+1)$ when $p$ is congruent to $5$ modulo $24$. In addition, it is\nshown that the ternary self-dual code is generated by the rows of the Hadamard\nmatrix. We also demonstrate that the third ternary extremal self-dual code of\nlength $60$ contains at least two inequivalent Hadamard matrices.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Makoto Araya",
      "Masaaki Harada",
      "Koji Momihara"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.15498"
  },
  {
    "id": "arXiv:2205.15510",
    "title": "Molecular Dipole Moment Learning via Rotationally Equivariant Gaussian  Process Regression with Derivatives in Molecular-orbital-based Machine  Learning",
    "abstract": "This study extends the accurate and transferable molecular-orbital-based\nmachine learning (MOB-ML) approach to modeling the contribution of electron\ncorrelation to dipole moments at the cost of Hartree-Fock computations. A\nmolecular-orbital-based (MOB) pairwise decomposition of the correlation part of\nthe dipole moment is applied, and these pair dipole moments could be further\nregressed as a universal function of molecular orbitals (MOs). The dipole MOB\nfeatures consist of the energy MOB features and their responses to electric\nfields. An interpretable and rotationally equivariant Gaussian process\nregression (GPR) with derivatives algorithm is introduced to learn the dipole\nmoment more efficiently. The proposed problem setup, feature design, and ML\nalgorithm are shown to provide highly-accurate models for both dipole moment\nand energies on water and fourteen small molecules. To demonstrate the ability\nof MOB-ML to function as generalized density-matrix functionals for molecular\ndipole moments and energies of organic molecules, we further apply the proposed\nMOB-ML approach to train and test the molecules from the QM9 dataset. The\napplication of local scalable GPR with Gaussian mixture model unsupervised\nclustering (GMM/GPR) scales up MOB-ML to a large-data regime while retaining\nthe prediction accuracy. In addition, compared with literature results, MOB-ML\nprovides the best test MAEs of 4.21 mDebye and 0.045 kcal/mol for dipole moment\nand energy models, respectively, when training on 110000 QM9 molecules. The\nexcellent transferability of the resulting QM9 models is also illustrated by\nthe accurate predictions for four different series of peptides.",
    "descriptor": "\nComments: 11 pages,6 figures\n",
    "authors": [
      "Jiace Sun",
      "Lixue Cheng",
      "Thomas F. Miller III"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15510"
  },
  {
    "id": "arXiv:2205.15543",
    "title": "AI-based automated Meibomian gland segmentation, classification and  reflection correction in infrared Meibography",
    "abstract": "Purpose: Develop a deep learning-based automated method to segment meibomian\nglands (MG) and eyelids, quantitatively analyze the MG area and MG ratio,\nestimate the meiboscore, and remove specular reflections from infrared images.\nMethods: A total of 1600 meibography images were captured in a clinical\nsetting. 1000 images were precisely annotated with multiple revisions by\ninvestigators and graded 6 times by meibomian gland dysfunction (MGD) experts.\nTwo deep learning (DL) models were trained separately to segment areas of the\nMG and eyelid. Those segmentation were used to estimate MG ratio and\nmeiboscores using a classification-based DL model. A generative adversarial\nnetwork was implemented to remove specular reflections from original images.\nResults: The mean ratio of MG calculated by investigator annotation and DL\nsegmentation was consistent 26.23% vs 25.12% in the upper eyelids and 32.34%\nvs. 32.29% in the lower eyelids, respectively. Our DL model achieved 73.01%\naccuracy for meiboscore classification on validation set and 59.17% accuracy\nwhen tested on images from independent center, compared to 53.44% validation\naccuracy by MGD experts. The DL-based approach successfully removes reflection\nfrom the original MG images without affecting meiboscore grading. Conclusions:\nDL with infrared meibography provides a fully automated, fast quantitative\nevaluation of MG morphology (MG Segmentation, MG area, MG ratio, and\nmeiboscore) which are sufficiently accurate for diagnosing dry eye disease.\nAlso, the DL removes specular reflection from images to be used by\nophthalmologists for distraction-free assessment.",
    "descriptor": "\nComments: 11 pages, 13 Figures, 5 Supplementary Figures\n",
    "authors": [
      "Ripon Kumar Saha",
      "A. M. Mahmud Chowdhury",
      "Kyung-Sun Na",
      "Gyu Deok Hwang",
      "Youngsub Eom",
      "Jaeyoung Kim",
      "Hae-Gon Jeon",
      "Ho Sik Hwang",
      "Euiheon Chung"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2205.15543"
  },
  {
    "id": "arXiv:2205.15548",
    "title": "Robust Projection based Anomaly Extraction (RPE) in Univariate  Time-Series",
    "abstract": "This paper presents a novel, closed-form, and data/computation efficient\nonline anomaly detection algorithm for time-series data. The proposed method,\ndubbed RPE, is a window-based method and in sharp contrast to the existing\nwindow-based methods, it is robust to the presence of anomalies in its window\nand it can distinguish the anomalies in time-stamp level. RPE leverages the\nlinear structure of the trajectory matrix of the time-series and employs a\nrobust projection step which makes the algorithm able to handle the presence of\nmultiple arbitrarily large anomalies in its window. A closed-form/non-iterative\nalgorithm for the robust projection step is provided and it is proved that it\ncan identify the corrupted time-stamps. RPE is a great candidate for the\napplications where a large training data is not available which is the common\nscenario in the area of time-series. An extensive set of numerical experiments\nshow that RPE can outperform the existing approaches with a notable margin.",
    "descriptor": "",
    "authors": [
      "Mostafa Rahmani",
      "Anoop Deoras",
      "Laurent Callot"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15548"
  },
  {
    "id": "arXiv:2205.15549",
    "title": "VC Theoretical Explanation of Double Descent",
    "abstract": "There has been growing interest in generalization performance of large\nmultilayer neural networks that can be trained to achieve zero training error,\nwhile generalizing well on test data. This regime is known as 'second descent'\nand it appears to contradict conventional view that optimal model complexity\nshould reflect optimal balance between underfitting and overfitting, aka the\nbias-variance trade-off. This paper presents VC-theoretical analysis of double\ndescent and shows that it can be fully explained by classical VC generalization\nbounds. We illustrate an application of analytic VC-bounds for modeling double\ndescent for classification problems, using empirical results for several\nlearning methods, such as SVM, Least Squares, and Multilayer Perceptron\nclassifiers. In addition, we discuss several possible reasons for\nmisinterpretation of VC-theoretical results in the machine learning community.",
    "descriptor": "",
    "authors": [
      "Eng Hock Lee",
      "Vladimir Cherkassky"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15549"
  },
  {
    "id": "arXiv:2205.15581",
    "title": "Comparing interpretation methods in mental state decoding analyses with  deep learning models",
    "abstract": "Deep learning (DL) methods find increasing application in mental state\ndecoding, where researchers seek to understand the mapping between mental\nstates (such as accepting or rejecting a gamble) and brain activity, by\nidentifying those brain regions (and networks) whose activity allows to\naccurately identify (i.e., decode) these states. Once DL models have been\ntrained to accurately decode a set of mental states, neuroimaging researchers\noften make use of interpretation methods from explainable artificial\nintelligence research to understand their learned mappings between mental\nstates and brain activity. Here, we compare the explanations of prominent\ninterpretation methods for the mental state decoding decisions of DL models\ntrained on three functional Magnetic Resonance Imaging (fMRI) datasets. We find\nthat interpretation methods that capture the model's decision process well, by\nproducing faithful explanations, generally produce explanations that are less\nin line with the results of standard analyses of the fMRI data, when compared\nto the explanations of interpretation methods with less explanation\nfaithfulness. Specifically, we find that interpretation methods that focus on\nhow sensitively a model's decoding decision changes with the values of the\ninput produce explanations that better match with the results of a standard\ngeneral linear model analysis of the fMRI data, while interpretation methods\nthat focus on identifying the specific contribution of an input feature's value\nto the decoding decision produce overall more faithful explanations that align\nless well with the results of standard analyses of the fMRI data.",
    "descriptor": "\nComments: 27 pages, 5 main figures\n",
    "authors": [
      "Armin W. Thomas",
      "Christopher R\u00e9",
      "Russell A. Poldrack"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15581"
  },
  {
    "id": "arXiv:2205.15587",
    "title": "The Born approximation in the three-dimensional Calder\u00f3n problem II:  Numerical reconstruction in the radial case",
    "abstract": "In this work we illustrate a number of properties of the Born approximation\nin the three-dimensional Calder\\'on inverse conductivity problem by numerical\nexperiments. The results are based on an explicit representation formula for\nthe Born approximation recently introduced by the authors. We focus on the\nparticular case of radial conductivities in the ball $B_R \\subset \\mathbb{R}^3\n$ of radius $R$, in which the linearization of the Calder\\'on problem is\nequivalent to a Hausdorff moment problem. We give numerical evidences that the\nBorn approximation is well defined for $L^{\\infty}$ conductivities, and we\npresent a novel numerical algorithm to reconstruct a radial conductivity from\nthe Born approximation under a suitable smallness assumption. We also show that\nthe Born approximation has depth-dependent uniqueness and approximation\ncapabilities depending on the distance (depth) to the boundary $\\partial B_R$.\nWe then investigate how increasing the radius $R$ affects the quality of the\nBorn approximation, and the existence of a scattering limit as $R\\to \\infty$.\nSimilar properties are also illustrated in the inverse boundary problem for the\nSchr\\\"odinger operator $-\\Delta +q$, and strong recovery of singularity results\nare observed in this case.",
    "descriptor": "\nComments: 31 pages, 15 figures\n",
    "authors": [
      "Juan A. Barcel\u00f3",
      "Carlos Castro",
      "Fabricio Maci\u00e0",
      "Crist\u00f3bal J. Mero\u00f1o"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.15587"
  },
  {
    "id": "arXiv:2205.15607",
    "title": "Generative Aging of Brain Images with Diffeomorphic Registration",
    "abstract": "Analyzing and predicting brain aging is essential for early prognosis and\naccurate diagnosis of cognitive diseases. The technique of neuroimaging, such\nas Magnetic Resonance Imaging (MRI), provides a noninvasive means of observing\nthe aging process within the brain. With longitudinal image data collection,\ndata-intensive Artificial Intelligence (AI) algorithms have been used to\nexamine brain aging. However, existing state-of-the-art algorithms tend to be\nrestricted to group-level predictions and suffer from unreal predictions. This\npaper proposes a methodology for generating longitudinal MRI scans that capture\nsubject-specific neurodegeneration and retain anatomical plausibility in aging.\nThe proposed methodology is developed within the framework of diffeomorphic\nregistration and relies on three key novel technological advances to generate\nsubject-level anatomically plausible predictions: i) a computationally\nefficient and individualized generative framework based on registration; ii) an\naging generative module based on biological linear aging progression; iii) a\nquality control module to fit registration for generation task. Our methodology\nwas evaluated on 2662 T1-weighted (T1-w) MRI scans from 796 participants from\nthree different cohorts. First, we applied 6 commonly used criteria to\ndemonstrate the aging simulation ability of the proposed methodology; Secondly,\nwe evaluated the quality of the synthetic images using quantitative\nmeasurements and qualitative assessment by a neuroradiologist. Overall, the\nexperimental results show that the proposed method can produce anatomically\nplausible predictions that can be used to enhance longitudinal datasets, in\nturn enabling data-hungry AI-driven healthcare tools.",
    "descriptor": "",
    "authors": [
      "Jingru Fu",
      "Antonios Tzortzakakis",
      "Jos\u00e9 Barroso",
      "Eric Westman",
      "Daniel Ferreira",
      "Rodrigo Moreno"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15607"
  },
  {
    "id": "arXiv:2205.15673",
    "title": "Dynamic interventions with limited knowledge in network games",
    "abstract": "This paper studies the problem of intervention design for steering the\nactions of noncooperative players in quadratic network games to the social\noptimum. The players choose their actions with the aim of maximizing their\nindividual payoff functions, while a central regulator uses interventions to\nmodify their marginal returns and maximize the social welfare function. This\nwork builds on the key observation that the solution to the steering problem\ndepends on the knowledge of the regulator on the players' parameters and the\nunderlying network. We, therefore, consider different scenarios based on\nlimited knowledge and propose suitable static, dynamic and adaptive\nintervention protocols. We formally prove convergence to the social optimum\nunder the proposed mechanisms. We demonstrate our theoretical findings on a\ncase study of Cournot competition with differentiated goods.",
    "descriptor": "",
    "authors": [
      "Mehran Shakarami",
      "Ashish Cherukuri",
      "Nima Monshizadeh"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.15673"
  },
  {
    "id": "arXiv:2205.15675",
    "title": "Contrastive Representation Learning for 3D Protein Structures",
    "abstract": "Learning from 3D protein structures has gained wide interest in protein\nmodeling and structural bioinformatics. Unfortunately, the number of available\nstructures is orders of magnitude lower than the training data sizes commonly\nused in computer vision and machine learning. Moreover, this number is reduced\neven further, when only annotated protein structures can be considered, making\nthe training of existing models difficult and prone to over-fitting. To address\nthis challenge, we introduce a new representation learning framework for 3D\nprotein structures. Our framework uses unsupervised contrastive learning to\nlearn meaningful representations of protein structures, making use of proteins\nfrom the Protein Data Bank. We show, how these representations can be used to\nsolve a large variety of tasks, such as protein function prediction, protein\nfold classification, structural similarity prediction, and protein-ligand\nbinding affinity prediction. Moreover, we show how fine-tuned networks,\npre-trained with our algorithm, lead to significantly improved task\nperformance, achieving new state-of-the-art results in many tasks.",
    "descriptor": "",
    "authors": [
      "Pedro Hermosilla",
      "Timo Ropinski"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15675"
  },
  {
    "id": "arXiv:2205.15680",
    "title": "Simulation-Based Inference with WALDO: Perfectly Calibrated Confidence  Regions Using Any Prediction or Posterior Estimation Algorithm",
    "abstract": "The vast majority of modern machine learning targets prediction problems,\nwith algorithms such as Deep Neural Networks revolutionizing the accuracy of\npoint predictions for high-dimensional complex data. Predictive approaches are\nnow used in many domain sciences to directly estimate internal parameters of\ninterest in theoretical simulator-based models. In parallel, common\nalternatives focus on estimating the full posterior using modern neural density\nestimators such as normalizing flows. However, an open problem in\nsimulation-based inference (SBI) is how to construct properly calibrated\nconfidence regions for internal parameters with nominal conditional coverage\nand high power. Many SBI methods are indeed known to produce overly confident\nposterior approximations, yielding misleading uncertainty estimates. Similarly,\nexisting approaches for uncertainty quantification in deep learning provide no\nguarantees on conditional coverage. In this work, we present WALDO, a novel\nmethod for constructing correctly calibrated confidence regions in SBI. WALDO\nreframes the well-known Wald test and uses Neyman inversion to convert point\npredictions and posteriors from any prediction or posterior estimation\nalgorithm to confidence sets with correct conditional coverage, even for finite\nsample sizes. As a concrete example, we demonstrate how a recently proposed\ndeep learning prediction approach for particle energies in high-energy physics\ncan be recalibrated using WALDO to produce confidence intervals with correct\ncoverage and high power.",
    "descriptor": "\nComments: 17 pages, 8 figures\n",
    "authors": [
      "Luca Masserano",
      "Tommaso Dorigo",
      "Rafael Izbicki",
      "Mikael Kuusela",
      "Ann B. Lee"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15680"
  },
  {
    "id": "arXiv:2205.15699",
    "title": "A novel approach to rating transition modelling via Machine Learning and  SDEs on Lie groups",
    "abstract": "In this paper, we introduce a novel methodology to model rating transitions\nwith a stochastic process. To introduce stochastic processes, whose values are\nvalid rating matrices, we noticed the geometric properties of stochastic\nmatrices and its link to matrix Lie groups. We give a gentle introduction to\nthis topic and demonstrate how It\\^o-SDEs in R will generate the desired model\nfor rating transitions. To calibrate the rating model to historical data, we\nuse a Deep-Neural-Network (DNN) called TimeGAN to learn the features of a time\nseries of historical rating matrices. Then, we use this DNN to generate\nsynthetic rating transition matrices. Afterwards, we fit the moments of the\ngenerated rating matrices and the rating process at specific time points, which\nresults in a good fit. After calibration, we discuss the quality of the\ncalibrated rating transition process by examining some properties that a time\nseries of rating matrices should satisfy, and we will see that this geometric\napproach works very well.",
    "descriptor": "",
    "authors": [
      "Kevin Kamm",
      "Michelle Muniz"
    ],
    "subjectives": [
      "Risk Management (q-fin.RM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15699"
  },
  {
    "id": "arXiv:2205.15720",
    "title": "Progressive Multi-scale Consistent Network for Multi-class Fundus Lesion  Segmentation",
    "abstract": "Effectively integrating multi-scale information is of considerable\nsignificance for the challenging multi-class segmentation of fundus lesions\nbecause different lesions vary significantly in scales and shapes. Several\nmethods have been proposed to successfully handle the multi-scale object\nsegmentation. However, two issues are not considered in previous studies. The\nfirst is the lack of interaction between adjacent feature levels, and this will\nlead to the deviation of high-level features from low-level features and the\nloss of detailed cues. The second is the conflict between the low-level and\nhigh-level features, this occurs because they learn different scales of\nfeatures, thereby confusing the model and decreasing the accuracy of the final\nprediction. In this paper, we propose a progressive multi-scale consistent\nnetwork (PMCNet) that integrates the proposed progressive feature fusion (PFF)\nblock and dynamic attention block (DAB) to address the aforementioned issues.\nSpecifically, PFF block progressively integrates multi-scale features from\nadjacent encoding layers, facilitating feature learning of each layer by\naggregating fine-grained details and high-level semantics. As features at\ndifferent scales should be consistent, DAB is designed to dynamically learn the\nattentive cues from the fused features at different scales, thus aiming to\nsmooth the essential conflicts existing in multi-scale features. The two\nproposed PFF and DAB blocks can be integrated with the off-the-shelf backbone\nnetworks to address the two issues of multi-scale and feature inconsistency in\nthe multi-class segmentation of fundus lesions, which will produce better\nfeature representation in the feature space. Experimental results on three\npublic datasets indicate that the proposed method is more effective than recent\nstate-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Along He",
      "Kai Wang",
      "Tao Li",
      "Wang Bo",
      "Hong Kang",
      "Huazhu Fu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15720"
  },
  {
    "id": "arXiv:2205.15747",
    "title": "Adversarial synthesis based data-augmentation for code-switched spoken  language identification",
    "abstract": "Spoken Language Identification (LID) is an important sub-task of Automatic\nSpeech Recognition(ASR) that is used to classify the language(s) in an audio\nsegment. Automatic LID plays an useful role in multilingual countries. In\nvarious countries, identifying a language becomes hard, due to the multilingual\nscenario where two or more than two languages are mixed together during\nconversation. Such phenomenon of speech is called as code-mixing or\ncode-switching. This nature is followed not only in India but also in many\nAsian countries. Such code-mixed data is hard to find, which further reduces\nthe capabilities of the spoken LID. Due to the lack of avalibility of this\ncode-mixed data, it becomes a minority class in LID task. Hence, this work\nprimarily addresses this problem using data augmentation as a solution on the\nminority code-switched class. This study focuses on Indic language code-mixed\nwith English. Spoken LID is performed on Hindi, code-mixed with English. This\nresearch proposes Generative Adversarial Network (GAN) based data augmentation\ntechnique performed using Mel spectrograms for audio data. GANs have already\nbeen proven to be accurate in representing the real data distribution in the\nimage domain. Proposed research exploits these capabilities of GANs in speech\ndomains such as speech classification, automatic speech recognition,etc. GANs\nare trained to generate Mel spectrograms of the minority code-mixed class which\nare then used to augment data for the classifier. Utilizing GANs give an\noverall improvement on Unweighted Average Recall by an amount of 3.5\\% as\ncompared to a Convolutional Recurrent Neural Network (CRNN) classifier used as\nthe baseline reference.",
    "descriptor": "\nComments: 9 pages, 8 figures\n",
    "authors": [
      "Parth Shastri",
      "Chirag Patil",
      "Poorval Wanere",
      "Dr. Shrinivas Mahajan",
      "Dr. Abhishek Bhatt",
      "Dr. Hardik Sailor"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15747"
  },
  {
    "id": "arXiv:2205.15772",
    "title": "The hybrid approach -- Convolutional Neural Networks and Expectation  Maximization Algorithm -- for Tomographic Reconstruction of Hyperspectral  Images",
    "abstract": "We present a simple but novel hybrid approach to hyperspectral data cube\nreconstruction from computed tomography imaging spectrometry (CTIS) images that\nsequentially combines neural networks and the iterative Expectation\nMaximization (EM) algorithm. We train and test the ability of the method to\nreconstruct data cubes of $100\\times100\\times25$ and $100\\times100\\times100$\nvoxels, corresponding to 25 and 100 spectral channels, from simulated CTIS\nimages generated by our CTIS simulator. The hybrid approach utilizes the\ninherent strength of the Convolutional Neural Network (CNN) with regard to\nnoise and its ability to yield consistent reconstructions and make use of the\nEM algorithm's ability to generalize to spectral images of any object without\ntraining. The hybrid approach achieves better performance than both the CNNs\nand EM alone for seen (included in CNN training) and unseen (excluded from CNN\ntraining) cubes for both the 25- and 100-channel cases. For the 25 spectral\nchannels, the improvements from CNN to the hybrid model (CNN + EM) in terms of\nthe mean-squared errors are between 14-26%. For 100 spectral channels, the\nimprovements between 19-40% are attained with the largest improvement of 40%\nfor the unseen data, to which the CNNs are not exposed during the training.",
    "descriptor": "\nComments: 29 pages, 13 figures and 2 tables. Supplemental material: 18 pages and 14 figures\n",
    "authors": [
      "Mads J. Ahleb\u00e6k",
      "Mads S. Peters",
      "Wei-Chih Huang",
      "Mads T. Frandsen",
      "Ren\u00e9 L. Eriksen",
      "Bjarke J\u00f8rgensen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15772"
  },
  {
    "id": "arXiv:2205.15784",
    "title": "Likelihood-Free Inference with Generative Neural Networks via Scoring  Rule Minimization",
    "abstract": "Bayesian Likelihood-Free Inference methods yield posterior approximations for\nsimulator models with intractable likelihood. Recently, many works trained\nneural networks to approximate either the intractable likelihood or the\nposterior directly. Most proposals use normalizing flows, namely neural\nnetworks parametrizing invertible maps used to transform samples from an\nunderlying base measure; the probability density of the transformed samples is\nthen accessible and the normalizing flow can be trained via maximum likelihood\non simulated parameter-observation pairs. A recent work [Ramesh et al., 2022]\napproximated instead the posterior with generative networks, which drop the\ninvertibility requirement and are thus a more flexible class of distributions\nscaling to high-dimensional and structured data. However, generative networks\nonly allow sampling from the parametrized distribution; for this reason, Ramesh\net al. [2022] follows the common solution of adversarial training, where the\ngenerative network plays a min-max game against a \"critic\" network. This\nprocedure is unstable and can lead to a learned distribution underestimating\nthe uncertainty - in extreme cases collapsing to a single point. Here, we\npropose to approximate the posterior with generative networks trained by\nScoring Rule minimization, an overlooked adversarial-free method enabling\nsmooth training and better uncertainty quantification. In simulation studies,\nthe Scoring Rule approach yields better performances with shorter training time\nwith respect to the adversarial framework.",
    "descriptor": "",
    "authors": [
      "Lorenzo Pacchiardi",
      "Ritabrata Dutta"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.15784"
  },
  {
    "id": "arXiv:2205.15809",
    "title": "Feature Learning in $L_{2}$-regularized DNNs: Attraction/Repulsion and  Sparsity",
    "abstract": "We study the loss surface of DNNs with $L_{2}$ regularization. We show that\nthe loss in terms of the parameters can be reformulated into a loss in terms of\nthe layerwise activations $Z_{\\ell}$ of the training set. This reformulation\nreveals the dynamics behind feature learning: each hidden representations\n$Z_{\\ell}$ are optimal w.r.t. to an attraction/repulsion problem and\ninterpolate between the input and output representations, keeping as little\ninformation from the input as necessary to construct the activation of the next\nlayer. For positively homogeneous non-linearities, the loss can be further\nreformulated in terms of the covariances of the hidden representations, which\ntakes the form of a partially convex optimization over a convex cone.\nThis second reformulation allows us to prove a sparsity result for\nhomogeneous DNNs: any local minimum of the $L_{2}$-regularized loss can be\nachieved with at most $N(N+1)$ neurons in each hidden layer (where $N$ is the\nsize of the training set). We show that this bound is tight by giving an\nexample of a local minimum which requires $N^{2}/4$ hidden neurons. But we also\nobserve numerically that in more traditional settings much less than $N^{2}$\nneurons are required to reach the minima.",
    "descriptor": "",
    "authors": [
      "Arthur Jacot",
      "Eugene Golikov",
      "Cl\u00e9ment Hongler",
      "Franck Gabriel"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2205.15809"
  },
  {
    "id": "arXiv:2205.15834",
    "title": "Attribution-based Explanations that Provide Recourse Cannot be Robust",
    "abstract": "Different users of machine learning methods require different explanations,\ndepending on their goals. To make machine learning accountable to society, one\nimportant goal is to get actionable options for recourse, which allow an\naffected user to change the decision $f(x)$ of a machine learning system by\nmaking limited changes to its input $x$. We formalize this by providing a\ngeneral definition of recourse sensitivity, which needs to be instantiated with\na utility function that describes which changes to the decisions are relevant\nto the user. This definition applies to local attribution methods, which\nattribute an importance weight to each input feature. It is often argued that\nsuch local attributions should be robust, in the sense that a small change in\nthe input $x$ that is being explained, should not cause a large change in the\nfeature weights. However, we prove formally that it is in general impossible\nfor any single attribution method to be both recourse sensitive and robust at\nthe same time. It follows that there must always exist counterexamples to at\nleast one of these properties. We provide such counterexamples for several\npopular attribution methods, including LIME, SHAP, Integrated Gradients and\nSmoothGrad. Our results also cover counterfactual explanations, which may be\nviewed as attributions that describe a perturbation of $x$. We further discuss\npossible ways to work around our impossibility result, for instance by allowing\nthe output to consist of sets with multiple attributions. Finally, we\nstrengthen our impossibility result for the restricted case where users are\nonly able to change a single attribute of x, by providing an exact\ncharacterization of the functions $f$ to which impossibility applies.",
    "descriptor": "\nComments: 19 pages, 4 figures\n",
    "authors": [
      "Hidde Fokkema",
      "Rianne de Heide",
      "Tim van Erven"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15834"
  },
  {
    "id": "arXiv:2205.15841",
    "title": "Multi-agent Multi-target Path Planning in Markov Decision Processes",
    "abstract": "Missions for teams of autonomous systems often require agents to visit\nmultiple targets in complex and dynamic operating conditions. We consider the\nproblem of visiting a set of targets in minimum time by a team of\nnon-communicating agents in a stochastic environment modeled as a Markov\ndecision process. We first consider the single-agent problem, and show that it\nis at least NP-complete by reducing it to a Hamiltonian path problem. Using\nBellman's optimality equation, we discuss an optimal algorithm that is\nexponential in the number of target states. Then, we tradeoff optimality for\ntime complexity by presenting a suboptimal algorithm that is polynomial at each\ntime step. We prove that the proposed algorithm generates optimal policies for\ncertain classes of Markov decision processes. We extend this algorithm to the\nmulti-agent case by proposing a heuristic partitioning algorithm of assigning\ntargets to agents. Our algorithm approximately minimizes the expected time to\nvisit the target states. We prove that the heuristic procedure generates\noptimal partitions for environments where the targets are naturally clustered.\nWe present the performance of our algorithms on random Markov decision\nprocesses, as well as a gridworld environment inspired by autonomous underwater\nvehicles operating in an ocean. We show that our algorithms are much faster\nthan the optimal procedure and more optimal than the currently available\nheuristic.",
    "descriptor": "",
    "authors": [
      "Farhad Nawaz",
      "Melkior Ornik"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.15841"
  },
  {
    "id": "arXiv:2205.15853",
    "title": "Predicting Day-Ahead Stock Returns using Search Engine Query Volumes: An  Application of Gradient Boosted Decision Trees to the S&P 100",
    "abstract": "The internet has changed the way we live, work and take decisions. As it is\nthe major modern resource for research, detailed data on internet usage\nexhibits vast amounts of behavioral information. This paper aims to answer the\nquestion whether this information can be facilitated to predict future returns\nof stocks on financial capital markets. In an empirical analysis it implements\ngradient boosted decision trees to learn relationships between abnormal returns\nof stocks within the S&P 100 index and lagged predictors derived from\nhistorical financial data, as well as search term query volumes on the internet\nsearch engine Google. Models predict the occurrence of day-ahead stock returns\nin excess of the index median. On a time frame from 2005 to 2017, all disparate\ndatasets exhibit valuable information. Evaluated models have average areas\nunder the receiver operating characteristic between 54.2% and 56.7%, clearly\nindicating a classification better than random guessing. Implementing a simple\nstatistical arbitrage strategy, models are used to create daily trading\nportfolios of ten stocks and result in annual performances of more than 57%\nbefore transaction costs. With ensembles of different data sets topping up the\nperformance ranking, the results further question the weak form and semi-strong\nform efficiency of modern financial capital markets. Even though transaction\ncosts are not included, the approach adds to the existing literature. It gives\nguidance on how to use and transform data on internet usage behavior for\nfinancial and economic modeling and forecasting.",
    "descriptor": "",
    "authors": [
      "Christopher Bockel-Rickermann"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15853"
  },
  {
    "id": "arXiv:2205.15855",
    "title": "Open-source Framework for Transonic Boundary Layer Natural Transition  Analysis over Complex Geometries in Nektar++",
    "abstract": "We introduce an open-source and unified framework for transition analysis for\nlaminar boundary layer natural transition at transonic conditions and over\ncomplex geometries, where surface irregularities may be present. Different\ncomputational tools are integrated in the framework, and therefore overcomes\nthe difficulties of two separate and usually quite disparate processes when\nusing $e^N$ method for transition analysis. To generate a baseflow with desired\npressure distribution, appropriate pressure compatible inflow boundary\ncondition needs to be developed and enforced. We first derive the system for 1D\nnumerical stability analysis for boundary conditions, and construct three types\nof pressure compatible inflow. We demonstrate that the entropy-pressure\ncompatible inflow is stable unlike other choices. Compared with the steady\nbaseflow computation, the unsteady simulation for the disturbance field is more\nchallenging for compressible flows because of complex wave reflections, which\ncan easily contaminate the results. We therefore introduce the two main sources\nof wave decontamination and corresponding methods to obtain clean signal. The\nworkflow within the framework is then verified by computing the disturbance\ndevelopment in 2D flat plate boundary layer flows at Mach $0.8$. The\n$N$-factors over a clean flat plate and a flat plate with a forward-facing step\nare generated, and agree well with the results from the reference. Following\nthe verified workflow, We then analyze the disturbance growth on a wing section\nof the CRM-NLF model. The N-factor on a 2D simulation is generated and studied.",
    "descriptor": "\nComments: 20 pages, 22 figures, presented at the 2022 AIAA Aviation Forum\n",
    "authors": [
      "Ganlin Lyu",
      "Chao Chen",
      "Xi Du",
      "Shahid Mughal",
      "Spencer J. Sherwin"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2205.15855"
  },
  {
    "id": "arXiv:2205.15898",
    "title": "Learning brain MRI quality control: a multi-factorial generalization  problem",
    "abstract": "Due to the growing number of MRI data, automated quality control (QC) has\nbecome essential, especially for larger scale analysis. Several attempts have\nbeen made in order to develop reliable and scalable QC pipelines. However, the\ngeneralization of these methods on new data independent of those used for\nlearning is a difficult problem because of the biases inherent in MRI data.\nThis work aimed at evaluating the performances of the MRIQC pipeline on various\nlarge-scale datasets (ABIDE, N = 1102 and CATI derived datasets, N = 9037) used\nfor both training and evaluation purposes. We focused our analysis on the MRIQC\npreprocessing steps and tested the pipeline with and without them. We further\nanalyzed the site-wise and study-wise predicted classification probability\ndistributions of the models without preprocessing trained on ABIDE and CATI\ndata. Our main results were that a model using features extracted from MRIQC\nwithout preprocessing yielded the best results when trained and evaluated on\nlarge multi-center datasets with a heterogeneous population (an improvement of\nthe ROC-AUC score on unseen data of 0.10 for the model trained on a subset of\nthe CATI dataset). We concluded that a model trained with data from a\nheterogeneous population, such as the CATI dataset, provides the best scores on\nunseen data. In spite of the performance improvement, the generalization\nabilities of the models remain questionable when looking at the\nsite-wise/study-wise probability predictions and the optimal classification\nthreshold derived from them.",
    "descriptor": "",
    "authors": [
      "Ghiles Reguig",
      "Marie Chupin",
      "Hugo Dary",
      "Eric Bardinet",
      "St\u00e9phane Leh\u00e9ricy",
      "Romain Valabregue"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2205.15898"
  },
  {
    "id": "arXiv:2205.15902",
    "title": "Variational inference via Wasserstein gradient flows",
    "abstract": "Along with Markov chain Monte Carlo (MCMC) methods, variational inference\n(VI) has emerged as a central computational approach to large-scale Bayesian\ninference. Rather than sampling from the true posterior $\\pi$, VI aims at\nproducing a simple but effective approximation $\\hat \\pi$ to $\\pi$ for which\nsummary statistics are easy to compute. However, unlike the well-studied MCMC\nmethodology, VI is still poorly understood and dominated by heuristics. In this\nwork, we propose principled methods for VI, in which $\\hat \\pi$ is taken to be\na Gaussian or a mixture of Gaussians, which rest upon the theory of gradient\nflows on the Bures-Wasserstein space of Gaussian measures. Akin to MCMC, it\ncomes with strong theoretical guarantees when $\\pi$ is log-concave.",
    "descriptor": "\nComments: 52 pages, 15 figures\n",
    "authors": [
      "Marc Lambert",
      "Sinho Chewi",
      "Francis Bach",
      "Silv\u00e8re Bonnabel",
      "Philippe Rigollet"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2205.15902"
  },
  {
    "id": "arXiv:2205.15903",
    "title": "Inferring 3D change detection from bitemporal optical images",
    "abstract": "Change detection is one of the most active research areas in Remote Sensing\n(RS). Most of the recently developed change detection methods are based on deep\nlearning (DL) algorithms. This kind of algorithms is generally focused on\ngenerating two-dimensional (2D) change maps, thus only identifying planimetric\nchanges in land use/land cover (LULC) and not considering nor returning any\ninformation on the corresponding elevation changes. Our work goes one step\nfurther, proposing two novel networks, able to solve simultaneously the 2D and\n3D CD tasks, and the 3DCD dataset, a novel and freely available dataset\nprecisely designed for this multitask. Particularly, the aim of this work is to\nlay the foundations for the development of DL algorithms able to automatically\ninfer an elevation (3D) CD map -- together with a standard 2D CD map --,\nstarting only from a pair of bitemporal optical images. The proposed\narchitectures, to perform the task described before, consist of a\ntransformer-based network, the MultiTask Bitemporal Images Transformer (MTBIT),\nand a deep convolutional network, the Siamese ResUNet (SUNet). Particularly,\nMTBIT is a transformer-based architecture, based on a semantic tokenizer. SUNet\ninstead combines, in a siamese encoder, skip connections and residual layers to\nlearn rich features, capable to solve efficiently the proposed task. These\nmodels are, thus, able to obtain 3D CD maps from two optical images taken at\ndifferent time instants, without the need to rely directly on elevation data\nduring the inference step. Encouraging results, obtained on the novel 3DCD\ndataset, are shown. The code and the 3DCD dataset are available at\n\\url{https://sites.google.com/uniroma1.it/3dchangedetection/home-page}.",
    "descriptor": "",
    "authors": [
      "Valerio Marsocci",
      "Virginia Coletta",
      "Roberta Ravanelli",
      "Simone Scardapane",
      "Mattia Crespi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15903"
  },
  {
    "id": "arXiv:2205.15941",
    "title": "Memory-efficient Segmentation of High-resolution Volumetric MicroCT  Images",
    "abstract": "In recent years, 3D convolutional neural networks have become the dominant\napproach for volumetric medical image segmentation. However, compared to their\n2D counterparts, 3D networks introduce substantially more training parameters\nand higher requirement for the GPU memory. This has become a major limiting\nfactor for designing and training 3D networks for high-resolution volumetric\nimages. In this work, we propose a novel memory-efficient network architecture\nfor 3D high-resolution image segmentation. The network incorporates both global\nand local features via a two-stage U-net-based cascaded framework and at the\nfirst stage, a memory-efficient U-net (meU-net) is developed. The features\nlearnt at the two stages are connected via post-concatenation, which further\nimproves the information flow. The proposed segmentation method is evaluated on\nan ultra high-resolution microCT dataset with typically 250 million voxels per\nvolume. Experiments show that it outperforms state-of-the-art 3D segmentation\nmethods in terms of both segmentation accuracy and memory efficiency.",
    "descriptor": "\nComments: The paper is accepted to MIDL 2022. The codes are available at this https URL\n",
    "authors": [
      "Yuan Wang",
      "Laura Blackie",
      "Irene Miguel-Aliaga",
      "Wenjia Bai"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15941"
  },
  {
    "id": "arXiv:2205.15942",
    "title": "Minimax Classification under Concept Drift with Multidimensional  Adaptation and Performance Guarantees",
    "abstract": "The statistical characteristics of instance-label pairs often change with\ntime in practical scenarios of supervised classification. Conventional learning\ntechniques adapt to such concept drift accounting for a scalar rate of change\nby means of a carefully chosen learning rate, forgetting factor, or window\nsize. However, the time changes in common scenarios are multidimensional, i.e.,\ndifferent statistical characteristics often change in a different manner. This\npaper presents adaptive minimax risk classifiers (AMRCs) that account for\nmultidimensional time changes by means of a multivariate and high-order\ntracking of the time-varying underlying distribution. In addition, differently\nfrom conventional techniques, AMRCs can provide computable tight performance\nguarantees. Experiments on multiple benchmark datasets show the classification\nimprovement of AMRCs compared to the state-of-the-art and the reliability of\nthe presented performance guarantees.",
    "descriptor": "",
    "authors": [
      "Ver\u00f3nica \u00c1lvarez",
      "Santiago Mazuelas",
      "Jose A. Lozano"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15942"
  },
  {
    "id": "arXiv:2205.15988",
    "title": "A deep learning approach to halo merger tree construction",
    "abstract": "A key ingredient for semi-analytic models (SAMs) of galaxy formation is the\nmass assembly history of haloes, encoded in a tree structure. The most commonly\nused method to construct halo merger histories is based on the outcomes of\nhigh-resolution, computationally intensive N-body simulations. We show that\nmachine learning (ML) techniques, in particular Generative Adversarial Networks\n(GANs), are a promising new tool to tackle this problem with a modest\ncomputational cost and retaining the best features of merger trees from\nsimulations. We train our GAN model with a limited sample of merger trees from\nthe EAGLE simulation suite, constructed using two halo finders-tree builder\nalgorithms: SUBFIND-D-TREES and ROCKSTAR-ConsistentTrees. Our GAN model\nsuccessfully learns to generate well-constructed merger tree structures with\nhigh temporal resolution, and to reproduce the statistical features of the\nsample of merger trees used for training, when considering up to three\nvariables in the training process. These inputs, whose representations are also\nlearned by our GAN model, are mass of the halo progenitors and the final\ndescendant, progenitor type (main halo or satellite) and distance of a\nprogenitor to that in the main branch. The inclusion of the latter two inputs\ngreatly improves the final learned representation of the halo mass growth\nhistory, especially for SUBFIND-like ML trees. When comparing equally sized\nsamples of ML merger trees with those of the EAGLE simulation, we find better\nagreement for SUBFIND-like ML trees. Finally, our GAN-based framework can be\nutilised to construct merger histories of low and intermediate mass haloes, the\nmost abundant in cosmological simulations.",
    "descriptor": "\nComments: 17 pages, 12 figures, 3 tables, 2 appendices\n",
    "authors": [
      "Sandra Robles",
      "Jonathan S. G\u00f3mez",
      "Ad\u00edn Ram\u00edrez Rivera",
      "Nelson D. Padilla",
      "Diego Dujovne"
    ],
    "subjectives": [
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15988"
  },
  {
    "id": "arXiv:2205.15993",
    "title": "Characterization of integral input-to-state stability for nonlinear  time-varying systems of infinite dimension",
    "abstract": "For large classes of infinite-dimensional time-varying control systems, the\nequivalence between integral input-to-state stability (iISS) and the\ncombination of global uniform asymptotic stability under zero input (0-GUAS)\nand uniformly bounded-energy input/bounded state (UBEBS) is established under a\nreasonable assumption of continuity of the trajectories with respect to the\ninput, at the zero input. By particularizing to specific instances of\ninfinite-dimensional systems, such as time-delay, or semilinear over Banach\nspaces, sufficient conditions are given in terms of the functions defining the\ndynamics. In addition, it is also shown that for semilinear systems whose\nnonlinear term satisfies an affine-in-the-state norm bound, it holds that iISS\nbecomes equivalent to just 0-GUAS, a fact known to hold for bilinear systems.\nAn additional important aspect is that the iISS notion considered is more\ngeneral than the standard one.",
    "descriptor": "\nComments: Submitted to SIAM J Control and Optimization\n",
    "authors": [
      "Jos\u00e9 L. Mancilla-Aguilar",
      "Jos\u00e9 E. Rojas-Ruiz",
      "Hernan Haimovich"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.15993"
  },
  {
    "id": "arXiv:1807.03144",
    "title": "Cut-off Theorems for the PV-model",
    "abstract": "Cut-off Theorems for the PV-model",
    "descriptor": "",
    "authors": [
      "Lisbeth Fajstrup"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/1807.03144"
  },
  {
    "id": "arXiv:1809.07051",
    "title": "Probabilistic completeness of RRT for geometric and kinodynamic planning  with forward propagation",
    "abstract": "Probabilistic completeness of RRT for geometric and kinodynamic planning  with forward propagation",
    "descriptor": "",
    "authors": [
      "Michal Kleinbort",
      "Kiril Solovey",
      "Zakary Littlefield",
      "Kostas E. Bekris",
      "Dan Halperin"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/1809.07051"
  },
  {
    "id": "arXiv:1812.11214",
    "title": "Kymatio: Scattering Transforms in Python",
    "abstract": "Kymatio: Scattering Transforms in Python",
    "descriptor": "",
    "authors": [
      "Mathieu Andreux",
      "Tom\u00e1s Angles",
      "Georgios Exarchakis",
      "Roberto Leonarduzzi",
      "Gaspar Rochette",
      "Louis Thiry",
      "John Zarka",
      "St\u00e9phane Mallat",
      "Joakim and\u00e9n",
      "Eugene Belilovsky",
      "Joan Bruna",
      "Vincent Lostanlen",
      "Muawiz Chaudhary",
      "Matthew J. Hirn",
      "Edouard Oyallon",
      "Sixin Zhang",
      "Carmine Cella",
      "Michael Eickenberg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1812.11214"
  },
  {
    "id": "arXiv:1910.05964",
    "title": "Cross-view kernel transfer",
    "abstract": "Cross-view kernel transfer",
    "descriptor": "",
    "authors": [
      "Riikka Huusari",
      "C\u00e9cile Capponi",
      "Paul Villoutreix",
      "Hachem Kadri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1910.05964"
  },
  {
    "id": "arXiv:1912.07579",
    "title": "Algorithms that \"Don't See Color\": Comparing Biases in Lookalike and  Special Ad Audiences",
    "abstract": "Algorithms that \"Don't See Color\": Comparing Biases in Lookalike and  Special Ad Audiences",
    "descriptor": "",
    "authors": [
      "Piotr Sapiezynski",
      "Avijit Ghosh",
      "Levi Kaplan",
      "Aaron Rieke",
      "Alan Mislove"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/1912.07579"
  },
  {
    "id": "arXiv:2003.01227",
    "title": "Fast Predictive Uncertainty for Classification with Bayesian Deep  Networks",
    "abstract": "Comments: Updated version. Accepted for publication at UAI2022",
    "descriptor": "\nComments: Updated version. Accepted for publication at UAI2022\n",
    "authors": [
      "Marius Hobbhahn",
      "Agustinus Kristiadi",
      "Philipp Hennig"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2003.01227"
  },
  {
    "id": "arXiv:2004.11515",
    "title": "Nonconvex regularization for sparse neural networks",
    "abstract": "Nonconvex regularization for sparse neural networks",
    "descriptor": "",
    "authors": [
      "Konstantin Pieper",
      "Armenak Petrosyan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2004.11515"
  },
  {
    "id": "arXiv:2005.14109",
    "title": "Local convergence of the FEM for the integral fractional Laplacian",
    "abstract": "Local convergence of the FEM for the integral fractional Laplacian",
    "descriptor": "",
    "authors": [
      "Markus Faustmann",
      "Michael Karkulik",
      "Jens Markus Melenk"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2005.14109"
  },
  {
    "id": "arXiv:2006.08505",
    "title": "Diversity Policy Gradient for Sample Efficient Quality-Diversity  Optimization",
    "abstract": "Comments: Add several baselines (Policy Gradient assisted MAP Elites, DIAYN, AGAC) Change writing to take the point of view of the evo community Change style, writing, explanation, figures",
    "descriptor": "\nComments: Add several baselines (Policy Gradient assisted MAP Elites, DIAYN, AGAC) Change writing to take the point of view of the evo community Change style, writing, explanation, figures\n",
    "authors": [
      "Thomas Pierrot",
      "Valentin Mac\u00e9",
      "F\u00e9lix Chalumeau",
      "Arthur Flajolet",
      "Geoffrey Cideron",
      "Karim Beguir",
      "Antoine Cully",
      "Olivier Sigaud",
      "Nicolas Perrin-Gilbert"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2006.08505"
  },
  {
    "id": "arXiv:2006.14171",
    "title": "A Closer Look at Invalid Action Masking in Policy Gradient Algorithms",
    "abstract": "Comments: Accepted into the proceedings of International FLAIRS Conference Proceedings, Vol. 35 (2022)",
    "descriptor": "\nComments: Accepted into the proceedings of International FLAIRS Conference Proceedings, Vol. 35 (2022)\n",
    "authors": [
      "Shengyi Huang",
      "Santiago Onta\u00f1\u00f3n"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.14171"
  },
  {
    "id": "arXiv:2006.15032",
    "title": "Numerical analysis of a structure-preserving space-discretization for an  anisotropic and heterogeneous boundary controlled N-dimensional wave equation  as port-Hamiltonian system",
    "abstract": "Comments: 36 pages, 12 figure, submitted",
    "descriptor": "\nComments: 36 pages, 12 figure, submitted\n",
    "authors": [
      "Ghislain Haine",
      "Denis Matignon",
      "Anass Serhani"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2006.15032"
  },
  {
    "id": "arXiv:2008.07284",
    "title": "Forward and inverse reinforcement learning sharing network weights and  hyperparameters",
    "abstract": "Comments: Accepted for publication in the Neural Networks",
    "descriptor": "\nComments: Accepted for publication in the Neural Networks\n",
    "authors": [
      "Eiji Uchibe",
      "Kenji Doya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2008.07284"
  },
  {
    "id": "arXiv:2008.13537",
    "title": "Neural Topic Model via Optimal Transport",
    "abstract": "Comments: Published in ICLR 2021, link: this https URL, code: this https URL",
    "descriptor": "\nComments: Published in ICLR 2021, link: this https URL, code: this https URL\n",
    "authors": [
      "He Zhao",
      "Dinh Phung",
      "Viet Huynh",
      "Trung Le",
      "Wray Buntine"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2008.13537"
  },
  {
    "id": "arXiv:2009.09538",
    "title": "Regret Bounds and Reinforcement Learning Exploration of EXP-based  Algorithms",
    "abstract": "Comments: 34 pages, 8 figures",
    "descriptor": "\nComments: 34 pages, 8 figures\n",
    "authors": [
      "Mengfan Xu",
      "Diego Klabjan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.09538"
  },
  {
    "id": "arXiv:2010.02849",
    "title": "CoRe: Color Regression for Multicolor Fashion Garments",
    "abstract": "Comments: 6 pages,3 figures,1 table",
    "descriptor": "\nComments: 6 pages,3 figures,1 table\n",
    "authors": [
      "Alexandre Rame",
      "Arthur Douillard",
      "Charles Ollion"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.02849"
  },
  {
    "id": "arXiv:2010.05210",
    "title": "Generalized Few-shot Semantic Segmentation",
    "abstract": "Comments: Accepted to CVPR 2022",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Zhuotao Tian",
      "Xin Lai",
      "Li Jiang",
      "Shu Liu",
      "Michelle Shu",
      "Hengshuang Zhao",
      "Jiaya Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2010.05210"
  },
  {
    "id": "arXiv:2010.07902",
    "title": "Entropic proofs of Singleton bounds for quantum error-correcting codes",
    "abstract": "Comments: 10 pages, 5 figures. Theorem 7 and Corollaries 8 and 9 added. Accepted version",
    "descriptor": "\nComments: 10 pages, 5 figures. Theorem 7 and Corollaries 8 and 9 added. Accepted version\n",
    "authors": [
      "Markus Grassl",
      "Felix Huber",
      "Andreas Winter"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2010.07902"
  },
  {
    "id": "arXiv:2011.00096",
    "title": "Independence in Infinite Probabilistic Databases",
    "abstract": "Independence in Infinite Probabilistic Databases",
    "descriptor": "",
    "authors": [
      "Martin Grohe",
      "Peter Lindner"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2011.00096"
  },
  {
    "id": "arXiv:2011.05181",
    "title": "Speed-Robust Scheduling -- Sand, Bricks, and Rocks",
    "abstract": "Speed-Robust Scheduling -- Sand, Bricks, and Rocks",
    "descriptor": "",
    "authors": [
      "Franziska Eberle",
      "Ruben Hoeksma",
      "Nicole Megow",
      "Lukas N\u00f6lke",
      "Kevin Schewior",
      "Bertrand Simon"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2011.05181"
  },
  {
    "id": "arXiv:2012.11261",
    "title": "Learning-Based Predictive Control via Real-Time Aggregate Flexibility",
    "abstract": "Comments: 13 pages, 5 figures, extension of arXiv:2006.13814",
    "descriptor": "\nComments: 13 pages, 5 figures, extension of arXiv:2006.13814\n",
    "authors": [
      "Tongxin Li",
      "Bo Sun",
      "Yue Chen",
      "Zixin Ye",
      "Steven H. Low",
      "Adam Wierman"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2012.11261"
  },
  {
    "id": "arXiv:2101.01356",
    "title": "Fixed-MAML for Few Shot Classification in Multilingual Speech Emotion  Recognition",
    "abstract": "Comments: Code at this https URL",
    "descriptor": "\nComments: Code at this https URL\n",
    "authors": [
      "Anugunj Naman",
      "Chetan Sinha",
      "Liliana Mancini"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2101.01356"
  },
  {
    "id": "arXiv:2101.11116",
    "title": "Exact and Approximate Heterogeneous Bayesian Decentralized Data Fusion",
    "abstract": "Comments: 16 pages, 8 figures, 2 tables, re-submitted to IEEE Transactions on Robotics (T-RO)",
    "descriptor": "\nComments: 16 pages, 8 figures, 2 tables, re-submitted to IEEE Transactions on Robotics (T-RO)\n",
    "authors": [
      "Ofer Dagan",
      "Nisar R. Ahmed"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2101.11116"
  },
  {
    "id": "arXiv:2102.06973",
    "title": "Efficient Deviation Types and Learning for Hindsight Rationality in  Extensive-Form Games: Corrections",
    "abstract": "Comments: Corrected technical report with corrections highlighted and annotated. 45 pages and 6 figures",
    "descriptor": "\nComments: Corrected technical report with corrections highlighted and annotated. 45 pages and 6 figures\n",
    "authors": [
      "Dustin Morrill",
      "Ryan D'Orazio",
      "Marc Lanctot",
      "James R. Wright",
      "Michael Bowling",
      "Amy Greenwald"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.06973"
  },
  {
    "id": "arXiv:2102.12981",
    "title": "The Black-Box Simplex Architecture for Runtime Assurance of Autonomous  CPS",
    "abstract": "The Black-Box Simplex Architecture for Runtime Assurance of Autonomous  CPS",
    "descriptor": "",
    "authors": [
      "Usama Mehmood",
      "Sanaz Sheikhi",
      "Stanley Bak",
      "Scott A. Smolka",
      "Scott D. Stoller"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2102.12981"
  },
  {
    "id": "arXiv:2103.09184",
    "title": "Formation Control for UAVs Using a Flux Guided Approach",
    "abstract": "Comments: 37 pages, 9 figures, 3 table",
    "descriptor": "\nComments: 37 pages, 9 figures, 3 table\n",
    "authors": [
      "John Hartley",
      "Hubert P. H. Shum",
      "Edmond S. L. Ho",
      "He Wang",
      "Subramanian Ramamoorthy"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.09184"
  },
  {
    "id": "arXiv:2103.09630",
    "title": "Optimal periodic resource allocation in reactive dynamical systems:  Application to microalgal production",
    "abstract": "Comments: International Journal of Robust and Nonlinear Control, Wiley, 2022",
    "descriptor": "\nComments: International Journal of Robust and Nonlinear Control, Wiley, 2022\n",
    "authors": [
      "Olivier Bernard",
      "Liu-Di Lu",
      "Julien Salomon"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Combinatorics (math.CO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2103.09630"
  },
  {
    "id": "arXiv:2104.09335",
    "title": "Investigating Outdoor Recognition Performance of Infrared Beacons for  Infrastructure-based Localization",
    "abstract": "Comments: Accepted at IEEE Intelligent Vehicle 2022",
    "descriptor": "\nComments: Accepted at IEEE Intelligent Vehicle 2022\n",
    "authors": [
      "Alexandru Kampmann",
      "Michael Lamberti",
      "Nikola Petrovic",
      "Stefan Kowalewski",
      "Bassam Alrifaee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2104.09335"
  },
  {
    "id": "arXiv:2104.10997",
    "title": "Economic MPC of Markov Decision Processes: Dissipativity in Undiscounted  Infinite-Horizon Optimal Control",
    "abstract": "Economic MPC of Markov Decision Processes: Dissipativity in Undiscounted  Infinite-Horizon Optimal Control",
    "descriptor": "",
    "authors": [
      "S\u00e9bastien Gros",
      "Mario Zanon"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2104.10997"
  },
  {
    "id": "arXiv:2105.00763",
    "title": "A rigged model of the breast for preoperative surgical planning",
    "abstract": "Comments: 20 pages, 8 figures, submitted to Journal of Biomechanics",
    "descriptor": "\nComments: 20 pages, 8 figures, submitted to Journal of Biomechanics\n",
    "authors": [
      "Arnaud Mazier",
      "Sophie Ribes",
      "Benjamin Gilles",
      "St\u00e9phane P.A Bordas"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2105.00763"
  },
  {
    "id": "arXiv:2105.05307",
    "title": "Distribution of the Scaled Condition Number of Single-spiked Complex  Wishart Matrices",
    "abstract": "Distribution of the Scaled Condition Number of Single-spiked Complex  Wishart Matrices",
    "descriptor": "",
    "authors": [
      "Pasan Dissanayake",
      "Prathapasinghe Dharmawansa",
      "Yang Chen"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2105.05307"
  },
  {
    "id": "arXiv:2105.07737",
    "title": "Perfectly-matched-layer truncation is exponentially accurate at high  frequency",
    "abstract": "Comments: 41 pages, 6 figures",
    "descriptor": "\nComments: 41 pages, 6 figures\n",
    "authors": [
      "Jeffrey Galkowski",
      "David Lafontaine",
      "Euan A. Spence"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)",
      "Spectral Theory (math.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.07737"
  },
  {
    "id": "arXiv:2106.00797",
    "title": "QLSD: Quantised Langevin stochastic dynamics for Bayesian federated  learning",
    "abstract": "QLSD: Quantised Langevin stochastic dynamics for Bayesian federated  learning",
    "descriptor": "",
    "authors": [
      "Maxime Vono",
      "Vincent Plassier",
      "Alain Durmus",
      "Aymeric Dieuleveut",
      "Eric Moulines"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation (stat.CO)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.00797"
  },
  {
    "id": "arXiv:2106.04018",
    "title": "Intrinsic Dimension Estimation Using Wasserstein Distances",
    "abstract": "Intrinsic Dimension Estimation Using Wasserstein Distances",
    "descriptor": "",
    "authors": [
      "Adam Block",
      "Zeyu Jia",
      "Yury Polyanskiy",
      "Alexander Rakhlin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.04018"
  },
  {
    "id": "arXiv:2106.04569",
    "title": "Simulated Adversarial Testing of Face Recognition Models",
    "abstract": "Comments: Published at IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2022",
    "descriptor": "\nComments: Published at IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2022\n",
    "authors": [
      "Nataniel Ruiz",
      "Adam Kortylewski",
      "Weichao Qiu",
      "Cihang Xie",
      "Sarah Adel Bargal",
      "Alan Yuille",
      "Stan Sclaroff"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.04569"
  },
  {
    "id": "arXiv:2106.06168",
    "title": "Generate, Annotate, and Learn: NLP with Synthetic Text",
    "abstract": "Comments: accepted to TACL2022",
    "descriptor": "\nComments: accepted to TACL2022\n",
    "authors": [
      "Xuanli He",
      "Islam Nassar",
      "Jamie Kiros",
      "Gholamreza Haffari",
      "Mohammad Norouzi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06168"
  },
  {
    "id": "arXiv:2106.07057",
    "title": "FairCanary: Rapid Continuous Explainable Fairness",
    "abstract": "Comments: Accepted as a full paper at the 2022 AAAI/ACM Conference on AI, Ethics, and Society",
    "descriptor": "\nComments: Accepted as a full paper at the 2022 AAAI/ACM Conference on AI, Ethics, and Society\n",
    "authors": [
      "Avijit Ghosh",
      "Aalok Shanbhag",
      "Christo Wilson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.07057"
  },
  {
    "id": "arXiv:2106.07162",
    "title": "Goal-Aware Neural SAT Solver",
    "abstract": "Goal-Aware Neural SAT Solver",
    "descriptor": "",
    "authors": [
      "Emils Ozolins",
      "Karlis Freivalds",
      "Andis Draguns",
      "Eliza Gaile",
      "Ronalds Zakovskis",
      "Sergejs Kozlovics"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.07162"
  },
  {
    "id": "arXiv:2106.07356",
    "title": "Mixture of Virtual-Kernel Experts for Multi-Objective User Profile  Modeling",
    "abstract": "Comments: 11 pages, accepted by SIGKDD'2022",
    "descriptor": "\nComments: 11 pages, accepted by SIGKDD'2022\n",
    "authors": [
      "Zhenhui Xu",
      "Meng Zhao",
      "Liqun Liu",
      "Lei Xiao",
      "Xiaopeng Zhang",
      "Bifeng Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07356"
  },
  {
    "id": "arXiv:2106.14831",
    "title": "Hybrid zonotopes: a new set representation for reachability analysis of  mixed logical dynamical systems",
    "abstract": "Comments: 16 pages, 5 figures. Revised manuscript including 5 pages of supplementary material appended, theoretical results unchanged",
    "descriptor": "\nComments: 16 pages, 5 figures. Revised manuscript including 5 pages of supplementary material appended, theoretical results unchanged\n",
    "authors": [
      "Trevor J. Bird",
      "Herschel C. Pangborn",
      "Neera Jain",
      "Justin P. Koeln"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.14831"
  },
  {
    "id": "arXiv:2106.15020",
    "title": "On the potential of sequential and non-sequential regression models for  Sentinel-1-based biomass prediction in Tanzanian miombo forests",
    "abstract": "On the potential of sequential and non-sequential regression models for  Sentinel-1-based biomass prediction in Tanzanian miombo forests",
    "descriptor": "",
    "authors": [
      "Sara Bj\u00f6rk",
      "Stian Normann Anfinsen",
      "Erik N\u00e6sset",
      "Terje Gobakken",
      "Eliakimu Zahabu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.15020"
  },
  {
    "id": "arXiv:2107.07511",
    "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free  Uncertainty Quantification",
    "abstract": "Comments: Blog and tutorial video this http URL",
    "descriptor": "\nComments: Blog and tutorial video this http URL\n",
    "authors": [
      "Anastasios N. Angelopoulos",
      "Stephen Bates"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.07511"
  },
  {
    "id": "arXiv:2107.08558",
    "title": "A Topological Perspective on Causal Inference",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Duligur Ibeling",
      "Thomas Icard"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2107.08558"
  },
  {
    "id": "arXiv:2108.03509",
    "title": "Compositional Generalization in Multilingual Semantic Parsing over  Wikidata",
    "abstract": "Comments: Accepted to TACL; Authors' final version, pre-MIT Press publication; Previous title: Multilingual Compositional Wikidata Questions",
    "descriptor": "\nComments: Accepted to TACL; Authors' final version, pre-MIT Press publication; Previous title: Multilingual Compositional Wikidata Questions\n",
    "authors": [
      "Ruixiang Cui",
      "Rahul Aralikatte",
      "Heather Lent",
      "Daniel Hershcovich"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.03509"
  },
  {
    "id": "arXiv:2108.04330",
    "title": "Creating synthetic night-time visible-light meteorological satellite  images using the GAN method",
    "abstract": "Creating synthetic night-time visible-light meteorological satellite  images using the GAN method",
    "descriptor": "",
    "authors": [
      "Wencong Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.04330"
  },
  {
    "id": "arXiv:2108.06779",
    "title": "Non-convex Generalized Nash Games for Energy Efficient Power Allocation  and Beamforming in mmWave Networks",
    "abstract": "Comments: to appear in IEEE Transactions on Signal Processing",
    "descriptor": "\nComments: to appear in IEEE Transactions on Signal Processing\n",
    "authors": [
      "Wenbo Wang",
      "Amir Leshem"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2108.06779"
  },
  {
    "id": "arXiv:2108.07041",
    "title": "Implicitly Regularized RL with Implicit Q-Values",
    "abstract": "Comments: AISTATS 2022",
    "descriptor": "\nComments: AISTATS 2022\n",
    "authors": [
      "Nino Vieillard",
      "Marcin Andrychowicz",
      "Anton Raichuk",
      "Olivier Pietquin",
      "Matthieu Geist"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.07041"
  },
  {
    "id": "arXiv:2108.08018",
    "title": "Timed Automata Robustness Analysis via Model Checking",
    "abstract": "Timed Automata Robustness Analysis via Model Checking",
    "descriptor": "",
    "authors": [
      "Jaroslav Bend\u00edk",
      "Ahmet Sencan",
      "Ebru Aydin Gol",
      "Ivana \u010cern\u00e1"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2108.08018"
  },
  {
    "id": "arXiv:2108.13137",
    "title": "Multiscale modeling of inelastic materials with Thermodynamics-based  Artificial Neural Networks (TANN)",
    "abstract": "Multiscale modeling of inelastic materials with Thermodynamics-based  Artificial Neural Networks (TANN)",
    "descriptor": "",
    "authors": [
      "Filippo Masi",
      "Ioannis Stefanou"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2108.13137"
  },
  {
    "id": "arXiv:2109.00162",
    "title": "Eyes Tell All: Irregular Pupil Shapes Reveal GAN-generated Faces",
    "abstract": "Comments: Version 3, 7 pages",
    "descriptor": "\nComments: Version 3, 7 pages\n",
    "authors": [
      "Hui Guo",
      "Shu Hu",
      "Xin Wang",
      "Ming-Ching Chang",
      "Siwei Lyu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.00162"
  },
  {
    "id": "arXiv:2109.01656",
    "title": "Thompson Sampling for Bandits with Clustered Arms",
    "abstract": "Comments: Paper accepted to IJCAI-2021. The supplementary material is not part of the IJCAI-21 Proceedings",
    "descriptor": "\nComments: Paper accepted to IJCAI-2021. The supplementary material is not part of the IJCAI-21 Proceedings\n",
    "authors": [
      "Emil Carlsson",
      "Devdatt Dubhashi",
      "Fredrik D. Johansson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.01656"
  },
  {
    "id": "arXiv:2109.06013",
    "title": "Learning to Ground Visual Objects for Visual Dialog",
    "abstract": "Comments: Findings of the Association for Computational Linguistics: EMNLP 2021",
    "descriptor": "\nComments: Findings of the Association for Computational Linguistics: EMNLP 2021\n",
    "authors": [
      "Feilong Chen",
      "Xiuyi Chen",
      "Can Xu",
      "Daxin Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06013"
  },
  {
    "id": "arXiv:2109.06126",
    "title": "Neural Network Guided Evolutionary Fuzzing for Finding Traffic  Violations of Autonomous Vehicles",
    "abstract": "Neural Network Guided Evolutionary Fuzzing for Finding Traffic  Violations of Autonomous Vehicles",
    "descriptor": "",
    "authors": [
      "Ziyuan Zhong",
      "Gail Kaiser",
      "Baishakhi Ray"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.06126"
  },
  {
    "id": "arXiv:2109.06162",
    "title": "SPARQLing Database Queries from Intermediate Question Decompositions",
    "abstract": "SPARQLing Database Queries from Intermediate Question Decompositions",
    "descriptor": "",
    "authors": [
      "Irina Saparina",
      "Anton Osokin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06162"
  },
  {
    "id": "arXiv:2109.07752",
    "title": "Deep Visual Navigation under Partial Observability",
    "abstract": "Comments: ICRA 2022. Demo and code available at: this https URL",
    "descriptor": "\nComments: ICRA 2022. Demo and code available at: this https URL\n",
    "authors": [
      "Bo Ai",
      "Wei Gao",
      "Vinay",
      "David Hsu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07752"
  },
  {
    "id": "arXiv:2109.08475",
    "title": "GoG: Relation-aware Graph-over-Graph Network for Visual Dialog",
    "abstract": "Comments: ACL Findings 2021. arXiv admin note: text overlap with arXiv:2109.06013",
    "descriptor": "\nComments: ACL Findings 2021. arXiv admin note: text overlap with arXiv:2109.06013\n",
    "authors": [
      "Feilong Chen",
      "Xiuyi Chen",
      "Fandong Meng",
      "Peng Li",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.08475"
  },
  {
    "id": "arXiv:2109.10504",
    "title": "KD-VLP: Improving End-to-End Vision-and-Language Pretraining with Object  Knowledge Distillation",
    "abstract": "Comments: Accepted by NAACL2022-Findings",
    "descriptor": "\nComments: Accepted by NAACL2022-Findings\n",
    "authors": [
      "Yongfei Liu",
      "Chenfei Wu",
      "Shao-yen Tseng",
      "Vasudev Lal",
      "Xuming He",
      "Nan Duan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.10504"
  },
  {
    "id": "arXiv:2109.12313",
    "title": "Safety-Critical Control and Planning for Obstacle Avoidance between  Polytopes with Control Barrier Functions",
    "abstract": "Comments: Accepted to IEEE International Conference on Robotics and Automation (ICRA 2022)",
    "descriptor": "\nComments: Accepted to IEEE International Conference on Robotics and Automation (ICRA 2022)\n",
    "authors": [
      "Akshay Thirugnanam",
      "Jun Zeng",
      "Koushil Sreenath"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2109.12313"
  },
  {
    "id": "arXiv:2109.14272",
    "title": "Computing Necessary Conditions for Near-Optimality in Capacity Expansion  Planning Problems",
    "abstract": "Comments: 8 pages, 10 figures, 1 table, accepted at PSCC2022",
    "descriptor": "\nComments: 8 pages, 10 figures, 1 table, accepted at PSCC2022\n",
    "authors": [
      "Antoine Dubois",
      "Damien Ernst"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.14272"
  },
  {
    "id": "arXiv:2109.15266",
    "title": "Modeling Interactions of Autonomous Vehicles and Pedestrians with Deep  Multi-Agent Reinforcement Learning for Collision Avoidance",
    "abstract": "Comments: IEEE Intelligent Vehicles Symposium 2022",
    "descriptor": "\nComments: IEEE Intelligent Vehicles Symposium 2022\n",
    "authors": [
      "Raphael Trumpp",
      "Harald Bayerlein",
      "David Gesbert"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2109.15266"
  },
  {
    "id": "arXiv:2110.00514",
    "title": "Virtual elements on agglomerated finite elements to increase the  critical time step in elastodynamic simulations",
    "abstract": "Comments: 32 pages, 30 figures",
    "descriptor": "\nComments: 32 pages, 30 figures\n",
    "authors": [
      "N. Sukumar",
      "Michael R. Tupek"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.00514"
  },
  {
    "id": "arXiv:2110.03744",
    "title": "Voice Reenactment with F0 and timing constraints and adversarial  learning of conversions",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2107.12346",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2107.12346\n",
    "authors": [
      "Frederik Bous",
      "Laurent Benaroya",
      "Nicolas Obin",
      "Axel Roebel"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.03744"
  },
  {
    "id": "arXiv:2110.04180",
    "title": "IHOP: Improved Statistical Query Recovery against Searchable Symmetric  Encryption through Quadratic Optimization",
    "abstract": "Comments: 18 pages",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Simon Oya",
      "Florian Kerschbaum"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.04180"
  },
  {
    "id": "arXiv:2110.05687",
    "title": "RWN: Robust Watermarking Network for Image Cropping Localization",
    "abstract": "RWN: Robust Watermarking Network for Image Cropping Localization",
    "descriptor": "",
    "authors": [
      "Qichao Ying",
      "Xiaoxiao Hu",
      "Xiangyu Zhang",
      "Zhenxing Qian",
      "Xinpeng Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05687"
  },
  {
    "id": "arXiv:2110.08175",
    "title": "MixQG: Neural Question Generation with Mixed Answer Types",
    "abstract": "Comments: camera-ready version",
    "descriptor": "\nComments: camera-ready version\n",
    "authors": [
      "Lidiya Murakhovs'ka",
      "Chien-Sheng Wu",
      "Philippe Laban",
      "Tong Niu",
      "Wenhao Liu",
      "Caiming Xiong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08175"
  },
  {
    "id": "arXiv:2110.08942",
    "title": "Joint SCSP-LROM: A novel approach to detect Cerebrovascular Anomalies  from EEG signals",
    "abstract": "Comments: Major changes have to be performed and reflected on it. Till then, I would like it to be withdrawn from here",
    "descriptor": "\nComments: Major changes have to be performed and reflected on it. Till then, I would like it to be withdrawn from here\n",
    "authors": [
      "Debojyoti Seth"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.08942"
  },
  {
    "id": "arXiv:2110.14422",
    "title": "Zero-shot Voice Conversion via Self-supervised Prosody Representation  Learning",
    "abstract": "Comments: Published in: 2022 International Joint Conference on Neural Networks (IJCNN)",
    "descriptor": "\nComments: Published in: 2022 International Joint Conference on Neural Networks (IJCNN)\n",
    "authors": [
      "Shijun Wang",
      "Dimche Kostadinov",
      "Damian Borth"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.14422"
  },
  {
    "id": "arXiv:2111.00242",
    "title": "Speech Denoising Using Only Single Noisy Audio Samples",
    "abstract": "Comments: 5 pages, 2 figures",
    "descriptor": "\nComments: 5 pages, 2 figures\n",
    "authors": [
      "Jiasong Wu",
      "Qingchun Li",
      "Youyong Kong",
      "Guanyu Yang",
      "Lotfi Senhadji",
      "Huazhong Shu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2111.00242"
  },
  {
    "id": "arXiv:2111.00770",
    "title": "Dense Prediction with Attentive Feature Aggregation",
    "abstract": "Comments: 21 pages, 15 figures",
    "descriptor": "\nComments: 21 pages, 15 figures\n",
    "authors": [
      "Yung-Hsu Yang",
      "Thomas E. Huang",
      "Min Sun",
      "Samuel Rota Bul\u00f2",
      "Peter Kontschieder",
      "Fisher Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00770"
  },
  {
    "id": "arXiv:2111.06787",
    "title": "BitextEdit: Automatic Bitext Editing for Improved Low-Resource Machine  Translation",
    "abstract": "BitextEdit: Automatic Bitext Editing for Improved Low-Resource Machine  Translation",
    "descriptor": "",
    "authors": [
      "Eleftheria Briakou",
      "Sida I. Wang",
      "Luke Zettlemoyer",
      "Marjan Ghazvininejad"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.06787"
  },
  {
    "id": "arXiv:2111.09410",
    "title": "EdgeML: Towards Network-Accelerated Federated Learning over Wireless  Edge",
    "abstract": "Comments: 14 pages, submitted to Journal of Computer Networks (ComNet) 2022",
    "descriptor": "\nComments: 14 pages, submitted to Journal of Computer Networks (ComNet) 2022\n",
    "authors": [
      "Pinyarash Pinyoanuntapong",
      "Prabhu Janakaraj",
      "Ravikumar Balakrishnan",
      "Minwoo Lee",
      "Chen Chen",
      "Pu Wang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.09410"
  },
  {
    "id": "arXiv:2111.09484",
    "title": "Information-theoretic formulation of dynamical systems: causality,  modeling, and control",
    "abstract": "Information-theoretic formulation of dynamical systems: causality,  modeling, and control",
    "descriptor": "",
    "authors": [
      "Adri\u00e1n Lozano-Dur\u00e1n",
      "Gonzalo Arranz"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Information Theory (cs.IT)",
      "Chaotic Dynamics (nlin.CD)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2111.09484"
  },
  {
    "id": "arXiv:2111.11402",
    "title": "The $n$-queens completion problem",
    "abstract": "Comments: to appear in Research in the Mathematical Sciences",
    "descriptor": "\nComments: to appear in Research in the Mathematical Sciences\n",
    "authors": [
      "Stefan Glock",
      "David Munh\u00e1 Correia",
      "Benny Sudakov"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2111.11402"
  },
  {
    "id": "arXiv:2111.14696",
    "title": "The Computational Drug Repositioning without Negative Sampling",
    "abstract": "Comments: 12 pages,10 figures",
    "descriptor": "\nComments: 12 pages,10 figures\n",
    "authors": [
      "Xinxing Yang",
      "Genke Yang",
      "Jian Chu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2111.14696"
  },
  {
    "id": "arXiv:2111.14726",
    "title": "Exploring Representational Alignment with Human Perception Using  Identically Represented Inputs",
    "abstract": "Comments: Under review",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Vedant Nanda",
      "Ayan Majumdar",
      "Camila Kolling",
      "John P. Dickerson",
      "Krishna P. Gummadi",
      "Bradley C. Love",
      "Adrian Weller"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.14726"
  },
  {
    "id": "arXiv:2112.01593",
    "title": "Types and Terms Translated: Unrestricted Resources in Encoding Functions  as Processes (Extended Version)",
    "abstract": "Comments: 24 pages, plus appendices. Extended version of a paper in the Post-proceedings of TYPES 2021. arXiv admin note: text overlap with arXiv:2104.14759",
    "descriptor": "\nComments: 24 pages, plus appendices. Extended version of a paper in the Post-proceedings of TYPES 2021. arXiv admin note: text overlap with arXiv:2104.14759\n",
    "authors": [
      "Joseph W. N. Paulus",
      "Daniele Nantes-Sobrinho",
      "Jorge A. P\u00e9rez"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2112.01593"
  },
  {
    "id": "arXiv:2112.07673",
    "title": "Machine learning a manifold",
    "abstract": "Comments: 7 pages, 2 figures. Version published in PRD. (SC+RH) + DC^2 propose mape + epsilon^2",
    "descriptor": "\nComments: 7 pages, 2 figures. Version published in PRD. (SC+RH) + DC^2 propose mape + epsilon^2\n",
    "authors": [
      "Sean Craven",
      "Djuna Croon",
      "Daniel Cutting",
      "Rachel Houtz"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07673"
  },
  {
    "id": "arXiv:2112.08693",
    "title": "Helmholtz equation and non-singular boundary elements applied to  multi-disciplinary physical problems",
    "abstract": "Helmholtz equation and non-singular boundary elements applied to  multi-disciplinary physical problems",
    "descriptor": "",
    "authors": [
      "Evert Klaseboer",
      "Qiang Sun"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Classical Physics (physics.class-ph)",
      "Computational Physics (physics.comp-ph)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2112.08693"
  },
  {
    "id": "arXiv:2112.12327",
    "title": "Making sense of electrical vehicle discussions using sentiment analysis  on closely related news and user comments",
    "abstract": "Making sense of electrical vehicle discussions using sentiment analysis  on closely related news and user comments",
    "descriptor": "",
    "authors": [
      "Xuan Jiang",
      "Josh Everts"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.12327"
  },
  {
    "id": "arXiv:2112.14418",
    "title": "Deep adaptive basis Galerkin method for high-dimensional evolution  equations with oscillatory solutions",
    "abstract": "Deep adaptive basis Galerkin method for high-dimensional evolution  equations with oscillatory solutions",
    "descriptor": "",
    "authors": [
      "Yiqi Gu",
      "Micheal K. Ng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.14418"
  },
  {
    "id": "arXiv:2112.15594",
    "title": "A Neural Network Solves, Explains, and Generates University Math  Problems by Program Synthesis and Few-Shot Learning at Human Level",
    "abstract": "Comments: 181 pages, 8 figures, 280 tables",
    "descriptor": "\nComments: 181 pages, 8 figures, 280 tables\n",
    "authors": [
      "Iddo Drori",
      "Sarah Zhang",
      "Reece Shuttleworth",
      "Leonard Tang",
      "Albert Lu",
      "Elizabeth Ke",
      "Kevin Liu",
      "Linda Chen",
      "Sunny Tran",
      "Newman Cheng",
      "Roman Wang",
      "Nikhil Singh",
      "Taylor L. Patti",
      "Jayson Lynch",
      "Avi Shporer",
      "Nakul Verma",
      "Eugene Wu",
      "Gilbert Strang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.15594"
  },
  {
    "id": "arXiv:2201.04288",
    "title": "Multiview Transformers for Video Recognition",
    "abstract": "Comments: CVPR 2022; arXiv v4: update results on Epic-Kitchens-100",
    "descriptor": "\nComments: CVPR 2022; arXiv v4: update results on Epic-Kitchens-100\n",
    "authors": [
      "Shen Yan",
      "Xuehan Xiong",
      "Anurag Arnab",
      "Zhichao Lu",
      "Mi Zhang",
      "Chen Sun",
      "Cordelia Schmid"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.04288"
  },
  {
    "id": "arXiv:2201.08164",
    "title": "From Anecdotal Evidence to Quantitative Evaluation Methods: A Systematic  Review on Evaluating Explainable AI",
    "abstract": "Comments: Link to website added: this https URL",
    "descriptor": "\nComments: Link to website added: this https URL\n",
    "authors": [
      "Meike Nauta",
      "Jan Trienes",
      "Shreyasi Pathak",
      "Elisa Nguyen",
      "Michelle Peters",
      "Yasmin Schmitt",
      "J\u00f6rg Schl\u00f6tterer",
      "Maurice van Keulen",
      "Christin Seifert"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.08164"
  },
  {
    "id": "arXiv:2201.08976",
    "title": "Sub-1.5 Time-Optimal Multi-Robot Path Planning on Grids in Polynomial  Time",
    "abstract": "Sub-1.5 Time-Optimal Multi-Robot Path Planning on Grids in Polynomial  Time",
    "descriptor": "",
    "authors": [
      "Teng Guo",
      "Jingjin Yu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2201.08976"
  },
  {
    "id": "arXiv:2201.09948",
    "title": "ReLSO: A Transformer-based Model for Latent Space Optimization and  Generation of Proteins",
    "abstract": "ReLSO: A Transformer-based Model for Latent Space Optimization and  Generation of Proteins",
    "descriptor": "",
    "authors": [
      "Egbert Castro",
      "Abhinav Godavarthi",
      "Julian Rubinfien",
      "Kevin B. Givechian",
      "Dhananjay Bhaskar",
      "Smita Krishnaswamy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.09948"
  },
  {
    "id": "arXiv:2201.10662",
    "title": "Semantics for two-dimensional type theory",
    "abstract": "Semantics for two-dimensional type theory",
    "descriptor": "",
    "authors": [
      "Benedikt Ahrens",
      "Paige Randall North",
      "Niels van der Weide"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2201.10662"
  },
  {
    "id": "arXiv:2201.11188",
    "title": "Crystal structure prediction with machine learning-based element  substitution",
    "abstract": "Comments: The full version of this paper is available at this https URL (Accepted 3 May 2022). Supplementary Information (pdf file) and Supplementary Data (CIF files) can be found online from the above URL",
    "descriptor": "\nComments: The full version of this paper is available at this https URL (Accepted 3 May 2022). Supplementary Information (pdf file) and Supplementary Data (CIF files) can be found online from the above URL\n",
    "authors": [
      "Minoru Kusaba",
      "Chang Liu",
      "Ryo Yoshida"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11188"
  },
  {
    "id": "arXiv:2201.11775",
    "title": "The Effect of Diversity in Meta-Learning",
    "abstract": "The Effect of Diversity in Meta-Learning",
    "descriptor": "",
    "authors": [
      "Ramnath Kumar",
      "Tristan Deleu",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11775"
  },
  {
    "id": "arXiv:2201.11783",
    "title": "Rethinking Learning Dynamics in RL using Adversarial Networks",
    "abstract": "Rethinking Learning Dynamics in RL using Adversarial Networks",
    "descriptor": "",
    "authors": [
      "Ramnath Kumar",
      "Tristan Deleu",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11783"
  },
  {
    "id": "arXiv:2201.11944",
    "title": "DICP: Doppler Iterative Closest Point Algorithm",
    "abstract": "Comments: Accepted at Robotics: Science and Systems (RSS) 2022",
    "descriptor": "\nComments: Accepted at Robotics: Science and Systems (RSS) 2022\n",
    "authors": [
      "Bruno Hexsel",
      "Heethesh Vhavle",
      "Yi Chen"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.11944"
  },
  {
    "id": "arXiv:2201.12769",
    "title": "MVP-Net: Multiple View Pointwise Semantic Segmentation of Large-Scale  Point Clouds",
    "abstract": "MVP-Net: Multiple View Pointwise Semantic Segmentation of Large-Scale  Point Clouds",
    "descriptor": "",
    "authors": [
      "Chuanyu Luo",
      "Xiaohan Li",
      "Nuo Cheng",
      "Han Li",
      "Shengguang Lei",
      "Pu Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.12769"
  },
  {
    "id": "arXiv:2202.01258",
    "title": "Accelerated Quality-Diversity for Robotics through Massive Parallelism",
    "abstract": "Accelerated Quality-Diversity for Robotics through Massive Parallelism",
    "descriptor": "",
    "authors": [
      "Bryan Lim",
      "Maxime Allard",
      "Luca Grillotti",
      "Antoine Cully"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.01258"
  },
  {
    "id": "arXiv:2202.01666",
    "title": "Proportional Fairness in Federated Learning",
    "abstract": "Comments: 30 pages",
    "descriptor": "\nComments: 30 pages\n",
    "authors": [
      "Guojun Zhang",
      "Saber Malekmohammadi",
      "Xi Chen",
      "Yaoliang Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.01666"
  },
  {
    "id": "arXiv:2202.02179",
    "title": "DelTact: A Vision-based Tactile Sensor Using Dense Color Pattern",
    "abstract": "Comments: 8 pages contents, 1 page references, 8 figures, 2 tables",
    "descriptor": "\nComments: 8 pages contents, 1 page references, 8 figures, 2 tables\n",
    "authors": [
      "Guanlan Zhang",
      "Yipai Du",
      "Hongyu Yu",
      "Michael Yu Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.02179"
  },
  {
    "id": "arXiv:2202.03057",
    "title": "Multi-Objective Quality Diversity Optimization",
    "abstract": "Multi-Objective Quality Diversity Optimization",
    "descriptor": "",
    "authors": [
      "Thomas Pierrot",
      "Guillaume Richard",
      "Karim Beguir",
      "Antoine Cully"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03057"
  },
  {
    "id": "arXiv:2202.03814",
    "title": "Optimal Transport of Classifiers to Fairness",
    "abstract": "Optimal Transport of Classifiers to Fairness",
    "descriptor": "",
    "authors": [
      "Maarten Buyl",
      "Tijl De Bie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.03814"
  },
  {
    "id": "arXiv:2202.04690",
    "title": "Smoothed Online Learning is as Easy as Statistical Learning",
    "abstract": "Smoothed Online Learning is as Easy as Statistical Learning",
    "descriptor": "",
    "authors": [
      "Adam Block",
      "Yuval Dagan",
      "Noah Golowich",
      "Alexander Rakhlin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04690"
  },
  {
    "id": "arXiv:2202.06083",
    "title": "Escaping Saddle Points with Bias-Variance Reduced Local Perturbed SGD  for Communication Efficient Nonconvex Distributed Learning",
    "abstract": "Comments: 46 pages",
    "descriptor": "\nComments: 46 pages\n",
    "authors": [
      "Tomoya Murata",
      "Taiji Suzuki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.06083"
  },
  {
    "id": "arXiv:2202.06255",
    "title": "Strategy Synthesis for Zero-sum Neuro-symbolic Concurrent Stochastic  Games",
    "abstract": "Comments: 30 pages, 4 figures",
    "descriptor": "\nComments: 30 pages, 4 figures\n",
    "authors": [
      "Rui Yan",
      "Gabriel Santos",
      "Gethin Norman",
      "David Parker",
      "Marta Kwiatkowska"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.06255"
  },
  {
    "id": "arXiv:2202.07318",
    "title": "An algorithmic solution to the Blotto game using multi-marginal  couplings",
    "abstract": "An algorithmic solution to the Blotto game using multi-marginal  couplings",
    "descriptor": "",
    "authors": [
      "Vianney Perchet",
      "Philippe Rigollet",
      "Thibaut Le Gouic"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07318"
  },
  {
    "id": "arXiv:2202.08682",
    "title": "A General Deep Learning framework for Neuron Instance Segmentation based  on Efficient UNet and Morphological Post-processing",
    "abstract": "A General Deep Learning framework for Neuron Instance Segmentation based  on Efficient UNet and Morphological Post-processing",
    "descriptor": "",
    "authors": [
      "Huaqian Wu",
      "Nicolas Souedet",
      "Caroline Jan",
      "C\u00e9dric Clouchoux",
      "Thierry Delzescaux"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08682"
  },
  {
    "id": "arXiv:2202.08808",
    "title": "Fast Dynamic Updates and Dynamic SpGEMM on MPI-Distributed Graphs",
    "abstract": "Comments: various updates",
    "descriptor": "\nComments: various updates\n",
    "authors": [
      "Alexander van der Grinten",
      "Geert Custers",
      "Duy Le Thanh",
      "Henning Meyerhenke"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.08808"
  },
  {
    "id": "arXiv:2202.09597",
    "title": "STAR-RIS-NOMA Networks: An Error Performance Perspective",
    "abstract": "Comments: Analyses are generalized to the multiple users scenario. Accepted in IEEE Communications Letters",
    "descriptor": "\nComments: Analyses are generalized to the multiple users scenario. Accepted in IEEE Communications Letters\n",
    "authors": [
      "Mahmoud Aldababsa",
      "Aymen Khaleel",
      "Ertugrul Basar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.09597"
  },
  {
    "id": "arXiv:2202.09685",
    "title": "Scalable Fine-Grained Parallel Cycle Enumeration Algorithms",
    "abstract": "Comments: To be published in Proceedings of the 34th ACM Symposium on Parallelism in Algorithms and Architectures (SPAA '22). The source codes of all the algorithms evaluated in our experiments are available here this https URL",
    "descriptor": "\nComments: To be published in Proceedings of the 34th ACM Symposium on Parallelism in Algorithms and Architectures (SPAA '22). The source codes of all the algorithms evaluated in our experiments are available here this https URL\n",
    "authors": [
      "Jovan Blanu\u0161a",
      "Paolo Ienne",
      "Kubilay Atasu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.09685"
  },
  {
    "id": "arXiv:2202.10994",
    "title": "An accelerated proximal gradient method for multiobjective optimization",
    "abstract": "An accelerated proximal gradient method for multiobjective optimization",
    "descriptor": "",
    "authors": [
      "Hiroki Tanabe",
      "Ellen H. Fukuda",
      "Nobuo Yamashita"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.10994"
  },
  {
    "id": "arXiv:2202.12184",
    "title": "Consistent data fusion with Parker",
    "abstract": "Consistent data fusion with Parker",
    "descriptor": "",
    "authors": [
      "Antoon Bronselaer",
      "Maribel Acosta"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2202.12184"
  },
  {
    "id": "arXiv:2202.12855",
    "title": "Atomic cross-chain exchanges of shared assets",
    "abstract": "Atomic cross-chain exchanges of shared assets",
    "descriptor": "",
    "authors": [
      "Krishnasuri Narayanam",
      "Venkatraman Ramakrishna",
      "Dhinakaran Vinayagamurthy",
      "Sandeep Nishad"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.12855"
  },
  {
    "id": "arXiv:2203.01008",
    "title": "UAV-Aided Decentralized Learning over Mesh Networks",
    "abstract": "Comments: Accepted to the 30th European Signal Processing Conference, EUSIPCO 2022",
    "descriptor": "\nComments: Accepted to the 30th European Signal Processing Conference, EUSIPCO 2022\n",
    "authors": [
      "Matteo Zecchin",
      "David Gesbert",
      "Marios Kountouris"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.01008"
  },
  {
    "id": "arXiv:2203.01272",
    "title": "Implicit Definitions with Differential Equations for KeYmaera X (System  Description)",
    "abstract": "Comments: Long version of paper at IJCAR 2022 (11th International Joint Conference on Automated Reasoning, August 8-10, 2022, Haifa, Israel)",
    "descriptor": "\nComments: Long version of paper at IJCAR 2022 (11th International Joint Conference on Automated Reasoning, August 8-10, 2022, Haifa, Israel)\n",
    "authors": [
      "James Gallicchio",
      "Yong Kiam Tan",
      "Stefan Mitsch",
      "Andr\u00e9 Platzer"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2203.01272"
  },
  {
    "id": "arXiv:2203.01360",
    "title": "Neural Galerkin Scheme with Active Learning for High-Dimensional  Evolution Equations",
    "abstract": "Neural Galerkin Scheme with Active Learning for High-Dimensional  Evolution Equations",
    "descriptor": "",
    "authors": [
      "Joan Bruna",
      "Benjamin Peherstorfer",
      "Eric Vanden-Eijnden"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.01360"
  },
  {
    "id": "arXiv:2203.02549",
    "title": "Structured Pruning is All You Need for Pruning CNNs at Initialization",
    "abstract": "Structured Pruning is All You Need for Pruning CNNs at Initialization",
    "descriptor": "",
    "authors": [
      "Yaohui Cai",
      "Weizhe Hua",
      "Hongzheng Chen",
      "G. Edward Suh",
      "Christopher De Sa",
      "Zhiru Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.02549"
  },
  {
    "id": "arXiv:2203.02762",
    "title": "DrawingInStyles: Portrait Image Generation and Editing with Spatially  Conditioned StyleGAN",
    "abstract": "Comments: 15 pages, 14 figures",
    "descriptor": "\nComments: 15 pages, 14 figures\n",
    "authors": [
      "Wanchao Su",
      "Hui Ye",
      "Shu-Yu Chen",
      "Lin Gao",
      "Hongbo Fu"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.02762"
  },
  {
    "id": "arXiv:2203.04044",
    "title": "Single-trajectory map equation",
    "abstract": "Comments: 17 pages, 13 figures",
    "descriptor": "\nComments: 17 pages, 13 figures\n",
    "authors": [
      "Tatsuro Kawamoto"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2203.04044"
  },
  {
    "id": "arXiv:2203.04123",
    "title": "On the complexity of invariant polynomials under the action of finite  reflection groups",
    "abstract": "On the complexity of invariant polynomials under the action of finite  reflection groups",
    "descriptor": "",
    "authors": [
      "Thi Xuan Vu"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2203.04123"
  },
  {
    "id": "arXiv:2203.04904",
    "title": "Model-Agnostic Multitask Fine-tuning for Few-shot Vision-Language  Transfer Learning",
    "abstract": "Comments: 7 pages, 6 figures, under review",
    "descriptor": "\nComments: 7 pages, 6 figures, under review\n",
    "authors": [
      "Zhenhailong Wang",
      "Hang Yu",
      "Manling Li",
      "Han Zhao",
      "Heng Ji"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04904"
  },
  {
    "id": "arXiv:2203.11703",
    "title": "Switching transformations for decentralized control of opinion patterns  in signed networks: application to dynamic task allocation",
    "abstract": "Switching transformations for decentralized control of opinion patterns  in signed networks: application to dynamic task allocation",
    "descriptor": "",
    "authors": [
      "Anastasia Bizyaeva",
      "Giovanna Amorim",
      "Maria Santos",
      "Alessio Franci",
      "Naomi Ehrich Leonard"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2203.11703"
  },
  {
    "id": "arXiv:2203.17118",
    "title": "Doubly-Robust Estimation for Correcting Position-Bias in Click Feedback  for Unbiased Learning to Rank",
    "abstract": "Doubly-Robust Estimation for Correcting Position-Bias in Click Feedback  for Unbiased Learning to Rank",
    "descriptor": "",
    "authors": [
      "Harrie Oosterhuis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2203.17118"
  },
  {
    "id": "arXiv:2204.02078",
    "title": "Semi-supervised Semantic Segmentation with Error Localization Network",
    "abstract": "Semi-supervised Semantic Segmentation with Error Localization Network",
    "descriptor": "",
    "authors": [
      "Donghyeon Kwon",
      "Suha Kwak"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02078"
  },
  {
    "id": "arXiv:2204.02610",
    "title": "Efficient Test-Time Model Adaptation without Forgetting",
    "abstract": "Comments: 17 pages, ICML 2022, conference",
    "descriptor": "\nComments: 17 pages, ICML 2022, conference\n",
    "authors": [
      "Shuaicheng Niu",
      "Jiaxiang Wu",
      "Yifan Zhang",
      "Yaofo Chen",
      "Shijian Zheng",
      "Peilin Zhao",
      "Mingkui Tan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.02610"
  },
  {
    "id": "arXiv:2204.02661",
    "title": "CAIPI in Practice: Towards Explainable Interactive Medical Image  Classification",
    "abstract": "Comments: Manuscript accepted at IFIP AIAI 2022, correct typo in Discussion",
    "descriptor": "\nComments: Manuscript accepted at IFIP AIAI 2022, correct typo in Discussion\n",
    "authors": [
      "Emanuel Slany",
      "Yannik Ott",
      "Stephan Scheele",
      "Jan Paulus",
      "Ute Schmid"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2204.02661"
  },
  {
    "id": "arXiv:2204.02693",
    "title": "Exploration with Global Consistency Using Real-Time Re-integration and  Active Loop Closure",
    "abstract": "Exploration with Global Consistency Using Real-Time Re-integration and  Active Loop Closure",
    "descriptor": "",
    "authors": [
      "Yichen Zhang",
      "Boyu Zhou",
      "Luqi Wang",
      "Shaojie Shen"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.02693"
  },
  {
    "id": "arXiv:2204.04913",
    "title": "Permutation-Invariant Relational Network for Multi-person 3D Pose  Estimation",
    "abstract": "Permutation-Invariant Relational Network for Multi-person 3D Pose  Estimation",
    "descriptor": "",
    "authors": [
      "Nicolas Ugrinovic",
      "Adria Ruiz",
      "Antonio Agudo",
      "Alberto Sanfeliu",
      "Francesc Moreno-Noguer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04913"
  },
  {
    "id": "arXiv:2204.07649",
    "title": "MultiEarth 2022 -- Multimodal Learning for Earth and Environment  Workshop and Challenge",
    "abstract": "MultiEarth 2022 -- Multimodal Learning for Earth and Environment  Workshop and Challenge",
    "descriptor": "",
    "authors": [
      "Miriam Cha",
      "Kuan Wei Huang",
      "Morgan Schmidt",
      "Gregory Angelides",
      "Mark Hamilton",
      "Sam Goldberg",
      "Armando Cabrera",
      "Phillip Isola",
      "Taylor Perron",
      "Bill Freeman",
      "Yen-Chen Lin",
      "Brandon Swenson",
      "Jean Piou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07649"
  },
  {
    "id": "arXiv:2204.07879",
    "title": "Polynomial-time Sparse Deconvolution",
    "abstract": "Polynomial-time Sparse Deconvolution",
    "descriptor": "",
    "authors": [
      "Hadi Daneshmand",
      "Francis Bach"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.07879"
  },
  {
    "id": "arXiv:2204.09457",
    "title": "On the relative asymptotic expressivity of inference frameworks",
    "abstract": "On the relative asymptotic expressivity of inference frameworks",
    "descriptor": "",
    "authors": [
      "Vera Koponen",
      "Felix Weitk\u00e4mper"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2204.09457"
  },
  {
    "id": "arXiv:2204.09521",
    "title": "A Data-Driven Method for Automated Data Superposition with Applications  in Soft Matter Science",
    "abstract": "Comments: 19 pages, 7 figures",
    "descriptor": "\nComments: 19 pages, 7 figures\n",
    "authors": [
      "Kyle R. Lennon",
      "Gareth H. McKinley",
      "James W. Swan"
    ],
    "subjectives": [
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Soft Condensed Matter (cond-mat.soft)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2204.09521"
  },
  {
    "id": "arXiv:2204.09804",
    "title": "Weighted Bayesian Gaussian Mixture Model for Roadside LiDAR Object  Detection",
    "abstract": "Weighted Bayesian Gaussian Mixture Model for Roadside LiDAR Object  Detection",
    "descriptor": "",
    "authors": [
      "Tianya Zhang",
      "Peter J. Jin",
      "Yi Ge"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.09804"
  },
  {
    "id": "arXiv:2204.10805",
    "title": "Revise and Resubmit: An Intertextual Model of Text-based Collaboration  in Peer Review",
    "abstract": "Revise and Resubmit: An Intertextual Model of Text-based Collaboration  in Peer Review",
    "descriptor": "",
    "authors": [
      "Ilia Kuznetsov",
      "Jan Buchmann",
      "Max Eichler",
      "Iryna Gurevych"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.10805"
  },
  {
    "id": "arXiv:2204.10952",
    "title": "A note on the $f$-divergences between multivariate location-scale  families with either prescribed scale matrices or location parameters",
    "abstract": "Comments: 17 pages, 1 table, 1 figure",
    "descriptor": "\nComments: 17 pages, 1 table, 1 figure\n",
    "authors": [
      "Frank Nielsen",
      "Kazuki Okamura"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.10952"
  },
  {
    "id": "arXiv:2204.12831",
    "title": "The Revisiting Problem in Simultaneous Localization and Mapping: A  Survey on Visual Loop Closure Detection",
    "abstract": "Comments: 25 pages, 15 figures",
    "descriptor": "\nComments: 25 pages, 15 figures\n",
    "authors": [
      "Konstantinos A. Tsintotas",
      "Loukas Bampis",
      "Antonios Gasteratos"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.12831"
  },
  {
    "id": "arXiv:2204.13911",
    "title": "Control-Theoretic Modeling of Multi-Species Water Quality Dynamics in  Drinking Water Networks: Survey, Methods, and Test Cases",
    "abstract": "Control-Theoretic Modeling of Multi-Species Water Quality Dynamics in  Drinking Water Networks: Survey, Methods, and Test Cases",
    "descriptor": "",
    "authors": [
      "Salma M. Elsherif",
      "Shen Wang",
      "Ahmad F. Taha",
      "Lina Sela",
      "Marcio H. Giacomoni",
      "Ahmed Abokifa"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2204.13911"
  },
  {
    "id": "arXiv:2204.14118",
    "title": "On the Optimization of Margin Distribution",
    "abstract": "On the Optimization of Margin Distribution",
    "descriptor": "",
    "authors": [
      "Meng-Zhang Qian",
      "Zheng Ai",
      "Teng Zhang",
      "Wei Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.14118"
  },
  {
    "id": "arXiv:2205.02655",
    "title": "Language Models Can See: Plugging Visual Controls in Text Generation",
    "abstract": "Comments: 21 pages, 5 figures, 5 tables; (v2 adds some experimental details)",
    "descriptor": "\nComments: 21 pages, 5 figures, 5 tables; (v2 adds some experimental details)\n",
    "authors": [
      "Yixuan Su",
      "Tian Lan",
      "Yahui Liu",
      "Fangyu Liu",
      "Dani Yogatama",
      "Yan Wang",
      "Lingpeng Kong",
      "Nigel Collier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.02655"
  },
  {
    "id": "arXiv:2205.04064",
    "title": "Augmentations: An Insight into their Effectiveness on Convolution Neural  Networks",
    "abstract": "Comments: Accepted at ICACDS-2022",
    "descriptor": "\nComments: Accepted at ICACDS-2022\n",
    "authors": [
      "Sabeesh Ethiraj",
      "Bharath Kumar Bolla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.04064"
  },
  {
    "id": "arXiv:2205.04330",
    "title": "Protecting Data from all Parties: Combining FHE and DP in Federated  Learning",
    "abstract": "Comments: 21 pages, 2 figures, 2 tables",
    "descriptor": "\nComments: 21 pages, 2 figures, 2 tables\n",
    "authors": [
      "Arnaud Grivet S\u00e9bert",
      "Renaud Sirdey",
      "Oana Stan",
      "C\u00e9dric Gouy-Pailler"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.04330"
  },
  {
    "id": "arXiv:2205.04812",
    "title": "The Impact of Partial Occlusion on Pedestrian Detectability",
    "abstract": "The Impact of Partial Occlusion on Pedestrian Detectability",
    "descriptor": "",
    "authors": [
      "Shane Gilroy",
      "Darragh Mullins",
      "Edward Jones",
      "Ashkan Parsi",
      "Martin Glavin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2205.04812"
  },
  {
    "id": "arXiv:2205.05232",
    "title": "Linear average-case complexity of algorithmic problems in groups",
    "abstract": "Comments: 20 pages",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Alexander Olshanskii",
      "Vladimir Shpilrain"
    ],
    "subjectives": [
      "Group Theory (math.GR)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2205.05232"
  },
  {
    "id": "arXiv:2205.05412",
    "title": "An Objective Method for Pedestrian Occlusion Level Classification",
    "abstract": "An Objective Method for Pedestrian Occlusion Level Classification",
    "descriptor": "",
    "authors": [
      "Shane Gilroy",
      "Martin Glavin",
      "Edward Jones",
      "Darragh Mullins"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.05412"
  },
  {
    "id": "arXiv:2205.06167",
    "title": "Optimal Methods for Higher-Order Smooth Monotone Variational  Inequalities",
    "abstract": "Comments: 21 Pages",
    "descriptor": "\nComments: 21 Pages\n",
    "authors": [
      "Deeksha Adil",
      "Brian Bullins",
      "Arun Jambulapati",
      "Sushant Sachdeva"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2205.06167"
  },
  {
    "id": "arXiv:2205.06921",
    "title": "Ferrite: A Judgmental Embedding of Session Types in Rust",
    "abstract": "Comments: Accidental duplication of arXiv:2009.13619",
    "descriptor": "\nComments: Accidental duplication of arXiv:2009.13619\n",
    "authors": [
      "Ruo Fei Chen",
      "Stephanie Balzer",
      "Bernardo Toninho"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2205.06921"
  },
  {
    "id": "arXiv:2205.07403",
    "title": "PillarNet: Real-Time and High-Performance Pillar-based 3D Object  Detection",
    "abstract": "PillarNet: Real-Time and High-Performance Pillar-based 3D Object  Detection",
    "descriptor": "",
    "authors": [
      "Guangsheng Shi",
      "Ruifeng Li",
      "Chao Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.07403"
  },
  {
    "id": "arXiv:2205.08473",
    "title": "ColonFormer: An Efficient Transformer based Method for Colon Polyp  Segmentation",
    "abstract": "ColonFormer: An Efficient Transformer based Method for Colon Polyp  Segmentation",
    "descriptor": "",
    "authors": [
      "Nguyen Thanh Duc",
      "Nguyen Thi Oanh",
      "Nguyen Thi Thuy",
      "Tran Minh Triet",
      "Dinh Viet Sang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.08473"
  },
  {
    "id": "arXiv:2205.08942",
    "title": "Sensing Time Effectiveness for Fitness to Drive Evaluation in  Neurological Patients",
    "abstract": "Comments: 24 pages, 4 figures, 2 tables",
    "descriptor": "\nComments: 24 pages, 4 figures, 2 tables\n",
    "authors": [
      "Nadica Miljkovi\u0107",
      "Jaka Sodnik"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Human-Computer Interaction (cs.HC)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2205.08942"
  },
  {
    "id": "arXiv:2205.09250",
    "title": "Bayesian Convolutional Neural Networks for Limited Data Hyperspectral  Remote Sensing Image Classification",
    "abstract": "Bayesian Convolutional Neural Networks for Limited Data Hyperspectral  Remote Sensing Image Classification",
    "descriptor": "",
    "authors": [
      "Mohammad Joshaghani",
      "Amirabbas Davari",
      "Faezeh Nejati Hatamian",
      "Andreas Maier",
      "Christian Riess"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.09250"
  },
  {
    "id": "arXiv:2205.09438",
    "title": "Gold-standard solutions to the Schr\u00f6dinger equation using deep  learning: How much physics do we need?",
    "abstract": "Comments: 10 pages + apppendix, 7 figures; V2: minor corrections to citations and reference energies for F, Ne, H2O",
    "descriptor": "\nComments: 10 pages + apppendix, 7 figures; V2: minor corrections to citations and reference energies for F, Ne, H2O\n",
    "authors": [
      "Leon Gerard",
      "Michael Scherbela",
      "Philipp Marquetand",
      "Philipp Grohs"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2205.09438"
  },
  {
    "id": "arXiv:2205.09576",
    "title": "Discovering Dynamic Functional Brain Networks via Spatial and  Channel-wise Attention",
    "abstract": "Comments: 12 pages,6 figures, submitted to 36th Conference on Neural Information Processing Systems (NeurIPS 2022)",
    "descriptor": "\nComments: 12 pages,6 figures, submitted to 36th Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Yiheng Liu",
      "Enjie Ge",
      "Mengshen He",
      "Zhengliang Liu",
      "Shijie Zhao",
      "Xintao Hu",
      "Dajiang Zhu",
      "Tianming Liu",
      "Bao Ge"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2205.09576"
  },
  {
    "id": "arXiv:2205.09852",
    "title": "Deconfounding Actor-Critic Network with Policy Adaptation for Dynamic  Treatment Regimes",
    "abstract": "Deconfounding Actor-Critic Network with Policy Adaptation for Dynamic  Treatment Regimes",
    "descriptor": "",
    "authors": [
      "Changchang Yin",
      "Ruoqi Liu",
      "Jeffrey Caterino",
      "Ping Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.09852"
  },
  {
    "id": "arXiv:2205.10513",
    "title": "Computable Artificial General Intelligence",
    "abstract": "Comments: Experiment code available on TechRxiv: this https URL",
    "descriptor": "\nComments: Experiment code available on TechRxiv: this https URL\n",
    "authors": [
      "Michael Timothy Bennett"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.10513"
  },
  {
    "id": "arXiv:2205.10971",
    "title": "Numerical method for the Fokker-Planck equation of Brownian motion  subordinated by inverse tempered stable subordinator with drift",
    "abstract": "Numerical method for the Fokker-Planck equation of Brownian motion  subordinated by inverse tempered stable subordinator with drift",
    "descriptor": "",
    "authors": [
      "Xiangong Tang",
      "Can Wang",
      "Weihua Deng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.10971"
  },
  {
    "id": "arXiv:2205.11107",
    "title": "Learning to branch with Tree MDPs",
    "abstract": "Comments: 10 pages, 2 figures, plus supplementary material",
    "descriptor": "\nComments: 10 pages, 2 figures, plus supplementary material\n",
    "authors": [
      "Lara Scavuzzo",
      "Feng Yang Chen",
      "Didier Ch\u00e9telat",
      "Maxime Gasse",
      "Andrea Lodi",
      "Neil Yorke-Smith",
      "Karen Aardal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2205.11107"
  },
  {
    "id": "arXiv:2205.11370",
    "title": "Use of Transformer-Based Models for Word-Level Transliteration of the  Book of the Dean of Lismore",
    "abstract": "Comments: 4th Celtic Language Technology Workshop",
    "descriptor": "\nComments: 4th Celtic Language Technology Workshop\n",
    "authors": [
      "Edward Gow-Smith",
      "Mark McConville",
      "William Gillies",
      "Jade Scott",
      "Roibeard \u00d3 Maolalaigh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.11370"
  },
  {
    "id": "arXiv:2205.11402",
    "title": "Causal Machine Learning for Healthcare and Precision Medicine",
    "abstract": "Comments: 19 pages, 4 figures, 1 table",
    "descriptor": "\nComments: 19 pages, 4 figures, 1 table\n",
    "authors": [
      "Pedro Sanchez",
      "Jeremy P. Voisey",
      "Tian Xia",
      "Hannah I. Watson",
      "Alison Q. ONeil",
      "Sotirios A. Tsaftaris"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.11402"
  },
  {
    "id": "arXiv:2205.12105",
    "title": "HiVLP: Hierarchical Vision-Language Pre-Training for Fast Image-Text  Retrieval",
    "abstract": "HiVLP: Hierarchical Vision-Language Pre-Training for Fast Image-Text  Retrieval",
    "descriptor": "",
    "authors": [
      "Feilong Chen",
      "Xiuyi Chen",
      "Jiaxin Shi",
      "Duzhen Zhang",
      "Jianlong Chang",
      "Qi Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.12105"
  },
  {
    "id": "arXiv:2205.12503",
    "title": "Maximising the Influence of Temporary Participants in Opinion Formation",
    "abstract": "Maximising the Influence of Temporary Participants in Opinion Formation",
    "descriptor": "",
    "authors": [
      "Zhiqiang Zhuang",
      "Kewen Wang",
      "Zhe Wang",
      "Junhu Wang",
      "Yinong Yang"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2205.12503"
  },
  {
    "id": "arXiv:2205.12634",
    "title": "Real-Time Video Deblurring via Lightweight Motion Compensation",
    "abstract": "Real-Time Video Deblurring via Lightweight Motion Compensation",
    "descriptor": "",
    "authors": [
      "Hyeongseok Son",
      "Junyong Lee",
      "Sunghyun Cho",
      "Seungyong Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.12634"
  },
  {
    "id": "arXiv:2205.12661",
    "title": "Implicit Function Theorem: Estimates on the size of the domain",
    "abstract": "Comments: 25 pages, 5 figures",
    "descriptor": "\nComments: 25 pages, 5 figures\n",
    "authors": [
      "Ashutosh Jindal",
      "Debasish Chatterjee",
      "Ravi Banavar"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.12661"
  },
  {
    "id": "arXiv:2205.12907",
    "title": "Highly efficient energy-conserving moment method for the  multi-dimensional Vlasov-Maxwell system",
    "abstract": "Highly efficient energy-conserving moment method for the  multi-dimensional Vlasov-Maxwell system",
    "descriptor": "",
    "authors": [
      "Tianai Yin",
      "Xinghui Zhong",
      "Yanli Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.12907"
  },
  {
    "id": "arXiv:2205.13135",
    "title": "LAMP 2.0: A Robust Multi-Robot SLAM System for Operation in Challenging  Large-Scale Underground Environments",
    "abstract": "LAMP 2.0: A Robust Multi-Robot SLAM System for Operation in Challenging  Large-Scale Underground Environments",
    "descriptor": "",
    "authors": [
      "Yun Chang",
      "Kamak Ebadi",
      "Christopher E. Denniston",
      "Muhammad Fadhil Ginting",
      "Antoni Rosinol",
      "Andrzej Reinke",
      "Matteo Palieri",
      "Jingnan Shi",
      "Arghya Chatterjee",
      "Benjamin Morrell",
      "Ali-akbar Agha-mohammadi",
      "Luca Carlone"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2205.13135"
  },
  {
    "id": "arXiv:2205.13265",
    "title": "Privacy-Preserving Wavelet Neural Network with Fully Homomorphic  Encryption",
    "abstract": "Comments: 17 pages; 3 figures, 10 tables",
    "descriptor": "\nComments: 17 pages; 3 figures, 10 tables\n",
    "authors": [
      "Syed Imtiaz Ahamed",
      "Vadlamani Ravi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.13265"
  },
  {
    "id": "arXiv:2205.13619",
    "title": "Fairness in Recommendation: A Survey",
    "abstract": "Comments: 37 pages, 2 figures, 1 table",
    "descriptor": "\nComments: 37 pages, 2 figures, 1 table\n",
    "authors": [
      "Yunqi Li",
      "Hanxiong Chen",
      "Shuyuan Xu",
      "Yingqiang Ge",
      "Juntao Tan",
      "Shuchang Liu",
      "Yongfeng Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.13619"
  },
  {
    "id": "arXiv:2205.13724",
    "title": "V-Doc : Visual questions answers with Documents",
    "abstract": "Comments: Accepted by CVPR 2022",
    "descriptor": "\nComments: Accepted by CVPR 2022\n",
    "authors": [
      "Yihao Ding",
      "Zhe Huang",
      "Runlin Wang",
      "Yanhang Zhang",
      "Xianru Chen",
      "Yuzhong Ma",
      "Hyunsuk Chung",
      "Soyeon Caren Han"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.13724"
  },
  {
    "id": "arXiv:2205.13958",
    "title": "Machine Learning-Based User Scheduling in Integrated  Satellite-HAPS-Ground Networks",
    "abstract": "Machine Learning-Based User Scheduling in Integrated  Satellite-HAPS-Ground Networks",
    "descriptor": "",
    "authors": [
      "Shasha Liu",
      "Hayssam Dahrouj",
      "Mohamed-Slim Alouini"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.13958"
  },
  {
    "id": "arXiv:2205.13996",
    "title": "Video2StyleGAN: Disentangling Local and Global Variations in a Video",
    "abstract": "Comments: Video : this https URL",
    "descriptor": "\nComments: Video : this https URL\n",
    "authors": [
      "Rameen Abdal",
      "Peihao Zhu",
      "Niloy J. Mitra",
      "Peter Wonka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2205.13996"
  },
  {
    "id": "arXiv:2205.14014",
    "title": "What Dense Graph Do You Need for Self-Attention?",
    "abstract": "Comments: Accepted by ICML 2022. Code is available at this https URL",
    "descriptor": "\nComments: Accepted by ICML 2022. Code is available at this https URL\n",
    "authors": [
      "Yuxing Wang",
      "Chu-Tak Lee",
      "Qipeng Guo",
      "Zhangyue Yin",
      "Yunhua Zhou",
      "Xuanjing Huang",
      "Xipeng Qiu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.14014"
  },
  {
    "id": "arXiv:2205.14125",
    "title": "Cycle Mutation: Evolving Permutations via Cycle Induction",
    "abstract": "Cycle Mutation: Evolving Permutations via Cycle Induction",
    "descriptor": "",
    "authors": [
      "Vincent A. Cicirello"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.14125"
  },
  {
    "id": "arXiv:2205.14191",
    "title": "Sensing Eating Events in Context: A Smartphone-Only Approach",
    "abstract": "Comments: Accepted for publication at IEEE Access",
    "descriptor": "\nComments: Accepted for publication at IEEE Access\n",
    "authors": [
      "Wageesha Bangamuarachchi",
      "Anju Chamantha",
      "Lakmal Meegahapola",
      "Salvador Ruiz-Correa",
      "Indika Perera",
      "Daniel Gatica-Perez"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2205.14191"
  },
  {
    "id": "arXiv:2205.14224",
    "title": "Will Bilevel Optimizers Benefit from Loops",
    "abstract": "Comments: 32 pages, 2 figures, 3 tables",
    "descriptor": "\nComments: 32 pages, 2 figures, 3 tables\n",
    "authors": [
      "Kaiyi Ji",
      "Mingrui Liu",
      "Yingbin Liang",
      "Lei Ying"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.14224"
  },
  {
    "id": "arXiv:2205.14247",
    "title": "Ainur: A Framework for Repeatable End-to-End Wireless Edge Computing  Testbed Research",
    "abstract": "Comments: 6 pages, 6 figures, demo session paper",
    "descriptor": "\nComments: 6 pages, 6 figures, demo session paper\n",
    "authors": [
      "Manuel Olgu\u00edn Mu\u00f1oz",
      "Seyed Samie Mostafavi",
      "Vishnu N. Moothedath",
      "James Gross"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2205.14247"
  },
  {
    "id": "arXiv:2205.14324",
    "title": "Differentially Private Covariance Revisited",
    "abstract": "Differentially Private Covariance Revisited",
    "descriptor": "",
    "authors": [
      "Wei Dong",
      "Yuting Liang",
      "Ke Yi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.14324"
  },
  {
    "id": "arXiv:2205.14354",
    "title": "Multi-Task Learning with Multi-query Transformer for Dense Prediction",
    "abstract": "Multi-Task Learning with Multi-query Transformer for Dense Prediction",
    "descriptor": "",
    "authors": [
      "Yangyang Xu",
      "Xiangtai Li",
      "Haobo Yuan",
      "Yibo Yang",
      "Jing Zhang",
      "Yunhai Tong",
      "Lefei Zhang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.14354"
  },
  {
    "id": "arXiv:2205.14365",
    "title": "Granular Generalized Variable Precision Rough Sets and Rational  Approximations",
    "abstract": "Comments: 52 Pages",
    "descriptor": "\nComments: 52 Pages\n",
    "authors": [
      "Mani A",
      "Sushmita Mitra"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2205.14365"
  },
  {
    "id": "arXiv:2205.14415",
    "title": "Non-stationary Transformers: Rethinking the Stationarity in Time Series  Forecasting",
    "abstract": "Non-stationary Transformers: Rethinking the Stationarity in Time Series  Forecasting",
    "descriptor": "",
    "authors": [
      "Yong Liu",
      "Haixu Wu",
      "Jianmin Wang",
      "Mingsheng Long"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.14415"
  },
  {
    "id": "arXiv:2205.14457",
    "title": "An adaptive admittance controller for collaborative drilling with a  robot based on subtask classification via deep learning",
    "abstract": "An adaptive admittance controller for collaborative drilling with a  robot based on subtask classification via deep learning",
    "descriptor": "",
    "authors": [
      "Berk Guler",
      "Pouya P. Niaz",
      "Alireza Madani",
      "Yusuf Aydin",
      "Cagatay Basdogan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.14457"
  },
  {
    "id": "arXiv:2205.14590",
    "title": "Independent and Decentralized Learning in Markov Potential Games",
    "abstract": "Comments: 42 pages, 3 figures",
    "descriptor": "\nComments: 42 pages, 3 figures\n",
    "authors": [
      "Chinmay Maheshwari",
      "Manxi Wu",
      "Druv Pai",
      "Shankar Sastry"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.14590"
  },
  {
    "id": "arXiv:2205.14647",
    "title": "Methodologies, Workloads, and Tools for Processing-in-Memory: Enabling  the Adoption of Data-Centric Architectures",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2012.11890",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2012.11890\n",
    "authors": [
      "Geraldo F. Oliveira",
      "Juan G\u00f3mez-Luna",
      "Saugata Ghose",
      "Onur Mutlu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2205.14647"
  },
  {
    "id": "arXiv:2205.14728",
    "title": "L3Cube-MahaNLP: Marathi Natural Language Processing Datasets, Models,  and Library",
    "abstract": "L3Cube-MahaNLP: Marathi Natural Language Processing Datasets, Models,  and Library",
    "descriptor": "",
    "authors": [
      "Raviraj Joshi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.14728"
  },
  {
    "id": "arXiv:2205.14923",
    "title": "Unbalanced CO-Optimal Transport",
    "abstract": "Unbalanced CO-Optimal Transport",
    "descriptor": "",
    "authors": [
      "Quang Huy Tran",
      "Hicham Janati",
      "Nicolas Courty",
      "R\u00e9mi Flamary",
      "Ievgen Redko",
      "Pinar Demetci",
      "Ritambhara Singh"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.14923"
  },
  {
    "id": "arXiv:2205.14925",
    "title": "The u-index: a simple metric to objectively measure academic impact of  individual researchers",
    "abstract": "Comments: 3 pages, 1 table, no figures",
    "descriptor": "\nComments: 3 pages, 1 table, no figures\n",
    "authors": [
      "Roberto Dillon"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2205.14925"
  },
  {
    "id": "arXiv:2205.14943",
    "title": "Data-driven Numerical Invariant Synthesis with Automatic Generation of  Attributes",
    "abstract": "Data-driven Numerical Invariant Synthesis with Automatic Generation of  Attributes",
    "descriptor": "",
    "authors": [
      "Ahmed Bouajjani",
      "Wael-Amine Boutglay",
      "Peter Habermehl"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.14943"
  },
  {
    "id": "arXiv:2205.14965",
    "title": "PSNet: Fast Data Structuring for Hierarchical Deep Learning on Point  Cloud",
    "abstract": "PSNet: Fast Data Structuring for Hierarchical Deep Learning on Point  Cloud",
    "descriptor": "",
    "authors": [
      "Luyang Li",
      "Ligang He",
      "Jinjin Gao",
      "Xie Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.14965"
  },
  {
    "id": "arXiv:2205.14967",
    "title": "Universally-Optimal Distributed Exact Min-Cut",
    "abstract": "Comments: 34 pages, accepted to PODC 2022",
    "descriptor": "\nComments: 34 pages, accepted to PODC 2022\n",
    "authors": [
      "Mohsen Ghaffari",
      "Goran Zuzic"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2205.14967"
  },
  {
    "id": "arXiv:2205.15053",
    "title": "Deblurring Photographs of Characters Using Deep Neural Networks",
    "abstract": "Comments: 15 pages, 13 figures",
    "descriptor": "\nComments: 15 pages, 13 figures\n",
    "authors": [
      "Thomas Germer",
      "Tobias Uelwer",
      "Stefan Harmeling"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15053"
  },
  {
    "id": "arXiv:2205.15060",
    "title": "Duplex Conversation: Towards Human-like Interaction in Spoken Dialogue  System",
    "abstract": "Comments: Accepted by KDD 2022, ADS track",
    "descriptor": "\nComments: Accepted by KDD 2022, ADS track\n",
    "authors": [
      "Ting-En Lin",
      "Yuchuan Wu",
      "Fei Huang",
      "Luo Si",
      "Jian Sun",
      "Yongbin Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.15060"
  },
  {
    "id": "arXiv:2205.15196",
    "title": "PAC Generalization via Invariant Representations",
    "abstract": "PAC Generalization via Invariant Representations",
    "descriptor": "",
    "authors": [
      "Advait Parulekar",
      "Karthikeyan Shanmugam",
      "Sanjay Shakkottai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.15196"
  },
  {
    "id": "arXiv:2205.15278",
    "title": "EAMM: One-Shot Emotional Talking Face via Audio-Based Emotion-Aware  Motion Model",
    "abstract": "Comments: Accepted by SIGGRAPH 2022 Conference Papers track",
    "descriptor": "\nComments: Accepted by SIGGRAPH 2022 Conference Papers track\n",
    "authors": [
      "Xinya Ji",
      "Hang Zhou",
      "Kaisiyuan Wang",
      "Qianyi Wu",
      "Wayne Wu",
      "Feng Xu",
      "Xun Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15278"
  },
  {
    "id": "arXiv:2205.15290",
    "title": "Zero-Shot and Few-Shot Learning for Lung Cancer Multi-Label  Classification using Vision Transformer",
    "abstract": "Zero-Shot and Few-Shot Learning for Lung Cancer Multi-Label  Classification using Vision Transformer",
    "descriptor": "",
    "authors": [
      "Fu-Ming Guo",
      "Yingfang Fan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15290"
  }
]
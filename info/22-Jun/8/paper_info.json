[
  {
    "id": "arXiv:2206.02782",
    "title": "Towards Job-Transition-Tag Graph for a Better Job Title Representation  Learning",
    "abstract": "Works on learning job title representation are mainly based on\n\\textit{Job-Transition Graph}, built from the working history of talents.\nHowever, since these records are usually messy, this graph is very sparse,\nwhich affects the quality of the learned representation and hinders further\nanalysis. To address this specific issue, we propose to enrich the graph with\nadditional nodes that improve the quality of job title representation.\nSpecifically, we construct \\textit{Job-Transition-Tag Graph}, a heterogeneous\ngraph containing two types of nodes, i.e., job titles and tags (i.e., words\nrelated to job responsibilities or functionalities). Along this line, we\nreformulate job title representation learning as the task of learning node\nembedding on the \\textit{Job-Transition-Tag Graph}. Experiments on two datasets\nshow the interest of our approach.",
    "descriptor": "",
    "authors": [
      "Jun Zhu",
      "C\u00e9line Hudelot"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.02782"
  },
  {
    "id": "arXiv:2206.02784",
    "title": "Intake Monitoring in Free-Living Conditions: Overview and Lessons we  Have Learned",
    "abstract": "The progress in artificial intelligence and machine learning algorithms over\nthe past decade has enabled the development of new methods for the objective\nmeasurement of eating, including both the measurement of eating episodes as\nwell as the measurement of in-meal eating behavior. These allow the study of\neating behavior outside the laboratory in free-living conditions, without the\nneed for video recordings and laborious manual annotations. In this paper, we\npresent a high-level overview of our recent work on intake monitoring using a\nsmartwatch, as well as methods using an in-ear microphone. We also present\nevaluation results of these methods in challenging, real-world datasets.\nFurthermore, we discuss use-cases of such intake monitoring tools for advancing\nresearch in eating behavior, for improving dietary monitoring, as well as for\ndeveloping evidence-based health policies. Our goal is to inform researchers\nand users of intake monitoring methods regarding (i) the development of new\nmethods based on commercially available devices, (ii) what to expect in terms\nof effectiveness, and (iii) how these methods can be used in research as well\nas in practical applications.",
    "descriptor": "",
    "authors": [
      "Christos Diou",
      "Konstantinos Kyritsis",
      "Vasileios Papapanagiotou",
      "Ioannis Sarafis"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02784"
  },
  {
    "id": "arXiv:2206.02785",
    "title": "Zeroth-Order SciML: Non-intrusive Integration of Scientific Software  with Deep Learning",
    "abstract": "Using deep learning (DL) to accelerate and/or improve scientific workflows\ncan yield discoveries that are otherwise impossible. Unfortunately, DL models\nhave yielded limited success in complex scientific domains due to large data\nrequirements. In this work, we propose to overcome this issue by integrating\nthe abundance of scientific knowledge sources (SKS) with the DL training\nprocess. Existing knowledge integration approaches are limited to using\ndifferentiable knowledge source to be compatible with first-order DL training\nparadigm. In contrast, our proposed approach treats knowledge source as a\nblack-box in turn allowing to integrate virtually any knowledge source. To\nenable an end-to-end training of SKS-coupled-DL, we propose to use zeroth-order\noptimization (ZOO) based gradient-free training schemes, which is\nnon-intrusive, i.e., does not require making any changes to the SKS. We\nevaluate the performance of our ZOO training scheme on two real-world material\nscience applications. We show that proposed scheme is able to effectively\nintegrate scientific knowledge with DL training and is able to outperform\npurely data-driven model for data-limited scientific applications. We also\ndiscuss some limitations of the proposed method and mention potentially\nworthwhile future directions.",
    "descriptor": "",
    "authors": [
      "Ioannis Tsaknakis",
      "Bhavya Kailkhura",
      "Sijia Liu",
      "Donald Loveland",
      "James Diffenderfer",
      "Anna Maria Hiszpanski",
      "Mingyi Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02785"
  },
  {
    "id": "arXiv:2206.02786",
    "title": "Impossibility of Collective Intelligence",
    "abstract": "Democratization of AI involves training and deploying machine learning models\nacross heterogeneous and potentially massive environments. Diversity of data\nopens up a number of possibilities to advance AI systems, but also introduces\npressing concerns such as privacy, security, and equity that require special\nattention. This work shows that it is theoretically impossible to design a\nrational learning algorithm that has the ability to successfully learn across\nheterogeneous environments, which we decoratively call collective intelligence\n(CI). By representing learning algorithms as choice correspondences over a\nhypothesis space, we are able to axiomatize them with essential properties.\nUnfortunately, the only feasible algorithm compatible with all of the axioms is\nthe standard empirical risk minimization (ERM) which learns arbitrarily from a\nsingle environment. Our impossibility result reveals informational\nincomparability between environments as one of the foremost obstacles for\nresearchers who design novel algorithms that learn from multiple environments,\nwhich sheds light on prerequisites for success in critical areas of machine\nlearning such as out-of-distribution generalization, federated learning,\nalgorithmic fairness, and multi-modal learning.",
    "descriptor": "\nComments: 25 pages, 2 figures\n",
    "authors": [
      "Krikamol Muandet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Theoretical Economics (econ.TH)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.02786"
  },
  {
    "id": "arXiv:2206.02790",
    "title": "Improving Model Understanding and Trust with Counterfactual Explanations  of Model Confidence",
    "abstract": "In this paper, we show that counterfactual explanations of confidence scores\nhelp users better understand and better trust an AI model's prediction in\nhuman-subject studies. Showing confidence scores in human-agent interaction\nsystems can help build trust between humans and AI systems. However, most\nexisting research only used the confidence score as a form of communication,\nand we still lack ways to explain why the algorithm is confident. This paper\nalso presents two methods for understanding model confidence using\ncounterfactual explanation: (1) based on counterfactual examples; and (2) based\non visualisation of the counterfactual space.",
    "descriptor": "\nComments: 8 pages, Accepted to IJCAI Workshop on Explainable Artificial Intelligence 2022\n",
    "authors": [
      "Thao Le",
      "Tim Miller",
      "Ronal Singh",
      "Liz Sonenberg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.02790"
  },
  {
    "id": "arXiv:2206.02791",
    "title": "Instance-Dependent Label-Noise Learning with Manifold-Regularized  Transition Matrix Estimation",
    "abstract": "In label-noise learning, estimating the transition matrix has attracted more\nand more attention as the matrix plays an important role in building\nstatistically consistent classifiers. However, it is very challenging to\nestimate the transition matrix T(x), where x denotes the instance, because it\nis unidentifiable under the instance-dependent noise(IDN). To address this\nproblem, we have noticed that, there are psychological and physiological\nevidences showing that we humans are more likely to annotate instances of\nsimilar appearances to the same classes, and thus poor-quality or ambiguous\ninstances of similar appearances are easier to be mislabeled to the correlated\nor same noisy classes. Therefore, we propose assumption on the geometry of T(x)\nthat \"the closer two instances are, the more similar their corresponding\ntransition matrices should be\". More specifically, we formulate above\nassumption into the manifold embedding, to effectively reduce the degree of\nfreedom of T(x) and make it stably estimable in practice. The proposed\nmanifold-regularized technique works by directly reducing the estimation error\nwithout hurting the approximation error about the estimation problem of T(x).\nExperimental evaluations on four synthetic and two real-world datasets\ndemonstrate that our method is superior to state-of-the-art approaches for\nlabel-noise learning under the challenging IDN.",
    "descriptor": "\nComments: accepted by CVPR2022\n",
    "authors": [
      "De Cheng",
      "Tongliang Liu",
      "Yixiong Ning",
      "Nannan Wang",
      "Bo Han",
      "Gang Niu",
      "Xinbo Gao",
      "Masashi Sugiyama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02791"
  },
  {
    "id": "arXiv:2206.02792",
    "title": "FIFA: Making Fairness More Generalizable in Classifiers Trained on  Imbalanced Data",
    "abstract": "Algorithmic fairness plays an important role in machine learning and imposing\nfairness constraints during learning is a common approach. However, many\ndatasets are imbalanced in certain label classes (e.g. \"healthy\") and sensitive\nsubgroups (e.g. \"older patients\"). Empirically, this imbalance leads to a lack\nof generalizability not only of classification, but also of fairness\nproperties, especially in over-parameterized models. For example,\nfairness-aware training may ensure equalized odds (EO) on the training data,\nbut EO is far from being satisfied on new users. In this paper, we propose a\ntheoretically-principled, yet Flexible approach that is\nImbalance-Fairness-Aware (FIFA). Specifically, FIFA encourages both\nclassification and fairness generalization and can be flexibly combined with\nmany existing fair learning methods with logits-based losses. While our main\nfocus is on EO, FIFA can be directly applied to achieve equalized opportunity\n(EqOpt); and under certain conditions, it can also be applied to other fairness\nnotions. We demonstrate the power of FIFA by combining it with a popular fair\nclassification algorithm, and the resulting algorithm achieves significantly\nbetter fairness generalization on several real-world datasets.",
    "descriptor": "",
    "authors": [
      "Zhun Deng",
      "Jiayao Zhang",
      "Linjun Zhang",
      "Ting Ye",
      "Yates Coley",
      "Weijie J. Su",
      "James Zou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.02792"
  },
  {
    "id": "arXiv:2206.02794",
    "title": "Machine learning models for determination of weldbead shape parameters  for gas metal arc welded T-joints -- A comparative study",
    "abstract": "The shape of a weld bead is critical in assessing the quality of the welded\njoint. In particular, this has a major impact in the accuracy of the results\nobtained from a numerical analysis. This study focuses on the statistical\ndesign techniques and the artificial neural networks, to predict the weld bead\nshape parameters of shielded Gas Metal Arc Welded (GMAW) fillet joints.\nExtensive testing was carried out on low carbon mild steel plates of\nthicknesses ranging from 3mm to 10mm. Welding voltage, welding current, and\nmoving heat source speed were considered as the welding parameters. Three types\nof multiple linear regression models (MLR) were created to establish an\nempirical equation for defining GMAW bead shape parameters considering\ninteractive and higher order terms. Additionally, artificial neural network\n(ANN) models were created based on similar scheme, and the relevance of\nspecific features was investigated using SHapley Additive exPlanations (SHAP).\nThe results reveal that MLR-based approach performs better than the ANN based\nmodels in terms of predictability and error assessment. This study shows the\nusefulness of the predictive tools to aid numerical analysis of welding.",
    "descriptor": "",
    "authors": [
      "R. Pradhan",
      "A.P Joshi",
      "M.R Sunny",
      "A. Sarkar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02794"
  },
  {
    "id": "arXiv:2206.02796",
    "title": "Interpolation-based Correlation Reduction Network for Semi-Supervised  Graph Learning",
    "abstract": "Graph Neural Networks (GNNs) have achieved promising performance in\nsemi-supervised node classification in recent years. However, the problem of\ninsufficient supervision, together with representation collapse, largely limits\nthe performance of the GNNs in this field. To alleviate the collapse of node\nrepresentations in semi-supervised scenario, we propose a novel graph\ncontrastive learning method, termed Interpolation-based Correlation Reduction\nNetwork (ICRN). In our method, we improve the discriminative capability of the\nlatent feature by enlarging the margin of decision boundaries and improving the\ncross-view consistency of the latent representation. Specifically, we first\nadopt an interpolation-based strategy to conduct data augmentation in the\nlatent space and then force the prediction model to change linearly between\nsamples. Second, we enable the learned network to tell apart samples across two\ninterpolation-perturbed views through forcing the correlation matrix across\nviews to approximate an identity matrix. By combining the two settings, we\nextract rich supervision information from both the abundant unlabeled nodes and\nthe rare yet valuable labeled nodes for discriminative representation learning.\nExtensive experimental results on six datasets demonstrate the effectiveness\nand the generality of ICRN compared to the existing state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Xihong Yang",
      "Yue Liu",
      "Sihang Zhou",
      "Xinwang Liu",
      "En Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02796"
  },
  {
    "id": "arXiv:2206.02829",
    "title": "RORL: Robust Offline Reinforcement Learning via Conservative Smoothing",
    "abstract": "Offline reinforcement learning (RL) provides a promising direction to exploit\nthe massive amount of offline data for complex decision-making tasks. Due to\nthe distribution shift issue, current offline RL algorithms are generally\ndesigned to be conservative for value estimation and action selection. However,\nsuch conservatism impairs the robustness of learned policies, leading to a\nsignificant change even for a small perturbation on observations. To trade off\nrobustness and conservatism, we propose Robust Offline Reinforcement Learning\n(RORL) with a novel conservative smoothing technique. In RORL, we explicitly\nintroduce regularization on the policy and the value function for states near\nthe dataset and additional conservative value estimation on these OOD states.\nTheoretically, we show RORL enjoys a tighter suboptimality bound than recent\ntheoretical results in linear MDPs. We demonstrate that RORL can achieve the\nstate-of-the-art performance on the general offline RL benchmark and is\nconsiderably robust to adversarial observation perturbation.",
    "descriptor": "\nComments: 23 pages, 10 figures\n",
    "authors": [
      "Rui Yang",
      "Chenjia Bai",
      "Xiaoteng Ma",
      "Zhaoran Wang",
      "Chongjie Zhang",
      "Lei Han"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.02829"
  },
  {
    "id": "arXiv:2206.02831",
    "title": "A Category Theoretic View of Contextual Types: from Simple Types to  Dependent Types",
    "abstract": "We describe the categorical semantics for a simply typed variant and a\nsimplified dependently typed variant of Cocon, a contextual modal type theory\nwhere the box modality mediates between the weak function space that is used to\nrepresent higher-order abstract syntax (HOAS) trees and the strong function\nspace that describes (recursive) computations about them. What makes Cocon\ndifferent from standard type theories is the presence of first-class contexts\nand contextual objects to describe syntax trees that are closed with respect to\na given context of assumptions. Following M. Hofmann's work, we use a presheaf\nmodel to characterise HOAS trees. Surprisingly, this model already provides the\nnecessary structure to also model Cocon. In particular, we can capture the\ncontextual objects of Cocon using a comonad $\\flat$ that restricts presheaves\nto their closed elements. This gives a simple semantic characterisation of the\ninvariants of contextual types (e.g. substitution invariance) and identifies\nCocon as a type-theoretic syntax of presheaf models. We further extend this\ncharacterisation to dependent types using categories with families and show\nthat we can model a fragment of Cocon without recursor in the Fitch-style\ndependent modal type theory presented by Birkedal et. al..",
    "descriptor": "",
    "authors": [
      "Jason Z.S. Hu",
      "Brigitte Pientka",
      "Ulrich Sch\u00f6pp"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2206.02831"
  },
  {
    "id": "arXiv:2206.02834",
    "title": "Collaborative Linear Bandits with Adversarial Agents: Near-Optimal  Regret Bounds",
    "abstract": "We consider a linear stochastic bandit problem involving $M$ agents that can\ncollaborate via a central server to minimize regret. A fraction $\\alpha$ of\nthese agents are adversarial and can act arbitrarily, leading to the following\ntension: while collaboration can potentially reduce regret, it can also disrupt\nthe process of learning due to adversaries. In this work, we provide a\nfundamental understanding of this tension by designing new algorithms that\nbalance the exploration-exploitation trade-off via carefully constructed robust\nconfidence intervals. We also complement our algorithms with tight analyses.\nFirst, we develop a robust collaborative phased elimination algorithm that\nachieves $\\tilde{O}\\left(\\alpha+ 1/\\sqrt{M}\\right) \\sqrt{dT}$ regret for each\ngood agent; here, $d$ is the model-dimension and $T$ is the horizon. For small\n$\\alpha$, our result thus reveals a clear benefit of collaboration despite\nadversaries. Using an information-theoretic argument, we then prove a matching\nlower bound, thereby providing the first set of tight, near-optimal regret\nbounds for collaborative linear bandits with adversaries. Furthermore, by\nleveraging recent advances in high-dimensional robust statistics, we\nsignificantly extend our algorithmic ideas and results to (i) the generalized\nlinear bandit model that allows for non-linear observation maps; and (ii) the\ncontextual bandit setting that allows for time-varying feature vectors.",
    "descriptor": "",
    "authors": [
      "Aritra Mitra",
      "Arman Adibi",
      "George J. Pappas",
      "Hamed Hassani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.02834"
  },
  {
    "id": "arXiv:2206.02840",
    "title": "Spatial Acoustic Projection for 3D Imaging Sonar Reconstruction",
    "abstract": "In this work we present a novel method for reconstructing 3D surfaces using a\nmulti-beam imaging sonar. We integrate the intensities measured by the sonar\nfrom different viewpoints for fixed cell positions in a 3D grid. For each cell\nwe integrate a feature vector that holds the mean intensity for a discretized\nrange of viewpoints. Based on the feature vectors and independent sparse range\nmeasurements that act as ground truth information, we train convolutional\nneural networks that allow us to predict the signed distance and direction to\nthe nearest surface for each cell. The predicted signed distances can be\nprojected into a truncated signed distance field (TSDF) along the predicted\ndirections. Utilizing the marching cubes algorithm, a polygon mesh can be\nrendered from the TSDF. Our method allows a dense 3D reconstruction from a\nlimited set of viewpoints and was evaluated on three real-world datasets.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Sascha Arnold",
      "Bilal Wehbe"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02840"
  },
  {
    "id": "arXiv:2206.02841",
    "title": "Researching Alignment Research: Unsupervised Analysis",
    "abstract": "AI alignment research is the field of study dedicated to ensuring that\nartificial intelligence (AI) benefits humans. As machine intelligence gets more\nadvanced, this research is becoming increasingly important. Researchers in the\nfield share ideas across different media to speed up the exchange of\ninformation. However, this focus on speed means that the research landscape is\nopaque, making it difficult for young researchers to enter the field. In this\nproject, we collected and analyzed existing AI alignment research. We found\nthat the field is growing quickly, with several subfields emerging in parallel.\nWe looked at the subfields and identified the prominent researchers, recurring\ntopics, and different modes of communication in each. Furthermore, we found\nthat a classifier trained on AI alignment research articles can detect relevant\narticles that we did not originally include in the dataset. We are sharing the\ndataset with the research community and hope to develop tools in the future\nthat will help both established researchers and young researchers get more\ninvolved in the field.",
    "descriptor": "",
    "authors": [
      "Jan H. Kirchner",
      "Logan Smith",
      "Jacques Thibodeau",
      "Kyle McDonell",
      "Laria Reynolds"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02841"
  },
  {
    "id": "arXiv:2206.02842",
    "title": "A High Order Stabilized Solver for the Volume Averaged Navier-Stokes  Equations",
    "abstract": "The Volume-Averaged Navier-Stokes equations are used to study fluid flow in\nthe presence of fixed or moving solids such as packed or fluidized beds. We\ndevelop a high-order finite element solver using both forms A and B of these\nequations. We introduce tailored stabilization techniques to prevent\noscillations in regions of sharp gradients, to relax the\nLadyzhenskaya-Babuska-Brezzi inf-sup condition, and to enhance the local mass\nconservation and the robustness of the formulation. We calculate the void\nfraction using the Particle Centroid Method. Using different drag models, we\ncalculate the drag force exerted by the solids on the fluid. We implement the\nmethod of manufactured solution to verify our solver. We demonstrate that the\nmodel preserves the order of convergence of the underlying finite element\ndiscretization. Finally, we simulate gas flow through a randomly packed bed and\nstudy the pressure drop and mass conservation properties to validate our model.",
    "descriptor": "",
    "authors": [
      "Toni El Geitani",
      "Shahab Golshan",
      "Bruno Blais"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2206.02842"
  },
  {
    "id": "arXiv:2206.02845",
    "title": "On Efficient Approximate Queries over Machine Learning Models",
    "abstract": "The question of answering queries over ML predictions has been gaining\nattention in the database community. This question is challenging because the\ncost of finding high quality answers corresponds to invoking an oracle such as\na human expert or an expensive deep neural network model on every single item\nin the DB and then applying the query. We develop a novel unified framework for\napproximate query answering by leveraging a proxy to minimize the oracle usage\nof finding high quality answers for both Precision-Target (PT) and\nRecall-Target (RT) queries. Our framework uses a judicious combination of\ninvoking the expensive oracle on data samples and applying the cheap proxy on\nthe objects in the DB. It relies on two assumptions. Under the Proxy Quality\nassumption, proxy quality can be quantified in a probabilistic manner w.r.t.\nthe oracle. This allows us to develop two algorithms: PQA that efficiently\nfinds high quality answers with high probability and no oracle calls, and PQE,\na heuristic extension that achieves empirically good performance with a small\nnumber of oracle calls. Alternatively, under the Core Set Closure assumption,\nwe develop two algorithms: CSC that efficiently returns high quality answers\nwith high probability and minimal oracle usage, and CSE, which extends it to\nmore general settings. Our extensive experiments on five real-world datasets on\nboth query types, PT and RT, demonstrate that our algorithms outperform the\nstate-of-the-art and achieve high result quality with provable statistical\nguarantees.",
    "descriptor": "\nComments: Submitted to VLDB 2023, 15 pages, 10 figures\n",
    "authors": [
      "Dujian Ding",
      "Sihem Amer-Yahia",
      "Laks VS Lakshmanan"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02845"
  },
  {
    "id": "arXiv:2206.02846",
    "title": "A Deeper Dive Into What Deep Spatiotemporal Networks Encode: Quantifying  Static vs. Dynamic Information",
    "abstract": "Deep spatiotemporal models are used in a variety of computer vision tasks,\nsuch as action recognition and video object segmentation. Currently, there is a\nlimited understanding of what information is captured by these models in their\nintermediate representations. For example, while it has been observed that\naction recognition algorithms are heavily influenced by visual appearance in\nsingle static frames, there is no quantitative methodology for evaluating such\nstatic bias in the latent representation compared to bias toward dynamic\ninformation (e.g. motion). We tackle this challenge by proposing a novel\napproach for quantifying the static and dynamic biases of any spatiotemporal\nmodel. To show the efficacy of our approach, we analyse two widely studied\ntasks, action recognition and video object segmentation. Our key findings are\nthreefold: (i) Most examined spatiotemporal models are biased toward static\ninformation; although, certain two-stream architectures with cross-connections\nshow a better balance between the static and dynamic information captured. (ii)\nSome datasets that are commonly assumed to be biased toward dynamics are\nactually biased toward static information. (iii) Individual units (channels) in\nan architecture can be biased toward static, dynamic or a combination of the\ntwo.",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Matthew Kowal",
      "Mennatullah Siam",
      "Md Amirul Islam",
      "Neil D. B. Bruce",
      "Richard P. Wildes",
      "Konstantinos G. Derpanis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02846"
  },
  {
    "id": "arXiv:2206.02848",
    "title": "Plagiarism deterrence for introductory programming",
    "abstract": "Plagiarism in introductory programming courses is an enormous challenge for\nboth students and institutions. For students, relying on the work of others too\nearly in their academic development can make it impossible to acquire necessary\nskills for independent success in the future. For institutions, widespread\nstudent cheating can dilute the quality of the educational experience being\noffered. Currently available solutions consider only pairwise comparisons\nbetween student submissions and focus on punitive deterrence. Our approach\ninstead relies on a class-wide statistical characterization that can be clearly\nand securely shared with students via an intuitive new p-value representing\nindependence of student effort. A pairwise, compression-based similarity\ndetection algorithm captures relationships between assignments more accurately.\nAn automated deterrence system is used to warn students that their behavior is\nbeing closely monitored. High-confidence instances are made directly available\nfor instructor review using our open-source toolkit. An unbiased scoring system\naids students and the instructor in understanding true independence of effort.\nPreliminary results indicate that the system can provide meaningful\nmeasurements of independence from week one, improving the efficacy of technical\neducation.",
    "descriptor": "",
    "authors": [
      "Simon J. Cohen",
      "Michael J. Martin",
      "Chance A. Shipley",
      "Abhishek Kumar",
      "Andrew R. Cohen"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.02848"
  },
  {
    "id": "arXiv:2206.02849",
    "title": "A Bird's-Eye Tutorial of Graph Attention Architectures",
    "abstract": "Graph Neural Networks (GNNs) have shown tremendous strides in performance for\ngraph-structured problems especially in the domains of natural language\nprocessing, computer vision and recommender systems. Inspired by the success of\nthe transformer architecture, there has been an ever-growing body of work on\nattention variants of GNNs attempting to advance the state of the art in many\nof these problems. Incorporating \"attention\" into graph mining has been viewed\nas a way to overcome the noisiness, heterogenity and complexity associated with\ngraph-structured data as well as to encode soft-inductive bias. It is hence\ncrucial and advantageous to study these variants from a bird's-eye view to\nassess their strengths and weaknesses. We provide a systematic and focused\ntutorial centered around attention based GNNs in a hope to benefit researchers\ndealing with graph-structured problems. Our tutorial looks at GNN variants from\nthe point of view of the attention function and iteratively builds the reader's\nunderstanding of different graph attention variants.",
    "descriptor": "\nComments: 8 pages Tutorial\n",
    "authors": [
      "Kaustubh D. Dhole",
      "Carl Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.02849"
  },
  {
    "id": "arXiv:2206.02850",
    "title": "Exploring the Potential of SAR Data for Cloud Removal in Optical  Satellite Imagery",
    "abstract": "The challenge of the cloud removal task can be alleviated with the aid of\nSynthetic Aperture Radar (SAR) images that can penetrate cloud cover. However,\nthe large domain gap between optical and SAR images as well as the severe\nspeckle noise of SAR images may cause significant interference in SAR-based\ncloud removal, resulting in performance degeneration. In this paper, we propose\na novel global-local fusion based cloud removal (GLF-CR) algorithm to leverage\nthe complementary information embedded in SAR images. Exploiting the power of\nSAR information to promote cloud removal entails two aspects. The first, global\nfusion, guides the relationship among all local optical windows to maintain the\nstructure of the recovered region consistent with the remaining cloud-free\nregions. The second, local fusion, transfers complementary information embedded\nin the SAR image that corresponds to cloudy areas to generate reliable texture\ndetails of the missing regions, and uses dynamic filtering to alleviate the\nperformance degradation caused by speckle noise. Extensive evaluation\ndemonstrates that the proposed algorithm can yield high quality cloud-free\nimages and performs favorably against state-of-the-art cloud removal\nalgorithms.",
    "descriptor": "",
    "authors": [
      "Fang Xu",
      "Yilei Shi",
      "Patrick Ebel",
      "Lei Yu",
      "Gui-Song Xia",
      "Wen Yang",
      "Xiao Xiang Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.02850"
  },
  {
    "id": "arXiv:2206.02852",
    "title": "CompartOS: CHERI Compartmentalization for Embedded Systems",
    "abstract": "Existing high-end embedded systems face frequent security attacks. Software\ncompartmentalization is one technique to limit the attacks' effects to the\ncompromised compartment and not the entire system. Unfortunately, the existing\nstate-of-the-art embedded hardware-software solutions do not work well to\nenforce software compartmentalization for high-end embedded systems. MPUs are\nnot fine-grained and suffer from significant scalability limitations as they\ncan only protect a small and fixed number of memory regions. On the other hand,\nMMUs suffer from non-determinism and coarse-grained protection.\nThis paper introduces CompartOS as a lightweight linkage-based\ncompartmentalization model for high-end, complex, mainstream embedded systems.\nCompartOS builds on CHERI, a capability-based hardware architecture, to meet\nscalability, availability, compatibility, and fine-grained security goals.\nMicrobenchmarks show that CompartOS' protection-domain crossing is 95% faster\nthan MPU-based IPC. We applied the CompartOS model, with low effort, to complex\nexisting systems, including TCP servers and a safety-critical automotive demo.\nCompartOS not only catches 10 out of 13 FreeRTOS-TCP published vulnerabilities\nthat MPU-based protection (e.g., uVisor) cannot catch but can also recover from\nthem. Further, our TCP throughput evaluations show that our CompartOS prototype\nis 52% faster than relevant MPU-based compartmentalization models (e.g., ACES),\nwith a 15% overhead compared to an unprotected system. This comes at an FPGA's\nLUTs overhead of 10.4% to support CHERI for an unprotected baseline RISC-V\nprocessor, compared to 7.6% to support MPU, while CHERI only incurs 1.3% of the\nregisters area overhead compared to 2% for MPU.",
    "descriptor": "",
    "authors": [
      "Hesham Almatary",
      "Michael Dodson",
      "Jessica Clarke",
      "Peter Rugg",
      "Ivan Gomes",
      "Michal Podhradsky",
      "Peter G. Neumann",
      "Simon W. Moore",
      "Robert N. M. Watson"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.02852"
  },
  {
    "id": "arXiv:2206.02855",
    "title": "Efficient entity-based reinforcement learning",
    "abstract": "Recent deep reinforcement learning (DRL) successes rely on end-to-end\nlearning from fixed-size observational inputs (e.g. image, state-variables).\nHowever, many challenging and interesting problems in decision making involve\nobservations or intermediary representations which are best described as a set\nof entities: either the image-based approach would miss small but important\ndetails in the observations (e.g. ojects on a radar, vehicles on satellite\nimages, etc.), the number of sensed objects is not fixed (e.g. robotic\nmanipulation), or the problem simply cannot be represented in a meaningful way\nas an image (e.g. power grid control, or logistics). This type of structured\nrepresentations is not directly compatible with current DRL architectures,\nhowever, there has been an increase in machine learning techniques directly\ntargeting structured information, potentially addressing this issue. We propose\nto combine recent advances in set representations with slot attention and graph\nneural networks to process structured data, broadening the range of\napplications of DRL algorithms. This approach allows to address entity-based\nproblems in an efficient and scalable way. We show that it can improve training\ntime and robustness significantly, and demonstrate their potential to handle\nstructured as well as purely visual domains, on multiple environments from the\nAtari Learning Environment and Simple Playgrounds.",
    "descriptor": "",
    "authors": [
      "Vince Jankovics",
      "Michael Garcia Ortiz",
      "Eduardo Alonso"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02855"
  },
  {
    "id": "arXiv:2206.02856",
    "title": "Physics and semantic informed multi-sensor calibration via optimization  theory and self-supervised learning",
    "abstract": "Achieving safe and reliable autonomous driving relies greatly on the ability\nto achieve an accurate and robust perception system; however, this cannot be\nfully realized without precisely calibrated sensors. Environmental and\noperational conditions as well as improper maintenance can produce calibration\nerrors inhibiting sensor fusion and, consequently, degrading the perception\nperformance. Traditionally, sensor calibration is performed in a controlled\nenvironment with one or more known targets. Such a procedure can only be\ncarried out in between drives and requires manual operation; a tedious task if\nneeded to be conducted on a regular basis. This sparked a recent interest in\nonline targetless methods, capable of yielding a set of geometric\ntransformations based on perceived environmental features, however, the\nrequired redundancy in sensing modalities makes this task even more\nchallenging, as the features captured by each modality and their\ndistinctiveness may vary. We present a holistic approach to performing joint\ncalibration of a camera-lidar-radar trio. Leveraging prior knowledge and\nphysical properties of these sensing modalities together with semantic\ninformation, we propose two targetless calibration methods within a cost\nminimization framework once via direct online optimization, and second via\nself-supervised learning (SSL).",
    "descriptor": "",
    "authors": [
      "Shmuel Y. Hayoun",
      "Meir Halachmi",
      "Doron Serebro",
      "Kfir Twizer",
      "Elinor Medezinski",
      "Liron Korkidi",
      "Moshik Cohen",
      "Itai Orr"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02856"
  },
  {
    "id": "arXiv:2206.02862",
    "title": "Low Complexity Beam Searching Using Trajectory Information in Mobile  Millimeter-wave Networks",
    "abstract": "Millimeter-wave and terahertz systems rely on beamforming/combining codebooks\nfor finding the best beam directions during the initial access procedure.\nExisting approaches suffer from large codebook sizes and high beam searching\noverhead in the presence of mobile devices. To alleviate this problem, we\nsuggest utilizing the similarity of the channel in adjacent locations to divide\nthe UE trajectory into a set of separate regions and maintain a set of\ncandidate paths for each region in a database. In this paper, we show the\ntradeoff between the number of regions and the signalling overhead, i.e.,\nhigher number of regions corresponds to higher signal-to-noise ratio (SNR) but\nalso higher signalling overhead for the database. We then propose an\noptimization framework to find the minimum number of regions based on the\ntrajectory of a mobile device. Using realistic ray tracing datasets, we\ndemonstrate that the proposed method reduces the beam searching complexity and\nlatency while providing high SNR.",
    "descriptor": "",
    "authors": [
      "Sara Khosravi",
      "Hossein S. Ghadikolaei",
      "Jens Zander",
      "Marina Petrova"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.02862"
  },
  {
    "id": "arXiv:2206.02868",
    "title": "A Human-Centric Take on Model Monitoring",
    "abstract": "Predictive models are increasingly used to make various consequential\ndecisions in high-stakes domains such as healthcare, finance, and policy. It\nbecomes critical to ensure that these models make accurate predictions, are\nrobust to shifts in the data, do not rely on spurious features, and do not\nunduly discriminate against minority groups. To this end, several approaches\nspanning various areas such as explainability, fairness, and robustness have\nbeen proposed in recent literature. Such approaches need to be human-centered\nas they cater to the understanding of the models to their users. However, there\nis a research gap in understanding the human-centric needs and challenges of\nmonitoring machine learning (ML) models once they are deployed. To fill this\ngap, we conducted an interview study with 13 practitioners who have experience\nat the intersection of deploying ML models and engaging with customers spanning\ndomains such as financial services, healthcare, hiring, online retail,\ncomputational advertising, and conversational assistants. We identified various\nhuman-centric challenges and requirements for model monitoring in real-world\napplications. Specifically, we found the need and the challenge for the model\nmonitoring systems to clarify the impact of the monitoring observations on\noutcomes. Further, such insights must be actionable, robust, customizable for\ndomain-specific use cases, and cognitively considerate to avoid information\noverload.",
    "descriptor": "\nComments: 4 pages, 0 figures\n",
    "authors": [
      "Murtuza N Shergadwala",
      "Himabindu Lakkaraju",
      "Krishnaram Kenthapadi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.02868"
  },
  {
    "id": "arXiv:2206.02871",
    "title": "Cooperation among an anonymous group protected Bitcoin during failures  of decentralization",
    "abstract": "Bitcoin is a digital currency designed to rely on a decentralized, trustless\nnetwork of anonymous agents. Using a pseudonymous-address-linking procedure\nthat achieves >99% sensitivity and >99% specificity, we reveal that between\nlaunch (January 3rd, 2009), and when the price reached $1 (February 9th, 2011),\nmost bitcoin was mined by only sixty-four agents. This was due to the rapid\nemergence of Pareto distributions in bitcoin income, producing such extensive\nresource centralization that almost all contemporary bitcoin addresses can be\nconnected to these top agents by a chain of six transactions. Centralization\ncreated a social dilemma. Attackers could routinely exploit bitcoin via a \"51%\nattack\", making it possible for them to repeatedly spend the same bitcoins. Yet\ndoing so would harm the community. Strikingly, we find that potential attackers\nalways chose to cooperate instead. We model this dilemma using an N-player\nCentipede game in which anonymous players can choose to exploit, and thereby\nundermine, an appreciating good. Combining theory and economic experiments, we\nshow that, even when individual payoffs are unchanged, cooperation is more\nfrequent when the game is played by an anonymous group. Although bitcoin was\ndesigned to rely on a decentralized, trustless network of anonymous agents, its\nearly success rested instead on cooperation among a small group of altruistic\nfounders.",
    "descriptor": "\nComments: 12 pages main text 6 main text figures 76 total pages 23 supplemental figures\n",
    "authors": [
      "Alyssa Blackburn",
      "Christoph Huber",
      "Yossi Eliaz",
      "Muhammad S. Shamim",
      "David Weisz",
      "Goutham Seshadri",
      "Kevin Kim",
      "Shengqi Hang",
      "Erez Lieberman Aiden"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Computers and Society (cs.CY)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.02871"
  },
  {
    "id": "arXiv:2206.02872",
    "title": "Optimal Adjacency Labels for Subgraphs of Cartesian Products",
    "abstract": "For any hereditary graph class $\\mathcal F$, we construct optimal adjacency\nlabeling schemes for the classes of subgraphs and induced subgraphs of\nCartesian products of graphs in $\\mathcal F$. As a consequence, we show that,\nif $\\mathcal F$ admits efficient adjacency labels (or, equivalently, small\ninduced-universal graphs) meeting the information-theoretic minimum, then the\nclasses of subgraphs and induced subgraphs of Cartesian products of graphs in\n$\\mathcal F$ do too.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Louis Esperet",
      "Nathaniel Harms",
      "Viktor Zamaraev"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2206.02872"
  },
  {
    "id": "arXiv:2206.02873",
    "title": "No Parameter Left Behind: How Distillation and Model Size Affect  Zero-Shot Retrieval",
    "abstract": "Recent work has shown that small distilled language models are strong\ncompetitors to models that are orders of magnitude larger and slower in a wide\nrange of information retrieval tasks. This has made distilled and dense models,\ndue to latency constraints, the go-to choice for deployment in real-world\nretrieval applications. In this work, we question this practice by showing that\nthe number of parameters and early query-document interaction play a\nsignificant role in the generalization ability of retrieval models. Our\nexperiments show that increasing model size results in marginal gains on\nin-domain test sets, but much larger gains in new domains never seen during\nfine-tuning. Furthermore, we show that rerankers largely outperform dense ones\nof similar size in several tasks. Our largest reranker reaches the state of the\nart in 12 of the 18 datasets of the Benchmark-IR (BEIR) and surpasses the\nprevious state of the art by 3 average points. Finally, we confirm that\nin-domain effectiveness is not a good indicator of zero-shot effectiveness.\nCode is available at\nhttps://github.com/guilhermemr04/scaling-zero-shot-retrieval.git",
    "descriptor": "",
    "authors": [
      "Guilherme Moraes Rosa",
      "Luiz Bonifacio",
      "Vitor Jeronymo",
      "Hugo Abonizio",
      "Marzieh Fadaee",
      "Roberto Lotufo",
      "Rodrigo Nogueira"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2206.02873"
  },
  {
    "id": "arXiv:2206.02874",
    "title": "Dissecting Tensor Cores via Microbenchmarks: Latency, Throughput and  Numerical Behaviors",
    "abstract": "Tensor Cores have been an important unit to accelerate Fused Matrix\nMultiplication Accumulation (MMA) in all NVIDIA GPUs since Volta Architecture.\nTo program Tensor Cores, users have to use either legacy wmma APIs or current\nmma APIs. Legacy wmma APIs are more easy-to-use but can only exploit limited\nfeatures and power of Tensor Cores. Specifically, wmma APIs support fewer\noperand shapes and can not leverage the new sparse matrix multiplication\nfeature of the newest Ampere Tensor Cores. However, the performance of current\nprogramming interface has not been well explored. Furthermore, the computation\nnumeric behaviors of low-precision floating points (TF32, BF16 and FP16)\nsupported by newest Ampere Tensor Cores are also mysterious. In this paper, we\nexplore the throughput and latency of current programming APIs. We also\nintuitively study the numeric behaviors of Tensor Cores MMA and profile the\nintermediate operations including multiplication, addition of inner product and\naddition of accumulation.",
    "descriptor": "",
    "authors": [
      "Wei Sun",
      "Ang Li",
      "Tong Geng",
      "Sander Stuijk",
      "Henk Corporaal"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2206.02874"
  },
  {
    "id": "arXiv:2206.02876",
    "title": "SpikiLi: A Spiking Simulation of LiDAR based Real-time Object Detection  for Autonomous Driving",
    "abstract": "Spiking Neural Networks are a recent and new neural network design approach\nthat promises tremendous improvements in power efficiency, computation\nefficiency, and processing latency. They do so by using asynchronous\nspike-based data flow, event-based signal generation, processing, and modifying\nthe neuron model to resemble biological neurons closely. While some initial\nworks have shown significant initial evidence of applicability to common deep\nlearning tasks, their applications in complex real-world tasks has been\nrelatively low. In this work, we first illustrate the applicability of spiking\nneural networks to a complex deep learning task namely Lidar based 3D object\ndetection for automated driving. Secondly, we make a step-by-step demonstration\nof simulating spiking behavior using a pre-trained convolutional neural\nnetwork. We closely model essential aspects of spiking neural networks in\nsimulation and achieve equivalent run-time and accuracy on a GPU. When the\nmodel is realized on a neuromorphic hardware, we expect to have significantly\nimproved power efficiency.",
    "descriptor": "\nComments: Accepted at Workshop on Event Sensing and Neuromorphic Engineering - 8th International Conference on Event-based Control, Communication, and Signal Processing\n",
    "authors": [
      "Sambit Mohapatra",
      "Thomas Mesquida",
      "Mona Hodaei",
      "Senthil Yogamani",
      "Heinrich Gotzig",
      "Patrick Mader"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.02876"
  },
  {
    "id": "arXiv:2206.02878",
    "title": "TPP: Transparent Page Placement for CXL-Enabled Tiered Memory",
    "abstract": "With increasing memory demands for datacenter applications and the emergence\nof coherent interfaces like CXL that enable main memory expansion, we are about\nto observe a wide adoption of tiered-memory subsystems in hyperscalers. In such\nsystems, main memory can constitute different memory technologies with varied\nperformance characteristics. In this paper, we characterize the memory usage of\na wide range of datacenter applications across the server fleet of a\nhyperscaler (Meta) to get insights into an application's memory access patterns\nand performance on a tiered memory system. Our characterizations show that\ndatacenter applications can benefit from tiered memory systems as there exist\nopportunities for offloading colder pages to slower memory tiers. Without\nefficient memory management, however, such systems can significantly degrade\nperformance.\nWe propose a novel OS-level application-transparent page placement mechanism\n(TPP) for efficient memory management. TPP employs a lightweight mechanism to\nidentify and place hot and cold pages to appropriate memory tiers. It enables\npage allocation to work independently from page reclamation logic that is,\notherwise, tightly coupled in today's Linux kernel. As a result, the local\nmemory tier has memory headroom for new allocations. At the same time, TPP can\npromptly promote performance-critical hot pages trapped in the slow memory\ntiers to the fast tier node. Both promotion and demotion mechanisms work\ntransparently without any prior knowledge of an application's memory access\nbehavior. We evaluate TPP with diverse workloads that consume significant\nportions of DRAM on Meta's server fleet and are sensitive to memory subsystem\nperformance. TPP's efficient page placement improves Linux's performance by up\nto 18%. TPP outperforms NUMA balancing and AutoTiering, state-of-the-art\nsolutions for tiered memory, by 10-17%.",
    "descriptor": "",
    "authors": [
      "Hasan Al Maruf",
      "Hao Wang",
      "Abhishek Dhanotia",
      "Johannes Weiner",
      "Niket Agarwal",
      "Pallab Bhattacharya",
      "Chris Petersen",
      "Mosharaf Chowdhury",
      "Shobhit Kanaujia",
      "Prakash Chauhan"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Operating Systems (cs.OS)"
    ],
    "url": "https://arxiv.org/abs/2206.02878"
  },
  {
    "id": "arXiv:2206.02880",
    "title": "A Learning- and Scenario-based MPC Design for Nonlinear Systems in LPV  Framework with Safety and Stability Guarantees",
    "abstract": "This paper presents a learning- and scenario-based model predictive control\n(MPC) design approach for systems modeled in linear parameter-varying (LPV)\nframework. Using input-output data collected from the system, a state-space LPV\nmodel with uncertainty quantification is first learned through the variational\nBayesian inference Neural Network (BNN) approach. The learned probabilistic\nmodel is assumed to contain the true dynamics of the system with a high\nprobability and used to generate scenarios which ensure safety for a\nscenario-based MPC. Moreover, to guarantee stability and enhance performance of\nthe closed-loop system, a parameter-dependent terminal cost and controller, as\nwell as a terminal robust positive invariant set are designed. Numerical\nexamples will be used to demonstrate that the proposed control design approach\ncan ensure safety and achieve desired control performance.",
    "descriptor": "\nComments: Under review of European Journal of Control\n",
    "authors": [
      "Yajie Bao",
      "Hossam S. Abbas",
      "Javad Mohammadpour Velni"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.02880"
  },
  {
    "id": "arXiv:2206.02881",
    "title": "Mesh-based Dynamics with Occlusion Reasoning for Cloth Manipulation",
    "abstract": "Self-occlusion is challenging for cloth manipulation, as it makes it\ndifficult to estimate the full state of the cloth. Ideally, a robot trying to\nunfold a crumpled or folded cloth should be able to reason about the cloth's\noccluded regions. We leverage recent advances in pose estimation for cloth to\nbuild a system that uses explicit occlusion reasoning to unfold a crumpled\ncloth. Specifically, we first learn a model to reconstruct the mesh of the\ncloth. However, the model will likely have errors due to the complexities of\nthe cloth configurations and due to ambiguities from occlusions. Our main\ninsight is that we can further refine the predicted reconstruction by\nperforming test-time finetuning with self-supervised losses. The obtained\nreconstructed mesh allows us to use a mesh-based dynamics model for planning\nwhile reasoning about occlusions. We evaluate our system both on cloth\nflattening as well as on cloth canonicalization, in which the objective is to\nmanipulate the cloth into a canonical pose. Our experiments show that our\nmethod significantly outperforms prior methods that do not explicitly account\nfor occlusions or perform test-time optimization.",
    "descriptor": "\nComments: RSS 2022\n",
    "authors": [
      "Zixuan Huang",
      "Xingyu Lin",
      "David Held"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02881"
  },
  {
    "id": "arXiv:2206.02882",
    "title": "Length preserving numerical schemes for Landau-Lifshitz equation based  on Lagrange multiplier approaches",
    "abstract": "We develop in this paper two classes of length preserving schemes for the\nLandau-Lifshitz equation based on two different Lagrange multiplier approaches.\nIn the first approach, the Lagrange multiplier $\\lambda(\\bx,t)$ equals to\n$|\\nabla m(\\bx,t)|^2$ at the continuous level, while in the second approach,\nthe Lagrange multiplier $\\lambda(\\bx,t)$ is introduced to enforce the length\nconstraint at the discrete level and is identically zero at the continuous\nlevel. By using a predictor-corrector approach, we construct efficient and\nrobust length preserving higher-order schemes for the Landau-Lifshitz equation,\nwith the computational cost dominated by the predictor step which is simply a\nsemi-implicit scheme. Furthermore, by introducing another space-independent\nLagrange multiplier, we construct energy dissipative, in addition to length\npreserving, schemes for the Landau-Lifshitz equation, at the expense of solving\none nonlinear algebraic equation. We present ample numerical experiments to\nvalidate the stability and accuracy for the proposed schemes, and also provide\na performance comparison with some existing schemes.",
    "descriptor": "",
    "authors": [
      "Qing Cheng",
      "Jie Shen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.02882"
  },
  {
    "id": "arXiv:2206.02883",
    "title": "Lane-Level Route Planning for Autonomous Vehicles",
    "abstract": "We present an algorithm that, given a representation of a road network in\nlane-level detail, computes a route that minimizes the expected cost to reach a\ngiven destination. In doing so, our algorithm allows us to solve for the\ncomplex trade-offs encountered when trying to decide not just which roads to\nfollow, but also when to change between the lanes making up these roads, in\norder to -- for example -- reduce the likelihood of missing a left exit while\nnot unnecessarily driving in the leftmost lane. This routing problem can\nnaturally be formulated as a Markov Decision Process (MDP), in which lane\nchange actions have stochastic outcomes. However, MDPs are known to be\ntime-consuming to solve in general. In this paper, we show that -- under\nreasonable assumptions -- we can use a Dijkstra-like approach to solve this\nstochastic problem, and benefit from its efficient $O(n \\log n)$ running time.\nThis enables an autonomous vehicle to exhibit natural lane-selection behavior\nas it efficiently plans an optimal route to its destination.",
    "descriptor": "\nComments: To appear at the 15th International Workshop on the Algorithmic Foundations of Robotics (WAFR) 2022\n",
    "authors": [
      "Mitchell Jones",
      "Maximilian Haas-Heger",
      "Jur van den Berg"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.02883"
  },
  {
    "id": "arXiv:2206.02885",
    "title": "Norm Participation Grounds Language",
    "abstract": "The striking recent advances in eliciting seemingly meaningful language\nbehaviour from language-only machine learning models have only made more\napparent, through the surfacing of clear limitations, the need to go beyond the\nlanguage-only mode and to ground these models \"in the world\". Proposals for\ndoing so vary in the details, but what unites them is that the solution is\nsought in the addition of non-linguistic data types such as images or video\nstreams, while largely keeping the mode of learning constant. I propose a\ndifferent, and more wide-ranging conception of how grounding should be\nunderstood: What grounds language is its normative nature. There are standards\nfor doing things right, these standards are public and authoritative, while at\nthe same time acceptance of authority can and must be disputed and negotiated,\nin interactions in which only bearers of normative status can rightfully\nparticipate. What grounds language, then, is the determined use that language\nusers make of it, and what it is grounded in is the community of language\nusers. I sketch this idea, and draw some conclusions for work on computational\nmodelling of meaningful language use.",
    "descriptor": "",
    "authors": [
      "David Schlangen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.02885"
  },
  {
    "id": "arXiv:2206.02886",
    "title": "Graph Rationalization with Environment-based Augmentations",
    "abstract": "Rationale is defined as a subset of input features that best explains or\nsupports the prediction by machine learning models. Rationale identification\nhas improved the generalizability and interpretability of neural networks on\nvision and language data. In graph applications such as molecule and polymer\nproperty prediction, identifying representative subgraph structures named as\ngraph rationales plays an essential role in the performance of graph neural\nnetworks. Existing graph pooling and/or distribution intervention methods\nsuffer from lack of examples to learn to identify optimal graph rationales. In\nthis work, we introduce a new augmentation operation called environment\nreplacement that automatically creates virtual data examples to improve\nrationale identification. We propose an efficient framework that performs\nrationale-environment separation and representation learning on the real and\naugmented examples in latent spaces to avoid the high complexity of explicit\ngraph decoding and encoding. Comparing against recent techniques, experiments\non seven molecular and four polymer real datasets demonstrate the effectiveness\nand efficiency of the proposed augmentation-based graph rationalization\nframework.",
    "descriptor": "\nComments: Accepted by KDD 2022\n",
    "authors": [
      "Gang Liu",
      "Tong Zhao",
      "Jiaxin Xu",
      "Tengfei Luo",
      "Meng Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02886"
  },
  {
    "id": "arXiv:2206.02887",
    "title": "Sample Complexity of Nonparametric Off-Policy Evaluation on  Low-Dimensional Manifolds using Deep Networks",
    "abstract": "We consider the off-policy evaluation problem of reinforcement learning using\ndeep neural networks. We analyze the deep fitted Q-evaluation method for\nestimating the expected cumulative reward of a target policy, when the data are\ngenerated from an unknown behavior policy. We show that, by choosing network\nsize appropriately, one can leverage the low-dimensional manifold structure in\nthe Markov decision process and obtain a sample-efficient estimator without\nsuffering from the curse of high representation dimensionality. Specifically,\nwe establish a sharp error bound for the fitted Q-evaluation that depends on\nthe intrinsic low dimension, the smoothness of the state-action space, and a\nfunction class-restricted $\\chi^2$-divergence. It is noteworthy that the\nrestricted $\\chi^2$-divergence measures the behavior and target policies' {\\it\nmismatch in the function space}, which can be small even if the two policies\nare not close to each other in their tabular forms. Numerical experiments are\nprovided to support our theoretical analysis.",
    "descriptor": "",
    "authors": [
      "Xiang Ji",
      "Minshuo Chen",
      "Mengdi Wang",
      "Tuo Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.02887"
  },
  {
    "id": "arXiv:2206.02891",
    "title": "A Justice-Based Framework for the Analysis of Algorithmic  Fairness-Utility Trade-Offs",
    "abstract": "In prediction-based decision-making systems, different perspectives can be at\nodds: The short-term business goals of the decision makers are often in\nconflict with the decision subjects' wish to be treated fairly. Balancing these\ntwo perspectives is a question of values. We provide a framework to make these\nvalue-laden choices clearly visible. For this, we assume that we are given a\ntrained model and want to find decision rules that balance the perspective of\nthe decision maker and of the decision subjects. We provide an approach to\nformalize both perspectives, i.e., to assess the utility of the decision maker\nand the fairness towards the decision subjects. In both cases, the idea is to\nelicit values from decision makers and decision subjects that are then turned\ninto something measurable. For the fairness evaluation, we build on the\nliterature on welfare-based fairness and ask what a fair distribution of\nutility (or welfare) looks like. In this step, we build on well-known theories\nof distributive justice. This allows us to derive a fairness score that we then\ncompare to the decision maker's utility for many different decision rules. This\nway, we provide an approach for balancing the utility of the decision maker and\nthe fairness towards the decision subjects for a prediction-based\ndecision-making system.",
    "descriptor": "",
    "authors": [
      "Corinna Hertweck",
      "Joachim Baumann",
      "Michele Loi",
      "Eleonora Vigan\u00f2",
      "Christoph Heitz"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02891"
  },
  {
    "id": "arXiv:2206.02892",
    "title": "Discriminative Models Can Still Outperform Generative Models in Aspect  Based Sentiment Analysis",
    "abstract": "Aspect-based Sentiment Analysis (ABSA) helps to explain customers' opinions\ntowards products and services. In the past, ABSA models were discriminative,\nbut more recently generative models have been used to generate aspects and\npolarities directly from text. In contrast, discriminative models commonly\nfirst select aspects from the text, and then classify the aspect's polarity.\nPrevious results showed that generative models outperform discriminative models\non several English ABSA datasets. Here, we evaluate and contrast two\nstate-of-the-art discriminative and generative models in several settings:\ncross-lingual, cross-domain, and cross-lingual and domain, to understand\ngeneralizability in settings other than English mono-lingual in-domain. Our\nmore thorough evaluation shows that, contrary to previous studies,\ndiscriminative models can still outperform generative models in almost all\nsettings.",
    "descriptor": "",
    "authors": [
      "Dhruv Mullick",
      "Alona Fyshe",
      "Bilal Ghanem"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.02892"
  },
  {
    "id": "arXiv:2206.02894",
    "title": "ASAP: Reconciling Asynchronous Real-Time Operations and Proofs of  Execution in Simple Embedded Systems",
    "abstract": "Embedded devices are increasingly ubiquitous and their importance is hard to\noverestimate. While they often support safety-critical functions (e.g., in\nmedical devices and sensor-alarm combinations), they are usually implemented\nunder strict cost/energy budgets, using low-end microcontroller units (MCUs)\nthat lack sophisticated security mechanisms. Motivated by this issue, recent\nwork developed architectures capable of generating Proofs of Execution (PoX)\nfor the correct/expected software in potentially compromised low-end MCUs. In\npractice, this capability can be leveraged to provide \"integrity from birth\" to\nsensor data, by binding the sensed results/outputs to an unforgeable\ncryptographic proof of execution of the expected sensing process. Despite this\nsignificant progress, current PoX schemes for low-end MCUs ignore the real-time\nneeds of many applications. In particular, security of current PoX schemes\nprecludes any interrupts during the execution being proved. We argue that lack\nof asynchronous capabilities (i.e., interrupts within PoX) can obscure PoX\nusefulness, as several applications require processing real-time and\nasynchronous events. To bridge this gap, we propose, implement, and evaluate an\nArchitecture for Secure Asynchronous Processing in PoX (ASAP). ASAP is secure\nunder full software compromise, enables asynchronous PoX, and incurs less\nhardware overhead than prior work.",
    "descriptor": "\nComments: 2022 59th ACM/IEEE Design Automation Conference (DAC)\n",
    "authors": [
      "Adam Caulfield",
      "Norrathep Rattanavipanon",
      "Ivan De Oliveira Nunes"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2206.02894"
  },
  {
    "id": "arXiv:2206.02897",
    "title": "Distributive Justice as the Foundational Premise of Fair ML:  Unification, Extension, and Interpretation of Group Fairness Metrics",
    "abstract": "Group fairness metrics are an established way of assessing the fairness of\nprediction-based decision-making systems. However, these metrics are still\ninsufficiently linked to philosophical theories, and their moral meaning is\noften unclear. We propose a general framework for analyzing the fairness of\ndecision systems based on theories of distributive justice, encompassing\ndifferent established ``patterns of justice'' that correspond to different\nnormative positions. We show that the most popular group fairness metrics can\nbe interpreted as special cases of our approach. Thus, we provide a unifying\nand interpretative framework for group fairness metrics that reveals the\nnormative choices associated with each of them and that allows understanding\ntheir moral substance. At the same time, we provide an extension of the space\nof possible fairness metrics beyond the ones currently discussed in the fair ML\nliterature. Our framework also allows overcoming several limitations of group\nfairness metrics that have been criticized in the literature, most notably (1)\nthat they are parity-based, i.e., that they demand some form of equality\nbetween groups, which may sometimes be harmful to marginalized groups, (2) that\nthey only compare decisions across groups, but not the resulting consequences\nfor these groups, and (3) that the full breadth of the distributive justice\nliterature is not sufficiently represented.",
    "descriptor": "",
    "authors": [
      "Joachim Baumann",
      "Corinna Hertweck",
      "Michele Loi",
      "Christoph Heitz"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02897"
  },
  {
    "id": "arXiv:2206.02902",
    "title": "Goal-Space Planning with Subgoal Models",
    "abstract": "This paper investigates a new approach to model-based reinforcement learning\nusing background planning: mixing (approximate) dynamic programming updates and\nmodel-free updates, similar to the Dyna architecture. Background planning with\nlearned models is often worse than model-free alternatives, such as Double DQN,\neven though the former uses significantly more memory and computation. The\nfundamental problem is that learned models can be inaccurate and often generate\ninvalid states, especially when iterated many steps. In this paper, we avoid\nthis limitation by constraining background planning to a set of (abstract)\nsubgoals and learning only local, subgoal-conditioned models. This goal-space\nplanning (GSP) approach is more computationally efficient, naturally\nincorporates temporal abstraction for faster long-horizon planning and avoids\nlearning the transition dynamics entirely. We show that our GSP algorithm can\nlearn significantly faster than a Double DQN baseline in a variety of\nsituations.",
    "descriptor": "",
    "authors": [
      "Chunlok Lo",
      "Gabor Mihucz",
      "Adam White",
      "Farzane Aminmansour",
      "Martha White"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02902"
  },
  {
    "id": "arXiv:2206.02903",
    "title": "Polymorphic-GAN: Generating Aligned Samples across Multiple Domains with  Learned Morph Maps",
    "abstract": "Modern image generative models show remarkable sample quality when trained on\na single domain or class of objects. In this work, we introduce a generative\nadversarial network that can simultaneously generate aligned image samples from\nmultiple related domains. We leverage the fact that a variety of object classes\nshare common attributes, with certain geometric differences. We propose\nPolymorphic-GAN which learns shared features across all domains and a\nper-domain morph layer to morph shared features according to each domain. In\ncontrast to previous works, our framework allows simultaneous modelling of\nimages with highly varying geometries, such as images of human faces, painted\nand artistic faces, as well as multiple different animal faces. We demonstrate\nthat our model produces aligned samples for all domains and show how it can be\nused for applications such as segmentation transfer and cross-domain image\nediting, as well as training in low-data regimes. Additionally, we apply our\nPolymorphic-GAN on image-to-image translation tasks and show that we can\ngreatly surpass previous approaches in cases where the geometric differences\nbetween domains are large.",
    "descriptor": "\nComments: CVPR 2022 Oral\n",
    "authors": [
      "Seung Wook Kim",
      "Karsten Kreis",
      "Daiqing Li",
      "Antonio Torralba",
      "Sanja Fidler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02903"
  },
  {
    "id": "arXiv:2206.02904",
    "title": "The Creativity of Text-based Generative Art",
    "abstract": "Text-based generation of digital images has made a giant leap towards\nbecoming a mainstream phenomenon. With text-based generative systems, anybody\ncan create digital images and artworks. This raises the question of whether\ntext-based generative art is creative. This paper expounds on the nature of\nhuman creativity involved in text-based generative art with a specific focus on\nthe practice of prompt engineering, drawing on Rhodes's conceptual model of\ncreativity. The paper critiques the current product-centered view of creativity\nwhich may fall short in the context of text-based generative art. An case\nexemplifying this shortcoming is provided and future opportunities for research\non text-based generative art are outlined.",
    "descriptor": "",
    "authors": [
      "Jonas Oppenlaender"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2206.02904"
  },
  {
    "id": "arXiv:2206.02905",
    "title": "Adjoint-based Adaptive Multi-Level Monte Carlo for Differential  Equations",
    "abstract": "We present a multi-level Monte Carlo (MLMC) algorithm with adaptively refined\nmeshes and accurately computed stopping-criteria utilizing adjoint-based a\nposteriori error analysis for differential equations. This is in contrast to\nclassical MLMC algorithms that use either a hierarchy of uniform meshes or\nadaptively refined meshes based on Richardson extrapolation, and employ a\nstopping criteria that relies on assumptions on the convergence rate of the\nMLMC levels. This work develops two adaptive refinement strategies for the MLMC\nalgorithm. These strategies are based on a decomposition of an error estimate\nof the MLMC bias and utilize variational analysis, adjoint problems and\ncomputable residuals.",
    "descriptor": "",
    "authors": [
      "Jehanzeb Chaudhry",
      "Zachary Stevens"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.02905"
  },
  {
    "id": "arXiv:2206.02906",
    "title": "Managing Bufferbloat in Storage Systems",
    "abstract": "Today, companies and data centers are moving towards distributed and\nserverless storage systems instead of traditional file systems. As a result of\nsuch transition, allocating sufficient resources to users and parties to\nsatisfy their service level demands has become crucial in distributed storage\nsystems. The Quality of Service (QoS) is a research area that tries to tackle\nsuch challenges. The schedulability of system components and requests is of\ngreat importance to achieve the QoS goals in a distributed storage. Many QoS\nsolutions are designed and implemented through request scheduling at different\nlevels of system architecture.\nHowever, the bufferbloat phenomenon in storage backends can compromise the\nrequest schedulability of the system. In a storage server, bufferbloat happens\nwhen the server submits all requests immediately to the storage backend due to\na too large buffer in the storage backend. In recent decades, many research\nworks tried to solve the bufferbloat problem for network systems.\nNevertheless, none of these works are suitable for storage system\nenvironments and workloads. This paper presents the SF_CoDel algorithm, an\nadaptive extension of the Controlled Delay (CoDel) algorithm, to mitigate the\nbufferbloat for different workloads in storage systems. SF_CoDel manages this\npurpose by controlling the amount of work submitted to the storage backend. The\nevaluation of our algorithm indicates that SF_CoDel can mitigate the\nbufferbloat in storage servers.",
    "descriptor": "",
    "authors": [
      "Esmaeil Mirvakili",
      "Samuel Just",
      "Carlos Maltzahn"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.02906"
  },
  {
    "id": "arXiv:2206.02911",
    "title": "Boundary informed inverse PDE problems on discrete Riemann surfaces",
    "abstract": "We employ neural networks to tackle inverse partial differential equations on\ndiscretized Riemann surfaces with boundary. To this end, we introduce the\nconcept of a graph with boundary which models these surfaces in a natural way.\nOur method uses a message passing technique to keep track of an unknown\ndifferential operator while using neural ODE solvers through the method of\nlines to capture the evolution in time. As training data, we use noisy and\nincomplete observations of sheaves on graphs at various timestamps. The novelty\nof this approach is in working with manifolds with nontrivial topology and\nutilizing the data on the graph boundary through a teacher forcing technique.\nDespite the increasing interest in learning dynamical systems from finite\nobservations, many current methods are limited in two general ways: first, they\nwork with topologically trivial spaces, and second, they fail to handle the\nboundary data on the ground space in a systematic way. The present work is an\nattempt at addressing these limitations. We run experiments with synthetic data\nof linear and nonlinear diffusion systems on orientable surfaces with positive\ngenus and boundary, and moreover, provide evidences for improvements upon the\nexisting paradigms.",
    "descriptor": "",
    "authors": [
      "Mehdi Garrousian",
      "Amirhossein Nouranizadeh"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02911"
  },
  {
    "id": "arXiv:2206.02912",
    "title": "Learning Treatment Plan Representations for Content Based Image  Retrieval",
    "abstract": "Objective: Knowledge based planning (KBP) typically involves training an\nend-to-end deep learning model to predict dose distributions. However, training\nend-to-end KBP methods may be associated with practical limitations due to the\nlimited size of medical datasets that are often used. To address these\nlimitations, we propose a content based image retrieval (CBIR) method for\nretrieving dose distributions of previously planned patients based on\nanatomical similarity. Approach: Our proposed CBIR method trains a\nrepresentation model that produces latent space embeddings of a patient's\nanatomical information. The latent space embeddings of new patients are then\ncompared against those of previous patients in a database for image retrieval\nof dose distributions. Summary metrics (e.g. dose-volume histogram, conformity\nindex, homogeneity index, etc.) are computed and can then be utilized in\nsubsequent automated planning. All source code for this project is available on\ngithub. Main Results: The retrieval performance of various CBIR methods is\nevaluated on a dataset consisting of both publicly available plans and clinical\nplans from our institution. This study compares various encoding methods,\nranging from simple autoencoders to more recent Siamese networks like SimSiam,\nand the best performance was observed for the multitask Siamese network.\nSignificance: Applying CBIR to inform subsequent treatment planning potentially\naddresses many limitations associated with end-to-end KBP. Our current results\ndemonstrate that excellent image retrieval performance can be obtained through\nslight changes to previously developed Siamese networks. We hope to integrate\nCBIR into automated planning workflow in future works, potentially through\nmethods like the MetaPlanner framework.",
    "descriptor": "",
    "authors": [
      "Charles Huang",
      "Varun Vasudevan",
      "Oscar Pastor-Serrano",
      "Md Tauhidul Islam",
      "Yusuke Nomura",
      "Yong Yang",
      "Lei Xing"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.02912"
  },
  {
    "id": "arXiv:2206.02915",
    "title": "8-bit Numerical Formats for Deep Neural Networks",
    "abstract": "Given the current trend of increasing size and complexity of machine learning\narchitectures, it has become of critical importance to identify new approaches\nto improve the computational efficiency of model training. In this context, we\naddress the advantages of floating-point over fixed-point representation, and\npresent an in-depth study on the use of 8-bit floating-point number formats for\nactivations, weights, and gradients for both training and inference. We explore\nthe effect of different bit-widths for exponents and significands and different\nexponent biases. The experimental results demonstrate that a suitable choice of\nthese low-precision formats enables faster training and reduced power\nconsumption without any degradation in accuracy for a range of deep learning\nmodels for image classification and language processing.",
    "descriptor": "",
    "authors": [
      "Badreddine Noune",
      "Philip Jones",
      "Daniel Justus",
      "Dominic Masters",
      "Carlo Luschi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02915"
  },
  {
    "id": "arXiv:2206.02916",
    "title": "Remember the Past: Distilling Datasets into Addressable Memories for  Neural Networks",
    "abstract": "We propose an algorithm that compresses the critical information of a large\ndataset into compact addressable memories. These memories can then be recalled\nto quickly re-train a neural network and recover the performance (instead of\nstoring and re-training on the full original dataset).\nBuilding upon the dataset distillation framework, we make a key observation\nthat a shared common representation allows for more efficient and effective\ndistillation. Concretely, we learn a set of bases (aka \"memories\") which are\nshared between classes and combined through learned flexible addressing\nfunctions to generate a diverse set of training examples. This leads to several\nbenefits: 1) the size of compressed data does not necessarily grow linearly\nwith the number of classes; 2) an overall higher compression rate with more\neffective distillation is achieved; and 3) more generalized queries are allowed\nbeyond recalling the original classes.\nWe demonstrate state-of-the-art results on the dataset distillation task\nacross five benchmarks, including up to 16.5% and 9.7% in retained accuracy\nimprovement when distilling CIFAR10 and CIFAR100 respectively. We then leverage\nour framework to perform continual learning, achieving state-of-the-art results\non four benchmarks, with 23.2% accuracy improvement on MANY.",
    "descriptor": "",
    "authors": [
      "Zhiwei Deng",
      "Olga Russakovsky"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02916"
  },
  {
    "id": "arXiv:2206.02921",
    "title": "Schema-Guided Event Graph Completion",
    "abstract": "We tackle a new task, event graph completion, which aims to predict missing\nevent nodes for event graphs. Existing link prediction or graph completion\nmethods have difficulty dealing with event graphs because they are usually\ndesigned for a single large graph such as a social network or a knowledge\ngraph, rather than multiple small dynamic event graphs. Moreover, they can only\npredict missing edges rather than missing nodes. In this work, we propose to\nutilize event schema, a template that describes the stereotypical structure of\nevent graphs, to address the above issues. Our schema-guided event graph\ncompletion approach first maps an instance event graph to a subgraph of the\nschema graph by a heuristic subgraph matching algorithm. Then it predicts\nwhether a candidate event node in the schema graph should be added to the\ninstantiated schema subgraph by characterizing two types of local topology of\nthe schema graph: neighbors of the candidate node and the subgraph, and paths\nthat connect the candidate node and the subgraph. These two modules are later\ncombined together for the final prediction. We also propose a self-supervised\nstrategy to construct training samples, as well as an inference algorithm that\nis specifically designed to complete event graphs. Extensive experimental\nresults on four datasets demonstrate that our proposed method achieves\nstate-of-the-art performance, with 4.3% to 19.4% absolute F1 gains over the\nbest baseline method on the four datasets.",
    "descriptor": "",
    "authors": [
      "Hongwei Wang",
      "Zixuan Zhang",
      "Sha Li",
      "Jiawei Han",
      "Yizhou Sun",
      "Hanghang Tong",
      "Joseph P. Olive",
      "Heng Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.02921"
  },
  {
    "id": "arXiv:2206.02923",
    "title": "Understanding Machine Learning Practitioners' Data Documentation  Perceptions, Needs, Challenges, and Desiderata",
    "abstract": "Data is central to the development and evaluation of machine learning (ML)\nmodels. However, the use of problematic or inappropriate datasets can result in\nharms when the resulting models are deployed. To encourage responsible AI\npractice through more deliberate reflection on datasets and transparency around\nthe processes by which they are created, researchers and practitioners have\nbegun to advocate for increased data documentation and have proposed several\ndata documentation frameworks. However, there is little research on whether\nthese data documentation frameworks meet the needs of ML practitioners, who\nboth create and consume datasets. To address this gap, we set out to understand\nML practitioners' data documentation perceptions, needs, challenges, and\ndesiderata, with the goal of deriving design requirements that can inform\nfuture data documentation frameworks. We conducted a series of semi-structured\ninterviews with 14 ML practitioners at a single large, international technology\ncompany. We had them answer a list of questions taken from datasheets for\ndatasets (Gebru, 2021). Our findings show that current approaches to data\ndocumentation are largely ad hoc and myopic in nature. Participants expressed\nneeds for data documentation frameworks to be adaptable to their contexts,\nintegrated into their existing tools and workflows, and automated wherever\npossible. Despite the fact that data documentation frameworks are often\nmotivated from the perspective of responsible AI, participants did not make the\nconnection between the questions that they were asked to answer and their\nresponsible AI implications. In addition, participants often had difficulties\nprioritizing the needs of dataset consumers and providing information that\nsomeone unfamiliar with their datasets might need to know. Based on these\nfindings, we derive seven design requirements for future data documentation\nframeworks.",
    "descriptor": "",
    "authors": [
      "Amy Heger",
      "Elizabeth B. Marquis",
      "Mihaela Vorvoreanu",
      "Hanna Wallach",
      "Jennifer Wortman Vaughan"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02923"
  },
  {
    "id": "arXiv:2206.02925",
    "title": "Tight basis cycle representatives for persistent homology of large data  sets",
    "abstract": "Persistent homology (PH) is a popular tool for topological data analysis that\nhas found applications across diverse areas of research. It provides a rigorous\nmethod to compute robust topological features in discrete experimental\nobservations that often contain various sources of uncertainties. Although\npowerful in theory, PH suffers from high computation cost that precludes its\napplication to large data sets. Additionally, most analyses using PH are\nlimited to computing the existence of nontrivial features. Precise localization\nof these features is not generally attempted because, by definition, localized\nrepresentations are not unique and because of even higher computation cost. For\nscientific applications, such a precise location is a sine qua non for\ndetermining functional significance. Here, we provide a strategy and algorithms\nto compute tight representative boundaries around nontrivial robust features in\nlarge data sets. To showcase the efficiency of our algorithms and the precision\nof computed boundaries, we analyze three data sets from different scientific\nfields. In the human genome, we found an unexpected effect on loops through\nchromosome 13 and the sex chromosomes, upon impairment of chromatin loop\nformation. In a distribution of galaxies in the universe, we found\nstatistically significant voids. In protein homologs with significantly\ndifferent topology, we found voids attributable to ligand-interaction,\nmutation, and differences between species.",
    "descriptor": "",
    "authors": [
      "Manu Aggarwal",
      "Vipul Periwal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02925"
  },
  {
    "id": "arXiv:2206.02928",
    "title": "Neuro-Symbolic Causal Language Planning with Commonsense Prompting",
    "abstract": "Language planning aims to implement complex high-level goals by decomposition\ninto sequential simpler low-level steps. Such procedural reasoning ability is\nessential for applications such as household robots and virtual assistants.\nAlthough language planning is a basic skill set for humans in daily life, it\nremains a challenge for large language models (LLMs) that lack deep-level\ncommonsense knowledge in the real world. Previous methods require either manual\nexemplars or annotated programs to acquire such ability from LLMs. In contrast,\nthis paper proposes Neuro-Symbolic Causal Language Planner (CLAP) that elicits\nprocedural knowledge from the LLMs with commonsense-infused prompting.\nPre-trained knowledge in LLMs is essentially an unobserved confounder that\ncauses spurious correlations between tasks and action plans. Through the lens\nof a Structural Causal Model (SCM), we propose an effective strategy in CLAP to\nconstruct prompts as a causal intervention toward our SCM. Using graph sampling\ntechniques and symbolic program executors, our strategy formalizes the\nstructured causal prompts from commonsense knowledge bases. CLAP obtains\nstate-of-the-art performance on WikiHow and RobotHow, achieving a relative\nimprovement of 5.28% in human evaluations under the counterfactual setting.\nThis indicates the superiority of CLAP in causal language planning semantically\nand sequentially.",
    "descriptor": "",
    "authors": [
      "Yujie Lu",
      "Weixi Feng",
      "Wanrong Zhu",
      "Wenda Xu",
      "Xin Eric Wang",
      "Miguel Eckstein",
      "William Yang Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02928"
  },
  {
    "id": "arXiv:2206.02929",
    "title": "$\\mathcal{L}_2$-optimal Reduced-order Modeling Using Parameter-separable  Forms",
    "abstract": "We provide a unifying framework for $\\mathcal{L}_2$-optimal reduced-order\nmodeling for linear time-invariant dynamical systems and stationary parametric\nproblems. Using parameter-separable forms of the reduced-model quantities, we\nderive the gradients of the $\\mathcal{L}_2$ cost function with respect to the\nreduced matrices, which then allows a non-intrusive, data-driven,\ngradient-based descent algorithm to construct the optimal approximant using\nonly output samples. By choosing an appropriate measure, the framework covers\nboth continuous (Lebesgue) and discrete cost functions. We show the efficacy of\nthe proposed algorithm via various numerical examples. Furthermore, we analyze\nunder what conditions the data-driven approximant can be obtained via\nprojection.",
    "descriptor": "\nComments: 21 pages, 10 figures\n",
    "authors": [
      "Petar Mlinari\u0107",
      "Serkan Gugercin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.02929"
  },
  {
    "id": "arXiv:2206.02930",
    "title": "Predicting Electricity Infrastructure Induced Wildfire Risk in  California",
    "abstract": "This paper examines the use of risk models to predict the timing and location\nof wildfires caused by electricity infrastructure. Our data include historical\nignition and wire-down points triggered by grid infrastructure collected\nbetween 2015 to 2019 in Pacific Gas & Electricity territory along with various\nweather, vegetation, and very high resolution data on grid infrastructure\nincluding location, age, materials. With these data we explore a range of\nmachine learning methods and strategies to manage training data imbalance. The\nbest area under the receiver operating characteristic we obtain is 0.776 for\ndistribution feeder ignitions and 0.824 for transmission line wire-down events,\nboth using the histogram-based gradient boosting tree algorithm (HGB) with\nunder-sampling. We then use these models to identify which information provides\nthe most predictive value. After line length, we find that weather and\nvegetation features dominate the list of top important features for ignition or\nwire-down risk. Distribution ignition models show more dependence on\nslow-varying vegetation variables such as burn index, energy release content,\nand tree height, whereas transmission wire-down models rely more on primary\nweather variables such as wind speed and precipitation. These results point to\nthe importance of improved vegetation modeling for feeder ignition risk models,\nand improved weather forecasting for transmission wire-down models. We observe\nthat infrastructure features make small but meaningful improvements to risk\nmodel predictive power.",
    "descriptor": "",
    "authors": [
      "Mengqi Yao",
      "Meghana Bharadwaj",
      "Zheng Zhang",
      "Baihong Jin",
      "Duncan S. Callaway"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02930"
  },
  {
    "id": "arXiv:2206.02932",
    "title": "Symbolic Knowledge Structures and Intuitive Knowledge Structures",
    "abstract": "This paper proposes that two distinct types of structures are present in the\nbrain: Symbolic Knowledge Structures (SKSs), used for formal symbolic\nreasoning, and Intuitive Knowledge Structures (IKSs), used for drawing informal\nassociations. The paper contains ideas for modeling and analyzing these\nstructures in an algorithmic style based on Spiking Neural Networks, following\nthe paradigm used in earlier work by Lynch, Musco, Parter, and co-workers. The\npaper also contains two examples of use of these structures, involving counting\nthrough a memorized sequence, and understanding simple stylized sentences.\nThe ideas presented here are preliminary and speculative, and do not (yet)\ncomprise a complete, coherent, algorithmic theory. I hope that posting this\npreliminary version will help the ideas to evolve into such a theory.",
    "descriptor": "\nComments: 33 pages\n",
    "authors": [
      "Nancy Lynch"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.02932"
  },
  {
    "id": "arXiv:2206.02946",
    "title": "On the Convergence of Optimizing Persistent-Homology-Based Losses",
    "abstract": "Topological loss based on persistent homology has shown promise in various\napplications. A topological loss enforces the model to achieve certain desired\ntopological property. Despite its empirical success, less is known about the\noptimization behavior of the loss. In fact, the topological loss involves\ncombinatorial configurations that may oscillate during optimization. In this\npaper, we introduce a general purpose regularized topology-aware loss. We\npropose a novel regularization term and also modify existing topological loss.\nThese contributions lead to a new loss function that not only enforces the\nmodel to have desired topological behavior, but also achieves satisfying\nconvergence behavior. Our main theoretical result guarantees that the loss can\nbe optimized efficiently, under mild assumptions.",
    "descriptor": "",
    "authors": [
      "Yikai Zhang",
      "Jiachen Yao",
      "Yusu Wang",
      "Chao Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Geometry (cs.CG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.02946"
  },
  {
    "id": "arXiv:2206.02948",
    "title": "Simple Mechanisms for Welfare Maximization in Rich Advertising Auctions",
    "abstract": "Internet ad auctions have evolved from a few lines of text to richer\ninformational layouts that include images, sitelinks, videos, etc. Ads in these\nnew formats occupy varying amounts of space, and an advertiser can provide\nmultiple formats, only one of which can be shown. The seller is now faced with\na multi-parameter mechanism design problem. Computing an efficient allocation\nis computationally intractable, and therefore the standard\nVickrey-Clarke-Groves (VCG) auction, while truthful and welfare-optimal, is\nimpractical.\nIn this paper, we tackle a fundamental problem in the design of modern ad\nauctions. We adopt a ``Myersonian'' approach and study allocation rules that\nare monotone both in the bid and set of rich ads. We show that such rules can\nbe paired with a payment function to give a truthful auction. Our main\ntechnical challenge is designing a monotone rule that yields a good\napproximation to the optimal welfare. Monotonicity doesn't hold for standard\nalgorithms, e.g. the incremental bang-per-buck order, that give good\napproximations to ``knapsack-like'' problems such as ours. In fact, we show\nthat no deterministic monotone rule can approximate the optimal welfare within\na factor better than $2$ (while there is a non-monotone FPTAS). Our main result\nis a new, simple, greedy and monotone allocation rule that guarantees a $3$\napproximation.\nIn ad auctions in practice, monotone allocation rules are often paired with\nthe so-called Generalized Second Price (GSP) payment rule, which charges the\nminimum threshold price below which the allocation changes. We prove that, even\nthough our monotone allocation rule paired with GSP is not truthful, its Price\nof Anarchy (PoA) is bounded. Under standard no overbidding assumption, we prove\na pure PoA bound of $6$ and a Bayes-Nash PoA bound of $\\frac{6}{(1 -\n\\frac{1}{e})}$. Finally, we experimentally test our algorithms on real-world\ndata.",
    "descriptor": "",
    "authors": [
      "Gagan Aggarwal",
      "Kshipra Bhawalkar",
      "Aranyak Mehta",
      "Divyarthi Mohan",
      "Alexandros Psomas"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2206.02948"
  },
  {
    "id": "arXiv:2206.02950",
    "title": "A Continuum Approach for Collaborative Task Processing in UAV MEC  Networks",
    "abstract": "Unmanned aerial vehicles (UAVs) are becoming a viable platform for sensing\nand estimation in a wide variety of applications including disaster response,\nsearch and rescue, and security monitoring. These sensing UAVs have limited\nbattery and computational capabilities, and thus must offload their data so it\ncan be processed to provide actionable intelligence. We consider a compute\nplatform consisting of a limited number of highly-resourced UAVs that act as\nmobile edge computing (MEC) servers to process the workload on premises. We\npropose a novel distributed solution to the collaborative processing problem\nthat adaptively positions the MEC UAVs in response to the changing workload\nthat arises both from the sensing UAVs' mobility and the task generation. Our\nsolution consists of two key building blocks: (1) an efficient workload\nestimation process by which the UAVs estimate the task field - a continuous\napproximation of the number of tasks to be processed at each location in the\nairspace, and (2) a distributed optimization method by which the UAVs partition\nthe task field so as to maximize the system throughput. We evaluate our\nproposed solution using realistic models of surveillance UAV mobility and show\nthat our method achieves up to 28% improvement in throughput over a\nnon-adaptive baseline approach.",
    "descriptor": "",
    "authors": [
      "Lorson Blair",
      "Carlos A. Varela",
      "Stacy Patterson"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.02950"
  },
  {
    "id": "arXiv:2206.02951",
    "title": "A semi-conjugate gradient method for solving unsymmetric positive  definite linear systems",
    "abstract": "The conjugate gradient (CG) method is a classic Krylov subspace method for\nsolving symmetric positive definite linear systems. We introduce an analogous\nsemi-conjugate gradient (SCG) method for unsymmetric positive definite linear\nsystems. Unlike CG, SCG requires the solution of a lower triangular linear\nsystem to produce each semi-conjugate direction. We prove that SCG is\ntheoretically equivalent to the full orthogonalization method (FOM), which is\nbased on the Arnoldi process and converges in a finite number of steps. Because\nSCG's triangular system increases in size each iteration, we study a sliding\nwindow implementation (SWI) to improve efficiency, and show that the directions\nproduced are still locally semi-conjugate. A counterexample illustrates that\nSWI is different from the direct incomplete orthogonalization method (DIOM),\nwhich is FOM with a sliding window. Numerical experiments from the\nconvection-diffusion equation and other applications show that SCG is robust\nand that the sliding window implementation SWI allows SCG to solve large\nsystems efficiently.",
    "descriptor": "",
    "authors": [
      "Na Huang",
      "Yu-Hong Dai",
      "Dominique Orban",
      "Michael A Saunders"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.02951"
  },
  {
    "id": "arXiv:2206.02956",
    "title": "Robust Time Series Dissimilarity Measure for Outlier Detection and  Periodicity Detection",
    "abstract": "Dynamic time warping (DTW) is an effective dissimilarity measure in many time\nseries applications. Despite its popularity, it is prone to noises and\noutliers, which leads to singularity problem and bias in the measurement. The\ntime complexity of DTW is quadratic to the length of time series, making it\ninapplicable in real-time applications. In this paper, we propose a novel time\nseries dissimilarity measure named RobustDTW to reduce the effects of noises\nand outliers. Specifically, the RobustDTW estimates the trend and optimizes the\ntime warp in an alternating manner by utilizing our designed temporal graph\ntrend filtering. To improve efficiency, we propose a multi-level framework that\nestimates the trend and the warp function at a lower resolution, and then\nrepeatedly refines them at a higher resolution. Based on the proposed\nRobustDTW, we further extend it to periodicity detection and outlier time\nseries detection. Experiments on real-world datasets demonstrate the superior\nperformance of RobustDTW compared to DTW variants in both outlier time series\ndetection and periodicity detection.",
    "descriptor": "",
    "authors": [
      "Xiaomin Song",
      "Qingsong Wen",
      "Yan Li",
      "Liang Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2206.02956"
  },
  {
    "id": "arXiv:2206.02957",
    "title": "GRETEL: A unified framework for Graph Counterfactual Explanation  Evaluation",
    "abstract": "Machine Learning (ML) systems are a building part of the modern tools which\nimpact our daily life in several application domains. Due to their black-box\nnature, those systems are hardly adopted in application domains (e.g. health,\nfinance) where understanding the decision process is of paramount importance.\nExplanation methods were developed to explain how the ML model has taken a\nspecific decision for a given case/instance. Graph Counterfactual Explanations\n(GCE) is one of the explanation techniques adopted in the Graph Learning\ndomain. The existing works of Graph Counterfactual Explanations diverge mostly\nin the problem definition, application domain, test data, and evaluation\nmetrics, and most existing works do not compare exhaustively against other\ncounterfactual explanation techniques present in the literature. We present\nGRETEL, a unified framework to develop and test GCE methods in several\nsettings. GRETEL is a highly extensible evaluation framework which promotes the\nOpen Science and the evaluations reproducibility by providing a set of\nwell-defined mechanisms to integrate and manage easily: both real and synthetic\ndatasets, ML models, state-of-the-art explanation techniques, and evaluation\nmeasures. To present GRETEL, we show the experiments conducted to integrate and\ntest several synthetic and real datasets with several existing explanation\ntechniques and base ML models.",
    "descriptor": "\nComments: 12 pages, 2 figures\n",
    "authors": [
      "Mario Alfonso Prado-Romero",
      "Giovanni Stilo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02957"
  },
  {
    "id": "arXiv:2206.02958",
    "title": "Beyond Faithfulness: A Framework to Characterize and Compare Saliency  Methods",
    "abstract": "Saliency methods calculate how important each input feature is to a machine\nlearning model's prediction, and are commonly used to understand model\nreasoning. \"Faithfulness\", or how fully and accurately the saliency output\nreflects the underlying model, is an oft-cited desideratum for these methods.\nHowever, explanation methods must necessarily sacrifice certain information in\nservice of user-oriented goals such as simplicity. To that end, and akin to\nperformance metrics, we frame saliency methods as abstractions: individual\ntools that provide insight into specific aspects of model behavior and entail\ntradeoffs. Using this framing, we describe a framework of nine dimensions to\ncharacterize and compare the properties of saliency methods. We group these\ndimensions into three categories that map to different phases of the\ninterpretation process: methodology, or how the saliency is calculated;\nsensitivity, or relationships between the saliency result and the underlying\nmodel or input; and, perceptibility, or how a user interprets the result. As we\nshow, these dimensions give us a granular vocabulary for describing and\ncomparing saliency methods -- for instance, allowing us to develop \"saliency\ncards\" as a form of documentation, or helping downstream users understand\ntradeoffs and choose a method for a particular use case. Moreover, by situating\nexisting saliency methods within this framework, we identify opportunities for\nfuture work, including filling gaps in the landscape and developing new\nevaluation metrics.",
    "descriptor": "\nComments: 13 pages, 5 figures, 2 tables\n",
    "authors": [
      "Angie Boggust",
      "Harini Suresh",
      "Hendrik Strobelt",
      "John V. Guttag",
      "Arvind Satyanarayan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02958"
  },
  {
    "id": "arXiv:2206.02960",
    "title": "Mobile Health Solution for College Student Mental Health: Interview  Study and Design Requirement Analysis",
    "abstract": "Background: Mental health problems are prevalent in college students. The\nCOVID-19 pandemic exacerbated the problems, and created a surge in the\npopularity of telehealth and mobile health solutions. Despite that mobile\nhealth is a promising approach to help students with mental health needs, few\nstudies exist in investigating key features students need in a mental health\nself-management tool. Objective: The objective of our study was to identified\nkey requirements and features for the design of a student-centered mental\nhealth self-management tool. Methods: An interview study was first conducted to\nunderstand college students' needs and preferences on a mental health\nself-management tool. Functional information requirement analysis was then\nconducted to translate the needs into design implications. Results: A total of\n153 university students were recruited for the semi-structured interview. The\nparticipants mentioned several features including coping techniques, artificial\nintelligence, time management, tracking, and communication with others.\nParticipant's preferences on usability and privacy settings were also\ncollected. The desired functions were analyzed and turned into design-agnostic\ninformation requirements. Conclusions: This study documents findings from\ninterviews with university students to understand their needs and preferences\nfor a tool to help with self-management of mental health.",
    "descriptor": "",
    "authors": [
      "Xiaomei Wang",
      "Alec Smith",
      "Bruce Keller",
      "Farzan Sasangohar"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.02960"
  },
  {
    "id": "arXiv:2206.02963",
    "title": "Improving Knowledge Graph Embedding via Iterative Self-Semantic  Knowledge Distillation",
    "abstract": "Knowledge graph embedding (KGE) has been intensively investigated for link\nprediction by projecting entities and relations into continuous vector spaces.\nCurrent popular high-dimensional KGE methods obtain quite slight performance\ngains while require enormous computation and memory costs. In contrast to\nhigh-dimensional KGE models, training low-dimensional models is more efficient\nand worthwhile for better deployments to practical intelligent systems.\nHowever, the model expressiveness of semantic information in knowledge graphs\n(KGs) is highly limited in the low dimension parameter space. In this paper, we\npropose iterative self-semantic knowledge distillation strategy to improve the\nKGE model expressiveness in the low dimension space. KGE model combined with\nour proposed strategy plays the teacher and student roles alternatively during\nthe whole training process. Specifically, at a certain iteration, the model is\nregarded as a teacher to provide semantic information for the student. At next\niteration, the model is regard as a student to incorporate the semantic\ninformation transferred from the teacher. We also design a novel semantic\nextraction block to extract iteration-based semantic information for the\ntraining model self-distillation. Iteratively incorporating and accumulating\niteration-based semantic information enables the low-dimensional model to be\nmore expressive for better link prediction in KGs. There is only one model\nduring the whole training, which alleviates the increase of computational\nexpensiveness and memory requirements. Furthermore, the proposed strategy is\nmodel-agnostic and can be seamlessly combined with other KGE models. Consistent\nand significant performance gains in experimental evaluations on four standard\ndatasets demonstrate the effectiveness of the proposed self-distillation\nstrategy.",
    "descriptor": "",
    "authors": [
      "Zhehui Zhou",
      "Defang Chen",
      "Can Wang",
      "Yan Feng",
      "Chun Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02963"
  },
  {
    "id": "arXiv:2206.02967",
    "title": "Masked Unsupervised Self-training for Zero-shot Image Classification",
    "abstract": "State-of-the-art computer vision models are mostly trained with supervised\nlearning using human-labeled images, which limits their scalability due to the\nexpensive annotation cost. While self-supervised representation learning has\nachieved impressive progress, it still requires a second stage of finetuning on\nlabeled data. On the other hand, models pre-trained with large-scale text-image\nsupervision (e.g., CLIP) have enabled zero-shot transfer to downstream image\nclassification tasks. However, the zero-shot performance of CLIP-like models\nare often insufficient for real-world adoption. In this paper, we aim to\nleverage the abundant unlabeled data to improve the performance of a\npre-trained zero-shot classifier on downstream tasks. We propose Masked\nUnsupervised Self-Training (MUST), a new approach which leverages two different\nand complimentary sources of supervision: pseudo-labels and raw images. MUST\njointly optimizes three objectives to learn both class-level global feature and\npixel-level local feature and enforces a regularization between the two. We\ndemonstrate the efficacy of MUST on 8 downstream tasks across a variety of\ndomains, where it improves upon CLIP by a large margin and narrows the\nperformance gap between unsupervised and supervised classification. For\ninstance, MUST achieves a zero-shot top-1 accuracy of 77.7% on ImageNet using\nViT-B, +9.4% higher than CLIP. Our code is available at\nhttps://github.com/salesforce/MUST.",
    "descriptor": "",
    "authors": [
      "Junnan Li",
      "Silvio Savarese",
      "Steven C.H. Hoi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02967"
  },
  {
    "id": "arXiv:2206.02971",
    "title": "Human Trafficking in Mexico: Data sources, Network Analysis and the  Limits of Dismantling Strategies",
    "abstract": "Human trafficking is a heartless crime that represents the second most\nprofitable crime in the world. Mexico's geographical position makes it a\ncountry with high levels of human trafficking. Using the snowball sampling\nmethod, the major contribution of this paper is the abstraction of the human\ntrafficking network on the southern border of Mexico. Based on a social network\nanalysis, it is identified that the criminal network is moderately centralized\n(44.32%) and with medium density (0.401). Therefore, the network has minimal\ncohesiveness and members may find it difficult to share information, money, or\nproducts among themselves. To evaluate different dismantling strategies to\ntackle the criminal organization, three algorithms are evaluated. We found that\nthe first actors to be removed are neither the most connected nor the most\nperipheral, but the actors who are moderately connected to people of their kind\nshould be removed. In summary, this paper provides a significant step forward\nto understand quantitatively human trafficking networks and evaluate the limits\nof dismantling strategies.",
    "descriptor": "",
    "authors": [
      "Sof\u00eda de la Mora Tostado",
      "Mayra N\u00fa\u00f1ez-L\u00f3pez",
      "Esteban A. Hern\u00e1ndez-Vargas"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.02971"
  },
  {
    "id": "arXiv:2206.02976",
    "title": "Recall Distortion in Neural Network Pruning and the Undecayed Pruning  Algorithm",
    "abstract": "Pruning techniques have been successfully used in neural networks to trade\naccuracy for sparsity. However, the impact of network pruning is not uniform:\nprior work has shown that the recall for underrepresented classes in a dataset\nmay be more negatively affected. In this work, we study such relative\ndistortions in recall by hypothesizing an intensification effect that is\ninherent to the model. Namely, that pruning makes recall relatively worse for a\nclass with recall below accuracy and, conversely, that it makes recall\nrelatively better for a class with recall above accuracy. In addition, we\npropose a new pruning algorithm aimed at attenuating such effect. Through\nstatistical analysis, we have observed that intensification is less severe with\nour algorithm but nevertheless more pronounced with relatively more difficult\ntasks, less complex models, and higher pruning ratios. More surprisingly, we\nconversely observe a de-intensification effect with lower pruning ratios.",
    "descriptor": "\nComments: (Under review.)\n",
    "authors": [
      "Aidan Good",
      "Jiaqi Lin",
      "Hannah Sieg",
      "Mikey Ferguson",
      "Xin Yu",
      "Shandian Zhe",
      "Jerzy Wieczorek",
      "Thiago Serra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02976"
  },
  {
    "id": "arXiv:2206.02977",
    "title": "DETR++: Taming Your Multi-Scale Detection Transformer",
    "abstract": "Convolutional Neural Networks (CNN) have dominated the field of detection\never since the success of AlexNet in ImageNet classification [12]. With the\nsweeping reform of Transformers [27] in natural language processing, Carion et\nal. [2] introduce the Transformer-based detection method, i.e., DETR. However,\ndue to the quadratic complexity in the self-attention mechanism in the\nTransformer, DETR is never able to incorporate multi-scale features as\nperformed in existing CNN-based detectors, leading to inferior results in small\nobject detection. To mitigate this issue and further improve performance of\nDETR, in this work, we investigate different methods to incorporate multi-scale\nfeatures and find that a Bi-directional Feature Pyramid (BiFPN) works best with\nDETR in further raising the detection precision. With this discovery, we\npropose DETR++, a new architecture that improves detection results by 1.9% AP\non MS COCO 2017, 11.5% AP on RICO icon detection, and 9.1% AP on RICO layout\nextraction over existing baselines.",
    "descriptor": "\nComments: T4V: Transformers for Vision workshop @ CVPR 2022\n",
    "authors": [
      "Chi Zhang",
      "Lijuan Liu",
      "Xiaoxue Zang",
      "Frederick Liu",
      "Hao Zhang",
      "Xinying Song",
      "Jindong Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02977"
  },
  {
    "id": "arXiv:2206.02978",
    "title": "Enhancing Dual-Encoders with Question and Answer Cross-Embeddings for  Answer Retrieval",
    "abstract": "Dual-Encoders is a promising mechanism for answer retrieval in question\nanswering (QA) systems. Currently most conventional Dual-Encoders learn the\nsemantic representations of questions and answers merely through matching\nscore. Researchers proposed to introduce the QA interaction features in scoring\nfunction but at the cost of low efficiency in inference stage. To keep\nindependent encoding of questions and answers during inference stage,\nvariational auto-encoder is further introduced to reconstruct answers\n(questions) from question (answer) embeddings as an auxiliary task to enhance\nQA interaction in representation learning in training stage. However, the needs\nof text generation and answer retrieval are different, which leads to hardness\nin training. In this work, we propose a framework to enhance the Dual-Encoders\nmodel with question answer cross-embeddings and a novel Geometry Alignment\nMechanism (GAM) to align the geometry of embeddings from Dual-Encoders with\nthat from Cross-Encoders. Extensive experimental results show that our\nframework significantly improves Dual-Encoders model and outperforms the\nstate-of-the-art method on multiple answer retrieval datasets.",
    "descriptor": "\nComments: Findings of EMNLP 2021(10 pages)\n",
    "authors": [
      "Yanmeng Wang",
      "Jun Bai",
      "Ye Wang",
      "Jianfei Zhang",
      "Wenge Rong",
      "Zongcheng Ji",
      "Shaojun Wang",
      "Jing Xiao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02978"
  },
  {
    "id": "arXiv:2206.02979",
    "title": "Wireless Self-Powered Visual and NDE low-Cost Inspection System For  Small Diameter Live Gas Distribution Mains",
    "abstract": "The arrangement of an in-pipe climbing robot that works using a sharp\ntransmission part to explore complex relationship of lines. Standard\nwheeled/continued in-pipe climbing robots are leaned to slip and take while\nresearching in pipe turns. The instrument helps in achieving the really\nunavoidable consequence of getting out slip and drag in the robot tracks during\nprogression. The proposed transmission likes the useful uttermost scopes of the\nstandard two-yield transmission, which is fostered the fundamental time for a\ntransmission with three outcomes. The instrument decisively changes the track\nvelocities of the robot considering the powers applied on each track inside the\nline relationship, by getting out the fundamental for any wonderful control.\nThe entertainment of the robot crossing in the line network in different\ndirection and in pipe-turns without slip shows the proposed course of action's\nampleness.",
    "descriptor": "\nComments: 2 figures. arXiv admin note: substantial text overlap with arXiv:2201.10468, arXiv:2205.09973\n",
    "authors": [
      "Shivani Naik",
      "Arjun Kumar",
      "Nitinesh Yadav",
      "K. M. Santosh"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.02979"
  },
  {
    "id": "arXiv:2206.02981",
    "title": "Decentralized Aggregation for Energy-Efficient Federated Learning via  Overlapped Clustering and D2D Communications",
    "abstract": "Federated learning (FL) has emerged as a distributed machine learning (ML)\ntechnique to train models without sharing users' private data. In this paper,\nwe propose a decentralized FL scheme that is called \\underline{f}ederated\n\\underline{l}earning \\underline{e}mpowered \\underline{o}verlapped\n\\underline{c}lustering for \\underline{d}ecentralized aggregation (FL-EOCD). The\nintroduced FL-EOCD leverages device-to-device (D2D) communications and\noverlapped clustering to enable decentralized aggregation, where a cluster is\ndefined as a coverage zone of a typical device. The devices located on the\noverlapped clusters are called bridge devices (BDs). In the proposed FL-EOCD\nscheme, a clustering topology is envisioned where clusters are connected\nthrough BDs, so as the aggregated models of each cluster is disseminated to the\nother clusters in a decentralized manner without the need for a global\naggregator or an additional hop of transmission. Unlike the star-based FL, the\nproposed FL-EOCD scheme involves a large number of local devices by reusing the\nRRBs in different non-adjacent clusters. To evaluate our proposed FL-EOCD\nscheme as opposed to baseline FL schemes, we consider minimizing the overall\nenergy-consumption of devices while maintaining the convergence rate of FL\nsubject to its time constraint. To this end, a joint optimization problem,\nconsidering scheduling the local devices/BDs to the CHs and computation\nfrequency allocation, is formulated, where an iterative solution to this joint\nproblem is devised. Extensive simulations are conducted to verify the\neffectiveness of the proposed FL-EOCD algorithm over FL conventional schemes in\nterms of energy consumption, latency, and convergence rate.",
    "descriptor": "\nComments: 15, 9 figures, Journal\n",
    "authors": [
      "Mohammed S. Al-Abiad",
      "Mohanad Obeed",
      "Md. Jahangir Hossain",
      "Anas Chaaban"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.02981"
  },
  {
    "id": "arXiv:2206.02982",
    "title": "DynaMaR: Dynamic Prompt with Mask Token Representation",
    "abstract": "Recent research has shown that large language models pretrained using\nunsupervised approaches can achieve significant performance improvement on many\ndownstream tasks. Typically when adapting these language models to downstream\ntasks, like a classification or regression task, we employ a fine-tuning\nparadigm in which the sentence representation from the language model is input\nto a task-specific head; the model is then fine-tuned end-to-end. However, with\nthe emergence of models like GPT-3, prompt-based fine-tuning has been proven to\nbe a successful approach for few-shot tasks. Inspired by this work, we study\ndiscrete prompt technologies in practice. There are two issues that arise with\nthe standard prompt approach. First, it can overfit on the prompt template.\nSecond, it requires manual effort to formulate the downstream task as a\nlanguage model problem. In this paper, we propose an improvement to\nprompt-based fine-tuning that addresses these two issues. We refer to our\napproach as DynaMaR -- Dynamic Prompt with Mask Token Representation. Results\nshow that DynaMaR can achieve an average improvement of 10% in few-shot\nsettings and improvement of 3.7% in data-rich settings over the standard\nfine-tuning approach on four e-commerce applications.",
    "descriptor": "",
    "authors": [
      "Xiaodi Sun",
      "Sunny Rajagopalan",
      "Priyanka Nigam",
      "Weiyi Lu",
      "Yi Xu",
      "Belinda Zeng",
      "Trishul Chilimbi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02982"
  },
  {
    "id": "arXiv:2206.02983",
    "title": "An Insight into The Intricacies of Lingual Paraphrasing Pragmatic  Discourse on The Purpose of Synonyms",
    "abstract": "The term \"paraphrasing\" refers to the process of presenting the sense of an\ninput text in a new way while preserving fluency. Scientific research\ndistribution is gaining traction, allowing both rookie and experienced\nscientists to participate in their respective fields. As a result, there is now\na massive demand for paraphrase tools that may efficiently and effectively\nassist scientists in modifying statements in order to avoid plagiarism. Natural\nLanguage Processing (NLP) is very much important in the realm of the process of\ndocument paraphrasing. We analyze and discuss existing studies on paraphrasing\nin the English language in this paper. Finally, we develop an algorithm to\nparaphrase any text document or paragraphs using WordNet and Natural Language\nTool Kit (NLTK) and maintain \"Using Synonyms\" techniques to achieve our result.\nFor 250 paragraphs, our algorithm achieved a paraphrase accuracy of 94.8%",
    "descriptor": "\nComments: 10 pages, 3 figures, Accepted in Bulletin of Electrical Engineering and Informatics (BEEI) Journal\n",
    "authors": [
      "Jabir Al Nahian",
      "Abu Kaisar Mohammad Masum",
      "Muntaser Mansur Syed",
      "Sheikh Abujar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.02983"
  },
  {
    "id": "arXiv:2206.02985",
    "title": "Structured Context Transformer for Generic Event Boundary Detection",
    "abstract": "Generic Event Boundary Detection (GEBD) aims to detect moments where humans\nnaturally perceive as event boundaries. In this paper, we present Structured\nContext Transformer (or SC-Transformer) to solve the GEBD task, which can be\ntrained in an end-to-end fashion. Specifically, we use the backbone\nconvolutional neural network (CNN) to extract the features of each video frame.\nTo capture temporal context information of each frame, we design the structure\ncontext transformer (SC-Transformer) by re-partitioning input frame sequence.\nNote that, the overall computation complexity of SC-Transformer is linear to\nthe video length. After that, the group similarities are computed to capture\nthe differences between frames. Then, a lightweight fully convolutional network\nis used to determine the event boundaries based on the grouped similarity maps.\nTo remedy the ambiguities of boundary annotations, the Gaussian kernel is\nadopted to preprocess the ground-truth event boundaries to further boost the\naccuracy. Extensive experiments conducted on the challenging Kinetics-GEBD and\nTAPOS datasets demonstrate the effectiveness of the proposed method compared to\nthe state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Congcong Li",
      "Xinyao Wang",
      "Dexiang Hong",
      "Yufei Wang",
      "Libo Zhang",
      "Tiejian Luo",
      "Longyin Wen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02985"
  },
  {
    "id": "arXiv:2206.02987",
    "title": "A Formalism of DNN Accelerator Flexibility",
    "abstract": "The high efficiency of domain-specific hardware accelerators for machine\nlearning (ML) has come from specialization, with the trade-off of less\nconfigurability/ flexibility. There is growing interest in developing flexible\nML accelerators to make them future-proof to the rapid evolution of Deep Neural\nNetworks (DNNs). However, the notion of accelerator flexibility has always been\nused in an informal manner, restricting computer architects from conducting\nsystematic apples-to-apples design-space exploration (DSE) across trillions of\nchoices. In this work, we formally define accelerator flexibility and show how\nit can be integrated for DSE. Specifically, we capture DNN accelerator\nflexibility across four axes: tiling, ordering, parallelization, and array\nshape. We categorize existing accelerators into 16 classes based on their axes\nof flexibility support, and define a precise quantification of the degree of\nflexibility of an accelerator across each axis. We leverage these to develop a\nnovel flexibility-aware DSE framework. We demonstrate how this can be used to\nperform first-of-their-kind evaluations, including an isolation study to\nidentify the individual impact of the flexibility axes. We demonstrate that\nadding flexibility features to a hypothetical DNN accelerator designed in 2014\nimproves runtime on future (i.e., present-day) DNNs by 11.8x geomean.",
    "descriptor": "",
    "authors": [
      "Sheng-Chun Kao",
      "Hyoukjun Kwon",
      "Michael Pellauer",
      "Angshuman Parashar",
      "Tushar Krishna"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2206.02987"
  },
  {
    "id": "arXiv:2206.02990",
    "title": "Distributionally Invariant Learning: Rationalization and Practical  Algorithms",
    "abstract": "The invariance property across environments is at the heart of invariant\nlearning methods for the Out-of-Distribution (OOD) Generalization problem.\nAlthough intuitively reasonable, strong assumptions on the availability and\nquality of environments have to be made for the learnability of the strict\ninvariance property. Recently, to relax the requirements for environments\nempirically, some works propose to learn pseudo-environments for invariant\nlearning. However, it could be misleading when pursuing strict invariance under\nlatent heterogeneity, since the underlying invariance could have been violated\nduring the pseudo-environment learning procedure. To this end, we come up with\nthe distributional invariance property as a relaxed alternative to the strict\ninvariance, which considers the invariance only among sub-populations down to a\nprescribed scale and allows a certain degree of variation. We reformulate the\ninvariant learning problem under latent heterogeneity into a relaxed form that\npursues the distributional invariance, based on which we propose our novel\nDistributionally Invariant Learning (DIL) framework as well as two\nimplementations named DIL-MMD and DIL-KL. Theoretically, we provide the\nguarantees for the distributional invariance as well as bounds of the\ngeneralization error gap. Extensive experimental results validate the\neffectiveness of our proposed algorithms.",
    "descriptor": "",
    "authors": [
      "Jiashuo Liu",
      "Jiayun Wu",
      "Jie Peng",
      "Zheyan Shen",
      "Bo Li",
      "Peng Cui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02990"
  },
  {
    "id": "arXiv:2206.02992",
    "title": "SMT-Based Model Checking of Industrial Simulink Models",
    "abstract": "The development of embedded systems requires formal analysis of models such\nas those described with MATLAB/Simulink. However, the increasing complexity of\nindustrial models makes analysis difficult. This paper proposes a model\nchecking method for Simulink models using SMT solvers. The proposed method aims\nat (1) automated, efficient and comprehensible verification of complex models,\n(2) numerically accurate analysis of models, and (3) demonstrating the analysis\nof Simulink models using an SMT solver (we use Z3). It first encodes a target\nmodel into a predicate logic formula in the domain of mathematical arithmetic\nand bit vectors. We explore how to encode various Simulink blocks exactly.\nThen, the method verifies a given invariance property using the\nk-induction-based algorithm that extracts a subsystem involving the target\nblock and unrolls the execution paths incrementally. In the experiment, we\napplied the proposed method and other tools to a set of models and properties.\nOur method successfully verified most of the properties including those\nunverified with other tools.",
    "descriptor": "\nComments: 16 pages, 5 figures, 1 table, submitted to ICFEM 2022\n",
    "authors": [
      "Daisuke Ishii",
      "Takashi Tomita",
      "Toshiaki Aoki",
      "Quyen Ngo",
      "Thi Bich Ngoc Do",
      "Hideaki Takai"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.02992"
  },
  {
    "id": "arXiv:2206.02993",
    "title": "False Consensus, Information Theory, and Prediction Markets",
    "abstract": "Our main result shows that when agents' private information about an event\nare independent conditioning on the event's outcome, then, after an initial\nannouncement, whenever agents have similar beliefs about the outcome, their\ninformation is aggregated. That is, there is no false consensus.\nOur main result has a short proof based on a natural information theoretic\nframework. A key ingredient of the framework is the equivalence between the\nsign of the ``interaction information'' and a super/sub-additive property of\nthe value of people's information. This provides an intuitive interpretation\nand an interesting application of the interaction information, which measures\nthe amount of information shared by three random variables.\nWe illustrate the power of this information theoretic framework by reproving\ntwo additional results within it: 1) that agents quickly agree when while\nannouncing beliefs in round robin fashion [Aaronson 2005]; and 2) results from\n[Chen et al 2010] on when prediction market agents should release information\nto maximize their payment. We also interpret the information theoretic\nframework and the above results in prediction markets by proving that the\nexpected reward of revealing information is the conditional mutual information\nof the information revealed.",
    "descriptor": "",
    "authors": [
      "Yuqing Kong",
      "Grant Schoenebeck"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2206.02993"
  },
  {
    "id": "arXiv:2206.02997",
    "title": "TadML: A fast temporal action detection with Mechanics-MLP",
    "abstract": "Temporal Action Detection(TAD) is a crucial but challenging task in video\nunderstanding.It is aimed at detecting both the type and start-end frame for\neach action instance in a long, untrimmed video.Most current models adopt both\nRGB and Optical-Flow streams for the TAD task. Thus, original RGB frames must\nbe converted manually into Optical-Flow frames with additional computation and\ntime cost, which is an obstacle to achieve real-time processing. At present,\nmany models adopt two-stage strategies, which would slow the inference speed\ndown and complicatedly tuning on proposals generating.By comparison, we propose\na one-stage anchor-free temporal localization method with RGB stream only, in\nwhich a novel Newtonian \\emph{Mechanics-MLP} architecture is established. It\nhas comparable accuracy with all existing state-of-the-art models, while\nsurpasses the inference speed of these methods by a large margin. The typical\ninference speed in this paper is astounding 4.44 video per second on THUMOS14.\nIn applications, because there is no need to convert optical flow, the\ninference speed will be faster.It also proves that \\emph{MLP} has great\npotential in downstream tasks such as TAD. The source code is available at\n\\url{https://github.com/BonedDeng/TadML}",
    "descriptor": "\nComments: 8 pages,3 figures\n",
    "authors": [
      "Bowen Deng",
      "Dongchang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02997"
  },
  {
    "id": "arXiv:2206.02998",
    "title": "Learning to Generate Artistic Character Line Drawing",
    "abstract": "Character line drawing synthesis can be formulated as a special case of\nimage-to-image translation problem that automatically manipulates the\nphoto-to-line drawing style transformation. In this paper, we present the first\ngenerative adversarial network based end-to-end trainable translation\narchitecture, dubbed P2LDGAN, for automatic generation of high-quality\ncharacter drawings from input photos/images. The core component of our approach\nis the joint geometric-semantic-driven generator, which uses our well-designed\ncross-scale dense skip connections framework to embed learned geometric and\nsemantic information for generating delicate line drawings. In order to support\nthe evaluation of our model, we release a new dataset including 1,532\nwell-matched pairs of freehand character line drawings as well as corresponding\ncharacter images/photos, where these line drawings with diverse styles are\nmanually drawn by skilled artists. Extensive experiments on our introduced\ndataset demonstrate the superior performance of our proposed models against the\nstate-of-the-art approaches in terms of quantitative, qualitative and human\nevaluations. Our code, models and dataset is available at\nhttps://github.com/cnyvfang/P2LDGAN.",
    "descriptor": "",
    "authors": [
      "Cheng-Yu Fang",
      "Xian-Feng Han",
      "Qi Zhong",
      "Shi-Jie Sun",
      "Guo-Qiang Xiao"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2206.02998"
  },
  {
    "id": "arXiv:2206.02999",
    "title": "DiMS: Distilling Multiple Steps of Iterative Non-Autoregressive  Transformers",
    "abstract": "The computational benefits of iterative non-autoregressive transformers\ndecrease as the number of decoding steps increases. As a remedy, we introduce\nDistill Multiple Steps (DiMS), a simple yet effective distillation technique to\ndecrease the number of required steps to reach a certain translation quality.\nThe distilled model enjoys the computational benefits of early iterations while\npreserving the enhancements from several iterative steps. DiMS relies on two\nmodels namely student and teacher. The student is optimized to predict the\noutput of the teacher after multiple decoding steps while the teacher follows\nthe student via a slow-moving average. The moving average keeps the teacher's\nknowledge updated and enhances the quality of the labels provided by the\nteacher. During inference, the student is used for translation and no\nadditional computation is added. We verify the effectiveness of DiMS on various\nmodels obtaining improvements of up to 7 BLEU points on distilled and 12 BLEU\npoints on raw WMT datasets for single-step translation. We release our code at\nhttps://github.com/layer6ai-labs/DiMS.",
    "descriptor": "",
    "authors": [
      "Sajad Norouzi",
      "Rasa Hosseinzadeh",
      "Felipe Perez",
      "Maksims Volkovs"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.02999"
  },
  {
    "id": "arXiv:2206.03001",
    "title": "PP-OCRv3: More Attempts for the Improvement of Ultra Lightweight OCR  System",
    "abstract": "Optical character recognition (OCR) technology has been widely used in\nvarious scenes, as shown in Figure 1. Designing a practical OCR system is still\na meaningful but challenging task. In previous work, considering the efficiency\nand accuracy, we proposed a practical ultra lightweight OCR system (PP-OCR),\nand an optimized version PP-OCRv2. In order to further improve the performance\nof PP-OCRv2, a more robust OCR system PP-OCRv3 is proposed in this paper.\nPP-OCRv3 upgrades the text detection model and text recognition model in 9\naspects based on PP-OCRv2. For text detector, we introduce a PAN module with\nlarge receptive field named LK-PAN, a FPN module with residual attention\nmechanism named RSE-FPN, and DML distillation strategy. For text recognizer,\nthe base model is replaced from CRNN to SVTR, and we introduce lightweight text\nrecognition network SVTR LCNet, guided training of CTC by attention, data\naugmentation strategy TextConAug, better pre-trained model by self-supervised\nTextRotNet, UDML, and UIM to accelerate the model and improve the effect.\nExperiments on real data show that the hmean of PP-OCRv3 is 5% higher than\nPP-OCRv2 under comparable inference speed. All the above mentioned models are\nopen-sourced and the code is available in the GitHub repository PaddleOCR which\nis powered by PaddlePaddle.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2109.03144\n",
    "authors": [
      "Chenxia Li",
      "Weiwei Liu",
      "Ruoyu Guo",
      "Xiaoting Yin",
      "Kaitao Jiang",
      "Yongkun Du",
      "Yuning Du",
      "Lingfeng Zhu",
      "Baohua Lai",
      "Xiaoguang Hu",
      "Dianhai Yu",
      "Yanjun Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.03001"
  },
  {
    "id": "arXiv:2206.03004",
    "title": "Driving in Real Life with Inverse Reinforcement Learning",
    "abstract": "In this paper, we introduce the first learning-based planner to drive a car\nin dense, urban traffic using Inverse Reinforcement Learning (IRL). Our\nplanner, DriveIRL, generates a diverse set of trajectory proposals, filters\nthese trajectories with a lightweight and interpretable safety filter, and then\nuses a learned model to score each remaining trajectory. The best trajectory is\nthen tracked by the low-level controller of our self-driving vehicle. We train\nour trajectory scoring model on a 500+ hour real-world dataset of expert\ndriving demonstrations in Las Vegas within the maximum entropy IRL framework.\nDriveIRL's benefits include: a simple design due to only learning the\ntrajectory scoring function, relatively interpretable features, and strong\nreal-world performance. We validated DriveIRL on the Las Vegas Strip and\ndemonstrated fully autonomous driving in heavy traffic, including scenarios\ninvolving cut-ins, abrupt braking by the lead vehicle, and hotel pickup/dropoff\nzones. Our dataset will be made public to help further research in this area.",
    "descriptor": "",
    "authors": [
      "Tung Phan-Minh",
      "Forbes Howington",
      "Ting-Sheng Chu",
      "Sang Uk Lee",
      "Momchil S. Tomov",
      "Nanxiang Li",
      "Caglayan Dicle",
      "Samuel Findler",
      "Francisco Suarez-Ruiz",
      "Robert Beaudoin",
      "Bo Yang",
      "Sammy Omari",
      "Eric M. Wolff"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03004"
  },
  {
    "id": "arXiv:2206.03008",
    "title": "Histogram Estimation under User-level Privacy with Heterogeneous Data",
    "abstract": "We study the problem of histogram estimation under user-level differential\nprivacy, where the goal is to preserve the privacy of all entries of any single\nuser. While there is abundant literature on this classical problem under the\nitem-level privacy setup where each user contributes only one data point,\nlittle has been known for the user-level counterpart. We consider the\nheterogeneous scenario where both the quantity and distribution of data can be\ndifferent for each user. We propose an algorithm based on a clipping strategy\nthat almost achieves a two-approximation with respect to the best clipping\nthreshold in hindsight. This result holds without any distribution assumptions\non the data. We also prove that the clipping bias can be significantly reduced\nwhen the counts are from non-i.i.d. Poisson distributions and show empirically\nthat our debiasing method provides improvements even without such constraints.\nExperiments on both real and synthetic datasets verify our theoretical findings\nand demonstrate the effectiveness of our algorithms.",
    "descriptor": "\nComments: 21 pages, 4 figures\n",
    "authors": [
      "Yuhan Liu",
      "Ananda Theertha Suresh",
      "Wennan Zhu",
      "Peter Kairouz",
      "Marco Gruteser"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.03008"
  },
  {
    "id": "arXiv:2206.03010",
    "title": "MS-RNN: A Flexible Multi-Scale Framework for Spatiotemporal Predictive  Learning",
    "abstract": "Spatiotemporal predictive learning is to predict future frames changes\nthrough historical prior knowledge. Previous work improves prediction\nperformance by making the network wider and deeper, but this also brings huge\nmemory overhead, which seriously hinders the development and application of the\ntechnology. Scale is another dimension to improve model performance in common\ncomputer vision task, which can decrease the computing requirements and better\nsense of context. Such an important improvement point has not been considered\nand explored by recent RNN models. In this paper, learning from the benefit of\nmulti-scale, we propose a general framework named Multi-Scale RNN (MS-RNN) to\nboost recent RNN models. We verify the MS-RNN framework by exhaustive\nexperiments on 4 different datasets (Moving MNIST, KTH, TaxiBJ, and HKO-7) and\nmultiple popular RNN models (ConvLSTM, TrajGRU, PredRNN, PredRNN++, MIM, and\nMotionRNN). The results show the efficiency that the RNN models incorporating\nour framework have much lower memory cost but better performance than before.\nOur code is released at \\url{https://github.com/mazhf/MS-RNN}.",
    "descriptor": "",
    "authors": [
      "Zhifeng Ma",
      "Hao Zhang",
      "Jie Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.03010"
  },
  {
    "id": "arXiv:2206.03012",
    "title": "TriBYOL: Triplet BYOL for Self-Supervised Representation Learning",
    "abstract": "This paper proposes a novel self-supervised learning method for learning\nbetter representations with small batch sizes. Many self-supervised learning\nmethods based on certain forms of the siamese network have emerged and received\nsignificant attention. However, these methods need to use large batch sizes to\nlearn good representations and require heavy computational resources. We\npresent a new triplet network combined with a triple-view loss to improve the\nperformance of self-supervised representation learning with small batch sizes.\nExperimental results show that our method can drastically outperform\nstate-of-the-art self-supervised learning methods on several datasets in\nsmall-batch cases. Our method provides a feasible solution for self-supervised\nlearning with real-world high-resolution images that uses small batch sizes.",
    "descriptor": "\nComments: Published as a conference paper at ICASSP 2022\n",
    "authors": [
      "Guang Li",
      "Ren Togo",
      "Takahiro Ogawa",
      "Miki Haseyama"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.03012"
  },
  {
    "id": "arXiv:2206.03014",
    "title": "The Devil is in the Labels: Noisy Label Correction for Robust Scene  Graph Generation",
    "abstract": "Unbiased SGG has achieved significant progress over recent years. However,\nalmost all existing SGG models have overlooked the ground-truth annotation\nqualities of prevailing SGG datasets, i.e., they always assume: 1) all the\nmanually annotated positive samples are equally correct; 2) all the\nun-annotated negative samples are absolutely background. In this paper, we\nargue that both assumptions are inapplicable to SGG: there are numerous \"noisy\"\ngroundtruth predicate labels that break these two assumptions, and these noisy\nsamples actually harm the training of unbiased SGG models. To this end, we\npropose a novel model-agnostic NoIsy label CorrEction strategy for SGG: NICE.\nNICE can not only detect noisy samples but also reassign more high-quality\npredicate labels to them. After the NICE training, we can obtain a cleaner\nversion of SGG dataset for model training. Specifically, NICE consists of three\ncomponents: negative Noisy Sample Detection (Neg-NSD), positive NSD (Pos-NSD),\nand Noisy Sample Correction (NSC). Firstly, in Neg-NSD, we formulate this task\nas an out-of-distribution detection problem, and assign pseudo labels to all\ndetected noisy negative samples. Then, in Pos-NSD, we use a clustering-based\nalgorithm to divide all positive samples into multiple sets, and treat the\nsamples in the noisiest set as noisy positive samples. Lastly, in NSC, we use a\nsimple but effective weighted KNN to reassign new predicate labels to noisy\npositive samples. Extensive results on different backbones and tasks have\nattested to the effectiveness and generalization abilities of each component of\nNICE.",
    "descriptor": "\nComments: Accepted by CVPR 2022\n",
    "authors": [
      "Lin Li",
      "Long Chen",
      "Yifeng Huang",
      "Zhimeng Zhang",
      "Songyang Zhang",
      "Jun Xiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.03014"
  },
  {
    "id": "arXiv:2206.03017",
    "title": "Development of Automatic Endotracheal Tube and Carina Detection on  Portable Supine Chest Radiographs using Artificial Intelligence",
    "abstract": "The image quality of portable supine chest radiographs is inherently poor due\nto low contrast and high noise. The endotracheal intubation detection requires\nthe locations of the endotracheal tube (ETT) tip and carina. The goal is to\nfind the distance between the ETT tip and the carina in chest radiography. To\novercome such a problem, we propose a feature extraction method with Mask\nR-CNN. The Mask R-CNN predicts a tube and a tracheal bifurcation in an image.\nThen, the feature extraction method is used to find the feature point of the\nETT tip and that of the carina. Therefore, the ETT-carina distance can be\nobtained. In our experiments, our results can exceed 96\\% in terms of recall\nand precision. Moreover, the object error is less than $4.7751\\pm 5.3420$ mm,\nand the ETT-carina distance errors are less than $5.5432\\pm 6.3100$ mm. The\nexternal validation shows that the proposed method is a high-robustness system.\nAccording to the Pearson correlation coefficient, we have a strong correlation\nbetween the board-certified intensivists and our result in terms of ETT-carina\ndistance.",
    "descriptor": "",
    "authors": [
      "Chi-Yeh Chen",
      "Min-Hsin Huang",
      "Yung-Nien Sun",
      "Chao-Han Lai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.03017"
  },
  {
    "id": "arXiv:2206.03018",
    "title": "What is the Metaverse? An Immersive Cyberspace and Open Challenges",
    "abstract": "The Metaverse refers to a virtual-physical blended space in which multiple\nusers can concurrently interact with a unified computer-generated environment\nand other users, which can be regarded as the next significant milestone of the\ncurrent cyberspace. This article primarily discusses the development and\nchallenges of the Metaverse. We first briefly describe the development of\ncyberspace and the necessity of technology enablers. Accordingly, our bottom-up\napproach highlights three critical technology enablers for the Metaverse:\nnetworks, systems, and users. Also, we highlight a number of indispensable\nissues, under technological and ecosystem perspectives, that build and sustain\nthe Metaverse.",
    "descriptor": "\nComments: 7 pages, 2 figures\n",
    "authors": [
      "Lik-Hang Lee",
      "Pengyuan Zhou",
      "Tristan Braud",
      "Pan Hui"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.03018"
  },
  {
    "id": "arXiv:2206.03019",
    "title": "The Survival Bandit Problem",
    "abstract": "We study the survival bandit problem, a variant of the multi-armed bandit\nproblem introduced in an open problem by Perotto et al. (2019), with a\nconstraint on the cumulative reward; at each time step, the agent receives a\n(possibly negative) reward and if the cumulative reward becomes lower than a\nprespecified threshold, the procedure stops, and this phenomenon is called\nruin. This is the first paper studying a framework where the ruin might occur\nbut not always. We first discuss that a sublinear regret is unachievable under\na naive definition of the regret. Next, we provide tight lower bounds on the\nprobability of ruin (as well as matching policies). Based on this lower bound,\nwe define the survival regret as an objective to minimize and provide a policy\nachieving a sublinear survival regret (at least in the case of integral\nrewards) when the time horizon $T$ is known.",
    "descriptor": "",
    "authors": [
      "Charles Riou",
      "Junya Honda",
      "Masashi Sugiyama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03019"
  },
  {
    "id": "arXiv:2206.03020",
    "title": "Adaptive Weighted Nonnegative Matrix Factorization for Robust Feature  Representation",
    "abstract": "Nonnegative matrix factorization (NMF) has been widely used to dimensionality\nreduction in machine learning. However, the traditional NMF does not properly\nhandle outliers, so that it is sensitive to noise. In order to improve the\nrobustness of NMF, this paper proposes an adaptive weighted NMF, which\nintroduces weights to emphasize the different importance of each data point,\nthus the algorithmic sensitivity to noisy data is decreased. It is very\ndifferent from the existing robust NMFs that use a slow growth similarity\nmeasure. Specifically, two strategies are proposed to achieve this: fuzzier\nweighted technique and entropy weighted regularized technique, and both of them\nlead to an iterative solution with a simple form. Experimental results showed\nthat new methods have more robust feature representation on several real\ndatasets with noise than exsiting methods.",
    "descriptor": "",
    "authors": [
      "Tingting Shen",
      "Junhang Li",
      "Can Tong",
      "Qiang He",
      "Chen Li",
      "Yudong Yao",
      "Yueyang Teng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03020"
  },
  {
    "id": "arXiv:2206.03021",
    "title": "Plot Writing From Pre-Trained Language Models",
    "abstract": "Pre-trained language models (PLMs) fail to generate long-form narrative text\nbecause they do not consider global structure. As a result, the generated texts\nare often incohesive, repetitive, or lack content. Recent work in story\ngeneration reintroduced explicit content planning in the form of prompts,\nkeywords, or semantic frames. Trained on large parallel corpora, these models\ncan generate more logical event sequences and thus more contentful stories.\nHowever, these intermediate representations are often not in natural language\nand cannot be utilized by PLMs without fine-tuning. We propose generating story\nplots using off-the-shelf PLMs while maintaining the benefit of content\nplanning to generate cohesive and contentful stories. Our proposed method,\nScratchPlot, first prompts a PLM to compose a content plan. Then, we generate\nthe story's body and ending conditioned on the content plan. Furthermore, we\ntake a generate-and-rank approach by using additional PLMs to rank the\ngenerated (story, ending) pairs. We benchmark our method with various baselines\nand achieved superior results in both human and automatic evaluation.",
    "descriptor": "\nComments: Accepted to INLG 2022; 16 pages, 11 figures\n",
    "authors": [
      "Yiping Jin",
      "Vishakha Kadam",
      "Dittaya Wanvarie"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.03021"
  },
  {
    "id": "arXiv:2206.03023",
    "title": "How Far I'll Go: Offline Goal-Conditioned Reinforcement Learning via  $f$-Advantage Regression",
    "abstract": "Offline goal-conditioned reinforcement learning (GCRL) promises\ngeneral-purpose skill learning in the form of reaching diverse goals from\npurely offline datasets. We propose $\\textbf{Go}$al-conditioned\n$f$-$\\textbf{A}$dvantage $\\textbf{R}$egression (GoFAR), a novel\nregression-based offline GCRL algorithm derived from a state-occupancy matching\nperspective; the key intuition is that the goal-reaching task can be formulated\nas a state-occupancy matching problem between a dynamics-abiding imitator agent\nand an expert agent that directly teleports to the goal. In contrast to prior\napproaches, GoFAR does not require any hindsight relabeling and enjoys\nuninterleaved optimization for its value and policy networks. These distinct\nfeatures confer GoFAR with much better offline performance and stability as\nwell as statistical performance guarantee that is unattainable for prior\nmethods. Furthermore, we demonstrate that GoFAR's training objectives can be\nre-purposed to learn an agent-independent goal-conditioned planner from purely\noffline source-domain data, which enables zero-shot transfer to new target\ndomains. Through extensive experiments, we validate GoFAR's effectiveness in\nvarious problem settings and tasks, significantly outperforming prior\nstate-of-art. Notably, on a real robotic dexterous manipulation task, while no\nother method makes meaningful progress, GoFAR acquires complex manipulation\nbehavior that successfully accomplishes diverse goals.",
    "descriptor": "\nComments: Project website: this https URL\n",
    "authors": [
      "Yecheng Jason Ma",
      "Jason Yan",
      "Dinesh Jayaraman",
      "Osbert Bastani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.03023"
  },
  {
    "id": "arXiv:2206.03025",
    "title": "OCHADAI at SemEval-2022 Task 2: Adversarial Training for Multilingual  Idiomaticity Detection",
    "abstract": "We propose a multilingual adversarial training model for determining whether\na sentence contains an idiomatic expression. Given that a key challenge with\nthis task is the limited size of annotated data, our model relies on\npre-trained contextual representations from different multi-lingual\nstate-of-the-art transformer-based language models (i.e., multilingual BERT and\nXLM-RoBERTa), and on adversarial training, a training method for further\nenhancing model generalization and robustness. Without relying on any\nhuman-crafted features, knowledge bases, or additional datasets other than the\ntarget datasets, our model achieved competitive results and ranked 6th place in\nSubTask A (zero-shot) setting and 15th place in SubTask A (one-shot) setting.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2105.05535\n",
    "authors": [
      "Lis Kanashiro Pereira",
      "Ichiro Kobayashi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.03025"
  },
  {
    "id": "arXiv:2206.03027",
    "title": "Learning Symbolic Operators: A Neurosymbolic Solution for Autonomous  Disassembly of Electric Vehicle Battery",
    "abstract": "The booming of electric vehicles demands efficient battery disassembly for\nrecycling to be environment-friendly. Currently, battery disassembly is still\nprimarily done by humans, probably assisted by robots, due to the unstructured\nenvironment and high uncertainties. It is highly desirable to design autonomous\nsolutions to improve work efficiency and lower human risks in high voltage and\ntoxic environments. This paper proposes a novel neurosymbolic method, which\naugments the traditional Variational Autoencoder (VAE) model to learn symbolic\noperators based on raw sensory inputs and their relationships. The symbolic\noperators include a probabilistic state symbol grounding model and a state\ntransition matrix for predicting states after each execution to enable\nautonomous task and motion planning. At last, the method's feasibility is\nverified through test results.",
    "descriptor": "",
    "authors": [
      "Yidong Du",
      "Wenshuo Wang",
      "Zhigang Wang",
      "Hua Yang",
      "Haitao Wang",
      "Yinghao Cai",
      "Ming Chen"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.03027"
  },
  {
    "id": "arXiv:2206.03031",
    "title": "Explainability in Mechanism Design: Recent Advances and the Road Ahead",
    "abstract": "Designing and implementing explainable systems is seen as the next step\ntowards increasing user trust in, acceptance of and reliance on Artificial\nIntelligence (AI) systems. While explaining choices made by black-box\nalgorithms such as machine learning and deep learning has occupied most of the\nlimelight, systems that attempt to explain decisions (even simple ones) in the\ncontext of social choice are steadily catching up. In this paper, we provide a\ncomprehensive survey of explainability in mechanism design, a domain\ncharacterized by economically motivated agents and often having no single\nchoice that maximizes all individual utility functions. We discuss the main\nproperties and goals of explainability in mechanism design, distinguishing them\nfrom those of Explainable AI in general. This discussion is followed by a\nthorough review of challenges one may face when when working on Explainable\nMechanism Design and propose a few solution concepts to those.",
    "descriptor": "",
    "authors": [
      "Sharadhi Alape Suryanarayana",
      "David Sarne",
      "Sarit Kraus"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2206.03031"
  },
  {
    "id": "arXiv:2206.03032",
    "title": "Intelligent Circuit Design and Implementation with Machine Learning",
    "abstract": "The stagnation of EDA technologies roots from insufficient knowledge reuse.\nIn practice, very similar simulation or optimization results may need to be\nrepeatedly constructed from scratch. This motivates my research on introducing\nmore 'intelligence' to EDA with machine learning (ML), which explores complex\ncorrelations in design flows based on prior data. Besides design time, I also\npropose ML solutions to boost IC performance by assisting the circuit\nmanagement at runtime. In this dissertation, I present multiple fast yet\naccurate ML models covering a wide range of chip design stages from the\nregister-transfer level (RTL) to sign-off, solving primary chip-design problems\nabout power, timing, interconnect, IR drop, routability, and design flow\ntuning. Targeting the RTL stage, I present APOLLO, a fully automated power\nmodeling framework. It constructs an accurate per-cycle power model by\nextracting the most power-correlated signals. The model can be further\nimplemented on chip for runtime power management with unprecedented low\nhardware costs. Targeting gate-level netlist, I present Net2 for early\nestimations on post-placement wirelength. It further enables more accurate\ntiming analysis without actual physical design information. Targeting circuit\nlayout, I present RouteNet for early routability prediction. As the first deep\nlearning-based routability estimator, some feature-extraction and model-design\nprinciples proposed in it are widely adopted by later works. I also present\nPowerNet for fast IR drop estimation. It captures spatial and temporal\ninformation about power distribution with a customized CNN architecture. Last,\nbesides targeting a single design step, I present FIST to efficiently tune\ndesign flow parameters during both logic synthesis and physical design.",
    "descriptor": "\nComments: Ph.D. Dissertation, 2022. Due to the limitation \"The abstract field cannot be longer than 1,920 characters\", the abstract here is shorter than that in the PDF file\n",
    "authors": [
      "Zhiyao Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03032"
  },
  {
    "id": "arXiv:2206.03033",
    "title": "Deep Learning Techniques for Visual Counting",
    "abstract": "In this thesis, I investigated and enhanced the visual counting task, which\nautomatically estimates the number of objects in still images or video frames.\nRecently, due to the growing interest in it, several CNN-based solutions have\nbeen suggested by the scientific community. These artificial neural networks\nprovide a way to automatically learn effective representations from raw visual\ndata and can be successfully employed to address typical challenges\ncharacterizing this task, such as different illuminations and object scales.\nBut apart from these difficulties, I targeted some other crucial limitations in\nthe adoption of CNNs, proposing solutions that I experimentally evaluated in\nthe context of the counting task which turns out to be particularly affected by\nthese shortcomings.\nIn particular, I tackled the problem related to the lack of data needed for\ntraining current CNN-based solutions. Given that the budget for labeling is\nlimited, data scarcity still represents an open problem, particularly evident\nin tasks such as the counting one, where the objects to be labeled are\nthousands per image. Specifically, I introduced synthetic datasets gathered\nfrom virtual environments, where the training labels are automatically\ncollected. I proposed Domain Adaptation strategies aiming at mitigating the\ndomain gap existing between the training and test data distributions. I\npresented a counting strategy where I took advantage of the redundant\ninformation characterizing datasets labeled by multiple annotators. Moreover, I\ntackled the engineering challenges coming out of the adoption of CNN techniques\nin environments with limited power resources. I introduced solutions for\ncounting vehicles directly onboard embedded vision systems. Finally, I designed\nan embedded modular Computer Vision-based system that can carry out several\ntasks to help monitor individual and collective human safety rules.",
    "descriptor": "\nComments: Version with high-quality images can be found at this https URL arXiv admin note: text overlap with arXiv:1802.03601, arXiv:1707.01202, arXiv:1809.02165, arXiv:1901.06026, arXiv:1808.01244 by other authors\n",
    "authors": [
      "Luca Ciampi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.03033"
  },
  {
    "id": "arXiv:2206.03044",
    "title": "CAISAR: A platform for Characterizing Artificial Intelligence Safety and  Robustness",
    "abstract": "We present CAISAR, an open-source platform under active development for the\ncharacterization of AI systems' robustness and safety. CAISAR provides a\nunified entry point for defining verification problems by using WhyML, the\nmature and expressive language of the Why3 verification platform. Moreover,\nCAISAR orchestrates and composes state-of-the-art machine learning verification\ntools which, individually, are not able to efficiently handle all problems but,\ncollectively, can cover a growing number of properties. Our aim is to assist,\non the one hand, the V\\&V process by reducing the burden of choosing the\nmethodology tailored to a given verification problem, and on the other hand the\ntools developers by factorizing useful features-visualization, report\ngeneration, property description-in one platform. CAISAR will soon be available\nat https://git.frama-c.com/pub/caisar.",
    "descriptor": "",
    "authors": [
      "Michele Alberti",
      "Fran\u00e7ois Bobot",
      "Zakaria Chihani",
      "Julien Girard-Satabin",
      "Augustin Lemesle"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.03044"
  },
  {
    "id": "arXiv:2206.03047",
    "title": "Fibonacci-like sequences for variants of the tower of Hanoi, and  corresponding graphs and gray codes",
    "abstract": "We modify the rules of the classical Tower of Hanoi puzzle in a quite natural\nway to get the Fibonacci sequence involved in the optimal algorithm of\nresolution, and show some nice properties of such a variant. In particular, we\ndeduce from this Tower of Hanoi-Fibonacci a Gray-like code on the set of binary\nwords without the factor 11, which has some properties intersting for itself\nand from which an iterative algorithm for the Tower of Hanoi-Fibonacci is\nobtained. Such an algorithm involves the Fibonacci substitution. Eventually, we\nbriefly extend the study to some natural generalizations.",
    "descriptor": "",
    "authors": [
      "Beno\u00eet Rittaud"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2206.03047"
  },
  {
    "id": "arXiv:2206.03048",
    "title": "Layered Depth Refinement with Mask Guidance",
    "abstract": "Depth maps are used in a wide range of applications from 3D rendering to 2D\nimage effects such as Bokeh. However, those predicted by single image depth\nestimation (SIDE) models often fail to capture isolated holes in objects and/or\nhave inaccurate boundary regions. Meanwhile, high-quality masks are much easier\nto obtain, using commercial auto-masking tools or off-the-shelf methods of\nsegmentation and matting or even by manual editing. Hence, in this paper, we\nformulate a novel problem of mask-guided depth refinement that utilizes a\ngeneric mask to refine the depth prediction of SIDE models. Our framework\nperforms layered refinement and inpainting/outpainting, decomposing the depth\nmap into two separate layers signified by the mask and the inverse mask. As\ndatasets with both depth and mask annotations are scarce, we propose a\nself-supervised learning scheme that uses arbitrary masks and RGB-D datasets.\nWe empirically show that our method is robust to different types of masks and\ninitial depth predictions, accurately refining depth values in inner and outer\nmask boundary regions. We further analyze our model with an ablation study and\ndemonstrate results on real applications. More information can be found at\nhttps://sooyekim.github.io/MaskDepth/ .",
    "descriptor": "\nComments: Accepted to CVPR 2022 (camera-ready version)\n",
    "authors": [
      "Soo Ye Kim",
      "Jianming Zhang",
      "Simon Niklaus",
      "Yifei Fan",
      "Simon Chen",
      "Zhe Lin",
      "Munchurl Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.03048"
  },
  {
    "id": "arXiv:2206.03060",
    "title": "Exploration of Systolic-Vector Architecture with Resource Scheduling for  Dynamic ML Workloads",
    "abstract": "As artificial intelligence (AI) and machine learning (ML) technologies\ndisrupt a wide range of industries, cloud datacenters face ever-increasing\ndemand in inference workloads. However, conventional CPU-based servers cannot\nhandle excessive computational requirements of deep neural network (DNN)\nmodels, while GPU-based servers suffer from huge power consumption and high\noperating cost. In this paper, we present a scalable systolic-vector\narchitecture that can cope with dynamically changing DNN workloads in cloud\ndatacenters. We first devise a lightweight DNN model description format called\nunified model format (UMF) that enables general model representation and fast\ndecoding in hardware accelerator. Based on this model format, we propose a\nheterogeneous architecture that features a load balancer that performs a\nhigh-level workload distribution and multiple systolic-vector clusters, in\nwhich each cluster consists of a programmable scheduler, throughput-oriented\nsystolic arrays, and function-oriented vector processors. We also propose a\nheterogeneity-aware scheduling algorithm that enables concurrent execution of\nmultiple DNN workloads while maximizing heterogeneous hardware utilization\nbased on computation and memory access time estimation. Finally, we build an\narchitecture simulation framework based on actual synthesis and place-and-route\nimplementation results and conduct design space exploration for the proposed\narchitecture. As a result, the proposed systolic-vector architecture achieves\n10.9x higher throughput performance and 30.17x higher energy efficiency than a\ncompatible GPU on realistic ML workloads. The proposed heterogeneity-aware\nscheduling algorithm improves the throughput and energy efficiency by 81% and\n20%, respectively, compared to a standard round-robin scheduling.",
    "descriptor": "",
    "authors": [
      "Jung-Hoon Kim",
      "Sungyeob Yoo",
      "Seungjae Moon",
      "Joo-Young Kim"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2206.03060"
  },
  {
    "id": "arXiv:2206.03061",
    "title": "Spatial Parsing and Dynamic Temporal Pooling networks for Human-Object  Interaction detection",
    "abstract": "The key of Human-Object Interaction(HOI) recognition is to infer the\nrelationship between human and objects. Recently, the image's Human-Object\nInteraction(HOI) detection has made significant progress. However, there is\nstill room for improvement in video HOI detection performance. Existing\none-stage methods use well-designed end-to-end networks to detect a video\nsegment and directly predict an interaction.\nIt makes the model learning and further optimization of the network more\ncomplex. This paper introduces the Spatial Parsing and Dynamic Temporal Pooling\n(SPDTP) network, which takes the entire video as a spatio-temporal graph with\nhuman and object nodes as input. Unlike existing methods, our proposed network\npredicts the difference between interactive and non-interactive pairs through\nexplicit spatial parsing, and then performs interaction recognition. Moreover,\nwe propose a learnable and differentiable Dynamic Temporal Module(DTM) to\nemphasize the keyframes of the video and suppress the redundant frame.\nFurthermore, the experimental results show that SPDTP can pay more attention to\nactive human-object pairs and valid keyframes. Overall, we achieve\nstate-of-the-art performance on CAD-120 dataset and Something-Else dataset.",
    "descriptor": "\nComments: Accepted by IJCNN2022\n",
    "authors": [
      "Hongsheng Li",
      "Guangming Zhu",
      "Wu Zhen",
      "Lan Ni",
      "Peiyi Shen",
      "Liang Zhang",
      "Ning Wang",
      "Cong Hua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.03061"
  },
  {
    "id": "arXiv:2206.03062",
    "title": "Object Scan Context: Object-centric Spatial Descriptor for Place  Recognition within 3D Point Cloud Map",
    "abstract": "Place recognition technology endows a SLAM algorithm with the ability to\neliminate accumulated errors and to relocalize itself. Existing methods on\npoint cloud-based place recognition often leverage the matching of global\ndescriptors which are lidar-centric. These methods have the following two major\ndefects: place recognition cannot be performed when the distance between the\ntwo point clouds is far, and only the rotation angle can be calculated without\nthe offset in the X and Y direction. To solve these two problems, we propose a\nnovel global descriptor, which is built around the Main Object, in this way,\ndescriptors are no longer dependent on the observation position. We analyze the\ntheory that this method can perfectly solve the above two problems, and conduct\na lot of experiments in KITTI and some extreme scenarios, which show that our\nmethod has obvious advantages over traditional methods.",
    "descriptor": "\nComments: 7 pages, 8 figures, submitted to IROS2022\n",
    "authors": [
      "Haodong Yuan",
      "Yudong Zhang",
      "Shengyin Fan",
      "Xue Li",
      "Jian Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.03062"
  },
  {
    "id": "arXiv:2206.03064",
    "title": "Minimum Efforts to Build an End-to-End Spatial-Temporal Action Detector",
    "abstract": "Spatial-temporal action detection is a vital part of video understanding.\nCurrent spatial-temporal action detection methods will first use an object\ndetector to obtain person candidate proposals. Then, the model will classify\nthe person candidates into different action categories. So-called two-stage\nmethods are heavy and hard to apply in real-world applications. Some existing\nmethods use a unified model structure, But they perform badly with the vanilla\nmodel and often need extra modules to boost the performance. In this paper, we\nexplore the strategy to build an end-to-end spatial-temporal action detector\nwith minimal modifications. To this end, we propose a new method named ME-STAD,\nwhich solves the spatial-temporal action detection problem in an end-to-end\nmanner. Besides the model design, we propose a novel labeling strategy to deal\nwith sparse annotations in spatial-temporal datasets. The proposed ME-STAD\nachieves better results (2.2% mAP boost) than original two-stage detectors and\naround 80% FLOPs reduction. Moreover, our proposed ME-STAD only has minimum\nmodifications with previous methods and does not require extra components. Our\ncode will be made public.",
    "descriptor": "",
    "authors": [
      "Lin Sui",
      "Chen-Lin Zhang",
      "Lixin Gu",
      "Feng Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.03064"
  },
  {
    "id": "arXiv:2206.03065",
    "title": "Universal Speech Enhancement with Score-based Diffusion",
    "abstract": "Removing background noise from speech audio has been the subject of\nconsiderable research and effort, especially in recent years due to the rise of\nvirtual communication and amateur sound recording. Yet background noise is not\nthe only unpleasant disturbance that can prevent intelligibility: reverb,\nclipping, codec artifacts, problematic equalization, limited bandwidth, or\ninconsistent loudness are equally disturbing and ubiquitous. In this work, we\npropose to consider the task of speech enhancement as a holistic endeavor, and\npresent a universal speech enhancement system that tackles 55 different\ndistortions at the same time. Our approach consists of a generative model that\nemploys score-based diffusion, together with a multi-resolution conditioning\nnetwork that performs enhancement with mixture density networks. We show that\nthis approach significantly outperforms the state of the art in a subjective\ntest performed by expert listeners. We also show that it achieves competitive\nobjective scores with just 4-8 diffusion steps, despite not considering any\nparticular strategy for fast sampling. We hope that both our methodology and\ntechnical contributions encourage researchers and practitioners to adopt a\nuniversal approach to speech enhancement, possibly framing it as a generative\ntask.",
    "descriptor": "\nComments: 23 pages, 6 figures; includes appendix; examples in this https URL\n",
    "authors": [
      "Joan Serr\u00e0",
      "Santiago Pascual",
      "Jordi Pons",
      "R. Oguz Araz",
      "Davide Scaini"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03065"
  },
  {
    "id": "arXiv:2206.03070",
    "title": "SubStrat: A Subset-Based Strategy for Faster AutoML",
    "abstract": "Automated machine learning (AutoML) frameworks have become important tools in\nthe data scientists' arsenal, as they dramatically reduce the manual work\ndevoted to the construction of ML pipelines. Such frameworks intelligently\nsearch among millions of possible ML pipelines - typically containing feature\nengineering, model selection and hyper parameters tuning steps - and finally\noutput an optimal pipeline in terms of predictive accuracy. However, when the\ndataset is large, each individual configuration takes longer to execute,\ntherefore the overall AutoML running times become increasingly high. To this\nend, we present SubStrat, an AutoML optimization strategy that tackles the data\nsize, rather than configuration space. It wraps existing AutoML tools, and\ninstead of executing them directly on the entire dataset, SubStrat uses a\ngenetic-based algorithm to find a small yet representative data subset which\npreserves a particular characteristic of the full data. It then employs the\nAutoML tool on the small subset, and finally, it refines the resulted pipeline\nby executing a restricted, much shorter, AutoML process on the large dataset.\nOur experimental results, performed on two popular AutoML frameworks,\nAuto-Sklearn and TPOT, show that SubStrat reduces their running times by 79%\n(on average), with less than 2% average loss in the accuracy of the resulted ML\npipeline.",
    "descriptor": "",
    "authors": [
      "Teddy Lazebnik",
      "Amit Somech",
      "Abraham Itzhak Weinberg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Databases (cs.DB)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.03070"
  },
  {
    "id": "arXiv:2206.03072",
    "title": "Intelligent Sliding Mode Control of an Overhead Container Crane",
    "abstract": "In this contribution, an intelligent controller is proposed for an\nunderactuated overhead container crane subject to both parameter uncertainties\nand unmodeled dynamics. The adopted approach is based on the sliding mode\nmethod to confer robustness against modeling inaccuracies and external\ndisturbances. Additionally, an adaptive fuzzy inference system is embedded\nwithin the control law to improve set-point regulation and trajectory tracking.\nIn order to evaluate the performance of the proposed intelligent scheme, the\ncontrol law was implemented and tested in a 1:6 scale experimental container\ncrane, available at the Institute of Mechanics and Ocean Engineering at Hamburg\nUniversity of Technology. The obtained experimental results demonstrate not\nonly the feasibility of the proposed scheme, but also its improved efficacy for\nboth stabilization and trajectory tracking problems.",
    "descriptor": "",
    "authors": [
      "Wallace Moreira Bessa",
      "Svenja Otto",
      "Edwin Kreuzer",
      "Robert Seifried"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.03072"
  },
  {
    "id": "arXiv:2206.03075",
    "title": "A Sequential Metamorphic Testing Framework for Understanding Automated  Driving Systems",
    "abstract": "Automated driving systems (ADS) are expected to be reliable and robust\nagainst a wide range of driving scenarios. Their decisions, first and foremost,\nmust be well understood. Understanding a decision made by ADS is a great\nchallenge, because it is not straightforward to tell whether the decision is\ncorrect or not, and how to verify it systematically. In this paper, a\nSequential MetAmoRphic Testing Smart framework is proposed based on metamorphic\ntesting, a mainstream software testing approach. In metamorphic testing,\nmetamorphic groups are constructed by selecting multiple inputs according to\nthe so-called metamorphic relations, which are basically the system's necessary\nproperties; the violation of certain relations by some corresponding\nmetamorphic groups implies the detection of erroneous system behaviors. The\nproposed framework makes use of sequences of metamorphic groups to understand\nADS behaviors, and is applicable without the need of ground-truth datasets. To\ndemonstrate its effectiveness, the framework is applied to test three ADS\nmodels that steer an autonomous car in different scenarios with another car\neither leading in front or approaching in the opposite direction. The conducted\nexperiments reveal a large number of undesirable behaviors in these top-ranked\ndeep learning models in the scenarios. These counter-intuitive behaviors are\nassociated with how the core models of ADS respond to different positions,\ndirections and properties of the other car in its proximity. Further analysis\nof the results helps identify critical factors affecting ADS decisions and thus\ndemonstrates that the framework can be used to provide a comprehensive\nunderstanding of ADS before their deployment",
    "descriptor": "\nComments: 11 pages, 6 figures, 3 tables\n",
    "authors": [
      "Quang-Hung Luu",
      "Huai Liu",
      "Tsong Yueh Chen",
      "Hai L. Vu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.03075"
  },
  {
    "id": "arXiv:2206.03077",
    "title": "An Exploratory Analysis of Feedback Types Used in Online Coding  Exercises",
    "abstract": "Online coding environments can help support computing students gain\nprogramming practice at their own pace. Especially informative feedback can be\nbeneficial during such self-guided, independent study phases. This research\naims at the identification of feedback types applied by CodingBat, Scratch and\nBlockly. Tutoring feedback as coined by Susanne Narciss along with the\nspecification of subtypes by Keuning, Jeuring and Heeren constitute the\ntheoretical basis. Accordingly, the five categories of elaborated feedback\n(knowledge about task requirements, knowledge about concepts, knowledge about\nmistakes, knowledge about how to proceed, and knowledge about meta-cognition)\nand their subtypes were utilized for the analysis of available feedback\noptions. The study revealed difficulties in identifying clear-cut boundaries\nbetween feedback types, as the offered feedback usually integrates more than\none type or subtype. Moreover, currently defined feedback types do not\nrigorously distinguish individualized and generic feedback. The lack of\ngranularity is also evident in the absence of subtypes relating to the\nknowledge type of the task. The analysis thus has implications for the future\ndesign and investigation of applied tutoring feedback. It encourages future\nresearch on feedback types and their implementation in the context of\nprogramming exercises to define feedback types that match the demands of novice\nprogrammers.",
    "descriptor": "\nComments: 15 pages, 3 figures\n",
    "authors": [
      "Natalie Kiesler"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.03077"
  },
  {
    "id": "arXiv:2206.03079",
    "title": "An Empirical Study of IoT Security Aspects at Sentence-Level in  Developer Textual Discussions",
    "abstract": "IoT is a rapidly emerging paradigm that now encompasses almost every aspect\nof our modern life. As such, ensuring the security of IoT devices is crucial.\nIoT devices can differ from traditional computing, thereby the design and\nimplementation of proper security measures can be challenging in IoT devices.\nWe observed that IoT developers discuss their security-related challenges in\ndeveloper forums like Stack Overflow(SO). However, we find that IoT security\ndiscussions can also be buried inside non-security discussions in SO. In this\npaper, we aim to understand the challenges IoT developers face while applying\nsecurity practices and techniques to IoT devices. We have two goals: (1)\nDevelop a model that can automatically find security-related IoT discussions in\nSO, and (2) Study the model output to learn about IoT developer\nsecurity-related challenges. First, we download 53K posts from SO that contain\ndiscussions about IoT. Second, we manually labeled 5,919 sentences from 53K\nposts as 1 or 0. Third, we use this benchmark to investigate a suite of deep\nlearning transformer models. The best performing model is called SecBot.\nFourth, we apply SecBot on the entire posts and find around 30K security\nrelated sentences. Fifth, we apply topic modeling to the security-related\nsentences. Then we label and categorize the topics. Sixth, we analyze the\nevolution of the topics in SO. We found that (1) SecBot is based on the\nretraining of the deep learning model RoBERTa. SecBot offers the best F1-Score\nof 0.935, (2) there are six error categories in misclassified samples by\nSecBot. SecBot was mostly wrong when the keywords/contexts were ambiguous\n(e.g., gateway can be a security gateway or a simple gateway), (3) there are 9\nsecurity topics grouped into three categories: Software, Hardware, and Network,\nand (4) the highest number of topics belongs to software security, followed by\nnetwork security.",
    "descriptor": "",
    "authors": [
      "Nibir Chandra Mandal",
      "Gias Uddin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.03079"
  },
  {
    "id": "arXiv:2206.03081",
    "title": "Negative Imaginary State Feedback Equivalence for a Class of Nonlinear  Systems",
    "abstract": "In this paper, we investigate the necessary and sufficient conditions under\nwhich a class of nonlinear systems are state feedback equivalent to nonlinear\nnegative imaginary (NI) systems with positive definite storage functions. The\nnonlinear systems of interest have a normal form of relative degree less than\nor equal to two. The nonlinearity of the system is restricted with respect to a\nsubset of the state variables, which are the state variables that have external\ndynamics. Under mild assumptions, such systems are state feedback equivalent to\nnonlinear NI systems and nonlinear output strictly negative imaginary (OSNI)\nsystems if and only if they are weakly minimum phase. Such a state feedback\ncontrol approach can also asymptotically stabilize the systems in question\nagainst nonlinear OSNI system uncertainties. A numerical example is provided to\nshow the process of the state feedback equivalence control and stabilization of\nuncertain systems.",
    "descriptor": "\nComments: 8 pages, 2 figures\n",
    "authors": [
      "Kanghong Shi",
      "Ian R. Petersen",
      "Igor G. Vladimirov"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.03081"
  },
  {
    "id": "arXiv:2206.03083",
    "title": "Pushing the Limits of Learning-based Traversability Analysis for  Autonomous Driving on CPU",
    "abstract": "Self-driving vehicles and autonomous ground robots require a reliable and\naccurate method to analyze the traversability of the surrounding environment\nfor safe navigation. This paper proposes and evaluates a real-time machine\nlearning-based Traversability Analysis method that combines geometric features\nwith appearance-based features in a hybrid approach based on a SVM classifier.\nIn particular, we show that integrating a new set of geometric and visual\nfeatures and focusing on important implementation details enables a noticeable\nboost in performance and reliability. The proposed approach has been compared\nwith state-of-the-art Deep Learning approaches on a public dataset of outdoor\ndriving scenarios. It reaches an accuracy of 89.2% in scenarios of varying\ncomplexity, demonstrating its effectiveness and robustness. The method runs\nfully on CPU and reaches comparable results with respect to the other methods,\noperates faster, and requires fewer hardware resources.",
    "descriptor": "\nComments: Accepted to 17th International Conference on Intelligent Autonomous Systems (IAS-17)\n",
    "authors": [
      "Daniel Fusaro",
      "Emilio Olivastri",
      "Daniele Evangelista",
      "Marco Imperoli",
      "Emanuele Menegatti",
      "Alberto Pretto"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.03083"
  },
  {
    "id": "arXiv:2206.03084",
    "title": "Content Privacy Enforcement Models in Decentralized Online Social  Networks: State of Play, Solutions, Limitations, and Future Directions",
    "abstract": "In recent years, Decentralized Online Social Networks (DOSNs) have been\nattracting the attention of many users because they reduce the risk of\ncensorship, surveillance, and information leakage from the service provider. In\ncontrast to the most popular Online Social Networks, which are based on\ncentralized architectures (e.g., Facebook, Twitter, or Instagram), DOSNs are\nnot based on a single service provider acting as a central authority. Indeed,\nthe contents that are published on DOSNs are stored on the devices made\navailable by their users, which cooperate to execute the tasks needed to\nprovide the service. To continuously guarantee their availability, the contents\npublished by a user could be stored on the devices of other users, simply\nbecause they are online when required. Consequently, such contents must be\nproperly protected by the DOSN infrastructure, in order to ensure that they can\nbe really accessed only by users who have the permission of the publishers. As\na consequence, DOSNs require efficient solutions for protecting the privacy of\nthe contents published by each user with respect to the other users of the\nsocial network. In this paper, we investigate and compare the principal content\nprivacy enforcement models adopted by current DOSNs evaluating their\nsuitability to support different types of privacy policies based on user\ngroups. Such evaluation is carried out by implementing several models and\ncomparing their performance for the typical operations performed on groups,\ni.e., content publish, user join and leave. Further, we also highlight the\nlimitations of current approaches and show future research directions. This\ncontribution, other than being interesting on its own, provides a blueprint for\nresearchers and practitioners interested in implementing DOSNs, and also\nhighlights a few open research directions.",
    "descriptor": "",
    "authors": [
      "Andrea De Salve",
      "Paolo Mori",
      "Laura Ricci",
      "Roberto Di Pietro"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.03084"
  },
  {
    "id": "arXiv:2206.03085",
    "title": "A Route Network Planning Method for Urban Air Delivery",
    "abstract": "High-tech giants and start-ups are investing in drone technologies to provide\nurban air delivery service, which is expected to solve the last-mile problem\nand mitigate road traffic congestion. However, air delivery service will not\nscale up without proper traffic management for drones in dense urban\nenvironment. Currently, a range of Concepts of Operations (ConOps) for unmanned\naircraft system traffic management (UTM) are being proposed and evaluated by\nresearchers, operators, and regulators. Among these, the tube-based (or\ncorridor-based) ConOps has emerged in operations in some regions of the world\nfor drone deliveries and is expected to continue serving certain scenarios that\nwith dense and complex airspace and requires centralized control in the future.\nTowards the tube-based ConOps, we develop a route network planning method to\ndesign routes (tubes) in a complex urban environment in this paper. In this\nmethod, we propose a priority structure to decouple the network planning\nproblem, which is NP-hard, into single-path planning problems. We also\nintroduce a novel space cost function to enable the design of dense and aligned\nroutes in a network. The proposed method is tested on various scenarios and\ncompared with other state-of-the-art methods. Results show that our method can\ngenerate near-optimal route networks with significant computational\ntime-savings.",
    "descriptor": "",
    "authors": [
      "Xinyu He",
      "Fang He",
      "Lishuai Li",
      "Lei Zhang",
      "Gang Xiao"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2206.03085"
  },
  {
    "id": "arXiv:2206.03086",
    "title": "Online Deep Clustering with Video Track Consistency",
    "abstract": "Several unsupervised and self-supervised approaches have been developed in\nrecent years to learn visual features from large-scale unlabeled datasets.\nTheir main drawback however is that these methods are hardly able to recognize\nvisual features of the same object if it is simply rotated or the perspective\nof the camera changes. To overcome this limitation and at the same time exploit\na useful source of supervision, we take into account video object tracks.\nFollowing the intuition that two patches in a track should have similar visual\nrepresentations in a learned feature space, we adopt an unsupervised\nclustering-based approach and constrain such representations to be labeled as\nthe same category since they likely belong to the same object or object part.\nExperimental results on two downstream tasks on different datasets demonstrate\nthe effectiveness of our Online Deep Clustering with Video Track Consistency\n(ODCT) approach compared to prior work, which did not leverage temporal\ninformation. In addition we show that exploiting an unsupervised\nclass-agnostic, yet noisy, track generator yields to better accuracy compared\nto relying on costly and precise track annotations.",
    "descriptor": "\nComments: Accepted at ICPR2022 as oral\n",
    "authors": [
      "Alessandra Alfani",
      "Federico Becattini",
      "Lorenzo Seidenari",
      "Alberto Del Bimbo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.03086"
  },
  {
    "id": "arXiv:2206.03087",
    "title": "Critical Regularizations for Neural Surface Reconstruction in the Wild",
    "abstract": "Neural implicit functions have recently shown promising results on surface\nreconstructions from multiple views. However, current methods still suffer from\nexcessive time complexity and poor robustness when reconstructing unbounded or\ncomplex scenes. In this paper, we present RegSDF, which shows that proper point\ncloud supervisions and geometry regularizations are sufficient to produce\nhigh-quality and robust reconstruction results. Specifically, RegSDF takes an\nadditional oriented point cloud as input, and optimizes a signed distance field\nand a surface light field within a differentiable rendering framework. We also\nintroduce the two critical regularizations for this optimization. The first one\nis the Hessian regularization that smoothly diffuses the signed distance values\nto the entire distance field given noisy and incomplete input. And the second\none is the minimal surface regularization that compactly interpolates and\nextrapolates the missing geometry. Extensive experiments are conducted on DTU,\nBlendedMVS, and Tanks and Temples datasets. Compared with recent neural surface\nreconstruction approaches, RegSDF is able to reconstruct surfaces with fine\ndetails even for open scenes with complex topologies and unstructured camera\ntrajectories.",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Jingyang Zhang",
      "Yao Yao",
      "Shiwei Li",
      "Tian Fang",
      "David McKinnon",
      "Yanghai Tsin",
      "Long Quan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.03087"
  },
  {
    "id": "arXiv:2206.03093",
    "title": "Beyond spectral gap: The role of the topology in decentralized learning",
    "abstract": "In data-parallel optimization of machine learning models, workers collaborate\nto improve their estimates of the model: more accurate gradients allow them to\nuse larger learning rates and optimize faster. We consider the setting in which\nall workers sample from the same dataset, and communicate over a sparse graph\n(decentralized). In this setting, current theory fails to capture important\naspects of real-world behavior. First, the 'spectral gap' of the communication\ngraph is not predictive of its empirical performance in (deep) learning.\nSecond, current theory does not explain that collaboration enables larger\nlearning rates than training alone. In fact, it prescribes smaller learning\nrates, which further decrease as graphs become larger, failing to explain\nconvergence in infinite graphs. This paper aims to paint an accurate picture of\nsparsely-connected distributed optimization when workers share the same data\ndistribution. We quantify how the graph topology influences convergence in a\nquadratic toy problem and provide theoretical results for general smooth and\n(strongly) convex objectives. Our theory matches empirical observations in deep\nlearning, and accurately describes the relative merits of different graph\ntopologies.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Thijs Vogels",
      "Hadrien Hendrikx",
      "Martin Jaggi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.03093"
  },
  {
    "id": "arXiv:2206.03097",
    "title": "Locality-sensitive bucketing functions",
    "abstract": "Many bioinformatics applications involve bucketing a set of sequences where\neach sequence is allowed to be assigned into multiple buckets. To achieve both\nhigh sensitivity and precision, bucketing methods are desired to assign similar\nsequences into the same buckets while assigning dissimilar sequences into\ndistinct buckets. Existing $k$-mer-based bucketing methods have been efficient\nin processing sequencing data with low-error rate, but encounter much reduced\nsensitivity on data with high-error rate. Locality-sensitive hashing (LSH)\nschemes are able to mitigate this issue through tolerating the edits in similar\nsequences, but state-of-the-art methods still have large gap. Here we\ngeneralize the LSH function by allowing it to hash one sequence into multiple\nbuckets. Formally, a bucketing function, which maps a sequence (of fixed\nlength) into a subset of buckets, is defined to be $(d_1, d_2)$-sensitive if\nany two sequences within an edit distance of $d_1$ are mapped into at least one\nshared bucket, and any two sequences with distance at least $d_2$ are mapped\ninto disjoint subsets of buckets. We construct LSB functions with a variety of\nvalues of $(d_1,d_2)$ and analyze their efficiency with respect to the total\nnumber of buckets needed as well as the number of buckets that a specific\nsequence is mapped to. We also prove lower bounds of these two parameters in\ndifferent settings and show that some of our constructed LSB functions are\noptimal. These results provide theoretical foundations for their practical use\nin analyzing sequencing data with high error rate while also providing insights\nfor the hardness of designing ungapped LSH functions.",
    "descriptor": "\nComments: 11 pages, 2 figures\n",
    "authors": [
      "Ke Chen",
      "Mingfu Shao"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.03097"
  },
  {
    "id": "arXiv:2206.03098",
    "title": "Better Best of Both Worlds Bounds for Bandits with Switching Costs",
    "abstract": "We study best-of-both-worlds algorithms for bandits with switching cost,\nrecently addressed by Rouyer, Seldin and Cesa-Bianchi, 2021. We introduce a\nsurprisingly simple and effective algorithm that simultaneously achieves\nminimax optimal regret bound of $\\mathcal{O}(T^{2/3})$ in the oblivious\nadversarial setting and a bound of $\\mathcal{O}(\\min\\{\\log\n(T)/\\Delta^2,T^{2/3}\\})$ in the stochastically-constrained regime, both with\n(unit) switching costs, where $\\Delta$ is the gap between the arms. In the\nstochastically constrained case, our bound improves over previous results due\nto Rouyer et al., that achieved regret of $\\mathcal{O}(T^{1/3}/\\Delta)$. We\naccompany our results with a lower bound showing that, in general,\n$\\tilde{\\Omega}(\\min\\{1/\\Delta^2,T^{2/3}\\})$ regret is unavoidable in the\nstochastically-constrained case for algorithms with $\\mathcal{O}(T^{2/3})$\nworst-case regret.",
    "descriptor": "",
    "authors": [
      "Idan Amir",
      "Guy Azov",
      "Tomer Koren",
      "Roi Livni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03098"
  },
  {
    "id": "arXiv:2206.03105",
    "title": "Dual Swin-Transformer based Mutual Interactive Network for RGB-D Salient  Object Detection",
    "abstract": "Salient Object Detection is the task of predicting the human attended region\nin a given scene. Fusing depth information has been proven effective in this\ntask. The main challenge of this problem is how to aggregate the complementary\ninformation from RGB modality and depth modality. However, conventional deep\nmodels heavily rely on CNN feature extractors, and the long-range contextual\ndependencies are usually ignored. In this work, we propose Dual\nSwin-Transformer based Mutual Interactive Network. We adopt Swin-Transformer as\nthe feature extractor for both RGB and depth modality to model the long-range\ndependencies in visual inputs. Before fusing the two branches of features into\none, attention-based modules are applied to enhance features from each\nmodality. We design a self-attention-based cross-modality interaction module\nand a gated modality attention module to leverage the complementary information\nbetween the two modalities. For the saliency decoding, we create different\nstages enhanced with dense connections and keep a decoding memory while the\nmulti-level encoding features are considered simultaneously. Considering the\ninaccurate depth map issue, we collect the RGB features of early stages into a\nskip convolution module to give more guidance from RGB modality to the final\nsaliency prediction. In addition, we add edge supervision to regularize the\nfeature learning process. Comprehensive experiments on five standard RGB-D SOD\nbenchmark datasets over four evaluation metrics demonstrate the superiority of\nthe proposed DTMINet method.",
    "descriptor": "",
    "authors": [
      "Chao Zeng",
      "Sam Kwong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.03105"
  },
  {
    "id": "arXiv:2206.03106",
    "title": "Performance of Offloading Strategies in Collocated Deployments of  Millimeter Wave NR-U Technology",
    "abstract": "5G New Radio (NR) technology operating in millimeter wave (mmWave) band is\nexpected to be utilized in areas with high and fluctuating traffic demands such\nas city squares, shopping malls, etc. The latter may result in quality of\nservice (QoS) violations. To deal with this challenge, 3GPP has recently\nproposed NR unlicensed (NR-U) technology that may utilize 60 GHz frequency\nband. In this paper, we investigate the deployment of NR-U base stations (BS)\nsimultaneously operating in licensed and unlicensed mmWave bands in presence of\ncompeting WiGig traffic, where NR-U users may use unlicensed band as long as\nsession rate requirements are met. To this aim, we utilize the tools of\nstochastic geometry, Markov chains, and queuing systems with random resource\nrequirements to simultaneously capture NR-U/WiGig coexistence mechanism and\nsession service dynamics in the presence of mmWave-specific channel\nimpairments. We then proceed comparing performance of different offloading\nstrategies by utilizing the eventual session loss probability as the main\nmetric of interest. Our results show non-trivial behaviour of the collision\nprobability in the unlicensed band as compared to lower frequency systems. The\nbaseline strategy, where a session is offloaded onto unlicensed band only when\nthere are no resources available in the licensed one, leads to the best\nperformance. The offloading strategy, where sessions with heavier-than-average\nrequirements are immediately directed onto unlicensed band results in just\n$2-5\\%$ performance loss. The worst performance is observed when sessions with\nsmaller-than-average requirements are offloaded onto unlicensed band.",
    "descriptor": "\nComments: 14 pages, 19 figures. Submitted to IEEE Transactions on Vehicular Technology\n",
    "authors": [
      "Anastasia Daraseliya",
      "Eduard Sopin",
      "Dmitri Moltchanov",
      "Yevgeni Koucheryavy",
      "Konstantin Samouylov"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.03106"
  },
  {
    "id": "arXiv:2206.03108",
    "title": "User Association and Multi-connectivity Strategies in Joint Terahertz  and Millimeter Wave 6G Systems",
    "abstract": "Terahertz (THz) wireless access is considered as a next step towards sixth\ngeneration (6G) cellular systems. By utilizing even higher frequency bands than\n5G millimeter wave (mmWave) New Radio (NR), they will operate over extreme\nbandwidth delivering unprecedented rates at the access interface. However, by\nrelying upon pencil-wide beams, these systems will not only inherit mmWave\npropagation challenges such as blockage phenomenon but introduce their own\nissues associated with micromobility of user equipment (UE). In this paper, we\nanalyze and compare user association schemes and multi-connectivity strategies\nfor joint 6G THz/mmWave deployments. Differently, from stochastic geometry\nstudies, we develop a unified analytically tractable framework that\nsimultaneously accounts for specifics of THz and mmWave radio part design and\ntraffic service specifics at mmWave and THz base stations (BS). Our results\nshow that (i) for negligible blockers density, $\\lambda_B\\leq{}0.1$ bl./$m^2$,\nthe operator needs to enlarge the coverage of THz BS by accepting sessions that\nexperience outage in case of blockage (ii) for $\\lambda_B>0.1$ bl./$m^2$, only\nthose sessions that does not experience outage in case of blockage need to be\naccepted at THz BS, (iii) THz/mmWave multi-connectivity improves the ongoing\nsession loss probability by $0.1-0.4$ depending on the system parameters.",
    "descriptor": "\nComments: 15 pages, 19 figures. Submitted to IEEE Transactions on Vehicular Technology\n",
    "authors": [
      "Eduard Sopin",
      "Dmitri Moltchanov",
      "Anastasia Daraseliya",
      "Yevgeni Koucheryavy",
      "Yuliya Gaidamaka"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.03108"
  },
  {
    "id": "arXiv:2206.03109",
    "title": "Relevant Reasoners in a Classical World",
    "abstract": "We develop a framework for epistemic logic that combines relevant modal logic\nwith classical propositional logic. In our framework the agent is modeled as\nreasoning in accordance with a relevant modal logic while the propositional\nfragment of our logics is classical. In order to achieve this feature, we\nmodify the relational semantics for relevant modal logics so that validity in a\nmodel is defined as satisfaction throughout a set of designated states that, as\nfar as propositional connectives are concerned, behave like classical possible\nworlds. The main technical result of the paper is a modular completeness\ntheorem parametrized by the relevant modal logic formalizing the agent's\nreasoning.",
    "descriptor": "\nComments: To appear in Advances in Modal Logic 2022\n",
    "authors": [
      "Igor Sedl\u00e1r",
      "Pietro Vigiani"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.03109"
  },
  {
    "id": "arXiv:2206.03111",
    "title": "MIRNF: Medical Image Registration via Neural Fields",
    "abstract": "Image registration is widely used in medical image analysis to provide\nspatial correspondences between two images. Recently learning-based methods\nutilizing convolutional neural networks (CNNs) have been proposed for solving\nimage registration problems. The learning-based methods tend to be much faster\nthan traditional optimization-based methods, but the accuracy improvements\ngained from the complex CNN-based methods are modest. Here we introduce a new\ndeep-neural net-based image registration framework, named \\textbf{MIRNF}, which\nrepresents the correspondence mapping with a continuous function implemented\nvia Neural Fields. MIRNF outputs either a deformation vector or velocity vector\ngiven a 3D coordinate as input. To ensure the mapping is diffeomorphic, the\nvelocity vector output from MIRNF is integrated using the Neural ODE solver to\nderive the correspondences between two images. Furthermore, we propose a hybrid\ncoordinate sampler along with a cascaded architecture to achieve the\nhigh-similarity mapping performance and low-distortion deformation fields. We\nconduct experiments on two 3D MR brain scan datasets, showing that our proposed\nframework provides state-of-art registration performance while maintaining\ncomparable optimization time.",
    "descriptor": "",
    "authors": [
      "Shanlin Sun",
      "Kun Han",
      "Deying Kong",
      "Chenyu You",
      "Xiaohui Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.03111"
  },
  {
    "id": "arXiv:2206.03112",
    "title": "Singapore Soundscape Site Selection Survey (S5): Identification of  Characteristic Soundscapes of Singapore via Weighted k-means Clustering",
    "abstract": "The ecological validity of soundscape studies usually rests on a choice of\nsoundscapes that are representative of the perceptual space under\ninvestigation. For example, a soundscape pleasantness study might investigate\nlocations with soundscapes ranging from \"pleasant\" to \"annoying\". The choice of\nsoundscapes is typically researcher-led, but a participant-led process can\nreduce selection bias and improve result reliability. Hence, we propose a\nrobust participant-led method to pinpoint characteristic soundscapes possessing\narbitrary perceptual attributes. We validate our method by identifying\nSingaporean soundscapes spanning the perceptual quadrants generated from the\n\"Pleasantness\" and \"Eventfulness\" axes of the ISO 12913-2 circumplex model of\nsoundscape perception, as perceived by local experts. From memory and\nexperience, 67 participants first selected locations corresponding to each\nperceptual quadrant in each major planning region of Singapore. We then\nperformed weighted k-means clustering on the selected locations, with weights\nfor each location derived from previous frequencies and durations spent in each\nlocation by each participant. Weights hence acted as proxies for participant\nconfidence. In total, 62 locations were thereby identified as suitable\nlocations with characteristic soundscapes for further research utilizing the\nISO 12913-2 perceptual quadrants. Audio-visual recordings and acoustic\ncharacterization of the soundscapes will be made in a future study.",
    "descriptor": "\nComments: 23 pages, 8 figures. Submitted to Sustainability\n",
    "authors": [
      "Kenneth Ooi",
      "Bhan Lam",
      "Joo Young Hong",
      "Karn N. Watcharasupat",
      "Zhen-Ting Ong",
      "Woon-Seng Gan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.03112"
  },
  {
    "id": "arXiv:2206.03113",
    "title": "Wavelet Prior Attention Learning in Axial Inpainting Network",
    "abstract": "Image inpainting is the task of filling masked or unknown regions of an image\nwith visually realistic contents, which has been remarkably improved by Deep\nNeural Networks (DNNs) recently. Essentially, as an inverse problem, the\ninpainting has the underlying challenges of reconstructing semantically\ncoherent results without texture artifacts. Many previous efforts have been\nmade via exploiting attention mechanisms and prior knowledge, such as edges and\nsemantic segmentation. However, these works are still limited in practice by an\navalanche of learnable prior parameters and prohibitive computational burden.\nTo this end, we propose a novel model -- Wavelet prior attention learning in\nAxial Inpainting Network (WAIN), whose generator contains the encoder, decoder,\nas well as two key components of Wavelet image Prior Attention (WPA) and\nstacked multi-layer Axial-Transformers (ATs). Particularly, the WPA guides the\nhigh-level feature aggregation in the multi-scale frequency domain, alleviating\nthe textual artifacts. Stacked ATs employ unmasked clues to help model\nreasonable features along with low-level features of horizontal and vertical\naxes, improving the semantic coherence. Extensive quantitative and qualitative\nexperiments on Celeba-HQ and Places2 datasets are conducted to validate that\nour WAIN can achieve state-of-the-art performance over the competitors. The\ncodes and models will be released.",
    "descriptor": "",
    "authors": [
      "Chenjie Cao",
      "Chengrong Wang",
      "Yuntao Zhang",
      "Yanwei Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.03113"
  },
  {
    "id": "arXiv:2206.03124",
    "title": "Normalisations of Existential Rules: Not so Innocuous!",
    "abstract": "Existential rules are an expressive knowledge representation language mainly\ndeveloped to query data. In the literature, they are often supposed to be in\nsome normal form that simplifies technical developments. For instance, a common\nassumption is that rule heads are atomic, i.e., restricted to a single atom.\nSuch assumptions are considered to be made without loss of generality as long\nas all sets of rules can be normalised while preserving entailment. However, an\nimportant question is whether the properties that ensure the decidability of\nreasoning are preserved as well. We provide a systematic study of the impact of\nthese procedures on the different chase variants with respect to chase\n(non-)termination and FO-rewritability. This also leads us to study open\nproblems related to chase termination of independent interest.",
    "descriptor": "\nComments: Published at 19th International Conference on Principles of Knowledge Representation and Reasoning, KR 2022\n",
    "authors": [
      "David Carral",
      "Lucas Larroque",
      "Marie-Laure Mugnier",
      "Micha\u00ebl Thomazo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.03124"
  },
  {
    "id": "arXiv:2206.03125",
    "title": "Monte Carlo integration with adaptive variance reduction: an asymptotic  analysis",
    "abstract": "The crude Monte Carlo approximates the integral $$S(f)=\\int_a^b f(x)\\,\\mathrm\ndx$$ with expected error (deviation) $\\sigma(f)N^{-1/2},$ where $\\sigma(f)^2$\nis the variance of $f$ and $N$ is the number of random samples. If $f\\in C^r$\nthen special variance reduction techniques can lower this error to the level\n$N^{-(r+1/2)}.$ In this paper, we consider methods of the form $$\\overline\nM_{N,r}(f)=S(L_{m,r}f)+M_n(f-L_{m,r}f),$$ where $L_{m,r}$ is the piecewise\npolynomial interpolation of $f$ of degree $r-1$ using a partition of the\ninterval $[a,b]$ into $m$ subintervals, $M_n$ is a Monte Carlo approximation\nusing $n$ samples of $f,$ and $N$ is the total number of function evaluations\nused. We derive asymptotic error formulas for the methods $\\overline M_{N,r}$\nthat use nonadaptive as well as adaptive partitions. Although the convergence\nrate $N^{-(r+1/2)}$ cannot be beaten, the asymptotic constants make a huge\ndifference. For example, for $\\int_0^1(x+d)^{-1}\\mathrm dx$ and $r=4$ the best\nadaptive methods overcome the nonadaptive ones roughly $10^{12}$ times if\n$d=10^{-4},$ and $10^{29}$ times if $d=10^{-8}.$ In addition, the proposed\nadaptive methods are easily implementable and can be well used for automatic\nintegration.\nWe believe that the obtained results can be generalized to multivariate\nintegration.",
    "descriptor": "",
    "authors": [
      "Leszek Plaskota",
      "Pawe\u0142 Przyby\u0142owicz",
      "\u0141ukasz St\u0119pie\u0144"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.03125"
  },
  {
    "id": "arXiv:2206.03126",
    "title": "Signal Propagation in Transformers: Theoretical Perspectives and the  Role of Rank Collapse",
    "abstract": "Transformers have achieved remarkable success in several domains, ranging\nfrom natural language processing to computer vision. Nevertheless, it has been\nrecently shown that stacking self-attention layers - the distinctive\narchitectural component of Transformers - can result in rank collapse of the\ntokens' representations at initialization. The question of if and how rank\ncollapse affects training is still largely unanswered, and its investigation is\nnecessary for a more comprehensive understanding of this architecture. In this\nwork, we shed new light on the causes and the effects of this phenomenon.\nFirst, we show that rank collapse of the tokens' representations hinders\ntraining by causing the gradients of the queries and keys to vanish at\ninitialization. Furthermore, we provide a thorough description of the origin of\nrank collapse and discuss how to prevent it via an appropriate depth-dependent\nscaling of the residual branches. Finally, our analysis unveils that specific\narchitectural hyperparameters affect the gradients of queries and values\ndifferently, leading to disproportionate gradient norms. This suggests an\nexplanation for the widespread use of adaptive methods for Transformers'\noptimization.",
    "descriptor": "",
    "authors": [
      "Lorenzo Noci",
      "Sotiris Anagnostidis",
      "Luca Biggio",
      "Antonio Orvieto",
      "Sidak Pal Singh",
      "Aurelien Lucchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03126"
  },
  {
    "id": "arXiv:2206.03127",
    "title": "Data-driven evolutionary algorithm for oil reservoir well-placement and  control optimization",
    "abstract": "Optimal well placement and well injection-production are crucial for the\nreservoir development to maximize the financial profits during the project\nlifetime. Meta-heuristic algorithms have showed good performance in solving\ncomplex, nonlinear and non-continuous optimization problems. However, a large\nnumber of numerical simulation runs are involved during the optimization\nprocess. In this work, a novel and efficient data-driven evolutionary\nalgorithm, called generalized data-driven differential evolutionary algorithm\n(GDDE), is proposed to reduce the number of simulation runs on well-placement\nand control optimization problems. Probabilistic neural network (PNN) is\nadopted as the classifier to select informative and promising candidates, and\nthe most uncertain candidate based on Euclidean distance is prescreened and\nevaluated with a numerical simulator. Subsequently, local surrogate model is\nbuilt by radial basis function (RBF) and the optimum of the surrogate, found by\noptimizer, is evaluated by the numerical simulator to accelerate the\nconvergence. It is worth noting that the shape factors of RBF model and PNN are\noptimized via solving hyper-parameter sub-expensive optimization problem. The\nresults show the optimization algorithm proposed in this study is very\npromising for a well-placement optimization problem of two-dimensional\nreservoir and joint optimization of Egg model.",
    "descriptor": "",
    "authors": [
      "Guodong Chen",
      "Xin Luo",
      "Jimmy Jiu Jiao",
      "Xiaoming Xue"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.03127"
  },
  {
    "id": "arXiv:2206.03128",
    "title": "Spatial-Temporal Adaptive Graph Convolution with Attention Network for  Traffic Forecasting",
    "abstract": "Traffic forecasting is one canonical example of spatial-temporal learning\ntask in Intelligent Traffic System. Existing approaches capture spatial\ndependency with a pre-determined matrix in graph convolution neural operators.\nHowever, the explicit graph structure losses some hidden representations of\nrelationships among nodes. Furthermore, traditional graph convolution neural\noperators cannot aggregate long-range nodes on the graph. To overcome these\nlimits, we propose a novel network, Spatial-Temporal Adaptive graph convolution\nwith Attention Network (STAAN) for traffic forecasting. Firstly, we adopt an\nadaptive dependency matrix instead of using a pre-defined matrix during GCN\nprocessing to infer the inter-dependencies among nodes. Secondly, we integrate\nPW-attention based on graph attention network which is designed for global\ndependency, and GCN as spatial block. What's more, a stacked dilated 1D\nconvolution, with efficiency in long-term prediction, is adopted in our\ntemporal block for capturing the different time series. We evaluate our STAAN\non two real-world datasets, and experiments validate that our model outperforms\nstate-of-the-art baselines.",
    "descriptor": "",
    "authors": [
      "Chen Weikang",
      "Li Yawen",
      "Xue Zhe",
      "Li Ang",
      "Wu Guobin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2206.03128"
  },
  {
    "id": "arXiv:2206.03129",
    "title": "Energy-preserving Mixed finite element methods for a ferrofluid flow  model",
    "abstract": "In this paper, we develop a class of mixed finite element methods for the\nferrofluid flow model proposed by Shliomis [Soviet Physics JETP, 1972]. We show\nthat the energy stability of the weak solutions to the model is preserved\nexactly for both the semi- and fully discrete finite element solutions.\nFurthermore, we prove the existence and uniqueness of the discrete solutions\nand derive optimal error estimates for both the the semi- and fully discrete\nschemes. Numerical experiments confirm the theoretical results.",
    "descriptor": "",
    "authors": [
      "Yongke Wu",
      "Xiaoping Xie"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.03129"
  },
  {
    "id": "arXiv:2206.03130",
    "title": "Towards Meta-learned Algorithm Selection using Implicit Fidelity  Information",
    "abstract": "Automatically selecting the best performing algorithm for a given dataset or\nranking multiple of them by their expected performance supports users in\ndeveloping new machine learning applications. Most approaches for this problem\nrely on dataset meta-features and landmarking performances to capture the\nsalient topology of the datasets and those topologies that the algorithms\nattend to. Landmarking usually exploits cheap algorithms not necessarily in the\npool of candidate algorithms to get inexpensive approximations of the topology.\nWhile somewhat indicative, handcrafted dataset meta-features and landmarks are\nlikely insufficient descriptors, strongly depending on the alignment of the\ngeometries the landmarks and candidates search for. We propose IMFAS, a method\nto exploit multi-fidelity landmarking information directly from the candidate\nalgorithms in the form of non-parametrically non-myopic meta-learned learning\ncurves via LSTM networks in a few-shot setting during testing. Using this\nmechanism, IMFAS jointly learns the topology of of the datasets and the\ninductive biases of algorithms without expensively training them to\nconvergence. IMFAS produces informative landmarks, easily enriched by arbitrary\nmeta-features at a low computational cost, capable of producing the desired\nranking using cheaper fidelities. We additionally show that it is able to beat\nSuccessive Halving with at most half the fidelity sequence during test time",
    "descriptor": "\nComments: 9 pages, 2 figures, 3 tables\n",
    "authors": [
      "Aditya Mohan",
      "Tim Ruhkopf",
      "Marius Lindauer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03130"
  },
  {
    "id": "arXiv:2206.03132",
    "title": "CitySpec: An Intelligent Assistant System for Requirement Specification  in Smart Cities",
    "abstract": "An increasing number of monitoring systems have been developed in smart\ncities to ensure that real-time operations of a city satisfy safety and\nperformance requirements. However, many existing city requirements are written\nin English with missing, inaccurate, or ambiguous information. There is a high\ndemand for assisting city policy makers in converting human-specified\nrequirements to machine-understandable formal specifications for monitoring\nsystems. To tackle this limitation, we build CitySpec, the first intelligent\nassistant system for requirement specification in smart cities. To create\nCitySpec, we first collect over 1,500 real-world city requirements across\ndifferent domains from over 100 cities and extract city-specific knowledge to\ngenerate a dataset of city vocabulary with 3,061 words. We also build a\ntranslation model and enhance it through requirement synthesis and develop a\nnovel online learning framework with validation under uncertainty. The\nevaluation results on real-world city requirements show that CitySpec increases\nthe sentence-level accuracy of requirement specification from 59.02% to 86.64%,\nand has strong adaptability to a new city and a new domain (e.g., F1 score for\nrequirements in Seattle increases from 77.6% to 93.75% with online learning).",
    "descriptor": "\nComments: This paper is accepted by SMARTCOMP 2022\n",
    "authors": [
      "Zirong Chen",
      "Isaac Li",
      "Haoxiang Zhang",
      "Sarah Preum",
      "John A. Stankovic",
      "Meiyi Ma"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03132"
  },
  {
    "id": "arXiv:2206.03139",
    "title": "Intra-agent speech permits zero-shot task acquisition",
    "abstract": "Human language learners are exposed to a trickle of informative,\ncontext-sensitive language, but a flood of raw sensory data. Through both\nsocial language use and internal processes of rehearsal and practice, language\nlearners are able to build high-level, semantic representations that explain\ntheir perceptions. Here, we take inspiration from such processes of \"inner\nspeech\" in humans (Vygotsky, 1934) to better understand the role of intra-agent\nspeech in embodied behavior. First, we formally pose intra-agent speech as a\nsemi-supervised problem and develop two algorithms that enable visually\ngrounded captioning with little labeled language data. We then experimentally\ncompute scaling curves over different amounts of labeled data and compare the\ndata efficiency against a supervised learning baseline. Finally, we incorporate\nintra-agent speech into an embodied, mobile manipulator agent operating in a 3D\nvirtual world, and show that with as few as 150 additional image captions,\nintra-agent speech endows the agent with the ability to manipulate and answer\nquestions about a new object without any related task-directed experience\n(zero-shot). Taken together, our experiments suggest that modelling intra-agent\nspeech is effective in enabling embodied agents to learn new tasks efficiently\nand without direct interaction experience.",
    "descriptor": "",
    "authors": [
      "Chen Yan",
      "Federico Carnevale",
      "Petko Georgiev",
      "Adam Santoro",
      "Aurelia Guy",
      "Alistair Muldal",
      "Chia-Chun Hung",
      "Josh Abramson",
      "Timothy Lillicrap",
      "Gregory Wayne"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.03139"
  },
  {
    "id": "arXiv:2206.03149",
    "title": "Self-Training of Handwritten Word Recognition for Synthetic-to-Real  Adaptation",
    "abstract": "Performances of Handwritten Text Recognition (HTR) models are largely\ndetermined by the availability of labeled and representative training samples.\nHowever, in many application scenarios labeled samples are scarce or costly to\nobtain. In this work, we propose a self-training approach to train a HTR model\nsolely on synthetic samples and unlabeled data. The proposed training scheme\nuses an initial model trained on synthetic data to make predictions for the\nunlabeled target dataset. Starting from this initial model with rather poor\nperformance, we show that a considerable adaptation is possible by training\nagainst the predicted pseudo-labels. Moreover, the investigated self-training\nstrategy does not require any manually annotated training samples. We evaluate\nthe proposed method on four widely used benchmark datasets and show its\neffectiveness on closing the gap to a model trained in a fully-supervised\nmanner.",
    "descriptor": "",
    "authors": [
      "Fabian Wolf",
      "Gernot A. Fink"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.03149"
  },
  {
    "id": "arXiv:2206.03151",
    "title": "Shuffled Check-in: Privacy Amplification towards Practical Distributed  Learning",
    "abstract": "Recent studies of distributed computation with formal privacy guarantees,\nsuch as differentially private (DP) federated learning, leverage random\nsampling of clients in each round (privacy amplification by subsampling) to\nachieve satisfactory levels of privacy. Achieving this however requires strong\nassumptions which may not hold in practice, including precise and uniform\nsubsampling of clients, and a highly trusted aggregator to process clients'\ndata. In this paper, we explore a more practical protocol, shuffled check-in,\nto resolve the aforementioned issues. The protocol relies on client making\nindependent and random decision to participate in the computation, freeing the\nrequirement of server-initiated subsampling, and enabling robust modelling of\nclient dropouts. Moreover, a weaker trust model known as the shuffle model is\nemployed instead of using a trusted aggregator. To this end, we introduce new\ntools to characterize the R\\'enyi differential privacy (RDP) of shuffled\ncheck-in. We show that our new techniques improve at least three times in\nprivacy guarantee over those using approximate DP's strong composition at\nvarious parameter regimes. Furthermore, we provide a numerical approach to\ntrack the privacy of generic shuffled check-in mechanism including distributed\nstochastic gradient descent (SGD) with Gaussian mechanism. To the best of our\nknowledge, this is also the first evaluation of Gaussian mechanism within the\nlocal/shuffle model under the distributed setting in the literature, which can\nbe of independent interest.",
    "descriptor": "\nComments: 16 pages, 4 figures\n",
    "authors": [
      "Seng Pei Liew",
      "Satoshi Hasegawa",
      "Tsubasa Takahashi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.03151"
  },
  {
    "id": "arXiv:2206.03159",
    "title": "The Structure of Interdisciplinary Science: Uncovering and Explaining  Roles in Citation Graphs",
    "abstract": "Role discovery is the task of dividing the set of nodes on a graph into\nclasses of structurally similar roles. Modern strategies for role discovery\ntypically rely on graph embedding techniques, which are capable of recognising\ncomplex local structures. However, when working with large, real-world\nnetworks, it is difficult to interpret or validate a set of roles identified\naccording to these methods. In this work, motivated by advancements in the\nfield of explainable artificial intelligence (XAI), we propose a new framework\nfor interpreting role assignments on large graphs using small subgraph\nstructures known as graphlets. We demonstrate our methods on a large,\nmultidisciplinary citation network, where we successfully identify a number of\nimportant citation patterns which reflect interdisciplinary research",
    "descriptor": "\nComments: submitted to the international conference on complex networks and their applications\n",
    "authors": [
      "Eoghan Cunningham",
      "Derek Greene"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.03159"
  },
  {
    "id": "arXiv:2206.03164",
    "title": "Utility of Equivariant Message Passing in Cortical Mesh Segmentation",
    "abstract": "The automated segmentation of cortical areas has been a long-standing\nchallenge in medical image analysis. The complex geometry of the cortex is\ncommonly represented as a polygon mesh, whose segmentation can be addressed by\ngraph-based learning methods. When cortical meshes are misaligned across\nsubjects, current methods produce significantly worse segmentation results,\nlimiting their ability to handle multi-domain data. In this paper, we\ninvestigate the utility of E(n)-equivariant graph neural networks (EGNNs),\ncomparing their performance against plain graph neural networks (GNNs). Our\nevaluation shows that GNNs outperform EGNNs on aligned meshes, due to their\nability to leverage the presence of a global coordinate system. On misaligned\nmeshes, the performance of plain GNNs drop considerably, while E(n)-equivariant\nmessage passing maintains the same segmentation results. The best results can\nalso be obtained by using plain GNNs on realigned data (co-registered meshes in\na global coordinate system).",
    "descriptor": "\nComments: 13 pages, 2 figures, accepted for MIUA 2022\n",
    "authors": [
      "D\u00e1niel Unyi",
      "Ferdinando Insalata",
      "Petar Veli\u010dkovi\u0107",
      "B\u00e1lint Gyires-T\u00f3th"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03164"
  },
  {
    "id": "arXiv:2206.03165",
    "title": "Decentralized Low-Latency Collaborative Inference via Ensembles on the  Edge",
    "abstract": "The success of deep neural networks (DNNs) is heavily dependent on\ncomputational resources. While DNNs are often employed on cloud servers, there\nis a growing need to operate DNNs on edge devices. Edge devices are typically\nlimited in their computational resources, yet, often multiple edge devices are\ndeployed in the same environment and can reliably communicate with each other.\nIn this work we propose to facilitate the application of DNNs on the edge by\nallowing multiple users to collaborate during inference to improve their\naccuracy. Our mechanism, coined {\\em edge ensembles}, is based on having\ndiverse predictors at each device, which form an ensemble of models during\ninference. To mitigate the communication overhead, the users share quantized\nfeatures, and we propose a method for aggregating multiple decisions into a\nsingle inference rule. We analyze the latency induced by edge ensembles,\nshowing that its performance improvement comes at the cost of a minor\nadditional delay under common assumptions on the communication network. Our\nexperiments demonstrate that collaborative inference via edge ensembles\nequipped with compact DNNs substantially improves the accuracy over having each\nuser infer locally, and can outperform using a single centralized DNN larger\nthan all the networks in the ensemble together.",
    "descriptor": "",
    "authors": [
      "May Malka",
      "Erez Farhan",
      "Hai Morgenstern",
      "Nir Shlezinger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.03165"
  },
  {
    "id": "arXiv:2206.03171",
    "title": "Look Back When Surprised: Stabilizing Reverse Experience Replay for  Neural Approximation",
    "abstract": "Experience replay methods, which are an essential part of reinforcement\nlearning(RL) algorithms, are designed to mitigate spurious correlations and\nbiases while learning from temporally dependent data. Roughly speaking, these\nmethods allow us to draw batched data from a large buffer such that these\ntemporal correlations do not hinder the performance of descent algorithms. In\nthis experimental work, we consider the recently developed and theoretically\nrigorous reverse experience replay (RER), which has been shown to remove such\nspurious biases in simplified theoretical settings. We combine RER with\noptimistic experience replay (OER) to obtain RER++, which is stable under\nneural function approximation. We show via experiments that this has a better\nperformance than techniques like prioritized experience replay (PER) on various\ntasks, with a significantly smaller computational complexity. It is well known\nin the RL literature that choosing examples greedily with the largest TD error\n(as in OER) or forming mini-batches with consecutive data points (as in RER)\nleads to poor performance. However, our method, which combines these\ntechniques, works very well.",
    "descriptor": "",
    "authors": [
      "Ramnath Kumar",
      "Dheeraj Nagaraj"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03171"
  },
  {
    "id": "arXiv:2206.03172",
    "title": "Representational Systems Theory: A Unified Approach to Encoding,  Analysing and Transforming Representations",
    "abstract": "The study of representations is of fundamental importance to any form of\ncommunication, and our ability to exploit them effectively is paramount. This\narticle presents a novel theory -- Representational Systems Theory -- that is\ndesigned to abstractly encode a wide variety of representations from three core\nperspectives: syntax, entailment, and their properties. By introducing the\nconcept of a construction space, we are able to encode each of these core\ncomponents under a single, unifying paradigm. Using our Representational\nSystems Theory, it becomes possible to structurally transform representations\nin one system into representations in another. An intrinsic facet of our\nstructural transformation technique is representation selection based on\nproperties that representations possess, such as their relative cognitive\neffectiveness or structural complexity. A major theoretical barrier to\nproviding general structural transformation techniques is a lack of terminating\nalgorithms. Representational Systems Theory permits the derivation of partial\ntransformations when no terminating algorithm can produce a full\ntransformation. Since Representational Systems Theory provides a universal\napproach to encoding representational systems, a further key barrier is\neliminated: the need to devise system-specific structural transformation\nalgorithms, that are necessary when different systems adopt different\nformalisation approaches. Consequently, Representational Systems Theory is the\nfirst general framework that provides a unified approach to encoding\nrepresentations, supports representation selection via structural\ntransformations, and has the potential for widespread practical application.",
    "descriptor": "\nComments: 118 pages total: 94 of main paper + 2 of references + 22 of appendices. Submitted to JACM. Authors Gem Stapleton and Daniel Raggi contributed equally to this research\n",
    "authors": [
      "Daniel Raggi",
      "Gem Stapleton",
      "Mateja Jamnik",
      "Aaron Stockdill",
      "Grecia Garcia Garcia",
      "Peter C-H. Cheng"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.03172"
  },
  {
    "id": "arXiv:2206.03173",
    "title": "Speaker-Guided Encoder-Decoder Framework for Emotion Recognition in  Conversation",
    "abstract": "The emotion recognition in conversation (ERC) task aims to predict the\nemotion label of an utterance in a conversation. Since the dependencies between\nspeakers are complex and dynamic, which consist of intra- and inter-speaker\ndependencies, the modeling of speaker-specific information is a vital role in\nERC. Although existing researchers have proposed various methods of speaker\ninteraction modeling, they cannot explore dynamic intra- and inter-speaker\ndependencies jointly, leading to the insufficient comprehension of context and\nfurther hindering emotion prediction. To this end, we design a novel speaker\nmodeling scheme that explores intra- and inter-speaker dependencies jointly in\na dynamic manner. Besides, we propose a Speaker-Guided Encoder-Decoder (SGED)\nframework for ERC, which fully exploits speaker information for the decoding of\nemotion. We use different existing methods as the conversational context\nencoder of our framework, showing the high scalability and flexibility of the\nproposed framework. Experimental results demonstrate the superiority and\neffectiveness of SGED.",
    "descriptor": "\nComments: Accepted by IJCAI-ECAI 2022\n",
    "authors": [
      "Yinan Bao",
      "Qianwen Ma",
      "Lingwei Wei",
      "Wei Zhou",
      "Songlin Hu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.03173"
  },
  {
    "id": "arXiv:2206.03178",
    "title": "Fooling Explanations in Text Classifiers",
    "abstract": "State-of-the-art text classification models are becoming increasingly reliant\non deep neural networks (DNNs). Due to their black-box nature, faithful and\nrobust explanation methods need to accompany classifiers for deployment in\nreal-life scenarios. However, it has been shown in vision applications that\nexplanation methods are susceptible to local, imperceptible perturbations that\ncan significantly alter the explanations without changing the predicted\nclasses. We show here that the existence of such perturbations extends to text\nclassifiers as well. Specifically, we introduceTextExplanationFooler (TEF), a\nnovel explanation attack algorithm that alters text input samples imperceptibly\nso that the outcome of widely-used explanation methods changes considerably\nwhile leaving classifier predictions unchanged. We evaluate the performance of\nthe attribution robustness estimation performance in TEF on five sequence\nclassification datasets, utilizing three DNN architectures and three\ntransformer architectures for each dataset. TEF can significantly decrease the\ncorrelation between unchanged and perturbed input attributions, which shows\nthat all models and explanation methods are susceptible to TEF perturbations.\nMoreover, we evaluate how the perturbations transfer to other model\narchitectures and attribution methods, and show that TEF perturbations are also\neffective in scenarios where the target model and explanation method are\nunknown. Finally, we introduce a semi-universal attack that is able to compute\nfast, computationally light perturbations with no knowledge of the attacked\nclassifier nor explanation method. Overall, our work shows that explanations in\ntext classifiers are very fragile and users need to carefully address their\nrobustness before relying on them in critical applications.",
    "descriptor": "",
    "authors": [
      "Adam Ivankay",
      "Ivan Girardi",
      "Chiara Marchiori",
      "Pascal Frossard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03178"
  },
  {
    "id": "arXiv:2206.03179",
    "title": "TSFEDL: A Python Library for Time Series Spatio-Temporal Feature  Extraction and Prediction using Deep Learning (with Appendices on Detailed  Network Architectures and Experimental Cases of Study)",
    "abstract": "The combination of convolutional and recurrent neural networks is a promising\nframework that allows the extraction of high-quality spatio-temporal features\ntogether with its temporal dependencies, which is key for time series\nprediction problems such as forecasting, classification or anomaly detection,\namongst others. In this paper, the TSFEDL library is introduced. It compiles 20\nstate-of-the-art methods for both time series feature extraction and\nprediction, employing convolutional and recurrent deep neural networks for its\nuse in several data mining tasks. The library is built upon a set of\nTensorflow+Keras and PyTorch modules under the AGPLv3 license. The performance\nvalidation of the architectures included in this proposal confirms the\nusefulness of this Python package.",
    "descriptor": "\nComments: 26 pages, 33 figures\n",
    "authors": [
      "Ignacio Aguilera-Martos",
      "\u00c1ngel M. Garc\u00eda-Vico",
      "Juli\u00e1n Luengo",
      "Sergio Damas",
      "Francisco J. Melero",
      "Jos\u00e9 Javier Valle-Alonso",
      "Francisco Herrera"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.03179"
  },
  {
    "id": "arXiv:2206.03181",
    "title": "Detecting Global Community Structure in a COVID-19 Activity Correlation  Network",
    "abstract": "The global pandemic of COVID-19 over the last 2.5 years have produced an\nenormous amount of epidemic/public health datasets, which may also be useful\nfor studying the underlying structure of our globally connected world. Here we\nused the Johns Hopkins University COVID-19 dataset to construct a correlation\nnetwork of countries/regions and studied its global community structure.\nSpecifically, we selected countries/regions that had at least 100,000\ncumulative positive cases from the dataset and generated a 7-day moving average\ntime series of new positive cases reported for each country/region. We then\ncalculated a time series of daily change exponents by taking the day-to-day\ndifference in log of the number of new positive cases. We constructed a\ncorrelation network by connecting countries/regions that had positive\ncorrelations in their daily change exponent time series using their Pearson\ncorrelation coefficient as the edge weight. Applying the modularity\nmaximization method revealed that there were three major communities: (1)\nMainly Europe + North America + Southeast Asia that showed similar six-peak\npatterns during the pandemic, (2) mainly Near/Middle East + Central/South Asia\n+ Central/South America that loosely followed Community 1 but had a notable\nincrease of activities because of the Delta variant and was later impacted\nsignificantly by the Omicron variant, and (3) mainly Africa + Central/East\nCanada + Australia that did not have much activities until a huge spike was\ncaused by the Omicron variant. These three communities were robustly detected\nunder varied settings. Constructing a 3D \"phase space\" by using the median\ncurves in those three communities for x-y-z coordinates generated an effective\nsummary trajectory of how the global pandemic progressed.",
    "descriptor": "\nComments: 11 pages, 4 figures, 1 table\n",
    "authors": [
      "Hiroki Sayama"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.03181"
  },
  {
    "id": "arXiv:2206.03183",
    "title": "Risk Measures and Upper Probabilities: Coherence and Stratification",
    "abstract": "Machine learning typically presupposes classical probability theory which\nimplies that aggregation is built upon expectation. There are now multiple\nreasons to motivate looking at richer alternatives to classical probability\ntheory as a mathematical foundation for machine learning. We systematically\nexamine a powerful and rich class of such alternatives, known variously as\nspectral risk measures, Choquet integrals or Lorentz norms. We present a range\nof characterization results, and demonstrate what makes this spectral family so\nspecial. In doing so we demonstrate a natural stratification of all coherent\nrisk measures in terms of the upper probabilities that they induce by\nexploiting results from the theory of rearrangement invariant Banach spaces. We\nempirically demonstrate how this new approach to uncertainty helps tackling\npractical machine learning problems.",
    "descriptor": "",
    "authors": [
      "Christian Fr\u00f6hlich",
      "Robert C. Williamson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2206.03183"
  },
  {
    "id": "arXiv:2206.03185",
    "title": "A new Hyper-heuristic based on Adaptive Simulated Annealing and  Reinforcement Learning for the Capacitated Electric Vehicle Routing Problem",
    "abstract": "Electric vehicles (EVs) have been adopted in urban areas to reduce\nenvironmental pollution and global warming as a result of the increasing number\nof freight vehicles. However, there are still deficiencies in routing the\ntrajectories of last-mile logistics that continue to impact social and economic\nsustainability. For that reason, in this paper, a hyper-heuristic (HH) approach\ncalled Hyper-heuristic Adaptive Simulated Annealing with Reinforcement Learning\n(HHASA$_{RL}$) is proposed. It is composed of a multi-armed bandit method and\nthe self-adaptive Simulated Annealing (SA) metaheuristic algorithm for solving\nthe problem called Capacitated Electric Vehicle Routing Problem (CEVRP). Due to\nthe limited number of charging stations and the travel range of EVs, the EVs\nmust require battery recharging moments in advance and reduce travel times and\ncosts. The HH implemented improves multiple minimum best-known solutions and\nobtains the best mean values for some high-dimensional instances for the\nproposed benchmark for the IEEE WCCI2020 competition.",
    "descriptor": "\nComments: 26 pages, 6 figures, 6 tables\n",
    "authors": [
      "Erick Rodr\u00edguez-Esparza",
      "Antonio D Masegosa",
      "Diego Oliva",
      "Enrique Onieva"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03185"
  },
  {
    "id": "arXiv:2206.03189",
    "title": "Quantifying the Effects of Working in VR for One Week",
    "abstract": "Virtual Reality (VR) provides new possibilities for modern knowledge work.\nHowever, the potential advantages of virtual work environments can only be used\nif it is feasible to work in them for an extended period of time. Until now,\nthere are limited studies of long-term effects when working in VR. This paper\naddresses the need for understanding such long-term effects. Specifically, we\nreport on a comparative study (n=16), in which participants were working in VR\nfor an entire week -- for five days, eight hours each day -- as well as in a\nbaseline physical desktop environment. This study aims to quantify the effects\nof exchanging a desktop-based work environment with a VR-based environment.\nHence, during this study, we do not present the participants with the best\npossible VR system but rather a setup delivering a comparable experience to\nworking in the physical desktop environment. The study reveals that, as\nexpected, VR results in significantly worse ratings across most measures. Among\nother results, we found concerning levels of simulator sickness, below average\nusability ratings and two participants dropped out on the first day using VR,\ndue to migraine, nausea and anxiety. Nevertheless, there is some indication\nthat participants gradually overcame negative first impressions and initial\ndiscomfort. Overall, this study helps lay the groundwork for subsequent\nresearch, by clearly highlighting current shortcomings and identifying\nopportunities for improving the experience of working in VR.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Verena Biener Snehanjali Kalamkar",
      "Negar Nouri",
      "Eyal Ofek",
      "Michel Pahud",
      "John J. Dudley",
      "Jinghui Hu",
      "Per Ola Kristensson",
      "Maheshya Weerasinghe",
      "Klen \u010copi\u010d Pucihar",
      "Matja\u017e Kljun",
      "Stephan Streuber",
      "Jens Grubert"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.03189"
  },
  {
    "id": "arXiv:2206.03190",
    "title": "TRAVEL: Traversable Ground and Above-Ground Object Segmentation Using  Graph Representation of 3D LiDAR Scans",
    "abstract": "Perception of traversable regions and objects of interest from a 3D point\ncloud is one of the critical tasks in autonomous navigation. A ground vehicle\nneeds to look for traversable terrains that are explorable by wheels. Then, to\nmake safe navigation decisions, the segmentation of objects positioned on those\nterrains has to be followed up. However, over-segmentation and\nunder-segmentation can negatively influence such navigation decisions. To that\nend, we propose TRAVEL, which performs traversable ground detection and object\nclustering simultaneously using the graph representation of a 3D point cloud.\nTo segment the traversable ground, a point cloud is encoded into a graph\nstructure, tri-grid field, which treats each tri-grid as a node. Then, the\ntraversable regions are searched and redefined by examining local convexity and\nconcavity of edges that connect nodes. On the other hand, our above-ground\nobject segmentation employs a graph structure by representing a group of\nhorizontally neighboring 3D points in a spherical-projection space as a node\nand vertical/horizontal relationship between nodes as an edge. Fully leveraging\nthe node-edge structure, the above-ground segmentation ensures real-time\noperation and mitigates over-segmentation. Through experiments using\nsimulations, urban scenes, and our own datasets, we have demonstrated that our\nproposed traversable ground segmentation algorithm outperforms other\nstate-of-the-art methods in terms of the conventional metrics and that our\nnewly proposed evaluation metrics are meaningful for assessing the above-ground\nsegmentation. We will make the code and our own dataset available to public at\nhttps://github.com/url-kaist/TRAVEL.",
    "descriptor": "\nComments: RA-L accepted\n",
    "authors": [
      "Minho Oh",
      "Euigon Jung",
      "Hyungtae Lim",
      "Wonho Song",
      "Sumin Hu",
      "Eungchang Mason Lee",
      "Junghee Park",
      "Jaekyung Kim",
      "Jangwoo Lee",
      "Hyun Myung"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.03190"
  },
  {
    "id": "arXiv:2206.03192",
    "title": "Generalized Data Distribution Iteration",
    "abstract": "To obtain higher sample efficiency and superior final performance\nsimultaneously has been one of the major challenges for deep reinforcement\nlearning (DRL). Previous work could handle one of these challenges but\ntypically failed to address them concurrently. In this paper, we try to tackle\nthese two challenges simultaneously. To achieve this, we firstly decouple these\nchallenges into two classic RL problems: data richness and\nexploration-exploitation trade-off. Then, we cast these two problems into the\ntraining data distribution optimization problem, namely to obtain desired\ntraining data within limited interactions, and address them concurrently via i)\nexplicit modeling and control of the capacity and diversity of behavior policy\nand ii) more fine-grained and adaptive control of selective/sampling\ndistribution of the behavior policy using a monotonic data distribution\noptimization. Finally, we integrate this process into Generalized Policy\nIteration (GPI) and obtain a more general framework called Generalized Data\nDistribution Iteration (GDI). We use the GDI framework to introduce\noperator-based versions of well-known RL methods from DQN to Agent57.\nTheoretical guarantee of the superiority of GDI compared with GPI is concluded.\nWe also demonstrate our state-of-the-art (SOTA) performance on Arcade Learning\nEnvironment (ALE), wherein our algorithm has achieved 9620.33% mean human\nnormalized score (HNS), 1146.39% median HNS and surpassed 22 human world\nrecords using only 200M training frames. Our performance is comparable to\nAgent57's while we consume 500 times less data. We argue that there is still a\nlong way to go before obtaining real superhuman agents in ALE.",
    "descriptor": "\nComments: 82 pages\n",
    "authors": [
      "Jiajun Fan",
      "Changnan Xiao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.03192"
  },
  {
    "id": "arXiv:2206.03194",
    "title": "High Order Numerical Scheme for Generalized Fractional Diffusion  Equations",
    "abstract": "In this paper, a higher order finite difference scheme is proposed for\nGeneralized Fractional Diffusion Equations (GFDEs). The fractional diffusion\nequation is considered in terms of the generalized fractional derivatives\n(GFDs) which uses the scale and weight functions in the definition. The GFD\nreduces to the Riemann-Liouville, Caputo derivatives and other fractional\nderivatives in a particular case. Due to importance of the scale and the weight\nfunctions in describing behaviour of real-life physical systems, we present the\nsolutions of the GFDEs by considering various scale and weight functions. The\nconvergence and stability analysis are also discussed for finite difference\nscheme (FDS) to validate the proposed method. We consider test examples for\nnumerical simulation of FDS to justify the proposed numerical method.",
    "descriptor": "\nComments: 27 pages, 5 figures\n",
    "authors": [
      "Kamlesh Kumar",
      "Rajesh K. Pandey"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.03194"
  },
  {
    "id": "arXiv:2206.03196",
    "title": "Improving Image Captioning with Control Signal of Sentence Quality",
    "abstract": "In the dataset of image captioning, each image is aligned with several\ncaptions. Despite the fact that the quality of these descriptions varies,\nexisting captioning models treat them equally in the training process. In this\npaper, we propose a new control signal of sentence quality, which is taken as\nan additional input to the captioning model. By integrating the control signal\ninformation, captioning models are aware of the quality level of the target\nsentences and handle them differently. Moreover, we propose a novel\nreinforcement training method specially designed for the control signal of\nsentence quality: Quality-oriented Self-Annotated Training (Q-SAT). Equipped\nwith R-Drop strategy, models controlled by the highest quality level surpass\nbaseline models a lot on accuracy-based evaluation metrics, which validates the\neffectiveness of our proposed methods.",
    "descriptor": "",
    "authors": [
      "Zhangzi Zhu",
      "Hong Qu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.03196"
  },
  {
    "id": "arXiv:2206.03200",
    "title": "FairVFL: A Fair Vertical Federated Learning Framework with Contrastive  Adversarial Learning",
    "abstract": "Vertical federated learning (VFL) is a privacy-preserving machine learning\nparadigm that can learn models from features distributed on different platforms\nin a privacy-preserving way. Since in real-world applications the data may\ncontain bias on fairness-sensitive features (e.g., gender), VFL models may\ninherit bias from training data and become unfair for some user groups.\nHowever, existing fair ML methods usually rely on the centralized storage of\nfairness-sensitive features to achieve model fairness, which are usually\ninapplicable in federated scenarios. In this paper, we propose a fair vertical\nfederated learning framework (FairVFL), which can improve the fairness of VFL\nmodels. The core idea of FairVFL is to learn unified and fair representations\nof samples based on the decentralized feature fields in a privacy-preserving\nway. Specifically, each platform with fairness-insensitive features first\nlearns local data representations from local features. Then, these local\nrepresentations are uploaded to a server and aggregated into a unified\nrepresentation for the target task. In order to learn fair unified\nrepresentations, we send them to each platform storing fairness-sensitive\nfeatures and apply adversarial learning to remove bias from the unified\nrepresentations inherited from the biased data. Moreover, for protecting user\nprivacy, we further propose a contrastive adversarial learning method to remove\nprivacy information from the unified representations in server before sending\nthem to the platforms keeping fairness-sensitive features. Experiments on two\nreal-world datasets validate that our method can effectively improve model\nfairness with user privacy well-protected.",
    "descriptor": "",
    "authors": [
      "Tao Qi",
      "Fangzhao Wu",
      "Chuhan Wu",
      "Lingjuan Lyu",
      "Tong Xu",
      "Zhongliang Yang",
      "Yongfeng Huang",
      "Xing Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03200"
  },
  {
    "id": "arXiv:2206.03201",
    "title": "Technologies and Computing Paradigms: Beyond Moore's law?",
    "abstract": "As it is pretty sure that Moore's law will end some day, questioning about\nthe post-Moore era is more than interesting. Similarly, looking for new\ncomputing paradigms that could provide solutions is important. Revisiting the\nhistory of digital electronics since the 60's provide significant insights on\nthe conditions for the success of a new emerging technology to replace the\ncurrently dominant one. Specifically, the past shows when constraints and\n{\\guillemotleft} walls {\\guillemotright} have contribute to evolution through\nimproved technical techniques and when they have provoked changes of\ntechnologies (evolution versus breakthrough). The main criteria for a new\ntechnology or a new computing paradigm is a significant performance improvement\n(at least one order of magnitude). Cost, space requirement, power and\nscalability are the other important parameters.",
    "descriptor": "\nComments: 12 pages, 20 figures, Research Report\n",
    "authors": [
      "Daniel Etiemble"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2206.03201"
  },
  {
    "id": "arXiv:2206.03203",
    "title": "Effective Preconditioners for Mixed-Dimensional Scalar Elliptic Problems",
    "abstract": "Discretization of flow in fractured porous media commonly lead to large\nsystems of linear equations that require dedicated solvers. In this work, we\ndevelop an efficient linear solver and its practical implementation for\nmixed-dimensional scalar elliptic problems. We design an effective\npreconditioner based on approximate block factorization and algebraic multigrid\ntechniques. Numerical results on benchmarks with complex fracture structures\ndemonstrate the effectiveness of the proposed linear solver and its robustness\nwith respect to different physical and discretization parameters.",
    "descriptor": "",
    "authors": [
      "Xiaozhe Hu",
      "Eirik Keilegavlen",
      "Jan M. Nordbotten"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.03203"
  },
  {
    "id": "arXiv:2206.03207",
    "title": "Omnivision forecasting: combining satellite observations with sky images  for improved intra-hour solar energy predictions",
    "abstract": "Integration of intermittent renewable energy sources into electric grids in\nlarge proportions is challenging. A well-established approach aimed at\naddressing this difficulty involves the anticipation of the upcoming energy\nsupply variability to adapt the response of the grid. In solar energy,\nshort-term changes in electricity production caused by occluding clouds can be\npredicted at different time scales from all-sky cameras (up to 30-min ahead)\nand satellite observations (up to 6h ahead). In this study, we integrate these\ntwo complementary points of view on the cloud cover in a single machine\nlearning framework to improve intra-hour (up to 60-min ahead) irradiance\nforecasting. Both deterministic and probabilistic predictions are evaluated in\ndifferent weather conditions (clear-sky, cloudy, overcast) and with different\ninput configurations (sky images, satellite observations and/or past irradiance\nvalues). Our results show that the hybrid model benefits predictions in\nclear-sky conditions and improves longer-term forecasting. This study lays the\ngroundwork for future novel approaches of combining sky images and satellite\nobservations in a single learning framework to advance solar nowcasting.",
    "descriptor": "\nComments: Submitted to Renewable Energy\n",
    "authors": [
      "Quentin Paletta",
      "Guillaume Arbod",
      "Joan Lasenby"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.03207"
  },
  {
    "id": "arXiv:2206.03208",
    "title": "From \"Where\" to \"What\": Towards Human-Understandable Explanations  through Concept Relevance Propagation",
    "abstract": "The emerging field of eXplainable Artificial Intelligence (XAI) aims to bring\ntransparency to today's powerful but opaque deep learning models. While local\nXAI methods explain individual predictions in form of attribution maps, thereby\nidentifying where important features occur (but not providing information about\nwhat they represent), global explanation techniques visualize what concepts a\nmodel has generally learned to encode. Both types of methods thus only provide\npartial insights and leave the burden of interpreting the model's reasoning to\nthe user. Only few contemporary techniques aim at combining the principles\nbehind both local and global XAI for obtaining more informative explanations.\nThose methods, however, are often limited to specific model architectures or\nimpose additional requirements on training regimes or data and label\navailability, which renders the post-hoc application to arbitrarily pre-trained\nmodels practically impossible. In this work we introduce the Concept Relevance\nPropagation (CRP) approach, which combines the local and global perspectives of\nXAI and thus allows answering both the \"where\" and \"what\" questions for\nindividual predictions, without additional constraints imposed. We further\nintroduce the principle of Relevance Maximization for finding representative\nexamples of encoded concepts based on their usefulness to the model. We thereby\nlift the dependency on the common practice of Activation Maximization and its\nlimitations. We demonstrate the capabilities of our methods in various\nsettings, showcasing that Concept Relevance Propagation and Relevance\nMaximization lead to more human interpretable explanations and provide deep\ninsights into the model's representations and reasoning through concept\natlases, concept composition analyses, and quantitative investigations of\nconcept subspaces and their role in fine-grained decision making.",
    "descriptor": "\nComments: 79 pages (40 pages manuscript, 10 pages references, 29 pages appendix) 51 figures (26 in manuscript, 25 in appendix) 1 table (in appendix)\n",
    "authors": [
      "Reduan Achtibat",
      "Maximilian Dreyer",
      "Ilona Eisenbraun",
      "Sebastian Bosse",
      "Thomas Wiegand",
      "Wojciech Samek",
      "Sebastian Lapuschkin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.03208"
  },
  {
    "id": "arXiv:2206.03210",
    "title": "Deep Neural Patchworks: Coping with Large Segmentation Tasks",
    "abstract": "Convolutional neural networks are the way to solve arbitrary image\nsegmentation tasks. However, when images are large, memory demands often exceed\nthe available resources, in particular on a common GPU. Especially in\nbiomedical imaging, where 3D images are common, the problems are apparent. A\ntypical approach to solve this limitation is to break the task into smaller\nsubtasks by dividing images into smaller image patches. Another approach, if\napplicable, is to look at the 2D image sections separately, and to solve the\nproblem in 2D. Often, the loss of global context makes such approaches less\neffective; important global information might not be present in the current\nimage patch, or the selected 2D image section. Here, we propose Deep Neural\nPatchworks (DNP), a segmentation framework that is based on hierarchical and\nnested stacking of patch-based networks that solves the dilemma between global\ncontext and memory limitations.",
    "descriptor": "",
    "authors": [
      "Marco Reisert",
      "Maximilian Russe",
      "Samer Elsheikh",
      "Elias Kellner",
      "Henrik Skibbe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03210"
  },
  {
    "id": "arXiv:2206.03211",
    "title": "Variational Meta Reinforcement Learning for Social Robotics",
    "abstract": "With the increasing presence of robots in our every-day environments,\nimproving their social skills is of utmost importance. Nonetheless, social\nrobotics still faces many challenges. One bottleneck is that robotic behaviors\nneed to be often adapted as social norms depend strongly on the environment.\nFor example, a robot should navigate more carefully around patients in a\nhospital compared to workers in an office. In this work, we investigate\nmeta-reinforcement learning (meta-RL) as a potential solution. Here, robot\nbehaviors are learned via reinforcement learning where a reward function needs\nto be chosen so that the robot learns an appropriate behavior for a given\nenvironment. We propose to use a variational meta-RL procedure that quickly\nadapts the robots' behavior to new reward functions. As a result, given a new\nenvironment different reward functions can be quickly evaluated and an\nappropriate one selected. The procedure learns a vectorized representation for\nreward functions and a meta-policy that can be conditioned on such a\nrepresentation. Given observations from a new reward function, the procedure\nidentifies its representation and conditions the meta-policy to it. While\ninvestigating the procedures' capabilities, we realized that it suffers from\nposterior collapse where only a subset of the dimensions in the representation\nencode useful information resulting in a reduced performance. Our second\ncontribution, a radial basis function (RBF) layer, partially mitigates this\nnegative effect. The RBF layer lifts the representation to a higher dimensional\nspace, which is more easily exploitable for the meta-policy. We demonstrate the\ninterest of the RBF layer and the usage of meta-RL for social robotics on four\nrobotic simulation tasks.",
    "descriptor": "\nComments: 16 pages, 14 figures submitted to Neural Networks\n",
    "authors": [
      "Anand Ballou",
      "Chris Reinke",
      "Xavier Alameda-Pineda"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.03211"
  },
  {
    "id": "arXiv:2206.03212",
    "title": "Dependency, Data and Decolonisation: A Framework for Decolonial Thinking  in Collaborative AI Research",
    "abstract": "This essay seeks to tie together thoughts on the political economy of\nacademia, the inequities in access to the academic means of production and\ndecolonial practice in data empowerment. To demonstrate this I will provide a\nbrief analysis of the neo-colonial, extractive practices of the Western\nAcademy, introduce concepts around decolonial AI practice and then use these to\nform an investigative framework. Using this framework, I present a brief case\nstudy of the AirQo project in Kampala, Uganda. The project aims to deploy a\nlow-cost air pollution sensor network across the city, using machine learning\nmethods to calibrate these sensors against reference instruments, providing\nhigh-quality air pollution data at a far lower cost.",
    "descriptor": "\nComments: 5 pages, NeurIPS Resistance AI Workshop\n",
    "authors": [
      "Dennis Reddyhoff"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.03212"
  },
  {
    "id": "arXiv:2206.03213",
    "title": "Improving Students' Academic Performance with AI and Semantic  Technologies",
    "abstract": "Artificial intelligence and semantic technologies are evolving and have been\napplied in various research areas, including the education domain. Higher\nEducation institutions strive to improve students' academic performance. Early\nintervention to at-risk students and a reasonable curriculum is vital for\nstudents' success. Prior research opted for deploying traditional machine\nlearning models to predict students' performance. In terms of curriculum\nsemantic analysis, after conducting a comprehensive systematic review regarding\nthe use of semantic technologies in the Computer Science curriculum, a major\nfinding of the study is that technologies used to measure similarity have\nlimitations in terms of accuracy and ambiguity in the representation of\nconcepts, courses, etc. To fill these gaps, in this study, three\nimplementations were developed, that is, to predict students' performance using\nmarks from the previous semester, to model a course representation in a\nsemantic way and compute the similarity, and to identify the prerequisite\nbetween two similar courses. Regarding performance prediction, we used the\ncombination of Genetic Algorithm and Long-Short Term Memory (LSTM) on a dataset\nfrom a Brazilian university containing 248730 records. As for similarity\nmeasurement, we deployed BERT to encode the sentences and used cosine\nsimilarity to obtain the distance between courses. With respect to prerequisite\nidentification, TextRazor was applied to extract concepts from course\ndescription, followed by employing SemRefD to measure the degree of\nprerequisite between two concepts. The outcomes of this study can be summarized\nas: (i) a breakthrough result improves Manrique's work by 2.5% in terms of\naccuracy in dropout prediction; (ii) uncover the similarity between courses\nbased on course description; (iii) identify the prerequisite over three\ncompulsory courses of School of Computing at ANU.",
    "descriptor": "",
    "authors": [
      "Yixin Cheng"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.03213"
  },
  {
    "id": "arXiv:2206.03215",
    "title": "Prote\u00e7\u00e3o intelectual de obras produzidas por sistemas baseados em  intelig\u00eancia artificial: uma vis\u00e3o tecnicista sobre o tema",
    "abstract": "The pervasiveness of Artificial Intelligence (AI) is unquestionable in our\nsociety. Even in the arts, AI is present. A notorious case is the song \"Hey\nYa!\" of the OutKast group, successful in the 2000s. At this time, the music\nindustry began to make decisions based on data to strategize based on\npredictions of listeners' habits. This case is just one of the countless\nexamples of AI applications in the arts. The advent of deep learning made it\npossible to build systems capable of accurately recognizing artistic style in\npaintings. Content generation is also possible; for example, Deepart customizes\nimages from two \\textit{inputs}: 1) an image to be customized; 2) a style of\npainting. The generation of songs according to specific styles from AI-based\nsystems is also possible. Such possibilities raise questions about the\nintellectual property of such works. On this occasion, who owns the copyright\nof a work produced from a system based on Artificial Intelligence? To the\ncreator of the AI? The company/corporation that subsidized the development of\nthis system? Or AI itself as a creator? This essay aims to contribute with a\ntechnicist view on the discussion of copyright applicability from works\nproduced by AI.",
    "descriptor": "\nComments: in Portuguese language. Texto publicado pelo Instituto Observat\\'orio de Direito Autoral, dispon\\'ivel em: this https URL\n",
    "authors": [
      "F\u00e1bio Manoel Fran\u00e7a Lobato"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.03215"
  },
  {
    "id": "arXiv:2206.03216",
    "title": "Data Governance in the Age of Large-Scale Data-Driven Language  Technology",
    "abstract": "The recent emergence and adoption of Machine Learning technology, and\nspecifically of Large Language Models, has drawn attention to the need for\nsystematic and transparent management of language data. This work proposes an\napproach to global language data governance that attempts to organize data\nmanagement amongst stakeholders, values, and rights. Our proposal is informed\nby prior work on distributed governance that accounts for human values and\ngrounded by an international research collaboration that brings together\nresearchers and practitioners from 60 countries. The framework we present is a\nmulti-party international governance structure focused on language data, and\nincorporating technical and organizational tools needed to support its work.",
    "descriptor": "\nComments: 32 pages: Full paper and Appendices\n",
    "authors": [
      "Yacine Jernite",
      "Huu Nguyen",
      "Stella Biderman",
      "Anna Rogers",
      "Maraim Masoud",
      "Valentin Danchev",
      "Samson Tan",
      "Alexandra Sasha Luccioni",
      "Nishant Subramani",
      "G\u00e9rard Dupont",
      "Jesse Dodge",
      "Kyle Lo",
      "Zeerak Talat",
      "Isaac Johnson",
      "Dragomir Radev",
      "Somaieh Nikpoor",
      "J\u00f6rg Frohberg",
      "Aaron Gokaslan",
      "Peter Henderson",
      "Rishi Bommasani",
      "Margaret Mitchell"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.03216"
  },
  {
    "id": "arXiv:2206.03217",
    "title": "A Perspective on K-12 AI Education",
    "abstract": "Artificial intelligence (AI), which enables machines to learn to perform a\ntask by training on diverse datasets, is one of the most revolutionary\ndevelopments in scientific history. Although AI and especially deep learning is\nrelatively new, it has already had transformative impact on medicine, biology,\ntransportation, entertainment, and beyond. As AI changes our daily lives at an\nincreasingly fast pace, we are challenged with preparing our society for an\nAI-driven future. To this end, a critical step is to ensure an AI-ready\nworkforce through education. Advocates of beginning instruction of AI basics at\nthe K-12 level typically note benefits to the workforce, economy, and national\nsecurity. In this complementary perspective, we discuss why learning AI is\nbeneficial for motivating students and promoting creative thinking, and how to\ndevelop a module-based approach that optimizes learning outcomes. We hope to\nexcite and engage more members of the education community to join the effort to\nadvance K-12 AI education in the USA and worldwide.",
    "descriptor": "\nComments: Accepted for publication in a special issue of the National Academy of Inventors Technology and Innovation journal\n",
    "authors": [
      "Nathan Wang",
      "Paul Tonko",
      "Nikil Ragav",
      "Michael Chungyoun",
      "Jonathan Plucker"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.03217"
  },
  {
    "id": "arXiv:2206.03220",
    "title": "A Transparency Index Framework for AI in Education",
    "abstract": "Numerous AI ethics checklists and frameworks have been proposed focusing on\ndifferent dimensions of ethical AI such as fairness, explainability, and\nsafety. Yet, no such work has been done on developing transparent AI systems\nfor real-world educational scenarios. This paper presents a Transparency Index\nframework that has been iteratively co-designed with different stakeholders of\nAI in education, including educators, ed-tech experts, and AI practitioners. We\nmap the requirements of transparency for different categories of stakeholders\nof AI in education and demonstrate that transparency considerations are\nembedded in the entire AI development process from the data collection stage\nuntil the AI system is deployed in the real world and iteratively improved. We\nalso demonstrate how transparency enables the implementation of other ethical\nAI dimensions in Education like interpretability, accountability, and safety.\nIn conclusion, we discuss the directions for future research in this newly\nemerging field. The main contribution of this study is that it highlights the\nimportance of transparency in developing AI-powered educational technologies\nand proposes an index framework for its conceptualization for AI in education.",
    "descriptor": "\nComments: 17 pages, 4 Figures, 2 Tables\n",
    "authors": [
      "Muhammad Ali Chaudhry",
      "Mutlu Cukurova",
      "Rose Luckin"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.03220"
  },
  {
    "id": "arXiv:2206.03221",
    "title": "To incentivize or not: Impact of blockchain-based cryptoeconmic tokens  on human information sharing behavior",
    "abstract": "Cryptoeconomic incentives in the form of blockchain-based tokens are seen as\nan enabler of the sharing economy which could shift society towards greater\nsustainability. Nevertheless, knowledge about the impact of those tokens on\nhuman sharing behavior is still limited, which challenges the design of\neffective cryptoeconomic incentives. This study applies the theory of\nself-determination to investigate the impact of those tokens on human behavior\nin an information sharing scenario. By utilising an experimental methodology in\nthe form of a randomized control trial with a 2x2 factorial design involving\n132 participants, the effects of two token incentives on human information\nsharing behavior are analysed. Individuals obtain these tokens in exchange for\ntheir shared information. Based on the collected tokens, individuals receive a\nmonetary payment and build reputation. Besides investigating the effect of\nthese incentives on the quantity of shared information, the study includes\nquality characteristics of information, such as accuracy and contextualisation.\nThe focus on quantity while excluding quality has been identified as a\nlimitation in previous work. Besides confirming previously known effects such\nas a crowding out of intrinsic motivation by incentives which also exists for\nblockchain-based tokens, the findings of this work show a until now unreported\ninteraction effect between multiple tokens when applied simultaneously. The\nfindings are critically discussed and put into context of recent work and\nethical considerations. The theory-based, empirical study is of interest to\nthose investigating the effect of cryptoeconomic tokens or digital currencies\non human behavior and supports the community to design effective personalized\nincentives for sharing economies.",
    "descriptor": "",
    "authors": [
      "Mark Christopher Ballandies"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.03221"
  },
  {
    "id": "arXiv:2206.03222",
    "title": "Improved Cardiac Arrhythmia Prediction Based on Heart Rate Variability  Analysis",
    "abstract": "Many types of ventricular and atrial cardiac arrhythmias have been discovered\nin clinical practice in the past 100 years, and these arrhythmias are a major\ncontributor to sudden cardiac death. Ventricular tachycardia, ventricular\nfibrillation, and paroxysmal atrial fibrillation are the most\ncommonly-occurring and dangerous arrhythmias, therefore early detection is\ncrucial to prevent any further complications and reduce fatalities. Implantable\ndevices such as pacemakers are commonly used in patients at high risk of sudden\ncardiac death. While great advances have been made in medical technology, there\nremain significant challenges in effective management of common arrhythmias.\nThis thesis proposes novel arrhythmia detection and prediction methods to\ndifferentiate cardiac arrhythmias from non-life-threatening cardiac events, to\nincrease the likelihood of detecting events that may lead to mortality, as well\nas reduce the incidence of unnecessary therapeutic intervention. The methods\nare based on detailed analysis of Heart Rate Variability (HRV) information. The\nresults of the work show good performance of the proposed methods and support\nthe potential for their deployment in resource-constrained devices for\nventricular and atrial arrhythmia prediction, such as implantable pacemakers\nand defibrillators.",
    "descriptor": "\nComments: PhD thesis\n",
    "authors": [
      "Ashkan Parsi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.03222"
  },
  {
    "id": "arXiv:2206.03223",
    "title": "Sensors for Mobile Robots",
    "abstract": "A sensor is a device that converts a physical parameter or an environmental\ncharacteristic (e.g., temperature, distance, speed, etc.) into a signal that\ncan be digitally measured and processed to perform specific tasks. Mobile\nrobots need sensors to measure properties of their environment, thus allowing\nfor safe navigation, complex perception and corresponding actions and effective\ninteractions with other agents that populate it. Sensors used by mobile robots\nrange from simple tactile sensors, such as bumpers, to complex vision-based\nsensors such as structured light cameras. All of them provide a digital output\n(e.g., a string, a set of values, a matrix, etc.) that can be processed by the\nrobot's computer. Such output is typically obtained by discretizing one or more\nanalog electrical signals by using an Analog to Digital Converter (ADC)\nincluded in the sensor. In this chapter we present the most common sensors used\nin mobile robotics, providing an introduction to their taxonomy, basic features\nand specifications. The description of the functionalities and the types of\napplications follows a bottom-up approach: the basic principles and components\non which the sensors are based are presented before describing real-world\nsensors, which are generally based on multiple technologies and basic devices.",
    "descriptor": "\nComments: This chapter will appear in: Ang, M.H., Khatib, O., Siciliano, B. (eds) Encyclopedia of Robotics. Springer, Berlin, Heidelberg\n",
    "authors": [
      "Henrik Andreasson",
      "Giorgio Grisetti",
      "Todor Stoyanov",
      "Alberto Pretto"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.03223"
  },
  {
    "id": "arXiv:2206.03224",
    "title": "The Beyond the Fence Musical and Computer Says Show Documentary",
    "abstract": "During 2015 and early 2016, the cultural application of Computational\nCreativity research and practice took a big leap forward, with a project where\nmultiple computational systems were used to provide advice and material for a\nnew musical theatre production. Billed as the world's first 'computer\nmusical... conceived by computer and substantially crafted by computer', Beyond\nThe Fence was staged in the Arts Theatre in London's West End during February\nand March of 2016. Various computational approaches to analytical and\ngenerative sub-projects were used to bring about the musical, and these efforts\nwere recorded in two 1-hour documentary films made by Wingspan Productions,\nwhich were aired on SkyArts under the title Computer Says Show. We provide\ndetails here of the project conception and execution, including details of the\nsystems which took on some of the creative responsibility in writing the\nmusical, and the contributions they made. We also provide details of the impact\nof the project, including a perspective from the two (human) writers with\noverall control of the creative aspects the musical.",
    "descriptor": "",
    "authors": [
      "Simon Colton",
      "Maria Teresa Llano",
      "Rose Hepworth",
      "John Charnley",
      "Catherine V. Gale",
      "Archie Baron",
      "Francois Pachet",
      "Pierre Roy",
      "Pablo Gervas",
      "Nick Collins",
      "Bob Sturm",
      "Tillman Weyde",
      "Daniel Wolff",
      "James Robert Lloyd"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.03224"
  },
  {
    "id": "arXiv:2206.03225",
    "title": "The Different Faces of AI Ethics Across the World: A  Principle-Implementation Gap Analysis",
    "abstract": "Artificial Intelligence (AI) is transforming our daily life with several\napplications in healthcare, space exploration, banking and finance. These rapid\nprogresses in AI have brought increasing attention to the potential impacts of\nAI technologies on society, with ethically questionable consequences. In recent\nyears, several ethical principles have been released by governments, national\nand international organisations. These principles outline high-level precepts\nto guide the ethical development, deployment, and governance of AI. However,\nthe abstract nature, diversity, and context-dependency of these principles make\nthem difficult to implement and operationalize, resulting in gaps between\nprinciples and their execution. Most recent work analysed and summarized\nexisting AI principles and guidelines but they did not provide findings on\nprinciple-implementation gaps and how to mitigate them. These findings are\nparticularly important to ensure that AI implementations are aligned with\nethical principles and values. In this paper, we provide a contextual and\nglobal evaluation of current ethical AI principles for all continents, with the\naim to identify potential principle characteristics tailored to specific\ncountries or applicable across countries. Next, we analyze the current level of\nAI readiness and current implementations of ethical AI principles in different\ncountries, to identify gaps in the implementation of AI principles and their\ncauses. Finally, we propose recommendations to mitigate the\nprinciple-implementation gaps.",
    "descriptor": "",
    "authors": [
      "Lionel Nganyewou Tidjon",
      "Foutse Khomh"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.03225"
  },
  {
    "id": "arXiv:2206.03226",
    "title": "Fairness and Explainability in Automatic Decision-Making Systems. A  challenge for computer science and law",
    "abstract": "The paper offers a contribution to the interdisciplinary constructs of\nanalyzing fairness issues in automatic algorithmic decisions. Section 1 shows\nthat technical choices in supervised learning have social implications that\nneed to be considered. Section 2 proposes a contextual approach to the issue of\nunintended group discrimination, i.e. decision rules that are facially neutral\nbut generate disproportionate impacts across social groups (e.g., gender, race\nor ethnicity). The contextualization will focus on the legal systems of the\nUnited States on the one hand and Europe on the other. In particular,\nlegislation and case law tend to promote different standards of fairness on\nboth sides of the Atlantic. Section 3 is devoted to the explainability of\nalgorithmic decisions; it will confront and attempt to cross-reference legal\nconcepts (in European and French law) with technical concepts and will\nhighlight the plurality, even polysemy, of European and French legal texts\nrelating to the explicability of algorithmic decisions. The conclusion proposes\ndirections for further research.",
    "descriptor": "",
    "authors": [
      "Thierry Kirat",
      "Olivia Tambou",
      "Virginie Do",
      "Alexis Tsouki\u00e0s"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.03226"
  },
  {
    "id": "arXiv:2206.03227",
    "title": "Does Crypto Kill? Relationship between Electricity Consumption Carbon  Footprints and Bitcoin Transactions",
    "abstract": "Cryptocurrencies are gaining more popularity due to their security, making\ncounterfeits impossible. However, these digital currencies have been criticized\nfor creating a large carbon footprint due to their algorithmic complexity and\ndecentralized system design for proof of work and mining. We hypothesize that\nthe carbon footprint of cryptocurrency transactions has a higher dependency on\ncarbon-rich fuel sources than green or renewable fuel sources. We provide a\nmachine learning framework to model such transactions and correlate them with\nthe electricity generation patterns to estimate and analyze their carbon cost.",
    "descriptor": "\nComments: 8 pages, 17 figures\n",
    "authors": [
      "Altanai Bisht",
      "Arielle Wilson",
      "Zachary Jeffreys",
      "Shadrokh Samavi"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03227"
  },
  {
    "id": "arXiv:2206.03229",
    "title": "Sharp $L^1$-Approximation of the log-Heston SDE by Euler-type methods",
    "abstract": "We study the $L^1$-approximation of the log-Heston SDE at equidistant time\npoints by Euler-type methods. We establish the convergence order $\n1/2-\\epsilon$ for $\\epsilon >0$ arbitrarily small, if the Feller index $\\nu$ of\nthe underlying CIR process satisfies $\\nu > 1$. Thus, we recover the standard\nconvergence order of the Euler scheme for SDEs with globally Lipschitz\ncoefficients. Moreover, we discuss the case $\\nu \\leq 1$ and illustrate our\nfindings by several numerical examples.",
    "descriptor": "",
    "authors": [
      "Annalena Mickel",
      "Andreas Neuenkirch"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.03229"
  },
  {
    "id": "arXiv:2206.03231",
    "title": "High-performance computing for super-resolution microscopy on a cluster  of computers",
    "abstract": "Multiple signal classification algorithm (MUSICAL) provides a\nsuper-resolution microscopy method. In the previous research, MUSICAL has\nenabled data-parallelism well on a desktop computer or a Linux-based server.\nHowever, the running time needs to be shorter. This paper will develop a new\nparallel MUSICAL with high efficiency and scalability on a cluster of\ncomputers. We achieve the purpose by using the optimal speed of the cluster\ncores, the latest parallel programming techniques, and the high-performance\ncomputing libraries, such as the Intel Threading Building Blocks (TBB), the\nIntel Math Kernel Library (MKL), and the unified parallel C++ (UPC++) for the\ncluster of computers. Our experimental results show that the new parallel\nMUSICAL achieves a speed-up of 240.29x within 10 seconds on the 256-core\ncluster with an efficiency of 93.86%. Our MUSICAL offers a high possibility for\nreal-life applications to make super-resolution microscopy within seconds.",
    "descriptor": "\nComments: 6 figures, 2 tables, conference paper\n",
    "authors": [
      "Quan Do",
      "Jon Ivar Kristiansen",
      "Krishna Agarwal",
      "Phuong Hoai Ha"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2206.03231"
  },
  {
    "id": "arXiv:2206.03233",
    "title": "Software Architecture for Mobile Robots",
    "abstract": "A software architecture defines the blueprints of a large computational\nsystem, and is thus a crucial part of the design and development effort. This\ntask has been explored extensively in the context of mobile robots, resulting\nin a plethora of reference designs and implementations. As the software\narchitecture defines the framework in which all components are implemented, it\nis naturally a very important aspect of a mobile robot system. In this chapter,\nwe overview the requirements that the particular problem domain (a mobile robot\nsystem) imposes on the software framework. We discuss some of the current\ndesign solutions, provide a historical perspective on common frameworks, and\noutline directions for future development.",
    "descriptor": "\nComments: This chapter will appear in: Ang, M.H., Khatib, O., Siciliano, B. (eds) Encyclopedia of Robotics. Springer, Berlin, Heidelberg\n",
    "authors": [
      "Henrik Andreasson",
      "Giorgio Grisetti",
      "Todor Stoyanov",
      "Alberto Pretto"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.03233"
  },
  {
    "id": "arXiv:2206.03234",
    "title": "Inferring Unfairness and Error from Population Statistics in Binary and  Multiclass Classification",
    "abstract": "We propose methods for making inferences on the fairness and accuracy of a\ngiven classifier, using only aggregate population statistics. This is necessary\nwhen it is impossible to obtain individual classification data, for instance\nwhen there is no access to the classifier or to a representative\nindividual-level validation set. We study fairness with respect to the\nequalized odds criterion, which we generalize to multiclass classification. We\npropose a measure of unfairness with respect to this criterion, which\nquantifies the fraction of the population that is treated unfairly. We then\nshow how inferences on the unfairness and error of a given classifier can be\nobtained using only aggregate label statistics such as the rate of prediction\nof each label in each sub-population, as well as the true rate of each label.\nWe derive inference procedures for binary classifiers and for multiclass\nclassifiers, for the case where confusion matrices in each sub-population are\nknown, and for the significantly more challenging case where they are unknown.\nWe report experiments on data sets representing diverse applications, which\ndemonstrate the effectiveness and the wide range of possible uses of the\nproposed methodology.",
    "descriptor": "",
    "authors": [
      "Sivan Sabato",
      "Eran Treister",
      "Elad Yom-Tov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.03234"
  },
  {
    "id": "arXiv:2206.03237",
    "title": "Blockchain for Business Process Enactment: A Taxonomy and Systematic  Literature Review",
    "abstract": "Blockchain has been proposed to facilitate the enactment of\ninterorganisational business processes. For such processes, blockchain can\nguarantee the enforcement of rules and the integrity of execution traces -\nwithout the need for a centralised trusted party. However, the enactment of\ninterorganisational processes pose manifold challenges. In this work, we ask\nwhat answers the research field offers in response to those challenges. To do\nso, we conduct a systematic literature review (SLR). As our guiding question,\nwe investigate the guarantees and capabilities of blockchain-based enactment\napproaches. Based on resulting empirical evidence, we develop a taxonomy for\nblockchain-based enactment. We find that a wide range of approaches support\ntraceability and correctness; however, research focusing on flexibility and\nscalability remains nascent. For all challenges, we point towards future\nresearch opportunities.",
    "descriptor": "\nComments: Preprint, Submitted to BPM 2022, Blockchain Forum\n",
    "authors": [
      "Fabian Stiehle",
      "Ingo Weber"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.03237"
  },
  {
    "id": "arXiv:2206.03239",
    "title": "Analyzing the impact of feature selection on the accuracy of heart  disease prediction",
    "abstract": "Heart Disease has become one of the most serious diseases that has a\nsignificant impact on human life. It has emerged as one of the leading causes\nof mortality among the people across the globe during the last decade. In order\nto prevent patients from further damage, an accurate diagnosis of heart disease\non time is an essential factor. Recently we have seen the usage of non-invasive\nmedical procedures, such as artificial intelligence-based techniques in the\nfield of medical. Specially machine learning employs several algorithms and\ntechniques that are widely used and are highly useful in accurately diagnosing\nthe heart disease with less amount of time. However, the prediction of heart\ndisease is not an easy task. The increasing size of medical datasets has made\nit a complicated task for practitioners to understand the complex feature\nrelations and make disease predictions. Accordingly, the aim of this research\nis to identify the most important risk-factors from a highly dimensional\ndataset which helps in the accurate classification of heart disease with less\ncomplications. For a broader analysis, we have used two heart disease datasets\nwith various medical features. The classification results of the benchmarked\nmodels proved that there is a high impact of relevant features on the\nclassification accuracy. Even with a reduced number of features, the\nperformance of the classification models improved significantly with a reduced\ntraining time as compared with models trained on full feature set.",
    "descriptor": "\nComments: Published in Healthcare Analytics, 2022\n",
    "authors": [
      "Muhammad Salman Pathan",
      "Avishek Nag",
      "Muhammad Mohisn Pathan",
      "Soumyabrata Dev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.03239"
  },
  {
    "id": "arXiv:2206.03241",
    "title": "Combining Genetic Programming and Particle Swarm Optimization to  Simplify Rugged Landscapes Exploration",
    "abstract": "Most real-world optimization problems are difficult to solve with traditional\nstatistical techniques or with metaheuristics. The main difficulty is related\nto the existence of a considerable number of local optima, which may result in\nthe premature convergence of the optimization process. To address this problem,\nwe propose a novel heuristic method for constructing a smooth surrogate model\nof the original function. The surrogate function is easier to optimize but\nmaintains a fundamental property of the original rugged fitness landscape: the\nlocation of the global optimum. To create such a surrogate model, we consider a\nlinear genetic programming approach enhanced by a self-tuning fitness function.\nThe proposed algorithm, called the GP-FST-PSO Surrogate Model, achieves\nsatisfactory results in both the search for the global optimum and the\nproduction of a visual approximation of the original benchmark function (in the\n2-dimensional case).",
    "descriptor": "",
    "authors": [
      "Gloria Pietropolli",
      "Giuliamaria Menara",
      "Mauro Castelli"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.03241"
  },
  {
    "id": "arXiv:2206.03242",
    "title": "Fast Exact String to D-Texts Alignments",
    "abstract": "In recent years, aligning a sequence to a pangenome has become a central\nproblem in genomics and pangenomics. A fast and accurate solution to this\nproblem can serve as a toolkit to many crucial tasks such as read-correction,\nMultiple Sequences Alignment (MSA), genome assemblies, variant calling, just to\nname a few. In this paper we propose a new, fast and exact method to align a\nstring to a D-string, the latter possibly representing an MSA, a pan-genome or\na partial assembly. An implementation of our tool dsa is publicly available at\nhttps://github.com/urbanslug/dsa",
    "descriptor": "",
    "authors": [
      "Njagi Moses Mwaniki",
      "Erik Garrison",
      "Nadia Pisanti"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Genomics (q-bio.GN)"
    ],
    "url": "https://arxiv.org/abs/2206.03242"
  },
  {
    "id": "arXiv:2206.03248",
    "title": "Rites de Passage: Elucidating Displacement to Emplacement of Refugees",
    "abstract": "Social media deliberations allow to explore refugee-related is-sues. AI-based\nstudies have investigated refugee issues mostly around a specific event and\nconsidered unimodal approaches. Contrarily, we have employed a multimodal\narchitecture for probing the refugee journeys from their home to host nations.\nWe draw insights from Arnold van Gennep's anthropological work 'Les Rites de\nPassage', which systematically analyzed an individual's transition from one\ngroup or society to another. Based on Gennep's\nseparation-transition-incorporation framework, we have identified four phases\nof refugee journeys: Arrival of Refugees, Temporal stay at Asylums,\nRehabilitation, and Integration of Refugees into the host nation. We collected\n0.23 million multimodal tweets from April 2020 to March 2021 for testing this\nproposed frame-work. We find that a combination of transformer-based language\nmodels and state-of-the-art image recognition models, such as fusion of\nBERT+LSTM and InceptionV4, can out-perform unimodal models. Subsequently, to\ntest the practical implication of our proposed model in real-time, we have\nconsidered 0.01 million multimodal tweets related to the 2022 Ukrainian refugee\ncrisis. An F1-score of 71.88 % for this 2022 crisis confirms the\ngeneralizability of our proposed framework.",
    "descriptor": "\nComments: This work has been accepted to appear at HT'22-33rd ACM Conference on Hypertext and Social Media\n",
    "authors": [
      "Aparup Khatua",
      "Wolfgang Nejdl"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03248"
  },
  {
    "id": "arXiv:2206.03250",
    "title": "6G-AUTOR: Autonomic CSI-Free Transceiver via Realtime On-Device Signal  Analytics",
    "abstract": "Next-generation wireless systems aim at fulfilling diverse application\nrequirements but fundamentally rely on point-to-point transmission qualities.\nAligning with recent AI-enabled wireless implementations, this paper introduces\nautonomic radios, 6G-AUTOR, that leverage novel algorithm-hardware separation\nplatforms, softwarization of transmission (TX) and reception (RX) operations,\nand automatic reconfiguration of RF frontends, to support link performance and\nresilience. As a comprehensive transceiver solution, our design encompasses\nseveral ML-driven models, each enhancing a specific aspect of either TX or RX,\nleading to robust transceiver operation under tight constraints of future\nwireless systems. A data-driven radio management module was developed via deep\nQ-networks to support fast-reconfiguration of TX resource blocks (RB) and\nproactive multi-agent access. Also, a ResNet-inspired fast-beamforming solution\nwas employed to enable robust communication to multiple receivers over the same\nRB, which has potential applications in realisation of cell-free\ninfrastructures. As a receiver the system was equipped with a capability of\nultra-broadband spectrum recognition. Apart from this, a fundamental tool -\nautomatic modulation classification (AMC) which involves a complex correntropy\nextraction, followed by a convolutional neural network (CNN)-based\nclassification, and a deep learning-based LDPC decoder were added to improve\nthe reception quality and radio performance. Simulations of individual\nalgorithms demonstrate that under appropriate training, each of the\ncorresponding radio functions have either outperformed or have performed on-par\nwith the benchmark solutions.",
    "descriptor": "\nComments: Preprint submitted to Ad Hoc Networks\n",
    "authors": [
      "Shih-Chun Lin",
      "Chia-Hung Lin",
      "K V S Rohit",
      "Liang C Chu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.03250"
  },
  {
    "id": "arXiv:2206.03252",
    "title": "CNTFET quaternary multipliers are less efficient than the corresponding  binary ones",
    "abstract": "We compare N*N quaternary digit and 2N*2N bit CNTFET multipliers in terms of\nWorst case delay, Chip area, Power and Power Delay Product (PDP) for N=1, N=2\nand N=4. Both multipliers use Wallace reduction trees. HSpice simulations with\n32-nm CNTFET parameters shows that the binary implementations are always more\nefficient: the 1*1 quit multiplier is far more complex than a 1*1 bit\nmultiplier (AND gate) and generate both product and a carry terms. Even with\nhalf number of terms, the quaternary reduction tree has the same number of\nterms than the binary one, and uses quaternary adders that are also more\ncomplicated than the binary ones. The quaternary multipliers have larger worst\ncase delays, more power dissipation and far more chip areas than the binary\nones computing the same amount of information.",
    "descriptor": "\nComments: 7 pages, 24 figures, research report. arXiv admin note: text overlap with arXiv:2005.02678\n",
    "authors": [
      "Daniel Etiemble"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2206.03252"
  },
  {
    "id": "arXiv:2206.03253",
    "title": "About Digital Twins, agents, and multiagent systems: a  cross-fertilisation journey",
    "abstract": "Digital Twins (DTs) are rapidly emerging as a fundamental brick of\nengineering cyber-physical systems, but their notion is still mostly bound to\nspecific business domains (e.g. manufacturing), goals (e.g. product design), or\napplication domains (e.g. the Internet of Things). As such, their value as\ngeneral purpose engineering abstractions is yet to be fully revealed. In this\npaper, we relate DTs with agents and multiagent systems, as the latter are\narguably the most rich abstractions available for the engineering of complex\nsocio-technical and cyber-physical systems, and the former could both fill in\nsome gaps in agent-oriented engineering and benefit from an agent-oriented\ninterpretation -- in a cross-fertilisation journey.",
    "descriptor": "\nComments: Digital Twin, Agent, Multiagent system, Cyber-physical system;16 pages; accepted and presented at EMAS2022 (workshop of AAMAS: this https URL)\n",
    "authors": [
      "Stefano Mariani",
      "Marco Picone",
      "Alessandro Ricci"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2206.03253"
  },
  {
    "id": "arXiv:2206.03254",
    "title": "Demystifying the Global Convergence Puzzle of Learning  Over-parameterized ReLU Nets in Very High Dimensions",
    "abstract": "This theoretical paper is devoted to developing a rigorous theory for\ndemystifying the global convergence phenomenon in a challenging scenario:\nlearning over-parameterized Rectified Linear Unit (ReLU) nets for very high\ndimensional dataset under very mild assumptions. A major ingredient of our\nanalysis is a fine-grained analysis of random activation matrices. The\nessential virtue of dissecting activation matrices is that it bridges the\ndynamics of optimization and angular distribution in high-dimensional data\nspace. This angle-based detailed analysis leads to asymptotic characterizations\nof gradient norm and directional curvature of objective function at each\ngradient descent iteration, revealing that the empirical loss function enjoys\nnice geometrical properties in the overparameterized setting. Along the way, we\nsignificantly improve existing theoretical bounds on both over-parameterization\ncondition and learning rate with very mild assumptions for learning very high\ndimensional data. Moreover, we uncover the role of the geometrical and spectral\nproperties of the input data in determining desired over-parameterization size\nand global convergence rate. All these clues allow us to discover a novel\ngeometric picture of nonconvex optimization in deep learning: angular\ndistribution in high-dimensional data space $\\mapsto$ spectrums of\noverparameterized activation matrices $\\mapsto$ favorable geometrical\nproperties of empirical loss landscape $\\mapsto$ global convergence phenomenon.\nFurthremore, our theoretical results imply that gradient-based nonconvex\noptimization algorithms have much stronger statistical guarantees with much\nmilder over-parameterization condition than exisiting theory states for\nlearning very high dimensional data, which is rarely explored so far.",
    "descriptor": "",
    "authors": [
      "Peng He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.03254"
  },
  {
    "id": "arXiv:2206.03256",
    "title": "Flexible Group Fairness Metrics for Survival Analysis",
    "abstract": "Algorithmic fairness is an increasingly important field concerned with\ndetecting and mitigating biases in machine learning models. There has been a\nwealth of literature for algorithmic fairness in regression and classification\nhowever there has been little exploration of the field for survival analysis.\nSurvival analysis is the prediction task in which one attempts to predict the\nprobability of an event occurring over time. Survival predictions are\nparticularly important in sensitive settings such as when utilising machine\nlearning for diagnosis and prognosis of patients. In this paper we explore how\nto utilise existing survival metrics to measure bias with group fairness\nmetrics. We explore this in an empirical experiment with 29 survival datasets\nand 8 measures. We find that measures of discrimination are able to capture\nbias well whereas there is less clarity with measures of calibration and\nscoring rules. We suggest further areas for research including prediction-based\nfairness metrics for distribution predictions.",
    "descriptor": "\nComments: Submitted to DSHealth 2022 (Workshop on Applied Data Science for Healthcare)\n",
    "authors": [
      "Raphael Sonabend",
      "Florian Pfisterer",
      "Alan Mishler",
      "Moritz Schauer",
      "Lukas Burk",
      "Sebastian Vollmer"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2206.03256"
  },
  {
    "id": "arXiv:2206.03258",
    "title": "The risk ethics of autonomous vehicles: a continuous trolley problem in  regular road traffic",
    "abstract": "Is the ethics of autonomous vehicles (AVs) restricted to weighing lives in\nunavoidable accidents? We argue that AVs distribute risks between road users in\nregular traffic situations, either explicitly or implicitly. This distribution\nof risks raises ethically relevant questions that cannot be evaded by simple\nheuristics such as \"hitting the brakes.\" Using an interactive, graphical\nrepresentation of different traffic situations, we measured participants'\npreferences on driving maneuvers of AVs in a representative survey in Germany.\nOur participants' preferences deviated significantly from mere collision\navoidance. Interestingly, our participants were willing to take risks\nthemselves for the benefit of other road users suggesting that the social\ndilemma of AVs may lessen in a context of risk.",
    "descriptor": "",
    "authors": [
      "Sebastian Kr\u00fcgel",
      "Matthias Uhl"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.03258"
  },
  {
    "id": "arXiv:2206.03259",
    "title": "Future Computer Systems and Networking Research in the Netherlands: A  Manifesto",
    "abstract": "Our modern society and competitive economy depend on a strong digital\nfoundation and, in turn, on sustained research and innovation in computer\nsystems and networks (CompSys). With this manifesto, we draw attention to\nCompSys as a vital part of ICT. Among ICT technologies, CompSys covers all the\nhardware and all the operational software layers that enable applications; only\napplication-specific details, and often only application-specific algorithms,\nare not part of CompSys. Each of the Top Sectors of the Dutch Economy, each\nroute in the National Research Agenda, and each of the UN Sustainable\nDevelopment Goals pose challenges that cannot be addressed without\ngroundbreaking CompSys advances. Looking at the 2030-2035 horizon, important\nnew applications will emerge only when enabled by CompSys developments.\nTriggered by the COVID-19 pandemic, millions moved abruptly online, raising\ninfrastructure scalability and data sovereignty issues; but governments\nprocessing social data and responsible social networks still require a paradigm\nshift in data sovereignty and sharing. AI already requires massive computer\nsystems which can cost millions per training task, but the current technology\nleaves an unsustainable energy footprint including large carbon emissions.\nComputational sciences such as bioinformatics, and \"Humanities for all\" and\n\"citizen data science\", cannot become affordable and efficient until computer\nsystems take a generational leap. Similarly, the emerging quantum internet\ndepends on (traditional) CompSys to bootstrap operation for the foreseeable\nfuture. Large commercial sectors, including finance and manufacturing, require\nspecialized computing and networking or risk becoming uncompetitive. And, at\nthe core of Dutch innovation, promising technology hubs, deltas, ports, and\nsmart cities, could see their promise stagger due to critical dependency on\nnon-European technology.",
    "descriptor": "\nComments: Position paper: 7 foundational research themes in computer science and networking research, 4 advances with outstanding impact on society, 10 recommendations, 50 pages. Co-signatories from (alphabetical order): ASTRON, CWI, Gaia-X NL, NIKHEF, RU Groningen, SIDN Labs, Solvinity, SURF, TNO, TU/e, TU Delft, UvA, U. Leiden, U. Twente, VU Amsterdam\n",
    "authors": [
      "Alexandru Iosup",
      "Fernando Kuipers",
      "Ana Lucia Varbanescu",
      "Paola Grosso",
      "Animesh Trivedi",
      "Jan Rellermeyer",
      "Lin Wang",
      "Alexandru Uta",
      "Francesco Regazzoni"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.03259"
  },
  {
    "id": "arXiv:2206.03261",
    "title": "Optimists at Heart: Why Do We Research Game AI? (Extended Version)",
    "abstract": "In this paper we survey the motivations behind contemporary game AI research\nby analysing individual publications, the researchers themselves, and the\ninstitutions that influence them. In doing so, we identify some negative\neffects on our field, caused both by external forces outside of our control as\nwell as institutionalised behaviours that are easily overlooked. We suggest how\nwe might begin to address some of these issues as a community, and reassert\nourselves as the primary driving force behind the field.",
    "descriptor": "\nComments: Extended version of a paper currently under review\n",
    "authors": [
      "Michael Cook"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.03261"
  },
  {
    "id": "arXiv:2206.03262",
    "title": "Using sensitive data to prevent discrimination by AI: Does the GDPR need  a new exception?",
    "abstract": "Organisations can use artificial intelligence to make decisions about people\nfor a variety of reasons, for instance, to select the best candidates from many\njob applications. However, AI systems can have discriminatory effects when used\nfor decision-making. To illustrate, an AI system could reject applications of\npeople with a certain ethnicity, while the organisation did not plan such\nethnicity discrimination. But in Europe, an organisation runs into a problem\nwhen it wants to assess whether its AI system accidentally leads to ethnicity\ndiscrimination: the organisation may not know the applicants' ethnicity. In\nprinciple, the GDPR bans the use of certain 'special categories of data'\n(sometimes called 'sensitive data'), which include data on ethnicity, religion,\nand sexual preference. The proposal for an AI Act of the European Commission\nincludes a provision that would enable organisations to use of special\ncategories of data for their auditing AI systems. This paper asks whether the\nGDPR's rules on special categories of personal data hinder the prevention of\nAI-driven discrimination. We argue that the GDPR does prohibit such use of\nspecial category data in many circumstances. We also map out the arguments for\nand against creating an exception to the GDPR's ban on using special categories\nof personal data, to enable preventing discrimination by AI systems. The paper\ndiscusses European law, but the paper can be relevant outside Europe too, as\nmany policymakers in the world grapple with the tension between privacy and\nnon-discrimination policy.",
    "descriptor": "",
    "authors": [
      "Marvin van Bekkum",
      "Frederik Zuiderveen Borgesius"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.03262"
  },
  {
    "id": "arXiv:2206.03263",
    "title": "Embedded Systems Education in the 2020s: Challenges, Reflections, and  Future Directions",
    "abstract": "Embedded computing systems are pervasive in our everyday lives, imparting\ndigital intelligence to a variety of electronic platforms used in our vehicles,\nsmart appliances, wearables, mobile devices, and computers. The need to train\nthe next generation of embedded systems designers and engineers with relevant\nskills across hardware, software, and their co-design remains pressing today.\nThis paper describes the evolution of embedded systems education over the past\ntwo decades and challenges facing the designers and instructors of embedded\nsystems curricula in the 2020s. Reflections from over a decade of teaching the\ndesign of embedded computing systems are presented, with insights on strategies\nthat show promise to address these challenges. Lastly, some important future\ndirections in embedded systems education are highlighted.",
    "descriptor": "",
    "authors": [
      "Sudeep Pasricha"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.03263"
  },
  {
    "id": "arXiv:2206.03264",
    "title": "Intelligent Energy Management Systems -- A Review",
    "abstract": "Climate change has become a major problem for humanity in the last two\ndecades. One of the reasons that caused it, is our daily energy waste. People\nconsume electricity in order to use home/work appliances and devices and also\nreach certain levels of comfort while working or being at home. However, even\nthough the environmental impact of this behavior is not immediately observed,\nit leads to increased CO2 emissions coming from energy generation from power\nplants. Confronting such a problem efficiently will affect both the environment\nand our society. Monitoring energy consumption in real-time, changing energy\nwastage behavior of occupants and using automations with incorporated energy\nsavings scenarios, are ways to decrease global energy footprint. In this\nreview, we study intelligent systems for energy management in residential,\ncommercial and educational buildings, classifying them in two major categories\ndepending on whether they provide direct or indirect control. The article also\ndiscusses what the strengths and weaknesses are, which optimization techniques\ndo they use and finally, provide insights about how these systems can be\nimproved in the future.",
    "descriptor": "",
    "authors": [
      "Stavros Mischos",
      "Eleanna Dalagdi",
      "Dimitris Vrakas"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.03264"
  },
  {
    "id": "arXiv:2206.03265",
    "title": "Marvolo: Programmatic Data Augmentation for Practical ML-Driven Malware  Detection",
    "abstract": "Data augmentation has been rare in the cyber security domain due to technical\ndifficulties in altering data in a manner that is semantically consistent with\nthe original data. This shortfall is particularly onerous given the unique\ndifficulty of acquiring benign and malicious training data that runs into\ncopyright restrictions, and that institutions like banks and governments\nreceive targeted malware that will never exist in large quantities. We present\nMARVOLO, a binary mutator that programmatically grows malware (and benign)\ndatasets in a manner that boosts the accuracy of ML-driven malware detectors.\nMARVOLO employs semantics-preserving code transformations that mimic the\nalterations that malware authors and defensive benign developers routinely make\nin practice , allowing us to generate meaningful augmented data. Crucially,\nsemantics-preserving transformations also enable MARVOLO to safely propagate\nlabels from original to newly-generated data samples without mandating\nexpensive reverse engineering of binaries. Further, MARVOLO embeds several key\noptimizations that keep costs low for practitioners by maximizing the density\nof diverse data samples generated within a given time (or resource) budget.\nExperiments using wide-ranging commercial malware datasets and a recent\nML-driven malware detector show that MARVOLO boosts accuracies by up to 5%,\nwhile operating on only a small fraction (15%) of the potential input binaries.",
    "descriptor": "\nComments: 15 pages, 7 figures\n",
    "authors": [
      "Michael D. Wong",
      "Edward Raff",
      "James Holt",
      "Ravi Netravali"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03265"
  },
  {
    "id": "arXiv:2206.03266",
    "title": "Machine Learning Sensors",
    "abstract": "Machine learning sensors represent a paradigm shift for the future of\nembedded machine learning applications. Current instantiations of embedded\nmachine learning (ML) suffer from complex integration, lack of modularity, and\nprivacy and security concerns from data movement. This article proposes a more\ndata-centric paradigm for embedding sensor intelligence on edge devices to\ncombat these challenges. Our vision for \"sensor 2.0\" entails segregating sensor\ninput data and ML processing from the wider system at the hardware level and\nproviding a thin interface that mimics traditional sensors in functionality.\nThis separation leads to a modular and easy-to-use ML sensor device. We discuss\nchallenges presented by the standard approach of building ML processing into\nthe software stack of the controlling microprocessor on an embedded system and\nhow the modularity of ML sensors alleviates these problems. ML sensors increase\nprivacy and accuracy while making it easier for system builders to integrate ML\ninto their products as a simple component. We provide examples of prospective\nML sensors and an illustrative datasheet as a demonstration and hope that this\nwill build a dialogue to progress us towards sensor 2.0.",
    "descriptor": "",
    "authors": [
      "Pete Warden",
      "Matthew Stewart",
      "Brian Plancher",
      "Colby Banbury",
      "Shvetank Prakash",
      "Emma Chen",
      "Zain Asgar",
      "Sachin Katti",
      "Vijay Janapa Reddi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2206.03266"
  },
  {
    "id": "arXiv:2206.03268",
    "title": "Ubiquitous knowledge empowers the Smart Factory: The impacts of a  Service-oriented Digital Twin on enterprises' performance",
    "abstract": "While the Industry 4.0 is idolizing the potential of an artificial\nintelligence embedded into \"things\", it is neglecting the role of the human\ncomponent, which is still indispensable in different manufacturing activities,\nsuch as a machine setup or maintenance operations. The present research study\nfirst proposes an Industrial Internet pyramid as emergent human-centric\nmanufacturing paradigm within Industry 4.0 in which central is the role of a\nUbiquitous Knowledge about the manufacturing system intuitively accessed and\nused by the manufacturing employees. Second, the prototype of a\nService-oriented Digital Twin, which leverage on a flexible ontology-oriented\nknowledge structure and on augmented reality combined to a vocal interaction\nsystem for an intuitive knowledge retrieval and fruition, has been designed and\ndeveloped to deliver this manufacturing knowledge. Two test-beds, complimentary\nfor the problems in practice (the former on the maintenance-production\ninterface in a large enterprise, the latter majorly focused in production and\nsetups in a small and medium enterprise), show the significant benefits in\nterms of time, costs and process quality, thus validating the approach\nproposed. This research shows that a human-centric and knowledge-driven\napproach can drive the performance of Industry 4.0 initiatives and lead a Smart\nFactory towards its full potential.",
    "descriptor": "\nComments: 16 pages, 12 figures, 5 tables\n",
    "authors": [
      "Francesco Longo",
      "Letizia Nicoletti",
      "Antonio Padovano"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.03268"
  },
  {
    "id": "arXiv:2206.03270",
    "title": "DLT Compliance Reporting",
    "abstract": "The IS discourse on the potential of distributed ledger technology (DLT) in\nthe financial services has grown at a tremendous pace in recent years. Yet,\nlittle has been said about the related implications for the costly and highly\nregulated process of compliance reporting. Working with a group of\nrepresentatives from industry and regulatory authorities, we employ the design\nscience research methodology (DSR) in the design, development, and evaluation\nof an artefact, enabling the automated collection and enrichment of\ntransactional data. Our findings indicate that DLT may facilitate the\nautomation of key compliance processes through the implementation of a\n\"pull-model\", in which regulators can access compliance data in near real-time\nto stage aggregate exposures at the supranational level. Generalizing our\npreliminary results, we present four propositions on the implications of DLT in\ncompliance. The findings contribute new practical insights on the topic of\ncompliance to the growing IS discourse on DLT.",
    "descriptor": "\nComments: Regulatory reporting, DLT, Compliance, Blockchain, Governance, 3 lines of defense, DSR, Design Science Research, EU supervisory data strategy, supervision\n",
    "authors": [
      "Henrik Axelsen",
      "Johannes Rude Jensen",
      "Omri Ross"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.03270"
  },
  {
    "id": "arXiv:2206.03271",
    "title": "On the Effectiveness of Fine-tuning Versus Meta-reinforcement Learning",
    "abstract": "Intelligent agents should have the ability to leverage knowledge from\npreviously learned tasks in order to learn new ones quickly and efficiently.\nMeta-learning approaches have emerged as a popular solution to achieve this.\nHowever, meta-reinforcement learning (meta-RL) algorithms have thus far been\nrestricted to simple environments with narrow task distributions. Moreover, the\nparadigm of pretraining followed by fine-tuning to adapt to new tasks has\nemerged as a simple yet effective solution in supervised and self-supervised\nlearning. This calls into question the benefits of meta-learning approaches\nalso in reinforcement learning, which typically come at the cost of high\ncomplexity. We hence investigate meta-RL approaches in a variety of\nvision-based benchmarks, including Procgen, RLBench, and Atari, where\nevaluations are made on completely novel tasks. Our findings show that when\nmeta-learning approaches are evaluated on different tasks (rather than\ndifferent variations of the same task), multi-task pretraining with fine-tuning\non new tasks performs equally as well, or better, than meta-pretraining with\nmeta test-time adaptation. This is encouraging for future research, as\nmulti-task pretraining tends to be simpler and computationally cheaper than\nmeta-RL. From these findings, we advocate for evaluating future meta-RL methods\non more challenging tasks and including multi-task pretraining with fine-tuning\nas a simple, yet strong baseline.",
    "descriptor": "",
    "authors": [
      "Zhao Mandi",
      "Pieter Abbeel",
      "Stephen James"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.03271"
  },
  {
    "id": "arXiv:2206.03273",
    "title": "City-Scale Synthetic Individual-level Vehicle Trip Data",
    "abstract": "The trip data that records each vehicle's trip behavior on the road network\ndescribes the operation of urban traffic from the perspective of individuals\nand is extremely valuable for transportation research. However, restricted by\ndata privacy, the trip data of individual-level cannot be opened for all\nresearchers, while the need for it is very urgent. In this paper, we produce a\ncity-scale synthetic individual-level trip data by regenerating for all\nindividuals based on their historical trip data. The availability and trip data\nprivacy protection are balanced during generation, making the synthetic dataset\nremains valuable and can be opened. A series of experiments were done to verify\nthe reliability of the dataset. The result shows that the synthetic data is\nconsistent with the real data at the aggregated level. Further, the trip\nbehaviors of individuals indicated by the trip data from the individual\nperspective are reasonable.",
    "descriptor": "",
    "authors": [
      "Guilong Li",
      "Yixian Chen",
      "Zhaocheng He"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.03273"
  },
  {
    "id": "arXiv:2206.03274",
    "title": "Minimizing Energy Consumption for End-to-End Slicing in 5G Wireless  Networks and Beyond",
    "abstract": "End-to-End (E2E) network slicing enables wireless networks to provide diverse\nservices on a common infrastructure. Each E2E slice, including resources of\nradio access network (RAN) and core network, is rented to mobile virtual\nnetwork operators (MVNOs) to provide a specific service to end-users. RAN\nslicing, which is realized through wireless network virtualization, involves\nsharing the frequency spectrum and base station antennas in RAN. Similarly, in\ncore slicing, which is achieved by network function virtualization, data center\nresources such as commodity servers and physical links are shared between users\nof different MVNOs. In this paper, we study E2E slicing with the aim of\nminimizing the total energy consumption. The stated optimization problem is\nnon-convex that is solved by a sub-optimal algorithm proposed here. The\nsimulation results show that our proposed joint power control, server and link\nallocation (JPSLA) algorithm achieves 30% improvement compared to the disjoint\nscheme, where RAN and core are sliced separately.",
    "descriptor": "\nComments: 6 pages, Published in WCNC 2022\n",
    "authors": [
      "Shiva Kazemi Taskou",
      "Mehdi Rasti",
      "Pedro H. J. Nardelli"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.03274"
  },
  {
    "id": "arXiv:2206.03275",
    "title": "The Algorithmic Imprint",
    "abstract": "When algorithmic harms emerge, a reasonable response is to stop using the\nalgorithm to resolve concerns related to fairness, accountability,\ntransparency, and ethics (FATE). However, just because an algorithm is removed\ndoes not imply its FATE-related issues cease to exist. In this paper, we\nintroduce the notion of the \"algorithmic imprint\" to illustrate how merely\nremoving an algorithm does not necessarily undo or mitigate its consequences.\nWe operationalize this concept and its implications through the 2020 events\nsurrounding the algorithmic grading of the General Certificate of Education\n(GCE) Advanced (A) Level exams, an internationally recognized UK-based high\nschool diploma exam administered in over 160 countries. While the algorithmic\nstandardization was ultimately removed due to global protests, we show how the\nremoval failed to undo the algorithmic imprint on the sociotechnical\ninfrastructures that shape students', teachers', and parents' lives. These\nevents provide a rare chance to analyze the state of the world both with and\nwithout algorithmic mediation. We situate our case study in Bangladesh to\nillustrate how algorithms made in the Global North disproportionately impact\nstakeholders in the Global South. Chronicling more than a year-long community\nengagement consisting of 47 inter-views, we present the first coherent timeline\nof \"what\" happened in Bangladesh, contextualizing \"why\" and \"how\" they happened\nthrough the lenses of the algorithmic imprint and situated algorithmic\nfairness. Analyzing these events, we highlight how the contours of the\nalgorithmic imprints can be inferred at the infrastructural, social, and\nindividual levels. We share conceptual and practical implications around how\nimprint-awareness can (a) broaden the boundaries of how we think about\nalgorithmic impact, (b) inform how we design algorithms, and (c) guide us in AI\ngovernance.",
    "descriptor": "\nComments: Accepted to ACM FAccT 2022\n",
    "authors": [
      "Upol Ehsan",
      "Ranjit Singh",
      "Jacob Metcalf",
      "Mark O. Riedl"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.03275"
  },
  {
    "id": "arXiv:2206.03276",
    "title": "Oxford-style Debates in Telecommunication and Computer Science Education",
    "abstract": "Oxford-style debating is a well-known tool in social sciences. Such formal\ndiscussions on particular topics are widely used by historians and\nsociologists. However, when we try to go beyond standard thinking, it turns out\nthat Oxford-style debating can be a great educational tool in telecommunication\nand computer science. This article presents this unusual method of education at\ntechnical universities and in the IT industry, and describes its features and\nchallenges. Best practices and examples of debating are provided, taking into\naccount emerging topics in telecommunications and computer science, such as\ncybersecurity. The article also contains feedback from IT engineers who\nparticipated in Oxford-style debates. All this aims to encourage this form of\neducation in telecommunication and computer science.",
    "descriptor": "\nComments: The article under the review in a journal\n",
    "authors": [
      "Marcin Niemiec"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.03276"
  },
  {
    "id": "arXiv:2206.03277",
    "title": "Driving and charging an EV in Australia: A real-world analysis",
    "abstract": "As outlined by the Intergovernmental Panel on Climate Change, electric\nvehicles (EVs) offer the greatest decarbonisation potential for land transport,\nin addition to other benefits, including reduced fuel and maintenance costs,\nimproved air quality, reduced noise pollution, and improved national fuel\nsecurity. Owing to these benefits, governments worldwide are planning and\nrolling out EV-favourable policies, and major car manufacturers are committing\nto fully electrifying their offerings over the coming decades. With the number\nof EVs on the roads expected to increase, it is imperative to understand the\neffect of EVs on transport and energy systems. While unmanaged charging of EVs\ncould potentially add stress to the electricity grid, managed charging of EVs\ncould be beneficial to the grid in terms of improved demand-supply management\nand improved integration of renewable energy sources into the grid, as well as\noffer other ancillary services. To assess the impact of EVs on the electricity\ngrid and their potential use as batteries-on-wheels through smart charging\ncapabilities, decision-makers need to understand how current EV owners drive\nand charge their vehicles. As such, an emerging area of research focuses on\nunderstanding these behaviours. Some studies have used stated preference\nsurveys of non-EV owners or data collected from EV trials to estimate EV\ndriving and charging patterns. Other studies have tried to decipher EV owners'\nbehaviour based on data collected from national surveys or as reported by EV\nowners. This study aims to fill this gap in the literature by collecting data\non real-world driving and charging patterns of 239 EVs across Australia. To\nthis effect, data collection from current EV owners via an application\nprogramming interface platform began in November 2021 and is currently live.",
    "descriptor": "\nComments: This work has been submitted to the 43rd Australasian Transport Research Forum (ATRF) 2022\n",
    "authors": [
      "Thara Philip",
      "Kai Li Lim",
      "Jake Whitehead"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2206.03277"
  },
  {
    "id": "arXiv:2206.03281",
    "title": "Unsupervised Context Aware Sentence Representation Pretraining for  Multi-lingual Dense Retrieval",
    "abstract": "Recent research demonstrates the effectiveness of using pretrained language\nmodels (PLM) to improve dense retrieval and multilingual dense retrieval. In\nthis work, we present a simple but effective monolingual pretraining task\ncalled contrastive context prediction~(CCP) to learn sentence representation by\nmodeling sentence level contextual relation. By pushing the embedding of\nsentences in a local context closer and pushing random negative samples away,\ndifferent languages could form isomorphic structure, then sentence pairs in two\ndifferent languages will be automatically aligned. Our experiments show that\nmodel collapse and information leakage are very easy to happen during\ncontrastive training of language model, but language-specific memory bank and\nasymmetric batch normalization operation play an essential role in preventing\ncollapsing and information leakage, respectively. Besides, a post-processing\nfor sentence embedding is also very effective to achieve better retrieval\nperformance. On the multilingual sentence retrieval task Tatoeba, our model\nachieves new SOTA results among methods without using bilingual data. Our model\nalso shows larger gain on Tatoeba when transferring between non-English pairs.\nOn two multi-lingual query-passage retrieval tasks, XOR Retrieve and Mr.TYDI,\nour model even achieves two SOTA results in both zero-shot and supervised\nsetting among all pretraining models using bilingual data.",
    "descriptor": "",
    "authors": [
      "Ning Wu",
      "Yaobo Liang",
      "Houxing Ren",
      "Linjun Shou",
      "Nan Duan",
      "Ming Gong",
      "Daxin Jiang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.03281"
  },
  {
    "id": "arXiv:2206.03285",
    "title": "Nezha: Deployable and High-Performance Consensus Using Synchronized  Clocks",
    "abstract": "Consensus protocols are widely used to build fault-tolerant applications. At\none end of the spectrum of such protocols, Multi-Paxos and Raft have seen\nwidespread adoption, but sacrifice significant latency and throughput. At the\nother end, protocols like Speculative Paxos and NOPaxos provide\nhigh-performance, but require specialized hardware and in-network\nfunctionality. This makes it hard to deploy them in environments such as the\npublic cloud, where cloud tenants cannot access the physical network. Our work\naims to bridge this gap between deployability and performance.\nWe present Nezha, a high-performance and deployable consensus protocol that\nexploits accurate software clock synchronization. Nezha does not require\nspecial hardware or physical network access, making it easily deployable in\nvirtualized environments. Instead, it uses a new primitive called\ndeadline-ordered multicast (DOM) which orders client-to-replica multicast\nrequests by deadlines specified in synchronized wall-clock time. We compare\nNezha to 4 baselines in the public cloud: Multi-Paxos, FastPaxos, NOPaxos and\nRaft. Evaluations show that Nezha outperforms the baselines by a median of 8.2x\n(range: 1.9-20.9x) in throughput, and by a median of 1.9x (range: 1.3x-3.7x) in\nlatency. We also use Nezha to replicate two applications (Redis and a prototype\nfinancial exchange) and show that Nezha can provide fault tolerance with only a\nmodest performance degradation: compared with the unreplicated system, Nezha\nsacrifices 5.9% throughput for Redis; it saturates the processing capacity of\nCloudEx and prolongs the order processing latency by 4.7%.",
    "descriptor": "\nComments: Under conference submission\n",
    "authors": [
      "Jinkun Geng",
      "Anirudh Sivaraman",
      "Balaji Prabhakar",
      "Mendel Rosenblum"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Databases (cs.DB)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.03285"
  },
  {
    "id": "arXiv:2206.03286",
    "title": "Examining the Implementation of Digital Health to Strengthen the  COVID-19 Pandemic Response and Recovery and Scale up Equitable Vaccine Access  in African Countries",
    "abstract": "The COVID-19 pandemic has profoundly impacted the world, having taken the\nlives of over 6 million individuals. Accordingly, this pandemic has caused a\nshift in conversations surrounding the burden of diseases worldwide, welcoming\ninsights from multidisciplinary fields including digital health and artificial\nintelligence. Africa faces a heavy disease burden that exacerbates the current\nCOVID-19 pandemic and limits the scope of public health preparedness, response,\ncontainment, and case management. Herein, we examined the potential impact of\ntransformative digital health technologies in mitigating the global health\ncrisis with reference to African countries. Furthermore, we proposed\nrecommendations for scaling up digital health technologies and artificial\nintelligence-based platforms to tackle the transmission of the SARS-CoV-2 and\nenable equitable vaccine access. Challenges related to the pandemic are\nnumerous. Rapid response and management strategies - that is, contract tracing,\ncase surveillance, diagnostic testing intensity, and most recently vaccine\ndistribution mapping - can overwhelm the health care delivery system that is\nfragile. Although challenges are vast, digital health technologies can play an\nessential role in achieving sustainable resilient recovery and building back\nbetter. It is plausible that African nations are better equipped to rapidly\nidentify, diagnose, and manage infected individuals for COVID-19, other\ndiseases, future outbreaks, and pandemics.",
    "descriptor": "\nComments: 8 Pages, 0 Figure\n",
    "authors": [
      "Olufunto A Olusanya",
      "Brianna White",
      "Chad A Melton",
      "Arash Shaban-Nejad"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.03286"
  },
  {
    "id": "arXiv:2206.03287",
    "title": "NeMF: Neural Motion Fields for Kinematic Animation",
    "abstract": "We present an implicit neural representation to learn the spatio-temporal\nspace of kinematic motions. Unlike previous work that represents motion as\ndiscrete sequential samples, we propose to express the vast motion space as a\ncontinuous function over time, hence the name Neural Motion Fields (NeMF).\nSpecifically, we use a neural network to learn this function for miscellaneous\nsets of motions, which is designed to be a generative model conditioned on a\ntemporal coordinate $t$ and a random vector $z$ for controlling the style. The\nmodel is then trained as a Variational Autoencoder (VAE) with motion encoders\nto sample the latent space. We train our model with diverse human motion\ndataset and quadruped dataset to prove its versatility, and finally deploy it\nas a generic motion prior to solve task-agnostic problems and show its\nsuperiority in different motion generation and editing applications, such as\nmotion interpolation, in-betweening, and re-navigating.",
    "descriptor": "",
    "authors": [
      "Chengan He",
      "Jun Saito",
      "James Zachary",
      "Holly Rushmeier",
      "Yi Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2206.03287"
  },
  {
    "id": "arXiv:2206.03288",
    "title": "Collaborative Intelligence Orchestration: Inconsistency-Based Fusion of  Semi-Supervised Learning and Active Learning",
    "abstract": "While annotating decent amounts of data to satisfy sophisticated learning\nmodels can be cost-prohibitive for many real-world applications. Active\nlearning (AL) and semi-supervised learning (SSL) are two effective, but often\nisolated, means to alleviate the data-hungry problem. Some recent studies\nexplored the potential of combining AL and SSL to better probe the unlabeled\ndata. However, almost all these contemporary SSL-AL works use a simple\ncombination strategy, ignoring SSL and AL's inherent relation. Further, other\nmethods suffer from high computational costs when dealing with large-scale,\nhigh-dimensional datasets. Motivated by the industry practice of labeling data,\nwe propose an innovative Inconsistency-based virtual aDvErsarial Active\nLearning (IDEAL) algorithm to further investigate SSL-AL's potential\nsuperiority and achieve mutual enhancement of AL and SSL, i.e., SSL propagates\nlabel information to unlabeled samples and provides smoothed embeddings for AL,\nwhile AL excludes samples with inconsistent predictions and considerable\nuncertainty for SSL. We estimate unlabeled samples' inconsistency by\naugmentation strategies of different granularities, including fine-grained\ncontinuous perturbation exploration and coarse-grained data transformations.\nExtensive experiments, in both text and image domains, validate the\neffectiveness of the proposed algorithm, comparing it against state-of-the-art\nbaselines. Two real-world case studies visualize the practical industrial value\nof applying and deploying the proposed data sampling algorithm.",
    "descriptor": "\nComments: Accepted to KDD 2022\n",
    "authors": [
      "Jiannan Guo",
      "Yangyang Kang",
      "Yu Duan",
      "Xiaozhong Liu",
      "Siliang Tang",
      "Wenqiao Zhang",
      "Kun Kuang",
      "Changlong Sun",
      "Fei Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03288"
  },
  {
    "id": "arXiv:2206.03289",
    "title": "Future Artificial Intelligence tools and perspectives in medicine",
    "abstract": "Purpose of review: Artificial intelligence (AI) has become popular in medical\napplications, specifically as a clinical support tool for computer-aided\ndiagnosis. These tools are typically employed on medical data (i.e., image,\nmolecular data, clinical variables, etc.) and used the statistical and machine\nlearning methods to measure the model performance. In this review, we\nsummarized and discussed the most recent radiomic pipeline used for clinical\nanalysis. Recent findings:Currently, limited management of cancers benefits\nfrom artificial intelligence, mostly related to a computer-aided diagnosis that\navoids a biopsy analysis that presents additional risks and costs. Most AI\ntools are based on imaging features, known as radiomic analysis that can be\nrefined into predictive models in non-invasively acquired imaging data. This\nreview explores the progress of AI-based radiomic tools for clinical\napplications with a brief description of necessary technical steps. Explaining\nnew radiomic approaches based on deep learning techniques will explain how the\nnew radiomic models (deep radiomic analysis) can benefit from deep\nconvolutional neural networks and be applied on limited data sets. Summary: To\nconsider the radiomic algorithms, further investigations are recommended to\ninvolve deep learning in radiomic models with additional validation steps on\nvarious cancer types.",
    "descriptor": "",
    "authors": [
      "Ahmad Chaddad",
      "Yousef Katib",
      "Lama Hassan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2206.03289"
  },
  {
    "id": "arXiv:2206.03291",
    "title": "GAAF: Searching Activation Functions for Binary Neural Networks through  Genetic Algorithm",
    "abstract": "Binary neural networks (BNNs) show promising utilization in cost and\npower-restricted domains such as edge devices and mobile systems. This is due\nto its significantly less computation and storage demand, but at the cost of\ndegraded performance. To close the accuracy gap, in this paper we propose to\nadd a complementary activation function (AF) ahead of the sign based\nbinarization, and rely on the genetic algorithm (GA) to automatically search\nfor the ideal AFs. These AFs can help extract extra information from the input\ndata in the forward pass, while allowing improved gradient approximation in the\nbackward pass. Fifteen novel AFs are identified through our GA-based search,\nwhile most of them show improved performance (up to 2.54% on ImageNet) when\ntesting on different datasets and network models. Our method offers a novel\napproach for designing general and application-specific BNN architecture. Our\ncode is available at this http URL",
    "descriptor": "",
    "authors": [
      "Yanfei Li",
      "Tong Geng",
      "Samuel Stein",
      "Ang Li",
      "Huimin Yu"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03291"
  },
  {
    "id": "arXiv:2206.03292",
    "title": "Adaptive Obstacle Avoidance Algorithm Based on Trajectory Learning",
    "abstract": "Most obstacle avoidance algorithms are only effective in specific\nenvironments, and they have low adaptability to some new environments. In this\npaper, we propose a trajectory learning (TL)-based obstacle avoidance\nalgorithm, which can learn implicit obstacle avoidance mechanism from\ntrajectories generated by general obstacle avoidance algorithms and achieves\nbetter adaptability. Specifically, we define a general data structure to\ndescribe the obstacle avoidance mechanism. Based on this structure, we\ntransform the learning of the obstacle avoidance algorithm into a multiclass\nclassification problem about the direction selection. Then, we design an\nartificial neural network (ANN) to fit multiclass classification function\nthrough supervised learning and finally obtain the obstacle avoidance mechanism\nthat generates the observed trajectories. Our algorithm can obtain the obstacle\navoidance mechanism similar to that demonstrated in the trajectories, and are\nadaptable to unseen environments. The automatic learning mechanism simplifies\nmodification and debugging of obstacle avoidance algorithms in applications.\nSimulation results demonstrate that the proposed algorithm can learn obstacle\navoidance strategy from trajectories and achieve better adaptability.",
    "descriptor": "",
    "authors": [
      "Yinghan Wang",
      "Hao Jiang",
      "Xiaoming Duan",
      "Jianping He"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.03292"
  },
  {
    "id": "arXiv:2206.03293",
    "title": "Joint Manifold Learning and Density Estimation Using Normalizing Flows",
    "abstract": "Based on the manifold hypothesis, real-world data often lie on a\nlow-dimensional manifold, while normalizing flows as a likelihood-based\ngenerative model are incapable of finding this manifold due to their structural\nconstraints. So, one interesting question arises: $\\textit{\"Can we find\nsub-manifold(s) of data in normalizing flows and estimate the density of the\ndata on the sub-manifold(s)?\"}$. In this paper, we introduce two approaches,\nnamely per-pixel penalized log-likelihood and hierarchical training, to answer\nthe mentioned question. We propose a single-step method for joint manifold\nlearning and density estimation by disentangling the transformed space obtained\nby normalizing flows to manifold and off-manifold parts. This is done by a\nper-pixel penalized likelihood function for learning a sub-manifold of the\ndata. Normalizing flows assume the transformed data is Gaussianizationed, but\nthis imposed assumption is not necessarily true, especially in high dimensions.\nTo tackle this problem, a hierarchical training approach is employed to improve\nthe density estimation on the sub-manifold. The results validate the\nsuperiority of the proposed methods in simultaneous manifold learning and\ndensity estimation using normalizing flows in terms of generated image quality\nand likelihood.",
    "descriptor": "",
    "authors": [
      "Seyedeh Fatemeh Razavi",
      "Mohammad Mahdi Mehmanchi",
      "Reshad Hosseini",
      "Mostafa Tavassolipour"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03293"
  },
  {
    "id": "arXiv:2206.03299",
    "title": "Generalization Error Bounds for Deep Neural Networks Trained by SGD",
    "abstract": "Generalization error bounds for deep neural networks trained by stochastic\ngradient descent (SGD) are derived by combining a dynamical control of an\nappropriate parameter norm and the Rademacher complexity estimate based on\nparameter norms. The bounds explicitly depend on the loss along the training\ntrajectory, and work for a wide range of network architectures including\nmultilayer perceptron (MLP) and convolutional neural networks (CNN). Compared\nwith other algorithm-depending generalization estimates such as uniform\nstability-based bounds, our bounds do not require $L$-smoothness of the\nnonconvex loss function, and apply directly to SGD instead of Stochastic\nLangevin gradient descent (SGLD). Numerical results show that our bounds are\nnon-vacuous and robust with the change of optimizer and network\nhyperparameters.",
    "descriptor": "",
    "authors": [
      "Mingze Wang",
      "Chao Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.03299"
  },
  {
    "id": "arXiv:2206.03301",
    "title": "Recent Advances in Bayesian Optimization",
    "abstract": "Bayesian optimization has emerged at the forefront of expensive black-box\noptimization due to its data efficiency. Recent years have witnessed a\nproliferation of studies on the development of new Bayesian optimization\nalgorithms and their applications. Hence, this paper attempts to provide a\ncomprehensive and updated survey of recent advances in Bayesian optimization\nand identify interesting open problems. We categorize the existing work on\nBayesian optimization into nine main groups according to the motivations and\nfocus of the proposed algorithms. For each category, we present the main\nadvances with respect to the construction of surrogate models and adaptation of\nthe acquisition functions. Finally, we discuss the open questions and suggest\npromising future research directions, in particular with regard to\nheterogeneity, privacy preservation, and fairness in distributed and federated\noptimization systems.",
    "descriptor": "",
    "authors": [
      "Xilu Wang",
      "Yaochu Jin",
      "Sebastian Schmitt",
      "Markus Olhofer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.03301"
  },
  {
    "id": "arXiv:2206.03304",
    "title": "On the balance between the training time and interpretability of neural  ODE for time series modelling",
    "abstract": "Most machine learning methods are used as a black box for modelling. We may\ntry to extract some knowledge from physics-based training methods, such as\nneural ODE (ordinary differential equation). Neural ODE has advantages like a\npossibly higher class of represented functions, the extended interpretability\ncompared to black-box machine learning models, ability to describe both trend\nand local behaviour. Such advantages are especially critical for time series\nwith complicated trends. However, the known drawback is the high training time\ncompared to the autoregressive models and long-short term memory (LSTM)\nnetworks widely used for data-driven time series modelling. Therefore, we\nshould be able to balance interpretability and training time to apply neural\nODE in practice. The paper shows that modern neural ODE cannot be reduced to\nsimpler models for time-series modelling applications. The complexity of neural\nODE is compared to or exceeds the conventional time-series modelling tools. The\nonly interpretation that could be extracted is the eigenspace of the operator,\nwhich is an ill-posed problem for a large system. Spectra could be extracted\nusing different classical analysis methods that do not have the drawback of\nextended time. Consequently, we reduce the neural ODE to a simpler linear form\nand propose a new view on time-series modelling using combined neural networks\nand an ODE system approach.",
    "descriptor": "",
    "authors": [
      "Yakov Golovanev",
      "Alexander Hvatov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Classical Analysis and ODEs (math.CA)"
    ],
    "url": "https://arxiv.org/abs/2206.03304"
  },
  {
    "id": "arXiv:2206.03305",
    "title": "Physics-Inspired Temporal Learning of Quadrotor Dynamics for Accurate  Model Predictive Trajectory Tracking",
    "abstract": "Accurately modeling quadrotor's system dynamics is critical for guaranteeing\nagile, safe, and stable navigation. The model needs to capture the system\nbehavior in multiple flight regimes and operating conditions, including those\nproducing highly nonlinear effects such as aerodynamic forces and torques,\nrotor interactions, or possible system configuration modifications. Classical\napproaches rely on handcrafted models and struggle to generalize and scale to\ncapture these effects. In this paper, we present a novel Physics-Inspired\nTemporal Convolutional Network (PI-TCN) approach to learning quadrotor's system\ndynamics purely from robot experience. Our approach combines the expressive\npower of sparse temporal convolutions and dense feed-forward connections to\nmake accurate system predictions. In addition, physics constraints are embedded\nin the training process to facilitate the network's generalization capabilities\nto data outside the training distribution. Finally, we design a model\npredictive control approach that incorporates the learned dynamics for accurate\nclosed-loop trajectory tracking fully exploiting the learned model predictions\nin a receding horizon fashion. Experimental results demonstrate that our\napproach accurately extracts the structure of the quadrotor's dynamics from\ndata, capturing effects that would remain hidden to classical approaches. To\nthe best of our knowledge, this is the first time physics-inspired deep\nlearning is successfully applied to temporal convolutional networks and to the\nsystem identification task, while concurrently enabling predictive control.",
    "descriptor": "\nComments: Video: this https URL\n",
    "authors": [
      "Alessandro Saviolo",
      "Guanrui Li",
      "Giuseppe Loianno"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.03305"
  },
  {
    "id": "arXiv:2206.03310",
    "title": "PyTSK: A Python Toolbox for TSK Fuzzy Systems",
    "abstract": "This paper presents PyTSK, a Python toolbox for developing Takagi-Sugeno-Kang\n(TSK) fuzzy systems. Based on scikit-learn and PyTorch, PyTSK allows users to\noptimize TSK fuzzy systems using fuzzy clustering or mini-batch gradient\ndescent (MBGD) based algorithms. Several state-of-the-art MBGD-based\noptimization algorithms are implemented in the toolbox, which can improve the\ngeneralization performance of TSK fuzzy systems, especially for big data\napplications. PyTSK can also be easily extended and customized for more\ncomplicated algorithms, such as modifying the structure of TSK fuzzy systems,\ndeveloping more sophisticated training algorithms, and combining TSK fuzzy\nsystems with neural networks. The code of PyTSK can be found at\nhttps://github.com/YuqiCui/pytsk.",
    "descriptor": "",
    "authors": [
      "Yuqi Cui",
      "Dongrui Wu",
      "Xue Jiang",
      "Yifan Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03310"
  },
  {
    "id": "arXiv:2206.03311",
    "title": "Theorizing Information Sources for Hope: Belief, Desire, Imagination,  and Metacognition",
    "abstract": "Introduction. Hope is a positive attitude oriented toward a possible (yet\nuncertain), desired outcome. Though hope is a virtue, hopelessness is\nwidespread and seems related not only to current events but also to information\nabout current events. This paper examines how hope can be sparked through\ninformation. Method. This study uses the philosophical methods of conceptual\nanalysis and design to advance a theoretical argument. Analysis. First, a\nconceptualization of hope is offered, drawing on work primarily in virtue\nethics. Then, four types of information sources for hope are theorized,\nbuilding on and synthesizing work from philosophy and psychology. Results. Four\ncategories of information source conducive to hopefulness are identified:\ninformation for forming beliefs about the past or future; information for\nengaging the moral imagination regarding possibilities for the future;\ninformation for sparking desire for particular moral outcomes; and information\nfor metacognition, or about how we become informed with respect to hope.\nConclusions. Hope is, in many cases, responsive to information. This suggests a\nmoral opportunity for information professionals and scholars to work toward\nconnecting people with information for hope, particularly in difficult times.\nAvenues for further research, particularly in information behavior and\npractices, are suggested.",
    "descriptor": "\nComments: Paper presented at Conceptions of Library & Information Science (CoLIS) 12 on May 31, 2022, in Oslo, Norway\n",
    "authors": [
      "Tim Gorichanaz"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.03311"
  },
  {
    "id": "arXiv:2206.03312",
    "title": "Neuro-Nav: A Library for Neurally-Plausible Reinforcement Learning",
    "abstract": "In this work we propose Neuro-Nav, an open-source library for neurally\nplausible reinforcement learning (RL). RL is among the most common modeling\nframeworks for studying decision making, learning, and navigation in biological\norganisms. In utilizing RL, cognitive scientists often handcraft environments\nand agents to meet the needs of their particular studies. On the other hand,\nartificial intelligence researchers often struggle to find benchmarks for\nneurally and biologically plausible representation and behavior (e.g., in\ndecision making or navigation). In order to streamline this process across both\nfields with transparency and reproducibility, Neuro-Nav offers a set of\nstandardized environments and RL algorithms drawn from canonical behavioral and\nneural studies in rodents and humans. We demonstrate that the toolkit\nreplicates relevant findings from a number of studies across both cognitive\nscience and RL literatures. We furthermore describe ways in which the library\ncan be extended with novel algorithms (including deep RL) and environments to\naddress future research needs of the field.",
    "descriptor": "",
    "authors": [
      "Arthur Juliani",
      "Samuel Barnett",
      "Brandon Davis",
      "Margaret Sereno",
      "Ida Momennejad"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03312"
  },
  {
    "id": "arXiv:2206.03315",
    "title": "Neural Network Decoders for Permutation Codes Correcting Different  Errors",
    "abstract": "Permutation codes were extensively studied in order to correct different\ntypes of errors for the applications on power line communication and rank\nmodulation for flash memory. In this paper, we introduce the neural network\ndecoders for permutation codes to correct these errors with one-shot decoding,\nwhich treat the decoding as $n$ classification tasks for non-binary symbols for\na code of length $n$. These are actually the first general decoders introduced\nto deal with any error type for these two applications. The performance of the\ndecoders is evaluated by simulations with different error models.",
    "descriptor": "",
    "authors": [
      "Yeow Meng Chee",
      "Hui Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03315"
  },
  {
    "id": "arXiv:2206.03317",
    "title": "Subject Membership Inference Attacks in Federated Learning",
    "abstract": "Privacy in Federated Learning (FL) is studied at two different granularities:\nitem-level, which protects individual data points, and user-level, which\nprotects each user (participant) in the federation. Nearly all of the private\nFL literature is dedicated to studying privacy attacks and defenses at these\ntwo granularities. Recently, subject-level privacy has emerged as an\nalternative privacy granularity to protect the privacy of individuals (data\nsubjects) whose data is spread across multiple (organizational) users in\ncross-silo FL settings. An adversary might be interested in recovering private\ninformation about these individuals (a.k.a. \\emph{data subjects}) by attacking\nthe trained model. A systematic study of these patterns requires complete\ncontrol over the federation, which is impossible with real-world datasets. We\ndesign a simulator for generating various synthetic federation configurations,\nenabling us to study how properties of the data, model design and training, and\nthe federation itself impact subject privacy risk. We propose three attacks for\n\\emph{subject membership inference} and examine the interplay between all\nfactors within a federation that affect the attacks' efficacy. We also\ninvestigate the effectiveness of Differential Privacy in mitigating this\nthreat. Our takeaways generalize to real-world datasets like FEMNIST, giving\ncredence to our findings.",
    "descriptor": "",
    "authors": [
      "Anshuman Suri",
      "Pallika Kanani",
      "Virendra J. Marathe",
      "Daniel W. Peterson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.03317"
  },
  {
    "id": "arXiv:2206.03318",
    "title": "LegoNN: Building Modular Encoder-Decoder Models",
    "abstract": "State-of-the-art encoder-decoder models (e.g. for machine translation (MT) or\nspeech recognition (ASR)) are constructed and trained end-to-end as an atomic\nunit. No component of the model can be (re-)used without the others. We\ndescribe LegoNN, a procedure for building encoder-decoder architectures with\ndecoder modules that can be reused across various MT and ASR tasks, without the\nneed for any fine-tuning. To achieve reusability, the interface between each\nencoder and decoder modules is grounded to a sequence of marginal distributions\nover a discrete vocabulary pre-defined by the model designer. We present two\napproaches for ingesting these marginals; one is differentiable, allowing the\nflow of gradients across the entire network, and the other is\ngradient-isolating. To enable portability of decoder modules between MT tasks\nfor different source languages and across other tasks like ASR, we introduce a\nmodality agnostic encoder which consists of a length control mechanism to\ndynamically adapt encoders' output lengths in order to match the expected input\nlength range of pre-trained decoders. We present several experiments to\ndemonstrate the effectiveness of LegoNN models: a trained language generation\nLegoNN decoder module from German-English (De-En) MT task can be reused with no\nfine-tuning for the Europarl English ASR and the Romanian-English (Ro-En) MT\ntasks to match or beat respective baseline models. When fine-tuned towards the\ntarget task for few thousand updates, our LegoNN models improved the Ro-En MT\ntask by 1.5 BLEU points, and achieved 12.5% relative WER reduction for the\nEuroparl ASR task. Furthermore, to show its extensibility, we compose a LegoNN\nASR model from three modules -- each has been learned within different\nend-to-end trained models on three different datasets -- boosting the WER\nreduction to 19.5%.",
    "descriptor": "\nComments: 13 pages; Submitted to TASLP 2022\n",
    "authors": [
      "Siddharth Dalmia",
      "Dmytro Okhonko",
      "Mike Lewis",
      "Sergey Edunov",
      "Shinji Watanabe",
      "Florian Metze",
      "Luke Zettlemoyer",
      "Abdelrahman Mohamed"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.03318"
  },
  {
    "id": "arXiv:2206.03319",
    "title": "A Differentially Private Linear-Time fPTAS for the Minimum Enclosing  Ball Problem",
    "abstract": "The Minimum Enclosing Ball (MEB) problem is one of the most fundamental\nproblems in clustering, with applications in operations research, statistics\nand computational geometry. In this works, we give the first differentially\nprivate (DP) fPTAS for the Minimum Enclosing Ball problem, improving both on\nthe runtime and the utility bound of the best known DP-PTAS for the problem, of\nGhazi et al. (2020). Given $n$ points in $\\R^d$ that are covered by the ball\n$B(\\theta_{opt},r_{opt})$, our simple iterative DP-algorithm returns a ball\n$B(\\theta,r)$ where $r\\leq (1+\\gamma)r_{opt}$ and which leaves at most $\\tilde\nO(\\frac{\\sqrt d}{\\gamma^2\\epsilon})$ points uncovered in $\\tilde O(\\nicefrac n\n{\\gamma^2})$-time. We also give a local-model version of our algorithm, that\nleaves at most $\\tilde O(\\frac{\\sqrt {nd}}{\\gamma^2\\epsilon})$ points\nuncovered, improving on the $n^{0.67}$-bound of Nissim and Stemmer (2018) (at\nthe expense of other parameters). In addition, we test our algorithm\nempirically and discuss future open problems.",
    "descriptor": "",
    "authors": [
      "Bar Mahpud",
      "Or Sheffet"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.03319"
  },
  {
    "id": "arXiv:2206.03321",
    "title": "Early Abnormal Detection of Sewage Pipe Network: Bagging of Various  Abnormal Detection Algorithms",
    "abstract": "Abnormalities of the sewage pipe network will affect the normal operation of\nthe whole city. Therefore, it is important to detect the abnormalities early.\nThis paper propose an early abnormal-detection method. The abnormalities are\ndetected by using the conventional algorithms, such as isolation forest\nalgorithm, two innovations are given: (1) The current and historical data\nmeasured by the sensors placed in the sewage pipe network (such as ultrasonic\nDoppler flowmeter) are taken as the overall dataset, and then the general\ndataset is detected by using the conventional anomaly detection method to\ndiagnose the anomaly of the data. The anomaly refers to the sample different\nfrom the others samples in the whole dataset. Because the definition of anomaly\nis not through the algorithm, but the whole dataset, the construction of the\nwhole dataset is the key to propose the early abnormal-detection algorithms.\n(2) A bagging strategy for a variety of conventional anomaly detection\nalgorithms is proposed to achieve the early detection of anomalies with the\nhigh precision and recall. The results show that this method can achieve the\nearly anomaly detection with the highest precision of 98.21%, the recall rate\n63.58% and F1-score of 0.774.",
    "descriptor": "",
    "authors": [
      "Zhen-Yu Zhang",
      "Guo-Xiang Shao",
      "Chun-Ming Qiu",
      "Yue-Jie Hou",
      "En-Ming Zhao",
      "Chi-Chun Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03321"
  },
  {
    "id": "arXiv:2206.03322",
    "title": "Deep Learning-based FEA surrogate for sub-sea pressure vessel",
    "abstract": "During the design process of an autonomous underwater vehicle (AUV), the\npressure vessel has a critical role. The pressure vessel contains dry\nelectronics, power sources, and other sensors that can not be flooded. A\ntraditional design approach for a pressure vessel design involves running\nmultiple Finite Element Analysis (FEA) based simulations and optimizing the\ndesign to find the best suitable design which meets the requirement. Running\nthese FEAs are computationally very costly for any optimization process and it\nbecomes difficult to run even hundreds of evaluation. In such a case, a better\napproach is the surrogate design with the goal of replacing FEA-based\nprediction with some learning-based regressor. Once the surrogate is trained\nfor a class of problem, then the learned response surface can be used to\nanalyze the stress effect without running the FEA for that class of problem.\nThe challenge of creating a surrogate for a class of problems is data\ngeneration. Since the process is computationally costly, it is not possible to\ndensely sample the design space and the learning response surface on sparse\ndata set becomes difficult. During experimentation, we observed that a Deep\nLearning-based surrogate outperforms other regression models on such sparse\ndata. In the present work, we are utilizing the Deep Learning-based model to\nreplace the costly finite element analysis-based simulation process. By\ncreating the surrogate we speed up the prediction on the other design much\nfaster than direct Finite element Analysis. We also compared our DL-based\nsurrogate with other classical Machine Learning (ML) based regression models(\nrandom forest and Gradient Boost regressor). We observed on the sparser data,\nthe DL-based surrogate performs much better than other regression models.",
    "descriptor": "",
    "authors": [
      "Harsh Vardhan",
      "Janos Sztipanovits"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.03322"
  },
  {
    "id": "arXiv:2206.03324",
    "title": "Efficient decentralized multi-agent learning in asymmetric queuing  systems",
    "abstract": "We study decentralized multi-agent learning in bipartite queuing systems, a\nstandard model for service systems. In particular, $N$ agents request service\nfrom $K$ servers in a fully decentralized way, i.e, by running the same\nalgorithm without communication. Previous decentralized algorithms are\nrestricted to symmetric systems, have performance that is degrading\nexponentially in the number of servers, require communication through shared\nrandomness and unique agent identities, and are computationally demanding. In\ncontrast, we provide a simple learning algorithm that, when run decentrally by\neach agent, leads the queuing system to have efficient performance in general\nasymmetric bipartite queuing systems while also having additional robustness\nproperties. Along the way, we provide the first UCB-based algorithm for the\ncentralized case of the problem, which resolves an open question by Krishnasamy\net al. (2016,2021).",
    "descriptor": "\nComments: Accepted for presentation at the Conference on Learning Theory (COLT) 2022\n",
    "authors": [
      "Daniel Freund",
      "Thodoris Lykouris",
      "Wentao Weng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03324"
  },
  {
    "id": "arXiv:2206.03325",
    "title": "Searching Similarity Measure for Binarized Neural Networks",
    "abstract": "Being a promising model to be deployed in resource-limited devices, Binarized\nNeural Networks (BNNs) have drawn extensive attention from both academic and\nindustry. However, comparing to the full-precision deep neural networks (DNNs),\nBNNs suffer from non-trivial accuracy degradation, limiting its applicability\nin various domains. This is partially because existing network components, such\nas the similarity measure, are specially designed for DNNs, and might be\nsub-optimal for BNNs.\nIn this work, we focus on the key component of BNNs -- the similarity\nmeasure, which quantifies the distance between input feature maps and filters,\nand propose an automatic searching method, based on genetic algorithm, for\nBNN-tailored similarity measure. Evaluation results on Cifar10 and Cifar100\nusing ResNet, NIN and VGG show that most of the identified similarty measure\ncan achieve considerable accuracy improvement (up to 3.39%) over the\ncommonly-used cross-correlation approach.",
    "descriptor": "",
    "authors": [
      "Yanfei Li",
      "Ang Li",
      "Huimin Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03325"
  },
  {
    "id": "arXiv:2206.03326",
    "title": "Efficient Machine Learning, Compilers, and Optimizations for Embedded  Systems",
    "abstract": "Deep Neural Networks (DNNs) have achieved great success in a massive number\nof artificial intelligence (AI) applications by delivering high-quality\ncomputer vision, natural language processing, and virtual reality applications.\nHowever, these emerging AI applications also come with increasing computation\nand memory demands, which are challenging to handle especially for the embedded\nsystems where limited computation/memory resources, tight power budgets, and\nsmall form factors are demanded. Challenges also come from the diverse\napplication-specific requirements, including real-time responses,\nhigh-throughput performance, and reliable inference accuracy. To address these\nchallenges, we will introduce a series of effective design methods in this book\nchapter to enable efficient algorithms, compilers, and various optimizations\nfor embedded systems.",
    "descriptor": "\nComments: This article will appear as a book chapter in a new book: Embedded Machine Learning for Cyber-Physical, IoT, and Edge Computing, Springer Nature\n",
    "authors": [
      "Xiaofan Zhang",
      "Yao Chen",
      "Cong Hao",
      "Sitao Huang",
      "Yuhong Li",
      "Deming Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2206.03326"
  },
  {
    "id": "arXiv:2206.03328",
    "title": "Concentration bounds for SSP Q-learning for average cost MDPs",
    "abstract": "We derive a concentration bound for a Q-learning algorithm for average cost\nMarkov decision processes based on an equivalent shortest path problem, and\ncompare it numerically with the alternative scheme based on relative value\niteration.",
    "descriptor": "\nComments: 6 pages, 2 figures\n",
    "authors": [
      "Shaan Ul Haque",
      "Vivek Borkar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.03328"
  },
  {
    "id": "arXiv:2206.03330",
    "title": "EEG-based Emotion Recognition with Spatial and Functional Brain Mapping  of CNS and PNS Signals",
    "abstract": "Emotion plays a significant role in our daily life. Recognition of emotion is\nwide-spread in the field of health care and human-computer interaction. Emotion\nis the result of the coordinated activities of cortical and subcortical neural\nprocesses, which correlate to specific physiological responses. However, the\nexisting emotion recognition techniques failed to combine various physiological\nsignals as one integrated feature representation. Meanwhile, many researchers\nignored the problem of over-fitting model with high accuracy, which was\nactually false high accuracy caused by improper pre-processing. In this paper,\nsigmoid baseline filtering is conducted to solve the over-fitting problem from\nsource. To construct a physiological-based algorithm, a 3D spatial and\nfunctional brain mapping is proposed based on human physiological mechanism and\ninternational electrode system, which combines the signals of the central and\nperipheral nervous system together. By combining the baseline filtering, 3D\nbrain mapping, and simple 4D-CNN, a novel emotion recognition model is finally\nproposed. Experiment results demonstrate that the performance of the proposed\nmodel is comparable to the state of art algorithms.",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Zhiyao Cen",
      "Xiangwen Deng",
      "Hengjie Zheng",
      "Jianing Zhao",
      "Anjie Jin",
      "Chentao Fu",
      "Tianqi Wang",
      "Shangming Yang",
      "Jingdian Yang"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2206.03330"
  },
  {
    "id": "arXiv:2206.03331",
    "title": "Improving the Diagnosis of Psychiatric Disorders with Self-Supervised  Graph State Space Models",
    "abstract": "Single subject prediction of brain disorders from neuroimaging data has\ngained increasing attention in recent years. Yet, for some heterogeneous\ndisorders such as major depression disorder (MDD) and autism spectrum disorder\n(ASD), the performance of prediction models on large-scale multi-site datasets\nremains poor. We present a two-stage framework to improve the diagnosis of\nheterogeneous psychiatric disorders from resting-state functional magnetic\nresonance imaging (rs-fMRI). First, we propose a self-supervised mask\nprediction task on data from healthy individuals that can exploit differences\nbetween healthy controls and patients in clinical datasets. Next, we train a\nsupervised classifier on the learned discriminative representations. To model\nrs-fMRI data, we develop Graph-S4; an extension to the recently proposed\nstate-space model S4 to graph settings where the underlying graph structure is\nnot known in advance. We show that combining the framework and Graph-S4 can\nsignificantly improve the diagnostic performance of neuroimaging-based single\nsubject prediction models of MDD and ASD on three open-source multi-center\nrs-fMRI clinical datasets.",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Ahmed El Gazzar",
      "Rajat Mani Thomas",
      "Guido Van Wingen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03331"
  },
  {
    "id": "arXiv:2206.03333",
    "title": "Assessing Project-Level Fine-Tuning of ML4SE Models",
    "abstract": "Machine Learning for Software Engineering (ML4SE) is an actively growing\nresearch area that focuses on methods that help programmers in their work. In\norder to apply the developed methods in practice, they need to achieve\nreasonable quality in order to help rather than distract developers. While the\ndevelopment of new approaches to code representation and data collection\nimproves the overall quality of the models, it does not take into account the\ninformation that we can get from the project at hand.\nIn this work, we investigate how the model's quality can be improved if we\ntarget a specific project. We develop a framework to assess quality\nimprovements that models can get after fine-tuning for the method name\nprediction task on a particular project. We evaluate three models of different\ncomplexity and compare their quality in three settings: trained on a large\ndataset of Java projects, further fine-tuned on the data from a particular\nproject, and trained from scratch on this data. We show that per-project\nfine-tuning can greatly improve the models' quality as they capture the\nproject's domain and naming conventions. We open-source the tool we used for\ndata collection, as well as the code to run the experiments:\nhttps://zenodo.org/record/6040745.",
    "descriptor": "\nComments: 12 pages, 3 figures\n",
    "authors": [
      "Egor Bogomolov",
      "Sergey Zhuravlev",
      "Egor Spirin",
      "Timofey Bryksin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03333"
  },
  {
    "id": "arXiv:2206.03334",
    "title": "Correlations of network trajectories",
    "abstract": "Temporal networks model how the interaction between elements in a complex\nsystem evolve over time. Just like complex systems display collective dynamics,\nhere we interpret temporal networks as trajectories performing a collective\nmotion in graph space, following a latent graph dynamical system. Under this\nparadigm, we propose a way to measure how the network pulsates and collectively\nfluctuates over time and space. To this aim, we extend the notion of linear\ncorrelations function to the case of sequences of network snapshots, i.e. a\nnetwork trajectory. We construct stochastic and deterministic graph dynamical\nsystems and show that the emergent collective correlations are well captured by\nsimple measures, and illustrate how these patterns are revealed in empirical\nnetworks arising in different domains.",
    "descriptor": "",
    "authors": [
      "Lucas Lacasa",
      "Jorge P. Rodriguez",
      "Victor M. Eguiluz"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.03334"
  },
  {
    "id": "arXiv:2206.03342",
    "title": "Group Properties of Polar Codes for Automorphism Ensemble Decoding",
    "abstract": "In this paper, we propose an analysis of the automorphism group of polar\ncodes, with the scope of designing codes tailored for automorphism ensemble\n(AE) decoding. We prove the equivalence between the notion of decreasing\nmonomial codes and the universal partial order (UPO) framework for the\ndescription of polar codes. Then, we analyze the algebraic properties of the\naffine automorphisms group of polar codes, providing a novel description of its\nstructure and proposing a classification of automorphisms providing the same\nresults under permutation decoding. Finally, we propose a method to list all\nthe automorphisms that may lead to different candidates under AE decoding; by\nintroducing the concept of redundant automorphisms, we find the maximum number\nof permutations providing possibly different codeword candidates under AE-SC,\nproposing a method to list all of them. A numerical analysis of the error\ncorrection performance of AE algorithm for the decoding of polar codes\nconcludes the paper.",
    "descriptor": "\nComments: submitted to IEEE for possible publication\n",
    "authors": [
      "Valerio Bioglio",
      "Ingmar Land",
      "Charles Pillet"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.03342"
  },
  {
    "id": "arXiv:2206.03348",
    "title": "Specification-Guided Learning of Nash Equilibria with High Social  Welfare",
    "abstract": "Reinforcement learning has been shown to be an effective strategy for\nautomatically training policies for challenging control problems. Focusing on\nnon-cooperative multi-agent systems, we propose a novel reinforcement learning\nframework for training joint policies that form a Nash equilibrium. In our\napproach, rather than providing low-level reward functions, the user provides\nhigh-level specifications that encode the objective of each agent. Then, guided\nby the structure of the specifications, our algorithm searches over policies to\nidentify one that provably forms an $\\epsilon$-Nash equilibrium (with high\nprobability). Importantly, it prioritizes policies in a way that maximizes\nsocial welfare across all agents. Our empirical evaluation demonstrates that\nour algorithm computes equilibrium policies with high social welfare, whereas\nstate-of-the-art baselines either fail to compute Nash equilibria or compute\nones with comparatively lower social welfare.",
    "descriptor": "",
    "authors": [
      "Kishor Jothimurugan",
      "Suguman Bansal",
      "Osbert Bastani",
      "Rajeev Alur"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03348"
  },
  {
    "id": "arXiv:2206.03351",
    "title": "AS2T: Arbitrary Source-To-Target Adversarial Attack on Speaker  Recognition Systems",
    "abstract": "Recent work has illuminated the vulnerability of speaker recognition systems\n(SRSs) against adversarial attacks, raising significant security concerns in\ndeploying SRSs. However, they considered only a few settings (e.g., some\ncombinations of source and target speakers), leaving many interesting and\nimportant settings in real-world attack scenarios alone. In this work, we\npresent AS2T, the first attack in this domain which covers all the settings,\nthus allows the adversary to craft adversarial voices using arbitrary source\nand target speakers for any of three main recognition tasks. Since none of the\nexisting loss functions can be applied to all the settings, we explore many\ncandidate loss functions for each setting including the existing and newly\ndesigned ones. We thoroughly evaluate their efficacy and find that some\nexisting loss functions are suboptimal. Then, to improve the robustness of AS2T\ntowards practical over-the-air attack, we study the possible distortions\noccurred in over-the-air transmission, utilize different transformation\nfunctions with different parameters to model those distortions, and incorporate\nthem into the generation of adversarial voices. Our simulated over-the-air\nevaluation validates the effectiveness of our solution in producing robust\nadversarial voices which remain effective under various hardware devices and\nvarious acoustic environments with different reverberation, ambient noises, and\nnoise levels. Finally, we leverage AS2T to perform thus far the largest-scale\nevaluation to understand transferability among 14 diverse SRSs. The\ntransferability analysis provides many interesting and useful insights which\nchallenge several findings and conclusion drawn in previous works in the image\ndomain. Our study also sheds light on future directions of adversarial attacks\nin the speaker recognition domain.",
    "descriptor": "",
    "authors": [
      "Guangke Chen",
      "Zhe Zhao",
      "Fu Song",
      "Sen Chen",
      "Lingling Fan",
      "Yang Liu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.03351"
  },
  {
    "id": "arXiv:2206.03352",
    "title": "Searching for Optimal Subword Tokenization in Cross-domain NER",
    "abstract": "Input distribution shift is one of the vital problems in unsupervised domain\nadaptation (UDA). The most popular UDA approaches focus on domain-invariant\nrepresentation learning, trying to align the features from different domains\ninto similar feature distributions. However, these approaches ignore the direct\nalignment of input word distributions between domains, which is a vital factor\nin word-level classification tasks such as cross-domain NER. In this work, we\nshed new light on cross-domain NER by introducing a subword-level solution,\nX-Piece, for input word-level distribution shift in NER. Specifically, we\nre-tokenize the input words of the source domain to approach the target subword\ndistribution, which is formulated and solved as an optimal transport problem.\nAs this approach focuses on the input level, it can also be combined with\nprevious DIRL methods for further improvement. Experimental results show the\neffectiveness of the proposed method based on BERT-tagger on four benchmark NER\ndatasets. Also, the proposed method is proved to benefit DIRL methods such as\nDANN.",
    "descriptor": "\nComments: IJCAI 2022\n",
    "authors": [
      "Ruotian Ma",
      "Yiding Tan",
      "Xin Zhou",
      "Xuanting Chen",
      "Di Liang",
      "Sirui Wang",
      "Wei Wu",
      "Tao Gui",
      "Qi Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.03352"
  },
  {
    "id": "arXiv:2206.03354",
    "title": "cViL: Cross-Lingual Training of Vision-Language Models using Knowledge  Distillation",
    "abstract": "Vision-and-language tasks are gaining popularity in the research community,\nbut the focus is still mainly on English. We propose a pipeline that utilizes\nEnglish-only vision-language models to train a monolingual model for a target\nlanguage. We propose to extend OSCAR+, a model which leverages object tags as\nanchor points for learning image-text alignments, to train on visual question\nanswering datasets in different languages. We propose a novel approach to\nknowledge distillation to train the model in other languages using parallel\nsentences. Compared to other models that use the target language in the\npretraining corpora, we can leverage an existing English model to transfer the\nknowledge to the target language using significantly lesser resources. We also\nrelease a large-scale visual question answering dataset in Japanese and Hindi\nlanguage. Though we restrict our work to visual question answering, our model\ncan be extended to any sequence-level classification task, and it can be\nextended to other languages as well. This paper focuses on two languages for\nthe visual question answering task - Japanese and Hindi. Our pipeline\noutperforms the current state-of-the-art models by a relative increase of 4.4%\nand 13.4% respectively in accuracy.",
    "descriptor": "\nComments: Accepted at ICPR 2022; 8 pages\n",
    "authors": [
      "Kshitij Gupta",
      "Devansh Gautam",
      "Radhika Mamidi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.03354"
  },
  {
    "id": "arXiv:2206.03356",
    "title": "Position Paper: Online Modeling for Offline Planning",
    "abstract": "The definition and representation of planning problems is at the heart of AI\nplanning research. A key part is the representation of action models. Decades\nof advances improving declarative action model representations resulted in\nnumerous theoretical advances, and capable, working, domain-independent\nplanners. However, despite the maturity of the field, AI planning technology is\nstill rarely used outside the research community, suggesting that current\nrepresentations fail to capture real-world requirements, such as utilizing\ncomplex mathematical functions and models learned from data. We argue that this\nis because the modeling process is assumed to have taken place and completed\nprior to the planning process, i.e., offline modeling for offline planning.\nThere are several challenges inherent to this approach, including: limited\nexpressiveness of declarative modeling languages; early commitment to modeling\nchoices and computation, that preclude using the most appropriate resolution\nfor each action model -- which can only be known during planning; and\ndifficulty in reliably using non-declarative, learned, models.\nWe therefore suggest to change the AI planning process, such that is carries\nout online modeling in offline planning, i.e., the use of action models that\nare computed or even generated as part of the planning process, as they are\naccessed. This generalizes the existing approach (offline modeling). The\nproposed definition admits novel planning processes, and we suggest one\nconcrete implementation, demonstrating the approach. We sketch initial results\nthat were obtained as part of a first attempt to follow this approach by\nplanning with action cost estimators. We conclude by discussing open\nchallenges.",
    "descriptor": "",
    "authors": [
      "Eyal Weiss",
      "Gal A. Kaminka"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.03356"
  },
  {
    "id": "arXiv:2206.03358",
    "title": "Towards a Coq formalization of a quantified modal logic",
    "abstract": "The Quantified Reflection Calculus with one modality, denoted by\n$\\mathsf{QRC}_1$, is a strictly positive quantified modal logic inspired by the\nunimodal fragment of the Reflection Calculus. The quantified strictly positive\nlanguage consists of a verum constant and relation symbols as atomic formulas,\nwith the only available connectives being the conjunction, the diamond, and the\nuniversal quantifier. $\\mathsf{QRC}_1$ statements are assertions of the form\n$\\varphi \\leadsto \\psi$ where $\\varphi$ and $\\psi$ are in this strictly\npositive language.\n$\\mathsf{QRC}_1$ was born out of the wish for a nice quantified provability\nlogic for theories of arithmetic such as Peano Arithmetic, even though\nVardanyan showed in 1986 that this is impossible in general. However,\nrestricting the language to the strictly positive fragment is a viable\nsolution, as shown by the author and Joosten in 2022.\n$\\mathsf{QRC}_1$ has been proved sound and complete with respect to constant\ndomain Kripke models. Furthermore, it has the finite model property with\nrespect to both the domain size and the number of worlds, implying its\ndecidability.\nCoq is an interactive theorem prover with which one can write definitions,\nexecutable algorithms, statements, and machine-checked proofs. We describe a\nCoq formalization of $\\mathsf{QRC}_1$ and of some relevant results, most\nnoticeably the Kripke soundness theorem. In the future, we aim to formalize the\nfull completeness proof and extract a decision procedure in order to\nmechanically check whether a given implication of strictly positive formulas is\nprovable in $\\mathsf{QRC}_1$ or not.",
    "descriptor": "\nComments: See this https URL for the associated Coq code\n",
    "authors": [
      "Ana de Almeida Borges"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.03358"
  },
  {
    "id": "arXiv:2206.03360",
    "title": "Towards Explainable Social Agent Authoring tools: A case study on  FAtiMA-Toolkit",
    "abstract": "The deployment of Socially Intelligent Agents (SIAs) in learning environments\nhas proven to have several advantages in different areas of application. Social\nAgent Authoring Tools allow scenario designers to create tailored experiences\nwith high control over SIAs behaviour, however, on the flip side, this comes at\na cost as the complexity of the scenarios and its authoring can become\noverbearing. In this paper we introduce the concept of Explainable Social Agent\nAuthoring Tools with the goal of analysing if authoring tools for social agents\nare understandable and interpretable. To this end we examine whether an\nauthoring tool, FAtiMA-Toolkit, is understandable and its authoring steps\ninterpretable, from the point-of-view of the author. We conducted two user\nstudies to quantitatively assess the Interpretability, Comprehensibility and\nTransparency of FAtiMA-Toolkit from the perspective of a scenario designer. One\nof the key findings is the fact that FAtiMA-Toolkit's conceptual model is, in\ngeneral, understandable, however the emotional-based concepts were not as\neasily understood and used by the authors. Although there are some positive\naspects regarding the explainability of FAtiMA-Toolkit, there is still progress\nto be made to achieve a fully explainable social agent authoring tool. We\nprovide a set of key concepts and possible solutions that can guide developers\nto build such tools.",
    "descriptor": "\nComments: 24 Pages, 6 figures, in submission limbo\n",
    "authors": [
      "Manuel Guimar\u00e3es",
      "Joana Campos",
      "Pedro A. Santos",
      "Jo\u00e3o Dias",
      "Rui Prada"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.03360"
  },
  {
    "id": "arXiv:2206.03361",
    "title": "Hierarchical Similarity Learning for Aliasing Suppression Image  Super-Resolution",
    "abstract": "As a highly ill-posed issue, single image super-resolution (SISR) has been\nwidely investigated in recent years. The main task of SISR is to recover the\ninformation loss caused by the degradation procedure. According to the Nyquist\nsampling theory, the degradation leads to aliasing effect and makes it hard to\nrestore the correct textures from low-resolution (LR) images. In practice,\nthere are correlations and self-similarities among the adjacent patches in the\nnatural images. This paper considers the self-similarity and proposes a\nhierarchical image super-resolution network (HSRNet) to suppress the influence\nof aliasing. We consider the SISR issue in the optimization perspective, and\npropose an iterative solution pattern based on the half-quadratic splitting\n(HQS) method. To explore the texture with local image prior, we design a\nhierarchical exploration block (HEB) and progressive increase the receptive\nfield. Furthermore, multi-level spatial attention (MSA) is devised to obtain\nthe relations of adjacent feature and enhance the high-frequency information,\nwhich acts as a crucial role for visual experience. Experimental result shows\nHSRNet achieves better quantitative and visual performance than other works,\nand remits the aliasing more effectively.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Yuqing Liu",
      "Qi Jia",
      "Jian Zhang",
      "Xin Fan",
      "Shanshe Wang",
      "Siwei Ma",
      "Wen Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.03361"
  },
  {
    "id": "arXiv:2206.03362",
    "title": "Building Robust Ensembles via Margin Boosting",
    "abstract": "In the context of adversarial robustness, a single model does not usually\nhave enough power to defend against all possible adversarial attacks, and as a\nresult, has sub-optimal robustness. Consequently, an emerging line of work has\nfocused on learning an ensemble of neural networks to defend against\nadversarial attacks. In this work, we take a principled approach towards\nbuilding robust ensembles. We view this problem from the perspective of\nmargin-boosting and develop an algorithm for learning an ensemble with maximum\nmargin. Through extensive empirical evaluation on benchmark datasets, we show\nthat our algorithm not only outperforms existing ensembling techniques, but\nalso large models trained in an end-to-end fashion. An important byproduct of\nour work is a margin-maximizing cross-entropy (MCE) loss, which is a better\nalternative to the standard cross-entropy (CE) loss. Empirically, we show that\nreplacing the CE loss in state-of-the-art adversarial training techniques with\nour MCE loss leads to significant performance improvement.",
    "descriptor": "\nComments: Accepted by ICML 2022\n",
    "authors": [
      "Dinghuai Zhang",
      "Hongyang Zhang",
      "Aaron Courville",
      "Yoshua Bengio",
      "Pradeep Ravikumar",
      "Arun Sai Suggala"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.03362"
  },
  {
    "id": "arXiv:2206.03365",
    "title": "DeepOPF-AL: Augmented Learning for Solving AC-OPF Problems with Multiple  Load-Solution Mappings",
    "abstract": "The existence of multiple load-solution mappings of non-convex AC-OPF\nproblems poses a fundamental challenge to deep neural network (DNN) schemes. As\nthe training dataset may contain a mixture of data points corresponding to\ndifferent load-solution mappings, the DNN can fail to learn a legitimate\nmapping and generate inferior solutions. We propose DeepOPF-AL as an\naugmented-learning approach to tackle this issue. The idea is to train a DNN to\nlearn a unique mapping from an augmented input, i.e., (load, initial point), to\nthe solution generated by an iterative OPF solver with the load and initial\npoint as intake. We then apply the learned augmented mapping to solve AC-OPF\nproblems much faster than conventional solvers. Simulation results over IEEE\ntest cases show that DeepOPF-AL achieves noticeably better optimality and\nsimilar feasibility and speedup performance, as compared to a recent DNN\nscheme, with the same DNN size yet elevated training complexity.",
    "descriptor": "\nComments: 3 pages,2 figures\n",
    "authors": [
      "Xiang Pan",
      "Wanjun Huang",
      "Minghua Chen",
      "Steven H. Low"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.03365"
  },
  {
    "id": "arXiv:2206.03367",
    "title": "Localizing Semantic Patches for Accelerating Image Classification",
    "abstract": "Existing works often focus on reducing the architecture redundancy for\naccelerating image classification but ignore the spatial redundancy of the\ninput image. This paper proposes an efficient image classification pipeline to\nsolve this problem. We first pinpoint task-aware regions over the input image\nby a lightweight patch proposal network called AnchorNet. We then feed these\nlocalized semantic patches with much smaller spatial redundancy into a general\nclassification network. Unlike the popular design of deep CNN, we aim to\ncarefully design the Receptive Field of AnchorNet without intermediate\nconvolutional paddings. This ensures the exact mapping from a high-level\nspatial location to the specific input image patch. The contribution of each\npatch is interpretable. Moreover, AnchorNet is compatible with any downstream\narchitecture. Experimental results on ImageNet show that our method outperforms\nSOTA dynamic inference methods with fewer inference costs. Our code is\navailable at https://github.com/winycg/AnchorNet.",
    "descriptor": "\nComments: Accepted by ICME-2022\n",
    "authors": [
      "Chuanguang Yang",
      "Zhulin An",
      "Yongjun Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.03367"
  },
  {
    "id": "arXiv:2206.03368",
    "title": "IL-MCAM: An interactive learning and multi-channel attention  mechanism-based weakly supervised colorectal histopathology image  classification approach",
    "abstract": "In recent years, colorectal cancer has become one of the most significant\ndiseases that endanger human health. Deep learning methods are increasingly\nimportant for the classification of colorectal histopathology images. However,\nexisting approaches focus more on end-to-end automatic classification using\ncomputers rather than human-computer interaction. In this paper, we propose an\nIL-MCAM framework. It is based on attention mechanisms and interactive\nlearning. The proposed IL-MCAM framework includes two stages: automatic\nlearning (AL) and interactivity learning (IL). In the AL stage, a multi-channel\nattention mechanism model containing three different attention mechanism\nchannels and convolutional neural networks is used to extract multi-channel\nfeatures for classification. In the IL stage, the proposed IL-MCAM framework\ncontinuously adds misclassified images to the training set in an interactive\napproach, which improves the classification ability of the MCAM model. We\ncarried out a comparison experiment on our dataset and an extended experiment\non the HE-NCT-CRC-100K dataset to verify the performance of the proposed\nIL-MCAM framework, achieving classification accuracies of 98.98% and 99.77%,\nrespectively. In addition, we conducted an ablation experiment and an\ninterchangeability experiment to verify the ability and interchangeability of\nthe three channels. The experimental results show that the proposed IL-MCAM\nframework has excellent performance in the colorectal histopathological image\nclassification tasks.",
    "descriptor": "",
    "authors": [
      "Haoyuan Chen",
      "Chen Li",
      "Xiaoyan Li",
      "Md Mamunur Rahaman",
      "Weiming Hu",
      "Yixin Li",
      "Wanli Liu",
      "Changhao Sun",
      "Hongzan Sun",
      "Xinyu Huang",
      "Marcin Grzegorzek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.03368"
  },
  {
    "id": "arXiv:2206.03373",
    "title": "Garment Avatars: Realistic Cloth Driving using Pattern Registration",
    "abstract": "Virtual telepresence is the future of online communication. Clothing is an\nessential part of a person's identity and self-expression. Yet, ground truth\ndata of registered clothes is currently unavailable in the required resolution\nand accuracy for training telepresence models for realistic cloth animation.\nHere, we propose an end-to-end pipeline for building drivable representations\nfor clothing. The core of our approach is a multi-view patterned cloth tracking\nalgorithm capable of capturing deformations with high accuracy. We further rely\non the high-quality data produced by our tracking method to build a Garment\nAvatar: an expressive and fully-drivable geometry model for a piece of\nclothing. The resulting model can be animated using a sparse set of views and\nproduces highly realistic reconstructions which are faithful to the driving\nsignals. We demonstrate the efficacy of our pipeline on a realistic virtual\ntelepresence application, where a garment is being reconstructed from two\nviews, and a user can pick and swap garment design as they wish. In addition,\nwe show a challenging scenario when driven exclusively with body pose, our\ndrivable garment avatar is capable of producing realistic cloth geometry of\nsignificantly higher quality than the state-of-the-art.",
    "descriptor": "",
    "authors": [
      "Oshri Halimi",
      "Fabian Prada",
      "Tuur Stuyck",
      "Donglai Xiang",
      "Timur Bagautdinov",
      "He Wen",
      "Ron Kimmel",
      "Takaaki Shiratori",
      "Chenglei Wu",
      "Yaser Sheikh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.03373"
  },
  {
    "id": "arXiv:2206.03376",
    "title": "On Outer Bi-Lipschitz Extensions of Linear Johnson-Lindenstrauss  Embeddings of Low-Dimensional Submanifolds of $\\mathbb{R}^N$",
    "abstract": "Let $\\mathcal{M}$ be a compact $d$-dimensional submanifold of $\\mathbb{R}^N$\nwith reach $\\tau$ and volume $V_{\\mathcal M}$. Fix $\\epsilon \\in (0,1)$. In\nthis paper we prove that a nonlinear function $f: \\mathbb{R}^N \\rightarrow\n\\mathbb{R}^{m}$ exists with $m \\leq C \\left(d / \\epsilon^2 \\right) \\log\n\\left(\\frac{\\sqrt[d]{V_{\\mathcal M}}}{\\tau} \\right)$ such that $$(1 - \\epsilon)\n\\| {\\bf x} - {\\bf y} \\|_2 \\leq \\left\\| f({\\bf x}) - f({\\bf y}) \\right\\|_2 \\leq\n(1 + \\epsilon) \\| {\\bf x} - {\\bf y} \\|_2$$ holds for all ${\\bf x} \\in\n\\mathcal{M}$ and ${\\bf y} \\in \\mathbb{R}^N$. In effect, $f$ not only serves as\na bi-Lipschitz function from $\\mathcal{M}$ into $\\mathbb{R}^{m}$ with\nbi-Lipschitz constants close to one, but also approximately preserves all\ndistances from points not in $\\mathcal{M}$ to all points in $\\mathcal{M}$ in\nits image. Furthermore, the proof is constructive and yields an algorithm which\nworks well in practice. In particular, it is empirically demonstrated herein\nthat such nonlinear functions allow for more accurate compressive nearest\nneighbor classification than standard linear Johnson-Lindenstrauss embeddings\ndo in practice.",
    "descriptor": "",
    "authors": [
      "Mark A. Iwen",
      "Mark Philip Roach"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Geometry (cs.CG)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03376"
  },
  {
    "id": "arXiv:2206.03377",
    "title": "RAAT: Relation-Augmented Attention Transformer for Relation Modeling in  Document-Level Event Extraction",
    "abstract": "In document-level event extraction (DEE) task, event arguments always scatter\nacross sentences (across-sentence issue) and multiple events may lie in one\ndocument (multi-event issue). In this paper, we argue that the relation\ninformation of event arguments is of great significance for addressing the\nabove two issues, and propose a new DEE framework which can model the relation\ndependencies, called Relation-augmented Document-level Event Extraction\n(ReDEE). More specifically, this framework features a novel and tailored\ntransformer, named as Relation-augmented Attention Transformer (RAAT). RAAT is\nscalable to capture multi-scale and multi-amount argument relations. To further\nleverage relation information, we introduce a separate event relation\nprediction task and adopt multi-task learning method to explicitly enhance\nevent extraction performance. Extensive experiments demonstrate the\neffectiveness of the proposed method, which can achieve state-of-the-art\nperformance on two public datasets. Our code is available at https://github.\ncom/TencentYoutuResearch/RAAT.",
    "descriptor": "\nComments: Accepted by NAACL 2022\n",
    "authors": [
      "Yuan Liang",
      "Zhuoxuan Jiang",
      "Di Yin",
      "Bo Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.03377"
  },
  {
    "id": "arXiv:2206.03378",
    "title": "Imitating Past Successes can be Very Suboptimal",
    "abstract": "Prior work has proposed a simple strategy for reinforcement learning (RL):\nlabel experience with the outcomes achieved in that experience, and then\nimitate the relabeled experience. These outcome-conditioned imitation learning\nmethods are appealing because of their simplicity, strong performance, and\nclose ties with supervised learning. However, it remains unclear how these\nmethods relate to the standard RL objective, reward maximization. In this\npaper, we prove that existing outcome-conditioned imitation learning methods do\nnot necessarily improve the policy; rather, in some settings they can decrease\nthe expected reward. Nonetheless, we show that a simple modification results in\na method that does guarantee policy improvement, under some assumptions. Our\naim is not to develop an entirely new method, but rather to explain how a\nvariant of outcome-conditioned imitation learning can be used to maximize\nrewards.",
    "descriptor": "",
    "authors": [
      "Benjamin Eysenbach",
      "Soumith Udatha",
      "Sergey Levine",
      "Ruslan Salakhutdinov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.03378"
  },
  {
    "id": "arXiv:2206.03380",
    "title": "Shape, Light & Material Decomposition from Images using Monte Carlo  Rendering and Denoising",
    "abstract": "Recent advances in differentiable rendering have enabled high-quality\nreconstruction of 3D scenes from multi-view images. Most methods rely on simple\nrendering algorithms: pre-filtered direct lighting or learned representations\nof irradiance. We show that a more realistic shading model, incorporating ray\ntracing and Monte Carlo integration, substantially improves decomposition into\nshape, materials & lighting. Unfortunately, Monte Carlo integration provides\nestimates with significant noise, even at large sample counts, which makes\ngradient-based inverse rendering very challenging. To address this, we\nincorporate multiple importance sampling and denoising in a novel inverse\nrendering pipeline. This substantially improves convergence and enables\ngradient-based optimization at low sample counts. We present an efficient\nmethod to jointly reconstruct geometry (explicit triangle meshes), materials,\nand lighting, which substantially improves material and light separation\ncompared to previous work. We argue that denoising can become an integral part\nof high quality inverse rendering pipelines.",
    "descriptor": "",
    "authors": [
      "Jon Hasselgren",
      "Nikolai Hofmann",
      "Jacob Munkberg"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.03380"
  },
  {
    "id": "arXiv:2206.03381",
    "title": "Software Verification of Hyperproperties Beyond k-Safety",
    "abstract": "Temporal hyperproperties are system properties that relate multiple execution\ntraces. For (finite-state) hardware, temporal hyperproperties are supported by\nmodel checking algorithms, and tools for general temporal logics like HyperLTL\nexist. For (infinite-state) software, the analysis of temporal hyperproperties\nhas, so far, been limited to $k$-safety properties, i.e., properties that\nstipulate the absence of a bad interaction between any $k$ traces. In this\npaper, we present an automated method for the verification of\n$\\forall^k\\exists^l$-safety properties in infinite-state systems. A\n$\\forall^k\\exists^l$-safety property stipulates that for any $k$ traces, there\nexist $l$ traces such that the resulting $k+l$ traces do not interact badly.\nThis combination of universal and existential quantification allows us to\nexpress many properties beyond $k$-safety, including, for example, generalized\nnon-interference or program refinement. Our method is based on a strategy-based\ninstantiation of existential trace quantification combined with a program\nreduction, both in the context of a fixed predicate abstraction. Importantly,\nour framework allows for mutual dependence of strategy and reduction.",
    "descriptor": "\nComments: CAV 2022\n",
    "authors": [
      "Raven Beutner",
      "Bernd Finkbeiner"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.03381"
  },
  {
    "id": "arXiv:2206.03382",
    "title": "Tutel: Adaptive Mixture-of-Experts at Scale",
    "abstract": "In recent years, Mixture-of-Experts (MoE) has emerged as a promising\ntechnique for deep learning that can scale the model capacity to trillion-plus\nparameters while reducing the computing cost via sparse computation. While MoE\nopens a new frontier of exceedingly large models, its implementation over\nthousands of GPUs has been limited due to mismatch between the dynamic nature\nof MoE and static parallelism/pipelining of the system. We present Tutel, a\nhighly scalable stack design and implementation for MoE with dynamically\nadaptive parallelism and pipelining. Tutel delivers adaptive parallelism\nswitching and adaptive pipelining at runtime, which achieves up to 1.74x and\n2.00x single MoE layer speedup, respectively. We also propose a novel\ntwo-dimensional hierarchical algorithm for MoE communication speedup that\noutperforms the previous state-of-the-art up to 20.7x over 2,048 GPUs.\nAggregating all techniques, Tutel finally delivers 4.96x and 5.75x speedup of a\nsingle MoE layer on 16 GPUs and 2,048 GPUs, respectively, over Fairseq: Meta's\nFacebook AI Research Sequence-to-Sequence Toolkit (Tutel is now partially\nadopted by Fairseq). Tutel source code is available in public:\nhttps://github.com/microsoft/tutel . Our evaluation shows that Tutel\nefficiently and effectively runs a real-world MoE-based model named SwinV2-MoE,\nbuilt upon Swin Transformer V2, a state-of-the-art computer vision\narchitecture. On efficiency, Tutel accelerates SwinV2-MoE, achieving up to\n1.55x and 2.11x speedup in training and inference over Fairseq, respectively.\nOn effectiveness, the SwinV2-MoE model achieves superior accuracy in both\npre-training and down-stream computer vision tasks such as COCO object\ndetection than the counterpart dense model, indicating the readiness of Tutel\nfor end-to-end real-world model training and inference. SwinV2-MoE is open\nsourced in https://github.com/microsoft/Swin-Transformer .",
    "descriptor": "",
    "authors": [
      "Changho Hwang",
      "Wei Cui",
      "Yifan Xiong",
      "Ziyue Yang",
      "Ze Liu",
      "Han Hu",
      "Zilong Wang",
      "Rafael Salas",
      "Jithin Jose",
      "Prabhat Ram",
      "Joe Chau",
      "Peng Cheng",
      "Fan Yang",
      "Mao Yang",
      "Yongqiang Xiong"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.03382"
  },
  {
    "id": "arXiv:2206.03383",
    "title": "On the Role of Discount Factor in Offline Reinforcement Learning",
    "abstract": "Offline reinforcement learning (RL) enables effective learning from\npreviously collected data without exploration, which shows great promise in\nreal-world applications when exploration is expensive or even infeasible. The\ndiscount factor, $\\gamma$, plays a vital role in improving online RL sample\nefficiency and estimation accuracy, but the role of the discount factor in\noffline RL is not well explored. This paper examines two distinct effects of\n$\\gamma$ in offline RL with theoretical analysis, namely the regularization\neffect and the pessimism effect. On the one hand, $\\gamma$ is a regulator to\ntrade-off optimality with sample efficiency upon existing offline techniques.\nOn the other hand, lower guidance $\\gamma$ can also be seen as a way of\npessimism where we optimize the policy's performance in the worst possible\nmodels. We empirically verify the above theoretical observation with tabular\nMDPs and standard D4RL tasks. The results show that the discount factor plays\nan essential role in the performance of offline RL algorithms, both under small\ndata regimes upon existing offline methods and in large data regimes without\nother conservatisms.",
    "descriptor": "\nComments: Thirty-ninth International Conference on Machine Learning\n",
    "authors": [
      "Hao Hu",
      "Yiqin Yang",
      "Qianchuan Zhao",
      "Chongjie Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03383"
  },
  {
    "id": "arXiv:2206.03388",
    "title": "Chemistry-Inspired Pattern Formation with Robotic Swarms",
    "abstract": "Self-organized emergent patterns can be widely seen in particle interactions\nproducing complex structures such as chemical elements and molecules. Inspired\nby these interactions, this work presents a novel stochastic approach that\nallows a swarm of heterogeneous robots to create emergent patterns in a\ncompletely decentralized fashion and relying only on local information. Our\napproach consists of modeling the swarm configuration as a dynamic Gibbs Random\nField (GRF) and setting constraints on the neighborhood system inspired by\nchemistry rules that dictate binding polarity between particles. Using the GRF\nmodel, we determine velocities for each robot, resulting in behaviors that lead\nto the creation of patterns or shapes. Simulated experiments show the\nversatility of the approach in producing a variety of patterns, and experiments\nwith a group of physical robots show the feasibility in potential applications.",
    "descriptor": "\nComments: Submitted to IEEE RA-L/IROS 2022\n",
    "authors": [
      "Paulo Rezeck",
      "Luiz Chaimowicz"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.03388"
  },
  {
    "id": "arXiv:2206.03390",
    "title": "Gender Bias in Word Embeddings: A Comprehensive Analysis of Frequency,  Syntax, and Semantics",
    "abstract": "The statistical regularities in language corpora encode well-known social\nbiases into word embeddings. Here, we focus on gender to provide a\ncomprehensive analysis of group-based biases in widely-used static English word\nembeddings trained on internet corpora (GloVe 2014, fastText 2017). Using the\nSingle-Category Word Embedding Association Test, we demonstrate the widespread\nprevalence of gender biases that also show differences in: (1) frequencies of\nwords associated with men versus women; (b) part-of-speech tags in\ngender-associated words; (c) semantic categories in gender-associated words;\nand (d) valence, arousal, and dominance in gender-associated words.\nFirst, in terms of word frequency: we find that, of the 1,000 most frequent\nwords in the vocabulary, 77% are more associated with men than women, providing\ndirect evidence of a masculine default in the everyday language of the\nEnglish-speaking world. Second, turning to parts-of-speech: the top\nmale-associated words are typically verbs (e.g., fight, overpower) while the\ntop female-associated words are typically adjectives and adverbs (e.g., giving,\nemotionally). Gender biases in embeddings also permeate parts-of-speech. Third,\nfor semantic categories: bottom-up, cluster analyses of the top 1,000 words\nassociated with each gender. The top male-associated concepts include roles and\ndomains of big tech, engineering, religion, sports, and violence; in contrast,\nthe top female-associated concepts are less focused on roles, including,\ninstead, female-specific slurs and sexual content, as well as appearance and\nkitchen terms. Fourth, using human ratings of word valence, arousal, and\ndominance from a ~20,000 word lexicon, we find that male-associated words are\nhigher on arousal and dominance, while female-associated words are higher on\nvalence.",
    "descriptor": "\nComments: 15 pages, 6 figures, accepted to AAAI/ACM Artificial Intelligence, Ethics, and Society\n",
    "authors": [
      "Aylin Caliskan",
      "Pimparkar Parth Ajay",
      "Tessa Charlesworth",
      "Robert Wolfe",
      "Mahzarin R. Banaji"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03390"
  },
  {
    "id": "arXiv:2206.03391",
    "title": "Data Stealing Attack on Medical Images: Is it Safe to Export Networks  from Data Lakes?",
    "abstract": "In privacy-preserving machine learning, it is common that the owner of the\nlearned model does not have any physical access to the data. Instead, only a\nsecured remote access to a data lake is granted to the model owner without any\nability to retrieve data from the data lake. Yet, the model owner may want to\nexport the trained model periodically from the remote repository and a question\narises whether this may cause is a risk of data leakage. In this paper, we\nintroduce the concept of data stealing attack during the export of neural\nnetworks. It consists in hiding some information in the exported network that\nallows the reconstruction outside the data lake of images initially stored in\nthat data lake. More precisely, we show that it is possible to train a network\nthat can perform lossy image compression and at the same time solve some\nutility tasks such as image segmentation. The attack then proceeds by exporting\nthe compression decoder network together with some image codes that leads to\nthe image reconstruction outside the data lake. We explore the feasibility of\nsuch attacks on databases of CT and MR images, showing that it is possible to\nobtain perceptually meaningful reconstructions of the target dataset, and that\nthe stolen dataset can be used in turns to solve a broad range of tasks.\nComprehensive experiments and analyses show that data stealing attacks should\nbe considered as a threat for sensitive imaging data sources.",
    "descriptor": "",
    "authors": [
      "Huiyu Li",
      "Nicholas Ayache",
      "Herv\u00e9 Delingette"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03391"
  },
  {
    "id": "arXiv:2206.03393",
    "title": "Towards Understanding and Mitigating Audio Adversarial Examples for  Speaker Recognition",
    "abstract": "Speaker recognition systems (SRSs) have recently been shown to be vulnerable\nto adversarial attacks, raising significant security concerns. In this work, we\nsystematically investigate transformation and adversarial training based\ndefenses for securing SRSs. According to the characteristic of SRSs, we present\n22 diverse transformations and thoroughly evaluate them using 7 recent\npromising adversarial attacks (4 white-box and 3 black-box) on speaker\nrecognition. With careful regard for best practices in defense evaluations, we\nanalyze the strength of transformations to withstand adaptive attacks. We also\nevaluate and understand their effectiveness against adaptive attacks when\ncombined with adversarial training. Our study provides lots of useful insights\nand findings, many of them are new or inconsistent with the conclusions in the\nimage and speech recognition domains, e.g., variable and constant bit rate\nspeech compressions have different performance, and some non-differentiable\ntransformations remain effective against current promising evasion techniques\nwhich often work well in the image domain. We demonstrate that the proposed\nnovel feature-level transformation combined with adversarial training is rather\neffective compared to the sole adversarial training in a complete white-box\nsetting, e.g., increasing the accuracy by 13.62% and attack cost by two orders\nof magnitude, while other transformations do not necessarily improve the\noverall defense capability. This work sheds further light on the research\ndirections in this field. We also release our evaluation platform SPEAKERGUARD\nto foster further research.",
    "descriptor": "",
    "authors": [
      "Guangke Chen",
      "Zhe Zhao",
      "Fu Song",
      "Sen Chen",
      "Lingling Fan",
      "Feng Wang",
      "Jiashui Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.03393"
  },
  {
    "id": "arXiv:2206.03396",
    "title": "Group privacy for personalized federated learning",
    "abstract": "Federated learning is a type of collaborative machine learning, where\nparticipating clients process their data locally, sharing only updates to the\ncollaborative model. This enables to build privacy-aware distributed machine\nlearning models, among others. The goal is the optimization of a statistical\nmodel's parameters by minimizing a cost function of a collection of datasets\nwhich are stored locally by a set of clients. This process exposes the clients\nto two issues: leakage of private information and lack of personalization of\nthe model. On the other hand, with the recent advancements in techniques to\nanalyze data, there is a surge of concern for the privacy violation of the\nparticipating clients. To mitigate this, differential privacy and its variants\nserve as a standard for providing formal privacy guarantees. Often the clients\nrepresent very heterogeneous communities and hold data which are very diverse.\nTherefore, aligned with the recent focus of the FL community to build a\nframework of personalized models for the users representing their diversity, it\nis also of utmost importance to protect against potential threats against the\nsensitive and personal information of the clients. $d$-privacy, which is a\ngeneralization of geo-indistinguishability, the lately popularized paradigm of\nlocation privacy, uses a metric-based obfuscation technique that preserves the\nspatial distribution of the original data. To address the issue of protecting\nthe privacy of the clients and allowing for personalized model training to\nenhance the fairness and utility of the system, we propose a method to provide\ngroup privacy guarantees exploiting some key properties of $d$-privacy which\nenables personalized models under the framework of FL. We provide with\ntheoretical justifications to the applicability and experimental validation on\nreal-world datasets to illustrate the working of the proposed method.",
    "descriptor": "",
    "authors": [
      "Filippo Galli",
      "Sayan Biswas",
      "Kangsoo Jung",
      "Catuscia Palamidessi",
      "Tommaso Cucinotta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.03396"
  },
  {
    "id": "arXiv:2206.03398",
    "title": "Towards a General Purpose CNN for Long Range Dependencies in  $\\mathrm{N}$D",
    "abstract": "The use of Convolutional Neural Networks (CNNs) is widespread in Deep\nLearning due to a range of desirable model properties which result in an\nefficient and effective machine learning framework. However, performant CNN\narchitectures must be tailored to specific tasks in order to incorporate\nconsiderations such as the input length, resolution, and dimentionality. In\nthis work, we overcome the need for problem-specific CNN architectures with our\nContinuous Convolutional Neural Network (CCNN): a single CNN architecture\nequipped with continuous convolutional kernels that can be used for tasks on\ndata of arbitrary resolution, dimensionality and length without structural\nchanges. Continuous convolutional kernels model long range dependencies at\nevery layer, and remove the need for downsampling layers and task-dependent\ndepths needed in current CNN architectures. We show the generality of our\napproach by applying the same CCNN to a wide set of tasks on sequential\n(1$\\mathrm{D}$) and visual data (2$\\mathrm{D}$). Our CCNN performs\ncompetitively and often outperforms the current state-of-the-art across all\ntasks considered.",
    "descriptor": "\nComments: First two authors contributed equally to this work\n",
    "authors": [
      "David W. Romero",
      "David M. Knigge",
      "Albert Gu",
      "Erik J. Bekkers",
      "Efstratios Gavves",
      "Jakub M. Tomczak",
      "Mark Hoogendoorn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.03398"
  },
  {
    "id": "arXiv:2206.03401",
    "title": "MIX-MAB: Reinforcement Learning-based Resource Allocation Algorithm for  LoRaWAN",
    "abstract": "This paper focuses on improving the resource allocation algorithm in terms of\npacket delivery ratio (PDR), i.e., the number of successfully received packets\nsent by end devices (EDs) in a long-range wide-area network (LoRaWAN). Setting\nthe transmission parameters significantly affects the PDR. Employing\nreinforcement learning (RL), we propose a resource allocation algorithm that\nenables the EDs to configure their transmission parameters in a distributed\nmanner. We model the resource allocation problem as a multi-armed bandit (MAB)\nand then address it by proposing a two-phase algorithm named MIX-MAB, which\nconsists of the exponential weights for exploration and exploitation (EXP3) and\nsuccessive elimination (SE) algorithms. We evaluate the MIX-MAB performance\nthrough simulation results and compare it with other existing approaches.\nNumerical results show that the proposed solution performs better than the\nexisting schemes in terms of convergence time and PDR.",
    "descriptor": "",
    "authors": [
      "Farzad Azizi",
      "Benyamin Teymuri",
      "Rojin Aslani",
      "Mehdi Rasti",
      "Jesse Tolvanen",
      "Pedro H. J. Nardelli"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.03401"
  },
  {
    "id": "arXiv:2206.03408",
    "title": "UAV-Enabled Integrated Sensing and Communication: Opportunities and  Challenges",
    "abstract": "Unmanned aerial vehicle (UAV)-enabled integrated sensing and communication\n(ISAC) has attracted growing research interests towards sixth-generation (6G)\nwireless networks, in which UAVs are exploited as aerial wireless platforms to\nprovide better coverage and enhanced sensing and communication (S\\&C) services.\nHowever, due to the UAVs' size, weight, and power (SWAP) constraints,\ncontrollable mobility, and strong line-of-sight (LoS) air-ground channels, the\nUAV-enabled ISAC introduces both new opportunities and challenges. This article\nprovides an overview on UAV-enabled ISAC, by presenting various solutions for\noptimizing the S\\&C performance. In particular, we first present the\nUAV-enabled joint sensing and communication, and discuss the UAV maneuver\ncontrol, wireless resource allocation, and interference management in the cases\nwith single and multiple UAVs. Then, we present two application scenarios to\nexploit the mutual assistance between S\\&C, namely sensing-assisted UAV\ncommunication and communication-assisted UAV sensing. Finally, we highlight\nseveral interesting research directions to motivate future work.",
    "descriptor": "\nComments: 8 pages, 6 figures. This work has been submitted to the IEEE for possible publication\n",
    "authors": [
      "Kaitao Meng",
      "Qingqing Wu",
      "Jie Xu",
      "Wen Chen",
      "Zhiyong Feng"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.03408"
  },
  {
    "id": "arXiv:2206.03410",
    "title": "Fast and Robust Non-Rigid Registration Using Accelerated  Majorization-Minimization",
    "abstract": "Non-rigid registration, which deforms a source shape in a non-rigid way to\nalign with a target shape, is a classical problem in computer vision. Such\nproblems can be challenging because of imperfect data (noise, outliers and\npartial overlap) and high degrees of freedom. Existing methods typically adopt\nthe $\\ell_{p}$ type robust norm to measure the alignment error and regularize\nthe smoothness of deformation, and use a proximal algorithm to solve the\nresulting non-smooth optimization problem. However, the slow convergence of\nsuch algorithms limits their wide applications. In this paper, we propose a\nformulation for robust non-rigid registration based on a globally smooth robust\nnorm for alignment and regularization, which can effectively handle outliers\nand partial overlaps. The problem is solved using the majorization-minimization\nalgorithm, which reduces each iteration to a convex quadratic problem with a\nclosed-form solution. We further apply Anderson acceleration to speed up the\nconvergence of the solver, enabling the solver to run efficiently on devices\nwith limited compute capability. Extensive experiments demonstrate the\neffectiveness of our method for non-rigid alignment between two shapes with\noutliers and partial overlaps, with quantitative evaluation showing that it\noutperforms state-of-the-art methods in terms of registration accuracy and\ncomputational speed. The source code is available at\nhttps://github.com/yaoyx689/AMM_NRR.",
    "descriptor": "",
    "authors": [
      "Yuxin Yao",
      "Bailin Deng",
      "Weiwei Xu",
      "Juyong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2206.03410"
  },
  {
    "id": "arXiv:2206.03418",
    "title": "Responsibility-Sensitive Safety: an Introduction with an Eye to Logical  Foundations and Formalization",
    "abstract": "Responsibility-sensitive safety (RSS) is an approach to the safety of\nautomated driving systems (ADS). It aims to introduce mathematically formulated\nsafety rules, compliance with which guarantees collision avoidance as a\nmathematical theorem. However, despite the emphasis on mathematical and logical\nguarantees, the logical foundations and formalization of RSS are largely an\nunexplored topic of study. In this paper, we present an introduction to RSS,\none that we expect will bridge between different research communities and pave\nthe way to a logical theory of RSS, its mathematical formalization, and\nsoftware tools of practical use.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Ichiro Hasuo"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.03418"
  },
  {
    "id": "arXiv:2206.03419",
    "title": "A Secure and Trusted Mechanism for Industrial IoT Network using  Blockchain",
    "abstract": "Industrial Internet-of-Things (IIoT) is a powerful IoT application which\nremodels the growth of industries by ensuring transparent communication among\nvarious entities such as hubs, manufacturing places and packaging units.\nIntroducing data science techniques within the IIoT improves the ability to\nanalyze the collected data in a more efficient manner, which current IIoT\narchitectures lack due to their distributed nature. From a security\nperspective, network anomalies/attackers pose high security risk in IIoT. In\nthis paper, we have addressed this problem, where a coordinator IoT device is\nelected to compute the trust of IoT devices to prevent the malicious devices to\nbe part of network. Further, the transparency of the data is ensured by\nintegrating a blockchain-based data model. The performance of the proposed\nframework is validated extensively and rigorously via MATLAB against various\nsecurity metrics such as attack strength, message alteration, and probability\nof false authentication. The simulation results suggest that the proposed\nsolution increases IIoT network security by efficiently detecting malicious\nattacks in the network.",
    "descriptor": "",
    "authors": [
      "Geetanjali Rathee",
      "Farhan Ahmad",
      "Naveen Jaglan",
      "Charalambos Konstantinou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.03419"
  },
  {
    "id": "arXiv:2206.03420",
    "title": "FedRel: An Adaptive Federated Relevance Framework for Spatial Temporal  Graph Learning",
    "abstract": "Spatial-temporal data contains rich information and has been widely studied\nin recent years due to the rapid development of relevant applications in many\nfields. For instance, medical institutions often use electrodes attached to\ndifferent parts of a patient to analyse the electorencephal data rich with\nspatial and temporal features for health assessment and disease diagnosis.\nExisting research has mainly used deep learning techniques such as\nconvolutional neural network (CNN) or recurrent neural network (RNN) to extract\nhidden spatial-temporal features. Yet, it is challenging to incorporate both\ninter-dependencies spatial information and dynamic temporal changes\nsimultaneously. In reality, for a model that leverages these spatial-temporal\nfeatures to fulfil complex prediction tasks, it often requires a colossal\namount of training data in order to obtain satisfactory model performance.\nConsidering the above-mentioned challenges, we propose an adaptive federated\nrelevance framework, namely FedRel, for spatial-temporal graph learning in this\npaper. After transforming the raw spatial-temporal data into high quality\nfeatures, the core Dynamic Inter-Intra Graph (DIIG) module in the framework is\nable to use these features to generate the spatial-temporal graphs capable of\ncapturing the hidden topological and long-term temporal correlation information\nin these graphs. To improve the model generalization ability and performance\nwhile preserving the local data privacy, we also design a relevance-driven\nfederated learning module in our framework to leverage diverse data\ndistributions from different participants with attentive aggregations of their\nmodels.",
    "descriptor": "",
    "authors": [
      "Tiehua Zhang",
      "Yuze Liu",
      "Zhishu Shen",
      "Rui Xu",
      "Xin Chen",
      "Xiaowei Huang",
      "Xi Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.03420"
  },
  {
    "id": "arXiv:2206.03425",
    "title": "Inexact and primal multilevel FETI-DP methods: a multilevel extension  and interplay with BDDC",
    "abstract": "We study a framework that allows to solve the coarse problem in the FETI-DP\nmethod approximately. It is based on the saddle-point formulation of the\nFETI-DP system with a block-triangular preconditioner. One of the blocks\napproximates the coarse problem, for which we use the multilevel BDDC method as\nthe main tool. This strategy then naturally leads to a version of multilevel\nFETI-DP method, and we show that the spectra of the multilevel FETI-DP and BDDC\npreconditioned operators are essentially the same. The theory is illustrated by\na set of numerical experiments, and we also present a few experiments when the\ncoarse solve is approximated by algebraic multigrid.",
    "descriptor": "\nComments: 19 pages, 5 figures, 3 tables\n",
    "authors": [
      "Bed\u0159ich Soused\u00edk"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.03425"
  },
  {
    "id": "arXiv:2206.03426",
    "title": "Improving Fairness in Graph Neural Networks via Mitigating Sensitive  Attribute Leakage",
    "abstract": "Graph Neural Networks (GNNs) have shown great power in learning node\nrepresentations on graphs. However, they may inherit historical prejudices from\ntraining data, leading to discriminatory bias in predictions. Although some\nwork has developed fair GNNs, most of them directly borrow fair representation\nlearning techniques from non-graph domains without considering the potential\nproblem of sensitive attribute leakage caused by feature propagation in GNNs.\nHowever, we empirically observe that feature propagation could vary the\ncorrelation of previously innocuous non-sensitive features to the sensitive\nones. This can be viewed as a leakage of sensitive information which could\nfurther exacerbate discrimination in predictions. Thus, we design two feature\nmasking strategies according to feature correlations to highlight the\nimportance of considering feature propagation and correlation variation in\nalleviating discrimination. Motivated by our analysis, we propose Fair View\nGraph Neural Network (FairVGNN) to generate fair views of features by\nautomatically identifying and masking sensitive-correlated features considering\ncorrelation variation after feature propagation. Given the learned fair views,\nwe adaptively clamp weights of the encoder to avoid using sensitive-related\nfeatures. Experiments on real-world datasets demonstrate that FairVGNN enjoys a\nbetter trade-off between model utility and fairness. Our code is publicly\navailable at\n\\href{https://github.com/YuWVandy/FairVGNN}{\\textcolor{blue}{https://github.com/YuWVandy/FairVGNN}}.",
    "descriptor": "",
    "authors": [
      "Yu Wang",
      "Yuying Zhao",
      "Yushun Dong",
      "Huiyuan Chen",
      "Jundong Li",
      "Tyler Derr"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03426"
  },
  {
    "id": "arXiv:2206.03428",
    "title": "Revealing Single Frame Bias for Video-and-Language Learning",
    "abstract": "Training an effective video-and-language model intuitively requires multiple\nframes as model inputs. However, it is unclear whether using multiple frames is\nbeneficial to downstream tasks, and if yes, whether the performance gain is\nworth the drastically-increased computation and memory costs resulting from\nusing more frames. In this work, we explore single-frame models for\nvideo-and-language learning. On a diverse set of video-and-language tasks\n(including text-to-video retrieval and video question answering), we show the\nsurprising result that, with large-scale pre-training and a proper frame\nensemble strategy at inference time, a single-frame trained model that does not\nconsider temporal information can achieve better performance than existing\nmethods that use multiple frames for training. This result reveals the\nexistence of a strong \"static appearance bias\" in popular video-and-language\ndatasets. Therefore, to allow for a more comprehensive evaluation of\nvideo-and-language models, we propose two new retrieval tasks based on existing\nfine-grained action recognition datasets that encourage temporal modeling. Our\ncode is available at https://github.com/jayleicn/singularity",
    "descriptor": "\nComments: 19 pages, 8 figures\n",
    "authors": [
      "Jie Lei",
      "Tamara L. Berg",
      "Mohit Bansal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.03428"
  },
  {
    "id": "arXiv:2206.03429",
    "title": "Generating Long Videos of Dynamic Scenes",
    "abstract": "We present a video generation model that accurately reproduces object motion,\nchanges in camera viewpoint, and new content that arises over time. Existing\nvideo generation methods often fail to produce new content as a function of\ntime while maintaining consistencies expected in real environments, such as\nplausible dynamics and object persistence. A common failure case is for content\nto never change due to over-reliance on inductive biases to provide temporal\nconsistency, such as a single latent code that dictates content for the entire\nvideo. On the other extreme, without long-term consistency, generated videos\nmay morph unrealistically between different scenes. To address these\nlimitations, we prioritize the time axis by redesigning the temporal latent\nrepresentation and learning long-term consistency from data by training on\nlonger videos. To this end, we leverage a two-phase training strategy, where we\nseparately train using longer videos at a low resolution and shorter videos at\na high resolution. To evaluate the capabilities of our model, we introduce two\nnew benchmark datasets with explicit focus on long-term temporal dynamics.",
    "descriptor": "",
    "authors": [
      "Tim Brooks",
      "Janne Hellsten",
      "Miika Aittala",
      "Ting-Chun Wang",
      "Timo Aila",
      "Jaakko Lehtinen",
      "Ming-Yu Liu",
      "Alexei A. Efros",
      "Tero Karras"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.03429"
  },
  {
    "id": "arXiv:2206.03430",
    "title": "Robot Self-Calibration Using Actuated 3D Sensors",
    "abstract": "Both, robot and hand-eye calibration haven been object to research for\ndecades. While current approaches manage to precisely and robustly identify the\nparameters of a robot's kinematic model, they still rely on external devices,\nsuch as calibration objects, markers and/or external sensors. Instead of trying\nto fit the recorded measurements to a model of a known object, this paper\ntreats robot calibration as an offline SLAM problem, where scanning poses are\nlinked to a fixed point in space by a moving kinematic chain. As such, the\npresented framework allows robot calibration using nothing but an arbitrary\neye-in-hand depth sensor, thus enabling fully autonomous self-calibration\nwithout any external tools. My new approach is utilizes a modified version of\nthe Iterative Closest Point algorithm to run bundle adjustment on multiple 3D\nrecordings estimating the optimal parameters of the kinematic model. A detailed\nevaluation of the system is shown on a real robot with various attached 3D\nsensors. The presented results show that the system reaches precision\ncomparable to a dedicated external tracking system at a fraction of its cost.",
    "descriptor": "\nComments: 15 pages, 9 figures\n",
    "authors": [
      "Arne Peters"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.03430"
  },
  {
    "id": "arXiv:2206.03431",
    "title": "Self-supervised Domain Adaptation in Crowd Counting",
    "abstract": "Self-training crowd counting has not been attentively explored though it is\none of the important challenges in computer vision. In practice, the fully\nsupervised methods usually require an intensive resource of manual annotation.\nIn order to address this challenge, this work introduces a new approach to\nutilize existing datasets with ground truth to produce more robust predictions\non unlabeled datasets, named domain adaptation, in crowd counting. While the\nnetwork is trained with labeled data, samples without labels from the target\ndomain are also added to the training process. In this process, the entropy map\nis computed and minimized in addition to the adversarial training process\ndesigned in parallel. Experiments on Shanghaitech, UCF_CC_50, and UCF-QNRF\ndatasets prove a more generalized improvement of our method over the other\nstate-of-the-arts in the cross-domain setting.",
    "descriptor": "\nComments: 5 pages, 2 figures, 3 tables\n",
    "authors": [
      "Pha Nguyen",
      "Thanh-Dat Truong",
      "Miaoqing Huang",
      "Yi Liang",
      "Ngan Le",
      "Khoa Luu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.03431"
  },
  {
    "id": "arXiv:2206.03436",
    "title": "Federated Hetero-Task Learning",
    "abstract": "To investigate the heterogeneity of federated learning in real-world\nscenarios, we generalize the classical federated learning to federated\nhetero-task learning, which emphasizes the inconsistency across the\nparticipants in federated learning in terms of both data distribution and\nlearning tasks. We also present B-FHTL, a federated hetero-task learning\nbenchmark consisted of simulation dataset, FL protocols and a unified\nevaluation mechanism. B-FHTL dataset contains three well-designed federated\nlearning tasks with increasing heterogeneity. Each task simulates the clients\nwith different data distributions and learning tasks. To ensure fair comparison\namong different FL algorithms, B-FHTL builds in a full suite of FL protocols by\nproviding high-level APIs to avoid privacy leakage, and presets most common\nevaluation metrics spanning across different learning tasks, such as\nregression, classification, text generation and etc. Furthermore, we compare\nthe FL algorithms in fields of federated multi-task learning, federated\npersonalization and federated meta learning within B-FHTL, and highlight the\ninfluence of heterogeneity and difficulties of federated hetero-task learning.\nOur benchmark, including the federated dataset, protocols, the evaluation\nmechanism and the preliminary experiment, is open-sourced at\nhttps://github.com/alibaba/FederatedScope/tree/contest/v1.0.",
    "descriptor": "",
    "authors": [
      "Liuyi Yao",
      "Dawei Gao",
      "Zhen Wang",
      "Yuexiang Xie",
      "Weirui Kuang",
      "Daoyuan Chen",
      "Haohui Wang",
      "Chenhe Dong",
      "Bolin Ding",
      "Yaliang Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03436"
  },
  {
    "id": "arXiv:2206.03440",
    "title": "Enhancing Strong PUF Security with Non-monotonic Response Quantization",
    "abstract": "Strong physical unclonable functions (PUFs) provide a low-cost authentication\nprimitive for resource constrained devices. However, most strong PUF\narchitectures can be modeled through learning algorithms with a limited number\nof CRPs. In this paper, we introduce the concept of non-monotonic response\nquantization for strong PUFs. Responses depend not only on which path is\nfaster, but also on the distance between the arriving signals. Our experiments\nshow that the resulting PUF has increased security against learning attacks. To\ndemonstrate, we designed and implemented a non-monotonically quantized\nring-oscillator based PUF in 65 nm technology. Measurement results show nearly\nideal uniformity and uniqueness, with bit error rate of 13.4% over the\ntemperature range from 0 C to 50 C.",
    "descriptor": "",
    "authors": [
      "Kleber Stangherlin",
      "Zhuanhao Wu",
      "Hiren Patel",
      "Manoj Sachdev"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.03440"
  },
  {
    "id": "arXiv:2206.03441",
    "title": "Robust Sparse Mean Estimation via Sum of Squares",
    "abstract": "We study the problem of high-dimensional sparse mean estimation in the\npresence of an $\\epsilon$-fraction of adversarial outliers. Prior work obtained\nsample and computationally efficient algorithms for this task for\nidentity-covariance subgaussian distributions. In this work, we develop the\nfirst efficient algorithms for robust sparse mean estimation without a priori\nknowledge of the covariance. For distributions on $\\mathbb R^d$ with\n\"certifiably bounded\" $t$-th moments and sufficiently light tails, our\nalgorithm achieves error of $O(\\epsilon^{1-1/t})$ with sample complexity $m =\n(k\\log(d))^{O(t)}/\\epsilon^{2-2/t}$. For the special case of the Gaussian\ndistribution, our algorithm achieves near-optimal error of $\\tilde O(\\epsilon)$\nwith sample complexity $m = O(k^4 \\mathrm{polylog}(d))/\\epsilon^2$. Our\nalgorithms follow the Sum-of-Squares based, proofs to algorithms approach. We\ncomplement our upper bounds with Statistical Query and low-degree polynomial\ntesting lower bounds, providing evidence that the sample-time-error tradeoffs\nachieved by our algorithms are qualitatively the best possible.",
    "descriptor": "\nComments: To appear in COLT 2022\n",
    "authors": [
      "Ilias Diakonikolas",
      "Daniel M. Kane",
      "Sushrut Karmalkar",
      "Ankit Pensia",
      "Thanasis Pittas"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.03441"
  },
  {
    "id": "arXiv:2206.03445",
    "title": "Timed automata as a formalism for expressing security: A survey on  theory and practice",
    "abstract": "Timed automata are a common formalism for the verification of concurrent\nsystems subject to timing constraints. They extend finite-state automata with\nclocks, that constrain the system behavior in locations, and to take\ntransitions. While timed automata were originally designed for safety (in the\nwide sense of correctness w.r.t. a formal property), they were progressively\nused in a number of works to guarantee security properties. In this work, we\nreview works studying security properties for timed automata in the last two\ndecades. We notably review theoretical works, with a particular focus on\nopacity, as well as more practical works, with a particular focus on attack\ntrees and their extensions. We derive main conclusions concerning open\nperspectives, as well as tool support.",
    "descriptor": "\nComments: This is the author version of the manuscript of the same name published in ACM Computing Surveys\n",
    "authors": [
      "Johan Arcile",
      "\u00c9tienne Andr\u00e9"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.03445"
  },
  {
    "id": "arXiv:2206.03446",
    "title": "Learning in Observable POMDPs, without Computationally Intractable  Oracles",
    "abstract": "Much of reinforcement learning theory is built on top of oracles that are\ncomputationally hard to implement. Specifically for learning near-optimal\npolicies in Partially Observable Markov Decision Processes (POMDPs), existing\nalgorithms either need to make strong assumptions about the model dynamics\n(e.g. deterministic transitions) or assume access to an oracle for solving a\nhard optimistic planning or estimation problem as a subroutine. In this work we\ndevelop the first oracle-free learning algorithm for POMDPs under reasonable\nassumptions. Specifically, we give a quasipolynomial-time end-to-end algorithm\nfor learning in \"observable\" POMDPs, where observability is the assumption that\nwell-separated distributions over states induce well-separated distributions\nover observations. Our techniques circumvent the more traditional approach of\nusing the principle of optimism under uncertainty to promote exploration, and\ninstead give a novel application of barycentric spanners to constructing policy\ncovers.",
    "descriptor": "",
    "authors": [
      "Noah Golowich",
      "Ankur Moitra",
      "Dhruv Rohatgi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.03446"
  },
  {
    "id": "arXiv:2206.03448",
    "title": "Learning Mobile Manipulation",
    "abstract": "Providing mobile robots with the ability to manipulate objects has, despite\ndecades of research, remained a challenging problem. The problem is\napproachable in constrained environments where there is ample prior knowledge\nof the environment layout and manipulatable objects. The challenge is in\nbuilding systems that scale beyond specific situational instances and\ngracefully operate in novel conditions. In the past, researchers used heuristic\nand simple rule-based strategies to accomplish tasks such as scene segmentation\nor reasoning about occlusion. These heuristic strategies work in constrained\nenvironments where a roboticist can make simplifying assumptions about\neverything from the geometries of the objects to be interacted with, level of\nclutter, camera position, lighting, and a myriad of other relevant variables.\nThe work in this thesis will demonstrate how to build a system for robotic\nmobile manipulation that is robust to changes in these variables. This\nrobustness will be enabled by recent simultaneous advances in the fields of big\ndata, deep learning, and simulation. The ability of simulators to create\nrealistic sensory data enables the generation of massive corpora of labeled\ntraining data for various grasping and navigation-based tasks. It is now\npossible to build systems that work in the real world trained using deep\nlearning entirely on synthetic data. The ability to train and test on synthetic\ndata allows for quick iterative development of new perception, planning and\ngrasp execution algorithms that work in many environments.",
    "descriptor": "\nComments: PhD thesis\n",
    "authors": [
      "David Watkins"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.03448"
  },
  {
    "id": "arXiv:2206.03449",
    "title": "The virtual element method on image-based domain approximations",
    "abstract": "We analyze and validate the virtual element method combined with a projection\napproach similar to the one in [1, 2], to solve problems on two dimensional\ndomains with curved boundaries approximated by polygonal domains obtained as\nthe union of squared elements out of a uniform structured mesh, such as the one\nthat naturally arise when the domain is issued from an image. We show, both\ntheoretically and numerically, that resorting to the use of polygonal element\nallows to satisfy the assumptions required for the stability of the projection\napproach, thus allowing to fully exploit the potential of higher order methods,\nwhich makes the resulting approach an effective alternative to the use of the\nfinite element method.",
    "descriptor": "",
    "authors": [
      "Silvia Bertoluzza",
      "Monica Montardini",
      "Micol Pennacchio",
      "Daniele Prada"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.03449"
  },
  {
    "id": "arXiv:2206.03450",
    "title": "A Trade-off-centered Framework of Content Moderation",
    "abstract": "Content moderation research typically prioritizes representing and addressing\nchallenges for one group of stakeholders or communities in one type of context.\nWhile taking a focused approach is reasonable or even favorable for empirical\ncase studies, it does not address how content moderation works in multiple\ncontexts. Through a systematic literature review of 86 content moderation\npapers that document empirical studies, we seek to uncover patterns and\ntensions within past content moderation research. We find that content\nmoderation can be characterized as a series of trade-offs around moderation\nactions, styles, philosophies, and values. We discuss how facilitating\ncooperation and preventing abuse, two key elements in Grimmelmann's definition\nof moderation, are inherently dialectical in practice. We close by showing how\nresearchers, designers, and moderators can use our framework of trade-offs in\ntheir own work, and arguing that trade-offs should be of central importance in\ninvestigating and designing content moderation.",
    "descriptor": "\nComments: To appear in ACM TOCHI\n",
    "authors": [
      "Jialun Aaron Jiang",
      "Peipei Nie",
      "Jed R. Brubaker",
      "Casey Fiesler"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.03450"
  },
  {
    "id": "arXiv:2206.03451",
    "title": "Combining physics-based and data-driven techniques for reliable hybrid  analysis and modeling using the corrective source term approach",
    "abstract": "Upcoming technologies like digital twins, autonomous, and artificial\nintelligent systems involving safety-critical applications require models which\nare accurate, interpretable, computationally efficient, and generalizable.\nUnfortunately, the two most commonly used modeling approaches, physics-based\nmodeling (PBM) and data-driven modeling (DDM) fail to satisfy all these\nrequirements. In the current work, we demonstrate how a hybrid approach\ncombining the best of PBM and DDM can result in models which can outperform\nthem both. We do so by combining partial differential equations based on first\nprinciples describing partially known physics with a black box DDM, in this\ncase, a deep neural network model compensating for the unknown physics. First,\nwe present a mathematical argument for why this approach should work and then\napply the hybrid approach to model two dimensional heat diffusion problem with\nan unknown source term. The result demonstrates the method's superior\nperformance in terms of accuracy, and generalizability. Additionally, it is\nshown how the DDM part can be interpreted within the hybrid framework to make\nthe overall approach reliable.",
    "descriptor": "",
    "authors": [
      "Sindre Stenen Blakseth",
      "Adil Rasheed",
      "Trond Kvamsdal",
      "Omer San"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03451"
  },
  {
    "id": "arXiv:2206.03452",
    "title": "Can CNNs Be More Robust Than Transformers?",
    "abstract": "The recent success of Vision Transformers is shaking the long dominance of\nConvolutional Neural Networks (CNNs) in image recognition for a decade.\nSpecifically, in terms of robustness on out-of-distribution samples, recent\nresearch finds that Transformers are inherently more robust than CNNs,\nregardless of different training setups. Moreover, it is believed that such\nsuperiority of Transformers should largely be credited to their\nself-attention-like architectures per se. In this paper, we question that\nbelief by closely examining the design of Transformers. Our findings lead to\nthree highly effective architecture designs for boosting robustness, yet simple\nenough to be implemented in several lines of code, namely a) patchifying input\nimages, b) enlarging kernel size, and c) reducing activation layers and\nnormalization layers. Bringing these components together, we are able to build\npure CNN architectures without any attention-like operations that is as robust\nas, or even more robust than, Transformers. We hope this work can help the\ncommunity better understand the design of robust neural architectures. The code\nis publicly available at https://github.com/UCSC-VLAA/RobustCNN.",
    "descriptor": "\nComments: tech report; code is available at this https URL\n",
    "authors": [
      "Zeyu Wang",
      "Yutong Bai",
      "Yuyin Zhou",
      "Cihang Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.03452"
  },
  {
    "id": "arXiv:2206.03457",
    "title": "Dependently-Typed Data Plane Programming",
    "abstract": "Programming languages like P4 enable specifying the behavior of network data\nplanes in software. However, with increasingly powerful and complex\napplications running in the network, the risk of faults also increases. Hence,\nthere is growing recognition of the need for methods and tools to statically\nverify the correctness of P4 code, especially as the language lacks basic\nsafety guarantees. Type systems are a lightweight and compositional way to\nestablish program properties, but there is a significant gap between the kinds\nof properties that can be proved using simple type systems (e.g., SafeP4) and\nthose that can be obtained using full-blown verification tools (e.g., p4v). In\nthis paper, we close this gap by developing $\\Pi$4, a dependently-typed version\nof P4 based on decidable refinements. We motivate the design of $\\Pi$4, prove\nthe soundness of its type system, develop an SMT-based implementation, and\npresent case studies that illustrate its applicability to a variety of data\nplane programs.",
    "descriptor": "\nComments: This version is the companion technical report for the submission to POPL'22\n",
    "authors": [
      "Matthias Eichholz",
      "Eric Hayden Campbell",
      "Matthias Krebs",
      "Nate Foster",
      "Mira Mezini"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2206.03457"
  },
  {
    "id": "arXiv:2206.03459",
    "title": "The b-symbol weight distributions of all semiprimitive irreducible  cyclic codes",
    "abstract": "Up to a new invariant $\\mu(b)$, the complete $b$-symbol weight distribution\nof a particular kind of two-weight irreducible cyclic codes, was recently\nobtained by Zhu et al. [Des. Codes Cryptogr., 90 (2022) 1113-1125]. The purpose\nof this paper is to simplify and generalize the results of Zhu et al., and\nobtain the $b$-symbol weight distributions of all one-weight and two-weight\nsemiprimitive irreducible cyclic codes.",
    "descriptor": "",
    "authors": [
      "Gerardo Vega"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.03459"
  },
  {
    "id": "arXiv:2206.03461",
    "title": "Fast Unsupervised Brain Anomaly Detection and Segmentation with  Diffusion Models",
    "abstract": "Deep generative models have emerged as promising tools for detecting\narbitrary anomalies in data, dispensing with the necessity for manual\nlabelling. Recently, autoregressive transformers have achieved state-of-the-art\nperformance for anomaly detection in medical imaging. Nonetheless, these models\nstill have some intrinsic weaknesses, such as requiring images to be modelled\nas 1D sequences, the accumulation of errors during the sampling process, and\nthe significant inference times associated with transformers. Denoising\ndiffusion probabilistic models are a class of non-autoregressive generative\nmodels recently shown to produce excellent samples in computer vision\n(surpassing Generative Adversarial Networks), and to achieve log-likelihoods\nthat are competitive with transformers while having fast inference times.\nDiffusion models can be applied to the latent representations learnt by\nautoencoders, making them easily scalable and great candidates for application\nto high dimensional data, such as medical images. Here, we propose a method\nbased on diffusion models to detect and segment anomalies in brain imaging. By\ntraining the models on healthy data and then exploring its diffusion and\nreverse steps across its Markov chain, we can identify anomalous areas in the\nlatent space and hence identify anomalies in the pixel space. Our diffusion\nmodels achieve competitive performance compared with autoregressive approaches\nacross a series of experiments with 2D CT and MRI data involving synthetic and\nreal pathological lesions with much reduced inference times, making their usage\nclinically viable.",
    "descriptor": "",
    "authors": [
      "Walter H. L. Pinaya",
      "Mark S. Graham",
      "Robert Gray",
      "Pedro F Da Costa",
      "Petru-Daniel Tudosiu",
      "Paul Wright",
      "Yee H. Mah",
      "Andrew D. MacKinnon",
      "James T. Teo",
      "Rolf Jager",
      "David Werring",
      "Geraint Rees",
      "Parashkev Nachev",
      "Sebastien Ourselin",
      "M. Jorge Cardoso"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2206.03461"
  },
  {
    "id": "arXiv:2206.03463",
    "title": "HM-LDM: A Hybrid-Membership Latent Distance Model",
    "abstract": "A central aim of modeling complex networks is to accurately embed networks in\norder to detect structures and predict link and node properties. The latent\nspace models (LSM) have become prominent frameworks for embedding networks and\ninclude the latent distance (LDM) and eigenmodel (LEM) as the most widely used\nLSM specifications. For latent community detection, the embedding space in LDMs\nhas been endowed with a clustering model whereas LEMs have been constrained to\npart-based non-negative matrix factorization (NMF) inspired representations\npromoting community discovery. We presently reconcile LSMs with latent\ncommunity detection by constraining the LDM representation to the D-simplex\nforming the hybrid-membership latent distance model (HM-LDM). We show that for\nsufficiently large simplex volumes this can be achieved without loss of\nexpressive power whereas by extending the model to squared Euclidean distances,\nwe recover the LEM formulation with constraints promoting part-based\nrepresentations akin to NMF. Importantly, by systematically reducing the volume\nof the simplex, the model becomes unique and ultimately leads to hard\nassignments of nodes to simplex corners. We demonstrate experimentally how the\nproposed HM-LDM admits accurate node representations in regimes ensuring\nidentifiability and valid community extraction. Importantly, HM-LDM naturally\nreconciles soft and hard community detection with network embeddings exploring\na simple continuous optimization procedure on a volume constrained simplex that\nadmits the systematic investigation of trade-offs between hard and mixed\nmembership community detection.",
    "descriptor": "",
    "authors": [
      "Nikolaos Nakis",
      "Abdulkadir \u00c7elikkanat",
      "Morten M\u00f8rup"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.03463"
  },
  {
    "id": "arXiv:2206.03466",
    "title": "Adversarial Reprogramming Revisited",
    "abstract": "Adversarial reprogramming, introduced by Elsayed, Goodfellow, and\nSohl-Dickstein, seeks to repurpose a neural network to perform a different\ntask, by manipulating its input without modifying its weights. We prove that\ntwo-layer ReLU neural networks with random weights can be adversarially\nreprogrammed to achieve arbitrarily high accuracy on Bernoulli data models over\nhypercube vertices, provided the network width is no greater than its input\ndimension. We also substantially strengthen a recent result of Phuong and\nLampert on directional convergence of gradient flow, and obtain as a corollary\nthat training two-layer ReLU neural networks on orthogonally separable datasets\ncan cause their adversarial reprogramming to fail. We support these theoretical\nresults by experiments that demonstrate that, as long as batch normalisation\nlayers are suitably initialised, even untrained networks with random weights\nare susceptible to adversarial reprogramming. This is in contrast to\nobservations in several recent works that suggested that adversarial\nreprogramming is not possible for untrained networks to any degree of\nreliability.",
    "descriptor": "",
    "authors": [
      "Matthias Englert",
      "Ranko Lazic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03466"
  },
  {
    "id": "arXiv:2206.03467",
    "title": "Discrete State-Action Abstraction via the Successor Representation",
    "abstract": "When reinforcement learning is applied with sparse rewards, agents must spend\na prohibitively long time exploring the unknown environment without any\nlearning signal. Abstraction is one approach that provides the agent with an\nintrinsic reward for transitioning in a latent space. Prior work focuses on\ndense continuous latent spaces, or requires the user to manually provide the\nrepresentation. Our approach is the first for automatically learning a discrete\nabstraction of the underlying environment. Moreover, our method works on\narbitrary input spaces, using an end-to-end trainable regularized successor\nrepresentation model. For transitions between abstract states, we train a set\nof temporally extended actions in the form of options, i.e., an action\nabstraction. Our proposed algorithm, Discrete State-Action Abstraction (DSAA),\niteratively swaps between training these options and using them to efficiently\nexplore more of the environment to improve the state abstraction. As a result,\nour model is not only useful for transfer learning but also in the online\nlearning setting. We empirically show that our agent is able to explore the\nenvironment and solve provided tasks more efficiently than baseline\nreinforcement learning algorithms. Our code is publicly available at\n\\url{https://github.com/amnonattali/dsaa}.",
    "descriptor": "",
    "authors": [
      "Amnon Attali",
      "Pedro Cisneros-Velarde",
      "Marco Morales",
      "Nancy M. Amato"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.03467"
  },
  {
    "id": "arXiv:2206.03468",
    "title": "Rate Distortion Tradeoff in Private Read Update Write in Federated  Submodel Learning",
    "abstract": "We investigate the rate distortion tradeoff in private read update write\n(PRUW) in relation to federated submodel learning (FSL). In FSL a machine\nlearning (ML) model is divided into multiple submodels based on different types\nof data used for training. Each user only downloads and updates the submodel\nrelevant to its local data. The process of downloading and updating the\nrequired submodel while guaranteeing privacy of the submodel index and the\nvalues of updates is known as PRUW. In this work, we study how the\ncommunication cost of PRUW can be reduced when a pre-determined amount of\ndistortion is allowed in the reading (download) and writing (upload) phases. We\ncharacterize the rate distortion tradeoff in PRUW along with a scheme that\nachieves the lowest communication cost while working under a given distortion\nbudget.",
    "descriptor": "",
    "authors": [
      "Sajani Vithana",
      "Sennur Ulukus"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.03468"
  },
  {
    "id": "arXiv:2206.03469",
    "title": "FDGNN: Fully Dynamic Graph Neural Network",
    "abstract": "Dynamic Graph Neural Networks recently became more and more important as\ngraphs from many scientific fields, ranging from mathematics, biology, social\nsciences, and physics to computer science, are dynamic by nature. While\ntemporal changes (dynamics) play an essential role in many real-world\napplications, most of the models in the literature on Graph Neural Networks\n(GNN) process static graphs. The few GNN models on dynamic graphs only consider\nexceptional cases of dynamics, e.g., node attribute-dynamic graphs or\nstructure-dynamic graphs limited to additions or changes to the graph's edges,\netc. Therefore, we present a novel Fully Dynamic Graph Neural Network (FDGNN)\nthat can handle fully-dynamic graphs in continuous time. The proposed method\nprovides a node and an edge embedding that includes their activity to address\nadded and deleted nodes or edges, and possible attributes. Furthermore, the\nembeddings specify Temporal Point Processes for each event to encode the\ndistributions of the structure- and attribute-related incoming graph events. In\naddition, our model can be updated efficiently by considering single events for\nlocal retraining.",
    "descriptor": "",
    "authors": [
      "Alice Moallemy-Oureh",
      "Silvia Beddar-Wiesing",
      "R\u00fcdiger Nather",
      "Josephine M. Thomas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03469"
  },
  {
    "id": "arXiv:2206.03474",
    "title": "A COVID-19 Search Engine (CO-SE) with Transformer-based Architecture",
    "abstract": "Coronavirus disease (COVID-19) is an infectious disease, which is caused by\nthe SARS-CoV-2 virus. Due to the growing literature on COVID-19, it is hard to\nget precise, up-to-date information about the virus. Practitioners, front-line\nworkers, and researchers require expert-specific methods to stay current on\nscientific knowledge and research findings. However, there are a lot of\nresearch papers being written on the subject, which makes it hard to keep up\nwith the most recent research. This problem motivates us to propose the design\nof the COVID-19 Search Engine (CO-SE), which is an algorithmic system that\nfinds relevant documents for each query (asked by a user) and answers complex\nquestions by searching a large corpus of publications. The CO-SE has a\nretriever component trained on the TF-IDF vectorizer that retrieves the\nrelevant documents from the system. It also consists of a reader component that\nconsists of a Transformer-based model, which is used to read the paragraphs and\nfind the answers related to the query from the retrieved documents. The\nproposed model has outperformed previous models, obtaining an exact match ratio\nscore of 71.45% and a semantic answer similarity score of 78.55%. It also\noutperforms other benchmark datasets, demonstrating the generalizability of the\nproposed approach.",
    "descriptor": "\nComments: Accepted in HealthCare Analytics\n",
    "authors": [
      "Shaina Raza"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.03474"
  },
  {
    "id": "arXiv:2206.03477",
    "title": "Short Blocklength Wiretap Channel Codes via Deep Learning: Design and  Performance Evaluation",
    "abstract": "We design short blocklength codes for the Gaussian wiretap channel under\ninformation-theoretic security guarantees. Our approach consists in decoupling\nthe reliability and secrecy constraints in our code design. Specifically, we\nhandle the reliability constraint via an autoencoder, and handle the secrecy\nconstraint with hash functions. For blocklengths smaller than or equal to 16,\nwe evaluate through simulations the probability of error at the legitimate\nreceiver and the leakage at the eavesdropper for our code construction. This\nleakage is defined as the mutual information between the confidential message\nand the eavesdropper's channel observations, and is empirically measured via a\nneural network-based mutual information estimator. Our simulation results\nprovide examples of codes with positive secrecy rates that outperform the best\nknown achievable secrecy rates obtained non-constructively for the Gaussian\nwiretap channel. Additionally, we show that our code design is suitable for the\ncompound and arbitrarily varying Gaussian wiretap channels, for which the\nchannel statistics are not perfectly known but only known to belong to a\npre-specified uncertainty set. These models not only capture uncertainty\nrelated to channel statistics estimation, but also scenarios where the\neavesdropper jams the legitimate transmission or influences its own channel\nstatistics by changing its location.",
    "descriptor": "",
    "authors": [
      "Vidhi Rana",
      "Remi A. Chou"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03477"
  },
  {
    "id": "arXiv:2206.03480",
    "title": "SHRED: 3D Shape Region Decomposition with Learned Local Operations",
    "abstract": "We present SHRED, a method for 3D SHape REgion Decomposition. SHRED takes a\n3D point cloud as input and uses learned local operations to produce a\nsegmentation that approximates fine-grained part instances. We endow SHRED with\nthree decomposition operations: splitting regions, fixing the boundaries\nbetween regions, and merging regions together. Modules are trained\nindependently and locally, allowing SHRED to generate high-quality\nsegmentations for categories not seen during training. We train and evaluate\nSHRED with fine-grained segmentations from PartNet; using its merge-threshold\nhyperparameter, we show that SHRED produces segmentations that better respect\nground-truth annotations compared with baseline methods, at any desired\ndecomposition granularity. Finally, we demonstrate that SHRED is useful for\ndownstream applications, out-performing all baselines on zero-shot fine-grained\npart instance segmentation and few-shot fine-grained semantic segmentation when\ncombined with methods that learn to label shape regions.",
    "descriptor": "",
    "authors": [
      "R. Kenny Jones",
      "Aalia Habib",
      "Daniel Ritchie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03480"
  },
  {
    "id": "arXiv:2206.03481",
    "title": "Topos: A Secure, Trustless, and Decentralized Interoperability Protocol",
    "abstract": "Topos is an open interoperability protocol designed to reduce as much as\npossible trust assumptions by replacing them with cryptographic constructions\nand decentralization while exhibiting massive scalability. The protocol does\nnot make use of a central blockchain, nor uses consensus to ensure consistent\ndelivery of messages across a heterogeneous ecosystem of public and private\nblockchains, named subnets, but instead relies on a weak causal reliable\nbroadcast implemented by a distributed network which we call\n$\\textit{Transmission Control Engine}$ (TCE). The validity of cross-subnet\nmessages is ensured by the $\\textit{Universal Certificate Interface}$ (UCI) and\nstems from zkSTARK proofs asserting the validity of subnets' state transitions\nexecuted by the Topos zkVM. Such proofs of computational integrity are publicly\nverifiable by any other participants in and out the protocol such as other\nsubnets or audit companies. The interface between the TCE and subnets leverages\nthe ICE-FROST protocol, an innovative threshold signature scheme, whose static\npublic key allows for uniquely identifying subnets after they register in the\nprotocol. The Topos protocol is designed to provide $\\textit{uniform security}$\nto the ecosystem and to handle any type of subnets (e.g., permissioned,\npermissionless) in order to fit any business use cases and pave the way for\nglobal adoption and a new standard for the Internet base layer.",
    "descriptor": "",
    "authors": [
      "Th\u00e9o Gauthier",
      "S\u00e9bastien Dan",
      "Monir Hadji",
      "Antonella Del Pozzo",
      "Yackolley Amoussou-Guenou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.03481"
  },
  {
    "id": "arXiv:2206.03482",
    "title": "Parametric Chordal Sparsity for SDP-based Neural Network Verification",
    "abstract": "Many future technologies rely on neural networks, but verifying the\ncorrectness of their behavior remains a major challenge. It is known that\nneural networks can be fragile in the presence of even small input\nperturbations, yielding unpredictable outputs. The verification of neural\nnetworks is therefore vital to their adoption, and a number of approaches have\nbeen proposed in recent years. In this paper we focus on semidefinite\nprogramming (SDP) based techniques for neural network verification, which are\nparticularly attractive because they can encode expressive behaviors while\nensuring a polynomial time decision. Our starting point is the DeepSDP\nframework proposed by Fazlyab et al, which uses quadratic constraints to\nabstract the verification problem into a large-scale SDP. When the size of the\nneural network grows, however, solving this SDP quickly becomes intractable.\nOur key observation is that by leveraging chordal sparsity and specific\nparametrizations of DeepSDP, we can decompose the primary computational\nbottleneck of DeepSDP -- a large linear matrix inequality (LMI) -- into an\nequivalent collection of smaller LMIs. Our parametrization admits a tunable\nparameter, allowing us to trade-off efficiency and accuracy in the verification\nprocedure. We call our formulation Chordal-DeepSDP, and provide experimental\nevaluation to show that it can: (1) effectively increase accuracy with the\ntunable parameter and (2) outperform DeepSDP on deeper networks.",
    "descriptor": "",
    "authors": [
      "Anton Xue",
      "Lars Lindemann",
      "Rajeev Alur"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.03482"
  },
  {
    "id": "arXiv:2206.03483",
    "title": "Few-Shot Learning by Dimensionality Reduction in Gradient Space",
    "abstract": "We introduce SubGD, a novel few-shot learning method which is based on the\nrecent finding that stochastic gradient descent updates tend to live in a\nlow-dimensional parameter subspace. In experimental and theoretical analyses,\nwe show that models confined to a suitable predefined subspace generalize well\nfor few-shot learning. A suitable subspace fulfills three criteria across the\ngiven tasks: it (a) allows to reduce the training error by gradient flow, (b)\nleads to models that generalize well, and (c) can be identified by stochastic\ngradient descent. SubGD identifies these subspaces from an eigendecomposition\nof the auto-correlation matrix of update directions across different tasks.\nDemonstrably, we can identify low-dimensional suitable subspaces for few-shot\nlearning of dynamical systems, which have varying properties described by one\nor few parameters of the analytical system description. Such systems are\nubiquitous among real-world applications in science and engineering. We\nexperimentally corroborate the advantages of SubGD on three distinct dynamical\nsystems problem settings, significantly outperforming popular few-shot learning\nmethods both in terms of sample efficiency and performance.",
    "descriptor": "\nComments: Accepted at Conference on Lifelong Learning Agents (CoLLAs) 2022. Code: this https URL Blog post: this https URL\n",
    "authors": [
      "Martin Gauch",
      "Maximilian Beck",
      "Thomas Adler",
      "Dmytro Kotsur",
      "Stefan Fiel",
      "Hamid Eghbal-zadeh",
      "Johannes Brandstetter",
      "Johannes Kofler",
      "Markus Holzleitner",
      "Werner Zellinger",
      "Daniel Klotz",
      "Sepp Hochreiter",
      "Sebastian Lehner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03483"
  },
  {
    "id": "arXiv:2206.03484",
    "title": "Detection Hub: Unifying Object Detection Datasets via Query Adaptation  on Language Embedding",
    "abstract": "Leveraging large-scale data can introduce performance gains on many computer\nvision tasks. Unfortunately, this does not happen in object detection when\ntraining a single model under multiple datasets together. We observe two main\nobstacles: taxonomy difference and bounding box annotation inconsistency, which\nintroduces domain gaps in different datasets that prevents us from joint\ntraining. In this paper, we show that these two challenges can be effectively\naddressed by simply adapting object queries on language embedding of categories\nper dataset. We design a detection hub to dynamically adapt queries on category\nembedding based on the different distributions of datasets. Unlike previous\nmethods attempted to learn a joint embedding for all datasets, our adaptation\nmethod can utilize the language embedding as semantic centers for common\ncategories, while learning the semantic bias towards specific categories\nbelonging to different datasets to handle annotation differences and make up\nthe domain gaps. These novel improvements enable us to end-to-end train a\nsingle detector on multiple datasets simultaneously to fully take their\nadvantages. Further experiments on joint training on multiple datasets\ndemonstrate the significant performance gains over separate individual\nfine-tuned detectors.",
    "descriptor": "",
    "authors": [
      "Lingchen Meng",
      "Xiyang Dai",
      "Yinpeng Chen",
      "Pengchuan Zhang",
      "Dongdong Chen",
      "Mengchen Liu",
      "Jianfeng Wang",
      "Zuxuan Wu",
      "Lu Yuan",
      "Yu-Gang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.03484"
  },
  {
    "id": "arXiv:2204.03417",
    "title": "Detecting Dysfluencies in Stuttering Therapy Using wav2vec 2.0",
    "abstract": "Stuttering is a varied speech disorder that harms an individual's\ncommunication ability. Persons who stutter (PWS) often use speech therapy to\ncope with their condition. Improving speech recognition systems for people with\nsuch non-typical speech or tracking the effectiveness of speech therapy would\nrequire systems that can detect dysfluencies while at the same time being able\nto detect speech techniques acquired in therapy.\nThis paper shows that fine-tuning wav2vec 2.0 for the classification of\nstuttering on a sizeable English corpus containing stuttered speech, in\nconjunction with multi-task learning, boosts the effectiveness of the\ngeneral-purpose wav2vec 2.0 features for detecting stuttering in speech; both\nwithin and across languages. We evaluate our method on Fluencybank and the\nGerman therapy-centric Kassel State of Fluency (KSoF) dataset by training\nSupport Vector Machine classifiers using features extracted from the fine-tuned\nmodels for six different stuttering-related events types: blocks,\nprolongations, sound repetitions, word repetitions, interjections, and -\nspecific to therapy - speech modifications. Using embeddings from the\nfine-tuned models leads to relative classification performance gains up to 27\\%\nw.r.t. F1-score.",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Sebastian P. Bayerl",
      "Dominik Wagner",
      "Elmar N\u00f6th",
      "Korbinian Riedhammer"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2204.03417"
  },
  {
    "id": "arXiv:2204.03428",
    "title": "Detecting Vocal Fatigue with Neural Embeddings",
    "abstract": "Vocal fatigue refers to the feeling of tiredness and weakness of voice due to\nextended utilization. This paper investigates the effectiveness of neural\nembeddings for the detection of vocal fatigue. We compare x-vectors,\nECAPA-TDNN, and wav2vec 2.0 embeddings on a corpus of academic spoken English.\nLow-dimensional mappings of the data reveal that neural embeddings capture\ninformation about the change in vocal characteristics of a speaker during\nprolonged voice usage. We show that vocal fatigue can be reliably predicted\nusing all three kinds of neural embeddings after only 50 minutes of continuous\nspeaking when temporal smoothing and normalization are applied to the extracted\nembeddings. We employ support vector machines for classification and achieve\naccuracy scores of 81% using x-vectors, 85% using ECAPA-TDNN embeddings, and\n82% using wav2vec 2.0 embeddings as input features. We obtain an accuracy score\nof 76%, when the trained system is applied to a different speaker and recording\nenvironment without any adaptation.",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Sebastian P. Bayerl",
      "Dominik Wagner",
      "Ilja Baumann",
      "Korbinian Riedhammer",
      "Tobias Bocklet"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2204.03428"
  },
  {
    "id": "arXiv:2206.02061",
    "title": "Low Power Neuromorphic EMG Gesture Classification",
    "abstract": "EMG (Electromyograph) signal based gesture recognition can prove vital for\napplications such as smart wearables and bio-medical neuro-prosthetic control.\nSpiking Neural Networks (SNNs) are promising for low-power, real-time EMG\ngesture recognition, owing to their inherent spike/event driven spatio-temporal\ndynamics. In literature, there are limited demonstrations of neuromorphic\nhardware implementation (at full chip/board/system scale) for EMG gesture\nclassification. Moreover, most literature attempts exploit primitive SNNs based\non LIF (Leaky Integrate and Fire) neurons. In this work, we address the\naforementioned gaps with following key contributions: (1) Low-power, high\naccuracy demonstration of EMG-signal based gesture recognition using\nneuromorphic Recurrent Spiking Neural Networks (RSNN). In particular, we\npropose a multi-time scale recurrent neuromorphic system based on special\ndouble-exponential adaptive threshold (DEXAT) neurons. Our network achieves\nstate-of-the-art classification accuracy (90%) while using ~53% lesser neurons\nthan best reported prior art on Roshambo EMG dataset. (2) A new multi-channel\nspike encoder scheme for efficient processing of real-valued EMG data on\nneuromorphic systems. (3) Unique multi-compartment methodology to implement\ncomplex adaptive neurons on Intel's dedicated neuromorphic Loihi chip is shown.\n(4) RSNN implementation on Loihi (Nahuku 32) achieves significant\nenergy/latency benefits of ~983X/19X compared to GPU for batch size as 50.",
    "descriptor": "\nComments: 3 Pages, 5 figures, 1 table\n",
    "authors": [
      "Sai Sukruth Bezugam",
      "Ahmed Shaban",
      "Manan Suri"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Hardware Architecture (cs.AR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.02061"
  },
  {
    "id": "arXiv:2206.02788",
    "title": "Accurate Virus Identification with Interpretable Raman Signatures by  Machine Learning",
    "abstract": "Rapid identification of newly emerging or circulating viruses is an important\nfirst step toward managing the public health response to potential outbreaks. A\nportable virus capture device coupled with label-free Raman Spectroscopy holds\nthe promise of fast detection by rapidly obtaining the Raman signature of a\nvirus followed by a machine learning approach applied to recognize the virus\nbased on its Raman spectrum, which is used as a fingerprint. We present such a\nmachine learning approach for analyzing Raman spectra of human and avian\nviruses. A Convolutional Neural Network (CNN) classifier specifically designed\nfor spectral data achieves very high accuracy for a variety of virus type or\nsubtype identification tasks. In particular, it achieves 99% accuracy for\nclassifying influenza virus type A vs. type B, 96% accuracy for classifying\nfour subtypes of influenza A, 95% accuracy for differentiating enveloped and\nnon-enveloped viruses, and 99% accuracy for differentiating avian coronavirus\n(infectious bronchitis virus, IBV) from other avian viruses. Furthermore,\ninterpretation of neural net responses in the trained CNN model using a\nfull-gradient algorithm highlights Raman spectral ranges that are most\nimportant to virus identification. By correlating ML-selected salient Raman\nranges with the signature ranges of known biomolecules and chemical functional\ngroups (for example, amide, amino acid, carboxylic acid), we verify that our ML\nmodel effectively recognizes the Raman signatures of proteins, lipids and other\nvital functional groups present in different viruses and uses a weighted\ncombination of these signatures to identify viruses.",
    "descriptor": "\nComments: 23 pages, 8 figures\n",
    "authors": [
      "Jiarong Ye",
      "Yin-Ting Yeh",
      "Yuan Xue",
      "Ziyang Wang",
      "Na Zhang",
      "He Liu",
      "Kunyan Zhang",
      "RyeAnne Ricker",
      "Zhuohang Yu",
      "Allison Roder",
      "Nestor Perea Lopez",
      "Lindsey Organtini",
      "Wallace Greene",
      "Susan Hafenstein",
      "Huaguang Lu",
      "Elodie Ghedin",
      "Mauricio Terrones",
      "Shengxi Huang",
      "Sharon Xiaolei Huang"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02788"
  },
  {
    "id": "arXiv:2206.02789",
    "title": "Efficient and Accurate Physics-aware Multiplex Graph Neural Networks for  3D Small Molecules and Macromolecule Complexes",
    "abstract": "Recent advances in applying Graph Neural Networks (GNNs) to molecular science\nhave showcased the power of learning three-dimensional (3D) structure\nrepresentations with GNNs. However, most existing GNNs suffer from the\nlimitations of insufficient modeling of diverse interactions, computational\nexpensive operations, and ignorance of vectorial values. Here, we tackle these\nlimitations by proposing a novel GNN model, Physics-aware Multiplex Graph\nNeural Network (PaxNet), to efficiently and accurately learn the\nrepresentations of 3D molecules for both small organic compounds and\nmacromolecule complexes. PaxNet separates the modeling of local and non-local\ninteractions inspired by molecular mechanics, and reduces the expensive\nangle-related computations. Besides scalar properties, PaxNet can also predict\nvectorial properties by learning an associated vector for each atom. To\nevaluate the performance of PaxNet, we compare it with state-of-the-art\nbaselines in two tasks. On small molecule dataset for predicting quantum\nchemical properties, PaxNet reduces the prediction error by 15% and uses 73%\nless memory than the best baseline. On macromolecule dataset for predicting\nprotein-ligand binding affinities, PaxNet outperforms the best baseline while\nreducing the memory consumption by 33% and the inference time by 85%. Thus,\nPaxNet provides a universal, robust and accurate method for large-scale machine\nlearning of molecules.",
    "descriptor": "\nComments: Preprint version\n",
    "authors": [
      "Shuo Zhang",
      "Yang Liu",
      "Lei Xie"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02789"
  },
  {
    "id": "arXiv:2206.02795",
    "title": "Forecasting COVID- 19 cases using Statistical Models and Ontology-based  Semantic Modelling: A real time data analytics approach",
    "abstract": "SARS-COV-19 is the most prominent issue which many countries face today. The\nfrequent changes in infections, recovered and deaths represents the dynamic\nnature of this pandemic. It is very crucial to predict the spreading rate of\nthis virus for accurate decision making against fighting with the situation of\ngetting infected through the virus, tracking and controlling the virus\ntransmission in the community. We develop a prediction model using statistical\ntime series models such as SARIMA and FBProphet to monitor the daily active,\nrecovered and death cases of COVID-19 accurately. Then with the help of various\ndetails across each individual patient (like height, weight, gender etc.), we\ndesigned a set of rules using Semantic Web Rule Language and some mathematical\nmodels for dealing with COVID19 infected cases on an individual basis. After\ncombining all the models, a COVID-19 Ontology is developed and performs various\nqueries using SPARQL query on designed Ontology which accumulate the risk\nfactors, provide appropriate diagnosis, precautions and preventive suggestions\nfor COVID Patients. After comparing the performance of SARIMA and FBProphet, it\nis observed that the SARIMA model performs better in forecasting of COVID\ncases. On individual basis COVID case prediction, approx. 497 individual\nsamples have been tested and classified into five different levels of COVID\nclasses such as Having COVID, No COVID, High Risk COVID case, Medium to High\nRisk case, and Control needed case.",
    "descriptor": "",
    "authors": [
      "Sadhana Tiwari",
      "Ritesh Chandra",
      "Sonali Agarwal"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02795"
  },
  {
    "id": "arXiv:2206.02797",
    "title": "FedNST: Federated Noisy Student Training for Automatic Speech  Recognition",
    "abstract": "Federated Learning (FL) enables training state-of-the-art Automatic Speech\nRecognition (ASR) models on user devices (clients) in distributed systems,\nhence preventing transmission of raw user data to a central server. A key\nchallenge facing practical adoption of FL for ASR is obtaining ground-truth\nlabels on the clients. Existing approaches rely on clients to manually\ntranscribe their speech, which is impractical for obtaining large training\ncorpora. A promising alternative is using semi-/self-supervised learning\napproaches to leverage unlabelled user data. To this end, we propose a new\nFederated ASR method called FedNST for noisy student training of distributed\nASR models with private unlabelled user data. We explore various facets of\nFedNST , such as training models with different proportions of unlabelled and\nlabelled data, and evaluate the proposed approach on 1173 simulated clients.\nEvaluating FedNST on LibriSpeech, where 960 hours of speech data is split\nequally into server (labelled) and client (unlabelled) data, showed a 22.5%\nrelative word error rate reduction (WERR) over a supervised baseline trained\nonly on server data.",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Haaris Mehmood",
      "Agnieszka Dobrowolska",
      "Karthikeyan Saravanan",
      "Mete Ozay"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02797"
  },
  {
    "id": "arXiv:2206.02806",
    "title": "Quantum Neural Network Classifiers: A Tutorial",
    "abstract": "Machine learning has achieved dramatic success over the past decade, with\napplications ranging from face recognition to natural language processing.\nMeanwhile, rapid progress has been made in the field of quantum computation\nincluding developing both powerful quantum algorithms and advanced quantum\ndevices. The interplay between machine learning and quantum physics holds the\nintriguing potential for bringing practical applications to the modern society.\nHere, we focus on quantum neural networks in the form of parameterized quantum\ncircuits. We will mainly discuss different structures and encoding strategies\nof quantum neural networks for supervised learning tasks, and benchmark their\nperformance utilizing Yao.jl, a quantum simulation package written in Julia\nLanguage. The codes are efficient, aiming to provide convenience for beginners\nin scientific works such as developing powerful variational quantum learning\nmodels and assisting the corresponding experimental demonstrations.",
    "descriptor": "\nComments: 25 pages, 4 figures, 5 tables\n",
    "authors": [
      "Weikang Li",
      "Zhide Lu",
      "Dong-Ling Deng"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02806"
  },
  {
    "id": "arXiv:2206.02819",
    "title": "Deep Learning Models of the Discrete Component of the Galactic  Interstellar Gamma-Ray Emission",
    "abstract": "A significant point-like component from the small scale (or discrete)\nstructure in the H2 interstellar gas might be present in the Fermi-LAT data,\nbut modeling this emission relies on observations of rare gas tracers only\navailable in limited regions of the sky. Identifying this contribution is\nimportant to discriminate gamma-ray point sources from interstellar gas, and to\nbetter characterize extended gamma-ray sources. We design and train\nconvolutional neural networks to predict this emission where observations of\nthese rare tracers do not exist and discuss the impact of this component on the\nanalysis of the Fermi-LAT data. In particular, we evaluate prospects to exploit\nthis methodology in the characterization of the Fermi-LAT Galactic center\nexcess through accurate modeling of point-like structures in the data to help\ndistinguish between a point-like or smooth nature for the excess. We show that\ndeep learning may be effectively employed to model the gamma-ray emission\ntraced by these rare H2 proxies within statistical significance in data-rich\nregions, supporting prospects to employ these methods in yet unobserved\nregions.",
    "descriptor": "\nComments: Submitted. Companion paper to \"Improved modeling of the discrete component of the galactic interstellar gamma-ray emission and implications for the Fermi--LAT galactic center excess\"\n",
    "authors": [
      "Alexander Shmakov",
      "Mohammadamin Tavakoli",
      "Pierre Baldi",
      "Christopher M. Karwin",
      "Alex Broughton",
      "Simona Murgia"
    ],
    "subjectives": [
      "High Energy Astrophysical Phenomena (astro-ph.HE)",
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Phenomenology (hep-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.02819"
  },
  {
    "id": "arXiv:2206.02837",
    "title": "EVC-Net: Multi-scale V-Net with Conditional Random Fields for Brain  Extraction",
    "abstract": "Brain extraction is one of the first steps of pre-processing 3D brain MRI\ndata. It is a prerequisite for any forthcoming brain imaging analyses. However,\nit is not a simple segmentation problem due to the complex structure of the\nbrain and human head. Although multiple solutions have been proposed in the\nliterature, we are still far from having truly robust methods. While previous\nmethods have used machine learning with structural/geometric priors, with the\ndevelopment of deep learning in computer vision tasks, there has been an\nincrease in proposed convolutional neural network architectures for this\nsemantic segmentation task. Yet, most models focus on improving the training\ndata and loss functions with little change in the architecture. In this paper,\nwe propose a novel architecture we call EVC-Net. EVC-Net adds lower scale\ninputs on each encoder block. This enhances the multi-scale scheme of the V-Net\narchitecture, hence increasing the efficiency of the model. Conditional Random\nFields, a popular approach for image segmentation before the deep learning era,\nare re-introduced here as an additional step for refining the network's output\nto capture fine-grained results in segmentation. We compare our model to\nstate-of-the-art methods such as HD-BET, Synthstrip and brainy. Results show\nthat even with limited training resources, EVC-Net achieves higher Dice\nCoefficient and Jaccard Index along with lower surface distance.",
    "descriptor": "",
    "authors": [
      "Jong Sung Park",
      "Shreyas Fadnavis",
      "Eleftherios Garyfallidis"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02837"
  },
  {
    "id": "arXiv:2206.02838",
    "title": "Invertible Sharpening Network for MRI Reconstruction Enhancement",
    "abstract": "High-quality MRI reconstruction plays a critical role in clinical\napplications. Deep learning-based methods have achieved promising results on\nMRI reconstruction. However, most state-of-the-art methods were designed to\noptimize the evaluation metrics commonly used for natural images, such as PSNR\nand SSIM, whereas the visual quality is not primarily pursued. Compared to the\nfully-sampled images, the reconstructed images are often blurry, where\nhigh-frequency features might not be sharp enough for confident clinical\ndiagnosis. To this end, we propose an invertible sharpening network\n(InvSharpNet) to improve the visual quality of MRI reconstructions. During\ntraining, unlike the traditional methods that learn to map the input data to\nthe ground truth, InvSharpNet adapts a backward training strategy that learns a\nblurring transform from the ground truth (fully-sampled image) to the input\ndata (blurry reconstruction). During inference, the learned blurring transform\ncan be inverted to a sharpening transform leveraging the network's\ninvertibility. The experiments on various MRI datasets demonstrate that\nInvSharpNet can improve reconstruction sharpness with few artifacts. The\nresults were also evaluated by radiologists, indicating better visual quality\nand diagnostic confidence of our proposed method.",
    "descriptor": "\nComments: Accepted by MICCAI 2022\n",
    "authors": [
      "Siyuan Dong",
      "Eric Z. Chen",
      "Lin Zhao",
      "Xiao Chen",
      "Yikang Liu",
      "Terrence Chen",
      "Shanhui Sun"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02838"
  },
  {
    "id": "arXiv:2206.02869",
    "title": "$u$-generation: solving systems of polynomials equation-by-equation",
    "abstract": "We develop a new method that improves the efficiency of equation-by-equation\nalgorithms for solving polynomial systems. Our method is based on a novel\ngeometric construction, and reduces the total number of homotopy paths that\nmust be numerically continued. These improvements may be applied to the basic\nalgorithms of numerical algebraic geometry in the settings of both projective\nand multiprojective varieties. Our computational experiments demonstrate\nsignificant savings obtained on several benchmark systems. We also present an\nextended case study on maximum likelihood estimation for rank-constrained\nsymmetric $n\\times n$ matrices, in which multiprojective $u$-generation allows\nus to complete the list of ML degrees for $n\\le 6.$",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Timothy Duff",
      "Anton Leykin",
      "Jose Israel Rodriguez"
    ],
    "subjectives": [
      "Algebraic Geometry (math.AG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.02869"
  },
  {
    "id": "arXiv:2206.02889",
    "title": "Conditional Seq2Seq model for the time-dependent two-level system",
    "abstract": "We apply the deep learning neural network architecture to the two-level\nsystem in quantum optics to solve the time-dependent Schrodinger equation. By\ncarefully designing the network structure and tuning parameters, above 90\npercent accuracy in super long-term predictions can be achieved in the case of\nrandom electric fields, which indicates a promising new method to solve the\ntime-dependent equation for two-level systems. By slightly modifying this\nnetwork, we think that this method can solve the two- or three-dimensional\ntime-dependent Schrodinger equation more efficiently than traditional\napproaches.",
    "descriptor": "\nComments: 17 pages, 6 figures\n",
    "authors": [
      "Bin Yang",
      "Mengxi Wu",
      "Winfried Teizer"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2206.02889"
  },
  {
    "id": "arXiv:2206.02909",
    "title": "Self-supervised Learning for Human Activity Recognition Using 700,000  Person-days of Wearable Data",
    "abstract": "Advances in deep learning for human activity recognition have been relatively\nlimited due to the lack of large labelled datasets. In this study, we leverage\nself-supervised learning techniques on the UK-Biobank activity tracker\ndataset--the largest of its kind to date--containing more than 700,000\nperson-days of unlabelled wearable sensor data. Our resulting activity\nrecognition model consistently outperformed strong baselines across seven\nbenchmark datasets, with an F1 relative improvement of 2.5%-100% (median\n18.4%), the largest improvements occurring in the smaller datasets. In contrast\nto previous studies, our results generalise across external datasets, devices,\nand environments. Our open-source model will help researchers and developers to\nbuild customisable and generalisable activity classifiers with high\nperformance.",
    "descriptor": "",
    "authors": [
      "Hang Yuan",
      "Shing Chan",
      "Andrew P. Creagh",
      "Catherine Tong",
      "David A. Clifton",
      "Aiden Doherty"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02909"
  },
  {
    "id": "arXiv:2206.02910",
    "title": "Regional Constellation Reconfiguration Problem: Integer Linear  Programming Formulation and Lagrangian Heuristic Method",
    "abstract": "A group of satellites -- with either homogeneous or heterogeneous orbital\ncharacteristics and/or hardware specifications -- can undertake a\nreconfiguration process due to variations in operations pertaining to regional\ncoverage missions. This paper investigates the problem of optimizing a\nsatellite constellation reconfiguration process against two competing mission\nobjectives: (i) the maximization of the total coverage reward and (ii) the\nminimization of the total cost of the transfer. The decision variables for the\nreconfiguration process include the design of the new configuration and the\nassignment of satellites from one configuration to another. We present a novel\nbi-objective integer linear programming formulation that combines constellation\ndesign and transfer problems. The formulation lends itself to the use of\ngeneric mixed-integer linear programming (MILP) methods such as the\nbranch-and-bound algorithm for the computation of provably-optimal solutions;\nhowever, these approaches become computationally prohibitive even for\nmoderately-sized instances. In response to this challenge, this paper proposes\na Lagrangian relaxation-based heuristic method that leverages the assignment\nproblem structure embedded in the problem. The results from the computational\nexperiments attest to the near-optimality of the Lagrangian heuristic solutions\nand significant improvement in the computational runtime compared to a\ncommercial MILP solver.",
    "descriptor": "\nComments: 36 pages, 8 figures, submitted to the Journal of Guidance, Control, and Dynamics\n",
    "authors": [
      "Hang Woon Lee",
      "Koki Ho"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.02910"
  },
  {
    "id": "arXiv:2206.02914",
    "title": "Training Subset Selection for Weak Supervision",
    "abstract": "Existing weak supervision approaches use all the data covered by weak signals\nto train a classifier. We show both theoretically and empirically that this is\nnot always optimal. Intuitively, there is a tradeoff between the amount of\nweakly-labeled data and the precision of the weak labels. We explore this\ntradeoff by combining pretrained data representations with the cut statistic\n(Muhlenbach et al., 2004) to select (hopefully) high-quality subsets of the\nweakly-labeled training data. Subset selection applies to any label model and\nclassifier and is very simple to plug in to existing weak supervision\npipelines, requiring just a few lines of code. We show our subset selection\nmethod improves the performance of weak supervision for a wide range of label\nmodels, classifiers, and datasets. Using less weakly-labeled data improves the\naccuracy of weak supervision pipelines by up to 19% (absolute) on benchmark\ntasks.",
    "descriptor": "",
    "authors": [
      "Hunter Lang",
      "Aravindan Vijayaraghavan",
      "David Sontag"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02914"
  },
  {
    "id": "arXiv:2206.02927",
    "title": "Spectral Bias Outside the Training Set for Deep Networks in the Kernel  Regime",
    "abstract": "We provide quantitative bounds measuring the $L^2$ difference in function\nspace between the trajectory of a finite-width network trained on finitely many\nsamples from the idealized kernel dynamics of infinite width and infinite data.\nAn implication of the bounds is that the network is biased to learn the top\neigenfunctions of the Neural Tangent Kernel not just on the training set but\nover the entire input space. This bias depends on the model architecture and\ninput distribution alone and thus does not depend on the target function which\ndoes not need to be in the RKHS of the kernel. The result is valid for deep\narchitectures with fully connected, convolutional, and residual layers.\nFurthermore the width does not need to grow polynomially with the number of\nsamples in order to obtain high probability bounds up to a stopping time. The\nproof exploits the low-effective-rank property of the Fisher Information Matrix\nat initialization, which implies a low effective dimension of the model (far\nsmaller than the number of parameters). We conclude that local capacity control\nfrom the low effective rank of the Fisher Information Matrix is still\nunderexplored theoretically.",
    "descriptor": "\nComments: 38 pages, 1 figure\n",
    "authors": [
      "Benjamin Bowman",
      "Guido Montufar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02927"
  },
  {
    "id": "arXiv:2206.02953",
    "title": "Sampling without Replacement Leads to Faster Rates in Finite-Sum Minimax  Optimization",
    "abstract": "We analyze the convergence rates of stochastic gradient algorithms for smooth\nfinite-sum minimax optimization and show that, for many such algorithms,\nsampling the data points without replacement leads to faster convergence\ncompared to sampling with replacement. For the smooth and strongly\nconvex-strongly concave setting, we consider gradient descent ascent and the\nproximal point method, and present a unified analysis of two popular\nwithout-replacement sampling strategies, namely Random Reshuffling (RR), which\nshuffles the data every epoch, and Single Shuffling or Shuffle Once (SO), which\nshuffles only at the beginning. We obtain tight convergence rates for RR and SO\nand demonstrate that these strategies lead to faster convergence than uniform\nsampling. Moving beyond convexity, we obtain similar results for smooth\nnonconvex-nonconcave objectives satisfying a two-sided Polyak-{\\L}ojasiewicz\ninequality. Finally, we demonstrate that our techniques are general enough to\nanalyze the effect of data-ordering attacks, where an adversary manipulates the\norder in which data points are supplied to the optimizer. Our analysis also\nrecovers tight rates for the incremental gradient method, where the data points\nare not shuffled at all.",
    "descriptor": "\nComments: 48 pages, 3 figures\n",
    "authors": [
      "Aniket Das",
      "Bernhard Sch\u00f6lkopf",
      "Michael Muehlebach"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.02953"
  },
  {
    "id": "arXiv:2206.02959",
    "title": "HMRNet: High and Multi-Resolution Network with Bidirectional Feature  Calibration for Brain Structure Segmentation in Radiotherapy",
    "abstract": "Accurate segmentation of Anatomical brain Barriers to Cancer spread (ABCs)\nplays an important role for automatic delineation of Clinical Target Volume\n(CTV) of brain tumors in radiotherapy. Despite that variants of U-Net are\nstate-of-the-art segmentation models, they have limited performance when\ndealing with ABCs structures with various shapes and sizes, especially thin\nstructures (e.g., the falx cerebri) that span only few slices. To deal with\nthis problem, we propose a High and Multi-Resolution Network (HMRNet) that\nconsists of a multi-scale feature learning branch and a high-resolution branch,\nwhich can maintain the high-resolution contextual information and extract more\nrobust representations of anatomical structures with various scales. We further\ndesign a Bidirectional Feature Calibration (BFC) block to enable the two\nbranches to generate spatial attention maps for mutual feature calibration.\nConsidering the different sizes and positions of ABCs structures, our network\nwas applied after a rough localization of each structure to obtain fine\nsegmentation results. Experiments on the MICCAI 2020 ABCs challenge dataset\nshowed that: 1) Our proposed two-stage segmentation strategy largely\noutperformed methods segmenting all the structures in just one stage; 2) The\nproposed HMRNet with two branches can maintain high-resolution representations\nand is effective to improve the performance on thin structures; 3) The proposed\nBFC block outperformed existing attention methods using monodirectional feature\ncalibration. Our method won the second place of ABCs 2020 challenge and has a\npotential for more accurate and reasonable delineation of CTV of brain tumors.",
    "descriptor": "\nComments: 11 pages, 6 figures, Accepted by IEEE JBHI\n",
    "authors": [
      "Hao Fu",
      "Guotai Wang",
      "Wenhui Lei",
      "Wei Xu",
      "Qianfei Zhao",
      "Shichuan Zhang",
      "Kang Li",
      "Shaoting Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02959"
  },
  {
    "id": "arXiv:2206.02962",
    "title": "Confounder Analysis in Measuring Representation in Product Funnels",
    "abstract": "This paper discusses an application of Shapley values in the causal inference\nfield, specifically on how to select the top confounder variables for coarsened\nexact matching method in a scalable way. We use a dataset from an observational\nexperiment involving LinkedIn members as a use case to test its applicability,\nand show that Shapley values are highly informational and can be leveraged for\nits robust importance-ranking capability.",
    "descriptor": "\nComments: 9 pages, 1 figure\n",
    "authors": [
      "Jilei Yang",
      "Wentao Su"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02962"
  },
  {
    "id": "arXiv:2206.02969",
    "title": "A Simple and Optimal Policy Design for Online Learning with Safety  against Heavy-tailed Risk",
    "abstract": "We design simple and optimal policies that ensure safety against heavy-tailed\nrisk in the classical multi-armed bandit problem. We start by showing that some\nwidely used policies such as the standard Upper Confidence Bound policy and the\nThompson Sampling policy incur heavy-tailed risk; that is, the worst-case\nprobability of incurring a linear regret slowly decays at a polynomial rate of\n$1/T$, where $T$ is the time horizon. We further show that this heavy-tailed\nrisk exists for all \"instance-dependent consistent\" policies. To ensure safety\nagainst such heavy-tailed risk, for the two-armed bandit setting, we provide a\nsimple policy design that (i) has the worst-case optimality for the expected\nregret at order $\\tilde O(\\sqrt{T})$ and (ii) has the worst-case tail\nprobability of incurring a linear regret decay at an exponential rate\n$\\exp(-\\Omega(\\sqrt{T}))$. We further prove that this exponential decaying rate\nof the tail probability is optimal across all policies that have worst-case\noptimality for the expected regret. Finally, we improve the policy design and\nanalysis to the general $K$-armed bandit setting. We provide detailed\ncharacterization of the tail probability bound for any regret threshold under\nour policy design. Namely, the worst-case probability of incurring a regret\nlarger than $x$ is upper bounded by $\\exp(-\\Omega(x/\\sqrt{KT}))$. Numerical\nexperiments are conducted to illustrate the theoretical findings. Our results\nreveal insights on the incompatibility between consistency and light-tailed\nrisk, whereas indicate that worst-case optimality on expected regret and\nlight-tailed risk are compatible.",
    "descriptor": "",
    "authors": [
      "David Simchi-Levi",
      "Zeyu Zheng",
      "Feng Zhu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2206.02969"
  },
  {
    "id": "arXiv:2206.02970",
    "title": "Total Controllability Analysis Discovers Explainable Drugs for Covid-19  Therapy and Prevention",
    "abstract": "Network medicine has been pursued for Covid-19 drug repurposing. One such\napproach adopts structural controllability, a theory for controlling a network\n(the cell). Motivated to protect the cell from viral infections, we extended\nthis theory to total controllability and introduced a new concept of control\nhubs. Perturbation to any control hub renders the cell uncontrollable by\nexogenous stimuli, e.g., viral infections, so control hubs are ideal drug\ntargets. We developed an efficient algorithm for finding all control hubs and\napplied it to the largest homogenous human protein-protein interaction network.\nOur new method outperforms several popular gene-selection methods, including\nthat based on structural controllability. The final 65 druggable control hubs\nare enriched with functions of cell proliferation, regulation of apoptosis, and\nresponses to cellular stress and nutrient levels, revealing critical pathways\ninduced by SARS-CoV-2. These druggable control hubs led to drugs in 4 major\ncategories: antiviral and anti-inflammatory agents, drugs on central nerve\nsystems, and dietary supplements and hormones that boost immunity. Their\nfunctions also provided deep insights into the therapeutic mechanisms of the\ndrugs for Covid-19 therapy, making the new approach an explainable drug\nrepurposing method. A remarkable example is Fostamatinib that has been shown to\nlower mortality, shorten the length of ICU stay, and reduce disease severity of\nhospitalized Covid-19 patients. The drug targets 10 control hubs, 9 of which\nare kinases that play key roles in cell differentiation and programmed death.\nOne such kinase is RIPK1 that directly interacts with viral protein nsp12, the\nRdRp of the virus. The study produced many control hubs that were not targets\nof existing drugs but were enriched with proteins on membranes and the\nNF-$\\kappa$B pathway, so are excellent candidate targets for new drugs.",
    "descriptor": "\nComments: Contact the corresponding authors for Supplemental Tables\n",
    "authors": [
      "Xinru Wei",
      "Chunyu Pan",
      "Xizhe Zhang",
      "Weixiong Zhang"
    ],
    "subjectives": [
      "Molecular Networks (q-bio.MN)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.02970"
  },
  {
    "id": "arXiv:2206.02972",
    "title": "Decomposed Linear Dynamical Systems (dLDS) for learning the latent  components of neural dynamics",
    "abstract": "Learning interpretable representations of neural dynamics at a population\nlevel is a crucial first step to understanding how neural activity relates to\nperception and behavior. Models of neural dynamics often focus on either\nlow-dimensional projections of neural activity, or on learning dynamical\nsystems that explicitly relate to the neural state over time. We discuss how\nthese two approaches are interrelated by considering dynamical systems as\nrepresentative of flows on a low-dimensional manifold. Building on this\nconcept, we propose a new decomposed dynamical system model that represents\ncomplex non-stationary and nonlinear dynamics of time-series data as a sparse\ncombination of simpler, more interpretable components. The decomposed nature of\nthe dynamics generalizes over previous switched approaches and enables modeling\nof overlapping and non-stationary drifts in the dynamics. We further present a\ndictionary learning-driven approach to model fitting, where we leverage recent\nresults in tracking sparse vectors over time. We demonstrate that our model can\nlearn efficient representations and smooth transitions between dynamical modes\nin both continuous-time and discrete-time examples. We show results on\nlow-dimensional linear and nonlinear attractors to demonstrate that our\ndecomposed dynamical systems model can well approximate nonlinear dynamics.\nAdditionally, we apply our model to C. elegans data, illustrating a diversity\nof dynamics that is obscured when classified into discrete states.",
    "descriptor": "\nComments: 25 pages, 15 figures\n",
    "authors": [
      "Noga Mudrik",
      "Yenho Chen",
      "Eva Yezerets",
      "Christopher J. Rozell",
      "Adam S. Charles"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Neurons and Cognition (q-bio.NC)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2206.02972"
  },
  {
    "id": "arXiv:2206.03002",
    "title": "Stationary states in two lane traffic: insights from kinetic theory",
    "abstract": "Kinetics of dilute heterogeneous traffic on a two lane road is formulated in\nthe framework of the Ben-Naim Krapivsky model and stationary state properties\nare analytically derived in the asymptotic limit. The heterogeneity is\nintroduced as a quenched disorder in desired speeds of vehicles. The model\nassumes that each vehicle/platoon in a lane moves ballistically until it\napproaches a slow moving vehicle/platoon and then joins it. Vehicles in a\nplatoon are assumed to escape the platoon at a constant rate by changing lanes.\nEach lane is assumed to have a different escape rate. As the stationary state\nis approached, the platoon density in the two lanes become equal, whereas the\nvehicle densities and fluxes are higher in the lane with lower escape rate. A\nmajority of the vehicles enjoy a free-flow if the harmonic mean of the escape\nrates of the lanes is comparable to average initial flux on the road. The\naverage platoon size is close to unity in the free-flow regime. If the harmonic\nmean is lower than the average initial flux, then vehicles with desired speeds\nlower than a characteristic speed $v^*$ still enjoy free-flow while those\nvehicles with desired speeds that are greater than $v^*$ experience congestion\nand form platoons behind the slower vehicles. The characteristic speed depends\non the mean of escape times $(R=(R_1+R_{-1})/2)$ of the two lanes (represented\nby 1 and -1) as $v^* \\sim R^{-\\frac{1}{\\mu+2}}$, where $\\mu$ is the exponent of\nthe quenched disorder distribution for desired speed in the small speed limit.\nThe average platoon size in a lane, when $v^* \\ll 1$, is proportional to\n$R^{\\frac{\\mu+1}{\\mu+2}}$ plus a lane dependent correction. Equations for the\nkinetics of platoon size distribution for two-lane traffic are also studied. It\nis shown that a stationary state with platoons as large as road length can\noccur only if the mean escape rate is independent of platoon size.",
    "descriptor": "",
    "authors": [
      "A. Sai Venkata Ramana",
      "Saif Eddin Jabari"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.03002"
  },
  {
    "id": "arXiv:2206.03003",
    "title": "Transformer-based Personalized Attention Mechanism (PersAM) for Medical  Images with Clinical Records",
    "abstract": "In medical image diagnosis, identifying the attention region, i.e., the\nregion of interest for which the diagnosis is made, is an important task.\nVarious methods have been developed to automatically identify target regions\nfrom given medical images. However, in actual medical practice, the diagnosis\nis made based not only on the images but also on a variety of clinical records.\nThis means that pathologists examine medical images with some prior knowledge\nof the patients and that the attention regions may change depending on the\nclinical records. In this study, we propose a method called the Personalized\nAttention Mechanism (PersAM), by which the attention regions in medical images\nare adaptively changed according to the clinical records. The primary idea of\nthe PersAM method is to encode the relationships between the medical images and\nclinical records using a variant of Transformer architecture. To demonstrate\nthe effectiveness of the PersAM method, we applied it to a large-scale digital\npathology problem of identifying the subtypes of 842 malignant lymphoma\npatients based on their gigapixel whole slide images and clinical records.",
    "descriptor": "",
    "authors": [
      "Yusuke Takagi",
      "Noriaki Hashimoto",
      "Hiroki Masuda",
      "Hiroaki Miyoshi",
      "Koichi Ohshima",
      "Hidekata Hontani",
      "Ichiro Takeuchi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.03003"
  },
  {
    "id": "arXiv:2206.03007",
    "title": "On Binomial coefficients of real arguments",
    "abstract": "As is well-known, a generalization of the classical concept of the factorial\n$n!$ for a real number $x\\in {\\mathbb R}$ is the value of Euler's gamma\nfunction $\\Gamma(1+x)$. In this connection, the notion of a binomial\ncoefficient naturally arose for admissible values of the real arguments.\nBy elementary means, it is proved a number of properties of binomial\ncoefficients $\\binom{r}{\\alpha}$ of real arguments $r,\\,\\alpha\\in {\\mathbb R}$\nsuch as analogs of unimodality, symmetry, Pascal's triangle, etc. for classical\nbinomial coefficients. The asymptotic behavior of such generalized binomial\ncoefficients of a special form is established.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Tatiana I. Fedoryaeva"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Classical Analysis and ODEs (math.CA)"
    ],
    "url": "https://arxiv.org/abs/2206.03007"
  },
  {
    "id": "arXiv:2206.03009",
    "title": "Self-Knowledge Distillation based Self-Supervised Learning for Covid-19  Detection from Chest X-Ray Images",
    "abstract": "The global outbreak of the Coronavirus 2019 (COVID-19) has overloaded\nworldwide healthcare systems. Computer-aided diagnosis for COVID-19 fast\ndetection and patient triage is becoming critical. This paper proposes a novel\nself-knowledge distillation based self-supervised learning method for COVID-19\ndetection from chest X-ray images. Our method can use self-knowledge of images\nbased on similarities of their visual features for self-supervised learning.\nExperimental results show that our method achieved an HM score of 0.988, an AUC\nof 0.999, and an accuracy of 0.957 on the largest open COVID-19 chest X-ray\ndataset.",
    "descriptor": "\nComments: Published as a conference paper at ICASSP 2022\n",
    "authors": [
      "Guang Li",
      "Ren Togo",
      "Takahiro Ogawa",
      "Miki Haseyama"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03009"
  },
  {
    "id": "arXiv:2206.03040",
    "title": "Learning Backward Compatible Embeddings",
    "abstract": "Embeddings, low-dimensional vector representation of objects, are fundamental\nin building modern machine learning systems. In industrial settings, there is\nusually an embedding team that trains an embedding model to solve intended\ntasks (e.g., product recommendation). The produced embeddings are then widely\nconsumed by consumer teams to solve their unintended tasks (e.g., fraud\ndetection). However, as the embedding model gets updated and retrained to\nimprove performance on the intended task, the newly-generated embeddings are no\nlonger compatible with the existing consumer models. This means that historical\nversions of the embeddings can never be retired or all consumer teams have to\nretrain their models to make them compatible with the latest version of the\nembeddings, both of which are extremely costly in practice. Here we study the\nproblem of embedding version updates and their backward compatibility. We\nformalize the problem where the goal is for the embedding team to keep updating\nthe embedding version, while the consumer teams do not have to retrain their\nmodels. We develop a solution based on learning backward compatible embeddings,\nwhich allows the embedding model version to be updated frequently, while also\nallowing the latest version of the embedding to be quickly transformed into any\nbackward compatible historical version of it, so that consumer teams do not\nhave to retrain their models. Under our framework, we explore six methods and\nsystematically evaluate them on a real-world recommender system application. We\nshow that the best method, which we call BC-Aligner, maintains backward\ncompatibility with existing unintended tasks even after multiple model version\nupdates. Simultaneously, BC-Aligner achieves the intended task performance\nsimilar to the embedding model that is solely optimized for the intended task.",
    "descriptor": "\nComments: KDD 2022, Applied Data Science Track\n",
    "authors": [
      "Weihua Hu",
      "Rajas Bansal",
      "Kaidi Cao",
      "Nikhil Rao",
      "Karthik Subbian",
      "Jure Leskovec"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03040"
  },
  {
    "id": "arXiv:2206.03043",
    "title": "COVIDx CT-3: A Large-scale, Multinational, Open-Source Benchmark Dataset  for Computer-aided COVID-19 Screening from Chest CT Images",
    "abstract": "Computed tomography (CT) has been widely explored as a COVID-19 screening and\nassessment tool to complement RT-PCR testing. To assist radiologists with\nCT-based COVID-19 screening, a number of computer-aided systems have been\nproposed; however, many proposed systems are built using CT data which is\nlimited in both quantity and diversity. Motivated to support efforts in the\ndevelopment of machine learning-driven screening systems, we introduce COVIDx\nCT-3, a large-scale multinational benchmark dataset for detection of COVID-19\ncases from chest CT images. COVIDx CT-3 includes 431,205 CT slices from 6,068\npatients across at least 17 countries, which to the best of our knowledge\nrepresents the largest, most diverse dataset of COVID-19 CT images in\nopen-access form. Additionally, we examine the data diversity and potential\nbiases of the COVIDx CT-3 dataset, finding that significant geographic and\nclass imbalances remain despite efforts to curate data from a wide variety of\nsources.",
    "descriptor": "\nComments: 3 pages\n",
    "authors": [
      "Tia Tuinstra",
      "Hayden Gunraj",
      "Alexander Wong"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.03043"
  },
  {
    "id": "arXiv:2206.03049",
    "title": "Siamese Encoder-based Spatial-Temporal Mixer for Growth Trend Prediction  of Lung Nodules on CT Scans",
    "abstract": "In the management of lung nodules, we are desirable to predict nodule\nevolution in terms of its diameter variation on Computed Tomography (CT) scans\nand then provide a follow-up recommendation according to the predicted result\nof the growing trend of the nodule. In order to improve the performance of\ngrowth trend prediction for lung nodules, it is vital to compare the changes of\nthe same nodule in consecutive CT scans. Motivated by this, we screened out\n4,666 subjects with more than two consecutive CT scans from the National Lung\nScreening Trial (NLST) dataset to organize a temporal dataset called NLSTt. In\nspecific, we first detect and pair regions of interest (ROIs) covering the same\nnodule based on registered CT scans. After that, we predict the texture\ncategory and diameter size of the nodules through models. Last, we annotate the\nevolution class of each nodule according to its changes in diameter. Based on\nthe built NLSTt dataset, we propose a siamese encoder to simultaneously exploit\nthe discriminative features of 3D ROIs detected from consecutive CT scans. Then\nwe novelly design a spatial-temporal mixer (STM) to leverage the interval\nchanges of the same nodule in sequential 3D ROIs and capture spatial\ndependencies of nodule regions and the current 3D ROI. According to the\nclinical diagnosis routine, we employ hierarchical loss to pay more attention\nto growing nodules. The extensive experiments on our organized dataset\ndemonstrate the advantage of our proposed method. We also conduct experiments\non an in-house dataset to evaluate the clinical utility of our method by\ncomparing it against skilled clinicians.",
    "descriptor": "\nComments: MICCAI 2022\n",
    "authors": [
      "Jiansheng Fang",
      "Jingwen Wang",
      "Anwei Li",
      "Yuguang Yan",
      "Yonghe Hou",
      "Chao Song",
      "Hongbo Liu",
      "Jiang Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.03049"
  },
  {
    "id": "arXiv:2206.03066",
    "title": "Recent Advances for Quantum Neural Networks in Generative Learning",
    "abstract": "Quantum computers are next-generation devices that hold promise to perform\ncalculations beyond the reach of classical computers. A leading method towards\nachieving this goal is through quantum machine learning, especially quantum\ngenerative learning. Due to the intrinsic probabilistic nature of quantum\nmechanics, it is reasonable to postulate that quantum generative learning\nmodels (QGLMs) may surpass their classical counterparts. As such, QGLMs are\nreceiving growing attention from the quantum physics and computer science\ncommunities, where various QGLMs that can be efficiently implemented on\nnear-term quantum machines with potential computational advantages are\nproposed. In this paper, we review the current progress of QGLMs from the\nperspective of machine learning. Particularly, we interpret these QGLMs,\ncovering quantum circuit born machines, quantum generative adversarial\nnetworks, quantum Boltzmann machines, and quantum autoencoders, as the quantum\nextension of classical generative learning models. In this context, we explore\ntheir intrinsic relation and their fundamental differences. We further\nsummarize the potential applications of QGLMs in both conventional machine\nlearning tasks and quantum physics. Last, we discuss the challenges and further\nresearch directions for QGLMs.",
    "descriptor": "\nComments: The first two authors contributed equally to this work\n",
    "authors": [
      "Jinkai Tian",
      "Xiaoyu Sun",
      "Yuxuan Du",
      "Shanshan Zhao",
      "Qing Liu",
      "Kaining Zhang",
      "Wei Yi",
      "Wanrong Huang",
      "Chaoyue Wang",
      "Xingyao Wu",
      "Min-Hsiu Hsieh",
      "Tongliang Liu",
      "Wenjing Yang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03066"
  },
  {
    "id": "arXiv:2206.03069",
    "title": "Patch-based image Super Resolution using generalized Gaussian mixture  model",
    "abstract": "Single Image Super Resolution (SISR) methods aim to recover the clean images\nin high resolution from low resolution observations.A family of patch-based\napproaches have received considerable attention and development. The minimum\nmean square error (MMSE) methodis a powerful image restoration method that uses\na probability model on the patches of images. This paper proposes an algorithm\nto learn a jointgeneralized Gaussian mixture model (GGMM) from a pair of the\nlow resolution patches and the corresponding high resolution patches fromthe\nreference data. We then reconstruct the high resolution image based on the MMSE\nmethod. Our numerical evaluations indicate that theMMSE-GGMM method competes\nwith other state of the art methods.",
    "descriptor": "",
    "authors": [
      "Dang-Phuong-Lan Nguyen",
      "Jean-Fran\u00e7ois Aujol",
      "Yannick Berthoumieu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.03069"
  },
  {
    "id": "arXiv:2206.03104",
    "title": "Crossing the Linguistic Causeway: A Binational Approach for Translating  Soundscape Attributes to Bahasa Melayu",
    "abstract": "Translation of perceptual descriptors such as the perceived affective quality\nattributes in the soundscape standard (ISO/TS 12913-2:2018) is an inherently\nintricate task, especially if the target language is used in multiple\ncountries. Despite geographical proximity and a shared language of Bahasa\nMelayu (Standard Malay), differences in culture and language education policies\nbetween Singapore and Malaysia could invoke peculiarities in the affective\nappraisal of sounds. To generate provisional translations of the eight\nperceived affective attributes -- eventful, vibrant, pleasant, calm,\nuneventful, monotonous, annoying, and chaotic -- into Bahasa Melayu that is\napplicable in both Singapore and Malaysia, a binational expert-led approach\nsupplemented by a quantitative evaluation framework was adopted. A set of\npreliminary translation candidates were developed via a four-stage process,\nfirstly by a qualified translator, which was then vetted by linguistics\nexperts, followed by examination via an experiential evaluation, and finally\nreviewed by the core research team. A total of 66 participants were then\nrecruited cross-nationally to quantitatively evaluate the preliminary\ntranslation candidates. Of the eight attributes, cross-national differences\nwere observed only in the translation of annoying. For instance,\n\"menjengkelkan\" was found to be significantly less understood in Singapore than\nin Malaysia, as well as less understandable than \"membingitkan\" within\nSingapore. Results of the quantitative evaluation also revealed the imperfect\nnature of foreign language translations for perceptual descriptors, which\nsuggests a possibility for exploring corrective measures.",
    "descriptor": "\nComments: Under review for Applied Acoustics (Special Issue on Soundscape Attributes Translation: Current Projects and Challenges)\n",
    "authors": [
      "Bhan Lam",
      "Julia Chieng",
      "Karn N. Watcharasupat",
      "Kenneth Ooi",
      "Zhen-Ting Ong",
      "Joo Young Hong",
      "Woon-Seng Gan"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.03104"
  },
  {
    "id": "arXiv:2206.03107",
    "title": "The fundamental solution of a 1D evolution equation with a sign changing  diffusion coefficient",
    "abstract": "In this work we investigate a 1D evolution equation involving a divergence\nform operator where the diffusion coefficient inside the divergence is sign\nchanging. Equivalently the evolution equation of interest can be interpreted as\nbehaving locally like a heat equation, and involving a transmission condition\nat some interface that prescribes in particular a change of sign of the first\norder space derivatives across the interface. We especially focus on the\nconstruction of fundamental solutions for the evolution equation. As the second\norder operator involved in the evolution equation is not elliptic, this cannot\nbe performed by standard tools for parabolic PDEs. However we manage in a first\ntime to provide a spectral representation of the semigroup associated to the\nequation, which leads to a first expression of the fundamental solution. In a\nsecond time, examining the case when the diffusion coefficient is piecewise\nconstant but remains positive, we do probabilistic computations involving the\nkilled Skew Brownian Motion (SBM), that provide a certain explicit expression\nof the fundamental solution for the positive case. It turns out that this\nexpression also provides a fundamental solution for the case when the\ncoefficient is sign changing, and can be interpreted as defining a pseudo SBM.\nThis pseudo SBM can be approached by a rescaled pseudo asymmetric random walk.\nWe infer from these different results various approximation schemes that we\ntest numerically.",
    "descriptor": "",
    "authors": [
      "\u00c9ric Bonnetier",
      "Pierre Etor\u00e9",
      "Miguel Martinez"
    ],
    "subjectives": [
      "Mathematical Physics (math-ph)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2206.03107"
  },
  {
    "id": "arXiv:2206.03150",
    "title": "Group Meritocratic Fairness in Linear Contextual Bandits",
    "abstract": "We study the linear contextual bandit problem where an agent has to select\none candidate from a pool and each candidate belongs to a sensitive group. In\nthis setting, candidates' rewards may not be directly comparable between\ngroups, for example when the agent is an employer hiring candidates from\ndifferent ethnic groups and some groups have a lower reward due to\ndiscriminatory bias and/or social injustice. We propose a notion of fairness\nthat states that the agent's policy is fair when it selects a candidate with\nhighest relative rank, which measures how good the reward is when compared to\ncandidates from the same group. This is a very strong notion of fairness, since\nthe relative rank is not directly observed by the agent and depends on the\nunderlying reward model and on the distribution of rewards. Thus we study the\nproblem of learning a policy which approximates a fair policy under the\ncondition that the contexts are independent between groups and the distribution\nof rewards of each group is absolutely continuous. In particular, we design a\ngreedy policy which at each round constructs a ridge regression estimator from\nthe observed context-reward pairs, and then computes an estimate of the\nrelative rank of each candidate using the empirical cumulative distribution\nfunction. We prove that the greedy policy achieves, after $T$ rounds, up to log\nfactors and with high probability, a fair pseudo-regret of order $\\sqrt{dT}$,\nwhere $d$ is the dimension of the context vectors. The policy also satisfies\ndemographic parity at each round when averaged over all possible information\navailable before the selection. We finally show with a proof of concept\nsimulation that our policy achieves sub-linear fair pseudo-regret also in\npractice.",
    "descriptor": "\nComments: 21 pages, 2 figures\n",
    "authors": [
      "Riccardo Grazzi",
      "Arya Akhavan",
      "John Isak Texas Falk",
      "Leonardo Cella",
      "Massimiliano Pontil"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03150"
  },
  {
    "id": "arXiv:2206.03166",
    "title": "A novel statistical approach for two-sample testing based on the overlap  coefficient",
    "abstract": "Here we propose a new nonparametric framework for two-sample testing, named\nas the OVL-$q$ ($q = 1, 2, \\ldots$). This can be regarded as a natural\nextension of the Smirnov test, which is equivalent to the OVL-1. We\nspecifically focus on the OVL-2, implement its fast algorithm, and show its\nsuperiority over other statistical tests in some experiments.",
    "descriptor": "\nComments: 25 pages, 5 figures\n",
    "authors": [
      "Atsushi Komaba",
      "Hisashi Johno",
      "Kazunori Nakamoto"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Discrete Mathematics (cs.DM)",
      "Mathematical Software (cs.MS)",
      "Probability (math.PR)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2206.03166"
  },
  {
    "id": "arXiv:2206.03182",
    "title": "Anonymous voting scheme using quantum assisted blockchain",
    "abstract": "Voting forms the most important tool for arriving at a decision in any\ninstitution. The changing needs of the civilization currently demands a\npractical yet secure electronic voting system, but any flaw related to the\napplied voting technology can lead to tampering of the results with the\nmalicious outcomes. Currently, blockchain technology due to its transparent\nstructure forms an emerging area of investigation for the development of voting\nsystems with a far greater security. However, various apprehensions are yet to\nbe conclusively resolved before using blockchain in high stakes elections.\nOther than this, the blockchain based voting systems are vulnerable to possible\nattacks by upcoming noisy intermediate scale quantum (NISQ) computer. To\ncircumvent, most of these limitations, in this work, we propose an anonymous\nvoting scheme based on quantum assisted blockchain by enhancing the advantages\noffered by blockchain with the quantum resources such as quantum random number\ngenerators and quantum key distribution. The purposed scheme is shown to\nsatisfy the requirements of a good voting scheme. Further, the voting scheme is\nauditable and can be implemented using the currently available technology.",
    "descriptor": "\nComments: We propose an anonymous voting scheme based on quantum assisted blockchain by enhancing the advantages offered by blockchain with the quantum resources such as quantum random number generators and quantum key distribution\n",
    "authors": [
      "Sandeep Mishra",
      "Kishore Thapliyal",
      "S Krish Rewanth",
      "Abhishek Parakh",
      "Anirban Pathak"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.03182"
  },
  {
    "id": "arXiv:2206.03198",
    "title": "Explaining the physics of transfer learning a data-driven subgrid-scale  closure to a different turbulent flow",
    "abstract": "Transfer learning (TL) is becoming a powerful tool in scientific applications\nof neural networks (NNs), such as weather/climate prediction and turbulence\nmodeling. TL enables out-of-distribution generalization (e.g., extrapolation in\nparameters) and effective blending of disparate training sets (e.g.,\nsimulations and observations). In TL, selected layers of a NN, already trained\nfor a base system, are re-trained using a small dataset from a target system.\nFor effective TL, we need to know 1) what are the best layers to re-train? and\n2) what physics are learned during TL? Here, we present novel analyses and a\nnew framework to address (1)-(2) for a broad range of multi-scale, nonlinear\nsystems. Our approach combines spectral analyses of the systems' data with\nspectral analyses of convolutional NN's activations and kernels, explaining the\ninner-workings of TL in terms of the system's nonlinear physics. Using\nsubgrid-scale modeling of several setups of 2D turbulence as test cases, we\nshow that the learned kernels are combinations of low-, band-, and high-pass\nfilters, and that TL learns new filters whose nature is consistent with the\nspectral differences of base and target systems. We also find the shallowest\nlayers are the best to re-train in these cases, which is against the common\nwisdom guiding TL in machine learning literature. Our framework identifies the\nbest layer(s) to re-train beforehand, based on physics and NN theory. Together,\nthese analyses explain the physics learned in TL and provide a framework to\nguide TL for wide-ranging applications in science and engineering, such as\nclimate change modeling.",
    "descriptor": "\nComments: 21 pages, 6 figures\n",
    "authors": [
      "Adam Subel",
      "Yifei Guan",
      "Ashesh Chattopadhyay",
      "Pedram Hassanzadeh"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.03198"
  },
  {
    "id": "arXiv:2206.03205",
    "title": "A Throughput Optimal Scheduling Policy for a Quantum Switch",
    "abstract": "We study a quantum switch that creates shared end-to-end entangled quantum\nstates to multiple sets of users that are connected to it. Each user is\nconnected to the switch via an optical link across which bipartite Bell-state\nentangled states are generated in each time-slot with certain probabilities,\nand the switch merges entanglements of links to create end-to-end entanglements\nfor users. One qubit of an entanglement of a link is stored at the switch and\nthe other qubit of the entanglement is stored at the user corresponding to the\nlink. Assuming that qubits of entanglements of links decipher after one\ntime-slot, we characterize the capacity region, which is defined as the set of\narrival rates of requests for end-to-end entanglements for which there exists a\nscheduling policy that stabilizes the switch. We propose a Max-Weight\nscheduling policy and show that it stabilizes the switch for all arrival rates\nthat lie in the capacity region. We also provide numerical results to support\nour analysis.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2106.00831\n",
    "authors": [
      "Thirupathaiah Vasantam",
      "Don Towsley"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2206.03205"
  },
  {
    "id": "arXiv:2206.03206",
    "title": "FlexLip: A Controllable Text-to-Lip System",
    "abstract": "The task of converting text input into video content is becoming an important\ntopic for synthetic media generation. Several methods have been proposed with\nsome of them reaching close-to-natural performances in constrained tasks. In\nthis paper, we tackle a subissue of the text-to-video generation problem, by\nconverting the text into lip landmarks. However, we do this using a modular,\ncontrollable system architecture and evaluate each of its individual\ncomponents. Our system, entitled FlexLip, is split into two separate modules:\ntext-to-speech and speech-to-lip, both having underlying controllable deep\nneural network architectures. This modularity enables the easy replacement of\neach of its components, while also ensuring the fast adaptation to new speaker\nidentities by disentangling or projecting the input features. We show that by\nusing as little as 20 min of data for the audio generation component, and as\nlittle as 5 min for the speech-to-lip component, the objective measures of the\ngenerated lip landmarks are comparable with those obtained when using a larger\nset of training samples. We also introduce a series of objective evaluation\nmeasures over the complete flow of our system by taking into consideration\nseveral aspects of the data and system configuration. These aspects pertain to\nthe quality and amount of training data, the use of pretrained models, and the\ndata contained therein, as well as the identity of the target speaker; with\nregard to the latter, we show that we can perform zero-shot lip adaptation to\nan unseen identity by simply updating the shape of the lips in our model.",
    "descriptor": "\nComments: 16 pages, 4 tables, 4 figures\n",
    "authors": [
      "Dan Oneata",
      "Beata Lorincz",
      "Adriana Stan",
      "Horia Cucu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.03206"
  },
  {
    "id": "arXiv:2206.03230",
    "title": "Shedding a PAC-Bayesian Light on Adaptive Sliced-Wasserstein Distances",
    "abstract": "The Sliced-Wasserstein distance (SW) is a computationally efficient and\ntheoretically grounded alternative to the Wasserstein distance. Yet, the\nliterature on its statistical properties with respect to the distribution of\nslices, beyond the uniform measure, is scarce. To bring new contributions to\nthis line of research, we leverage the PAC-Bayesian theory and the central\nobservation that SW actually hinges on a slice-distribution-dependent Gibbs\nrisk, the kind of quantity PAC-Bayesian bounds have been designed to\ncharacterize. We provide four types of results: i) PAC-Bayesian generalization\nbounds that hold on what we refer as adaptive Sliced-Wasserstein distances,\ni.e. distances defined with respect to any distribution of slices, ii) a\nprocedure to learn the distribution of slices that yields a maximally\ndiscriminative SW, by optimizing our PAC-Bayesian bounds, iii) an insight on\nhow the performance of the so-called distributional Sliced-Wasserstein distance\nmay be explained through our theory, and iv) empirical illustrations of our\nfindings.",
    "descriptor": "",
    "authors": [
      "Ruben Ohana",
      "Kimia Nadjahi",
      "Alain Rakotomamonjy",
      "Liva Ralaivola"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03230"
  },
  {
    "id": "arXiv:2206.03247",
    "title": "Towards better Interpretable and Generalizable AD detection using  Collective Artificial Intelligence",
    "abstract": "Accurate diagnosis and prognosis of Alzheimer's disease are crucial for\ndeveloping new therapies and reducing the associated costs. Recently, with the\nadvances of convolutional neural networks, deep learning methods have been\nproposed to automate these two tasks using structural MRI. However, these\nmethods often suffer from a lack of interpretability and generalization and\nhave limited prognosis performance. In this paper, we propose a novel deep\nframework designed to overcome these limitations. Our pipeline consists of two\nstages. In the first stage, 125 3D U-Nets are used to estimate voxelwise grade\nscores over the whole brain. The resulting 3D maps are then fused to construct\nan interpretable 3D grading map indicating the disease severity at the\nstructure level. As a consequence, clinicians can use this map to detect the\nbrain structures affected by the disease. In the second stage, the grading map\nand subject's age are used to perform classification with a graph convolutional\nneural network. Experimental results based on 2106 subjects demonstrated\ncompetitive performance of our deep framework compared to state-of-the-art\nmethods on different datasets for both AD diagnosis and prognosis. Moreover, we\nfound that using a large number of U-Nets processing different overlapping\nbrain areas improved the generalization capacity of the proposed methods.",
    "descriptor": "",
    "authors": [
      "Huy-Dung Nguyen",
      "Micha\u00ebl Cl\u00e9ment",
      "Boris Mansencal",
      "Pierrick Coup\u00e9"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.03247"
  },
  {
    "id": "arXiv:2206.03255",
    "title": "Do interests affect grant application success? The role of  organizational proximity",
    "abstract": "Bias in grant allocation is a critical issue, as the expectation is that\ngrants are given to the best researchers, and not to applicants that are\nsocially, organizationally, or topic-wise near-by the decision-makers. In this\npaper, we investigate the effect of organizational proximity, defined as an\napplicant with the same affiliation as one of the panel members (a near-by\npanelist), on the probability of getting a grant. This study is based on one of\nthe most prominent grant schemes in Europe, with overall excellent scientists\nas panel members. Various aspects of this organizational proximity are\nanalyzed: Who gains from it? Does it have a gender dimension? Is it bias, or\ncan it be explained by performance differences? We do find that the probability\nto get funded increases significantly for those that apply in a panel where\nthere is a panelist from the institution where the applicant has agreed to use\nthe grant. At the same time, the effect differs between disciplines and\ncountries, and men profit more of it than women do. Finally, depending on how\none defines what counts as the best researchers, the near-by panelist effect\ncan be interpreted as preferential attachment (quality links to quality) or as\nbias and particularism.",
    "descriptor": "\nComments: 20 pager, 2 figures, 6 tables, preprint\n",
    "authors": [
      "Charlie Mom",
      "Peter van den Besselaar"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.03255"
  },
  {
    "id": "arXiv:2206.03314",
    "title": "Integrating Random Effects in Deep Neural Networks",
    "abstract": "Modern approaches to supervised learning like deep neural networks (DNNs)\ntypically implicitly assume that observed responses are statistically\nindependent. In contrast, correlated data are prevalent in real-life\nlarge-scale applications, with typical sources of correlation including\nspatial, temporal and clustering structures. These correlations are either\nignored by DNNs, or ad-hoc solutions are developed for specific use cases. We\npropose to use the mixed models framework to handle correlated data in DNNs. By\ntreating the effects underlying the correlation structure as random effects,\nmixed models are able to avoid overfitted parameter estimates and ultimately\nyield better predictive performance. The key to combining mixed models and DNNs\nis using the Gaussian negative log-likelihood (NLL) as a natural loss function\nthat is minimized with DNN machinery including stochastic gradient descent\n(SGD). Since NLL does not decompose like standard DNN loss functions, the use\nof SGD with NLL presents some theoretical and implementation challenges, which\nwe address. Our approach which we call LMMNN is demonstrated to improve\nperformance over natural competitors in various correlation scenarios on\ndiverse simulated and real datasets. Our focus is on a regression setting and\ntabular datasets, but we also show some results for classification. Our code is\navailable at https://github.com/gsimchoni/lmmnn.",
    "descriptor": "\nComments: 53 pages, 9 figures\n",
    "authors": [
      "Giora Simchoni",
      "Saharon Rosset"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03314"
  },
  {
    "id": "arXiv:2206.03336",
    "title": "Parotid Gland MRI Segmentation Based on Swin-Unet and Multimodal Images",
    "abstract": "Parotid gland tumors account for approximately 2% to 10% of head and neck\ntumors. Preoperative tumor localization, differential diagnosis, and subsequent\nselection of appropriate treatment for parotid gland tumors is critical.\nHowever, the relative rarity of these tumors and the highly dispersed tissue\ntypes have left an unmet need for a subtle differential diagnosis of such\nneoplastic lesions based on preoperative radiomics. Recently, deep learning\nmethods have developed rapidly, especially Transformer beats the traditional\nconvolutional neural network in computer vision. Many new Transformer-based\nnetworks have been proposed for computer vision tasks. In this study,\nmulticenter multimodal parotid gland MRI images were collected. The Swin-Unet\nwhich was based on Transformer was used. MRI images of STIR, T1 and T2\nmodalities were combined into a three-channel data to train the network. We\nachieved segmentation of the region of interest for parotid gland and tumor.\nThe DSC of the model on the test set was 88.63%, MPA was 99.31%, MIoU was\n83.99%, and HD was 3.04. Then a series of comparison experiments were designed\nin this paper to further validate the segmentation performance of the\nalgorithm.",
    "descriptor": "",
    "authors": [
      "Yin Dai",
      "Zi'an Xu",
      "Fayu Liu",
      "Siqi Li",
      "Sheng Liu",
      "Lifu Shi",
      "Jun Fu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03336"
  },
  {
    "id": "arXiv:2206.03345",
    "title": "Preconditioned Gradient Descent for Overparameterized Nonconvex  Burer--Monteiro Factorization with Global Optimality Certification",
    "abstract": "We consider using gradient descent to minimize the nonconvex function\n$f(X)=\\phi(XX^{T})$ over an $n\\times r$ factor matrix $X$, in which $\\phi$ is\nan underlying smooth convex cost function defined over $n\\times n$ matrices.\nWhile only a second-order stationary point $X$ can be provably found in\nreasonable time, if $X$ is additionally rank deficient, then its rank\ndeficiency certifies it as being globally optimal. This way of certifying\nglobal optimality necessarily requires the search rank $r$ of the current\niterate $X$ to be overparameterized with respect to the rank $r^{\\star}$ of the\nglobal minimizer $X^{\\star}$. Unfortunately, overparameterization significantly\nslows down the convergence of gradient descent, from a linear rate with\n$r=r^{\\star}$ to a sublinear rate when $r>r^{\\star}$, even when $\\phi$ is\nstrongly convex. In this paper, we propose an inexpensive preconditioner that\nrestores the convergence rate of gradient descent back to linear in the\noverparameterized case, while also making it agnostic to possible\nill-conditioning in the global minimizer $X^{\\star}$.",
    "descriptor": "",
    "authors": [
      "Gavin Zhang",
      "Salar Fattahi",
      "Richard Y. Zhang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.03345"
  },
  {
    "id": "arXiv:2206.03353",
    "title": "Adaptive Regularization for Adversarial Training",
    "abstract": "Adversarial training, which is to enhance robustness against adversarial\nattacks, has received much attention because it is easy to generate\nhuman-imperceptible perturbations of data to deceive a given deep neural\nnetwork. In this paper, we propose a new adversarial training algorithm that is\ntheoretically well motivated and empirically superior to other existing\nalgorithms. A novel feature of the proposed algorithm is to use a data-adaptive\nregularization for robustifying a prediction model. We apply more\nregularization to data which are more vulnerable to adversarial attacks and\nvice versa. Even though the idea of data-adaptive regularization is not new,\nour data-adaptive regularization has a firm theoretical base of reducing an\nupper bound of the robust risk. Numerical experiments illustrate that our\nproposed algorithm improves the generalization (accuracy on clean samples) and\nrobustness (accuracy on adversarial attacks) simultaneously to achieve the\nstate-of-the-art performance.",
    "descriptor": "",
    "authors": [
      "Dongyoon Yang",
      "Insung Kong",
      "Yongdai Kim"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03353"
  },
  {
    "id": "arXiv:2206.03359",
    "title": "An efficient semi-supervised quality control system trained using  physics-based MRI-artefact generators and adversarial training",
    "abstract": "Large medical imaging data sets are becoming increasingly available. A common\nchallenge in these data sets is to ensure that each sample meets minimum\nquality requirements devoid of significant artefacts. Despite a wide range of\nexisting automatic methods having been developed to identify imperfections and\nartefacts in medical imaging, they mostly rely on data-hungry methods. In\nparticular, the lack of sufficient scans with artefacts available for training\nhas created a barrier in designing and deploying machine learning in clinical\nresearch. To tackle this problem, we propose a novel framework having four main\ncomponents: (1) a set of artefact generators inspired by magnetic resonance\nphysics to corrupt brain MRI scans and augment a training dataset, (2) a set of\nabstract and engineered features to represent images compactly, (3) a feature\nselection process that depends on the class of artefact to improve\nclassification performance, and (4) a set of Support Vector Machine (SVM)\nclassifiers trained to identify artefacts. Our novel contributions are\nthreefold: first, we use the novel physics-based artefact generators to\ngenerate synthetic brain MRI scans with controlled artefacts as a data\naugmentation technique. This will avoid the labour-intensive collection and\nlabelling process of scans with rare artefacts. Second, we propose a large pool\nof abstract and engineered image features developed to identify 9 different\nartefacts for structural MRI. Finally, we use an artefact-based feature\nselection block that, for each class of artefacts, finds the set of features\nthat provide the best classification performance. We performed validation\nexperiments on a large data set of scans with artificially-generated artefacts,\nand in a multiple sclerosis clinical trial where real artefacts were identified\nby experts, showing that the proposed pipeline outperforms traditional methods.",
    "descriptor": "",
    "authors": [
      "Daniele Ravi",
      "Frederik Barkhof",
      "Daniel C. Alexander",
      "Geoffrey JM Parker",
      "Arman Eshaghi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03359"
  },
  {
    "id": "arXiv:2206.03364",
    "title": "KPGT: Knowledge-Guided Pre-training of Graph Transformer for Molecular  Property Prediction",
    "abstract": "Designing accurate deep learning models for molecular property prediction\nplays an increasingly essential role in drug and material discovery. Recently,\ndue to the scarcity of labeled molecules, self-supervised learning methods for\nlearning generalizable and transferable representations of molecular graphs\nhave attracted lots of attention. In this paper, we argue that there exist two\nmajor issues hindering current self-supervised learning methods from obtaining\ndesired performance on molecular property prediction, that is, the ill-defined\npre-training tasks and the limited model capacity. To this end, we introduce\nKnowledge-guided Pre-training of Graph Transformer (KPGT), a novel\nself-supervised learning framework for molecular graph representation learning,\nto alleviate the aforementioned issues and improve the performance on the\ndownstream molecular property prediction tasks. More specifically, we first\nintroduce a high-capacity model, named Line Graph Transformer (LiGhT), which\nemphasizes the importance of chemical bonds and is mainly designed to model the\nstructural information of molecular graphs. Then, a knowledge-guided\npre-training strategy is proposed to exploit the additional knowledge of\nmolecules to guide the model to capture the abundant structural and semantic\ninformation from large-scale unlabeled molecular graphs. Extensive\ncomputational tests demonstrated that KPGT can offer superior performance over\ncurrent state-of-the-art methods on several molecular property prediction\ntasks.",
    "descriptor": "\nComments: 11 pages, to appear in KDD 2022 research track\n",
    "authors": [
      "Han Li",
      "Dan Zhao",
      "Jianyang Zeng"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.03364"
  },
  {
    "id": "arXiv:2206.03369",
    "title": "Computational Doob's $h$-transforms for Online Filtering of Discretely  Observed Diffusions",
    "abstract": "This paper is concerned with online filtering of discretely observed\nnonlinear diffusion processes. Our approach is based on the fully adapted\nauxiliary particle filter, which involves Doob's $h$-transforms that are\ntypically intractable. We propose a computational framework to approximate\nthese $h$-transforms by solving the underlying backward Kolmogorov equations\nusing nonlinear Feynman-Kac formulas and neural networks. The methodology\nallows one to train a locally optimal particle filter prior to the\ndata-assimilation procedure. Numerical experiments illustrate that the proposed\napproach can be orders of magnitude more efficient than the bootstrap particle\nfilter in the regime of highly informative observations, when the observations\nare extreme under the model, and if the state dimension is large.",
    "descriptor": "\nComments: 14 pages, 5 figures\n",
    "authors": [
      "Nicolas Chopin",
      "Andras Fulop",
      "Jeremy Heng",
      "Alexandre H. Thiery"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2206.03369"
  },
  {
    "id": "arXiv:2206.03371",
    "title": "On random embeddings and their application to optimisation",
    "abstract": "Random embeddings project high-dimensional spaces to low-dimensional ones;\nthey are careful constructions which allow the approximate preservation of key\nproperties, such as the pair-wise distances between points. Often in the field\nof optimisation, one needs to explore high-dimensional spaces representing the\nproblem data or its parameters and thus the computational cost of solving an\noptimisation problem is connected to the size of the data/variables. This\nthesis studies the theoretical properties of norm-preserving random embeddings,\nand their application to several classes of optimisation problems.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2105.11815\n",
    "authors": [
      "Zhen Shao"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Data Structures and Algorithms (cs.DS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.03371"
  },
  {
    "id": "arXiv:2206.03375",
    "title": "Walking on Vertices and Edges by Continuous-Time Quantum Walk",
    "abstract": "The quantum walk dynamics obey the laws of quantum mechanics with an extra\nlocality constraint, which demands that the evolution operator is local in the\nsense that the walker must visit the neighboring locations before endeavoring\nto distant places. Usually, the Hamiltonian is obtained from either the\nadjacency or the laplacian matrix of the graph and the walker hops from\nvertices to neighboring vertices. In this work, we define a version of the\ncontinuous-time quantum walk that allows the walker to hop from vertices to\nedges and vice versa. As an application, we analyze the spatial search\nalgorithm on the complete bipartite graph by modifying the new version of the\nHamiltonian with an extra term that depends on the location of the marked\nvertex or marked edge, similar to what is done in the standard continuous-time\nquantum walk model. We show that the optimal running time to find either a\nvertex or an edge is $O(\\sqrt{N_e})$ with success probability $1+o(1)$, where\n$N_e$ is the number of edges of the complete bipartite graph.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Caue F. T. Silva",
      "Daniel Posner",
      "Renato Portugal"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2206.03375"
  },
  {
    "id": "arXiv:2206.03400",
    "title": "The Influence of Dataset Partitioning on Dysfluency Detection Systems",
    "abstract": "This paper empirically investigates the influence of different data splits\nand splitting strategies on the performance of dysfluency detection systems.\nFor this, we perform experiments using wav2vec 2.0 models with a classification\nhead as well as support vector machines (SVM) in conjunction with the features\nextracted from the wav2vec 2.0 model to detect dysfluencies. We train and\nevaluate the systems with different non-speaker-exclusive and speaker-exclusive\nsplits of the Stuttering Events in Podcasts (SEP-28k) dataset to shed some\nlight on the variability of results w.r.t. to the partition method used.\nFurthermore, we show that the SEP-28k dataset is dominated by only a few\nspeakers, making it difficult to evaluate. To remedy this problem, we created\nSEP-28k-Extended (SEP-28k-E), containing semi-automatically generated speaker\nand gender information for the SEP-28k corpus, and suggest different data\nsplits, each useful for evaluating other aspects of methods for dysfluency\ndetection.",
    "descriptor": "\nComments: Accepted at the 25th International Conference on Text, Speech and Dialogue (TSD 2022)\n",
    "authors": [
      "Sebastian P. Bayerl",
      "Dominik Wagner",
      "Elmar N\u00f6th",
      "Tobias Bocklet",
      "Korbinian Riedhammer"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2206.03400"
  },
  {
    "id": "arXiv:2206.03413",
    "title": "Exploring the combination of deep-learning based direct segmentation and  deformable image registration for cone-beam CT based auto-segmentation for  adaptive radiotherapy",
    "abstract": "CBCT-based online adaptive radiotherapy (ART) calls for accurate\nauto-segmentation models to reduce the time cost for physicians to edit\ncontours, since the patient is immobilized on the treatment table waiting for\ntreatment to start. However, auto-segmentation of CBCT images is a difficult\ntask, majorly due to low image quality and lack of true labels for training a\ndeep learning (DL) model. Meanwhile CBCT auto-segmentation in ART is a unique\ntask compared to other segmentation problems, where manual contours on planning\nCT (pCT) are available. To make use of this prior knowledge, we propose to\ncombine deformable image registration (DIR) and direct segmentation (DS) on\nCBCT for head and neck patients. First, we use deformed pCT contours derived\nfrom multiple DIR methods between pCT and CBCT as pseudo labels for training.\nSecond, we use deformed pCT contours as bounding box to constrain the region of\ninterest for DS. Meanwhile deformed pCT contours are used as pseudo labels for\ntraining, but are generated from different DIR algorithms from bounding box.\nThird, we fine-tune the model with bounding box on true labels. We found that\nDS on CBCT trained with pseudo labels and without utilizing any prior knowledge\nhas very poor segmentation performance compared to DIR-only segmentation.\nHowever, adding deformed pCT contours as bounding box in the DS network can\ndramatically improve segmentation performance, comparable to DIR-only\nsegmentation. The DS model with bounding box can be further improved by\nfine-tuning it with some real labels. Experiments showed that 7 out of 19\nstructures have at least 0.2 dice similarity coefficient increase compared to\nDIR-only segmentation. Utilizing deformed pCT contours as pseudo labels for\ntraining and as bounding box for shape and location feature extraction in a DS\nmodel is a good way to combine DIR and DS.",
    "descriptor": "",
    "authors": [
      "Xiao Liang",
      "Howard Morgan",
      "Ti Bai",
      "Michael Dohopolski",
      "Dan Nguyen",
      "Steve Jiang"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.03413"
  },
  {
    "id": "arXiv:2206.03422",
    "title": "Vertex-critical $(P_3+\\ell P_1)$-free and vertex-critical (gem,  co-gem)-free graphs",
    "abstract": "A graph $G$ is $k$-vertex-critical if $\\chi(G)=k$ but $\\chi(G-v)<k$ for all\n$v\\in V(G)$ where $\\chi(G)$ denotes the chromatic number of $G$. We show that\nthere are only finitely many $k$-critical $(P_3+\\ell P_1)$-free graphs for all\n$k$ and all $\\ell$. Together with previous results, the only graphs $H$ for\nwhich it is unknown if there are an infinite number of $k$-vertex-critical\n$H$-free graphs is $H=(P_4+\\ell P_1)$ for all $\\ell\\ge 1$. We consider a\nrestriction on the smallest open case, and show that there are only finitely\nmany $k$-vertex-critical (gem, co-gem)-free graphs for all $k$, where\ngem$=\\overline{P_4+P_1}$. To do this, we show the stronger result that every\nvertex-critical (gem, co-gem)-free graph is either complete or a clique\nexpansion of $C_5$. This characterization allows us to give the complete list\nof all $k$-vertex-critical (gem, co-gem)-free graphs for all $k\\le 16$",
    "descriptor": "",
    "authors": [
      "Tala Abuadas",
      "Ben Cameron",
      "Ch\u00ednh T. Ho\u00e0ng",
      "Joe Sawada"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2206.03422"
  },
  {
    "id": "arXiv:2206.03439",
    "title": "Solving Non-local Fokker-Planck Equations by Deep Learning",
    "abstract": "Physics-informed neural networks (PiNNs) recently emerged as a powerful\nsolver for a large class of partial differential equations under various\ninitial and boundary conditions. In this paper, we propose trapz-PiNNs,\nphysics-informed neural networks incorporated with a modified trapezoidal rule\nrecently developed for accurately evaluating fractional laplacian and solve the\nspace-fractional Fokker-Planck equations in 2D and 3D. We describe the modified\ntrapezoidal rule in detail and verify the second-order accuracy. We demonstrate\ntrapz-PiNNs have high expressive power through predicting solution with low\n$\\mathcal{L}^2$ relative error on a variety of numerical examples. We also use\nlocal metrics such as pointwise absolute and relative errors to analyze where\ncould be further improved. We present an effective method for improving\nperformance of trapz-PiNN on local metrics, provided that physical observations\nof high-fidelity simulation of the true solution are available. Besides the\nusual advantages of the deep learning solvers such as adaptivity and\nmesh-independence, the trapz-PiNN is able to solve PDEs with fractional\nlaplacian with arbitrary $\\alpha\\in (0,2)$ and specializes on rectangular\ndomain. It also has potential to be generalized into higher dimensions.",
    "descriptor": "",
    "authors": [
      "Senbao Jiang",
      "Xiaofan Li"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.03439"
  },
  {
    "id": "arXiv:2206.03465",
    "title": "On entropic and almost multilinear representability of matroids",
    "abstract": "This article is concerned with two notions of generalized matroid\nrepresentations motivated by information theory and computer science. The first\ninvolves representations by discrete random variables and the second\napproximate representations by subspace arrangements. In both cases we show\nthat there is no algorithm that checks whether such a representation exists. As\na consequence, the conditional independence implication problem is undecidable,\nwhich gives an independent answer to a question in information theory by Geiger\nand Pearl that was recently also answered by Cheuk Ting Li. These problems are\nclosely related to problems of characterizing the achievable rates in certain\nnetwork coding problems and of constructing secret sharing schemes. Our methods\nto approach these problems are mostly algebraic. Specifically, they involve\nreductions from the uniform word problem for finite groups and the word problem\nfor sofic groups.",
    "descriptor": "\nComments: 57 pages. Comments are welcome!\n",
    "authors": [
      "Lukas K\u00fchne",
      "Geva Yashfe"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.03465"
  },
  {
    "id": "arXiv:1812.06569",
    "title": "Comparator automata in quantitative verification",
    "abstract": "Comparator automata in quantitative verification",
    "descriptor": "",
    "authors": [
      "Suguman Bansal",
      "Swarat Chaudhuri",
      "Moshe Y. Vardi"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/1812.06569"
  },
  {
    "id": "arXiv:1812.06663",
    "title": "Attending Category Disentangled Global Context for Image Classification",
    "abstract": "Comments: I have not gotten legal permission to post it on arXiv from the corresponding authors",
    "descriptor": "\nComments: I have not gotten legal permission to post it on arXiv from the corresponding authors\n",
    "authors": [
      "Keke Tang",
      "Guodong Wei",
      "Runnan Chen",
      "Jie Zhu",
      "Zhaoquan Gu",
      "Wenping Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1812.06663"
  },
  {
    "id": "arXiv:1907.03411",
    "title": "Unbiased estimators for random design regression",
    "abstract": "Unbiased estimators for random design regression",
    "descriptor": "",
    "authors": [
      "Micha\u0142 Derezi\u0144ski",
      "Manfred K. Warmuth",
      "Daniel Hsu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1907.03411"
  },
  {
    "id": "arXiv:1907.04752",
    "title": "Sparse Regular Expression Matching",
    "abstract": "Sparse Regular Expression Matching",
    "descriptor": "",
    "authors": [
      "Philip Bille",
      "Inge Li G\u00f8rtz"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/1907.04752"
  },
  {
    "id": "arXiv:1911.03098",
    "title": "Building an Aerial-Ground Robotics System for Precision Farming: An  Adaptable Solution",
    "abstract": "Comments: Published in IEEE Robotics & Automation Magazine, vol. 28, no. 3, pp. 29-49, Sept. 2021",
    "descriptor": "\nComments: Published in IEEE Robotics & Automation Magazine, vol. 28, no. 3, pp. 29-49, Sept. 2021\n",
    "authors": [
      "Alberto Pretto",
      "St\u00e9phanie Aravecchia",
      "Wolfram Burgard",
      "Nived Chebrolu",
      "Christian Dornhege",
      "Tillmann Falck",
      "Freya Fleckenstein",
      "Alessandra Fontenla",
      "Marco Imperoli",
      "Raghav Khanna",
      "Frank Liebisch",
      "Philipp Lottes",
      "Andres Milioto",
      "Daniele Nardi",
      "Sandro Nardi",
      "Johannes Pfeifer",
      "Marija Popovi\u0107",
      "Ciro Potena",
      "C\u00e9dric Pradalier",
      "Elisa Rothacker-Feder",
      "Inkyu Sa",
      "Alexander Schaefer",
      "Roland Siegwart",
      "Cyrill Stachniss",
      "Achim Walter",
      "Wera Winterhalter",
      "Xiaolong Wu",
      "Juan Nieto"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/1911.03098"
  },
  {
    "id": "arXiv:1911.03855",
    "title": "Correcting Sociodemographic Selection Biases for Population Prediction  from Social Media",
    "abstract": "Comments: Published at the 16th International AAAI Conference on Web and Social Media (ICWSM) 2022",
    "descriptor": "\nComments: Published at the 16th International AAAI Conference on Web and Social Media (ICWSM) 2022\n",
    "authors": [
      "Salvatore Giorgi",
      "Veronica Lynn",
      "Keshav Gupta",
      "Farhan Ahmed",
      "Sandra Matz",
      "Lyle Ungar",
      "H. Andrew Schwartz"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/1911.03855"
  },
  {
    "id": "arXiv:1912.13008",
    "title": "Approximating Gromov-Hausdorff Distance in Euclidean Space",
    "abstract": "Approximating Gromov-Hausdorff Distance in Euclidean Space",
    "descriptor": "",
    "authors": [
      "Sushovan Majhi",
      "Jeffrey Vitter",
      "Carola Wenk"
    ],
    "subjectives": [
      "Metric Geometry (math.MG)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/1912.13008"
  },
  {
    "id": "arXiv:2001.02892",
    "title": "A Generalized Probabilistic Learning Approach for Multi-Fidelity  Uncertainty Propagation in Complex Physical Simulations",
    "abstract": "Comments: 35 pages, 16 figures",
    "descriptor": "\nComments: 35 pages, 16 figures\n",
    "authors": [
      "Jonas Nitzler",
      "Jonas Biehler",
      "Niklas Fehn",
      "Phaedon-Stelios Koutsourelakis",
      "Wolfgang A. Wall"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2001.02892"
  },
  {
    "id": "arXiv:2001.05633",
    "title": "Master equation of discrete time graphon mean field games and teams",
    "abstract": "Comments: 26 pages, 6 figures. arXiv admin note: text overlap with arXiv:1905.04154",
    "descriptor": "\nComments: 26 pages, 6 figures. arXiv admin note: text overlap with arXiv:1905.04154\n",
    "authors": [
      "Deepanshu Vasal",
      "Rajesh K Mishra",
      "Sriram Vishwanath"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2001.05633"
  },
  {
    "id": "arXiv:2002.06838",
    "title": "Stratified Rule-Aware Network for Abstract Visual Reasoning",
    "abstract": "Comments: AAAI 2021 paper. Code: this https URL",
    "descriptor": "\nComments: AAAI 2021 paper. Code: this https URL\n",
    "authors": [
      "Sheng Hu",
      "Yuqing Ma",
      "Xianglong Liu",
      "Yanlu Wei",
      "Shihao Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2002.06838"
  },
  {
    "id": "arXiv:2006.01236",
    "title": "Aperiodicity, Star-freeness, and First-order Logic Definability of  Structured Context-Free Languages",
    "abstract": "Comments: We fixed some issues and added examples. This version is a submission to LMCS",
    "descriptor": "\nComments: We fixed some issues and added examples. This version is a submission to LMCS\n",
    "authors": [
      "Dino Mandrioli",
      "Matteo Pradella",
      "Stefano Crespi Reghizzi"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2006.01236"
  },
  {
    "id": "arXiv:2006.16745",
    "title": "Machine learning fairness notions: Bridging the gap with real-world  applications",
    "abstract": "Machine learning fairness notions: Bridging the gap with real-world  applications",
    "descriptor": "",
    "authors": [
      "Karima Makhlouf",
      "Sami Zhioua",
      "Catuscia Palamidessi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.16745"
  },
  {
    "id": "arXiv:2007.10490",
    "title": "Estimating Probabilistic Safe WCET Ranges of Real-Time Systems at Design  Stages",
    "abstract": "Estimating Probabilistic Safe WCET Ranges of Real-Time Systems at Design  Stages",
    "descriptor": "",
    "authors": [
      "Jaekwon Lee",
      "Seung Yeob Shin",
      "Shiva Nejati",
      "Lionel C. Briand",
      "Yago Isasi Parache"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2007.10490"
  },
  {
    "id": "arXiv:2009.00596",
    "title": "Twitter Corpus of the #BlackLivesMatter Movement And Counter Protests:  2013 to 2021",
    "abstract": "Comments: Published at the 16th International AAAI Conference on Web and Social Media (ICWSM) 2022",
    "descriptor": "\nComments: Published at the 16th International AAAI Conference on Web and Social Media (ICWSM) 2022\n",
    "authors": [
      "Salvatore Giorgi",
      "Sharath Chandra Guntuku",
      "McKenzie Himelein-Wachowiak",
      "Amy Kwarteng",
      "Sy Hwang",
      "Muhammad Rahman",
      "Brenda Curtis"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2009.00596"
  },
  {
    "id": "arXiv:2010.08233",
    "title": "Concurrent Process Histories and Resource Transducers",
    "abstract": "Comments: 22 pages. Many Figures. Extended version of this https URL",
    "descriptor": "\nComments: 22 pages. Many Figures. Extended version of this https URL\n",
    "authors": [
      "Chad Nester"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2010.08233"
  },
  {
    "id": "arXiv:2011.08077",
    "title": "The Problem with XSD Binary Floating Point Datatypes in RDF",
    "abstract": "Comments: 17 pages, 3 figures",
    "descriptor": "\nComments: 17 pages, 3 figures\n",
    "authors": [
      "Jan Martin Keil",
      "Merle G\u00e4n\u00dfinger"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2011.08077"
  },
  {
    "id": "arXiv:2012.03555",
    "title": "Improving Makespan in Dynamic Task Scheduling for Cloud Robotic Systems  with Time Window Constraints",
    "abstract": "Comments: This work has been submitted to the Springer Nature for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the Springer Nature for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Saeid Alirezazadeh",
      "Lu\u00eds A. Alexandre"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2012.03555"
  },
  {
    "id": "arXiv:2101.07077",
    "title": "Yet Another Representation of Binary Decision Trees: A Mathematical  Demonstration",
    "abstract": "Yet Another Representation of Binary Decision Trees: A Mathematical  Demonstration",
    "descriptor": "",
    "authors": [
      "Jinxiong Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.07077"
  },
  {
    "id": "arXiv:2102.01460",
    "title": "Learning to Segment Human Body Parts with Synthetically Trained Deep  Convolutional Networks",
    "abstract": "Comments: This paper has been published in: Proceedings of the 16th International Conference on Intelligent Autonomous Systems (IAS 2021)",
    "descriptor": "\nComments: This paper has been published in: Proceedings of the 16th International Conference on Intelligent Autonomous Systems (IAS 2021)\n",
    "authors": [
      "Alessandro Saviolo",
      "Matteo Bonotto",
      "Daniele Evangelista",
      "Marco Imperoli",
      "Jacopo Lazzaro",
      "Emanuele Menegatti",
      "Alberto Pretto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.01460"
  },
  {
    "id": "arXiv:2102.05912",
    "title": "On Transportation of Mini-batches: A Hierarchical Approach",
    "abstract": "Comments: Accepted to ICML 2022, 34 pages, 16 figures, 9 tables",
    "descriptor": "\nComments: Accepted to ICML 2022, 34 pages, 16 figures, 9 tables\n",
    "authors": [
      "Khai Nguyen",
      "Dang Nguyen",
      "Quoc Nguyen",
      "Tung Pham",
      "Hung Bui",
      "Dinh Phung",
      "Trung Le",
      "Nhat Ho"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.05912"
  },
  {
    "id": "arXiv:2103.04789",
    "title": "Look, Cast and Mold: Learning 3D Shape Manifold from Single-view  Synthetic Data",
    "abstract": "Comments: this work is no longer under development",
    "descriptor": "\nComments: this work is no longer under development\n",
    "authors": [
      "Qianyu Feng",
      "Yawei Luo",
      "Keyang Luo",
      "Yi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.04789"
  },
  {
    "id": "arXiv:2103.06595",
    "title": "Bump Hunting in Latent Space",
    "abstract": "Comments: Version as published",
    "descriptor": "\nComments: Version as published\n",
    "authors": [
      "Bla\u017e Bortolato",
      "Barry M. Dillon",
      "Jernej F. Kamenik",
      "Aleks Smolkovi\u010d"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)"
    ],
    "url": "https://arxiv.org/abs/2103.06595"
  },
  {
    "id": "arXiv:2104.01369",
    "title": "Private Computation of Polynomials over Networks",
    "abstract": "Comments: 12 pages, 4 figures",
    "descriptor": "\nComments: 12 pages, 4 figures\n",
    "authors": [
      "Teimour Hosseinalizadeh",
      "Fatih Turkmen",
      "Nima Monshizadeh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2104.01369"
  },
  {
    "id": "arXiv:2104.05031",
    "title": "Deformable Capsules for Object Detection",
    "abstract": "Deformable Capsules for Object Detection",
    "descriptor": "",
    "authors": [
      "Rodney Lalonde",
      "Naji Khosravan",
      "Ulas Bagci"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.05031"
  },
  {
    "id": "arXiv:2104.05642",
    "title": "Common Limitations of Image Processing Metrics: A Picture Story",
    "abstract": "Comments: This is a dynamic paper on limitations of commonly used metrics. The current version discusses metrics for image-level classification, semantic segmentation, object detection and instance segmentation. For missing use cases, comments or questions, please contact a.reinke@dkfz.de or l.maier-hein@dkfz.de. Substantial contributions to this document will be acknowledged with a co-authorship",
    "descriptor": "\nComments: This is a dynamic paper on limitations of commonly used metrics. The current version discusses metrics for image-level classification, semantic segmentation, object detection and instance segmentation. For missing use cases, comments or questions, please contact a.reinke@dkfz.de or l.maier-hein@dkfz.de. Substantial contributions to this document will be acknowledged with a co-authorship\n",
    "authors": [
      "Annika Reinke",
      "Minu D. Tizabi",
      "Carole H. Sudre",
      "Matthias Eisenmann",
      "Tim R\u00e4dsch",
      "Michael Baumgartner",
      "Laura Acion",
      "Michela Antonelli",
      "Tal Arbel",
      "Spyridon Bakas",
      "Peter Bankhead",
      "Arriel Benis",
      "M. Jorge Cardoso",
      "Veronika Cheplygina",
      "Evangelia Christodoulou",
      "Beth Cimini",
      "Gary S. Collins",
      "Keyvan Farahani",
      "Bram van Ginneken",
      "Ben Glocker",
      "Patrick Godau",
      "Fred Hamprecht",
      "Daniel A. Hashimoto",
      "Doreen Heckmann-N\u00f6tzel",
      "Michael M. Hoffmann",
      "Merel Huisman",
      "Fabian Isensee",
      "Pierre Jannin",
      "Charles E. Kahn",
      "Alexandros Karargyris",
      "Alan Karthikesalingam",
      "Bernhard Kainz",
      "Emre Kavur",
      "Hannes Kenngott",
      "Jens Kleesiek",
      "Thijs Kooi",
      "Michal Kozubek",
      "Anna Kreshuk",
      "Tahsin Kurc",
      "Bennett A. Landman",
      "Geert Litjens",
      "Amin Madani",
      "Klaus Maier-Hein",
      "Anne L. Martel",
      "Peter Mattson",
      "Erik Meijering",
      "Bjoern Menze",
      "David Moher"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.05642"
  },
  {
    "id": "arXiv:2104.07091",
    "title": "SummScreen: A Dataset for Abstractive Screenplay Summarization",
    "abstract": "Comments: ACL 2022",
    "descriptor": "\nComments: ACL 2022\n",
    "authors": [
      "Mingda Chen",
      "Zewei Chu",
      "Sam Wiseman",
      "Kevin Gimpel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.07091"
  },
  {
    "id": "arXiv:2104.11271",
    "title": "A Systematic Survey on Android API Usage for Data-Driven Analytics with  Smartphones",
    "abstract": "Comments: This paper has been accepted by ACM Computing Surveys (CSUR), 2022",
    "descriptor": "\nComments: This paper has been accepted by ACM Computing Surveys (CSUR), 2022\n",
    "authors": [
      "Hansoo Lee",
      "Joonyoung Park",
      "Uichin Lee"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2104.11271"
  },
  {
    "id": "arXiv:2104.14855",
    "title": "An augmented Lagrangian preconditioner for the magnetohydrodynamics  equations at high Reynolds and coupling numbers",
    "abstract": "An augmented Lagrangian preconditioner for the magnetohydrodynamics  equations at high Reynolds and coupling numbers",
    "descriptor": "",
    "authors": [
      "Fabian Laakmann",
      "Patrick E. Farrell",
      "Lawrence Mitchell"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2104.14855"
  },
  {
    "id": "arXiv:2105.07076",
    "title": "Efficient Algorithms for Constructing an Interpolative Decomposition",
    "abstract": "Comments: Disclaimer: we do not have any experiments on very large matrices, so these findings are only conclusive for relatively small matrices",
    "descriptor": "\nComments: Disclaimer: we do not have any experiments on very large matrices, so these findings are only conclusive for relatively small matrices\n",
    "authors": [
      "Rishi Advani",
      "Sean O'Hagan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.07076"
  },
  {
    "id": "arXiv:2105.09666",
    "title": "Optimizing the Use of Behavioral Locking for High-Level Synthesis",
    "abstract": "Comments: Accepted for publication in IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems",
    "descriptor": "\nComments: Accepted for publication in IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems\n",
    "authors": [
      "Christian Pilato",
      "Luca Collini",
      "Luca Cassano",
      "Donatella Sciuto",
      "Siddharth Garg",
      "Ramesh Karri"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.09666"
  },
  {
    "id": "arXiv:2105.14388",
    "title": "Dynamic Placement in Refugee Resettlement",
    "abstract": "Comments: Expanded related work, added experiments with bootstrapped arrivals in Section 7.2, added various experiments in the appendix",
    "descriptor": "\nComments: Expanded related work, added experiments with bootstrapped arrivals in Section 7.2, added various experiments in the appendix\n",
    "authors": [
      "Narges Ahani",
      "Paul G\u00f6lz",
      "Ariel D. Procaccia",
      "Alexander Teytelboym",
      "Andrew C. Trapp"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2105.14388"
  },
  {
    "id": "arXiv:2105.14859",
    "title": "Consistency Regularization for Variational Auto-Encoders",
    "abstract": "Consistency Regularization for Variational Auto-Encoders",
    "descriptor": "",
    "authors": [
      "Samarth Sinha",
      "Adji B. Dieng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14859"
  },
  {
    "id": "arXiv:2106.01853",
    "title": "On the Computation of the Zariski Closure of Finitely Generated Groups  of Matrices",
    "abstract": "On the Computation of the Zariski Closure of Finitely Generated Groups  of Matrices",
    "descriptor": "",
    "authors": [
      "Klara Nosan",
      "Amaury Pouly",
      "Sylvain Schmitz",
      "Mahsa Shirmohammadi",
      "James Worrell"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Algebraic Geometry (math.AG)",
      "Group Theory (math.GR)"
    ],
    "url": "https://arxiv.org/abs/2106.01853"
  },
  {
    "id": "arXiv:2106.07176",
    "title": "SAS: Self-Augmentation Strategy for Language Model Pre-training",
    "abstract": "Comments: 11 pages, 5 figures",
    "descriptor": "\nComments: 11 pages, 5 figures\n",
    "authors": [
      "Yifei Xu",
      "Jingqiao Zhang",
      "Ru He",
      "Liangzhu Ge",
      "Chao Yang",
      "Cheng Yang",
      "Ying Nian Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.07176"
  },
  {
    "id": "arXiv:2106.15927",
    "title": "A Robust Classification-autoencoder to Defend Outliers and Adversaries",
    "abstract": "A Robust Classification-autoencoder to Defend Outliers and Adversaries",
    "descriptor": "",
    "authors": [
      "Lijia Yu",
      "Xiao-Shan Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.15927"
  },
  {
    "id": "arXiv:2107.05455",
    "title": "A Local Diagnosis Algorithm for Hypercube-like Networks under the BGM  Diagnosis Model",
    "abstract": "A Local Diagnosis Algorithm for Hypercube-like Networks under the BGM  Diagnosis Model",
    "descriptor": "",
    "authors": [
      "Cheng-Kuan Lin",
      "Tzu-Liang Kung",
      "Chun-Nan Hung",
      "Yuan-Hsiang Teng"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2107.05455"
  },
  {
    "id": "arXiv:2107.09370",
    "title": "An Embedding of ReLU Networks and an Analysis of their Identifiability",
    "abstract": "Comments: Constructive Approximation camera-ready",
    "descriptor": "\nComments: Constructive Approximation camera-ready\n",
    "authors": [
      "Pierre Stock",
      "R\u00e9mi Gribonval"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.09370"
  },
  {
    "id": "arXiv:2107.13405",
    "title": "Unstructured Handwashing Recognition using Smartwatch to Reduce Contact  Transmission of Pathogens",
    "abstract": "Unstructured Handwashing Recognition using Smartwatch to Reduce Contact  Transmission of Pathogens",
    "descriptor": "",
    "authors": [
      "Emanuele Lattanzi",
      "Lorenzo Calisti",
      "Valerio Freschi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2107.13405"
  },
  {
    "id": "arXiv:2108.02602",
    "title": "Tikhonov Regularization of Circle-Valued Signals",
    "abstract": "Tikhonov Regularization of Circle-Valued Signals",
    "descriptor": "",
    "authors": [
      "Laurent Condat"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2108.02602"
  },
  {
    "id": "arXiv:2108.09645",
    "title": "Improving Mini-batch Optimal Transport via Partial Transportation",
    "abstract": "Comments: Accepted to ICML 2022, 36 pages, 18 figures, 18 tables",
    "descriptor": "\nComments: Accepted to ICML 2022, 36 pages, 18 figures, 18 tables\n",
    "authors": [
      "Khai Nguyen",
      "Dang Nguyen",
      "The-Anh Vu-Le",
      "Tung Pham",
      "Nhat Ho"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.09645"
  },
  {
    "id": "arXiv:2109.00527",
    "title": "Boosting Search Engines with Interactive Agents",
    "abstract": "Comments: Published in Transactions on Machine Learning Research (06/2022)",
    "descriptor": "\nComments: Published in Transactions on Machine Learning Research (06/2022)\n",
    "authors": [
      "Leonard Adolphs",
      "Benjamin Boerschinger",
      "Christian Buck",
      "Michelle Chen Huebscher",
      "Massimiliano Ciaramita",
      "Lasse Espeholt",
      "Thomas Hofmann",
      "Yannic Kilcher",
      "Sascha Rothe",
      "Pier Giuseppe Sessa",
      "Lierni Sestorain Saralegui"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.00527"
  },
  {
    "id": "arXiv:2109.01494",
    "title": "Computing Graph Descriptors on Edge Streams",
    "abstract": "Comments: Extension of work accepted to PAKDD 2020",
    "descriptor": "\nComments: Extension of work accepted to PAKDD 2020\n",
    "authors": [
      "Zohair Raza Hassan",
      "Sarwan Ali",
      "Imdadullah Khan",
      "Mudassir Shabbir",
      "Waseem Abbas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2109.01494"
  },
  {
    "id": "arXiv:2109.07118",
    "title": "Low-Resource Named Entity Recognition Based on Multi-hop Dependency  Trigger",
    "abstract": "Low-Resource Named Entity Recognition Based on Multi-hop Dependency  Trigger",
    "descriptor": "",
    "authors": [
      "Jiangxu Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.07118"
  },
  {
    "id": "arXiv:2109.07711",
    "title": "DeepMTS: Deep Multi-task Learning for Survival Prediction in Patients  with Advanced Nasopharyngeal Carcinoma using Pretreatment PET/CT",
    "abstract": "Comments: Accepted at IEEE Journal of Biomedical and Health Informatics (JBHI)",
    "descriptor": "\nComments: Accepted at IEEE Journal of Biomedical and Health Informatics (JBHI)\n",
    "authors": [
      "Mingyuan Meng",
      "Bingxin Gu",
      "Lei Bi",
      "Shaoli Song",
      "David Dagan Feng",
      "Jinman Kim"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07711"
  },
  {
    "id": "arXiv:2109.08913",
    "title": "Intelligent Reflecting Surface Aided MIMO with Cascaded Line-of-Sight  Links: Channel Modelling and Capacity Analysis",
    "abstract": "Intelligent Reflecting Surface Aided MIMO with Cascaded Line-of-Sight  Links: Channel Modelling and Capacity Analysis",
    "descriptor": "",
    "authors": [
      "Mingchen Zhang",
      "Xiaojun Yuan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2109.08913"
  },
  {
    "id": "arXiv:2109.13595",
    "title": "The Fragility of Optimized Bandit Algorithms",
    "abstract": "The Fragility of Optimized Bandit Algorithms",
    "descriptor": "",
    "authors": [
      "Lin Fan",
      "Peter W. Glynn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2109.13595"
  },
  {
    "id": "arXiv:2110.00808",
    "title": "Cycle-Consistent World Models for Domain Independent Latent Imagination",
    "abstract": "Cycle-Consistent World Models for Domain Independent Latent Imagination",
    "descriptor": "",
    "authors": [
      "Sidney Bender",
      "Tim Joseph",
      "Marius Zoellner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.00808"
  },
  {
    "id": "arXiv:2110.02329",
    "title": "Task-aware Privacy Preservation for Multi-dimensional Data",
    "abstract": "Comments: Accepted by 39th International Conference on Machine Learning (ICML 2022)",
    "descriptor": "\nComments: Accepted by 39th International Conference on Machine Learning (ICML 2022)\n",
    "authors": [
      "Jiangnan Cheng",
      "Ao Tang",
      "Sandeep Chinchali"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02329"
  },
  {
    "id": "arXiv:2110.06803",
    "title": "Learn to Ignore: Domain Adaptation for Multi-Site MRI Analysis",
    "abstract": "Learn to Ignore: Domain Adaptation for Multi-Site MRI Analysis",
    "descriptor": "",
    "authors": [
      "Julia Wolleb",
      "Robin Sandk\u00fchler",
      "Florentin Bieder",
      "Muhamed Barakovic",
      "Nouchine Hadjikhani",
      "Athina Papadopoulou",
      "\u00d6zg\u00fcr Yaldizli",
      "Jens Kuhle",
      "Cristina Granziera",
      "Philippe C. Cattin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.06803"
  },
  {
    "id": "arXiv:2110.11150",
    "title": "Lottery Tickets with Nonzero Biases",
    "abstract": "Lottery Tickets with Nonzero Biases",
    "descriptor": "",
    "authors": [
      "Jonas Fischer",
      "Advait Gadhikar",
      "Rebekka Burkholz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.11150"
  },
  {
    "id": "arXiv:2110.12372",
    "title": "Uncertainty-Guided Lung Nodule Segmentation with Feature-Aware Attention",
    "abstract": "Comments: 10 pages, 4 figures, 30 references",
    "descriptor": "\nComments: 10 pages, 4 figures, 30 references\n",
    "authors": [
      "Han Yang",
      "Lu Shen",
      "Mengke Zhang",
      "Qiuli Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12372"
  },
  {
    "id": "arXiv:2110.13492",
    "title": "TUNet: A Block-online Bandwidth Extension Model based on Transformers  and Self-supervised Pretraining",
    "abstract": "Comments: Published as a conference paper at ICASSP 2022, 5 pages, 4 figures, 3 tables",
    "descriptor": "\nComments: Published as a conference paper at ICASSP 2022, 5 pages, 4 figures, 3 tables\n",
    "authors": [
      "Viet-Anh Nguyen",
      "Anh H. T. Nguyen",
      "Andy W. H. Khong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.13492"
  },
  {
    "id": "arXiv:2110.13817",
    "title": "Multilevel Inverter Real-Time Simulation and Optimization Through Hybrid  GA/PSO Algorithm",
    "abstract": "Comments: 26 pages, 22 pictures",
    "descriptor": "\nComments: 26 pages, 22 pictures\n",
    "authors": [
      "Hussein Zolfaghari",
      "Hamidreza Momeni",
      "Hossein Karimi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.13817"
  },
  {
    "id": "arXiv:2110.15871",
    "title": "From Theories on Styles to their Transfer in Text: Bridging the Gap with  a Hierarchical Survey",
    "abstract": "Comments: 58 pages, 2 figures, 10 tables. Revised version, submitted to the Journal of Natural Language Engineering, Cambridge University Press",
    "descriptor": "\nComments: 58 pages, 2 figures, 10 tables. Revised version, submitted to the Journal of Natural Language Engineering, Cambridge University Press\n",
    "authors": [
      "Enrica Troiano",
      "Aswathy Velutharambath",
      "Roman Klinger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.15871"
  },
  {
    "id": "arXiv:2111.01872",
    "title": "Towards Fairness-Aware Federated Learning",
    "abstract": "Comments: 16 pages, 4 figures",
    "descriptor": "\nComments: 16 pages, 4 figures\n",
    "authors": [
      "Yuxin Shi",
      "Han Yu",
      "Cyril Leung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2111.01872"
  },
  {
    "id": "arXiv:2111.05249",
    "title": "Fracture Modes for Realtime Destruction",
    "abstract": "Fracture Modes for Realtime Destruction",
    "descriptor": "",
    "authors": [
      "Silvia Sell\u00e1n",
      "Jack Luong",
      "Leticia Mattos Da Silva",
      "Aravind Ramakrishnan",
      "Yuchuan Yang",
      "Alec Jacobson"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2111.05249"
  },
  {
    "id": "arXiv:2111.05992",
    "title": "On the Use and Misuse of Absorbing States in Multi-agent Reinforcement  Learning",
    "abstract": "Comments: RL in Games Workshop AAAI 2022",
    "descriptor": "\nComments: RL in Games Workshop AAAI 2022\n",
    "authors": [
      "Andrew Cohen",
      "Ervin Teng",
      "Vincent-Pierre Berges",
      "Ruo-Ping Dong",
      "Hunter Henry",
      "Marwan Mattar",
      "Alexander Zook",
      "Sujoy Ganguly"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.05992"
  },
  {
    "id": "arXiv:2111.08708",
    "title": "Automated skin lesion segmentation using multi-scale feature extraction  scheme and dual-attention mechanism",
    "abstract": "Automated skin lesion segmentation using multi-scale feature extraction  scheme and dual-attention mechanism",
    "descriptor": "",
    "authors": [
      "G Jignesh Chowdary",
      "G V S N Durga Yathisha",
      "Suganya G",
      "Premalatha M"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.08708"
  },
  {
    "id": "arXiv:2111.10140",
    "title": "Learning in High-Dimensional Feature Spaces Using ANOVA-Based Fast  Matrix-Vector Multiplication",
    "abstract": "Comments: Official Code this https URL",
    "descriptor": "\nComments: Official Code this https URL\n",
    "authors": [
      "Franziska Nestler",
      "Martin Stoll",
      "Theresa Wagner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.10140"
  },
  {
    "id": "arXiv:2111.11153",
    "title": "Plant 'n' Seek: Can You Find the Winning Ticket?",
    "abstract": "Plant 'n' Seek: Can You Find the Winning Ticket?",
    "descriptor": "",
    "authors": [
      "Jonas Fischer",
      "Rebekka Burkholz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.11153"
  },
  {
    "id": "arXiv:2111.12602",
    "title": "Hierarchical Graph-Convolutional Variational AutoEncoding for Generative  Modelling of Human Motion",
    "abstract": "Comments: Under Review",
    "descriptor": "\nComments: Under Review\n",
    "authors": [
      "Anthony Bourached",
      "Robert Gray",
      "Xiaodong Guan",
      "Ryan-Rhys Griffiths",
      "Ashwani Jha",
      "Parashkev Nachev"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2111.12602"
  },
  {
    "id": "arXiv:2111.13336",
    "title": "MAE-DET: Revisiting Maximum Entropy Principle in Zero-Shot NAS for  Efficient Object Detection",
    "abstract": "Comments: Accepted by ICML 2022",
    "descriptor": "\nComments: Accepted by ICML 2022\n",
    "authors": [
      "Zhenhong Sun",
      "Ming Lin",
      "Xiuyu Sun",
      "Zhiyu Tan",
      "Hao Li",
      "Rong Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.13336"
  },
  {
    "id": "arXiv:2111.15645",
    "title": "Survey Descent: A Multipoint Generalization of Gradient Descent for  Nonsmooth Optimization",
    "abstract": "Survey Descent: A Multipoint Generalization of Gradient Descent for  Nonsmooth Optimization",
    "descriptor": "",
    "authors": [
      "X.Y. Han",
      "Adrian S. Lewis"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Geometry (cs.CG)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.15645"
  },
  {
    "id": "arXiv:2112.01473",
    "title": "Neural Point Light Fields",
    "abstract": "Comments: 9 pages, replacement changed font of equations",
    "descriptor": "\nComments: 9 pages, replacement changed font of equations\n",
    "authors": [
      "Julian Ost",
      "Issam Laradji",
      "Alejandro Newell",
      "Yuval Bahat",
      "Felix Heide"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2112.01473"
  },
  {
    "id": "arXiv:2112.01695",
    "title": "Hybrid Instance-aware Temporal Fusion for Online Video Instance  Segmentation",
    "abstract": "Comments: AAAI 2022",
    "descriptor": "\nComments: AAAI 2022\n",
    "authors": [
      "Xiang Li",
      "Jinglu Wang",
      "Xiao Li",
      "Yan Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01695"
  },
  {
    "id": "arXiv:2112.02030",
    "title": "Direction-Oriented Stress-Constrained Topology Optimization of  Orthotropic Materials",
    "abstract": "Direction-Oriented Stress-Constrained Topology Optimization of  Orthotropic Materials",
    "descriptor": "",
    "authors": [
      "Ahmed Moter",
      "Mohamed Abdelhamid",
      "Aleksander Czekanski"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.02030"
  },
  {
    "id": "arXiv:2201.00261",
    "title": "ARPIST: Provably Accurate and Stable Numerical Integration over  Spherical Triangles",
    "abstract": "Comments: 28 pages, 14 figures, submitted to Journal of Computational and Applied Mathematics",
    "descriptor": "\nComments: 28 pages, 14 figures, submitted to Journal of Computational and Applied Mathematics\n",
    "authors": [
      "Yipeng Li",
      "Xiangmin Jiao"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2201.00261"
  },
  {
    "id": "arXiv:2201.03907",
    "title": "Common Message Acknowledgments: Massive ARQ Protocols for Wireless  Access",
    "abstract": "Comments: Accepted by IEEE Transactions on Communications",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Communications\n",
    "authors": [
      "Anders E. Kal\u00f8r",
      "Rados\u0142aw Kotaba",
      "Petar Popovski"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2201.03907"
  },
  {
    "id": "arXiv:2201.05125",
    "title": "GradMax: Growing Neural Networks using Gradient Information",
    "abstract": "Comments: ICLR 2022",
    "descriptor": "\nComments: ICLR 2022\n",
    "authors": [
      "Utku Evci",
      "Bart van Merri\u00ebnboer",
      "Thomas Unterthiner",
      "Max Vladymyrov",
      "Fabian Pedregosa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.05125"
  },
  {
    "id": "arXiv:2201.05624",
    "title": "Scientific Machine Learning through Physics-Informed Neural Networks:  Where we are and What's next",
    "abstract": "Scientific Machine Learning through Physics-Informed Neural Networks:  Where we are and What's next",
    "descriptor": "",
    "authors": [
      "Salvatore Cuomo",
      "Vincenzo Schiano di Cola",
      "Fabio Giampaolo",
      "Gianluigi Rozza",
      "Maziar Raissi",
      "Francesco Piccialli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2201.05624"
  },
  {
    "id": "arXiv:2201.08512",
    "title": "Vertical Federated Edge Learning with Distributed Integrated Sensing and  Communication",
    "abstract": "Comments: 5 pages, 7 figures, accepted by IEEE Communications Letters",
    "descriptor": "\nComments: 5 pages, 7 figures, accepted by IEEE Communications Letters\n",
    "authors": [
      "Peixi Liu",
      "Guangxu Zhu",
      "Wei Jiang",
      "Wu Luo",
      "Jie Xu",
      "Shuguang Cui"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2201.08512"
  },
  {
    "id": "arXiv:2201.11218",
    "title": "DNNFuser: Generative Pre-Trained Transformer as a Generalized Mapper for  Layer Fusion in DNN Accelerators",
    "abstract": "DNNFuser: Generative Pre-Trained Transformer as a Generalized Mapper for  Layer Fusion in DNN Accelerators",
    "descriptor": "",
    "authors": [
      "Sheng-Chun Kao",
      "Xiaoyu Huang",
      "Tushar Krishna"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11218"
  },
  {
    "id": "arXiv:2201.12179",
    "title": "Plug & Play Attacks: Towards Robust and Flexible Model Inversion Attacks",
    "abstract": "Comments: Accepted by ICML 2022 as Oral",
    "descriptor": "\nComments: Accepted by ICML 2022 as Oral\n",
    "authors": [
      "Lukas Struppek",
      "Dominik Hintersdorf",
      "Antonio De Almeida Correia",
      "Antonia Adler",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.12179"
  },
  {
    "id": "arXiv:2201.12843",
    "title": "On Recoverability of Graph Neural Network Representations",
    "abstract": "On Recoverability of Graph Neural Network Representations",
    "descriptor": "",
    "authors": [
      "Maxim Fishman",
      "Chaim Baskin",
      "Evgenii Zheltonozhskii",
      "Almog David",
      "Ron Banner",
      "Avi Mendelson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12843"
  },
  {
    "id": "arXiv:2202.00512",
    "title": "Progressive Distillation for Fast Sampling of Diffusion Models",
    "abstract": "Comments: Published as a conference paper at ICLR 2022",
    "descriptor": "\nComments: Published as a conference paper at ICLR 2022\n",
    "authors": [
      "Tim Salimans",
      "Jonathan Ho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.00512"
  },
  {
    "id": "arXiv:2202.00529",
    "title": "Molecular Representation Learning via Heterogeneous Motif Graph Neural  Networks",
    "abstract": "Comments: International Conference on Machine Learning (2022)",
    "descriptor": "\nComments: International Conference on Machine Learning (2022)\n",
    "authors": [
      "Zhaoning Yu",
      "Hongyang Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00529"
  },
  {
    "id": "arXiv:2202.01661",
    "title": "Selection in the Presence of Implicit Bias: The Advantage of  Intersectional Constraints",
    "abstract": "Comments: This is the full version of a paper accepted for presentation in ACM FAccT 2022",
    "descriptor": "\nComments: This is the full version of a paper accepted for presentation in ACM FAccT 2022\n",
    "authors": [
      "Anay Mehrotra",
      "Bary S. R. Pradelski",
      "Nisheeth K. Vishnoi"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Theoretical Economics (econ.TH)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.01661"
  },
  {
    "id": "arXiv:2202.03250",
    "title": "Reweighing auxiliary losses in supervised learning",
    "abstract": "Reweighing auxiliary losses in supervised learning",
    "descriptor": "",
    "authors": [
      "Durga Sivasubramanian",
      "Ayush Maheshwari",
      "Pradeep Shenoy",
      "Prathosh AP",
      "Ganesh Ramakrishnan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03250"
  },
  {
    "id": "arXiv:2202.06187",
    "title": "On the Convergence of Clustered Federated Learning",
    "abstract": "Comments: draft",
    "descriptor": "\nComments: draft\n",
    "authors": [
      "Jie Ma",
      "Guodong Long",
      "Tianyi Zhou",
      "Jing Jiang",
      "Chengqi Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.06187"
  },
  {
    "id": "arXiv:2202.07136",
    "title": "Debiased Self-Training for Semi-Supervised Learning",
    "abstract": "Debiased Self-Training for Semi-Supervised Learning",
    "descriptor": "",
    "authors": [
      "Baixu Chen",
      "Junguang Jiang",
      "Ximei Wang",
      "Pengfei Wan",
      "Jianmin Wang",
      "Mingsheng Long"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07136"
  },
  {
    "id": "arXiv:2202.09653",
    "title": "The Pareto Frontier of Instance-Dependent Guarantees in Multi-Player  Multi-Armed Bandits with no Communication",
    "abstract": "Comments: Accepted for presentation at Conference on Learning Theory (COLT) 2022",
    "descriptor": "\nComments: Accepted for presentation at Conference on Learning Theory (COLT) 2022\n",
    "authors": [
      "Allen Liu",
      "Mark Sellke"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.09653"
  },
  {
    "id": "arXiv:2202.09671",
    "title": "Truncated Diffusion Probabilistic Models",
    "abstract": "Truncated Diffusion Probabilistic Models",
    "descriptor": "",
    "authors": [
      "Huangjie Zheng",
      "Pengcheng He",
      "Weizhu Chen",
      "Mingyuan Zhou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.09671"
  },
  {
    "id": "arXiv:2202.09931",
    "title": "Deconstructing Distributions: A Pointwise Framework of Learning",
    "abstract": "Comments: GK and NG contributed equally. v2: Added Figures 4, 5",
    "descriptor": "\nComments: GK and NG contributed equally. v2: Added Figures 4, 5\n",
    "authors": [
      "Gal Kaplun",
      "Nikhil Ghosh",
      "Saurabh Garg",
      "Boaz Barak",
      "Preetum Nakkiran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.09931"
  },
  {
    "id": "arXiv:2202.11788",
    "title": "Generative modeling via tensor train sketching",
    "abstract": "Generative modeling via tensor train sketching",
    "descriptor": "",
    "authors": [
      "Y. Hur",
      "J. G. Hoskins",
      "M. Lindsey",
      "E.M. Stoudenmire",
      "Y. Khoo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.11788"
  },
  {
    "id": "arXiv:2202.11844",
    "title": "First is Better Than Last for Training Data Influence",
    "abstract": "First is Better Than Last for Training Data Influence",
    "descriptor": "",
    "authors": [
      "Chih-Kuan Yeh",
      "Ankur Taly",
      "Mukund Sundararajan",
      "Frederick Liu",
      "Pradeep Ravikumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.11844"
  },
  {
    "id": "arXiv:2202.12448",
    "title": "Deep neural networks for fine-grained surveillance of overdose mortality",
    "abstract": "Comments: Accepted to appear in the American Journal of Epidemiology",
    "descriptor": "\nComments: Accepted to appear in the American Journal of Epidemiology\n",
    "authors": [
      "Patrick J. Ward",
      "April M. Young",
      "Svetla Slavova",
      "Madison Liford",
      "Lara Daniels",
      "Ripley Lucas",
      "Ramakanth Kavuluru"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.12448"
  },
  {
    "id": "arXiv:2202.13361",
    "title": "Benign Underfitting of Stochastic Gradient Descent",
    "abstract": "Benign Underfitting of Stochastic Gradient Descent",
    "descriptor": "",
    "authors": [
      "Tomer Koren",
      "Roi Livni",
      "Yishay Mansour",
      "Uri Sherman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.13361"
  },
  {
    "id": "arXiv:2203.01601",
    "title": "Syntax-Aware Network for Handwritten Mathematical Expression Recognition",
    "abstract": "Comments: CVPR 2022",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Ye Yuan",
      "Xiao Liu",
      "Wondimu Dikubab",
      "Hui Liu",
      "Zhilong Ji",
      "Zhongqin Wu",
      "Xiang Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.01601"
  },
  {
    "id": "arXiv:2203.01784",
    "title": "Revisiting Click-based Interactive Video Object Segmentation",
    "abstract": "Comments: ICIP 2022. 5 pages = 4 pages of content + 1 page of references",
    "descriptor": "\nComments: ICIP 2022. 5 pages = 4 pages of content + 1 page of references\n",
    "authors": [
      "Stephane Vujasinovic",
      "Sebastian Bullinger",
      "Stefan Becker",
      "Norbert Scherer-Negenborn",
      "Michael Arens",
      "Rainer Stiefelhagen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.01784"
  },
  {
    "id": "arXiv:2203.01928",
    "title": "Label-Free Explainability for Unsupervised Models",
    "abstract": "Comments: Presented in ICML 2022",
    "descriptor": "\nComments: Presented in ICML 2022\n",
    "authors": [
      "Jonathan Crabb\u00e9",
      "Mihaela van der Schaar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.01928"
  },
  {
    "id": "arXiv:2203.02553",
    "title": "Optimal Clock Synchronization with Signatures",
    "abstract": "Optimal Clock Synchronization with Signatures",
    "descriptor": "",
    "authors": [
      "Christoph Lenzen",
      "Julian Loss"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.02553"
  },
  {
    "id": "arXiv:2203.04588",
    "title": "Unsupervised Domain Adaptation across FMCW Radar Configurations Using  Margin Disparity Discrepancy",
    "abstract": "Comments: 5 pages, 2 figures, accepted as a conference paper for EUSIPCO 2022",
    "descriptor": "\nComments: 5 pages, 2 figures, accepted as a conference paper for EUSIPCO 2022\n",
    "authors": [
      "Rodrigo Hernangomez",
      "Igor Bjelakovic",
      "Lorenzo Servadei",
      "Slawomir Stanczak"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.04588"
  },
  {
    "id": "arXiv:2203.04857",
    "title": "Neuro-symbolic Natural Logic with Introspective Revision for Natural  Language Inference",
    "abstract": "Comments: To appear at TACL 2022, MIT Press",
    "descriptor": "\nComments: To appear at TACL 2022, MIT Press\n",
    "authors": [
      "Yufei Feng",
      "Xiaoyu Yang",
      "Xiaodan Zhu",
      "Michael Greenspan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.04857"
  },
  {
    "id": "arXiv:2203.05369",
    "title": "A Contribution-based Device Selection Scheme in Federated Learning",
    "abstract": "Comments: This work has been accepted for publication in IEEE Communications Letters",
    "descriptor": "\nComments: This work has been accepted for publication in IEEE Communications Letters\n",
    "authors": [
      "Shashi Raj Pandey",
      "Lam D. Nguyen",
      "Petar Popovski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.05369"
  },
  {
    "id": "arXiv:2203.05900",
    "title": "Identifiability of Causal-based Fairness Notions: A State of the Art",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2010.09553",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2010.09553\n",
    "authors": [
      "Karima Makhlouf",
      "Sami Zhioua",
      "Catuscia Palamidessi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.05900"
  },
  {
    "id": "arXiv:2203.07574",
    "title": "Time-series image denoising of pressure-sensitive paint data by  projected multivariate singular spectrum analysis",
    "abstract": "Comments: 16 pages, 12 figures",
    "descriptor": "\nComments: 16 pages, 12 figures\n",
    "authors": [
      "Yuya Ohmichi",
      "Kohmi Takahashi",
      "Kazuyuki Nakakita"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2203.07574"
  },
  {
    "id": "arXiv:2203.07941",
    "title": "Reachability In Simple Neural Networks",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2108.13179",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2108.13179\n",
    "authors": [
      "Marco S\u00e4lzer",
      "Martin Lange"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07941"
  },
  {
    "id": "arXiv:2203.08733",
    "title": "The Outliers Theorem Revisited",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:1907.01018",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1907.01018\n",
    "authors": [
      "Samuel Epstein"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2203.08733"
  },
  {
    "id": "arXiv:2203.09308",
    "title": "Few-Shot Learning on Graphs",
    "abstract": "Few-Shot Learning on Graphs",
    "descriptor": "",
    "authors": [
      "Chuxu Zhang",
      "Kaize Ding",
      "Jundong Li",
      "Xiangliang Zhang",
      "Yanfang Ye",
      "Nitesh V. Chawla",
      "Huan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.09308"
  },
  {
    "id": "arXiv:2203.10472",
    "title": "Federated Spatial Reuse Optimization in Next-Generation Decentralized  IEEE 802.11 WLANs",
    "abstract": "Federated Spatial Reuse Optimization in Next-Generation Decentralized  IEEE 802.11 WLANs",
    "descriptor": "",
    "authors": [
      "Francesc Wilhelmi",
      "Jernej Hribar",
      "Selim F. Yilmaz",
      "Emre Ozfatura",
      "Kerem Ozfatura",
      "Ozlem Yildiz",
      "Deniz G\u00fcnd\u00fcz",
      "Hao Chen",
      "Xiaoying Ye",
      "Lizhao You",
      "Yulin Shao",
      "Paolo Dini",
      "Boris Bellalta"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.10472"
  },
  {
    "id": "arXiv:2203.10726",
    "title": "TransFusion: Multi-view Divergent Fusion for Medical Image Segmentation  with Transformers",
    "abstract": "TransFusion: Multi-view Divergent Fusion for Medical Image Segmentation  with Transformers",
    "descriptor": "",
    "authors": [
      "Di Liu",
      "Yunhe Gao",
      "Qilong Zhangli",
      "Ligong Han",
      "Zhaoyang Xia",
      "Xiaoxiao He",
      "Song Wen",
      "Zhennan Yan",
      "Mu Zhou",
      "Dimitris Metaxas"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.10726"
  },
  {
    "id": "arXiv:2203.11187",
    "title": "Relevant CommonSense Subgraphs for \"What if...\" Procedural Reasoning",
    "abstract": "Comments: Accepted by ACL 2022 findings short paper",
    "descriptor": "\nComments: Accepted by ACL 2022 findings short paper\n",
    "authors": [
      "Chen Zheng",
      "Parisa Kordjamshidi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.11187"
  },
  {
    "id": "arXiv:2203.11510",
    "title": "Continuous Optimization for Control of Hybrid Systems with Hysteresis  via Time-Freezing",
    "abstract": "Comments: Accepted for publication at The IEEE Control Systems Letters (L-CSS)",
    "descriptor": "\nComments: Accepted for publication at The IEEE Control Systems Letters (L-CSS)\n",
    "authors": [
      "Armin Nurkanovi\u0107",
      "Moritz Diehl"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.11510"
  },
  {
    "id": "arXiv:2203.11516",
    "title": "NOSNOC: A Software Package for Numerical Optimal Control of Nonsmooth  Systems",
    "abstract": "Comments: Accepted for publication for the IEEE Control Systems Letters (L-CSS)",
    "descriptor": "\nComments: Accepted for publication for the IEEE Control Systems Letters (L-CSS)\n",
    "authors": [
      "Armin Nurkanovi\u0107",
      "Moritz Diehl"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.11516"
  },
  {
    "id": "arXiv:2203.12290",
    "title": "Cell segmentation from telecentric bright-field transmitted light  microscopy images using a Residual Attention U-Net: a case study on HeLa line",
    "abstract": "Comments: 32 pages, 7 figures",
    "descriptor": "\nComments: 32 pages, 7 figures\n",
    "authors": [
      "Ali Ghaznavi",
      "Renata Rychtarikova",
      "Mohammadmehdi Saberioon",
      "Dalibor Stys"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.12290"
  },
  {
    "id": "arXiv:2203.15439",
    "title": "Eventor: An Efficient Event-Based Monocular Multi-View Stereo  Accelerator on FPGA Platform",
    "abstract": "Comments: 6 pages, accepted by DAC 2022",
    "descriptor": "\nComments: 6 pages, accepted by DAC 2022\n",
    "authors": [
      "Mingjun Li",
      "Jianlei Yang",
      "Yingjie Qi",
      "Meng Dong",
      "Yuhao Yang",
      "Runze Liu",
      "Weitao Pan",
      "Bei Yu",
      "Weisheng Zhao"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15439"
  },
  {
    "id": "arXiv:2203.16826",
    "title": "Stability Conditions for Remote State Estimation of Multiple Systems  over Semi-Markov Wireless Fading Channels",
    "abstract": "Comments: Paper accepted by IEEE L-CSS. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: Paper accepted by IEEE L-CSS. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Wanchun Liu",
      "Daniel E. Quevedo",
      "Branka Vucetic",
      "Yonghui Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.16826"
  },
  {
    "id": "arXiv:2204.04322",
    "title": "Iterative Depth-First Search for FOND Planning",
    "abstract": "Iterative Depth-First Search for FOND Planning",
    "descriptor": "",
    "authors": [
      "Ramon Fraga Pereira",
      "Andr\u00e9 G. Pereira",
      "Frederico Messa",
      "Giuseppe De Giacomo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.04322"
  },
  {
    "id": "arXiv:2204.04853",
    "title": "Neural Lagrangian Schr\u00f6dinger Bridge",
    "abstract": "Neural Lagrangian Schr\u00f6dinger Bridge",
    "descriptor": "",
    "authors": [
      "Takeshi Koshizuka",
      "Issei Sato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2204.04853"
  },
  {
    "id": "arXiv:2204.05762",
    "title": "Nanomatrix: Scalable Construction of Crowded Biological Environments",
    "abstract": "Nanomatrix: Scalable Construction of Crowded Biological Environments",
    "descriptor": "",
    "authors": [
      "Ruwayda Alharbi",
      "Ond\u0159ej Strnad",
      "Tobias Klein",
      "Ivan Viola"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2204.05762"
  },
  {
    "id": "arXiv:2204.06397",
    "title": "Trajectory-based Algorithm Selection with Warm-starting",
    "abstract": "Trajectory-based Algorithm Selection with Warm-starting",
    "descriptor": "",
    "authors": [
      "Anja Jankovic",
      "Diederick Vermetten",
      "Ana Kostovska",
      "Jacob de Nobel",
      "Tome Eftimov",
      "Carola Doerr"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2204.06397"
  },
  {
    "id": "arXiv:2204.06828",
    "title": "Deep Vehicle Detection in Satellite Video",
    "abstract": "Deep Vehicle Detection in Satellite Video",
    "descriptor": "",
    "authors": [
      "Roman Pflugfelder",
      "Axel Weissenfeld",
      "Julian Wagner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.06828"
  },
  {
    "id": "arXiv:2204.07492",
    "title": "A Machine Learning Tutorial for Operational Meteorology, Part I:  Traditional Machine Learning",
    "abstract": "A Machine Learning Tutorial for Operational Meteorology, Part I:  Traditional Machine Learning",
    "descriptor": "",
    "authors": [
      "Randy J. Chase",
      "David R. Harrison",
      "Amanda Burke",
      "Gary M. Lackmann",
      "Amy McGovern"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07492"
  },
  {
    "id": "arXiv:2204.12446",
    "title": "Beyond Lipschitz: Sharp Generalization and Excess Risk Bounds for  Full-Batch GD",
    "abstract": "Comments: 33 pages",
    "descriptor": "\nComments: 33 pages\n",
    "authors": [
      "Konstantinos E. Nikolakakis",
      "Farzin Haddadpour",
      "Amin Karbasi",
      "Dionysios S. Kalogerias"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.12446"
  },
  {
    "id": "arXiv:2204.12454",
    "title": "Differentiable Zooming for Multiple Instance Learning on Whole-Slide  Images",
    "abstract": "Comments: Typos corrected; Changed dataset name from INSEC to CRC upon dataset creators' request;",
    "descriptor": "\nComments: Typos corrected; Changed dataset name from INSEC to CRC upon dataset creators' request;\n",
    "authors": [
      "Kevin Thandiackal",
      "Boqi Chen",
      "Pushpak Pati",
      "Guillaume Jaume",
      "Drew F. K. Williamson",
      "Maria Gabrani",
      "Orcun Goksel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.12454"
  },
  {
    "id": "arXiv:2205.01306",
    "title": "CANShield: Signal-based Intrusion Detection for Controller Area Networks",
    "abstract": "Comments: 15 pages, 6 figures, A version of this paper is accepted by escar USA 2022",
    "descriptor": "\nComments: 15 pages, 6 figures, A version of this paper is accepted by escar USA 2022\n",
    "authors": [
      "Md Hasan Shahriar",
      "Yang Xiao",
      "Pablo Moriano",
      "Wenjing Lou",
      "Y. Thomas Hou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01306"
  },
  {
    "id": "arXiv:2205.01703",
    "title": "Improving In-Context Few-Shot Learning via Self-Supervised Training",
    "abstract": "Comments: NAACL 2022",
    "descriptor": "\nComments: NAACL 2022\n",
    "authors": [
      "Mingda Chen",
      "Jingfei Du",
      "Ramakanth Pasunuru",
      "Todor Mihaylov",
      "Srini Iyer",
      "Veselin Stoyanov",
      "Zornitsa Kozareva"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.01703"
  },
  {
    "id": "arXiv:2205.02418",
    "title": "Quasi-SMC based on MPC for a constrained continuous-time nonlinear  system with external disturbances",
    "abstract": "Quasi-SMC based on MPC for a constrained continuous-time nonlinear  system with external disturbances",
    "descriptor": "",
    "authors": [
      "Huan Meng"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.02418"
  },
  {
    "id": "arXiv:2205.02544",
    "title": "The Race to the Vulnerable: Measuring the Log4j Shell Incident",
    "abstract": "Comments: Proc. of Network Traffic Measurement and Analysis Conference (TMA '22), camera ready",
    "descriptor": "\nComments: Proc. of Network Traffic Measurement and Analysis Conference (TMA '22), camera ready\n",
    "authors": [
      "Raphael Hiesgen",
      "Marcin Nawrocki",
      "Thomas C. Schmidt",
      "Matthias W\u00e4hlisch"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.02544"
  },
  {
    "id": "arXiv:2205.03040",
    "title": "Fusion: Efficient and Secure Inference Resilient to Malicious Server and  Curious Clients",
    "abstract": "Comments: 15 pages, 4 figures",
    "descriptor": "\nComments: 15 pages, 4 figures\n",
    "authors": [
      "Caiqin Dong",
      "Jian Weng",
      "Yao Tong",
      "Jia-Nan Liu",
      "Anjia Yang",
      "Yudan Cheng",
      "Yue Zhang",
      "Shun Hu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.03040"
  },
  {
    "id": "arXiv:2205.03860",
    "title": "Zero and R2D2: A Large-scale Chinese Cross-modal Benchmark and A  Vision-Language Framework",
    "abstract": "Zero and R2D2: A Large-scale Chinese Cross-modal Benchmark and A  Vision-Language Framework",
    "descriptor": "",
    "authors": [
      "Chunyu Xie",
      "Heng Cai",
      "Jianfei Song",
      "Jincheng Li",
      "Fanjing Kong",
      "Xiaoyu Wu",
      "Henrique Morimitsu",
      "Lin Yao",
      "Dexin Wang",
      "Dawei Leng",
      "Xiangyang Ji",
      "Yafeng Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.03860"
  },
  {
    "id": "arXiv:2205.04033",
    "title": "A Contraction-constrained Model Predictive Control for Nonlinear  Processes using Disturbance Forecasts",
    "abstract": "Comments: Accepted for presentation at 7th International Symposium on Advanced Control of Industrial Processes (AdCONIP 2022)",
    "descriptor": "\nComments: Accepted for presentation at 7th International Symposium on Advanced Control of Industrial Processes (AdCONIP 2022)\n",
    "authors": [
      "Ryan McCloy",
      "Lai Wei",
      "Jie Bao"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2205.04033"
  },
  {
    "id": "arXiv:2205.04745",
    "title": "PaCHash: Packed and Compressed Hash Tables",
    "abstract": "PaCHash: Packed and Compressed Hash Tables",
    "descriptor": "",
    "authors": [
      "Florian Kurpicz",
      "Hans-Peter Lehmann",
      "Peter Sanders"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2205.04745"
  },
  {
    "id": "arXiv:2205.07536",
    "title": "Reachability Constrained Reinforcement Learning",
    "abstract": "Comments: Accepted by ICML 2022",
    "descriptor": "\nComments: Accepted by ICML 2022\n",
    "authors": [
      "Dongjie Yu",
      "Haitong Ma",
      "Shengbo Eben Li",
      "Jianyu Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.07536"
  },
  {
    "id": "arXiv:2205.07556",
    "title": "An Effective Transformer-based Solution for RSNA Intracranial Hemorrhage  Detection Competition",
    "abstract": "An Effective Transformer-based Solution for RSNA Intracranial Hemorrhage  Detection Competition",
    "descriptor": "",
    "authors": [
      "Fangxin Shang",
      "Siqi Wang",
      "Xiaorong Wang",
      "Yehui Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.07556"
  },
  {
    "id": "arXiv:2205.07572",
    "title": "The Cartesian Grid Active Flux Method with Adaptive Mesh Refinement",
    "abstract": "The Cartesian Grid Active Flux Method with Adaptive Mesh Refinement",
    "descriptor": "",
    "authors": [
      "Donna Calhoun",
      "Erik Chudzik",
      "Christiane Helzel"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.07572"
  },
  {
    "id": "arXiv:2205.07865",
    "title": "Simple Contrastive Graph Clustering",
    "abstract": "Comments: There is an error in the introduction of the loss-pass denoiseing operation. We mistakenly describe the hyper-parameter k in section 3.3",
    "descriptor": "\nComments: There is an error in the introduction of the loss-pass denoiseing operation. We mistakenly describe the hyper-parameter k in section 3.3\n",
    "authors": [
      "Yue Liu",
      "Xihong Yang",
      "Sihang Zhou",
      "Xinwang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.07865"
  },
  {
    "id": "arXiv:2205.08473",
    "title": "ColonFormer: An Efficient Transformer based Method for Colon Polyp  Segmentation",
    "abstract": "ColonFormer: An Efficient Transformer based Method for Colon Polyp  Segmentation",
    "descriptor": "",
    "authors": [
      "Nguyen Thanh Duc",
      "Nguyen Thi Oanh",
      "Nguyen Thi Thuy",
      "Tran Minh Triet",
      "Dinh Viet Sang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.08473"
  },
  {
    "id": "arXiv:2205.09026",
    "title": "VLC Physical Layer Security through RIS-aided Jamming Receiver for 6G  Wireless Networks",
    "abstract": "VLC Physical Layer Security through RIS-aided Jamming Receiver for 6G  Wireless Networks",
    "descriptor": "",
    "authors": [
      "Simone Soderi",
      "Alessandro Brighente",
      "Federico Turrin",
      "Mauro Conti"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.09026"
  },
  {
    "id": "arXiv:2205.09382",
    "title": "BabyNet: Residual Transformer Module for Birth Weight Prediction on  Fetal Ultrasound Video",
    "abstract": "Comments: Early accepted for 25th International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI) 2022, Singapore",
    "descriptor": "\nComments: Early accepted for 25th International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI) 2022, Singapore\n",
    "authors": [
      "Szymon P\u0142otka",
      "Michal K. Grzeszczyk",
      "Robert Brawura-Biskupski-Samaha",
      "Pawe\u0142 Gutaj",
      "Micha\u0142 Lipa",
      "Tomasz Trzci\u0144ski",
      "Arkadiusz Sitek"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09382"
  },
  {
    "id": "arXiv:2205.09786",
    "title": "Subset Node Anomaly Tracking over Large Dynamic Graphs",
    "abstract": "Comments: 9 pages + 2 pages supplement, accepted to 2022 ACM SIGKDD Research Track",
    "descriptor": "\nComments: 9 pages + 2 pages supplement, accepted to 2022 ACM SIGKDD Research Track\n",
    "authors": [
      "Xingzhi Guo",
      "Baojian Zhou",
      "Steven Skiena"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2205.09786"
  },
  {
    "id": "arXiv:2205.10278",
    "title": "A framework for self-supervised MR image reconstruction using  sub-sampling via Noisier2Noise",
    "abstract": "Comments: Submitted to IEEE Computational Imaging",
    "descriptor": "\nComments: Submitted to IEEE Computational Imaging\n",
    "authors": [
      "Charles Millard",
      "Mark Chiew"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.10278"
  },
  {
    "id": "arXiv:2205.11283",
    "title": "SelfReformer: Self-Refined Network with Transformer for Salient Object  Detection",
    "abstract": "SelfReformer: Self-Refined Network with Transformer for Salient Object  Detection",
    "descriptor": "",
    "authors": [
      "Yi Ke Yun",
      "Weisi Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11283"
  },
  {
    "id": "arXiv:2205.13776",
    "title": "PrivacyDates: A Framework for More Privacy-Preserving Timestamp Data  Types",
    "abstract": "Comments: Accepted and presented at the conference GI Sicherheit 2022",
    "descriptor": "\nComments: Accepted and presented at the conference GI Sicherheit 2022\n",
    "authors": [
      "Christian Burkert",
      "Jonathan Balack",
      "Hannes Federrath"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.13776"
  },
  {
    "id": "arXiv:2205.13797",
    "title": "AsyncFedED: Asynchronous Federated Learning with Euclidean Distance  based Adaptive Weight Aggregation",
    "abstract": "AsyncFedED: Asynchronous Federated Learning with Euclidean Distance  based Adaptive Weight Aggregation",
    "descriptor": "",
    "authors": [
      "Qiyuan Wang",
      "Qianqian Yang",
      "Shibo He",
      "Zhiguo Shi",
      "Jiming Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2205.13797"
  },
  {
    "id": "arXiv:2205.14228",
    "title": "Sparse Conditional Hidden Markov Model for Weakly Supervised Named  Entity Recognition",
    "abstract": "Comments: 11 pages, 8 figures, 11 tables",
    "descriptor": "\nComments: 11 pages, 8 figures, 11 tables\n",
    "authors": [
      "Yinghao Li",
      "Le Song",
      "Chao Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.14228"
  },
  {
    "id": "arXiv:2205.14465",
    "title": "ByteComp: Revisiting Gradient Compression in Distributed Training",
    "abstract": "ByteComp: Revisiting Gradient Compression in Distributed Training",
    "descriptor": "",
    "authors": [
      "Zhuang Wang",
      "Haibin Lin",
      "Yibo Zhu",
      "T. S. Eugene Ng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2205.14465"
  },
  {
    "id": "arXiv:2205.14474",
    "title": "DeepRM: Deep Recurrent Matching for 6D Pose Refinement",
    "abstract": "Comments: 6 pages, 2 figures, Submitted to IEEE Robotics and Automation Letters (RA-L)",
    "descriptor": "\nComments: 6 pages, 2 figures, Submitted to IEEE Robotics and Automation Letters (RA-L)\n",
    "authors": [
      "Alexander Avery",
      "Andreas Savakis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.14474"
  },
  {
    "id": "arXiv:2205.14498",
    "title": "Towards a Security Stress-Test for Cloud Configurations",
    "abstract": "Comments: Conference: The IEEE International Conference on Cloud Computing (CLOUD) 2022",
    "descriptor": "\nComments: Conference: The IEEE International Conference on Cloud Computing (CLOUD) 2022\n",
    "authors": [
      "Francesco Minna",
      "Fabio Massacci",
      "Katja Tuma"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.14498"
  },
  {
    "id": "arXiv:2205.14837",
    "title": "Enhancing Sequential Recommendation with Graph Contrastive Learning",
    "abstract": "Comments: 8 pages, 3 figures, Accepted by IJCAI 2022",
    "descriptor": "\nComments: 8 pages, 3 figures, Accepted by IJCAI 2022\n",
    "authors": [
      "Yixin Zhang",
      "Yong Liu",
      "Yonghui Xu",
      "Hao Xiong",
      "Chenyi Lei",
      "Wei He",
      "Lizhen Cui",
      "Chunyan Miao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.14837"
  },
  {
    "id": "arXiv:2205.14839",
    "title": "Adversarial Bandits Robust to $S$-Switch Regret",
    "abstract": "Adversarial Bandits Robust to $S$-Switch Regret",
    "descriptor": "",
    "authors": [
      "Jung-hun Kim",
      "Se-Young Yun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.14839"
  },
  {
    "id": "arXiv:2205.14938",
    "title": "Harnessing spectral representations for subgraph alignment",
    "abstract": "Harnessing spectral representations for subgraph alignment",
    "descriptor": "",
    "authors": [
      "Marco Pegoraro",
      "Riccardo Marin",
      "Arianna Rampini",
      "Simone Melzi",
      "Luca Cosmo",
      "Emanuele Rodol\u00e0"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.14938"
  },
  {
    "id": "arXiv:2205.14964",
    "title": "Effectiveness and Scalability of Fuzzing Techniques in CI/CD Pipelines",
    "abstract": "Comments: 12 pages, 5 figures",
    "descriptor": "\nComments: 12 pages, 5 figures\n",
    "authors": [
      "Thijs Klooster",
      "Fatih Turkmen",
      "Gerben Broenink",
      "Ruben ten Hove",
      "Marcel B\u00f6hme"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.14964"
  },
  {
    "id": "arXiv:2205.15173",
    "title": "Self-Supervised Pre-training of Vision Transformers for Dense Prediction  Tasks",
    "abstract": "Self-Supervised Pre-training of Vision Transformers for Dense Prediction  Tasks",
    "descriptor": "",
    "authors": [
      "Jaonary Rabarisoa",
      "Valentin Belissen",
      "Florian Chabot",
      "Quoc-Cuong Pham"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15173"
  },
  {
    "id": "arXiv:2205.15503",
    "title": "Leveraging Pre-Trained Language Models to Streamline Natural Language  Interaction for Self-Tracking",
    "abstract": "Comments: Accepted to NAACL '22 2nd Workshop on Bridging Human-Computer Interaction and Natural Language Processing. 10 pages including appendix, 2 figures, and 1 table",
    "descriptor": "\nComments: Accepted to NAACL '22 2nd Workshop on Bridging Human-Computer Interaction and Natural Language Processing. 10 pages including appendix, 2 figures, and 1 table\n",
    "authors": [
      "Young-Ho Kim",
      "Sungdong Kim",
      "Minsuk Chang",
      "Sang-Woo Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2205.15503"
  },
  {
    "id": "arXiv:2205.15516",
    "title": "Multi-Scan Multi-Sensor Multi-Object State Estimation",
    "abstract": "Multi-Scan Multi-Sensor Multi-Object State Estimation",
    "descriptor": "",
    "authors": [
      "D. Moratuwage",
      "B.-N. Vo",
      "B.-T. Vo",
      "C. Shim"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2205.15516"
  },
  {
    "id": "arXiv:2205.15704",
    "title": "Mitigating Dataset Bias by Using Per-sample Gradient",
    "abstract": "Comments: 28 pages, 9 figures",
    "descriptor": "\nComments: 28 pages, 9 figures\n",
    "authors": [
      "Sumyeong Ahn",
      "Seongyoon Kim",
      "Se-young Yun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15704"
  },
  {
    "id": "arXiv:2206.00047",
    "title": "Evolving Domain Generalization",
    "abstract": "Evolving Domain Generalization",
    "descriptor": "",
    "authors": [
      "William Wei Wang",
      "Gezheng Xu",
      "Ruizhi Pu",
      "Jiaqi Li",
      "Fan Zhou",
      "Changjian Shui",
      "Charles Ling",
      "Christian Gagn\u00e9",
      "Boyu Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00047"
  },
  {
    "id": "arXiv:2206.00592",
    "title": "Stopping Silent Sneaks: Defending against Malicious Mixes with  Topological Engineering",
    "abstract": "Stopping Silent Sneaks: Defending against Malicious Mixes with  Topological Engineering",
    "descriptor": "",
    "authors": [
      "Xinshu Ma",
      "Florentin Rochet",
      "Tariq Elahi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.00592"
  },
  {
    "id": "arXiv:2206.00707",
    "title": "Collaborative Learning of Distributions under Heterogeneity and  Communication Constraints",
    "abstract": "Collaborative Learning of Distributions under Heterogeneity and  Communication Constraints",
    "descriptor": "",
    "authors": [
      "Xinmeng Huang",
      "Donghwan Lee",
      "Edgar Dobriban",
      "Hamed Hassani"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00707"
  },
  {
    "id": "arXiv:2206.00807",
    "title": "Applied Federated Learning: Architectural Design for Robust and  Efficient Learning in Privacy Aware Settings",
    "abstract": "Applied Federated Learning: Architectural Design for Robust and  Efficient Learning in Privacy Aware Settings",
    "descriptor": "",
    "authors": [
      "Branislav Stojkovic",
      "Jonathan Woodbridge",
      "Zhihan Fang",
      "Jerry Cai",
      "Andrey Petrov",
      "Sathya Iyer",
      "Daoyu Huang",
      "Patrick Yau",
      "Arvind Sastha Kumar",
      "Hitesh Jawa",
      "Anamita Guha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00807"
  },
  {
    "id": "arXiv:2206.00920",
    "title": "Federated Learning with a Sampling Algorithm under Isoperimetry",
    "abstract": "Federated Learning with a Sampling Algorithm under Isoperimetry",
    "descriptor": "",
    "authors": [
      "Lukang Sun",
      "Adil Salim",
      "Peter Richt\u00e1rik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00920"
  },
  {
    "id": "arXiv:2206.00934",
    "title": "Deep neural networks can stably solve high-dimensional, noisy,  non-linear inverse problems",
    "abstract": "Deep neural networks can stably solve high-dimensional, noisy,  non-linear inverse problems",
    "descriptor": "",
    "authors": [
      "Andr\u00e9s Felipe Lerma Pineda",
      "Philipp Christian Petersen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.00934"
  },
  {
    "id": "arXiv:2206.00997",
    "title": "Is Mapping Necessary for Realistic PointGoal Navigation?",
    "abstract": "Comments: Corrected typos in the Abstract",
    "descriptor": "\nComments: Corrected typos in the Abstract\n",
    "authors": [
      "Ruslan Partsey",
      "Erik Wijmans",
      "Naoki Yokoyama",
      "Oles Dobosevych",
      "Dhruv Batra",
      "Oleksandr Maksymets"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.00997"
  },
  {
    "id": "arXiv:2206.01008",
    "title": "Approximate Network Motif Mining Via Graph Learning",
    "abstract": "Approximate Network Motif Mining Via Graph Learning",
    "descriptor": "",
    "authors": [
      "Carlos Oliver",
      "Dexiong Chen",
      "Vincent Mallet",
      "Pericles Philippopoulos",
      "Karsten Borgwardt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.01008"
  },
  {
    "id": "arXiv:2206.01274",
    "title": "Algorithmic Stability of Heavy-Tailed Stochastic Gradient Descent on  Least Squares",
    "abstract": "Comments: 40 pages",
    "descriptor": "\nComments: 40 pages\n",
    "authors": [
      "Anant Raj",
      "Melih Barsbey",
      "Mert G\u00fcrb\u00fczbalaban",
      "Lingjiong Zhu",
      "Umut \u015eim\u015fekli"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01274"
  },
  {
    "id": "arXiv:2206.01332",
    "title": "Optimal Activation Functions for the Random Features Regression Model",
    "abstract": "Optimal Activation Functions for the Random Features Regression Model",
    "descriptor": "",
    "authors": [
      "Jianxin Wang",
      "Jos\u00e9 Bento"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01332"
  },
  {
    "id": "arXiv:2206.01696",
    "title": "Deep Learning Prediction of Severe Health Risks for Pediatric COVID-19  Patients with a Large Feature Set in 2021 BARDA Data Challenge",
    "abstract": "Comments: Acknowledgment updated, minor typos fixed",
    "descriptor": "\nComments: Acknowledgment updated, minor typos fixed\n",
    "authors": [
      "Sajid Mahmud",
      "Elham Soltanikazemi",
      "Frimpong Boadu",
      "Ashwin Dhakal",
      "Jianlin Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01696"
  },
  {
    "id": "arXiv:2206.01878",
    "title": "Remote Collaboration Fuses Fewer Breakthrough Ideas",
    "abstract": "Remote Collaboration Fuses Fewer Breakthrough Ideas",
    "descriptor": "",
    "authors": [
      "Yiling Lin",
      "Carl Benedikt Frey",
      "Lingfei Wu"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "General Economics (econ.GN)"
    ],
    "url": "https://arxiv.org/abs/2206.01878"
  },
  {
    "id": "arXiv:2206.01910",
    "title": "The Spike Gating Flow: A Hierarchical Structure Based Spiking Neural  Network for Online Gesture Recognition",
    "abstract": "The Spike Gating Flow: A Hierarchical Structure Based Spiking Neural  Network for Online Gesture Recognition",
    "descriptor": "",
    "authors": [
      "Zihao Zhao",
      "Yanhong Wang",
      "Qiaosha Zou",
      "Tie Xu",
      "Fangbo Tao",
      "Jiansong Zhang",
      "Xiaoan Wang",
      "C.-J. Richard Shi",
      "Junwen Luo",
      "Yuan Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.01910"
  },
  {
    "id": "arXiv:2206.01992",
    "title": "CAINNFlow: Convolutional block Attention modules and Invertible Neural  Networks Flow for anomaly detection and localization tasks",
    "abstract": "CAINNFlow: Convolutional block Attention modules and Invertible Neural  Networks Flow for anomaly detection and localization tasks",
    "descriptor": "",
    "authors": [
      "Ruiqing Yan",
      "Fan Zhang",
      "Mengyuan Huang",
      "Wu Liu",
      "Dongyu Hu",
      "Jinfeng Li",
      "Qiang Liu",
      "Jingrong Jiang",
      "Qianjin Guo",
      "Linghan Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.01992"
  },
  {
    "id": "arXiv:2206.02211",
    "title": "Variable-rate hierarchical CPC leads to acoustic unit discovery in  speech",
    "abstract": "Comments: Submitted to 36th Conference on Neural Information Processing Systems (NeurIPS 2022)",
    "descriptor": "\nComments: Submitted to 36th Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Santiago Cuervo",
      "Adrian \u0141a\u0144cucki",
      "Ricard Marxer",
      "Pawe\u0142 Rychlikowski",
      "Jan Chorowski"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.02211"
  },
  {
    "id": "arXiv:2206.02249",
    "title": "Rapid Learning of Spatial Representations for Goal-Directed Navigation  Based on a Novel Model of Hippocampal Place Fields",
    "abstract": "Rapid Learning of Spatial Representations for Goal-Directed Navigation  Based on a Novel Model of Hippocampal Place Fields",
    "descriptor": "",
    "authors": [
      "Adedapo Alabi",
      "Dieter Vanderelst",
      "Ali Minai"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.02249"
  },
  {
    "id": "arXiv:2206.02257",
    "title": "Efficient Annotation and Learning for 3D Hand Pose Estimation: A Survey",
    "abstract": "Efficient Annotation and Learning for 3D Hand Pose Estimation: A Survey",
    "descriptor": "",
    "authors": [
      "Takehiko Ohkawa",
      "Ryosuke Furuta",
      "Yoichi Sato"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02257"
  },
  {
    "id": "arXiv:2206.02260",
    "title": "SealID: Saimaa ringed seal re-identification dataset",
    "abstract": "Comments: 15 pages, 9 figures",
    "descriptor": "\nComments: 15 pages, 9 figures\n",
    "authors": [
      "Ekaterina Nepovinnykh",
      "Tuomas Eerola",
      "Vincent Biard",
      "Piia Mutka",
      "Marja Niemi",
      "Heikki K\u00e4lvi\u00e4inen",
      "Mervi Kunnasranta"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2206.02260"
  },
  {
    "id": "arXiv:2206.02336",
    "title": "On the Advance of Making Language Models Better Reasoners",
    "abstract": "On the Advance of Making Language Models Better Reasoners",
    "descriptor": "",
    "authors": [
      "Yifei Li",
      "Zeqi Lin",
      "Shizhuo Zhang",
      "Qiang Fu",
      "Bei Chen",
      "Jian-Guang Lou",
      "Weizhu Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02336"
  },
  {
    "id": "arXiv:2206.02380",
    "title": "Adaptive Rollout Length for Model-Based RL Using Model-Free Deep RL",
    "abstract": "Adaptive Rollout Length for Model-Based RL Using Model-Free Deep RL",
    "descriptor": "",
    "authors": [
      "Abhinav Bhatia",
      "Philip S. Thomas",
      "Shlomo Zilberstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02380"
  },
  {
    "id": "arXiv:2206.02455",
    "title": "Mean Estimation in High-Dimensional Binary Markov Gaussian Mixture  Models",
    "abstract": "Mean Estimation in High-Dimensional Binary Markov Gaussian Mixture  Models",
    "descriptor": "",
    "authors": [
      "Yihan Zhang",
      "Nir Weinberger"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02455"
  },
  {
    "id": "arXiv:2206.02498",
    "title": "NORPPA: NOvel Ringed seal re-identification by Pelage Pattern  Aggregation",
    "abstract": "Comments: 22 pages, 13 figures, 5 tables",
    "descriptor": "\nComments: 22 pages, 13 figures, 5 tables\n",
    "authors": [
      "Ekaterina Nepovinnykh",
      "Ilia Chelak",
      "Tuomas Eerola",
      "Heikki K\u00e4lvi\u00e4inen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02498"
  },
  {
    "id": "arXiv:2206.02512",
    "title": "UTTS: Unsupervised TTS with Conditional Disentangled Sequential  Variational Auto-encoder",
    "abstract": "UTTS: Unsupervised TTS with Conditional Disentangled Sequential  Variational Auto-encoder",
    "descriptor": "",
    "authors": [
      "Jiachen Lian",
      "Chunlei Zhang",
      "Gopala Krishna Anumanchipalli",
      "Dong Yu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2206.02512"
  },
  {
    "id": "arXiv:2206.02525",
    "title": "Dynamic DNNs Meet Runtime Resource Management on Mobile and Embedded  Platforms",
    "abstract": "Comments: Accepted as a presentation at Fourth UK Mobile, Wearable and Ubiquitous Systems Research Symposium (MobiUK 2022)",
    "descriptor": "\nComments: Accepted as a presentation at Fourth UK Mobile, Wearable and Ubiquitous Systems Research Symposium (MobiUK 2022)\n",
    "authors": [
      "Lei Xun",
      "Bashir M. Al-Hashimi",
      "Jonathon Hare",
      "Geoff V. Merrett"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2206.02525"
  },
  {
    "id": "arXiv:2206.02617",
    "title": "Per-Instance Privacy Accounting for Differentially Private Stochastic  Gradient Descent",
    "abstract": "Per-Instance Privacy Accounting for Differentially Private Stochastic  Gradient Descent",
    "descriptor": "",
    "authors": [
      "Da Yu",
      "Gautam Kamath",
      "Janardhan Kulkarni",
      "Tie-Yan Liu",
      "Jian Yin",
      "Huishuai Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.02617"
  },
  {
    "id": "arXiv:2206.02670",
    "title": "Robust Adversarial Attacks Detection based on Explainable Deep  Reinforcement Learning For UAV Guidance and Planning",
    "abstract": "Comments: 13 pages, 20 figures",
    "descriptor": "\nComments: 13 pages, 20 figures\n",
    "authors": [
      "Thomas Hickling",
      "Nabil Aouf",
      "Phillippa Spencer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.02670"
  },
  {
    "id": "arXiv:2206.02761",
    "title": "Dual Decomposition of Convex Optimization Layers for Consistent  Attention in Medical Images",
    "abstract": "Comments: 12 pages, 5 figures. In proceedings of the 39th International Conference on Machine Learning, Baltimore, Maryland, USA, PMLR 162, 2022. Copyright 2022 by the author(s)",
    "descriptor": "\nComments: 12 pages, 5 figures. In proceedings of the 39th International Conference on Machine Learning, Baltimore, Maryland, USA, PMLR 162, 2022. Copyright 2022 by the author(s)\n",
    "authors": [
      "Tom Ron",
      "Michal Weiler-Sagie",
      "Tamir Hazan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02761"
  }
]
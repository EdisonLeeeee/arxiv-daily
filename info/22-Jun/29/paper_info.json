[
  {
    "id": "arXiv:2206.13507",
    "title": "Envelope imbalanced ensemble model with deep sample learning and  local-global structure consistency",
    "abstract": "The class imbalance problem is important and challenging. Ensemble approaches\nare widely used to tackle this problem because of their effectiveness. However,\nexisting ensemble methods are always applied into original samples, while not\nconsidering the structure information among original samples. The limitation\nwill prevent the imbalanced learning from being better. Besides, research shows\nthat the structure information among samples includes local and global\nstructure information. Based on the analysis above, an imbalanced ensemble\nalgorithm with the deep sample pre-envelope network (DSEN) and local-global\nstructure consistency mechanism (LGSCM) is proposed here to solve the\nproblem.This algorithm can guarantee high-quality deep envelope samples for\nconsidering the local manifold and global structures information, which is\nhelpful for imbalance learning. First, the deep sample envelope pre-network\n(DSEN) is designed to mine structure information among samples.Then, the local\nmanifold structure metric (LMSM) and global structure distribution metric\n(GSDM) are designed to construct LGSCM to enhance distribution consistency of\ninterlayer samples. Next, the DSEN and LGSCM are put together to form the final\ndeep sample envelope network (DSEN-LG). After that, base classifiers are\napplied on the layers of deep samples respectively.Finally, the predictive\nresults from base classifiers are fused through bagging ensemble learning\nmechanism. To demonstrate the effectiveness of the proposed method, forty-four\npublic datasets and more than ten representative relevant algorithms are chosen\nfor verification. The experimental results show that the algorithm is\nsignificantly better than other imbalanced ensemble algorithms.",
    "descriptor": "\nComments: 21 pages,5 figures\n",
    "authors": [
      "Fan Li",
      "Xiaoheng Zhang",
      "Yongming Li",
      "Pin Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.13507"
  },
  {
    "id": "arXiv:2206.13508",
    "title": "Data Augmentation techniques in time series domain: A survey and  taxonomy",
    "abstract": "With the latest advances in deep learning generative models, it has not taken\nlong to take advantage of their remarkable performance in the area of time\nseries. Deep neural networks used to work with time series depend heavily on\nthe breadth and consistency of the datasets used in training. These types of\ncharacteristic are not usually abundant in the real world, where they are\nusually limited and often with privacy constraints that must be guaranteed.\nTherefore, an effective way is to increase the number of data using \\gls{da}\ntechniques, either by adding noise or permutations and by generating new\nsynthetic data. It is systematically review the current state-of-the-art in the\narea to provide an overview of all available algorithms and proposes a taxonomy\nof the most relevant researches. The efficiency of the different variants will\nbe evaluated; as a vital part of the process, the different metrics to evaluate\nthe performance and the main problems concerning each model will be analysed.\nThe ultimate goal of this study is to provide a summary of the evolution and\nperformance of areas that produce better results to guide future researchers in\nthis field.",
    "descriptor": "\nComments: 25 pages, 8 figures\n",
    "authors": [
      "Edgar Talavera",
      "Guillermo Iglesias",
      "\u00c1ngel Gonz\u00e1lez-Prieto",
      "Alberto Mozo",
      "Sandra G\u00f3mez-Canaval"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.13508"
  },
  {
    "id": "arXiv:2206.13509",
    "title": "Solution and Fitness Evolution (SAFE): A Study of Multiobjective  Problems",
    "abstract": "We have recently presented SAFE -- Solution And Fitness Evolution -- a\ncommensalistic coevolutionary algorithm that maintains two coevolving\npopulations: a population of candidate solutions and a population of candidate\nobjective functions. We showed that SAFE was successful at evolving solutions\nwithin a robotic maze domain. Herein we present an investigation of SAFE's\nadaptation and application to multiobjective problems, wherein candidate\nobjective functions explore different weightings of each objective. Though\npreliminary, the results suggest that SAFE, and the concept of coevolving\nsolutions and objective functions, can identify a similar set of optimal\nmultiobjective solutions without explicitly employing a Pareto front for\nfitness calculation and parent selection. These findings support our hypothesis\nthat the SAFE algorithm concept can not only solve complex problems, but can\nadapt to the challenge of problems with multiple objectives.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2206.12707\n",
    "authors": [
      "Moshe Sipper",
      "Jason H. Moore",
      "Ryan J. Urbanowicz"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.13509"
  },
  {
    "id": "arXiv:2206.13510",
    "title": "Structural Entropy Guided Graph Hierarchical Pooling",
    "abstract": "Following the success of convolution on non-Euclidean space, the\ncorresponding pooling approaches have also been validated on various tasks\nregarding graphs. However, because of the fixed compression quota and stepwise\npooling design, these hierarchical pooling methods still suffer from local\nstructure damage and suboptimal problem. In this work, inspired by structural\nentropy, we propose a hierarchical pooling approach, SEP, to tackle the two\nissues. Specifically, without assigning the layer-specific compression quota, a\nglobal optimization algorithm is designed to generate the cluster assignment\nmatrices for pooling at once. Then, we present an illustration of the local\nstructure damage from previous methods in the reconstruction of ring and grid\nsynthetic graphs. In addition to SEP, we further design two classification\nmodels, SEP-G and SEP-N for graph classification and node classification,\nrespectively. The results show that SEP outperforms state-of-the-art graph\npooling methods on graph classification benchmarks and obtains superior\nperformance on node classifications.",
    "descriptor": "\nComments: Accepted by ICML 2022\n",
    "authors": [
      "Junran Wu",
      "Xueyuan Chen",
      "Ke Xu",
      "Shangzhe Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.13510"
  },
  {
    "id": "arXiv:2206.13511",
    "title": "Design and control analysis of a deployable clustered hyperbolic  paraboloid cable net",
    "abstract": "This paper presents an analytical and experimental design and deployment\ncontrol analysis of a hyperbolic paraboloid cable net based on clustering\nactuation strategies. First, the dynamics and statics for clustered tensegrity\nstructures (CTS) are given. Then, we propose the topology design of the\ndeployable hyperbolic paraboloid cable net. The deployability of the cable net\nis achieved by using clustered cables. It is shown that the clustered cables\nsignificantly reduce the number of actuators required for control. The\ndeployment trajectory and actuation prestress in the cables are designed to\nensure the tensions are feasible during the deployment process. Then, we\ncompare the deployment analysis's open-loop and closed-loop control strategies.\nFinally, a lab-scale model is constructed to validate the actuation laws. We\ntest the static performance and deployment process of the experimental model.\nResults show that the closed-loop control approach is more stable and smoother\nthan the open-loop one in the deployment process. The approaches developed in\nthis paper can also be used for various deployable tensegrity structures.",
    "descriptor": "\nComments: 20 pages, 24 figures\n",
    "authors": [
      "Shuo Ma",
      "Kai Lu",
      "Muhao Chen",
      "Robert E. Skelton"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.13511"
  },
  {
    "id": "arXiv:2206.13516",
    "title": "Improving Clinical Efficiency and Reducing Medical Errors through  NLP-enabled diagnosis of Health Conditions from Transcription Reports",
    "abstract": "Misdiagnosis rates are one of the leading causes of medical errors in\nhospitals, affecting over 12 million adults across the US. To address the high\nrate of misdiagnosis, this study utilizes 4 NLP-based algorithms to determine\nthe appropriate health condition based on an unstructured transcription report.\nFrom the Logistic Regression, Random Forest, LSTM, and CNNLSTM models, the\nCNN-LSTM model performed the best with an accuracy of 97.89%. We packaged this\nmodel into a authenticated web platform for accessible assistance to\nclinicians. Overall, by standardizing health care diagnosis and structuring\ntranscription reports, our NLP platform drastically improves the clinical\nefficiency and accuracy of hospitals worldwide.",
    "descriptor": "\nComments: All authors contributed equally\n",
    "authors": [
      "Krish Maniar",
      "Shafin Haque",
      "Kabir Ramzan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.13516"
  },
  {
    "id": "arXiv:2206.13517",
    "title": "ProGen2: Exploring the Boundaries of Protein Language Models",
    "abstract": "Attention-based models trained on protein sequences have demonstrated\nincredible success at classification and generation tasks relevant for\nartificial intelligence-driven protein design. However, we lack a sufficient\nunderstanding of how very large-scale models and data play a role in effective\nprotein model development. We introduce a suite of protein language models,\nnamed ProGen2, that are scaled up to 6.4B parameters and trained on different\nsequence datasets drawn from over a billion proteins from genomic, metagenomic,\nand immune repertoire databases. ProGen2 models show state-of-the-art\nperformance in capturing the distribution of observed evolutionary sequences,\ngenerating novel viable sequences, and predicting protein fitness without\nadditional finetuning. As large model sizes and raw numbers of protein\nsequences continue to become more widely accessible, our results suggest that a\ngrowing emphasis needs to be placed on the data distribution provided to a\nprotein sequence model. We release the ProGen2 models and code at\nhttps://github.com/salesforce/progen.",
    "descriptor": "",
    "authors": [
      "Erik Nijkamp",
      "Jeffrey Ruffolo",
      "Eli N. Weinstein",
      "Nikhil Naik",
      "Ali Madani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2206.13517"
  },
  {
    "id": "arXiv:2206.13559",
    "title": "Parameter-Efficient Image-to-Video Transfer Learning",
    "abstract": "Capitalizing on large pre-trained models for various downstream tasks of\ninterest have recently emerged with promising performance. Due to the\never-growing model size, the standard full fine-tuning based task adaptation\nstrategy becomes prohibitively costly in terms of model training and storage.\nThis has led to a new research direction in parameter-efficient transfer\nlearning. However, existing attempts typically focus on downstream tasks from\nthe same modality (e.g., image understanding) of the pre-trained model. This\ncreates a limit because in some specific modalities, (e.g., video\nunderstanding) such a strong pre-trained model with sufficient knowledge is\nless or not available. In this work, we investigate such a novel cross-modality\ntransfer learning setting, namely parameter-efficient image-to-video transfer\nlearning. To solve this problem, we propose a new Spatio-Temporal Adapter\n(ST-Adapter) for parameter-efficient fine-tuning per video task. With a\nbuilt-in spatio-temporal reasoning capability in a compact design, ST-Adapter\nenables a pre-trained image model without temporal knowledge to reason about\ndynamic video content at a small (~8%) per-task parameter cost, requiring\napproximately 20 times fewer updated parameters compared to previous work.\nExtensive experiments on video action recognition tasks show that our\nST-Adapter can match or even outperform the strong full fine-tuning strategy\nand state-of-the-art video models, whilst enjoying the advantage of parameter\nefficiency.",
    "descriptor": "",
    "authors": [
      "Junting Pan",
      "Ziyi Lin",
      "Xiatian Zhu",
      "Jing Shao",
      "Hongsheng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.13559"
  },
  {
    "id": "arXiv:2206.13560",
    "title": "Reflecting on Recurring Failures in IoT Development",
    "abstract": "As IoT systems are given more responsibility and autonomy, they offer greater\nbenefits, but also carry greater risks. We believe this trend invigorates an\nold challenge of software engineering: how to develop high-risk\nsoftware-intensive systems safely and securely under market pressures? As a\nfirst step, we conducted a systematic analysis of recent IoT failures to\nidentify engineering challenges. We collected and analyzed 22 news reports and\nstudied the sources, impacts, and repair strategies of failures in IoT systems.\nWe observed failure trends both within and across application domains. We also\nobserved that failure themes have persisted over time. To alleviate these\ntrends, we outline a research agenda toward a Failure-Aware Software\nDevelopment Life Cycle for IoT development. We propose an encyclopedia of\nfailures and an empirical basis for system postmortems, complemented by\nappropriate automated tools.",
    "descriptor": "\nComments: Under submission at the New Ideas and Emerging Results Track (NIER) at The 37th IEEE/ACM International Conference on Automated Software Engineering (ASE 2022)\n",
    "authors": [
      "Dharun Anandayuvaraj",
      "James C. Davis"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.13560"
  },
  {
    "id": "arXiv:2206.13562",
    "title": "Towards a Failure-Aware SDLC for Internet of Things",
    "abstract": "Internet of Things systems carry substantial engineering risks including\ncatastrophic physical failures. To aid software engineers in developing\nreliable IoT systems, we conducted an experiment to evaluate the influence of\nlearning treatments on design decisions. Specifically, we compared the\ninfluence of a set of design guidelines (current practice) and failure stories\n(proposed learning treatment) on developers' design rationale. We conducted an\nexperiment with 21 computer engineering students using a questionnaire. We\nobserved that both treatments helped subjects reason about criticality as a\npart of their design rationale. However, failure stories had a greater effect\nat enabling subjects to reason about safety as a part of their design\nrationale. We share our results illustrating the effects of a failure-aware\ndesign process and propose new research directions to enable a Failure-Aware\nSoftware Development Life Cycle for IoT development.",
    "descriptor": "\nComments: Under submission at the Ideas, Visions and Reflections Track (IVR) at The 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE 2022)\n",
    "authors": [
      "Dharun Anandayuvaraj",
      "Pujita Thulluri",
      "Justin Figueroa",
      "Harshit Shandilya",
      "James C. Davis"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.13562"
  },
  {
    "id": "arXiv:2206.13577",
    "title": "A View Independent Classification Framework for Yoga Postures",
    "abstract": "Yoga is a globally acclaimed and widely recommended practice for a healthy\nliving. Maintaining correct posture while performing a Yogasana is of utmost\nimportance. In this work, we employ transfer learning from Human Pose\nEstimation models for extracting 136 key-points spread all over the body to\ntrain a Random Forest classifier which is used for estimation of the Yogasanas.\nThe results are evaluated on an in-house collected extensive yoga video\ndatabase of 51 subjects recorded from 4 different camera angles. We propose a 3\nstep scheme for evaluating the generalizability of a Yoga classifier by testing\nit on 1) unseen frames, 2) unseen subjects, and 3) unseen camera angles. We\nargue that for most of the applications, validation accuracies on unseen\nsubjects and unseen camera angles would be most important. We empirically\nanalyze over three public datasets, the advantage of transfer learning and the\npossibilities of target leakage. We further demonstrate that the classification\naccuracies critically depend on the cross validation method employed and can\noften be misleading. To promote further research, we have made key-points\ndataset and code publicly available.",
    "descriptor": "",
    "authors": [
      "Mustafa Chasmai",
      "Nirjhar Das",
      "Aman Bhardwaj",
      "Rahul Garg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.13577"
  },
  {
    "id": "arXiv:2206.13585",
    "title": "Heterogeneous mixtures of dictionary functions to approximate subspace  invariance in Koopman operators",
    "abstract": "Koopman operators model nonlinear dynamics as a linear dynamic system acting\non a nonlinear function as the state. This nonstandard state is often called a\nKoopman observable and is usually approximated numerically by a superposition\nof functions drawn from a \\textit{dictionary}. A widely used algorithm, is\n\\textit{Extended Dynamic Mode Decomposition}, where the dictionary functions\nare drawn from a fixed, homogeneous class of functions. Recently, deep learning\ncombined with EDMD has been used to learn novel dictionary functions in an\nalgorithm called deep dynamic mode decomposition (deepDMD). The learned\nrepresentation both (1) accurately models and (2) scales well with the\ndimension of the original nonlinear system. In this paper we analyze the\nlearned dictionaries from deepDMD and explore the theoretical basis for their\nstrong performance. We discover a novel class of dictionary functions to\napproximate Koopman observables. Error analysis of these dictionary functions\nshow they satisfy a property of subspace approximation, which we define as\nuniform finite approximate closure. We discover that structured mixing of\nheterogeneous dictionary functions drawn from different classes of nonlinear\nfunctions achieve the same accuracy and dimensional scaling as deepDMD. This\nmixed dictionary does so with an order of magnitude reduction in parameters,\nwhile maintaining geometric interpretability. Our results provide a hypothesis\nto explain the success of deep neural networks in learning numerical\napproximations to Koopman operators.",
    "descriptor": "\nComments: 14 pages, 7 figures, journal paper\n",
    "authors": [
      "Charles A. Johnson",
      "Shara Balakrishnan",
      "Enoch Yeung"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.13585"
  },
  {
    "id": "arXiv:2206.13591",
    "title": "Reduced Optimal Power Flow Using Graph Neural Network",
    "abstract": "OPF problems are formulated and solved for power system operations,\nespecially for determining generation dispatch points in real-time. For large\nand complex power system networks with large numbers of variables and\nconstraints, finding the optimal solution for real-time OPF in a timely manner\nrequires a massive amount of computing power. This paper presents a new method\nto reduce the number of constraints in the original OPF problem using a graph\nneural network (GNN). GNN is an innovative machine learning model that utilizes\nfeatures from nodes, edges, and network topology to maximize its performance.\nIn this paper, we proposed a GNN model to predict which lines would be heavily\nloaded or congested with given load profiles and generation capacities. Only\nthese critical lines will be monitored in an OPF problem, creating a reduced\nOPF (ROPF) problem. Significant saving in computing time is expected from the\nproposed ROPF model. A comprehensive analysis of predictions from the GNN model\nwas also made. It is concluded that the application of GNN for ROPF is able to\nreduce computing time while retaining solution quality.",
    "descriptor": "\nComments: 6 pages, 16 figures, 3 tables, Submitted (under review) to 54th North American Power Symposium (NAPS 2022)\n",
    "authors": [
      "Thuan Pham",
      "Xingpeng Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.13591"
  },
  {
    "id": "arXiv:2206.13594",
    "title": "Cyber Network Resilience against Self-Propagating Malware Attacks",
    "abstract": "Self-propagating malware (SPM) has led to huge financial losses, major data\nbreaches, and widespread service disruptions in recent years. In this paper, we\nexplore the problem of developing cyber resilient systems capable of mitigating\nthe spread of SPM attacks. We begin with an in-depth study of a well-known\nself-propagating malware, WannaCry, and present a compartmental model called\nSIIDR that accurately captures the behavior observed in real-world attack\ntraces. Next, we investigate ten cyber defense techniques, including existing\nedge and node hardening strategies, as well as newly developed methods based on\nreconfiguring network communication (NodeSplit) and isolating communities. We\nevaluate all defense strategies in detail using six real-world communication\ngraphs collected from a large retail network and compare their performance\nacross a wide range of attacks and network topologies. We show that several of\nthese defenses are able to efficiently reduce the spread of SPM attacks modeled\nwith SIIDR. For instance, given a strong attack that infects 97% of nodes when\nno defense is employed, strategically securing a small number of nodes (0.08%)\nreduces the infection footprint in one of the networks down to 1%.",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Alesia Chernikova",
      "Nicol\u00f2 Gozzi",
      "Simona Boboila",
      "Priyanka Angadi",
      "John Loughner",
      "Matthew Wilden",
      "Nicola Perra",
      "Tina Eliassi-Rad",
      "Alina Oprea"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Dynamical Systems (math.DS)",
      "Spectral Theory (math.SP)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2206.13594"
  },
  {
    "id": "arXiv:2206.13597",
    "title": "NeuRIS: Neural Reconstruction of Indoor Scenes Using Normal Priors",
    "abstract": "Reconstructing 3D indoor scenes from 2D images is an important task in many\ncomputer vision and graphics applications. A main challenge in this task is\nthat large texture-less areas in typical indoor scenes make existing methods\nstruggle to produce satisfactory reconstruction results. We propose a new\nmethod, named NeuRIS, for high quality reconstruction of indoor scenes. The key\nidea of NeuRIS is to integrate estimated normal of indoor scenes as a prior in\na neural rendering framework for reconstructing large texture-less shapes and,\nimportantly, to do this in an adaptive manner to also enable the reconstruction\nof irregular shapes with fine details. Specifically, we evaluate the\nfaithfulness of the normal priors on-the-fly by checking the multi-view\nconsistency of reconstruction during the optimization process. Only the normal\npriors accepted as faithful will be utilized for 3D reconstruction, which\ntypically happens in the regions of smooth shapes possibly with weak texture.\nHowever, for those regions with small objects or thin structures, for which the\nnormal priors are usually unreliable, we will only rely on visual features of\nthe input images, since such regions typically contain relatively rich visual\nfeatures (e.g., shade changes and boundary contours). Extensive experiments\nshow that NeuRIS significantly outperforms the state-of-the-art methods in\nterms of reconstruction quality.",
    "descriptor": "",
    "authors": [
      "Jiepeng Wang",
      "Peng Wang",
      "Xiaoxiao Long",
      "Christian Theobalt",
      "Taku Komura",
      "Lingjie Liu",
      "Wenping Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.13597"
  },
  {
    "id": "arXiv:2206.13599",
    "title": "Nowhere to Hide: Detecting Obfuscated Fingerprinting Scripts",
    "abstract": "As the web moves away from stateful tracking, browser fingerprinting is\nbecoming more prevalent. Unfortunately, existing approaches to detect browser\nfingerprinting do not take into account potential evasion tactics such as code\nobfuscation. To address this gap, we investigate the robustness of a\nstate-of-the-art fingerprinting detection approach against various\noff-the-shelf obfuscation tools. Overall, we find that the combination of\nstatic and dynamic analysis is robust against different types of obfuscation.\nWhile some obfuscators are able to induce false negatives in static analysis,\ndynamic analysis is still able detect these cases. Since obfuscation does not\ninduce significant false positives, the combination of static and dynamic\nanalysis is still able to accurately detect obfuscated fingerprinting scripts.",
    "descriptor": "",
    "authors": [
      "Ray Ngan",
      "Surya Konkimalla",
      "Zubair Shafiq"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.13599"
  },
  {
    "id": "arXiv:2206.13601",
    "title": "Efficient Deep Learning Using Non-Volatile Memory Technology",
    "abstract": "Embedded machine learning (ML) systems have now become the dominant platform\nfor deploying ML serving tasks and are projected to become of equal importance\nfor training ML models. With this comes the challenge of overall efficient\ndeployment, in particular low power and high throughput implementations, under\nstringent memory constraints. In this context, non-volatile memory (NVM)\ntechnologies such as STT-MRAM and SOT-MRAM have significant advantages compared\nto conventional SRAM due to their non-volatility, higher cell density, and\nscalability features. While prior work has investigated several architectural\nimplications of NVM for generic applications, in this work we present\nDeepNVM++, a comprehensive framework to characterize, model, and analyze\nNVM-based caches in GPU architectures for deep learning (DL) applications by\ncombining technology-specific circuit-level models and the actual memory\nbehavior of various DL workloads. DeepNVM++ relies on iso-capacity and iso-area\nperformance and energy models for last-level caches implemented using\nconventional SRAM and emerging STT-MRAM and SOT-MRAM technologies. In the\niso-capacity case, STT-MRAM and SOT-MRAM provide up to 3.8x and 4.7x\nenergy-delay product (EDP) reduction and 2.4x and 2.8x area reduction compared\nto conventional SRAM, respectively. Under iso-area assumptions, STT-MRAM and\nSOT-MRAM provide up to 2.2x and 2.4x EDP reduction and accommodate 2.3x and\n3.3x cache capacity when compared to SRAM, respectively. We also perform a\nscalability analysis and show that STT-MRAM and SOT-MRAM achieve orders of\nmagnitude EDP reduction when compared to SRAM for large cache capacities.\nDeepNVM++ is demonstrated on STT-/SOT-MRAM technologies and can be used for the\ncharacterization, modeling, and analysis of any NVM technology for last-level\ncaches in GPUs for DL applications.",
    "descriptor": "\nComments: This article will appear as a book chapter in the book titled \"Embedded Machine Learning for Cyber-Physical, IoT, and Edge Computing\". arXiv admin note: substantial text overlap with arXiv:2012.04559\n",
    "authors": [
      "Ahmet Inci",
      "Mehmet Meric Isgenc",
      "Diana Marculescu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.13601"
  },
  {
    "id": "arXiv:2206.13602",
    "title": "Molecular Geometry Pretraining with SE(3)-Invariant Denoising Distance  Matching",
    "abstract": "Pretraining molecular representations is critical in a variety of\napplications in drug and material discovery due to the limited number of\nlabeled molecules, yet most of existing work focuses on pretraining on 2D\nmolecular graphs. The power of pretraining on 3D geometric structures, however,\nhas been less explored, owning to the difficulty of finding a sufficient proxy\ntask to empower the pretraining to effectively extract essential features from\nthe geometric structures. Motivated by the dynamic nature of 3D molecules,\nwhere the continuous motion of a molecule in the 3D Euclidean space forms a\nsmooth potential energy surface, we propose a 3D coordinate denoising\npretraining framework to model such an energy landscape. Leveraging a\nSE(3)-invariant score matching method, we propose SE(3)-DDM where the\ncoordinate denoising proxy task is effectively boiled down to the denoising of\nthe pairwise atomic distances in a molecule. Our comprehensive experiments\nconfirm the effectiveness and robustness of our proposed method.",
    "descriptor": "",
    "authors": [
      "Shengchao Liu",
      "Hongyu Guo",
      "Jian Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.13602"
  },
  {
    "id": "arXiv:2206.13603",
    "title": "BeamsNet: A data-driven Approach Enhancing Doppler Velocity Log  Measurements for Autonomous Underwater Vehicle Navigation",
    "abstract": "Autonomous underwater vehicles (AUV) perform various applications such as\nseafloor mapping and underwater structure health monitoring. Commonly, an\ninertial navigation system aided by a Doppler velocity log (DVL) is used to\nprovide the vehicle's navigation solution. In such fusion, the DVL provides the\nvelocity vector of the AUV, which determines the navigation solution's accuracy\nand helps estimate the navigation states. This paper proposes BeamsNet, an\nend-to-end deep learning framework to regress the estimated DVL velocity vector\nthat improves the accuracy of the velocity vector estimate, and could replace\nthe model-based approach. Two versions of BeamsNet, differing in their input to\nthe network, are suggested. The first uses the current DVL beam measurements\nand inertial sensors data, while the other utilizes only DVL data, taking the\ncurrent and past DVL measurements for the regression process. Both simulation\nand sea experiments were made to validate the proposed learning approach\nrelative to the model-based approach. Sea experiments were made with the Snapir\nAUV in the Mediterranean Sea, collecting approximately four hours of DVL and\ninertial sensor data. Our results show that the proposed approach achieved an\nimprovement of more than 60% in estimating the DVL velocity vector.",
    "descriptor": "",
    "authors": [
      "Nadav Cohen",
      "Itzik Klein"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.13603"
  },
  {
    "id": "arXiv:2206.13606",
    "title": "Online Resource Allocation under Horizon Uncertainty",
    "abstract": "We study stochastic online resource allocation: a decision maker needs to\nallocate limited resources to stochastically-generated sequentially-arriving\nrequests in order to maximize reward. Motivated by practice, we consider a\ndata-driven setting in which requests are drawn independently from a\ndistribution that is unknown to the decision maker. Online resource allocation\nand its special cases have been studied extensively in the past, but these\nprevious results crucially and universally rely on a practically-untenable\nassumption: the total number of requests (the horizon) is known to the decision\nmaker in advance. In many applications, such as revenue management and online\nadvertising, the number of requests can vary widely because of fluctuations in\ndemand or user traffic intensity. In this work, we develop online algorithms\nthat are robust to horizon uncertainty. In sharp contrast to the known-horizon\nsetting, we show that no algorithm can achieve a constant asymptotic\ncompetitive ratio that is independent of the horizon uncertainty. We then\nintroduce a novel algorithm that combines dual mirror descent with a\ncarefully-chosen target consumption sequence and prove that it achieves a\nbounded competitive ratio. Our algorithm is near-optimal in the sense that its\ncompetitive ratio attains the optimal rate of growth when the horizon\nuncertainty grows large.",
    "descriptor": "",
    "authors": [
      "Santiago Balseiro",
      "Christian Kroer",
      "Rachitesh Kumar"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.13606"
  },
  {
    "id": "arXiv:2206.13607",
    "title": "Improved Text Classification via Test-Time Augmentation",
    "abstract": "Test-time augmentation -- the aggregation of predictions across transformed\nexamples of test inputs -- is an established technique to improve the\nperformance of image classification models. Importantly, TTA can be used to\nimprove model performance post-hoc, without additional training. Although\ntest-time augmentation (TTA) can be applied to any data modality, it has seen\nlimited adoption in NLP due in part to the difficulty of identifying\nlabel-preserving transformations. In this paper, we present augmentation\npolicies that yield significant accuracy improvements with language models. A\nkey finding is that augmentation policy design -- for instance, the number of\nsamples generated from a single, non-deterministic augmentation -- has a\nconsiderable impact on the benefit of TTA. Experiments across a binary\nclassification task and dataset show that test-time augmentation can deliver\nconsistent improvements over current state-of-the-art approaches.",
    "descriptor": "",
    "authors": [
      "Helen Lu",
      "Divya Shanmugam",
      "Harini Suresh",
      "John Guttag"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.13607"
  },
  {
    "id": "arXiv:2206.13608",
    "title": "Reducing Annotation Need in Self-Explanatory Models for Lung Nodule  Diagnosis",
    "abstract": "Feature-based self-explanatory methods explain their classification in terms\nof human-understandable features. In the medical imaging community, this\nsemantic matching of clinical knowledge adds significantly to the\ntrustworthiness of the AI. However, the cost of additional annotation of\nfeatures remains a pressing issue. We address this problem by proposing\ncRedAnno, a data-/annotation-efficient self-explanatory approach for lung\nnodule diagnosis. cRedAnno considerably reduces the annotation need by\nintroducing self-supervised contrastive learning to alleviate the burden of\nlearning most parameters from annotation, replacing end-to-end training with\ntwo-stage training. When training with hundreds of nodule samples and only 1%\nof their annotations, cRedAnno achieves competitive accuracy in predicting\nmalignancy, meanwhile significantly surpassing most previous works in\npredicting nodule attributes. Visualisation of the learned space further\nindicates that the correlation between the clustering of malignancy and nodule\nattributes coincides with clinical knowledge. Our complete code is open-source\navailable: https://github.com/ludles/credanno.",
    "descriptor": "\nComments: 10 pages, 4 figures, 2 tables\n",
    "authors": [
      "Jiahao Lu",
      "Chong Yin",
      "Oswin Krause",
      "Kenny Erleben",
      "Michael Bachmann Nielsen",
      "Sune Darkner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.13608"
  },
  {
    "id": "arXiv:2206.13610",
    "title": "Quantitative and Metric Rewriting: Abstract, Non-Expansive, and Graded  Systems",
    "abstract": "We introduce a general theory of quantitative and metric rewriting systems,\nnamely systems with a rewriting relation enriched over quantales modelling\nabstract quantities. We develop theories of abstract and term-based systems,\nrefining cornerstone results of rewriting theory (such as Newman's Lemma,\nChurch-Rosser Theorem, and critical pair-like lemmas) to a metric and\nquantitative setting. To avoid distance trivialisation and lack of confluence\nissues, we introduce non-expansive, linear term rewriting systems, and then\ngeneralise the latter to the novel class of graded term rewriting systems.\nThese systems make quantitative rewriting modal and context-sensitive, this\nendowing rewriting with coeffectful behaviours. We apply the theory developed\nto several examples coming from the fields of quantitative algebras,\nprogramming language semantics, and algorithms.",
    "descriptor": "",
    "authors": [
      "Francesco Gavazzo",
      "Cecilia Di Florio"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.13610"
  },
  {
    "id": "arXiv:2206.13611",
    "title": "ClearBuds: Wireless Binaural Earbuds for Learning-Based Speech  Enhancement",
    "abstract": "We present ClearBuds, the first hardware and software system that utilizes a\nneural network to enhance speech streamed from two wireless earbuds. Real-time\nspeech enhancement for wireless earbuds requires high-quality sound separation\nand background cancellation, operating in real-time and on a mobile phone.\nClear-Buds bridges state-of-the-art deep learning for blind audio source\nseparation and in-ear mobile systems by making two key technical contributions:\n1) a new wireless earbud design capable of operating as a synchronized,\nbinaural microphone array, and 2) a lightweight dual-channel speech enhancement\nneural network that runs on a mobile device. Our neural network has a novel\ncascaded architecture that combines a time-domain conventional neural network\nwith a spectrogram-based frequency masking neural network to reduce the\nartifacts in the audio output. Results show that our wireless earbuds achieve a\nsynchronization error less than 64 microseconds and our network has a runtime\nof 21.4 milliseconds on an accompanying mobile phone. In-the-wild evaluation\nwith eight users in previously unseen indoor and outdoor multipath scenarios\ndemonstrates that our neural network generalizes to learn both spatial and\nacoustic cues to perform noise suppression and background speech removal. In a\nuser-study with 37 participants who spent over 15.4 hours rating 1041 audio\nsamples collected in-the-wild, our system achieves improved mean opinion score\nand background noise suppression.\nProject page with demos: https://clearbuds.cs.washington.edu",
    "descriptor": "\nComments: 12 pages, Published in Mobisys 2022\n",
    "authors": [
      "Ishan Chatterjee",
      "Maruchi Kim",
      "Vivek Jayaram",
      "Shyamnath Gollakota",
      "Ira Kemelmacher-Shlizerman",
      "Shwetak Patel",
      "Steven M. Seitz"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.13611"
  },
  {
    "id": "arXiv:2206.13614",
    "title": "Measuring and Clustering Network Attackers using Medium-Interaction  Honeypots",
    "abstract": "Network honeypots are often used by information security teams to measure the\nthreat landscape in order to secure their networks. With the advancement of\nhoneypot development, today's medium-interaction honeypots provide a way for\nsecurity teams and researchers to deploy these active defense tools that\nrequire little maintenance on a variety of protocols. In this work, we deploy\nsuch honeypots on five different protocols on the public Internet and study the\nintent and sophistication of the attacks we observe. We then use the\ninformation gained to develop a clustering approach that identifies\ncorrelations in attacker behavior to discover IPs that are highly likely to be\ncontrolled by a single operator, illustrating the advantage of using these\nhoneypots for data collection.",
    "descriptor": "\nComments: In Proceedings of the 7th IEEE EuroS&P Workshop on Traffic Measurements for Cybersecurity (WTMC 2022)\n",
    "authors": [
      "Zain Shamsi",
      "Daniel Zhang",
      "Daehyun Kyoung",
      "Alex Liu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.13614"
  },
  {
    "id": "arXiv:2206.13619",
    "title": "DeepPERF: A Deep Learning-Based Approach For Improving Software  Performance",
    "abstract": "Improving software performance is an important yet challenging part of the\nsoftware development cycle. Today, the majority of performance inefficiencies\nare identified and patched by performance experts. Recent advancements in deep\nlearning approaches and the wide-spread availability of open source data\ncreates a great opportunity to automate the identification and patching of\nperformance problems. In this paper, we present DeepPERF, a transformer-based\napproach to suggest performance improvements for C# applications. We pretrain\nDeepPERF on English and Source code corpora and followed by finetuning for the\ntask of generating performance improvement patches for C# applications. Our\nevaluation shows that our model can generate the same performance improvement\nsuggestion as the developer fix in ~53% of the cases, getting ~34% of them\nverbatim in our expert-verified dataset of performance changes made by C#\ndevelopers. Additionally, we evaluate DeepPERF on 50 open source C#\nrepositories on GitHub using both benchmark and unit tests and find that our\nmodel is able to suggest valid performance improvements that can improve both\nCPU usage and Memory allocations. So far we've submitted 19 pull-requests with\n28 different performance optimizations and 11 of these PRs have been approved\nby the project owners.",
    "descriptor": "",
    "authors": [
      "Spandan Garg",
      "Roshanak Zilouchian Moghaddam",
      "Colin B. Clement",
      "Neel Sundaresan",
      "Chen Wu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2206.13619"
  },
  {
    "id": "arXiv:2206.13623",
    "title": "Learning Controllable 3D Level Generators",
    "abstract": "Procedural Content Generation via Reinforcement Learning (PCGRL) foregoes the\nneed for large human-authored data-sets and allows agents to train explicitly\non functional constraints, using computable, user-defined measures of quality\ninstead of target output. We explore the application of PCGRL to 3D domains, in\nwhich content-generation tasks naturally have greater complexity and potential\npertinence to real-world applications. Here, we introduce several PCGRL tasks\nfor the 3D domain, Minecraft (Mojang Studios, 2009). These tasks will challenge\nRL-based generators using affordances often found in 3D environments, such as\njumping, multiple dimensional movement, and gravity. We train an agent to\noptimize each of these tasks to explore the capabilities of previous research\nin PCGRL. This agent is able to generate relatively complex and diverse levels,\nand generalize to random initial states and control targets. Controllability\ntests in the presented tasks demonstrate their utility to analyze success and\nfailure for 3D generators.",
    "descriptor": "\nComments: 9 pages, 9 figures\n",
    "authors": [
      "Zehua Jiang",
      "Sam Earle",
      "Michael C. Green",
      "Julian Togelius"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.13623"
  },
  {
    "id": "arXiv:2206.13624",
    "title": "Augmentation-Based Preconditioners for Saddle-Point Systems with  Singular Leading Blocks",
    "abstract": "We consider the iterative solution of symmetric saddle-point matrices with a\nsingular leading block. We develop a new ideal positive definite block diagonal\npreconditioner that yields a preconditioned operator with four distinct\neigenvalues. We offer a few techniques for making the preconditioner practical,\nand illustrate the effectiveness of our approach with numerical experiments.",
    "descriptor": "",
    "authors": [
      "Susanne Bradley",
      "Chen Greif"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.13624"
  },
  {
    "id": "arXiv:2206.13626",
    "title": "Patch Selection for Melanoma Classification",
    "abstract": "In medical image processing, the most important information is often located\non small parts of the image. Patch-based approaches aim at using only the most\nrelevant parts of the image. Finding ways to automatically select the patches\nis a challenge. In this paper, we investigate two criteria to choose patches:\nentropy and a spectral similarity criterion. We perform experiments at\ndifferent levels of patch size. We train a Convolutional Neural Network on the\nsubsets of patches and analyze the training time. We find that, in addition to\nrequiring less preprocessing time, the classifiers trained on the datasets of\npatches selected based on entropy converge faster than on those selected based\non the spectral similarity criterion and, furthermore, lead to higher accuracy.\nMoreover, patches of high entropy lead to faster convergence and better\naccuracy than patches of low entropy.",
    "descriptor": "",
    "authors": [
      "Guillaume Lachaud",
      "Patricia Conde-Cespedes",
      "Maria Trocan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.13626"
  },
  {
    "id": "arXiv:2206.13627",
    "title": "Learning constitutive models from microstructural simulations via a  non-intrusive reduced basis method: Extension to geometrical  parameterizations",
    "abstract": "Understanding structure-property relations is essential to optimally design\nmaterials for specific applications. Two-scale simulations are often employed\nto analyze the effect of the microstructure on a component's macroscopic\nproperties. However, they are typically computationally expensive and\ninfeasible in multi-query contexts such as optimization and material design. To\nmake such analyses amenable, the microscopic simulations can be replaced by\nsurrogate models that must be able to handle a wide range of microstructural\nparameters. This work focuses on extending the methodology of a previous work,\nwhere an accurate surrogate model was constructed for microstructures under\nvarying loading and material parameters using proper orthogonal decomposition\nand Gaussian process regression, to treat geometrical parameters. To this end,\na method that transforms different geometries onto a parent domain is\npresented. We propose to solve an auxiliary problem based on linear elasticity\nto obtain the geometrical transformations. Using these transformations,\ncombined with the nonlinear microscopic problem, we derive a fast-to-evaluate\nsurrogate model with the following key features: (1) the predictions of the\neffective quantities are independent of the auxiliary problem, (2) the\npredicted stress fields fulfill the microscopic balance laws and are periodic,\n(3) the method is non-intrusive, (4) the stress field for all geometries can be\nrecovered, and (5) the sensitivities are available and can be readily used for\noptimization and material design. The proposed methodology is tested on several\ncomposite microstructures, where rotations and large variations in the shape of\ninclusions are considered. Finally, a two-scale example is shown, where the\nsurrogate model achieves a high accuracy and significant speed up,\ndemonstrating its potential in two-scale shape optimization and material design\nproblems.",
    "descriptor": "",
    "authors": [
      "Theron Guo",
      "Francesco A. B. Silva",
      "Ond\u0159ej Roko\u0161",
      "Karen Veroy"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2206.13627"
  },
  {
    "id": "arXiv:2206.13628",
    "title": "Multi-scale Network with Attentional Multi-resolution Fusion for Point  Cloud Semantic Segmentation",
    "abstract": "In this paper, we present a comprehensive point cloud semantic segmentation\nnetwork that aggregates both local and global multi-scale information. First,\nwe propose an Angle Correlation Point Convolution (ACPConv) module to\neffectively learn the local shapes of points. Second, based upon ACPConv, we\nintroduce a local multi-scale split (MSS) block that hierarchically connects\nfeatures within one single block and gradually enlarges the receptive field\nwhich is beneficial for exploiting the local context. Third, inspired by HRNet\nwhich has excellent performance on 2D image vision tasks, we build an HRNet\ncustomized for point cloud to learn global multi-scale context. Lastly, we\nintroduce a point-wise attention fusion approach that fuses multi-resolution\npredictions and further improves point cloud semantic segmentation performance.\nOur experimental results and ablations on several benchmark datasets show that\nour proposed method is effective and able to achieve state-of-the-art\nperformances compared to existing methods.",
    "descriptor": "\nComments: ICPR 2022, poster\n",
    "authors": [
      "Yuyan Li",
      "Ye Duan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.13628"
  },
  {
    "id": "arXiv:2206.13630",
    "title": "Toward an ImageNet Library of Functions for Global Optimization  Benchmarking",
    "abstract": "Knowledge of search-landscape features of BlackBox Optimization (BBO)\nproblems offers valuable information in light of the Algorithm Selection and/or\nConfiguration problems. Exploratory Landscape Analysis (ELA) models have gained\nsuccess in identifying predefined human-derived features and in facilitating\nportfolio selectors to address those challenges. Unlike ELA approaches, the\ncurrent study proposes to transform the identification problem into an image\nrecognition problem, with a potential to detect conception-free, machine-driven\nlandscape features. To this end, we introduce the notion of Landscape Images,\nwhich enables us to generate imagery instances per a benchmark function, and\nthen target the classification challenge over a diverse generalized dataset of\nfunctions. We address it as a supervised multi-class image recognition problem\nand apply basic artificial neural network models to solve it. The efficacy of\nour approach is numerically validated on the noise free BBOB and IOHprofiler\nbenchmarking suites. This evident successful learning is another step toward\nautomated feature extraction and local structure deduction of BBO problems. By\nusing this definition of landscape images, and by capitalizing on existing\ncapabilities of image recognition algorithms, we foresee the construction of an\nImageNet-like library of functions for training generalized detectors that rely\non machine-driven features.",
    "descriptor": "",
    "authors": [
      "Boris Yazmir",
      "Ofer M. Shir"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.13630"
  },
  {
    "id": "arXiv:2206.13631",
    "title": "Learning Semantics-Aware Locomotion Skills from Human Demonstration",
    "abstract": "The semantics of the environment, such as the terrain type and property,\nreveals important information for legged robots to adjust their behaviors. In\nthis work, we present a framework that learns semantics-aware locomotion skills\nfrom perception for quadrupedal robots, such that the robot can traverse\nthrough complex offroad terrains with appropriate speeds and gaits using\nperception information. Due to the lack of high-fidelity outdoor simulation,\nour framework needs to be trained directly in the real world, which brings\nunique challenges in data efficiency and safety. To ensure sample efficiency,\nwe pre-train the perception model with an off-road driving dataset. To avoid\nthe risks of real-world policy exploration, we leverage human demonstration to\ntrain a speed policy that selects a desired forward speed from camera image.\nFor maximum traversability, we pair the speed policy with a gait selector,\nwhich selects a robust locomotion gait for each forward speed. Using only 40\nminutes of human demonstration data, our framework learns to adjust the speed\nand gait of the robot based on perceived terrain semantics, and enables the\nrobot to walk over 6km without failure at close-to-optimal speed.",
    "descriptor": "",
    "authors": [
      "Yuxiang Yang",
      "Xiangyun Meng",
      "Wenhao Yu",
      "Tingnan Zhang",
      "Jie Tan",
      "Byron Boots"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.13631"
  },
  {
    "id": "arXiv:2206.13637",
    "title": "Utility Theory for Sequential Decision Making",
    "abstract": "The von Neumann-Morgenstern (VNM) utility theorem shows that under certain\naxioms of rationality, decision-making is reduced to maximizing the expectation\nof some utility function. We extend these axioms to increasingly structured\nsequential decision making settings and identify the structure of the\ncorresponding utility functions. In particular, we show that memoryless\npreferences lead to a utility in the form of a per transition reward and\nmultiplicative factor on the future return. This result motivates a\ngeneralization of Markov Decision Processes (MDPs) with this structure on the\nagent's returns, which we call Affine-Reward MDPs. A stronger constraint on\npreferences is needed to recover the commonly used cumulative sum of scalar\nrewards in MDPs. A yet stronger constraint simplifies the utility function for\ngoal-seeking agents in the form of a difference in some function of states that\nwe call potential functions. Our necessary and sufficient conditions demystify\nthe reward hypothesis that underlies the design of rational agents in\nreinforcement learning by adding an axiom to the VNM rationality axioms and\nmotivates new directions for AI research involving sequential decision making.",
    "descriptor": "\nComments: ICML 2022\n",
    "authors": [
      "Mehran Shakerinava",
      "Siamak Ravanbakhsh"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.13637"
  },
  {
    "id": "arXiv:2206.13644",
    "title": "Feature Refinement to Improve High Resolution Image Inpainting",
    "abstract": "In this paper, we address the problem of degradation in inpainting quality of\nneural networks operating at high resolutions. Inpainting networks are often\nunable to generate globally coherent structures at resolutions higher than\ntheir training set. This is partially attributed to the receptive field\nremaining static, despite an increase in image resolution. Although downscaling\nthe image prior to inpainting produces coherent structure, it inherently lacks\ndetail present at higher resolutions. To get the best of both worlds, we\noptimize the intermediate featuremaps of a network by minimizing a multiscale\nconsistency loss at inference. This runtime optimization improves the\ninpainting results and establishes a new state-of-the-art for high resolution\ninpainting. Code is available at:\nhttps://github.com/geomagical/lama-with-refiner/tree/refinement.",
    "descriptor": "\nComments: 5 pages, 5 figures, Published in CVPR Workshop on Computer Vision for Augmented and Virtual Reality, New Orleans, LA, 2022\n",
    "authors": [
      "Prakhar Kulshreshtha",
      "Brian Pugh",
      "Salma Jiddi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.13644"
  },
  {
    "id": "arXiv:2206.13646",
    "title": "On bounds for norms of reparameterized ReLU artificial neural network  parameters: sums of fractional powers of the Lipschitz norm control the  network parameter vector",
    "abstract": "It is an elementary fact in the scientific literature that the Lipschitz norm\nof the realization function of a feedforward fully-connected rectified linear\nunit (ReLU) artificial neural network (ANN) can, up to a multiplicative\nconstant, be bounded from above by sums of powers of the norm of the ANN\nparameter vector. Roughly speaking, in this work we reveal in the case of\nshallow ANNs that the converse inequality is also true. More formally, we prove\nthat the norm of the equivalence class of ANN parameter vectors with the same\nrealization function is, up to a multiplicative constant, bounded from above by\nthe sum of powers of the Lipschitz norm of the ANN realization function (with\nthe exponents $ 1/2 $ and $ 1 $). Moreover, we prove that this upper bound only\nholds when employing the Lipschitz norm but does neither hold for H\\\"older\nnorms nor for Sobolev-Slobodeckij norms. Furthermore, we prove that this upper\nbound only holds for sums of powers of the Lipschitz norm with the exponents $\n1/2 $ and $ 1 $ but does not hold for the Lipschitz norm alone.",
    "descriptor": "\nComments: 39 pages, 1 figure. arXiv admin note: substantial text overlap with arXiv:2112.09684\n",
    "authors": [
      "Arnulf Jentzen",
      "Timo Kr\u00f6ger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.13646"
  },
  {
    "id": "arXiv:2206.13654",
    "title": "Wav2Vec-Aug: Improved self-supervised training with limited data",
    "abstract": "Self-supervised learning (SSL) of speech representations has received much\nattention over the last few years but most work has focused on languages and\ndomains with an abundance of unlabeled data. However, for many languages there\nis a shortage even in the unlabeled data which limits the effectiveness of SSL.\nIn this work, we focus on the problem of applying SSL to domains with limited\navailable data by leveraging data augmentation for Wav2Vec 2.0 pretraining.\nFurther, we propose improvements to each component of the model which result in\na combined relative word error rate (WER) improvement of up to 13% compared to\nWav2Vec 2.0 on Librispeech test-clean / other.",
    "descriptor": "",
    "authors": [
      "Anuroop Sriram",
      "Michael Auli",
      "Alexei Baevski"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.13654"
  },
  {
    "id": "arXiv:2206.13655",
    "title": "Deployment of ML Models using Kubeflow on Different Cloud Providers",
    "abstract": "This project aims to explore the process of deploying Machine learning models\non Kubernetes using an open-source tool called Kubeflow [1] - an end-to-end ML\nStack orchestration toolkit. We create end-to-end Machine Learning models on\nKubeflow in the form of pipelines and analyze various points including the ease\nof setup, deployment models, performance, limitations and features of the tool.\nWe hope that our project acts almost like a seminar/introductory report that\ncan help vanilla cloud/Kubernetes users with zero knowledge on Kubeflow use\nKubeflow to deploy ML models. From setup on different clouds to serving our\ntrained model over the internet - we give details and metrics detailing the\nperformance of Kubeflow.",
    "descriptor": "",
    "authors": [
      "Aditya Pandey",
      "Maitreya Sonawane",
      "Sumit Mamtani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.13655"
  },
  {
    "id": "arXiv:2206.13657",
    "title": "DigiTac: A DIGIT-TacTip Hybrid Tactile Sensor for Comparing Low-Cost  High-Resolution Robot Touch",
    "abstract": "Deep learning combined with high-resolution tactile sensing could lead to\nhighly capable dexterous robots. However, progress is slow because of the\nspecialist equipment and expertise. The DIGIT tactile sensor offers low-cost\nentry to high-resolution touch using GelSight-type sensors. Here we customize\nthe DIGIT to have a 3D-printed sensing surface based on the TacTip family of\nsoft biomimetic optical tactile sensors. The DIGIT-TacTip (DigiTac) enables\ndirect comparison between these distinct tactile sensor types. For this\ncomparison, we introduce a tactile robot system comprising a desktop arm,\nmounts and 3D-printed test objects. We use tactile servo control with a PoseNet\ndeep learning model to compare the DIGIT, DigiTac and TacTip for edge- and\nsurface-following over 3D-shapes. All three sensors performed similarly at pose\nprediction, but their constructions led to differing performances at servo\ncontrol, offering guidance for researchers selecting or innovating tactile\nsensors. All hardware and software for reproducing this study will be openly\nreleased.",
    "descriptor": "\nComments: 7 pages. Accepted in RA-L\n",
    "authors": [
      "Nathan F. Lepora",
      "Yijiong Lin",
      "Ben Money-Coomes",
      "John Lloyd"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.13657"
  },
  {
    "id": "arXiv:2206.13658",
    "title": "Geo-Situation for Modeling Causality of Geo-Events in Knowledge Graphs",
    "abstract": "This paper proposes a framework for representing and reasoning causality\nbetween geographic events by introducing the notion of Geo-Situation. This\nconcept links to observational snapshots that represent sets of conditions, and\neither acts as the setting of a geo-event or influences the initiation of a\ngeo-event. We envision the use of this framework within knowledge graphs that\nrepresent geographic entities will help answer the important question of why a\ngeographic event occurred.",
    "descriptor": "",
    "authors": [
      "Shirly Stephen",
      "Wenwen Li",
      "Torsten Hahmann"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.13658"
  },
  {
    "id": "arXiv:2206.13660",
    "title": "DF-SCA: Dynamic Frequency Side Channel Attacks are Practical",
    "abstract": "The arm race between hardware security engineers and side-channel researchers\nhas become more competitive with more sophisticated attacks and defenses in the\nlast decade. While modern hardware features improve the system performance\nsignificantly, they may create new attack surfaces for malicious people to\nextract sensitive information about users without physical access to the victim\ndevice. Although many previously exploited hardware and OS features were\npatched by OS developers and chip vendors, any feature that is accessible from\nuserspace applications can be exploited to perform software-based side-channel\nattacks.\nIn this paper, we present DF-SCA, which is a software-based dynamic frequency\nside-channel attack on Linux and Android OS devices. We exploit unprivileged\naccess to cpufreq interface that exposes real-time CPU core frequency values\ndirectly correlated with the system utilization, creating a reliable\nside-channel for attackers. We show that Dynamic Voltage and Frequency Scaling\n(DVFS) feature in modern systems can be utilized to perform website\nfingerprinting attacks for Google Chrome and Tor browsers on modern Intel, AMD,\nand ARM architectures. We further extend our analysis to a wide selection of\nscaling governors on Intel and AMD CPUs, verifying that all scaling governors\nprovide enough information on the visited web page. Moreover, we extract\nproperties of keystroke patterns on frequency readings, that leads to 95%\naccuracy to distinguish the keystrokes from other activities on Android phones.\nWe leverage inter-keystroke timings of a user by training a k-th nearest\nneighbor model, which achieves 88% password recovery rate in the first guess on\nBank of America application. Finally, we propose several countermeasures to\nmask the user activity to mitigate DF-SCA on Linux-based systems.",
    "descriptor": "",
    "authors": [
      "Debopriya Roy Dipta",
      "Berk Gulmezoglu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.13660"
  },
  {
    "id": "arXiv:2206.13673",
    "title": "How Many Events do You Need? Event-based Visual Place Recognition Using  Sparse But Varying Pixels",
    "abstract": "Event cameras continue to attract interest due to desirable characteristics\nsuch as high dynamic range, low latency, virtually no motion blur, and high\nenergy efficiency. One of the potential applications of event camera research\nlies in visual place recognition for robot localization, where a query\nobservation has to be matched to the corresponding reference place in the\ndatabase. In this letter, we explore the distinctiveness of event streams from\na small subset of pixels (in the tens or hundreds). We demonstrate that the\nabsolute difference in the number of events at those pixel locations\naccumulated into event frames can be sufficient for the place recognition task,\nwhen pixels that display large variations in the reference set are used. Using\nsuch sparse (over image coordinates) but varying (variance over the number of\nevents per pixel location) pixels enables frequent and computationally cheap\nupdates of the location estimates. Furthermore, when event frames contain a\nconstant number of events, our method takes full advantage of the event-driven\nnature of the sensory stream and displays promising robustness to changes in\nvelocity. We evaluate our proposed approach on the Brisbane-Event-VPR dataset\nin an outdoor driving scenario, as well as the newly contributed indoor\nQCR-Event-VPR dataset that was captured with a DAVIS346 camera mounted on a\nmobile robotic platform. Our results show that our approach achieves\ncompetitive performance when compared to several baseline methods on those\ndatasets, and is particularly well suited for compute- and energy-constrained\nplatforms such as interplanetary rovers.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Tobias Fischer",
      "Michael Milford"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.13673"
  },
  {
    "id": "arXiv:2206.13676",
    "title": "TTS-CGAN: A Transformer Time-Series Conditional GAN for Biosignal Data  Augmentation",
    "abstract": "Signal measurement appearing in the form of time series is one of the most\ncommon types of data used in medical machine learning applications. Such\ndatasets are often small in size, expensive to collect and annotate, and might\ninvolve privacy issues, which hinders our ability to train large,\nstate-of-the-art deep learning models for biomedical applications. For\ntime-series data, the suite of data augmentation strategies we can use to\nexpand the size of the dataset is limited by the need to maintain the basic\nproperties of the signal. Generative Adversarial Networks (GANs) can be\nutilized as another data augmentation tool. In this paper, we present TTS-CGAN,\na transformer-based conditional GAN model that can be trained on existing\nmulti-class datasets and generate class-specific synthetic time-series\nsequences of arbitrary length. We elaborate on the model architecture and\ndesign strategies. Synthetic sequences generated by our model are\nindistinguishable from real ones, and can be used to complement or replace real\nsignals of the same type, thus achieving the goal of data augmentation. To\nevaluate the quality of the generated data, we modify the wavelet coherence\nmetric to be able to compare the similarity between two sets of signals, and\nalso conduct a case study where a mix of synthetic and real data are used to\ntrain a deep learning model for sequence classification. Together with other\nvisualization techniques and qualitative evaluation approaches, we demonstrate\nthat TTS-CGAN generated synthetic data are similar to real data, and that our\nmodel performs better than the other state-of-the-art GAN models built for\ntime-series data generation.",
    "descriptor": "\nComments: under review\n",
    "authors": [
      "Xiaomin Li",
      "Anne Hee Hiong Ngu",
      "Vangelis Metsis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.13676"
  },
  {
    "id": "arXiv:2206.13677",
    "title": "Towards Global-Scale Crowd+AI Techniques to Map and Assess Sidewalks for  People with Disabilities",
    "abstract": "There is a lack of data on the location, condition, and accessibility of\nsidewalks across the world, which not only impacts where and how people travel\nbut also fundamentally limits interactive mapping tools and urban analytics. In\nthis paper, we describe initial work in semi-automatically building a sidewalk\nnetwork topology from satellite imagery using hierarchical multi-scale\nattention models, inferring surface materials from street-level images using\nactive learning-based semantic segmentation, and assessing sidewalk condition\nand accessibility features using Crowd+AI. We close with a call to create a\ndatabase of labeled satellite and streetscape scenes for sidewalks and sidewalk\naccessibility issues along with standardized benchmarks.",
    "descriptor": "\nComments: CVPR 2022 AVA (Accessibility, Vision, and Autonomy Meet) Workshop\n",
    "authors": [
      "Maryam Hosseini",
      "Mikey Saugstad",
      "Fabio Miranda",
      "Andres Sevtsuk",
      "Claudio T. Silva",
      "Jon E. Froehlich"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.13677"
  },
  {
    "id": "arXiv:2206.13678",
    "title": "Strengthened Partial-Ordering Based ILP Models for the Vertex Coloring  Problem",
    "abstract": "The vertex coloring problem asks for the minimum number of colors that can be\nassigned to the vertices of a given graph such that each two adjacent vertices\nget different colors. For this NP-hard problem, a variety of integer linear\nprogramming (ILP) models have been suggested. Among them, the assignment based\nand the partial-ordering based ILP models are attractive due to their\nsimplicity and easy extendability. Moreover, on sparse graphs, both models\nturned out to be among the strongest exact approaches for solving the vertex\ncoloring problem. In this work, we suggest additional strengthening constraints\nfor the partial-ordering based ILP model, and show that they lead to improved\nlower bounds of the corresponding LP relaxation. Our computational experiments\nconfirm that the new constraints are also leading to practical improvements. In\nparticular, we are able to find the optimal solution of a previously open\ninstance from the DIMACS benchmark set for vertex coloring problems",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Adalat Jabrayilov",
      "Petra Mutzel"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2206.13678"
  },
  {
    "id": "arXiv:2206.13687",
    "title": "POEM: Out-of-Distribution Detection with Posterior Sampling",
    "abstract": "Out-of-distribution (OOD) detection is indispensable for machine learning\nmodels deployed in the open world. Recently, the use of an auxiliary outlier\ndataset during training (also known as outlier exposure) has shown promising\nperformance. As the sample space for potential OOD data can be prohibitively\nlarge, sampling informative outliers is essential. In this work, we propose a\nnovel posterior sampling-based outlier mining framework, POEM, which\nfacilitates efficient use of outlier data and promotes learning a compact\ndecision boundary between ID and OOD data for improved detection. We show that\nPOEM establishes state-of-the-art performance on common benchmarks. Compared to\nthe current best method that uses a greedy sampling strategy, POEM improves the\nrelative performance by 42.0% and 24.2% (FPR95) on CIFAR-10 and CIFAR-100,\nrespectively. We further provide theoretical insights on the effectiveness of\nPOEM for OOD detection.",
    "descriptor": "\nComments: ICML 2022 (Long Talk); First two authors contributed equally\n",
    "authors": [
      "Yifei Ming",
      "Ying Fan",
      "Yixuan Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.13687"
  },
  {
    "id": "arXiv:2206.13689",
    "title": "Tiny-Sepformer: A Tiny Time-Domain Transformer Network for Speech  Separation",
    "abstract": "Time-domain Transformer neural networks have proven their superiority in\nspeech separation tasks. However, these models usually have a large number of\nnetwork parameters, thus often encountering the problem of GPU memory\nexplosion. In this paper, we proposed Tiny-Sepformer, a tiny version of\nTransformer network for speech separation. We present two techniques to reduce\nthe model parameters and memory consumption: (1) Convolution-Attention (CA)\nblock, spliting the vanilla Transformer to two paths, multi-head attention and\n1D depthwise separable convolution, (2) parameter sharing, sharing the layer\nparameters within the CA block. In our experiments, Tiny-Sepformer could\ngreatly reduce the model size, and achieves comparable separation performance\nwith vanilla Sepformer on WSJ0-2/3Mix datasets.",
    "descriptor": "\nComments: Accepted by Interspeech 2022\n",
    "authors": [
      "Jian Luo",
      "Jianzong Wang",
      "Ning Cheng",
      "Edward Xiao",
      "Xulong Zhang",
      "Jing Xiao"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.13689"
  },
  {
    "id": "arXiv:2206.13690",
    "title": "Identifying the requirement conflicts in SRS documents using  transformer-based sentence embeddings",
    "abstract": "High quality software systems typically require a set of clear, complete and\ncomprehensive requirements. In the process of software development life cycle,\na software requirement specification (SRS) document lays the foundation of\nproduct development by defining the set of functional and nonfunctional\nrequirements. It also improves the quality of software products and ensure\ntimely delivery of the projects. These requirements are typically documented in\nnatural language which might lead to misinterpretations and conflicts between\nthe requirements. In this study, we aim to identify the conflicts in\nrequirements by analyzing their semantic compositions and contextual meanings.\nWe propose an approach for automatic conflict detection, which consists of two\nphases: identifying conflict candidates based on textual similarity, and using\nsemantic analysis to filter the conflicts. The similarity-based conflict\ndetection strategy involves finding the appropriate candidate requirements with\nthe help of sentence embeddings and cosine similarity measures. Semantic\nconflict detection is an additional step applied over all the candidates\nidentified in the first phase, where the useful information is extracted in the\nform of entities to be used for determining the overlapping portions of texts\nbetween the requirements. We test the generalizability of our approach using\nfive SRS documents from different domains. Our experiments show that the\nproposed conflict detection strategy can capture the conflicts with high\naccuracy, and help automate the entire conflict detection process.",
    "descriptor": "",
    "authors": [
      "Garima Malik",
      "Mucahit Cevik",
      "Devang Parikh",
      "Ayse Basar"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.13690"
  },
  {
    "id": "arXiv:2206.13691",
    "title": "Dummy Prototypical Networks for Few-Shot Open-Set Keyword Spotting",
    "abstract": "Keyword spotting is the task of detecting a keyword in streaming audio.\nConventional keyword spotting targets predefined keywords classification, but\nthere is growing attention in few-shot (query-by-example) keyword spotting,\ne.g., N-way classification given M-shot support samples. Moreover, in\nreal-world scenarios, there can be utterances from unexpected categories\n(open-set) which need to be rejected rather than classified as one of the N\nclasses. Combining the two needs, we tackle few-shot open-set keyword spotting\nwith a new benchmark setting, named splitGSC. We propose episode-known dummy\nprototypes based on metric learning to detect an open-set better and introduce\na simple and powerful approach, Dummy Prototypical Networks (D-ProtoNets). Our\nD-ProtoNets shows clear margins compared to recent few-shot open-set\nrecognition (FSOSR) approaches in the suggested splitGSC. We also verify our\nmethod on a standard benchmark, miniImageNet, and D-ProtoNets shows the\nstate-of-the-art open-set detection rate in FSOSR.",
    "descriptor": "\nComments: Proceedings of INTERSPEECH 2022\n",
    "authors": [
      "Byeonggeun Kim",
      "Seunghan Yang",
      "Inseop Chung",
      "Simyung Chang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.13691"
  },
  {
    "id": "arXiv:2206.13697",
    "title": "Graph Condensation via Receptive Field Distribution Matching",
    "abstract": "Graph neural networks (GNNs) enable the analysis of graphs using deep\nlearning, with promising results in capturing structured information in graphs.\nThis paper focuses on creating a small graph to represent the original graph,\nso that GNNs trained on the size-reduced graph can make accurate predictions.\nWe view the original graph as a distribution of receptive fields and aim to\nsynthesize a small graph whose receptive fields share a similar distribution.\nThus, we propose Graph Condesation via Receptive Field Distribution Matching\n(GCDM), which is accomplished by optimizing the synthetic graph through the use\nof a distribution matching loss quantified by maximum mean discrepancy (MMD).\nAdditionally, we demonstrate that the synthetic graph generated by GCDM is\nhighly generalizable to a variety of models in evaluation phase and that the\ncondensing speed is significantly improved using this framework.",
    "descriptor": "",
    "authors": [
      "Mengyang Liu",
      "Shanchuan Li",
      "Xinshi Chen",
      "Le Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.13697"
  },
  {
    "id": "arXiv:2206.13700",
    "title": "Domain Agnostic Few-shot Learning for Speaker Verification",
    "abstract": "Deep learning models for verification systems often fail to generalize to new\nusers and new environments, even though they learn highly discriminative\nfeatures. To address this problem, we propose a few-shot domain generalization\nframework that learns to tackle distribution shift for new users and new\ndomains. Our framework consists of domain-specific and domain-aggregation\nnetworks, which are the experts on specific and combined domains, respectively.\nBy using these networks, we generate episodes that mimic the presence of both\nnovel users and novel domains in the training phase to eventually produce\nbetter generalization. To save memory, we reduce the number of domain-specific\nnetworks by clustering similar domains together. Upon extensive evaluation on\nartificially generated noise domains, we can explicitly show generalization\nability of our framework. In addition, we apply our proposed methods to the\nexisting competitive architecture on the standard benchmark, which shows\nfurther performance improvements.",
    "descriptor": "\nComments: Proceedings of INTERSPEECH 2022\n",
    "authors": [
      "Seunghan Yang",
      "Debasmit Das",
      "Janghoon Cho",
      "Hyoungwoo Park",
      "Sungrack Yun"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.13700"
  },
  {
    "id": "arXiv:2206.13703",
    "title": "Kwame for Science: An AI Teaching Assistant for Science Education in  West Africa",
    "abstract": "Africa has a high student-to-teacher ratio which limits students' access to\nteachers. Consequently, students struggle to get answers to their questions. In\nthis work, we extended Kwame, our previous AI teaching assistant, adapted it\nfor science education, and deployed it as a web app. Kwame for Science answers\nquestions of students based on the Integrated Science subject of the West\nAfrican Senior Secondary Certificate Examination (WASSCE). Kwame for Science is\na Sentence-BERT-based question-answering web app that displays 3 paragraphs as\nanswers along with a confidence score in response to science questions.\nAdditionally, it displays the top 5 related past exam questions and their\nanswers in addition to the 3 paragraphs. Our preliminary evaluation of the\nKwame for Science with a 2.5-week real-world deployment showed a top 3 accuracy\nof 87.5% (n=56) with 190 users across 11 countries. Kwame for Science will\nenable the delivery of scalable, cost-effective, and quality remote education\nto millions of people across Africa.",
    "descriptor": "\nComments: 5 pages, Under review at Fourth Workshop on Intelligent Textbooks (iTextbooks) at the 23th International Conference on Artificial Intelligence in Education (AIED 2022)\n",
    "authors": [
      "George Boateng",
      "Samuel John",
      "Andrew Glago",
      "Samuel Boateng",
      "Victor Kumbol"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.13703"
  },
  {
    "id": "arXiv:2206.13704",
    "title": "Involuntary Stabilization in Discrete-Event Physical Human-Robot  Interaction",
    "abstract": "Robots are used by humans not only as tools but also to interactively assist\nand cooperate with humans, thereby forming physical human-robot interactions.\nIn these interactions, there is a risk that a feedback loop causes unstable\nforce interaction, in which force escalation exposes a human to danger.\nPrevious studies have analyzed the stability of voluntary interaction but have\nneglected involuntary behavior in the interaction. In contrast to the previous\nstudies, this study considered the involuntary behavior: a human's force\nreproduction bias for discrete-event human-robot force interaction. We derived\nan asymptotic stability condition based on a mathematical bias model and found\nthat the bias asymptotically stabilizes a human's implicit equilibrium point\nfar from the implicit equilibrium point and destabilizes the point near the\npoint. The bias model, convergence of the interaction toward the implicit\nequilibrium point, and divergence around the point were consistently verified\nvia behavioral experiments under three kinds of interactions using three\ndifferent body parts: a hand finger, wrist, and foot. Our results imply that\nhumans implicitly secure a stable and close relationship between themselves and\nrobots with their involuntary behavior.",
    "descriptor": "",
    "authors": [
      "Hisayoshi Muramatsu",
      "Yoshihiro Itaguchi",
      "Seiichiro Katsura"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.13704"
  },
  {
    "id": "arXiv:2206.13708",
    "title": "Personalized Keyword Spotting through Multi-task Learning",
    "abstract": "Keyword spotting (KWS) plays an essential role in enabling speech-based user\ninteraction on smart devices, and conventional KWS (C-KWS) approaches have\nconcentrated on detecting user-agnostic pre-defined keywords. However, in\npractice, most user interactions come from target users enrolled in the device\nwhich motivates to construct personalized keyword spotting. We design two\npersonalized KWS tasks; (1) Target user Biased KWS (TB-KWS) and (2) Target user\nOnly KWS (TO-KWS). To solve the tasks, we propose personalized keyword spotting\nthrough multi-task learning (PK-MTL) that consists of multi-task learning and\ntask-adaptation. First, we introduce applying multi-task learning on keyword\nspotting and speaker verification to leverage user information to the keyword\nspotting system. Next, we design task-specific scoring functions to adapt to\nthe personalized KWS tasks thoroughly. We evaluate our framework on\nconventional and personalized scenarios, and the results show that PK-MTL can\ndramatically reduce the false alarm rate, especially in various practical\nscenarios.",
    "descriptor": "\nComments: Proceedings of INTERSPEECH 2022\n",
    "authors": [
      "Seunghan Yang",
      "Byeonggeun Kim",
      "Inseop Chung",
      "Simyung Chang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.13708"
  },
  {
    "id": "arXiv:2206.13714",
    "title": "Generalized Policy Improvement Algorithms with Theoretically Supported  Sample Reuse",
    "abstract": "Real-world sequential decision making requires data-driven algorithms that\nprovide practical guarantees on performance throughout training while also\nmaking efficient use of data. Model-free deep reinforcement learning represents\na framework for such data-driven decision making, but existing algorithms\ntypically only focus on one of these goals while sacrificing performance with\nrespect to the other. On-policy algorithms guarantee policy improvement\nthroughout training but suffer from high sample complexity, while off-policy\nalgorithms make efficient use of data through sample reuse but lack theoretical\nguarantees. In order to balance these competing goals, we develop a class of\nGeneralized Policy Improvement algorithms that combines the policy improvement\nguarantees of on-policy methods with the efficiency of theoretically supported\nsample reuse. We demonstrate the benefits of this new class of algorithms\nthrough extensive experimental analysis on a variety of continuous control\ntasks from the DeepMind Control Suite.",
    "descriptor": "",
    "authors": [
      "James Queeney",
      "Ioannis Ch. Paschalidis",
      "Christos G. Cassandras"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.13714"
  },
  {
    "id": "arXiv:2206.13715",
    "title": "Split Two-Tower Model for Efficient and Privacy-Preserving Cross-device  Federated Recommendation",
    "abstract": "Federated Recommendation can mitigate the systematical privacy risks of\ntraditional recommendation since it allows the model training and online\ninferring without centralized user data collection. Most existing works assume\nthat all user devices are available and adequate to participate in the\nFederated Learning. However, in practice, the complex recommendation models\ndesigned for accurate prediction and massive item data cause a high computation\nand communication cost to the resource-constrained user device, resulting in\npoor performance or training failure. Therefore, how to effectively compress\nthe computation and communication overhead to achieve efficient federated\nrecommendations across ubiquitous mobile devices remains a significant\nchallenge. This paper introduces split learning into the two-tower\nrecommendation models and proposes STTFedRec, a privacy-preserving and\nefficient cross-device federated recommendation framework. STTFedRec achieves\nlocal computation reduction by splitting the training and computation of the\nitem model from user devices to a performance-powered server. The server with\nthe item model provides low-dimensional item embeddings instead of raw item\ndata to the user devices for local training and online inferring, achieving\nserver broadcast compression. The user devices only need to perform similarity\ncalculations with cached user embeddings to achieve efficient online inferring.\nWe also propose an obfuscated item request strategy and multi-party circular\nsecret sharing chain to enhance the privacy protection of model training. The\nexperiments conducted on two public datasets demonstrate that STTFedRec\nimproves the average computation time and communication size of the baseline\nmodels by about 40 times and 42 times in the best-case scenario with balanced\nrecommendation accuracy.",
    "descriptor": "",
    "authors": [
      "Jiangcheng Qin",
      "Baisong Liu",
      "Xueyuan Zhang",
      "Jiangbo Qian"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.13715"
  },
  {
    "id": "arXiv:2206.13717",
    "title": "A Combination of Host Overloading Detection and Virtual Machine  Selection in Cloud Server Consolidation based on Learning Method",
    "abstract": "In cloud data center (CDC), reducing energy consumption while maintaining\nperformance has always been a hot issue. In server consolidation, the\ntraditional solution is to divide the problem into multiple small problems such\nas host overloading detection, virtual machine (VM) selection and VM placement\nand solve them step by step. However, the design of host overloading detection\nstrategies and VM selection strategies cannot be directly linked to the\nultimate goal of reducing energy consumption and ensuring performance. This\npaper proposes a learning-based VM selection strategy that selects appropriate\nVMs for migration without direct host overloading detection. Thereby reducing\nthe generation of SLAV, ensuring the performance and reducing the energy\nconsumption of CDC. Simulations driven by real VM workload traces show that our\nmethod outperforms the existing methods in reducing SLAV generation and CDC\nenergy consumption.",
    "descriptor": "",
    "authors": [
      "Li Huixi",
      "Xiao Yinhao",
      "Shen Yongluo"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.13717"
  },
  {
    "id": "arXiv:2206.13718",
    "title": "The Third Place Solution for CVPR2022 AVA Accessibility Vision and  Autonomy Challenge",
    "abstract": "The goal of AVA challenge is to provide vision-based benchmarks and methods\nrelevant to accessibility. In this paper, we introduce the technical details of\nour submission to the CVPR2022 AVA Challenge. Firstly, we conducted some\nexperiments to help employ proper model and data augmentation strategy for this\ntask. Secondly, an effective training strategy was applied to improve the\nperformance. Thirdly, we integrated the results from two different segmentation\nframeworks to improve the performance further. Experimental results demonstrate\nthat our approach can achieve a competitive result on the AVA test set.\nFinally, our approach achieves 63.008\\%AP@0.50:0.95 on the test set of CVPR2022\nAVA Challenge.",
    "descriptor": "\nComments: The third place solution for CVPR2022 AVA Accessibility Vision and Autonomy Challenge\n",
    "authors": [
      "Bo Yan",
      "Leilei Cao",
      "Zhuang Li",
      "Hongbin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.13718"
  },
  {
    "id": "arXiv:2206.13720",
    "title": "SHELS: Exclusive Feature Sets for Novelty Detection and Continual  Learning Without Class Boundaries",
    "abstract": "While deep neural networks (DNNs) have achieved impressive classification\nperformance in closed-world learning scenarios, they typically fail to\ngeneralize to unseen categories in dynamic open-world environments, in which\nthe number of concepts is unbounded. In contrast, human and animal learners\nhave the ability to incrementally update their knowledge by recognizing and\nadapting to novel observations. In particular, humans characterize concepts via\nexclusive (unique) sets of essential features, which are used for both\nrecognizing known classes and identifying novelty. Inspired by natural\nlearners, we introduce a Sparse High-level-Exclusive, Low-level-Shared feature\nrepresentation (SHELS) that simultaneously encourages learning exclusive sets\nof high-level features and essential, shared low-level features. The\nexclusivity of the high-level features enables the DNN to automatically detect\nout-of-distribution (OOD) data, while the efficient use of capacity via sparse\nlow-level features permits accommodating new knowledge. The resulting approach\nuses OOD detection to perform class-incremental continual learning without\nknown class boundaries. We show that using SHELS for novelty detection results\nin statistically significant improvements over state-of-the-art OOD detection\napproaches over a variety of benchmark datasets. Further, we demonstrate that\nthe SHELS model mitigates catastrophic forgetting in a class-incremental\nlearning setting,enabling a combined novelty detection and accommodation\nframework that supports learning in open-world settings",
    "descriptor": "",
    "authors": [
      "Meghna Gummadi",
      "David Kent",
      "Jorge A. Mendez",
      "Eric Eaton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.13720"
  },
  {
    "id": "arXiv:2206.13723",
    "title": "Prescribed-Time Synchronization of Multiweighted and Directed Complex  Networks",
    "abstract": "In this note, we study the prescribed-time (PT) synchronization of\nmultiweighted and directed complex networks (MWDCNs) via pinning control.\nUnlike finite-time and fixed-time synchronization, the time for synchronization\ncan be preset as needed, which is independent of initial values and parameters\nlike coupling strength. First and foremost, we reveal the essence of PT\nstability by improper integral, L'Hospital rule and Taylor expansion theory.\nMany controllers established previously for PT stability can be included in our\nnew model. Then, we apply this new result on MWDCNs as an application. The\nsynchronization error at the prescribed time is discussed carefully, so, PT\nsynchronization can be reached. The network topology can be directed and\ndisconnected, which means that the outer coupling matrices (OCMs) can be\nasymmetric and not connected. The relationships between nodes are allowed to be\ncooperative or competitive, so elements in OCMs and inner coupling matrices\n(ICMs) can be positive or negative. We use the rearranging variables' order\ntechnique to combine ICMs and OCMs together to get the sum matrices, which can\nmake a bridge between multiweighted and single-weighted networks. Finally,\nsimulations are presented to illustrate the effectiveness of our theory.",
    "descriptor": "\nComments: 18 pages, 3 figures\n",
    "authors": [
      "Linlong Xu",
      "Xiwei Liu"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.13723"
  },
  {
    "id": "arXiv:2206.13727",
    "title": "Persistent homology-based descriptor for machine-learning potential",
    "abstract": "Constructing efficient descriptors that represent atomic configurations is\ncrucial for developing a superior machine-learning potential. Widely used\nconventional descriptors are based on two- or three-body correlations of atomic\ndistribution. Recently, several limitations of these many-body descriptors in\nclassifying different configurations were revealed, which have detrimental\neffects on the prediction of physical properties. We proposed a new class of\ndescriptors based on persistent homology. We focused on the two-dimensional\nvisualization of persistent homology, that is, a persistence diagram, as a\ndescriptor of atomic configurations in the form of an image. We demonstrated\nthat convolutional neural network models based on this descriptor provide\nsufficient accuracy in predicting the mean energies per atom of amorphous\ngraphene and amorphous carbon. Our results provide an avenue for improving\nmachine-learning potential using descriptors that depict both topological and\ngeometric information.",
    "descriptor": "\nComments: 16 pages, 4 figures\n",
    "authors": [
      "Emi Minamitani",
      "Ippei Obayashi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Materials Science (cond-mat.mtrl-sci)"
    ],
    "url": "https://arxiv.org/abs/2206.13727"
  },
  {
    "id": "arXiv:2206.13728",
    "title": "Boosting R-CNN: Reweighting R-CNN Samples by RPN's Error for Underwater  Object Detection",
    "abstract": "Complicated underwater environments bring new challenges to object detection,\nsuch as unbalanced light conditions, low contrast, occlusion, and mimicry of\naquatic organisms. Under these circumstances, the objects captured by the\nunderwater camera will become vague, and the generic detectors often fail on\nthese vague objects. This work aims to solve the problem from two perspectives:\nuncertainty modeling and hard example mining. We propose a two-stage underwater\ndetector named boosting R-CNN, which comprises three key components. First, a\nnew region proposal network named RetinaRPN is proposed, which provides\nhigh-quality proposals and considers objectness and IoU prediction for\nuncertainty to model the object prior probability. Second, the probabilistic\ninference pipeline is introduced to combine the first-stage prior uncertainty\nand the second-stage classification score to model the final detection score.\nFinally, we propose a new hard example mining method named boosting\nreweighting. Specifically, when the region proposal network miscalculates the\nobject prior probability for a sample, boosting reweighting will increase the\nclassification loss of the sample in the R-CNN head during training, while\nreducing the loss of easy samples with accurately estimated priors. Thus, a\nrobust detection head in the second stage can be obtained. During the inference\nstage, the R-CNN has the capability to rectify the error of the first stage to\nimprove the performance. Comprehensive experiments on two underwater datasets\nand two generic object detection datasets demonstrate the effectiveness and\nrobustness of our method.",
    "descriptor": "",
    "authors": [
      "Pinhao Song",
      "Hong Liu",
      "Linhui Dai",
      "Tao Wang",
      "Zhan Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.13728"
  },
  {
    "id": "arXiv:2206.13731",
    "title": "On two-variable guarded fragment logic with expressive local Presburger  constraints",
    "abstract": "We consider the extension of two-variable guarded fragment logic with local\nPresburger quantifiers. These are quantifiers that can express properties such\nas ``the number of incoming blue edges plus twice the number of outgoing red\nedges is at most three times the number of incoming green edges'' and captures\nvarious description logics up to $\\mathcal{ALCIH}b^{\\textsf{self}}$. We show\nthat the satisfiability of this logic is EXP-complete. While the lower bound\nalready holds for the standard two-variable guarded fragment logic, the upper\nbound is established by a novel, yet simple deterministic graph theoretic based\nalgorithm.",
    "descriptor": "",
    "authors": [
      "Chia-Hsuan Lu",
      "Tony Tan"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.13731"
  },
  {
    "id": "arXiv:2206.13732",
    "title": "A Comprehensive Survey on Deep Gait Recognition: Algorithms, Datasets  and Challenges",
    "abstract": "Gait recognition aims at identifying a person at a distance through visual\ncameras. With the emergence of deep learning, significant advancements in gait\nrecognition have achieved inspiring success in many scenarios by utilizing deep\nlearning techniques. Nevertheless, the increasing need for video surveillance\nintroduces more challenges, including robust recognition under various\nvariances, modeling motion information in gait sequences, unfair performance\ncomparison due to protocol variances, biometrics security, and privacy\nprevention. This paper provides a comprehensive survey of deep learning for\ngait recognition. We first present the odyssey of gait recognition from\ntraditional algorithms to deep models, providing explicit knowledge of the\nwhole workflow of a gait recognition system. Then deep learning for gait\nrecognition is discussed from the perspective of deep representations and\narchitecture with an in-depth summary. Specifically, deep gait representations\nare categorized into static and dynamic features, while deep architectures\ninclude single-stream and multi-stream architecture. Following our proposed\ntaxonomy with novelty, it can be beneficial for providing inspiration and\npromoting the perception of deep gait recognition. Besides, we also present a\ncomprehensive summary of all vision-based gait datasets and the performance\nanalysis. Finally, the article discusses some open issues with significant\npotential prospects.",
    "descriptor": "",
    "authors": [
      "Chuanfu Shen",
      "Shiqi Yu",
      "Jilong Wang",
      "George Q. Huang",
      "Liang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.13732"
  },
  {
    "id": "arXiv:2206.13734",
    "title": "H-GCN: A Graph Convolutional Network Accelerator on Versal ACAP  Architecture",
    "abstract": "Graph Neural Networks (GNNs) have drawn tremendous attention due to their\nunique capability to extend Machine Learning (ML) approaches to applications\nbroadly-defined as having unstructured data, especially graphs. Compared with\nother Machine Learning (ML) modalities, the acceleration of Graph Neural\nNetworks (GNNs) is more challenging due to the irregularity and heterogeneity\nderived from graph typologies. Existing efforts, however, have focused mainly\non handling graphs' irregularity and have not studied their heterogeneity.\nTo this end we propose H-GCN, a PL (Programmable Logic) and AIE (AI Engine)\nbased hybrid accelerator that leverages the emerging heterogeneity of Xilinx\nVersal Adaptive Compute Acceleration Platforms (ACAPs) to achieve\nhigh-performance GNN inference. In particular, H-GCN partitions each graph into\nthree subgraphs based on its inherent heterogeneity, and processes them using\nPL and AIE, respectively. To further improve performance, we explore the\nsparsity support of AIE and develop an efficient density-aware method to\nautomatically map tiles of sparse matrix-matrix multiplication (SpMM) onto the\nsystolic tensor array. Compared with state-of-the-art GCN accelerators, H-GCN\nachieves, on average, speedups of 1.1~2.3X.",
    "descriptor": "\nComments: 8 pages, 8 figures, 4 tables, accepted by FPL'22\n",
    "authors": [
      "Chengming Zhang",
      "Tong Geng",
      "Anqi Guo",
      "Jiannan Tian",
      "Martin Herbordt",
      "Ang Li",
      "Dingwen Tao"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.13734"
  },
  {
    "id": "arXiv:2206.13737",
    "title": "Adversarial Consistency for Single Domain Generalization in Medical  Image Segmentation",
    "abstract": "An organ segmentation method that can generalize to unseen contrasts and\nscanner settings can significantly reduce the need for retraining of deep\nlearning models. Domain Generalization (DG) aims to achieve this goal. However,\nmost DG methods for segmentation require training data from multiple domains\nduring training. We propose a novel adversarial domain generalization method\nfor organ segmentation trained on data from a \\emph{single} domain. We\nsynthesize the new domains via learning an adversarial domain synthesizer (ADS)\nand presume that the synthetic domains cover a large enough area of plausible\ndistributions so that unseen domains can be interpolated from synthetic\ndomains. We propose a mutual information regularizer to enforce the semantic\nconsistency between images from the synthetic domains, which can be estimated\nby patch-level contrastive learning. We evaluate our method for various organ\nsegmentation for unseen modalities, scanning protocols, and scanner sites.",
    "descriptor": "\nComments: MICCAI2022 accpted\n",
    "authors": [
      "Yanwu Xu",
      "Shaoan Xie",
      "Maxwell Reynolds1",
      "Matthew Ragoza1",
      "Mingming Gong",
      "Kayhan Batmanghelich"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.13737"
  },
  {
    "id": "arXiv:2206.13739",
    "title": "Divide-and-Conquer Determinization of B\u00fcchi Automata based on SCC  Decomposition",
    "abstract": "The determinization of a nondeterministic B\\\"uchi automaton (NBA) is a\nfundamental construction of automata theory, with applications to probabilistic\nverification and reactive synthesis. The standard determinization\nconstructions, such as the ones based on the Safra-Piterman's approach, work on\nthe whole NBA. In this work we propose a divide-and-conquer determinization\napproach. To this end, we first classify the strongly connected components\n(SCCs) of the given NBA as inherently weak, deterministic accepting, and\nnondeterministic accepting. We then present how to determinize each type of SCC\nindependently from the others; this results in an easier handling of the\ndeterminization algorithm that takes advantage of the structure of that SCC.\nOnce all SCCs have been determinized, we show how to compose them so to obtain\nthe final equivalent deterministic Emerson-Lei automaton, which can be\nconverted into a deterministic Rabin automaton without blow-up of states and\ntransitions. We implement our algorithm in a our tool COLA and empirically\nevaluate COLA with the state-of-the-art tools Spot and OWL on a large set of\nbenchmarks from the literature. The experimental results show that our\nprototype COLA outperforms Spot and OWL regarding the number of states and\ntransitions.",
    "descriptor": "\nComments: This is an extended version of our CAV'22 paper\n",
    "authors": [
      "Yong Li",
      "Andrea Turrini",
      "Weizhi Feng",
      "Moshe Y. Vardi",
      "Lijun Zhang"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2206.13739"
  },
  {
    "id": "arXiv:2206.13741",
    "title": "Social-aware Cooperative Caching in Fog Radio Access Networks",
    "abstract": "In this paper, the cooperative caching problem in fog radio access networks\n(F-RANs) is investigated to jointly optimize the transmission delay and energy\nconsumption. Exploiting the potential social relationships among fog access\npoints (F-APs), we firstly propose a clustering scheme based on hedonic\ncoalition game (HCG) to improve the potential cooperation gain. Then,\nconsidering that the optimization problem is non-deterministic polynomial hard\n(NP-hard), we further propose an improved firefly algorithm (FA) based\ncooperative caching scheme, which utilizes a mutation strategy based on local\ncontent popularity to avoid pre-mature convergence. Simulation results show\nthat our proposed scheme can effectively reduce the content transmission delay\nand energy consumption in comparison with the baselines.",
    "descriptor": "\nComments: 6 pages, 5 figures. This paper has been accepted by IEEE ICC 2022\n",
    "authors": [
      "Baotian Fan",
      "Yanxiang Jiang",
      "Fu-Chun Zheng",
      "Mehdi Bennis",
      "Xiaohu You"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.13741"
  },
  {
    "id": "arXiv:2206.13742",
    "title": "The COVID-19 Pandemic on the Turkish Twittersphere",
    "abstract": "With the increase in the time spent at home, social media platforms' role has\nbecome an integral part of the public discussion in the COVID-19 period.\nIndividuals use social media platforms to express their emotions, interact, and\nengage in public debate. Therefore, it is essential to analyze social media\nplatforms for those wanting to understand public opinion during the pandemic.\nThis thesis is the first study that examines the Turkish Twitter-sphere to\nunderstand the change in public opinion during the COVID-19 outbreak. For that\npurpose, starting from 12 February 2020 (one month before the first announced\ncoronavirus cases in Turkey), 4.3 million Turkish tweets with a broad range of\nkeywords are collected until June 2020 to investigate the public opinion change\non different topics and to examine the actors leading to that change. The scope\nof the analysis is not only health-related discussion but also includes a\nbroader range of themes such as politics, economy, and disinformation. This\nstudy also collects 4.15 million Turkish tweets with keywords of vaccine\n(\"a\\c{s}{\\i}\" in Turkish) from 4 April 2020 until 17 March 2021 to unpack the\nhealth of the information ecosystem. Preliminary results suggest that (i)\nreligion is the prominent phenomenon in Turkish people's perception of the\npandemic, (ii) and the Turkish Twitter-sphere is highly vulnerable to\nmis/disinformation operations, and (iii) several communities with divergent\ninterests exist in the vaccine network.",
    "descriptor": "",
    "authors": [
      "Burak Ozturan"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.13742"
  },
  {
    "id": "arXiv:2206.13746",
    "title": "Few-Shot Fine-Grained Entity Typing with Automatic Label Interpretation  and Instance Generation",
    "abstract": "We study the problem of few-shot Fine-grained Entity Typing (FET), where only\na few annotated entity mentions with contexts are given for each entity type.\nRecently, prompt-based tuning has demonstrated superior performance to standard\nfine-tuning in few-shot scenarios by formulating the entity type classification\ntask as a ''fill-in-the-blank'' problem. This allows effective utilization of\nthe strong language modeling capability of Pre-trained Language Models (PLMs).\nDespite the success of current prompt-based tuning approaches, two major\nchallenges remain: (1) the verbalizer in prompts is either manually designed or\nconstructed from external knowledge bases, without considering the target\ncorpus and label hierarchy information, and (2) current approaches mainly\nutilize the representation power of PLMs, but have not explored their\ngeneration power acquired through extensive general-domain pre-training. In\nthis work, we propose a novel framework for few-shot FET consisting of two\nmodules: (1) an entity type label interpretation module automatically learns to\nrelate type labels to the vocabulary by jointly leveraging few-shot instances\nand the label hierarchy, and (2) a type-based contextualized instance generator\nproduces new instances based on given instances to enlarge the training set for\nbetter generalization. On three benchmark datasets, our model outperforms\nexisting methods by significant margins. Code can be found at\nhttps://github.com/teapot123/Fine-Grained-Entity-Typing.",
    "descriptor": "\nComments: Accepted to KDD 2022 Research Track\n",
    "authors": [
      "Jiaxin Huang",
      "Yu Meng",
      "Jiawei Han"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.13746"
  },
  {
    "id": "arXiv:2206.13747",
    "title": "Fire Dragon and Unicorn Princess; Gender Stereotypes and Children's  Products in Search Engine Responses",
    "abstract": "Search engines in e-commerce settings allow users to search, browse, and\nselect items from a wide range of products available online including\nchildren's items. Children's products such as toys, books, and learning\nmaterials often have stereotype-based gender associations. Both academic\nresearch and public campaigns are working to promote stereotype-free childhood\ndevelopment. However, to date, e-commerce search engines have not received as\nmuch attention as physical stores, product design, or marketing as a potential\nchannel of gender stereotypes. To fill this gap, in this paper, we study the\nmanifestations of gender stereotypes in e-commerce sites when responding to\nqueries related to children's products by exploring query suggestions and\nsearch results. We have three primary contributions. First, we provide an\naggregated list of children's products with associated gender stereotypes from\nthe existing body of research. Second, we provide preliminary methods for\nidentifying and quantifying gender stereotypes in system's responses. Third, to\nshow the importance of attending this problem, we identify the existence of\ngender stereotypes in query suggestions and search results across multiple\ne-commerce sites.",
    "descriptor": "\nComments: SIGIR ecom'22: ACM SIGIR Workshop on eCommerce\n",
    "authors": [
      "Amifa Raj",
      "Michael D. Ekstrand"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.13747"
  },
  {
    "id": "arXiv:2206.13748",
    "title": "Phrase Mining",
    "abstract": "Extracting frequent words from a collection of texts is performed on a great\nscale in many subjects. Extracting phrases, on the other hand, is not commonly\ndone due to inherent complications when extracting phrases, the most\nsignificant complication being that of double-counting, where words or phrases\nare counted when they appear inside longer phrases that themselves are also\ncounted. Several papers have been written on phrase mining that describe\nsolutions to this issue; however, they either require a list of so-called\nquality phrases to be available to the extracting process, or they require\nhuman interaction to identify those quality phrases during the process. We\npresent a method that eliminates double-counting without the need to identify\nlists of quality phrases. In the context of a set of texts, we define a\nprincipal phrase as a phrase that does not cross punctuation marks, does not\nstart with a stop word, with the exception of the stop words \"not\" and \"no\",\ndoes not end with a stop word, is frequent within those texts without being\ndouble counted, and is meaningful to the user. Our method can identify such\nprincipal phrases independently without human input, and enables their\nextraction from any texts. An R package called phm has been developed that\nimplements this method.",
    "descriptor": "\nComments: 14 pages, 4 tables\n",
    "authors": [
      "Ellie Small",
      "Javier Cabrera"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2206.13748"
  },
  {
    "id": "arXiv:2206.13749",
    "title": "Adaptive Multi-view Rule Discovery for Weakly-Supervised Compatible  Products Prediction",
    "abstract": "On e-commerce platforms, predicting if two products are compatible with each\nother is an important functionality to achieve trustworthy product\nrecommendation and search experience for consumers. However, accurately\npredicting product compatibility is difficult due to the heterogeneous product\ndata and the lack of manually curated training data. We study the problem of\ndiscovering effective labeling rules that can enable weakly-supervised product\ncompatibility prediction. We develop AMRule, a multi-view rule discovery\nframework that can (1) adaptively and iteratively discover novel rulers that\ncan complement the current weakly-supervised model to improve compatibility\nprediction; (2) discover interpretable rules from both structured attribute\ntables and unstructured product descriptions. AMRule adaptively discovers\nlabeling rules from large-error instances via a boosting-style strategy, the\nhigh-quality rules can remedy the current model's weak spots and refine the\nmodel iteratively. For rule discovery from structured product attributes, we\ngenerate composable high-order rules from decision trees; and for rule\ndiscovery from unstructured product descriptions, we generate prompt-based\nrules from a pre-trained language model. Experiments on 4 real-world datasets\nshow that AMRule outperforms the baselines by 5.98% on average and improves\nrule quality and rule proposal efficiency.",
    "descriptor": "\nComments: KDD 2022 Applied Data Science Track\n",
    "authors": [
      "Rongzhi Zhang",
      "Rebecca West",
      "Xiquan Cui",
      "Chao Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.13749"
  },
  {
    "id": "arXiv:2206.13752",
    "title": "Sub-Block Rearranged Staircase Codes for Optical Transport Networks",
    "abstract": "We propose a new family of spatially coupled product codes, called sub-block\nrearranged staircase (SR-staircase) codes. Each SR-staircase code block is\nconstructed by encoding rearranged preceding code blocks and new information\nblocks, where the rearrangement involves sub-blocks decomposition and\ntransposition. The proposed codes can be constructed to have each code block\nsize of $1/q$ to that of the conventional staircase codes while having the same\nrate and component codes, for any positive integer $q$. In this regard, we can\nuse strong algebraic component codes to construct SR-staircase codes with a\nsimilar or the same code block size and rate as staircase codes with weak\ncomponent codes. Moreover, both waterfall and error floor performance can be\nfurther improved by using a large coupling width. The superior performance of\nthe proposed codes is demonstrated through density evolution and error floor\nanalysis as well as simulation.",
    "descriptor": "\nComments: 6 pages, 3 figures, 1 table, accepted by the 2022 IEEE International Symposium on Information Theory (ISIT). arXiv admin note: substantial text overlap with arXiv:2201.09415\n",
    "authors": [
      "Min Qiu",
      "Jinhong Yuan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.13752"
  },
  {
    "id": "arXiv:2206.13754",
    "title": "DistSPECTRL: Distributing Specifications in Multi-Agent Reinforcement  Learning Systems",
    "abstract": "While notable progress has been made in specifying and learning objectives\nfor general cyber-physical systems, applying these methods to distributed\nmulti-agent systems still pose significant challenges. Among these are the need\nto (a) craft specification primitives that allow expression and interplay of\nboth local and global objectives, (b) tame explosion in the state and action\nspaces to enable effective learning, and (c) minimize coordination frequency\nand the set of engaged participants for global objectives. To address these\nchallenges, we propose a novel specification framework that allows natural\ncomposition of local and global objectives used to guide training of a\nmulti-agent system. Our technique enables learning expressive policies that\nallow agents to operate in a coordination-free manner for local objectives,\nwhile using a decentralized communication protocol for enforcing global ones.\nExperimental results support our claim that sophisticated multi-agent\ndistributed planning problems can be effectively realized using\nspecification-guided learning.",
    "descriptor": "\nComments: ECML-PKDD 2022\n",
    "authors": [
      "Joe Eappen",
      "Suresh Jagannathan"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.13754"
  },
  {
    "id": "arXiv:2206.13756",
    "title": "On the Impact of Noises in Crowd-Sourced Data for Speech Translation",
    "abstract": "Training speech translation (ST) models requires large and high-quality\ndatasets. MuST-C is one of the most widely used ST benchmark datasets. It\ncontains around 400 hours of speech-transcript-translation data for each of the\neight translation directions. This dataset passes several quality-control\nfilters during creation. However, we find that MuST-C still suffers from three\nmajor quality issues: audio-text misalignment, inaccurate translation, and\nunnecessary speaker's name. What are the impacts of these data quality issues\nfor model development and evaluation? In this paper, we propose an automatic\nmethod to fix or filter the above quality issues, using English-German (En-De)\ntranslation as an example. Our experiments show that ST models perform better\non clean test sets, and the rank of proposed models remains consistent across\ndifferent test sets. Besides, simply removing misaligned data points from the\ntraining set does not lead to a better ST model.",
    "descriptor": "\nComments: Accepted to IWSLT 2022 as a scientific paper\n",
    "authors": [
      "Siqi Ouyang",
      "Rong Ye",
      "Lei Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.13756"
  },
  {
    "id": "arXiv:2206.13757",
    "title": "Flexible text generation for counterfactual fairness probing",
    "abstract": "A common approach for testing fairness issues in text-based classifiers is\nthrough the use of counterfactuals: does the classifier output change if a\nsensitive attribute in the input is changed? Existing counterfactual generation\nmethods typically rely on wordlists or templates, producing simple\ncounterfactuals that don't take into account grammar, context, or subtle\nsensitive attribute references, and could miss issues that the wordlist\ncreators had not considered. In this paper, we introduce a task for generating\ncounterfactuals that overcomes these shortcomings, and demonstrate how large\nlanguage models (LLMs) can be leveraged to make progress on this task. We show\nthat this LLM-based method can produce complex counterfactuals that existing\nmethods cannot, comparing the performance of various counterfactual generation\nmethods on the Civil Comments dataset and showing their value in evaluating a\ntoxicity classifier.",
    "descriptor": "",
    "authors": [
      "Zee Fryer",
      "Vera Axelrod",
      "Ben Packer",
      "Alex Beutel",
      "Jilin Chen",
      "Kellie Webster"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.13757"
  },
  {
    "id": "arXiv:2206.13758",
    "title": "Exploring linguistic feature and model combination for speech  recognition based automatic AD detection",
    "abstract": "Early diagnosis of Alzheimer's disease (AD) is crucial in facilitating\npreventive care and delay progression. Speech based automatic AD screening\nsystems provide a non-intrusive and more scalable alternative to other clinical\nscreening techniques. Scarcity of such specialist data leads to uncertainty in\nboth model selection and feature learning when developing such systems. To this\nend, this paper investigates the use of feature and model combination\napproaches to improve the robustness of domain fine-tuning of BERT and Roberta\npre-trained text encoders on limited data, before the resulting embedding\nfeatures being fed into an ensemble of backend classifiers to produce the final\nAD detection decision via majority voting. Experiments conducted on the\nADReSS20 Challenge dataset suggest consistent performance improvements were\nobtained using model and feature combination in system development.\nState-of-the-art AD detection accuracies of 91.67 percent and 93.75 percent\nwere obtained using manual and ASR speech transcripts respectively on the\nADReSS20 test set consisting of 48 elderly speakers.",
    "descriptor": "\nComments: Accepted by INTERSPEECH 2022\n",
    "authors": [
      "Yi Wang",
      "Tianzi Wang",
      "Zi Ye",
      "Lingwei Meng",
      "Shoukang Hu",
      "Xixin Wu",
      "Xunying Liu",
      "Helen Meng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.13758"
  },
  {
    "id": "arXiv:2206.13761",
    "title": "Classification of ADHD Patients Using Kernel Hierarchical Extreme  Learning Machine",
    "abstract": "Recently, the application of deep learning models to diagnose\nneuropsychiatric diseases from brain imaging data has received more and more\nattention. However, in practice, exploring interactions in brain functional\nconnectivity based on operational magnetic resonance imaging data is critical\nfor studying mental illness. Since Attention-Deficit and Hyperactivity Disorder\n(ADHD) is a type of chronic disease that is very difficult to diagnose in the\nearly stages, it is necessary to improve the diagnosis accuracy of such illness\nusing machine learning models treating patients before the critical condition.\nIn this study, we utilize the dynamics of brain functional connectivity to\nmodel features from medical imaging data, which can extract the differences in\nbrain function interactions between Normal Control (NC) and ADHD. To meet that\nrequirement, we employ the Bayesian connectivity change-point model to detect\nbrain dynamics using the local binary encoding approach and kernel hierarchical\nextreme learning machine for classifying features. To verify our model, we\nexperimented with it on several real-world children's datasets, and our results\nachieved superior classification rates compared to the state-of-the-art models.",
    "descriptor": "\nComments: 8 pages, 6 figures. arXiv admin note: substantial text overlap with arXiv:2202.08953\n",
    "authors": [
      "Sartaj Ahmed Salman",
      "Zhichao Lian",
      "Milad Taleby Ahvanooey",
      "Hiroki Takahashi",
      "Yuduo Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.13761"
  },
  {
    "id": "arXiv:2206.13764",
    "title": "Detecting Arbitrary Order Beneficial Feature Interactions for  Recommender Systems",
    "abstract": "Detecting beneficial feature interactions is essential in recommender\nsystems, and existing approaches achieve this by examining all the possible\nfeature interactions. However, the cost of examining all the possible\nhigher-order feature interactions is prohibitive (exponentially growing with\nthe order increasing). Hence existing approaches only detect limited order\n(e.g., combinations of up to four features) beneficial feature interactions,\nwhich may miss beneficial feature interactions with orders higher than the\nlimitation. In this paper, we propose a hypergraph neural network based model\nnamed HIRS. HIRS is the first work that directly generates beneficial feature\ninteractions of arbitrary orders and makes recommendation predictions\naccordingly. The number of generated feature interactions can be specified to\nbe much smaller than the number of all the possible interactions and hence, our\nmodel admits a much lower running time. To achieve an effective algorithm, we\nexploit three properties of beneficial feature interactions, and propose\ndeep-infomax-based methods to guide the interaction generation. Our\nexperimental results show that HIRS outperforms state-of-the-art algorithms by\nup to 5% in terms of recommendation accuracy.",
    "descriptor": "\nComments: KDD 2022, 11 pages, 12 figures, 5 tables\n",
    "authors": [
      "Yixin Su",
      "Yunxiang Zhao",
      "Sarah Erfani",
      "Junhao Gan",
      "Rui Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.13764"
  },
  {
    "id": "arXiv:2206.13765",
    "title": "Indiscernibles and Wideness in Monadically Stable and Monadically NIP  Classes",
    "abstract": "An indiscernible sequence $(\\bar a_i)_{1\\leq i\\leq n}$ in a structure is an\nordered sequence of tuples of elements which is very homogeneous in the sense\nthat any two finite subsequences of the same length satisfy the same\nfirst-order formulas. We provide new characterizations of monadically stable\nand monadically NIP classes of structures in terms of indiscernible sequences\nby showing that they impose a strong structure on their neighborhoods. In\nparticular, we show that every formula~$\\phi(x,\\bar y)$, where $x$ is a single\nfree variable, has alternation rank at most $2$ over every sufficiently long\nindiscernible sequence in a monadically NIP class. We provide a second new\ncharacterization of monadically stable classes of graphs in terms of a new\nnotion called flip-wideness. Flip-wideness generalizes the notion of uniform\nquasi-wideness, which characterizes nowhere dense classes and had a key impact\non the combinatorial and algorithmic treatment of nowhere dense classes. All\nour proofs are constructive and yield efficient algorithms.",
    "descriptor": "",
    "authors": [
      "Jan Dreier",
      "Nikolas M\u00e4hlmann",
      "Sebastian Siebertz",
      "Szymon Toru\u0144czyk"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.13765"
  },
  {
    "id": "arXiv:2206.13772",
    "title": "Abstract interpretation, Hoare logic, and incorrectness logic for  quantum programs",
    "abstract": "Abstract interpretation, Hoare logic, and incorrectness (or reverse Hoare)\nlogic are powerful techniques for static analysis of computer programs. All of\nthem have been successfully extended to the quantum setting, but largely\ndeveloped in parallel. In this paper, we examine the relationship between these\ntechniques in the context of verifying quantum while-programs, where the\nabstract domain and the set of assertions for quantum states are\nwell-structured. In particular, we show that any complete quantum abstract\ninterpretation induces a quantum Hoare logic and a quantum incorrectness logic,\nboth of which are sound and relatively complete. Unlike the logics proposed in\nthe literature, the induced logic systems are in a forward manner, making them\nmore useful in certain applications. Conversely, any sound and relatively\ncomplete quantum Hoare logic or quantum incorrectness logic induces a complete\nquantum abstract interpretation. As an application, we are able to show the\nnon-existence of any sound and relatively complete quantum Hoare logic or\nincorrectness logic if tuples of local subspaces are taken as assertions.",
    "descriptor": "\nComments: 26 pages\n",
    "authors": [
      "Yuan Feng",
      "Sanjiang Li"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.13772"
  },
  {
    "id": "arXiv:2206.13773",
    "title": "On Relaxation of Dominant Sets",
    "abstract": "In a graph $G = (V,E)$, a k-ruling set $S$ is one in which all vertices $V$ \\\n$S$ are at most $k$ distance from $S$. Finding a minimum k-ruling set is\nintrinsically linked to the minimum dominating set problem and maximal\nindependent set problem, which have been extensively studied in graph theory.\nThis paper presents the first known algorithm for solving all k-ruling set\nproblems in conjunction with known minimum dominating set algorithms at only\nadditional polynomial time cost compared to a minimum dominating set. The\nalgorithm further succeeds for $(\\alpha, \\alpha - 1)$ ruling sets in which\n$\\alpha > 1$, for which constraints exist on the proximity of vertices v $\\in\nS$. This secondary application instead works in conjunction with maximal\nindependent set algorithms.",
    "descriptor": "",
    "authors": [
      "Max Koster"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2206.13773"
  },
  {
    "id": "arXiv:2206.13774",
    "title": "Assessment of U.S. Department of Transportation Lane-Level Map for  Connected Vehicle Applications",
    "abstract": "High-definition (Hi-Def) digital maps are an indispensable automated driving\ntechnology that is developing rapidly. There are various commercial or\ngovernmental map products in the market. It is notable that the U.S. Department\nof Transportation (USDOT) map tool allows the user to create MAP and Signal\nPhase and Timing (SPaT) messages with free access. However, an analysis of the\naccuracy of this map tool is currently lacking in the literature. This paper\nprovides such an analysis. The analysis manually selects 39 feature points\nwithin about 200 meters of the verified point and 55 feature points over longer\ndistances from the verified point. All feature locations are surveyed using\nGNSS and mapped using the USDOT tool. Different error sources are evaluated to\nallow assessment of the USDOT map accuracy. In this investigation, The USDOT\nmap tool is demonstrated to achieve 17 centimeters horizontal accuracy, which\nmeets the lane-level map requirement. The maximum horizontal map error is less\nthan 30 centimeters.",
    "descriptor": "\nComments: 6 pages, 6 figures\n",
    "authors": [
      "Wang Hu",
      "David Oswald",
      "Guoyuan Wu",
      "Jay A. Farrell"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.13774"
  },
  {
    "id": "arXiv:2206.13776",
    "title": "A Scalable Blockchain-based Smart Contract Model for Decentralized  Voltage Stability Using Sharding Technique",
    "abstract": "Blockchain technologies are one possible avenue for increasing the resilience\nof the Smart Grid, by decentralizing the monitoring and control of system-level\nobjectives such as voltage stability protection. They furthermore offer\nbenefits in data immutability and traceability, as blockchains are\ncryptographically secured. However, the performance of blockchain-based systems\nin real-time grid monitoring and control has never been empirically tested.\nThis study proposes implementing a decentralized voltage stability algorithm\nusing blockchain-based smart contracts, as a testbed for evaluating the\nperformance of blockchains in real-time control. We furthermore investigate\nsharding mechanisms as a means of improving the system's scalability with fixed\ncomputing resources. We implement our models as a proof-of-concept prototype\nsystem using Hyperledger Fabric as our blockchain platform, the Matpower\nlibrary in MATLAB as our power system simulator, and Hyperledger Caliper as our\nperformance evaluation tool. We found that sharding does indeed lead to a\nsubstantial improvement in system scalability for this domain, measured by both\ntransaction success rates and transaction latency.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Kimia Honari",
      "Xiaotian Zhou",
      "Sara Rouhani",
      "Scott Dick",
      "Hao Liang",
      "James Miller Li",
      "James Miller"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.13776"
  },
  {
    "id": "arXiv:2206.13778",
    "title": "CC-Riddle: A Question Answering Dataset of Chinese Character Riddles",
    "abstract": "Chinese character riddle is a challenging riddle game which takes a single\ncharacter as the solution. The riddle describes the pronunciation, shape and\nmeaning of the solution character with rhetoric techniques. In this paper, we\npropose a Chinese character riddle dataset covering the majority of common\nsimplified Chinese characters by crawling riddles from the Web and generating\nbrand new ones. In the generation stage, we provide the Chinese phonetic\nalphabet, decomposition and explanation of the solution character for the\ngeneration model and get multiple riddle descriptions for each tested\ncharacter. Then the generated riddles are manually filtered and the final\ndataset, CC-Riddle is composed of both human-written riddles and filtered\ngenerated riddles. Furthermore, we build a character riddle QA system based on\nour dataset and find that the existing models struggle to solve such tricky\nquestions. CC-Riddle is now publicly available.",
    "descriptor": "\nComments: 10 pages, 8 figures, 7 tables\n",
    "authors": [
      "Fan Xu",
      "Yunxiang Zhang",
      "Xiaojun Wan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.13778"
  },
  {
    "id": "arXiv:2206.13784",
    "title": "Optimisation models for the day-ahead energy and reserve scheduling of a  hybrid wind-battery virtual power plant",
    "abstract": "This work presents a suite of two optimisation models for the short-term\nscheduling and redispatch of a virtual power plant (VPP) composed of a wind\nfarm and a Li-ion battery, that participates in the day-ahead energy and\nsecondary regulation reserve markets of the Iberian electricity market. First,\na two-stage stochastic mixed-integer linear programming model is used to obtain\nthe VPP's generation and reserve schedule and the opportunity cost of the\nenergy stored in the battery. The model has an hourly resolution and a\nlook-ahead period beyond the markets' scheduling horizon and considers the\nhourly battery degradation costs as a function of both the depth of discharge\nand the discharge rate. Different strategies are evaluated to forecast the\nreal-time use of the committed secondary regulation reserves. Second, a\ndeterministic MILP model is used to determine the redispatch of the VPP using\nas input the generation and reserve schedule and the VPP's storage opportunity\ncost provided by the former model and is executed on an hourly rolling basis.\nThe results obtained show that the proposed models are effective for the\nshort-term scheduling and redispatch of the VPP used with a low computational\ntime, making them tractable and practical for their daily use.",
    "descriptor": "\nComments: 13 pages, 8 figures and 2 tables\n",
    "authors": [
      "Daniel Fern\u00e1ndez-Mu\u00f1oz",
      "Juan I. P\u00e9rez-D\u00edaz"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.13784"
  },
  {
    "id": "arXiv:2206.13785",
    "title": "3D Multi-Object Tracking with Differentiable Pose Estimation",
    "abstract": "We propose a novel approach for joint 3D multi-object tracking and\nreconstruction from RGB-D sequences in indoor environments. To this end, we\ndetect and reconstruct objects in each frame while predicting dense\ncorrespondences mappings into a normalized object space. We leverage those\ncorrespondences to inform a graph neural network to solve for the optimal,\ntemporally-consistent 7-DoF pose trajectories of all objects. The novelty of\nour method is two-fold: first, we propose a new graph-based approach for\ndifferentiable pose estimation over time to learn optimal pose trajectories;\nsecond, we present a joint formulation of reconstruction and pose estimation\nalong the time axis for robust and geometrically consistent multi-object\ntracking. In order to validate our approach, we introduce a new synthetic\ndataset comprising 2381 unique indoor sequences with a total of 60k rendered\nRGB-D images for multi-object tracking with moving objects and camera positions\nderived from the synthetic 3D-FRONT dataset. We demonstrate that our method\nimproves the accumulated MOTA score for all test sequences by 24.8% over\nexisting state-of-the-art methods. In several ablations on synthetic and\nreal-world sequences, we show that our graph-based, fully end-to-end-learnable\napproach yields a significant boost in tracking performance.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Dominik Schmauser",
      "Zeju Qiu",
      "Norman M\u00fcller",
      "Matthias Nie\u00dfner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.13785"
  },
  {
    "id": "arXiv:2206.13787",
    "title": "Improving Correlation Capture in Generating Imbalanced Data using  Differentially Private Conditional GANs",
    "abstract": "Despite the remarkable success of Generative Adversarial Networks (GANs) on\ntext, images, and videos, generating high-quality tabular data is still under\ndevelopment owing to some unique challenges such as capturing dependencies in\nimbalanced data, optimizing the quality of synthetic patient data while\npreserving privacy. In this paper, we propose DP-CGANS, a differentially\nprivate conditional GAN framework consisting of data transformation, sampling,\nconditioning, and networks training to generate realistic and\nprivacy-preserving tabular data. DP-CGANS distinguishes categorical and\ncontinuous variables and transforms them to latent space separately. Then, we\nstructure a conditional vector as an additional input to not only presents the\nminority class in the imbalanced data, but also capture the dependency between\nvariables. We inject statistical noise to the gradients in the networking\ntraining process of DP-CGANS to provide a differential privacy guarantee. We\nextensively evaluate our model with state-of-the-art generative models on three\npublic datasets and two real-world personal health datasets in terms of\nstatistical similarity, machine learning performance, and privacy measurement.\nWe demonstrate that our model outperforms other comparable models, especially\nin capturing dependency between variables. Finally, we present the balance\nbetween data utility and privacy in synthetic data generation considering the\ndifferent data structure and characteristics of real-world datasets such as\nimbalance variables, abnormal distributions, and sparsity of data.",
    "descriptor": "",
    "authors": [
      "Chang Sun",
      "Johan van Soest",
      "Michel Dumontier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.13787"
  },
  {
    "id": "arXiv:2206.13796",
    "title": "Adapted variable density subsampling for compressed sensing",
    "abstract": "Recent results in compressed sensing showed that the optimal subsampling\nstrategy should take into account the sparsity pattern of the signal at hand.\nThis oracle-like knowledge, even though desirable, nevertheless remains elusive\nin most practical application. We try to close this gap by showing how the\nsparsity patterns can instead be characterised via a probability distribution\non the supports of the sparse signals allowing us to again derive optimal\nsubsampling strategies. This probability distribution can be easily estimated\nfrom signals of the same signal class, achieving state of the art performance\nin numerical experiments. Our approach also extends to structured acquisition,\nwhere instead of isolated measurements, blocks of measurements are taken.",
    "descriptor": "",
    "authors": [
      "Simon Ruetz"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.13796"
  },
  {
    "id": "arXiv:2206.13801",
    "title": "Joint Precoding for Active Intelligent Transmitting Surface Empowered  Outdoor-to-Indoor Communication in mmWave Cellular Networks",
    "abstract": "Outdoor-to-indoor communications in millimeter-wave (mmWave) cellular\nnetworks have been one challenging research problem due to the severe\nattenuation and the high penetration loss caused by the propagation\ncharacteristics of mmWave signals. We propose a viable solution to implement\nthe outdoor-to-indoor mmWave communication system with the aid of an active\nintelligent transmitting surface (active-ITS), where the active-ITS allows the\nincoming signal from an outdoor base station (BS) to pass through the surface\nand be received by the indoor user-equipments (UEs) after shifting its phase\nand magnifying its amplitude. Then, the problem of joint precoding of the BS\nand active-ITS is investigated to maximize the weighted sum-rate (WSR) of the\ncommunication system. An efficient block coordinate descent (BCD) based\nalgorithm is developed to solve it with the suboptimal solutions in nearly\nclosed-forms. In addition, to reduce the size and hardware cost of an\nactive-ITS, we provide a block-amplifying architecture to partially remove the\ncircuit components for power-amplifying, where multiple transmissive-type\nelements (TEs) in each block share a same power amplifier. Simulations indicate\nthat active-ITS has the potential of achieving a given performance with much\nfewer TEs compared to the passive-ITS under the same total system power\nconsumption, which makes it suitable for application to the size-limited and\naesthetic-needed scenario, and the inevitable performance degradation caused by\nthe block-amplifying architecture is acceptable.",
    "descriptor": "\nComments: 30 pages, 8 figures\n",
    "authors": [
      "Xie Xie",
      "Chen He",
      "Feifei Gao",
      "Zhu Han",
      "Z. Jane Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.13801"
  },
  {
    "id": "arXiv:2206.13803",
    "title": "FedRare: Federated Learning with Intra- and Inter-Client Contrast for  Effective Rare Disease Classification",
    "abstract": "Federated learning (FL), enabling different medical institutions or clients\nto train a model collaboratively without data privacy leakage, has drawn great\nattention in medical imaging communities recently. Though inter-client data\nheterogeneity has been thoroughly studied, the class imbalance problem due to\nthe existence of rare diseases still is under-explored. In this paper, we\npropose a novel FL framework FedRare for medical image classification\nespecially on dealing with data heterogeneity with the existence of rare\ndiseases. In FedRare, each client trains a model locally to extract\nhighly-separable latent features for classification via intra-client supervised\ncontrastive learning. Considering the limited data on rare diseases, we build\npositive sample queues for augmentation (i.e. data re-sampling). The server in\nFedRare would collect the latent features from clients and automatically select\nthe most reliable latent features as guidance sent back to clients. Then, each\nclient is jointly trained by an inter-client contrastive loss to align its\nlatent features to the federated latent features of full classes. In this way,\nthe parameter/feature variances across clients are effectively minimized,\nleading to better convergence and performance improvements. Experimental\nresults on the publicly-available dataset for skin lesion diagnosis demonstrate\nFedRare's superior performance. Under the 10-client federated setting where\nfour clients have no rare disease samples, FedRare achieves an average increase\nof 9.60% and 5.90% in balanced accuracy compared to the baseline framework\nFedAvg and the state-of-the-art approach FedIRM respectively. Considering the\nboard existence of rare diseases in clinical scenarios, we believe FedRare\nwould benefit future FL framework design for medical image classification. The\nsource code of this paper is publicly available at\nhttps://github.com/wnn2000/FedRare.",
    "descriptor": "",
    "authors": [
      "Nannan Wu",
      "Li Yu",
      "Xin Yang",
      "Kwang-Ting Cheng",
      "Zengqiang Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.13803"
  },
  {
    "id": "arXiv:2206.13804",
    "title": "Multivariable Grid-Forming Converters with Direct States Control",
    "abstract": "A multi-input multi-output based grid-forming (MIMO-GFM) converter has been\nproposed using multivariable feedback control, which has been proven as a\nsuperior and robust system using low-order controllers. However, the original\nMIMO-GFM control is easily affected by the high-frequency components especially\nfor the converter without inner cascaded voltage and current loops and when it\nis connected into a strong grid. This paper proposes an improved MIMO-GFM\ncontrol method, where the frequency and internal voltage are chosen as state\nvariables to be controlled directly. In this way, the impact of high-frequency\ncomponents is eliminated without increasing the complexity of the control\nsystem. The H-infinity synthesis is used to tune the parameters to obtain an\noptimized performance. Experimental results verify the effectiveness of the\nproposed method.",
    "descriptor": "",
    "authors": [
      "Meng Chen",
      "Dao Zhou",
      "Frede Blaabjerg"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.13804"
  },
  {
    "id": "arXiv:2206.13810",
    "title": "Gray Images of Cyclic Codes over $\\mathbb{Z}_{p^2}$ and  $\\mathbb{Z}_p\\mathbb{Z}_{p^2}",
    "abstract": "In the paper, we firstly study the algebraic structures of $\\mathbb{Z}_p\n\\mathbb{Z}_{p^k}$-additive cyclic codes and give the generator polynomials and\nthe minimal spanning set of these codes. Secondly, a necessary and sufficient\ncondition for a class of $\\mathbb{Z}_p\\mathbb{Z}_{p^2}$-additive codes whose\nGray images are linear (not necessarily cyclic) over $\\mathbb{Z}_p$ is given.\nMoreover, as for some special families of cyclic codes over $\\mathbb{Z}_{9}$\nand $\\mathbb{Z}_3 \\mathbb{Z}_{9}$, the linearity of the Gray images is\ndetermined.",
    "descriptor": "",
    "authors": [
      "Minjia Shi",
      "Xuan Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.13810"
  },
  {
    "id": "arXiv:2206.13811",
    "title": "Influence of a Medium on Capacitive Power Transfer Capability",
    "abstract": "Despite the advantages of capacitive power transfer (CPT), inductive power\ntransfer (IPT) is still preferred. The reason: IPT systems have a gap power\ndensity in air that is 400 times greater. Conclusively, IPT can transmit more\npower than CPT over greater distances in air, but what about other media? This\npaper gives an answer on how media, different from air, influence the power\ntransfer over different distances. First, we analyze theoretically the\ncapacitive coupling with different media in the gap. Next, we simulate the CPT\nsystem using finite element software and compared it with the theoretical\nanalysis. Finally, we employ the results of the finite element simulation in a\npower electronic simulation to examine the influence of the medium on the\nelectrical power transfer.",
    "descriptor": "\nComments: 4 pages, 9 figures, IEEE WPW 2022\n",
    "authors": [
      "Cedric Lecluyse",
      "Ben Minnaert",
      "Simon Ravyts",
      "Michael Kleemann"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.13811"
  },
  {
    "id": "arXiv:2206.13813",
    "title": "Sublinear-Time Clustering Oracle for Signed Graphs",
    "abstract": "Social networks are often modeled using signed graphs, where vertices\ncorrespond to users and edges have a sign that indicates whether an interaction\nbetween users was positive or negative. The arising signed graphs typically\ncontain a clear community structure in the sense that the graph can be\npartitioned into a small number of polarized communities, each defining a\nsparse cut and indivisible into smaller polarized sub-communities. We provide a\nlocal clustering oracle for signed graphs with such a clear community\nstructure, that can answer membership queries, i.e., \"Given a vertex $v$, which\ncommunity does $v$ belong to?\", in sublinear time by reading only a small\nportion of the graph. Formally, when the graph has bounded maximum degree and\nthe number of communities is at most $O(\\log n)$, then with\n$\\tilde{O}(\\sqrt{n}\\operatorname{poly}(1/\\varepsilon))$ preprocessing time, our\noracle can answer each membership query in\n$\\tilde{O}(\\sqrt{n}\\operatorname{poly}(1/\\varepsilon))$ time, and it correctly\nclassifies a $(1-\\varepsilon)$-fraction of vertices w.r.t. a set of hidden\nplanted ground-truth communities. Our oracle is desirable in applications where\nthe clustering information is needed for only a small number of vertices.\nPreviously, such local clustering oracles were only known for unsigned graphs;\nour generalization to signed graphs requires a number of new ideas and gives a\nnovel spectral analysis of the behavior of random walks with signs. We evaluate\nour algorithm for constructing such an oracle and answering membership queries\non both synthetic and real-world datasets, validating its performance in\npractice.",
    "descriptor": "\nComments: To appear at ICML'22\n",
    "authors": [
      "Stefan Neumann",
      "Pan Peng"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.13813"
  },
  {
    "id": "arXiv:2206.13816",
    "title": "Learning the Evolutionary and Multi-scale Graph Structure for  Multivariate Time Series Forecasting",
    "abstract": "Recent studies have shown great promise in applying graph neural networks for\nmultivariate time series forecasting, where the interactions of time series are\ndescribed as a graph structure and the variables are represented as the graph\nnodes. Along this line, existing methods usually assume that the graph\nstructure (or the adjacency matrix), which determines the aggregation manner of\ngraph neural network, is fixed either by definition or self-learning. However,\nthe interactions of variables can be dynamic and evolutionary in real-world\nscenarios. Furthermore, the interactions of time series are quite different if\nthey are observed at different time scales. To equip the graph neural network\nwith a flexible and practical graph structure, in this paper, we investigate\nhow to model the evolutionary and multi-scale interactions of time series. In\nparticular, we first provide a hierarchical graph structure cooperated with the\ndilated convolution to capture the scale-specific correlations among time\nseries. Then, a series of adjacency matrices are constructed under a recurrent\nmanner to represent the evolving correlations at each layer. Moreover, a\nunified neural network is provided to integrate the components above to get the\nfinal prediction. In this way, we can capture the pair-wise correlations and\ntemporal dependency simultaneously. Finally, experiments on both single-step\nand multi-step forecasting tasks demonstrate the superiority of our method over\nthe state-of-the-art approaches.",
    "descriptor": "",
    "authors": [
      "Junchen Ye",
      "Zihan Liu",
      "Bowen Du",
      "Leilei Sun",
      "Weimiao Li",
      "Yanjie Fu",
      "Hui Xiong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.13816"
  },
  {
    "id": "arXiv:2206.13817",
    "title": "Comparison of Speech Representations for the MOS Prediction System",
    "abstract": "Automatic methods to predict Mean Opinion Score (MOS) of listeners have been\nresearched to assure the quality of Text-to-Speech systems. Many previous\nstudies focus on architectural advances (e.g. MBNet, LDNet, etc.) to capture\nrelations between spectral features and MOS in a more effective way and\nachieved high accuracy. However, the optimal representation in terms of\ngeneralization capability still largely remains unknown. To this end, we\ncompare the performance of Self-Supervised Learning (SSL) features obtained by\nthe wav2vec framework to that of spectral features such as magnitude of\nspectrogram and melspectrogram. Moreover, we propose to combine the SSL\nfeatures and features which we believe to retain essential information to the\nautomatic MOS to compensate each other for their drawbacks. We conduct\ncomprehensive experiments on a large-scale listening test corpus collected from\npast Blizzard and Voice Conversion Challenges. We found that the wav2vec\nfeature set showed the best generalization even though the given ground-truth\nwas not always reliable. Furthermore, we found that the combinations performed\nthe best and analyzed how they bridged the gap between spectral and the wav2vec\nfeature sets.",
    "descriptor": "\nComments: 5 pages, 4 figures\n",
    "authors": [
      "Aki Kunikoshi",
      "Jaebok Kim",
      "Wonsuk Jun",
      "K\u00e5re Sj\u00f6lander"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.13817"
  },
  {
    "id": "arXiv:2206.13828",
    "title": "Improving Tese Case Generation for Python Native Libraries Through  Constraints on Input Data Structures",
    "abstract": "Modern Python projects execute computational functions using native libraries\nand give Python interfaces to boost execution speed; hence, testing these\nlibraries becomes critical to the project's robustness. One challenge is that\nexisting approaches use coverage to guide generation, but native libraries run\nas black boxes to Python code with no execution information. Another is that\ndynamic binary instrumentation reduces testing performance as it needs to\nmonitor both native libraries and the Python virtual machine.\nTo address these challenges, in this paper, we propose an automated test case\ngeneration approach that works at the Python code layer. Our insight is that\nmany path conditions in native libraries are for processing input data\nstructures through interacting with the VM. In our approach, we instrument the\nPython Interpreter to monitor the interactions between native libraries and VM,\nderive constraints on the structures, and then use the constraints to guide\ntest case generation. We implement our approach in a tool named PyCing and\napply it to six widely-used Python projects. The experimental results reveal\nthat with the structure constraint guidance, PyCing can cover more execution\npaths than existing test cases and state-of-the-art tools. Also, with the\ncheckers in the testing framework Pytest, PyCing can identify segmentation\nfaults in 10 Python interfaces and memory leaks in 9. Our instrumentation\nstrategy also has an acceptable influence on testing efficiency.",
    "descriptor": "\nComments: 11 panges\n",
    "authors": [
      "Xin Zhang",
      "Xutong Ma",
      "Jiwen Yan",
      "Baoquan Cui",
      "Jun Yan",
      "Jian Zhang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.13828"
  },
  {
    "id": "arXiv:2206.13829",
    "title": "Cross-Forgery Analysis of Vision Transformers and CNNs for Deepfake  Image Detection",
    "abstract": "Deepfake Generation Techniques are evolving at a rapid pace, making it\npossible to create realistic manipulated images and videos and endangering the\nserenity of modern society. The continual emergence of new and varied\ntechniques brings with it a further problem to be faced, namely the ability of\ndeepfake detection models to update themselves promptly in order to be able to\nidentify manipulations carried out using even the most recent methods. This is\nan extremely complex problem to solve, as training a model requires large\namounts of data, which are difficult to obtain if the deepfake generation\nmethod is too recent. Moreover, continuously retraining a network would be\nunfeasible. In this paper, we ask ourselves if, among the various deep learning\ntechniques, there is one that is able to generalise the concept of deepfake to\nsuch an extent that it does not remain tied to one or more specific deepfake\ngeneration methods used in the training set. We compared a Vision Transformer\nwith an EfficientNetV2 on a cross-forgery context based on the ForgeryNet\ndataset. From our experiments, It emerges that EfficientNetV2 has a greater\ntendency to specialize often obtaining better results on training methods while\nVision Transformers exhibit a superior generalization ability that makes them\nmore competent even on images generated with new methodologies.",
    "descriptor": "",
    "authors": [
      "Davide Alessandro Coccomini",
      "Roberto Caldelli",
      "Fabrizio Falchi",
      "Claudio Gennaro",
      "Giuseppe Amato"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.13829"
  },
  {
    "id": "arXiv:2206.13831",
    "title": "Gradual Soundness: Lessons from Static Python",
    "abstract": "Context: Gradually-typed languages allow typed and untyped code to\ninteroperate, but typically come with significant drawbacks. In some languages,\nthe types are unreliable; in others, communication across type boundaries can\nbe extremely expensive; and still others allow only limited forms of\ninteroperability. The research community is actively seeking a sound, fast, and\nexpressive approach to gradual typing.\nInquiry: This paper describes Static Python, a language developed by\nengineers at Instagram that has proven itself sound, fast, and reasonably\nexpressive in production. Static Python's approach to gradual types is\nessentially a programmer-tunable combination of the concrete and transient\napproaches from the literature. Concrete types provide full soundness and low\nperformance overhead, but impose nonlocal constraints. Transient types are\nsound in a shallow sense and easier to use; they help to bridge the gap between\nuntyped code and typed concrete code.\nApproach: We evaluate the language in its current state and develop a model\nthat captures the essence of its approach to gradual types. We draw upon\npersonal communication, bug reports, and the Static Python regression test\nsuite to develop this model.\nKnowledge: Our main finding is that the gradual soundness that arises from a\nmix of concrete and transient types is an effective way to lower the\nmaintenance cost of the concrete approach. We also find that method-based JIT\ntechnology can eliminate the costs of the transient approach. On a more\ntechnical level, this paper describes two contributions: a model of Static\nPython and a performance evaluation of Static Python. The process of\nformalization found several errors in the implementation, including fatal\nerrors.\nGrounding: Our model of Static Python is implemented in PLT Redex and tested\nusing property-based soundness tests and 265 tests from the Static Python\nregression suite. This paper includes a small core of the model to convey the\nmain ideas of the Static Python approach and its soundness. Our performance\nclaims are based on production experience in the Instagram web server.\nMigrations to Static Python in the server have caused a 3.7\\% increase in\nrequests handled per second at maximum CPU load.\nImportance: Static Python is the first sound gradual language whose\npiece-meal application to a realistic codebase has consistently improved\nperformance. Other language designers may wish to replicate its approach,\nespecially those who currently maintain unsound gradual languages and are\nseeking a path to soundness.",
    "descriptor": "",
    "authors": [
      "Kuang-Chen Lu",
      "Ben Greenman",
      "Carl Meyer",
      "Dino Viehland",
      "Aniket Panse",
      "Shriram Krishnamurthi"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2206.13831"
  },
  {
    "id": "arXiv:2206.13838",
    "title": "Inertia Estimation through Covariance Matrix",
    "abstract": "This work presents a technique to estimate on-line the inertia of a power\nsystem based on environment measurements. The proposed approach utilizes the\ncovariance matrix of these measurements and solves an optimization problem that\nfits such measurements to the synchronous machine classical model. We show that\nthe proposed technique is adequate to accurately estimate the actual inertia of\nsynchronous machines and also the virtual inertia provided by the controllers\nof converter-interfaced generators that emulate the behavior of synchronous\nmachines. We also show that the proposed approach is able to estimate the\ndamping of the machines. This feature is exploited to estimate the droop of\ngrid-following converters. The technique is comprehensively tested on a\nmodified version of the IEEE 39-bus system.",
    "descriptor": "",
    "authors": [
      "Federico Bizzarri",
      "Davide del Giudice",
      "Samuele Grillo",
      "Daniele Linaro",
      "Angelo Brambilla",
      "Federico Milano"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.13838"
  },
  {
    "id": "arXiv:2206.13839",
    "title": "On the Calculation of the Variance of Algebraic Variables in Power  System Dynamic Models with Stochastic Processes",
    "abstract": "This letter presents a technique to calculate the variance of algebraic\nvariables of power system models represented as a set of stochastic\ndifferential-algebraic equations. The technique utilizes the solution of a\nLyapunov equation and requires the calculation of the state matrix of the\nsystem. The IEEE 14-bus system serves to demonstrate the accuracy of the\nproposed technique over a wide range of variances of stochastic processes. The\naccuracy is evaluated by comparing the results with those obtained with Monte\nCarlo time domain simulations. Finally, a case study based on a 1479-bus\ndynamic model of the all-island Irish transmission system shows the\ncomputational efficiency of the proposed approach compared to the Monte Carlo\nmethod.",
    "descriptor": "",
    "authors": [
      "Federico Bizzarri",
      "Davide del Giudice",
      "Muhammad Adeen",
      "Samuele Grillo",
      "Daniele Linaro",
      "Angelo Brambilla",
      "Federico Milano"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.13839"
  },
  {
    "id": "arXiv:2206.13841",
    "title": "Program Semantics and a Verification Technique for Knowledge-Based  Multi-Agent Systems",
    "abstract": "We give a relational and a weakest precondition semantics for\n``knowledge-based programs'', i.e., programs that restrict observability of\nvariables so as to richly express changes in the knowledge of agents who can or\ncannot observe said variables. Based on these knowledge-based programs, we\ndefine a program-epistemic logic to model complex epistemic properties of the\nexecution of multi-agent systems. We translate the validity of\nprogram-epistemic logic formulae into first-order validity, using our weakest\nprecondition semantics and an ingenious book-keeping of variable assignment. We\nimplement our translation in Haskell in a general way (i.e., independently of\nthe programs in the logical statements), and test this novel verification\nmethod for our new program-epistemic logic on a series of well-established\nexamples.",
    "descriptor": "",
    "authors": [
      "Francesco Belardinelli",
      "Ioana Boureanu",
      "Vadim Malvone",
      "Solofomampionona Fortunat Rajaona"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.13841"
  },
  {
    "id": "arXiv:2206.13843",
    "title": "Manu: A Cloud Native Vector Database Management System",
    "abstract": "With the development of learning-based embedding models, embedding vectors\nare widely used for analyzing and searching unstructured data. As vector\ncollections exceed billion-scale, fully managed and horizontally scalable\nvector databases are necessary. In the past three years, through interaction\nwith our 1200+ industry users, we have sketched a vision for the features that\nnext-generation vector databases should have, which include long-term\nevolvability, tunable consistency, good elasticity, and high performance. We\npresent Manu, a cloud native vector database that implements these features. It\nis difficult to integrate all these features if we follow traditional DBMS\ndesign rules. As most vector data applications do not require complex data\nmodels and strong data consistency, our design philosophy is to relax the data\nmodel and consistency constraints in exchange for the aforementioned features.\nSpecifically, Manu firstly exposes the write-ahead log (WAL) and binlog as\nbackbone services. Secondly, write components are designed as log publishers\nwhile all read-only analytic and search components are designed as independent\nsubscribers to the log services. Finally, we utilize multi-version concurrency\ncontrol (MVCC) and a delta consistency model to simplify the communication and\ncooperation among the system components. These designs achieve a low coupling\namong the system components, which is essential for elasticity and evolution.\nWe also extensively optimize Manu for performance and usability with\nhardware-aware implementations and support for complex search semantics.",
    "descriptor": "\nComments: 14 pages, 13 figures\n",
    "authors": [
      "Rentong Guo",
      "Xiaofan Luan",
      "Long Xiang",
      "Xiao Yan",
      "Xiaomeng Yi",
      "Jigao Luo",
      "Qianya Cheng",
      "Weizhi Xu",
      "Jiarui Luo",
      "Frank Liu",
      "Zhenshan Cao",
      "Yanliang Qiao",
      "Ting Wang",
      "Bo Tang",
      "Charles Xie"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2206.13843"
  },
  {
    "id": "arXiv:2206.13844",
    "title": "Cooperative Multi-Agent Search on Endogenously-Changing Fitness  Landscapes",
    "abstract": "We use a multi-agent system to model how agents (representing firms) may\ncollaborate and adapt in a business 'landscape' where some, more influential,\nfirms are given the power to shape the landscape of other firms. The landscapes\nwe study are based on the well-known NK model of Kauffman, with the addition of\n'shapers', firms that can change the landscape's features for themselves and\nall other players. Our work investigates how firms that are additionally\nendowed with cognitive and experiential search, and the ability to form\ncollaborations with other firms, can use these capabilities to adapt more\nquickly and adeptly. We find that, in a collaborative group, firms must still\nhave a mind of their own and resist direct mimicry of stronger partners to\nattain better heights collectively. Larger groups and groups with more\ninfluential members generally do better, so targeted intelligent cooperation is\nbeneficial. These conclusions are tentative, and our results show a sensitivity\nto landscape ruggedness and \"malleability\" (i.e. the capacity of the landscape\nto be changed by the shaper firms). Overall, our work demonstrates the\npotential of computer science, evolution, and machine learning to contribute to\nbusiness strategy in these complex environments.",
    "descriptor": "",
    "authors": [
      "Chin Woei Lim",
      "Richard Allmendinger",
      "Joshua Knowles",
      "Ayesha Alhosani",
      "Mercedes Bleda"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.13844"
  },
  {
    "id": "arXiv:2206.13845",
    "title": "Welfare-Optimized Recommender Systems",
    "abstract": "We present a recommender system based on the Random Utility Model. Online\nshoppers are modeled as rational decision makers with limited information, and\nthe recommendation task is formulated as the problem of optimally enriching the\nshopper's awareness set. Notably, the price information and the shopper's\nWillingness-To-Pay play crucial roles. Furthermore, to better account for the\ncommercial nature of the recommendation, we unify the retailer and shoppers'\ncontradictory objectives into a single welfare metric, which we propose as a\nnew recommendation goal. We test our framework on synthetic data and show its\nperformance in a wide range of scenarios. This new framework, that was absent\nfrom the Recommender System literature, opens the door to Welfare-Optimized\nRecommender Systems, couponing, and price optimization.",
    "descriptor": "",
    "authors": [
      "Benjamin Heymann",
      "Flavian Vasile",
      "David Rohde"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.13845"
  },
  {
    "id": "arXiv:2206.13850",
    "title": "When the Sun Goes Down: Repairing Photometric Losses for All-Day Depth  Estimation",
    "abstract": "Self-supervised deep learning methods for joint depth and ego-motion\nestimation can yield accurate trajectories without needing ground-truth\ntraining data. However, as they typically use photometric losses, their\nperformance can degrade significantly when the assumptions these losses make\n(e.g. temporal illumination consistency, a static scene, and the absence of\nnoise and occlusions) are violated. This limits their use for e.g. nighttime\nsequences, which tend to contain many point light sources (including on dynamic\nobjects) and low signal-to-noise ratio (SNR) in darker image regions. In this\npaper, we show how to use a combination of three techniques to allow the\nexisting photometric losses to work for both day and nighttime images. First,\nwe introduce a per-pixel neural intensity transformation to compensate for the\nlight changes that occur between successive frames. Second, we predict a\nper-pixel residual flow map that we use to correct the reprojection\ncorrespondences induced by the estimated ego-motion and depth from the\nnetworks. And third, we denoise the training images to improve the robustness\nand accuracy of our approach. These changes allow us to train a single model\nfor both day and nighttime images without needing separate encoders or extra\nfeature networks like existing methods. We perform extensive experiments and\nablation studies on the challenging Oxford RobotCar dataset to demonstrate the\nefficacy of our approach for both day and nighttime sequences.",
    "descriptor": "",
    "authors": [
      "Madhu Vankadari",
      "Stuart Golodetz",
      "Sourav Garg",
      "Sangyun Shin",
      "Andrew Markham",
      "Niki Trigoni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.13850"
  },
  {
    "id": "arXiv:2206.13851",
    "title": "Which arithmetic operations can be performed in constant time in the RAM  model with addition?",
    "abstract": "In the literature of algorithms, the specific computation model is often not\nexplicit as it is assumed that the model of computation is the RAM (Random\nAccess Machine) model. However, the RAM model itself is ill-founded in the\nliterature, with disparate definitions and no unified results.\nThe ambition of this paper is to found the RAM model from scratch by\nexhibiting a RAM model that enjoys interesting algorithmic properties and the\nrobustness of its complexity classes, notably LIN, the class of linear-time\ncomputable problems, or the now well-known CONST-DELAY-lin class of enumeration\nproblems computable with constant delay after linear-time preprocessing,\nThe computation model that we define is a RAM whose contents and addresses of\nregisters are $O(N)$, where $N$ is the size (number of registers) of the input,\nand where the time cost of each instruction is 1 (unit cost criterion). The key\nto the foundation of our RAM model will be to prove that even if addition is\nthe only primitive operation, such a RAM can still compute all the basic\narithmetic operations in constant time after a linear-time preprocessing.\nMoreover, while the RAM handles only $O(N)$ integers in each register, we will\nshow that our RAM can handle $O(N^d)$ integers, for any fixed d, by storing\nthem on $O(d)$ registers and we will have surprising algorithms that computes\nmany operations acting on these \"polynomial\" integers -- addition, subtraction,\nmultiplication, division, exponential, integer logarithm, integer square root\n(or $c$-th root, for any integer $c$), bitwise logical operations, and, more\ngenerally, any operation computable in linear time on a cellular automaton --\nin constant time after a linear-time preprocessing.",
    "descriptor": "",
    "authors": [
      "\u00c9tienne Grandjean",
      "Louis Jachiet"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.13851"
  },
  {
    "id": "arXiv:2206.13852",
    "title": "Get Your Memory Right: The Crispy Resource Allocation Assistant for  Large-Scale Data Processing",
    "abstract": "Distributed dataflow systems like Apache Spark and Apache Hadoop enable\ndata-parallel processing of large datasets on clusters. Yet, selecting\nappropriate computational resources for dataflow jobs -- that neither lead to\nbottlenecks nor to low resource utilization -- is often challenging, even for\nexpert users such as data engineers. Further, existing automated approaches to\nresource selection rely on the assumption that a job is recurring to learn from\nprevious runs or to warrant the cost of full test runs to learn from. However,\nthis assumption often does not hold since many jobs are too unique.\nTherefore, we present Crispy, a method for optimizing data processing cluster\nconfigurations based on job profiling runs with small samples of the dataset on\njust a single machine. Crispy attempts to extrapolate the memory usage for the\nfull dataset to then choose a cluster configuration with enough total memory.\nIn our evaluation on a dataset with 1031 Spark and Hadoop jobs, we see a\nreduction of job execution costs by 56% compared to the baseline, while on\naverage spending less than ten minutes on profiling runs per job on a\nconsumer-grade laptop.",
    "descriptor": "\nComments: 9 pages, 3 figures, 2 tables, IEEE IC2E 2022\n",
    "authors": [
      "Jonathan Will",
      "Lauritz Thamsen",
      "Jonathan Bader",
      "Dominik Scheinert",
      "Odej Kao"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.13852"
  },
  {
    "id": "arXiv:2206.13856",
    "title": "SMT-based Weighted Model Integration with Structure Awareness",
    "abstract": "Weighted Model Integration (WMI) is a popular formalism aimed at unifying\napproaches for probabilistic inference in hybrid domains, involving logical and\nalgebraic constraints. Despite a considerable amount of recent work, allowing\nWMI algorithms to scale with the complexity of the hybrid problem is still a\nchallenge. In this paper we highlight some substantial limitations of existing\nstate-of-the-art solutions, and develop an algorithm that combines SMT-based\nenumeration, an efficient technique in formal verification, with an effective\nencoding of the problem structure. This allows our algorithm to avoid\ngenerating redundant models, resulting in substantial computational savings. An\nextensive experimental evaluation on both synthetic and real-world datasets\nconfirms the advantage of the proposed solution over existing alternatives.",
    "descriptor": "\nComments: Accepted for the 38th Conference on Uncertainty in Artificial Intelligence (UAI 2022)\n",
    "authors": [
      "Giuseppe Spallitta",
      "Gabriele Masina",
      "Paolo Morettin",
      "Andrea Passerini",
      "Roberto Sebastiani"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.13856"
  },
  {
    "id": "arXiv:2206.13858",
    "title": "Accurate and Real-time Pseudo Lidar Detection: Is Stereo Neural Network  Really Necessary?",
    "abstract": "The proposal of Pseudo-Lidar representation has significantly narrowed the\ngap between visual-based and active Lidar-based 3D object detection. However,\ncurrent researches exclusively focus on pushing the accuracy improvement of\nPseudo-Lidar by taking the advantage of complex and time-consuming neural\nnetworks. Seldom explore the profound characteristics of Pseudo-Lidar\nrepresentation to obtain the promoting opportunities. In this paper, we dive\ndeep into the pseudo Lidar representation and argue that the performance of 3D\nobject detection is not fully dependent on the high precision stereo depth\nestimation. We demonstrate that even for the unreliable depth estimation, with\nproper data processing and refining, it can achieve comparable 3D object\ndetection accuracy. With this finding, we further show the possibility that\nutilizing fast but inaccurate stereo matching algorithms in the Pseudo-Lidar\nsystem to achieve low latency responsiveness. In the experiments, we develop a\nsystem with a less powerful stereo matching predictor and adopt the proposed\nrefinement schemes to improve the accuracy. The evaluation on the KITTI\nbenchmark shows that the presented system achieves competitive accuracy to the\nstate-of-the-art approaches with only 23 ms computing, showing it is a suitable\ncandidate for deploying to real car-hold applications.",
    "descriptor": "",
    "authors": [
      "Haitao Meng",
      "Changcai Li",
      "Gang Chen",
      "Alois Knoll"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.13858"
  },
  {
    "id": "arXiv:2206.13861",
    "title": "LiteCON: An All-Photonic Neuromorphic Accelerator for Energy-efficient  Deep Learning (Preprint)",
    "abstract": "Deep learning is highly pervasive in today's data-intensive era. In\nparticular, convolutional neural networks (CNNs) are being widely adopted in a\nvariety of fields for superior accuracy. However, computing deep CNNs on\ntraditional CPUs and GPUs brings several performance and energy pitfalls.\nSeveral novel approaches based on ASIC, FPGA, and resistive-memory devices have\nbeen recently demonstrated with promising results. Most of them target only the\ninference (testing) phase of deep learning. There have been very limited\nattempts to design a full-fledged deep learning accelerator capable of both\ntraining and inference. It is due to the highly compute and memory-intensive\nnature of the training phase. In this paper, we propose LiteCON, a novel analog\nphotonics CNN accelerator. LiteCON uses silicon microdisk-based convolution,\nmemristor-based memory, and dense-wavelength-division-multiplexing for\nenergy-efficient and ultrafast deep learning. We evaluate LiteCON using a\ncommercial CAD framework (IPKISS) on deep learning benchmark models including\nLeNet and VGG-Net. Compared to the state-of-the-art, LiteCON improves the CNN\nthroughput, energy efficiency, and computational efficiency by up to 32x, 37x,\nand 5x respectively with trivial accuracy degradation.",
    "descriptor": "\nComments: 24 pages, 17 figures, to appear in ACM Transactions on Architecture & Code Optimization (TACO). arXiv admin note: substantial text overlap with arXiv:2102.10140\n",
    "authors": [
      "Dharanidhar Dang",
      "Bill Lin",
      "Debashis Sahoo"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.13861"
  },
  {
    "id": "arXiv:2206.13876",
    "title": "Hyper-Specific Prefixes: Gotta Enjoy the Little Things in Interdomain  Routing",
    "abstract": "Autonomous Systems (ASes) exchange reachability information between each\nother using BGP -- the de-facto standard inter-AS routing protocol. While IPv4\n(IPv6) routes more specific than /24 (/48) are commonly filtered (and hence not\npropagated), route collectors still observe many of them. In this work, we take\na closer look at those \"hyper-specific\" prefixes (HSPs). In particular, we\nanalyze their prevalence, use cases, and whether operators use them\nintentionally or accidentally. While their total number increases over time,\nmost HSPs can only be seen by route collector peers. Nonetheless, some HSPs can\nbe seen constantly throughout an entire year and propagate widely. We find that\nmost HSPs represent (internal) routes to peering infrastructure or are related\nto address block relocations or blackholing. While hundreds of operators\nintentionally add HSPs to well-known routing databases, we observe that many\nHSPs are possibly accidentally leaked routes.",
    "descriptor": "\nComments: See this https URL for continuously updated HSP analyses and statistics\n",
    "authors": [
      "Khwaja Zubair Sediqi",
      "Lars Prehn",
      "Oliver Gasser"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.13876"
  },
  {
    "id": "arXiv:2206.13879",
    "title": "Higher-order convergence of finite element methods for the stochastic  Stokes equations",
    "abstract": "Numerical analysis for the stochastic Stokes/Navier-Stokes equations is still\nchallenging even though it has been well done for the corresponding\ndeterministic equations. In particular, the existing error estimates of finite\nelement methods for the stochastic equations all suffer from the order\nreduction with respect to the spatial discretizations. The best convergence\nresult obtained for these fully discrete schemes is only half-order in time and\nfirst-order in space, which is not optimal in space in the traditional sense.\nThe purpose of this article is to establish the strong convergence of\n$O(\\tau^{1/2}+ h^2)$ and $O(\\tau^{1/2}+ h)$ in the $L^2$ norm for the inf-sup\nstable velocity-pressure finite element approximations, where $\\tau$ and $h$\ndenote the temporal stepsize and spatial mesh size, respectively. The error\nestimates are of optimal order for the spatial discretization considered in\nthis article (with MINI element), and consistent with the numerical\nexperiments. The analysis is based on the fully discrete Stokes semigroup\ntechniques and the corresponding new estimates.",
    "descriptor": "",
    "authors": [
      "Buyang Li",
      "Shu Ma",
      "Weiwei Sun"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.13879"
  },
  {
    "id": "arXiv:2206.13880",
    "title": "Spatial Positioning Token (SPToken) for Smart Parking",
    "abstract": "In this paper, we describe an approach to guide drivers searching for a\nparking space (PS). The proposed system suggests a sequence of routes that\ndrivers should traverse in order to maximise the expected likelihood of finding\na PS and minimise the travel distance. This system is built on our recent\narchitecture SPToken, which combines both Distributed Ledger Technology (DLT)\nand Reinforcement Learning (RL) to realise a system for the estimation of an\nunknown distribution without disturbing the environment. For this, we use a\nnumber of virtual tokens that are passed from vehicle to vehicle to enable a\nmassively parallelised RL system that estimates the best route for a given\norigin-destination (OD) pair, using crowdsourced information from participant\nvehicles. Additionally, a moving window with reward memory mechanism is\nincluded to better cope with non-stationary environments. Simulation results\nare given to illustrate the efficacy of our system.",
    "descriptor": "\nComments: 12 pages, 5 figures, 27th ITS World Congress, Hamburg, Germany, 11-15 October 2021\n",
    "authors": [
      "Roman Overko",
      "Rodrigo Ord\u00f3\u00f1ez-Hurtado",
      "Sergiy Zhuk",
      "Robert Shorten"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.13880"
  },
  {
    "id": "arXiv:2206.13882",
    "title": "CSI Sensing from Heterogeneous User Feedbacks: A Constrained Phase  Retrieval Approach",
    "abstract": "This paper investigates the downlink channel state information (CSI) sensing\nin 5G heterogeneous networks composed of user equipments (UEs) with different\nfeedback capabilities. We aim to enhance the CSI accuracy of UEs only affording\nthe low-resolution Type-I codebook. While existing works have demonstrated that\nthe task can be accomplished by solving a phase retrieval (PR) formulation\nbased on the feedback of precoding matrix indicator (PMI) and channel quality\nindicator (CQI), they need many feedback rounds. In this paper, we propose a\nnovel CSI sensing scheme that can significantly reduce the feedback overhead.\nOur scheme involves a novel parameter dimension reduction design by exploiting\nthe spatial consistency of wireless channels among nearby UEs, and a\nconstrained PR (CPR) formulation that characterizes the feasible region of CSI\nby the PMI information. To address the computational challenge due to the\nnon-convexity and the large number of constraints of CPR, we develop a\ntwo-stage algorithm that firstly identifies and removes inactive constraints,\nfollowed by a fast first-order algorithm. The study is further extended to\nmulti-carrier systems. Extensive tests over DeepMIMO and QuaDriGa datasets\nshowcase that our designs greatly outperform existing methods and achieve the\nhigh-resolution Type-II codebook performance with a few rounds of feedback.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Lei Li",
      "Xing Zeng",
      "Ya-Feng Liu",
      "Yanqing Xu",
      "Tsung-Hui Chang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.13882"
  },
  {
    "id": "arXiv:2206.13883",
    "title": "Improving Worst Case Visual Localization Coverage via Place-specific  Sub-selection in Multi-camera Systems",
    "abstract": "6-DoF visual localization systems utilize principled approaches rooted in 3D\ngeometry to perform accurate camera pose estimation of images to a map. Current\ntechniques use hierarchical pipelines and learned 2D feature extractors to\nimprove scalability and increase performance. However, despite gains in typical\nrecall@0.25m type metrics, these systems still have limited utility for\nreal-world applications like autonomous vehicles because of their `worst' areas\nof performance - the locations where they provide insufficient recall at a\ncertain required error tolerance. Here we investigate the utility of using\n`place specific configurations', where a map is segmented into a number of\nplaces, each with its own configuration for modulating the pose estimation\nstep, in this case selecting a camera within a multi-camera system. On the Ford\nAV benchmark dataset, we demonstrate substantially improved worst-case\nlocalization performance compared to using off-the-shelf pipelines - minimizing\nthe percentage of the dataset which has low recall at a certain error\ntolerance, as well as improved overall localization performance. Our proposed\napproach is particularly applicable to the crowdsharing model of autonomous\nvehicle deployment, where a fleet of AVs are regularly traversing a known\nroute.",
    "descriptor": "\nComments: 8 pages, 5 figures, To be published in RA-L 2022\n",
    "authors": [
      "Stephen Hausler",
      "Ming Xu",
      "Sourav Garg",
      "Punarjay Chakravarty",
      "Shubham Shrivastava",
      "Ankit Vora",
      "Michael Milford"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.13883"
  },
  {
    "id": "arXiv:2206.13885",
    "title": "Computation as uncertainty reduction: a simplified order-theoretic  framework",
    "abstract": "Although there is a somewhat standard formalization of computability on\ncountable sets given by Turing machines, the same cannot be said about\nuncountable sets. Among the approaches to define computability in these sets,\norder-theoretic structures have proven to be useful. Here, we discuss the\nmathematical structure needed to define computability using order-theoretic\nconcepts. In particular, we introduce a more general framework and discuss its\nlimitations compared to the previous one in domain theory. We expose four\nfeatures in which the stronger requirements in the domain-theoretic structure\nallow to improve upon the more general framework: computable elements,\ncomputable functions, model dependence of computability and complexity theory.\nCrucially, we show computability of elements in uncountable spaces can be\ndefined in this new setup, and argue why this is not the case for computable\nfunctions. Moreover, we show the stronger setup diminishes the dependence of\ncomputability on the chosen order-theoretic structure and that, although a\nsuitable complexity theory can be defined in the stronger framework and the\nmore general one posesses a notion of computable elements, there appears to be\nno proper notion of element complexity in the latter.",
    "descriptor": "",
    "authors": [
      "Pedro Hack",
      "Daniel A. Braun",
      "Sebastian Gottwald"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2206.13885"
  },
  {
    "id": "arXiv:2206.13887",
    "title": "Generating near-infrared facial expression datasets with dimensional  affect labels",
    "abstract": "Facial expression analysis has long been an active research area of computer\nvision. Traditional methods mainly analyse images for prototypical discrete\nemotions; as a result, they do not provide an accurate depiction of the complex\nemotional states in humans. Furthermore, illumination variance remains a\nchallenge for face analysis in the visible light spectrum. To address these\nissues, we propose using a dimensional model based on valence and arousal to\nrepresent a wider range of emotions, in combination with near infra-red (NIR)\nimagery, which is more robust to illumination changes. Since there are no\nexisting NIR facial expression datasets with valence-arousal labels available,\nwe present two complementary data augmentation methods (face morphing and\nCycleGAN approach) to create NIR image datasets with dimensional emotion labels\nfrom existing categorical and/or visible-light datasets. Our experiments show\nthat these generated NIR datasets are comparable to existing datasets in terms\nof data quality and baseline prediction performance.",
    "descriptor": "",
    "authors": [
      "Calvin Chen",
      "Stefan Winkler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.13887"
  },
  {
    "id": "arXiv:2206.13888",
    "title": "Explaining Any ML Model? -- On Goals and Capabilities of XAI",
    "abstract": "An increasing ubiquity of machine learning (ML) motivates research on\nalgorithms to explain ML models and their predictions -- so-called eXplainable\nArtificial Intelligence (XAI). Despite many survey papers and discussions, the\ngoals and capabilities of XAI algorithms are far from being well understood. We\nargue that this is because of a problematic reasoning scheme in XAI literature:\nXAI algorithms are said to complement ML models with desired properties, such\nas \"interpretability\", or \"explainability\". These properties are in turn\nassumed to contribute to a goal, like \"trust\" in an ML system. But most\nproperties lack precise definitions and their relationship to such goals is far\nfrom obvious. The result is a reasoning scheme that obfuscates research results\nand leaves an important question unanswered: What can one expect from XAI\nalgorithms? In this article, we clarify the goals and capabilities of XAI\nalgorithms from a concrete perspective: that of their users. Explaining ML\nmodels is only necessary if users have questions about them. We show that users\ncan ask diverse questions, but that only one of them can be answered by current\nXAI algorithms. Answering this core question can be trivial, difficult or even\nimpossible, depending on the ML application. Based on these insights, we\noutline which capabilities policymakers, researchers and society can reasonably\nexpect from XAI algorithms.",
    "descriptor": "",
    "authors": [
      "Moritz Renftle",
      "Holger Trittenbach",
      "Michael Poznic",
      "Reinhard Heil"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.13888"
  },
  {
    "id": "arXiv:2206.13889",
    "title": "Parallel Instance Filtering for Malware Detection",
    "abstract": "Machine learning algorithms are widely used in the area of malware detection.\nWith the growth of sample amounts, training of classification algorithms\nbecomes more and more expensive. In addition, training data sets may contain\nredundant or noisy instances. The problem to be solved is how to select\nrepresentative instances from large training data sets without reducing the\naccuracy. This work presents a new parallel instance selection algorithm called\nParallel Instance Filtering (PIF). The main idea of the algorithm is to split\nthe data set into non-overlapping subsets of instances covering the whole data\nset and apply a filtering process for each subset. Each subset consists of\ninstances that have the same nearest enemy. As a result, the PIF algorithm is\nfast since subsets are processed independently of each other using parallel\ncomputation. We compare the PIF algorithm with several state-of-the-art\ninstance selection algorithms on a large data set of 500,000 malicious and\nbenign samples. The feature set was extracted using static analysis, and it\nincludes metadata from the portable executable file format. Our experimental\nresults demonstrate that the proposed instance selection algorithm reduces the\nsize of a training data set significantly with the only slightly decreased\naccuracy. The PIF algorithm outperforms existing instance selection methods\nused in the experiments in terms of the ratio between average classification\naccuracy and storage percentage.",
    "descriptor": "",
    "authors": [
      "Martin Jure\u010dek",
      "Olha Jure\u010dkov\u00e1"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.13889"
  },
  {
    "id": "arXiv:2206.13891",
    "title": "Feature Learning for Dimensionality Reduction toward Maximal Extraction  of Hidden Patterns",
    "abstract": "Dimensionality reduction (DR) plays a vital role in the visual analysis of\nhigh-dimensional data. One main aim of DR is to reveal hidden patterns that lie\non intrinsic low-dimensional manifolds. However, DR often overlooks important\npatterns when the manifolds are strongly distorted or hidden by certain\ninfluential data attributes. This paper presents a feature learning framework,\nFEALM, designed to generate an optimized set of data projections for nonlinear\nDR in order to capture important patterns in the hidden manifolds. These\nprojections produce maximally different nearest-neighbor graphs so that\nresultant DR outcomes are significantly different. To achieve such a\ncapability, we design an optimization algorithm as well as introduce a new\ngraph dissimilarity measure, called neighbor-shape dissimilarity. Additionally,\nwe develop interactive visualizations to assist comparison of obtained DR\nresults and interpretation of each DR result. We demonstrate FEALM's\neffectiveness through experiments using synthetic datasets and multiple case\nstudies on real-world datasets.",
    "descriptor": "",
    "authors": [
      "Takanori Fujiwara",
      "Yun-Hsin Kuo",
      "Anders Ynnerman",
      "Kwan-Liu Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.13891"
  },
  {
    "id": "arXiv:2206.13896",
    "title": "Subsequences With Gap Constraints: Complexity Bounds for Matching and  Analysis Problems",
    "abstract": "We consider subsequences with gap constraints, i.e., length-k subsequences p\nthat can be embedded into a string w such that the induced gaps (i.e., the\nfactors of w between the positions to which p is mapped to) satisfy given gap\nconstraints $gc = (C_1, C_2, ..., C_{k-1})$; we call p a gc-subsequence of w.\nIn the case where the gap constraints gc are defined by lower and upper length\nbounds $C_i = (L^-_i, L^+_i) \\in \\mathbb{N}^2$ and/or regular languages $C_i\n\\in REG$, we prove tight (conditional on the orthogonal vectors (OV)\nhypothesis) complexity bounds for checking whether a given p is a\ngc-subsequence of a string w. We also consider the whole set of all\ngc-subsequences of a string, and investigate the complexity of the\nuniversality, equivalence and containment problems for these sets of\ngc-subsequences.",
    "descriptor": "",
    "authors": [
      "Joel D. Day",
      "Maria Kosche",
      "Florin Manea",
      "Markus L. Schmid"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2206.13896"
  },
  {
    "id": "arXiv:2206.13901",
    "title": "Value Function Decomposition for Iterative Design of Reinforcement  Learning Agents",
    "abstract": "Designing reinforcement learning (RL) agents is typically a difficult process\nthat requires numerous design iterations. Learning can fail for a multitude of\nreasons, and standard RL methods provide too few tools to provide insight into\nthe exact cause. In this paper, we show how to integrate value decomposition\ninto a broad class of actor-critic algorithms and use it to assist in the\niterative agent-design process. Value decomposition separates a reward function\ninto distinct components and learns value estimates for each. These value\nestimates provide insight into an agent's learning and decision-making process\nand enable new training methods to mitigate common problems. As a\ndemonstration, we introduce SAC-D, a variant of soft actor-critic (SAC) adapted\nfor value decomposition. SAC-D maintains similar performance to SAC, while\nlearning a larger set of value predictions. We also introduce\ndecomposition-based tools that exploit this information, including a new reward\ninfluence metric, which measures each reward component's effect on agent\ndecision-making. Using these tools, we provide several demonstrations of\ndecomposition's use in identifying and addressing problems in the design of\nboth environments and agents. Value decomposition is broadly applicable and\neasy to incorporate into existing algorithms and workflows, making it a\npowerful tool in an RL practitioner's toolbox.",
    "descriptor": "\nComments: 9 content pages, 12 Appendix pages, 19 figures\n",
    "authors": [
      "James MacGlashan",
      "Evan Archer",
      "Alisa Devlic",
      "Takuma Seno",
      "Craig Sherstan",
      "Peter R. Wurman",
      "Peter Stone"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.13901"
  },
  {
    "id": "arXiv:2206.13904",
    "title": "A Contribution to the Defense of Liquid Democracy",
    "abstract": "Liquid democracy is a hybrid direct-representative decision making process\nthat provides each voter with the option of either voting directly or to\ndelegate their vote to another voter, i.e., to a representative of their\nchoice. One of the proposed advantages of liquid democracy is that, in general,\nit is assumed that voters will delegate their vote to others that are better\ninformed, which leads to more informed and better decisions. Considering an\naudience from various knowledge domains, we provide an accessible high-level\nanalysis of a prominent critique of liquid democracy by Caragiannis and Micha.\nCaragiannis and Micha's critique contains three central topics: 1. Analysis\nusing their $\\alpha$-delegation model, which does not assume delegation to the\nmore informed; 2. Novel delegation network structures where it is advantageous\nto delegate to the less informed rather than the more informed; and 3. Due to\nNP hardness, the implied impracticability of a social network obtaining an\noptimal delegation structure. We show that in the real world, Caragiannis and\nMicha's critique of liquid democracy has little or no relevance. Respectively,\nour critique is based on: 1. The identification of incorrect\n$\\alpha$-delegation model assumptions; 2. A lack of novel delegation structures\nand their effect in a real-world implementation of liquid democracy, which\nwould be guaranteed with constraints that sensibly distribute voting power; and\n3. The irrelevance of an optimal delegation structure if the correct result is\nguaranteed regardless. We conclude that Caragiannis and Micha's critique has no\nsignificant negative relevance to the proposition of liquid democracy.",
    "descriptor": "",
    "authors": [
      "Gregory Butterworth",
      "Richard Booth"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Computer Science and Game Theory (cs.GT)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.13904"
  },
  {
    "id": "arXiv:2206.13905",
    "title": "Fast Simulation of Particulate Suspensions Enabled by Graph Neural  Network",
    "abstract": "Predicting the dynamic behaviors of particles in suspension subject to\nhydrodynamic interaction (HI) and external drive can be critical for many\napplications. By harvesting advanced deep learning techniques, the present work\nintroduces a new framework, hydrodynamic interaction graph neural network\n(HIGNN), for inferring and predicting the particles' dynamics in Stokes\nsuspensions. It overcomes the limitations of traditional approaches in\ncomputational efficiency, accuracy, and/or transferability. In particular, by\nuniting the data structure represented by a graph and the neural networks with\nlearnable parameters, the HIGNN constructs surrogate modeling for the mobility\ntensor of particles which is the key to predicting the dynamics of particles\nsubject to HI and external forces. To account for the many-body nature of HI,\nwe generalize the state-of-the-art GNN by introducing higher-order connectivity\ninto the graph and the corresponding convolutional operation. For training the\nHIGNN, we only need the data for a small number of particles in the domain of\ninterest, and hence the training cost can be maintained low. Once constructed,\nthe HIGNN permits fast predictions of the particles' velocities and is\ntransferable to suspensions of different numbers/concentrations of particles in\nthe same domain and to any external forcing. It has the ability to accurately\ncapture both the long-range HI and short-range lubrication effects. We\ndemonstrate the accuracy, efficiency, and transferability of the proposed HIGNN\nframework in a variety of systems. The requirement on computing resource is\nminimum: most simulations only require a desktop with one GPU; the simulations\nfor a large suspension of 100,000 particles call for up to 6 GPUs.",
    "descriptor": "",
    "authors": [
      "Zhan Ma",
      "Zisheng Ye",
      "Wenxiao Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2206.13905"
  },
  {
    "id": "arXiv:2206.13909",
    "title": "QTI Submission to DCASE 2021: residual normalization for  device-imbalanced acoustic scene classification with efficient design",
    "abstract": "This technical report describes the details of our TASK1A submission of the\nDCASE2021 challenge. The goal of the task is to design an audio scene\nclassification system for device-imbalanced datasets under the constraints of\nmodel complexity. This report introduces four methods to achieve the goal.\nFirst, we propose Residual Normalization, a novel feature normalization method\nthat uses instance normalization with a shortcut path to discard unnecessary\ndevice-specific information without losing useful information for\nclassification. Second, we design an efficient architecture, BC-ResNet-Mod, a\nmodified version of the baseline architecture with a limited receptive field.\nThird, we exploit spectrogram-to-spectrogram translation from one to multiple\ndevices to augment training data. Finally, we utilize three model compression\nschemes: pruning, quantization, and knowledge distillation to reduce model\ncomplexity. The proposed system achieves an average test accuracy of 76.3% in\nTAU Urban Acoustic Scenes 2020 Mobile, development dataset with 315k\nparameters, and average test accuracy of 75.3% after compression to 61.0KB of\nnon-zero parameters.",
    "descriptor": "\nComments: tech report; won 1st place in DCASE2021 challenge. arXiv admin note: substantial text overlap with arXiv:2111.06531\n",
    "authors": [
      "Byeonggeun Kim",
      "Seunghan Yang",
      "Jangho Kim",
      "Simyung Chang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.13909"
  },
  {
    "id": "arXiv:2206.13914",
    "title": "Dependency Parsing with Backtracking using Deep Reinforcement Learning",
    "abstract": "Greedy algorithms for NLP such as transition based parsing are prone to error\npropagation. One way to overcome this problem is to allow the algorithm to\nbacktrack and explore an alternative solution in cases where new evidence\ncontradicts the solution explored so far. In order to implement such a\nbehavior, we use reinforcement learning and let the algorithm backtrack in\ncases where such an action gets a better reward than continuing to explore the\ncurrent solution. We test this idea on both POS tagging and dependency parsing\nand show that backtracking is an effective means to fight against error\npropagation.",
    "descriptor": "\nComments: Accepted for publication in Transactions of the Association for Computational Linguistics\n",
    "authors": [
      "Franck Dary",
      "Maxime Petit",
      "Alexis Nasr"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.13914"
  },
  {
    "id": "arXiv:2206.13918",
    "title": "Extending Shinohara's Algorithm for Computing Descriptive  (Angluin-Style) Patterns to Subsequence Patterns",
    "abstract": "The introduction of pattern languages in the seminal work [Angluin, ``Finding\nPatterns Common to a Set of Strings'', JCSS 1980] has revived the classical\nmodel of inductive inference (learning in the limit, gold-style learning). In\n[Shinohara, ``Polynomial Time Inference of Pattern Languages and Its\nApplication'', 7th IBM Symposium on Mathematical Foundations of Computer\nScience 1982] a simple and elegant algorithm has been introduced that, based on\nmembership queries, computes a pattern that is descriptive for a given sample\nof input strings (and, consequently, can be employed in strategies for\ninductive inference). In this paper, we give a brief survey of the recent work\n[Kleest-Mei{\\ss}ner et al., ``Discovering Event Queries from Traces: Laying\nFoundations for Subsequence-Queries with Wildcards and Gap-Size Constraints'',\nICDT 2022], where the classical concepts of Angluin-style (descriptive)\npatterns and the respective Shinohara's algorithm are extended to a query class\nwith applications in complex event recognition -- a modern topic from\ndatabases.",
    "descriptor": "",
    "authors": [
      "Markus L. Schmid"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2206.13918"
  },
  {
    "id": "arXiv:2206.13920",
    "title": "A quantitative extension of Interval Temporal Logic over infinite words",
    "abstract": "Model checking for Halpern and Shoham's interval temporal logic HS has been\nrecently investigated in a systematic way, and it is known to be decidable\nunder three distinct semantics (state-based, trace-based and tree-based\nsemantics). Here, we focus on the trace-based semantics, where the main\nsemantic entities are the infinite execution paths (traces) of the given Kripke\nstructure, assuming in addition homogeneity in the propositional valuation. We\nintroduce a quantitative extension of HS over traces, called Difference HS\n(DHS) allowing one to express timing constraints on the difference among\ninterval lengths (durations). The quantitative extension of some modalities\nleads immediately to undecidability, so, we investigate the decidability border\nfor the model checking and satisfiability problems by considering strict\nsyntactical fragments of DHS. In particular, we identify the maximal decidable\nfragment DHSS of DHS proving in addition that the considered problems for the\nfragment are at least 2EXPSPACE-hard. Moreover, by exploiting new results on\nlinear-time hybrid logics, we show that for an equally expressive fragment of\nDHSS, the problems are EXPSPACE-complete. Finally, we provide a\ncharacterization of HS over traces by means of the one-variable fragment of a\nnovel hybrid logic.",
    "descriptor": "",
    "authors": [
      "Laura Bozzelli",
      "Adriano Peron"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.13920"
  },
  {
    "id": "arXiv:2206.13923",
    "title": "SLOVA: Uncertainty Estimation Using Single Label One-Vs-All Classifier",
    "abstract": "Deep neural networks present impressive performance, yet they cannot reliably\nestimate their predictive confidence, limiting their applicability in high-risk\ndomains. We show that applying a multi-label one-vs-all loss reveals\nclassification ambiguity and reduces model overconfidence. The introduced SLOVA\n(Single Label One-Vs-All) model redefines typical one-vs-all predictive\nprobabilities to a single label situation, where only one class is the correct\nanswer. The proposed classifier is confident only if a single class has a high\nprobability and other probabilities are negligible. Unlike the typical softmax\nfunction, SLOVA naturally detects out-of-distribution samples if the\nprobabilities of all other classes are small. The model is additionally\nfine-tuned with exponential calibration, which allows us to precisely align the\nconfidence score with model accuracy. We verify our approach on three tasks.\nFirst, we demonstrate that SLOVA is competitive with the state-of-the-art on\nin-distribution calibration. Second, the performance of SLOVA is robust under\ndataset shifts. Finally, our approach performs extremely well in the detection\nof out-of-distribution samples. Consequently, SLOVA is a tool that can be used\nin various applications where uncertainty modeling is required.",
    "descriptor": "",
    "authors": [
      "Bartosz W\u00f3jcik",
      "Jacek Grela",
      "Marek \u015amieja",
      "Krzysztof Misztal",
      "Jacek Tabor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.13923"
  },
  {
    "id": "arXiv:2206.13924",
    "title": "Physical Layer Abstraction Model for RadioWeaves",
    "abstract": "RadioWeaves, in which distributed antennas with integrated radio and compute\nresources serve a large number of users, is envisioned to provide high data\nrates in next generation wireless systems. In this paper, we develop a physical\nlayer abstraction model to evaluate the performance of different RadioWeaves\ndeployment scenarios. This model helps speed up system-level simulators of the\nRadioWeaves and is made up of two blocks. The first block generates a vector of\nsignal-to-interference-plus-noise ratios (SINRs) corresponding to each\ncoherence block, and the second block predicts the packet error rate\ncorresponding to the SINRs generated. The vector of SINRs generated depends on\ndifferent parameters such as the number of users, user locations, antenna\nconfigurations, and precoders. We have also considered different antenna gain\npatterns, such as omni-directional and directional microstrip patch antennas.\nOur model exploits the benefits of exponential effective SINR mapping (EESM).\nWe study the robustness and accuracy of the EESM for RadioWeaves.",
    "descriptor": "\nComments: 6 pages, 7 figures. Accepted for publication in 2022 IEEE 95th Vehicular Technology Conference: VTC2022-Spring\n",
    "authors": [
      "Rimalapudi Sarvendranath",
      "Unnikrishnan Kunnath Ganesan",
      "Zakir Hussain Shaik",
      "Erik G. Larsson"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.13924"
  },
  {
    "id": "arXiv:2206.13927",
    "title": "On the Axiomatisation of Branching Bisimulation Congruence over CCS",
    "abstract": "In this paper we investigate the equational theory of (the restriction,\nrelabelling, and recursion free fragment of) CCS modulo rooted branching\nbisimilarity, which is a classic, bisimulation-based notion of equivalence that\nabstracts from internal computational steps in process behaviour. Firstly, we\nshow that CCS is not finitely based modulo the considered congruence. As a key\nstep of independent interest in the proof of that negative result, we prove\nthat each CCS process has a unique parallel decomposition into indecomposable\nprocesses modulo branching bisimilarity. As a second main contribution, we show\nthat, when the set of actions is finite, rooted branching bisimilarity has a\nfinite equational basis over CCS enriched with the left merge and communication\nmerge operators from ACP.",
    "descriptor": "",
    "authors": [
      "Luca Aceto",
      "Valentina Castiglioni",
      "Anna Ingolfsdottir",
      "Bas Luttik"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.13927"
  },
  {
    "id": "arXiv:2206.13932",
    "title": "Discrete Morse Sandwich: Fast Computation of Persistence Diagrams for  Scalar Data -- An Algorithm and A Benchmark",
    "abstract": "This paper introduces an efficient algorithm for persistence diagram\ncomputation, given an input piecewise linear scalar field f defined on a\nd-dimensional simplicial complex K, with $d \\leq 3$. Our method extends the\nseminal \"PairCells\" algorithm by introducing three main accelerations. First,\nwe express this algorithm within the setting of discrete Morse theory, which\nconsiderably reduces the number of input simplices to consider. Second, we\nintroduce a stratification approach to the problem, that we call \"sandwiching\".\nSpecifically, minima-saddle persistence pairs ($D_0(f)$) and saddle-maximum\npersistence pairs ($D_{d-1}(f)$) are efficiently computed by respectively\nprocessing with a Union-Find the unstable sets of 1-saddles and the stable sets\nof (d-1)-saddles. This fast processing of the dimensions 0 and (d-1) further\nreduces, and drastically, the number of critical simplices to consider for the\ncomputation of $D_1(f)$, the intermediate layer of the sandwich. Third, we\ndocument several performance improvements via shared-memory parallelism. We\nprovide an open-source implementation of our algorithm for reproducibility\npurposes. We also contribute a reproducible benchmark package, which exploits\nthree-dimensional data from a public repository and compares our algorithm to a\nvariety of publicly available implementations. Extensive experiments indicate\nthat our algorithm improves by two orders of magnitude the time performance of\nthe seminal \"PairCells\" algorithm it extends. Moreover, it also improves memory\nfootprint and time performance over a selection of 14 competing approaches,\nwith a substantial gain over the fastest available approaches, while producing\na strictly identical output. We illustrate the utility of our contributions\nwith an application to the fast and robust extraction of persistent\n1-dimensional generators on surfaces, volume data and high-dimensional point\nclouds.",
    "descriptor": "",
    "authors": [
      "Pierre Guillou",
      "Jules Vidal",
      "Julien Tierny"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Geometry (cs.CG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.13932"
  },
  {
    "id": "arXiv:2206.13933",
    "title": "Accurate and fast identification of minimally prepared bacteria  phenotypes using Raman spectroscopy assisted by machine learning",
    "abstract": "The worldwide increase of antimicrobial resistance (AMR) is a serious threat\nto human health. To avert the spread of AMR, fast reliable diagnostics tools\nthat facilitate optimal antibiotic stewardship are an unmet need. In this\nregard, Raman spectroscopy promises rapid label- and culture-free\nidentification and antimicrobial susceptibility testing (AST) in a single step.\nHowever, even though many Raman-based bacteria-identification and AST studies\nhave demonstrated impressive results, some shortcomings must be addressed. To\nbridge the gap between proof-of-concept studies and clinical application, we\nhave developed machine learning techniques in combination with a novel\ndata-augmentation algorithm, for fast identification of minimally prepared\nbacteria phenotypes and the distinctions of methicillin-resistant (MR) from\nmethicillin-susceptible (MS) bacteria. For this we have implemented a spectral\ntransformer model for hyper-spectral Raman images of bacteria. We show that our\nmodel outperforms the standard convolutional neural network models on a\nmultitude of classification problems, both in terms of accuracy and in terms of\ntraining time. We attain more than 96$\\%$ classification accuracy on a dataset\nconsisting of 15 different classes and 95.6$\\%$ classification accuracy for six\nMR-MS bacteria species. More importantly, our results are obtained using only\nfast and easy-to-produce training and test data",
    "descriptor": "\nComments: 14 pages, 5 figures\n",
    "authors": [
      "Benjamin Lundquist Thomsen",
      "Jesper B. Christensen",
      "Olga Rodenko",
      "Iskander Usenov",
      "Rasmus Birkholm Gr\u00f8nnemose",
      "Thomas Emil Andersen",
      "Mikael Lassen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2206.13933"
  },
  {
    "id": "arXiv:2206.13936",
    "title": "Haul Road Mapping from GPS Traces",
    "abstract": "Automation in mining requires accurate maps of road networks on site. Because\nroads on open-cut mines are dynamic in nature and continuously changing,\nmanually updating road maps is tedious and error-prone. This paper investigates\nthe possibility of automatically deriving an accurate representation of the\nroad network using GPS data available from haul trucks operating on site. We\npresent an overview of approaches proposed in literature and test the\nperformance of publicly available methods on GPS data collected from trucks\noperating on site. Based on shortcomings seen in all tested algorithms, a\npost-processing step is developed which geometrically analyses the created road\nmap for artefacts typical of free-drive areas on mine sites and significantly\nimproves the quality of the final road network graph.",
    "descriptor": "",
    "authors": [
      "Konstantin M. Seiler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.13936"
  },
  {
    "id": "arXiv:2206.13937",
    "title": "A Deep Learning Approach to Nonconvex Energy Minimization for  Martensitic Phase Transitions",
    "abstract": "We propose a mesh-free method to solve nonconvex energy minimization problems\nfor martensitic phase transitions and twinning in crystals, using the deep\nlearning approach. These problems pose multiple challenges to both analysis and\ncomputation, as they involve multiwell gradient energies with large numbers of\nlocal minima, each involving a topologically complex microstructure of free\nboundaries with gradient jumps. We use the Deep Ritz method, whereby candidates\nfor minimizers are represented by parameter-dependent deep neural networks, and\nthe energy is minimized with respect to network parameters. The new essential\ningredient is a novel activation function proposed here, which is a smoothened\nrectified linear unit we call SmReLU; this captures the structure of minimizers\nwhere usual activation functions fail. The method is mesh-free and thus can\napproximate free boundaries essential to this problem without any special\ntreatment, and is extremely simple to implement. We show the results of many\nnumerical computations demonstrating the success of our method.",
    "descriptor": "",
    "authors": [
      "Xiaoli Chen",
      "Phoebus Rosakis",
      "Zhizhang Wu",
      "Zhiwen Zhang"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2206.13937"
  },
  {
    "id": "arXiv:2206.13939",
    "title": "Functional Optimization Reinforcement Learning for Real-Time Bidding",
    "abstract": "Real-time bidding is the new paradigm of programmatic advertising. An\nadvertiser wants to make the intelligent choice of utilizing a\n\\textbf{Demand-Side Platform} to improve the performance of their ad campaigns.\nExisting approaches are struggling to provide a satisfactory solution for\nbidding optimization due to stochastic bidding behavior. In this paper, we\nproposed a multi-agent reinforcement learning architecture for RTB with\nfunctional optimization. We designed four agents bidding environment: three\nLagrange-multiplier based functional optimization agents and one baseline agent\n(without any attribute of functional optimization) First, numerous attributes\nhave been assigned to each agent, including biased or unbiased win probability,\nLagrange multiplier, and click-through rate. In order to evaluate the proposed\nRTB strategy's performance, we demonstrate the results on ten sequential\nsimulated auction campaigns. The results show that agents with functional\nactions and rewards had the most significant average winning rate and winning\nsurplus, given biased and unbiased winning information respectively. The\nexperimental evaluations show that our approach significantly improve the\ncampaign's efficacy and profitability.",
    "descriptor": "",
    "authors": [
      "Yining Lu",
      "Changjie Lu",
      "Naina Bandyopadhyay",
      "Manoj Kumar",
      "Gaurav Gupta"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.13939"
  },
  {
    "id": "arXiv:2206.13942",
    "title": "A Theoretical Computer Science Perspective on Free Will",
    "abstract": "We consider the paradoxical concept of free will from the perspective of\nTheoretical Computer Science (TCS), a branch of mathematics concerned with\nunderstanding the underlying principles of computation and complexity,\nincluding the implications and surprising consequences of resource limitations.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2107.13704\n",
    "authors": [
      "Lenore Blum",
      "Manuel Blum"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.13942"
  },
  {
    "id": "arXiv:2206.13947",
    "title": "Long Range Language Modeling via Gated State Spaces",
    "abstract": "State space models have shown to be effective at modeling long range\ndependencies, specially on sequence classification tasks. In this work we focus\non autoregressive sequence modeling over English books, Github source code and\nArXiv mathematics articles. Based on recent developments around the\neffectiveness of gated activation functions, we propose a new layer named Gated\nState Space (GSS) and show that it trains significantly faster than the\ndiagonal version of S4 (i.e. DSS) on TPUs, is fairly competitive with several\nwell-tuned Transformer-based baselines and exhibits zero-shot generalization to\nlonger inputs while being straightforward to implement. Finally, we show that\nleveraging self-attention to model local dependencies improves the performance\nof GSS even further.",
    "descriptor": "",
    "authors": [
      "Harsh Mehta",
      "Ankit Gupta",
      "Ashok Cutkosky",
      "Behnam Neyshabur"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.13947"
  },
  {
    "id": "arXiv:2206.13951",
    "title": "Robustifying Vision Transformer without Retraining from Scratch by  Test-Time Class-Conditional Feature Alignment",
    "abstract": "Vision Transformer (ViT) is becoming more popular in image processing.\nSpecifically, we investigate the effectiveness of test-time adaptation (TTA) on\nViT, a technique that has emerged to correct its prediction during test-time by\nitself. First, we benchmark various test-time adaptation approaches on ViT-B16\nand ViT-L16. It is shown that the TTA is effective on ViT and the\nprior-convention (sensibly selecting modulation parameters) is not necessary\nwhen using proper loss function. Based on the observation, we propose a new\ntest-time adaptation method called class-conditional feature alignment (CFA),\nwhich minimizes both the class-conditional distribution differences and the\nwhole distribution differences of the hidden representation between the source\nand target in an online manner. Experiments of image classification tasks on\ncommon corruption (CIFAR-10-C, CIFAR-100-C, and ImageNet-C) and domain\nadaptation (digits datasets and ImageNet-Sketch) show that CFA stably\noutperforms the existing baselines on various datasets. We also verify that CFA\nis model agnostic by experimenting on ResNet, MLP-Mixer, and several ViT\nvariants (ViT-AugReg, DeiT, and BeiT). Using BeiT backbone, CFA achieves 19.8%\ntop-1 error rate on ImageNet-C, outperforming the existing test-time adaptation\nbaseline 44.0%. This is a state-of-the-art result among TTA methods that do not\nneed to alter training phase.",
    "descriptor": "\nComments: Accepted to IJCAI-ECAI2022. Code is available at this https URL\n",
    "authors": [
      "Takeshi Kojima",
      "Yutaka Matsuo",
      "Yusuke Iwasawa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.13951"
  },
  {
    "id": "arXiv:2206.13953",
    "title": "RAW-GNN: RAndom Walk Aggregation based Graph Neural Network",
    "abstract": "Graph-Convolution-based methods have been successfully applied to\nrepresentation learning on homophily graphs where nodes with the same label or\nsimilar attributes tend to connect with one another. Due to the homophily\nassumption of Graph Convolutional Networks (GCNs) that these methods use, they\nare not suitable for heterophily graphs where nodes with different labels or\ndissimilar attributes tend to be adjacent. Several methods have attempted to\naddress this heterophily problem, but they do not change the fundamental\naggregation mechanism of GCNs because they rely on summation operators to\naggregate information from neighboring nodes, which is implicitly subject to\nthe homophily assumption. Here, we introduce a novel aggregation mechanism and\ndevelop a RAndom Walk Aggregation-based Graph Neural Network (called RAW-GNN)\nmethod. The proposed approach integrates the random walk strategy with graph\nneural networks. The new method utilizes breadth-first random walk search to\ncapture homophily information and depth-first search to collect heterophily\ninformation. It replaces the conventional neighborhoods with path-based\nneighborhoods and introduces a new path-based aggregator based on Recurrent\nNeural Networks. These designs make RAW-GNN suitable for both homophily and\nheterophily graphs. Extensive experimental results showed that the new method\nachieved state-of-the-art performance on a variety of homophily and heterophily\ngraphs.",
    "descriptor": "",
    "authors": [
      "Di Jin",
      "Rui Wang",
      "Meng Ge",
      "Dongxiao He",
      "Xiang Li",
      "Wei Lin",
      "Weixiong Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.13953"
  },
  {
    "id": "arXiv:2206.13959",
    "title": "Comparing and extending the use of defeasible argumentation with  quantitative data in real-world contexts",
    "abstract": "Dealing with uncertain, contradicting, and ambiguous information is still a\ncentral issue in Artificial Intelligence (AI). As a result, many formalisms\nhave been proposed or adapted so as to consider non-monotonicity, with only a\nlimited number of works and researchers performing any sort of comparison among\nthem. A non-monotonic formalism is one that allows the retraction of previous\nconclusions or claims, from premises, in light of new evidence, offering some\ndesirable flexibility when dealing with uncertainty. This research article\nfocuses on evaluating the inferential capacity of defeasible argumentation, a\nformalism particularly envisioned for modelling non-monotonic reasoning. In\naddition to this, fuzzy reasoning and expert systems, extended for handling\nnon-monotonicity of reasoning, are selected and employed as baselines, due to\ntheir vast and accepted use within the AI community. Computational trust was\nselected as the domain of application of such models. Trust is an ill-defined\nconstruct, hence, reasoning applied to the inference of trust can be seen as\nnon-monotonic. Inference models were designed to assign trust scalars to\neditors of the Wikipedia project. In particular, argument-based models\ndemonstrated more robustness than those built upon the baselines despite the\nknowledge bases or datasets employed. This study contributes to the body of\nknowledge through the exploitation of defeasible argumentation and its\ncomparison to similar approaches. The practical use of such approaches coupled\nwith a modular design that facilitates similar experiments was exemplified and\ntheir respective implementations made publicly available on GitHub [120, 121].\nThis work adds to previous works, empirically enhancing the generalisability of\ndefeasible argumentation as a compelling approach to reason with quantitative\ndata and uncertain knowledge.",
    "descriptor": "",
    "authors": [
      "Lucas Rizzo",
      "Luca Longo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.13959"
  },
  {
    "id": "arXiv:2206.13960",
    "title": "Dynamic Memory for Interpretable Sequential Optimisation",
    "abstract": "Real-world applications of reinforcement learning for recommendation and\nexperimentation faces a practical challenge: the relative reward of different\nbandit arms can evolve over the lifetime of the learning agent. To deal with\nthese non-stationary cases, the agent must forget some historical knowledge, as\nit may no longer be relevant to minimise regret. We present a solution to\nhandling non-stationarity that is suitable for deployment at scale, to provide\nbusiness operators with automated adaptive optimisation. Our solution aims to\nprovide interpretable learning that can be trusted by humans, whilst responding\nto non-stationarity to minimise regret. To this end, we develop an adaptive\nBayesian learning agent that employs a novel form of dynamic memory. It enables\ninterpretability through statistical hypothesis testing, by targeting a set\npoint of statistical power when comparing rewards and adjusting its memory\ndynamically to achieve this power. By design, the agent is agnostic to\ndifferent kinds of non-stationarity. Using numerical simulations, we compare\nits performance against an existing proposal and show that, under multiple\nnon-stationary scenarios, our agent correctly adapts to real changes in the\ntrue rewards. In all bandit solutions, there is an explicit trade-off between\nlearning and achieving maximal performance. Our solution sits on a different\npoint on this trade-off when compared to another similarly robust approach: we\nprioritise interpretability, which relies on more learning, at the cost of some\nregret. We describe the architecture of a large-scale deployment of automatic\noptimisation-as-a-service where our agent achieves interpretability whilst\nadapting to changing circumstances.",
    "descriptor": "\nComments: 2nd International Workshop on Online and Adaptive Recommender Systems, 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, 2022, Washington DC\n",
    "authors": [
      "Srivas Chennu",
      "Andrew Maher",
      "Jamie Martin",
      "Subash Prabanantham"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.13960"
  },
  {
    "id": "arXiv:2206.13962",
    "title": "Multi-Prior Learning via Neural Architecture Search for Blind Face  Restoration",
    "abstract": "Blind Face Restoration (BFR) aims to recover high-quality face images from\nlow-quality ones and usually resorts to facial priors for improving restoration\nperformance. However, current methods still suffer from two major difficulties:\n1) how to derive a powerful network architecture without extensive hand tuning;\n2) how to capture complementary information from multiple facial priors in one\nnetwork to improve restoration performance. To this end, we propose a Face\nRestoration Searching Network (FRSNet) to adaptively search the suitable\nfeature extraction architecture within our specified search space, which can\ndirectly contribute to the restoration quality. On the basis of FRSNet, we\nfurther design our Multiple Facial Prior Searching Network (MFPSNet) with a\nmulti-prior learning scheme. MFPSNet optimally extracts information from\ndiverse facial priors and fuses the information into image features, ensuring\nthat both external guidance and internal features are reserved. In this way,\nMFPSNet takes full advantage of semantic-level (parsing maps), geometric-level\n(facial heatmaps), reference-level (facial dictionaries) and pixel-level\n(degraded images) information and thus generates faithful and realistic images.\nQuantitative and qualitative experiments show that MFPSNet performs favorably\non both synthetic and real-world datasets against the state-of-the-art BFR\nmethods. The codes are publicly available at:\nhttps://github.com/YYJ1anG/MFPSNet.",
    "descriptor": "\nComments: 13 pages, 5 figures\n",
    "authors": [
      "Yanjiang Yu",
      "Puyang Zhang",
      "Kaihao Zhang",
      "Wenhan Luo",
      "Changsheng Li",
      "Ye Yuan",
      "Guoren Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.13962"
  },
  {
    "id": "arXiv:2206.13963",
    "title": "Primitive Graph Learning for Unified Vector Mapping",
    "abstract": "Large-scale vector mapping is important for transportation, city planning,\nand survey and census. We propose GraphMapper, a unified framework for\nend-to-end vector map extraction from satellite images. Our key idea is a novel\nunified representation of shapes of different topologies named \"primitive\ngraph\", which is a set of shape primitives and their pairwise relationship\nmatrix. Then, we convert vector shape prediction, regularization, and topology\nreconstruction into a unique primitive graph learning problem. Specifically,\nGraphMapper is a generic primitive graph learning network based on global shape\ncontext modelling through multi-head-attention. An embedding space sorting\nmethod is developed for accurate primitive relationship modelling. We\nempirically demonstrate the effectiveness of GraphMapper on two challenging\nmapping tasks, building footprint regularization and road network topology\nreconstruction. Our model outperforms state-of-the-art methods by 8-10% in both\ntasks on public benchmarks. All code will be publicly available.",
    "descriptor": "",
    "authors": [
      "Lei Wang",
      "Min Dai",
      "Jianan He",
      "Jingwei Huang",
      "Mingwei Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.13963"
  },
  {
    "id": "arXiv:2206.13964",
    "title": "Learning Gait Representation from Massive Unlabelled Walking Videos: A  Benchmark",
    "abstract": "Gait depicts individuals' unique and distinguishing walking patterns and has\nbecome one of the most promising biometric features for human identification.\nAs a fine-grained recognition task, gait recognition is easily affected by many\nfactors and usually requires a large amount of completely annotated data that\nis costly and insatiable. This paper proposes a large-scale self-supervised\nbenchmark for gait recognition with contrastive learning, aiming to learn the\ngeneral gait representation from massive unlabelled walking videos for\npractical applications via offering informative walking priors and diverse\nreal-world variations. Specifically, we collect a large-scale unlabelled gait\ndataset GaitLU-1M consisting of 1.02M walking sequences and propose a\nconceptually simple yet empirically powerful baseline model GaitSSB.\nExperimentally, we evaluate the pre-trained model on four widely-used gait\nbenchmarks, CASIA-B, OU-MVLP, GREW and Gait3D with or without transfer\nlearning. The unsupervised results are comparable to or even better than the\nearly model-based and GEI-based methods. After transfer learning, our method\noutperforms existing methods by a large margin in most cases. Theoretically, we\ndiscuss the critical issues for gait-specific contrastive framework and present\nsome insights for further study. As far as we know, GaitLU-1M is the first\nlarge-scale unlabelled gait dataset, and GaitSSB is the first method that\nachieves remarkable unsupervised results on the aforementioned benchmarks. The\nsource code of GaitSSB will be integrated into OpenGait which is available at\nhttps://github.com/ShiqiYu/OpenGait.",
    "descriptor": "",
    "authors": [
      "Chao Fan",
      "Saihui Hou",
      "Jilong Wang",
      "Yongzhen Huang",
      "Shiqi Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.13964"
  },
  {
    "id": "arXiv:2206.13965",
    "title": "Analysis of Individual Conversational Volatility in Tandem  Telecollaboration for Second Language Learning",
    "abstract": "Second language learning can be enabled by tandem collaboration where\nstudents are grouped into video conference calls while learning the native\nlanguage of other student(s) on the calls. This places students in an online\nenvironment where the more outgoing can actively contribute and engage in\ndialogue while those more shy and unsure of their second language skills can\nsit back and coast through the calls. We have built and deployed the L2L system\nwhich records timings of conversational utterances from all participants in a\ncall. We generate visualisations including participation rates and timelines\nfor each student in each call and present these on a dashboard. We have\nrecently developed a measure called personal conversational volatility for how\ndynamic has been each student's contribution to the dialogue in each call. We\npresent an analysis of conversational volatility measures for a sample of 19\nindividual English-speaking students from our University who are learning\nFrenchm, in each of 86 tandem telecollaboration calls over one teaching\nsemester. Our analysis shows there is a need to look into the nature of the\ninteractions and see if the choices of discussion topics assigned to them were\ntoo difficult for some students and that may have influenced their engagement\nin some way.",
    "descriptor": "\nComments: 21st European Conference on e-Learning, October 2022, Brighton, UK\n",
    "authors": [
      "Alan F. Smeaton",
      "Aparajita Dey-Plissonneau",
      "Hyowon Lee",
      "Mingming Liu",
      "Michael Scriney"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.13965"
  },
  {
    "id": "arXiv:2206.13966",
    "title": "Dext-Gen: Dexterous Grasping in Sparse Reward Environments with Full  Orientation Control",
    "abstract": "Reinforcement learning is a promising method for robotic grasping as it can\nlearn effective reaching and grasping policies in difficult scenarios. However,\nachieving human-like manipulation capabilities with sophisticated robotic hands\nis challenging because of the problem's high dimensionality. Although remedies\nsuch as reward shaping or expert demonstrations can be employed to overcome\nthis issue, they often lead to oversimplified and biased policies. We present\nDext-Gen, a reinforcement learning framework for Dexterous Grasping in sparse\nreward ENvironments that is applicable to a variety of grippers and learns\nunbiased and intricate policies. Full orientation control of the gripper and\nobject is achieved through smooth orientation representation. Our approach has\nreasonable training durations and provides the option to include desired prior\nknowledge. The effectiveness and adaptability of the framework to different\nscenarios is demonstrated in simulated experiments.",
    "descriptor": "",
    "authors": [
      "Martin Schuck",
      "Jan Br\u00fcdigam",
      "Alexandre Capone",
      "Stefan Sosnowski",
      "Sandra Hirche"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.13966"
  },
  {
    "id": "arXiv:2206.13968",
    "title": "Information Entropy Initialized Concrete Autoencoder for Optimal Sensor  Placement and Reconstruction of Geophysical Fields",
    "abstract": "We propose a new approach to the optimal placement of sensors for the problem\nof reconstructing geophysical fields from sparse measurements. Our method\nconsists of two stages. In the first stage, we estimate the variability of the\nphysical field as a function of spatial coordinates by approximating its\ninformation entropy through the Conditional PixelCNN network. To calculate the\nentropy, a new ordering of a two-dimensional data array (spiral ordering) is\nproposed, which makes it possible to obtain the entropy of a physical field\nsimultaneously for several spatial scales. In the second stage, the entropy of\nthe physical field is used to initialize the distribution of optimal sensor\nlocations. This distribution is further optimized with the Concrete Autoencoder\narchitecture with the straight-through gradient estimator and adversarial loss\nto simultaneously minimize the number of sensors and maximize reconstruction\naccuracy. Our method scales linearly with data size, unlike commonly used\nPrincipal Component Analysis. We demonstrate our method on the two examples:\n(a) temperature and (b) salinity fields around the Barents Sea and the Svalbard\ngroup of islands. For these examples, we compute the reconstruction error of\nour method and a few baselines. We test our approach against two baselines (1)\nPCA with QR factorization and (2) climatology. We find out that the obtained\noptimal sensor locations have clear physical interpretation and correspond to\nthe boundaries between sea currents.",
    "descriptor": "\nComments: 18 pages, 6 figures\n",
    "authors": [
      "Nikita Turko",
      "Alexander Lobashev",
      "Konstantin Ushakov",
      "Maxim Kaurkin",
      "Rashit Ibrayev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.13968"
  },
  {
    "id": "arXiv:2206.13969",
    "title": "MACSA: A Multimodal Aspect-Category Sentiment Analysis Dataset with  Multimodal Fine-grained Aligned Annotations",
    "abstract": "Multimodal fine-grained sentiment analysis has recently attracted increasing\nattention due to its broad applications. However, the existing multimodal\nfine-grained sentiment datasets most focus on annotating the fine-grained\nelements in text but ignore those in images, which leads to the fine-grained\nelements in visual content not receiving the full attention they deserve. In\nthis paper, we propose a new dataset, the Multimodal Aspect-Category Sentiment\nAnalysis (MACSA) dataset, which contains more than 21K text-image pairs. The\ndataset provides fine-grained annotations for both textual and visual content\nand firstly uses the aspect category as the pivot to align the fine-grained\nelements between the two modalities. Based on our dataset, we propose the\nMultimodal ACSA task and a multimodal graph-based aligned model (MGAM), which\nadopts a fine-grained cross-modal fusion method. Experimental results show that\nour method can facilitate the baseline comparison for future research on this\ncorpus. We will make the dataset and code publicly available.",
    "descriptor": "",
    "authors": [
      "Hao Yang",
      "Yanyan Zhao",
      "Jianwei Liu",
      "Yang Wu",
      "Bing Qin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.13969"
  },
  {
    "id": "arXiv:2206.13970",
    "title": "RAPID: AppRoximAte Pipelined Soft Multipliers and Dividers for  High-Throughput and Energy-Efficiency",
    "abstract": "The rapid updates in error-resilient applications along with their quest for\nhigh throughput have motivated designing fast approximate functional units for\nField-Programmable Gate Arrays (FPGAs). Studies that proposed imprecise\nfunctional techniques are posed with three shortcomings: first, most inexact\nmultipliers and dividers are specialized for Application-Specific Integrated\nCircuit (ASIC) platforms. Second, state-of-the-art (SoA) approximate units are\nsubstituted, mostly in a single kernel of a multi-kernel application. Moreover,\nthe end-to-end assessment is adopted on the Quality of Results (QoR), but not\non the overall gained performance. Finally, existing imprecise components are\nnot designed to support a pipelined approach, which could boost the operating\nfrequency/throughput of, e.g., division-included applications. In this paper,\nwe propose RAPID, the first pipelined approximate multiplier and divider\narchitecture, customized for FPGAs. The proposed units efficiently utilize\n6-input Look-up Tables (6-LUTs) and fast carry chains to implement Mitchell's\napproximate algorithms. Our novel error-refinement scheme not only has\nnegligible overhead over the baseline Mitchell's approach but also boosts its\naccuracy to 99.4% for arbitrary size of multiplication and division.\nExperimental results demonstrate the efficiency of the proposed pipelined and\nnon-pipelined RAPID multipliers and dividers over accurate counterparts.\nMoreover, the end-to-end evaluations of RAPID, deployed in three multi-kernel\napplications in the domains of bio-signal processing, image processing, and\nmoving object tracking for Unmanned Air Vehicles (UAV) indicate up to 45%\nimprovements in area, latency, and Area-Delay-Product (ADP), respectively, over\naccurate kernels, with negligible loss in QoR.",
    "descriptor": "",
    "authors": [
      "Zahra Ebrahimi",
      "Muhammad Zaid",
      "Mark Wijtvliet",
      "Akash Kumar"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2206.13970"
  },
  {
    "id": "arXiv:2206.13973",
    "title": "Towards a Grounded Theory of Causation for Embodied AI",
    "abstract": "There exist well-developed frameworks for causal modelling, but these require\nrather a lot of human domain expertise to define causal variables and perform\ninterventions. In order to enable autonomous agents to learn abstract causal\nmodels through interactive experience, the existing theoretical foundations\nneed to be extended and clarified. Existing frameworks give no guidance\nregarding variable choice / representation, and more importantly, give no\nindication as to which behaviour policies or physical transformations of state\nspace shall count as interventions. The framework sketched in this paper\ndescribes actions as transformations of state space, for instance induced by an\nagent running a policy. This makes it possible to describe in a uniform way\nboth transformations of the micro-state space and abstract models thereof, and\nsay when the latter is veridical / grounded / natural. We then introduce\n(causal) variables, define a mechanism as an invariant predictor, and say when\nan action can be viewed as a ``surgical intervention'', thus bringing the\nobjective of causal representation & intervention skill learning into clearer\nfocus.",
    "descriptor": "",
    "authors": [
      "Taco Cohen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.13973"
  },
  {
    "id": "arXiv:2206.13974",
    "title": "Joint Generator-Ranker Learning for Natural Language Generation",
    "abstract": "Due to exposure bias, most existing natural language generation (NLG) models\ntrained by maximizing the likelihood objective predict poor text results during\nthe inference stage. In this paper, to tackle this problem, we revisit the\ngenerate-then-rank framework and propose a joint generator-ranker (JGR)\ntraining algorithm for text generation tasks. In JGR, the generator model is\ntrained by maximizing two objectives: the likelihood of the training corpus and\nthe expected reward given by the ranker model. Meanwhile, the ranker model\ntakes input samples from the generator model and learns to distinguish good\nsamples from the generation pool. The generator and ranker models are\nalternately optimized till convergence. In the empirical study, the proposed\nJGR model achieves new state-of-the-art performance on five public benchmarks\ncovering three popular generation tasks: summarization, question generation,\nand response generation. We will make code, data, and models available at\nhttps://github.com/microsoft/AdvNLG.",
    "descriptor": "\nComments: In progress\n",
    "authors": [
      "Weizhou Shen",
      "Yeyun Gong",
      "Yelong Shen",
      "Song Wang",
      "Xiaojun Quan",
      "Nan Duan",
      "Weizhu Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.13974"
  },
  {
    "id": "arXiv:2206.13979",
    "title": "Attack Agnostic Dataset: Towards Generalization and Stabilization of  Audio DeepFake Detection",
    "abstract": "Audio DeepFakes allow the creation of high-quality, convincing utterances and\ntherefore pose a threat due to its potential applications such as impersonation\nor fake news. Methods for detecting these manipulations should be characterized\nby good generalization and stability leading to robustness against attacks\nconducted with techniques that are not explicitly included in the training. In\nthis work, we introduce Attack Agnostic Dataset - a combination of two audio\nDeepFakes and one anti-spoofing datasets that, thanks to the disjoint use of\nattacks, can lead to better generalization of detection methods. We present a\nthorough analysis of current DeepFake detection methods and consider different\naudio features (front-ends). In addition, we propose a model based on LCNN with\nLFCC and mel-spectrogram front-end, which not only is characterized by a good\ngeneralization and stability results but also shows improvement over LFCC-based\nmode - we decrease standard deviation on all folds and EER in two folds by up\nto 5%.",
    "descriptor": "\nComments: Proceedings of INTERSPEECH 2022\n",
    "authors": [
      "Piotr Kawa",
      "Marcin Plata",
      "Piotr Syga"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.13979"
  },
  {
    "id": "arXiv:2206.13980",
    "title": "Label-enhanced Prototypical Network with Contrastive Learning for  Multi-label Few-shot Aspect Category Detection",
    "abstract": "Multi-label aspect category detection allows a given review sentence to\ncontain multiple aspect categories, which is shown to be more practical in\nsentiment analysis and attracting increasing attention. As annotating large\namounts of data is time-consuming and labor-intensive, data scarcity occurs\nfrequently in real-world scenarios, which motivates multi-label few-shot aspect\ncategory detection. However, research on this problem is still in infancy and\nfew methods are available. In this paper, we propose a novel label-enhanced\nprototypical network (LPN) for multi-label few-shot aspect category detection.\nThe highlights of LPN can be summarized as follows. First, it leverages label\ndescription as auxiliary knowledge to learn more discriminative prototypes,\nwhich can retain aspect-relevant information while eliminating the harmful\neffect caused by irrelevant aspects. Second, it integrates with contrastive\nlearning, which encourages that the sentences with the same aspect label are\npulled together in embedding space while simultaneously pushing apart the\nsentences with different aspect labels. In addition, it introduces an adaptive\nmulti-label inference module to predict the aspect count in the sentence, which\nis simple yet effective. Extensive experimental results on three datasets\ndemonstrate that our proposed model LPN can consistently achieve\nstate-of-the-art performance.",
    "descriptor": "\nComments: Accepted to KDD 2022\n",
    "authors": [
      "Han Liu",
      "Feng Zhang",
      "Xiaotong Zhang",
      "Siyang Zhao",
      "Junjie Sun",
      "Hong Yu",
      "Xianchao Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.13980"
  },
  {
    "id": "arXiv:2206.13981",
    "title": "Hybrid Ensemble for Fake News Detection: An attempt",
    "abstract": "Fake News Detection has been a challenging problem in the field of Machine\nLearning. Researchers have approached it via several techniques using old\nStatistical Classification models and modern Deep Learning. Today, with the\ngrowing amount of data, developments in the field of NLP and ML, and an\nincrease in the computation power at disposal, there are infinite permutations\nand combinations to approach this problem from a different perspective. In this\npaper, we try different methods to tackle Fake News, and try to build, and\npropose the possibilities of a Hybrid Ensemble combining the classical Machine\nLearning techniques with the modern Deep Learning Approaches",
    "descriptor": "",
    "authors": [
      "Lovedeep Singh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.13981"
  },
  {
    "id": "arXiv:2206.13982",
    "title": "A Proposed Bi-LSTM Method to Fake News Detection",
    "abstract": "Recent years have seen an explosion in social media usage, allowing people to\nconnect with others. Since the appearance of platforms such as Facebook and\nTwitter, such platforms influence how we speak, think, and behave. This problem\nnegatively undermines confidence in content because of the existence of fake\nnews. For instance, false news was a determining factor in influencing the\noutcome of the U.S. presidential election and other sites. Because this\ninformation is so harmful, it is essential to make sure we have the necessary\ntools to detect and resist it. We applied Bidirectional Long Short-Term Memory\n(Bi-LSTM) to determine if the news is false or real in order to showcase this\nstudy. A number of foreign websites and newspapers were used for data\ncollection. After creating & running the model, the work achieved 84% model\naccuracy and 62.0 F1-macro scores with training data.",
    "descriptor": "\nComments: Accepted and published in 2022 International Conference for Advancement in Technology, 5 pages, 8 figures\n",
    "authors": [
      "Taminul Islam",
      "MD Alamin Hosen",
      "Akhi Mony",
      "MD Touhid Hasan",
      "Israt Jahan",
      "Arindom Kundu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.13982"
  },
  {
    "id": "arXiv:2206.13983",
    "title": "BAGEL: A Benchmark for Assessing Graph Neural Network Explanations",
    "abstract": "The problem of interpreting the decisions of machine learning is a\nwell-researched and important. We are interested in a specific type of machine\nlearning model that deals with graph data called graph neural networks.\nEvaluating interpretability approaches for graph neural networks (GNN)\nspecifically are known to be challenging due to the lack of a commonly accepted\nbenchmark. Given a GNN model, several interpretability approaches exist to\nexplain GNN models with diverse (sometimes conflicting) evaluation\nmethodologies. In this paper, we propose a benchmark for evaluating the\nexplainability approaches for GNNs called Bagel. In Bagel, we firstly propose\nfour diverse GNN explanation evaluation regimes -- 1) faithfulness, 2)\nsparsity, 3) correctness. and 4) plausibility. We reconcile multiple evaluation\nmetrics in the existing literature and cover diverse notions for a holistic\nevaluation. Our graph datasets range from citation networks, document graphs,\nto graphs from molecules and proteins. We conduct an extensive empirical study\non four GNN models and nine post-hoc explanation approaches for node and graph\nclassification tasks. We open both the benchmarks and reference implementations\nand make them available at https://github.com/Mandeep-Rathee/Bagel-benchmark.",
    "descriptor": "",
    "authors": [
      "Mandeep Rathee",
      "Thorben Funke",
      "Avishek Anand",
      "Megha Khosla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.13983"
  },
  {
    "id": "arXiv:2206.13984",
    "title": "Fundamental Limits of Communication Efficiency for Model Aggregation in  Distributed Learning: A Rate-Distortion Approach",
    "abstract": "One of the main focuses in distributed learning is communication efficiency,\nsince model aggregation at each round of training can consist of millions to\nbillions of parameters. Several model compression methods, such as gradient\nquantization and sparsification, have been proposed to improve the\ncommunication efficiency of model aggregation. However, the\ninformation-theoretic minimum communication cost for a given distortion of\ngradient estimators is still unknown. In this paper, we study the fundamental\nlimit of communication cost of model aggregation in distributed learning from a\nrate-distortion perspective. By formulating the model aggregation as a vector\nGaussian CEO problem, we derive the rate region bound and sum-rate-distortion\nfunction for the model aggregation problem, which reveals the minimum\ncommunication rate at a particular gradient distortion upper bound. We also\nanalyze the communication cost at each iteration and total communication cost\nbased on the sum-rate-distortion function with the gradient statistics of\nreal-world datasets. It is found that the communication gain by exploiting the\ncorrelation between worker nodes is significant for SignSGD, and a high\ndistortion of gradient estimator can achieve low total communication cost in\ngradient compression.",
    "descriptor": "\nComments: 30 pages, 8 figures, the conference version has been accepted by ISIT2021\n",
    "authors": [
      "Naifu Zhang",
      "Meixia Tao",
      "Jia Wang",
      "Fan Xu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.13984"
  },
  {
    "id": "arXiv:2206.13991",
    "title": "Increasing Confidence in Adversarial Robustness Evaluations",
    "abstract": "Hundreds of defenses have been proposed to make deep neural networks robust\nagainst minimal (adversarial) input perturbations. However, only a handful of\nthese defenses held up their claims because correctly evaluating robustness is\nextremely challenging: Weak attacks often fail to find adversarial examples\neven if they unknowingly exist, thereby making a vulnerable network look\nrobust. In this paper, we propose a test to identify weak attacks, and thus\nweak defense evaluations. Our test slightly modifies a neural network to\nguarantee the existence of an adversarial example for every sample.\nConsequentially, any correct attack must succeed in breaking this modified\nnetwork. For eleven out of thirteen previously-published defenses, the original\nevaluation of the defense fails our test, while stronger attacks that break\nthese defenses pass it. We hope that attack unit tests - such as ours - will be\na major component in future robustness evaluations and increase confidence in\nan empirical field that is currently riddled with skepticism.",
    "descriptor": "\nComments: Oral at CVPR 2022 Workshop (Art of Robustness). Project website this https URL\n",
    "authors": [
      "Roland S. Zimmermann",
      "Wieland Brendel",
      "Florian Tramer",
      "Nicholas Carlini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.13991"
  },
  {
    "id": "arXiv:2206.13995",
    "title": "New MDS Entanglement-Assisted Quantum Codes from $h$-Dimension Hermitian  Hull MDS Codes",
    "abstract": "The intersection ${\\bf C}\\bigcap {\\bf C}^{\\perp_H}$ of a linear code ${\\bf C}\n\\subset {\\bf F}_{q^2}$ and its Hermitian dual ${\\bf C}^{\\perp_H}$ is called the\nHermitian hull of this code. A linear code ${\\bf C} \\subset {\\bf F}_{q^2}$\nsatisfying ${\\bf C} \\subset {\\bf C}^{\\perp_H}$ is called Hermitian\nself-orthogonal. Many Hermitian self-orthogonal codes were given for the\nconstruction of MDS quantum error correction codes (QECCs). In this paper we\nprove that for a nonnegative integer $h$ satisfying $0 \\leq h \\leq k$, a linear\nHermitian self-orthogonal $[n, k]_{q^2}$ code is equivalent to a linear\n$h$-dimension Hermitian hull code. Therefore a lot of new MDS\nentanglement-assisted quantum error correction (EAQEC) codes can be constructed\nfrom previous known Hermitian self-orthogonal codes. Actually our method shows\nthat previous constructed quantum MDS codes from Hermitian self-orthogonal\ncodes can be transformed to MDS entanglement-assisted quantum codes with\nnonzero consumption parameter $c$ directly.",
    "descriptor": "\nComments: 15 pages, MDS quantum codes can be transformed to MDS Entanglement-assisted quantum codes with nonzero c parameters directly\n",
    "authors": [
      "Hao Chen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.13995"
  },
  {
    "id": "arXiv:2206.13996",
    "title": "Detecting tiny objects in aerial images: A normalized Wasserstein  distance and a new benchmark",
    "abstract": "Tiny object detection (TOD) in aerial images is challenging since a tiny\nobject only contains a few pixels. State-of-the-art object detectors do not\nprovide satisfactory results on tiny objects due to the lack of supervision\nfrom discriminative features. Our key observation is that the Intersection over\nUnion (IoU) metric and its extensions are very sensitive to the location\ndeviation of the tiny objects, which drastically deteriorates the quality of\nlabel assignment when used in anchor-based detectors. To tackle this problem,\nwe propose a new evaluation metric dubbed Normalized Wasserstein Distance (NWD)\nand a new RanKing-based Assigning (RKA) strategy for tiny object detection. The\nproposed NWD-RKA strategy can be easily embedded into all kinds of anchor-based\ndetectors to replace the standard IoU threshold-based one, significantly\nimproving label assignment and providing sufficient supervision information for\nnetwork training. Tested on four datasets, NWD-RKA can consistently improve\ntiny object detection performance by a large margin. Besides, observing\nprominent noisy labels in the Tiny Object Detection in Aerial Images (AI-TOD)\ndataset, we are motivated to meticulously relabel it and release AI-TOD-v2 and\nits corresponding benchmark. In AI-TOD-v2, the missing annotation and location\nerror problems are considerably mitigated, facilitating more reliable training\nand validation processes. Embedding NWD-RKA into DetectoRS, the detection\nperformance achieves 4.3 AP points improvement over state-of-the-art\ncompetitors on AI-TOD-v2. Datasets, codes, and more visualizations are\navailable at: https://chasel-tsui.github.io/AI-TOD-v2/",
    "descriptor": "\nComments: Accepted by ISPRS Journal of Photogrammetry and Remote Sensing\n",
    "authors": [
      "Chang Xu",
      "Jinwang Wang",
      "Wen Yang",
      "Huai Yu",
      "Lei Yu",
      "Gui-Song Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.13996"
  },
  {
    "id": "arXiv:2206.13998",
    "title": "Learning Symmetric Rules with SATNet",
    "abstract": "SATNet is a differentiable constraint solver with a custom backpropagation\nalgorithm, which can be used as a layer in a deep-learning system. It is a\npromising proposal for bridging deep learning and logical reasoning. In fact,\nSATNet has been successfully applied to learn, among others, the rules of a\ncomplex logical puzzle, such as Sudoku, just from input and output pairs where\ninputs are given as images. In this paper, we show how to improve the learning\nof SATNet by exploiting symmetries in the target rules of a given but unknown\nlogical puzzle or more generally a logical formula. We present SymSATNet, a\nvariant of SATNet that translates the given symmetries of the target rules to a\ncondition on the parameters of SATNet and requires that the parameters should\nhave a particular parametric form that guarantees the condition. The\nrequirement dramatically reduces the number of parameters to learn for the\nrules with enough symmetries, and makes the parameter learning of SymSATNet\nmuch easier than that of SATNet. We also describe a technique for automatically\ndiscovering symmetries of the target rules from examples. Our experiments with\nSudoku and Rubik's cube show the substantial improvement of SymSATNet over the\nbaseline SATNet.",
    "descriptor": "\nComments: 22 pages, 3 figures, the first two authors contributed equally to this work\n",
    "authors": [
      "Sangho Lim",
      "Eun-Gyeol Oh",
      "Hongseok Yang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)",
      "Group Theory (math.GR)"
    ],
    "url": "https://arxiv.org/abs/2206.13998"
  },
  {
    "id": "arXiv:2206.13999",
    "title": "Orthogonal Delay-Doppler Division Multiplexing Modulation",
    "abstract": "Inspired by the orthogonal time frequency space (OTFS) modulation, in this\npaper, we consider designing a multicarrier (MC) modulation on delay-Doppler\n(DD) plane, to couple the modulated signal with a doubly-selective channel\nhaving DD resolutions. A key challenge for the design of DD plane MC modulation\nis to investigate whether a realizable pulse orthogonal with respect to the DD\nplane's fine resolutions exists or not. To this end, we first indicate that a\nfeasible DD plane MC modulation is essentially a type of staggered multitone\nmodulation. Then, analogous to orthogonal frequency division multiplexing, we\npropose an orthogonal delay-Doppler division multiplexing (ODDM) modulation,\nand design the corresponding transmit pulse. Furthermore, we prove that the\nproposed transmit pulse is orthogonal with respect to the DD plane's\nresolutions and therefore a realizable DD plane orthogonal pulse does exist.\nThe orthogonality of this particular pulse significantly eases the derivation\nof the ODDM's DD domain channel input-output relation, and yields a channel\nmatrix with an elegant block-circulant-like structure. We demonstrate that the\nODDM outperforms the OTFS in terms of out-of-band emission and bit error rate,\nby achieving perfect coupling between the modulated signal and the DD channel.",
    "descriptor": "\nComments: This paper has been accepted by IEEE Trans. Wireless Commun. arXiv admin note: text overlap with arXiv:2206.13382\n",
    "authors": [
      "Hai Lin",
      "Jinhong Yuan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.13999"
  },
  {
    "id": "arXiv:2206.14000",
    "title": "SINC: Service Information Augmented Open-Domain Conversation",
    "abstract": "Generative open-domain dialogue systems can benefit from external knowledge,\nbut the lack of external knowledge resources and the difficulty in finding\nrelevant knowledge limit the development of this technology. To this end, we\npropose a knowledge-driven dialogue task using dynamic service information.\nSpecifically, we use a large number of service APIs that can provide high\ncoverage and spatiotemporal sensitivity as external knowledge sources. The\ndialogue system generates queries to request external services along with user\ninformation, get the relevant knowledge, and generate responses based on this\nknowledge. To implement this method, we collect and release the first open\ndomain Chinese service knowledge dialogue dataset DuSinc. At the same time, we\nconstruct a baseline model PLATO-SINC, which realizes the automatic utilization\nof service information for dialogue. Both automatic evaluation and human\nevaluation show that our proposed new method can significantly improve the\neffect of open-domain conversation, and the session-level overall score in\nhuman evaluation is improved by 59.29% compared with the dialogue pre-training\nmodel PLATO-2. The dataset and benchmark model will be open sourced.",
    "descriptor": "\nComments: 12pages, 7 figures\n",
    "authors": [
      "Han Zhou",
      "Xinchao Xu",
      "Wenquan Wu",
      "Zhengyu Niu",
      "Hua Wu",
      "Siqi Bao",
      "Fan Wang",
      "Haifeng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.14000"
  },
  {
    "id": "arXiv:2206.14004",
    "title": "On the amplification of security and privacy risks by post-hoc  explanations in machine learning models",
    "abstract": "A variety of explanation methods have been proposed in recent years to help\nusers gain insights into the results returned by neural networks, which are\notherwise complex and opaque black-boxes. However, explanations give rise to\npotential side-channels that can be leveraged by an adversary for mounting\nattacks on the system. In particular, post-hoc explanation methods that\nhighlight input dimensions according to their importance or relevance to the\nresult also leak information that weakens security and privacy. In this work,\nwe perform the first systematic characterization of the privacy and security\nrisks arising from various popular explanation techniques. First, we propose\nnovel explanation-guided black-box evasion attacks that lead to 10 times\nreduction in query count for the same success rate. We show that the\nadversarial advantage from explanations can be quantified as a reduction in the\ntotal variance of the estimated gradient. Second, we revisit the membership\ninformation leaked by common explanations. Contrary to observations in prior\nstudies, via our modified attacks we show significant leakage of membership\ninformation (above 100% improvement over prior results), even in a much\nstricter black-box setting. Finally, we study explanation-guided model\nextraction attacks and demonstrate adversarial gains through a large reduction\nin query count.",
    "descriptor": "\nComments: 9 pages, appendix: 2 pages\n",
    "authors": [
      "Pengrui Quan",
      "Supriyo Chakraborty",
      "Jeya Vikranth Jeyakumar",
      "Mani Srivastava"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.14004"
  },
  {
    "id": "arXiv:2206.14007",
    "title": "The Importance of (Exponentially More) Computing Power",
    "abstract": "Denizens of Silicon Valley have called Moore's Law \"the most important graph\nin human history,\" and economists have found that Moore's Law-powered I.T.\nrevolution has been one of the most important sources of national productivity\ngrowth. But data substantiating these claims tend to either be abstracted - for\nexample by examining spending on I.T., rather than I.T. itself - or anecdotal.\nIn this paper, we assemble direct quantitative evidence of the impact that\ncomputing power has had on five domains: two computing bellwethers (Chess and\nGo), and three economically important applications (weather prediction, protein\nfolding, and oil exploration). Computing power explains 49%-94% of the\nperformance improvements in these domains. But whereas economic theory\ntypically assumes a power-law relationship between inputs and outputs, we find\nthat an exponential increase in computing power is needed to get linear\nimprovements in these outcomes. This helps clarify why the exponential growth\nof computing power from Moore's Law has been so important for progress, and why\nperformance improvements across many domains are becoming economically tenuous\nas Moore's Law breaks down.",
    "descriptor": "",
    "authors": [
      "Neil C. Thompson",
      "Shuning Ge",
      "Gabriel F. Manso"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Computers and Society (cs.CY)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2206.14007"
  },
  {
    "id": "arXiv:2206.14009",
    "title": "Show Me Your Face, And I'll Tell You How You Speak",
    "abstract": "When we speak, the prosody and content of the speech can be inferred from the\nmovement of our lips. In this work, we explore the task of lip to speech\nsynthesis, i.e., learning to generate speech given only the lip movements of a\nspeaker where we focus on learning accurate lip to speech mappings for multiple\nspeakers in unconstrained, large vocabulary settings. We capture the speaker's\nvoice identity through their facial characteristics, i.e., age, gender,\nethnicity and condition them along with the lip movements to generate speaker\nidentity aware speech. To this end, we present a novel method \"Lip2Speech\",\nwith key design choices to achieve accurate lip to speech synthesis in\nunconstrained scenarios. We also perform various experiments and extensive\nevaluation using quantitative, qualitative metrics and human evaluation.",
    "descriptor": "",
    "authors": [
      "Christen Millerdurai",
      "Lotfy Abdel Khaliq",
      "Timon Ulrich"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.14009"
  },
  {
    "id": "arXiv:2206.14011",
    "title": "Taxonomy and evolution predicting using deep learning in images",
    "abstract": "Molecular and morphological characters, as important parts of biological\ntaxonomy, are contradictory but need to be integrated. Organism's image\nrecognition and bioinformatics are emerging and hot problems nowadays but with\na gap between them. In this work, a multi-branching recognition framework\nmediated by genetic information bridges this barrier, which establishes the\nlink between macro-morphology and micro-molecular information of mushrooms. The\nnovel multi-perspective structure is proposed to fuse the feature images from\nthree branching models, which significantly improves the accuracy of\nrecognition by about 10% and up to more than 90%. Further, genetic information\nis implemented to the mushroom image recognition task by using genetic distance\nembeddings as the representation space for predicting image distance and\nspecies identification. Semantic overfitting of traditional classification\ntasks and the granularity of fine-grained image recognition are also discussed\nin depth for the first time. The generalizability of the model was investigated\nin fine-grained scenarios using zero-shot learning tasks, which could predict\nthe taxonomic and evolutionary information of unseen samples. We presented the\nfirst method to map images to DNA, namely used an encoder mapping image to\ngenetic distances, and then decoded DNA through a pre-trained decoder, where\nthe total test accuracy on 37 species for DNA prediction is 87.45%. This study\ncreates a novel recognition framework by systematically studying the mushroom\nimage recognition problem, bridging the gap between macroscopic biological\ninformation and microscopic molecular information, which will provide a new\nreference for intelligent biometrics in the future.",
    "descriptor": "",
    "authors": [
      "Jiewen Xiao",
      "Wenbin Liao",
      "Ming Zhang",
      "Jing Wang",
      "Jianxin Wang",
      "Yihua Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.14011"
  },
  {
    "id": "arXiv:2206.14016",
    "title": "The Case for RISP: A Reduced Instruction Spiking Processor",
    "abstract": "In this paper, we introduce RISP, a reduced instruction spiking processor.\nWhile most spiking neuroprocessors are based on the brain, or notions from the\nbrain, we present the case for a spiking processor that simplifies rather than\ncomplicates. As such, it features discrete integration cycles, configurable\nleak, and little else. We present the computing model of RISP and highlight the\nbenefits of its simplicity. We demonstrate how it aids in developing hand built\nneural networks for simple computational tasks, detail how it may be employed\nto simplify neural networks built with more complicated machine learning\ntechniques, and demonstrate how it performs similarly to other spiking\nneurprocessors.",
    "descriptor": "\nComments: 5 pages, 5 figures\n",
    "authors": [
      "James S. Plank",
      "ChaoHui Zheng",
      "Bryson Gullett",
      "Nicholas Skuda",
      "Charles Rizzo",
      "Catherine D. Schuman",
      "Garrett S. Rose"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.14016"
  },
  {
    "id": "arXiv:2206.14017",
    "title": "Proton: Probing Schema Linking Information from Pre-trained Language  Models for Text-to-SQL Parsing",
    "abstract": "The importance of building text-to-SQL parsers which can be applied to new\ndatabases has long been acknowledged, and a critical step to achieve this goal\nis schema linking, i.e., properly recognizing mentions of unseen columns or\ntables when generating SQLs. In this work, we propose a novel framework to\nelicit relational structures from large-scale pre-trained language models\n(PLMs) via a probing procedure based on Poincar\\'e distance metric, and use the\ninduced relations to augment current graph-based parsers for better schema\nlinking. Compared with commonly-used rule-based methods for schema linking, we\nfound that probing relations can robustly capture semantic correspondences,\neven when surface forms of mentions and entities differ. Moreover, our probing\nprocedure is entirely unsupervised and requires no additional parameters.\nExtensive experiments show that our framework sets new state-of-the-art\nperformance on three benchmarks. We empirically verify that our probing\nprocedure can indeed find desired relational structures through qualitative\nanalysis.",
    "descriptor": "\nComments: Accepted at KDD 2022\n",
    "authors": [
      "Lihan Wang",
      "Bowen Qin",
      "Binyuan Hui",
      "Bowen Li",
      "Min Yang",
      "Bailin Wang",
      "Binhua Li",
      "Fei Huang",
      "Luo Si",
      "Yongbin Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.14017"
  },
  {
    "id": "arXiv:2206.14020",
    "title": "Rethinking Adversarial Examples for Location Privacy Protection",
    "abstract": "We have investigated a new application of adversarial examples, namely\nlocation privacy protection against landmark recognition systems. We introduce\nmask-guided multimodal projected gradient descent (MM-PGD), in which\nadversarial examples are trained on different deep models. Image contents are\nprotected by analyzing the properties of regions to identify the ones most\nsuitable for blending in adversarial examples. We investigated two region\nidentification strategies: class activation map-based MM-PGD, in which the\ninternal behaviors of trained deep models are targeted; and human-vision-based\nMM-PGD, in which regions that attract less human attention are targeted.\nExperiments on the Places365 dataset demonstrated that these strategies are\npotentially effective in defending against black-box landmark recognition\nsystems without the need for much image manipulation.",
    "descriptor": "",
    "authors": [
      "Trung-Nghia Le",
      "Ta Gu",
      "Huy H. Nguyen",
      "Isao Echizen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.14020"
  },
  {
    "id": "arXiv:2206.14048",
    "title": "Short-Term Plasticity Neurons Learning to Learn and Forget",
    "abstract": "Short-term plasticity (STP) is a mechanism that stores decaying memories in\nsynapses of the cerebral cortex. In computing practice, STP has been used, but\nmostly in the niche of spiking neurons, even though theory predicts that it is\nthe optimal solution to certain dynamic tasks. Here we present a new type of\nrecurrent neural unit, the STP Neuron (STPN), which indeed turns out strikingly\npowerful. Its key mechanism is that synapses have a state, propagated through\ntime by a self-recurrent connection-within-the-synapse. This formulation\nenables training the plasticity with backpropagation through time, resulting in\na form of learning to learn and forget in the short term. The STPN outperforms\nall tested alternatives, i.e. RNNs, LSTMs, other models with fast weights, and\ndifferentiable plasticity. We confirm this in both supervised and reinforcement\nlearning (RL), and in tasks such as Associative Retrieval, Maze Exploration,\nAtari video games, and MuJoCo robotics. Moreover, we calculate that, in\nneuromorphic or biological circuits, the STPN minimizes energy consumption\nacross models, as it depresses individual synapses dynamically. Based on these,\nbiological STP may have been a strong evolutionary attractor that maximizes\nboth efficiency and computational power. The STPN now brings these neuromorphic\nadvantages also to a broad spectrum of machine learning practice. Code is\navailable at https://github.com/NeuromorphicComputing/stpn",
    "descriptor": "\nComments: Accepted at ICML 2022\n",
    "authors": [
      "Hector Garcia Rodriguez",
      "Qinghai Guo",
      "Timoleon Moraitis"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2206.14048"
  },
  {
    "id": "arXiv:2206.14049",
    "title": "TAMOLS: Terrain-Aware Motion Optimization for Legged Systems",
    "abstract": "Terrain geometry is, in general, non-smooth, non-linear, non-convex, and, if\nperceived through a robot-centric visual unit, appears partially occluded and\nnoisy. This work presents the complete control pipeline capable of handling the\naforementioned problems in real-time. We formulate a trajectory optimization\nproblem that jointly optimizes over the base pose and footholds, subject to a\nheightmap. To avoid converging into undesirable local optima, we deploy a\ngraduated optimization technique. We embed a compact, contact-force free\nstability criterion that is compatible with the non-flat ground formulation.\nDirect collocation is used as transcription method, resulting in a non-linear\noptimization problem that can be solved online in less than ten milliseconds.\nTo increase robustness in the presence of external disturbances, we close the\ntracking loop with a momentum observer. Our experiments demonstrate stair\nclimbing, walking on stepping stones, and over gaps, utilizing various dynamic\ngaits.",
    "descriptor": "\nComments: Accepted as regular T-RO paper\n",
    "authors": [
      "Fabian Jenelten",
      "Ruben Grandia",
      "Farbod Farshidian",
      "Marco Hutter"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.14049"
  },
  {
    "id": "arXiv:2206.14051",
    "title": "Modeling Extraneous Activity Delays in Business Process Simulation",
    "abstract": "Business Process Simulation (BPS) is a common approach to estimate the impact\nof changes to a business process on its performance measures. For example, BPS\nallows us to estimate what would be the cycle time of a process if we automated\none of its activities. The starting point of BPS is a business process model\nannotated with simulation parameters (a BPS model). Several studies have\nproposed methods to automatically discover BPS models from event logs via\nprocess mining. However, current techniques in this space discover BPS models\nthat only capture waiting times caused by resource contention or resource\nunavailability. Oftentimes, a considerable portion of the waiting time in a\nbusiness process is caused by extraneous delays, e.g. a resource waits for the\ncustomer to return a phone call. This paper proposes a method that discovers\nextraneous delays from input data, and injects timer events into a BPS model to\ncapture the discovered delays. An empirical evaluation involving synthetic and\nreal-life logs shows that the approach produces BPS models that better reflect\nthe temporal dynamics of the process, relative to BPS models that do not\ncapture extraneous delays.",
    "descriptor": "\nComments: Preprint submitted to the 4th International Conference on Process Mining (ICPM 2022)\n",
    "authors": [
      "David Chapela-Campa",
      "Marlon Dumas"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14051"
  },
  {
    "id": "arXiv:2206.14053",
    "title": "Bengali Common Voice Speech Dataset for Automatic Speech Recognition",
    "abstract": "Bengali is one of the most spoken languages in the world with over 300\nmillion speakers globally. Despite its popularity, research into the\ndevelopment of Bengali speech recognition systems is hindered due to the lack\nof diverse open-source datasets. As a way forward, we have crowdsourced the\nBengali Common Voice Speech Dataset, which is a sentence-level automatic speech\nrecognition corpus. Collected on the Mozilla Common Voice platform, the dataset\nis part of an ongoing campaign that has led to the collection of over 400 hours\nof data in 2 months and is growing rapidly. Our analysis shows that our dataset\nhas more speaker, phoneme, and environmental diversity compared to the OpenSLR\nBengali ASR dataset, the largest existing open-source Bengali speech dataset.\nWe present insights obtained from the dataset and discuss key linguistic\nchallenges that need to be addressed in future versions. Additionally, we\nreport the current performance of a few Automatic Speech Recognition (ASR)\nalgorithms and set a benchmark for future research.",
    "descriptor": "",
    "authors": [
      "Samiul Alam",
      "Asif Sushmit",
      "Zaowad Abdullah",
      "Shahrin Nakkhatra",
      "MD. Nazmuddoha Ansary",
      "Syed Mobassir Hossen",
      "Sazia Morshed Mehnaz",
      "Tahsin Reasat",
      "Ahmed Imtiaz Humayun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.14053"
  },
  {
    "id": "arXiv:2206.14055",
    "title": "Towards Lexical Gender Inference: A Scalable Methodology using Online  Databases",
    "abstract": "This paper presents a new method for automatically detecting words with\nlexical gender in large-scale language datasets. Currently, the evaluation of\ngender bias in natural language processing relies on manually compiled lexicons\nof gendered expressions, such as pronouns ('he', 'she', etc.) and nouns with\nlexical gender ('mother', 'boyfriend', 'policewoman', etc.). However, manual\ncompilation of such lists can lead to static information if they are not\nperiodically updated and often involve value judgments by individual annotators\nand researchers. Moreover, terms not included in the list fall out of the range\nof analysis. To address these issues, we devised a scalable, dictionary-based\nmethod to automatically detect lexical gender that can provide a dynamic,\nup-to-date analysis with high coverage. Our approach reaches over 80% accuracy\nin determining the lexical gender of nouns retrieved randomly from a Wikipedia\nsample and when testing on a list of gendered words used in previous research.",
    "descriptor": "\nComments: 12 pages, 4 tables, 2 figures. Article published under different title in Proceedings of the Second Workshop on Language Technology for Equality, Diversity and Inclusion at ACL 2022\n",
    "authors": [
      "Marion Bartl",
      "Susan Leavy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.14055"
  },
  {
    "id": "arXiv:2206.14056",
    "title": "Deep Neural Networks pruning via the Structured Perspective  Regularization",
    "abstract": "In Machine Learning, Artificial Neural Networks (ANNs) are a very powerful\ntool, broadly used in many applications. Often, the selected (deep)\narchitectures include many layers, and therefore a large amount of parameters,\nwhich makes training, storage and inference expensive. This motivated a stream\nof research about compressing the original networks into smaller ones without\nexcessively sacrificing performances. Among the many proposed compression\napproaches, one of the most popular is \\emph{pruning}, whereby entire elements\nof the ANN (links, nodes, channels, \\ldots) and the corresponding weights are\ndeleted. Since the nature of the problem is inherently combinatorial (what\nelements to prune and what not), we propose a new pruning method based on\nOperational Research tools. We start from a natural Mixed-Integer-Programming\nmodel for the problem, and we use the Perspective Reformulation technique to\nstrengthen its continuous relaxation. Projecting away the indicator variables\nfrom this reformulation yields a new regularization term, which we call the\nStructured Perspective Regularization, that leads to structured pruning of the\ninitial architecture. We test our method on some ResNet architectures applied\nto CIFAR-10, CIFAR-100 and ImageNet datasets, obtaining competitive\nperformances w.r.t.~the state of the art for structured pruning.",
    "descriptor": "",
    "authors": [
      "Matteo Cacciola",
      "Antonio Frangioni",
      "Xinlin Li",
      "Andrea Lodi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.14056"
  },
  {
    "id": "arXiv:2206.14057",
    "title": "Safe Exploration Incurs Nearly No Additional Sample Complexity for  Reward-free RL",
    "abstract": "While the primary goal of the exploration phase in reward-free reinforcement\nlearning (RF-RL) is to reduce the uncertainty in the estimated model with\nminimum number of trajectories, in practice, the agent often needs to abide by\ncertain safety constraint at the same time. It remains unclear how such safe\nexploration requirement would affect the corresponding sample complexity to\nachieve the desired optimality of the obtained policy in planning. In this\nwork, we make a first attempt to answer this question. In particular, we\nconsider the scenario where a safe baseline policy is known beforehand, and\npropose a unified Safe reWard-frEe ExploraTion (SWEET) framework. We then\nparticularize the SWEET framework to the tabular and the low-rank MDP settings,\nand develop algorithms coined Tabular-SWEET and Low-rank-SWEET, respectively.\nBoth algorithms leverage the concavity and continuity of the newly introduced\ntruncated value functions, and are guaranteed to achieve zero constraint\nviolation during exploration with high probability. Furthermore, both\nalgorithms can provably find a near-optimal policy subject to any constraint in\nthe planning phase. Remarkably, the sample complexities under both algorithms\nmatch or even outperform the state of the art in their constraint-free\ncounterparts up to some constant factors, proving that safety constraint hardly\nincreases the sample complexity for RF-RL.",
    "descriptor": "",
    "authors": [
      "Ruiquan Huang",
      "Jing Yang",
      "Yingbin Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.14057"
  },
  {
    "id": "arXiv:2206.14068",
    "title": "FuSeBMC v4: Improving code coverage with smart seeds via fuzzing and  static analysis",
    "abstract": "Bounded model checking (BMC) and fuzzing techniques are among the most\neffective methods for detecting errors and security vulnerabilities in\nsoftware. However, there is still a shortcoming in detecting these errors due\nto the inability to cover large areas in the target code. Coverage standards\nand measures are also an excellent way to ascertain the effectiveness of the\ntest suite. We propose FuSeBMC v4, a test generator that relies on smart seeds\nto improve the hybrid fuzzer to achieve high C programs coverage. First,\nFuSeBMC analyses and incrementally injects goal labels into the given C program\nto guide BMC and Evolutionary Fuzzing engines. Also, It ranks these goal labels\naccording to the given strategy. After that, the engines are employed to\nproduce smart seeds quickly to use later. Then, FuSeBMC coordinates between the\nengines and seed distribution by the Tracer. This Tracer generally manages the\ntool to record the goals covered and transfer the information between the\nengines by providing a shared memory to harness the power and take advantage of\nthe power of each engine. So that the BMC engine helps give the seed that makes\nthe fuzzing engine not struggle with complex mathematical guards. Furthermore,\nTracer evaluates test cases dynamically to convert high-impact cases into seeds\nfor subsequent test fuzzing. As a result, we received three awards for\nparticipation in the fourth international competition in software testing\n(Test-Comp 2022), outperforming all state-of-the-art tools in every category,\nincluding the coverage category.",
    "descriptor": "\nComments: 21 pages, In The Formal Aspects of Computing Journal (FAC 2022)\n",
    "authors": [
      "Kaled M. Alshmrany",
      "Mohannad Aldughaim",
      "Ahmed Bhayat",
      "Fedor Shmarov",
      "Fatimah Aljaafari",
      "Lucas C. Cordeiro"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.14068"
  },
  {
    "id": "arXiv:2206.14069",
    "title": "Equivariant Priors for Compressed Sensing with Unknown Orientation",
    "abstract": "In compressed sensing, the goal is to reconstruct the signal from an\nunderdetermined system of linear measurements. Thus, prior knowledge about the\nsignal of interest and its structure is required. Additionally, in many\nscenarios, the signal has an unknown orientation prior to measurements. To\naddress such recovery problems, we propose using equivariant generative models\nas a prior, which encapsulate orientation information in their latent space.\nThereby, we show that signals with unknown orientations can be recovered with\niterative gradient descent on the latent space of these models and provide\nadditional theoretical recovery guarantees. We construct an equivariant\nvariational autoencoder and use the decoder as generative prior for compressed\nsensing. We discuss additional potential gains of the proposed approach in\nterms of convergence and latency.",
    "descriptor": "",
    "authors": [
      "Anna Kuzina",
      "Kumar Pratik",
      "Fabio Valerio Massoli",
      "Arash Behboodi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.14069"
  },
  {
    "id": "arXiv:2206.14071",
    "title": "R2: Heuristic Bug-Based Any-angle Path-Planning using Lazy Searches",
    "abstract": "R2 is a novel online any-angle path planner that uses heuristic bug-based or\nray casting approaches to find optimal paths in 2D maps with non-convex,\npolygonal obstacles. R2 is competitive to traditional free-space planners,\nfinding paths quickly if queries have direct line-of-sight. On large sparse\nmaps with few obstacle contours, which are likely to occur in practice, R2\noutperforms free-space planners, and can be much faster than state-of-the-art\nfree-space expansion planner Anya. On maps with many contours, Anya performs\nfaster than R2. R2 is built on RayScan, introducing lazy-searches and a\nsource-pledge counter to find successors optimistically on contiguous contours.\nThe novel approach bypasses most successors on jagged contours to reduce\nexpensive line-of-sight checks, therefore requiring no pre-processing to be a\ncompetitive online any-angle planner.",
    "descriptor": "",
    "authors": [
      "Yan Kai Lai",
      "Prahlad Vadakkepat",
      "Abdullah Al Mamun",
      "Cheng Xiang",
      "Tong Heng Lee"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.14071"
  },
  {
    "id": "arXiv:2206.14076",
    "title": "Reasoning about Moving Target Defense in Attack Modeling Formalisms",
    "abstract": "Since 2009, Moving Target Defense (MTD) has become a new paradigm of\ndefensive mechanism that frequently changes the state of the target system to\nconfuse the attacker. This frequent change is costly and leads to a trade-off\nbetween misleading the attacker and disrupting the quality of service.\nOptimizing the MTD activation frequency is necessary to develop this defense\nmechanism when facing realistic, multi-step attack scenarios. Attack modeling\nformalisms based on DAG are prominently used to specify these scenarios. Our\ncontribution is a new DAG-based formalism for MTDs and its translation into a\nPrice Timed Markov Decision Process to find the best activation frequencies\nagainst the attacker's time/cost-optimal strategies. For the first time, MTD\nactivation frequencies are analyzed in a state-of-the-art DAG-based\nrepresentation. Moreover, this is the first paper that considers the\nspecificity of MTDs in the automatic analysis of attack modeling formalisms.\nFinally, we present some experimental results using Uppaal Stratego to\ndemonstrate its applicability and relevance.",
    "descriptor": "",
    "authors": [
      "Gabriel Ballot",
      "Vadim Malvone",
      "Jean Leneutre",
      "Etienne Borde"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2206.14076"
  },
  {
    "id": "arXiv:2206.14077",
    "title": "DSME-LoRa: Seamless Long Range Communication Between Arbitrary Nodes in  the Constrained IoT",
    "abstract": "Long range radio communication is preferred in many IoT deployments as it\navoids the complexity of multi-hop wireless networks. LoRa is a popular,\nenergy-efficient wireless modulation but its networking substrate LoRaWAN\nintroduces severe limitations to its users. In this paper, we present and\nthoroughly analyze DSME-LoRa, a system design of LoRa with IEEE 802.15.4 DSME\nas a MAC layer. DSME-LoRa offers the advantage of seamless client-to-client\ncommunication beyond the pure gateway-centric transmission of LoRaWAN. We\nevaluate its feasibility via a full-stack implementation on the popular RIOT\noperating system, assess its steady-state packet flows in an analytical\nstochastic Markov model, and quantify its scalability in massive communication\nscenarios using large scale network simulations. Our findings indicate that\nDSME-LoRa is indeed a powerful approach that opens LoRa to standard network\nlayers and outperforms LoRaWAN in many dimensions.",
    "descriptor": "\nComments: 44 pages (incl. References), 27 figures,8 tables\n",
    "authors": [
      "Jos\u00e9 \u00c1lamos",
      "Peter Kietzmann",
      "Thomas Schmidt",
      "Matthias Waehlisch"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.14077"
  },
  {
    "id": "arXiv:2206.14080",
    "title": "An Algebraic Construction Technique for Codes over Hurwitz Integers",
    "abstract": "Let {\\alpha} be a prime Hurwitz integer. H{\\alpha}, which is the set of\nresidual class with respect to related modulo function in the rings of Hurwitz\nintegers, is a subset of H, which is the set of all Hurwitz integers. We\nconsider left congruent module {\\alpha} and, the domain of related modulo\nfunction in this study is ZN({\\alpha}), which is residual class ring of\nordinary integers with N({\\alpha}) elements, which is the norm of prime Hurwitz\ninteger {\\alpha}. In this study, we present an algebraic construction\ntechnique, which is a modulo function formed depending on two modulo\noperations, for codes over Hurwitz integers. Thereby, we obtain the residue\nclass rings of Hurwitz integers with N({\\alpha}) size. In addition, we present\nsome results for mathematical notations used in two modulo functions, and for\nthe algebraic construction technique formed depending upon two modulo\nfunctions. Moreover, we present graphs obtained by graph layout methods, such\nas spring, high-dimensional, and spiral embedding, for the set of the residual\nclass obtained with respect to the related modulo function in the rings of\nHurwitz integers.",
    "descriptor": "",
    "authors": [
      "Ramazan Duran",
      "Murat Guzeltepe"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2206.14080"
  },
  {
    "id": "arXiv:2206.14081",
    "title": "Linear programming-based solution methods for constrained POMDPs",
    "abstract": "Constrained partially observable Markov decision processes (CPOMDPs) have\nbeen used to model various real-world phenomena. However, they are notoriously\ndifficult to solve to optimality, and there exist only a few approximation\nmethods for obtaining high-quality solutions. In this study, we use grid-based\napproximations in combination with linear programming (LP) models to generate\napproximate policies for CPOMDPs. We consider five CPOMDP problem instances and\nconduct a detailed numerical study of both their finite and infinite horizon\nformulations. We first establish the quality of the approximate unconstrained\nPOMDP policies through a comparative analysis with exact solution methods. We\nthen show the performance of the LP-based CPOMDP solution approaches for\nvarying budget levels (i.e., cost limits) for different problem instances.\nFinally, we show the flexibility of LP-based approaches by applying\ndeterministic policy constraints, and investigate the impact that these\nconstraints have on collected rewards and CPU run time. Our analysis\ndemonstrates that LP models can effectively generate approximate policies for\nboth finite and infinite horizon problems, while providing the flexibility to\nincorporate various additional constraints into the underlying model.",
    "descriptor": "\nComments: 27 pages\n",
    "authors": [
      "Can Kavaklioglu",
      "Robert Helmeczi",
      "Mucahit Cevik"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.14081"
  },
  {
    "id": "arXiv:2206.14085",
    "title": "Continual Learning with Transformers for Image Classification",
    "abstract": "In many real-world scenarios, data to train machine learning models become\navailable over time. However, neural network models struggle to continually\nlearn new concepts without forgetting what has been learnt in the past. This\nphenomenon is known as catastrophic forgetting and it is often difficult to\nprevent due to practical constraints, such as the amount of data that can be\nstored or the limited computation sources that can be used. Moreover, training\nlarge neural networks, such as Transformers, from scratch is very costly and\nrequires a vast amount of training data, which might not be available in the\napplication domain of interest. A recent trend indicates that dynamic\narchitectures based on an expansion of the parameters can reduce catastrophic\nforgetting efficiently in continual learning, but this needs complex tuning to\nbalance the growing number of parameters and barely share any information\nacross tasks. As a result, they struggle to scale to a large number of tasks\nwithout significant overhead. In this paper, we validate in the computer vision\ndomain a recent solution called Adaptive Distillation of Adapters (ADA), which\nis developed to perform continual learning using pre-trained Transformers and\nAdapters on text classification tasks. We empirically demonstrate on different\nclassification tasks that this method maintains a good predictive performance\nwithout retraining the model or increasing the number of model parameters over\nthe time. Besides it is significantly faster at inference time compared to the\nstate-of-the-art methods.",
    "descriptor": "\nComments: Appeared in CVPR CLVision workshop. arXiv admin note: substantial text overlap with arXiv:2203.04640\n",
    "authors": [
      "Beyza Ermis",
      "Giovanni Zappella",
      "Martin Wistuba",
      "Aditya Rawal",
      "Cedric Archambeau"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.14085"
  },
  {
    "id": "arXiv:2206.14089",
    "title": "Placing (Historical) Facts on a Timeline: A Classification cum Coref  Resolution Approach",
    "abstract": "A timeline provides one of the most effective ways to visualize the important\nhistorical facts that occurred over a period of time, presenting the insights\nthat may not be so apparent from reading the equivalent information in textual\nform. By leveraging generative adversarial learning for important sentence\nclassification and by assimilating knowledge based tags for improving the\nperformance of event coreference resolution we introduce a two staged system\nfor event timeline generation from multiple (historical) text documents. We\ndemonstrate our results on two manually annotated historical text documents.\nOur results can be extremely helpful for historians, in advancing research in\nhistory and in understanding the socio-political landscape of a country as\nreflected in the writings of famous personas.",
    "descriptor": "\nComments: Accepted at the main conference of ECML PKDD 2022 as a long paper. The camera-ready version\n",
    "authors": [
      "Sayantan Adak",
      "Altaf Ahmad",
      "Aditya Basu",
      "Animesh Mukherjee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.14089"
  },
  {
    "id": "arXiv:2206.14091",
    "title": "Compilation Forking: A Fast and Flexible Way of Generating Data for  Compiler-Internal Machine Learning Tasks",
    "abstract": "Compiler optimization decisions are often based on hand-crafted heuristics\ncentered around a few established benchmark suites. Alternatively, they can be\nlearned from feature and performance data produced during compilation. However,\ndata-driven compiler optimizations based on machine learning models require\nlarge sets of quality data for training in order to match or even outperform\nexisting human-crafted heuristics. In static compilation setups, related work\nhas addressed this problem with iterative compilation. However, a dynamic\ncompiler may produce different data depending on dynamically-chosen compilation\nstrategies, which aggravates the generation of comparable data. We propose\ncompilation forking, a technique for generating consistent feature and\nperformance data from arbitrary, dynamically-compiled programs. Different\nversions of program parts with the same profiling and compilation history are\nexecuted within single program runs to minimize noise stemming from dynamic\ncompilation and the runtime environment. Our approach facilitates large-scale\nperformance evaluations of compiler optimization decisions. Additionally,\ncompilation forking supports creating domain-specific compilation strategies\nbased on machine learning by providing the data for model training. We\nimplemented compilation forking in the GraalVM compiler in a\nprogramming-language-agnostic way. To assess the quality of the generated data,\nwe trained several machine learning models to replace compiler heuristics for\nloop-related optimizations. The trained models perform equally well to the\nhighly-tuned compiler heuristics when comparing the geometric means of\nbenchmark suite performances. Larger impacts on few single benchmarks range\nfrom speedups of 20% to slowdowns of 17%. The presented approach can be\nimplemented in any dynamic compiler. We believe that it can help to analyze\ncompilation decisions and leverage the use of machine learning into dynamic\ncompilation.",
    "descriptor": "",
    "authors": [
      "Raphael Mosaner",
      "David Leopoldseder",
      "Wolfgang Kisling",
      "Lukas Stadler",
      "Hanspeter M\u00f6ssenb\u00f6ck"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2206.14091"
  },
  {
    "id": "arXiv:2206.14092",
    "title": "Learning the Solution Operator of Boundary Value Problems using Graph  Neural Networks",
    "abstract": "As an alternative to classical numerical solvers for partial differential\nequations (PDEs) subject to boundary value constraints, there has been a surge\nof interest in investigating neural networks that can solve such problems\nefficiently. In this work, we design a general solution operator for two\ndifferent time-independent PDEs using graph neural networks (GNNs) and spectral\ngraph convolutions. We train the networks on simulated data from a finite\nelements solver on a variety of shapes and inhomogeneities. In contrast to\nprevious works, we focus on the ability of the trained operator to generalize\nto previously unseen scenarios. Specifically, we test generalization to meshes\nwith different shapes and superposition of solutions for a different number of\ninhomogeneities. We find that training on a diverse dataset with lots of\nvariation in the finite element meshes is a key ingredient for achieving good\ngeneralization results in all cases. With this, we believe that GNNs can be\nused to learn solution operators that generalize over a range of properties and\nproduce solutions much faster than a generic solver. Our dataset, which we make\npublicly available, can be used and extended to verify the robustness of these\nmodels under varying conditions.",
    "descriptor": "",
    "authors": [
      "Winfried L\u00f6tzsch",
      "Simon Ohler",
      "Johannes S. Otterbach"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.14092"
  },
  {
    "id": "arXiv:2206.14094",
    "title": "Towards Prescribed Accuracy in Under-tuned Super-Twisting Sliding Mode  Control Loops -- Experimental Verification",
    "abstract": "Obtaining prescribed accuracy bounds in super-twisting sliding mode control\nloops often falls short in terms of the applicability of the controller in\nhigh-performance systems. This is due to the fact that the selection of the\ncontroller gains that are derived from the conditions for finite-time\nconvergence may be too restrictive in connection to actuator limitations and\ninduced chatter. Previous work has shown that in case of periodic\nperturbations, there can be a systematic selection of much lower controller\ngains that guarantees boundedness of the closed-loop solutions within\npredetermined accuracy bounds. This study presents an experimental validation\nof these findings carried out on a commercial industrial motor system.",
    "descriptor": "\nComments: Accepted and presented in the 2022 American Control Conference (ACC), held in Atlanta Georgia, USA\n",
    "authors": [
      "Dimitrios Papageorgiou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.14094"
  },
  {
    "id": "arXiv:2206.14097",
    "title": "Auditing Purchases without SKU using Text Description and Similarity  Search",
    "abstract": "In this paper, we focus on the problem of auditing MRO (maintenance, repair,\nand operating) purchases that do not have SKU (Stock-Keep Unit) Those specific\npurchases not only lack SKU but also contain short text descriptions, making\nthe audit processes even more difficult. Our goal is to compare recent\npurchases with older ones using only the description provided by the purchase\nprocess. Therefore, evaluating price differences can uncover possible flaws\nduring the acquiring phase. However, the text of the items that we were working\non was very small, with numbers due to the nature of the products and we have a\nlimited amount of time to develop the solution which was 8 weeks. As result, we\nshowed that working using a well-oriented methodology we were able to deliver a\nsuccessful MVP and achieve the results expected for the client, extended its\nsearch database by 30%, and allowed it to have a recovery of up to 20 million\ndollars.",
    "descriptor": "",
    "authors": [
      "Ana Paula Appel",
      "Anderson Luis de Paula Silva",
      "Adriana Reigota Silva",
      "Caique Dutra Santos",
      "Thiago Logo da Silva",
      "Rafael Poggi de Araujo",
      "Luiz Carlos Faray de Aquino"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.14097"
  },
  {
    "id": "arXiv:2206.14098",
    "title": "RevBiFPN: The Fully Reversible Bidirectional Feature Pyramid Network",
    "abstract": "This work introduces the RevSilo, the first reversible module for\nbidirectional multi-scale feature fusion. Like other reversible methods,\nRevSilo eliminates the need to store hidden activations by recomputing them.\nExisting reversible methods, however, do not apply to multi-scale feature\nfusion and are therefore not applicable to a large class of networks.\nBidirectional multi-scale feature fusion promotes local and global coherence\nand has become a de facto design principle for networks targeting spatially\nsensitive tasks e.g. HRNet and EfficientDet. When paired with high-resolution\ninputs, these networks achieve state-of-the-art results across various computer\nvision tasks, but training them requires substantial accelerator memory for\nsaving large, multi-resolution activations. These memory requirements cap\nnetwork size and limit progress. Using reversible recomputation, the RevSilo\nalleviates memory issues while still operating across resolution scales.\nStacking RevSilos, we create RevBiFPN, a fully reversible bidirectional feature\npyramid network. For classification, RevBiFPN is competitive with networks such\nas EfficientNet while using up to 19.8x lesser training memory. When fine-tuned\non COCO, RevBiFPN provides up to a 2.5% boost in AP over HRNet using fewer MACs\nand a 2.4x reduction in training-time memory.",
    "descriptor": "\nComments: Presented at the ICML 2022 Workshop on Hardware Aware Efficient Training, Baltimore, Maryland, USA\n",
    "authors": [
      "Vitaliy Chiley",
      "Vithursan Thangarasa",
      "Abhay Gupta",
      "Anshul Samar",
      "Joel Hestness",
      "Dennis DeCoste"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.14098"
  },
  {
    "id": "arXiv:2206.14103",
    "title": "Workflows to driving high-performance interactive supercomputing for  urgent decision making",
    "abstract": "Interactive urgent computing is a small but growing user of supercomputing\nresources. However there are numerous technical challenges that must be\novercome to make supercomputers fully suited to the wide range of urgent\nworkloads which could benefit from the computational power delivered by such\ninstruments. An important question is how to connect the different components\nof an urgent workload; namely the users, the simulation codes, and external\ndata sources, together in a structured and accessible manner.\nIn this paper we explore the role of workflows from both the perspective of\nmarshalling and control of urgent workloads, and at the individual HPC machine\nlevel. Ultimately requiring two workflow systems, by using a space weather\nprediction urgent use-cases, we explore the benefit that these two workflow\nsystems provide especially when one exploits the flexibility enabled by them\ninteroperating.",
    "descriptor": "\nComments: Pre-print of paper accepted to the InteractiveHPC workshop of ISC2022\n",
    "authors": [
      "Nick Brown",
      "Rupert Nash",
      "Gordon Gibb",
      "Evgenij Belikov",
      "Artur Podobas",
      "Wei Der Chien",
      "Stefano Markidis",
      "Markus Flatken",
      "Andreas Gerndt"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.14103"
  },
  {
    "id": "arXiv:2206.14107",
    "title": "Special subsets of addresses for blockchains using the secp256k1 curve",
    "abstract": "In 2020 Sala, Sogiorno and Taufer have been able to find the private keys of\nsome Bitcoin addresses, thus being able to spend the cryptocurrency linked to\nthem. This result was unexpected, since the recovery of non-trivial private\nkeys for blockchain addresses is deemed to be an infeasible problem. In this\npaper we widen this analysis by mounting a similar attack to other small\nsubsets of the set of private keys. We then apply it to other blockchains as\nwell, examining Ethereum, Dogecoin, Litecoin, Dash, Zcash and Bitcoin Cash. In\naddition to the results, we also explain the techniques we have used to perform\nthis exhaustive search for all the addresses that have ever appeared in these\nblockchains.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Antonio J. Di Scala",
      "Andrea Gangemi",
      "Giuliano Romeo",
      "Gabriele Vernetti"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.14107"
  },
  {
    "id": "arXiv:2206.14112",
    "title": "Weighted Average-convexity and Cooperative Games",
    "abstract": "We generalize the notion of convexity and average-convexity to the notion of\nweighted average-convexity. We show several results on the relation between\nweighted average-convexity and cooperative games. First, we prove that if a\ngame is weighted average-convex, then the corresponding weighted Shapley value\nis in the core. Second, we exhibit necessary conditions for a communication\nTU-game to preserve the weighted average-convexity. Finally, we provide a\ncomplete characterization when the underlying graph is a priority decreasing\ntree.",
    "descriptor": "",
    "authors": [
      "Alexandre Skoda",
      "Xavier Venel"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2206.14112"
  },
  {
    "id": "arXiv:2206.14116",
    "title": "SSL-Lanes: Self-Supervised Learning for Motion Forecasting in Autonomous  Driving",
    "abstract": "Self-supervised learning (SSL) is an emerging technique that has been\nsuccessfully employed to train convolutional neural networks (CNNs) and graph\nneural networks (GNNs) for more transferable, generalizable, and robust\nrepresentation learning. However its potential in motion forecasting for\nautonomous driving has rarely been explored. In this study, we report the first\nsystematic exploration and assessment of incorporating self-supervision into\nmotion forecasting. We first propose to investigate four novel self-supervised\nlearning tasks for motion forecasting with theoretical rationale and\nquantitative and qualitative comparisons on the challenging large-scale\nArgoverse dataset. Secondly, we point out that our auxiliary SSL-based learning\nsetup not only outperforms forecasting methods which use transformers,\ncomplicated fusion mechanisms and sophisticated online dense goal candidate\noptimization algorithms in terms of performance accuracy, but also has low\ninference time and architectural complexity. Lastly, we conduct several\nexperiments to understand why SSL improves motion forecasting. Code is\nopen-sourced at \\url{https://github.com/AutoVision-cloud/SSL-Lanes}.",
    "descriptor": "\nComments: 16 pages, 7 figures\n",
    "authors": [
      "Prarthana Bhattacharyya",
      "Chengjie Huang",
      "Krzysztof Czarnecki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.14116"
  },
  {
    "id": "arXiv:2206.14118",
    "title": "GitHub Actions: The Impact on the Pull Request Process",
    "abstract": "Automated tools are frequently used in social coding repositories to perform\nrepetitive activities that are part of the distributed software development\nprocess. Recently, GitHub introduced GitHub Actions, a feature providing\nautomated workflows for repository maintainers. Understanding and anticipating\nthe effects of adopting such kind of technology is important for planning and\nmanagement. Our research investigates how projects use GitHub Actions, what the\ncommunities discuss about them, and how activity indicators change after their\nadoption. Our results indicate that a considerable number of projects adopt\nGitHub Actions (almost 30% of our sample) and that developers frequently ask\nfor help with them. Our findings also suggest that the adoption of GitHub\nActions leads to more rejections of pull requests (PRs), more communication in\naccepted PRs and less in rejected PRs, fewer commits in accepted PRs and more\nin rejected PRs, and more time to accept a PR. We found similar results in the\nUtility Actions but we found fewer rejected PRs for the Code Quality Actions.\nOur results are especially relevant for practitioners to consider these effects\nwhen adopting GitHub Actions on their projects.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2103.12224, arXiv:2103.13547\n",
    "authors": [
      "Mairieli Wessel",
      "Joseph Vargovich",
      "Marco A. Gerosa",
      "Christoph Treude"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.14118"
  },
  {
    "id": "arXiv:2206.14122",
    "title": "Learning Variable Impedance Control for Aerial Sliding on Uneven  Heterogeneous Surfaces by Proprioceptive and Tactile Sensing",
    "abstract": "The recent development of novel aerial vehicles capable of physically\ninteracting with the environment leads to new applications such as\ncontact-based inspection. These tasks require the robotic system to exchange\nforces with partially-known environments, which may contain uncertainties\nincluding unknown spatially-varying friction properties and discontinuous\nvariations of the surface geometry. Finding a control strategy that is robust\nagainst these environmental uncertainties remains an open challenge. This paper\npresents a learning-based adaptive control strategy for aerial sliding tasks.\nIn particular, the gains of a standard impedance controller are adjusted in\nreal-time by a policy based on the current control signals, proprioceptive\nmeasurements, and tactile sensing. This policy is trained in simulation with\nsimplified actuator dynamics in a student-teacher learning setup. The\nreal-world performance of the proposed approach is verified using a tilt-arm\nomnidirectional flying vehicle. The proposed controller structure combines\ndata-driven and model-based control methods, enabling our approach to\nsuccessfully transfer directly and without adaptation from simulation to the\nreal platform. Compared to fine-tuned state of the art interaction control\nmethods we achieve reduced tracking error and improved disturbance rejection.",
    "descriptor": "",
    "authors": [
      "Weixuan Zhang",
      "Lionel Ott",
      "Marco Tognon",
      "Roland Siegwart"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.14122"
  },
  {
    "id": "arXiv:2206.14125",
    "title": "Simplifying Dataflow Dialogue Design",
    "abstract": "In \\citep{andreas2020task-oriented}, a dataflow (DF) based dialogue system\nwas introduced, showing clear advantages compared to many commonly used current\nsystems. This was accompanied by the release of SMCalFlow, a practically\nrelevant, manually annotated dataset, more detailed and much larger than any\ncomparable dialogue dataset. Despite these remarkable contributions, the\ncommunity has not shown further interest in this direction. What are the\nreasons for this lack of interest? And how can the community be encouraged to\nengage in research in this direction?\nOne explanation may be the perception that this approach is too complex -\nboth the the annotation and the system. This paper argues that this perception\nis wrong: 1) Suggestions for a simplified format for the annotation of the\ndataset are presented, 2) An implementation of the DF execution engine is\nreleased\\footnote{https://github.com/telepathylabsai/OpenDF}, which can serve\nas a sandbox allowing researchers to easily implement, and experiment with, new\nDF dialogue designs. The hope is that these contributions will help engage more\npractitioners in exploring new ideas and designs for DF based dialogue systems.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2206.13425\n",
    "authors": [
      "Joram Meron"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.14125"
  },
  {
    "id": "arXiv:2206.14133",
    "title": "Item Recommendation Using User Feedback Data and Item Profile",
    "abstract": "Matrix factorization (MS) is a collaborative filtering (CF) based approach,\nwhich is widely used for recommendation systems (RS). In this research work, we\ndeal with the content recommendation problem for users in a content management\nsystem (CMS) based on users' feedback data. The CMS is applied for publishing\nand pushing curated content to the employees of a company or an organization.\nHere, we have used the user's feedback data and content data to solve the\ncontent recommendation problem. We prepare individual user profiles and then\ngenerate recommendation results based on different categories, including Direct\nInteraction, Social Share, and Reading Statistics, of user's feedback data.\nSubsequently, we analyze the effect of the different categories on the\nrecommendation results. The results have shown that different categories of\nfeedback data have different impacts on recommendation accuracy. The best\nperformance achieves if we include all types of data for the recommendation\ntask. We also incorporate content similarity as a regularization term into an\nMF model for designing a hybrid model. Experimental results have shown that the\nproposed hybrid model demonstrates better performance compared with the\ntraditional MF-based models.",
    "descriptor": "",
    "authors": [
      "Debashish Roy",
      "Rajarshi Roy Chowdhury",
      "Abdullah Bin Nasser",
      "Afdhal Azmi",
      "Marzieh Babaeianjelodar"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.14133"
  },
  {
    "id": "arXiv:2206.14134",
    "title": "Hamiltonian Monte Carlo Particle Swarm Optimizer",
    "abstract": "We introduce the Hamiltonian Monte Carlo Particle Swarm Optimizer (HMC-PSO),\nan optimization algorithm that reaps the benefits of both Exponentially\nAveraged Momentum PSO and HMC sampling. The coupling of the position and\nvelocity of each particle with Hamiltonian dynamics in the simulation allows\nfor extensive freedom for exploration and exploitation of the search space. It\nalso provides an excellent technique to explore highly non-convex functions\nwhile ensuring efficient sampling. We extend the method to approximate error\ngradients in closed form for Deep Neural Network (DNN) settings. We discuss\npossible methods of coupling and compare its performance to that of\nstate-of-the-art optimizers on the Golomb's Ruler problem and Classification\ntasks.",
    "descriptor": "\nComments: Submitted to PPSN\n",
    "authors": [
      "Omatharv Bharat Vaidya",
      "Rithvik Terence DSouza",
      "Snehanshu Saha",
      "Soma Dhavala",
      "Swagatam Das"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.14134"
  },
  {
    "id": "arXiv:2206.14135",
    "title": "Towards Explainable Metaheuristic: Mining Surrogate Fitness Models for  Importance of Variables",
    "abstract": "Metaheuristic search algorithms look for solutions that either maximise or\nminimise a set of objectives, such as cost or performance. However most\nreal-world optimisation problems consist of nonlinear problems with complex\nconstraints and conflicting objectives. The process by which a GA arrives at a\nsolution remains largely unexplained to the end-user. A poorly understood\nsolution will dent the confidence a user has in the arrived at solution. We\npropose that investigation of the variables that strongly influence solution\nquality and their relationship would be a step toward providing an explanation\nof the near-optimal solution presented by a metaheuristic. Through the use of\nfour benchmark problems we use the population data generated by a Genetic\nAlgorithm (GA) to train a surrogate model, and investigate the learning of the\nsearch space by the surrogate model. We compare what the surrogate has learned\nafter being trained on population data generated after the first generation and\ncontrast this with a surrogate model trained on the population data from all\ngenerations. We show that the surrogate model picks out key characteristics of\nthe problem as it is trained on population data from each generation. Through\nmining the surrogate model we can build a picture of the learning process of a\nGA, and thus an explanation of the solution presented by the GA. The aim being\nto build trust and confidence in the end-user about the solution presented by\nthe GA, and encourage adoption of the model.",
    "descriptor": "",
    "authors": [
      "Manjinder Singh",
      "Alexander E.I. Brownlee",
      "David Cairns"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.14135"
  },
  {
    "id": "arXiv:2206.14136",
    "title": "Gender Bias in Password Managers",
    "abstract": "For the first time, we report gender bias in people's choice and use of\npassword managers, through a semi-structured interview ($n=18$) and a\nquestionnaire-based survey ($n=200$, conducted `in the wild'). Not only do\nwomen and men prefer different types of password managers, but software\nfeatures that women and men frequently use also differ. These differences are\nstatistically significant. The factors that women and men consider the most\nimportant or influential in choosing their password managers differ, too.\nChoice of convenience and brand are on the top of the women's consideration,\nwhereas security and the number of features top the list for men. This\ndifference is statistically significant.",
    "descriptor": "",
    "authors": [
      "Jeff Yan",
      "Dearbhla McCabe"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.14136"
  },
  {
    "id": "arXiv:2206.14137",
    "title": "aSTDP: A More Biologically Plausible Learning",
    "abstract": "Spike-timing dependent plasticity in biological neural networks has been\nproven to be important during biological learning process. On the other hand,\nartificial neural networks use a different way to learn, such as\nBack-Propagation or Contrastive Hebbian Learning. In this work we introduce\napproximate STDP, a new neural networks learning framework more similar to the\nbiological learning process. It uses only STDP rules for supervised and\nunsupervised learning, every neuron distributed learn patterns and don' t need\na global loss or other supervised information. We also use a numerical way to\napproximate the derivatives of each neuron in order to better use SDTP learning\nand use the derivatives to set a target for neurons to accelerate training and\ntesting process. The framework can make predictions or generate patterns in one\nmodel without additional configuration. Finally, we verified our framework on\nMNIST dataset for classification and generation tasks.",
    "descriptor": "\nComments: 17 pages, 6 figures. arXiv admin note: text overlap with arXiv:1912.00009\n",
    "authors": [
      "Shiyuan Li"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.14137"
  },
  {
    "id": "arXiv:2206.14142",
    "title": "Let the paintings play",
    "abstract": "In this paper, we introduce a mathematical method to extract similarities\nbetween paintings and musical tracks. Our approach is based on the\ndigitalization of both paintings and musical tracks by means of finite\nexpansions in terms of orthogonal basis functions (with both Fourier and\nwavelet bases). The best fit between a specific painting and a sample of\nmusical tracks from a given composer is achieved via an $L^2$ projection upon a\nfinite-dimensional subspace. Several examples are provided for the analysis of\na collection of works of art by the Italian artist Marcello Morandini. Finally,\nwe have developed an original applet that implements the process above and\nwhich can be freely downloaded from the site\nhttps://github.com/pgerva/playing-paintings.git",
    "descriptor": "",
    "authors": [
      "Paola Gervasio",
      "Alfio Quarteroni",
      "Daniele Cassani"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.14142"
  },
  {
    "id": "arXiv:2206.14145",
    "title": "Question Personalization in an Intelligent Tutoring System",
    "abstract": "This paper investigates personalization in the field of intelligent tutoring\nsystems (ITS). We hypothesize that personalization in the way questions are\nasked improves student learning outcomes. Previous work on dialogue-based ITS\npersonalization has yet to address question phrasing. We show that generating\nversions of the questions suitable for students at different levels of subject\nproficiency improves student learning gains, using variants written by a domain\nexpert and an experimental A/B test. This insight demonstrates that the\nlinguistic realization of questions in an ITS affects the learning outcomes for\nstudents.",
    "descriptor": "\nComments: To be published in AIED Late Breaking Results 2022\n",
    "authors": [
      "Sabina Elkins",
      "Robert Belfer",
      "Ekaterina Kochmar",
      "Iulian Serban",
      "Jackie C.K. Cheung"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.14145"
  },
  {
    "id": "arXiv:2206.14148",
    "title": "Memory Safe Computations with XLA Compiler",
    "abstract": "Software packages like TensorFlow and PyTorch are designed to support linear\nalgebra operations, and their speed and usability determine their success.\nHowever, by prioritising speed, they often neglect memory requirements. As a\nconsequence, the implementations of memory-intensive algorithms that are\nconvenient in terms of software design can often not be run for large problems\ndue to memory overflows. Memory-efficient solutions require complex programming\napproaches with significant logic outside the computational framework. This\nimpairs the adoption and use of such algorithms. To address this, we developed\nan XLA compiler extension that adjusts the computational data-flow\nrepresentation of an algorithm according to a user-specified memory limit. We\nshow that k-nearest neighbour and sparse Gaussian process regression methods\ncan be run at a much larger scale on a single device, where standard\nimplementations would have failed. Our approach leads to better use of hardware\nresources. We believe that further focus on removing memory constraints at a\ncompiler level will widen the range of machine learning methods that can be\ndeveloped in the future.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Artem Artemev",
      "Tilman Roeder",
      "Mark van der Wilk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.14148"
  },
  {
    "id": "arXiv:2206.14150",
    "title": "Autonomous Smart Grid Fault Detection",
    "abstract": "Smart grid plays a crucial role for the smart society and the upcoming carbon\nneutral society. Achieving autonomous smart grid fault detection is critical\nfor smart grid system state awareness, maintenance and operation. This paper\nfocuses on fault monitoring in smart grid and discusses the inherent technical\nchallenges and solutions. In particular, we first present the basic principles\nof smart grid fault detection. Then, we explain the new requirements for\nautonomous smart grid fault detection, the technical challenges and their\npossible solutions. A case study is introduced, as a preliminary study for\nautonomous smart grid fault detection. In addition, we highlight relevant\ndirections for future research.",
    "descriptor": "",
    "authors": [
      "Qiyue Li",
      "Yuxing Deng",
      "Xin Liu",
      "Wei Sun",
      "Weitao Li",
      "Jie Li",
      "Zhi Liu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.14150"
  },
  {
    "id": "arXiv:2206.14153",
    "title": "Multi-Fault Diagnosis Of Industrial Rotating Machines Using Data-Driven  Approach: A Review Of Two Decades Of Research",
    "abstract": "Industry 4.0 is an era of smart manufacturing. Manufacturing is impossible\nwithout the use of machinery. Majority of these machines comprise rotating\ncomponents and are called rotating machines. The engineers' top priority is to\nmaintain these critical machines to reduce the unplanned shutdown and increase\nthe useful life of machinery. Predictive maintenance (PDM) is the current trend\nof smart maintenance. The challenging task in PDM is to diagnose the type of\nfault. With Artificial Intelligence (AI) advancement, data-driven approach for\npredictive maintenance is taking a new flight towards smart manufacturing.\nSeveral researchers have published work related to fault diagnosis in rotating\nmachines, mainly exploring a single type of fault. However, a consolidated\nreview of literature that focuses more on multi-fault diagnosis of rotating\nmachines is lacking. There is a need to systematically cover all the aspects\nright from sensor selection, data acquisition, feature extraction, multi-sensor\ndata fusion to the systematic review of AI techniques employed in multi-fault\ndiagnosis. In this regard, this paper attempts to achieve the same by\nimplementing a systematic literature review on a Data-driven approach for\nmulti-fault diagnosis of Industrial Rotating Machines using Preferred Reporting\nItems for Systematic Reviews and Meta-Analysis (PRISMA) method. The PRISMA\nmethod is a collection of guidelines for the composition and structure of\nsystematic reviews and other meta-analyses. This paper identifies the\nfoundational work done in the field and gives a comparative study of different\naspects related to multi-fault diagnosis of industrial rotating machines. The\npaper also identifies the major challenges, research gap. It gives solutions\nusing recent advancements in AI in implementing multi-fault diagnosis, giving a\nstrong base for future research in this field.",
    "descriptor": "\nComments: 64 pages\n",
    "authors": [
      "Shreyas Gawde",
      "Shruti Patil",
      "Satish Kumar",
      "Pooja Kamat",
      "Ketan Kotecha",
      "Ajith Abraham"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.14153"
  },
  {
    "id": "arXiv:2206.14155",
    "title": "Position-Agnostic Autonomous Navigation in Vineyards with Deep  Reinforcement Learning",
    "abstract": "Precision agriculture is rapidly attracting research to efficiently introduce\nautomation and robotics solutions to support agricultural activities. Robotic\nnavigation in vineyards and orchards offers competitive advantages in\nautonomously monitoring and easily accessing crops for harvesting, spraying and\nperforming time-consuming necessary tasks. Nowadays, autonomous navigation\nalgorithms exploit expensive sensors which also require heavy computational\ncost for data processing. Nonetheless, vineyard rows represent a challenging\noutdoor scenario where GPS and Visual Odometry techniques often struggle to\nprovide reliable positioning information. In this work, we combine Edge AI with\nDeep Reinforcement Learning to propose a cutting-edge lightweight solution to\ntackle the problem of autonomous vineyard navigation without exploiting precise\nlocalization data and overcoming task-tailored algorithms with a flexible\nlearning-based approach. We train an end-to-end sensorimotor agent which\ndirectly maps noisy depth images and position-agnostic robot state information\nto velocity commands and guides the robot to the end of a row, continuously\nadjusting its heading for a collision-free central trajectory. Our extensive\nexperimentation in realistic simulated vineyards demonstrates the effectiveness\nof our solution and the generalization capabilities of our agent.",
    "descriptor": "",
    "authors": [
      "Mauro Martini",
      "Simone Cerrato",
      "Francesco Salvetti",
      "Simone Angarano",
      "Marcello Chiaberge"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.14155"
  },
  {
    "id": "arXiv:2206.14157",
    "title": "How to Steer Your Adversary: Targeted and Efficient Model Stealing  Defenses with Gradient Redirection",
    "abstract": "Model stealing attacks present a dilemma for public machine learning APIs. To\nprotect financial investments, companies may be forced to withhold important\ninformation about their models that could facilitate theft, including\nuncertainty estimates and prediction explanations. This compromise is harmful\nnot only to users but also to external transparency. Model stealing defenses\nseek to resolve this dilemma by making models harder to steal while preserving\nutility for benign users. However, existing defenses have poor performance in\npractice, either requiring enormous computational overheads or severe utility\ntrade-offs. To meet these challenges, we present a new approach to model\nstealing defenses called gradient redirection. At the core of our approach is a\nprovably optimal, efficient algorithm for steering an adversary's training\nupdates in a targeted manner. Combined with improvements to surrogate networks\nand a novel coordinated defense strategy, our gradient redirection defense,\ncalled GRAD${}^2$, achieves small utility trade-offs and low computational\noverhead, outperforming the best prior defenses. Moreover, we demonstrate how\ngradient redirection enables reprogramming the adversary with arbitrary\nbehavior, which we hope will foster work on new avenues of defense.",
    "descriptor": "\nComments: ICML 2022\n",
    "authors": [
      "Mantas Mazeika",
      "Bo Li",
      "David Forsyth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.14157"
  },
  {
    "id": "arXiv:2206.14163",
    "title": "Verifiable Goal Recognition for Autonomous Driving with Occlusions",
    "abstract": "When used in autonomous driving, goal recognition allows the future behaviour\nof other vehicles to be more accurately predicted. A recent goal recognition\nmethod for autonomous vehicles, GRIT, has been shown to be fast, accurate,\ninterpretable and verifiable. In autonomous driving, vehicles can encounter\nnovel scenarios that were unseen during training, and the environment is\npartially observable due to occlusions. However, GRIT can only operate in fixed\nframe scenarios, with full observability. We present a novel goal recognition\nmethod named Goal Recognition with Interpretable Trees under Occlusion (OGRIT),\nwhich solves these shortcomings of GRIT. We demonstrate that OGRIT can\ngeneralise between different scenarios and handle missing data due to\nocclusions, while still being fast, accurate, interpretable and verifiable.",
    "descriptor": "",
    "authors": [
      "Cillian Brewitt",
      "Massimiliano Tamborski",
      "Stefano V. Albrecht"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14163"
  },
  {
    "id": "arXiv:2206.14164",
    "title": "Visualizing and Alleviating the Effect of Radial Distortion on Camera  Calibration Using Principal Lines",
    "abstract": "Preparing appropriate images for camera calibration is crucial to obtain\naccurate results. In this paper, new suggestions for preparing such data to\nalleviate the adverse effect of radial distortion for a calibration procedure\nusing principal lines are developed through the investigations of: (i)\nidentifying directions of checkerboard movements in an image which will result\nin maximum (and minimum) influence on the calibration results, and (ii)\ninspecting symmetry and monotonicity of such effect in (i) using the above\nprincipal lines. Accordingly, it is suggested that the estimation of principal\npoint should based on linearly independent pairs of nearly parallel principal\nlines, with a member in each pair corresponds to a near 180-degree rotation (in\nthe image plane) of the other. Experimental results show that more robust and\nconsistent calibration results for the foregoing estimation can actually be\nobtained, compared with the renowned algebraic methods which estimate\ndistortion parameters explicitly.",
    "descriptor": "",
    "authors": [
      "Jen-Hui Chuang",
      "Hsin-Yi Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.14164"
  },
  {
    "id": "arXiv:2206.14168",
    "title": "Comparison of metadata with relevance for bibliometrics between  Microsoft Academic Graph and OpenAlex until 2020",
    "abstract": "Microsoft Academic Graph (MAG) has been studied a lot concerning its\nsuitability for bibliometric evaluations. In May 2021, it was announced that it\nwould retire on December 31, 2021. Soon after that, the non-profit organization\nOurResearch, aiming at providing 'a fully open catalog of the global research\nsystem', announced they would preserve and incorporate the last full MAG\ncorpus, only excluding patent data, and to continue and hopefully improve it.\nAfter the launch of OpenAlex in January 2022, it is of interest to know if the\nusefulness of the MAG data is preserved or even improved in OpenAlex. To this\nend, we compared metadata that are relevant for bibliometric analyses (in\nparticular field and time normalization of citations) of MAG and OpenAlex: -\nthe coverage of documents over the years, - the agreement of bibliographic\ndata, - the numbers of references of each document, - the kind and distribution\nof document types, - the distribution and relation of subject classifications.",
    "descriptor": "\nComments: 11 pages, 3 figures, 6 tables; submitted to the 26th International Conference on Science, Technology and Innovation Indicators (STI 2022)\n",
    "authors": [
      "Thomas Scheidsteger",
      "Robin Haunschild"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2206.14168"
  },
  {
    "id": "arXiv:2206.14169",
    "title": "Creation and Analysis of an International Corpus of Privacy Laws",
    "abstract": "The landscape of privacy laws and regulations around the world is complex and\never-changing. National and super-national laws, agreements, decrees, and other\ngovernment-issued rules form a patchwork that companies must follow to operate\ninternationally. To examine the status and evolution of this patchwork, we\nintroduce the Government Privacy Instructions Corpus, or GPI Corpus, of 1,043\nprivacy laws, regulations, and guidelines, covering 182 jurisdictions. This\ncorpus enables a large-scale quantitative and qualitative examination of legal\nfoci on privacy. We examine the temporal distribution of when GPIs were created\nand illustrate the dramatic increase in privacy legislation over the past 50\nyears, although a finer-grained examination reveals that the rate of increase\nvaries depending on the personal data types that GPIs address. Our exploration\nalso demonstrates that most privacy laws respectively address relatively few\npersonal data types, showing that comprehensive privacy legislation remains\nrare. Additionally, topic modeling results show the prevalence of common themes\nin GPIs, such as finance, healthcare, and telecommunications. Finally, we\nrelease the corpus to the research community to promote further study.",
    "descriptor": "\nComments: 14 pages, 7 figures, 7 tables\n",
    "authors": [
      "Sonu Gupta",
      "Ellen Poplavska",
      "Nora O'Toole",
      "Siddhant Arora",
      "Thomas Norton",
      "Norman Sadeh",
      "Shomir Wilson"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.14169"
  },
  {
    "id": "arXiv:2206.14170",
    "title": "Risk Perspective Exploration in Distributional Reinforcement Learning",
    "abstract": "Distributional reinforcement learning demonstrates state-of-the-art\nperformance in continuous and discrete control settings with the features of\nvariance and risk, which can be used to explore. However, the exploration\nmethod employing the risk property is hard to find, although numerous\nexploration methods in Distributional RL employ the variance of return\ndistribution per action. In this paper, we present risk scheduling approaches\nthat explore risk levels and optimistic behaviors from a risk perspective. We\ndemonstrate the performance enhancement of the DMIX algorithm using risk\nscheduling in a multi-agent setting with comprehensive experiments.",
    "descriptor": "\nComments: ICML 2022 Workshop (AI for Agent Based Modelling)\n",
    "authors": [
      "Jihwan Oh",
      "Joonkee Kim",
      "Se-Young Yun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14170"
  },
  {
    "id": "arXiv:2206.14171",
    "title": "Formally Unimodular Packings for the Gaussian Wiretap Channel",
    "abstract": "This paper introduces the family of lattice-like packings, which generalizes\nlattices, consisting of packings possessing periodicity and geometric\nuniformity. The subfamily of formally unimodular (lattice-like) packings is\nfurther investigated. It can be seen as a generalization of the unimodular and\nisodual lattices, and the Construction A formally unimodular packings obtained\nfrom formally self-dual codes are presented. Recently, lattice coding for the\nGaussian wiretap channel has been considered. A measure called secrecy function\nwas proposed to characterize the eavesdropper's probability of correctly\ndecoding. The aim is to determine the global maximum value of the secrecy\nfunction, called (strong) secrecy gain.\nWe further apply lattice-like packings to coset coding for the Gaussian\nwiretap channel and show that the family of formally unimodular packings shares\nthe same secrecy function behavior as unimodular and isodual lattices. We\npropose a universal approach to determine the secrecy gain of a Construction A\nformally unimodular packing obtained from a formally self-dual code. From the\nweight distribution of a code, we provide a necessary condition for a formally\nself-dual code such that its Construction A formally unimodular packing is\nsecrecy-optimal. Finally, we demonstrate that formally unimodular\npackings/lattices can achieve higher secrecy gain than the best-known\nunimodular lattices.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2111.01439\n",
    "authors": [
      "Maiara F. Bollauf",
      "Hsuan-Yin Lin",
      "\u00d8yvind Ytrehus"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.14171"
  },
  {
    "id": "arXiv:2206.14175",
    "title": "InvAASTCluster : On Applying Invariant-Based Program Clustering to  Introductory Programming Assignments",
    "abstract": "Due to the vast number of students enrolled in Massive Open Online Courses\n(MOOCs), there has been an increasing number of automated program repair\ntechniques focused on introductory programming assignments (IPAs). Such\nstate-of-the-art techniques use program clustering to take advantage of\nprevious correct student implementations to repair a given new incorrect\nsubmission. Usually, these repair techniques use clustering methods since\nanalyzing all available correct student submissions to repair a program is not\nfeasible. The clustering methods use program representations based on several\nfeatures such as abstract syntax tree (AST), syntax, control flow, and data\nflow. However, these features are sometimes brittle when representing\nsemantically similar programs.\nThis paper proposes InvAASTCluster, a novel approach for program clustering\nthat takes advantage of dynamically generated program invariants observed over\nseveral program executions to cluster semantically equivalent IPAs. Our main\nobjective is to find a more suitable representation of programs using a\ncombination of the program's semantics, through its invariants, and its\nstructure, through its anonymized abstract syntax tree. The evaluation of\nInvAASTCluster shows that the proposed program representation outperforms\nsyntax-based representations when clustering a set of different correct IPAs.\nFurthermore, we integrate InvAASTCluster into a state-of-the-art\nclustering-based program repair tool and evaluate it on a set of IPAs. Our\nresults show that InvAASTCluster advances the current state-of-the-art when\nused by clustering-based program repair tools by repairing a larger number of\nstudents' programs in a shorter amount of time.",
    "descriptor": "\nComments: 21 pages, 6 Figures, 4 Tables. GitHub repo: this https URL\n",
    "authors": [
      "Pedro Orvalho",
      "Mikol\u00e1\u0161 Janota",
      "Vasco Manquinho"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2206.14175"
  },
  {
    "id": "arXiv:2206.14176",
    "title": "DayDreamer: World Models for Physical Robot Learning",
    "abstract": "To solve tasks in complex environments, robots need to learn from experience.\nDeep reinforcement learning is a common approach to robot learning but requires\na large amount of trial and error to learn, limiting its deployment in the\nphysical world. As a consequence, many advances in robot learning rely on\nsimulators. On the other hand, learning inside of simulators fails to capture\nthe complexity of the real world, is prone to simulator inaccuracies, and the\nresulting behaviors do not adapt to changes in the world. The Dreamer algorithm\nhas recently shown great promise for learning from small amounts of interaction\nby planning within a learned world model, outperforming pure reinforcement\nlearning in video games. Learning a world model to predict the outcomes of\npotential actions enables planning in imagination, reducing the amount of trial\nand error needed in the real environment. However, it is unknown whether\nDreamer can facilitate faster learning on physical robots. In this paper, we\napply Dreamer to 4 robots to learn online and directly in the real world,\nwithout simulators. Dreamer trains a quadruped robot to roll off its back,\nstand up, and walk from scratch and without resets in only 1 hour. We then push\nthe robot and find that Dreamer adapts within 10 minutes to withstand\nperturbations or quickly roll over and stand back up. On two different robotic\narms, Dreamer learns to pick and place multiple objects directly from camera\nimages and sparse rewards, approaching human performance. On a wheeled robot,\nDreamer learns to navigate to a goal position purely from camera images,\nautomatically resolving ambiguity about the robot orientation. Using the same\nhyperparameters across all experiments, we find that Dreamer is capable of\nonline learning in the real world, establishing a strong baseline. We release\nour infrastructure for future applications of world models to robot learning.",
    "descriptor": "\nComments: Website: this https URL\n",
    "authors": [
      "Philipp Wu",
      "Alejandro Escontrela",
      "Danijar Hafner",
      "Ken Goldberg",
      "Pieter Abbeel"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14176"
  },
  {
    "id": "arXiv:2206.14180",
    "title": "High-Resolution Virtual Try-On with Misalignment and Occlusion-Handled  Conditions",
    "abstract": "Image-based virtual try-on aims to synthesize an image of a person wearing a\ngiven clothing item. To solve the task, the existing methods warp the clothing\nitem to fit the person's body and generate the segmentation map of the person\nwearing the item, before fusing the item with the person. However, when the\nwarping and the segmentation generation stages operate individually without\ninformation exchange, the misalignment between the warped clothes and the\nsegmentation map occurs, which leads to the artifacts in the final image. The\ninformation disconnection also causes excessive warping near the clothing\nregions occluded by the body parts, so called pixel-squeezing artifacts. To\nsettle the issues, we propose a novel try-on condition generator as a unified\nmodule of the two stages (i.e., warping and segmentation generation stages). A\nnewly proposed feature fusion block in the condition generator implements the\ninformation exchange, and the condition generator does not create any\nmisalignment or pixel-squeezing artifacts. We also introduce discriminator\nrejection that filters out the incorrect segmentation map predictions and\nassures the performance of virtual try-on frameworks. Experiments on a\nhigh-resolution dataset demonstrate that our model successfully handles the\nmisalignment and the occlusion, and significantly outperforms the baselines.\nCode is available at https://github.com/sangyun884/HR-VITON.",
    "descriptor": "",
    "authors": [
      "Sangyun Lee",
      "Gyojung Gu",
      "Sunghyun Park",
      "Seunghwan Choi",
      "Jaegul Choo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.14180"
  },
  {
    "id": "arXiv:2206.14181",
    "title": "The NLP Sandbox: an efficient model-to-data system to enable federated  and unbiased evaluation of clinical NLP models",
    "abstract": "Objective The evaluation of natural language processing (NLP) models for\nclinical text de-identification relies on the availability of clinical notes,\nwhich is often restricted due to privacy concerns. The NLP Sandbox is an\napproach for alleviating the lack of data and evaluation frameworks for NLP\nmodels by adopting a federated, model-to-data approach. This enables unbiased\nfederated model evaluation without the need for sharing sensitive data from\nmultiple institutions. Materials and Methods We leveraged the Synapse\ncollaborative framework, containerization software, and OpenAPI generator to\nbuild the NLP Sandbox (nlpsandbox.io). We evaluated two state-of-the-art NLP\nde-identification focused annotation models, Philter and NeuroNER, using data\nfrom three institutions. We further validated model performance using data from\nan external validation site. Results We demonstrated the usefulness of the NLP\nSandbox through de-identification clinical model evaluation. The external\ndeveloper was able to incorporate their model into the NLP Sandbox template and\nprovide user experience feedback. Discussion We demonstrated the feasibility of\nusing the NLP Sandbox to conduct a multi-site evaluation of clinical text\nde-identification models without the sharing of data. Standardized model and\ndata schemas enable smooth model transfer and implementation. To generalize the\nNLP Sandbox, work is required on the part of data owners and model developers\nto develop suitable and standardized schemas and to adapt their data or model\nto fit the schemas. Conclusions The NLP Sandbox lowers the barrier to utilizing\nclinical data for NLP model evaluation and facilitates federated, multi-site,\nunbiased evaluation of NLP models.",
    "descriptor": "",
    "authors": [
      "Yao Yan",
      "Thomas Yu",
      "Kathleen Muenzen",
      "Sijia Liu",
      "Connor Boyle",
      "George Koslowski",
      "Jiaxin Zheng",
      "Nicholas Dobbins",
      "Clement Essien",
      "Hongfang Liu",
      "Larsson Omberg",
      "Meliha Yestigen",
      "Bradley Taylor",
      "James A Eddy",
      "Justin Guinney",
      "Sean Mooney",
      "Thomas Schaffter"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.14181"
  },
  {
    "id": "arXiv:2206.14182",
    "title": "Entropy Inequalities and Gaussian Comparisons",
    "abstract": "We establish a general class of entropy inequalities that take the concise\nform of Gaussian comparisons. The main result unifies many classical and recent\nresults, including the Shannon-Stam inequality, the Brunn-Minkowski inequality,\nthe Zamir-Feder inequality, the Brascamp-Lieb and Barthe inequalities, the\nAnantharam-Jog-Nair inequality, and others.",
    "descriptor": "\nComments: 23 pages. Comments welcome\n",
    "authors": [
      "Efe Aras",
      "Thomas A. Courtade"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.14182"
  },
  {
    "id": "arXiv:2206.14187",
    "title": "Evaluating Understanding on Conceptual Abstraction Benchmarks",
    "abstract": "A long-held objective in AI is to build systems that understand concepts in a\nhumanlike way. Setting aside the difficulty of building such a system, even\ntrying to evaluate one is a challenge, due to present-day AI's relative opacity\nand its proclivity for finding shortcut solutions. This is exacerbated by\nhumans' tendency to anthropomorphize, assuming that a system that can recognize\none instance of a concept must also understand other instances, as a human\nwould. In this paper, we argue that understanding a concept requires the\nability to use it in varied contexts. Accordingly, we propose systematic\nevaluations centered around concepts, by probing a system's ability to use a\ngiven concept in many different instantiations. We present case studies of such\nan evaluations on two domains -- RAVEN (inspired by Raven's Progressive\nMatrices) and the Abstraction and Reasoning Corpus (ARC) -- that have been used\nto develop and assess abstraction abilities in AI systems. Our concept-based\napproach to evaluation reveals information about AI systems that conventional\ntest sets would have left hidden.",
    "descriptor": "\nComments: EBeM'22: AI Evaluation Beyond Metrics, July 24, 2022, Vienna, Austria\n",
    "authors": [
      "Victor Vikram Odouard",
      "Melanie Mitchell"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14187"
  },
  {
    "id": "arXiv:2206.14189",
    "title": "A Formal Specification of Operating System based on ARINC 653",
    "abstract": "In this paper, by using the formal language \\emph{Circus}, we give a formal\nspecification of an operating system based on ARINC 653 standard. Our\nspecification includes interrupt handling, time and memory management,\npartition and process scheduling, system call response and related APEX\nservices. Especially, the concurrent behaviours of partitions and processes are\nalso specified.",
    "descriptor": "\nComments: 139 pages\n",
    "authors": [
      "Ziyan Wang",
      "Yan Zhang"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.14189"
  },
  {
    "id": "arXiv:2206.14191",
    "title": "Zero-Shot Building Control",
    "abstract": "Heating and cooling systems in buildings account for 31% of global energy\nuse, much of which are regulated by Rule Based Controllers (RBCs) that neither\nmaximise energy efficiency nor minimise emissions by interacting optimally with\nthe grid. Control via Reinforcement Learning (RL) has been shown to\nsignificantly improve building energy efficiency, but existing solutions\nrequire pre-training in simulators that are prohibitively expensive to obtain\nfor every building in the world. In response, we show it is possible to perform\nsafe, zero-shot control of buildings by combining ideas from system\nidentification and model-based RL. We call this combination PEARL\n(Probabilistic Emission-Abating Reinforcement Learning) and show it reduces\nemissions without pre-training, needing only a three hour commissioning period.\nIn experiments across three varied building energy simulations, we show PEARL\noutperforms an existing RBC once, and popular RL baselines in all cases,\nreducing building emissions by as much as 31% whilst maintaining thermal\ncomfort.",
    "descriptor": "\nComments: 10 pages, 4 figures + supplementary material\n",
    "authors": [
      "Scott R. Jeen",
      "Jonathan M. Cullen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14191"
  },
  {
    "id": "arXiv:2206.14195",
    "title": "Pedestrian 3D Bounding Box Prediction",
    "abstract": "Safety is still the main issue of autonomous driving, and in order to be\nglobally deployed, they need to predict pedestrians' motions sufficiently in\nadvance. While there is a lot of research on coarse-grained (human center\nprediction) and fine-grained predictions (human body keypoints prediction), we\nfocus on 3D bounding boxes, which are reasonable estimates of humans without\nmodeling complex motion details for autonomous vehicles. This gives the\nflexibility to predict in longer horizons in real-world settings. We suggest\nthis new problem and present a simple yet effective model for pedestrians' 3D\nbounding box prediction. This method follows an encoder-decoder architecture\nbased on recurrent neural networks, and our experiments show its effectiveness\nin both the synthetic (JTA) and real-world (NuScenes) datasets. The learned\nrepresentation has useful information to enhance the performance of other\ntasks, such as action anticipation. Our code is available online:\nhttps://github.com/vita-epfl/bounding-box-prediction",
    "descriptor": "\nComments: Accepted and published in hEART2022 (the 10th Symposium of the European Association for Research in Transportation): this http URL\n",
    "authors": [
      "Saeed Saadatnejad",
      "Yi Zhou Ju",
      "Alexandre Alahi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.14195"
  },
  {
    "id": "arXiv:2206.13504",
    "title": "AI-based computer-aided diagnostic system of chest digital tomography  synthesis: Demonstrating comparative advantage with X-ray-based AI systems",
    "abstract": "Compared with chest X-ray (CXR) imaging, which is a single image projected\nfrom the front of the patient, chest digital tomosynthesis (CDTS) imaging can\nbe more advantageous for lung lesion detection because it acquires multiple\nimages projected from multiple angles of the patient. Various clinical\ncomparative analysis and verification studies have been reported to demonstrate\nthis, but there were no artificial intelligence (AI)-based comparative analysis\nstudies. Existing AI-based computer-aided detection (CAD) systems for lung\nlesion diagnosis have been developed mainly based on CXR images; however,\nCAD-based on CDTS, which uses multi-angle images of patients in various\ndirections, has not been proposed and verified for its usefulness compared to\nCXR-based counterparts. This study develops/tests a CDTS-based AI CAD system to\ndetect lung lesions to demonstrate performance improvements compared to\nCXR-based AI CAD. We used multiple projection images as input for the\nCDTS-based AI model and a single-projection image as input for the CXR-based AI\nmodel to fairly compare and evaluate the performance between models. The\nproposed CDTS-based AI CAD system yielded sensitivities of 0.782 and 0.785 and\naccuracies of 0.895 and 0.837 for the performance of detecting tuberculosis and\npneumonia, respectively, against normal subjects. These results show higher\nperformance than sensitivities of 0.728 and 0.698 and accuracies of 0.874 and\n0.826 for detecting tuberculosis and pneumonia through the CXR-based AI CAD,\nwhich only uses a single projection image in the frontal direction. We found\nthat CDTS-based AI CAD improved the sensitivity of tuberculosis and pneumonia\nby 5.4% and 8.7% respectively, compared to CXR-based AI CAD without loss of\naccuracy. Therefore, we comparatively prove that CDTS-based AI CAD technology\ncan improve performance more than CXR, enhancing the clinical applicability of\nCDTS.",
    "descriptor": "\nComments: Kyung-Su Kim, Ju Hwan Lee, and Seong Je Oh have contributed equally to this work as the co-first author. Kyung-Su Kim (kskim.doc@gmail.com) and Myung Jin Chung (mj1.chung@samsung.com) have contributed equally to this work as the co-corresponding author\n",
    "authors": [
      "Kyung-Su Kim",
      "Ju Hwan Lee",
      "Seong Je Oh",
      "Myung Jin Chung"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.13504"
  },
  {
    "id": "arXiv:2206.13505",
    "title": "Deep Learning-Based Defect Classification and Detection in SEM Images",
    "abstract": "This proposes a novel ensemble deep learning-based model to accurately\nclassify, detect and localize different defect categories for aggressive\npitches and thin resists (High NA applications).In particular, we train\nRetinaNet models using different ResNet, VGGNet architectures as backbone and\npresent the comparison between the accuracies of these models and their\nperformance analysis on SEM images with different types of defect patterns such\nas bridge, break and line collapses. Finally, we propose a preference-based\nensemble strategy to combine the output predictions from different models in\norder to achieve better performance on classification and detection of defects.\nAs CDSEM images inherently contain a significant level of noise, detailed\nfeature information is often shadowed by noise. For certain resist profiles,\nthe challenge is also to differentiate between a microbridge, footing, break,\nand zones of probable breaks. Therefore, we have applied an unsupervised\nmachine learning model to denoise the SEM images to remove the False-Positive\ndefects and optimize the effect of stochastic noise on structured pixels for\nbetter metrology and enhanced defect inspection. We repeated the defect\ninspection step with the same trained model and performed a comparative\nanalysis for \"robustness\" and \"accuracy\" metric with conventional approach for\nboth noisy/denoised image pair. The proposed ensemble method demonstrates\nimprovement of the average precision metric (mAP) of the most difficult defect\nclasses. In this work we have developed a novel robust supervised deep learning\ntraining scheme to accurately classify as well as localize different defect\ntypes in SEM images with high degree of accuracy. Our proposed approach\ndemonstrates its effectiveness both quantitatively and qualitatively.",
    "descriptor": "",
    "authors": [
      "Bappaditya Deya",
      "Dipam Goswamif",
      "Sandip Haldera",
      "Kasem Khalilb",
      "Philippe Leraya",
      "Magdy A. Bayoumi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.13505"
  },
  {
    "id": "arXiv:2206.13506",
    "title": "Tensor Recovery Based on A Novel Non-convex Function Minimax Logarithmic  Concave Penalty Function",
    "abstract": "Non-convex relaxation methods have been widely used in tensor recovery\nproblems, and compared with convex relaxation methods, can achieve better\nrecovery results. In this paper, a new non-convex function, Minimax Logarithmic\nConcave Penalty (MLCP) function, is proposed, and some of its intrinsic\nproperties are analyzed, among which it is interesting to find that the\nLogarithmic function is an upper bound of the MLCP function. The proposed\nfunction is generalized to tensor cases, yielding tensor MLCP and weighted\ntensor $L\\gamma$-norm. Consider that its explicit solution cannot be obtained\nwhen applying it directly to the tensor recovery problem. Therefore, the\ncorresponding equivalence theorems to solve such problem are given, namely,\ntensor equivalent MLCP theorem and equivalent weighted tensor $L\\gamma$-norm\ntheorem. In addition, we propose two EMLCP-based models for classic tensor\nrecovery problems, namely low-rank tensor completion (LRTC) and tensor robust\nprincipal component analysis (TRPCA), and design proximal alternate\nlinearization minimization (PALM) algorithms to solve them individually.\nFurthermore, based on the Kurdyka-{\\L}ojasiwicz property, it is proved that the\nsolution sequence of the proposed algorithm has finite length and converges to\nthe critical point globally. Finally, Extensive experiments show that proposed\nalgorithm achieve good results, and it is confirmed that the MLCP function is\nindeed better than the Logarithmic function in the minimization problem, which\nis consistent with the analysis of theoretical properties.",
    "descriptor": "",
    "authors": [
      "Hongbing Zhang",
      "Xinyi Liu",
      "Chang Liu",
      "Hongtao Fan",
      "Yajing Li",
      "Xinyun Zhu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.13506"
  },
  {
    "id": "arXiv:2206.13568",
    "title": "AutoInit: Automatic Initialization via Jacobian Tuning",
    "abstract": "Good initialization is essential for training Deep Neural Networks (DNNs).\nOftentimes such initialization is found through a trial and error approach,\nwhich has to be applied anew every time an architecture is substantially\nmodified, or inherited from smaller size networks leading to sub-optimal\ninitialization. In this work we introduce a new and cheap algorithm, that\nallows one to find a good initialization automatically, for general\nfeed-forward DNNs. The algorithm utilizes the Jacobian between adjacent network\nblocks to tune the network hyperparameters to criticality. We solve the\ndynamics of the algorithm for fully connected networks with ReLU and derive\nconditions for its convergence. We then extend the discussion to more general\narchitectures with BatchNorm and residual connections. Finally, we apply our\nmethod to ResMLP and VGG architectures, where the automatic one-shot\ninitialization found by our method shows good performance on vision tasks.",
    "descriptor": "\nComments: 22 pages, 5 figures\n",
    "authors": [
      "Tianyu He",
      "Darshil Doshi",
      "Andrey Gromov"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.13568"
  },
  {
    "id": "arXiv:2206.13578",
    "title": "Materials Transformers Language Models for Generative Materials Design:  a benchmark study",
    "abstract": "Pre-trained transformer language models on large unlabeled corpus have\nproduced state-of-the-art results in natural language processing, organic\nmolecule design, and protein sequence generation. However, no such models have\nbeen applied to learn the composition patterns of inorganic materials. Here we\ntrain a series of seven modern transformer language models (GPT, GPT-2,\nGPT-Neo, GPT-J, BLMM, BART, and RoBERTa) using the expanded formulas from\nmaterial deposited in the ICSD, OQMD, and Materials Projects databases. Six\ndifferent datasets with/out non-charge-neutral or balanced electronegativity\nsamples are used to benchmark the performances and uncover the generation\nbiases of modern transformer models for the generative design of materials\ncompositions. Our extensive experiments showed that the causal language models\nbased materials transformers can generate chemically valid materials\ncompositions with as high as 97.54\\% to be charge neutral and 91.40\\% to be\nelectronegativity balanced, which has more than 6 times higher enrichment\ncompared to a baseline pseudo-random sampling algorithm. These models also\ndemonstrate high novelty and their potential in new materials discovery has\nbeen proved by their capability to recover the leave-out materials. We also\nfind that the properties of the generated samples can be tailored by training\nthe models with selected training sets such as high-bandgap materials. Our\nexperiments also showed that different models each have their own preference in\nterms of the properties of the generated samples and their running time\ncomplexity varies a lot. We have applied our materials transformer models to\ndiscover a set of new materials as validated using DFT calculations.",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Nihang Fu",
      "Lai Wei",
      "Yuqi Song",
      "Qinyang Li",
      "Rui Xin",
      "Sadman Sadeed Omee",
      "Rongzhi Dong",
      "Edirisuriya M. Dilanga Siriwardane",
      "Jianjun Hu"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.13578"
  },
  {
    "id": "arXiv:2206.13580",
    "title": "Rankings from multimodal pairwise comparisons",
    "abstract": "The task of ranking individuals or teams, based on a set of comparisons\nbetween pairs, arises in various contexts, including sporting competitions and\nthe analysis of dominance hierarchies among animals and humans. Given data on\nwhich competitors beat which others, the challenge is to rank the competitors\nfrom best to worst. Here we study the problem of computing rankings when there\nare multiple, potentially conflicting modes of comparison, such as multiple\ntypes of dominance behaviors among animals. We assume that we do not know a\npriori what information each behavior conveys about the ranking, or even\nwhether they convey any information at all. Nonetheless we show that it is\npossible to compute a ranking in this situation and present a fast method for\ndoing so, based on a combination of an expectation-maximization algorithm and a\nmodified Bradley-Terry model. We give a selection of example applications to\nboth animal and human competition.",
    "descriptor": "\nComments: 10 pages, 1 table, and 6 figures\n",
    "authors": [
      "M. E. J. Newman"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.13580"
  },
  {
    "id": "arXiv:2206.13581",
    "title": "Exact Spectral Norm Regularization for Neural Networks",
    "abstract": "We pursue a line of research that seeks to regularize the spectral norm of\nthe Jacobian of the input-output mapping for deep neural networks. While\nprevious work rely on upper bounding techniques, we provide a scheme that\ntargets the exact spectral norm. We showcase that our algorithm achieves an\nimproved generalization performance compared to previous spectral\nregularization techniques while simultaneously maintaining a strong safeguard\nagainst natural and adversarial noise. Moreover, we further explore some\nprevious reasoning concerning the strong adversarial protection that Jacobian\nregularization provides and show that it can be misleading.",
    "descriptor": "",
    "authors": [
      "Anton Johansson",
      "Claes Stranneg\u00e5rd",
      "Niklas Engsner",
      "Petter Mostad"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.13581"
  },
  {
    "id": "arXiv:2206.13613",
    "title": "Flexible-Rate Learned Hierarchical Bi-Directional Video Compression With  Motion Refinement and Frame-Level Bit Allocation",
    "abstract": "This paper presents improvements and novel additions to our recent work on\nend-to-end optimized hierarchical bi-directional video compression to further\nadvance the state-of-the-art in learned video compression. As an improvement,\nwe combine motion estimation and prediction modules and compress refined\nresidual motion vectors for improved rate-distortion performance. As novel\naddition, we adapted the gain unit proposed for image compression to\nflexible-rate video compression in two ways: first, the gain unit enables a\nsingle encoder model to operate at multiple rate-distortion operating points;\nsecond, we exploit the gain unit to control bit allocation among intra-coded\nvs. bi-directionally coded frames by fine tuning corresponding models for truly\nflexible-rate learned video coding. Experimental results demonstrate that we\nobtain state-of-the-art rate-distortion performance exceeding those of all\nprior art in learned video coding.",
    "descriptor": "\nComments: Accepted for publication in IEEE International Conference on Image Processing (ICIP 2022)\n",
    "authors": [
      "Eren Cetin",
      "M. Akin Yilmaz",
      "A. Murat Tekalp"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.13613"
  },
  {
    "id": "arXiv:2206.13617",
    "title": "Semidefinite programming bounds for few-distance sets in the Hamming and  Johnson spaces",
    "abstract": "We study the maximum cardinality problem of a set of few distances in the\nHamming and Johnson spaces. We formulate semidefinite programs for this problem\nand extend the 2011 works by Barg-Musin and Musin-Nozaki. As our main result,\nwe find new parameters for which the maximum size of two- and three-distance\nsets is known exactly.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Alexander Barg",
      "Ching-Yi Lai",
      "Pin-Chieh Tseng",
      "Wei-Hsuan Yu"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.13617"
  },
  {
    "id": "arXiv:2206.13629",
    "title": "Nonparametric, Nonasymptotic Confidence Bands with Paley-Wiener Kernels  for Band-Limited Functions",
    "abstract": "The paper introduces a method to construct confidence bands for bounded,\nband-limited functions based on a finite sample of input-output pairs. The\napproach is distribution-free w.r.t. the observation noises and only the\nknowledge of the input distribution is assumed. It is nonparametric, that is,\nit does not require a parametric model of the regression function and the\nregions have non-asymptotic guarantees. The algorithm is based on the theory of\nPaley-Wiener reproducing kernel Hilbert spaces. The paper first studies the\nfully observable variant, when there are no noises on the observations and only\nthe inputs are random; then it generalizes the ideas to the noisy case using\ngradient-perturbation methods. Finally, numerical experiments demonstrating\nboth cases are presented.",
    "descriptor": "",
    "authors": [
      "Bal\u00e1zs Csan\u00e1d Cs\u00e1ji",
      "B\u00e1lint Horv\u00e1th"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.13629"
  },
  {
    "id": "arXiv:2206.13632",
    "title": "Omni-Seg+: A Scale-aware Dynamic Network for Pathological Image  Segmentation",
    "abstract": "Comprehensive semantic segmentation on renal pathological images is\nchallenging due to the heterogeneous scales of the objects. For example, on a\nwhole slide image (WSI), the cross-sectional areas of glomeruli can be 64 times\nlarger than that of the peritubular capillaries, making it impractical to\nsegment both objects on the same patch, at the same scale. To handle this\nscaling issue, prior studies have typically trained multiple segmentation\nnetworks in order to match the optimal pixel resolution of heterogeneous tissue\ntypes. This multi-network solution is resource-intensive and fails to model the\nspatial relationship between tissue types. In this paper, we propose the\nOmni-Seg+ network, a scale-aware dynamic neural network that achieves\nmulti-object (six tissue types) and multi-scale (5X to 40X scale) pathological\nimage segmentation via a single neural network. The contribution of this paper\nis three-fold: (1) a novel scale-aware controller is proposed to generalize the\ndynamic neural network from single-scale to multi-scale; (2) semi-supervised\nconsistency regularization of pseudo-labels is introduced to model the\ninter-scale correlation of unannotated tissue types into a single end-to-end\nlearning paradigm; and (3) superior scale-aware generalization is evidenced by\ndirectly applying a model trained on human kidney images to mouse kidney\nimages, without retraining. By learning from ~150,000 human pathological image\npatches from six tissue types at three different resolutions, our approach\nachieved superior segmentation performance according to human visual assessment\nand evaluation of image-omics (i.e., spatial transcriptomics). The official\nimplementation is available at https://github.com/ddrrnn123/Omni-Seg.",
    "descriptor": "",
    "authors": [
      "Ruining Deng",
      "Quan Liu",
      "Can Cui",
      "Tianyuan Yao",
      "Jun Long",
      "Zuhayr Asad",
      "R. Michael Womick",
      "Zheyu Zhu",
      "Agnes B. Fogo",
      "Shilin Zhao",
      "Haichun Yang",
      "Yuankai Huo"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.13632"
  },
  {
    "id": "arXiv:2206.13634",
    "title": "Discrete Stochastic Optimization for Public Health Interventions with  Constraints",
    "abstract": "Many public health threats exist, motivating the need to find optimal\nintervention strategies. Given the stochastic nature of the threats (e.g., the\nspread of pandemic influenza, the occurrence of drug overdoses, and the\nprevalence of alcohol-related threats), deterministic optimization approaches\nmay be inappropriate. In this paper, we implement a stochastic optimization\nmethod to address aspects of the 2009 H1N1 and the COVID-19 pandemics, with the\nspread of disease modeled by the open source Monte Carlo simulations, FluTE and\nCovasim, respectively. Without testing every possible option, the objective of\nthe optimization is to determine the best combination of intervention\nstrategies so as to result in minimal economic loss to society. To reach our\nobjective, this application-oriented paper uses the discrete simultaneous\nperturbation stochastic approximation method (DSPSA), a recursive\nsimulation-based optimization algorithm, to update the input parameters in the\ndisease simulation software so that the output iteratively approaches minimal\neconomic loss. Assuming that the simulation models for the spread of disease\n(FluTE for H1N1 and Covasim for COVID-19 in our case) are accurate\nrepresentations for the population being studied, the simulation-based strategy\nwe present provides decision makers a powerful tool to mitigate potential human\nand economic losses from any epidemic. The basic approach is also applicable in\nother public health problems, such as opioid abuse and drunk driving.",
    "descriptor": "",
    "authors": [
      "Zewei Li",
      "James C. Spall"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.13634"
  },
  {
    "id": "arXiv:2206.13643",
    "title": "Definable and Non-definable Notions of Structure",
    "abstract": "Definability is a key notion in the theory of Grothendieck fibrations that\ncharacterises when an external property of objects can be accessed from within\nthe internal logic of the base of a fibration. In this paper we consider a\ngeneralisation of definability from properties of objects to structures on\nobjects, introduced by Shulman under the name local representability.\nWe first develop some general theory and show how to recover existing notions\ndue to B\\'{e}nabou and Johnstone as special cases. We give several examples of\ndefinable and non definable notions o structure, focusing on algebraic weak\nfactorisation systems, which can be naturally viewed as notions of structure on\ncodomain fibrations. Regarding definability, we give a sufficient criterion for\ncofibrantly generated awfs's to be definable, generalising a construction of\nthe universe for cubical sets, but also including some very different looking\nexamples that do not satisfy tininess in the internal sense, that exponential\nfunctors have a right adjoint. Our examples of non definability include the\nidentification of logical principles holding for the interval objects in\nsimplicial sets and Bezem-Coquand-Huber cubical sets that suffice to show a\ncertain definition of Kan fibration is not definable.",
    "descriptor": "",
    "authors": [
      "Andrew W. Swan"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2206.13643"
  },
  {
    "id": "arXiv:2206.13645",
    "title": "Wide Quantum Circuit Optimization with Topology Aware Synthesis",
    "abstract": "Unitary synthesis is an optimization technique that can achieve optimal\nmulti-qubit gate counts while mapping quantum circuits to restrictive qubit\ntopologies. However, synthesis algorithms are ultimately limited in scalability\nby their exponentially growing runtime and memory requirements. Applying\nunitary synthesis to quantum circuits wider than 5 qubits requires\ndivide-and-conquer partitioning of circuits into smaller components that can be\ndirectly optimized. In this work, we will explore the impact of qubit topology\non the multi-qubit gate count of circuits optimized with synthesis. We present\nTopAS, a topology aware synthesis tool built with the $BQSKit$ framework that\npartitions logical, unmapped, quantum circuits and matches subcircuits with\nsparse qubit subtopologies that balance the often opposing demands of the\nsynthesis and mapping algorithms. We demonstrate how this technique can be used\nto improve the multi-qubit gate count and depth of large width quantum circuits\nmapped to realistic sparse qubit topologies. We compare large scale synthesis\nalgorithms which focus on optimizing quantum circuits before and after mapping,\nand demonstrate that applying synthesis to unmapped logical circuits is able to\nreduce the the number of multi-qubit gates an average of 11.5% more compared to\noptimization after mapping when targeting a 2D mesh physical topology. When\ncompared with traditional quantum compilers using peephole optimization and\nmapping algorithms from the $Qiskit$ or $t|ket\\rangle$ toolkits, our approach\nis able to provide significant improvements in performance, reducing\nmulti-qubit gate count up to 62.2% and 29.9% on average.",
    "descriptor": "",
    "authors": [
      "Mathias Weiden",
      "Justin Kalloor",
      "John Kubiatowicz",
      "Ed Younis",
      "Costin Iancu"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2206.13645"
  },
  {
    "id": "arXiv:2206.13648",
    "title": "Supervised Learning with General Risk Functionals",
    "abstract": "Standard uniform convergence results bound the generalization gap of the\nexpected loss over a hypothesis class. The emergence of risk-sensitive learning\nrequires generalization guarantees for functionals of the loss distribution\nbeyond the expectation. While prior works specialize in uniform convergence of\nparticular functionals, our work provides uniform convergence for a general\nclass of H\\\"older risk functionals for which the closeness in the Cumulative\nDistribution Function (CDF) entails closeness in risk. We establish the first\nuniform convergence results for estimating the CDF of the loss distribution,\nyielding guarantees that hold simultaneously both over all H\\\"older risk\nfunctionals and over all hypotheses. Thus licensed to perform empirical risk\nminimization, we develop practical gradient-based methods for minimizing\ndistortion risks (widely studied subset of H\\\"older risks that subsumes the\nspectral risks, including the mean, conditional value at risk, cumulative\nprospect theory risks, and others) and provide convergence guarantees. In\nexperiments, we demonstrate the efficacy of our learning procedure, both in\nsettings where uniform convergence results hold and in high-dimensional\nsettings with deep networks.",
    "descriptor": "",
    "authors": [
      "Liu Leqi",
      "Audrey Huang",
      "Zachary C. Lipton",
      "Kamyar Azizzadenesheli"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.13648"
  },
  {
    "id": "arXiv:2206.13669",
    "title": "Studying Generalization Through Data Averaging",
    "abstract": "The generalization of machine learning models has a complex dependence on the\ndata, model and learning algorithm. We study train and test performance, as\nwell as the generalization gap given by the mean of their difference over\ndifferent data set samples to understand their ``typical\" behavior. We derive\nan expression for the gap as a function of the covariance between the model\nparameter distribution and the train loss, and another expression for the\naverage test performance, showing test generalization only depends on\ndata-averaged parameter distribution and the data-averaged loss. We show that\nfor a large class of model parameter distributions a modified generalization\ngap is always non-negative. By specializing further to parameter distributions\nproduced by stochastic gradient descent (SGD), along with a few approximations\nand modeling considerations, we are able to predict some aspects about how the\ngeneralization gap and model train and test performance vary as a function of\nSGD noise. We evaluate these predictions empirically on the Cifar10\nclassification task based on a ResNet architecture.",
    "descriptor": "",
    "authors": [
      "Carlos A. Gomez-Uribe"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.13669"
  },
  {
    "id": "arXiv:2206.13680",
    "title": "Attention-based conditioning methods using variable frame rate for  style-robust speaker verification",
    "abstract": "We propose an approach to extract speaker embeddings that are robust to\nspeaking style variations in text-independent speaker verification. Typically,\nspeaker embedding extraction includes training a DNN for speaker classification\nand using the bottleneck features as speaker representations. Such a network\nhas a pooling layer to transform frame-level to utterance-level features by\ncalculating statistics over all utterance frames, with equal weighting.\nHowever, self-attentive embeddings perform weighted pooling such that the\nweights correspond to the importance of the frames in a speaker classification\ntask. Entropy can capture acoustic variability due to speaking style\nvariations. Hence, an entropy-based variable frame rate vector is proposed as\nan external conditioning vector for the self-attention layer to provide the\nnetwork with information that can address style effects. This work explores\nfive different approaches to conditioning. The best conditioning approach,\nconcatenation with gating, provided statistically significant improvements over\nthe x-vector baseline in 12/23 tasks and was the same as the baseline in 11/23\ntasks when using the UCLA speaker variability database. It also significantly\noutperformed self-attention without conditioning in 9/23 tasks and was worse in\n1/23. The method also showed significant improvements in multi-speaker\nscenarios of SITW.",
    "descriptor": "\nComments: To appear in Interspeech, 2022\n",
    "authors": [
      "Amber Afshan",
      "Abeer Alwan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.13680"
  },
  {
    "id": "arXiv:2206.13684",
    "title": "Learning from human perception to improve automatic speaker verification  in style-mismatched conditions",
    "abstract": "Our prior experiments show that humans and machines seem to employ different\napproaches to speaker discrimination, especially in the presence of speaking\nstyle variability. The experiments examined read versus conversational speech.\nListeners focused on speaker-specific idiosyncrasies while \"telling speakers\ntogether\", and on relative distances in a shared acoustic space when \"telling\nspeakers apart\". However, automatic speaker verification (ASV) systems use the\nsame loss function irrespective of target or non-target trials. To improve ASV\nperformance in the presence of style variability, insights learnt from human\nperception are used to design a new training loss function that we refer to as\n\"CllrCE loss\". CllrCE loss uses both speaker-specific idiosyncrasies and\nrelative acoustic distances between speakers to train the ASV system. When\nusing the UCLA speaker variability database, in the x-vector and conditioning\nsetups, CllrCE loss results in significant relative improvements in EER by\n1-66%, and minDCF by 1-31% and 1-56%, respectively, when compared to the\nx-vector baseline. Using the SITW evaluation tasks, which involve different\nconversational speech tasks, the proposed loss combined with self-attention\nconditioning results in significant relative improvements in EER by 2-5% and\nminDCF by 6-12% over baseline. In the SITW case, performance improvements were\nconsistent only with conditioning.",
    "descriptor": "\nComments: To appear in Interspeech, 2022\n",
    "authors": [
      "Amber Afshan",
      "Abeer Alwan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.13684"
  },
  {
    "id": "arXiv:2206.13722",
    "title": "Low Altitude 3-D Coverage Performance Analysis in Cell-Free Distributed  Collaborative Massive MIMO Systems",
    "abstract": "To improve the poor performance of distributed operation and non-scalability\nof centralized operation in traditional cell-free massive MIMO, we propose a\ncell-free distributed collaborative (CFDC) massive multiple-input\nmultiple-output (MIMO) system based on a novel two-layer model to take\nadvantages of the distributed cloud-edge-end collaborative architecture in\nbeyond 5G (B5G) internet of things (IoT) environment to provide strong\nflexibility and scalability. We further ultilize the proposed CFDC massive MIMO\nsystem to support the low altitude three-dimensional (3-D) coverage scenario\nwith unmanned aerial vehicles (UAVs), while accounting for 3-D Rician channel\nestimation, user-centric association and different scalable receiving schemes.\nSince coexisted UAVs and ground users (GUEs) cause greater interference, we\nultilize user-centric association strategy and minimum-mean-square error (MMSE)\nchannel state information (CSI) estimation to obtain the estimated CSI of UAVs\nand GUEs. Under the CFDC scenarios, scalable receiving schemes as maximum ratio\ncombing (MRC), partial zero-forcing (P-ZF) and partial minimum-mean-square\nerror (P-MMSE) can be performed at edge servers and the closed-form expressions\nfor uplink spectral efficiency (SE) are derived. Based on the derived\nexpressions, we propose an efficient power control algorithm by solving a\nmulti-objective optimization problem (MOOP) between maximizing the average SE\nof UAVs and GUEs simultaneously with Deep Q-Network (DQN). Numerical results\nverify the accuracy of the derived closed-form expressions and the\neffectiveness of the coexisted UAVs and GUEs transmission scheme in CFDC\nmassive MIMO systems. The SE analysis under various system parameters offers\nnumerous flexibilities for system optimization.",
    "descriptor": "",
    "authors": [
      "Jiamin Li",
      "Qijun Pan",
      "Pengcheng Zhu",
      "Dongming Wang",
      "Xiaohu You"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.13722"
  },
  {
    "id": "arXiv:2206.13740",
    "title": "GAN-based Super-Resolution and Segmentation of Retinal Layers in Optical  coherence tomography Scans",
    "abstract": "In this paper, we design a Generative Adversarial Network (GAN)-based\nsolution for super-resolution and segmentation of optical coherence tomography\n(OCT) scans of the retinal layers. OCT has been identified as a non-invasive\nand inexpensive modality of imaging to discover potential biomarkers for the\ndiagnosis and progress determination of neurodegenerative diseases, such as\nAlzheimer's Disease (AD). Current hypotheses presume the thickness of the\nretinal layers, which are analyzable within OCT scans, can be effective\nbiomarkers. As a logical first step, this work concentrates on the challenging\ntask of retinal layer segmentation and also super-resolution for higher clarity\nand accuracy. We propose a GAN-based segmentation model and evaluate\nincorporating popular networks, namely, U-Net and ResNet, in the GAN\narchitecture with additional blocks of transposed convolution and sub-pixel\nconvolution for the task of upscaling OCT images from low to high resolution by\na factor of four. We also incorporate the Dice loss as an additional\nreconstruction loss term to improve the performance of this joint optimization\ntask. Our best model configuration empirically achieved the Dice coefficient of\n0.867 and mIOU of 0.765.",
    "descriptor": "\nComments: 5 pages,7 figures\n",
    "authors": [
      "Paria Jeihouni",
      "Omid Dehzangi",
      "Annahita Amireskandari",
      "Ali Rezai",
      "Nasser M. Nasrabadi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.13740"
  },
  {
    "id": "arXiv:2206.13760",
    "title": "Interrelate Training and Searching: A Unified Online Clustering  Framework for Speaker Diarization",
    "abstract": "For online speaker diarization, samples arrive incrementally, and the overall\ndistribution of the samples is invisible. Moreover, in most existing\nclustering-based methods, the training objective of the embedding extractor is\nnot designed specially for clustering. To improve online speaker diarization\nperformance, we propose a unified online clustering framework, which provides\nan interactive manner between embedding extractors and clustering algorithms.\nSpecifically, the framework consists of two highly coupled parts:\nclustering-guided recurrent training (CGRT) and truncated beam searching\nclustering (TBSC). The CGRT introduces the clustering algorithm into the\ntraining process of embedding extractors, which could provide not only\ncluster-aware information for the embedding extractor, but also crucial\nparameters for the clustering process afterward. And with these parameters,\nwhich contain preliminary information of the metric space, the TBSC penalizes\nthe probability score of each cluster, in order to output more accurate\nclustering results in online fashion with low latency. With the above\ninnovations, our proposed online clustering system achieves 14.48\\% DER with\ncollar 0.25 at 2.5s latency on the AISHELL-4, while the DER of the offline\nagglomerative hierarchical clustering is 14.57\\%.",
    "descriptor": "\nComments: Accepted by Interspeech 2022\n",
    "authors": [
      "Yifan Chen",
      "Yifan Guo",
      "Qingxuan Li",
      "Gaofeng Cheng",
      "Pengyuan Zhang",
      "Yonghong Yan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2206.13760"
  },
  {
    "id": "arXiv:2206.13762",
    "title": "A Hierarchical Speaker Representation Framework for One-shot Singing  Voice Conversion",
    "abstract": "Typically, singing voice conversion (SVC) depends on an embedding vector,\nextracted from either a speaker lookup table (LUT) or a speaker recognition\nnetwork (SRN), to model speaker identity. However, singing contains more\nexpressive speaker characteristics than conversational speech. It is suspected\nthat a single embedding vector may only capture averaged and coarse-grained\nspeaker characteristics, which is insufficient for the SVC task. To this end,\nthis work proposes a novel hierarchical speaker representation framework for\nSVC, which can capture fine-grained speaker characteristics at different\ngranularity. It consists of an up-sampling stream and three down-sampling\nstreams. The up-sampling stream transforms the linguistic features into audio\nsamples, while one down-sampling stream of the three operates in the reverse\ndirection. It is expected that the temporal statistics of each down-sampling\nblock can represent speaker characteristics at different granularity, which\nwill be engaged in the up-sampling blocks to enhance the speaker modeling.\nExperiment results verify that the proposed method outperforms both the LUT and\nSRN based SVC systems. Moreover, the proposed system supports the one-shot SVC\nwith only a few seconds of reference audio.",
    "descriptor": "\nComments: Accepted to INTERSPEECH 2022\n",
    "authors": [
      "Xu Li",
      "Shansong Liu",
      "Ying Shan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2206.13762"
  },
  {
    "id": "arXiv:2206.13768",
    "title": "Algorithms for audio inpainting based on probabilistic nonnegative  matrix factorization",
    "abstract": "Audio inpainting, i.e., the task of restoring missing or occluded audio\nsignal samples, usually relies on sparse representations or autoregressive\nmodeling. In this paper, we propose to structure the spectrogram with\nnonnegative matrix factorization (NMF) in a probabilistic framework. First, we\ntreat the missing samples as latent variables, and derive two\nexpectation-maximization algorithms for estimating the parameters of the model,\ndepending on whether we formulate the problem in the time- or time-frequency\ndomain. Then, we treat the missing samples as parameters, and we address this\nnovel problem by deriving an alternating minimization scheme. We assess the\npotential of these algorithms for the task of restoring short- to middle-length\ngaps in music signals. Experiments reveal great convergence properties of the\nproposed methods, as well as competitive performance when compared to\nstate-of-the-art audio inpainting techniques.",
    "descriptor": "",
    "authors": [
      "Ond\u0159ej Mokr\u00fd",
      "Paul Magron",
      "Thomas Oberlin",
      "C\u00e9dric F\u00e9votte"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2206.13768"
  },
  {
    "id": "arXiv:2206.13807",
    "title": "Two Methods for Spoofing-Aware Speaker Verification: Multi-Layer  Perceptron Score Fusion Model and Integrated Embedding Projector",
    "abstract": "The use of deep neural networks (DNN) has dramatically elevated the\nperformance of automatic speaker verification (ASV) over the last decade.\nHowever, ASV systems can be easily neutralized by spoofing attacks. Therefore,\nthe Spoofing-Aware Speaker Verification (SASV) challenge is designed and held\nto promote development of systems that can perform ASV considering spoofing\nattacks by integrating ASV and spoofing countermeasure (CM) systems. In this\npaper, we propose two back-end systems: multi-layer perceptron score fusion\nmodel (MSFM) and integrated embedding projector (IEP). The MSFM, score fusion\nback-end system, derived SASV score utilizing ASV and CM scores and embeddings.\nOn the other hand,IEP combines ASV and CM embeddings into SASV embedding and\ncalculates final SASV score based on the cosine similarity. We effectively\nintegrated ASV and CM systems through proposed MSFM and IEP and achieved the\nSASV equal error rates 0.56%, 1.32% on the official evaluation trials of the\nSASV 2022 challenge.",
    "descriptor": "\nComments: 5 pages, 4 figures, 5 tables, accepted to 2022 Interspeech as a conference paper\n",
    "authors": [
      "Jungwoo Heo",
      "Ju-ho Kim",
      "Hyun-seo Shin"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2206.13807"
  },
  {
    "id": "arXiv:2206.13808",
    "title": "Speaker Verification in Multi-Speaker Environments Using Temporal  Feature Fusion",
    "abstract": "Verifying the identity of a speaker is crucial in modern human-machine\ninterfaces, e.g., to ensure privacy protection or to enable biometric\nauthentication. Classical speaker verification (SV) approaches estimate a\nfixed-dimensional embedding from a speech utterance that encodes the speaker's\nvoice characteristics. A speaker is verified if his/her voice embedding is\nsufficiently similar to the embedding of the claimed speaker. However, such\napproaches assume that only a single speaker exists in the input. The presence\nof concurrent speakers is likely to have detrimental effects on the\nperformance. To address SV in a multi-speaker environment, we propose an\nend-to-end deep learning-based SV system that detects whether the target\nspeaker exists within an input or not. First, an embedding is estimated from a\nreference utterance to represent the target's characteristics. Second,\nframe-level features are estimated from the input mixture. The reference\nembedding is then fused frame-wise with the mixture's features to allow\ndistinguishing the target from other speakers on a frame basis. Finally, the\nfused features are used to predict whether the target speaker is active in the\nspeech segment or not. Experimental evaluation shows that the proposed method\noutperforms the x-vector in multi-speaker conditions.",
    "descriptor": "\nComments: To be presented at EUSIPCO 2022\n",
    "authors": [
      "Ahmad Aloradi",
      "Wolfgang Mack",
      "Mohamed Elminshawi",
      "Emanu\u00ebl A. P. Habets"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2206.13808"
  },
  {
    "id": "arXiv:2206.13865",
    "title": "RetrieverTTS: Modeling Decomposed Factors for Text-Based Speech  Insertion",
    "abstract": "This paper proposes a new \"decompose-and-edit\" paradigm for the text-based\nspeech insertion task that facilitates arbitrary-length speech insertion and\neven full sentence generation. In the proposed paradigm, global and local\nfactors in speech are explicitly decomposed and separately manipulated to\nachieve high speaker similarity and continuous prosody. Specifically, we\nproposed to represent the global factors by multiple tokens, which are\nextracted by cross-attention operation and then injected back by link-attention\noperation. Due to the rich representation of global factors, we manage to\nachieve high speaker similarity in a zero-shot manner. In addition, we\nintroduce a prosody smoothing task to make the local prosody factor\ncontext-aware and therefore achieve satisfactory prosody continuity. We further\nachieve high voice quality with an adversarial training stage. In the\nsubjective test, our method achieves state-of-the-art performance in both\nnaturalness and similarity. Audio samples can be found at\nhttps://ydcustc.github.io/retrieverTTS-demo/.",
    "descriptor": "\nComments: 5 pages, 1 figure, 3 tables. Accepted by Interspeech 2022\n",
    "authors": [
      "Dacheng Yin",
      "Chuanxin Tang",
      "Yanqing Liu",
      "Xiaoqiang Wang",
      "Zhiyuan Zhao",
      "Yucheng Zhao",
      "Zhiwei Xiong",
      "Sheng Zhao",
      "Chong Luo"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2206.13865"
  },
  {
    "id": "arXiv:2206.13872",
    "title": "Disentangling Embedding Spaces with Minimal Distributional Assumptions",
    "abstract": "Interest in understanding and factorizing learned embedding spaces is\ngrowing. For instance, recent concept-based explanation techniques analyze a\nmachine learning model in terms of interpretable latent components. Such\ncomponents have to be discovered in the model's embedding space, e.g., through\nindependent component analysis (ICA) or modern disentanglement learning\ntechniques. While these unsupervised approaches offer a sound formal framework,\nthey either require access to a data generating function or impose rigid\nassumptions on the data distribution, such as independence of components, that\nare often violated in practice. In this work, we link conceptual explainability\nfor vision models with disentanglement learning and ICA. This enables us to\nprovide first theoretical results on how components can be identified without\nrequiring any distributional assumptions. From these insights, we derive the\ndisjoint attributions (DA) concept discovery method that is applicable to a\nbroader class of problems than current approaches but yet possesses a formal\nidentifiability guarantee. In an extensive comparison against component\nanalysis and over 300 state-of-the-art disentanglement models, DA stably\nmaintains superior performance, even under varying distributions and\ncorrelation strengths.",
    "descriptor": "\nComments: 23 pages. The first two authors contributed equally\n",
    "authors": [
      "Tobias Leemann",
      "Michael Kirchhof",
      "Yao Rong",
      "Enkelejda Kasneci",
      "Gjergji Kasneci"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.13872"
  },
  {
    "id": "arXiv:2206.13873",
    "title": "High-order Lohner-type algorithm for rigorous computation of Poincar\u00e9  maps in systems of Delay Differential Equations with several delays",
    "abstract": "We present a Lohner-type algorithm for rigorous integration of systems of\nDelay Differential Equations (DDEs) with multiple delays and its application in\ncomputation of Poincar\\'e maps to study the dynamics of some bounded, eternal\nsolutions. The algorithm is based on a piecewise Taylor representation of the\nsolutions in the phase-space and it exploits the smoothing of solutions\noccurring in DDEs to produces enclosures of solutions of a high order. We apply\nthe topological techniques to prove various kinds of dynamical behavior, for\nexample, existence of (apparently) unstable periodic orbits in Mackey-Glass\nEquation (in the regime of parameters where chaos is numerically observed) and\npersistence of symbolic dynamics in a delay-perturbed chaotic ODE (the\nR\\\"ossler system).",
    "descriptor": "",
    "authors": [
      "Robert Szczelina",
      "Piotr Zgliczy\u0144ski"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.13873"
  },
  {
    "id": "arXiv:2206.13899",
    "title": "Computing diffraction anomalies as nonlinear eigenvalue problems",
    "abstract": "When a plane electromagnetic wave impinges upon a diffraction grating or\nother periodic structures, reflected and transmitted waves propagate away from\nthe structure in different radiation channels. A diffraction anomaly occurs\nwhen the outgoing waves in one or more radiation channels vanish. Zero\nreflection, zero transmission and perfect absorption are important examples of\ndiffraction anomalies, and they are useful for manipulating electromagnetic\nwaves and light. Since diffraction anomalies appear only at specific\nfrequencies and/or wavevectors, and may require the tuning of structural or\nmaterial parameters, they are relatively difficult to find by standard\nnumerical methods. Iterative methods may be used, but good initial guesses are\nrequired. To determine all diffraction anomalies in a given frequency interval,\nit is necessary to repeatedly solve the diffraction problem for many\nfrequencies. In this paper, an efficient numerical method is developed for\ncomputing diffraction anomalies. The method relies on nonlinear eigenvalue\nformulations for scattering anomalies and solves the nonlinear eigenvalue\nproblems by a contour-integral method. Numerical examples involving periodic\narrays of cylinders are presented to illustrate the new method.",
    "descriptor": "",
    "authors": [
      "Zitao Mai",
      "Ya Yan Lu"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Numerical Analysis (math.NA)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2206.13899"
  },
  {
    "id": "arXiv:2206.13903",
    "title": "AS-IntroVAE: Adversarial Similarity Distance Makes Robust IntroVAE",
    "abstract": "Recently, introspective models like IntroVAE and S-IntroVAE have excelled in\nimage generation and reconstruction tasks. The principal characteristic of\nintrospective models is the adversarial learning of VAE, where the encoder\nattempts to distinguish between the real and the fake (i.e., synthesized)\nimages. However, due to the unavailability of an effective metric to evaluate\nthe difference between the real and the fake images, the posterior collapse and\nthe vanishing gradient problem still exist, reducing the fidelity of the\nsynthesized images. In this paper, we propose a new variation of IntroVAE\ncalled Adversarial Similarity Distance Introspective Variational Autoencoder\n(AS-IntroVAE). We theoretically analyze the vanishing gradient problem and\nconstruct a new Adversarial Similarity Distance (AS-Distance) using the\n2-Wasserstein distance and the kernel trick. With weight annealing on\nAS-Distance and KL-Divergence, the AS-IntroVAE are able to generate stable and\nhigh-quality images. The posterior collapse problem is addressed by making\nper-batch attempts to transform the image so that it better fits the prior\ndistribution in the latent space. Compared with the per-image approach, this\nstrategy fosters more diverse distributions in the latent space, allowing our\nmodel to produce images of great diversity. Comprehensive experiments on\nbenchmark datasets demonstrate the effectiveness of AS-IntroVAE on image\ngeneration and reconstruction tasks.",
    "descriptor": "",
    "authors": [
      "Changjie Lu",
      "Shen Zheng",
      "Zirui Wang",
      "Omar Dib",
      "Gaurav Gupta"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.13903"
  },
  {
    "id": "arXiv:2206.13910",
    "title": "Epidemic Control Modeling using Parsimonious Models and Markov Decision  Processes",
    "abstract": "Many countries have experienced at least two waves of the COVID-19 pandemic.\nThe second wave is far more dangerous as distinct strains appear more harmful\nto human health, but it stems from the complacency about the first wave. This\npaper introduces a parsimonious yet representative stochastic epidemic model\nthat simulates the uncertain spread of the disease regardless of the latency\nand recovery time distributions. We also propose a Markov decision process to\nseek an optimal trade-off between the usage of the healthcare system and the\neconomic costs of an epidemic. We apply the model to COVID-19 data from New\nDelhi, India and simulate the epidemic spread with different policy review\ntimes. The results show that the optimal policy acts swiftly to curb the\nepidemic in the first wave, thus avoiding the collapse of the healthcare system\nand the future costs of posterior outbreaks. An analysis of the recent collapse\nof the healthcare system of India during the second COVID-19 wave suggests that\nmany lives could have been preserved if swift mitigation was promoted after the\nfirst wave.",
    "descriptor": "",
    "authors": [
      "Edilson F. Arruda",
      "Tarun Sharma",
      "Rodrigo e A. Alexandre",
      "Sinnu Susan Thomas"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.13910"
  },
  {
    "id": "arXiv:2206.13916",
    "title": "Grid Tariffs for Peak Demand Reduction: Is there a Price Signal Conflict  with Electricity Spot Prices?",
    "abstract": "The electricity grid is expected to require vast investments due to the\ndecarbonization-by-electrification trend, calling for a change in grid tariff\ndesign which provides proper incentives for reducing peak loads. However, price\nsignals from grid tariffs could be distorted from electricity spot prices which\nalso represents a significant of the total consumer electricity bill. This\npaper attempts to identify whether there is a price signal conflict between\ngrid tariffs and spot prices. Four different grid tariff designs are compared,\nusing a generic demand response model as part of a cost-minimizing linear\nprogram to simulate the reduction in peak load. The method is applied to\nmetered electricity demand from 3608 consumers in Oslo, Norway. Results show\nthat new grid tariff designs reduce peak loads by 1-4%, and that reduction in\npeak load is smaller when consumers are subject to electricity spot prices.",
    "descriptor": "\nComments: 11 pages, 4 figures, submitted to European Energy Market 2022 Conference\n",
    "authors": [
      "Sigurd Bjarghov",
      "Matthias Hofmann"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.13916"
  },
  {
    "id": "arXiv:2206.14109",
    "title": "Optimization of QKD Networks with Classical and Quantum Annealing",
    "abstract": "This paper analyses a classical and a quantum annealing approach to compute\nthe minimum deployment of Quantum Key Distribution (QKD) hardware in a tier 1\nprovider network. The ensemble of QKD systems needs to be able to exchange as\nmany encryption keys between all network nodes in order to encrypt the data\npayload, which is defined by traffic demand matrices. Redundancy and latency\nrequirements add additional boundary conditions. The result of the optimization\nproblem yields a classical heuristic network planners may utilize for planning\nfuture QKD quantum networks.",
    "descriptor": "",
    "authors": [
      "Bob Godar",
      "Christoph Roch",
      "Jonas Stein",
      "Marc Geitz",
      "Bettina Lehmann",
      "Matthias Gunkel",
      "Volker F\u00fcrst",
      "Fred Hofmann"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2206.14109"
  },
  {
    "id": "arXiv:2206.14114",
    "title": "On the universality of the volatility formation process: when machine  learning and rough volatility agree",
    "abstract": "We train an LSTM network based on a pooled dataset made of hundreds of liquid\nstocks aiming to forecast the next daily realized volatility for all stocks.\nShowing the consistent outperformance of this universal LSTM relative to other\nasset-specific parametric models, we uncover nonparametric evidences of a\nuniversal volatility formation mechanism across assets relating past market\nrealizations, including daily returns and volatilities, to current\nvolatilities. A parsimonious parametric forecasting device combining the rough\nfractional stochastic volatility and quadratic rough Heston models with fixed\nparameters results in the same level of performance as the universal LSTM,\nwhich confirms the universality of the volatility formation process from a\nparametric perspective.",
    "descriptor": "",
    "authors": [
      "Mathieu Rosenbaum",
      "Jianfei Zhang"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)",
      "Computational Finance (q-fin.CP)",
      "Risk Management (q-fin.RM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.14114"
  },
  {
    "id": "arXiv:2206.14115",
    "title": "Quantum Neural Architecture Search with Quantum Circuits Metric and  Bayesian Optimization",
    "abstract": "Quantum neural networks are promising for a wide range of applications in the\nNoisy Intermediate-Scale Quantum era. As such, there is an increasing demand\nfor automatic quantum neural architecture search. We tackle this challenge by\ndesigning a quantum circuits metric for Bayesian optimization with Gaussian\nprocess. To this goal, we propose a new quantum gates distance that\ncharacterizes the gates' action over every quantum state and provide a\ntheoretical perspective on its geometrical properties. Our approach\nsignificantly outperforms the benchmark on three empirical quantum machine\nlearning problems including training a quantum generative adversarial network,\nsolving combinatorial optimization in the MaxCut problem, and simulating\nquantum Fourier transform. Our method can be extended to characterize behaviors\nof various quantum machine learning models.",
    "descriptor": "\nComments: accepted to ICML 2022 Workshop AI4Science\n",
    "authors": [
      "Trong Duong",
      "Sang T. Truong",
      "Minh Tam",
      "Bao Bach",
      "Ju-Young Ryu",
      "June-Koo Kevin Rhee"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14115"
  },
  {
    "id": "arXiv:2206.14165",
    "title": "Expressive, Variable, and Controllable Duration Modelling in TTS",
    "abstract": "Duration modelling has become an important research problem once more with\nthe rise of non-attention neural text-to-speech systems. The current approaches\nlargely fall back to relying on previous statistical parametric speech\nsynthesis technology for duration prediction, which poorly models the\nexpressiveness and variability in speech. In this paper, we propose two\nalternate approaches to improve duration modelling. First, we propose a\nduration model conditioned on phrasing that improves the predicted durations\nand provides better modelling of pauses. We show that the duration model\nconditioned on phrasing improves the naturalness of speech over our baseline\nduration model. Second, we also propose a multi-speaker duration model called\nCauliflow, that uses normalising flows to predict durations that better match\nthe complex target duration distribution. Cauliflow performs on par with our\nother proposed duration model in terms of naturalness, whilst providing\nvariable durations for the same prompt and variable levels of expressiveness.\nLastly, we propose to condition Cauliflow on parameters that provide an\nintuitive control of the pacing and pausing in the synthesised speech in a\nnovel way.",
    "descriptor": "\nComments: Accepted to be published in the Proceedings of InterSpeech 2022\n",
    "authors": [
      "Ammar Abbas",
      "Thomas Merritt",
      "Alexis Moinet",
      "Sri Karlapati",
      "Ewa Muszynska",
      "Simon Slangen",
      "Elia Gatti",
      "Thomas Drugman"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2206.14165"
  },
  {
    "id": "arXiv:2206.14184",
    "title": "Integral Transforms in a Physics-Informed (Quantum) Neural Network  setting: Applications & Use-Cases",
    "abstract": "In many computational problems in engineering and science, function or model\ndifferentiation is essential, but also integration is needed. An important\nclass of computational problems include so-called integro-differential\nequations which include both integrals and derivatives of a function. In\nanother example, stochastic differential equations can be written in terms of a\npartial differential equation of a probability density function of the\nstochastic variable. To learn characteristics of the stochastic variable based\non the density function, specific integral transforms, namely moments, of the\ndensity function need to be calculated. Recently, the machine learning paradigm\nof Physics-Informed Neural Networks emerged with increasing popularity as a\nmethod to solve differential equations by leveraging automatic differentiation.\nIn this work, we propose to augment the paradigm of Physics-Informed Neural\nNetworks with automatic integration in order to compute complex integral\ntransforms on trained solutions, and to solve integro-differential equations\nwhere integrals are computed on-the-fly during training. Furthermore, we\nshowcase the techniques in various application settings, numerically simulating\nquantum computer-based neural networks as well as classical neural networks.",
    "descriptor": "\nComments: 11 pages, 8 figures\n",
    "authors": [
      "Niraj Kumar",
      "Evan Philip",
      "Vincent E. Elfving"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.14184"
  },
  {
    "id": "arXiv:1906.00756",
    "title": "The Strength of Structural Diversity in Online Social Networks",
    "abstract": "Comments: 16 pages, 6 figures",
    "descriptor": "\nComments: 16 pages, 6 figures\n",
    "authors": [
      "Yafei Zhang",
      "Lin Wang",
      "Jonathan J. H. Zhu",
      "Xiaofan Wang",
      "Alex 'Sandy' Pentland"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/1906.00756"
  },
  {
    "id": "arXiv:1906.04199",
    "title": "Synthesis of Computable Regular Functions of Infinite Words",
    "abstract": "Synthesis of Computable Regular Functions of Infinite Words",
    "descriptor": "",
    "authors": [
      "V. Dave",
      "E. Filiot",
      "S. Krishna",
      "N. Lhote"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/1906.04199"
  },
  {
    "id": "arXiv:2003.03201",
    "title": "Automated Repair of Resource Leaks in Android Applications",
    "abstract": "Automated Repair of Resource Leaks in Android Applications",
    "descriptor": "",
    "authors": [
      "Bhargav Nagaraja Bhatt",
      "Carlo A. Furia"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2003.03201"
  },
  {
    "id": "arXiv:2004.00275",
    "title": "Differentially Private Algorithms for Statistical Verification of  Cyber-Physical Systems",
    "abstract": "Comments: Under review for IEEE Open Journal of Control Systems",
    "descriptor": "\nComments: Under review for IEEE Open Journal of Control Systems\n",
    "authors": [
      "Yu Wang",
      "Hussein Sibai",
      "Mark Yen",
      "Sayan Mitra",
      "Geir E. Dullerud"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2004.00275"
  },
  {
    "id": "arXiv:2006.01027",
    "title": "Go viral or go broadcast? Characterizing the virality and growth of  cascades",
    "abstract": "Comments: 10 pages, 15 figures, 2 tables",
    "descriptor": "\nComments: 10 pages, 15 figures, 2 tables\n",
    "authors": [
      "Yafei Zhang",
      "Lin Wang",
      "Jonathan J. H. Zhu",
      "Xiaofan Wang"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2006.01027"
  },
  {
    "id": "arXiv:2008.08454",
    "title": "Exploring the Impacts from Datasets to Monocular Depth Estimation (MDE)  Models with MineNavi",
    "abstract": "Comments: 6 pages,10 figures",
    "descriptor": "\nComments: 6 pages,10 figures\n",
    "authors": [
      "Xiangtong Wang",
      "Binbin Liang",
      "Menglong Yang",
      "Wei Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2008.08454"
  },
  {
    "id": "arXiv:2008.10796",
    "title": "Deep Variational Network Toward Blind Image Restoration",
    "abstract": "Comments: Extended Version of VDNet (NeurIPS 2019)",
    "descriptor": "\nComments: Extended Version of VDNet (NeurIPS 2019)\n",
    "authors": [
      "Zongsheng Yue",
      "Hongwei Yong",
      "Qian Zhao",
      "Lei Zhang",
      "Deyu Meng",
      "Kwan-Yen K. Wong"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2008.10796"
  },
  {
    "id": "arXiv:2008.12073",
    "title": "DrumGAN: Synthesis of Drum Sounds With Timbral Feature Conditioning  Using Generative Adversarial Networks",
    "abstract": "Comments: 8 pages, 1 figure, 3 tables, accepted in Proc. of the 21st International Society for Music Information Retrieval (ISMIR2020)",
    "descriptor": "\nComments: 8 pages, 1 figure, 3 tables, accepted in Proc. of the 21st International Society for Music Information Retrieval (ISMIR2020)\n",
    "authors": [
      "J. Nistal",
      "S. Lattner",
      "G. Richard"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2008.12073"
  },
  {
    "id": "arXiv:2011.06070",
    "title": "Quantifying and Learning Linear Symmetry-Based Disentanglement",
    "abstract": "Comments: The Thirty-ninth International Conference on Machine Learning (ICML 2022)",
    "descriptor": "\nComments: The Thirty-ninth International Conference on Machine Learning (ICML 2022)\n",
    "authors": [
      "Loek Tonnaer",
      "Luis A. P\u00e9rez Rey",
      "Vlado Menkovski",
      "Mike Holenderski",
      "Jacobus W. Portegies"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.06070"
  },
  {
    "id": "arXiv:2011.07881",
    "title": "Value Function Approximations via Kernel Embeddings for No-Regret  Reinforcement Learning",
    "abstract": "Value Function Approximations via Kernel Embeddings for No-Regret  Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Sayak Ray Chowdhury",
      "Rafael Oliveira"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.07881"
  },
  {
    "id": "arXiv:2101.00756",
    "title": "NCQ: Code reuse support for node.js developers",
    "abstract": "Comments: Submitted to IEEE Transactions on Software Engineering",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Software Engineering\n",
    "authors": [
      "Brittany Reid",
      "Marcelo d`Amorim",
      "Markus Wagner",
      "Christoph Treude"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2101.00756"
  },
  {
    "id": "arXiv:2101.03297",
    "title": "Incentive Design and Profit Sharing in Multi-modal Transportation  Network",
    "abstract": "Incentive Design and Profit Sharing in Multi-modal Transportation  Network",
    "descriptor": "",
    "authors": [
      "Yuntian Deng",
      "Shiping Shao",
      "Archak Mittal",
      "Richard Twumasi-Boakye",
      "James Fishelson",
      "Abhishek Gupta",
      "Ness B. Shroff"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2101.03297"
  },
  {
    "id": "arXiv:2101.06827",
    "title": "HyperNTF: A Hypergraph Regularized Nonnegative Tensor Factorization for  Dimensionality Reduction",
    "abstract": "Comments: 15 pages",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Wanguang Yin",
      "Youzhi Qu",
      "Zhengming Ma",
      "Quanying Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2101.06827"
  },
  {
    "id": "arXiv:2102.03523",
    "title": "Ownership Verification of DNN Architectures via Hardware Cache Side  Channels",
    "abstract": "Comments: The paper has been accepted by IEEE Transactions on Circuits and Systems for Video Technology",
    "descriptor": "\nComments: The paper has been accepted by IEEE Transactions on Circuits and Systems for Video Technology\n",
    "authors": [
      "Xiaoxuan Lou",
      "Shangwei Guo",
      "Jiwei Li",
      "Tianwei Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2102.03523"
  },
  {
    "id": "arXiv:2102.08185",
    "title": "Block-Chain Technologies in Healthcare Analytics",
    "abstract": "Comments: 14 pages, 4 figures",
    "descriptor": "\nComments: 14 pages, 4 figures\n",
    "authors": [
      "Fathima Begum M",
      "Subhashini Narayan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2102.08185"
  },
  {
    "id": "arXiv:2103.05134",
    "title": "Constrained Learning with Non-Convex Losses",
    "abstract": "Constrained Learning with Non-Convex Losses",
    "descriptor": "",
    "authors": [
      "Luiz F. O. Chamon",
      "Santiago Paternain",
      "Miguel Calvo-Fullana",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.05134"
  },
  {
    "id": "arXiv:2103.05854",
    "title": "NegDL: Privacy-Preserving Deep Learning Based on Negative Database",
    "abstract": "NegDL: Privacy-Preserving Deep Learning Based on Negative Database",
    "descriptor": "",
    "authors": [
      "Dongdong Zhao",
      "Pingchuan Zhang",
      "Jianwen Xiang",
      "Jing Tian"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2103.05854"
  },
  {
    "id": "arXiv:2103.07449",
    "title": "Cooperative Self-training of Machine Reading Comprehension",
    "abstract": "Comments: NAACL 2022",
    "descriptor": "\nComments: NAACL 2022\n",
    "authors": [
      "Hongyin Luo",
      "Shang-Wen Li",
      "Mingye Gao",
      "Seunghak Yu",
      "James Glass"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.07449"
  },
  {
    "id": "arXiv:2103.15708",
    "title": "Dynamically Modelling Heterogeneous Higher-Order Interactions for  Malicious Behavior Detection in Event Logs",
    "abstract": "Dynamically Modelling Heterogeneous Higher-Order Interactions for  Malicious Behavior Detection in Event Logs",
    "descriptor": "",
    "authors": [
      "Corentin Larroche",
      "Johan Mazel",
      "Stephan Cl\u00e9men\u00e7on"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2103.15708"
  },
  {
    "id": "arXiv:2104.04342",
    "title": "Distributed Bayesian Online Learning for Cooperative Manipulation",
    "abstract": "Distributed Bayesian Online Learning for Cooperative Manipulation",
    "descriptor": "",
    "authors": [
      "Pablo Budde gen. Dohmann",
      "Armin Lederer",
      "Marcel Di\u00dfemond",
      "Sandra Hirche"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.04342"
  },
  {
    "id": "arXiv:2104.15022",
    "title": "Deep Image Destruction: Vulnerability of Deep Image-to-Image Models  against Adversarial Attacks",
    "abstract": "Comments: ICPR2022",
    "descriptor": "\nComments: ICPR2022\n",
    "authors": [
      "Jun-Ho Choi",
      "Huan Zhang",
      "Jun-Hyuk Kim",
      "Cho-Jui Hsieh",
      "Jong-Seok Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2104.15022"
  },
  {
    "id": "arXiv:2105.00071",
    "title": "Evaluating Attribution in Dialogue Systems: The BEGIN Benchmark",
    "abstract": "Comments: TACL, 12 pages, 9 figures, 2 tables",
    "descriptor": "\nComments: TACL, 12 pages, 9 figures, 2 tables\n",
    "authors": [
      "Nouha Dziri",
      "Hannah Rashkin",
      "Tal Linzen",
      "David Reitter"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.00071"
  },
  {
    "id": "arXiv:2105.03726",
    "title": "Mental Models of Adversarial Machine Learning",
    "abstract": "Comments: accepted at SOUPS 2022",
    "descriptor": "\nComments: accepted at SOUPS 2022\n",
    "authors": [
      "Lukas Bieringer",
      "Kathrin Grosse",
      "Michael Backes",
      "Battista Biggio",
      "Katharina Krombholz"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.03726"
  },
  {
    "id": "arXiv:2105.07289",
    "title": "A new mixed finite-element method for $H^2$ elliptic problems",
    "abstract": "A new mixed finite-element method for $H^2$ elliptic problems",
    "descriptor": "",
    "authors": [
      "Patrick E. Farrell",
      "Abdalaziz Hamdan",
      "Scott P. MacLachlan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.07289"
  },
  {
    "id": "arXiv:2105.14633",
    "title": "A learning-based projection method for model order reduction of  transport problems",
    "abstract": "Comments: 25 pages",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Zhichao Peng",
      "Min Wang",
      "Fengyan Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.14633"
  },
  {
    "id": "arXiv:2106.00135",
    "title": "Assessing the Impacts of Nonideal Communications on Distributed Optimal  Power Flow Algorithms",
    "abstract": "Comments: 11 pages with 21 figures, the paper is submitted to IEEE Transactions on Smart Grid",
    "descriptor": "\nComments: 11 pages with 21 figures, the paper is submitted to IEEE Transactions on Smart Grid\n",
    "authors": [
      "Mohannad Alkhraijah",
      "Carlos Menendez",
      "Daniel K. Molzahn"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.00135"
  },
  {
    "id": "arXiv:2106.02866",
    "title": "Conditional Contrastive Learning for Improving Fairness in  Self-Supervised Learning",
    "abstract": "Conditional Contrastive Learning for Improving Fairness in  Self-Supervised Learning",
    "descriptor": "",
    "authors": [
      "Martin Q. Ma",
      "Yao-Hung Hubert Tsai",
      "Paul Pu Liang",
      "Han Zhao",
      "Kun Zhang",
      "Ruslan Salakhutdinov",
      "Louis-Philippe Morency"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02866"
  },
  {
    "id": "arXiv:2106.03693",
    "title": "Learning by Transference: Training Graph Neural Networks on Growing  Graphs",
    "abstract": "Learning by Transference: Training Graph Neural Networks on Growing  Graphs",
    "descriptor": "",
    "authors": [
      "Juan Cervino",
      "Luana Ruiz",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.03693"
  },
  {
    "id": "arXiv:2106.06438",
    "title": "Encoding of probability distributions for Asymmetric Numeral Systems",
    "abstract": "Comments: 7 pages, 6 figures",
    "descriptor": "\nComments: 7 pages, 6 figures\n",
    "authors": [
      "Jarek Duda"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.06438"
  },
  {
    "id": "arXiv:2106.06574",
    "title": "Landscape Correspondence of Empirical and Population Risks in the  Eigendecomposition Problem",
    "abstract": "Landscape Correspondence of Empirical and Population Risks in the  Eigendecomposition Problem",
    "descriptor": "",
    "authors": [
      "Shuang Li",
      "Gongguo Tang",
      "Michael B. Wakin"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.06574"
  },
  {
    "id": "arXiv:2106.08176",
    "title": "Automated triaging of head MRI examinations using convolutional neural  networks",
    "abstract": "Comments: Accepted as an oral presentation at Medical Imaging with Deep Learning (MIDL) 2021",
    "descriptor": "\nComments: Accepted as an oral presentation at Medical Imaging with Deep Learning (MIDL) 2021\n",
    "authors": [
      "David A. Wood",
      "Sina Kafiabadi",
      "Ayisha Al Busaidi",
      "Emily Guilhem",
      "Antanas Montvila",
      "Siddharth Agarwal",
      "Jeremy Lynch",
      "Matthew Townend",
      "Gareth Barker",
      "Sebastien Ourselin",
      "James H. Cole",
      "Thomas C. Booth"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08176"
  },
  {
    "id": "arXiv:2106.11257",
    "title": "Secure Distributed Training at Scale",
    "abstract": "Comments: Accepted to International Conference on Machine Learning (ICML 2021). 61 pages, 10 figures. The version 3 improves clarity, contains more experiments and implementation details. Code: this https URL",
    "descriptor": "\nComments: Accepted to International Conference on Machine Learning (ICML 2021). 61 pages, 10 figures. The version 3 improves clarity, contains more experiments and implementation details. Code: this https URL\n",
    "authors": [
      "Eduard Gorbunov",
      "Alexander Borzunov",
      "Michael Diskin",
      "Max Ryabinin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.11257"
  },
  {
    "id": "arXiv:2106.12524",
    "title": "Learning quantum circuits of some $T$ gates",
    "abstract": "Comments: 14 pages, 7 figures. The notion $T$-rank is introduced. Lemma 13 has been modified. Several related statements are revised",
    "descriptor": "\nComments: 14 pages, 7 figures. The notion $T$-rank is introduced. Lemma 13 has been modified. Several related statements are revised\n",
    "authors": [
      "Ching-Yi Lai",
      "Hao-Chung Cheng"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.12524"
  },
  {
    "id": "arXiv:2107.08829",
    "title": "Visual Adversarial Imitation Learning using Variational Models",
    "abstract": "Visual Adversarial Imitation Learning using Variational Models",
    "descriptor": "",
    "authors": [
      "Rafael Rafailov",
      "Tianhe Yu",
      "Aravind Rajeswaran",
      "Chelsea Finn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.08829"
  },
  {
    "id": "arXiv:2107.12930",
    "title": "gaBERT -- an Irish Language Model",
    "abstract": "Comments: Proceedings of the 13th Conference on Language Resources and Evaluation (LREC 2022), pages 4774-4788, Marseille, France, 20-25 June 2022, European Language Resources Association (ELRA)",
    "descriptor": "\nComments: Proceedings of the 13th Conference on Language Resources and Evaluation (LREC 2022), pages 4774-4788, Marseille, France, 20-25 June 2022, European Language Resources Association (ELRA)\n",
    "authors": [
      "James Barry",
      "Joachim Wagner",
      "Lauren Cassidy",
      "Alan Cowap",
      "Teresa Lynn",
      "Abigail Walsh",
      "M\u00edche\u00e1l J. \u00d3 Meachair",
      "Jennifer Foster"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.12930"
  },
  {
    "id": "arXiv:2108.02299",
    "title": "Exploring D3 Implementation Challenges on Stack Overflow",
    "abstract": "Comments: Accepted as a short paper to IEEE VIS 2022",
    "descriptor": "\nComments: Accepted as a short paper to IEEE VIS 2022\n",
    "authors": [
      "Leilani Battle",
      "Danni Feng",
      "Kelli Webber"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2108.02299"
  },
  {
    "id": "arXiv:2108.03706",
    "title": "Online Bootstrap Inference For Policy Evaluation in Reinforcement  Learning",
    "abstract": "Comments: To Appear in Journal of the American Statistical Association",
    "descriptor": "\nComments: To Appear in Journal of the American Statistical Association\n",
    "authors": [
      "Pratik Ramprasad",
      "Yuantong Li",
      "Zhuoran Yang",
      "Zhaoran Wang",
      "Will Wei Sun",
      "Guang Cheng"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2108.03706"
  },
  {
    "id": "arXiv:2108.05015",
    "title": "VisEvent: Reliable Object Tracking via Collaboration of Frame and Event  Flows",
    "abstract": "Comments: In Peer Review",
    "descriptor": "\nComments: In Peer Review\n",
    "authors": [
      "Xiao Wang",
      "Jianing Li",
      "Lin Zhu",
      "Zhipeng Zhang",
      "Zhe Chen",
      "Xin Li",
      "Yaowei Wang",
      "Yonghong Tian",
      "Feng Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.05015"
  },
  {
    "id": "arXiv:2108.06096",
    "title": "SHACL: A Description Logic in Disguise",
    "abstract": "Comments: Presented at LPNRM conference 2022",
    "descriptor": "\nComments: Presented at LPNRM conference 2022\n",
    "authors": [
      "Bart Bogaerts",
      "Maxime Jakubowski",
      "Jan Van den Bussche"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2108.06096"
  },
  {
    "id": "arXiv:2108.06706",
    "title": "Temporal Action Segmentation with High-level Complex Activity Labels",
    "abstract": "Comments: 12 pages, 6 figures",
    "descriptor": "\nComments: 12 pages, 6 figures\n",
    "authors": [
      "Guodong Ding",
      "Angela Yao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.06706"
  },
  {
    "id": "arXiv:2108.07470",
    "title": "Three linear, unconditionally stable, second order decoupling methods  for the Allen--Cahn--Navier--Stokes phase field model",
    "abstract": "Comments: 24 pages, 7 figures, 3 tables",
    "descriptor": "\nComments: 24 pages, 7 figures, 3 tables\n",
    "authors": [
      "Ruonan Cao",
      "Nan Jiang",
      "Huanhuan Yang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2108.07470"
  },
  {
    "id": "arXiv:2108.10453",
    "title": "Continuous Treatment Recommendation with Deep Survival Dose Response  Function",
    "abstract": "Continuous Treatment Recommendation with Deep Survival Dose Response  Function",
    "descriptor": "",
    "authors": [
      "Jie Zhu",
      "Blanca Gallego"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)"
    ],
    "url": "https://arxiv.org/abs/2108.10453"
  },
  {
    "id": "arXiv:2109.00708",
    "title": "Efficient Algorithms For Fair Clustering with a New Fairness Notion",
    "abstract": "Comments: 41 Pages, 12 Figures, 2 Tables",
    "descriptor": "\nComments: 41 Pages, 12 Figures, 2 Tables\n",
    "authors": [
      "Shivam Gupta",
      "Ganesh Ghalme",
      "Narayanan C. Krishnan",
      "Shweta Jain"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2109.00708"
  },
  {
    "id": "arXiv:2109.01383",
    "title": "A Multi-Sensor Interface to Improve the Learning Experience in Arc  Welding Training Tasks",
    "abstract": "A Multi-Sensor Interface to Improve the Learning Experience in Arc  Welding Training Tasks",
    "descriptor": "",
    "authors": [
      "Hoi-Yin Lee",
      "Peng Zhou",
      "Anqing Duan",
      "Jiangliu Wang",
      "Victor Wu",
      "David Navarro-Alarcon"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.01383"
  },
  {
    "id": "arXiv:2109.03856",
    "title": "Local Augmentation for Graph Neural Networks",
    "abstract": "Comments: Accepted by ICML'22",
    "descriptor": "\nComments: Accepted by ICML'22\n",
    "authors": [
      "Songtao Liu",
      "Rex Ying",
      "Hanze Dong",
      "Lanqing Li",
      "Tingyang Xu",
      "Yu Rong",
      "Peilin Zhao",
      "Junzhou Huang",
      "Dinghao Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.03856"
  },
  {
    "id": "arXiv:2109.04344",
    "title": "EvilModel 2.0: Bringing Neural Network Models into Malware Attacks",
    "abstract": "Comments: A newer version of this paper has been accepted at Computers & Security. Free access to the final version at this https URL before August 16, 2022. This paper is an extended version of work that was first presented at the 26th IEEE Symposium on Computers and Communications (ISCC 2021)",
    "descriptor": "\nComments: A newer version of this paper has been accepted at Computers & Security. Free access to the final version at this https URL before August 16, 2022. This paper is an extended version of work that was first presented at the 26th IEEE Symposium on Computers and Communications (ISCC 2021)\n",
    "authors": [
      "Zhi Wang",
      "Chaoge Liu",
      "Xiang Cui",
      "Jie Yin",
      "Xutong Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.04344"
  },
  {
    "id": "arXiv:2109.05429",
    "title": "EMVLight: A Decentralized Reinforcement Learning Framework for Efficient  Passage of Emergency Vehicles",
    "abstract": "Comments: Proceedings of the 36th AAAI Conference on Artificial Intelligence (AAAI-22)",
    "descriptor": "\nComments: Proceedings of the 36th AAAI Conference on Artificial Intelligence (AAAI-22)\n",
    "authors": [
      "Haoran Su",
      "Yaofeng Desmond Zhong",
      "Biswadip Dey",
      "Amit Chakraborty"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.05429"
  },
  {
    "id": "arXiv:2109.05742",
    "title": "Domain Generalization for Medical Image Segmentation via Hierarchical  Consistency Regularization",
    "abstract": "Comments: this paper is currently not published",
    "descriptor": "\nComments: this paper is currently not published\n",
    "authors": [
      "Yijun Yang",
      "Shujun Wang",
      "Lei Zhu",
      "Pheng-Ann Heng",
      "Lequan Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.05742"
  },
  {
    "id": "arXiv:2109.09190",
    "title": "Harnessing the Power of Ego Network Layers for Link Prediction in Online  Social Networks",
    "abstract": "Comments: This work was partially funded by the following projects. European Union's Horizon 2020 research and innovation programme: SoBigData++ (No 871042), HumaneAI-Net (No 952026), MARVEL (No 957337). Italian PON-MISE program: OK-INSAID project (No ARS01 00917). CHIST-ERA program: SAI project (grant CHIST-ERA-19-XAI-010, funded by MUR, grant number not yet available). in IEEE Transactions on Computational Social Systems, 2022",
    "descriptor": "\nComments: This work was partially funded by the following projects. European Union's Horizon 2020 research and innovation programme: SoBigData++ (No 871042), HumaneAI-Net (No 952026), MARVEL (No 957337). Italian PON-MISE program: OK-INSAID project (No ARS01 00917). CHIST-ERA program: SAI project (grant CHIST-ERA-19-XAI-010, funded by MUR, grant number not yet available). in IEEE Transactions on Computational Social Systems, 2022\n",
    "authors": [
      "Mustafa Toprak",
      "Chiara Boldrini",
      "Andrea Passarella",
      "Marco Conti"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.09190"
  },
  {
    "id": "arXiv:2109.12065",
    "title": "DeepStroke: An Efficient Stroke Screening Framework for Emergency Rooms  with Multimodal Adversarial Deep Learning",
    "abstract": "DeepStroke: An Efficient Stroke Screening Framework for Emergency Rooms  with Multimodal Adversarial Deep Learning",
    "descriptor": "",
    "authors": [
      "Tongan Cai",
      "Haomiao Ni",
      "Mingli Yu",
      "Xiaolei Huang",
      "Kelvin Wong",
      "John Volpi",
      "James Z. Wang",
      "Stephen T.C. Wong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.12065"
  },
  {
    "id": "arXiv:2109.12079",
    "title": "SEED: Semantic Graph based Deep detection for type-4 clone",
    "abstract": "Comments: 18 pages",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Zhipeng Xue",
      "Zhijie Jiang",
      "Chenlin Huang",
      "Rulin Xu",
      "Xiangbing Huang",
      "Liumin Hu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2109.12079"
  },
  {
    "id": "arXiv:2109.12355",
    "title": "Suboptimal nonlinear model predictive control with input move-blocking",
    "abstract": "Comments: Added missing condition to Eq. (11); Added reference to difference inclusion (12) in Prop. 7 and Prop. 10; Removed typos;",
    "descriptor": "\nComments: Added missing condition to Eq. (11); Added reference to difference inclusion (12) in Prop. 7 and Prop. 10; Removed typos;\n",
    "authors": [
      "Artemi Makarow",
      "Christoph R\u00f6smann",
      "Torsten Bertram"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2109.12355"
  },
  {
    "id": "arXiv:2109.13099",
    "title": "Clone-based code method usage pattern mining",
    "abstract": "Comments: 5 pages, accepted by ICPC2022-ERA",
    "descriptor": "\nComments: 5 pages, accepted by ICPC2022-ERA\n",
    "authors": [
      "Zhipeng Xue",
      "Yuanliang Zhang",
      "Rulin Xu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2109.13099"
  },
  {
    "id": "arXiv:2109.14545",
    "title": "Activation Functions in Deep Learning: A Comprehensive Survey and  Benchmark",
    "abstract": "Comments: Accepted in Neurocomputing, Elsevier",
    "descriptor": "\nComments: Accepted in Neurocomputing, Elsevier\n",
    "authors": [
      "Shiv Ram Dubey",
      "Satish Kumar Singh",
      "Bidyut Baran Chaudhuri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2109.14545"
  },
  {
    "id": "arXiv:2109.14569",
    "title": "An Expert System for Redesigning Software for Cloud Applications",
    "abstract": "Comments: version 3",
    "descriptor": "\nComments: version 3\n",
    "authors": [
      "Rahul Yedida",
      "Rahul Krishna",
      "Anup Kalia",
      "Tim Menzies",
      "Jin Xiao",
      "Maja Vukovic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.14569"
  },
  {
    "id": "arXiv:2109.15233",
    "title": "Solving the Real Robot Challenge using Deep Reinforcement Learning",
    "abstract": "Comments: Published in AICS 2021 (this http URL). Paper updated to clarify procedure used to train the policy",
    "descriptor": "\nComments: Published in AICS 2021 (this http URL). Paper updated to clarify procedure used to train the policy\n",
    "authors": [
      "Robert McCarthy",
      "Francisco Roldan Sanchez",
      "Qiang Wang",
      "David Cordova Bulens",
      "Kevin McGuinness",
      "Noel O'Connor",
      "Stephen J. Redmond"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.15233"
  },
  {
    "id": "arXiv:2109.15295",
    "title": "Deciding All Behavioral Equivalences at Once: A Game for  Linear-Time--Branching-Time Spectroscopy",
    "abstract": "Comments: Extended and revised version of TACAS21-paper \"A Game for Linear-time--Branching-time Spectroscopy\"",
    "descriptor": "\nComments: Extended and revised version of TACAS21-paper \"A Game for Linear-time--Branching-time Spectroscopy\"\n",
    "authors": [
      "Benjamin Bisping",
      "David N. Jansen",
      "Uwe Nestmann"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2109.15295"
  },
  {
    "id": "arXiv:2110.00602",
    "title": "Applied Measure Theory for Probabilistic Modeling",
    "abstract": "Applied Measure Theory for Probabilistic Modeling",
    "descriptor": "",
    "authors": [
      "Chad Scherrer",
      "Moritz Schauer"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2110.00602"
  },
  {
    "id": "arXiv:2110.00855",
    "title": "SurvTRACE: Transformers for Survival Analysis with Competing Events",
    "abstract": "Comments: ACM-BCB 2022",
    "descriptor": "\nComments: ACM-BCB 2022\n",
    "authors": [
      "Zifeng Wang",
      "Jimeng Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.00855"
  },
  {
    "id": "arXiv:2110.01346",
    "title": "Clustering with Respect to the Information Distance",
    "abstract": "Comments: 12 pages; 3 figures. A version of this paper is accepted for publication in the Theoretical Computer Science journal",
    "descriptor": "\nComments: 12 pages; 3 figures. A version of this paper is accepted for publication in the Theoretical Computer Science journal\n",
    "authors": [
      "Andrei Romashchenko"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2110.01346"
  },
  {
    "id": "arXiv:2110.01925",
    "title": "Journalists' ego networks in Twitter: invariant and distinctive  structural features",
    "abstract": "Comments: This work was partially funded by the following projects. European Union's Horizon 2020 research and innovation programme: SoBigData++ (No 871042), HumaneAI-Net (No 952026), MARVEL (No 957337). Italian PON-MISE program: OK-INSAID project (No ARS01 00917). CHIST-ERA program: SAI project (grant CHIST-ERA-19-XAI-010, funded by MUR, grant number not yet available)",
    "descriptor": "\nComments: This work was partially funded by the following projects. European Union's Horizon 2020 research and innovation programme: SoBigData++ (No 871042), HumaneAI-Net (No 952026), MARVEL (No 957337). Italian PON-MISE program: OK-INSAID project (No ARS01 00917). CHIST-ERA program: SAI project (grant CHIST-ERA-19-XAI-010, funded by MUR, grant number not yet available)\n",
    "authors": [
      "Mustafa Toprak",
      "Chiara Boldrini",
      "Andrea Passarella",
      "Marco Conti"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.01925"
  },
  {
    "id": "arXiv:2110.02544",
    "title": "Learning to Iteratively Solve Routing Problems with Dual-Aspect  Collaborative Transformer",
    "abstract": "Comments: Accepted at NeurIPS 2021",
    "descriptor": "\nComments: Accepted at NeurIPS 2021\n",
    "authors": [
      "Yining Ma",
      "Jingwen Li",
      "Zhiguang Cao",
      "Wen Song",
      "Le Zhang",
      "Zhenghua Chen",
      "Jing Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.02544"
  },
  {
    "id": "arXiv:2110.05371",
    "title": "Graph-Based Machine Learning Improves Just-in-Time Defect Prediction",
    "abstract": "Comments: 18 pages, 2 figures, 2 tables; references added; expanded results to match baseline conditions",
    "descriptor": "\nComments: 18 pages, 2 figures, 2 tables; references added; expanded results to match baseline conditions\n",
    "authors": [
      "Jonathan Bryan",
      "Pablo Moriano"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.05371"
  },
  {
    "id": "arXiv:2110.08101",
    "title": "An Artificial Neural Network-Based Model Predictive Control for  Three-phase Flying Capacitor Multi-Level Inverter",
    "abstract": "Comments: This paper has been accepted for publication at IEEE Access. It has 12 pages, 22 figures, 5 tables",
    "descriptor": "\nComments: This paper has been accepted for publication at IEEE Access. It has 12 pages, 22 figures, 5 tables\n",
    "authors": [
      "Abualkasim Bakeer",
      "Ihab S. Mohamed",
      "Parisa Boodaghi Malidarreh",
      "Intissar Hattabi",
      "Lantao Liu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08101"
  },
  {
    "id": "arXiv:2110.08232",
    "title": "Fire Together Wire Together: A Dynamic Pruning Approach with  Self-Supervised Mask Prediction",
    "abstract": "Fire Together Wire Together: A Dynamic Pruning Approach with  Self-Supervised Mask Prediction",
    "descriptor": "",
    "authors": [
      "Sara Elkerdawy",
      "Mostafa Elhoushi",
      "Hong Zhang",
      "Nilanjan Ray"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08232"
  },
  {
    "id": "arXiv:2110.14763",
    "title": "Using PPP Information to Implement a Global Real-Time Virtual Network  DGNSS Approach",
    "abstract": "Comments: 14 pages, 8 tables, 4 figures, Code and data are available at this https URL",
    "descriptor": "\nComments: 14 pages, 8 tables, 4 figures, Code and data are available at this https URL\n",
    "authors": [
      "Wang Hu",
      "Ashim Neupane",
      "Jay A. Farrell"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.14763"
  },
  {
    "id": "arXiv:2110.15504",
    "title": "A Remark on Random Vectors and Irreducible Representations",
    "abstract": "A Remark on Random Vectors and Irreducible Representations",
    "descriptor": "",
    "authors": [
      "Alexander Kushkuley"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Numerical Analysis (math.NA)",
      "Representation Theory (math.RT)"
    ],
    "url": "https://arxiv.org/abs/2110.15504"
  },
  {
    "id": "arXiv:2111.01365",
    "title": "Koopman Q-learning: Offline Reinforcement Learning via Symmetries of  Dynamics",
    "abstract": "Koopman Q-learning: Offline Reinforcement Learning via Symmetries of  Dynamics",
    "descriptor": "",
    "authors": [
      "Matthias Weissenbacher",
      "Samarth Sinha",
      "Animesh Garg",
      "Yoshinobu Kawahara"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01365"
  },
  {
    "id": "arXiv:2111.02740",
    "title": "Sequential Movie Genre Prediction using Average Transition Probability  with Clustering",
    "abstract": "Comments: Published as a journal (this https URL)",
    "descriptor": "\nComments: Published as a journal (this https URL)\n",
    "authors": [
      "Jihyeon Kim",
      "Jinkyung Kim",
      "Jaeyoung Choi"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2111.02740"
  },
  {
    "id": "arXiv:2111.03629",
    "title": "Objective measurement of pitch extractors' responses to frequency  modulated sounds and two reference pitch extraction methods for analyzing  voice pitch responses to auditory stimulation",
    "abstract": "Comments: ICASSP2022 rejected this. The substantially revised version was submitted to Interspeech2022 and accepted. It is arXiv:2204.00911",
    "descriptor": "\nComments: ICASSP2022 rejected this. The substantially revised version was submitted to Interspeech2022 and accepted. It is arXiv:2204.00911\n",
    "authors": [
      "Hideki Kawahara",
      "Kohei Yatabe",
      "Ken-Ichi Sakakibara",
      "Tatsuya Kitamura",
      "Hideki Banno",
      "Masanori Morise"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Human-Computer Interaction (cs.HC)",
      "Audio and Speech Processing (eess.AS)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.03629"
  },
  {
    "id": "arXiv:2111.04904",
    "title": "Joint Neural AEC and Beamforming with Double-Talk Detection",
    "abstract": "Comments: Accepted in Interspeech 2022",
    "descriptor": "\nComments: Accepted in Interspeech 2022\n",
    "authors": [
      "Vinay Kothapally",
      "Yong Xu",
      "Meng Yu",
      "Shi-Xiong Zhang",
      "Dong Yu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.04904"
  },
  {
    "id": "arXiv:2111.05225",
    "title": "Helly systems and certificates in optimization",
    "abstract": "Helly systems and certificates in optimization",
    "descriptor": "",
    "authors": [
      "Amitabh Basu",
      "Tongtong Chen",
      "Michele Conforti",
      "Hongyi Jiang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2111.05225"
  },
  {
    "id": "arXiv:2111.07896",
    "title": "Performance bounds of adaptive MPC with bounded parameter uncertainties",
    "abstract": "Performance bounds of adaptive MPC with bounded parameter uncertainties",
    "descriptor": "",
    "authors": [
      "Francisco Moreno-Mora",
      "Lukas Beckenbach",
      "Stefan Streif"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.07896"
  },
  {
    "id": "arXiv:2111.08570",
    "title": "Tracking Blobs in the Turbulent Edge Plasma of a Tokamak Fusion Device",
    "abstract": "Comments: 13 pages, 7 figures",
    "descriptor": "\nComments: 13 pages, 7 figures\n",
    "authors": [
      "Woonghee Han",
      "Randall A. Pietersen",
      "Rafael Villamor-Lora",
      "Matthew Beveridge",
      "Nicola Offeddu",
      "Theodore Golfinopoulos",
      "Christian Theiler",
      "James L. Terry",
      "Earl S. Marmar",
      "Iddo Drori"
    ],
    "subjectives": [
      "Plasma Physics (physics.plasm-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.08570"
  },
  {
    "id": "arXiv:2111.11097",
    "title": "UMBRELLA: Uncertainty-Aware Model-Based Offline Reinforcement Learning  Leveraging Planning",
    "abstract": "Comments: Best Paper Award @ Advances in Neural Information Processing Systems - Machine Learning for Autonomous Driving Workshop (NeurIPS 2021 ML4AD)",
    "descriptor": "\nComments: Best Paper Award @ Advances in Neural Information Processing Systems - Machine Learning for Autonomous Driving Workshop (NeurIPS 2021 ML4AD)\n",
    "authors": [
      "Christopher Diehl",
      "Timo Sievernich",
      "Martin Kr\u00fcger",
      "Frank Hoffmann",
      "Torsten Bertram"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.11097"
  },
  {
    "id": "arXiv:2111.12707",
    "title": "MHFormer: Multi-Hypothesis Transformer for 3D Human Pose Estimation",
    "abstract": "Comments: Accepted by CVPR 2022. Open Sourced",
    "descriptor": "\nComments: Accepted by CVPR 2022. Open Sourced\n",
    "authors": [
      "Wenhao Li",
      "Hong Liu",
      "Hao Tang",
      "Pichao Wang",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12707"
  },
  {
    "id": "arXiv:2111.14758",
    "title": "Local convergence of alternating low-rank optimization methods with  overrelaxation",
    "abstract": "Local convergence of alternating low-rank optimization methods with  overrelaxation",
    "descriptor": "",
    "authors": [
      "Ivan V. Oseledets",
      "Maxim V. Rakhuba",
      "Andr\u00e9 Uschmajew"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.14758"
  },
  {
    "id": "arXiv:2111.15588",
    "title": "SimpleTRON: Simple Transformer with O(N) Complexity",
    "abstract": "SimpleTRON: Simple Transformer with O(N) Complexity",
    "descriptor": "",
    "authors": [
      "Uladzislau Yorsh",
      "Alexander Kovalenko",
      "Vojt\u011bch Van\u010dura",
      "Daniel Va\u0161ata",
      "Pavel Kord\u00edk",
      "Tom\u00e1\u0161 Mikolov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.15588"
  },
  {
    "id": "arXiv:2112.02265",
    "title": "\"Stop Asian Hate!\" : Refining Detection of Anti-Asian Hate Speech During  the COVID-19 Pandemic",
    "abstract": "\"Stop Asian Hate!\" : Refining Detection of Anti-Asian Hate Speech During  the COVID-19 Pandemic",
    "descriptor": "",
    "authors": [
      "Huy Nghiem",
      "Fred Morstatter"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.02265"
  },
  {
    "id": "arXiv:2112.04796",
    "title": "Detecting potentially harmful and protective suicide-related content on  twitter: A machine learning approach",
    "abstract": "Detecting potentially harmful and protective suicide-related content on  twitter: A machine learning approach",
    "descriptor": "",
    "authors": [
      "Hannah Metzler",
      "Hubert Baginski",
      "Thomas Niederkrotenthaler",
      "David Garcia"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.04796"
  },
  {
    "id": "arXiv:2112.10138",
    "title": "Anisotropic mesh adaptation for region-based segmentation accounting for  image spatial information",
    "abstract": "Comments: 41 pages, 13 figures, 5 tables",
    "descriptor": "\nComments: 41 pages, 13 figures, 5 tables\n",
    "authors": [
      "Matteo Giacomini",
      "Simona Perotto"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.10138"
  },
  {
    "id": "arXiv:2112.11487",
    "title": "On the parallel complexity of Group Isomorphism and canonization via  Weisfeiler-Leman",
    "abstract": "Comments: This is significantly different than the previous version; we thank an anonymous reviewer for pointing out errors in the previous version",
    "descriptor": "\nComments: This is significantly different than the previous version; we thank an anonymous reviewer for pointing out errors in the previous version\n",
    "authors": [
      "Joshua A. Grochow",
      "Michael Levet"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Logic in Computer Science (cs.LO)",
      "Group Theory (math.GR)"
    ],
    "url": "https://arxiv.org/abs/2112.11487"
  },
  {
    "id": "arXiv:2112.11628",
    "title": "SkipNode: On Alleviating Over-smoothing for Deep Graph Convolutional  Networks",
    "abstract": "Comments: 12 pages, 5 figures",
    "descriptor": "\nComments: 12 pages, 5 figures\n",
    "authors": [
      "Weigang Lu",
      "Yibing Zhan",
      "Ziyu Guan",
      "Liu Liu",
      "Baosheng Yu",
      "Wei Zhao",
      "Yaming Yang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.11628"
  },
  {
    "id": "arXiv:2112.12619",
    "title": "Variational Learning of Euler-Lagrange Dynamics from Data",
    "abstract": "Variational Learning of Euler-Lagrange Dynamics from Data",
    "descriptor": "",
    "authors": [
      "Sina Ober-Bl\u00f6baum",
      "Christian Offen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.12619"
  },
  {
    "id": "arXiv:2112.13834",
    "title": "What do Large Language Models Learn about Scripts?",
    "abstract": "Comments: 12 pages, 3 figures, 10 tables (including appendix), preprint",
    "descriptor": "\nComments: 12 pages, 3 figures, 10 tables (including appendix), preprint\n",
    "authors": [
      "Abhilasha Sancheti",
      "Rachel Rudinger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.13834"
  },
  {
    "id": "arXiv:2112.13979",
    "title": "Towards Transactive Energy: An Analysis of Information-related Practical  Issues",
    "abstract": "Comments: 10 pages, 2 figures",
    "descriptor": "\nComments: 10 pages, 2 figures\n",
    "authors": [
      "Yue Chen",
      "Yu Yang",
      "Xiaoyuan Xu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.13979"
  },
  {
    "id": "arXiv:2201.00150",
    "title": "Cross-Domain Deep Code Search with Few-Shot Meta Learning",
    "abstract": "Comments: Accepted by ICSE 2022 (The 44th International Conference on Software Engineering)",
    "descriptor": "\nComments: Accepted by ICSE 2022 (The 44th International Conference on Software Engineering)\n",
    "authors": [
      "Yitian Chai",
      "Hongyu Zhang",
      "Beijun Shen",
      "Xiaodong Gu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2201.00150"
  },
  {
    "id": "arXiv:2201.00976",
    "title": "Survey on the Convergence of Machine Learning and Blockchain",
    "abstract": "Survey on the Convergence of Machine Learning and Blockchain",
    "descriptor": "",
    "authors": [
      "Shengwen Ding",
      "Chenhui Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2201.00976"
  },
  {
    "id": "arXiv:2201.04600",
    "title": "Deep Symbolic Regression for Recurrent Sequences",
    "abstract": "Deep Symbolic Regression for Recurrent Sequences",
    "descriptor": "",
    "authors": [
      "St\u00e9phane d'Ascoli",
      "Pierre-Alexandre Kamienny",
      "Guillaume Lample",
      "Fran\u00e7ois Charton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.04600"
  },
  {
    "id": "arXiv:2201.06354",
    "title": "Improving the Security of the IEEE 802.15.6 Standard for Medical BANs",
    "abstract": "Comments: Published in IEEE Access",
    "descriptor": "\nComments: Published in IEEE Access\n",
    "authors": [
      "Muhammad Ali Siddiqi",
      "Georg Hahn",
      "Said Hamdioui",
      "Wouter A. Serdijn",
      "Christos Strydis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2201.06354"
  },
  {
    "id": "arXiv:2201.07322",
    "title": "Transparent Single-Cell Set Classification with Kernel Mean Embeddings",
    "abstract": "Comments: Accepted as Oral by ACM-BCB 2022. Codes are avialbe at this https URL",
    "descriptor": "\nComments: Accepted as Oral by ACM-BCB 2022. Codes are avialbe at this https URL\n",
    "authors": [
      "Siyuan Shan",
      "Vishal Baskaran",
      "Haidong Yi",
      "Jolene Ranek",
      "Natalie Stanley",
      "Junier Oliva"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2201.07322"
  },
  {
    "id": "arXiv:2201.09415",
    "title": "Sub-Block Rearranged Staircase Codes",
    "abstract": "Comments: 16 pages, 7 figures, 2 tables, accepted by IEEE Transactions on Communications",
    "descriptor": "\nComments: 16 pages, 7 figures, 2 tables, accepted by IEEE Transactions on Communications\n",
    "authors": [
      "Min Qiu",
      "Jinhong Yuan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2201.09415"
  },
  {
    "id": "arXiv:2201.09659",
    "title": "Surrogate Neural Network Model for Sensitivity Analysis and Uncertainty  Quantification of the Mechanical Behavior in the Optical Lens-Barrel Assembly",
    "abstract": "Surrogate Neural Network Model for Sensitivity Analysis and Uncertainty  Quantification of the Mechanical Behavior in the Optical Lens-Barrel Assembly",
    "descriptor": "",
    "authors": [
      "Shantanu Shahane",
      "Erman Guleryuz",
      "Diab W Abueidda",
      "Allen Lee",
      "Joe Liu",
      "Xin Yu",
      "Raymond Chiu",
      "Seid Koric",
      "Narayana R Aluru",
      "Placid M Ferreira"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2201.09659"
  },
  {
    "id": "arXiv:2201.12195",
    "title": "Measure Estimation in the Barycentric Coding Model",
    "abstract": "Comments: ICML 2022",
    "descriptor": "\nComments: ICML 2022\n",
    "authors": [
      "Matthew Werenski",
      "Ruijie Jiang",
      "Abiy Tasissa",
      "Shuchin Aeron",
      "James M. Murphy"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2201.12195"
  },
  {
    "id": "arXiv:2201.12523",
    "title": "Efficient, Out-of-Memory Sparse MTTKRP on Massively Parallel  Architectures",
    "abstract": "Comments: Accepted to ICS 2022",
    "descriptor": "\nComments: Accepted to ICS 2022\n",
    "authors": [
      "Andy Nguyen",
      "Ahmed E. Helal",
      "Fabio Checconi",
      "Jan Laukemann",
      "Jesmin Jahan Tithi",
      "Yongseok Soh",
      "Teresa Ranadive",
      "Fabrizio Petrini",
      "Jee W. Choi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2201.12523"
  },
  {
    "id": "arXiv:2201.13063",
    "title": "NeuralTailor: Reconstructing Sewing Pattern Structures from 3D Point  Clouds of Garments",
    "abstract": "Comments: Updated to the version accepted to SIGGRAPH 2022 (Journal Track)",
    "descriptor": "\nComments: Updated to the version accepted to SIGGRAPH 2022 (Journal Track)\n",
    "authors": [
      "Maria Korosteleva",
      "Sung-Hee Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2201.13063"
  },
  {
    "id": "arXiv:2202.00803",
    "title": "Discrete Dirac reduction of implicit Lagrangian systems with abelian  symmetry groups",
    "abstract": "Comments: 31 pages, 4 figures",
    "descriptor": "\nComments: 31 pages, 4 figures\n",
    "authors": [
      "\u00c1lvaro Rodr\u00edguez Abella",
      "Melvin Leok"
    ],
    "subjectives": [
      "Mathematical Physics (math-ph)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.00803"
  },
  {
    "id": "arXiv:2202.02628",
    "title": "Improved Certified Defenses against Data Poisoning with (Deterministic)  Finite Aggregation",
    "abstract": "Comments: International Conference on Machine Learning (ICML), 2022",
    "descriptor": "\nComments: International Conference on Machine Learning (ICML), 2022\n",
    "authors": [
      "Wenxiao Wang",
      "Alexander Levine",
      "Soheil Feizi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.02628"
  },
  {
    "id": "arXiv:2202.02981",
    "title": "Neural Tangent Kernel Analysis of Deep Narrow Neural Networks",
    "abstract": "Neural Tangent Kernel Analysis of Deep Narrow Neural Networks",
    "descriptor": "",
    "authors": [
      "Jongmin Lee",
      "Joo Young Choi",
      "Ernest K. Ryu",
      "Albert No"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.02981"
  },
  {
    "id": "arXiv:2202.03316",
    "title": "Bow-Tie Structures of Twitter Discursive Communities",
    "abstract": "Comments: 47 pages, 25 figures, 7 tables",
    "descriptor": "\nComments: 47 pages, 25 figures, 7 tables\n",
    "authors": [
      "Mattia Mattei",
      "Manuel Pratelli",
      "Guido Caldarelli",
      "Marinella Petrocchi",
      "Fabio Saracco"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2202.03316"
  },
  {
    "id": "arXiv:2202.03528",
    "title": "TACTiS: Transformer-Attentional Copulas for Time Series",
    "abstract": "Comments: 47 pages, 33 figures, camera-ready version, Thirty-ninth International Conference on Machine Learning (ICML 2022)",
    "descriptor": "\nComments: 47 pages, 33 figures, camera-ready version, Thirty-ninth International Conference on Machine Learning (ICML 2022)\n",
    "authors": [
      "Alexandre Drouin",
      "\u00c9tienne Marcotte",
      "Nicolas Chapados"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.03528"
  },
  {
    "id": "arXiv:2202.04365",
    "title": "AIVC: Artificial Intelligence based Video Codec",
    "abstract": "AIVC: Artificial Intelligence based Video Codec",
    "descriptor": "",
    "authors": [
      "Th\u00e9o Ladune",
      "Pierrick Philippe"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.04365"
  },
  {
    "id": "arXiv:2202.04634",
    "title": "Offline Reinforcement Learning with Realizability and Single-policy  Concentrability",
    "abstract": "Offline Reinforcement Learning with Realizability and Single-policy  Concentrability",
    "descriptor": "",
    "authors": [
      "Wenhao Zhan",
      "Baihe Huang",
      "Audrey Huang",
      "Nan Jiang",
      "Jason D. Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.04634"
  },
  {
    "id": "arXiv:2202.06503",
    "title": "Adaptive Graph Convolutional Networks for Weakly Supervised Anomaly  Detection in Videos",
    "abstract": "Adaptive Graph Convolutional Networks for Weakly Supervised Anomaly  Detection in Videos",
    "descriptor": "",
    "authors": [
      "Congqi Cao",
      "Xin Zhang",
      "Shizhou Zhang",
      "Peng Wang",
      "Yanning Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.06503"
  },
  {
    "id": "arXiv:2202.06915",
    "title": "Stochastic linear optimization never overfits with quadratically-bounded  losses on general data",
    "abstract": "Comments: Improves upon the COLT 2022 camera ready; please use the latest arXiv version!",
    "descriptor": "\nComments: Improves upon the COLT 2022 camera ready; please use the latest arXiv version!\n",
    "authors": [
      "Matus Telgarsky"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.06915"
  },
  {
    "id": "arXiv:2202.08302",
    "title": "Cost-Efficient Distributed Learning via Combinatorial Multi-Armed  Bandits",
    "abstract": "Cost-Efficient Distributed Learning via Combinatorial Multi-Armed  Bandits",
    "descriptor": "",
    "authors": [
      "Maximilian Egger",
      "Rawad Bitar",
      "Antonia Wachter-Zeh",
      "Deniz G\u00fcnd\u00fcz"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.08302"
  },
  {
    "id": "arXiv:2202.09298",
    "title": "Stratified Multivariate Multiscale Dispersion Entropy for Physiological  Signal Analysis",
    "abstract": "Stratified Multivariate Multiscale Dispersion Entropy for Physiological  Signal Analysis",
    "descriptor": "",
    "authors": [
      "Evangelos Kafantaris",
      "Tsz-Yan Milly Lo",
      "Javier Escudero"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.09298"
  },
  {
    "id": "arXiv:2202.09791",
    "title": "Contextual Semantic Embeddings for Ontology Subsumption Prediction",
    "abstract": "Comments: This article arXiv:2202.09791 should be replaced by our new version arXiv:2112.10006",
    "descriptor": "\nComments: This article arXiv:2202.09791 should be replaced by our new version arXiv:2112.10006\n",
    "authors": [
      "Jiaoyan Chen",
      "Yuan He",
      "Ernesto Jimenez-Ruiz",
      "Hang Dong",
      "Ian Horrocks"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.09791"
  },
  {
    "id": "arXiv:2202.12664",
    "title": "Automorphisms of Set Families and of Families of Cliques in an Interval  Graph in FPT Time",
    "abstract": "Automorphisms of Set Families and of Families of Cliques in an Interval  Graph in FPT Time",
    "descriptor": "",
    "authors": [
      "Deniz A\u011fao\u011flu \u00c7a\u011f\u0131r\u0131c\u0131",
      "Petr Hlin\u011bn\u00fd"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2202.12664"
  },
  {
    "id": "arXiv:2202.13341",
    "title": "Perceived Overlap: A Prerequisite for VAE Disentanglement",
    "abstract": "Comments: 16 pages, 11 figures, 4 tables",
    "descriptor": "\nComments: 16 pages, 11 figures, 4 tables\n",
    "authors": [
      "Nathan Michlo",
      "Steven James",
      "Richard Klein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.13341"
  },
  {
    "id": "arXiv:2203.00316",
    "title": "First do not fall: learning to exploit a wall with a damaged humanoid  robot",
    "abstract": "Comments: Accepted in IEEE Robotics and Automation Letters, June, 2022 Video presenting the results: this https URL",
    "descriptor": "\nComments: Accepted in IEEE Robotics and Automation Letters, June, 2022 Video presenting the results: this https URL\n",
    "authors": [
      "Timoth\u00e9e Anne",
      "Elo\u00efse Dalin",
      "Ivan Bergonzani",
      "Serena Ivaldi",
      "Jean-Baptiste Mouret"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.00316"
  },
  {
    "id": "arXiv:2203.00806",
    "title": "Dojo: A Differentiable Physics Engine for Robotics",
    "abstract": "Comments: prepared for CoRL 2022",
    "descriptor": "\nComments: prepared for CoRL 2022\n",
    "authors": [
      "Taylor A. Howell",
      "Simon Le Cleac'h",
      "J. Zico Kolter",
      "Mac Schwager",
      "Zachary Manchester"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.00806"
  },
  {
    "id": "arXiv:2203.01324",
    "title": "Exploring Smoothness and Class-Separation for Semi-supervised Medical  Image Segmentation",
    "abstract": "Comments: Accepted by MICCAI 2022",
    "descriptor": "\nComments: Accepted by MICCAI 2022\n",
    "authors": [
      "Yicheng Wu",
      "Zhonghua Wu",
      "Qianyi Wu",
      "Zongyuan Ge",
      "Jianfei Cai"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.01324"
  },
  {
    "id": "arXiv:2203.02846",
    "title": "Region Proposal Rectification Towards Robust Instance Segmentation of  Biological Images",
    "abstract": "Region Proposal Rectification Towards Robust Instance Segmentation of  Biological Images",
    "descriptor": "",
    "authors": [
      "Qilong Zhangli",
      "Jingru Yi",
      "Di Liu",
      "Xiaoxiao He",
      "Zhaoyang Xia",
      "Qi Chang",
      "Ligong Han",
      "Yunhe Gao",
      "Song Wen",
      "Haiming Tang",
      "He Wang",
      "Mu Zhou",
      "Dimitris Metaxas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.02846"
  },
  {
    "id": "arXiv:2203.02992",
    "title": "Locally checkable problems parameterized by clique-width",
    "abstract": "Locally checkable problems parameterized by clique-width",
    "descriptor": "",
    "authors": [
      "Narmina Baghirova",
      "Carolina Luc\u00eda Gonzalez",
      "Bernard Ries",
      "David Schindl"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2203.02992"
  },
  {
    "id": "arXiv:2203.03513",
    "title": "Cartoon-texture evolution for two-region image segmentation",
    "abstract": "Comments: 26 pages, 2 tables, 6 figures",
    "descriptor": "\nComments: 26 pages, 2 tables, 6 figures\n",
    "authors": [
      "Laura Antonelli",
      "Valentina De Simone",
      "Marco Viola"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03513"
  },
  {
    "id": "arXiv:2203.03635",
    "title": "Stepwise Feature Fusion: Local Guides Global",
    "abstract": "Comments: 10 pages, 5 figures",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Jinfeng Wang",
      "Qiming Huang",
      "Feilong Tang",
      "Jia Meng",
      "Jionglong Su",
      "Sifan Song"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03635"
  },
  {
    "id": "arXiv:2203.04503",
    "title": "An Energy Sharing Mechanism Considering Network Constraints and Market  Power Limitation",
    "abstract": "Comments: 23 pages, 14 figures",
    "descriptor": "\nComments: 23 pages, 14 figures\n",
    "authors": [
      "Yue Chen",
      "Changhong Zhao",
      "Steven H. Low",
      "Adam Wierman"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.04503"
  },
  {
    "id": "arXiv:2203.05744",
    "title": "Semi-constraint Optimal Transport for Entity Alignment with Dangling  Cases",
    "abstract": "Comments: A fully revised version of \"An Accurate Unsupervised Method for Joint Entity Alignment and Dangling Entity Detection\", arXiv:2203.05147",
    "descriptor": "\nComments: A fully revised version of \"An Accurate Unsupervised Method for Joint Entity Alignment and Dangling Entity Detection\", arXiv:2203.05147\n",
    "authors": [
      "Shengxuan Luo",
      "Pengyu Cheng",
      "Sheng Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.05744"
  },
  {
    "id": "arXiv:2203.06768",
    "title": "Let Users Decide: Navigating the Trade-offs between Costs and Robustness  in Algorithmic Recourse",
    "abstract": "Let Users Decide: Navigating the Trade-offs between Costs and Robustness  in Algorithmic Recourse",
    "descriptor": "",
    "authors": [
      "Martin Pawelczyk",
      "Teresa Datta",
      "Johannes van-den-Heuvel",
      "Gjergji Kasneci",
      "Himabindu Lakkaraju"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2203.06768"
  },
  {
    "id": "arXiv:2203.09454",
    "title": "Synthetic-to-Real Domain Adaptation using Contrastive Unpaired  Translation",
    "abstract": "Synthetic-to-Real Domain Adaptation using Contrastive Unpaired  Translation",
    "descriptor": "",
    "authors": [
      "Benedikt T. Imbusch",
      "Max Schwarz",
      "Sven Behnke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09454"
  },
  {
    "id": "arXiv:2203.09475",
    "title": "CaRTS: Causality-driven Robot Tool Segmentation from Vision and  Kinematics Data",
    "abstract": "Comments: Accepted to MICCAI 2022",
    "descriptor": "\nComments: Accepted to MICCAI 2022\n",
    "authors": [
      "Hao Ding",
      "Jintan Zhang",
      "Peter Kazanzides",
      "Jie Ying Wu",
      "Mathias Unberath"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09475"
  },
  {
    "id": "arXiv:2203.09862",
    "title": "Finite-sample analysis of identification of switched linear systems with  arbitrary or restricted switching",
    "abstract": "Finite-sample analysis of identification of switched linear systems with  arbitrary or restricted switching",
    "descriptor": "",
    "authors": [
      "Shengling Shi",
      "Othmane Mazhar",
      "Bart De Schutter"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.09862"
  },
  {
    "id": "arXiv:2203.12139",
    "title": "Approximate Inference for Stochastic Planning in Factored Spaces",
    "abstract": "Approximate Inference for Stochastic Planning in Factored Spaces",
    "descriptor": "",
    "authors": [
      "Zhennan Wu",
      "Roni Khardon"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2203.12139"
  },
  {
    "id": "arXiv:2203.12786",
    "title": "Bellman Residual Orthogonalization for Offline Reinforcement Learning",
    "abstract": "Comments: Revised version with further connection with the literature",
    "descriptor": "\nComments: Revised version with further connection with the literature\n",
    "authors": [
      "Andrea Zanette",
      "Martin J. Wainwright"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.12786"
  },
  {
    "id": "arXiv:2203.12937",
    "title": "SelfRemaster: Self-Supervised Speech Restoration with  Analysis-by-Synthesis Approach Using Channel Modeling",
    "abstract": "Comments: Accepted to INTERSPEECH 2022",
    "descriptor": "\nComments: Accepted to INTERSPEECH 2022\n",
    "authors": [
      "Takaaki Saeki",
      "Shinnosuke Takamichi",
      "Tomohiko Nakamura",
      "Naoko Tanji",
      "Hiroshi Saruwatari"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.12937"
  },
  {
    "id": "arXiv:2203.12940",
    "title": "mcBERT: Momentum Contrastive Learning with BERT for Zero-Shot Slot  Filling",
    "abstract": "Comments: Accepted to INTERSPEECH 2022",
    "descriptor": "\nComments: Accepted to INTERSPEECH 2022\n",
    "authors": [
      "Seong-Hwan Heo",
      "WonKee Lee",
      "Jong-Hyeok Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.12940"
  },
  {
    "id": "arXiv:2203.13339",
    "title": "Leveraging unsupervised and weakly-supervised data to improve direct  speech-to-speech translation",
    "abstract": "Comments: Interspeech 2022",
    "descriptor": "\nComments: Interspeech 2022\n",
    "authors": [
      "Ye Jia",
      "Yifan Ding",
      "Ankur Bapna",
      "Colin Cherry",
      "Yu Zhang",
      "Alexis Conneau",
      "Nobuyuki Morioka"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.13339"
  },
  {
    "id": "arXiv:2203.14822",
    "title": "Row monomial matrices and \u010cerny conjecture, short proof",
    "abstract": "Comments: Some Lemmas are not accurate",
    "descriptor": "\nComments: Some Lemmas are not accurate\n",
    "authors": [
      "A.N. Trahtman"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2203.14822"
  },
  {
    "id": "arXiv:2204.02033",
    "title": "Enhanced Neck Feature Representation for Object Detection in Aerial  Images",
    "abstract": "Comments: 5 pages, 4 figures",
    "descriptor": "\nComments: 5 pages, 4 figures\n",
    "authors": [
      "Yuchen Shen",
      "Dong Zhang",
      "Zhihao Song",
      "Xuesong Jiang",
      "Qiaolin Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02033"
  },
  {
    "id": "arXiv:2204.02320",
    "title": "Learning Generalizable Dexterous Manipulation from Human Grasp  Affordance",
    "abstract": "Comments: project page: this https URL",
    "descriptor": "\nComments: project page: this https URL\n",
    "authors": [
      "Yueh-Hua Wu",
      "Jiashun Wang",
      "Xiaolong Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.02320"
  },
  {
    "id": "arXiv:2204.06478",
    "title": "BEHM-GAN: Bandwidth Extension of Historical Music using Generative  Adversarial Networks",
    "abstract": "Comments: Accepted at IEEE Transactions on Audio, Speech, and Language Processing",
    "descriptor": "\nComments: Accepted at IEEE Transactions on Audio, Speech, and Language Processing\n",
    "authors": [
      "Eloi Moliner",
      "Vesa V\u00e4lim\u00e4ki"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2204.06478"
  },
  {
    "id": "arXiv:2204.06938",
    "title": "Flowing the Information from Shannon to Fisher: Towards the Fundamental  Tradeoff in ISAC",
    "abstract": "Comments: 3 figures, 12 pages, submitted to IEEE Globecom 2022",
    "descriptor": "\nComments: 3 figures, 12 pages, submitted to IEEE Globecom 2022\n",
    "authors": [
      "Yifeng Xiong",
      "Fan Liu",
      "Yuanhao Cui",
      "Weijie Yuan",
      "Tony Xiao Han"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.06938"
  },
  {
    "id": "arXiv:2204.07553",
    "title": "Improving Rare Word Recognition with LM-aware MWER Training",
    "abstract": "Comments: To appear in INTERSPEECH 2022",
    "descriptor": "\nComments: To appear in INTERSPEECH 2022\n",
    "authors": [
      "Weiran Wang",
      "Tongzhou Chen",
      "Tara N. Sainath",
      "Ehsan Variani",
      "Rohit Prabhavalkar",
      "Ronny Huang",
      "Bhuvana Ramabhadran",
      "Neeraj Gaur",
      "Sepand Mavandadi",
      "Cal Peyser",
      "Trevor Strohman",
      "Yanzhang He",
      "David Rybach"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.07553"
  },
  {
    "id": "arXiv:2204.08198",
    "title": "UTNLP at SemEval-2022 Task 6: A Comparative Analysis of Sarcasm  Detection Using Generative-based and Mutation-based Data Augmentation",
    "abstract": "Comments: 6 pages, 2 figures, International Workshop on Semantic Evaluation co-located with NAACL",
    "descriptor": "\nComments: 6 pages, 2 figures, International Workshop on Semantic Evaluation co-located with NAACL\n",
    "authors": [
      "Amirhossein Abaskohi",
      "Arash Rasouli",
      "Tanin Zeraati",
      "Behnam Bahrak"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.08198"
  },
  {
    "id": "arXiv:2204.08345",
    "title": "Extracting Targeted Training Data from ASR Models, and How to Mitigate  It",
    "abstract": "Comments: Accepted to appear at Interspeech'22",
    "descriptor": "\nComments: Accepted to appear at Interspeech'22\n",
    "authors": [
      "Ehsan Amid",
      "Om Thakkar",
      "Arun Narayanan",
      "Rajiv Mathews",
      "Fran\u00e7oise Beaufays"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.08345"
  },
  {
    "id": "arXiv:2204.09606",
    "title": "Detecting Unintended Memorization in Language-Model-Fused ASR",
    "abstract": "Comments: Interspeech 2022",
    "descriptor": "\nComments: Interspeech 2022\n",
    "authors": [
      "W. Ronny Huang",
      "Steve Chien",
      "Om Thakkar",
      "Rajiv Mathews"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.09606"
  },
  {
    "id": "arXiv:2204.10662",
    "title": "OPerA: Object-Centric Performance Analysis",
    "abstract": "OPerA: Object-Centric Performance Analysis",
    "descriptor": "",
    "authors": [
      "Gyunam Park",
      "Jan Niklas Adams",
      "Wil. M. P. van der Aalst"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.10662"
  },
  {
    "id": "arXiv:2204.11515",
    "title": "Multimodal Dual Emotion with Fusion of Visual Sentiment for Rumor  Detection",
    "abstract": "Multimodal Dual Emotion with Fusion of Visual Sentiment for Rumor  Detection",
    "descriptor": "",
    "authors": [
      "Ge Wang",
      "Li Tan",
      "Ziliang Shang",
      "He Liu"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.11515"
  },
  {
    "id": "arXiv:2204.12106",
    "title": "Razumikhin and Krasovskii Approaches for Safe Stabilization",
    "abstract": "Comments: 15 pages, 12 figures, accepted as Regular Paper by Automatica",
    "descriptor": "\nComments: 15 pages, 12 figures, accepted as Regular Paper by Automatica\n",
    "authors": [
      "Wei Ren",
      "Raphael M. Jungers",
      "Dimos V. Dimarogonas"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.12106"
  },
  {
    "id": "arXiv:2205.00162",
    "title": "A Novel Work-Efficient APSP Algorithm for GPUs",
    "abstract": "A Novel Work-Efficient APSP Algorithm for GPUs",
    "descriptor": "",
    "authors": [
      "Yelai Feng",
      "Huaixi Wang"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Computational Complexity (cs.CC)",
      "Networking and Internet Architecture (cs.NI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2205.00162"
  },
  {
    "id": "arXiv:2205.03530",
    "title": "Gigs with Guarantees: Achieving Fair Wage for Food Delivery Workers",
    "abstract": "Comments: Appeared in International Joint Conference on Artificial Intelligence (IJCAI) 2022",
    "descriptor": "\nComments: Appeared in International Joint Conference on Artificial Intelligence (IJCAI) 2022\n",
    "authors": [
      "Ashish Nair",
      "Rahul Yadav",
      "Anjali Gupta",
      "Abhijnan Chakraborty",
      "Sayan Ranu",
      "Amitabha Bagchi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2205.03530"
  },
  {
    "id": "arXiv:2205.03920",
    "title": "From Discovery to Production: Challenges and Novel Methodologies for  Next Generation Biomanufacturing",
    "abstract": "Comments: 15 pages, 5 figures",
    "descriptor": "\nComments: 15 pages, 5 figures\n",
    "authors": [
      "Wei Xie",
      "Giulia Pedrielli"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.03920"
  },
  {
    "id": "arXiv:2205.04066",
    "title": "Multi-level Consistency Learning for Semi-supervised Domain Adaptation",
    "abstract": "Comments: IJCAI 2022",
    "descriptor": "\nComments: IJCAI 2022\n",
    "authors": [
      "Zizheng Yan",
      "Yushuang Wu",
      "Guanbin Li",
      "Yipeng Qin",
      "Xiaoguang Han",
      "Shuguang Cui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.04066"
  },
  {
    "id": "arXiv:2205.05715",
    "title": "Causal discovery under a confounder blanket",
    "abstract": "Comments: Camera ready version (UAI 2022)",
    "descriptor": "\nComments: Camera ready version (UAI 2022)\n",
    "authors": [
      "David S. Watson",
      "Ricardo Silva"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.05715"
  },
  {
    "id": "arXiv:2205.05800",
    "title": "Stochastic first-order methods for average-reward Markov decision  processes",
    "abstract": "Stochastic first-order methods for average-reward Markov decision  processes",
    "descriptor": "",
    "authors": [
      "Tianjiao Li",
      "Feiyang Wu",
      "Guanghui Lan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.05800"
  },
  {
    "id": "arXiv:2205.07874",
    "title": "Revisiting the Updates of a Pre-trained Model for Few-shot Learning",
    "abstract": "Comments: ICML 2022 Workshop on Updatable Machine Learning; 19 pages, 11 figures, 9 tables",
    "descriptor": "\nComments: ICML 2022 Workshop on Updatable Machine Learning; 19 pages, 11 figures, 9 tables\n",
    "authors": [
      "Yujin Kim",
      "Jaehoon Oh",
      "Sungnyun Kim",
      "Se-Young Yun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.07874"
  },
  {
    "id": "arXiv:2205.09255",
    "title": "CALIPSO: A Differentiable Solver for Trajectory Optimization with Conic  and Complementarity Constraints",
    "abstract": "Comments: added appendices",
    "descriptor": "\nComments: added appendices\n",
    "authors": [
      "Taylor A. Howell",
      "Simon Le Cleac'h",
      "Kevin Tracy",
      "Zachary Manchester"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.09255"
  },
  {
    "id": "arXiv:2205.09296",
    "title": "Opinion Manipulation on Farsi Twitter",
    "abstract": "Comments: 21 pages, 9 figures, two appendices",
    "descriptor": "\nComments: 21 pages, 9 figures, two appendices\n",
    "authors": [
      "Amirhossein Farzam",
      "Parham Moradi",
      "Saeedeh Mohammadi",
      "Zahra Padar",
      "Alexandra A. Siegel"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2205.09296"
  },
  {
    "id": "arXiv:2205.09745",
    "title": "Understanding Gradient Descent on Edge of Stability in Deep Learning",
    "abstract": "Comments: This paper has been accepted for conference proceedings in the 39th International Conference on Machine Learning (ICML), 2022",
    "descriptor": "\nComments: This paper has been accepted for conference proceedings in the 39th International Conference on Machine Learning (ICML), 2022\n",
    "authors": [
      "Sanjeev Arora",
      "Zhiyuan Li",
      "Abhishek Panigrahi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2205.09745"
  },
  {
    "id": "arXiv:2205.09841",
    "title": "Subcellular Protein Localisation in the Human Protein Atlas using  Ensembles of Diverse Deep Architectures",
    "abstract": "Subcellular Protein Localisation in the Human Protein Atlas using  Ensembles of Diverse Deep Architectures",
    "descriptor": "",
    "authors": [
      "Syed Sameed Husain",
      "Eng-Jon Ong",
      "Dmitry Minskiy",
      "Mikel Bober-Irizar",
      "Amaia Irizar",
      "Miroslaw Bober"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.09841"
  },
  {
    "id": "arXiv:2205.11725",
    "title": "A Survey on Neural Open Information Extraction: Current Status and  Future Directions",
    "abstract": "Comments: Accepted by IJCAI22 survey track",
    "descriptor": "\nComments: Accepted by IJCAI22 survey track\n",
    "authors": [
      "Shaowen Zhou",
      "Bowen Yu",
      "Aixin Sun",
      "Cheng Long",
      "Jingyang Li",
      "Haiyang Yu",
      "Jian Sun",
      "Yongbin Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.11725"
  },
  {
    "id": "arXiv:2205.12468",
    "title": "Multiview Textured Mesh Recovery by Differentiable Rendering",
    "abstract": "Multiview Textured Mesh Recovery by Differentiable Rendering",
    "descriptor": "",
    "authors": [
      "Lixiang Lin",
      "Jianke Zhu",
      "Yisu Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.12468"
  },
  {
    "id": "arXiv:2205.13827",
    "title": "Error Bound of Empirical $\\ell_2$ Risk Minimization for Noisy Standard  and Generalized Phase Retrieval Problems",
    "abstract": "Comments: 44 pages, 6 figures",
    "descriptor": "\nComments: 44 pages, 6 figures\n",
    "authors": [
      "Junren Chen",
      "Michael K. Ng"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.13827"
  },
  {
    "id": "arXiv:2205.14100",
    "title": "GIT: A Generative Image-to-text Transformer for Vision and Language",
    "abstract": "GIT: A Generative Image-to-text Transformer for Vision and Language",
    "descriptor": "",
    "authors": [
      "Jianfeng Wang",
      "Zhengyuan Yang",
      "Xiaowei Hu",
      "Linjie Li",
      "Kevin Lin",
      "Zhe Gan",
      "Zicheng Liu",
      "Ce Liu",
      "Lijuan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.14100"
  },
  {
    "id": "arXiv:2205.14953",
    "title": "Multi-Agent Reinforcement Learning is a Sequence Modeling Problem",
    "abstract": "Multi-Agent Reinforcement Learning is a Sequence Modeling Problem",
    "descriptor": "",
    "authors": [
      "Muning Wen",
      "Jakub Grudzien Kuba",
      "Runji Lin",
      "Weinan Zhang",
      "Ying Wen",
      "Jun Wang",
      "Yaodong Yang"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.14953"
  },
  {
    "id": "arXiv:2206.01413",
    "title": "Impact of the composition of feature extraction and class sampling in  medicare fraud detection",
    "abstract": "Impact of the composition of feature extraction and class sampling in  medicare fraud detection",
    "descriptor": "",
    "authors": [
      "Akrity Kumari",
      "Narinder Singh Punn",
      "Sanjay Kumar Sonbhadra",
      "Sonali Agarwal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01413"
  },
  {
    "id": "arXiv:2206.01612",
    "title": "OmniXAI: A Library for Explainable AI",
    "abstract": "Comments: Wait for the Github release. The name of the library may need to be changed due to legal concerns",
    "descriptor": "\nComments: Wait for the Github release. The name of the library may need to be changed due to legal concerns\n",
    "authors": [
      "Wenzhuo Yang",
      "Hung Le",
      "Silvio Savarese",
      "Steven C.H. Hoi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01612"
  },
  {
    "id": "arXiv:2206.01731",
    "title": "Empirical Study of Quality Image Assessment for Synthesis of Fetal Head  Ultrasound Imaging with DCGANs",
    "abstract": "Empirical Study of Quality Image Assessment for Synthesis of Fetal Head  Ultrasound Imaging with DCGANs",
    "descriptor": "",
    "authors": [
      "Thea Bautista",
      "Jacqueline Matthew",
      "Hamideh Kerdegari",
      "Laura Peralta Pereira",
      "Miguel Xochicale"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.01731"
  },
  {
    "id": "arXiv:2206.05837",
    "title": "NeuralODF: Learning Omnidirectional Distance Fields for 3D Shape  Representation",
    "abstract": "NeuralODF: Learning Omnidirectional Distance Fields for 3D Shape  Representation",
    "descriptor": "",
    "authors": [
      "Trevor Houchens",
      "Cheng-You Lu",
      "Shivam Duggal",
      "Rao Fu",
      "Srinath Sridhar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.05837"
  },
  {
    "id": "arXiv:2206.05928",
    "title": "Compressive Clustering with an Optical Processing Unit",
    "abstract": "Compressive Clustering with an Optical Processing Unit",
    "descriptor": "",
    "authors": [
      "Luc Giffon",
      "R\u00e9mi Gribonval"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.05928"
  },
  {
    "id": "arXiv:2206.06043",
    "title": "Combining BMC and Fuzzing Techniques for Finding Software  Vulnerabilities in Concurrent Programs",
    "abstract": "Combining BMC and Fuzzing Techniques for Finding Software  Vulnerabilities in Concurrent Programs",
    "descriptor": "",
    "authors": [
      "Fatimah K. Aljaafari",
      "Rafael Menezes",
      "Edoardo Manino",
      "Fedor Shmarov",
      "Mustafa A. Mustafa",
      "Lucas C. Cordeiro"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.06043"
  },
  {
    "id": "arXiv:2206.06975",
    "title": "DeepTPI: Test Point Insertion with Deep Reinforcement Learning",
    "abstract": "Comments: Accepted by ITC 2022",
    "descriptor": "\nComments: Accepted by ITC 2022\n",
    "authors": [
      "Zhengyuan Shi",
      "Min Li",
      "Sadaf Khan",
      "Liuzheng Wang",
      "Naixing Wang",
      "Yu Huang",
      "Qiang Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2206.06975"
  },
  {
    "id": "arXiv:2206.07371",
    "title": "On the Stability of Modified Patankar Methods",
    "abstract": "Comments: 30 pages, 14 Figures",
    "descriptor": "\nComments: 30 pages, 14 Figures\n",
    "authors": [
      "Thomas Izgin",
      "Philipp \u00d6ffner"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.07371"
  },
  {
    "id": "arXiv:2206.08495",
    "title": "Yankee Swap: a Fast and Simple Fair Allocation Mechanism for Matroid  Rank Valuations",
    "abstract": "Yankee Swap: a Fast and Simple Fair Allocation Mechanism for Matroid  Rank Valuations",
    "descriptor": "",
    "authors": [
      "Vignesh Viswanathan",
      "Yair Zick"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.08495"
  },
  {
    "id": "arXiv:2206.09055",
    "title": "Augmented Imagefication: A Data-driven Fault Detection Method for  Aircraft Air Data Sensors",
    "abstract": "Comments: a crucial design defect to acquire flying data by simulation",
    "descriptor": "\nComments: a crucial design defect to acquire flying data by simulation\n",
    "authors": [
      "Hang Zhao",
      "Jinyi Ma",
      "Zhongzhi Li",
      "Yiqun Dong",
      "Jianliang Ai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.09055"
  },
  {
    "id": "arXiv:2206.09142",
    "title": "Redundancy Reduction Twins Network: A Training framework for  Multi-output Emotion Regression",
    "abstract": "Comments: 5 pages, accepted by ICML Exvo workshop",
    "descriptor": "\nComments: 5 pages, accepted by ICML Exvo workshop\n",
    "authors": [
      "Xin Jing",
      "Meishu Song",
      "Andreas Triantafyllopoulos",
      "Zijiang Yang",
      "Bj\u00f6rn W. Schuller"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.09142"
  },
  {
    "id": "arXiv:2206.09411",
    "title": "A Stirling-type formula for the distribution of the length of longest  increasing subsequences, applied to finite size corrections to the random  matrix limit",
    "abstract": "Comments: 24 pages, 6 figures, 3 table; simplifications in {\\S}3.2: derived kernels have finite rank; improved numerical stabilization in {\\S}3.3; associated table of exact values has been extended for up to $n=1000$",
    "descriptor": "\nComments: 24 pages, 6 figures, 3 table; simplifications in {\\S}3.2: derived kernels have finite rank; improved numerical stabilization in {\\S}3.3; associated table of exact values has been extended for up to $n=1000$\n",
    "authors": [
      "Folkmar Bornemann"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Mathematical Physics (math-ph)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2206.09411"
  },
  {
    "id": "arXiv:2206.09887",
    "title": "How to Assess Trustworthy AI in Practice",
    "abstract": "Comments: On behalf of the Z-Inspection$^{\\small{\\circledR}}$ initiative (2022)",
    "descriptor": "\nComments: On behalf of the Z-Inspection$^{\\small{\\circledR}}$ initiative (2022)\n",
    "authors": [
      "Roberto V. Zicari",
      "Julia Amann",
      "Fr\u00e9d\u00e9rick Bruneault",
      "Megan Coffee",
      "Boris D\u00fcdder",
      "Eleanore Hickman",
      "Alessio Gallucci",
      "Thomas Krendl Gilbert",
      "Thilo Hagendorff",
      "Irmhild van Halem",
      "Elisabeth Hildt",
      "Sune Holm",
      "Georgios Kararigas",
      "Pedro Kringen",
      "Vince I. Madai",
      "Emilie Wiinblad Mathez",
      "Jesmin Jahan Tithi",
      "Dennis Vetter",
      "Magnus Westerlund",
      "Renee Wurth"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.09887"
  },
  {
    "id": "arXiv:2206.09961",
    "title": "Critical Investigation of Failure Modes in Physics-informed Neural  Networks",
    "abstract": "Critical Investigation of Failure Modes in Physics-informed Neural  Networks",
    "descriptor": "",
    "authors": [
      "Shamsulhaq Basir",
      "Inanc Senocak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.09961"
  },
  {
    "id": "arXiv:2206.10049",
    "title": "The Capacity of 3 User Linear Computation Broadcast",
    "abstract": "The Capacity of 3 User Linear Computation Broadcast",
    "descriptor": "",
    "authors": [
      "Yuhang Yao",
      "Syed A. Jafar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.10049"
  },
  {
    "id": "arXiv:2206.10477",
    "title": "Survival Kernets: Scalable and Interpretable Deep Kernel Survival  Analysis with an Accuracy Guarantee",
    "abstract": "Comments: Added reference to Zhong et al. 2022",
    "descriptor": "\nComments: Added reference to Zhong et al. 2022\n",
    "authors": [
      "George H. Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.10477"
  },
  {
    "id": "arXiv:2206.11017",
    "title": "Object Type Clustering using Markov Directly-Follow Multigraph in  Object-Centric Process Mining",
    "abstract": "Object Type Clustering using Markov Directly-Follow Multigraph in  Object-Centric Process Mining",
    "descriptor": "",
    "authors": [
      "Amin Jalali"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.11017"
  },
  {
    "id": "arXiv:2206.11049",
    "title": "Dynamic Restrained Uncertainty Weighting Loss for Multitask Learning of  Vocal Expression",
    "abstract": "Comments: 5 pages",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Meishu Song",
      "Zijiang Yang",
      "Andreas Triantafyllopoulos",
      "Xin Jing",
      "Vincent Karas",
      "Xie Jiangjian",
      "Zixing Zhang",
      "Yamamoto Yoshiharu",
      "Bjoern W. Schuller"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.11049"
  },
  {
    "id": "arXiv:2206.11078",
    "title": "Traffic-Twitter Transformer: A Nature Language Processing-joined  Framework For Network-wide Traffic Forecasting",
    "abstract": "Traffic-Twitter Transformer: A Nature Language Processing-joined  Framework For Network-wide Traffic Forecasting",
    "descriptor": "",
    "authors": [
      "Meng-Ju Tsai",
      "Zhiyong Cui",
      "Hao Yang",
      "Yinhai Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.11078"
  },
  {
    "id": "arXiv:2206.11168",
    "title": "Ordered Subgraph Aggregation Networks",
    "abstract": "Comments: Fixed link to code repository",
    "descriptor": "\nComments: Fixed link to code repository\n",
    "authors": [
      "Chendi Qian",
      "Gaurav Rattan",
      "Floris Geerts",
      "Christopher Morris",
      "Mathias Niepert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.11168"
  },
  {
    "id": "arXiv:2206.11339",
    "title": "Precipitation event-based networks: an analysis of the relations between  network metrics and meteorological properties",
    "abstract": "Comments: 5 pages, 2 figures",
    "descriptor": "\nComments: 5 pages, 2 figures\n",
    "authors": [
      "Aurelienne A. S. Jorge",
      "Douglas Uba",
      "Alex A. Fernandes",
      "Izabelly C. Costa",
      "Leonardo B. L. Santos"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.11339"
  },
  {
    "id": "arXiv:2206.11357",
    "title": "GACT: Activation Compressed Training for General Architectures",
    "abstract": "GACT: Activation Compressed Training for General Architectures",
    "descriptor": "",
    "authors": [
      "Xiaoxuan Liu",
      "Lianmin Zheng",
      "Dequan Wang",
      "Yukuo Cen",
      "Weize Chen",
      "Xu Han",
      "Jianfei Chen",
      "Zhiyuan Liu",
      "Jie Tang",
      "Joey Gonzalez",
      "Michael Mahoney",
      "Alvin Cheung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.11357"
  },
  {
    "id": "arXiv:2206.11723",
    "title": "Self-Supervised Training with Autoencoders for Visual Anomaly Detection",
    "abstract": "Self-Supervised Training with Autoencoders for Visual Anomaly Detection",
    "descriptor": "",
    "authors": [
      "Alexander Bauer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.11723"
  },
  {
    "id": "arXiv:2206.11810",
    "title": "Inductive Conformal Prediction: A Straightforward Introduction with  Examples in Python",
    "abstract": "Comments: 6 pages, 11 figures, tutorial",
    "descriptor": "\nComments: 6 pages, 11 figures, tutorial\n",
    "authors": [
      "Martim Sousa"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.11810"
  },
  {
    "id": "arXiv:2206.11892",
    "title": "DDPM-CD: Remote Sensing Change Detection using Denoising Diffusion  Probabilistic Models",
    "abstract": "Comments: Code available at: this https URL",
    "descriptor": "\nComments: Code available at: this https URL\n",
    "authors": [
      "Wele Gedara Chaminda Bandara",
      "Nithin Gopalakrishnan Nair",
      "Vishal M. Patel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.11892"
  },
  {
    "id": "arXiv:2206.11992",
    "title": "The LBNL Superfacility Project Report",
    "abstract": "Comments: 85 pages, 23 figures",
    "descriptor": "\nComments: 85 pages, 23 figures\n",
    "authors": [
      "Deborah Bard",
      "Cory Snavely",
      "Lisa Gerhardt",
      "Jason Lee",
      "Becci Totzke",
      "Katie Antypas",
      "William Arndt",
      "Johannes Blaschke",
      "Suren Byna",
      "Ravi Cheema",
      "Shreyas Cholia",
      "Mark Day",
      "Bjoern Enders",
      "Aditi Gaur",
      "Annette Greiner",
      "Taylor Groves",
      "Mariam Kiran",
      "Quincey Koziol",
      "Tom Lehman",
      "Kelly Rowland",
      "Chris Samuel",
      "Ashwin Selvarajan",
      "Alex Sim",
      "David Skinner",
      "Laurie Stephey",
      "Rollin Thomas",
      "Gabor Torok"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.11992"
  },
  {
    "id": "arXiv:2206.12236",
    "title": "Multi-relational Instruction Association Graph for Cross-architecture  Binary Similarity Comparison",
    "abstract": "Comments: Accepted by EAI SecureComm 2022, 20 pages, 3 figures",
    "descriptor": "\nComments: Accepted by EAI SecureComm 2022, 20 pages, 3 figures\n",
    "authors": [
      "Qige Song",
      "Yongzheng Zhang",
      "Shuhao Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.12236"
  },
  {
    "id": "arXiv:2206.12401",
    "title": "Debiasing Learning for Membership Inference Attacks Against Recommender  Systems",
    "abstract": "Comments: Accepted by KDD 2022",
    "descriptor": "\nComments: Accepted by KDD 2022\n",
    "authors": [
      "Zihan Wang",
      "Na Huang",
      "Fei Sun",
      "Pengjie Ren",
      "Zhumin Chen",
      "Hengliang Luo",
      "Maarten de Rijke",
      "Zhaochun Ren"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.12401"
  },
  {
    "id": "arXiv:2206.12520",
    "title": "Learning to learn online with neuromodulated synaptic plasticity in  spiking neural networks",
    "abstract": "Learning to learn online with neuromodulated synaptic plasticity in  spiking neural networks",
    "descriptor": "",
    "authors": [
      "Samuel Schmidgall",
      "Joe Hays"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.12520"
  },
  {
    "id": "arXiv:2206.12531",
    "title": "Maximum independent set (stable set) problem: A mathematical programming  model with valid inequalities and computational testing",
    "abstract": "Comments: Corrected a few typos in the previous version",
    "descriptor": "\nComments: Corrected a few typos in the previous version\n",
    "authors": [
      "Prabhu Manyem"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.12531"
  },
  {
    "id": "arXiv:2206.12663",
    "title": "Statistical inference with implicit SGD: proximal Robbins-Monro vs.  Polyak-Ruppert",
    "abstract": "Comments: Accepted to the 39 th International Conference on Machine Learning. This version contains corrections to typos found after submitting the camera-ready version",
    "descriptor": "\nComments: Accepted to the 39 th International Conference on Machine Learning. This version contains corrections to typos found after submitting the camera-ready version\n",
    "authors": [
      "Yoonhyung Lee",
      "Sungdong Lee",
      "Joong-Ho Won"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2206.12663"
  },
  {
    "id": "arXiv:2206.12680",
    "title": "Topology-aware Generalization of Decentralized SGD",
    "abstract": "Comments: Accepted for publication in ICML 2022",
    "descriptor": "\nComments: Accepted for publication in ICML 2022\n",
    "authors": [
      "Tongtian Zhu",
      "Fengxiang He",
      "Lan Zhang",
      "Zhengyang Niu",
      "Mingli Song",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.12680"
  },
  {
    "id": "arXiv:2206.12755",
    "title": "Training Your Sparse Neural Network Better with Any Mask",
    "abstract": "Comments: Accepted by ICML 2022",
    "descriptor": "\nComments: Accepted by ICML 2022\n",
    "authors": [
      "Ajay Jaiswal",
      "Haoyu Ma",
      "Tianlong Chen",
      "Ying Ding",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.12755"
  },
  {
    "id": "arXiv:2206.12869",
    "title": "Image Aesthetics Assessment Using Graph Attention Network",
    "abstract": "Comments: International Conference on Pattern Recognition (ICPR), 2022",
    "descriptor": "\nComments: International Conference on Pattern Recognition (ICPR), 2022\n",
    "authors": [
      "Koustav Ghosal",
      "Aljosa Smolic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.12869"
  },
  {
    "id": "arXiv:2206.13042",
    "title": "A Strategy Optimized Pix2pix Approach for SAR-to-Optical Image  Translation Task",
    "abstract": "A Strategy Optimized Pix2pix Approach for SAR-to-Optical Image  Translation Task",
    "descriptor": "",
    "authors": [
      "Fujian Cheng",
      "Yashu Kang",
      "Chunlei Chen",
      "Kezhao Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.13042"
  },
  {
    "id": "arXiv:2206.13238",
    "title": "SR-DEM: an efficient discrete element method framework for particles  with surface of revolution",
    "abstract": "SR-DEM: an efficient discrete element method framework for particles  with surface of revolution",
    "descriptor": "",
    "authors": [
      "Fei-Liang Yuan",
      "Martin Sommerfeld",
      "Berend van Wachem"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2206.13238"
  },
  {
    "id": "arXiv:2206.13280",
    "title": "Expressive power of binary and ternary neural networks",
    "abstract": "Expressive power of binary and ternary neural networks",
    "descriptor": "",
    "authors": [
      "Aleksandr Beknazaryan"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.13280"
  },
  {
    "id": "arXiv:2206.13318",
    "title": "Key-frame Guided Network for Thyroid Nodule Recognition using Ultrasound  Videos",
    "abstract": "Key-frame Guided Network for Thyroid Nodule Recognition using Ultrasound  Videos",
    "descriptor": "",
    "authors": [
      "Yuchen Wang",
      "Zhongyu Li",
      "Xiangxiang Cui",
      "Liangliang Zhang",
      "Xiang Luo",
      "Meng Yang",
      "Shi Chang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.13318"
  },
  {
    "id": "arXiv:2206.13348",
    "title": "A Novel Unified Self-alignment Method of SINS Based on FGO",
    "abstract": "Comments: 9 pages, Journal Papers",
    "descriptor": "\nComments: 9 pages, Journal Papers\n",
    "authors": [
      "Hanwen Zhou",
      "Xiufen Ye"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.13348"
  },
  {
    "id": "arXiv:2206.13404",
    "title": "Avocodo: Generative Adversarial Network for Artifact-free Vocoder",
    "abstract": "Avocodo: Generative Adversarial Network for Artifact-free Vocoder",
    "descriptor": "",
    "authors": [
      "Taejun Bak",
      "Junmo Lee",
      "Hanbin Bae",
      "Jinhyeok Yang",
      "Jae-Sung Bae",
      "Young-Sun Joo"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2206.13404"
  },
  {
    "id": "arXiv:2206.13424",
    "title": "Benchopt: Reproducible, efficient and collaborative optimization  benchmarks",
    "abstract": "Benchopt: Reproducible, efficient and collaborative optimization  benchmarks",
    "descriptor": "",
    "authors": [
      "Thomas Moreau",
      "Mathurin Massias",
      "Alexandre Gramfort",
      "Pierre Ablin",
      "Pierre-Antoine Bannier",
      "Benjamin Charlier",
      "Mathieu Dagr\u00e9ou",
      "Tom Dupr\u00e9 la Tour",
      "Ghislain Durif",
      "Cassio F. Dantas",
      "Quentin Klopfenstein",
      "Johan Larsson",
      "En Lai",
      "Tanguy Lefort",
      "Benoit Mal\u00e9zieux",
      "Badr Moufad",
      "Binh T. Nguyen",
      "Alain Rakotomamonjy",
      "Zaccharie Ramzi",
      "Joseph Salmon",
      "Samuel Vaiter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.13424"
  },
  {
    "id": "arXiv:2206.13441",
    "title": "EMVLight: a Multi-agent Reinforcement Learning Framework for an  Emergency Vehicle Decentralized Routing and Traffic Signal Control System",
    "abstract": "Comments: 19 figures, 10 tables. Manuscript extended on previous work arXiv:2109.05429, arXiv:2111.00278",
    "descriptor": "\nComments: 19 figures, 10 tables. Manuscript extended on previous work arXiv:2109.05429, arXiv:2111.00278\n",
    "authors": [
      "Haoran Su",
      "Yaofeng D. Zhong",
      "Joseph Y.J. Chow",
      "Biswadip Dey",
      "Li Jin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.13441"
  },
  {
    "id": "arXiv:2206.13503",
    "title": "On the Importance of Application-Grounded Experimental Design for  Evaluating Explainable ML Methods",
    "abstract": "On the Importance of Application-Grounded Experimental Design for  Evaluating Explainable ML Methods",
    "descriptor": "",
    "authors": [
      "Kasun Amarasinghe",
      "Kit T. Rodolfa",
      "S\u00e9rgio Jesus",
      "Valerie Chen",
      "Vladimir Balayan",
      "Pedro Saleiro",
      "Pedro Bizarro",
      "Ameet Talwalkar",
      "Rayid Ghani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.13503"
  }
]
[
  {
    "id": "arXiv:2206.01725",
    "title": "Sentences as connection paths: A neural language architecture of  sentence structure in the brain",
    "abstract": "This article presents a neural language architecture of sentence structure in\nthe brain, in which sentences are temporal connection paths that interconnect\nneural structures underlying their words. Words remain 'in-situ', hence they\nare always content-addressable. Arbitrary and novel sentences (with novel\nwords) can be created with 'neural blackboards' for words and sentences. Hence,\nthe unlimited productivity of natural language can be achieved with a 'fixed'\nsmall world like network structure. The article focuses on the neural\nblackboard for sentences. The architecture uses only one 'connection matrix'\nfor binding all structural relations between words in sentences. Its ability to\nrepresent arbitrary (English) sentences is discussed in detail, based on a\ncomprehensive analysis of them. The architecture simulates intra-cranial brain\nactivity observed during sentence processing and fMRI observations related to\nsentence complexity and ambiguity. The simulations indicate that the observed\neffects relate to global control over the architecture, not to the sentence\nstructures involved, which predicts higher activity differences related to\ncomplexity and ambiguity with higher comprehension capacity. Other aspects\ndiscussed are the 'intrinsic' sentence structures provided by connection paths\nand their relation to scope and inflection, the use of a dependency parser for\ncontrol of binding, long-distance dependencies and gaps, question answering,\nambiguity resolution based on backward processing without explicit\nbacktracking, garden paths, and performance difficulties related to embeddings.",
    "descriptor": "\nComments: 14 pages, 5 figures article; 60 pages, 28 figures supplementary information\n",
    "authors": [
      "Frank van der Velde"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2206.01725"
  },
  {
    "id": "arXiv:2206.01726",
    "title": "Average-case analysis of the Gaussian Elimination with Partial Pivoting",
    "abstract": "The Gaussian Elimination with Partial Pivoting (GEPP) is a classical\nalgorithm for solving systems of linear equations. Although in specific cases\nthe loss of precision in GEPP due to roundoff errors can be very significant,\nempirical evidence strongly suggests that for a {\\it typical} square\ncoefficient matrix, GEPP is numerically stable. We obtain a (partial)\ntheoretical justification of this phenomenon by showing that, given the random\n$n\\times n$ standard Gaussian coefficient matrix $A$, the {\\it growth factor}\nof the Gaussian Elimination with Partial Pivoting is at most polynomially large\nin $n$ with probability close to one. This implies that with probability close\nto one the number of bits of precision sufficient to solve $Ax = b$ to $m$ bits\nof accuracy using GEPP is $m+O(\\log n)$, which improves an earlier estimate\n$m+O(\\log^2 n)$ of Sankar, and which we conjecture to be optimal by the order\nof magnitude. We further provide tail estimates of the growth factor which can\nbe used to support the empirical observation that GEPP is more stable than the\nGaussian Elimination with no pivoting.",
    "descriptor": "",
    "authors": [
      "Han Huang",
      "Konstantin Tikhomirov"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2206.01726"
  },
  {
    "id": "arXiv:2206.01727",
    "title": "New Progress in Classic Area: Polynomial Root-squaring and Root-finding",
    "abstract": "The DLG root-squaring iterations by Dandelin 1826, Lobachevsky 1834, and\nGraeffe 1837 have been the main approach to root-finding for a univariate\npolynomial p(x) in the 19th century and beyond, but not so nowadays because of\nsevere numerical instability of these iterations. We circumvent this problem\nbased on simple but novel links of the iterations at first to the evaluation of\nhigh order derivatives of the ratio p'(x)/p(x) at x=0 and then further to\ncomputing the power sums of the reciprocals of the roots of p(x). By expressing\nthe power sums as Cauchy integrals over a sufficiently large circle on a\ncomplex plane, we devise fast and numerically stable algorithms for the DLG\niterations and for their more recent extension to Fiedler-Gemignani's\niterations. Our algorithms can be applied to a black box polynomial p(x) --\ngiven by a black box for its evaluation rather than by its coefficients, which\nenables important computational benefits, including efficient recursive as well\nas concurrent approximation of a selected set of the zeros of p(x) or even all\nof the zeros.",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Victor Y. Pan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.01727"
  },
  {
    "id": "arXiv:2206.01730",
    "title": "Nonsmooth automatic differentiation: a cheap gradient principle and  other complexity results",
    "abstract": "We provide a simple model to estimate the computational costs of the backward\nand forward modes of algorithmic differentiation for a wide class of nonsmooth\nprograms. Prominent examples are the famous relu and convolutional neural\nnetworks together with their standard loss functions. Using the recent notion\nof conservative gradients, we then establish a \"nonsmooth cheap gradient\nprinciple\" for backpropagation encompassing most concrete applications.\nNonsmooth backpropagation's cheapness contrasts with concurrent forward\napproaches which have, at this day, dimensional-dependent worst case estimates.\nIn order to understand this class of methods, we relate the complexity of\ncomputing a large number of directional derivatives to that of matrix\nmultiplication. This shows a fundamental limitation for improving forward AD\nfor that task. Finally, while the fastest algorithms for computing a Clarke\nsubgradient are linear in the dimension, it appears that computing two distinct\nClarke (resp. lexicographic) subgradients for simple neural networks is\nNP-Hard.",
    "descriptor": "",
    "authors": [
      "J\u00e9r\u00f4me Bolte",
      "Ryan Boustany",
      "Edouard Pauwels",
      "B\u00e9atrice Pesquet-Popescu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.01730"
  },
  {
    "id": "arXiv:2206.01733",
    "title": "Adversarial RAW: Image-Scaling Attack Against Imaging Pipeline",
    "abstract": "Deep learning technologies have become the backbone for the development of\ncomputer vision. With further explorations, deep neural networks have been\nfound vulnerable to well-designed adversarial attacks. Most of the vision\ndevices are equipped with image signal processing (ISP) pipeline to implement\nRAW-to-RGB transformations and embedded into data preprocessing module for\nefficient image processing. Actually, ISP pipeline can introduce adversarial\nbehaviors to post-capture images while data preprocessing may destroy attack\npatterns. However, none of the existing adversarial attacks takes into account\nthe impacts of both ISP pipeline and data preprocessing. In this paper, we\ndevelop an image-scaling attack targeting on ISP pipeline, where the crafted\nadversarial RAW can be transformed into attack image that presents entirely\ndifferent appearance once being scaled to a specific-size image. We first\nconsider the gradient-available ISP pipeline, i.e., the gradient information\ncan be directly used in the generation process of adversarial RAW to launch the\nattack. To make the adversarial attack more applicable, we further consider the\ngradient-unavailable ISP pipeline, in which a proxy model that well learns the\nRAW-to-RGB transformations is proposed as the gradient oracles. Extensive\nexperiments show that the proposed adversarial attacks can craft adversarial\nRAW data against the target ISP pipelines with high attack rates.",
    "descriptor": "",
    "authors": [
      "Junjian Li",
      "Honglong Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.01733"
  },
  {
    "id": "arXiv:2206.01734",
    "title": "Using UAS Imagery and Computer Vision to Support Site-Specific Weed  Control in Corn",
    "abstract": "Currently, weed control in a corn field is performed by a blanket application\nof herbicides that do not consider spatial distribution information of weeds\nand also uses an extensive amount of chemical herbicides. To reduce the amount\nof chemicals, we used drone-based high-resolution imagery and computer-vision\ntechniques to perform site-specific weed control in corn.",
    "descriptor": "\nComments: 16 Figures, 3 Tables,. arXiv admin note: substantial text overlap with arXiv:2204.12417\n",
    "authors": [
      "Ranjan Sapkota",
      "Paulo Flores"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.01734"
  },
  {
    "id": "arXiv:2206.01748",
    "title": "Federated Deep Learning Meets Autonomous Vehicle Perception: Design and  Verification",
    "abstract": "Realizing human-like perception is a challenge in open driving scenarios due\nto corner cases and visual occlusions. To gather knowledge of rare and occluded\ninstances, federated learning empowered connected autonomous vehicle (FLCAV)\nhas been proposed, which leverages vehicular networks to establish federated\ndeep neural networks (DNNs) from distributed data captured by vehicles and road\nsensors. Without the need of data aggregation, FLCAV preserves privacy while\nreducing communication and annotation costs compared with conventional\ncentralized learning. However, it is challenging to determine the network\nresources and road sensor poses for multi-stage training with multi-modal\ndatasets in multi-variant scenarios. This article presents networking and\ntraining frameworks for FLCAV perception. Multi-layer graph resource allocation\nand vehicle-road pose contrastive methods are proposed to address the network\nmanagement and sensor pose problems, respectively. We also develop CarlaFLCAV,\na software platform that implements the above system and methods. Experimental\nresults confirm the superiority of the proposed techniques compared with\nvarious benchmarks.",
    "descriptor": "\nComments: 9 pages, 5 figures, submitted to IEEE for possible publication\n",
    "authors": [
      "Shuai Wang",
      "Chengyang Li",
      "Qi Hao",
      "Chengzhong Xu",
      "Derrick Wing Kwan Ng",
      "Yonina C. Eldar",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01748"
  },
  {
    "id": "arXiv:2206.01749",
    "title": "Uncertainty Estimation in Machine Learning",
    "abstract": "Most machine learning techniques are based upon statistical learning theory,\noften simplified for the sake of computing speed. This paper is focused on the\nuncertainty aspect of mathematical modeling in machine learning. Regression\nanalysis is chosen to further investigate the evaluation aspect of uncertainty\nin model coefficients and, more importantly, in the output feature value\npredictions. A survey demonstrates major stages in the conventional least\nsquares approach to the creation of the regression model, along with its\nuncertainty estimation. On the other hand, it is shown that in machine learning\nthe model complexity and severe nonlinearity become serious obstacles to\nuncertainty evaluation. Furthermore, the process of machine model training\ndemands high computing power, not available at the level of personal computers.\nThis is why so-called pre-trained models are widely used in such areas of\nmachine learning as natural language processing. The latest example of a\npre-trained model is the Generative Pre-trained Transformer 3 with hundreds of\nbillions of parameters and a half-terabyte training dataset. Similarly,\nmathematical models built from real data are growing in complexity which is\naccompanied by the growing amount of training data. However, when machine\nmodels and their predictions are used in decision-making, one needs to estimate\nuncertainty and evaluate accompanying risks. This problem could be resolved\nwith non-parametric techniques at the expense of greater demand for computing\npower, which can be offered by modern supercomputers available, including those\nutilizing graphical and tensor processing units along with the conventional\ncentral processors.",
    "descriptor": "\nComments: 5 pages, 6 figures\n",
    "authors": [
      "Valentin Arkov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.01749"
  },
  {
    "id": "arXiv:2206.01767",
    "title": "[Re] Badder Seeds: Reproducing the Evaluation of Lexical Methods for  Bias Measurement",
    "abstract": "Combating bias in NLP requires bias measurement. Bias measurement is almost\nalways achieved by using lexicons of seed terms, i.e. sets of words specifying\nstereotypes or dimensions of interest. This reproducibility study focuses on\nthe original authors' main claim that the rationale for the construction of\nthese lexicons needs thorough checking before usage, as the seeds used for bias\nmeasurement can themselves exhibit biases. The study aims to evaluate the\nreproducibility of the quantitative and qualitative results presented in the\npaper and the conclusions drawn thereof. We reproduce most of the results\nsupporting the original authors' general claim: seed sets often suffer from\nbiases that affect their performance as a baseline for bias metrics. Generally,\nour results mirror the original paper's. They are slightly different on select\noccasions, but not in ways that undermine the paper's general intent to show\nthe fragility of seed sets.",
    "descriptor": "\nComments: 15 pages, 7 figures\n",
    "authors": [
      "Jille van der Togt",
      "Lea Tiyavorabun",
      "Matteo Rosati",
      "Giulio Starace"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.01767"
  },
  {
    "id": "arXiv:2206.01772",
    "title": "Radar Guided Dynamic Visual Attention for Resource-Efficient RGB Object  Detection",
    "abstract": "An autonomous system's perception engine must provide an accurate\nunderstanding of the environment for it to make decisions. Deep learning based\nobject detection networks experience degradation in the performance and\nrobustness for small and far away objects due to a reduction in object's\nfeature map as we move to higher layers of the network. In this work, we\npropose a novel radar-guided spatial attention for RGB images to improve the\nperception quality of autonomous vehicles operating in a dynamic environment.\nIn particular, our method improves the perception of small and long range\nobjects, which are often not detected by the object detectors in RGB mode. The\nproposed method consists of two RGB object detectors, namely the Primary\ndetector and a lightweight Secondary detector. The primary detector takes a\nfull RGB image and generates primary detections. Next, the radar proposal\nframework creates regions of interest (ROIs) for object proposals by projecting\nthe radar point cloud onto the 2D RGB image. These ROIs are cropped and fed to\nthe secondary detector to generate secondary detections which are then fused\nwith the primary detections via non-maximum suppression. This method helps in\nrecovering the small objects by preserving the object's spatial features\nthrough an increase in their receptive field. We evaluate our fusion method on\nthe challenging nuScenes dataset and show that our fusion method with SSD-lite\nas primary and secondary detector improves the baseline primary yolov3\ndetector's recall by 14% while requiring three times fewer computational\nresources.",
    "descriptor": "\nComments: Accepted in International Joint Conference on Neural Networks (IJCNN) 2022\n",
    "authors": [
      "Hemant Kumawat",
      "Saibal Mukhopadhyay"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.01772"
  },
  {
    "id": "arXiv:2206.01775",
    "title": "Seamless Interaction Design with Coexistence and Cooperation Modes for  Robust Human-Robot Collaboration",
    "abstract": "A robot needs multiple interaction modes to robustly collaborate with a human\nin complicated industrial tasks. We develop a Coexistence-and-Cooperation\n(CoCo) human-robot collaboration system. Coexistence mode enables the robot to\nwork with the human on different sub-tasks independently in a shared space.\nCooperation mode enables the robot to follow human guidance and recover\nfailures. A human intention tracking algorithm takes in both human and robot\nmotion measurements as input and provides a switch on the interaction modes. We\ndemonstrate the effectiveness of CoCo system in a use case analogous to a real\nworld multi-step assembly task.",
    "descriptor": "\nComments: Accepted by CASE 2022 Workshop on Adaptive and Resilient Cyber-Physical Manufacturing Networks\n",
    "authors": [
      "Zhe Huang",
      "Ye-Ji Mun",
      "Xiang Li",
      "Yiqing Xie",
      "Ninghan Zhong",
      "Weihang Liang",
      "Junyi Geng",
      "Tan Chen",
      "Katherine Driggs-Campbell"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.01775"
  },
  {
    "id": "arXiv:2206.01776",
    "title": "Properties of a Ternary Infinite Word",
    "abstract": "We study the properties of the ternary infinite word p =\n012102101021012101021012 ... , that is, the fixed point of the map h:0->01,\n1->21, 2->0. We determine its factor complexity, critical exponent, and prove\nthat it is 2-balanced. We compute its abelian complexity and determine the\nlengths of its bispecial factors. Finally, we give a characterization of p in\nterms of avoided factors.",
    "descriptor": "",
    "authors": [
      "James Currie",
      "Pascal Ochem",
      "Narad Rampersad",
      "Jeffrey Shallit"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Combinatorics (math.CO)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.01776"
  },
  {
    "id": "arXiv:2206.01777",
    "title": "Real-Time Super-Resolution for Real-World Images on Mobile Devices",
    "abstract": "Image Super-Resolution (ISR), which aims at recovering High-Resolution (HR)\nimages from the corresponding Low-Resolution (LR) counterparts. Although recent\nprogress in ISR has been remarkable. However, they are way too computationally\nintensive to be deployed on edge devices, since most of the recent approaches\nare deep learning-based. Besides, these methods always fail in real-world\nscenes, since most of them adopt a simple fixed \"ideal\" bicubic downsampling\nkernel from high-quality images to construct LR/HR training pairs which may\nlose track of frequency-related details. In this work, an approach for\nreal-time ISR on mobile devices is presented, which is able to deal with a wide\nrange of degradations in real-world scenarios. Extensive experiments on\ntraditional super-resolution datasets (Set5, Set14, BSD100, Urban100, Manga109,\nDIV2K) and real-world images with a variety of degradations demonstrate that\nour method outperforms the state-of-art methods, resulting in higher PSNR and\nSSIM, lower noise and better visual quality. Most importantly, our method\nachieves real-time performance on mobile or edge devices.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2004.13674\n",
    "authors": [
      "Jie Cai",
      "Zibo Meng",
      "Jiaming Ding",
      "Chiu Man Ho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.01777"
  },
  {
    "id": "arXiv:2206.01781",
    "title": "The Before, During, and After of Multi-Robot Deadlock",
    "abstract": "Collision avoidance for multirobot systems is a well-studied problem.\nRecently, control barrier functions (CBFs) have been proposed for synthesizing\ncontrollers that guarantee collision avoidance and goal stabilization for\nmultiple robots. However, it has been noted that reactive control synthesis\nmethods (such as CBFs) are prone to \\textit{deadlock}, an equilibrium of system\ndynamics that causes the robots to stall before reaching their goals. In this\npaper, we analyze the closed-loop dynamics of robots using CBFs, to\ncharacterize controller parameters, initial conditions, and goal locations that\ninvariably lead the system to deadlock. Using tools from duality theory, we\nderive geometric properties of robot configurations of an $N$ robot system once\nit is in deadlock and we justify them using the mechanics interpretation of KKT\nconditions. Our key deductions are that 1) system deadlock is characterized by\na force-equilibrium on robots and 2) deadlock occurs to ensure safety when\nsafety is on the brink of being violated. These deductions allow us to\ninterpret deadlock as a subset of the state space, and we show that this set is\nnon-empty and located on the boundary of the safe set. By exploiting these\nproperties, we analyze the number of admissible robot configurations in\ndeadlock and develop a provably-correct decentralized algorithm for deadlock\nresolution to safely deliver the robots to their goals. This algorithm is\nvalidated in simulations as well as experimentally on Khepera-IV robots.",
    "descriptor": "\nComments: Accepted to International Journal of Robotics Research 2022, WAFR 2020 Special Issue\n",
    "authors": [
      "Jaskaran Grover",
      "Changliu Liu",
      "Katia Sycara"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.01781"
  },
  {
    "id": "arXiv:2206.01784",
    "title": "Onesweep: A Faster Least Significant Digit Radix Sort for GPUs",
    "abstract": "We present Onesweep, a least-significant digit (LSD) radix sorting algorithm\nfor large GPU sorting problems residing in global memory. Our parallel\nalgorithm employs a method of single-pass prefix sum that only requires ~2n\nglobal read/write operations for each digit-binning iteration. This exhibits a\nsignificant reduction in last-level memory traffic versus contemporary GPU\nradix sorting implementations, where each iteration of digit binning requires\ntwo passes through the dataset totaling ~3n global memory operations.\nOn the NVIDIA A100 GPU, our approach achieves 29.4 GKey/s when sorting 256M\nrandom 32-bit keys. Compared to CUB, the current state-of-the-art GPU LSD radix\nsort, our approach provides a speedup of ~1.5x. For 32-bit keys with varied\ndistributions, our approach provides more consistent performance compared to\nHRS, the current state-of-the-art GPU MSD radix sort, and outperforms it in\nalmost all cases.",
    "descriptor": "\nComments: 12 pages, 11 figures, 2 tables\n",
    "authors": [
      "Andy Adinets",
      "Duane Merrill"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.01784"
  },
  {
    "id": "arXiv:2206.01792",
    "title": "Gradient-preserving hyper-reduction of nonlinear dynamical systems via  discrete empirical interpolation",
    "abstract": "This work proposes a hyper-reduction method for nonlinear parametric\ndynamical systems characterized by gradient fields such as (port-)Hamiltonian\nsystems and gradient flows. The gradient structure is associated with\nconservation of invariants or with dissipation and hence plays a crucial role\nin the description of the physical properties of the system. Traditional\nhyper-reduction of nonlinear gradient fields yields efficient approximations\nthat, however, lack the gradient structure. We focus on Hamiltonian gradients\nand we propose to first decompose the nonlinear part of the Hamiltonian, mapped\ninto a suitable reduced space, into the sum of d terms, each characterized by a\nsparse dependence on the system state. Then, the hyper-reduced approximation is\nobtained via discrete empirical interpolation (DEIM) of the Jacobian of the\nderived d-valued nonlinear function. The resulting hyper-reduced model retains\nthe gradient structure and its computationally complexity is independent of the\nsize of the full model. Moreover, a priori error estimates show that the\nhyper-reduced model converges to the reduced model and the Hamiltonian is\nasymptotically preserved. Whenever the nonlinear Hamiltonian gradient is not\nglobally reducible, i.e. its evolution requires high-dimensional DEIM\napproximation spaces, an adaptive strategy is performed. This consists in\nupdating the hyper-reduced Hamiltonian via a low-rank correction of the DEIM\nbasis. Numerical tests demonstrate the applicability of the proposed approach\nto general nonlinear operators and runtime speedups compared to the full and\nthe reduced models.",
    "descriptor": "",
    "authors": [
      "Cecilia Pagliantini",
      "Federico Vismara"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.01792"
  },
  {
    "id": "arXiv:2206.01794",
    "title": "Additive MIL: Intrinsic Interpretability for Pathology",
    "abstract": "Multiple Instance Learning (MIL) has been widely applied in pathology towards\nsolving critical problems such as automating cancer diagnosis and grading,\npredicting patient prognosis, and therapy response. Deploying these models in a\nclinical setting requires careful inspection of these black boxes during\ndevelopment and deployment to identify failures and maintain physician trust.\nIn this work, we propose a simple formulation of MIL models, which enables\ninterpretability while maintaining similar predictive performance. Our Additive\nMIL models enable spatial credit assignment such that the contribution of each\nregion in the image can be exactly computed and visualized. We show that our\nspatial credit assignment coincides with regions used by pathologists during\ndiagnosis and improves upon classical attention heatmaps from attention MIL\nmodels. We show that any existing MIL model can be made additive with a simple\nchange in function composition. We also show how these models can debug model\nfailures, identify spurious features, and highlight class-wise regions of\ninterest, enabling their use in high-stakes environments such as clinical\ndecision-making.",
    "descriptor": "",
    "authors": [
      "Syed Ashar Javed",
      "Dinkar Juyal",
      "Harshith Padigela",
      "Amaro Taylor-Weiner",
      "Limin Yu",
      "Aaditya Prakash"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01794"
  },
  {
    "id": "arXiv:2206.01797",
    "title": "Prophecy Variables for Hyperproperty Verification",
    "abstract": "Temporal logics for hyperproperties like HyperLTL use trace quantifiers to\nexpress properties that relate multiple system runs. In practice, the\nverification of such specifications is mostly limited to formulas without\nquantifier alternation, where verification can be reduced to checking a trace\nproperty over the self-composition of the system. Quantifier alternations like\n$\\forall \\pi. \\exists \\pi'. \\phi$, can either be solved by complementation or\nwith an interpretation as a two-person game between a $\\forall$-player, who\nincrementally constructs the trace $\\pi$, and an $\\exists$-player, who\nconstructs $\\pi'$ in such a way that $\\pi$ and $\\pi'$ together satisfy $\\phi$.\nThe game-based approach is significantly cheaper but incomplete because the\n$\\exists$-player does not know the future moves of the $\\forall$-player. In\nthis paper, we establish that the game-based approach can be made complete by\nadding ($\\omega$-regular) temporal prophecies. Our proof is constructive,\nyielding an effective algorithm for the generation of a complete set of\nprophecies.",
    "descriptor": "\nComments: CSF 2022\n",
    "authors": [
      "Raven Beutner",
      "Bernd Finkbeiner"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.01797"
  },
  {
    "id": "arXiv:2206.01802",
    "title": "Do-Operation Guided Causal Representation Learning with Reduced  Supervision Strength",
    "abstract": "Causal representation learning has been proposed to encode relationships\nbetween factors presented in the high dimensional data. However, existing\nmethods suffer from merely using a large amount of labeled data and ignore the\nfact that samples generated by the same causal mechanism follow the same causal\nrelationships. In this paper, we seek to explore such information by leveraging\ndo-operation for reducing supervision strength. We propose a framework which\nimplements do-operation by swapping latent cause and effect factors encoded\nfrom a pair of inputs. Moreover, we also identify the inadequacy of existing\ncausal representation metrics empirically and theoretically, and introduce new\nmetrics for better evaluation. Experiments conducted on both synthetic and real\ndatasets demonstrate the superiorities of our method compared with\nstate-of-the-art methods.",
    "descriptor": "\nComments: 16 pages 13 figures\n",
    "authors": [
      "Jiageng Zhu",
      "Hanchen Xie",
      "Wael AbdAlmageed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2206.01802"
  },
  {
    "id": "arXiv:2206.01804",
    "title": "A factor model of multilayer network interdependence",
    "abstract": "Multilayer networks describe the rich ways in which nodes are related through\ndifferent types of connections in separate layers. These multiple relationships\nare naturally represented by an adjacency tensor that can be interpreted using\ntechniques from multilinear algebra. In this work we propose the use of the\nnonnegative Tucker decomposition (NNTuck) with KL-divergence as an expressive\nfactor model for multilayer networks that naturally generalizes existing\nmethods for stochastic block models of multilayer networks. We show how the\nNNTuck provides an intuitive factor-based perspective on layer dependence and\nenables linear-algebraic techniques for analyzing dependence with respect to\nspecific layers. Algorithmically, we show that using expectation maximization\n(EM) to maximize this log-likelihood under the NNTuck model is step-by-step\nequivalent to tensorial multiplicative updates for the nonnegative Tucker\ndecomposition under a KL loss, extending a previously known equivalence from\nnonnegative matrices to nonnegative tensors. Using both synthetic and\nreal-world data, we evaluate the use and interpretation of the NNTuck as a\nmodel of multilayer networks. The ability to quantify dependencies between\nlayers has the potential to inform survey instruments for collecting social\nnetwork data, identify redundancies in the structure of a network, and indicate\nrelationships between disparate layers. Therefore, we propose a definition of\nlayer dependence based on using a likelihood ratio test to evaluate three\nnested models: the layer independent, layer dependent, and layer redundant\nNNTucks. We show how these definitions, paired with analysis of the factor\nmatrices in the NNTuck, can be used to understand and interpret layer\ndependence in different contexts.",
    "descriptor": "",
    "authors": [
      "Izabel Aguiar",
      "Dane Taylor",
      "Johan Ugander"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.01804"
  },
  {
    "id": "arXiv:2206.01807",
    "title": "Learning Fine Scale Dynamics from Coarse Observations via Inner  Recurrence",
    "abstract": "Recent work has focused on data-driven learning of the evolution of unknown\nsystems via deep neural networks (DNNs), with the goal of conducting long term\nprediction of the dynamics of the unknown system. In many real-world\napplications, data from time-dependent systems are often collected on a time\nscale that is coarser than desired, due to various restrictions during the data\nacquisition process. Consequently, the observed dynamics can be severely\nunder-sampled and do not reflect the true dynamics of the underlying system.\nThis paper presents a computational technique to learn the fine-scale dynamics\nfrom such coarsely observed data. The method employs inner recurrence of a DNN\nto recover the fine-scale evolution operator of the underlying system. In\naddition to mathematical justification, several challenging numerical examples,\nincluding unknown systems of both ordinary and partial differential equations,\nare presented to demonstrate the effectiveness of the proposed method.",
    "descriptor": "",
    "authors": [
      "Victor Churchill",
      "Dongbin Xiu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.01807"
  },
  {
    "id": "arXiv:2206.01812",
    "title": "Challenges to Solving Combinatorially Hard Long-Horizon Deep RL Tasks",
    "abstract": "Deep reinforcement learning has shown promise in discrete domains requiring\ncomplex reasoning, including games such as Chess, Go, and Hanabi. However, this\ntype of reasoning is less often observed in long-horizon, continuous domains\nwith high-dimensional observations, where instead RL research has predominantly\nfocused on problems with simple high-level structure (e.g. opening a drawer or\nmoving a robot as fast as possible). Inspired by combinatorially hard\noptimization problems, we propose a set of robotics tasks which admit many\ndistinct solutions at the high-level, but require reasoning about states and\nrewards thousands of steps into the future for the best performance.\nCritically, while RL has traditionally suffered on complex, long-horizon tasks\ndue to sparse rewards, our tasks are carefully designed to be solvable without\nspecialized exploration. Nevertheless, our investigation finds that standard RL\nmethods often neglect long-term effects due to discounting, while\ngeneral-purpose hierarchical RL approaches struggle unless additional abstract\ndomain knowledge can be exploited.",
    "descriptor": "",
    "authors": [
      "Andrew C. Li",
      "Pashootan Vaezipoor",
      "Rodrigo Toro Icarte",
      "Sheila A. McIlraith"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.01812"
  },
  {
    "id": "arXiv:2206.01813",
    "title": "Learning sRGB-to-Raw-RGB De-rendering with Content-Aware Metadata",
    "abstract": "Most camera images are rendered and saved in the standard RGB (sRGB) format\nby the camera's hardware. Due to the in-camera photo-finishing routines,\nnonlinear sRGB images are undesirable for computer vision tasks that assume a\ndirect relationship between pixel values and scene radiance. For such\napplications, linear raw-RGB sensor images are preferred. Saving images in\ntheir raw-RGB format is still uncommon due to the large storage requirement and\nlack of support by many imaging applications. Several \"raw reconstruction\"\nmethods have been proposed that utilize specialized metadata sampled from the\nraw-RGB image at capture time and embedded in the sRGB image. This metadata is\nused to parameterize a mapping function to de-render the sRGB image back to its\noriginal raw-RGB format when needed. Existing raw reconstruction methods rely\non simple sampling strategies and global mapping to perform the de-rendering.\nThis paper shows how to improve the de-rendering results by jointly learning\nsampling and reconstruction. Our experiments show that our learned sampling can\nadapt to the image content to produce better raw reconstructions than existing\nmethods. We also describe an online fine-tuning strategy for the reconstruction\nnetwork to improve results further.",
    "descriptor": "\nComments: CVPR 2022 (GitHub: this https URL)\n",
    "authors": [
      "Seonghyeon Nam",
      "Abhijith Punnappurath",
      "Marcus A. Brubaker",
      "Michael S. Brown"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.01813"
  },
  {
    "id": "arXiv:2206.01815",
    "title": "Option Discovery for Autonomous Generation of Symbolic Knowledge",
    "abstract": "In this work we present an empirical study where we demonstrate the\npossibility of developing an artificial agent that is capable to autonomously\nexplore an experimental scenario. During the exploration, the agent is able to\ndiscover and learn interesting options allowing to interact with the\nenvironment without any pre-assigned goal, then abstract and re-use the\nacquired knowledge to solve possible tasks assigned ex-post. We test the system\nin the so-called Treasure Game domain described in the recent literature and we\nempirically demonstrate that the discovered options can be abstracted in an\nprobabilistic symbolic planning model (using the PPDDL language), which allowed\nthe agent to generate symbolic plans to achieve extrinsic goals.",
    "descriptor": "",
    "authors": [
      "Gabriele Sartor",
      "Davide Zollo",
      "Marta Cialdea Mayer",
      "Angelo Oddi",
      "Riccardo Rasconi",
      "Vieri Giuliano Santucci"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.01815"
  },
  {
    "id": "arXiv:2206.01816",
    "title": "Contrastive learning unifies $t$-SNE and UMAP",
    "abstract": "Neighbor embedding methods $t$-SNE and UMAP are the de facto standard for\nvisualizing high-dimensional datasets. They appear to use very different loss\nfunctions with different motivations, and the exact relationship between them\nhas been unclear. Here we show that UMAP is effectively negative sampling\napplied to the $t$-SNE loss function. We explain the difference between\nnegative sampling and noise-contrastive estimation (NCE), which has been used\nto optimize $t$-SNE under the name NCVis. We prove that, unlike NCE, negative\nsampling learns a scaled data distribution. When applied in the neighbor\nembedding setting, it yields more compact embeddings with increased attraction,\nexplaining differences in appearance between UMAP and $t$-SNE. Further, we\ngeneralize the notion of negative sampling and obtain a spectrum of embeddings,\nencompassing visualizations similar to $t$-SNE, NCVis, and UMAP. Finally, we\nexplore the connection between representation learning in the SimCLR setting\nand neighbor embeddings, and show that (i) $t$-SNE can be optimized using the\nInfoNCE loss and in a parametric setting; (ii) various contrastive losses with\nonly few noise samples can yield competitive performance in the SimCLR setup.",
    "descriptor": "\nComments: 29 pages, 13 figures\n",
    "authors": [
      "Sebastian Damrich",
      "Jan Niklas B\u00f6hm",
      "Fred A. Hamprecht",
      "Dmitry Kobak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.01816"
  },
  {
    "id": "arXiv:2206.01818",
    "title": "QAGCN: A Graph Convolutional Network-based Multi-Relation Question  Answering System",
    "abstract": "Answering multi-relation questions over knowledge graphs is a challenging\ntask as it requires multi-step reasoning over a huge number of possible paths.\nReasoning-based methods with complex reasoning mechanisms, such as\nreinforcement learning-based sequential decision making, have been regarded as\nthe default pathway for this task. However, these mechanisms are difficult to\nimplement and train, which hampers their reproducibility and transferability to\nnew domains. In this paper, we propose QAGCN - a simple but effective and novel\nmodel that leverages attentional graph convolutional networks that can perform\nmulti-step reasoning during the encoding of knowledge graphs. As a consequence,\ncomplex reasoning mechanisms are avoided. In addition, to improve efficiency,\nwe retrieve answers using highly-efficient embedding computations and, for\nbetter interpretability, we extract interpretable paths for returned answers.\nOn widely adopted benchmark datasets, the proposed model has been demonstrated\ncompetitive against state-of-the-art methods that rely on complex reasoning\nmechanisms. We also conducted extensive experiments to scrutinize the\nefficiency and contribution of each component of our model.",
    "descriptor": "",
    "authors": [
      "Ruijie Wang",
      "Luca Rossetto",
      "Michael Cochez",
      "Abraham Bernstein"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01818"
  },
  {
    "id": "arXiv:2206.01820",
    "title": "A Robust Backpropagation-Free Framework for Images",
    "abstract": "While current deep learning algorithms have been successful for a wide\nvariety of artificial intelligence (AI) tasks, including those involving\nstructured image data, they present deep neurophysiological conceptual issues\ndue to their reliance on the gradients computed by backpropagation of errors\n(backprop) to obtain synaptic weight adjustments; hence are biologically\nimplausible. We present a more biologically plausible approach, the\nerror-kernel driven activation alignment (EKDAA) algorithm, to train\nconvolution neural networks (CNNs) using locally derived error transmission\nkernels and error maps. We demonstrate the efficacy of EKDAA by performing the\ntask of visual-recognition on the Fashion MNIST, CIFAR-10 and SVHN benchmarks\nas well as conducting blackbox robustness tests on adversarial examples derived\nfrom these datasets. Furthermore, we also present results for a CNN trained\nusing a non-differentiable activation function. All recognition results nearly\nmatches that of backprop and exhibit greater adversarial robustness compared to\nbackprop.",
    "descriptor": "",
    "authors": [
      "Timothy Zee",
      "Alexander G. Ororbia",
      "Ankur Mali",
      "Ifeoma Nwogu"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01820"
  },
  {
    "id": "arXiv:2206.01821",
    "title": "EAANet: Efficient Attention Augmented Convolutional Networks",
    "abstract": "Humans can effectively find salient regions in complex scenes. Self-attention\nmechanisms were introduced into Computer Vision (CV) to achieve this. Attention\nAugmented Convolutional Network (AANet) is a mixture of convolution and\nself-attention, which increases the accuracy of a typical ResNet. However, The\ncomplexity of self-attention is O(n2) in terms of computation and memory usage\nwith respect to the number of input tokens. In this project, we propose EAANet:\nEfficient Attention Augmented Convolutional Networks, which incorporates\nefficient self-attention mechanisms in a convolution and self-attention hybrid\narchitecture to reduce the model's memory footprint. Our best model show\nperformance improvement over AA-Net and ResNet18. We also explore different\nmethods to augment Convolutional Network with self-attention mechanisms and\nshow the difficulty of training those methods compared to ResNet. Finally, we\nshow that augmenting efficient self-attention mechanisms with ResNet scales\nbetter with input size than normal self-attention mechanisms. Therefore, our\nEAANet is more capable of working with high-resolution images.",
    "descriptor": "\nComments: 8 pages, 4 figures. Not published\n",
    "authors": [
      "Runqing Zhang",
      "Tianshu Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01821"
  },
  {
    "id": "arXiv:2206.01822",
    "title": "HDDL 2.1: Towards Defining an HTN Formalism with Time",
    "abstract": "Real world applications of planning, like in industry and robotics, require\nmodelling rich and diverse scenarios. Their resolution usually requires\ncoordinated and concurrent action executions. In several cases, such planning\nproblems are naturally decomposed in a hierarchical way and expressed by a\nHierarchical Task Network (HTN) formalism. The PDDL language used to specify\nplanning domains has evolved to cover the different planning paradigms.\nHowever, formulating real and complex scenarios where numerical and temporal\nconstraints concur in defining a solution is still a challenge. Our proposition\naims at filling the gap between existing planning languages and operational\nneeds. To do so, we propose to extend HDDL taking inspiration from PDDL 2.1 and\nANML to express temporal and numerical expressions. This paper opens\ndiscussions on the semantics and the syntax needed to extend HDDL, and\nillustrate these needs with the modelling of an Earth Observing Satellite\nplanning problem.",
    "descriptor": "",
    "authors": [
      "D. Pellier",
      "H. Fiorino",
      "M. Grand",
      "A. Albore",
      "R. Bailon-Ruiz"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.01822"
  },
  {
    "id": "arXiv:2206.01823",
    "title": "Relevance in Dialogue: Is Less More? An Empirical Comparison of Existing  Metrics, and a Novel Simple Metric",
    "abstract": "In this work, we evaluate various existing dialogue relevance metrics, find\nstrong dependency on the dataset, often with poor correlation with human scores\nof relevance, and propose modifications to reduce data requirements and domain\nsensitivity while improving correlation. Our proposed metric achieves\nstate-of-the-art performance on the HUMOD dataset while reducing measured\nsensitivity to dataset by 37%-66%. We achieve this without fine-tuning a\npretrained language model, and using only 3,750 unannotated human dialogues and\na single negative example. Despite these limitations, we demonstrate\ncompetitive performance on four datasets from different domains. Our code,\nincluding our metric and experiments, is open sourced.",
    "descriptor": "\nComments: 18 pages, 7 figures\n",
    "authors": [
      "Ian Berlot-Attwell",
      "Frank Rudzicz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.01823"
  },
  {
    "id": "arXiv:2206.01829",
    "title": "Drawing out of Distribution with Neuro-Symbolic Generative Models",
    "abstract": "Learning general-purpose representations from perceptual inputs is a hallmark\nof human intelligence. For example, people can write out numbers or characters,\nor even draw doodles, by characterizing these tasks as different instantiations\nof the same generic underlying process -- compositional arrangements of\ndifferent forms of pen strokes. Crucially, learning to do one task, say\nwriting, implies reasonable competence at another, say drawing, on account of\nthis shared process. We present Drawing out of Distribution (DooD), a\nneuro-symbolic generative model of stroke-based drawing that can learn such\ngeneral-purpose representations. In contrast to prior work, DooD operates\ndirectly on images, requires no supervision or expensive test-time inference,\nand performs unsupervised amortised inference with a symbolic stroke model that\nbetter enables both interpretability and generalization. We evaluate DooD on\nits ability to generalise across both data and tasks. We first perform\nzero-shot transfer from one dataset (e.g. MNIST) to another (e.g. Quickdraw),\nacross five different datasets, and show that DooD clearly outperforms\ndifferent baselines. An analysis of the learnt representations further\nhighlights the benefits of adopting a symbolic stroke model. We then adopt a\nsubset of the Omniglot challenge tasks, and evaluate its ability to generate\nnew exemplars (both unconditionally and conditionally), and perform one-shot\nclassification, showing that DooD matches the state of the art. Taken together,\nwe demonstrate that DooD does indeed capture general-purpose representations\nacross both data and task, and takes a further step towards building general\nand robust concept-learning systems.",
    "descriptor": "\nComments: Submitted to NeurIPS 2022\n",
    "authors": [
      "Yichao Liang",
      "Joshua B. Tenenbaum",
      "Tuan Anh Le",
      "N. Siddharth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2206.01829"
  },
  {
    "id": "arXiv:2206.01831",
    "title": "Spatial Feature Mapping for 6DoF Object Pose Estimation",
    "abstract": "This work aims to estimate 6Dof (6D) object pose in background clutter.\nConsidering the strong occlusion and background noise, we propose to utilize\nthe spatial structure for better tackling this challenging task. Observing that\nthe 3D mesh can be naturally abstracted by a graph, we build the graph using 3D\npoints as vertices and mesh connections as edges. We construct the\ncorresponding mapping from 2D image features to 3D points for filling the graph\nand fusion of the 2D and 3D features. Afterward, a Graph Convolutional Network\n(GCN) is applied to help the feature exchange among objects' points in 3D\nspace. To address the problem of rotation symmetry ambiguity for objects, a\nspherical convolution is utilized and the spherical features are combined with\nthe convolutional features that are mapped to the graph. Predefined 3D\nkeypoints are voted and the 6DoF pose is obtained via the fitting optimization.\nTwo scenarios of inference, one with the depth information and the other\nwithout it are discussed. Tested on the datasets of YCB-Video and LINEMOD, the\nexperiments demonstrate the effectiveness of our proposed method.",
    "descriptor": "\nComments: Pattern Recognition\n",
    "authors": [
      "Jianhan Mei",
      "Xudong Jiang",
      "Henghui Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01831"
  },
  {
    "id": "arXiv:2206.01832",
    "title": "Kallima: A Clean-label Framework for Textual Backdoor Attacks",
    "abstract": "Although Deep Neural Network (DNN) has led to unprecedented progress in\nvarious natural language processing (NLP) tasks, research shows that deep\nmodels are extremely vulnerable to backdoor attacks. The existing backdoor\nattacks mainly inject a small number of poisoned samples into the training\ndataset with the labels changed to the target one. Such mislabeled samples\nwould raise suspicion upon human inspection, potentially revealing the attack.\nTo improve the stealthiness of textual backdoor attacks, we propose the first\nclean-label framework Kallima for synthesizing mimesis-style backdoor samples\nto develop insidious textual backdoor attacks. We modify inputs belonging to\nthe target class with adversarial perturbations, making the model rely more on\nthe backdoor trigger. Our framework is compatible with most existing backdoor\ntriggers. The experimental results on three benchmark datasets demonstrate the\neffectiveness of the proposed method.",
    "descriptor": "",
    "authors": [
      "Xiaoyi Chen",
      "Yinpeng Dong",
      "Zeyu Sun",
      "Shengfang Zhai",
      "Qingni Shen",
      "Zhonghai Wu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.01832"
  },
  {
    "id": "arXiv:2206.01833",
    "title": "Leveraging Heterogeneous Capabilities in Multi-Agent Systems for  Environmental Conflict Resolution",
    "abstract": "In this paper, we introduce a high-level controller synthesis framework that\nenables teams of heterogeneous agents to assist each other in resolving\nenvironmental conflicts that appear at runtime. This conflict resolution method\nis built upon temporal-logic-based reactive synthesis to guarantee safety and\ntask completion under specific environment assumptions. In heterogeneous\nmulti-agent systems, every agent is expected to complete its own tasks in\nservice of a global team objective. However, at runtime, an agent may encounter\nun-modeled obstacles (e.g., doors or walls) that prevent it from achieving its\nown task. To address this problem, we take advantage of the capability of other\nheterogeneous agents to resolve the obstacle. A controller framework is\nproposed to redirect agents with the capability of resolving the appropriate\nobstacles to the required target when such a situation is detected. A set of\ncase studies involving a bipedal robot Digit and a quadcopter are used to\nevaluate the controller performance in action. Additionally, we implement the\nproposed framework on a physical multi-agent robotic system to demonstrate its\nviability for real world applications.",
    "descriptor": "\nComments: Submitted to The International Symposium on Robotics Research (ISRR) 2022\n",
    "authors": [
      "Michael Enqi Cao",
      "Jonas Warnke",
      "Yunhai Han",
      "Xinpei Ni",
      "Ye Zhao",
      "Samuel Coogan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.01833"
  },
  {
    "id": "arXiv:2206.01836",
    "title": "Dimension Independent Generalization of DP-SGD for Overparameterized  Smooth Convex Optimization",
    "abstract": "This paper considers the generalization performance of differentially private\nconvex learning. We demonstrate that the convergence analysis of Langevin\nalgorithms can be used to obtain new generalization bounds with differential\nprivacy guarantees for DP-SGD. More specifically, by using some recently\nobtained dimension-independent convergence results for stochastic Langevin\nalgorithms with convex objective functions, we obtain $O(n^{-1/4})$ privacy\nguarantees for DP-SGD with the optimal excess generalization error of\n$\\tilde{O}(n^{-1/2})$ for certain classes of overparameterized smooth convex\noptimization problems. This improves previous DP-SGD results for such problems\nthat contain explicit dimension dependencies, so that the resulting\ngeneralization bounds become unsuitable for overparameterized models used in\npractical applications.",
    "descriptor": "",
    "authors": [
      "Yi-An Ma",
      "Teodor Vanislavov Marinov",
      "Tong Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.01836"
  },
  {
    "id": "arXiv:2206.01838",
    "title": "Differentially Private Model Compression",
    "abstract": "Recent papers have shown that large pre-trained language models (LLMs) such\nas BERT, GPT-2 can be fine-tuned on private data to achieve performance\ncomparable to non-private models for many downstream Natural Language\nProcessing (NLP) tasks while simultaneously guaranteeing differential privacy.\nThe inference cost of these models -- which consist of hundreds of millions of\nparameters -- however, can be prohibitively large. Hence, often in practice,\nLLMs are compressed before they are deployed in specific applications. In this\npaper, we initiate the study of differentially private model compression and\npropose frameworks for achieving 50% sparsity levels while maintaining nearly\nfull performance. We demonstrate these ideas on standard GLUE benchmarks using\nBERT models, setting benchmarks for future research on this topic.",
    "descriptor": "",
    "authors": [
      "Fatemehsadat Mireshghallah",
      "Arturs Backurs",
      "Huseyin A Inan",
      "Lukas Wutschitz",
      "Janardhan Kulkarni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.01838"
  },
  {
    "id": "arXiv:2206.01841",
    "title": "Coffee Roast Intelligence",
    "abstract": "As the coffee industry has grown, there would be more demand for roasted\ncoffee beans, as well as increased rivalry for selling coffee and attracting\ncustomers. As the flavor of each variety of coffee is dependent on the degree\nof roasting of the coffee beans, it is vital to maintain a consistent quality\nrelated to the degree of roasting. Each barista has their own method for\ndetermining the degree of roasting. However, extrinsic circumstances such as\nlight, fatigue, and other factors may alter their judgment. As a result, the\nquality of the coffee cannot be controlled. The Coffee Roast Intelligence\napplication is a machine learning-based study of roasted coffee bean degrees\nclassification produced as an Android application platform that identifies the\ncolor of coffee beans by photographing or uploading them while roasting. This\napplication displays the text showing at what level the coffee beans have been\nroasted, as well as informs the percent chance of class prediction to the\nconsumers. Users may also keep track of the result of the predictions related\nto the roasting level of coffee beans.",
    "descriptor": "\nComments: 6 pages, 13 figures, 3 tables, this work was presented at the CSC498 COMPUTER SCIENCE CAPSTONE PROJECT I and CSC499 COMPUTER SCIENCE CAPSTONE PROJECT II courses\n",
    "authors": [
      "Sakdipat Ontoum",
      "Thitaree Khemanantakul",
      "Pornphat Sroison",
      "Tuul Triyason",
      "Bunthit Watanapa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01841"
  },
  {
    "id": "arXiv:2206.01843",
    "title": "Visual Clues: Bridging Vision and Language Foundations for Image  Paragraph Captioning",
    "abstract": "People say, \"A picture is worth a thousand words\". Then how can we get the\nrich information out of the image? We argue that by using visual clues to\nbridge large pretrained vision foundation models and language models, we can do\nso without any extra cross-modal training. Thanks to the strong zero-shot\ncapability of foundation models, we start by constructing a rich semantic\nrepresentation of the image (e.g., image tags, object attributes / locations,\ncaptions) as a structured textual prompt, called visual clues, using a vision\nfoundation model. Based on visual clues, we use large language model to produce\na series of comprehensive descriptions for the visual content, which is then\nverified by the vision model again to select the candidate that aligns best\nwith the image. We evaluate the quality of generated descriptions by\nquantitative and qualitative measurement. The results demonstrate the\neffectiveness of such a structured semantic representation.",
    "descriptor": "",
    "authors": [
      "Yujia Xie",
      "Luowei Zhou",
      "Xiyang Dai",
      "Lu Yuan",
      "Nguyen Bach",
      "Ce Liu",
      "Michael Zeng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.01843"
  },
  {
    "id": "arXiv:2206.01846",
    "title": "Ultra-Low-Complexity Algorithms with Structurally Optimal Multi-Group  Multicast Beamforming in Large-Scale Systems",
    "abstract": "We consider an ultra-low-complexity multi-group multicast beamforming design\nfor large-scale systems. For the quality-of-service (QoS) problem, by utilizing\nthe optimal multicast beamforming structure obtained recently in [2], we\nconvert the original problem into a non-convex weight optimization problem of a\nlower dimension and propose two fast first-order algorithms to solve it. Both\nalgorithms are based on successive convex approximation (SCA) and provide fast\niterative updates to solve each SCA subproblem. The first algorithm uses a\nsaddle point reformulation in the dual domain and applies the extragradient\nmethod with an adaptive step-size procedure to find the saddle point with\nsimple closed-form updates. The second algorithm adopts the alternating\ndirection method of multipliers (ADMM) method by converting each SCA subproblem\ninto a favorable ADMM structure. The structure leads to simple closed-form ADMM\nupdates, where the problem in each update block can be further decomposed into\nparallel subproblems of small sizes, for which closed-form solutions are\nobtained. We also propose efficient initialization methods to obtain favorable\ninitial points that facilitate fast convergence. Furthermore, taking advantage\nof the proposed fast algorithms, for the max-min fair (MMF) problem, we propose\na simple closed-form scaling scheme that directly uses the solution obtained\nfrom the QoS problem, avoiding the conventional computationally expensive\nmethod that iteratively solves the inverse QoS problem. We further develop\nlower and upper bounds on the performance of this scaling scheme. Simulation\nresults show that the proposed algorithms offer near-optimal performance with\nsubstantially lower computational complexity than the state-of-the-art\nalgorithms for large-scale systems.",
    "descriptor": "\nComments: 13 pages, 7 figures\n",
    "authors": [
      "Chong Zhang",
      "Min Dong",
      "Ben Liang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.01846"
  },
  {
    "id": "arXiv:2206.01848",
    "title": "Automated Feedback Generation for Competition-Level Code",
    "abstract": "Competitive programming has become a popular way for programmers to test\ntheir skills. Large-scale online programming contests attract millions of\nexperienced programmers to compete against each other. Competition-level\nprogramming problems are challenging in nature, and participants often fail to\nsolve the problem on their first attempt. Some online platforms for competitive\nprogramming allow programmers to practice on competition-level problems as\nwell, and the standard feedback for an incorrect practice submission is the\nfirst test case that the submission fails. Often, the failed test case does not\nprovide programmers with enough information to resolve the errors in their\ncode, and they abandon the problem after several more unsuccessful attempts.\nWe present Clef, the first data-driven tool that can generate feedback on\ncompetition-level code automatically by repairing programmers' incorrect\nsubmissions. The key development is that Clef can learn how to generate repairs\nfor incorrect submissions by examining the repairs that other programmers made\nto their own submissions over time. Since the differences between an incorrect\nprogram and a correct program for the same task may be significant, we\nintroduce a new data structure, merge trees, to capture the changes between\nsubmissions. Merge trees are versatile: they can encode both large\nalgorithm-level redesigns and small statement-level alterations. Clef applies\nthe patterns it learns from a database of submissions to generate repairs for\nnew submissions outside the database. We evaluated Clef on six real-world\nproblems from Codeforces, the world's largest platform for competitive\nprogramming. Clef achieves 42.1% accuracy in repairing programmers' incorrect\nsubmissions. Even when given incorrect submissions from programmers who never\nfound the solution to a problem on their own, Clef repairs the users' programs\n34.1% of the time.",
    "descriptor": "",
    "authors": [
      "Jialu Zhang",
      "De Li",
      "John C. Kolesar",
      "Hanyuan Shi",
      "Ruzica Piskac"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.01848"
  },
  {
    "id": "arXiv:2206.01851",
    "title": "Out-of-Distribution Detection using BiGAN and MDL",
    "abstract": "We consider the following problem: we have a large dataset of normal data\navailable. We are now given a new, possibly quite small, set of data, and we\nare to decide if these are normal data, or if they are indicating a new\nphenomenon. This is a novelty detection or out-of-distribution detection\nproblem. An example is in medicine, where the normal data is for people with no\nknown disease, and the new dataset people with symptoms. Other examples could\nbe in security. We solve this problem by training a bidirectional generative\nadversarial network (BiGAN) on the normal data and using a Gaussian graphical\nmodel to model the output. We then use universal source coding, or minimum\ndescription length (MDL) on the output to decide if it is a new distribution,\nin an implementation of Kolmogorov and Martin-L\\\"{o}f randomness. We apply the\nmethodology to both MNIST data and a real-world electrocardiogram (ECG) dataset\nof healthy and patients with Kawasaki disease, and show better performance in\nterms of the ROC curve than similar methods.",
    "descriptor": "",
    "authors": [
      "Mojtaba Abolfazli",
      "Mohammad Zaeri Arimani",
      "Anders Host-Madsen",
      "June Zhang",
      "Andras Bratincsak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.01851"
  },
  {
    "id": "arXiv:2206.01856",
    "title": "Poisson2Sparse: Self-Supervised Poisson Denoising From a Single Image",
    "abstract": "Image enhancement approaches often assume that the noise is signal\nindependent, and approximate the degradation model as zero-mean additive\nGaussian noise. However, this assumption does not hold for biomedical imaging\nsystems where sensor-based sources of noise are proportional to signal\nstrengths, and the noise is better represented as a Poisson process. In this\nwork, we explore a sparsity and dictionary learning-based approach and present\na novel self-supervised learning method for single-image denoising where the\nnoise is approximated as a Poisson process, requiring no clean ground-truth\ndata. Specifically, we approximate traditional iterative optimization\nalgorithms for image denoising with a recurrent neural network which enforces\nsparsity with respect to the weights of the network. Since the sparse\nrepresentations are based on the underlying image, it is able to suppress the\nspurious components (noise) in the image patches, thereby introducing implicit\nregularization for denoising task through the network structure. Experiments on\ntwo bio-imaging datasets demonstrate that our method outperforms the\nstate-of-the-art approaches in terms of PSNR and SSIM. Our qualitative results\ndemonstrate that, in addition to higher performance on standard quantitative\nmetrics, we are able to recover much more subtle details than other compared\napproaches.",
    "descriptor": "",
    "authors": [
      "Calvin-Khang Ta",
      "Abhishek Aich",
      "Akash Gupta",
      "Amit K. Roy-Chowdhury"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.01856"
  },
  {
    "id": "arXiv:2206.01857",
    "title": "Design and Implementation of an Heuristic-Enhanced Branch-and-Bound  Solver for MILP",
    "abstract": "We present a solver for Mixed Integer Programs (MIP) developed for the MIP\ncompetition 2022. Given the 10 minutes bound on the computational time\nestablished by the rules of the competition, our method focuses on finding a\nfeasible solution and improves it through a Branch-and-Bound algorithm. Another\nrule of the competition allows the use of up to 8 threads. Each thread is given\na different primal heuristic, which has been tuned by hyper-parameters, to find\na feasible solution. In every thread, once a feasible solution is found, we\nstop and we use a Branch-and-Bound method, embedded with local search\nheuristics, to ameliorate the incumbent solution. The three variants of the\nDiving heuristic that we implemented manage to find a feasible solution for 10\ninstances of the training data set. These heuristics are the best performing\namong the heuristics that we implemented. Our Branch-and-Bound algorithm is\neffective on a small portion of the training data set, and it manages to find\nan incumbent feasible solution for an instance that we could not solve with the\nDiving heuristics. Overall, our combined methods, when implemented with\nextensive computational power, can solve 11 of the 19 problems of the training\ndata set within the time limit. Our submission to the MIP competition was\nawarded the \"Outstanding Student Submission\" honorable mention.",
    "descriptor": "\nComments: 10 pages, 1 figure, 4 tables, MIP 2022 competition\n",
    "authors": [
      "Warley Almeida Silva",
      "Federico Bobbio",
      "Flore Caye",
      "Defeng Liu",
      "Justine Pepin",
      "Carl Perreault-Lafleur",
      "William St-Arnaud"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.01857"
  },
  {
    "id": "arXiv:2206.01859",
    "title": "Extreme Compression for Pre-trained Transformers Made Simple and  Efficient",
    "abstract": "Extreme compression, particularly ultra-low bit precision (binary/ternary)\nquantization, has been proposed to fit large NLP models on resource-constraint\ndevices. However, to preserve the accuracy for such aggressive compression\nschemes, cutting-edge methods usually introduce complicated compression\npipelines, e.g., multi-stage expensive knowledge distillation with extensive\nhyperparameter tuning. Also, they oftentimes focus less on smaller transformer\nmodels that have already been heavily compressed via knowledge distillation and\nlack a systematic study to show the effectiveness of their methods. In this\npaper, we perform a very comprehensive systematic study to measure the impact\nof many key hyperparameters and training strategies from previous works. As a\nresult, we find out that previous baselines for ultra-low bit precision\nquantization are significantly under-trained. Based on our study, we propose a\nsimple yet effective compression pipeline for extreme compression, named XTC.\nXTC demonstrates that (1) we can skip the pre-training knowledge distillation\nto obtain a 5-layer BERT while achieving better performance than previous\nstate-of-the-art methods, e.g., the 6-layer TinyBERT; (2) extreme quantization\nplus layer reduction is able to reduce the model size by 50x, resulting in new\nstate-of-the-art results on GLUE tasks.",
    "descriptor": "\nComments: 10 pages, 4 figures\n",
    "authors": [
      "Xiaoxia Wu",
      "Zhewei Yao",
      "Minjia Zhang",
      "Conglong Li",
      "Yuxiong He"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01859"
  },
  {
    "id": "arXiv:2206.01861",
    "title": "ZeroQuant: Efficient and Affordable Post-Training Quantization for  Large-Scale Transformers",
    "abstract": "How to efficiently serve ever-larger trained natural language models in\npractice has become exceptionally challenging even for powerful cloud servers\ndue to their prohibitive memory/computation requirements. In this work, we\npresent an efficient and affordable post-training quantization approach to\ncompress large Transformer-based models, termed as ZeroQuant. ZeroQuant is an\nend-to-end quantization and inference pipeline with three main components: (1)\na fine-grained hardware-friendly quantization scheme for both weight and\nactivations; (2) a novel affordable layer-by-layer knowledge distillation\nalgorithm (LKD) even without the access to the original training data; (3) a\nhighly-optimized quantization system backend support to remove the\nquantization/dequantization overhead. As such, we are able to show that: (1)\nZeroQuant can reduce the precision for weights and activations to INT8 in a\ncost-free way for both BERT and GPT3-style models with minimal accuracy impact,\nwhich leads to up to 5.19x/4.16x speedup on those models compared to FP16\ninference; (2) ZeroQuant plus LKD affordably quantize the weights in the\nfully-connected module to INT4 along with INT8 weights in the attention module\nand INT8 activations, resulting in 3x memory footprint reduction compared to\nthe FP16 model; (3) ZeroQuant can be directly applied to two of the largest\nopen-sourced language models, including GPT-J6B and GPT-NeoX20, for which our\nINT8 model achieves similar accuracy as the FP16 model but achieves up to 5.2x\nbetter efficiency.",
    "descriptor": "\nComments: 11 pages, 4 figures\n",
    "authors": [
      "Zhewei Yao",
      "Reza Yazdani Aminabadi",
      "Minjia Zhang",
      "Xiaoxia Wu",
      "Conglong Li",
      "Yuxiong He"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01861"
  },
  {
    "id": "arXiv:2206.01863",
    "title": "Recurrent Image Registration using Mutual Attention based Network",
    "abstract": "Image registration is an important task in medical imaging which estimates\nthe spatial transformation between different images. Many previous studies have\nused learning-based methods for multi-stage registration to perform 3D image\nregistration to improve performance. The performance of the multi-stage\napproach, however, is limited by the size of the receptive field where complex\nmotion does not occur at a single spatial scale. We propose a new registration\nnetwork combining recursive network architecture and mutual attention mechanism\nto overcome these limitations. Compared with the previous deep learning\nmethods, our network based on the recursive structure achieves the highest\naccuracy in lung Computed Tomography (CT) data set (Dice score of 92\\% and\naverage surface distance of 3.8mm for lungs) and one of the most accurate\nresults in abdominal CT data set with 9 organs of various sizes (Dice score of\n55\\% and average surface distance of 7.8mm). We also showed that adding 3\nrecursive networks is sufficient to achieve the state-of-the-art results\nwithout a significant increase in the inference time.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2203.04290\n",
    "authors": [
      "Jian-Qing Zheng",
      "Ziyang Wang",
      "Baoru Huang",
      "Ngee Han Lim",
      "Tonia Vincent",
      "Bartlomiej W. Papiez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01863"
  },
  {
    "id": "arXiv:2206.01864",
    "title": "Model-Informed Generative Adversarial Network (MI-GAN) for Learning  Optimal Power Flow",
    "abstract": "The optimal power flow (OPF) problem, as a critical component of power system\noperations, becomes increasingly difficult to solve due to the variability,\nintermittency, and unpredictability of renewable energy brought to the power\nsystem. Although traditional optimization techniques, such as stochastic and\nrobust optimization approaches, could be used to address the OPF problem in the\nface of renewable energy uncertainty, their effectiveness in dealing with\nlarge-scale problems remains limited. As a result, deep learning techniques,\nsuch as neural networks, have recently been developed to improve computational\nefficiency in solving large-scale OPF problems. However, the feasibility and\noptimality of the solution may not be guaranteed. In this paper, we propose an\noptimization model-informed generative adversarial network (MI-GAN) framework\nto solve OPF under uncertainty. The main contributions are summarized into\nthree aspects: (1) to ensure feasibility and improve optimality of generated\nsolutions, three important layers are proposed: feasibility filter layer,\ncomparison layer, and gradient-guided layer; (2) in the GAN-based framework, an\nefficient model-informed selector incorporating these three new layers is\nestablished; and (3) a new recursive iteration algorithm is also proposed to\nimprove solution optimality. The numerical results on IEEE test systems show\nthat the proposed method is very effective and promising.",
    "descriptor": "",
    "authors": [
      "Yuxuan Li",
      "Chaoyue Zhao",
      "Chenang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.01864"
  },
  {
    "id": "arXiv:2206.01866",
    "title": "Robust and Kernelized Data-Enabled Predictive Control for Nonlinear  Systems",
    "abstract": "This paper presents a robust and kernelized data-enabled predictive control\n(RoKDeePC) algorithm to perform model-free optimal control for nonlinear\nsystems using only input and output data. The algorithm combines robust\npredictive control and a non-parametric representation of nonlinear systems\nenabled by regularized kernel methods. The latter is based on implicitly\nlearning the nonlinear behavior of the system via the representer theorem.\nInstead of seeking a model and then performing control design, our method goes\ndirectly from data to control. This allows us to robustify the control inputs\nagainst the uncertainties in data by considering a min-max optimization problem\nto calculate the optimal control sequence. We show that by incorporating a\nproper uncertainty set, this min-max problem can be reformulated as a nonconvex\nbut structured minimization problem. By exploiting its structure, we present a\nprojected gradient descent algorithm to effectively solve this problem.\nFinally, we test the RoKDeePC on two nonlinear example systems - one academic\ncase study and a grid-forming converter feeding a nonlinear load - and compare\nit with some existing nonlinear data-driven predictive control methods.",
    "descriptor": "",
    "authors": [
      "Linbin Huang",
      "John Lygeros",
      "Florian D\u00f6rfler"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.01866"
  },
  {
    "id": "arXiv:2206.01867",
    "title": "SPGNet: Spatial Projection Guided 3D Human Pose Estimation in Low  Dimensional Space",
    "abstract": "We propose a method SPGNet for 3D human pose estimation that mixes\nmulti-dimensional re-projection into supervised learning. In this method, the\n2D-to-3D-lifting network predicts the global position and coordinates of the 3D\nhuman pose. Then, we re-project the estimated 3D pose back to the 2D key points\nalong with spatial adjustments. The loss functions compare the estimated 3D\npose with the 3D pose ground truth, and re-projected 2D pose with the input 2D\npose. In addition, we propose a kinematic constraint to restrict the predicted\ntarget with constant human bone length. Based on the estimation results for the\ndataset Human3.6M, our approach outperforms many state-of-the-art methods both\nqualitatively and quantitatively.",
    "descriptor": "",
    "authors": [
      "Zihan Wang",
      "Ruimin Chen",
      "Mengxuan Liu",
      "Guanfang Dong",
      "Anup Basu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01867"
  },
  {
    "id": "arXiv:2206.01869",
    "title": "Multiple-scattering frequency-time hybrid solver for the wave equation  in interior domains",
    "abstract": "This paper proposes a frequency-time hybrid solver for the time-dependent\nwave equation in two-dimensional interior spatial domains. The approach relies\non four main elements, namely, 1) A multiple scattering strategy that\ndecomposes a given time-domain problem into a sequence of limited-duration\ntime-domain problems of scattering by overlapping open-arcs, each one of which\nis reduced (by means of the Fourier transform) to a sequence of Helmholtz\nfrequency-domain problems; 2) Boundary integral equations on overlapping\nboundary patches for the solution of the frequency-domain problems in point 1);\n3) A smooth \"Time-windowing and recentering\" methodology that enables both\ntreatment of incident signals of long duration and long time simulation; and,\n4) A Fourier transform algorithm that delivers numerically dispersionless,\nspectrally-accurate time evolution for given incident fields. By recasting the\ninterior time-domain problem in terms of a sequence of open-arc multiple\nscattering events, the proposed approach regularizes the full interior\nfrequency domain problem-which, if obtained by either Fourier or Laplace\ntransformation of the corresponding interior time-domain problem, must\nencapsulate infinitely many scattering events, giving rise to non-uniqueness\nand eigenfunctions in the Fourier case, and ill conditioning in the Laplace\ncase. Numerical examples are included which demonstrate the accuracy and\nefficiency of the proposed methodology.",
    "descriptor": "\nComments: 30 pages, 15 figures, 3 tables\n",
    "authors": [
      "Oscar P. Bruno",
      "Tao Yin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.01869"
  },
  {
    "id": "arXiv:2206.01871",
    "title": "Estimating the Effect of Team Hitting Strategies Using Counterfactual  Virtual Simulation in Baseball",
    "abstract": "In baseball, every play on the field is quantitatively evaluated and has an\neffect on individual and team strategies. The weighted on base average (wOBA)\nis well known as a measure of an batter's hitting contribution. However, this\nmeasure ignores the game situation, such as the runners on base, which coaches\nand batters are known to consider when employing multiple hitting strategies,\nyet, the effectiveness of these strategies is unknown. This is probably because\n(1) we cannot obtain the batter's strategy and (2) it is difficult to estimate\nthe effect of the strategies. Here, we propose a new method for estimating the\neffect using counterfactual batting simulation. To this end, we propose a deep\nlearning model that transforms batting ability when batting strategy is\nchanged. This method can estimate the effects of various strategies, which has\nbeen traditionally difficult with actual game data. We found that, when the\nswitching cost of batting strategies can be ignored, the use of different\nstrategies increased runs. When the switching cost is considered, the\nconditions for increasing runs were limited. Our validation results suggest\nthat our simulation could clarify the effect of using multiple batting\nstrategies.",
    "descriptor": "\nComments: 14 pages, 6 figures\n",
    "authors": [
      "Hiroshi Nakahara",
      "Kazuya Takeda",
      "Keisuke Fujii"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01871"
  },
  {
    "id": "arXiv:2206.01872",
    "title": "Affine Symplectic Grassmann codes",
    "abstract": "In this article we introduce a new class of linear codes, called affine\nsymplectic Grassmann codes, and determine their parameters, automorphism group,\nminimum distance codewords, dual code and other key features. These linear\ncodes are defined from affine part of polar symplectic Grassmann codes. They\ncombine polar symplectic Grassmann codes and affine Grassmann codes.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2110.08964\n",
    "authors": [
      "Fernando Pi\u00f1ero Gonz\u00e1lez",
      "Doel Rivera-Laboy"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.01872"
  },
  {
    "id": "arXiv:2206.01874",
    "title": "An Unpooling Layer for Graph Generation",
    "abstract": "We propose a novel and trainable graph unpooling layer for effective graph\ngeneration. Given a graph with features, the unpooling layer enlarges this\ngraph and learns its desired new structure and features. Since this unpooling\nlayer is trainable, it can be applied to graph generation either in the decoder\nof a variational autoencoder or in the generator of a generative adversarial\nnetwork (GAN). We prove that the unpooled graph remains connected and any\nconnected graph can be sequentially unpooled from a 3-nodes graph. We apply the\nunpooling layer within the GAN generator. Since the most studied instance of\ngraph generation is molecular generation, we test our ideas in this context.\nUsing the QM9 and ZINC datasets, we demonstrate the improvement obtained by\nusing the unpooling layer instead of an adjacency-matrix-based approach.",
    "descriptor": "",
    "authors": [
      "Yinglong Guo",
      "Dongmian Zou",
      "Gilad Lerman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.01874"
  },
  {
    "id": "arXiv:2206.01875",
    "title": "Prospective Preference Enhanced Mixed Attentive Model for Session-based  Recommendation",
    "abstract": "Session-based recommendation aims to generate recommendations for the next\nitem of users' interest based on a given session. In this manuscript, we\ndevelop prospective preference enhanced mixed attentive model (P2MAM) to\ngenerate session-based recommendations using two important factors: temporal\npatterns and estimates of users' prospective preferences. Unlike existing\nmethods, P2MAM models the temporal patterns using a light-weight while\neffective position-sensitive attention mechanism. In P2MAM, we also leverage\nthe estimate of users' prospective preferences to signify important items, and\ngenerate better recommendations. Our experimental results demonstrate that\nP2MAM models significantly outperform the state-of-the-art methods in six\nbenchmark datasets, with an improvement as much as 19.2%. In addition, our\nrun-time performance comparison demonstrates that during testing, P2MAM models\nare much more efficient than the best baseline method, with a significant\naverage speedup of 47.7 folds.",
    "descriptor": "\nComments: Under review by IEEE Transactions on Knowledge and Data Engineering (TKDE)\n",
    "authors": [
      "Bo Peng",
      "Chang-Yu Tai",
      "Srinivasan Parthasarathy",
      "Xia Ning"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.01875"
  },
  {
    "id": "arXiv:2206.01878",
    "title": "Remote Collaboration Fuses Fewer Breakthrough Ideas",
    "abstract": "Scientists and inventors around the world are more plentiful and\ninterconnected today than ever before. But while there are more people making\ndiscoveries, and more ideas that can be reconfigured in novel ways, research\nsuggests that new ideas are getting harder to find-contradicting recombinant\ngrowth theory. In this paper, we shed new light on this apparent puzzle.\nAnalyzing 20 million research articles and 4 million patent applications across\nthe globe over the past half-century, we begin by documenting the rise of\nremote collaboration across locations, underlining the growing\ninterconnectedness of scientists and inventors globally. However, we also show\nthat for all fields, periods, and team sizes, researchers in these distributed\nteams are consistently less likely to make breakthrough discoveries relative to\ntheir onsite counterparts. Using a novel dataset that allows us to explore the\ndivision of labor within each team, we find that distributed team members tend\nto collaborate in technical tasks-like collecting and analyzing data-but are\nless likely to join forces in conceptual tasks, such as conceiving new ideas\nand designing research. Hence, while remote teams collaborate in theory, actual\ncooperation centers on late-stage, technical project tasks, involving more\ncodified knowledge. We conclude that despite striking improvements in remote\nwork technology in recent years, remote teams are less likely to integrate\nexisting knowledge to produce new, disruptive ideas. This also provides an\nexplanation for why new ideas are getting harder to find.",
    "descriptor": "",
    "authors": [
      "Yiling Lin",
      "Carl Benedikt Frey",
      "Lingfei Wu"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "General Economics (econ.GN)"
    ],
    "url": "https://arxiv.org/abs/2206.01878"
  },
  {
    "id": "arXiv:2206.01880",
    "title": "Learning in Congestion Games with Bandit Feedback",
    "abstract": "Learning Nash equilibria is a central problem in multi-agent systems. In this\npaper, we investigate congestion games, a class of games with benign\ntheoretical structure and broad real-world applications. We first propose a\ncentralized algorithm based on the optimism in the face of uncertainty\nprinciple for congestion games with (semi-)bandit feedback, and obtain\nfinite-sample guarantees. Then we propose a decentralized algorithm via a novel\ncombination of the Frank-Wolfe method and G-optimal design. By exploiting the\nstructure of the congestion game, we show the sample complexity of both\nalgorithms depends only polynomially on the number of players and the number of\nfacilities, but not the size of the action set, which can be exponentially\nlarge in terms of the number of facilities. We further define a new problem\nclass, Markov congestion games, which allows us to model the non-stationarity\nin congestion games. We propose a centralized algorithm for Markov congestion\ngames, whose sample complexity again has only polynomial dependence on all\nrelevant problem parameters, but not the size of the action set.",
    "descriptor": "\nComments: 33 pages\n",
    "authors": [
      "Qiwen Cui",
      "Zhihan Xiong",
      "Maryam Fazel",
      "Simon S. Du"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.01880"
  },
  {
    "id": "arXiv:2206.01881",
    "title": "Face Recognition Accuracy Across Demographics: Shining a Light Into the  Problem",
    "abstract": "This is the first work that we are aware of to explore how the level of\nbrightness of the skin region in a pair of face images impacts face recognition\naccuracy. Image pairs with both images having mean face skin brightness in an\nupper-middle range of brightness are found to have the highest matching\naccuracy across demographics and matchers. Image pairs with both images having\nmean face skin brightness that is too dark or too light are found to have an\nincreased false match rate (FMR). Image pairs with strongly different face skin\nbrightness are found to have decreased FMR and increased false non-match rate\n(FNMR). Using a brightness information metric that captures the variation in\nbrightness in the face skin region, the variation in matching accuracy is shown\nto correlate with the level of information available in the face skin region.\nFor operational scenarios where image acquisition is controlled, we propose\nacquiring images with lighting adjusted to yield face skin brightness in a\nnarrow range.",
    "descriptor": "",
    "authors": [
      "Haiyu Wu",
      "V\u00edtor Albiero",
      "K. S. Krishnapriya",
      "Michael C. King",
      "Kevin W. Bowyer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01881"
  },
  {
    "id": "arXiv:2206.01882",
    "title": "Study of Robust Adaptive Power Allocation Techniques for Rate Splitting  based MU-MIMO systems",
    "abstract": "Rate splitting (RS) systems can better deal with imperfect channel state\ninformation at the transmitter (CSIT) than conventional approaches. However,\nthis requires an appropriate power allocation that often has a high\ncomputational complexity, which might be inadequate for practical and large\nsystems. To this end, adaptive power allocation techniques can provide good\nperformance with low computational cost. This work presents novel robust and\nadaptive power allocation technique for RS-based multiuser multiple-input\nmultiple-output (MU-MIMO) systems. In particular, we develop a robust adaptive\npower allocation based on stochastic gradient learning and the minimization of\nthe mean-square error between the transmitted symbols of the RS system and the\nreceived signal. The proposed robust power allocation strategy incorporates\nknowledge of the variance of the channel errors to deal with imperfect CSIT and\nadjust power levels in the presence of uncertainty. An analysis of the\nconvexity and stability of the proposed power allocation algorithms is\nprovided, together with a study of their computational complexity and\ntheoretical bounds relating the power allocation strategies. Numerical results\nshow that the sum-rate of an RS system with adaptive power allocation\noutperforms RS and conventional MU-MIMO systems under imperfect CSIT.\n%\\vspace{-0.75em}",
    "descriptor": "\nComments: 27 pages, 10 figures\n",
    "authors": [
      "A. R. Flores",
      "R. C. de Lamare"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.01882"
  },
  {
    "id": "arXiv:2206.01883",
    "title": "A symmetrized parametric finite element method for anisotropic surface  diffusion ii. three dimensions",
    "abstract": "For the evolution of a closed surface under anisotropic surface diffusion\nwith a general anisotropic surface energy $\\gamma(\\boldsymbol{n})$ in three\ndimensions (3D), where $\\boldsymbol{n}$ is the unit outward normal vector, by\nintroducing a novel symmetric positive definite surface energy matrix\n$\\boldsymbol{Z}_k(\\boldsymbol{n})$ depending on a stabilizing function\n$k(\\boldsymbol{n})$ and the Cahn-Hoffman $\\boldsymbol{\\xi}$-vector, we present\na new symmetrized variational formulation for anisotropic surface diffusion\nwith weakly or strongly anisotropic surface energy, which preserves two\nimportant structures including volume conservation and energy dissipation. Then\nwe propose a structural-preserving parametric finite element method (SP-PFEM)\nto discretize the symmetrized variational problem, which preserves the volume\nin the discretized level. Under a relatively mild and simple condition on\n$\\gamma(\\boldsymbol{n})$, we show that SP-PFEM is unconditionally energy-stable\nfor almost all anisotropic surface energies $\\gamma(\\boldsymbol{n})$ arising in\npractical applications. Extensive numerical results are reported to demonstrate\nthe efficiency and accuracy as well as energy dissipation of the proposed\nSP-PFEM for solving anisotropic surface diffusion in 3D.",
    "descriptor": "",
    "authors": [
      "Weizhu Bao",
      "Yifei Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.01883"
  },
  {
    "id": "arXiv:2206.01884",
    "title": "A Superimposed Divide-and-Conquer Image Recognition Method for SEM  Images of Nanoparticles on The Surface of Monocrystalline silicon with High  Aggregation Degree",
    "abstract": "The nanoparticle size and distribution information in the SEM images of\nsilicon crystals are generally counted by manual methods. The realization of\nautomatic machine recognition is significant in materials science. This paper\nproposed a superposition partitioning image recognition method to realize\nautomatic recognition and information statistics of silicon crystal\nnanoparticle SEM images. Especially for the complex and highly aggregated\ncharacteristics of silicon crystal particle size, an accurate recognition step\nand contour statistics method based on morphological processing are given. This\nmethod has technical reference value for the recognition of Monocrystalline\nsilicon surface nanoparticle images under different SEM shooting conditions.\nBesides, it outperforms other methods in terms of recognition accuracy and\nalgorithm efficiency.",
    "descriptor": "",
    "authors": [
      "Ruiling Xiao",
      "Jiayang Niu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.01884"
  },
  {
    "id": "arXiv:2206.01885",
    "title": "Data-driven Construction of Hierarchical Matrices with Nested Bases",
    "abstract": "Hierarchical matrices provide a powerful representation for significantly\nreducing the computational complexity associated with dense kernel matrices.\nFor general kernel functions, interpolation-based methods are widely used for\nthe efficient construction of hierarchical matrices. In this paper, we present\na fast hierarchical data reduction (HiDR) procedure with $O(n)$ complexity for\nthe memory-efficient construction of hierarchical matrices with nested bases\nwhere $n$ is the number of data points. HiDR aims to reduce the given data in a\nhierarchical way so as to obtain $O(1)$ representations for all nearfield and\nfarfield interactions. Based on HiDR, a linear complexity $\\mathcal{H}^2$\nmatrix construction algorithm is proposed. The use of data-driven methods\nenables {better efficiency than other general-purpose methods} and flexible\ncomputation without accessing the kernel function. Experiments demonstrate\nsignificantly improved memory efficiency of the proposed data-driven method\ncompared to interpolation-based methods over a wide range of kernels. Though\nthe method is not optimized for any special kernel, benchmark experiments for\nthe Coulomb kernel show that the proposed general-purpose algorithm offers\ncompetitive performance for hierarchical matrix construction compared to\nseveral state-of-the-art algorithms for the Coulomb kernel.",
    "descriptor": "\nComments: 26 pages, 20 figures\n",
    "authors": [
      "Difeng Cai",
      "Hua Huang",
      "Edmond Chow",
      "Yuanzhe Xi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.01885"
  },
  {
    "id": "arXiv:2206.01888",
    "title": "Reward Poisoning Attacks on Offline Multi-Agent Reinforcement Learning",
    "abstract": "We expose the danger of reward poisoning in offline multi-agent reinforcement\nlearning (MARL), whereby an attacker can modify the reward vectors to different\nlearners in an offline data set while incurring a poisoning cost. Based on the\npoisoned data set, all rational learners using some confidence-bound-based MARL\nalgorithm will infer that a target policy - chosen by the attacker and not\nnecessarily a solution concept originally - is the Markov perfect dominant\nstrategy equilibrium for the underlying Markov Game, hence they will adopt this\npotentially damaging target policy in the future. We characterize the exact\nconditions under which the attacker can install a target policy. We further\nshow how the attacker can formulate a linear program to minimize its poisoning\ncost. Our work shows the need for robust MARL against adversarial attacks.",
    "descriptor": "",
    "authors": [
      "Young Wu",
      "Jermey McMahan",
      "Xiaojin Zhu",
      "Qiaomin Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2206.01888"
  },
  {
    "id": "arXiv:2206.01889",
    "title": "Initial Study into Application of Feature Density and  Linguistically-backed Embedding to Improve Machine Learning-based  Cyberbullying Detection",
    "abstract": "In this research, we study the change in the performance of machine learning\n(ML) classifiers when various linguistic preprocessing methods of a dataset\nwere used, with the specific focus on linguistically-backed embeddings in\nConvolutional Neural Networks (CNN). Moreover, we study the concept of Feature\nDensity and confirm its potential to comparatively predict the performance of\nML classifiers, including CNN. The research was conducted on a Formspring\ndataset provided in a Kaggle competition on automatic cyberbullying detection.\nThe dataset was re-annotated by objective experts (psychologists), as the\nimportance of professional annotation in cyberbullying research has been\nindicated multiple times. The study confirmed the effectiveness of Neural\nNetworks in cyberbullying detection and the correlation between classifier\nperformance and Feature Density while also proposing a new approach of training\nvarious linguistically-backed embeddings for Convolutional Neural Networks.",
    "descriptor": "",
    "authors": [
      "Juuso Eronen",
      "Michal Ptaszynski",
      "Fumito Masui",
      "Gniewosz Leliwa",
      "Michal Wroczynski",
      "Mateusz Piech",
      "Aleksander Smywinski-Pohl"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01889"
  },
  {
    "id": "arXiv:2206.01894",
    "title": "Soft Retargeting Network for Click Through Rate Prediction",
    "abstract": "The study of user interest models has received a great deal of attention in\nclick through rate (CTR) prediction recently. These models aim at capturing\nuser interest from different perspectives, including user interest evolution,\nsession interest, multiple interests, etc. In this paper, we focus on a new\ntype of user interest, i.e., user retargeting interest. User retargeting\ninterest is defined as user's click interest on target items the same as or\nsimilar to historical click items. We propose a novel soft retargeting network\n(SRN) to model this specific interest. Specifically, we first calculate the\nsimilarity between target item and each historical item with the help of graph\nembedding. Then we learn to aggregate the similarity weights to measure the\nextent of user's click interest on target item. Furthermore, we model the\nevolution of user retargeting interest. Experimental results on public datasets\nand industrial dataset demonstrate that our model achieves significant\nimprovements over state-of-the-art models.",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Xiaochen Li",
      "Xin Song",
      "Pengjia Yuan",
      "Xialong Liu",
      "Yu Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.01894"
  },
  {
    "id": "arXiv:2206.01895",
    "title": "Receding Horizon Navigation and Target Tracking for Aerial Detection of  Transient Radioactivity",
    "abstract": "The paper presents a receding horizon planning and control strategy for\nquadrotor-type \\ac{mav}s to navigate reactively and intercept a moving target\nin a cluttered unknown and dynamic environment. Leveraging a lightweight\nshort-range sensor that generates a point-cloud within a relatively narrow and\nshort \\ac{fov}, and an \\acs{ssd}-MobileNet based Deep neural network running on\nboard the \\ac{mav}, the proposed motion planning and control strategy produces\nsafe and dynamically feasible \\ac{mav} trajectories within the sensor\n\\acs{fov}, which the vehicle uses to autonomously navigate, pursue, and\nintercept its moving target. This task is completed without reliance on a\nglobal planner or prior information about the environment or the moving target.\nThe effectiveness of the reported planner is demonstrated numerically and\nexperimentally in cluttered indoor and outdoor environments featuring maximum\nspeeds of up to 4.5-5~m/s.",
    "descriptor": "",
    "authors": [
      "Indrajeet Yadav",
      "Micheal Sebok",
      "Herbert G Tanner"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.01895"
  },
  {
    "id": "arXiv:2206.01896",
    "title": "Adaptive Tree Backup Algorithms for Temporal-Difference Reinforcement  Learning",
    "abstract": "Q($\\sigma$) is a recently proposed temporal-difference learning method that\ninterpolates between learning from expected backups and sampled backups. It has\nbeen shown that intermediate values for the interpolation parameter $\\sigma \\in\n[0,1]$ perform better in practice, and therefore it is commonly believed that\n$\\sigma$ functions as a bias-variance trade-off parameter to achieve these\nimprovements. In our work, we disprove this notion, showing that the choice of\n$\\sigma=0$ minimizes variance without increasing bias. This indicates that\n$\\sigma$ must have some other effect on learning that is not fully understood.\nAs an alternative, we hypothesize the existence of a new trade-off: larger\n$\\sigma$-values help overcome poor initializations of the value function, at\nthe expense of higher statistical variance. To automatically balance these\nconsiderations, we propose Adaptive Tree Backup (ATB) methods, whose weighted\nbackups evolve as the agent gains experience. Our experiments demonstrate that\nadaptive strategies can be more effective than relying on fixed or\ntime-annealed $\\sigma$-values.",
    "descriptor": "\nComments: RLDM 2022. 4 pages, 1 figure\n",
    "authors": [
      "Brett Daley",
      "Isaac Chan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01896"
  },
  {
    "id": "arXiv:2206.01898",
    "title": "Saliency Attack: Towards Imperceptible Black-box Adversarial Attack",
    "abstract": "Deep neural networks are vulnerable to adversarial examples, even in the\nblack-box setting where the attacker is only accessible to the model output.\nRecent studies have devised effective black-box attacks with high query\nefficiency. However, such performance is often accompanied by compromises in\nattack imperceptibility, hindering the practical use of these approaches. In\nthis paper, we propose to restrict the perturbations to a small salient region\nto generate adversarial examples that can hardly be perceived. This approach is\nreadily compatible with many existing black-box attacks and can significantly\nimprove their imperceptibility with little degradation in attack success rate.\nFurther, we propose the Saliency Attack, a new black-box attack aiming to\nrefine the perturbations in the salient region to achieve even better\nimperceptibility. Extensive experiments show that compared to the\nstate-of-the-art black-box attacks, our approach achieves much better\nimperceptibility scores, including most apparent distortion (MAD), $L_0$ and\n$L_2$ distances, and also obtains significantly higher success rates judged by\na human-like threshold on MAD. Importantly, the perturbations generated by our\napproach are interpretable to some extent. Finally, it is also demonstrated to\nbe robust to different detection-based defenses.",
    "descriptor": "",
    "authors": [
      "Zeyu Dai",
      "Shengcai Liu",
      "Ke Tang",
      "Qing Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01898"
  },
  {
    "id": "arXiv:2206.01899",
    "title": "Evaluation of creating scoring opportunities for teammates in soccer via  trajectory prediction",
    "abstract": "Evaluating the individual movements for teammates in soccer players is\ncrucial for assessing teamwork, scouting, and fan engagement. It has been said\nthat players in a 90-min game do not have the ball for about 87 minutes on\naverage. However, it has remained difficult to evaluate an attacking player\nwithout receiving the ball, and to reveal how movement contributes to the\ncreation of scoring opportunities for teammates. In this paper, we evaluate\nplayers who create off-ball scoring opportunities by comparing actual movements\nwith the reference movements generated via trajectory prediction. First, we\npredict the trajectories of players using a graph variational recurrent neural\nnetwork that can accurately model the relationship between players and predict\nthe long-term trajectory. Next, based on the difference in the modified\noff-ball evaluation index between the actual and the predicted trajectory as a\nreference, we evaluate how the actual movement contributes to scoring\nopportunity compared to the predicted movement. For verification, we examined\nthe relationship with the annual salary, the goals, and the rating in the game\nby experts for all games of a team in a professional soccer league in a year.\nThe results show that the annual salary and the proposed indicator correlated\nsignificantly, which could not be explained by the existing indicators and\ngoals. Our results suggest the effectiveness of the proposed method as an\nindicator for a player without the ball to create a scoring chance for\nteammates.",
    "descriptor": "\nComments: 22 pages, 8 figures. arXiv admin note: text overlap with arXiv:1803.07612 by other authors\n",
    "authors": [
      "Masakiyo Teranishi",
      "Kazushi Tsutsui",
      "Kazuya Takeda",
      "Keisuke Fujii"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2206.01899"
  },
  {
    "id": "arXiv:2206.01900",
    "title": "Estimating counterfactual treatment outcomes over time in complex  multi-agent scenarios",
    "abstract": "Evaluation of intervention in a multi-agent system, e.g., when humans should\nintervene in autonomous driving systems and when a player should pass to\nteammates for a good shot, is challenging in various engineering and scientific\nfields. Estimating the individual treatment effect (ITE) using counterfactual\nlong-term prediction is practical to evaluate such interventions. However, most\nof the conventional frameworks did not consider the time-varying complex\nstructure of multi-agent relationships and covariate counterfactual prediction.\nThis may sometimes lead to erroneous assessments of ITE and interpretation\nproblems. Here we propose an interpretable, counterfactual recurrent network in\nmulti-agent systems to estimate the effect of the intervention. Our model\nleverages graph variational recurrent neural networks and theory-based\ncomputation with domain knowledge for the ITE estimation framework based on\nlong-term prediction of multi-agent covariates and outcomes, which can confirm\nunder the circumstances under which the intervention is effective. On simulated\nmodels of an automated vehicle and biological agents with time-varying\nconfounders, we show that our methods achieved lower estimation errors in\ncounterfactual covariates and the most effective treatment timing than the\nbaselines. Furthermore, using real basketball data, our methods performed\nrealistic counterfactual predictions and evaluated the counterfactual passes in\nshot scenarios.",
    "descriptor": "\nComments: 13 pages, 6 figures\n",
    "authors": [
      "Keisuke Fujii",
      "Koh Takeuchi",
      "Atsushi Kuribayashi",
      "Naoya Takeishi",
      "Yoshinobu Kawahara",
      "Kazuya Takeda"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.01900"
  },
  {
    "id": "arXiv:2206.01901",
    "title": "Enabling Heterogeneous, Multicore SoC Research with RISC-V and ESP",
    "abstract": "Heterogeneous, multicore SoC architectures are a critical component of\ntoday's computing landscape. However, supporting both increasing heterogeneity\nand multicore execution are significant design challenges. Meanwhile, the\ngrowing RISC-V and open-source hardware (OSH) movements have resulted in an\nincreased number of open-source RISC-V processor implementations; however,\nthere are fewer open source SoC design platforms that integrate these processor\ncores. We present modifications to ESP, an open-source SoC design platform, to\nenable multicore execution with the RISC-V CVA6 processor. Our implementation\nis modular and based on standardized interfaces. These properties simplify the\nintegration of new cores. Our modifications enable RISC-V-based SoCs designed\nwith ESP for FPGA to boot Linux SMP and execute multithreaded applications.\nCoupled with ESP's emphasis on accelerator-centric architectures, our\ncontributions enable the seamless design of a wide range of heterogeneous,\nmulticore SoCs.",
    "descriptor": "\nComments: To appear in the Sixth Workshop on Computer Architecture Research with RISC-V (CARRV 2022)\n",
    "authors": [
      "Joseph Zuckerman",
      "Paolo Mantovani",
      "Davide Giri",
      "Luca P. Carloni"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2206.01901"
  },
  {
    "id": "arXiv:2206.01904",
    "title": "Soft Adversarial Training Can Retain Natural Accuracy",
    "abstract": "Adversarial training for neural networks has been in the limelight in recent\nyears. The advancement in neural network architectures over the last decade has\nled to significant improvement in their performance. It sparked an interest in\ntheir deployment for real-time applications. This process initiated the need to\nunderstand the vulnerability of these models to adversarial attacks. It is\ninstrumental in designing models that are robust against adversaries. Recent\nworks have proposed novel techniques to counter the adversaries, most often\nsacrificing natural accuracy. Most suggest training with an adversarial version\nof the inputs, constantly moving away from the original distribution. The focus\nof our work is to use abstract certification to extract a subset of inputs for\n(hence we call it 'soft') adversarial training. We propose a training framework\nthat can retain natural accuracy without sacrificing robustness in a\nconstrained setting. Our framework specifically targets moderately critical\napplications which require a reasonable balance between robustness and\naccuracy. The results testify to the idea of soft adversarial training for the\ndefense against adversarial attacks. At last, we propose the scope of future\nwork for further improvement of this framework.",
    "descriptor": "\nComments: 7 pages, 6 figures\n",
    "authors": [
      "Abhijith Sharma",
      "Apurva Narayan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.01904"
  },
  {
    "id": "arXiv:2206.01905",
    "title": "Distributed processing of continuous range queries over moving objects",
    "abstract": "Monitoring range queries over moving objects is essential to extensive\nlocation-based services. The challenge faced with these location-based services\nis having to process numerous concurrent range queries over a large volume of\nmoving objects. However, the existing range query processing algorithms are\nalmost centralized based on one single machine, which are hard to address the\nchallenge due to the limited memory and computing resources. To address this\nissue, we propose a distributed search solution for processing concurrent range\nqueries over moving objects in this work. Firstly, a Distributed Dynamic Index\n(DDI) that consists of a global grid index and local dynamic M-ary tree indexes\nwas proposed to maintain the moving objects and support the search algorithm.\nNext, a Distributed Range Query Algorithm (DRQA) was designed based on DDI,\nwhich introduces an incremental search strategy to monitor the range queries as\nobjects evolve; during the process, it further designs a computation sharing\nparadigm for processing multiple concurrent queries by making full use of their\ncommon computation to decrease the search cost. Finally, three object datasets\nwith different distributions were simulated on a New York road network and\nthree baseline methods were introduced to more sufficiently evaluate the\nperformance of our proposal. Compared with state-of-the-art method, the initial\nquery cost of the DRQA algorithm reduces by $22.7\\%$ and the incremental query\ncost drops by 15.2%, which certifies the superiority of our method over\nexisting approaches.",
    "descriptor": "",
    "authors": [
      "Hui Zhu",
      "Ziqiang Yu"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2206.01905"
  },
  {
    "id": "arXiv:2206.01906",
    "title": "Hybrid Architectures for Distributed Machine Learning in Heterogeneous  Wireless Networks",
    "abstract": "The ever-growing data privacy concerns have transformed machine learning (ML)\narchitectures from centralized to distributed, leading to federated learning\n(FL) and split learning (SL) as the two most popular privacy-preserving ML\nparadigms. However, implementing either conventional FL or SL alone with\ndiverse network conditions (e.g., device-to-device (D2D) and cellular\ncommunications) and heterogeneous clients (e.g., heterogeneous\ncomputation/communication/energy capabilities) may face significant challenges,\nparticularly poor architecture scalability and long training time. To this end,\nthis article proposes two novel hybrid distributed ML architectures, namely,\nhybrid split FL (HSFL) and hybrid federated SL (HFSL), by combining the\nadvantages of both FL and SL in D2D-enabled heterogeneous wireless networks.\nSpecifically, the performance comparison and advantages of HSFL and HFSL are\nanalyzed generally. Promising open research directions are presented to offer\ncommendable reference for future research. Finally, primary simulations are\nconducted upon considering three datasets under non-independent and identically\ndistributed settings, to verify the feasibility of our proposed architectures,\nwhich can significantly reduce communication/computation cost and training\ntime, as compared with conventional FL and SL.",
    "descriptor": "\nComments: 8 pages,3 figures\n",
    "authors": [
      "Zhipeng Cheng",
      "Xuwei Fan",
      "Minghui Liwang",
      "Minghui Min",
      "Xianbin Wang",
      "Xiaojiang Du"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.01906"
  },
  {
    "id": "arXiv:2206.01908",
    "title": "Video-based Human-Object Interaction Detection from Tubelet Tokens",
    "abstract": "We present a novel vision Transformer, named TUTOR, which is able to learn\ntubelet tokens, served as highly-abstracted spatiotemporal representations, for\nvideo-based human-object interaction (V-HOI) detection. The tubelet tokens\nstructurize videos by agglomerating and linking semantically-related patch\ntokens along spatial and temporal domains, which enjoy two benefits: 1)\nCompactness: each tubelet token is learned by a selective attention mechanism\nto reduce redundant spatial dependencies from others; 2) Expressiveness: each\ntubelet token is enabled to align with a semantic instance, i.e., an object or\na human, across frames, thanks to agglomeration and linking. The effectiveness\nand efficiency of TUTOR are verified by extensive experiments. Results shows\nour method outperforms existing works by large margins, with a relative mAP\ngain of $16.14\\%$ on VidHOI and a 2 points gain on CAD-120 as well as a $4\n\\times$ speedup.",
    "descriptor": "",
    "authors": [
      "Danyang Tu",
      "Wei Sun",
      "Xiongkuo Min",
      "Guangtao Zhai",
      "Wei Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01908"
  },
  {
    "id": "arXiv:2206.01909",
    "title": "Toward Learning Robust and Invariant Representations with Alignment  Regularization and Data Augmentation",
    "abstract": "Data augmentation has been proven to be an effective technique for developing\nmachine learning models that are robust to known classes of distributional\nshifts (e.g., rotations of images), and alignment regularization is a technique\noften used together with data augmentation to further help the model learn\nrepresentations invariant to the shifts used to augment the data. In this\npaper, motivated by a proliferation of options of alignment regularizations, we\nseek to evaluate the performances of several popular design choices along the\ndimensions of robustness and invariance, for which we introduce a new test\nprocedure. Our synthetic experiment results speak to the benefits of squared l2\nnorm regularization. Further, we also formally analyze the behavior of\nalignment regularization to complement our empirical study under assumptions we\nconsider realistic. Finally, we test this simple technique we identify\n(worst-case data augmentation with squared l2 norm alignment regularization)\nand show that the benefits of this method outrun those of the specially\ndesigned methods. We also release a software package in both TensorFlow and\nPyTorch for users to use the method with a couple of lines at\nhttps://github.com/jyanln/AlignReg.",
    "descriptor": "\nComments: to appear at KDD 2022, the software package is at this https URL arXiv admin note: text overlap with arXiv:2011.13052\n",
    "authors": [
      "Haohan Wang",
      "Zeyi Huang",
      "Xindi Wu",
      "Eric P. Xing"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01909"
  },
  {
    "id": "arXiv:2206.01910",
    "title": "The Spike Gating Flow: A Hierarchical Structure Based Spiking Neural  Network for Online Gesture Recognition",
    "abstract": "Action recognition is an exciting research avenue for artificial intelligence\nsince it may be a game changer in the emerging industrial fields such as\nrobotic visions and automobiles. However, current deep learning faces major\nchallenges for such applications because of the huge computational cost and the\ninefficient learning. Hence, we develop a novel brain-inspired Spiking Neural\nNetwork (SNN) based system titled Spiking Gating Flow (SGF) for online action\nlearning. The developed system consists of multiple SGF units which assembled\nin a hierarchical manner. A single SGF unit involves three layers: a feature\nextraction layer, an event-driven layer and a histogram-based training layer.\nTo demonstrate the developed system capabilities, we employ a standard Dynamic\nVision Sensor (DVS) gesture classification as a benchmark. The results indicate\nthat we can achieve 87.5% accuracy which is comparable with Deep Learning (DL),\nbut at smaller training/inference data number ratio 1.5:1. And only a single\ntraining epoch is required during the learning process. Meanwhile, to the best\nof our knowledge, this is the highest accuracy among the non-backpropagation\nalgorithm based SNNs. At last, we conclude the few-shot learning paradigm of\nthe developed network: 1) a hierarchical structure-based network design\ninvolves human prior knowledge; 2) SNNs for content based global dynamic\nfeature detection.",
    "descriptor": "",
    "authors": [
      "Zihao Zhao",
      "Yanhong Wang",
      "Qiaosha Zou",
      "Tie Xu",
      "Fangbo Tao",
      "Jiansong Zhang",
      "Xiaoan Wang",
      "C.-J. Richard Shi",
      "Junwen Luo",
      "Yuan Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.01910"
  },
  {
    "id": "arXiv:2206.01912",
    "title": "Markovian Decentralized Ensemble Control for Demand Response",
    "abstract": "With the advancement in smart grid and smart energy devices, demand response\nbecomes one of the most economic and feasible solutions to ease the load stress\nof the power grids during peak hours. In this work, we propose a fully\ndecentralized ensemble control framework with consensus for demand response\n(DR) events and compatible control methods based on random policies. We show\nthat under the consensus that is tailored to DR, our proposed decentralized\ncontrol method yields the same optimality as the centralized control method in\nboth myopic and multistage settings.",
    "descriptor": "",
    "authors": [
      "Guanze Peng",
      "Robert Mieth",
      "Deepjyoti Deka",
      "Yury Dvorkin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.01912"
  },
  {
    "id": "arXiv:2206.01913",
    "title": "Neural Lyapunov Control of Unknown Nonlinear Systems with Stability  Guarantees",
    "abstract": "Learning for control of dynamical systems with formal guarantees remains a\nchallenging task. This paper proposes a learning framework to simultaneously\nstabilize an unknown nonlinear system with a neural controller and learn a\nneural Lyapunov function to certify a region of attraction (ROA) for the\nclosed-loop system. The algorithmic structure consists of two neural networks\nand a satisfiability modulo theories (SMT) solver. The first neural network is\nresponsible for learning the unknown dynamics. The second neural network aims\nto identify a valid Lyapunov function and a provably stabilizing nonlinear\ncontroller. The SMT solver then verifies that the candidate Lyapunov function\nindeed satisfies the Lyapunov conditions. We provide theoretical guarantees of\nthe proposed learning framework in terms of the closed-loop stability for the\nunknown nonlinear system. We illustrate the effectiveness of the approach with\na set of numerical experiments.",
    "descriptor": "",
    "authors": [
      "Ruikun Zhou",
      "Thanin Quartz",
      "Hans De Sterck",
      "Jun Liu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.01913"
  },
  {
    "id": "arXiv:2206.01914",
    "title": "Achievement of Objectives of Library Information Management: Result of  Right Structuring of Library Network System",
    "abstract": "The world is transforming through a revolution and development in the\nprogression of information and its broadcasting. The number of research\njournals, books and reports being published the world over has been increasing\nphenomenally. Currently, about five lakh books, one lakh periodicals, lakhs of\npatents, thousands of standards and numerous other types of documents are being\npublished every year. The hypothesis was tested using SPSS to obtain\ncovariances by going to Analyze Correlate Bivariate, A Likert type scale was\nprepared and used to capture the feedback using the feedback survey Total 90\nlibrary staff were asked to complete this survey through questionnaires.",
    "descriptor": "",
    "authors": [
      "Vikash Prajapat",
      "Dr. Rupali Dilip Taru"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.01914"
  },
  {
    "id": "arXiv:2206.01916",
    "title": "Nerfels: Renderable Neural Codes for Improved Camera Pose Estimation",
    "abstract": "This paper presents a framework that combines traditional keypoint-based\ncamera pose optimization with an invertible neural rendering mechanism. Our\nproposed 3D scene representation, Nerfels, is locally dense yet globally\nsparse. As opposed to existing invertible neural rendering systems which\noverfit a model to the entire scene, we adopt a feature-driven approach for\nrepresenting scene-agnostic, local 3D patches with renderable codes. By\nmodelling a scene only where local features are detected, our framework\neffectively generalizes to unseen local regions in the scene via an optimizable\ncode conditioning mechanism in the neural renderer, all while maintaining the\nlow memory footprint of a sparse 3D map representation. Our model can be\nincorporated to existing state-of-the-art hand-crafted and learned local\nfeature pose estimators, yielding improved performance when evaluating on\nScanNet for wide camera baseline scenarios.",
    "descriptor": "\nComments: Published at CVPRW with supplementary material\n",
    "authors": [
      "Gil Avraham",
      "Julian Straub",
      "Tianwei Shen",
      "Tsun-Yi Yang",
      "Hugo Germain",
      "Chris Sweeney",
      "Vasileios Balntas",
      "David Novotny",
      "Daniel DeTone",
      "Richard Newcombe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01916"
  },
  {
    "id": "arXiv:2206.01918",
    "title": "Automated Audio Captioning with Epochal Difficult Captions for  Curriculum Learning",
    "abstract": "In this paper, we propose an algorithm, Epochal Difficult Captions, to\nsupplement the training of any model for the Automated Audio Captioning task.\nEpochal Difficult Captions is an elegant evolution to the keyword estimation\ntask that previous work have used to train the encoder of the AAC model.\nEpochal Difficult Captions modifies the target captions based on a curriculum\nand a difficulty level determined as a function of current epoch. Epochal\nDifficult Captions can be used with any model architecture and is a lightweight\nfunction that does not increase training time. We test our results on three\nsystems and show that using Epochal Difficult Captions consistently improves\nperformance",
    "descriptor": "\nComments: 4 content pages, 1 reference page\n",
    "authors": [
      "Andrew Koh",
      "Soham Tiwari",
      "Chng Eng Siong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.01918"
  },
  {
    "id": "arXiv:2206.01919",
    "title": "Leveraging Machine Learning for Ransomware Detection",
    "abstract": "The current pandemic situation has increased cyber-attacks drastically\nworldwide. The attackers are using malware like trojans, spyware, rootkits,\nworms, ransomware heavily. Ransomware is the most notorious malware, yet we did\nnot have any defensive mechanism to prevent or detect a zero-day attack. Most\ndefensive products in the industry rely on either signature-based mechanisms or\ntraffic-based anomalies detection. Therefore, researchers are adopting machine\nlearning and deep learning to develop a behaviour-based mechanism for detecting\nmalware. Though we have some hybrid mechanisms that perform static and dynamic\nanalysis of executable for detection, we have not any full proof detection\nproof of concept, which can be used to develop a full proof product specific to\nransomware. In this work, we have developed a proof of concept for ransomware\ndetection using machine learning models. We have done detailed analysis and\ncompared efficiency between several machine learning models like decision tree,\nrandom forest, KNN, SVM, XGBoost and Logistic Regression. We obtained 98.21%\naccuracy and evaluated various metrics like precision, recall, TP, TN, FP, and\nFN.",
    "descriptor": "",
    "authors": [
      "Nanda Rani",
      "Sunita Vikrant Dhavale"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.01919"
  },
  {
    "id": "arXiv:2206.01922",
    "title": "Classification at the Accuracy Limit -- Facing the Problem of Data  Ambiguity",
    "abstract": "Data classification, the process of analyzing data and organizing it into\ncategories, is a fundamental computing problem of natural and artificial\ninformation processing systems. Ideally, the performance of classifier models\nwould be evaluated using unambiguous data sets, where the 'correct' assignment\nof category labels to the input data vectors is unequivocal. In real-world\nproblems, however, a significant fraction of actually occurring data vectors\nwill be located in a boundary zone between or outside of all categories, so\nthat perfect classification cannot even in principle be achieved. We derive the\ntheoretical limit for classification accuracy that arises from the overlap of\ndata categories. By using a surrogate data generation model with adjustable\nstatistical properties, we show that sufficiently powerful classifiers based on\ncompletely different principles, such as perceptrons and Bayesian models, all\nperform at this universal accuracy limit. Remarkably, the accuracy limit is not\naffected by applying non-linear transformations to the data, even if these\ntransformations are non-reversible and drastically reduce the information\ncontent of the input data. We compare emerging data embeddings produced by\nsupervised and unsupervised training, using MNIST and human EEG recordings\nduring sleep. We find that categories are not only well separated in the final\nlayers of classifiers trained with back-propagation, but to a smaller degree\nalso after unsupervised dimensionality reduction. This suggests that\nhuman-defined categories, such as hand-written digits or sleep stages, can\nindeed be considered as 'natural kinds'.",
    "descriptor": "",
    "authors": [
      "Claus Metzner",
      "Achim Schilling",
      "Maximilian Traxdorf",
      "Konstantin Tziridis",
      "Holger Schulze",
      "Patrick Krauss"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2206.01922"
  },
  {
    "id": "arXiv:2206.01923",
    "title": "From Pixels to Objects: Cubic Visual Attention for Visual Question  Answering",
    "abstract": "Recently, attention-based Visual Question Answering (VQA) has achieved great\nsuccess by utilizing question to selectively target different visual areas that\nare related to the answer. Existing visual attention models are generally\nplanar, i.e., different channels of the last conv-layer feature map of an image\nshare the same weight. This conflicts with the attention mechanism because CNN\nfeatures are naturally spatial and channel-wise. Also, visual attention models\nare usually conducted on pixel-level, which may cause region discontinuous\nproblems. In this paper, we propose a Cubic Visual Attention (CVA) model by\nsuccessfully applying a novel channel and spatial attention on object regions\nto improve VQA task. Specifically, instead of attending to pixels, we first\ntake advantage of the object proposal networks to generate a set of object\ncandidates and extract their associated conv features. Then, we utilize the\nquestion to guide channel attention and spatial attention calculation based on\nthe con-layer feature map. Finally, the attended visual features and the\nquestion are combined to infer the answer. We assess the performance of our\nproposed CVA on three public image QA datasets, including COCO-QA, VQA and\nVisual7W. Experimental results show that our proposed method significantly\noutperforms the state-of-the-arts.",
    "descriptor": "",
    "authors": [
      "Jingkuan Song",
      "Pengpeng Zeng",
      "Lianli Gao",
      "Heng Tao Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01923"
  },
  {
    "id": "arXiv:2206.01926",
    "title": "Optimal Codeword Construction for DNA-based Finite Automata",
    "abstract": "Biomolecular computation has emerged as an important area of computer science\nresearch due to its high information density, immense parallelism opportunity\nalong with potential applications in cryptography, genetic engineering and\nbioinformatics. Computational frameworks using DNA molecules have been proposed\nin the literature to accomplish varied tasks such as simulating logical\noperations, performing matrix multiplication, and encoding instances of NP-hard\nproblems. In one of the key applications, several studies have proposed\nconstruction of finite automata using DNA hybridisation and ligation. The state\nand symbol encoding of these finite automata are done manually. In this\nmanuscript, we study the codeword construction problem for this approach. We\nderive exact theoretical bounds on the number of symbols and states in the\nfinite automata and also obtain the complete set of symbols in a specific case.\nFor automatic encoding, two different solutions, based on a heuristic and on\nInteger Linear Programming (ILP), are proposed. Furthermore, we propose an\nearly simulation-based validation of laboratory experiments. Our proposed flow\naccepts a finite automaton, automatically encodes the symbols for the actual\nexperiments and executes the simulation step-by-step.",
    "descriptor": "",
    "authors": [
      "Anupam Chattopadhyay",
      "Arnab Chakrabarti"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2206.01926"
  },
  {
    "id": "arXiv:2206.01927",
    "title": "Variational Monte Carlo Approach to Partial Differential Equations with  Neural Networks",
    "abstract": "The accurate numerical solution of partial differential equations is a\ncentral task in numerical analysis allowing to model a wide range of natural\nphenomena by employing specialized solvers depending on the scenario of\napplication. Here, we develop a variational approach for solving partial\ndifferential equations governing the evolution of high dimensional probability\ndistributions. Our approach naturally works on the unbounded continuous domain\nand encodes the full probability density function through its variational\nparameters, which are adapted dynamically during the evolution to optimally\nreflect the dynamics of the density. For the considered benchmark cases we\nobserve excellent agreement with numerical solutions as well as analytical\nsolutions in regimes inaccessible to traditional computational approaches.",
    "descriptor": "\nComments: 6 + 3 pages, 4 figures\n",
    "authors": [
      "Moritz Reh",
      "Martin G\u00e4rttner"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.01927"
  },
  {
    "id": "arXiv:2206.01931",
    "title": "Discovering Ancestral Instrumental Variables for Causal Inference from  Observational Data",
    "abstract": "Instrumental variable (IV) is a powerful approach to inferring the causal\neffect of a treatment on an outcome of interest from observational data even\nwhen there exist latent confounders between the treatment and the outcome.\nHowever, existing IV methods require that an IV is selected and justified with\ndomain knowledge. An invalid IV may lead to biased estimates. Hence,\ndiscovering a valid IV is critical to the applications of IV methods. In this\npaper, we study and design a data-driven algorithm to discover valid IVs from\ndata under mild assumptions. We develop the theory based on partial ancestral\ngraphs (PAGs) to support the search for a set of candidate Ancestral IVs\n(AIVs), and for each possible AIV, the identification of its conditioning set.\nBased on the theory, we propose a data-driven algorithm to discover a pair of\nIVs from data. The experiments on synthetic and real-world datasets show that\nthe developed IV discovery algorithm estimates accurate estimates of causal\neffects in comparison with the state-of-the-art IV based causal effect\nestimators.",
    "descriptor": "\nComments: 10 pages, 5 figures and 1 table\n",
    "authors": [
      "Debo Cheng",
      "Jiuyong Li",
      "Lin Liu",
      "Kui Yu",
      "Thuc Duy Lee",
      "Jixue Liu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.01931"
  },
  {
    "id": "arXiv:2206.01932",
    "title": "Demeter: A Fast and Energy-Efficient Food Profiler using  Hyperdimensional Computing in Memory",
    "abstract": "Food profiling is an essential step in any food monitoring system needed to\nprevent health risks and potential frauds in the food industry. Significant\nimprovements in sequencing technologies are pushing food profiling to become\nthe main computational bottleneck. State-of-the-art profilers are unfortunately\ntoo costly for food profiling.\nOur goal is to design a food profiler that solves the main limitations of\nexisting profilers, namely (1) working on massive data structures and (2)\nincurring considerable data movement, for a real-time monitoring system. To\nthis end, we propose Demeter, the first platform-independent framework for food\nprofiling. Demeter overcomes the first limitation through the use of\nhyperdimensional computing (HDC) and efficiently performs the accurate\nfew-species classification required in food profiling. We overcome the second\nlimitation by the use of an in-memory hardware accelerator for Demeter (named\nAcc-Demeter) based on memristor devices. Acc-Demeter actualizes several\ndomain-specific optimizations and exploits the inherent characteristics of\nmemristors to improve the overall performance and energy consumption of\nAcc-Demeter.\nWe compare Demeter's accuracy with other industrial food profilers using\ndetailed software modeling. We synthesize Acc-Demeter's required hardware using\nUMC's 65nm library by considering an accurate PCM model based on silicon-based\nprototypes. Our evaluations demonstrate that Acc-Demeter achieves a (1)\nthroughput improvement of 192x and 724x and (2) memory reduction of 36x and 33x\ncompared to Kraken2 and MetaCache (2 state-of-the-art profilers), respectively,\non typical food-related databases. Demeter maintains an acceptable profiling\naccuracy (within 2% of existing tools) and incurs a very low area overhead.",
    "descriptor": "",
    "authors": [
      "Taha Shahroodi",
      "Mahdi Zahedi",
      "Can Firtina",
      "Mohammed Alser",
      "Stephan Wong",
      "Onur Mutlu",
      "Said Hamdioui"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Genomics (q-bio.GN)"
    ],
    "url": "https://arxiv.org/abs/2206.01932"
  },
  {
    "id": "arXiv:2206.01934",
    "title": "Stochastic Multiple Target Sampling Gradient Descent",
    "abstract": "Sampling from an unnormalized target distribution is an essential problem\nwith many applications in probabilistic inference. Stein Variational Gradient\nDescent (SVGD) has been shown to be a powerful method that iteratively updates\na set of particles to approximate the distribution of interest. Furthermore,\nwhen analysing its asymptotic properties, SVGD reduces exactly to a\nsingle-objective optimization problem and can be viewed as a probabilistic\nversion of this single-objective optimization problem. A natural question then\narises: \"Can we derive a probabilistic version of the multi-objective\noptimization?\". To answer this question, we propose Stochastic Multiple Target\nSampling Gradient Descent (MT-SGD), enabling us to sample from multiple\nunnormalized target distributions. Specifically, our MT-SGD conducts a flow of\nintermediate distributions gradually orienting to multiple target\ndistributions, which allows the sampled particles to move to the joint\nhigh-likelihood region of the target distributions. Interestingly, the\nasymptotic analysis shows that our approach reduces exactly to the\nmultiple-gradient descent algorithm for multi-objective optimization, as\nexpected. Finally, we conduct comprehensive experiments to demonstrate the\nmerit of our approach to multi-task learning.",
    "descriptor": "\nComments: 23 pages\n",
    "authors": [
      "Hoang Phan",
      "Ngoc Tran",
      "Trung Le",
      "Toan Tran",
      "Nhat Ho",
      "Dinh Phung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.01934"
  },
  {
    "id": "arXiv:2206.01936",
    "title": "DOBC-Based Frequency & Voltage Regulation Strategy for PV-Diesel Hybrid  Microgrid During Islanding Conditions",
    "abstract": "This paper proposes a disturbance observer-based control (DOBC) method for\nfrequency and voltage regulation of a solar photovoltaic (PV)-diesel\ngenerator(DG) based hybrid microgrid during islanding conditions. The DOBC is\nintegrated as a feed-forward control to the synchronous generator based DG,\nwhich handles real-time power mismatches and regulates the microgrid frequency\nand voltage under islanding. To substantiate the operational robustness of the\ndeveloped controller under real-time uncertainties arising due to variability\nin PV output and load, the controller has been tested under worstcase\nuncertainty conditions. The proposed controller has been developed as a\nMATLAB/Simulink model and the results are validated on the real-time simulator\nOPAL-RT. The effectiveness of the proposed control scheme has further been\nvalidated in the presence of communication delays and noisy load conditions.\nResults verify the dynamic performance of the controller in regulating the\nsystem frequency and voltage for low-inertia microgrids. Finally, the proposed\ncontrol strategy has been implemented on laboratory scale microgrid setup in\nwhich synchronous generator based diesel generator regulates system frequency\nfast and efficiently under worst case uncertainty scenario.",
    "descriptor": "",
    "authors": [
      "Himanshu Grover",
      "Ashu Verma",
      "T. S. Bhatti"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.01936"
  },
  {
    "id": "arXiv:2206.01939",
    "title": "Learning Generative Factors of Neuroimaging Data with Variational  auto-encoders",
    "abstract": "Neuroimaging techniques produce high-dimensional, stochastic data from which\nit might be challenging to extract high-level knowledge about the phenomena of\ninterest. We address this challenge by applying the framework of generative\nmodelling to 1) classify multiple pathologies, 2) recover neurological\nmechanisms of those pathologies in a data-driven manner and 3) learn robust\nrepresentations of neuroimaging data. We illustrate the applicability of the\nproposed approach to identifying schizophrenia, either followed or not by\nauditory verbal hallucinations. We further demonstrate the ability of the\nframework to learn disease-related mechanisms that are consistent with current\ndomain knowledge. We also compare the proposed framework with several benchmark\napproaches and indicate its advantages.",
    "descriptor": "",
    "authors": [
      "Maksim Zhdanov",
      "Saskia Steinmann",
      "Nico Hoffmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2206.01939"
  },
  {
    "id": "arXiv:2206.01942",
    "title": "Occlusion-Resistant Instance Segmentation of Piglets in Farrowing Pens  Using Center Clustering Network",
    "abstract": "Computer vision enables the development of new approaches to monitor the\nbehavior, health, and welfare of animals. Instance segmentation is a\nhigh-precision method in computer vision for detecting individual animals of\ninterest. This method can be used for in-depth analysis of animals, such as\nexamining their subtle interactive behaviors, from videos and images. However,\nexisting deep-learning-based instance segmentation methods have been mostly\ndeveloped based on public datasets, which largely omit heavy occlusion\nproblems; therefore, these methods have limitations in real-world applications\ninvolving object occlusions, such as farrowing pen systems used on pig farms in\nwhich the farrowing crates often impede the sow and piglets. In this paper, we\npropose a novel occlusion-resistant Center Clustering Network for instance\nsegmentation, dubbed as CClusnet-Inseg. Specifically, CClusnet-Inseg uses each\npixel to predict object centers and trace these centers to form masks based on\nclustering results, which consists of a network for segmentation and center\noffset vector map, Density-Based Spatial Clustering of Applications with Noise\n(DBSCAN) algorithm, Centers-to-Mask (C2M) and Remain-Centers-to-Mask (RC2M)\nalgorithms, and a pseudo-occlusion generator (POG). In all, 4,600 images were\nextracted from six videos collected from six farrowing pens to train and\nvalidate our method. CClusnet-Inseg achieves a mean average precision (mAP) of\n83.6; it outperformed YOLACT++ and Mask R-CNN, which had mAP values of 81.2 and\n74.7, respectively. We conduct comprehensive ablation studies to demonstrate\nthe advantages and effectiveness of core modules of our method. In addition, we\napply CClusnet-Inseg to multi-object tracking for animal monitoring, and the\npredicted object center that is a conjunct output could serve as an\nocclusion-resistant representation of the location of an object.",
    "descriptor": "\nComments: Accepted in CV4Animals Workshop of CVPR 2022 (IJCV journal track)\n",
    "authors": [
      "Endai Huang",
      "Axiu Mao",
      "Yongjian Wu",
      "Haiming Gan",
      "Maria Camila Ceballos",
      "Thomas D. Parsons",
      "Junhui Hou",
      "Kai Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01942"
  },
  {
    "id": "arXiv:2206.01944",
    "title": "Robust Meta-learning with Sampling Noise and Label Noise via  Eigen-Reptile",
    "abstract": "Recent years have seen a surge of interest in meta-learning techniques for\ntackling the few-shot learning (FSL) problem. However, the meta-learner is\nprone to overfitting since there are only a few available samples, which can be\nidentified as sampling noise on a clean dataset. Moreover, when handling the\ndata with noisy labels, the meta-learner could be extremely sensitive to label\nnoise on a corrupted dataset. To address these two challenges, we present\nEigen-Reptile (ER) that updates the meta-parameters with the main direction of\nhistorical task-specific parameters to alleviate sampling and label noise.\nSpecifically, the main direction is computed in a fast way, where the scale of\nthe calculated matrix is related to the number of gradient steps instead of the\nnumber of parameters. Furthermore, to obtain a more accurate main direction for\nEigen-Reptile in the presence of many noisy labels, we further propose\nIntrospective Self-paced Learning (ISPL). We have theoretically and\nexperimentally demonstrated the soundness and effectiveness of the proposed\nEigen-Reptile and ISPL. Particularly, our experiments on different tasks show\nthat the proposed method is able to outperform or achieve highly competitive\nperformance compared with other gradient-based methods with or without noisy\nlabels. The code and data for the proposed method are provided for research\npurposes https://github.com/Anfeather/Eigen-Reptile.",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Dong Chen",
      "Lingfei Wu",
      "Siliang Tang",
      "Xiao Yun",
      "Bo Long",
      "Yueting Zhuang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.01944"
  },
  {
    "id": "arXiv:2206.01945",
    "title": "On the exponential convergence of input-output signals of nonlinear  feedback systems",
    "abstract": "We show that the integral-constraint-based robust feedback stability theorem\nfor certain Lurye systems exhibits the property that the endogenous\ninput-output signals enjoy an exponential convergence rate for all initial\nconditions of the linear time-invariant subsystem. More generally, we provide\nconditions under which a feedback interconnection of possibly open-loop\nunbounded subsystems to admit such an exponential convergence property, using\nperturbation analysis and a combination of tools including integral quadratic\nconstraints, directed gap measure, and exponential weightings. As an\napplication, we apply the result to first-order convex optimisation methods. In\nparticular, by making use of the Zames-Falb multipliers, we state conditions\nfor these methods to converge exponentially when applied to strongly convex\nfunctions with Lipschitz gradients.",
    "descriptor": "\nComments: This paper has been submitted to Automatica\n",
    "authors": [
      "Sei Zhen Khong",
      "Lanlan Su",
      "Di Zhao"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.01945"
  },
  {
    "id": "arXiv:2206.01946",
    "title": "Complementing B\u00fcchi Automata with Ranker (Technical Report)",
    "abstract": "We present the tool Ranker for complementing B\\\"uchi automata (BAs). Ranker\nbuilds on our previous optimizations of rank-based BA complementation and\npushes them even further using numerous heuristics to produce even smaller\nautomata. Moreover, it contains novel optimizations of specialized\nconstructions for complementing (i) inherently weak automata and (ii)\nsemi-deterministic automata, all delivered in a robust tool. The optimizations\nsignificantly improve the usability of Ranker, as shown in an extensive\nexperimental evaluation with real-world benchmarks, where Ranker produced in\nthe majority of cases a strictly smaller complement than other state-of-the-art\ntools.",
    "descriptor": "",
    "authors": [
      "Vojt\u011bch Havlena",
      "Ond\u0159ej Leng\u00e1l",
      "Barbora \u0160mahl\u00edkov\u00e1"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.01946"
  },
  {
    "id": "arXiv:2206.01949",
    "title": "Exploring the Potential of Feature Density in Estimating Machine  Learning Classifier Performance with Application to Cyberbullying Detection",
    "abstract": "In this research. we analyze the potential of Feature Density (HD) as a way\nto comparatively estimate machine learning (ML) classifier performance prior to\ntraining. The goal of the study is to aid in solving the problem of\nresource-intensive training of ML models which is becoming a serious issue due\nto continuously increasing dataset sizes and the ever rising popularity of Deep\nNeural Networks (DNN). The issue of constantly increasing demands for more\npowerful computational resources is also affecting the environment, as training\nlarge-scale ML models are causing alarmingly-growing amounts of CO2, emissions.\nOur approach 1s to optimize the resource-intensive training of ML models for\nNatural Language Processing to reduce the number of required experiments\niterations. We expand on previous attempts on improving classifier training\nefficiency with FD while also providing an insight to the effectiveness of\nvarious linguistically-backed feature preprocessing methods for dialog\nclassification, specifically cyberbullying detection.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2111.01689\n",
    "authors": [
      "Juuso Eronen",
      "Michal Ptaszynski",
      "Fumito Masui",
      "Gniewosz Leliwa",
      "Michal Wroczynski"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01949"
  },
  {
    "id": "arXiv:2206.01950",
    "title": "Comparing Performance of Different Linguistically-Backed Word Embeddings  for Cyberbullying Detection",
    "abstract": "In most cases, word embeddings are learned only from raw tokens or in some\ncases, lemmas. This includes pre-trained language models like BERT. To\ninvestigate on the potential of capturing deeper relations between lexical\nitems and structures and to filter out redundant information, we propose to\npreserve the morphological, syntactic and other types of linguistic information\nby combining them with the raw tokens or lemmas. This means, for example,\nincluding parts-of-speech or dependency information within the used lexical\nfeatures. The word embeddings can then be trained on the combinations instead\nof just raw tokens. It is also possible to later apply this method to the\npre-training of huge language models and possibly enhance their performance.\nThis would aid in tackling problems which are more sophisticated from the point\nof view of linguistic representation, such as detection of cyberbullying.",
    "descriptor": "",
    "authors": [
      "Juuso Eronen",
      "Michal Ptaszynski",
      "Fumito Masui"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01950"
  },
  {
    "id": "arXiv:2206.01953",
    "title": "Quantifying and Using System Uncertainty in UAV Navigation",
    "abstract": "As autonomous systems increasingly rely on Deep Neural Networks (DNN) to\nimplement the navigation pipeline functions, uncertainty estimation methods\nhave become paramount for estimating confidence in DNN predictions. Bayesian\nDeep Learning (BDL) offers a principled approach to model uncertainties in\nDNNs. However, DNN components from autonomous systems partially capture\nuncertainty, or more importantly, the uncertainty effect in downstream tasks is\nignored. This paper provides a method to capture the overall system uncertainty\nin a UAV navigation task. In particular, we study the effect of the uncertainty\nfrom perception representations in downstream control predictions. Moreover, we\nleverage the uncertainty in the system's output to improve control decisions\nthat positively impact the UAV's performance on its task.",
    "descriptor": "\nComments: Accepted at the ICRA 2022 Workshop on Releasing Robots into the Wild: Simulations, Benchmarks, and Deployment\n",
    "authors": [
      "Fabio Arnez",
      "Ansgar Radermacher",
      "Huascar Espinoza"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.01953"
  },
  {
    "id": "arXiv:2206.01954",
    "title": "MPE inference using an Incremental Build-Infer-Approximate Paradigm",
    "abstract": "Exact inference of the most probable explanation (MPE) in Bayesian networks\nis known to be NP-complete. In this paper, we propose an algorithm for\napproximate MPE inference that is based on the incremental\nbuild-infer-approximate (IBIA) framework. We use this framework to obtain an\nordered set of partitions of the Bayesian network and the corresponding\nmax-calibrated clique trees. We show that the maximum belief in the last\npartition gives an estimate of the probability of the MPE assignment. We\npropose an iterative algorithm for decoding, in which the subset of variables\nfor which an assignment is obtained is guaranteed to increase in every\niteration. There are no issues of convergence, and we do not perform a search\nfor solutions. Even though it is a single shot algorithm, we obtain valid\nassignments in 100 out of the 117 benchmarks used for testing. The accuracy of\nour solution is comparable to a branch and bound search in majority of the\nbenchmarks, with competitive run times.",
    "descriptor": "",
    "authors": [
      "Shivani Bathla",
      "Vinita Vasudevan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.01954"
  },
  {
    "id": "arXiv:2206.01956",
    "title": "Multi-Party Computation in IoT for Privacy-Preservation",
    "abstract": "Preservation of privacy has been a serious concern with the increasing use of\nIoT-assisted smart systems and their ubiquitous smart sensors. To solve the\nissue, the smart systems are being trained to depend more on aggregated data\ninstead of directly using raw data. However, most of the existing strategies\nfor privacy-preserving data aggregation, either depend on computation-intensive\nHomomorphic Encryption based operations or communication-intensive\ncollaborative mechanisms. Unfortunately, none of the approaches are directly\nsuitable for a resource-constrained IoT system. In this work, we leverage the\nconcurrent-transmission-based communication technology to efficiently realize a\nMulti-Party Computation (MPC) based strategy, the well-known Shamir's Secret\nSharing (SSS), and optimize the same to make it suitable for real-world IoT\nsystems.",
    "descriptor": "\nComments: Accepted in 42nd IEEE International Conference on Distributed Computing Systems (ICDCS), 2022, Bologna, Italy\n",
    "authors": [
      "Himanshu Goyal",
      "Sudipta Saha"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.01956"
  },
  {
    "id": "arXiv:2206.01958",
    "title": "Instance-wise Prompt Tuning for Pretrained Language Models",
    "abstract": "Prompt Learning has recently gained great popularity in bridging the gap\nbetween pretraining tasks and various downstream tasks. It freezes Pretrained\nLanguage Models (PLMs) and only tunes a few task-related parameters (prompts)\nfor downstream tasks, greatly reducing the cost of tuning giant models. The key\nenabler of this is the idea of querying PLMs with task-specific knowledge\nimplicated in prompts. This paper reveals a major limitation of existing\nmethods that the indiscriminate prompts for all input data in a task ignore the\nintrinsic knowledge from input data, resulting in sub-optimal performance. We\nintroduce Instance-wise Prompt Tuning (IPT), the first prompt learning paradigm\nthat injects knowledge from the input data instances to the prompts, thereby\nproviding PLMs with richer and more concrete context information. We devise a\nseries of strategies to produce instance-wise prompts, addressing various\nconcerns like model quality and cost-efficiency. Across multiple tasks and\nresource settings, IPT significantly outperforms task-based prompt learning\nmethods, and achieves comparable performance to conventional finetuning with\nonly 0.5% - 1.5% of tuned parameters.",
    "descriptor": "",
    "authors": [
      "Yuezihan Jiang",
      "Hao Yang",
      "Junyang Lin",
      "Hanyu Zhao",
      "An Yang",
      "Chang Zhou",
      "Hongxia Yang",
      "Zhi Yang",
      "Bin Cui"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.01958"
  },
  {
    "id": "arXiv:2206.01961",
    "title": "C$^3$Fusion: Consistent Contrastive Colon Fusion, Towards Deep SLAM in  Colonoscopy",
    "abstract": "3D colon reconstruction from Optical Colonoscopy (OC) to detect non-examined\nsurfaces remains an unsolved problem. The challenges arise from the nature of\noptical colonoscopy data, characterized by highly reflective low-texture\nsurfaces, drastic illumination changes and frequent tracking loss. Recent\nmethods demonstrate compelling results, but suffer from: (1) frangible\nframe-to-frame (or frame-to-model) pose estimation resulting in many tracking\nfailures; or (2) rely on point-based representations at the cost of scan\nquality. In this paper, we propose a novel reconstruction framework that\naddresses these issues end to end, which result in both quantitatively and\nqualitatively accurate and robust 3D colon reconstruction. Our SLAM approach,\nwhich employs correspondences based on contrastive deep features, and deep\nconsistent depth maps, estimates globally optimized poses, is able to recover\nfrom frequent tracking failures, and estimates a global consistent 3D model;\nall within a single framework. We perform an extensive experimental evaluation\non multiple synthetic and real colonoscopy videos, showing high-quality results\nand comparisons against relevant baselines.",
    "descriptor": "",
    "authors": [
      "Erez Posner",
      "Adi Zholkover",
      "Netanel Frank",
      "Moshe Bouhnik"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01961"
  },
  {
    "id": "arXiv:2206.01962",
    "title": "Formal Specifications from Natural Language",
    "abstract": "We study the ability of language models to translate natural language into\nformal specifications with complex semantics. In particular, we fine-tune\noff-the-shelf language models on three datasets consisting of structured\nEnglish sentences and their corresponding formal representation: 1) First-order\nlogic (FOL), commonly used in software verification and theorem proving; 2)\nlinear-time temporal logic (LTL), which forms the basis for industrial hardware\nspecification languages; and 3) regular expressions (regex), frequently used in\nprogramming and search. Our experiments show that, in these diverse domains,\nthe language models achieve competitive performance to the respective\nstate-of-the-art with the benefits of being easy to access, cheap to fine-tune,\nand without a particular need for domain-specific reasoning. Additionally, we\nshow that the language models have a unique selling point: they benefit from\ntheir generalization capabilities from pre-trained knowledge on natural\nlanguage, e.g., to generalize to unseen variable names.",
    "descriptor": "",
    "authors": [
      "Christopher Hahn",
      "Frederik Schmitt",
      "Julia J. Tillman",
      "Niklas Metzger",
      "Julian Siber",
      "Bernd Finkbeiner"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01962"
  },
  {
    "id": "arXiv:2206.01966",
    "title": "Development and Evaluation of Dental Image Exchange and Management  System: A User-Centered Perspective",
    "abstract": "Introduction: Systems that exist in the hospital or clinic settings are\ncapable of providing services in the physical environment. These systems (e.g.,\nPicture Archiving and communication systems) provide remote service for\npatients. To design such systems, we need some unique methods such as software\ndevelopment life cycle and different methods such as prototyping. Clinical\nsetting: This study designs an image exchange system in the private dental\nsector of Urmia city using user-centered methods and prototyping. Methods:\nInformation was collected based on each stage's software development life\ncycle. Interviews and observations were used to gather user-needs data, such as\nobject-oriented programming for developing a Prototype. Results: The users'\nneeds were determined to consider at the beginning. Ease of use, security, and\nmobile apps were their most essential needs. Then, the prototype was designed\nand evaluated in the focus group session. These steps continued until users\nwere satisfied in the focus group. Eventually, after the users' consent, the\nprototype became the final system. Discussion: Instant access to Information,\nvolunteering, user interface design, and usefulness were the most critical\nvariables users considered. The advantage of this system also includes less\nradiation to the patient due to not losing and missing the clips of the\npatient's images. Conclusion: The success of such a system requires the\nconsideration of end-users needs and their application to the system. In\naddition to this system, having an electronic health record can improve the\ntreatment process and improve the work of the medical staff.",
    "descriptor": "\nComments: 3 figures, 5 tables\n",
    "authors": [
      "B Rahimi",
      "S Karimian",
      "A Ghaznavi",
      "M Jafari Heydarlou"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Multimedia (cs.MM)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.01966"
  },
  {
    "id": "arXiv:2206.01970",
    "title": "PHEE: A phased hybrid evaluation-enhanced approach for identifying  influential users in social networks",
    "abstract": "For the purpose of maximizing the spread of influence caused by a certain\nsmall number k of nodes in a social network, we are asked to find a k-subset of\nnodes (i.e., a seed set) with the best capacity to influence the nodes not in\nit. This problem of influence maximization (IM) has wide application, belongs\nto subset problems, and is NP-hard. To solve it, we should theoretically\nexamine all seed sets and evaluate their influence spreads, which is\ntime-consuming. Therefore, metaheuristic strategies are generally employed to\ngain a good seed set within a reasonable time. We observe that many algorithms\nfor the IM problem only adopt a uniform mechanism in the whole solution search\nprocess, which lacks a response measure when the algorithm becomes trapped in a\nlocal optimum. To address this issue, we propose a phased hybrid\nevaluation-enhanced (PHEE) approach for IM, which utilizes two distinct search\nstrategies to enhance the search of optimal solutions: a randomized range\ndivision evolutionary (RandRDE) algorithm to improve the solution quality, and\na fast convergence strategy. Our approach is evaluated on 10 real-world social\nnetworks of different sizes and types. Experimental results demonstrate that\nour algorithm is efficient and obtains the best influence spread for all the\ndatasets compared with three state-of-the-art algorithms, outperforms the time\nconsuming CELF algorithm on four datasets, and performs worse than CELF on only\ntwo networks.",
    "descriptor": "",
    "authors": [
      "Enqiang Zhu",
      "Haosen Wang",
      "Yu Zhang",
      "Kai Zhang",
      "Chanjuan Liu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.01970"
  },
  {
    "id": "arXiv:2206.01972",
    "title": "MACC: Cross-Layer Multi-Agent Congestion Control with Deep Reinforcement  Learning",
    "abstract": "Congestion Control (CC), as the core networking task to efficiently utilize\nnetwork capacity, received great attention and widely used in various Internet\ncommunication applications such as 5G, Internet-of-Things, UAN, and more.\nVarious CC algorithms have been proposed both on network and transport layers\nsuch as Active Queue Management (AQM) algorithm and Transmission Control\nProtocol (TCP) congestion control mechanism. But it is hard to model dynamic\nAQM/TCP system and cooperate two algorithms to obtain excellent performance\nunder different communication scenarios. In this paper, we explore the\nperformance of multi-agent reinforcement learning-based cross-layer congestion\ncontrol algorithms and present cooperation performance of two agents, known as\nMACC (Multi-agent Congestion Control). We implement MACC in NS3. The simulation\nresults show that our scheme outperforms other congestion control combination\nin terms of throughput and delay, etc. Not only does it proves that networking\nprotocols based on multi-agent deep reinforcement learning is efficient for\ncommunication managing, but also verifies that networking area can be used as\nnew playground for machine learning algorithms.",
    "descriptor": "\nComments: 7 pages, 8 figures\n",
    "authors": [
      "Jianing Bai",
      "Tianhao Zhang",
      "Guangming Xie"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.01972"
  },
  {
    "id": "arXiv:2206.01975",
    "title": "Super-localized orthogonal decomposition for convection-dominated  diffusion problems",
    "abstract": "This paper presents a multi-scale method for convection-dominated diffusion\nproblems in the regime of large P\\'eclet numbers. The application of the\nsolution operator to piecewise constant right-hand sides on some arbitrary\ncoarse mesh defines a finite-dimensional coarse ansatz space with favorable\napproximation properties. For some relevant error measures, including the\n$L^2$-norm, the Galerkin projection onto this generalized finite element space\neven yields $\\varepsilon$-independent error bounds, $\\varepsilon$ being the\nsingular perturbation parameter. By constructing an approximate local basis,\nthe approach becomes a novel multi-scale method in the spirit of the\nSuper-Localized Orthogonal Decomposition (SLOD). The error caused by basis\nlocalization can be estimated in an a-posteriori way. In contrast to existing\nmulti-scale methods, numerical experiments indicate $\\varepsilon$-independent\nconvergence without preasymptotic effects even in the under-resolved regime of\nlarge mesh P\\'eclet numbers.",
    "descriptor": "\nComments: 26 pages, 11 figures\n",
    "authors": [
      "Francesca Bonizzoni",
      "Philip Freese",
      "Daniel Peterseim"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.01975"
  },
  {
    "id": "arXiv:2206.01978",
    "title": "Inbetween: Visual Selection in Parametric Design",
    "abstract": "The act of selection plays a leading role in the design process and in the\ndefinition of personal style. This work introduces visual selection catalogs\ninto parametric design environments. A two-fold contribution is presented: (i)\nguidelines for construction of a minimal-bias visual selection catalog from a\nparametric space, and (ii) Inbetween, a catalog for a parametric typeface that\nadheres to the guidelines, allows for font selection from a continuous design\nspace, and enables the investigation of personal style. A user study conducted\namong graphic designers, revealed self-coherent characteristics in selection\npatterns, and a high correlation in selection patterns within tasks. These\nfindings suggest that such patterns reflect personal user styles, formalizing\nthe style selection process as traversals of decision trees. Together, our\nguidelines and catalog aid in making visual selection a key building block in\nthe digital creation process and validate selection processes as a measure of\npersonal style.",
    "descriptor": "\nComments: tool can be found at this https URL\n",
    "authors": [
      "Rony Ginosar",
      "Amit Zoran"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.01978"
  },
  {
    "id": "arXiv:2206.01980",
    "title": "Modelling and Mining of Patient Pathways: A Scoping Review",
    "abstract": "The sequence of visits and procedures performed by the patient in the health\nsystem, also known as the patient's pathway or trajectory, can reveal important\ninformation about the clinical treatment adopted and the health service\nprovided. The rise of electronic health data availability made it possible to\nassess the pathways of a large number of patients. Nevertheless, some\nchallenges also arose concerning how to synthesize these pathways and how to\nmine them from the data, fostering a new field of research. The objective of\nthis review is to survey this new field of research, highlighting\nrepresentation models, mining techniques, methods of analysis, and examples of\ncase studies.",
    "descriptor": "\nComments: 24 pages, 6 figures, 1 table\n",
    "authors": [
      "Caroline de Oliveira Costa Souza Rosa",
      "Marcia Ito",
      "Alex Borges Vieira",
      "Antonio Tadeu Azevedo Gomes"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01980"
  },
  {
    "id": "arXiv:2206.01984",
    "title": "Geodesic Properties of a Generalized Wasserstein Embedding for Time  Series Analysis",
    "abstract": "Transport-based metrics and related embeddings (transforms) have recently\nbeen used to model signal classes where nonlinear structures or variations are\npresent. In this paper, we study the geodesic properties of time series data\nwith a generalized Wasserstein metric and the geometry related to their signed\ncumulative distribution transforms in the embedding space. Moreover, we show\nhow understanding such geometric characteristics can provide added\ninterpretability to certain time series classifiers, and be an inspiration for\nmore robust classifiers.",
    "descriptor": "",
    "authors": [
      "Shiying Li",
      "Abu Hasnat Mohammad Rubaiyat",
      "Gustavo K. Rohde"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Geometric Topology (math.GT)"
    ],
    "url": "https://arxiv.org/abs/2206.01984"
  },
  {
    "id": "arXiv:2206.01986",
    "title": "Rethinking the Openness of CLIP",
    "abstract": "Contrastive Language-Image Pre-training (CLIP) has demonstrated great\npotential in realizing open-vocabulary image classification in a matching\nstyle, because of its holistic use of natural language supervision that covers\nunconstrained real-world visual concepts. However, it is, in turn, also\ndifficult to evaluate and analyze the openness of CLIP-like models, since they\nare in theory open to any vocabulary but the actual accuracy varies. To address\nthe insufficiency of conventional studies on openness, we resort to an\nincremental view and define the extensibility, which essentially approximates\nthe model's ability to deal with new visual concepts, by evaluating openness\nthrough vocabulary expansions. Our evaluation based on extensibility shows that\nCLIP-like models are hardly truly open and their performances degrade as the\nvocabulary expands to different degrees. Further analysis reveals that the\nover-estimation of openness is not because CLIP-like models fail to capture the\ngeneral similarity of image and text features of novel visual concepts, but\nbecause of the confusion among competing text features, that is, they are not\nstable with respect to the vocabulary. In light of this, we propose to improve\nthe openness of CLIP from the perspective of feature space by enforcing the\ndistinguishability of text features. Our method retrieves relevant texts from\nthe pre-training corpus to enhance prompts for inference, which boosts the\nextensibility and stability of CLIP even without fine-tuning.",
    "descriptor": "\nComments: 21 pages, 13 figures\n",
    "authors": [
      "Shuhuai Ren",
      "Lei Li",
      "Xuancheng Ren",
      "Guangxiang Zhao",
      "Xu Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01986"
  },
  {
    "id": "arXiv:2206.01987",
    "title": "Atypical lexical abbreviations identification in Russian medical texts",
    "abstract": "Abbreviation is a method of word formation that aims to construct the\nshortened term from the first letters of the initial phrase. Implicit\nabbreviations frequently cause the comprehension difficulties for unprepared\nreaders. In this paper, we propose an efficient ML-based algorithm which allows\nto identify the abbreviations in Russian texts. The method achieves ROC AUC\nscore 0.926 and F1 score 0.706 which are confirmed as competitive in comparison\nwith the baselines. Along with the pipeline, we also establish first to our\nknowledge Russian dataset that is relevant for the desired task.",
    "descriptor": "",
    "authors": [
      "Anna Berdichevskaia"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.01987"
  },
  {
    "id": "arXiv:2206.01988",
    "title": "Cross-modal Clinical Graph Transformer for Ophthalmic Report Generation",
    "abstract": "Automatic generation of ophthalmic reports using data-driven neural networks\nhas great potential in clinical practice. When writing a report,\nophthalmologists make inferences with prior clinical knowledge. This knowledge\nhas been neglected in prior medical report generation methods. To endow models\nwith the capability of incorporating expert knowledge, we propose a Cross-modal\nclinical Graph Transformer (CGT) for ophthalmic report generation (ORG), in\nwhich clinical relation triples are injected into the visual features as prior\nknowledge to drive the decoding procedure. However, two major common Knowledge\nNoise (KN) issues may affect models' effectiveness. 1) Existing general\nbiomedical knowledge bases such as the UMLS may not align meaningfully to the\nspecific context and language of the report, limiting their utility for\nknowledge injection. 2) Incorporating too much knowledge may divert the visual\nfeatures from their correct meaning. To overcome these limitations, we design\nan automatic information extraction scheme based on natural language processing\nto obtain clinical entities and relations directly from in-domain training\nreports. Given a set of ophthalmic images, our CGT first restores a sub-graph\nfrom the clinical graph and injects the restored triples into visual features.\nThen visible matrix is employed during the encoding procedure to limit the\nimpact of knowledge. Finally, reports are predicted by the encoded cross-modal\nfeatures via a Transformer decoder. Extensive experiments on the large-scale\nFFA-IR benchmark demonstrate that the proposed CGT is able to outperform\nprevious benchmark methods and achieve state-of-the-art performances.",
    "descriptor": "\nComments: CVPR 2022 (Poster)\n",
    "authors": [
      "Mingjie Li",
      "Wenjia Cai",
      "Karin Verspoor",
      "Shirui Pan",
      "Xiaodan Liang",
      "Xiaojun Chang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01988"
  },
  {
    "id": "arXiv:2206.01990",
    "title": "Combining the Morris Method and Multiple Error Metrics to Assess Aquifer  Characteristics and Recharge in the Lower Ticino Basin, in Italy",
    "abstract": "Groundwater flow model accuracy is often limited by the uncertainty in model\nparameters that characterize the aquifer properties and the aquifer recharge.\nAquifer properties such as the hydraulic conductivity can have an uncertainty\nspanning orders of magnitude. Meanwhile, parameters used to configure model\nboundary conditions can introduce additional uncertainty. In this study, the\nMorris Method sensitivity analysis is performed on multiple quantities of\ninterest to assess the sensitivity of a groundwater flow model to uncertain\ninput parameters. The Morris Method determines which of these parameters are\nless influential on model outputs. Uninfluential parameters can be set constant\nduring subsequent parameter optimization to reduce the computational expense.\nCombining multiple quantities of interest (e.g., RMSE, groundwater fluxes) when\nperforming both the Morris Method and parameter optimization offers a more\ncomplete assessment of groundwater models, providing a more reliable and\nphysically consistent estimate of uncertain parameters. The parameter\noptimization procedure also provides us an estimate of the residual uncertainty\nin the parameter values, resulting in a more complete estimate of the remaining\nuncertainty. By employing such techniques, the current study was able to\nestimate the aquifer hydraulic conductivity and recharge rate due to rice field\nirrigation in a groundwater basin in Northern Italy, revealing a significant\nproportion of surficial aquifer recharge (approximately 81-94%) during the\nlater summer is due to the flood irrigation practices applied to these fields.",
    "descriptor": "\nComments: first submission\n",
    "authors": [
      "Emily A. Baker",
      "Alessandro Cappato",
      "Sara Todeschini",
      "Lorenzo Tamellini",
      "Giancarlo Sangalli",
      "Alessandro Reali",
      "Sauro Manenti"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2206.01990"
  },
  {
    "id": "arXiv:2206.01991",
    "title": "Constructing unbiased gradient estimators with finite variance for  conditional stochastic optimization",
    "abstract": "We study stochastic gradient descent for solving conditional stochastic\noptimization problems, in which an objective to be minimized is given by a\nparametric nested expectation with an outer expectation taken with respect to\none random variable and an inner conditional expectation with respect to the\nother random variable. The gradient of such a parametric nested expectation is\nagain expressed as a nested expectation, which makes it hard for the standard\nnested Monte Carlo estimator to be unbiased. In this paper, we show under some\nconditions that a multilevel Monte Carlo gradient estimator is unbiased and has\nfinite variance and finite expected computational cost, so that the standard\ntheory from stochastic optimization for a parametric (non-nested) expectation\ndirectly applies. We also discuss a special case for which yet another unbiased\ngradient estimator with finite variance and cost can be constructed.",
    "descriptor": "\nComments: 19 pages, 2 figures\n",
    "authors": [
      "Takashi Goda",
      "Wataru Kitade"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.01991"
  },
  {
    "id": "arXiv:2206.01992",
    "title": "CAINNFlow: Convolutional block Attention modules and Invertible Neural  Networks Flow for anomaly detection and localization tasks",
    "abstract": "Detection of object anomalies is crucial in industrial processes, but\nunsupervised anomaly detection and localization is particularly important due\nto the difficulty of obtaining a large number of defective samples and the\nunpredictable types of anomalies in real life. Among the existing unsupervised\nanomaly detection and localization methods, the NF-based scheme has achieved\nbetter results. However, the two subnets (complex functions) si(ui) and ti(ui)\nin NF are usually multilayer perceptrons, which need to squeeze the input\nvisual features from 2D flattening to 1D, destroying the spatial location\nrelationship in the feature map and losing the spatial structure information.\nIn order to retain and effectively extract spatial structure information, we\ndesign in this study a complex function model with alternating CBAM embedded in\na stacked 3*3 full convolution, which is able to retain and effectively extract\nspatial structure information in the normalized flow model. Extensive\nexperimental results on the MVTec AD dataset show that CAINNFlow achieves\nadvanced levels of accuracy and inference efficiency based on CNN and\nTransformer backbone networks as feature extractors, and CAINNFlow achieves a\npixel-level AUC of 98.76\\% for anomaly detection in MVTec AD.",
    "descriptor": "",
    "authors": [
      "Ruiqing Yan",
      "Fan Zhang",
      "Mengyuan Huang",
      "Wu Liu",
      "Dongyu Hu",
      "Jinfeng Li",
      "Qiang Liu",
      "Jingrong Jiang",
      "Qianjin Guo",
      "Linghan Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.01992"
  },
  {
    "id": "arXiv:2206.01995",
    "title": "Combinatorial Causal Bandits",
    "abstract": "In combinatorial causal bandits (CCB), the learning agent chooses at most $K$\nvariables in each round to intervene, collects feedback from the observed\nvariables, with the goal of minimizing expected regret on the target variable\n$Y$. Different from all prior studies on causal bandits, CCB needs to deal with\nexponentially large action space. We study under the context of binary\ngeneralized linear models (BGLMs) with a succinct parametric representation of\nthe causal models. We present the algorithm BGLM-OFU for Markovian BGLMs (i.e.\nno hidden variables) based on the maximum likelihood estimation method, and\nshow that it achieves $O(\\sqrt{T}\\log T)$ regret, where $T$ is the time\nhorizon. For the special case of linear models with hidden variables, we apply\ncausal inference techniques such as the do-calculus to convert the original\nmodel into a Markovian model, and then show that our BGLM-OFU algorithm and\nanother algorithm based on the linear regression both solve such linear models\nwith hidden variables. Our novelty includes (a) considering the combinatorial\nintervention action space, (b) considering general causal models including ones\nwith hidden variables, (c) integrating and adapting techniques from diverse\nstudies such as generalized linear bandits and online influence maximization,\nand (d) not relying on unrealistic assumptions such as knowing the joint\ndistribution of the parents of $Y$ under all interventions used in some prior\nstudies.",
    "descriptor": "\nComments: 22 pages, 1 figure\n",
    "authors": [
      "Shi Feng",
      "Wei Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.01995"
  },
  {
    "id": "arXiv:2206.01999",
    "title": "MSR: Making Self-supervised learning Robust to Aggressive Augmentations",
    "abstract": "Most recent self-supervised learning methods learn visual representation by\ncontrasting different augmented views of images. Compared with supervised\nlearning, more aggressive augmentations have been introduced to further improve\nthe diversity of training pairs. However, aggressive augmentations may distort\nimages' structures leading to a severe semantic shift problem that augmented\nviews of the same image may not share the same semantics, thus degrading the\ntransfer performance. To address this problem, we propose a new SSL paradigm,\nwhich counteracts the impact of semantic shift by balancing the role of weak\nand aggressively augmented pairs. Specifically, semantically inconsistent pairs\nare of minority and we treat them as noisy pairs. Note that deep neural\nnetworks (DNNs) have a crucial memorization effect that DNNs tend to first\nmemorize clean (majority) examples before overfitting to noisy (minority)\nexamples. Therefore, we set a relatively large weight for aggressively\naugmented data pairs at the early learning stage. With the training going on,\nthe model begins to overfit noisy pairs. Accordingly, we gradually reduce the\nweights of aggressively augmented pairs. In doing so, our method can better\nembrace the aggressive augmentations and neutralize the semantic shift problem.\nExperiments show that our model achieves 73.1% top-1 accuracy on ImageNet-1K\nwith ResNet-50 for 200 epochs, which is a 2.5% improvement over BYOL. Moreover,\nexperiments also demonstrate that the learned representations can transfer well\nfor various downstream tasks.",
    "descriptor": "",
    "authors": [
      "Yingbin Bai",
      "Erkun Yang",
      "Zhaoqing Wang",
      "Yuxuan Du",
      "Bo Han",
      "Cheng Deng",
      "Dadong Wang",
      "Tongliang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01999"
  },
  {
    "id": "arXiv:2206.02000",
    "title": "Hybrid Value Estimation for Off-policy Evaluation and Offline  Reinforcement Learning",
    "abstract": "Value function estimation is an indispensable subroutine in reinforcement\nlearning, which becomes more challenging in the offline setting. In this paper,\nwe propose Hybrid Value Estimation (HVE) to reduce value estimation error,\nwhich trades off bias and variance by balancing between the value estimation\nfrom offline data and the learned model. Theoretical analysis discloses that\nHVE enjoys a better error bound than the direct methods. HVE can be leveraged\nin both off-policy evaluation and offline reinforcement learning settings. We,\ntherefore, provide two concrete algorithms Off-policy HVE (OPHVE) and\nModel-based Offline HVE (MOHVE), respectively. Empirical evaluations on MuJoCo\ntasks corroborate the theoretical claim. OPHVE outperforms other off-policy\nevaluation methods in all three metrics measuring the estimation effectiveness,\nwhile MOHVE achieves better or comparable performance with state-of-the-art\noffline reinforcement learning algorithms. We hope that HVE could shed some\nlight on further research on reinforcement learning from fixed data.",
    "descriptor": "",
    "authors": [
      "Xue-Kun Jin",
      "Xu-Hui Liu",
      "Shengyi Jiang",
      "Yang Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02000"
  },
  {
    "id": "arXiv:2206.02001",
    "title": "Surprising Instabilities in Training Deep Networks and a Theoretical  Analysis",
    "abstract": "We discover restrained numerical instabilities in current training practices\nof deep networks with SGD. We show numerical error (on the order of the\nsmallest floating point bit) induced from floating point arithmetic in training\ndeep nets can be amplified significantly and result in significant test\naccuracy variance, comparable to the test accuracy variance due to\nstochasticity in SGD. We show how this is likely traced to instabilities of the\noptimization dynamics that are restrained, i.e., localized over iterations and\nregions of the weight tensor space. We do this by presenting a theoretical\nframework using numerical analysis of partial differential equations (PDE), and\nanalyzing the gradient descent PDE of a simplified convolutional neural network\n(CNN). We show that it is stable only under certain conditions on the learning\nrate and weight decay. We reproduce the localized instabilities in the PDE for\nthe simplified network, which arise when the conditions are violated.",
    "descriptor": "",
    "authors": [
      "Yuxin Sun",
      "Dong Lao",
      "Ganesh Sundaramoorthi",
      "Anthony Yezzi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.02001"
  },
  {
    "id": "arXiv:2206.02002",
    "title": "CVNets: High Performance Library for Computer Vision",
    "abstract": "We introduce CVNets, a high-performance open-source library for training deep\nneural networks for visual recognition tasks, including classification,\ndetection, and segmentation. CVNets supports image and video understanding\ntools, including data loading, data transformations, novel data sampling\nmethods, and implementations of several standard networks with similar or\nbetter performance than previous studies.\nOur source code is available at: \\url{https://github.com/apple/ml-cvnets}.",
    "descriptor": "\nComments: Technical report\n",
    "authors": [
      "Sachin Mehta",
      "Farzad Abdolhosseini",
      "Mohammad Rastegari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02002"
  },
  {
    "id": "arXiv:2206.02006",
    "title": "Combinatorial optimization for low bit-width neural networks",
    "abstract": "Low-bit width neural networks have been extensively explored for deployment\non edge devices to reduce computational resources. Existing approaches have\nfocused on gradient-based optimization in a two-stage train-and-compress\nsetting or as a combined optimization where gradients are quantized during\ntraining. Such schemes require high-performance hardware during the training\nphase and usually store an equivalent number of full-precision weights apart\nfrom the quantized weights. In this paper, we explore methods of direct\ncombinatorial optimization in the problem of risk minimization with binary\nweights, which can be made equivalent to a non-monotone submodular maximization\nunder certain conditions. We employ an approximation algorithm for the cases\nwith single and multilayer neural networks. For linear models, it has\n$\\mathcal{O}(nd)$ time complexity where $n$ is the sample size and $d$ is the\ndata dimension. We show that a combination of greedy coordinate descent and\nthis novel approach can attain competitive accuracy on binary classification\ntasks.",
    "descriptor": "",
    "authors": [
      "Han Zhou",
      "Aida Ashrafi",
      "Matthew B. Blaschko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02006"
  },
  {
    "id": "arXiv:2206.02008",
    "title": "Hidden Degrees of Freedom in Implicit Vortex Filaments",
    "abstract": "This paper presents a new representation of curve dynamics, with applications\nto vortex filaments in fluid simulation. Instead of representing these\nfilaments with explicit curve geometry and Lagrangian equations of motion, we\nrepresent curves implicitly with a new co-dimensional 2 level set description.\nOur implicit representation admits several redundant mathematical degrees of\nfreedom in both the configuration and the dynamics of the curves, which can be\ntailored specifically to improve numerical robustness, in contrast to naive\napproaches for implicit curve dynamics that suffer from overwhelming numerical\nstability problems. Furthermore, we note how these hidden degrees of freedom\nperfectly map to a Clebsch representation in fluid dynamics. Motivated by these\nobservations, we introduce untwisted level set functions and non-swirling\ndynamics which successfully regularize sources of numerical instability,\nparticularly in the twisting modes around curve filaments. The result is a\nnovel simulation method which produces stable dynamics for large numbers of\ninteracting vortex filaments and effortlessly handles topological changes and\nre-connection events.",
    "descriptor": "\nComments: We will later upload a supplementary video\n",
    "authors": [
      "Sadashige Ishida",
      "Chris Wojtan",
      "Albert Chern"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Dynamical Systems (math.DS)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2206.02008"
  },
  {
    "id": "arXiv:2206.02010",
    "title": "Variational regularization with oversmoothing penalty term in Banach  spaces",
    "abstract": "In the present work, we discuss variational regularization for ill-posed\nnonlinear problems with focus on an oversmoothing penalty term. This means in\nour model that the searched-for solution of the considered nonlinear operator\nequation does not belong to the domain of definition of the penalty functional.\nIn the past years, such variational regularization has been investigated\ncomprehensively in Hilbert scales. Our present study tries to continue and to\nextend those investigations to Banach scales. This new study includes\nconvergence rates results for a priori choices of the regularization parameter,\nboth for H\\\"older-type smoothness and low order-type smoothness. The necessary\ntools for low order smoothness in the Banach space setting are provided.",
    "descriptor": "",
    "authors": [
      "Robert Plato",
      "Bernd Hofmann"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.02010"
  },
  {
    "id": "arXiv:2206.02013",
    "title": "Causal Discovery in Heterogeneous Environments Under the Sparse  Mechanism Shift Hypothesis",
    "abstract": "Machine learning approaches commonly rely on the assumption of independent\nand identically distributed (i.i.d.) data. In reality, however, this assumption\nis almost always violated due to distribution shifts between environments.\nAlthough valuable learning signals can be provided by heterogeneous data from\nchanging distributions, it is also known that learning under arbitrary\n(adversarial) changes is impossible. Causality provides a useful framework for\nmodeling distribution shifts, since causal models encode both observational and\ninterventional distributions. In this work, we explore the sparse mechanism\nshift hypothesis, which posits that distribution shifts occur due to a small\nnumber of changing causal conditionals. Motivated by this idea, we apply it to\nlearning causal structure from heterogeneous environments, where i.i.d. data\nonly allows for learning an equivalence class of graphs without restrictive\nassumptions. We propose the Mechanism Shift Score (MSS), a score-based approach\namenable to various empirical estimators, which provably identifies the entire\ncausal structure with high probability if the sparse mechanism shift hypothesis\nholds. Empirically, we verify behavior predicted by the theory and compare\nmultiple estimators and score functions to identify the best approaches in\npractice. Compared to other methods, we show how MSS bridges a gap by both\nbeing nonparametric as well as explicitly leveraging sparse changes.",
    "descriptor": "\nComments: JvK and BS are shared last authors. 10 pages + references + appendix; 11 figures\n",
    "authors": [
      "Ronan Perry",
      "Julius von K\u00fcgelgen",
      "Bernhard Sch\u00f6lkopf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.02013"
  },
  {
    "id": "arXiv:2206.02014",
    "title": "Actuarial Applications of Natural Language Processing Using  Transformers: Case Studies for Using Text Features in an Actuarial Context",
    "abstract": "This tutorial demonstrates workflows to incorporate text data into actuarial\nclassification and regression tasks. The main focus is on methods employing\ntransformer-based models. A dataset of car accident descriptions with an\naverage length of 400 words, available in English and German, and a dataset\nwith short property insurance claims descriptions are used to demonstrate these\ntechniques. The case studies tackle challenges related to a multi-lingual\nsetting and long input sequences. They also show ways to interpret model\noutput, to assess and improve model performance, by fine-tuning the models to\nthe domain of application or to a specific prediction task. Finally, the\ntutorial provides practical approaches to handle classification tasks in\nsituations with no or only few labeled data. The results achieved by using the\nlanguage-understanding skills of off-the-shelf natural language processing\n(NLP) models with only minimal pre-processing and fine-tuning clearly\ndemonstrate the power of transfer learning for practical applications.",
    "descriptor": "\nComments: 41 pages, 28 figures\n",
    "authors": [
      "Andreas Troxler",
      "J\u00fcrg Schelldorfer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.02014"
  },
  {
    "id": "arXiv:2206.02015",
    "title": "APES: Articulated Part Extraction from Sprite Sheets",
    "abstract": "Rigged puppets are one of the most prevalent representations to create 2D\ncharacter animations. Creating these puppets requires partitioning characters\ninto independently moving parts. In this work, we present a method to\nautomatically identify such articulated parts from a small set of character\nposes shown in a sprite sheet, which is an illustration of the character that\nartists often draw before puppet creation. Our method is trained to infer\narticulated parts, e.g. head, torso and limbs, that can be re-assembled to best\nreconstruct the given poses. Our results demonstrate significantly better\nperformance than alternatives qualitatively and quantitatively.Our project page\nhttps://zhan-xu.github.io/parts/ includes our code and data.",
    "descriptor": "",
    "authors": [
      "Zhan Xu",
      "Matthew Fisher",
      "Yang Zhou",
      "Deepali Aneja",
      "Rushikesh Dudhat",
      "Li Yi",
      "Evangelos Kalogerakis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2206.02015"
  },
  {
    "id": "arXiv:2206.02016",
    "title": "Is $L^2$ Physics-Informed Loss Always Suitable for Training  Physics-Informed Neural Network?",
    "abstract": "The Physics-Informed Neural Network (PINN) approach is a new and promising\nway to solve partial differential equations using deep learning. The $L^2$\nPhysics-Informed Loss is the de-facto standard in training Physics-Informed\nNeural Networks. In this paper, we challenge this common practice by\ninvestigating the relationship between the loss function and the approximation\nquality of the learned solution. In particular, we leverage the concept of\nstability in the literature of partial differential equation to study the\nasymptotic behavior of the learned solution as the loss approaches zero. With\nthis concept, we study an important class of high-dimensional non-linear PDEs\nin optimal control, the Hamilton-Jacobi-Bellman(HJB) Equation, and prove that\nfor general $L^p$ Physics-Informed Loss, a wide class of HJB equation is stable\nonly if $p$ is sufficiently large. Therefore, the commonly used $L^2$ loss is\nnot suitable for training PINN on those equations, while $L^{\\infty}$ loss is a\nbetter choice. Based on the theoretical insight, we develop a novel PINN\ntraining algorithm to minimize the $L^{\\infty}$ loss for HJB equations which is\nin a similar spirit to adversarial training. The effectiveness of the proposed\nalgorithm is empirically demonstrated through experiments.",
    "descriptor": "",
    "authors": [
      "Chuwei Wang",
      "Shanda Li",
      "Di He",
      "Liwei Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.02016"
  },
  {
    "id": "arXiv:2206.02019",
    "title": "Symmetry as a Representation of Intuitive Geometry?",
    "abstract": "Recognition of geometrical patterns seems to be an important aspect of human\nintelligence. Geometric pattern recognition is used in many intelligence tests,\nincluding Dehaene's odd-one-out test of Core Geometry (CG)) based on intuitive\ngeometrical concepts (Dehaene et al., 2006). Earlier work has developed a\nsymmetry-based cognitive model of Dehaene's test and demonstrated performance\ncomparable to that of humans. In this work, we further investigate the role of\nsymmetry in geometrical intuition and build a cognitive model for the\n2-Alternative Forced Choice (2-AFC) variation of the CG test (Marupudi & Varma\n2021). In contrast to Dehaene's test, 2-AFC leaves almost no space for\ncognitive models based on generalization over multiple examples. Our\nsymmetry-based model achieves an accuracy comparable to the human average on\nthe 2-AFC test and appears to capture an essential part of intuitive geometry.",
    "descriptor": "\nComments: CogSci 2022 Camera ready version\n",
    "authors": [
      "Wangcheng Xu",
      "Snejana Shegheva",
      "Ashok Goel"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02019"
  },
  {
    "id": "arXiv:2206.02025",
    "title": "Between Rate-Distortion Theory & Value Equivalence in Model-Based  Reinforcement Learning",
    "abstract": "The quintessential model-based reinforcement-learning agent iteratively\nrefines its estimates or prior beliefs about the true underlying model of the\nenvironment. Recent empirical successes in model-based reinforcement learning\nwith function approximation, however, eschew the true model in favor of a\nsurrogate that, while ignoring various facets of the environment, still\nfacilitates effective planning over behaviors. Recently formalized as the value\nequivalence principle, this algorithmic technique is perhaps unavoidable as\nreal-world reinforcement learning demands consideration of a simple,\ncomputationally-bounded agent interacting with an overwhelmingly complex\nenvironment. In this work, we entertain an extreme scenario wherein some\ncombination of immense environment complexity and limited agent capacity\nentirely precludes identifying an exactly value-equivalent model. In light of\nthis, we embrace a notion of approximate value equivalence and introduce an\nalgorithm for incrementally synthesizing simple and useful approximations of\nthe environment from which an agent might still recover near-optimal behavior.\nCrucially, we recognize the information-theoretic nature of this lossy\nenvironment compression problem and use the appropriate tools of\nrate-distortion theory to make mathematically precise how value equivalence can\nlend tractability to otherwise intractable sequential decision-making problems.",
    "descriptor": "\nComments: Accepted to the Multi-Disciplinary Conference on Reinforcement Learning and Decision Making (RLDM) 2022\n",
    "authors": [
      "Dilip Arumugam",
      "Benjamin Van Roy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.02025"
  },
  {
    "id": "arXiv:2206.02027",
    "title": "Implicit Neural Representation for Mesh-Free Inverse Obstacle Scattering",
    "abstract": "Implicit representation of shapes as level sets of multilayer perceptrons has\nrecently flourished in different shape analysis, compression, and\nreconstruction tasks. In this paper, we introduce an implicit neural\nrepresentation-based framework for solving the inverse obstacle scattering\nproblem in a mesh-free fashion. We efficiently express the obstacle shape as\nthe zero-level set of a signed distance function which is implicitly determined\nby a small number of network parameters. To solve the direct scattering\nproblem, we implement the implicit boundary integral method. It uses\nprojections of the grid points in the tubular neighborhood onto the boundary to\ncompute the PDE solution instead of a grid-size-dependent extraction method of\nsurface points such as Marching Cubes. The implicit representation conveniently\nhandles the shape perturbation in the optimization process. To update the\nshape, we use PyTorch's automatic differentiation to backpropagate the loss\nfunction w.r.t. the network parameters, allowing us to avoid complex and\nerror-prone manual derivation of the shape derivative. The proposed framework\nmakes the inverse scattering problem more tractable with fewer parameters to\noptimize in comparison to the memory-inefficient grid-based approaches and\noutputs high-quality reconstruction results.",
    "descriptor": "\nComments: extended abstract, 3 pages, 4 figures\n",
    "authors": [
      "Tin Vla\u0161i\u0107",
      "Hieu Nguyen",
      "Ivan Dokmani\u0107"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.02027"
  },
  {
    "id": "arXiv:2206.02029",
    "title": "Guided Deep Metric Learning",
    "abstract": "Deep Metric Learning (DML) methods have been proven relevant for visual\nsimilarity learning. However, they sometimes lack generalization properties\nbecause they are trained often using an inappropriate sample selection strategy\nor due to the difficulty of the dataset caused by a distributional shift in the\ndata. These represent a significant drawback when attempting to learn the\nunderlying data manifold. Therefore, there is a pressing need to develop better\nways of obtaining generalization and representation of the underlying manifold.\nIn this paper, we propose a novel approach to DML that we call Guided Deep\nMetric Learning, a novel architecture oriented to learning more compact\nclusters, improving generalization under distributional shifts in DML. This\nnovel architecture consists of two independent models: A multi-branch master\nmodel, inspired from a Few-Shot Learning (FSL) perspective, generates a reduced\nhypothesis space based on prior knowledge from labeled data, which guides or\nregularizes the decision boundary of a student model during training under an\noffline knowledge distillation scheme. Experiments have shown that the proposed\nmethod is capable of a better manifold generalization and representation to up\nto 40% improvement (Recall@1, CIFAR10), using guidelines suggested by Musgrave\net al. to perform a more fair and realistic comparison, which is currently\nabsent in the literature",
    "descriptor": "",
    "authors": [
      "Jorge Gonzalez-Zapata",
      "Ivan Reyes-Amezcua",
      "Daniel Flores-Araiza",
      "Mauricio Mendez-Ruiz",
      "Gilberto Ochoa-Ruiz",
      "Andres Mendez-Vazquez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02029"
  },
  {
    "id": "arXiv:2206.02032",
    "title": "A Neural Network Approach for Homogenization of Multiscale Problems",
    "abstract": "We propose a neural network-based approach to the homogenization of\nmultiscale problems. The proposed method uses a derivative-free formulation of\na training loss, which incorporates Brownian walkers to find the macroscopic\ndescription of a multiscale PDE solution. Compared with other network-based\napproaches for multiscale problems, the proposed method is free from the design\nof hand-crafted neural network architecture and the cell problem to calculate\nthe homogenization coefficient. The exploration neighborhood of the Brownian\nwalkers affects the overall learning trajectory. We determine the bounds of\nmicro- and macro-time steps that capture the local heterogeneous and global\nhomogeneous solution behaviors, respectively, through a neural network. The\nbounds imply that the computational cost of the proposed method is independent\nof the microscale periodic structure for the standard periodic problems. We\nvalidate the efficiency and robustness of the proposed method through a suite\nof linear and nonlinear multiscale problems with periodic and random field\ncoefficients.",
    "descriptor": "\nComments: 20 pages, 6 figures\n",
    "authors": [
      "Jihun Han",
      "Yoonsang Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.02032"
  },
  {
    "id": "arXiv:2206.02034",
    "title": "A Control Theoretic Framework for Adaptive Gradient Optimizers in  Machine Learning",
    "abstract": "Adaptive gradient methods have become popular in optimizing deep neural\nnetworks; recent examples include AdaGrad and Adam. Although Adam usually\nconverges faster, variations of Adam, for instance, the AdaBelief algorithm,\nhave been proposed to enhance Adam's poor generalization ability compared to\nthe classical stochastic gradient method. This paper develops a generic\nframework for adaptive gradient methods that solve non-convex optimization\nproblems. We first model the adaptive gradient methods in a state-space\nframework, which allows us to present simpler convergence proofs of adaptive\noptimizers such as AdaGrad, Adam, and AdaBelief. We then utilize the transfer\nfunction paradigm from classical control theory to propose a new variant of\nAdam, coined AdamSSM. We add an appropriate pole-zero pair in the transfer\nfunction from squared gradients to the second moment estimate. We prove the\nconvergence of the proposed AdamSSM algorithm. Applications on benchmark\nmachine learning tasks of image classification using CNN architectures and\nlanguage modeling using LSTM architecture demonstrate that the AdamSSM\nalgorithm improves the gap between generalization accuracy and faster\nconvergence than the recent adaptive gradient methods.",
    "descriptor": "",
    "authors": [
      "Kushal Chakrabarti",
      "Nikhil Chopra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.02034"
  },
  {
    "id": "arXiv:2206.02036",
    "title": "Interpolating Between Softmax Policy Gradient and Neural Replicator  Dynamics with Capped Implicit Exploration",
    "abstract": "Neural replicator dynamics (NeuRD) is an alternative to the foundational\nsoftmax policy gradient (SPG) algorithm motivated by online learning and\nevolutionary game theory. The NeuRD expected update is designed to be nearly\nidentical to that of SPG, however, we show that the Monte Carlo updates differ\nin a substantial way: the importance correction accounting for a sampled action\nis nullified in the SPG update, but not in the NeuRD update. Naturally, this\ncauses the NeuRD update to have higher variance than its SPG counterpart.\nBuilding on implicit exploration algorithms in the adversarial bandit setting,\nwe introduce capped implicit exploration (CIX) estimates that allow us to\nconstruct NeuRD-CIX, which interpolates between this aspect of NeuRD and SPG.\nWe show how CIX estimates can be used in a black-box reduction to construct\nbandit algorithms with regret bounds that hold with high probability and the\nbenefits this entails for NeuRD-CIX in sequential decision-making settings. Our\nanalysis reveals a bias--variance tradeoff between SPG and NeuRD, and shows how\ntheory predicts that NeuRD-CIX will perform well more consistently than NeuRD\nwhile retaining NeuRD's advantages over SPG in non-stationary environments.",
    "descriptor": "\nComments: At Reinforcement Learning and Decision Making 2022, June 2022. 9 pages and 1 figure\n",
    "authors": [
      "Dustin Morrill",
      "Esra'a Saleh",
      "Michael Bowling",
      "Amy Greenwald"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.02036"
  },
  {
    "id": "arXiv:2206.02039",
    "title": "Beyond Value: CHECKLIST for Testing Inferences in Planning-Based RL",
    "abstract": "Reinforcement learning (RL) agents are commonly evaluated via their expected\nvalue over a distribution of test scenarios. Unfortunately, this evaluation\napproach provides limited evidence for post-deployment generalization beyond\nthe test distribution. In this paper, we address this limitation by extending\nthe recent CheckList testing methodology from natural language processing to\nplanning-based RL. Specifically, we consider testing RL agents that make\ndecisions via online tree search using a learned transition model and value\nfunction. The key idea is to improve the assessment of future performance via a\nCheckList approach for exploring and assessing the agent's inferences during\ntree search. The approach provides the user with an interface and general\nquery-rule mechanism for identifying potential inference flaws and validating\nexpected inference invariances. We present a user study involving knowledgeable\nAI researchers using the approach to evaluate an agent trained to play a\ncomplex real-time strategy game. The results show the approach is effective in\nallowing users to identify previously-unknown flaws in the agent's reasoning.\nIn addition, our analysis provides insight into how AI experts use this type of\ntesting approach, which may help improve future instantiations.",
    "descriptor": "\nComments: This work will appear in the Proceedings of the 32nd International Conference on Automated Planning and Scheduling (ICAPS2022) this https URL\n",
    "authors": [
      "Kin-Ho Lam",
      "Delyar Tabatabai",
      "Jed Irvine",
      "Donald Bertucci",
      "Anita Ruangrotsakun",
      "Minsuk Kahng",
      "Alan Fern"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02039"
  },
  {
    "id": "arXiv:2206.02042",
    "title": "Developing hierarchical anticipations via neural network-based event  segmentation",
    "abstract": "Humans can make predictions on various time scales and hierarchical levels.\nThereby, the learning of event encodings seems to play a crucial role. In this\nwork we model the development of hierarchical predictions via autonomously\nlearned latent event codes. We present a hierarchical recurrent neural network\narchitecture, whose inductive learning biases foster the development of\nsparsely changing latent state that compress sensorimotor sequences. A higher\nlevel network learns to predict the situations in which the latent states tend\nto change. Using a simulated robotic manipulator, we demonstrate that the\nsystem (i) learns latent states that accurately reflect the event structure of\nthe data, (ii) develops meaningful temporal abstract predictions on the higher\nlevel, and (iii) generates goal-anticipatory behavior similar to gaze behavior\nfound in eye-tracking studies with infants. The architecture offers a step\ntowards autonomous, self-motivated learning of compressed hierarchical\nencodings of gathered experiences and the exploitation of these encodings for\nthe generation of highly versatile, adaptive behavior.",
    "descriptor": "\nComments: under review\n",
    "authors": [
      "Christian Gumbsch",
      "Maurits Adam",
      "Birgit Elsner",
      "Georg Martius",
      "Martin V.Butz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02042"
  },
  {
    "id": "arXiv:2206.02043",
    "title": "UAV-Aided Multi-Community Federated Learning",
    "abstract": "In this work, we investigate the problem of an online trajectory design for\nan Unmanned Aerial Vehicle (UAV) in a Federated Learning (FL) setting where\nseveral different communities exist, each defined by a unique task to be\nlearned. In this setting, spatially distributed devices belonging to each\ncommunity collaboratively contribute towards training their community model via\nwireless links provided by the UAV. Accordingly, the UAV acts as a mobile\norchestrator coordinating the transmissions and the learning schedule among the\ndevices in each community, intending to accelerate the learning process of all\ntasks. We propose a heuristic metric as a proxy for the training performance of\nthe different tasks. Capitalizing on this metric, a surrogate objective is\ndefined which enables us to jointly optimize the UAV trajectory and the\nscheduling of the devices by employing convex optimization techniques and graph\ntheory. The simulations illustrate the out-performance of our solution when\ncompared to other handpicked static and mobile UAV deployment baselines.",
    "descriptor": "",
    "authors": [
      "Mohamad Mestoukirdi",
      "Omid Esrafilian",
      "David Gesbert",
      "Qianrui Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02043"
  },
  {
    "id": "arXiv:2206.02047",
    "title": "On the Generalization Power of the Overfitted Three-Layer Neural Tangent  Kernel Model",
    "abstract": "In this paper, we study the generalization performance of overparameterized\n3-layer NTK models. We show that, for a specific set of ground-truth functions\n(which we refer to as the \"learnable set\"), the test error of the overfitted\n3-layer NTK is upper bounded by an expression that decreases with the number of\nneurons of the two hidden layers. Different from 2-layer NTK where there exists\nonly one hidden-layer, the 3-layer NTK involves interactions between two\nhidden-layers. Our upper bound reveals that, between the two hidden-layers, the\ntest error descends faster with respect to the number of neurons in the second\nhidden-layer (the one closer to the output) than with respect to that in the\nfirst hidden-layer (the one closer to the input). We also show that the\nlearnable set of 3-layer NTK without bias is no smaller than that of 2-layer\nNTK models with various choices of bias in the neurons. However, in terms of\nthe actual generalization performance, our results suggest that 3-layer NTK is\nmuch less sensitive to the choices of bias than 2-layer NTK, especially when\nthe input dimension is large.",
    "descriptor": "",
    "authors": [
      "Peizhong Ju",
      "Xiaojun Lin",
      "Ness B. Shroff"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.02047"
  },
  {
    "id": "arXiv:2206.02050",
    "title": "Learning Speaker-specific Lip-to-Speech Generation",
    "abstract": "Understanding the lip movement and inferring the speech from it is\nnotoriously difficult for the common person. The task of accurate lip-reading\ngets help from various cues of the speaker and its contextual or environmental\nsetting. Every speaker has a different accent and speaking style, which can be\ninferred from their visual and speech features. This work aims to understand\nthe correlation/mapping between speech and the sequence of lip movement of\nindividual speakers in an unconstrained and large vocabulary. We model the\nframe sequence as a prior to the transformer in an auto-encoder setting and\nlearned a joint embedding that exploits temporal properties of both audio and\nvideo. We learn temporal synchronization using deep metric learning, which\nguides the decoder to generate speech in sync with input lip movements. The\npredictive posterior thus gives us the generated speech in speaker speaking\nstyle. We have trained our model on the Grid and Lip2Wav Chemistry lecture\ndataset to evaluate single speaker natural speech generation tasks from lip\nmovement in an unconstrained natural setting. Extensive evaluation using\nvarious qualitative and quantitative metrics with human evaluation also shows\nthat our method outperforms the Lip2Wav Chemistry dataset(large vocabulary in\nan unconstrained setting) by a good margin across almost all evaluation metrics\nand marginally outperforms the state-of-the-art on GRID dataset.",
    "descriptor": "\nComments: Accepted at ICPR 2022\n",
    "authors": [
      "Munender Varshney",
      "Ravindra Yadav",
      "Vinay P. Namboodiri",
      "Rajesh M Hegde"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.02050"
  },
  {
    "id": "arXiv:2206.02051",
    "title": "Fast and Accurate Error Simulation for CNNs against Soft Errors",
    "abstract": "The great quest for adopting AI-based computation for\nsafety-/mission-critical applications motivates the interest towards methods\nfor assessing the robustness of the application w.r.t. not only its\ntraining/tuning but also errors due to faults, in particular soft errors,\naffecting the underlying hardware. Two strategies exist: architecture-level\nfault injection and application-level functional error simulation. We present a\nframework for the reliability analysis of Convolutional Neural Networks (CNNs)\nvia an error simulation engine that exploits a set of validated error models\nextracted from a detailed fault injection campaign. These error models are\ndefined based on the corruption patterns of the output of the CNN operators\ninduced by faults and bridge the gap between fault injection and error\nsimulation, exploiting the advantages of both approaches. We compared our\nmethodology against SASSIFI for the accuracy of functional error simulation\nw.r.t. fault injection, and against TensorFI in terms of speedup for the error\nsimulation strategy. Experimental results show that our methodology achieves\nabout 99\\% accuracy of the fault effects w.r.t. SASSIFI, and a speedup ranging\nfrom 44x up to 63x w.r.t. TensorFI, that only implements a limited set of error\nmodels.",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Computers\n",
    "authors": [
      "Cristiana Bolchini",
      "Luca Cassano",
      "Antonio Miele",
      "Alessandro Toschi"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02051"
  },
  {
    "id": "arXiv:2206.02056",
    "title": "Interpretable Models Capable of Handling Systematic Missingness in  Imbalanced Classes and Heterogeneous Datasets",
    "abstract": "Application of interpretable machine learning techniques on medical datasets\nfacilitate early and fast diagnoses, along with getting deeper insight into the\ndata. Furthermore, the transparency of these models increase trust among\napplication domain experts. Medical datasets face common issues such as\nheterogeneous measurements, imbalanced classes with limited sample size, and\nmissing data, which hinder the straightforward application of machine learning\ntechniques. In this paper we present a family of prototype-based (PB)\ninterpretable models which are capable of handling these issues. The models\nintroduced in this contribution show comparable or superior performance to\nalternative techniques applicable in such situations. However, unlike ensemble\nbased models, which have to compromise on easy interpretation, the PB models\nhere do not. Moreover we propose a strategy of harnessing the power of\nensembles while maintaining the intrinsic interpretability of the PB models, by\naveraging the model parameter manifolds. All the models were evaluated on a\nsynthetic (publicly available dataset) in addition to detailed analyses of two\nreal-world medical datasets (one publicly available). Results indicated that\nthe models and strategies we introduced addressed the challenges of real-world\nmedical data, while remaining computationally inexpensive and transparent, as\nwell as similar or superior in performance compared to their alternatives.",
    "descriptor": "",
    "authors": [
      "Sreejita Ghosh",
      "Elizabeth S. Baranowski",
      "Michael Biehl",
      "Wiebke Arlt",
      "Peter Tino",
      "Kerstin Bunte"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02056"
  },
  {
    "id": "arXiv:2206.02059",
    "title": "Your Neighbors Are Communicating: Towards Powerful and Scalable Graph  Neural Networks",
    "abstract": "Message passing graph neural networks (GNNs) are known to have their\nexpressiveness upper-bounded by 1-dimensional Weisfeiler-Lehman (1-WL)\nalgorithm. To achieve more powerful GNNs, existing attempts either require ad\nhoc features, or involve operations that incur high time and space\ncomplexities. In this work, we propose a general and provably powerful GNN\nframework that preserves the scalability of message passing scheme. In\nparticular, we first propose to empower 1-WL for graph isomorphism test by\nconsidering edges among neighbors, giving rise to NC-1-WL. The expressiveness\nof NC-1-WL is shown to be strictly above 1-WL but below 3-WL theoretically.\nFurther, we propose the NC-GNN framework as a differentiable neural version of\nNC-1-WL. Our simple implementation of NC-GNN is provably as powerful as\nNC-1-WL. Experiments demonstrate that our NC-GNN achieves remarkable\nperformance on various benchmarks.",
    "descriptor": "",
    "authors": [
      "Meng Liu",
      "Haiyang Yu",
      "Shuiwang Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02059"
  },
  {
    "id": "arXiv:2206.02060",
    "title": "A privacy preserving querying mechanism with high utility for electric  vehicles",
    "abstract": "With the recent rise in awareness about advancing towards a sustainable\nfuture, electric vehicles (EVs) are becoming more popular. As there are way\nfewer charging stations than EVs, range anxiety plays a major role in the\nrising number of queries made by EVs along their journeys to find the nearest\navailable charging station, and such online querying is handled by third-party\nservice providers and communicated via the Edge cloud. On the other hand, with\nthe recent drive towards an information-based society, the use of personal data\nin various analytics is surging like never before. Hence, the risk of privacy\nviolation of data is also increasing. One of the recently popularised methods\nformalising utility-preserving location privacy is geo-indistinguishability, a\ngeneralisation of the local differential privacy, which is the state-of-the-art\nstandard for privacy protection. However, the noise should be calibrated\ncarefully, taking into account the implications for potential utility-loss for\nthe users affecting their quality of service (QoS). In this paper, we consider\nEVs dynamically querying about charging stations along their journeys, and we\ntheorize approximate geo-indistinguishability (AGeoI) on road networks which\nallows the EVs to obfuscate the individual query locations while keeping them\nwithin their preferred area of interest, as journeys are very sensitive to a\nsharp loss in QoS incurring a high cost to be covered. We propose a novel\nmethod to protect the privacy of EVs, both for the individual query locations\nand against the threat of tracing their journeys, by applying AGeoI that\nenables the users to substantially preserve their QoS. We lay out an analytical\ninsight on our method and experimentally illustrate that under our method a\nvery high fraction of the EVs attain privacy for free, and, in general, the\nutility-loss suffered due to gain in privacy is significantly low.",
    "descriptor": "",
    "authors": [
      "Ugur Ilker Atmaca",
      "Sayan Biswas",
      "Carsten Maple",
      "Catuscia Palamidessi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.02060"
  },
  {
    "id": "arXiv:2206.02062",
    "title": "Performance Analysis of SPAD-Based Optical Wireless Communication with  OFDM",
    "abstract": "In recent years, there has been a growing interest in the use of\nsingle-photon avalanche diode (SPAD) in optical wireless communication (OWC).\nSPAD operates in the Geiger mode and can act as a photon counting receiver\nobviating the need for a transimpedance amplifier (TIA). Although a SPAD\nreceiver can provide higher sensitivity compared to the traditional linear\nphotodetectors, it suffers from the dead-time-induced nonlinearity. To improve\nthe data rates of SPAD-based OWC systems, optical orthogonal frequency division\nmultiplexing (OFDM) can be employed. This paper provides a comprehensive\ntheoretical analysis of the SPAD-based OWC systems using OFDM signalling\nconsidering the effects of signal clipping, SPAD nonlinearity, and\nsignal-dependent shot noise. An equivalent additive Gaussian noise channel\nmodel is proposed to describe the performance of the SPAD-based OFDM system.\nThe statistics of the proposed channel model and the analytical expressions of\nthe signal-to-noise ratio (SNR) and bit error rate (BER) are derived in closed\nforms. By means of extensive numerical results, the impact of the unique\nreceiver nonlinearity on the system performance is investigated. The results\ndemonstrate new insights into different optical power regimes of reliable\noperation for SPAD-based OFDM systems even well beyond SPAD saturation level.",
    "descriptor": "",
    "authors": [
      "Shenjie Huang",
      "Yichen Li",
      "Cheng Chen",
      "Mohammad Dehghani Soltani",
      "Robert Henderson",
      "Majid Safari",
      "Harald Haas"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.02062"
  },
  {
    "id": "arXiv:2206.02063",
    "title": "Active Bayesian Causal Inference",
    "abstract": "Causal discovery and causal reasoning are classically treated as separate and\nconsecutive tasks: one first infers the causal graph, and then uses it to\nestimate causal effects of interventions. However, such a two-stage approach is\nuneconomical, especially in terms of actively collected interventional data,\nsince the causal query of interest may not require a fully-specified causal\nmodel. From a Bayesian perspective, it is also unnatural, since a causal query\n(e.g., the causal graph or some causal effect) can be viewed as a latent\nquantity subject to posterior inference -- other unobserved quantities that are\nnot of direct interest (e.g., the full causal model) ought to be marginalized\nout in this process and contribute to our epistemic uncertainty. In this work,\nwe propose Active Bayesian Causal Inference (ABCI), a fully-Bayesian active\nlearning framework for integrated causal discovery and reasoning, which jointly\ninfers a posterior over causal models and queries of interest. In our approach\nto ABCI, we focus on the class of causally-sufficient, nonlinear additive noise\nmodels, which we model using Gaussian processes. We sequentially design\nexperiments that are maximally informative about our target causal query,\ncollect the corresponding interventional data, and update our beliefs to choose\nthe next experiment. Through simulations, we demonstrate that our approach is\nmore data-efficient than several baselines that only focus on learning the full\ncausal graph. This allows us to accurately learn downstream causal queries from\nfewer samples while providing well-calibrated uncertainty estimates for the\nquantities of interest.",
    "descriptor": "\nComments: RP & JvK are shared last authors. 10 pages + references + appendices (26 pages total); 6 Figs\n",
    "authors": [
      "Christian Toth",
      "Lars Lorch",
      "Christian Knoll",
      "Andreas Krause",
      "Franz Pernkopf",
      "Robert Peharz",
      "Julius von K\u00fcgelgen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.02063"
  },
  {
    "id": "arXiv:2206.02066",
    "title": "PIDNet: A Real-time Semantic Segmentation Network Inspired from PID  Controller",
    "abstract": "Two-branch network architecture has shown its efficiency and effectiveness\nfor real-time semantic segmentation tasks. However, direct fusion of low-level\ndetails and high-level semantics will lead to a phenomenon that the detailed\nfeatures are easily overwhelmed by surrounding contextual information, namely\novershoot in this paper, which limits the improvement of the accuracy of\nexisted two-branch models. In this paper, we bridge a connection between\nConvolutional Neural Network (CNN) and Proportional-Integral-Derivative (PID)\ncontroller and reveal that the two-branch network is nothing but a\nProportional-Integral (PI) controller, which inherently suffers from the\nsimilar overshoot issue. To alleviate this issue, we propose a novel\nthree-branch network architecture: PIDNet, which possesses three branches to\nparse the detailed, context and boundary information (derivative of semantics),\nrespectively, and employs boundary attention to guide the fusion of detailed\nand context branches in final stage. The family of PIDNets achieve the best\ntrade-off between inference speed and accuracy and their test accuracy\nsurpasses all the existed models with similar inference speed on Cityscapes,\nCamVid and COCO-Stuff datasets. Especially, PIDNet-S achieves 78.6% mIOU with\ninference speed of 93.2 FPS on Cityscapes test set and 81.6% mIOU with speed of\n153.7 FPS on CamVid test set.",
    "descriptor": "\nComments: 11 pages, 10 figures\n",
    "authors": [
      "Jiacong Xu",
      "Zixiang Xiong",
      "Shankar P. Bhattacharyya"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02066"
  },
  {
    "id": "arXiv:2206.02067",
    "title": "Learning Robust Representations Of Generative Models Using Set-Based  Artificial Fingerprints",
    "abstract": "With recent progress in deep generative models, the problem of identifying\nsynthetic data and comparing their underlying generative processes has become\nan imperative task for various reasons, including fighting visual\nmisinformation and source attribution. Existing methods often approximate the\ndistance between the models via their sample distributions. In this paper, we\napproach the problem of fingerprinting generative models by learning\nrepresentations that encode the residual artifacts left by the generative\nmodels as unique signals that identify the source models. We consider these\nunique traces (a.k.a. \"artificial fingerprints\") as representations of\ngenerative models, and demonstrate their usefulness in both the discriminative\ntask of source attribution and the unsupervised task of defining a similarity\nbetween the underlying models. We first extend the existing studies on\nfingerprints of GANs to four representative classes of generative models (VAEs,\nFlows, GANs and score-based models), and demonstrate their existence and\nattributability. We then improve the stability and attributability of the\nfingerprints by proposing a new learning method based on set-encoding and\ncontrastive training. Our set-encoder, unlike existing methods that operate on\nindividual images, learns fingerprints from a \\textit{set} of images. We\ndemonstrate improvements in the stability and attributability through\ncomparisons to state-of-the-art fingerprint methods and ablation studies.\nFurther, our method employs contrastive training to learn an implicit\nsimilarity between models. We discover latent families of generative models\nusing this metric in a standard hierarchical clustering algorithm.",
    "descriptor": "",
    "authors": [
      "Hae Jin Song",
      "Wael AbdAlmageed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02067"
  },
  {
    "id": "arXiv:2206.02070",
    "title": "All One Needs to Know about Priors for Deep Image Restoration and  Enhancement: A Survey",
    "abstract": "Image restoration and enhancement is a process of improving the image quality\nby removing degradations, such as noise, blur, and resolution degradation. Deep\nlearning (DL) has recently been applied to image restoration and enhancement.\nDue to its ill-posed property, plenty of works have explored priors to\nfacilitate training deep neural networks (DNNs). However, the importance of\npriors has not been systematically studied and analyzed by far in the research\ncommunity. Therefore, this paper serves as the first study that provides a\ncomprehensive overview of recent advancements of priors for deep image\nrestoration and enhancement. Our work covers five primary contents: (1) A\ntheoretical analysis of priors for deep image restoration and enhancement; (2)\nA hierarchical and structural taxonomy of priors commonly used in the DL-based\nmethods; (3) An insightful discussion on each prior regarding its principle,\npotential, and applications; (4) A summary of crucial problems by highlighting\nthe potential future directions to spark more research in the community; (5) An\nopen-source repository that provides a taxonomy of all mentioned works and code\nlinks.",
    "descriptor": "",
    "authors": [
      "Yunfan Lu",
      "Yiqi Lin",
      "Hao Wu",
      "Yunhao Luo",
      "Xu Zheng",
      "Lin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2206.02070"
  },
  {
    "id": "arXiv:2206.02072",
    "title": "Deciding What to Model: Value-Equivalent Sampling for Reinforcement  Learning",
    "abstract": "The quintessential model-based reinforcement-learning agent iteratively\nrefines its estimates or prior beliefs about the true underlying model of the\nenvironment. Recent empirical successes in model-based reinforcement learning\nwith function approximation, however, eschew the true model in favor of a\nsurrogate that, while ignoring various facets of the environment, still\nfacilitates effective planning over behaviors. Recently formalized as the value\nequivalence principle, this algorithmic technique is perhaps unavoidable as\nreal-world reinforcement learning demands consideration of a simple,\ncomputationally-bounded agent interacting with an overwhelmingly complex\nenvironment, whose underlying dynamics likely exceed the agent's capacity for\nrepresentation. In this work, we consider the scenario where agent limitations\nmay entirely preclude identifying an exactly value-equivalent model,\nimmediately giving rise to a trade-off between identifying a model that is\nsimple enough to learn while only incurring bounded sub-optimality. To address\nthis problem, we introduce an algorithm that, using rate-distortion theory,\niteratively computes an approximately-value-equivalent, lossy compression of\nthe environment which an agent may feasibly target in lieu of the true model.\nWe prove an information-theoretic, Bayesian regret bound for our algorithm that\nholds for any finite-horizon, episodic sequential decision-making problem.\nCrucially, our regret bound can be expressed in one of two possible forms,\nproviding a performance guarantee for finding either the simplest model that\nachieves a desired sub-optimality gap or, alternatively, the best model given a\nlimit on agent capacity.",
    "descriptor": "",
    "authors": [
      "Dilip Arumugam",
      "Benjamin Van Roy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.02072"
  },
  {
    "id": "arXiv:2206.02074",
    "title": "Explaining Hyperproperty Violations",
    "abstract": "Hyperproperties relate multiple computation traces to each other. Model\ncheckers for hyperproperties thus return, in case a system model violates the\nspecification, a set of traces as a counterexample. Fixing the erroneous\nrelations between traces in the system that led to the counterexample is a\ndifficult manual effort that highly benefits from additional explanations. In\nthis paper, we present an explanation method for counterexamples to\nhyperproperties described in the specification logic HyperLTL. We extend\nHalpern and Pearl's definition of actual causality to sets of traces witnessing\nthe violation of a HyperLTL formula, which allows us to identify the events\nthat caused the violation. We report on the implementation of our method and\nshow that it significantly improves on previous approaches for analyzing\ncounterexamples returned by HyperLTL model checkers.",
    "descriptor": "\nComments: 34th International Conference on Computer-Aided Verification (CAV 2022)\n",
    "authors": [
      "Norine Coenen",
      "Raimund Dachselt",
      "Bernd Finkbeiner",
      "Hadar Frenkel",
      "Christopher Hahn",
      "Tom Horak",
      "Niklas Metzger",
      "Julian Siber"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.02074"
  },
  {
    "id": "arXiv:2206.02078",
    "title": "Straggler-Resilient Personalized Federated Learning",
    "abstract": "Federated Learning is an emerging learning paradigm that allows training\nmodels from samples distributed across a large network of clients while\nrespecting privacy and communication restrictions. Despite its success,\nfederated learning faces several challenges related to its decentralized\nnature. In this work, we develop a novel algorithmic procedure with theoretical\nspeedup guarantees that simultaneously handles two of these hurdles, namely (i)\ndata heterogeneity, i.e., data distributions can vary substantially across\nclients, and (ii) system heterogeneity, i.e., the computational power of the\nclients could differ significantly. Our method relies on ideas from\nrepresentation learning theory to find a global common representation using all\nclients' data and learn a user-specific set of parameters leading to a\npersonalized solution for each client. Furthermore, our method mitigates the\neffects of stragglers by adaptively selecting clients based on their\ncomputational characteristics and statistical significance, thus achieving, for\nthe first time, near optimal sample complexity and provable logarithmic\nspeedup. Experimental results support our theoretical findings showing the\nsuperiority of our method over alternative personalized federated schemes in\nsystem and data heterogeneous environments.",
    "descriptor": "",
    "authors": [
      "Isidoros Tziotis",
      "Zebang Shen",
      "Ramtin Pedarsani",
      "Hamed Hassani",
      "Aryan Mokhtari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.02078"
  },
  {
    "id": "arXiv:2206.02079",
    "title": "Multilingual Neural Machine Translation with Deep Encoder and Multiple  Shallow Decoders",
    "abstract": "Recent work in multilingual translation advances translation quality\nsurpassing bilingual baselines using deep transformer models with increased\ncapacity. However, the extra latency and memory costs introduced by this\napproach may make it unacceptable for efficiency-constrained applications. It\nhas recently been shown for bilingual translation that using a deep encoder and\nshallow decoder (DESD) can reduce inference latency while maintaining\ntranslation quality, so we study similar speed-accuracy trade-offs for\nmultilingual translation. We find that for many-to-one translation we can\nindeed increase decoder speed without sacrificing quality using this approach,\nbut for one-to-many translation, shallow decoders cause a clear quality drop.\nTo ameliorate this drop, we propose a deep encoder with multiple shallow\ndecoders (DEMSD) where each shallow decoder is responsible for a disjoint\nsubset of target languages. Specifically, the DEMSD model with 2-layer decoders\nis able to obtain a 1.8x speedup on average compared to a standard transformer\nmodel with no drop in translation quality.",
    "descriptor": "\nComments: EACL 2021\n",
    "authors": [
      "Xiang Kong",
      "Adithya Renduchintala",
      "James Cross",
      "Yuqing Tang",
      "Jiatao Gu",
      "Xian Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.02079"
  },
  {
    "id": "arXiv:2206.02082",
    "title": "Towards Fast Adaptation of Pretrained Contrastive Models for  Multi-channel Video-Language Retrieval",
    "abstract": "Multi-channel video-language retrieval require models to understand\ninformation from different modalities (e.g. video+question, video+speech) and\nreal-world knowledge to correctly link a video with a textual response or\nquery. Fortunately, multimodal contrastive models have been shown to be highly\neffective at aligning entities in images/videos and text, e.g., CLIP; text\ncontrastive models have been extensively studied recently for their strong\nability of producing discriminative sentence embeddings, e.g., SimCSE. Their\nabilities are exactly needed by multi-channel video-language retrieval.\nHowever, it is not clear how to quickly adapt these two lines of models to\nmulti-channel video-language retrieval-style tasks. In this paper, we identify\na principled model design space with two axes: how to represent videos and how\nto fuse video and text information. Based on categorization of recent methods,\nwe investigate the options of representing videos using continuous feature\nvectors or discrete text tokens; for the fusion method, we explore a multimodal\ntransformer or a pretrained contrastive text model. We extensively evaluate the\nfour combinations on five video-language datasets. We surprisingly find that\ndiscrete text tokens coupled with a pretrained contrastive text model yields\nthe best performance. This combination can even outperform state-of-the-art on\nthe iVQA dataset without the additional training on millions of video-language\ndata. Further analysis shows that this is because representing videos as text\ntokens captures the key visual information with text tokens that are naturally\naligned with text models and the text models obtained rich knowledge during\ncontrastive pretraining process. All the empirical analysis we obtain for the\nfour variants establishes a solid foundation for future research on leveraging\nthe rich knowledge of pretrained contrastive models.",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Xudong Lin",
      "Simran Tiwari",
      "Shiyuan Huang",
      "Manling Li",
      "Mike Zheng Shou",
      "Heng Ji",
      "Shih-Fu Chang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02082"
  },
  {
    "id": "arXiv:2206.02083",
    "title": "Geometric Theory for Program Testing",
    "abstract": "Formal methods for verification of programs are extended to testing of\nprograms. Their combination is intended to lead to benefits in reliable program\ndevelopment, testing, and evolution. Our geometric theory of testing is\nintended to serve as the specification of a testing environment, included as\nthe last stage of a toolchain that assists professional programmers, amateurs,\nand students of Computer Science. The testing environment includes an automated\nalgorithm which locates errors in a test that has been run, and assists in\ncorrecting them. It does this by displaying, on a monitor screen, a stick\ndiagram of causal chains in the execution of the program under test. The\ndiagram can then be navigated backwards in the familiar style of a satnav\nfollowing roads on a map. This will reveal selections of places at which the\nprogram should be modified to remove the error.",
    "descriptor": "",
    "authors": [
      "Bernhard Moller",
      "Tony Hoare",
      "Zhe Hou",
      "Jin Song Dong"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2206.02083"
  },
  {
    "id": "arXiv:2206.02086",
    "title": "Towards the Creation of a Nutrition and Food Group Based Image Database",
    "abstract": "Food classification is critical to the analysis of nutrients comprising foods\nreported in dietary assessment. Advances in mobile and wearable sensors,\ncombined with new image based methods, particularly deep learning based\napproaches, have shown great promise to improve the accuracy of food\nclassification to assess dietary intake. However, these approaches are\ndata-hungry and their performances are heavily reliant on the quantity and\nquality of the available datasets for training the food classification model.\nExisting food image datasets are not suitable for fine-grained food\nclassification and the following nutrition analysis as they lack fine-grained\nand transparently derived food group based identification which are often\nprovided by trained dietitians with expert domain knowledge. In this paper, we\npropose a framework to create a nutrition and food group based image database\nthat contains both visual and hierarchical food categorization information to\nenhance links to the nutrient profile of each food. We design a protocol for\nlinking food group based food codes in the U.S. Department of Agriculture's\n(USDA) Food and Nutrient Database for Dietary Studies (FNDDS) to a food image\ndataset, and implement a web-based annotation tool for efficient deployment of\nthis protocol.Our proposed method is used to build a nutrition and food group\nbased image database including 16,114 food images representing the 74 most\nfrequently consumed What We Eat in America (WWEIA) food sub-categories in the\nUnited States with 1,865 USDA food code matched to a nutrient database, the\nUSDA FNDDS nutrient database.",
    "descriptor": "",
    "authors": [
      "Zeman Shao",
      "Jiangpeng He",
      "Ya-Yuan Yu",
      "Luotao Lin",
      "Alexandra Cowan",
      "Heather Eicher-Miller",
      "Fengqing Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02086"
  },
  {
    "id": "arXiv:2206.02087",
    "title": "Accurate Scoliosis Vertebral Landmark Localization on X-ray Images via  Shape-constrained Multi-stage Cascaded CNNs",
    "abstract": "Vertebral landmark localization is a crucial step for variant spine-related\nclinical applications, which requires detecting the corner points of 17\nvertebrae. However, the neighbor landmarks often disturb each other for the\nhomogeneous appearance of vertebrae, which makes vertebral landmark\nlocalization extremely difficult. In this paper, we propose multi-stage\ncascaded convolutional neural networks (CNNs) to split the single task into two\nsequential steps, i.e., center point localization to roughly locate 17 center\npoints of vertebrae, and corner point localization to find 4 corner points for\neach vertebra without distracted by others. Landmarks in each step are located\ngradually from a set of initialized points by regressing offsets via cascaded\nCNNs. Principal Component Analysis (PCA) is employed to preserve a shape\nconstraint in offset regression to resist the mutual attraction of vertebrae.\nWe evaluate our method on the AASCE dataset that consists of 609 tight spinal\nanterior-posterior X-ray images and each image contains 17 vertebrae composed\nof the thoracic and lumbar spine for spinal shape characterization.\nExperimental results demonstrate our superior performance of vertebral landmark\nlocalization over other state-of-the-arts with the relative error decreasing\nfrom 3.2e-3 to 7.2e-4.",
    "descriptor": "\nComments: 9 pages, submitted to IEEE Journal of Biomedical and Health Informatics\n",
    "authors": [
      "Zhiwei Wang",
      "Jinxin Lv",
      "Yunqiao Yang",
      "Yuanhuai Liang",
      "Yi Lin",
      "Qiang Li",
      "Xin Li",
      "Xin Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02087"
  },
  {
    "id": "arXiv:2206.02092",
    "title": "Bandit Theory and Thompson Sampling-Guided Directed Evolution for  Sequence Optimization",
    "abstract": "Directed Evolution (DE), a landmark wet-lab method originated in 1960s,\nenables discovery of novel protein designs via evolving a population of\ncandidate sequences. Recent advances in biotechnology has made it possible to\ncollect high-throughput data, allowing the use of machine learning to map out a\nprotein's sequence-to-function relation. There is a growing interest in machine\nlearning-assisted DE for accelerating protein optimization. Yet the theoretical\nunderstanding of DE, as well as the use of machine learning in DE, remains\nlimited. In this paper, we connect DE with the bandit learning theory and make\na first attempt to study regret minimization in DE. We propose a Thompson\nSampling-guided Directed Evolution (TS-DE) framework for sequence optimization,\nwhere the sequence-to-function mapping is unknown and querying a single value\nis subject to costly and noisy measurements. TS-DE updates a posterior of the\nfunction based on collected measurements. It uses a posterior-sampled function\nestimate to guide the crossover recombination and mutation steps in DE. In the\ncase of a linear model, we show that TS-DE enjoys a Bayesian regret of order\n$\\tilde O(d^{2}\\sqrt{MT})$, where $d$ is feature dimension, $M$ is population\nsize and $T$ is number of rounds. This regret bound is nearly optimal,\nconfirming that bandit learning can provably accelerate DE. It may have\nimplications for more general sequence optimization and evolutionary\nalgorithms.",
    "descriptor": "",
    "authors": [
      "Hui Yuan",
      "Chengzhuo Ni",
      "Huazheng Wang",
      "Xuezhou Zhang",
      "Le Cong",
      "Csaba Szepesv\u00e1ri",
      "Mengdi Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.02092"
  },
  {
    "id": "arXiv:2206.02093",
    "title": "LAE: Language-Aware Encoder for Monolingual and Multilingual ASR",
    "abstract": "Despite the rapid progress in automatic speech recognition (ASR) research,\nrecognizing multilingual speech using a unified ASR system remains highly\nchallenging. Previous works on multilingual speech recognition mainly focus on\ntwo directions: recognizing multiple monolingual speech or recognizing\ncode-switched speech that uses different languages interchangeably within a\nsingle utterance. However, a pragmatic multilingual recognizer is expected to\nbe compatible with both directions. In this work, a novel language-aware\nencoder (LAE) architecture is proposed to handle both situations by\ndisentangling language-specific information and generating frame-level\nlanguage-aware representations during encoding. In the LAE, the primary\nencoding is implemented by the shared block while the language-specific blocks\nare used to extract specific representations for each language. To learn\nlanguage-specific information discriminatively, a language-aware training\nmethod is proposed to optimize the language-specific blocks in LAE. Experiments\nconducted on Mandarin-English code-switched speech suggest that the proposed\nLAE is capable of discriminating different languages in frame-level and shows\nsuperior performance on both monolingual and multilingual ASR tasks. With\neither a real-recorded or simulated code-switched dataset, the proposed LAE\nachieves statistically significant improvements on both CTC and neural\ntransducer systems. Code is released",
    "descriptor": "",
    "authors": [
      "Jinchuan Tian",
      "Jianwei Yu",
      "Chunlei Zhang",
      "Chao Weng",
      "Yuexian Zou",
      "Dong Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02093"
  },
  {
    "id": "arXiv:2206.02094",
    "title": "Using Connectome Features to Constrain Echo State Networks",
    "abstract": "We report an improvement to the conventional Echo State Network (ESN), which\nalready achieves competitive performance in one-dimensional time series\nprediction of dynamical systems. Our model -- a 20$\\%$-dense ESN with reservoir\nweights derived from a fruit fly connectome (and from its bootstrapped\ndistribution) -- yields superior performance on a chaotic time series\nprediction task, and furthermore alleviates the ESN's high-variance problem. We\nalso find that an arbitrary positioning of weights can degrade ESN performance\nand variance; and that this can be remedied in particular by employing\nconnectome-derived weight positions. Herein we consider four connectome\nfeatures -- namely, the sparsity, positioning, distribution, and clustering of\nweights -- and construct corresponding model classes (A, B, B${}_2$, C) from an\nappropriate null model ESN; one with its reservoir layer replaced by a fruit\nfly connectivity matrix. After tuning relevant hyperparameters and selecting\nthe best instance of each model class, we train and validate all models for\nmulti-step prediction on size-variants (50, 250, 500, and 750 training input\nsteps) of the Mackey-Glass chaotic time series; and compute their performance\n(Mean-Squared Error) and variance across train-validate trials.",
    "descriptor": "\nComments: 12 pages, 9 figures\n",
    "authors": [
      "Jacob Morra",
      "Mark Daley"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.02094"
  },
  {
    "id": "arXiv:2206.02095",
    "title": "ARC -- Actor Residual Critic for Adversarial Imitation Learning",
    "abstract": "Adversarial Imitation Learning (AIL) is a class of popular state-of-the-art\nImitation Learning algorithms where an artificial adversary's misclassification\nis used as a reward signal and is optimized by any standard Reinforcement\nLearning (RL) algorithm. Unlike most RL settings, the reward in AIL is\ndifferentiable but model-free RL algorithms do not make use of this property to\ntrain a policy. In contrast, we leverage the differentiability property of the\nAIL reward function and formulate a class of Actor Residual Critic (ARC) RL\nalgorithms that draw a parallel to the standard Actor-Critic (AC) algorithms in\nRL literature and uses a residual critic, C function (instead of the standard Q\nfunction) to approximate only the discounted future return (excluding the\nimmediate reward). ARC algorithms have similar convergence properties as the\nstandard AC algorithms with the additional advantage that the gradient through\nthe immediate reward is exact. For the discrete (tabular) case with finite\nstates, actions, and known dynamics, we prove that policy iteration with $C$\nfunction converges to an optimal policy. In the continuous case with function\napproximation and unknown dynamics, we experimentally show that ARC aided AIL\noutperforms standard AIL in simulated continuous-control and real robotic\nmanipulation tasks. ARC algorithms are simple to implement and can be\nincorporated into any existing AIL implementation with an AC algorithm.",
    "descriptor": "",
    "authors": [
      "Ankur Deka",
      "Changliu Liu",
      "Katia Sycara"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.02095"
  },
  {
    "id": "arXiv:2206.02096",
    "title": "PEER: A Comprehensive and Multi-Task Benchmark for Protein Sequence  Understanding",
    "abstract": "We are now witnessing significant progress of deep learning methods in a\nvariety of tasks (or datasets) of proteins. However, there is a lack of a\nstandard benchmark to evaluate the performance of different methods, which\nhinders the progress of deep learning in this field. In this paper, we propose\nsuch a benchmark called PEER, a comprehensive and multi-task benchmark for\nProtein sEquence undERstanding. PEER provides a set of diverse protein\nunderstanding tasks including protein function prediction, protein localization\nprediction, protein structure prediction, protein-protein interaction\nprediction, and protein-ligand interaction prediction. We evaluate different\ntypes of sequence-based methods for each task including traditional feature\nengineering approaches, different sequence encoding methods as well as\nlarge-scale pre-trained protein language models. In addition, we also\ninvestigate the performance of these methods under the multi-task learning\nsetting. Experimental results show that large-scale pre-trained protein\nlanguage models achieve the best performance for most individual tasks, and\njointly training multiple tasks further boosts the performance. The datasets\nand source codes of this benchmark will be open-sourced soon.",
    "descriptor": "\nComments: Research project paper. arXiv v1: release all benchmark results (source code will be released soon in the next version)\n",
    "authors": [
      "Minghao Xu",
      "Zuobai Zhang",
      "Jiarui Lu",
      "Zhaocheng Zhu",
      "Yangtian Zhang",
      "Chang Ma",
      "Runcheng Liu",
      "Jian Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02096"
  },
  {
    "id": "arXiv:2206.02098",
    "title": "Search Space Adaptation for Differentiable Neural Architecture Search in  Image Classification",
    "abstract": "As deep neural networks achieve unprecedented performance in various tasks,\nneural architecture search (NAS), a research field for designing neural network\narchitectures with automated processes, is actively underway. More recently,\ndifferentiable NAS has a great impact by reducing the search cost to the level\nof training a single network. Besides, the search space that defines candidate\narchitectures to be searched directly affects the performance of the final\narchitecture. In this paper, we propose an adaptation scheme of the search\nspace by introducing a search scope. The effectiveness of proposed method is\ndemonstrated with ProxylessNAS for the image classification task. Furthermore,\nwe visualize the trajectory of architecture parameter updates and provide\ninsights to improve the architecture search.",
    "descriptor": "\nComments: 3 pages, 3 figures\n",
    "authors": [
      "Youngkee Kim",
      "Soyi Jung",
      "Minseok Choi",
      "Joongheon Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02098"
  },
  {
    "id": "arXiv:2206.02099",
    "title": "Point-to-Voxel Knowledge Distillation for LiDAR Semantic Segmentation",
    "abstract": "This article addresses the problem of distilling knowledge from a large\nteacher model to a slim student network for LiDAR semantic segmentation.\nDirectly employing previous distillation approaches yields inferior results due\nto the intrinsic challenges of point cloud, i.e., sparsity, randomness and\nvarying density. To tackle the aforementioned problems, we propose the\nPoint-to-Voxel Knowledge Distillation (PVD), which transfers the hidden\nknowledge from both point level and voxel level. Specifically, we first\nleverage both the pointwise and voxelwise output distillation to complement the\nsparse supervision signals. Then, to better exploit the structural information,\nwe divide the whole point cloud into several supervoxels and design a\ndifficulty-aware sampling strategy to more frequently sample supervoxels\ncontaining less-frequent classes and faraway objects. On these supervoxels, we\npropose inter-point and inter-voxel affinity distillation, where the similarity\ninformation between points and voxels can help the student model better capture\nthe structural information of the surrounding environment. We conduct extensive\nexperiments on two popular LiDAR segmentation benchmarks, i.e., nuScenes and\nSemanticKITTI. On both benchmarks, our PVD consistently outperforms previous\ndistillation approaches by a large margin on three representative backbones,\ni.e., Cylinder3D, SPVNAS and MinkowskiNet. Notably, on the challenging nuScenes\nand SemanticKITTI datasets, our method can achieve roughly 75% MACs reduction\nand 2x speedup on the competitive Cylinder3D model and rank 1st on the\nSemanticKITTI leaderboard among all published algorithms. Our code is available\nat https://github.com/cardwing/Codes-for-PVKD.",
    "descriptor": "\nComments: CVPR 2022; Our model ranks 1st on Waymo and SemanticKITTI (single-scan) challenges, and ranks 3rd on SemanticKITTI (multi-scan) challenge; Code: this https URL\n",
    "authors": [
      "Yuenan Hou",
      "Xinge Zhu",
      "Yuexin Ma",
      "Chen Change Loy",
      "Yikang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02099"
  },
  {
    "id": "arXiv:2206.02100",
    "title": "ACORN: Network Control Plane Abstraction using Route Nondeterminism",
    "abstract": "Networks are hard to configure correctly, and misconfigurations occur\nfrequently, leading to outages or security breaches. Formal verification\ntechniques have been applied to guarantee the correctness of network\nconfigurations, thereby improving network reliability. This work addresses\nverification of distributed network control planes, with two distinct\ncontributions to improve the scalability of formal verification. Our first\ncontribution is a hierarchy of abstractions of varying precision which\nintroduce nondeterminism into the route selection procedure that routers use to\nselect the best available route. We prove the soundness of these abstractions\nand show their benefits. Our second contribution is a novel SMT encoding which\nuses symbolic graphs to encode all possible stable routing trees that are\ncompliant with the given network control plane configurations. We have\nimplemented our abstractions and SMT encodings in a prototype tool called\nACORN. Our evaluations show that our abstractions can provide significant\nrelative speedups (up to 323x) in performance, and ACORN can scale up to\n$\\approx37,000$ routers (organized in FatTree topologies, with synthesized\nshortest-path routing and valley-free policies) for verifying reachability.\nThis far exceeds the performance of existing tools for control plane\nverification.",
    "descriptor": "\nComments: 23 pages, 10 figures\n",
    "authors": [
      "Divya Raghunathan",
      "Ryan Beckett",
      "Aarti Gupta",
      "David Walker"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.02100"
  },
  {
    "id": "arXiv:2206.02102",
    "title": "AUTM Flow: Atomic Unrestricted Time Machine for Monotonic Normalizing  Flows",
    "abstract": "Nonlinear monotone transformations are used extensively in normalizing flows\nto construct invertible triangular mappings from simple distributions to\ncomplex ones. In existing literature, monotonicity is usually enforced by\nrestricting function classes or model parameters and the inverse transformation\nis often approximated by root-finding algorithms as a closed-form inverse is\nunavailable. In this paper, we introduce a new integral-based approach termed\n\"Atomic Unrestricted Time Machine (AUTM)\", equipped with unrestricted\nintegrands and easy-to-compute explicit inverse. AUTM offers a versatile and\nefficient way to the design of normalizing flows with explicit inverse and\nunrestricted function classes or parameters. Theoretically, we present a\nconstructive proof that AUTM is universal: all monotonic normalizing flows can\nbe viewed as limits of AUTM flows. We provide a concrete example to show how to\napproximate any given monotonic normalizing flow using AUTM flows with\nguaranteed convergence. The result implies that AUTM can be used to transform\nan existing flow into a new one equipped with explicit inverse and unrestricted\nparameters. The performance of the new approach is evaluated on high\ndimensional density estimation, variational inference and image generation.\nExperiments demonstrate superior speed and memory efficiency of AUTM.",
    "descriptor": "\nComments: 20 pages, 3 figures\n",
    "authors": [
      "Difeng Cai",
      "Yuliang Ji",
      "Huan He",
      "Qiang Ye",
      "Yuanzhe Xi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.02102"
  },
  {
    "id": "arXiv:2206.02104",
    "title": "ContraCLIP: Interpretable GAN generation driven by pairs of contrasting  sentences",
    "abstract": "This work addresses the problem of discovering non-linear interpretable paths\nin the latent space of pre-trained GANs in a model-agnostic manner. In the\nproposed method, the discovery is driven by a set of pairs of natural language\nsentences with contrasting semantics, named semantic dipoles, that serve as the\nlimits of the interpretation that we require by the trainable latent paths to\nencode. By using the pre-trained CLIP encoder, the sentences are projected into\nthe vision-language space, where they serve as dipoles, and where RBF-based\nwarping functions define a set of non-linear directional paths, one for each\nsemantic dipole, allowing in this way traversals from one semantic pole to the\nother. By defining an objective that discovers paths in the latent space of\nGANs that generate changes along the desired paths in the vision-language\nembedding space, we provide an intuitive way of controlling the underlying\ngenerative factors and address some of the limitations of the state-of-the-art\nworks, namely, that a) they are typically tailored to specific GAN\narchitectures (i.e., StyleGAN), b) they disregard the relative position of the\nmanipulated and the original image in the image embedding and the relative\nposition of the image and the text embeddings, and c) they lead to abrupt image\nmanipulations and quickly arrive at regions of low density and, thus, low image\nquality, providing limited control of the generative factors. We provide\nextensive qualitative and quantitative results that demonstrate our claims with\ntwo pre-trained GANs, and make the code and the pre-trained models publicly\navailable at: https://github.com/chi0tzp/ContraCLIP",
    "descriptor": "",
    "authors": [
      "Christos Tzelepis",
      "James Oldfield",
      "Georgios Tzimiropoulos",
      "Ioannis Patras"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02104"
  },
  {
    "id": "arXiv:2206.02107",
    "title": "Interpretable Mixture of Experts for Structured Data",
    "abstract": "With the growth of machine learning for structured data, the need for\nreliable model explanations is essential, especially in high-stakes\napplications. We introduce a novel framework, Interpretable Mixture of Experts\n(IME), that provides interpretability for structured data while preserving\naccuracy. IME consists of an assignment module and a mixture of interpretable\nexperts such as linear models where each sample is assigned to a single\ninterpretable expert. This results in an inherently-interpretable architecture\nwhere the explanations produced by IME are the exact descriptions of how the\nprediction is computed. In addition to constituting a standalone\ninherently-interpretable architecture, an additional IME capability is that it\ncan be integrated with existing Deep Neural Networks (DNNs) to offer\ninterpretability to a subset of samples while maintaining the accuracy of the\nDNNs. Experiments on various structured datasets demonstrate that IME is more\naccurate than a single interpretable model and performs comparably to existing\nstate-of-the-art deep learning models in terms of accuracy while providing\nfaithful explanations.",
    "descriptor": "",
    "authors": [
      "Aya Abdelsalam Ismail",
      "Sercan \u00d6. Arik",
      "Jinsung Yoon",
      "Ankur Taly",
      "Soheil Feizi",
      "Tomas Pfister"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02107"
  },
  {
    "id": "arXiv:2206.02109",
    "title": "Delay Alignment Modulation: Manipulating Channel Delay Spread for  Efficient Single- and Multi-Carrier Communication",
    "abstract": "The evolution of mobile communication networks has always been accompanied by\nthe advancement of inter-symbol interference (ISI) mitigation techniques, from\nequalization in 2G, spread spectrum and RAKE receiver in 3G, to OFDM in 4G and\n5G. Looking forward towards 6G, by exploiting the extremely large spatial\ndimension brought by large antenna arrays and multi-path sparsity of millimeter\nwave (mmWave)/Terahertz channels, we propose a novel ISI mitigation technique,\ntermed delay alignment modulation (DAM). The key ideas of DAM are path delay\npre-compensation and path-based beamforming, i.e., by deliberately introducing\nsymbol delays to compensate respective multi-path delays of the channel, so\nthat with appropriate per-path-based beamforming, the multi-path signal\ncomponents will arrive at the receiver simultaneously and constructively. To\ngain some insights, we first show that perfect delay alignment can be achieved\nto transform the time-dispersive channel to time non-dispersive channel,\nwithout sophisticated channel equalization or multi-carrier processing. This\nthus enables efficient equalization-free single-carrier transmission or CP-free\nOFDM transmission. When perfect DAM is infeasible or undesirable, we propose\nthe generic DAM technique to significantly reduce the channel delay spread.\nThis thus provides a new DoF to combat channel time dispersion for more\nefficient single- or multi-carrier signal transmissions. As an illustration, we\npropose the novel DAM-OFDM technique, which may save the CP overhead or\nmitigate the PAPR and CFO issues suffered by conventional OFDM. We show that\nDAM-OFDM involves joint frequency-domain and time-domain beamforming\noptimization, for which a closed-form solution is derived. Simulation results\nshow that the proposed DAM-OFDM achieves significant performance gains over the\nconventional OFDM, in terms of spectral efficiency, BER and PAPR.",
    "descriptor": "\nComments: 14 Pages, 14 figures\n",
    "authors": [
      "Haiquan Lu",
      "Yong Zeng"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.02109"
  },
  {
    "id": "arXiv:2206.02110",
    "title": "Computer Vision-based Characterization of Large-scale Jet Flames using a  Synthetic Infrared Image Generation Approach",
    "abstract": "Among the different kinds of fire accidents that can occur during industrial\nactivities that involve hazardous materials, jet fires are one of the\nlesser-known types. This is because they are often involved in a process that\ngenerates a sequence of other accidents of greater magnitude, known as domino\neffect. Flame impingement usually causes domino effects, and jet fires present\nspecific features that can significantly increase the probability of this\nhappening. These features become relevant from a risk analysis perspective,\nmaking their proper characterization a crucial task. Deep Learning approaches\nhave become extensively used for tasks such as jet fire characterization;\nhowever, these methods are heavily dependent on the amount of data and the\nquality of the labels. Data acquisition of jet fires involve expensive\nexperiments, especially so if infrared imagery is used. Therefore, this paper\nproposes the use of Generative Adversarial Networks to produce plausible\ninfrared images from visible ones, making experiments less expensive and\nallowing for other potential applications. The results suggest that it is\npossible to realistically replicate the results for experiments carried out\nusing both visible and infrared cameras. The obtained results are compared with\nsome previous experiments, and it is shown that similar results were obtained.",
    "descriptor": "\nComments: Pre-print submitted to Engineering Science and Technology, an International Journal\n",
    "authors": [
      "Carmina P\u00e9rez-Guerrero",
      "Jorge Francisco Cipri\u00e1n-S\u00e1nchez",
      "Adriana Palacios",
      "Gilberto Ochoa-Ruiz",
      "Miguel Gonzalez-Mendoza",
      "Vahid Foroughi",
      "Elsa Pastor",
      "Gerardo Rodriguez-Hernandez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.02110"
  },
  {
    "id": "arXiv:2206.02111",
    "title": "LASSO-Based Multiple-Line Outage Identification In Partially Observable  Power Systems",
    "abstract": "Phasor measurement units (PMUs) create ample real-time monitoring\nopportunities for modern power systems. Among them, line outage detection and\nidentification remains a crucial but challenging task. Current works on outage\nidentification succeed in full PMU deployment and single-line outages.\nPerformance however degrades for multiple-line outage with partial system\nobservability. We propose a novel framework of multiple-line outage\nidentification using partial nodal voltage measurements. Using alternating\ncurrent (AC) power flow model, phase angle signatures of outages are extracted\nand used to group lines into minimal diagnosable clusters. Identification is\nthen formulated into an underdetermined sparse regression problem solved by\nlasso. Tested on IEEE 39-bus system with 25% and 50% PMU coverage, the proposed\nidentification method is 93% and 80% accurate for single- and double-line\noutages. Our study suggests that the AC power flow is better at capturing\noutage patterns and sacrificing some precision could yield substantial\nimprovement in identification accuracy. These findings could contribute to the\ndevelopment of future control schemes that help power systems resist and\nrecover from outage disruptions in real time.",
    "descriptor": "\nComments: 9 pages, 6 figures\n",
    "authors": [
      "Xiaozhou Yang",
      "Nan Chen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2206.02111"
  },
  {
    "id": "arXiv:2206.02114",
    "title": "Speech Detection Task Against Asian Hate: BERT the Central, While  Data-Centric Studies the Crucial",
    "abstract": "With the epidemic continuing, hatred against Asians is intensifying in\ncountries outside Asia, especially among the Chinese. Thus, there is an urgent\nneed to detect and prevent hate speech toward Asians effectively. In this work,\nwe first create COVID-HATE-2022, an annotated dataset that is an extension of\nthe anti-Asian hate speech dataset on Twitter, including 2,035 annotated tweets\nfetched in early February 2022, which are labeled based on specific criteria,\nand we present the comprehensive collection of scenarios of hate and non-hate\ntweets in the dataset. Second, we fine-tune the BERT models based on the\nrelevant datasets, and demonstrate strategies including 1) cleaning the\nhashtags, usernames being @, URLs, and emojis before the fine-tuning process,\nand 2) training with the data while validating with the \"clean\" data (and the\nopposite) are not effective for improving performance. Third, we investigate\nthe performance of advanced fine-tuning strategies with 1) model-centric\napproaches, such as discriminative fine-tuning, gradual unfreezing, and warmup\nsteps, and 2) data-centric approaches, which incorporate data trimming and data\naugmenting, and show that both strategies generally improve the performance,\nwhile data-centric ones outperform the others, which demonstrate the\nfeasibility and effectiveness of the data-centric approaches.",
    "descriptor": "",
    "authors": [
      "Xin Lian"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.02114"
  },
  {
    "id": "arXiv:2206.02115",
    "title": "Learning Binarized Graph Representations with Multi-faceted Quantization  Reinforcement for Top-K Recommendation",
    "abstract": "Learning vectorized embeddings is at the core of various recommender systems\nfor user-item matching. To perform efficient online inference, representation\nquantization, aiming to embed the latent features by a compact sequence of\ndiscrete numbers, recently shows the promising potentiality in optimizing both\nmemory and computation overheads. However, existing work merely focuses on\nnumerical quantization whilst ignoring the concomitant information loss issue,\nwhich, consequently, leads to conspicuous performance degradation. In this\npaper, we propose a novel quantization framework to learn Binarized Graph\nRepresentations for Top-K Recommendation (BiGeaR). BiGeaR introduces\nmulti-faceted quantization reinforcement at the pre-, mid-, and post-stage of\nbinarized representation learning, which substantially retains the\nrepresentation informativeness against embedding binarization. In addition to\nsaving the memory footprint, BiGeaR further develops solid online inference\nacceleration with bitwise operations, providing alternative flexibility for the\nrealistic deployment. The empirical results over five large real-world\nbenchmarks show that BiGeaR achieves about 22%~40% performance improvement over\nthe state-of-the-art quantization-based recommender system, and recovers about\n95%~102% of the performance capability of the best full-precision counterpart\nwith over 8x time and space reduction.",
    "descriptor": "\nComments: Accepted by SIGKDD 2022\n",
    "authors": [
      "Yankai Chen",
      "Huifeng Guo",
      "Yingxue Zhang",
      "Chen Ma",
      "Ruiming Tang",
      "Jingjie Li",
      "Irwin King"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.02115"
  },
  {
    "id": "arXiv:2206.02116",
    "title": "Cannot See the Forest for the Trees: Aggregating Multiple Viewpoints to  Better Classify Objects in Videos",
    "abstract": "Recently, both long-tailed recognition and object tracking have made great\nadvances individually. TAO benchmark presented a mixture of the two,\nlong-tailed object tracking, in order to further reflect the aspect of the\nreal-world. To date, existing solutions have adopted detectors showing\nrobustness in long-tailed distributions, which derive per-frame results. Then,\nthey used tracking algorithms that combine the temporally independent\ndetections to finalize tracklets. However, as the approaches did not take\ntemporal changes in scenes into account, inconsistent classification results in\nvideos led to low overall performance. In this paper, we present a set\nclassifier that improves accuracy of classifying tracklets by aggregating\ninformation from multiple viewpoints contained in a tracklet. To cope with\nsparse annotations in videos, we further propose augmentation of tracklets that\ncan maximize data efficiency. The set classifier is plug-and-playable to\nexisting object trackers, and highly improves the performance of long-tailed\nobject tracking. By simply attaching our method to QDTrack on top of\nResNet-101, we achieve the new state-of-the-art, 19.9% and 15.7% TrackAP_50 on\nTAO validation and test sets, respectively.",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Sukjun Hwang",
      "Miran Heo",
      "Seoung Wug Oh",
      "Seon Joo Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02116"
  },
  {
    "id": "arXiv:2206.02118",
    "title": "ShapePU: A New PU Learning Framework Regularized by Global Consistency  for Scribble Supervised Cardiac Segmentation",
    "abstract": "Cardiac segmentation is an essential step for the diagnosis of cardiovascular\ndiseases. However, pixel-wise dense labeling is both costly and time-consuming.\nScribble, as a form of sparse annotation, is more accessible than full\nannotations. However, it's particularly challenging to train a segmentation\nnetwork with weak supervision from scribbles. To tackle this problem, we\npropose a new scribble-guided method for cardiac segmentation, based on the\nPositive-Unlabeled (PU) learning framework and global consistency\nregularization, and termed as ShapePU. To leverage unlabeled pixels via PU\nlearning, we first present an Expectation-Maximization (EM) algorithm to\nestimate the proportion of each class in the unlabeled pixels. Given the\nestimated ratios, we then introduce the marginal probability maximization to\nidentify the classes of unlabeled pixels. To exploit shape knowledge, we apply\ncutout operations to training images, and penalize the inconsistent\nsegmentation results. Evaluated on two open datasets, i.e, ACDC and MSCMRseg,\nour scribble-supervised ShapePU surpassed the fully supervised approach\nrespectively by 1.4% and 9.8% in average Dice, and outperformed the\nstate-of-the-art weakly supervised and PU learning methods by large margins.\nOur code is available at https://github.com/BWGZK/ShapePU.",
    "descriptor": "\nComments: 11 pages,4 figures\n",
    "authors": [
      "Ke Zhang",
      "Xiahai Zhuang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02118"
  },
  {
    "id": "arXiv:2206.02119",
    "title": "A Multimodal Corpus for Emotion Recognition in Sarcasm",
    "abstract": "While sentiment and emotion analysis have been studied extensively, the\nrelationship between sarcasm and emotion has largely remained unexplored. A\nsarcastic expression may have a variety of underlying emotions. For example, \"I\nlove being ignored\" belies sadness, while \"my mobile is fabulous with a battery\nbackup of only 15 minutes!\" expresses frustration. Detecting the emotion behind\na sarcastic expression is non-trivial yet an important task. We undertake the\ntask of detecting the emotion in a sarcastic statement, which to the best of\nour knowledge, is hitherto unexplored. We start with the recently released\nmultimodal sarcasm detection dataset (MUStARD) pre-annotated with 9 emotions.\nWe identify and correct 343 incorrect emotion labels (out of 690). We double\nthe size of the dataset, label it with emotions along with valence and arousal\nwhich are important indicators of emotional intensity. Finally, we label each\nsarcastic utterance with one of the four sarcasm types-Propositional, Embedded,\nLikeprefixed and Illocutionary, with the goal of advancing sarcasm detection\nresearch. Exhaustive experimentation with multimodal (text, audio, and video)\nfusion models establishes a benchmark for exact emotion recognition in sarcasm\nand outperforms the state-of-art sarcasm detection. We release the dataset\nenriched with various annotations and the code for research purposes:\nhttps://github.com/apoorva-nunna/MUStARD_Plus_Plus",
    "descriptor": "",
    "authors": [
      "Anupama Ray",
      "Shubham Mishra",
      "Apoorva Nunna",
      "Pushpak Bhattacharyya"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.02119"
  },
  {
    "id": "arXiv:2206.02120",
    "title": "MPANet: Multi-Patch Attention For Infrared Small Target object Detection",
    "abstract": "Infrared small target detection (ISTD) has attracted widespread attention and\nbeen applied in various fields. Due to the small size of infrared targets and\nthe noise interference from complex backgrounds, the performance of ISTD using\nconvolutional neural networks (CNNs) is restricted. Moreover, the constriant\nthat long-distance dependent features can not be encoded by the vanilla CNNs\nalso impairs the robustness of capturing targets' shapes and locations in\ncomplex scenarios. To this end, a multi-patch attention network (MPANet) based\non the axial-attention encoder and the multi-scale patch branch (MSPB)\nstructure is proposed. Specially, an axial-attention-improved encoder\narchitecture is designed to highlight the effective features of small targets\nand suppress background noises. Furthermore, the developed MSPB structure fuses\nthe coarse-grained and fine-grained features from different semantic scales.\nExtensive experiments on the SIRST dataset show the superiority performance and\neffectiveness of the proposed MPANet compared to the state-of-the-art methods.",
    "descriptor": "\nComments: 4 pages 3 figures\n",
    "authors": [
      "Ao Wang",
      "Wei Li",
      "Xin Wu",
      "Zhanchao Huang",
      "Ran Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02120"
  },
  {
    "id": "arXiv:2206.02126",
    "title": "Learning Dynamics and Generalization in Reinforcement Learning",
    "abstract": "Solving a reinforcement learning (RL) problem poses two competing challenges:\nfitting a potentially discontinuous value function, and generalizing well to\nnew observations. In this paper, we analyze the learning dynamics of temporal\ndifference algorithms to gain novel insight into the tension between these two\nobjectives. We show theoretically that temporal difference learning encourages\nagents to fit non-smooth components of the value function early in training,\nand at the same time induces the second-order effect of discouraging\ngeneralization. We corroborate these findings in deep RL agents trained on a\nrange of environments, finding that neural networks trained using temporal\ndifference algorithms on dense reward tasks exhibit weaker generalization\nbetween states than randomly initialized networks and networks trained with\npolicy gradient methods. Finally, we investigate how post-training policy\ndistillation may avoid this pitfall, and show that this approach improves\ngeneralization to novel environments in the ProcGen suite and improves\nrobustness to input perturbations.",
    "descriptor": "",
    "authors": [
      "Clare Lyle",
      "Mark Rowland",
      "Will Dabney",
      "Marta Kwiatkowska",
      "Yarin Gal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02126"
  },
  {
    "id": "arXiv:2206.02127",
    "title": "DeeprETA: An ETA Post-processing System at Scale",
    "abstract": "Estimated Time of Arrival (ETA) plays an important role in delivery and\nride-hailing platforms. For example, Uber uses ETAs to calculate fares,\nestimate pickup times, match riders to drivers, plan deliveries, and more.\nCommonly used route planning algorithms predict an ETA conditioned on the best\navailable route, but such ETA estimates can be unreliable when the actual route\ntaken is not known in advance. In this paper, we describe an ETA\npost-processing system in which a deep residual ETA network (DeeprETA) refines\nnaive ETAs produced by a route planning algorithm. Offline experiments and\nonline tests demonstrate that post-processing by DeeprETA significantly\nimproves upon the accuracy of naive ETAs as measured by mean and median\nabsolute error. We further show that post-processing by DeeprETA attains lower\nerror than competitive baseline regression models.",
    "descriptor": "",
    "authors": [
      "Xinyu Hu",
      "Tanmay Binaykiya",
      "Eric Frank",
      "Olcay Cirit"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02127"
  },
  {
    "id": "arXiv:2206.02131",
    "title": "Federated Adversarial Training with Transformers",
    "abstract": "Federated learning (FL) has emerged to enable global model training over\ndistributed clients' data while preserving its privacy. However, the global\ntrained model is vulnerable to the evasion attacks especially, the adversarial\nexamples (AEs), carefully crafted samples to yield false classification.\nAdversarial training (AT) is found to be the most promising approach against\nevasion attacks and it is widely studied for convolutional neural network\n(CNN). Recently, vision transformers have been found to be effective in many\ncomputer vision tasks. To the best of the authors' knowledge, there is no work\nthat studied the feasibility of AT in a FL process for vision transformers.\nThis paper investigates such feasibility with different federated model\naggregation methods and different vision transformer models with different\ntokenization and classification head techniques. In order to improve the robust\naccuracy of the models with the not independent and identically distributed\n(Non-IID), we propose an extension to FedAvg aggregation method, called\nFedWAvg. By measuring the similarities between the last layer of the global\nmodel and the last layer of the client updates, FedWAvg calculates the weights\nto aggregate the local models updates. The experiments show that FedWAvg\nimproves the robust accuracy when compared with other state-of-the-art\naggregation methods.",
    "descriptor": "",
    "authors": [
      "Ahmed Aldahdooh",
      "Wassim Hamidouche",
      "Olivier D\u00e9forges"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02131"
  },
  {
    "id": "arXiv:2206.02136",
    "title": "LDRNet: Enabling Real-time Document Localization on Mobile Devices",
    "abstract": "While Identity Document Verification (IDV) technology on mobile devices\nbecomes ubiquitous in modern business operations, the risk of identity theft\nand fraud is increasing. The identity document holder is normally required to\nparticipate in an online video interview to circumvent impostors. However, the\ncurrent IDV process depends on an additional human workforce to support online\nstep-by-step guidance which is inefficient and expensive. The performance of\nexisting AI-based approaches cannot meet the real-time and lightweight demands\nof mobile devices. In this paper, we address those challenges by designing an\nedge intelligence-assisted approach for real-time IDV. Aiming at improving the\nresponsiveness of the IDV process, we propose a new document localization model\nfor mobile devices, LDRNet, to Localize the identity Document in Real-time. On\nthe basis of a lightweight backbone network, we build three prediction branches\nfor LDRNet, the corner points prediction, the line borders prediction and the\ndocument classification. We design novel supplementary targets, the\nequal-division points, and use a new loss function named Line Loss, to improve\nthe speed and accuracy of our approach. In addition to the IDV process, LDRNet\nis an efficient and reliable document localization alternative for all kinds of\nmobile applications. As a matter of proof, we compare the performance of LDRNet\nwith other popular approaches on localizing general document datasets. The\nexperimental results show that LDRNet runs at a speed up to 790 FPS which is\n47x faster, while still achieving comparable Jaccard Index(JI) in single-model\nand single-scale tests.",
    "descriptor": "",
    "authors": [
      "Han Wu",
      "Holland Qian",
      "Huaming Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2206.02136"
  },
  {
    "id": "arXiv:2206.02139",
    "title": "Early Stage Convergence and Global Convergence of Training Mildly  Parameterized Neural Networks",
    "abstract": "The convergence of GD and SGD when training mildly parameterized neural\nnetworks starting from random initialization is studied. For a broad range of\nmodels and loss functions, including the most commonly used square loss and\ncross entropy loss, we prove an ``early stage convergence'' result. We show\nthat the loss is decreased by a significant amount in the early stage of the\ntraining, and this decrease is fast. Furthurmore, for exponential type loss\nfunctions, and under some assumptions on the training data, we show global\nconvergence of GD. Instead of relying on extreme over-parameterization, our\nstudy is based on a microscopic analysis of the activation patterns for the\nneurons, which helps us derive more powerful lower bounds for the gradient. The\nresults on activation patterns, which we call ``neuron partition'', help build\nintuitions for understanding the behavior of neural networks' training\ndynamics, and may be of independent interest.",
    "descriptor": "",
    "authors": [
      "Mingze Wang",
      "Chao Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.02139"
  },
  {
    "id": "arXiv:2206.02144",
    "title": "Product safety idioms: a method for building causal Bayesian networks  for product safety and risk assessment",
    "abstract": "Idioms are small, reusable Bayesian network (BN) fragments that represent\ngeneric types of uncertain reasoning. This paper shows how idioms can be used\nto build causal BNs for product safety and risk assessment that use a\ncombination of data and knowledge. We show that the specific product safety\nidioms that we introduce are sufficient to build full BN models to evaluate\nsafety and risk for a wide range of products. The resulting models can be used\nby safety regulators and product manufacturers even when there are limited (or\nno) product testing data.",
    "descriptor": "",
    "authors": [
      "Joshua Hunte",
      "Martin Neil",
      "Norman Fenton"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02144"
  },
  {
    "id": "arXiv:2206.02146",
    "title": "Recurrent Video Restoration Transformer with Guided Deformable Attention",
    "abstract": "Video restoration aims at restoring multiple high-quality frames from\nmultiple low-quality frames. Existing video restoration methods generally fall\ninto two extreme cases, i.e., they either restore all frames in parallel or\nrestore the video frame by frame in a recurrent way, which would result in\ndifferent merits and drawbacks. Typically, the former has the advantage of\ntemporal information fusion. However, it suffers from large model size and\nintensive memory consumption; the latter has a relatively small model size as\nit shares parameters across frames; however, it lacks long-range dependency\nmodeling ability and parallelizability. In this paper, we attempt to integrate\nthe advantages of the two cases by proposing a recurrent video restoration\ntransformer, namely RVRT. RVRT processes local neighboring frames in parallel\nwithin a globally recurrent framework which can achieve a good trade-off\nbetween model size, effectiveness, and efficiency. Specifically, RVRT divides\nthe video into multiple clips and uses the previously inferred clip feature to\nestimate the subsequent clip feature. Within each clip, different frame\nfeatures are jointly updated with implicit feature aggregation. Across\ndifferent clips, the guided deformable attention is designed for clip-to-clip\nalignment, which predicts multiple relevant locations from the whole inferred\nclip and aggregates their features by the attention mechanism. Extensive\nexperiments on video super-resolution, deblurring, and denoising show that the\nproposed RVRT achieves state-of-the-art performance on benchmark datasets with\nbalanced model size, testing memory and runtime.",
    "descriptor": "\nComments: Code: this https URL\n",
    "authors": [
      "Jingyun Liang",
      "Yuchen Fan",
      "Xiaoyu Xiang",
      "Rakesh Ranjan",
      "Eddy Ilg",
      "Simon Green",
      "Jiezhang Cao",
      "Kai Zhang",
      "Radu Timofte",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.02146"
  },
  {
    "id": "arXiv:2206.02150",
    "title": "BenchFaaS: Benchmarking Serverless Functions in an Edge Computing  Network Testbed",
    "abstract": "The serverless computing model has evolved as one of the key solutions in the\ncloud for fast autoscaling and capacity planning. In edge computing\nenvironments, however, the serverless model is challenged by the system\nheterogeneity and performance variability. In this paper, we introduce\nBenchFaaS, an edge computing network testbed built with state-of-the-art free-\nand open source software tools which automates the deployment and benchmarking\nof serverless functions. Our edge computing network considers a cluster of\nvirtual machines and Raspberry Pis, and is designed to benchmark serverless\nfunctions under different hardware and network conditions. We measure and\nevaluate: (i) overhead incurred by testbed, (ii) performance of compute\nintensive tasks, (iii) impact of application payload size, (iv) scalability,\nand (v) performance of chained serverless functions. We share the lessons\nlearnt in engineering and implementing an open source edge computing network\ntestbed. The measurements indicate that a properly dimensioned system can\neffectively deploy resource constrained edge computing devices as a serverless\ninfrastructure. We also show that a computer system closer to the edge does not\nalways yield a better network system performance overall.",
    "descriptor": "",
    "authors": [
      "Francisco Carpio",
      "Marc Michalke",
      "Admela Jukan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.02150"
  },
  {
    "id": "arXiv:2206.02152",
    "title": "Which models are innately best at uncertainty estimation?",
    "abstract": "Deep neural networks must be equipped with an uncertainty estimation\nmechanism when deployed for risk-sensitive tasks. This paper studies the\nrelationship between deep architectures and their training regimes with their\ncorresponding selective prediction and uncertainty estimation performance. We\nconsider both in-distribution uncertainties and class-out-of-distribution ones.\nMoreover, we consider some of the most popular estimation performance metrics\npreviously proposed including AUROC, ECE, AURC, and coverage for selective\naccuracy constraint. We present a novel and comprehensive study of selective\nprediction and the uncertainty estimation performance of 484 existing\npretrained deep ImageNet classifiers that are available at popular\nrepositories. We identify numerous and previously unknown factors that affect\nuncertainty estimation and examine the relationships between the different\nmetrics. We find that distillation-based training regimes consistently yield\nbetter uncertainty estimations than other training schemes such as vanilla\ntraining, pretraining on a larger dataset and adversarial training. We also\nprovide strong empirical evidence showing that ViT is by far the most superior\narchitecture in terms of uncertainty estimation performance, judging by any\naspect, in both in-distribution and class-out-of-distribution scenarios.",
    "descriptor": "",
    "authors": [
      "Ido Galil",
      "Mohammed Dabbah",
      "Ran El-Yaniv"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02152"
  },
  {
    "id": "arXiv:2206.02153",
    "title": "HPGNN: Using Hierarchical Graph Neural Networks for Outdoor Point Cloud  Processing",
    "abstract": "Inspired by recent improvements in point cloud processing for autonomous\nnavigation, we focus on using hierarchical graph neural networks for processing\nand feature learning over large-scale outdoor LiDAR point clouds. We observe\nthat existing GNN based methods fail to overcome challenges of scale and\nirregularity of points in outdoor datasets. Addressing the need to preserve\nstructural details while learning over a larger volume efficiently, we propose\nHierarchical Point Graph Neural Network (HPGNN). It learns node features at\nvarious levels of graph coarseness to extract information. This enables to\nlearn over a large point cloud while retaining fine details that existing\npoint-level graph networks struggle to achieve. Connections between multiple\nlevels enable a point to learn features in multiple scales, in a few\niterations. We design HPGNN as a purely GNN-based approach, so that it offers\nmodular expandability as seen with other point-based and Graph network\nbaselines. To illustrate the improved processing capability, we compare\nprevious point based and GNN models for semantic segmentation with our HPGNN,\nachieving a significant improvement for GNNs (+36.7 mIoU) on the SemanticKITTI\ndataset.",
    "descriptor": "\nComments: Accepted for ICPR 2022\n",
    "authors": [
      "Arulmolivarman Thieshanthan",
      "Amashi Niwarthana",
      "Pamuditha Somarathne",
      "Tharindu Wickremasinghe",
      "Ranga Rodrigo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02153"
  },
  {
    "id": "arXiv:2206.02156",
    "title": "Perspectives of Non-Expert Users on Cyber Security and Privacy: An  Analysis of Online Discussions on Twitter",
    "abstract": "Current research on users` perspectives of cyber security and privacy related\nto traditional and smart devices at home is very active, but the focus is often\nmore on specific modern devices such as mobile and smart IoT devices in a home\ncontext. In addition, most were based on smaller-scale empirical studies such\nas online surveys and interviews. We endeavour to fill these research gaps by\nconducting a larger-scale study based on a real-world dataset of 413,985 tweets\nposted by non-expert users on Twitter in six months of three consecutive years\n(January and February in 2019, 2020 and 2021). Two machine learning-based\nclassifiers were developed to identify the 413,985 tweets. We analysed this\ndataset to understand non-expert users` cyber security and privacy\nperspectives, including the yearly trend and the impact of the COVID-19\npandemic. We applied topic modelling, sentiment analysis and qualitative\nanalysis of selected tweets in the dataset, leading to various interesting\nfindings. For instance, we observed a 54% increase in non-expert users` tweets\non cyber security and/or privacy related topics in 2021, compared to before the\nstart of global COVID-19 lockdowns (January 2019 to February 2020). We also\nobserved an increased level of help-seeking tweets during the COVID-19\npandemic. Our analysis revealed a diverse range of topics discussed by\nnon-expert users across the three years, including VPNs, Wi-Fi, smartphones,\nlaptops, smart home devices, financial security, and security and privacy\nissues involving different stakeholders. Overall negative sentiment was\nobserved across almost all topics non-expert users discussed on Twitter in all\nthe three years. Our results confirm the multi-faceted nature of non-expert\nusers` perspectives on cyber security and privacy and call for more holistic,\ncomprehensive and nuanced research on different facets of such perspectives.",
    "descriptor": "\nComments: 18 pages, 5 figures, submitted to Computers & Security\n",
    "authors": [
      "Nandita Pattnaik",
      "Shujun Li",
      "Jason R.C. Nurse"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02156"
  },
  {
    "id": "arXiv:2206.02157",
    "title": "Never mind the metrics -- what about the uncertainty? Visualising  confusion matrix metric distributions",
    "abstract": "There are strong incentives to build models that demonstrate outstanding\npredictive performance on various datasets and benchmarks. We believe these\nincentives risk a narrow focus on models and on the performance metrics used to\nevaluate and compare them -- resulting in a growing body of literature to\nevaluate and compare metrics. This paper strives for a more balanced\nperspective on classifier performance metrics by highlighting their\ndistributions under different models of uncertainty and showing how this\nuncertainty can easily eclipse differences in the empirical performance of\nclassifiers. We begin by emphasising the fundamentally discrete nature of\nempirical confusion matrices and show how binary matrices can be meaningfully\nrepresented in a three dimensional compositional lattice, whose cross-sections\nform the basis of the space of receiver operating characteristic (ROC) curves.\nWe develop equations, animations and interactive visualisations of the contours\nof performance metrics within (and beyond) this ROC space, showing how some are\naffected by class imbalance. We provide interactive visualisations that show\nthe discrete posterior predictive probability mass functions of true and false\npositive rates in ROC space, and how these relate to uncertainty in performance\nmetrics such as Balanced Accuracy (BA) and the Matthews Correlation Coefficient\n(MCC). Our hope is that these insights and visualisations will raise greater\nawareness of the substantial uncertainty in performance metric estimates that\ncan arise when classifiers are evaluated on empirical datasets and benchmarks,\nand that classification model performance claims should be tempered by this\nunderstanding.",
    "descriptor": "\nComments: 60 pages, 45 figures\n",
    "authors": [
      "David Lovell",
      "Dimity Miller",
      "Jaiden Capra",
      "Andrew Bradley"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.02157"
  },
  {
    "id": "arXiv:2206.02158",
    "title": "Vanilla Feature Distillation for Improving the Accuracy-Robustness  Trade-Off in Adversarial Training",
    "abstract": "Adversarial training has been widely explored for mitigating attacks against\ndeep models. However, most existing works are still trapped in the dilemma\nbetween higher accuracy and stronger robustness since they tend to fit a model\ntowards robust features (not easily tampered with by adversaries) while\nignoring those non-robust but highly predictive features. To achieve a better\nrobustness-accuracy trade-off, we propose the Vanilla Feature Distillation\nAdversarial Training (VFD-Adv), which conducts knowledge distillation from a\npre-trained model (optimized towards high accuracy) to guide adversarial\ntraining towards higher accuracy, i.e., preserving those non-robust but\npredictive features. More specifically, both adversarial examples and their\nclean counterparts are forced to be aligned in the feature space by distilling\npredictive representations from the pre-trained/clean model, while previous\nworks barely utilize predictive features from clean models. Therefore, the\nadversarial training model is updated towards maximally preserving the accuracy\nas gaining robustness. A key advantage of our method is that it can be\nuniversally adapted to and boost existing works. Exhaustive experiments on\nvarious datasets, classification models, and adversarial training algorithms\ndemonstrate the effectiveness of our proposed method.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Guodong Cao",
      "Zhibo Wang",
      "Xiaowei Dong",
      "Zhifei Zhang",
      "Hengchang Guo",
      "Zhan Qin",
      "Kui Ren"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02158"
  },
  {
    "id": "arXiv:2206.02160",
    "title": "Sentiment Analysis of Online Travel Reviews Based on Capsule Network and  Sentiment Lexicon",
    "abstract": "With the development of online travel services, it has great application\nprospects to timely mine users' evaluation emotions for travel services and use\nthem as indicators to guide the improvement of online travel service quality.\nIn this paper, we study the text sentiment classification of online travel\nreviews based on social media online comments and propose the SCCL model based\non capsule network and sentiment lexicon. SCCL model aims at the lack of\nconsideration of local features and emotional semantic features of the text in\nthe language model that can efficiently extract text context features like BERT\nand GRU. Then make the following improvements to their shortcomings. On the one\nhand, based on BERT-BiGRU, the capsule network is introduced to extract local\nfeatures while retaining good context features. On the other hand, the\nsentiment lexicon is introduced to extract the emotional sequence of the text\nto provide richer emotional semantic features for the model. To enhance the\nuniversality of the sentiment lexicon, the improved SO-PMI algorithm based on\nTF-IDF is used to expand the lexicon, so that the lexicon can also perform well\nin the field of online travel reviews.",
    "descriptor": "",
    "authors": [
      "Jia Wang",
      "Junping Du",
      "Yingxia Shao",
      "Ang Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02160"
  },
  {
    "id": "arXiv:2206.02163",
    "title": "MotionCNN: A Strong Baseline for Motion Prediction in Autonomous Driving",
    "abstract": "To plan a safe and efficient route, an autonomous vehicle should anticipate\nfuture motions of other agents around it. Motion prediction is an extremely\nchallenging task that recently gained significant attention within the research\ncommunity. In this work, we present a simple and yet very strong baseline for\nmultimodal motion prediction based purely on Convolutional Neural Networks.\nWhile being easy-to-implement, the proposed approach achieves competitive\nperformance compared to the state-of-the-art methods and ranks 3rd on the 2021\nWaymo Open Dataset Motion Prediction Challenge. Our source code is publicly\navailable at GitHub",
    "descriptor": "\nComments: CVPR Workshop on Autonomous Driving 2021. Waymo Motion Prediction Challenge 2021\n",
    "authors": [
      "Stepan Konev",
      "Kirill Brodt",
      "Artsiom Sanakoyeu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02163"
  },
  {
    "id": "arXiv:2206.02164",
    "title": "Estimating and Mitigating the Congestion Effect of Curbside Pick-ups and  Drop-offs: A Causal Inference Approach",
    "abstract": "Curb space is one of the busiest areas in urban road networks. Especially in\nrecent years, the rapid increase of ride-hailing trips and commercial\ndeliveries has induced massive pick-ups/drop-offs (PUDOs), which occupy the\nlimited curb space that was designed and built decades ago. These PUDOs could\njam curb utilization and disturb the mainline traffic flow, evidently leading\nto significant societal externalities. However, there is a lack of an\nanalytical framework that rigorously quantifies and mitigates the congestion\neffect of PUDOs in the system view, particularly with little data support and\ninvolvement of confounding effects. In view of this, this paper develops a\nrigorous causal inference approach to estimate the congestion effect of PUDOs\non general networks. A causal graph is set to represent the spatio-temporal\nrelationship between PUDOs and traffic speed, and a double and separated\nmachine learning (DSML) method is proposed to quantify how PUDOs affect traffic\ncongestion. Additionally, a re-routing formulation is developed and solved to\nencourage passenger walking and traffic flow re-routing to achieve system\noptimal. Numerical experiments are conducted using real-world data in the\nManhattan area. On average, 100 additional units of PUDOs in a region could\nreduce the traffic speed by 3.70 and 4.54 mph on weekdays and weekends,\nrespectively. Re-routing trips with PUDOs on curbs could respectively reduce\nthe system-wide total travel time by 2.44\\% and 2.12\\% in Midtown and Central\nPark on weekdays. Sensitivity analysis is also conducted to demonstrate the\neffectiveness and robustness of the proposed framework.",
    "descriptor": "",
    "authors": [
      "Xiaohui Liu",
      "Sean Qian",
      "Wei Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2206.02164"
  },
  {
    "id": "arXiv:2206.02165",
    "title": "A Survey on Deep Learning based Channel Estimation in Doubly Dispersive  Environments",
    "abstract": "Wireless communications systems are impacted by multi-path fading and Doppler\nshift in dynamic environments, where the channel becomes doubly-dispersive and\nits estimation becomes an arduous task. Only a few pilots are used for channel\nestimation in conventional approaches to preserve high data rate transmission.\nConsequently, such estimators experience a significant performance degradation\nin high mobility scenarios. Recently, deep learning has been employed for\ndoubly-dispersive channel estimation due to its low-complexity, robustness, and\ngood generalization ability. Against this backdrop, the current paper presents\na comprehensive survey on channel estimation techniques based on deep learning\nby deeply investigating different methods. The study also provides extensive\nexperimental simulations followed by a computational complexity analysis. After\nconsidering different parameters such as modulation order, mobility, frame\nlength, and deep learning architecture, the performance of the studied\nestimators is evaluated in several mobility scenarios. In addition, the source\ncodes are made available online in order to make the results reproducible.",
    "descriptor": "\nComments: Submitted to IEEE Access\n",
    "authors": [
      "Abdul Karim Gizzini",
      "Marwa Chafii"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.02165"
  },
  {
    "id": "arXiv:2206.02169",
    "title": "Formally Verified Solution Methods for Infinite-Horizon Markov Decision  Processes",
    "abstract": "We formally verify executable algorithms for solving Markov decision\nprocesses (MDPs) in the interactive theorem prover Isabelle/HOL. We build on\nexisting formalizations of probability theory to analyze the expected total\nreward criterion on infinite-horizon problems. Our developments formalize the\nBellman equation and give conditions under which optimal policies exist. Based\non this analysis, we verify dynamic programming algorithms to solve tabular\nMDPs. We evaluate the formally verified implementations experimentally on\nstandard problems and show they are practical. Furthermore, we show that,\ncombined with efficient unverified implementations, our system can compete with\nand even outperform state-of-the-art systems.",
    "descriptor": "",
    "authors": [
      "Maximilian Sch\u00e4feller",
      "Mohammad Abdulaziz"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.02169"
  },
  {
    "id": "arXiv:2206.02171",
    "title": "Near-Term Advances in Quantum Natural Language Processing",
    "abstract": "This paper describes experiments showing that some problems in natural\nlanguage processing can already be addressed using quantum computers. The\nexamples presented here include topic classification using both a quantum\nsupport vector machine and a bag-of-words approach, bigram modeling that can be\napplied to sequences of words and formal concepts, and ambiguity resolution in\nverb-noun composition.\nWhile the datasets used are still small, the systems described have been run\non physical quantum computers. These implementations and their results are\ndescribed along with the algorithms and mathematical approaches used.",
    "descriptor": "",
    "authors": [
      "Dominic Widdows",
      "Daiwei Zhu",
      "Chase Zimmerman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.02171"
  },
  {
    "id": "arXiv:2206.02178",
    "title": "Factored Conditional Filtering: Tracking States and Estimating  Parameters in High-Dimensional Spaces",
    "abstract": "This paper introduces the factored conditional filter, a new filtering\nalgorithm for simultaneously tracking states and estimating parameters in\nhigh-dimensional state spaces. The conditional nature of the algorithm is used\nto estimate parameters and the factored nature is used to decompose the state\nspace into low-dimensional subspaces in such a way that filtering on these\nsubspaces gives distributions whose product is a good approximation to the\ndistribution on the entire state space. The conditions for successful\napplication of the algorithm are that observations be available at the subspace\nlevel and that the transition model can be factored into local transition\nmodels that are approximately confined to the subspaces; these conditions are\nwidely satisfied in computer science, engineering, and geophysical filtering\napplications. We give experimental results on tracking epidemics and estimating\nparameters in large contact networks that show the effectiveness of our\napproach.",
    "descriptor": "\nComments: 85 pages with appendix\n",
    "authors": [
      "Dawei Chen",
      "Samuel Yang-Zhao",
      "John Lloyd",
      "Kee Siong Ng"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02178"
  },
  {
    "id": "arXiv:2206.02179",
    "title": "A Simple Meta-learning Paradigm for Zero-shot Intent Classification with  Mixture Attention Mechanism",
    "abstract": "Zero-shot intent classification is a vital and challenging task in dialogue\nsystems, which aims to deal with numerous fast-emerging unacquainted intents\nwithout annotated training data. To obtain more satisfactory performance, the\ncrucial points lie in two aspects: extracting better utterance features and\nstrengthening the model generalization ability. In this paper, we propose a\nsimple yet effective meta-learning paradigm for zero-shot intent\nclassification. To learn better semantic representations for utterances, we\nintroduce a new mixture attention mechanism, which encodes the pertinent word\noccurrence patterns by leveraging the distributional signature attention and\nmulti-layer perceptron attention simultaneously. To strengthen the transfer\nability of the model from seen classes to unseen classes, we reformulate\nzero-shot intent classification with a meta-learning strategy, which trains the\nmodel by simulating multiple zero-shot classification tasks on seen categories,\nand promotes the model generalization ability with a meta-adapting procedure on\nmimic unseen categories. Extensive experiments on two real-world dialogue\ndatasets in different languages show that our model outperforms other strong\nbaselines on both standard and generalized zero-shot intent classification\ntasks.",
    "descriptor": "\nComments: Accepted to SIGIR 2022\n",
    "authors": [
      "Han Liu",
      "Siyang Zhao",
      "Xiaotong Zhang",
      "Feng Zhang",
      "Junjie Sun",
      "Hong Yu",
      "Xianchao Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.02179"
  },
  {
    "id": "arXiv:2206.02180",
    "title": "Semi-Supervised Learning for Mars Imagery Classification and  Segmentation",
    "abstract": "With the progress of Mars exploration, numerous Mars image data are collected\nand need to be analyzed. However, due to the imbalance and distortion of\nMartian data, the performance of existing computer vision models is\nunsatisfactory. In this paper, we introduce a semi-supervised framework for\nmachine vision on Mars and try to resolve two specific tasks: classification\nand segmentation. Contrastive learning is a powerful representation learning\ntechnique. However, there is too much information overlap between Martian data\nsamples, leading to a contradiction between contrastive learning and Martian\ndata. Our key idea is to reconcile this contradiction with the help of\nannotations and further take advantage of unlabeled data to improve\nperformance. For classification, we propose to ignore inner-class pairs on\nlabeled data as well as neglect negative pairs on unlabeled data, forming\nsupervised inter-class contrastive learning and unsupervised similarity\nlearning. For segmentation, we extend supervised inter-class contrastive\nlearning into an element-wise mode and use online pseudo labels for supervision\non unlabeled areas. Experimental results show that our learning strategies can\nimprove the classification and segmentation models by a large margin and\noutperform state-of-the-art approaches.",
    "descriptor": "",
    "authors": [
      "Wenjing Wang",
      "Lilang Lin",
      "Zejia Fan",
      "Jiaying Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02180"
  },
  {
    "id": "arXiv:2206.02181",
    "title": "Optimizing Sensing Matrices for Spherical Near-Field Antenna  Measurements",
    "abstract": "In this article, we address the problem of reducing the number of required\nsamples for Spherical Near-Field Antenna Measurements (SNF) by using Compressed\nSensing (CS). A condition to ensure the numerical performance of sparse\nrecovery algorithms is the design of a sensing matrix with low mutual\ncoherence. Without fixing any part of the sampling pattern, we propose sampling\npoints that minimize the mutual coherence of the respective sensing matrix by\nusing augmented Lagrangian method. Numerical experiments show that the proposed\nsampling scheme yields a higher recovery success in terms of phase transition\ndiagram when compared to other known sampling patterns, such as the spiral and\nHammersley sampling schemes. Furthermore, we also demonstrate that the\napplication of CS with an optimized sensing matrix requires fewer samples than\nclassical approaches to reconstruct the Spherical Mode Coefficients (SMCs) and\nfar-field pattern.",
    "descriptor": "",
    "authors": [
      "Arya Bangun",
      "Cosme Culotta-L\u00f3pez"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.02181"
  },
  {
    "id": "arXiv:2206.02183",
    "title": "Functional Ensemble Distillation",
    "abstract": "Bayesian models have many desirable properties, most notable is their ability\nto generalize from limited data and to properly estimate the uncertainty in\ntheir predictions. However, these benefits come at a steep computational cost\nas Bayesian inference, in most cases, is computationally intractable. One\npopular approach to alleviate this problem is using a Monte-Carlo estimation\nwith an ensemble of models sampled from the posterior. However, this approach\nstill comes at a significant computational cost, as one needs to store and run\nmultiple models at test time. In this work, we investigate how to best distill\nan ensemble's predictions using an efficient model. First, we argue that\ncurrent approaches that simply return distribution over predictions cannot\ncompute important properties, such as the covariance between predictions, which\ncan be valuable for further processing. Second, in many limited data settings,\nall ensemble members achieve nearly zero training loss, namely, they produce\nnear-identical predictions on the training set which results in sub-optimal\ndistilled models. To address both problems, we propose a novel and general\ndistillation approach, named Functional Ensemble Distillation (FED), and we\ninvestigate how to best distill an ensemble in this setting. We find that\nlearning the distilled model via a simple augmentation scheme in the form of\nmixup augmentation significantly boosts the performance. We evaluated our\nmethod on several tasks and showed that it achieves superior results in both\naccuracy and uncertainty estimation compared to current approaches.",
    "descriptor": "",
    "authors": [
      "Coby Penso",
      "Idan Achituve",
      "Ethan Fetaya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.02183"
  },
  {
    "id": "arXiv:2206.02185",
    "title": "Packing, Hitting and Coloring Squares",
    "abstract": "Given a family of squares in the plane, their $packing \\ problem$ asks for\nthe maximum number, $\\nu$, of pairwise disjoint squares among them, while their\n$hitting \\ problem$ asks for the minimum number, $\\tau$, of points hitting all\nof them, $\\tau \\ge \\nu$. Both problems are NP-hard even if all the rectangles\nare unit squares and their sides are parallel to the axes.\nThe main results of this work are providing the first bounds for the $\\tau /\n\\nu$ ratio on not necessarily axis-parallel squares. We establish an upper\nbound of $6$ for unit squares and $10$ for squares of varying sizes. The worst\nratios we can provide with examples are $3$ and $4$, respectively. For\ncomparison, in the axis-parallel case, the supremum of the considered ratio is\nin the interval $[\\frac{3}{2},2]$ for unit squares and $[\\frac{3}{2},4]$ for\narbitrary squares. The new bounds necessitate a mixture of novel and classical\ntechniques of possibly extendable use.\nFurthermore, we study rectangles with a bounded ``aspect ratio'', where the\n$aspect \\ ratio$ of a rectangle is the larger side of a rectangle divided by\nits smaller side. We improve on the well-known best $\\tau/\\nu$ bound, which is\nquadratic in terms of the aspect ratio. We reduce it from quadratic to linear\nfor rectangles, even if they are not axis-parallel, and from linear to\nlogarithmic, for axis-parallel rectangles.\nFinally, we prove similar bounds for the chromatic numbers of squares and\nrectangles with a bounded aspect ratio.",
    "descriptor": "\nComments: 26 pages (plus 7 pages of Appendix)\n",
    "authors": [
      "Marco Caoduro",
      "Andr\u00e1s Seb\u0151"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2206.02185"
  },
  {
    "id": "arXiv:2206.02187",
    "title": "M2FNet: Multi-modal Fusion Network for Emotion Recognition in  Conversation",
    "abstract": "Emotion Recognition in Conversations (ERC) is crucial in developing\nsympathetic human-machine interaction. In conversational videos, emotion can be\npresent in multiple modalities, i.e., audio, video, and transcript. However,\ndue to the inherent characteristics of these modalities, multi-modal ERC has\nalways been considered a challenging undertaking. Existing ERC research focuses\nmainly on using text information in a discussion, ignoring the other two\nmodalities. We anticipate that emotion recognition accuracy can be improved by\nemploying a multi-modal approach. Thus, in this study, we propose a Multi-modal\nFusion Network (M2FNet) that extracts emotion-relevant features from visual,\naudio, and text modality. It employs a multi-head attention-based fusion\nmechanism to combine emotion-rich latent representations of the input data. We\nintroduce a new feature extractor to extract latent features from the audio and\nvisual modality. The proposed feature extractor is trained with a novel\nadaptive margin-based triplet loss function to learn emotion-relevant features\nfrom the audio and visual data. In the domain of ERC, the existing methods\nperform well on one benchmark dataset but not on others. Our results show that\nthe proposed M2FNet architecture outperforms all other methods in terms of\nweighted average F1 score on well-known MELD and IEMOCAP datasets and sets a\nnew state-of-the-art performance in ERC.",
    "descriptor": "\nComments: Accepted for publication in the 5th Multimodal Learning and Applications (MULA) Workshop at CVPR 2022\n",
    "authors": [
      "Vishal Chudasama",
      "Purbayan Kar",
      "Ashish Gudmalwar",
      "Nirmesh Shah",
      "Pankaj Wasnik",
      "Naoyuki Onoe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.02187"
  },
  {
    "id": "arXiv:2206.02194",
    "title": "FOF: Learning Fourier Occupancy Field for Monocular Real-time Human  Reconstruction",
    "abstract": "The advent of deep learning has led to significant progress in monocular\nhuman reconstruction. However, existing representations, such as parametric\nmodels, voxel grids, meshes and implicit neural representations, have\ndifficulties achieving high-quality results and real-time speed at the same\ntime. In this paper, we propose Fourier Occupancy Field (FOF), a novel\npowerful, efficient and flexible 3D representation, for monocular real-time and\naccurate human reconstruction. The FOF represents a 3D object with a 2D field\northogonal to the view direction where at each 2D position the occupancy field\nof the object along the view direction is compactly represented with the first\nfew terms of Fourier series, which retains the topology and neighborhood\nrelation in the 2D domain. A FOF can be stored as a multi-channel image, which\nis compatible with 2D convolutional neural networks and can bridge the gap\nbetween 3D geometries and 2D images. The FOF is very flexible and extensible,\ne.g., parametric models can be easily integrated into a FOF as a prior to\ngenerate more robust results. Based on FOF, we design the first 30+FPS\nhigh-fidelity real-time monocular human reconstruction framework. We\ndemonstrate the potential of FOF on both public dataset and real captured data.\nThe code will be released for research purposes.",
    "descriptor": "",
    "authors": [
      "Qiao Feng",
      "Yebin Liu",
      "Yu-Kun Lai",
      "Jingyu Yang",
      "Kun Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02194"
  },
  {
    "id": "arXiv:2206.02196",
    "title": "Machine learning applications for electricity market agent-based models:  A systematic literature review",
    "abstract": "The electricity market has a vital role to play in the decarbonisation of the\nenergy system. However, the electricity market is made up of many different\nvariables and data inputs. These variables and data inputs behave in sometimes\nunpredictable ways which can not be predicted a-priori. It has therefore been\nsuggested that agent-based simulations are used to better understand the\ndynamics of the electricity market. Agent-based models provide the opportunity\nto integrate machine learning and artificial intelligence to add intelligence,\nmake better forecasts and control the power market in better and more efficient\nways. In this systematic literature review, we review 55 papers published\nbetween 2016 and 2021 which focus on machine learning applied to agent-based\nelectricity market models. We find that research clusters around popular\ntopics, such as bidding strategies. However, there exists a long-tail of\ndifferent research applications that could benefit from the high intensity\nresearch from the more investigated applications.",
    "descriptor": "",
    "authors": [
      "Alexander J. M. Kell",
      "Stephen McGough",
      "Matthew Forshaw"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02196"
  },
  {
    "id": "arXiv:2206.02198",
    "title": "A Quasi-Uniform Approach to Characterizing the Boundary of the Almost  Entropic Region",
    "abstract": "The convex closure of entropy vectors for quasi-uniform random vectors is the\nsame as the closure of the entropy region. Thus, quasi-uniform random vectors\nconstitute an important class of random vectors for characterizing the entropy\nregion. Moreover, the one-to-one correspondence between quasi-uniform codes and\nquasi-uniform random vectors makes quasi-uniform random vectors of central\nimportance for designing effective codes for communication systems. In this\npaper, we present a novel approach that utilizes quasi-uniform random vectors\nfor characterizing the boundary of the almost entropic region. In particular,\nwe use the notion of quasi-uniform random vectors to establish looseness of\nknown inner bounds for the entropy vectors at the boundary of the almost\nentropic region for three random variables. For communication models such as\nnetwork coding, our approach can be applied to design network codes from\nquasi-uniform entropy vectors.",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Satyajit Thakor",
      "Dauood Saleem"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.02198"
  },
  {
    "id": "arXiv:2206.02199",
    "title": "DarkSLAM: GAN-assisted Visual SLAM for Reliable Operation in Low-light  Conditions",
    "abstract": "Existing visual SLAM approaches are sensitive to illumination, with their\nprecision drastically falling in dark conditions due to feature extractor\nlimitations. The algorithms currently used to overcome this issue are not able\nto provide reliable results due to poor performance and noisiness, and the\nlocalization quality in dark conditions is still insufficient for practical\nuse. In this paper, we present a novel SLAM method capable of working in low\nlight using Generative Adversarial Network (GAN) preprocessing module to\nenhance the light conditions on input images, thus improving the localization\nrobustness. The proposed algorithm was evaluated on a custom indoor dataset\nconsisting of 14 sequences with varying illumination levels and ground truth\ndata collected using a motion capture system. According to the experimental\nresults, the reliability of the proposed approach remains high even in\nextremely low light conditions, providing 25.1% tracking time on darkest\nsequences, whereas existing approaches achieve tracking only 0.6% of the\nsequence time.",
    "descriptor": "\nComments: Accepted paper at IEEE Vehicular Technology Conference 2022 (IEEE VTC 2022), IEEE copyright\n",
    "authors": [
      "Alena Savinykh",
      "Mikhail Kurenkov",
      "Evgeny Kruzhkov",
      "Evgeny Yudin",
      "Andrei Potapov",
      "Pavel Karpyshev",
      "Dzmitry Tsetserukou"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.02199"
  },
  {
    "id": "arXiv:2206.02200",
    "title": "GridShift: A Faster Mode-seeking Algorithm for Image Segmentation and  Object Tracking",
    "abstract": "In machine learning and computer vision, mean shift (MS) qualifies as one of\nthe most popular mode-seeking algorithms used for clustering and image\nsegmentation. It iteratively moves each data point to the weighted mean of its\nneighborhood data points. The computational cost required to find the neighbors\nof each data point is quadratic to the number of data points. Consequently, the\nvanilla MS appears to be very slow for large-scale datasets. To address this\nissue, we propose a mode-seeking algorithm called GridShift, with significant\nspeedup and principally based on MS. To accelerate, GridShift employs a\ngrid-based approach for neighbor search, which is linear in the number of data\npoints. In addition, GridShift moves the active grid cells (grid cells\nassociated with at least one data point) in place of data points towards the\nhigher density, a step that provides more speedup. The runtime of GridShift is\nlinear in the number of active grid cells and exponential in the number of\nfeatures. Therefore, it is ideal for large-scale low-dimensional applications\nsuch as object tracking and image segmentation. Through extensive experiments,\nwe showcase the superior performance of GridShift compared to other MS-based as\nwell as state-of-the-art algorithms in terms of accuracy and runtime on\nbenchmark datasets for image segmentation. Finally, we provide a new\nobject-tracking algorithm based on GridShift and show promising results for\nobject tracking compared to CamShift and meanshift++.",
    "descriptor": "",
    "authors": [
      "Abhishek Kumar",
      "Oladayo S. Ajani",
      "Swagatam Das",
      "Rammohan Mallipeddi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02200"
  },
  {
    "id": "arXiv:2206.02203",
    "title": "3D Convolutional with Attention for Action Recognition",
    "abstract": "Human action recognition is one of the challenging tasks in computer vision.\nThe current action recognition methods use computationally expensive models for\nlearning spatio-temporal dependencies of the action. Models utilizing RGB\nchannels and optical flow separately, models using a two-stream fusion\ntechnique, and models consisting of both convolutional neural network (CNN) and\nlong-short term memory (LSTM) network are few examples of such complex models.\nMoreover, fine-tuning such complex models is computationally expensive as well.\nThis paper proposes a deep neural network architecture for learning such\ndependencies consisting of a 3D convolutional layer, fully connected (FC)\nlayers, and attention layer, which is simpler to implement and gives a\ncompetitive performance on the UCF-101 dataset. The proposed method first\nlearns spatial and temporal features of actions through 3D-CNN, and then the\nattention mechanism helps the model to locate attention to essential features\nfor recognition.",
    "descriptor": "",
    "authors": [
      "Labina Shrestha",
      "Shikha Dubey",
      "Farrukh Olimov",
      "Muhammad Aasim Rafique",
      "Moongu Jeon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02203"
  },
  {
    "id": "arXiv:2206.02206",
    "title": "Performance Comparison of Simple Transformer and Res-CNN-BiLSTM for  Cyberbullying Classification",
    "abstract": "The task of text classification using Bidirectional based LSTM architectures\nis computationally expensive and time consuming to train. For this,\ntransformers were discovered which effectively give good performance as\ncompared to the traditional deep learning architectures. In this paper we\npresent a performance based comparison between simple transformer based network\nand Res-CNN-BiLSTM based network for cyberbullying text classification problem.\nThe results obtained show that transformer we trained with 0.65 million\nparameters has significantly being able to beat the performance of\nRes-CNN-BiLSTM with 48.82 million parameters for faster training speeds and\nmore generalized metrics. The paper also compares the 1-dimensional character\nlevel embedding network and 100-dimensional glove embedding network with\ntransformer.",
    "descriptor": "\nComments: 7 Pages with 2 figures and 1 table\n",
    "authors": [
      "Raunak Joshi",
      "Abhishek Gupta"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02206"
  },
  {
    "id": "arXiv:2206.02207",
    "title": "OBAMA, an Ontology-Based Software Tool for Agile Method Adoption",
    "abstract": "Tools like Prot\\'eg\\'e support the creation and edition of one or more\nontologies in a single workspace. They nevertheless require a user to be\nfamiliar with this kind of abstractions and their supporting techniques such as\na reasoner and SPARQL queries. This paper presents a step-by-step\nimplementation of a prototype-tool that allows retrieving and displaying easily\nthe information about agile practices contained in an ontology using Python\nprogramming language. Future development includes the flexible insertion,\nmodification, and removal of knowledge by the user.",
    "descriptor": "",
    "authors": [
      "Soreangsey Kiv",
      "Yves Wautelet",
      "Samedi Heng",
      "Manuel Kolp"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.02207"
  },
  {
    "id": "arXiv:2206.02208",
    "title": "Stylistic Fingerprints, POS-tags and Inflected Languages: A Case Study  in Polish",
    "abstract": "In stylometric investigations, frequencies of the most frequent words (MFWs)\nand character n-grams outperform other style-markers, even if their performance\nvaries significantly across languages. In inflected languages, word endings\nplay a prominent role, and hence different word forms cannot be recognized\nusing generic text tokenization. Countless inflected word forms make\nfrequencies sparse, making most statistical procedures complicated. Presumably,\napplying one of the NLP techniques, such as lemmatization and/or parsing, might\nincrease the performance of classification. The aim of this paper is to examine\nthe usefulness of grammatical features (as assessed via POS-tag n-grams) and\nlemmatized forms in recognizing authorial profiles, in order to address the\nunderlying issue of the degree of freedom of choice within lexis and grammar.\nUsing a corpus of Polish novels, we performed a series of supervised authorship\nattribution benchmarks, in order to compare the classification accuracy for\ndifferent types of lexical and syntactic style-markers. Even if the performance\nof POS-tags as well as lemmatized forms was notoriously worse than that of\nlexical markers, the difference was not substantial and never exceeded ca. 15%.",
    "descriptor": "",
    "authors": [
      "Maciej Eder",
      "Rafa\u0142. L. G\u00f3rski"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.02208"
  },
  {
    "id": "arXiv:2206.02211",
    "title": "Variable-rate hierarchical CPC leads to acoustic unit discovery in  speech",
    "abstract": "The success of deep learning comes from its ability to capture the\nhierarchical structure of data by learning high-level representations defined\nin terms of low-level ones. In this paper we explore self-supervised learning\nof hierarchical representations of speech by applying multiple levels of\nContrastive Predictive Coding (CPC). We observe that simply stacking two CPC\nmodels does not yield significant improvements over single-level architectures.\nInspired by the fact that speech is often described as a sequence of discrete\nunits unevenly distributed in time, we propose a model in which the output of a\nlow-level CPC module is non-uniformly downsampled to directly minimize the loss\nof a high-level CPC module. The latter is designed to also enforce a prior of\nseparability and discreteness in its representations by enforcing dissimilarity\nof successive high-level representations through focused negative sampling, and\nby quantization of the prediction targets. Accounting for the structure of the\nspeech signal improves upon single-level CPC features and enhances the\ndisentanglement of the learned representations, as measured by downstream\nspeech recognition tasks, while resulting in a meaningful segmentation of the\nsignal that closely resembles phone boundaries.",
    "descriptor": "\nComments: Submitted to 36th Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Santiago Cuervo",
      "Adrian \u0141a\u0144cucki",
      "Ricard Marxer",
      "Pawe\u0142 Rychlikowski",
      "Jan Chorowski"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.02211"
  },
  {
    "id": "arXiv:2206.02216",
    "title": "Sequential Counterfactual Decision-Making Under Confounded Reward",
    "abstract": "We investigate the limitations of random trials when the cause of interest is\nconfounded with the effect by formalizing a counterfactual policy-space where\nthe agent's natural predilection is input to a soft-intervention.",
    "descriptor": "",
    "authors": [
      "Erik Skalnes"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02216"
  },
  {
    "id": "arXiv:2206.02217",
    "title": "Learning a Mesh Motion Technique with Application to Fluid-Structure  Interaction and Shape Optimization",
    "abstract": "Mesh degeneration is a bottleneck for fluid-structure interaction (FSI)\nsimulations and for shape optimization via the method of mappings. In both\ncases, an appropriate mesh motion technique is required. The choice is\ntypically based on heuristics, e.g., the solution operators of partial\ndifferential equations (PDE), such as the Laplace or biharmonic equation.\nEspecially the latter, which shows good numerical performance for large\ndisplacements, is expensive. Moreover, from a continuous perspective, choosing\nthe mesh motion technique is to a certain extent arbitrary and has no influence\non the physically relevant quantities. Therefore, we consider approaches\ninspired by machine learning. We present a hybrid PDE-NN approach, where the\nneural network (NN) serves as parameterization of a coefficient in a second\norder nonlinear PDE. We ensure existence of solutions for the nonlinear PDE by\nthe choice of the neural network architecture. Moreover, we propose a splitting\nof the monolithic FSI system into three smaller subsystems, in order to\nsegregate the mesh motion. We assess the quality of the learned mesh motion\ntechnique by applying it to a FSI benchmark problem.",
    "descriptor": "",
    "authors": [
      "Johannes Haubner",
      "Miroslav Kuchta"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.02217"
  },
  {
    "id": "arXiv:2206.02220",
    "title": "U(1) Symmetry-breaking Observed in Generic CNN Bottleneck Layers",
    "abstract": "We report on a significant discovery linking deep convolutional neural\nnetworks (CNN) to biological vision and fundamental particle physics. A model\nof information propagation in a CNN is proposed via an analogy to an optical\nsystem, where bosonic particles (i.e. photons) are concentrated as the 2D\nspatial resolution of the image collapses to a focal point $1\\times 1=1$. A 3D\nspace $(x,y,t)$ is defined by $(x,y)$ coordinates in the image plane and CNN\nlayer $t$, where a principal ray $(0,0,t)$ runs in the direction of information\npropagation through both the optical axis and the image center pixel located at\n$(x,y)=(0,0)$, about which the sharpest possible spatial focus is limited to a\ncircle of confusion in the image plane. Our novel insight is to model the\nprincipal optical ray $(0,0,t)$ as geometrically equivalent to the medial\nvector in the positive orthant $I(x,y) \\in R^{N+}$ of a $N$-channel activation\nspace, e.g. along the greyscale (or luminance) vector $(t,t,t)$ in $RGB$ colour\nspace. Information is thus concentrated into an energy potential\n$E(x,y,t)=\\|I(x,y,t)\\|^2$, which, particularly for bottleneck layers $t$ of\ngeneric CNNs, is highly concentrated and symmetric about the spatial origin\n$(0,0,t)$ and exhibits the well-known \"Sombrero\" potential of the boson\nparticle. This symmetry is broken in classification, where bottleneck layers of\ngeneric pre-trained CNN models exhibit a consistent class-specific bias towards\nan angle $\\theta \\in U(1)$ defined simultaneously in the image plane and in\nactivation feature space. Initial observations validate our hypothesis from\ngeneric pre-trained CNN activation maps and a bare-bones memory-based\nclassification scheme, with no training or tuning. Training from scratch using\na random $U(1)$ class label the leads to improved classification in all cases.",
    "descriptor": "",
    "authors": [
      "Louis-Fran\u00e7ois Bouchard",
      "Mohsen Ben Lazreg",
      "Matthew Toews"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02220"
  },
  {
    "id": "arXiv:2206.02230",
    "title": "Finetuning a Kalaallisut-English machine translation system using  web-crawled data",
    "abstract": "West Greenlandic, known by native speakers as Kalaallisut, is an extremely\nlow-resource polysynthetic language spoken by around 56,000 people in\nGreenland. Here, we attempt to finetune a pretrained Kalaallisut-to-English\nneural machine translation (NMT) system using web-crawled pseudoparallel\nsentences from around 30 multilingual websites. We compile a corpus of over\n93,000 Kalaallisut sentences and over 140,000 Danish sentences, then use\ncross-lingual sentence embeddings and approximate nearest-neighbors search in\nan attempt to mine near-translations from these corpora. Finally, we translate\nthe Danish sentence to English to obtain a synthetic Kalaallisut-English\naligned corpus. Although the resulting dataset is too small and noisy to\nimprove the pretrained MT model, we believe that with additional resources, we\ncould construct a better pseudoparallel corpus and achieve more promising\nresults on MT. We also note other possible uses of the monolingual Kalaallisut\ndata and discuss directions for future work. We make the code and data for our\nexperiments publicly available.",
    "descriptor": "",
    "authors": [
      "Alex Jones"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02230"
  },
  {
    "id": "arXiv:2206.02231",
    "title": "Models of human preference for learning reward functions",
    "abstract": "The utility of reinforcement learning is limited by the alignment of reward\nfunctions with the interests of human stakeholders. One promising method for\nalignment is to learn the reward function from human-generated preferences\nbetween pairs of trajectory segments. These human preferences are typically\nassumed to be informed solely by partial return, the sum of rewards along each\nsegment. We find this assumption to be flawed and propose modeling preferences\ninstead as arising from a different statistic: each segment's regret, a measure\nof a segment's deviation from optimal decision-making. Given infinitely many\npreferences generated according to regret, we prove that we can identify a\nreward function equivalent to the reward function that generated those\npreferences. We also prove that the previous partial return model lacks this\nidentifiability property without preference noise that reveals rewards'\nrelative proportions, and we empirically show that our proposed regret\npreference model outperforms it with finite training data in otherwise the same\nsetting. Additionally, our proposed regret preference model better predicts\nreal human preferences and also learns reward functions from these preferences\nthat lead to policies that are better human-aligned. Overall, this work\nestablishes that the choice of preference model is impactful, and our proposed\nregret preference model provides an improvement upon a core assumption of\nrecent research.",
    "descriptor": "\nComments: 9 pages (24 pages with references and appendix), 13 figures\n",
    "authors": [
      "W. Bradley Knox",
      "Stephane Hatgis-Kessell",
      "Serena Booth",
      "Scott Niekum",
      "Peter Stone",
      "Alessandro Allievi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.02231"
  },
  {
    "id": "arXiv:2206.02234",
    "title": "Two Decades of Bengali Handwritten Digit Recognition: A Survey",
    "abstract": "Handwritten Digit Recognition (HDR) is one of the most challenging tasks in\nthe domain of Optical Character Recognition (OCR). Irrespective of language,\nthere are some inherent challenges of HDR, which mostly arise due to the\nvariations in writing styles across individuals, writing medium and\nenvironment, inability to maintain the same strokes while writing any digit\nrepeatedly, etc. In addition to that, the structural complexities of the digits\nof a particular language may lead to ambiguous scenarios of HDR. Over the\nyears, researchers have developed numerous offline and online HDR pipelines,\nwhere different image processing techniques are combined with traditional\nMachine Learning (ML)-based and/or Deep Learning (DL)-based architectures.\nAlthough evidence of extensive review studies on HDR exists in the literature\nfor languages, such as: English, Arabic, Indian, Farsi, Chinese, etc., few\nsurveys on Bengali HDR (BHDR) can be found, which lack a comprehensive analysis\nof the challenges, the underlying recognition process, and possible future\ndirections. In this paper, the characteristics and inherent ambiguities of\nBengali handwritten digits along with a comprehensive insight of two decades of\nthe state-of-the-art datasets and approaches towards offline BHDR have been\nanalyzed. Furthermore, several real-life application-specific studies, which\ninvolve BHDR, have also been discussed in detail. This paper will also serve as\na compendium for researchers interested in the science behind offline BHDR,\ninstigating the exploration of newer avenues of relevant research that may\nfurther lead to better offline recognition of Bengali handwritten digits in\ndifferent application areas.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. 35 pages, 20 figures, 12 tables\n",
    "authors": [
      "A.B.M. Ashikur Rahman",
      "Md. Bakhtiar Hasan",
      "Sabbir Ahmed",
      "Tasnim Ahmed",
      "Md. Hamjajul Ashmafee",
      "Mohammad Ridwan Kabir",
      "Md. Hasanul Kabir"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02234"
  },
  {
    "id": "arXiv:2206.02237",
    "title": "Enforcing Group Fairness in Algorithmic Decision Making: Utility  Maximization Under Sufficiency",
    "abstract": "Binary decision making classifiers are not fair by default. Fairness\nrequirements are an additional element to the decision making rationale, which\nis typically driven by maximizing some utility function. In that sense,\nalgorithmic fairness can be formulated as a constrained optimization problem.\nThis paper contributes to the discussion on how to implement fairness, focusing\non the fairness concepts of positive predictive value (PPV) parity, false\nomission rate (FOR) parity, and sufficiency (which combines the former two). We\nshow that group-specific threshold rules are optimal for PPV parity and FOR\nparity, similar to well-known results for other group fairness criteria.\nHowever, depending on the underlying population distributions and the utility\nfunction, we find that sometimes an upper-bound threshold rule for one group is\noptimal: utility maximization under PPV parity (or FOR parity) might thus lead\nto selecting the individuals with the smallest utility for one group, instead\nof selecting the most promising individuals. This result is counter-intuitive\nand in contrast to the analogous solutions for statistical parity and equality\nof opportunity. We also provide a solution for the optimal decision rules\nsatisfying the fairness constraint sufficiency. We show that more complex\ndecision rules are required and that this leads to within-group unfairness for\nall but one of the groups. We illustrate our findings based on simulated and\nreal data.",
    "descriptor": "\nComments: 14 pages, accepted to ACM FAccT 2022, code available on GitHub: this https URL\n",
    "authors": [
      "Joachim Baumann",
      "Anik\u00f3 Hann\u00e1k",
      "Christoph Heitz"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02237"
  },
  {
    "id": "arXiv:2206.02238",
    "title": "OntoMerger: An Ontology Integration Library for Deduplicating and  Connecting Knowledge Graph Nodes",
    "abstract": "Duplication of nodes is a common problem encountered when building knowledge\ngraphs (KGs) from heterogeneous datasets, where it is crucial to be able to\nmerge nodes having the same meaning. OntoMerger is a Python ontology\nintegration library whose functionality is to deduplicate KG nodes. Our\napproach takes a set of KG nodes, mappings and disconnected hierarchies and\ngenerates a set of merged nodes together with a connected hierarchy. In\naddition, the library provides analytic and data testing functionalities that\ncan be used to fine-tune the inputs, further reducing duplication, and to\nincrease connectivity of the output graph. OntoMerger can be applied to a wide\nvariety of ontologies and KGs. In this paper we introduce OntoMerger and\nillustrate its functionality on a real-world biomedical KG.",
    "descriptor": "\nComments: Code available under: this https URL\n",
    "authors": [
      "David Geleta",
      "Andriy Nikolov",
      "Mark ODonoghue",
      "Benedek Rozemberczki",
      "Anna Gogleva",
      "Valentina Tamma",
      "Terry R. Payne"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2206.02238"
  },
  {
    "id": "arXiv:2206.02239",
    "title": "Winner does not take all: contrasting centrality in adversarial networks",
    "abstract": "In adversarial networks, edges correspond to negative interactions such as\ncompetition or dominance. We introduce a new type of node called a low-key\nleader in adversarial networks, distinguished by contrasting the centrality\nmeasures of CON score and PageRank. We present a novel hypothesis that low-key\nleaders are ubiquitous in adversarial networks and provide evidence by\nconsidering data from real-world networks, including dominance networks in 172\nanimal populations, trading networks between G20 nations, and Bitcoin trust\nnetworks. We introduce a random graph model that generates directed graphs with\nlow-key leaders.",
    "descriptor": "",
    "authors": [
      "Anthony Bonato",
      "Joey Kapusin",
      "Jiajie Yuan"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.02239"
  },
  {
    "id": "arXiv:2206.02241",
    "title": "Conceptual Design of the Memory System of the Robot Cognitive  Architecture ArmarX",
    "abstract": "We consider the memory system as a key component of any technical cognitive\nsystem that can play a central role in bridging the gap between high-level\nsymbolic discrete representations used for reasoning, planning and semantic\nscene understanding and low-level sensorimotor continuous representations used\nfor control. In this work we described conceptual and technical characteristics\nsuch a memory system has to fulfill, together with the underlying data\nrepresentation. We identify these characteristics based on the experience we\ngained in developing our ARMAR humanoid robot systems and discuss practical\nexamples that demonstrate what a memory system of a humanoid robot performing\ntasks in human-centered environments should support, such as multi-modality,\nintrospectability, hetero associativity, predictability or an inherently\nepisodic structure. Based on these characteristics, we extended our robot\nsoftware framework ArmarX into a unified cognitive architecture that is used in\nrobots of the ARMAR humanoid robot family. Further, we describe, how the\ndevelopment of robot software led us to this novel memory-enabled cognitive\narchitecture and we show how the memory is used by the robots to implement\nmemory-driven behaviors.",
    "descriptor": "",
    "authors": [
      "Fabian Peller-Konrad",
      "Rainer-Kartmann",
      "Christian R. G. Dreher",
      "Andre Meixner",
      "Fabian Reister",
      "Markus Grotz",
      "Tamim Asfour"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.02241"
  },
  {
    "id": "arXiv:2206.02243",
    "title": "Resource Optimization for Blockchain-based Federated Learning in Mobile  Edge Computing",
    "abstract": "With the development of mobile edge computing (MEC) and blockchain-based\nfederated learning (BCFL), a number of studies suggest deploying BCFL on edge\nservers. In this case, resource-limited edge servers need to serve both mobile\ndevices for their offloading tasks and the BCFL system for model training and\nblockchain consensus in a cost-efficient manner without sacrificing the service\nquality to any side. To address this challenge, this paper proposes a resource\nallocation scheme for edge servers, aiming to provide the optimal services with\nthe minimum cost. Specifically, we first analyze the energy consumed by the MEC\nand BCFL tasks, and then use the completion time of each task as the service\nquality constraint. Then, we model the resource allocation challenge into a\nmultivariate, multi-constraint, and convex optimization problem. To solve the\nproblem in a progressive manner, we design two algorithms based on the\nalternating direction method of multipliers (ADMM) in both the homogeneous and\nheterogeneous situations with equal and on-demand resource distribution\nstrategies, respectively. The validity of our proposed algorithms is proved via\nrigorous theoretical analysis. Through extensive experiments, the convergence\nand efficiency of our proposed resource allocation schemes are evaluated. To\nthe best of our knowledge, this is the first work to investigate the resource\nallocation dilemma of edge servers for BCFL in MEC.",
    "descriptor": "",
    "authors": [
      "Zhilin Wang",
      "Qin Hu",
      "Zehui Xiong"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.02243"
  },
  {
    "id": "arXiv:2206.02244",
    "title": "Conditions for Oscillator Small-Signal Amplitude-Phase Orthogonality",
    "abstract": "The paper explores a previously unknown connection relating the symmetry\nproperties of an oscillator steady-state to the orthogonal representation of\namplitude and phase variables in the small-signal regime. It is shown that only\ncircuits producing perfectly symmetric steady-states can produce an orthogonal\nFloquet decomposition. Considering room temperature operation this scenario\nimplies zero AM-PM noise conversion. This surprising and novel result follows\ndirectly from the predictions of a rigorous model framework first described\nherein. The work presented in this text extend the current state-of-the-art\nw.r.t. oscillator small-signal/noise characterization.",
    "descriptor": "\nComments: 18 pages, 10 figures\n",
    "authors": [
      "Torsten Djurhuus",
      "Viktor Krozer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Classical Analysis and ODEs (math.CA)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.02244"
  },
  {
    "id": "arXiv:2206.02245",
    "title": "ACHORD: Communication-Aware Multi-Robot Coordination with Intermittent  Connectivity",
    "abstract": "Communication is an important capability for multi-robot exploration because\n(1) inter-robot communication (comms) improves coverage efficiency and (2)\nrobot-to-base comms improves situational awareness. Exploring comms-restricted\n(e.g., subterranean) environments requires a multi-robot system to tolerate and\nanticipate intermittent connectivity, and to carefully consider comms\nrequirements, otherwise mission-critical data may be lost. In this paper, we\ndescribe and analyze ACHORD (Autonomous & Collaborative High-Bandwidth\nOperations with Radio Droppables), a multi-layer networking solution which\ntightly co-designs the network architecture and high-level decision-making for\nimproved comms. ACHORD provides bandwidth prioritization and timely and\nreliable data transfer despite intermittent connectivity. Furthermore, it\nexposes low-layer networking metrics to the application layer to enable robots\nto autonomously monitor, map, and extend the network via droppable radios, as\nwell as restore connectivity to improve collaborative exploration. We evaluate\nour solution with respect to the comms performance in several challenging\nunderground environments including the DARPA SubT Finals competition\nenvironment. Our findings support the use of data stratification and flow\ncontrol to improve bandwidth-usage.",
    "descriptor": "\nComments: 8 pages, 8 figures\n",
    "authors": [
      "Maira Saboia",
      "Lillian Clark",
      "Vivek Thangavelu",
      "Jeffrey A. Edlund",
      "Kyohei Otsu",
      "Gustavo J. Correa",
      "Vivek Shankar Varadharajan",
      "Angel Santamaria-Navarro",
      "Thomas Touma",
      "Amanda Bouman",
      "Hovhannes Melikyan",
      "Torkom Pailevanian",
      "Sung-Kyun Kim",
      "Avak Archanian",
      "Tiago Stegun Vaquero",
      "Giovanni Beltrame",
      "Nils Napp",
      "Gustavo Pessin",
      "Ali-akbar Agha-mohammadi"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.02245"
  },
  {
    "id": "arXiv:2206.02246",
    "title": "Zero-Shot Voice Conditioning for Denoising Diffusion TTS Models",
    "abstract": "We present a novel way of conditioning a pretrained denoising diffusion\nspeech model to produce speech in the voice of a novel person unseen during\ntraining. The method requires a short (~3 seconds) sample from the target\nperson, and generation is steered at inference time, without any training\nsteps. At the heart of the method lies a sampling process that combines the\nestimation of the denoising model with a low-pass version of the new speaker's\nsample. The objective and subjective evaluations show that our sampling method\ncan generate a voice similar to that of the target speaker in terms of\nfrequency, with an accuracy comparable to state-of-the-art methods, and without\ntraining.",
    "descriptor": "",
    "authors": [
      "Alon Levkovitch",
      "Eliya Nachmani",
      "Lior Wolf"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.02246"
  },
  {
    "id": "arXiv:2206.02248",
    "title": "LNGate$^2$: Secure Bidirectional IoT Micro-payments using Bitcoin's  Lightning Network and Threshold Cryptography",
    "abstract": "Bitcoin has emerged as a revolutionary payment system with its decentralized\nledger concept; however it has significant problems such as high transaction\nfees and low throughput. Lightning Network (LN), which was introduced much\nlater, solves most of these problems with an innovative concept called\noff-chain payments. With this advancement, Bitcoin has become an attractive\nvenue to perform micro-payments which can also be adopted in many IoT\napplications (e.g., toll payments). Nevertheless, it is not feasible to host LN\nand Bitcoin on IoT devices due to the storage, memory, and processing\nrestrictions. Therefore, in this paper, we propose a secure and efficient\nprotocol that enables an IoT device to use LN's functions through an untrusted\ngateway node. Through this gateway which hosts the LN and Bitcoin nodes, the\nIoT device can open & close LN channels and send & receive LN payments. This\ndelegation approach is powered by a threshold cryptography based scheme that\nrequires the IoT device and the LN gateway to jointly perform all LN\noperations. Specifically, we propose thresholdizing LN's Bitcoin public and\nprivate keys as well as its public and private keys for the new channel states\n(i.e., commitment points). We prove with a game theoretical security analysis\nthat the IoT device is secure against collusion and stealing attacks. We\nimplemented the proposed protocol by changing LN's source code and thoroughly\nevaluated its performance using a Raspberry Pi. Our evaluation results show\nthat the protocol is fast, does not bring extra cost overhead and can be run on\nlow data-rate wireless networks. To the best of our knowledge, this is the\nfirst work that implemented threshold cryptography in LN.",
    "descriptor": "\nComments: Journal extension of this https URL arXiv admin note: substantial text overlap with arXiv:2105.08902\n",
    "authors": [
      "Ahmet Kurt",
      "Kemal Akkaya",
      "Sabri Yilmaz",
      "Suat Mercan",
      "Omer Shlomovits",
      "Enes Erdin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.02248"
  },
  {
    "id": "arXiv:2206.02252",
    "title": "Exploring Cross-lingual Textual Style Transfer with Large Multilingual  Language Models",
    "abstract": "Detoxification is a task of generating text in polite style while preserving\nmeaning and fluency of the original toxic text. Existing detoxification methods\nare designed to work in one exact language. This work investigates multilingual\nand cross-lingual detoxification and the behavior of large multilingual models\nlike in this setting. Unlike previous works we aim to make large language\nmodels able to perform detoxification without direct fine-tuning in given\nlanguage. Experiments show that multilingual models are capable of performing\nmultilingual style transfer. However, models are not able to perform\ncross-lingual detoxification and direct fine-tuning on exact language is\ninevitable.",
    "descriptor": "",
    "authors": [
      "Daniil Moskovskiy",
      "Daryna Dementieva",
      "Alexander Panchenko"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.02252"
  },
  {
    "id": "arXiv:2206.02254",
    "title": "Augmenting Netflix Search with In-Session Adapted Recommendations",
    "abstract": "We motivate the need for recommendation systems that can cater to the members\nin-the-moment intent by leveraging their interactions from the current session.\nWe provide an overview of an end-to-end in-session adaptive recommendations\nsystem in the context of Netflix Search. We discuss the challenges and\npotential solutions when developing such a system at production scale.",
    "descriptor": "\nComments: 5 pages, 2 figures\n",
    "authors": [
      "Moumita Bhattacharya",
      "Sudarshan Lamkhede"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02254"
  },
  {
    "id": "arXiv:2206.02255",
    "title": "Modeling GPU Dynamic Parallelism for Self Similar Density Workloads",
    "abstract": "Dynamic Parallelism (DP) is a runtime feature of the GPU programming model\nthat allows GPU threads to execute additional GPU kernels, recursively. Apart\nfrom making the programming of parallel hierarchical patterns easier, DP can\nalso speedup problems that exhibit a heterogeneous data layout by focusing,\nthrough a subdivision process, the finite GPU resources on the sub-regions that\nexhibit more parallelism. However, doing an optimal subdivision process is not\ntrivial, as there are different parameters that play an important role in the\nfinal performance of DP. Moreover, the current programming abstraction for DP\nalso introduces an overhead that can penalize the final performance. In this\nwork we present a subdivision cost model for problems that exhibit self similar\ndensity (SSD) workloads (such as fractals), in order understand what parameters\nprovide the fastest subdivision approach. Also, we introduce a new subdivision\nimplementation, named \\textit{Adaptive Serial Kernels} (ASK), as a smaller\noverhead alternative to CUDA's Dynamic Parallelism. Using the cost model on the\nMandelbrot Set as a case study shows that the optimal scheme is to start with\nan initial subdivision between $g=[2,16]$, then keep subdividing in regions of\n$r=2,4$, and stop when regions reach a size of $B \\sim 32$. The experimental\nresults agree with the theoretical parameters, confirming the usability of the\ncost model. In terms of performance, the proposed ASK approach runs up to $\\sim\n60\\%$ faster than Dynamic Parallelism in the Mandelbrot set, and up to\n$12\\times$ faster than a basic exhaustive implementation, whereas DP is up to\n$7.5\\times$.",
    "descriptor": "\nComments: submitted to Journal\n",
    "authors": [
      "Felipe A. Quezada",
      "Crist\u00f3bal A. Navarro",
      "Miguel Romero",
      "Cristhian Aguilera"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2206.02255"
  },
  {
    "id": "arXiv:2206.02256",
    "title": "Use-Case-Grounded Simulations for Explanation Evaluation",
    "abstract": "A growing body of research runs human subject evaluations to study whether\nproviding users with explanations of machine learning models can help them with\npractical real-world use cases. However, running user studies is challenging\nand costly, and consequently each study typically only evaluates a limited\nnumber of different settings, e.g., studies often only evaluate a few\narbitrarily selected explanation methods. To address these challenges and aid\nuser study design, we introduce Use-Case-Grounded Simulated Evaluations\n(SimEvals). SimEvals involve training algorithmic agents that take as input the\ninformation content (such as model explanations) that would be presented to\neach participant in a human subject study, to predict answers to the use case\nof interest. The algorithmic agent's test set accuracy provides a measure of\nthe predictiveness of the information content for the downstream use case. We\nrun a comprehensive evaluation on three real-world use cases (forward\nsimulation, model debugging, and counterfactual reasoning) to demonstrate that\nSimevals can effectively identify which explanation methods will help humans\nfor each use case. These results provide evidence that SimEvals can be used to\nefficiently screen an important set of user study design decisions, e.g.\nselecting which explanations should be presented to the user, before running a\npotentially costly user study.",
    "descriptor": "",
    "authors": [
      "Valerie Chen",
      "Nari Johnson",
      "Nicholay Topin",
      "Gregory Plumb",
      "Ameet Talwalkar"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02256"
  },
  {
    "id": "arXiv:2206.02257",
    "title": "Efficient Annotation and Learning for 3D Hand Pose Estimation: A Survey",
    "abstract": "In this survey, we present comprehensive analysis of 3D hand pose estimation\nfrom the perspective of efficient annotation and learning. In particular, we\nstudy recent approaches for 3D hand pose annotation and learning methods with\nlimited annotated data. In 3D hand pose estimation, collecting 3D hand pose\nannotation is a key step in developing hand pose estimators and their\napplications, such as video understanding, AR/VR, and robotics. However,\nacquiring annotated 3D hand poses is cumbersome, e.g., due to the difficulty of\naccessing 3D information and occlusion. Motivated by elucidating how recent\nworks address the annotation issue, we investigated annotation methods\nclassified as manual, synthetic-model-based, hand-sensor-based, and\ncomputational approaches. Since these annotation methods are not always\navailable on a large scale, we examined methods of learning 3D hand poses when\nwe do not have enough annotated data, namely self-supervised pre-training,\nsemi-supervised learning, and domain adaptation. Based on the analysis of these\nefficient annotation and learning, we further discuss limitations and possible\nfuture directions of this field.",
    "descriptor": "",
    "authors": [
      "Takehiko Ohkawa",
      "Ryosuke Furuta",
      "Yoichi Sato"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02257"
  },
  {
    "id": "arXiv:2206.02260",
    "title": "SealID: Saimaa ringed seal re-identification dataset",
    "abstract": "Wildlife camera traps and crowd-sourced image material provide novel\npossibilities to monitor endangered animal species. However, massive image\nvolumes that these methods produce are overwhelming for researchers to go\nthrough manually which calls for automatic systems to perform the analysis. The\nanalysis task that has gained the most attention is the re-identification of\nindividuals, as it allows, for example, to study animal migration or to\nestimate the population size. The Saimaa ringed seal (Pusa hispida saimensis)\nis an endangered subspecies only found in the Lake Saimaa, Finland, and is one\nof the few existing freshwater seal species. Ringed seals have permanent pelage\npatterns that are unique to each individual which can be used for the\nidentification of individuals. Large variation in poses further exacerbated by\nthe deformable nature of seals together with varying appearance and low\ncontrast between the ring pattern and the rest of the pelage makes the Saimaa\nringed seal re-identification task very challenging, providing a good benchmark\nto evaluate state-of-the-art re-identification methods. Therefore, we make our\nSaimaa ringed seal image (SealID) dataset (N=57) publicly available for\nresearch purposes. In this paper, the dataset is described, the evaluation\nprotocol for re-identification methods is proposed, and the results for two\nbaseline methods HotSpotter and NORPPA are provided. The SealID dataset has\nbeen made publicly available.",
    "descriptor": "\nComments: 15 pages, 9 figures\n",
    "authors": [
      "Ekaterina Nepovinnykh",
      "Tuomas Eerola",
      "Vincent Biard",
      "Piia Mutka",
      "Marja Niemi",
      "Heikki K\u00e4lvi\u00e4inen",
      "Mervi Kunnasranta"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2206.02260"
  },
  {
    "id": "arXiv:2206.02261",
    "title": "Towards Individual Grevy's Zebra Identification via Deep 3D Fitting and  Metric Learning",
    "abstract": "This paper combines deep learning techniques for species detection, 3D model\nfitting, and metric learning in one pipeline to perform individual animal\nidentification from photographs by exploiting unique coat patterns. This is the\nfirst work to attempt this and, compared to traditional 2D bounding box or\nsegmentation based CNN identification pipelines, the approach provides\neffective and explicit view-point normalisation and allows for a straight\nforward visualisation of the learned biometric population space. Note that due\nto the use of metric learning the pipeline is also readily applicable to open\nset and zero shot re-identification scenarios. We apply the proposed approach\nto individual Grevy's zebra (Equus grevyi) identification and show in a small\nstudy on the SMALST dataset that the use of 3D model fitting can indeed benefit\nperformance. In particular, back-projected textures from 3D fitted models\nimprove identification accuracy from 48.0% to 56.8% compared to 2D bounding box\napproaches for the dataset. Whilst the study is far too small accurately to\nestimate the full performance potential achievable in larger-scale real-world\napplication settings and in comparisons against polished tools, our work lays\nthe conceptual and practical foundations for a next step in animal biometrics\ntowards deep metric learning driven, fully 3D-aware animal identification in\nopen population settings. We publish network weights and relevant facilitating\nsource code with this paper for full reproducibility and as inspiration for\nfurther research.",
    "descriptor": "\nComments: 4 pages, 5 figures, 1 table\n",
    "authors": [
      "Maria Stennett",
      "Daniel I. Rubenstein",
      "Tilo Burghardt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02261"
  },
  {
    "id": "arXiv:2206.02262",
    "title": "Diffusion-GAN: Training GANs with Diffusion",
    "abstract": "For stable training of generative adversarial networks (GANs), injecting\ninstance noise into the input of the discriminator is considered as a\ntheoretically sound solution, which, however, has not yet delivered on its\npromise in practice. This paper introduces Diffusion-GAN that employs a\nGaussian mixture distribution, defined over all the diffusion steps of a\nforward diffusion chain, to inject instance noise. A random sample from the\nmixture, which is diffused from an observed or generated data, is fed as the\ninput to the discriminator. The generator is updated by backpropagating its\ngradient through the forward diffusion chain, whose length is adaptively\nadjusted to control the maximum noise-to-data ratio allowed at each training\nstep. Theoretical analysis verifies the soundness of the proposed\nDiffusion-GAN, which provides model- and domain-agnostic differentiable\naugmentation. A rich set of experiments on diverse datasets show that\nDiffusion-GAN can provide stable and data-efficient GAN training, bringing\nconsistent performance improvement over strong GAN baselines for synthesizing\nphoto-realistic images.",
    "descriptor": "",
    "authors": [
      "Zhendong Wang",
      "Huangjie Zheng",
      "Pengcheng He",
      "Weizhu Chen",
      "Mingyuan Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.02262"
  },
  {
    "id": "arXiv:2206.02270",
    "title": "Estimating Building Energy Efficiency From Street View Imagery, Aerial  Imagery, and Land Surface Temperature Data",
    "abstract": "In the race towards carbon neutrality, the building sector has fallen behind\nand bears the potential to endanger the progress made across other industries.\nThis is because buildings exhibit a life span of several decades which creates\nsubstantial inertia in the face of climate change. This inertia is further\nexacerbated by the scale of the existing building stock. With several billion\noperational buildings around the globe, working towards a carbon-neutral\nbuilding sector requires solutions which enable stakeholders to accurately\nidentify and retrofit subpar buildings at scale. However, improving the energy\nefficiency of the existing building stock through retrofits in a targeted and\nefficient way remains challenging. This is because, as of today, the energy\nefficiency of buildings is generally determined by on-site visits of certified\nenergy auditors which makes the process slow, costly, and geographically\nincomplete. In order to accelerate the identification of promising retrofit\ntargets, this work proposes a new method which can estimate a building's energy\nefficiency using purely remotely sensed data such as street view and aerial\nimagery, OSM-derived footprint areas, and satellite-borne land surface\ntemperature (LST) measurements. We find that in the binary setting of\ndistinguishing efficient from inefficient buildings, our end-to-end deep\nlearning model achieves a macro-averaged F1-score of 62.06\\%. As such, this\nwork shows the potential and complementary nature of remotely sensed data in\npredicting building attributes such as energy efficiency and opens up new\nopportunities for future work to integrate additional data sources.",
    "descriptor": "",
    "authors": [
      "Kevin Mayer",
      "Lukas Haas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02270"
  },
  {
    "id": "arXiv:2206.02274",
    "title": "An information upper bound for probability sensitivity",
    "abstract": "Uncertain input of a mathematical model induces uncertainties in the output\nand probabilistic sensitivity analysis identifies the influential inputs to\nguide decision-making. Of practical concern is the probability that the output\nwould, or would not, exceed a threshold, and the probability sensitivity\ndepends on this threshold which is often uncertain. The Fisher information and\nthe Kullback-Leibler divergence have been recently proposed in the literature\nas threshold-independent sensitivity metrics. We present mathematical proof\nthat the information-theoretical metrics provide an upper bound for the\nprobability sensitivity. The proof is elementary, relying only on a special\nversion of the Cauchy-Schwarz inequality called Titu's lemma. Despite various\ninequalities exist for probabilities, little is known of probability\nsensitivity bounds and the one proposed here is new to the present authors'\nknowledge. The probability sensitivity bound is extended, analytically and with\nnumerical examples, to the Fisher information of both the input and output. It\nthus provides a solid mathematical basis for decision-making based on\nprobabilistic sensitivity metrics.",
    "descriptor": "\nComments: 19 pages, 5 figures, for the datasets generated during and/or analysed during the current study, see this http URL\n",
    "authors": [
      "Jiannan Yang",
      "Robin S. Langley"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Numerical Analysis (math.NA)",
      "Statistics Theory (math.ST)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2206.02274"
  },
  {
    "id": "arXiv:2206.02275",
    "title": "Sharper Rates and Flexible Framework for Nonconvex SGD with Client and  Data Sampling",
    "abstract": "We revisit the classical problem of finding an approximately stationary point\nof the average of $n$ smooth and possibly nonconvex functions. The optimal\ncomplexity of stochastic first-order methods in terms of the number of gradient\nevaluations of individual functions is $\\mathcal{O}\\left(n +\nn^{1/2}\\varepsilon^{-1}\\right)$, attained by the optimal SGD methods\n$\\small\\sf\\color{green}{SPIDER}$(arXiv:1807.01695) and\n$\\small\\sf\\color{green}{PAGE}$(arXiv:2008.10898), for example, where\n$\\varepsilon$ is the error tolerance. However, i) the big-$\\mathcal{O}$\nnotation hides crucial dependencies on the smoothness constants associated with\nthe functions, and ii) the rates and theory in these methods assume simplistic\nsampling mechanisms that do not offer any flexibility. In this work we remedy\nthe situation. First, we generalize the $\\small\\sf\\color{green}{PAGE}$\nalgorithm so that it can provably work with virtually any (unbiased) sampling\nmechanism. This is particularly useful in federated learning, as it allows us\nto construct and better understand the impact of various combinations of client\nand data sampling strategies. Second, our analysis is sharper as we make\nexplicit use of certain novel inequalities that capture the intricate interplay\nbetween the smoothness constants and the sampling procedure. Indeed, our\nanalysis is better even for the simple sampling procedure analyzed in the\n$\\small\\sf\\color{green}{PAGE}$ paper. However, this already improved bound can\nbe further sharpened by a different sampling scheme which we propose. In\nsummary, we provide the most general and most accurate analysis of optimal SGD\nin the smooth nonconvex regime. Finally, our theoretical findings are supposed\nwith carefully designed experiments.",
    "descriptor": "\nComments: 25 pages, 6 figures\n",
    "authors": [
      "Alexander Tyurin",
      "Lukang Sun",
      "Konstantin Burlachenko",
      "Peter Richt\u00e1rik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.02275"
  },
  {
    "id": "arXiv:2206.02277",
    "title": "Conceptual Modeling with Constraints",
    "abstract": "An important factor in guaranteeing the quality of a system is developing a\nconceptual model that reflects the knowledge about its domain as well as\nknowledge about the functions it has to perform. In software engineering,\nconceptual modeling has gained importance as a discipline that offers\nlanguages, methods, and methodologies to address the complexity of software\ndevelopment. The key to understanding such complexity is using tools such as\ndiagrams at various levels of representation. A conceptual model must include\nall relevant static and behavioral aspects of its domain. In UML, the static\naspects include structural diagrams that represent the internal architecture of\na system with a special focus on the classes, the connections and interactions\nthat they have, and integrity constraints over the state of the domain. UML\ndoes not have sufficient expressiveness for complete specifications of certain\nconstraints. Constraints assist in analyzing permissible design requirements\nand the limitations of the intended functions. To overcome the limitations of\nthe graphical notation, other types of languages are used to complement the\ndiagrammatic language (e.g., the textual Object Constraint Language [OCL]). In\nthis paper, we study how to express constraints diagrammatically using the\nthinging machine (TM) through examples taken from the UML/OCL literature. This\nwould contribute to further understanding the notion of constraint in\nconceptual modeling. It also demonstrates the expressiveness and limitation of\nthe TM. The paper suggests that the TM can provide a diagrammatic constraints\nlanguage in conceptual models.",
    "descriptor": "\nComments: 12 pages, 24 figures\n",
    "authors": [
      "Sabah Al-Fedaghi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.02277"
  },
  {
    "id": "arXiv:2206.02280",
    "title": "Annotation Error Detection: Analyzing the Past and Present for a More  Coherent Future",
    "abstract": "Annotated data is an essential ingredient in natural language processing for\ntraining and evaluating machine learning models. It is therefore very desirable\nfor the annotations to be of high quality. Recent work, however, has shown that\nseveral popular datasets contain a surprising amount of annotation errors or\ninconsistencies. To alleviate this issue, many methods for annotation error\ndetection have been devised over the years. While researchers show that their\napproaches work well on their newly introduced datasets, they rarely compare\ntheir methods to previous work or on the same datasets. This raises strong\nconcerns on methods' general performance and makes it difficult to asses their\nstrengths and weaknesses. We therefore reimplement 18 methods for detecting\npotential annotation errors and evaluate them on 9 English datasets for text\nclassification as well as token and span labeling. In addition, we define a\nuniform evaluation setup including a new formalization of the annotation error\ndetection task, evaluation protocol and general best practices. To facilitate\nfuture research and reproducibility, we release our datasets and\nimplementations in an easy-to-use and open source software package.",
    "descriptor": "",
    "authors": [
      "Jan-Christoph Klie",
      "Bonnie Webber",
      "Iryna Gurevych"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.02280"
  },
  {
    "id": "arXiv:2206.02281",
    "title": "E^2VTS: Energy-Efficient Video Text Spotting from Unmanned Aerial  Vehicles",
    "abstract": "Unmanned Aerial Vehicles (UAVs) based video text spotting has been\nextensively used in civil and military domains. UAV's limited battery capacity\nmotivates us to develop an energy-efficient video text spotting solution. In\nthis paper, we first revisit RCNN's crop & resize training strategy and\nempirically find that it outperforms aligned RoI sampling on a real-world video\ntext dataset captured by UAV. To reduce energy consumption, we further propose\na multi-stage image processor that takes videos' redundancy, continuity, and\nmixed degradation into account. Lastly, the model is pruned and quantized\nbefore deployed on Raspberry Pi. Our proposed energy-efficient video text\nspotting solution, dubbed as E^2VTS, outperforms all previous methods by\nachieving a competitive tradeoff between energy efficiency and performance. All\nour codes and pre-trained models are available at\nhttps://github.com/wuzhenyusjtu/LPCVC20-VideoTextSpotting.",
    "descriptor": "",
    "authors": [
      "Zhenyu Hu",
      "Zhenyu Wu",
      "Pengcheng Pi",
      "Yunhe Xue",
      "Jiayi Shen",
      "Jianchao Tan",
      "Xiangru Lian",
      "Zhangyang Wang",
      "Ji Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02281"
  },
  {
    "id": "arXiv:2206.02283",
    "title": "Situation Theory and Channel theory as a Unified Framework for Imperfect  Information Management",
    "abstract": "This article argues that the Situation theory and the Channel theory can be\nused as a general framework for Imperfect Information Management. Different\nkinds of imperfections are uncertainty, imprecision, vagueness, incompleteness,\ninconsistency, and context-dependency which can be handled pretty well by our\nbrain. Basic approaches like probability theory and standard logic are\nintrinsically inefficient in modeling fallacious minds. The generalized\nprobability and nonstandard logic theories have epistemological motivations to\nprovide better models for information integration in cognitive agents. Among\nmany models of them, possibility theory and probabilistic logic theory are the\nbest approaches. I argue, based on a review of different approaches to\nImperfect Information Management, that a good framework for it is the Situation\ntheory of Barwise and the Channel theory of Barwise-Seligman. These theories\nhave relied on a powerful and unique epistemological-based notion of\ninformation to refer to partiality. These frameworks have a proper approach for\ncontext modeling to handle common knowledge and incomplete information. Also,\nthey distinguish belief from knowledge clearly to model the non-monotonic and\ndynamic nature of knowledge. They discern the logic of the world from\ninformation flow in the mind. The objectification process in these theories\nreveals to us the nature of default or probabilistic rules in perceptions. The\nconcept of the channel can be used to represent those types of reasoning\nmechanisms that move from one model or logic to another one. The imprecision in\nour perceptions causes fuzziness in reasoning and vagueness in communication\nthat can be represented by some suitable classifications connected by some\nchannels. This new framework like a network framework can provide a scalable\nand open framework to cover different models based on a relativistic notion of\ntruth.",
    "descriptor": "\nComments: 37 pages, 12 figures, 1 table\n",
    "authors": [
      "Farhad Naderian"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.02283"
  },
  {
    "id": "arXiv:2206.02284",
    "title": "Tagged-MRI2Audio with Attention Guided Heterogeneous Translator",
    "abstract": "Understanding the underlying relationship between tongue and oropharyngeal\nmuscle deformation seen in tagged-MRI and intelligible speech plays an\nimportant role in advancing speech motor control theories and treatment of\nspeech related-disorders. Because of their heterogeneous representations,\nhowever, direct mapping between the two modalities -- i.e., two-dimensional\n(mid-sagittal slice) plus time tagged-MRI sequence and its corresponding\none-dimensional waveform -- is not straightforward. Instead, we resort to\ntwo-dimensional spectrograms as an intermediate representation, which contains\nboth pitch and resonance, from which to develop an end-to-end deep learning\nframework to translate from a sequence of tagged-MRI to its corresponding audio\nwaveform with limited dataset size. Our framework is based on a novel fully\nconvolutional asymmetry translator with guidance of a self residual attention\nstrategy to specifically exploit the moving muscular structures during speech.\nIn addition, we leverage a pairwise correlation of the samples with the same\nutterances with a latent space representation disentanglement strategy.\nFurthermore, we incorporate an adversarial training approach with generative\nadversarial networks to offer improved realism on our generated spectrograms.\nOur experimental results, carried out with a total of 63 tagged-MRI sequences\nalongside speech acoustics, showed that our framework enabled the generation of\nclear audio waveforms from a sequence of tagged-MRI, surpassing competing\nmethods.",
    "descriptor": "\nComments: MICCAI 2022 (early accept)\n",
    "authors": [
      "Xiaofeng Liu",
      "Fangxu Xing",
      "Jerry L. Prince",
      "Jiachen Zhuo",
      "Maureen Stone",
      "Georges El Fakhri",
      "Jonghye Woo"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.02284"
  },
  {
    "id": "arXiv:2206.02285",
    "title": "Story Beyond the Eye: Glyph Positions Break PDF Text Redaction",
    "abstract": "In the past redaction involved the use of black or white markers or paper\ncut-outs to obscure content on physical paper. Today many redactions take place\non digital PDF documents and redaction is often performed by software tools.\nTypical redaction tools remove text from PDF documents and draw a black or\nwhite rectangle in its place, mimicking a physical redaction. This practice is\nthought to be secure when the redacted text is removed and cannot be\n\"copy-pasted\" from the PDF document. We find this common conception is false --\nexisting PDF redactions can be broken by precise measurements of non-redacted\ncharacter positioning information.\nWe develop a deredaction tool for automatically finding and breaking these\nvulnerable redactions. We report on 11 different redaction tools, finding the\nmajority do not remove redaction-breaking information, including some Adobe\nAcrobat workflows. We empirically measure the information leaks, finding some\nredactions leak upwards of 15 bits of information, creating a 32,768-fold\nreduction in the space of potential redacted texts. We demonstrate a lower\nbound on the impact of these leaks via a 22,120 document study, including\n18,975 Office of the Inspector General (OIG) investigation reports, where we\nfind 769 vulnerable named-entity redactions. We find leaked information reduces\nthe contents for 164 of these redacted names to less than 494 possibilities\nfrom a 7 million name dictionary. We show these findings impact by breaking\nredactions from the Epstein/Maxwell case, Manafort case, and a released Snowden\ndocument. Moreover, we develop an efficient algorithm for locating\ncopy-pastable redactions and find over 100,000 poorly redacted words in US\ncourt documents. Current PDF text redaction methods are insufficient for named\nentity protection.",
    "descriptor": "",
    "authors": [
      "Maxwell Bland",
      "Anushya Iyer",
      "Kirill Levchenko"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.02285"
  },
  {
    "id": "arXiv:2206.02286",
    "title": "AugLoss: A Learning Methodology for Real-World Dataset Corruption",
    "abstract": "Deep Learning (DL) models achieve great successes in many domains. However,\nDL models increasingly face safety and robustness concerns, including noisy\nlabeling in the training stage and feature distribution shifts in the testing\nstage. Previous works made significant progress in addressing these problems,\nbut the focus has largely been on developing solutions for only one problem at\na time. For example, recent work has argued for the use of tunable robust loss\nfunctions to mitigate label noise, and data augmentation (e.g., AugMix) to\ncombat distribution shifts. As a step towards addressing both problems\nsimultaneously, we introduce AugLoss, a simple but effective methodology that\nachieves robustness against both train-time noisy labeling and test-time\nfeature distribution shifts by unifying data augmentation and robust loss\nfunctions. We conduct comprehensive experiments in varied settings of\nreal-world dataset corruption to showcase the gains achieved by AugLoss\ncompared to previous state-of-the-art methods. Lastly, we hope this work will\nopen new directions for designing more robust and reliable DL models under\nreal-world corruptions.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Kyle Otstot",
      "John Kevin Cava",
      "Tyler Sypherd",
      "Lalitha Sankar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.02286"
  },
  {
    "id": "arXiv:2206.02287",
    "title": "Integral Line-of-Sight Curved Path Following of Helical Microswimmers  Actuated by Rotating Magnetic Dipoles",
    "abstract": "This short paper investigates the problem of curved path following for\nhelical microswimmers actuated by rotating magnetic dipoles. The proposed\nsolution, which relies on an integral line-of-sight (ILOS) guidance law, can be\nutilized in both below and beyond step-out frequency regimes.",
    "descriptor": "\nComments: Accepted in International Conference on Manipulation, Automation and Robotics at Small Scales (MARSS), July 2022\n",
    "authors": [
      "Alireza Mohammadi",
      "Mark W. Spong"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.02287"
  },
  {
    "id": "arXiv:2206.02288",
    "title": "ACT: Semi-supervised Domain-adaptive Medical Image Segmentation with  Asymmetric Co-Training",
    "abstract": "We aim to develop semi-supervised domain adaptation (SSDA) for medical image\nsegmentation, which is largely underexplored. We propose to exploit both\nlabeled source and target domain data, in addition to unlabeled target data in\na unified manner. Specifically, we present a novel asymmetric co-training (ACT)\nframework to integrate these subsets and avoid the domination of the source\ndomain data. Following a divide-and-conquer strategy, we explicitly decouple\nthe label supervisions in SSDA into two asymmetric sub-tasks, including\nsemi-supervised learning (SSL) and UDA, and leverage different knowledge from\ntwo segmentors to take into account the distinction between the source and\ntarget label supervisions. The knowledge learned in the two modules is then\nadaptively integrated with ACT, by iteratively teaching each other, based on\nthe confidence-aware pseudo-label. In addition, pseudo label noise is\nwell-controlled with an exponential MixUp decay scheme for smooth propagation.\nExperiments on cross-modality brain tumor MRI segmentation tasks using the\nBraTS18 database showed, even with limited labeled target samples, ACT yielded\nmarked improvements over UDA and state-of-the-art SSDA methods.",
    "descriptor": "\nComments: MICCAI 2022 (early accept)\n",
    "authors": [
      "Xiaofeng Liu",
      "Fangxu Xing",
      "Nadya Shusharina",
      "Ruth Lim",
      "C-C Jay Kuo",
      "Georges El Fakhri",
      "Jonghye Woo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02288"
  },
  {
    "id": "arXiv:2206.02291",
    "title": "Pretrained Models for Multilingual Federated Learning",
    "abstract": "Since the advent of Federated Learning (FL), research has applied these\nmethods to natural language processing (NLP) tasks. Despite a plethora of\npapers in FL for NLP, no previous works have studied how multilingual text\nimpacts FL algorithms. Furthermore, multilingual text provides an interesting\navenue to examine the impact of non-IID text (e.g. different languages) on FL\nin naturally occurring data. We explore three multilingual language tasks,\nlanguage modeling, machine translation, and text classification using differing\nfederated and non-federated learning algorithms. Our results show that using\npretrained models reduces the negative effects of FL, helping them to perform\nnear or better than centralized (no privacy) learning, even when using non-IID\npartitioning.",
    "descriptor": "\nComments: NAACL 2022\n",
    "authors": [
      "Orion Weller",
      "Marc Marone",
      "Vladimir Braverman",
      "Dawn Lawrie",
      "Benjamin Van Durme"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.02291"
  },
  {
    "id": "arXiv:2206.02295",
    "title": "HIFI-Net: A Novel Network for Enhancement to Underwater Images",
    "abstract": "A novel network for enhancement to underwater images is proposed in this\npaper. It contains a Reinforcement Fusion Module for Haar wavelet images\n(RFM-Haar) based on Reinforcement Fusion Unit (RFU), which is used to fuse an\noriginal image and some important information within it. Fusion is achieved for\nbetter enhancement. As this network make \"Haar Images into Fusion Images\", it\nis called HIFI-Net. The experimental results show the proposed HIFI-Net\nperforms best among many state-of-the-art methods on three datasets at three\nnormal metrics and a new metric.",
    "descriptor": "\nComments: 7 pages, 4 figures\n",
    "authors": [
      "Jiajia Zhou",
      "Junbin Zhuang",
      "Yan Zheng",
      "Di Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02295"
  },
  {
    "id": "arXiv:2206.02300",
    "title": "On the horizontal compression of dag-derivations in minimal purely  implicational logic",
    "abstract": "In this report, we define (plain) Dag-like derivations in the purely\nimplicational fragment of minimal logic $M_{\\imply}$. Introduce the horizontal\ncollapsing set of rules and the algorithm {\\bf HC}. Explain why {\\bf HC} can\ntransform any polynomial height-bounded tree-like proof of a $M_{\\imply}$\ntautology into a smaller dag-like proof. Sketch a proof that {\\bf HC} preserves\nthe soundness of any tree-like ND in $M_{\\imply}$ in its dag-like version after\nthe horizontal collapsing application. We show some experimental results about\napplying the compression method to a class of (huge) propositional proofs and\nan example, with non-hamiltonian graphs, for qualitative analysis. The\ncontributions include the comprehensive presentation of the set of horizontal\ncompression (HC), the (sketch) of a proof that HC rules preserve soundness and\nthe demonstration that the compressed dag-like proofs are polynomially\nupper-bounded when the submitted tree-like proof is height and foundation\npoly-bounded. Finally, in the appendix, we show an algorithm that verifies in\npolynomial time on the size of the dag-like proofs whether they are valid\nproofs of their conclusions.",
    "descriptor": "\nComments: This is a comprehensive report describing the set of rules and the algorithm for compressing Natural Deduction proofs in the purely implicational minimal logic.It reports some experiments with an implementation applied to a class of huge proofs\n",
    "authors": [
      "Edward Hermann Haeusler",
      "Jos\u00e9 Fl\u00e1vio Cavalcante Barros Junior"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.02300"
  },
  {
    "id": "arXiv:2206.02305",
    "title": "Fully Persistent Spatial Data Structures for Efficient Queries in  Path-Dependent Motion Planning Applications",
    "abstract": "Motion planning is a ubiquitous problem that is often a bottleneck in robotic\napplications. We demonstrate that motion planning problems such as minimum\nconstraint removal, belief-space planning, and visibility-aware motion planning\n(VAMP) benefit from a path-dependent formulation, in which the state at a\nsearch node is represented implicitly by the path to that node. A naive\napproach to computing the feasibility of a successor node in such a\npath-dependent formulation takes time linear in the path length to the node, in\ncontrast to a (possibly very large) constant time for a more typical search\nformulation. For long-horizon plans, performing this linear-time computation,\nwhich we call the lookback, for each node becomes prohibitive. To improve upon\nthis, we introduce the use of a fully persistent spatial data structure\n(FPSDS), which bounds the size of the lookback. We then focus on the\napplication of the FPSDS in VAMP, which involves incremental geometric\ncomputations that can be accelerated by filtering configurations with bounding\nvolumes using nearest-neighbor data structures. We demonstrate an asymptotic\nand practical improvement in the runtime of finding VAMP solutions in several\nillustrative domains. To the best of our knowledge, this is the first use of a\nfully persistent data structure for accelerating motion planning.",
    "descriptor": "\nComments: Presented at the 2022 IEEE International Conference on Robotics and Automation (ICRA) and will appear in the official proceedings\n",
    "authors": [
      "Sathwik Karnik",
      "Tom\u00e1s Lozano-P\u00e9rez",
      "Leslie Pack Kaelbling",
      "Gustavo Nunes Goretkin"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.02305"
  },
  {
    "id": "arXiv:2206.02306",
    "title": "Mapping Visual Themes among Authentic and Coordinated Memes",
    "abstract": "What distinguishes authentic memes from those created by state actors? I\nutilize a self-supervised vision model, DeepCluster (Caron et al. 2019), to\nlearn low-dimensional visual embeddings of memes and apply K-means to jointly\ncluster authentic and coordinated memes without additional inputs. I find that\nauthentic and coordinated memes share a large fraction of visual themes but\nwith varying degrees. Coordinated memes from Russian IRA accounts promote more\nthemes around celebrities, quotes, screenshots, military, and gender. Authentic\nReddit memes include more themes with comics and movie characters. A simple\nlogistic regression on the low-dimensional embeddings can discern IRA memes\nfrom Reddit memes with an out-sample testing accuracy of 0.84.",
    "descriptor": "",
    "authors": [
      "Keng-Chi Chang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.02306"
  },
  {
    "id": "arXiv:2206.02307",
    "title": "Bootstrapping Semi-supervised Medical Image Segmentation with  Anatomical-aware Contrastive Distillation",
    "abstract": "Contrastive learning has shown great promise over annotation scarcity\nproblems in the context of medical image segmentation. Existing approaches\ntypically assume a balanced class distribution for both labeled and unlabeled\nmedical images. However, medical image data in reality is commonly imbalanced\n(i.e., multi-class label imbalance), which naturally yields blurry contours and\nusually incorrectly labels rare objects. Moreover, it remains unclear whether\nall negative samples are equally negative. In this work, we present ACTION, an\nAnatomical-aware ConTrastive dIstillatiON framework, for semi-supervised\nmedical image segmentation. Specifically, we first develop an iterative\ncontrastive distillation algorithm by softly labeling the negatives rather than\nbinary supervision between positive and negative pairs. We also capture more\nsemantically similar features from the randomly chosen negative set compared to\nthe positives to enforce the diversity of the sampled data. Second, we raise a\nmore important question: Can we really handle imbalanced samples to yield\nbetter performance? Hence, the key innovation in ACTION is to learn global\nsemantic relationship across the entire dataset and local anatomical features\namong the neighbouring pixels with minimal additional memory footprint. During\nthe training, we introduce anatomical contrast by actively sampling a sparse\nset of hard negative pixels, which can generate smoother segmentation\nboundaries and more accurate predictions. Extensive experiments across two\nbenchmark datasets and different unlabeled settings show that ACTION performs\ncomparable or better than the current state-of-the-art supervised and\nsemi-supervised methods. Our code and models will be publicly available.",
    "descriptor": "",
    "authors": [
      "Chenyu You",
      "Weicheng Dai",
      "Lawrence Staib",
      "James S. Duncan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.02307"
  },
  {
    "id": "arXiv:2206.02310",
    "title": "CYRUS Soccer Simulation 2D Team Description Paper 2021",
    "abstract": "In this report, we briefly present the technical procedure and simulation\nsteps for the 2D soccer simulation of team Cyrus. We emphasize on this document\non how the prediction of teammates' behavior is performed. In our proposed\nmethod, the agent receives the noisy inputs from the server, and predicts the\nball holder full state behavior. Taking advantage of this approach for choosing\nthe optimal view angle shows 11.30% improvement on the expected win rate.",
    "descriptor": "",
    "authors": [
      "Nader Zare",
      "Aref Sayareh",
      "Mahtab Sarvmaili",
      "Omid Amini",
      "Amilcar Soares",
      "Stan Matwin"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.02310"
  },
  {
    "id": "arXiv:2206.02314",
    "title": "Transmission of Bernoulli Sources Using Convolutional LDGM Codes",
    "abstract": "We propose in this paper to exploit convolutional low density generator\nmatrix (LDGM) codes for transmission of Bernoulli sources over binary-input\noutput-symmetric (BIOS) channels. To this end, we present a new framework to\nprove the coding theorems for linear codes, which unifies the channel coding\ntheorem, the source coding theorem and the joint source-channel coding (JSCC)\ntheorem. In the presented framework, the systematic bits and the corresponding\nparity-check bits play different roles. Precisely, the noisy systematic bits\nare used to limit the list size of typical codewords, while the noisy\nparity-check bits are used to select from the list the maximum likelihood\ncodeword. This new framework for linear codes allows that the systematic bits\nand the parity-check bits are transmitted in different ways and over different\nchannels. With this framework, we prove that the Bernoulli generator matrix\ncodes (BGMCs) are capacity-achieving over BIOS channels, entropy-achieving for\nBernoulli sources, and also system-capacity-achieving for JSCC applications. A\nlower bound on the bit-error rate (BER) is derived for linear codes, which can\nbe used to predict the error floors and hence serves as a simple tool to design\nthe JSCC system. Numerical results show that the convolutional LDGM codes\nperform well in the waterfall region and match well with the derived error\nfloors, which can be lowered down if required by simply increasing the encoding\nmemory.",
    "descriptor": "\nComments: 24 pages, 13 figures\n",
    "authors": [
      "Yixin Wang",
      "Tingting Zhu",
      "Xiao Ma"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.02314"
  },
  {
    "id": "arXiv:2206.02319",
    "title": "Energy-Constrained Computation Offloading in Space-Air-Ground Integrated  Networks using Distributionally Robust Optimization",
    "abstract": "With the rapid development of connecting massive devices to the Internet,\nespecially for remote areas without cellular network infrastructures,\nspace-air-ground integrated networks (SAGINs) emerge and offload\ncomputation-intensive tasks. In this paper, we consider a SAGIN, where multiple\nlow-earth-orbit (LEO) satellites providing connections to the cloud server, an\nunmanned aerial vehicle (UAV), and nearby base stations (BSs) providing edge\ncomputing services are included. The UAV flies along a fixed trajectory to\ncollect tasks generated by Internet of Things (IoT) devices, and forwards these\ntasks to a BS or the cloud server for further processing. To facilitate\nefficient processing, the UAV needs to decide where to offload as well as the\nproportion of offloaded tasks. However, in practice, due to the variability of\nenvironment and actual demand, the amount of arrival tasks is uncertain. If the\ndeterministic optimization is utilized to develop offloading strategy,\nunnecessary system overhead or higher task drop rate may occur, which severely\ndamages the system robustness. To address this issue, we characterize the\nuncertainty with a data-driven approach, and formulate a distributionally\nrobust optimization problem to minimize the expected energy-constrained system\nlatency under the worst-case probability distribution. Furthermore, the\ndistributionally robust latency optimization algorithm is proposed to reach the\nsuboptimal solution. Finally, we perform simulations on the realworld data set,\nand compare with other benchmark schemes to verify the efficiency and\nrobustness of our proposed algorithm.",
    "descriptor": "\nComments: 12 pages, 6 figures, IEEE TVT\n",
    "authors": [
      "Yali Chen",
      "Bo Ai",
      "Yong Niu",
      "Hongliang Zhang",
      "Zhu Han"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.02319"
  },
  {
    "id": "arXiv:2206.02323",
    "title": "ID-Agnostic User Behavior Pre-training for Sequential Recommendation",
    "abstract": "Recently, sequential recommendation has emerged as a widely studied topic.\nExisting researches mainly design effective neural architectures to model user\nbehavior sequences based on item IDs. However, this kind of approach highly\nrelies on user-item interaction data and neglects the attribute- or\ncharacteristic-level correlations among similar items preferred by a user. In\nlight of these issues, we propose IDA-SR, which stands for ID-Agnostic User\nBehavior Pre-training approach for Sequential Recommendation. Instead of\nexplicitly learning representations for item IDs, IDA-SR directly learns item\nrepresentations from rich text information. To bridge the gap between text\nsemantics and sequential user behaviors, we utilize the pre-trained language\nmodel as text encoder, and conduct a pre-training architecture on the\nsequential user behaviors. In this way, item text can be directly utilized for\nsequential recommendation without relying on item IDs. Extensive experiments\nshow that the proposed approach can achieve comparable results when only using\nID-agnostic item representations, and performs better than baselines by a large\nmargin when fine-tuned with ID information.",
    "descriptor": "\nComments: 5 pages, 3 figures\n",
    "authors": [
      "Shanlei Mu",
      "Yupeng Hou",
      "Wayne Xin Zhao",
      "Yaliang Li",
      "Bolin Ding"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.02323"
  },
  {
    "id": "arXiv:2206.02325",
    "title": "Evaluation-oriented Knowledge Distillation for Deep Face Recognition",
    "abstract": "Knowledge distillation (KD) is a widely-used technique that utilizes large\nnetworks to improve the performance of compact models. Previous KD approaches\nusually aim to guide the student to mimic the teacher's behavior completely in\nthe representation space. However, such one-to-one corresponding constraints\nmay lead to inflexible knowledge transfer from the teacher to the student,\nespecially those with low model capacities. Inspired by the ultimate goal of KD\nmethods, we propose a novel Evaluation oriented KD method (EKD) for deep face\nrecognition to directly reduce the performance gap between the teacher and\nstudent models during training. Specifically, we adopt the commonly used\nevaluation metrics in face recognition, i.e., False Positive Rate (FPR) and\nTrue Positive Rate (TPR) as the performance indicator. According to the\nevaluation protocol, the critical pair relations that cause the TPR and FPR\ndifference between the teacher and student models are selected. Then, the\ncritical relations in the student are constrained to approximate the\ncorresponding ones in the teacher by a novel rank-based loss function, giving\nmore flexibility to the student with low capacity. Extensive experimental\nresults on popular benchmarks demonstrate the superiority of our EKD over\nstate-of-the-art competitors.",
    "descriptor": "\nComments: CVPR2022 Oral\n",
    "authors": [
      "Yuge Huang",
      "Jiaxiang Wu",
      "Xingkun Xu",
      "Shouhong Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02325"
  },
  {
    "id": "arXiv:2206.02326",
    "title": "Asymptotic Instance-Optimal Algorithms for Interactive Decision Making",
    "abstract": "Past research on interactive decision making problems (bandits, reinforcement\nlearning, etc.) mostly focuses on the minimax regret that measures the\nalgorithm's performance on the hardest instance. However, an ideal algorithm\nshould adapt to the complexity of a particular problem instance and incur\nsmaller regrets on easy instances than worst-case instances. In this paper, we\ndesign the first asymptotic instance-optimal algorithm for general interactive\ndecision making problems with finite number of decisions under mild conditions.\nOn \\textit{every} instance $f$, our algorithm outperforms \\emph{all} consistent\nalgorithms (those achieving non-trivial regrets on all instances), and has\nasymptotic regret $\\mathcal{C}(f) \\ln n$, where $\\mathcal{C}(f)$ is an exact\ncharacterization of the complexity of $f$. The key step of the algorithm\ninvolves hypothesis testing with active data collection. It computes the most\neconomical decisions with which the algorithm collects observations to test\nwhether an estimated instance is indeed correct; thus, the complexity\n$\\mathcal{C}(f)$ is the minimum cost to test the instance $f$ against other\ninstances. Our results, instantiated on concrete problems, recover the\nclassical gap-dependent bounds for multi-armed bandits [Lai and Robbins, 1985]\nand prior works on linear bandits [Lattimore and Szepesvari, 2017], and improve\nupon the previous best instance-dependent upper bound [Xu et al., 2021] for\nreinforcement learning.",
    "descriptor": "\nComments: 52 pages\n",
    "authors": [
      "Kefan Dong",
      "Tengyu Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02326"
  },
  {
    "id": "arXiv:2206.02327",
    "title": "JigsawHSI: a network for Hyperspectral Image classification",
    "abstract": "This article describes the performance of JigsawHSI,a convolutional neural\nnetwork (CNN) based on Inception but tailored for geoscientific analyses, on\nclassification with the Indian Pines, Pavia University and Salinas\nhyperspectral image data sets. The network is compared against HybridSN, a\nspectral-spatial 3D-CNN followed by 2D-CNN that achieves state-of-the-art\nresults in the datasets. This short article proves that JigsawHSI is able to\nmeet or exceed HybridSN performance in all three cases. Additionally, the code\nand toolkit are made available.",
    "descriptor": "\nComments: 5 pages, 3 figures, not peer reviewed\n",
    "authors": [
      "Jaime Moraga",
      "H. Sebnem Duzgun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.02327"
  },
  {
    "id": "arXiv:2206.02330",
    "title": "Linear MSRD codes with Different Matrix Sizes",
    "abstract": "A sum-rank-metric code attaining the Singleton bound is called maximum\nsum-rank distance (MSRD). MSRD codes have applications in space-time coding and\nconstruction of partial-MDS codes for repair in distributed storage. MSRD codes\nhave been constructed in some parameter cases. In this paper we construct a\n${\\bf F}_q$-linear MSRD code over some field ${\\bf F}_q$ with different matrix\nsizes $n_1>n_2>\\cdots>n_t$ satisfying $n_i \\geq n_{i+1}^2+\\cdots+n_t^2$ for\n$i=1, 2, \\ldots, t-1$ for any given minimum sum-rank distance. Many good linear\nsum-rank-metric codes over small fields with such different matrix sizes are\ngiven. A lower bound on the dimensions of constructed ${\\bf F}_{q^2}$-linear\nsum-rank-metric codes over ${\\bf F}_{q^2}$ with such different matrix sizes and\ngiven minimum sum-rank distances is also presented.",
    "descriptor": "\nComments: 17 pages. arXiv admin note: text overlap with arXiv:2205.13087\n",
    "authors": [
      "Hao Chen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.02330"
  },
  {
    "id": "arXiv:2206.02331",
    "title": "MASNet:Improve Performance of Siamese Networks with Mutual-attention for  Remote Sensing Change Detection Tasks",
    "abstract": "Siamese networks are widely used for remote sensing change detection tasks. A\nvanilla siamese network has two identical feature extraction branches which\nshare weights, these two branches work independently and the feature maps are\nnot fused until about to be sent to a decoder head. However we find that it is\ncritical to exchange information between two feature extraction branches at\nearly stage for change detection task. In this work we present Mutual-Attention\nSiamese Network (MASNet), a general siamese network with mutual-attention\nplug-in, so to exchange information between the two feature extraction\nbranches. We show that our modification improve the performance of siamese\nnetworks on multi change detection datasets, and it works for both\nconvolutional neural network and visual transformer.",
    "descriptor": "\nComments: XXIV ISPRS Congress\n",
    "authors": [
      "Hongbin Zhou",
      "Yupeng Ren",
      "Qiankun Li",
      "Jun Yin",
      "Yonggang Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02331"
  },
  {
    "id": "arXiv:2206.02332",
    "title": "Effects of Augmented-Reality-Based Assisting Interfaces on Drivers'  Object-wise Situational Awareness in Highly Autonomous Vehicles",
    "abstract": "Although partially autonomous driving (AD) systems are already available in\nproduction vehicles, drivers are still required to maintain a sufficient level\nof situational awareness (SA) during driving. Previous studies have shown that\nproviding information about the AD's capability using user interfaces can\nimprove the driver's SA. However, displaying too much information increases the\ndriver's workload and can distract or overwhelm the driver. Therefore, to\ndesign an efficient user interface (UI), it is necessary to understand its\neffect under different circumstances. In this paper, we focus on a UI based on\naugmented reality (AR), which can highlight potential hazards on the road. To\nunderstand the effect of highlighting on drivers' SA for objects with different\ntypes and locations under various traffic densities, we conducted an in-person\nexperiment with 20 participants on a driving simulator. Our study results show\nthat the effects of highlighting on drivers' SA varied by traffic densities,\nobject locations and object types. We believe our study can provide guidance in\nselecting which object to highlight for the AR-based driver-assistance\ninterface to optimize SA for drivers driving and monitoring partially\nautonomous vehicles.",
    "descriptor": "\nComments: 10 pages, 11 figures, IV 2022\n",
    "authors": [
      "Xiaofeng Gao",
      "Xingwei Wu",
      "Samson Ho",
      "Teruhisa Misu",
      "Kumar Akash"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.02332"
  },
  {
    "id": "arXiv:2206.02334",
    "title": "Hashing Learning with Hyper-Class Representation",
    "abstract": "Existing unsupervised hash learning is a kind of attribute-centered\ncalculation. It may not accurately preserve the similarity between data. This\nleads to low down the performance of hash function learning. In this paper, a\nhash algorithm is proposed with a hyper-class representation. It is a two-steps\napproach. The first step finds potential decision features and establish\nhyper-class. The second step constructs hash learning based on the hyper-class\ninformation in the first step, so that the hash codes of the data within the\nhyper-class are as similar as possible, as well as the hash codes of the data\nbetween the hyper-classes are as different as possible. To evaluate the\nefficiency, a series of experiments are conducted on four public datasets. The\nexperimental results show that the proposed hash algorithm is more efficient\nthan the compared algorithms, in terms of mean average precision (MAP), average\nprecision (AP) and Hamming radius 2 (HAM2)",
    "descriptor": "",
    "authors": [
      "Shichao Zhang",
      "Jiaye Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02334"
  },
  {
    "id": "arXiv:2206.02336",
    "title": "On the Advance of Making Language Models Better Reasoners",
    "abstract": "Large language models such as GPT-3 and PaLM have shown remarkable\nperformance in few-shot learning. However, they still struggle with reasoning\ntasks such as the arithmetic benchmark GSM8K. Recent advances deliberately\nguide the language model to generate a chain of reasoning steps before\nproducing the final answer, successfully boosting the GSM8K benchmark from\n17.9% to 58.1% in terms of problem solving rate. In this paper, we propose a\nnew approach, DiVeRSe (Diverse Verifier on Reasoning Step), to further advance\ntheir reasoning capability. DiVeRSe first explores different prompts to enhance\nthe diversity in reasoning paths. Second, DiVeRSe introduces a verifier to\ndistinguish good answers from bad answers for a better weighted voting.\nFinally, DiVeRSe verifies the correctness of each single step rather than all\nthe steps in a whole. We conduct extensive experiments using the latest\nlanguage model code-davinci-002 and demonstrate that DiVeRSe can achieve new\nstate-of-the-art performance on six out of eight reasoning benchmarks (e.g.,\nGSM8K 74.4% to 83.2%), outperforming the PaLM model with 540B parameters.",
    "descriptor": "",
    "authors": [
      "Yifei Li",
      "Zeqi Lin",
      "Shizhuo Zhang",
      "Qiang Fu",
      "Bei Chen",
      "Jian-Guang Lou",
      "Weizhu Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02336"
  },
  {
    "id": "arXiv:2206.02338",
    "title": "OrdinalCLIP: Learning Rank Prompts for Language-Guided Ordinal  Regression",
    "abstract": "This paper presents a language-powered paradigm for ordinal regression.\nExisting methods usually treat each rank as a category and employ a set of\nweights to learn these concepts. These methods are easy to overfit and usually\nattain unsatisfactory performance as the learned concepts are mainly derived\nfrom the training set. Recent large pre-trained vision-language models like\nCLIP have shown impressive performance on various visual tasks. In this paper,\nwe propose to learn the rank concepts from the rich semantic CLIP latent space.\nSpecifically, we reformulate this task as an image-language matching problem\nwith a contrastive objective, which regards labels as text and obtains a\nlanguage prototype from a text encoder for each rank. While prompt engineering\nfor CLIP is extremely time-consuming, we propose OrdinalCLIP, a differentiable\nprompting method for adapting CLIP for ordinal regression. OrdinalCLIP consists\nof learnable context tokens and learnable rank embeddings; The learnable rank\nembeddings are constructed by explicitly modeling numerical continuity,\nresulting in well-ordered, compact language prototypes in the CLIP space. Once\nlearned, we can only save the language prototypes and discard the huge language\nmodel, resulting in zero additional computational overhead compared with the\nlinear head counterpart. Experimental results show that our paradigm achieves\ncompetitive performance in general ordinal regression tasks, and gains\nimprovements in few-shot and distribution shift settings for age estimation.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Wanhua Li",
      "Xiaoke Huang",
      "Zheng Zhu",
      "Yansong Tang",
      "Xiu Li",
      "Jiwen Lu",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02338"
  },
  {
    "id": "arXiv:2206.02341",
    "title": "Complex Locomotion Skill Learning via Differentiable Physics",
    "abstract": "Differentiable physics enables efficient gradient-based optimizations of\nneural network (NN) controllers. However, existing work typically only delivers\nNN controllers with limited capability and generalizability. We present a\npractical learning framework that outputs unified NN controllers capable of\ntasks with significantly improved complexity and diversity. To systematically\nimprove training robustness and efficiency, we investigated a suite of\nimprovements over the baseline approach, including periodic activation\nfunctions, and tailored loss functions. In addition, we find our adoption of\nbatching and an Adam optimizer effective in training complex locomotion tasks.\nWe evaluate our framework on differentiable mass-spring and material point\nmethod (MPM) simulations, with challenging locomotion tasks and multiple robot\ndesigns. Experiments show that our learning framework, based on differentiable\nphysics, delivers better results than reinforcement learning and converges much\nfaster. We demonstrate that users can interactively control soft robot\nlocomotion and switch among multiple goals with specified velocity, height, and\ndirection instructions using a unified NN controller trained in our system.",
    "descriptor": "",
    "authors": [
      "Yu Fang",
      "Jiancheng Liu",
      "Mingrui Zhang",
      "Jiasheng Zhang",
      "Yidong Ma",
      "Minchen Li",
      "Yuanming Hu",
      "Chenfanfu Jiang",
      "Tiantian Liu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02341"
  },
  {
    "id": "arXiv:2206.02342",
    "title": "WHU-Stereo: A Challenging Benchmark for Stereo Matching of  High-Resolution Satellite Images",
    "abstract": "Stereo matching of high-resolution satellite images (HRSI) is still a\nfundamental but challenging task in the field of photogrammetry and remote\nsensing. Recently, deep learning (DL) methods, especially convolutional neural\nnetworks (CNNs), have demonstrated tremendous potential for stereo matching on\npublic benchmark datasets. However, datasets for stereo matching of satellite\nimages are scarce. To facilitate further research, this paper creates and\npublishes a challenging dataset, termed WHU-Stereo, for stereo matching DL\nnetwork training and testing. This dataset is created by using airborne LiDAR\npoint clouds and high-resolution stereo imageries taken from the Chinese\nGaoFen-7 satellite (GF-7). The WHU-Stereo dataset contains more than 1700\nepipolar rectified image pairs, which cover six areas in China and includes\nvarious kinds of landscapes. We have assessed the accuracy of ground-truth\ndisparity maps, and it is proved that our dataset achieves comparable precision\ncompared with existing state-of-the-art stereo matching datasets. To verify its\nfeasibility, in experiments, the hand-crafted SGM stereo matching algorithm and\nrecent deep learning networks have been tested on the WHU-Stereo dataset.\nExperimental results show that deep learning networks can be well trained and\nachieves higher performance than hand-crafted SGM algorithm, and the dataset\nhas great potential in remote sensing application. The WHU-Stereo dataset can\nserve as a challenging benchmark for stereo matching of high-resolution\nsatellite images, and performance evaluation of deep learning models. Our\ndataset is available at https://github.com/Sheng029/WHU-Stereo",
    "descriptor": "",
    "authors": [
      "Shenhong Li",
      "Sheng He",
      "San Jiang",
      "Wanshou Jiang",
      "Lin Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02342"
  },
  {
    "id": "arXiv:2206.02343",
    "title": "Contrastive Graph Multimodal Model for Text Classification in Videos",
    "abstract": "The extraction of text information in videos serves as a critical step\ntowards semantic understanding of videos. It usually involved in two steps: (1)\ntext recognition and (2) text classification. To localize texts in videos, we\ncan resort to large numbers of text recognition methods based on OCR\ntechnology. However, to our knowledge, there is no existing work focused on the\nsecond step of video text classification, which will limit the guidance to\ndownstream tasks such as video indexing and browsing. In this paper, we are the\nfirst to address this new task of video text classification by fusing\nmultimodal information to deal with the challenging scenario where different\ntypes of video texts may be confused with various colors, unknown fonts and\ncomplex layouts. In addition, we tailor a specific module called CorrelationNet\nto reinforce feature representation by explicitly extracting layout\ninformation. Furthermore, contrastive learning is utilized to explore inherent\nconnections between samples using plentiful unlabeled videos. Finally, we\nconstruct a new well-defined industrial dataset from the news domain, called\nTI-News, which is dedicated to building and evaluating video text recognition\nand classification applications. Extensive experiments on TI-News demonstrate\nthe effectiveness of our method.",
    "descriptor": "",
    "authors": [
      "Ye Liu",
      "Changchong Lu",
      "Chen Lin",
      "Di Yin",
      "Bo Ren"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02343"
  },
  {
    "id": "arXiv:2206.02344",
    "title": "Decentralized, Communication- and Coordination-free Learning in  Structured Matching Markets",
    "abstract": "We study the problem of online learning in competitive settings in the\ncontext of two-sided matching markets. In particular, one side of the market,\nthe agents, must learn about their preferences over the other side, the firms,\nthrough repeated interaction while competing with other agents for successful\nmatches. We propose a class of decentralized, communication- and\ncoordination-free algorithms that agents can use to reach to their stable match\nin structured matching markets. In contrast to prior works, the proposed\nalgorithms make decisions based solely on an agent's own history of play and\nrequires no foreknowledge of the firms' preferences. Our algorithms are\nconstructed by splitting up the statistical problem of learning one's\npreferences, from noisy observations, from the problem of competing for firms.\nWe show that under realistic structural assumptions on the underlying\npreferences of the agents and firms, the proposed algorithms incur a regret\nwhich grows at most logarithmically in the time horizon. Our results show that,\nin the case of matching markets, competition need not drastically affect the\nperformance of decentralized, communication and coordination free online\nlearning algorithms.",
    "descriptor": "\nComments: 41 pages, 2 figures\n",
    "authors": [
      "Chinmay Maheshwari",
      "Eric Mazumdar",
      "Shankar Sastry"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2206.02344"
  },
  {
    "id": "arXiv:2206.02345",
    "title": "Anomaly Detection with Test Time Augmentation and Consistency Evaluation",
    "abstract": "Deep neural networks are known to be vulnerable to unseen data: they may\nwrongly assign high confidence stcores to out-distribuion samples. Recent works\ntry to solve the problem using representation learning methods and specific\nmetrics. In this paper, we propose a simple, yet effective post-hoc anomaly\ndetection algorithm named Test Time Augmentation Anomaly Detection (TTA-AD),\ninspired by a novel observation. Specifically, we observe that in-distribution\ndata enjoy more consistent predictions for its original and augmented versions\non a trained network than out-distribution data, which separates\nin-distribution and out-distribution samples. Experiments on various\nhigh-resolution image benchmark datasets demonstrate that TTA-AD achieves\ncomparable or better detection performance under dataset-vs-dataset anomaly\ndetection settings with a 60%~90\\% running time reduction of existing\nclassifier-based algorithms. We provide empirical verification that the key to\nTTA-AD lies in the remaining classes between augmented features, which has long\nbeen partially ignored by previous works. Additionally, we use RUNS as a\nsurrogate to analyze our algorithm theoretically.",
    "descriptor": "",
    "authors": [
      "Haowei He",
      "Jiaye Teng",
      "Yang Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02345"
  },
  {
    "id": "arXiv:2206.02349",
    "title": "Invariant Grounding for Video Question Answering",
    "abstract": "Video Question Answering (VideoQA) is the task of answering questions about a\nvideo. At its core is understanding the alignments between visual scenes in\nvideo and linguistic semantics in question to yield the answer. In leading\nVideoQA models, the typical learning objective, empirical risk minimization\n(ERM), latches on superficial correlations between video-question pairs and\nanswers as the alignments. However, ERM can be problematic, because it tends to\nover-exploit the spurious correlations between question-irrelevant scenes and\nanswers, instead of inspecting the causal effect of question-critical scenes.\nAs a result, the VideoQA models suffer from unreliable reasoning. In this work,\nwe first take a causal look at VideoQA and argue that invariant grounding is\nthe key to ruling out the spurious correlations. Towards this end, we propose a\nnew learning framework, Invariant Grounding for VideoQA (IGV), to ground the\nquestion-critical scene, whose causal relations with answers are invariant\nacross different interventions on the complement. With IGV, the VideoQA models\nare forced to shield the answering process from the negative influence of\nspurious correlations, which significantly improves the reasoning ability.\nExperiments on three benchmark datasets validate the superiority of IGV in\nterms of accuracy, visual explainability, and generalization ability over the\nleading baselines.",
    "descriptor": "\nComments: CVPR2022 Oral\n",
    "authors": [
      "Yicong Li",
      "Xiang Wang",
      "Junbin Xiao",
      "Wei Ji",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02349"
  },
  {
    "id": "arXiv:2206.02350",
    "title": "Modeling the Material-Inventory Transportation Problem Using  Multi-Objective Optimization",
    "abstract": "In the era of industry 4.0, procurement in supply chain management is the key\nto developing information management systems. It directly affects production\nplanning failure. In this case, it is the process to prepare and confirming the\nmaterial inventory is in the ordinal stages and be able to produce the products\nin any production line. In terms of industrial informatics, it can provide\ninformation management approaches for leveraging data sharing between\nfactories. The multiobjective optimization will be enabled by integrating\nmaterial inventory, production planning and monitoring, and transportation\nplanning collaboration. The material-inventory transportation problem is the\nvirtual factory situation when production plan failure occurs. It becomes the\ncost to transport material between each factory and the distribution to\nclients. In this study, the question of the material-inventory transportation\nproblem is: How can we transport other materials from one factory into another\nfactory? This study proposed a model to find out about the adjustment of\nmaterial inventory through transportation. The objective of this model is to\nminimize the whole production cost and total transportation cost.",
    "descriptor": "\nComments: 4 pages, submitted to the SICE Annual Conference 2020\n",
    "authors": [
      "Issarapong Khuankrue",
      "Sudchai Boonto",
      "Yasuhiro Tsujimura"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.02350"
  },
  {
    "id": "arXiv:2206.02353",
    "title": "Beyond Just Vision: A Review on Self-Supervised Representation Learning  on Multimodal and Temporal Data",
    "abstract": "Recently, Self-Supervised Representation Learning (SSRL) has attracted much\nattention in the field of computer vision, speech, natural language processing\n(NLP), and recently, with other types of modalities, including time series from\nsensors. The popularity of self-supervised learning is driven by the fact that\ntraditional models typically require a huge amount of well-annotated data for\ntraining. Acquiring annotated data can be a difficult and costly process.\nSelf-supervised methods have been introduced to improve the efficiency of\ntraining data through discriminative pre-training of models using supervisory\nsignals that have been freely obtained from the raw data. Unlike existing\nreviews of SSRL that have pre-dominately focused upon methods in the fields of\nCV or NLP for a single data mode, we aim to provide the first comprehensive\nreview of multimodal self-supervised learning methods for temporal data. To\nthis end, we 1) provide a comprehensive categorization of existing SSRL\nmethods, 2) introduce a generic pipeline by defining the key components of a\nSSRL framework, 3) compare existing models in terms of their objective\nfunction, network architecture and potential applications, and 4) review\nexisting multimodal techniques in each category and various modalities.\nFinally, we present existing weaknesses and future opportunities. We believe\nour work develops a perspective on the requirements of SSRL in domains that\nutilise multimodal and/or temporal data",
    "descriptor": "\nComments: 36 pages, 5 figures, 9 tables, Survey paper\n",
    "authors": [
      "Shohreh Deldari",
      "Hao Xue",
      "Aaqib Saeed",
      "Jiayuan He",
      "Daniel V. Smith",
      "Flora D. Salim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02353"
  },
  {
    "id": "arXiv:2206.02355",
    "title": "Relation Matters: Foreground-aware Graph-based Relational Reasoning for  Domain Adaptive Object Detection",
    "abstract": "Domain Adaptive Object Detection (DAOD) focuses on improving the\ngeneralization ability of object detectors via knowledge transfer. Recent\nadvances in DAOD strive to change the emphasis of the adaptation process from\nglobal to local in virtue of fine-grained feature alignment methods. However,\nboth the global and local alignment approaches fail to capture the topological\nrelations among different foreground objects as the explicit dependencies and\ninteractions between and within domains are neglected. In this case, only\nseeking one-vs-one alignment does not necessarily ensure the precise knowledge\ntransfer. Moreover, conventional alignment-based approaches may be vulnerable\nto catastrophic overfitting regarding those less transferable regions (e.g.\nbackgrounds) due to the accumulation of inaccurate localization results in the\ntarget domain. To remedy these issues, we first formulate DAOD as an open-set\ndomain adaptation problem, in which the foregrounds and backgrounds are seen as\nthe ``known classes'' and ``unknown class'' respectively. Accordingly, we\npropose a new and general framework for DAOD, named Foreground-aware\nGraph-based Relational Reasoning (FGRR), which incorporates graph structures\ninto the detection pipeline to explicitly model the intra- and inter-domain\nforeground object relations on both pixel and semantic spaces, thereby endowing\nthe DAOD model with the capability of relational reasoning beyond the popular\nalignment-based paradigm. The inter-domain visual and semantic correlations are\nhierarchically modeled via bipartite graph structures, and the intra-domain\nrelations are encoded via graph attention mechanisms. Empirical results\ndemonstrate that the proposed FGRR exceeds the state-of-the-art performance on\nfour DAOD benchmarks.",
    "descriptor": "\nComments: Accepted by IEEE T-PAMI\n",
    "authors": [
      "Chaoqi Chen",
      "Jiongcheng Li",
      "Hong-Yu Zhou",
      "Xiaoguang Han",
      "Yue Huang",
      "Xinghao Ding",
      "Yizhou Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02355"
  },
  {
    "id": "arXiv:2206.02359",
    "title": "An inverse random source problem for the Helium production-diffusion  equation driven by a fractional Brownian motion",
    "abstract": "In this paper, we consider the prediction of the helium concentrations as\nfunction of a spatially variable source term perturbed by fractional Brownian\nmotion. For the direct problem, we show that it is well-posed and has a unique\nmild solution under some conditions. For the inverse problem, the uniqueness\nand the instability are given. In the meanwhile, we determine the statistical\nproperties of the source from the expectation and covariance of the final-time\ndata u(r,T). Finally, numerical implements are given to verify the\neffectiveness of the proposed reconstruction.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2101.04744 by other authors\n",
    "authors": [
      "Jing Li",
      "Hao Cheng",
      "Xiaoxiao Geng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.02359"
  },
  {
    "id": "arXiv:2206.02361",
    "title": "Neural-inspired Measurement Observability",
    "abstract": "The neural encoding by biological sensors of flying insects, which prefilters\nstimulus data before sending it to the central nervous system in the form of\nvoltage spikes, enables sensing capabilities that are computationally low-cost\nwhile also being highly robust to noise. This process, which can be modeled as\nthe composition of a linear moving average filter and a nonlinear decision\nfunction, inspired the work reported here to improve engineered sensing\nperformance by maximizing the observability of particular neural-inspired\ncomposite measurement functions. We first present a tool to determine the\nobservability of a linear system with measurement delay (the first element of\nthe composition), then use a Lie algebraic observability approach to study\nnonlinear autonomous systems with output delay (the second element of the\ncomposition). The Lie algebraic tools are then extended to address overall\nobservability of systems with composite outputs as in the neural encoder model\nwe adopt. The analytical outcomes are supported using the empirical\nobservability Gramian, and optimal sensor placement on a bioinspired wing model\nis performed using metrics based on the empirical Gramian.",
    "descriptor": "\nComments: 18 pages, 7 figures\n",
    "authors": [
      "Burak Boyac\u0131o\u011flu",
      "Alice C. Schwarze",
      "Bingni W. Brunton",
      "Kristi A. Morgansen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.02361"
  },
  {
    "id": "arXiv:2206.02363",
    "title": "Knowledge-based Document Classification with Shannon Entropy",
    "abstract": "Document classification is the detection specific content of interest in text\ndocuments. In contrast to the data-driven machine learning classifiers,\nknowledge-based classifiers can be constructed based on domain specific\nknowledge, which usually takes the form of a collection of subject related\nkeywords. While typical knowledge-based classifiers compute a prediction score\nbased on the keyword abundance, it generally suffers from noisy detections due\nto the lack of guiding principle in gauging the keyword matches. In this paper,\nwe propose a novel knowledge-based model equipped with Shannon Entropy, which\nmeasures the richness of information and favors uniform and diverse keyword\nmatches. Without invoking any positive sample, such method provides a simple\nand explainable solution for document classification. We show that the Shannon\nEntropy significantly improves the recall at fixed level of false positive\nrate. Also, we show that the model is more robust against change of data\ndistribution at inference while compared with traditional machine learning,\nparticularly when the positive training samples are very limited.",
    "descriptor": "",
    "authors": [
      "AtMa P.O. Chan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.02363"
  },
  {
    "id": "arXiv:2206.02366",
    "title": "Scan2Part: Fine-grained and Hierarchical Part-level Understanding of  Real-World 3D Scans",
    "abstract": "We propose Scan2Part, a method to segment individual parts of objects in\nreal-world, noisy indoor RGB-D scans. To this end, we vary the part hierarchies\nof objects in indoor scenes and explore their effect on scene understanding\nmodels. Specifically, we use a sparse U-Net-based architecture that captures\nthe fine-scale detail of the underlying 3D scan geometry by leveraging a\nmulti-scale feature hierarchy. In order to train our method, we introduce the\nScan2Part dataset, which is the first large-scale collection providing detailed\nsemantic labels at the part level in the real-world setting. In total, we\nprovide 242,081 correspondences between 53,618 PartNet parts of 2,477 ShapeNet\nobjects and 1,506 ScanNet scenes, at two spatial resolutions of 2 cm$^3$ and 5\ncm$^3$. As output, we are able to predict fine-grained per-object part labels,\neven when the geometry is coarse or partially missing.",
    "descriptor": "\nComments: In Proceedings of the 17th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications\n",
    "authors": [
      "Alexandr Notchenko",
      "Vladislav Ishimtsev",
      "Alexey Artemov",
      "Vadim Selyutin",
      "Emil Bogomolov",
      "Evgeny Burnaev"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02366"
  },
  {
    "id": "arXiv:2206.02367",
    "title": "Subtitle-based Viewport Prediction for 360-degree Virtual Tourism Video",
    "abstract": "360-degree streaming videos can provide a rich immersive experiences to the\nusers. However, it requires an extremely high bandwidth network. One of the\ncommon solutions for saving bandwidth consumption is to stream only a portion\nof video covered by the user's viewport. To do that, the user's viewpoint\nprediction is indispensable. In existing viewport prediction methods, they\nmainly concentrate on the user's head movement trajectory and video saliency.\nNone of them consider navigation information contained in the video, which can\nturn the attention of the user to specific regions in the video with high\nprobability. Such information can be included in video subtitles, especially\nthe one in 360-degree virtual tourism videos. This fact reveals the potential\ncontribution of video subtitles to viewport prediction. Therefore, in this\npaper, a subtitle-based viewport prediction model for 360-degree virtual\ntourism videos is proposed. This model leverages the navigation information in\nthe video subtitles in addition to head movement trajectory and video saliency,\nto improve the prediction accuracy. The experimental results demonstrate that\nthe proposed model outperforms baseline methods which only use head movement\ntrajectory and video saliency for viewport prediction.",
    "descriptor": "",
    "authors": [
      "Chuanzhe Jing",
      "Tho Nguyen Duc",
      "Phan Xuan Tan",
      "Eiji Kamioka"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2206.02367"
  },
  {
    "id": "arXiv:2206.02368",
    "title": "Bi-SimCut: A Simple Strategy for Boosting Neural Machine Translation",
    "abstract": "We introduce Bi-SimCut: a simple but effective training strategy to boost\nneural machine translation (NMT) performance. It consists of two procedures:\nbidirectional pretraining and unidirectional finetuning. Both procedures\nutilize SimCut, a simple regularization method that forces the consistency\nbetween the output distributions of the original and the cutoff sentence pairs.\nWithout leveraging extra dataset via back-translation or integrating\nlarge-scale pretrained model, Bi-SimCut achieves strong translation performance\nacross five translation benchmarks (data sizes range from 160K to 20.2M): BLEU\nscores of 31.16 for en -> de and 38.37 for de -> en on the IWSLT14 dataset,\n30.78 for en -> de and 35.15 for de -> en on the WMT14 dataset, and 27.17 for\nzh -> en on the WMT17 dataset. SimCut is not a new method, but a version of\nCutoff (Shen et al., 2020) simplified and adapted for NMT, and it could be\nconsidered as a perturbation-based method. Given the universality and\nsimplicity of SimCut and Bi-SimCut, we believe they can serve as strong\nbaselines for future NMT research.",
    "descriptor": "",
    "authors": [
      "Pengzhi Gao",
      "Zhongjun He",
      "Hua Wu",
      "Haifeng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02368"
  },
  {
    "id": "arXiv:2206.02369",
    "title": "Learning to Break the Loop: Analyzing and Mitigating Repetitions for  Neural Text Generation",
    "abstract": "While large-scale neural language models, such as GPT2 and BART, have\nachieved impressive results on various text generation tasks, they tend to get\nstuck in undesirable sentence-level loops with maximization-based decoding\nalgorithms (\\textit{e.g.}, greedy search). This phenomenon is counter-intuitive\nsince there are few consecutive sentence-level repetitions in human corpora\n(e.g., 0.02\\% in Wikitext-103). To investigate the underlying reasons for\ngenerating consecutive sentence-level repetitions, we study the relationship\nbetween the probabilities of the repetitive tokens and their previous\nrepetitions in the context. Through our quantitative experiments, we find that\n1) Language models have a preference to repeat the previous sentence; 2) The\nsentence-level repetitions have a \\textit{self-reinforcement effect}: the more\ntimes a sentence is repeated in the context, the higher the probability of\ncontinuing to generate that sentence; 3) The sentences with higher initial\nprobabilities usually have a stronger self-reinforcement effect. Motivated by\nour findings, we propose a simple and effective training method \\textbf{DITTO}\n(Pseu\\underline{D}o-Repet\\underline{IT}ion\nPenaliza\\underline{T}i\\underline{O}n), where the model learns to penalize\nprobabilities of sentence-level repetitions from pseudo repetitive data.\nAlthough our method is motivated by mitigating repetitions, experiments show\nthat DITTO not only mitigates the repetition issue without sacrificing\nperplexity, but also achieves better generation quality. Extensive experiments\non open-ended text generation (Wikitext-103) and text summarization\n(CNN/DailyMail) demonstrate the generality and effectiveness of our method.",
    "descriptor": "",
    "authors": [
      "Jin Xu",
      "Xiaojiang Liu",
      "Jianhao Yan",
      "Deng Cai",
      "Huayang Li",
      "Jian Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.02369"
  },
  {
    "id": "arXiv:2206.02371",
    "title": "Markovian Interference in Experiments",
    "abstract": "We consider experiments in dynamical systems where interventions on some\nexperimental units impact other units through a limiting constraint (such as a\nlimited inventory). Despite outsize practical importance, the best estimators\nfor this `Markovian' interference problem are largely heuristic in nature, and\ntheir bias is not well understood. We formalize the problem of inference in\nsuch experiments as one of policy evaluation. Off-policy estimators, while\nunbiased, apparently incur a large penalty in variance relative to\nstate-of-the-art heuristics. We introduce an on-policy estimator: the\nDifferences-In-Q's (DQ) estimator. We show that the DQ estimator can in general\nhave exponentially smaller variance than off-policy evaluation. At the same\ntime, its bias is second order in the impact of the intervention. This yields a\nstriking bias-variance tradeoff so that the DQ estimator effectively dominates\nstate-of-the-art alternatives. From a theoretical perspective, we introduce\nthree separate novel techniques that are of independent interest in the theory\nof Reinforcement Learning (RL). Our empirical evaluation includes a set of\nexperiments on a city-scale ride-hailing simulator.",
    "descriptor": "",
    "authors": [
      "Vivek F. Farias",
      "Andrew A. Li",
      "Tianyi Peng",
      "Andrew T. Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.02371"
  },
  {
    "id": "arXiv:2206.02373",
    "title": "Sports Re-ID: Improving Re-Identification Of Players In Broadcast Videos  Of Team Sports",
    "abstract": "This work focuses on player re-identification in broadcast videos of team\nsports. Specifically, we focus on identifying the same player in images\ncaptured from different camera viewpoints during any given moment of a match.\nThis task differs from traditional applications of person re-id in a few\nimportant ways. Firstly, players from the same team wear highly similar\nclothes, thereby making it harder to tell them apart. Secondly, there are only\na few number of samples for each identity, which makes it harder to train a\nre-id system. Thirdly, the resolutions of the images are often quite low and\nvary a lot. This combined with heavy occlusions and fast movements of players\ngreatly increase the challenges for re-id. In this paper, we propose a simple\nbut effective hierarchical data sampling procedure and a centroid loss function\nthat, when used together, increase the mean average precision (mAP) by 7 - 11.5\nand the rank-1 (R1) by 8.8 - 14.9 without any change in the network or\nhyper-parameters used. Our data sampling procedure improves the similarity of\nthe training and test distributions, and thereby aids in creating better\nestimates of the centroids of the embeddings (or feature vectors).\nSurprisingly, our study shows that in the presence of severely limited data, as\nis the case for our application, a simple centroid loss function based on\neuclidean distances significantly outperforms the popular triplet-centroid loss\nfunction. We show comparable improvements for both convolutional networks and\nvision transformers. Our approach is among the top ranked methods in the\nSoccerNet Re-Identification Challenge 2022 leaderboard (test-split) with a mAP\nof 86.0 and a R1 of 81.5. On the sequestered challenge split, we achieve an mAP\nof 84.9 and a R1 of 80.1. Research on re-id for sports-related applications is\nvery limited and our work presents one of the first discussions in the\nliterature on this.",
    "descriptor": "",
    "authors": [
      "Bharath Comandur"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02373"
  },
  {
    "id": "arXiv:2206.02374",
    "title": "CorticalFlow: A Diffeomorphic Mesh Deformation Module for Cortical  Surface Reconstruction",
    "abstract": "In this paper we introduce CorticalFlow, a new geometric deep-learning model\nthat, given a 3-dimensional image, learns to deform a reference template\ntowards a targeted object. To conserve the template mesh's topological\nproperties, we train our model over a set of diffeomorphic transformations.\nThis new implementation of a flow Ordinary Differential Equation (ODE)\nframework benefits from a small GPU memory footprint, allowing the generation\nof surfaces with several hundred thousand vertices. To reduce topological\nerrors introduced by its discrete resolution, we derive numeric conditions\nwhich improve the manifoldness of the predicted triangle mesh. To exhibit the\nutility of CorticalFlow, we demonstrate its performance for the challenging\ntask of brain cortical surface reconstruction. In contrast to current\nstate-of-the-art, CorticalFlow produces superior surfaces while reducing the\ncomputation time from nine and a half minutes to one second. More\nsignificantly, CorticalFlow enforces the generation of anatomically plausible\nsurfaces; the absence of which has been a major impediment restricting the\nclinical relevance of such surface reconstruction methods.",
    "descriptor": "",
    "authors": [
      "L\u00e9o Lebrat",
      "Rodrigo Santa Cruz",
      "Fr\u00e9d\u00e9ric de Gournay",
      "Darren Fu",
      "Pierrick Bourgeat",
      "Jurgen Fripp",
      "Clinton Fookes",
      "Olivier Salvado"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02374"
  },
  {
    "id": "arXiv:2206.02377",
    "title": "Bayesian intrinsic groupwise registration via explicit hierarchical  disentanglement",
    "abstract": "Previous methods on multimodal groupwise registration typically require\ncertain highly specialized similarity metrics with restrained applicability. In\nthis work, we instead propose a general framework which formulates groupwise\nregistration as a procedure of hierarchical Bayesian inference. Here, the\nimaging process of multimodal medical images, including shape transition and\nappearance variation, is characterized by a disentangled variational\nauto-encoder. To this end, we propose a novel variational posterior and network\narchitecture that facilitate joint learning of the common structural\nrepresentation and the desired spatial correspondences. The performance of the\nproposed model was validated on two publicly available multimodal datasets,\ni.e., BrainWeb and MS-CMR of the heart. Results have demonstrated the efficacy\nof our framework in realizing multimodal groupwise registration in an\nend-to-end fashion.",
    "descriptor": "",
    "authors": [
      "Xin Wang",
      "Xinzhe Luo",
      "Xiahai Zhuang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02377"
  },
  {
    "id": "arXiv:2206.02380",
    "title": "Adaptive Rollout Length for Model-Based RL using Model-Free Deep RL",
    "abstract": "Model-based reinforcement learning promises to learn an optimal policy from\nfewer interactions with the environment compared to model-free reinforcement\nlearning by learning an intermediate model of the environment in order to\npredict future interactions. When predicting a sequence of interactions, the\nrollout length, which limits the prediction horizon, is a critical\nhyperparameter as accuracy of the predictions diminishes in the regions that\nare further away from real experience. As a result, with a longer rollout\nlength, an overall worse policy is learned in the long run. Thus, the\nhyperparameter provides a trade-off between quality and efficiency. In this\nwork, we frame the problem of tuning the rollout length as a meta-level\nsequential decision-making problem that optimizes the final policy learned by\nmodel-based reinforcement learning given a fixed budget of environment\ninteractions by adapting the hyperparameter dynamically based on feedback from\nthe learning process, such as accuracy of the model and the remaining budget of\ninteractions. We use model-free deep reinforcement learning to solve the\nmeta-level decision problem and demonstrate that our approach outperforms\ncommon heuristic baselines on two well-known reinforcement learning\nenvironments.",
    "descriptor": "",
    "authors": [
      "Abhinav Bhatia",
      "Philip S. Thomas",
      "Shlomo Zilberstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02380"
  },
  {
    "id": "arXiv:2206.02383",
    "title": "Efficient Minimax Optimal Global Optimization of Lipschitz Continuous  Multivariate Functions",
    "abstract": "In this work, we propose an efficient minimax optimal global optimization\nalgorithm for multivariate Lipschitz continuous functions. To evaluate the\nperformance of our approach, we utilize the average regret instead of the\ntraditional simple regret, which, as we show, is not suitable for use in the\nmultivariate non-convex optimization because of the inherent hardness of the\nproblem itself. Since we study the average regret of the algorithm, our results\ndirectly imply a bound for the simple regret as well. Instead of constructing\nlower bounding proxy functions, our method utilizes a predetermined query\ncreation rule, which makes it computationally superior to the Piyavskii-Shubert\nvariants. We show that our algorithm achieves an average regret bound of\n$O(L\\sqrt{n}T^{-\\frac{1}{n}})$ for the optimization of an $n$-dimensional\n$L$-Lipschitz continuous objective in a time horizon $T$, which we show to be\nminimax optimal.",
    "descriptor": "",
    "authors": [
      "Kaan Gokcesu",
      "Hakan Gokcesu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Complexity (cs.CC)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.02383"
  },
  {
    "id": "arXiv:2206.02384",
    "title": "Towards Practical Privacy-Preserving Solution for Outsourced Neural  Network Inference",
    "abstract": "When neural network model and data are outsourced to cloud server for\ninference, it is desired to preserve the confidentiality of model and data as\nthe involved parties (i.e., cloud server, model providing client and data\nproviding client) may not trust mutually. Solutions were proposed based on\nmulti-party computation, trusted execution environment (TEE) and leveled or\nfully homomorphic encryption (LHE/FHE), but their limitations hamper practical\napplication. We propose a new framework based on synergistic integration of LHE\nand TEE, which enables collaboration among mutually-untrusted three parties,\nwhile minimizing the involvement of (relatively) resource-constrained TEE and\nallowing the full utilization of the untrusted but more resource-rich part of\nserver. We also propose a generic and efficient LHE-based inference scheme as\nan important performance-determining component of the framework. We\nimplemented/evaluated the proposed system on a moderate platform and show that,\nour proposed scheme is more applicable/scalable to various settings, and has\nbetter performance, compared to the state-of-the-art LHE-based solutions.",
    "descriptor": "",
    "authors": [
      "Pinglan Liu",
      "Wensheng Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.02384"
  },
  {
    "id": "arXiv:2206.02385",
    "title": "On Hamiltonian-Connected and Mycielski graphs",
    "abstract": "A graph $G$ is Hamiltonian-connected if there exists a Hamiltonian path\nbetween any two vertices of $G$. It is known that if $G$ is 2-connected then\nthe graph $G^2$ is Hamiltonian-connected. In this paper we prove that the\nsquare of every self-complementary graph of order grater than 4 is\nHamiltonian-connected. If $G$ is a $k$-critical graph, then we prove that the\nMycielski graph $\\mu(G)$ is $(k+1)$-critical graph. Jarnicki et al.[7] proved\nthat for every Hamiltonian graph of odd order, the Mycielski graph $\\mu(G)$ of\n$G$ is Hamiltonian-connected. They also pose a conjecture that if $G$ is\nHamiltonian-connected and not $K_2$ then $\\mu(G)$ is Hamiltonian-connected. In\nthis paper we also prove this conjecture.",
    "descriptor": "",
    "authors": [
      "Ashok Kumar Das",
      "Indrajit Paul"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2206.02385"
  },
  {
    "id": "arXiv:2206.02386",
    "title": "Restructuring Graph for Higher Homophily via Learnable Spectral  Clustering",
    "abstract": "While a growing body of literature has been studying new Graph Neural\nNetworks (GNNs) that work on both homophilic and heterophilic graphs, little\nwork has been done on adapting classical GNNs to less-homophilic graphs.\nAlthough lacking the ability to work with less-homophilic graphs, classical\nGNNs still stand out in some properties such as efficiency, simplicity and\nexplainability. We propose a novel graph restructuring method to maximize the\nbenefit of prevalent GNNs with the homophilic assumption. Our contribution is\nthreefold: a) learning the weight of pseudo-eigenvectors for an adaptive\nspectral clustering that aligns well with known node labels, b) proposing a new\nhomophilic metric that measures how two nodes with the same label are likely to\nbe connected, and c) reconstructing the adjacency matrix based on the result of\nadaptive spectral clustering to maximize the homophilic scores. The\nexperimental results show that our graph restructuring method can significantly\nboost the performance of six classical GNNs by an average of 25% on\nless-homophilic graphs. The boosted performance is comparable to\nstate-of-the-art methods.",
    "descriptor": "\nComments: 17 pages, 8 figures\n",
    "authors": [
      "Shouheng Li",
      "Dongwoo Kim",
      "Qing Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.02386"
  },
  {
    "id": "arXiv:2206.02389",
    "title": "A sentiment analysis model for car review texts based on adversarial  training and whole word mask BERT",
    "abstract": "In the field of car evaluation, more and more netizens choose to express\ntheir opinions on the Internet platform, and these comments will affect the\ndecision-making of buyers and the trend of car word-of-mouth. As an important\nbranch of natural language processing (NLP), sentiment analysis provides an\neffective research method for analyzing the sentiment types of massive car\nreview texts. However, due to the lexical professionalism and large text noise\nof review texts in the automotive field, when a general sentiment analysis\nmodel is applied to car reviews, the accuracy of the model will be poor. To\novercome these above challenges, we aim at the sentiment analysis task of car\nreview texts. From the perspective of word vectors, pre-training is carried out\nby means of whole word mask of proprietary vocabulary in the automotive field,\nand then training data is carried out through the strategy of an adversarial\ntraining set. Based on this, we propose a car review text sentiment analysis\nmodel based on adversarial training and whole word mask BERT(ATWWM-BERT).",
    "descriptor": "",
    "authors": [
      "Xingchen Liu",
      "Yawen Li",
      "Yingxia Shao",
      "Ang Li",
      "Jian Liang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.02389"
  },
  {
    "id": "arXiv:2206.02391",
    "title": "Automated Circuit Sizing with Multi-objective Optimization based on  Differential Evolution and Bayesian Inference",
    "abstract": "With the ever increasing complexity of specifications, manual sizing for\nanalog circuits recently became very challenging. Especially for innovative,\nlarge-scale circuits designs, with tens of design variables, operating\nconditions and conflicting objectives to be optimized, design engineers spend\nmany weeks, running time-consuming simulations, in their attempt at finding the\nright configuration. Recent years brought machine learning and optimization\ntechniques to the field of analog circuits design, with evolutionary algorithms\nand Bayesian models showing good results for circuit sizing. In this context,\nwe introduce a design optimization method based on Generalized Differential\nEvolution 3 (GDE3) and Gaussian Processes (GPs). The proposed method is able to\nperform sizing for complex circuits with a large number of design variables and\nmany conflicting objectives to be optimized. While state-of-the-art methods\nreduce multi-objective problems to single-objective optimization and\npotentially induce a prior bias, we search directly over the multi-objective\nspace using Pareto dominance and ensure that diverse solutions are provided to\nthe designers to choose from. To the best of our knowledge, the proposed method\nis the first to specifically address the diversity of the solutions, while also\nfocusing on minimizing the number of simulations required to reach feasible\nconfigurations. We evaluate the introduced method on two voltage regulators\nshowing different levels of complexity and we highlight that the proposed\ninnovative candidate selection method and survival policy leads to obtaining\nfeasible solutions, with a high degree of diversity, much faster than with GDE3\nor Bayesian Optimization-based algorithms.",
    "descriptor": "\nComments: 48 pages, 13 figures, submitted to Knowledge Based Systems\n",
    "authors": [
      "Catalin Visan",
      "Octavian Pascu",
      "Marius Stanescu",
      "Elena-Diana Sandru",
      "Cristian Diaconu",
      "Andi Buzo",
      "Georg Pelz",
      "Horia Cucu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02391"
  },
  {
    "id": "arXiv:2206.02392",
    "title": "Semi-Supervised Segmentation of Mitochondria from Electron Microscopy  Images Using Spatial Continuity",
    "abstract": "Morphology of mitochondria plays critical roles in mediating their\nphysiological functions. Accurate segmentation of mitochondria from 3D electron\nmicroscopy (EM) images is essential to quantitative characterization of their\nmorphology at the nanometer scale. Fully supervised deep learning models\ndeveloped for this task achieve excellent performance but require substantial\namounts of annotated data for training. However, manual annotation of EM images\nis laborious and time-consuming because of their large volumes, limited\ncontrast, and low signal-to-noise ratios (SNRs). To overcome this challenge, we\npropose a semi-supervised deep learning model that segments mitochondria by\nleveraging the spatial continuity of their structural, morphological, and\ncontextual information in both labeled and unlabeled images. We use random\npiecewise affine transformation to synthesize comprehensive and realistic\nmitochondrial morphology for augmentation of training data. Experiments on the\nEPFL dataset show that our model achieves performance similar as that of\nstate-of-the-art fully supervised models but requires only ~20% of their\nannotated training data. Our semi-supervised model is versatile and can also\naccurately segment other spatially continuous structures from EM images. Data\nand code of this study are openly accessible at\nhttps://github.com/cbmi-group/MPP.",
    "descriptor": "\nComments: 4 pages of main text, 5 pages of supplementary material and 1 page of references\n",
    "authors": [
      "Yunpeng Xiao",
      "Youpeng Zhao",
      "Ge Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02392"
  },
  {
    "id": "arXiv:2206.02394",
    "title": "An Estimation Framework for Passerby Engagement Interacting with Social  Robots",
    "abstract": "Social robots are expected to be a human labor support technology, and one\napplication of them is an advertising medium in public spaces. When social\nrobots provide information, such as recommended shops, adaptive communication\naccording to the user's state is desired. User engagement, which is also\ndefined as the level of interest in the robot, is likely to play an important\nrole in adaptive communication. Therefore, in this paper, we propose a new\nframework to estimate user engagement. The proposed method focuses on four\nunsolved open problems: multi-party interactions, process of state change in\nengagement, difficulty in annotating engagement, and interaction dataset in the\nreal world. The accuracy of the proposed method for estimating engagement was\nevaluated using interaction duration. The results show that the interaction\nduration can be accurately estimated by considering the influence of the\nbehaviors of other people; this also implies that the proposed model accurately\nestimates the level of engagement during interaction with the robot.",
    "descriptor": "",
    "authors": [
      "Taichi Sakaguchi",
      "Yuki Okafuji",
      "Kohei Matsumura",
      "Jun Baba",
      "Junya Nakanishi"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.02394"
  },
  {
    "id": "arXiv:2206.02396",
    "title": "Large $k$-gons in a 1.5D Terrain",
    "abstract": "Given is a 1.5D terrain $\\mathcal{T}$, i.e., an $x$-monotone polygonal chain\nin $\\mathbb{R}^2$. For a given $2\\le k\\le n$, our objective is to approximate\nthe largest area or perimeter convex polygon of exactly or at most $k$ vertices\ninside $\\mathcal{T}$. For a constant $k>3$, we design an FPTAS that efficiently\napproximates the largest convex polygons with at most $k$ vertices, within a\nfactor $(1-\\epsilon)$. For the case where $k=2$, we design an $O(n)$ time exact\nalgorithm for computing the longest line segment in $\\mathcal{T}$, and for\n$k=3$, we design an $O(n \\log n)$ time exact algorithm for computing the\nlargest-perimeter triangle that lies within $\\mathcal{T}$.",
    "descriptor": "",
    "authors": [
      "Vahideh Keikha"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2206.02396"
  },
  {
    "id": "arXiv:2206.02404",
    "title": "A Simple yet Effective Method for Graph Classification",
    "abstract": "In deep neural networks, better results can often be obtained by increasing\nthe complexity of previously developed basic models. However, it is unclear\nwhether there is a way to boost performance by decreasing the complexity of\nsuch models. Intuitively, given a problem, a simpler data structure comes with\na simpler algorithm. Here, we investigate the feasibility of improving graph\nclassification performance while simplifying the learning process. Inspired by\nstructural entropy on graphs, we transform the data sample from graphs to\ncoding trees, which is a simpler but essential structure for graph data.\nFurthermore, we propose a novel message passing scheme, termed hierarchical\nreporting, in which features are transferred from leaf nodes to root nodes by\nfollowing the hierarchical structure of coding trees. We then present a tree\nkernel and a convolutional network to implement our scheme for graph\nclassification. With the designed message passing scheme, the tree kernel and\nconvolutional network have a lower runtime complexity of $O(n)$ than\nWeisfeiler-Lehman subtree kernel and other graph neural networks of at least\n$O(hm)$. We empirically validate our methods with several graph classification\nbenchmarks and demonstrate that they achieve better performance and lower\ncomputational consumption than competing approaches.",
    "descriptor": "\nComments: Accepted by IJCAI2022. arXiv admin note: substantial text overlap with arXiv:2109.02027\n",
    "authors": [
      "Junran Wu",
      "Shangzhe Li",
      "Jianhao Li",
      "Yicheng Pan",
      "Ke Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02404"
  },
  {
    "id": "arXiv:2206.02405",
    "title": "Robust Image Protection Countering Cropping Manipulation",
    "abstract": "Image cropping is an inexpensive and effective operation of maliciously\naltering image contents. Existing cropping detection mechanisms analyze the\nfundamental traces of image cropping, for example, chromatic aberration and\nvignetting to uncover cropping attack, yet fragile to common post-processing\nattacks which deceive forensics by removing such cues. Besides, they ignore the\nfact that recovering the cropped-out contents can unveil the purpose of the\nbehaved cropping attack. This paper presents a novel robust watermarking scheme\nfor image Cropping Localization and Recovery (CLR-Net). We first protect the\noriginal image by introducing imperceptible perturbations. Then, typical image\npost-processing attacks are simulated to erode the protected image. On the\nrecipient's side, we predict the cropping mask and recover the original image.\nWe propose two plug-and-play networks to improve the real-world robustness of\nCLR-Net, namely, the Fine-Grained generative JPEG simulator (FG-JPEG) and the\nSiamese image pre-processing network. To the best of our knowledge, we are the\nfirst to address the combined challenge of image cropping localization and\nentire image recovery from a fragment. Experiments demonstrate that CLR-Net can\naccurately localize the cropping as well as recover the details of the\ncropped-out regions with both high quality and fidelity, despite of the\npresence of image processing attacks of varied types.",
    "descriptor": "",
    "authors": [
      "Qichao Ying",
      "Hang Zhou",
      "Zhenxing Qian",
      "Sheng Li",
      "Xinpeng Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.02405"
  },
  {
    "id": "arXiv:2206.02407",
    "title": "Green Interference Based Symbiotic Security in Integrated  Satellite-terrestrial Communications",
    "abstract": "In this paper, we investigate secure transmissions in integrated\nsatellite-terrestrial communications and the green interference based symbiotic\nsecurity scheme is proposed. Particularly, the co-channel interference induced\nby the spectrum sharing between satellite and terrestrial networks and the\ninter-beam interference due to frequency reuse among satellite multi-beam serve\nas the green interference to assist the symbiotic secure transmission, where\nthe secure transmissions of both satellite and terrestrial links are guaranteed\nsimultaneously. Specifically, to realize the symbiotic security, we formulate a\nproblem to maximize the sum secrecy rate of satellite users by cooperatively\nbeamforming optimizing and a constraint of secrecy rate of each terrestrial\nuser is guaranteed. Since the formulated problem is non-convex and intractable,\nthe Taylor expansion and semi-definite relaxation (SDR) are adopted to further\nreformulate this problem, and the successive convex approximation (SCA)\nalgorithm is designed to solve it. Finally, the tightness of the relaxation is\nproved. In addition, numerical results verify the efficiency of our proposed\napproach.",
    "descriptor": "",
    "authors": [
      "Zhisheng Yin",
      "Nan Cheng",
      "Tom H.Luan",
      "Yilong Hui",
      "Wei Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.02407"
  },
  {
    "id": "arXiv:2206.02409",
    "title": "Is More Data All You Need? A Causal Exploration",
    "abstract": "Curating a large scale medical imaging dataset for machine learning\napplications is both time consuming and expensive. Balancing the workload\nbetween model development, data collection and annotations is difficult for\nmachine learning practitioners, especially under time constraints. Causal\nanalysis is often used in medicine and economics to gain insights about the\neffects of actions and policies. In this paper we explore the effect of dataset\ninterventions on the output of image classification models. Through a causal\napproach we investigate the effects of the quantity and type of data we need to\nincorporate in a dataset to achieve better performance for specific subtasks.\nThe main goal of this paper is to highlight the potential of causal analysis as\na tool for resource optimization for developing medical imaging ML\napplications. We explore this concept with a synthetic dataset and an exemplary\nuse-case for Diabetic Retinopathy image analysis.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Athanasios Vlontzos",
      "Hadrien Reynaud",
      "Bernhard Kainz"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.02409"
  },
  {
    "id": "arXiv:2206.02410",
    "title": "CARE: Resource Allocation Using Sparse Communication",
    "abstract": "We propose a new framework for studying effective resource allocation in a\nload balancing system under sparse communication, a problem that arises, for\ninstance, in data centers. At the core of our approach is state approximation,\nwhere the load balancer first estimates the servers' states via a carefully\ndesigned communication protocol, and subsequently feeds the said approximated\nstate into a load balancing algorithm to generate a routing decision.\nSpecifically, we show that by using a novel approximation algorithm and\nserver-side-adaptive communication protocol, the load balancer can obtain good\nqueue-length approximations using a communication frequency that decays\nquadratically in the maximum approximation error. Furthermore, using a\ndiffusion-scaled analysis, we prove that the load balancer achieves\nasymptotically optimal performance whenever the approximation error scales at a\nlower rate than the square-root of the total processing capacity, which\nincludes as a special case constant-error approximations. Using simulations, we\nfind that the proposed policies achieve performance that matches or outperforms\nthe state-of-the-art load balancing algorithms while reducing communication\nrates by as much as 90%. Taken as a whole, our results demonstrate that it is\npossible to achieve good performance even under very sparse communication, and\nprovide strong evidence that approximate states serve as a robust and powerful\ninformation intermediary for designing communication-efficient load balancing\nsystems.",
    "descriptor": "",
    "authors": [
      "Gal Mendelson",
      "Kuang Xu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.02410"
  },
  {
    "id": "arXiv:2206.02417",
    "title": "Fast Adversarial Training with Adaptive Step Size",
    "abstract": "While adversarial training and its variants have shown to be the most\neffective algorithms to defend against adversarial attacks, their extremely\nslow training process makes it hard to scale to large datasets like ImageNet.\nThe key idea of recent works to accelerate adversarial training is to\nsubstitute multi-step attacks (e.g., PGD) with single-step attacks (e.g.,\nFGSM). However, these single-step methods suffer from catastrophic overfitting,\nwhere the accuracy against PGD attack suddenly drops to nearly 0% during\ntraining, destroying the robustness of the networks. In this work, we study the\nphenomenon from the perspective of training instances. We show that\ncatastrophic overfitting is instance-dependent and fitting instances with\nlarger gradient norm is more likely to cause catastrophic overfitting. Based on\nour findings, we propose a simple but effective method, Adversarial Training\nwith Adaptive Step size (ATAS). ATAS learns an instancewise adaptive step size\nthat is inversely proportional to its gradient norm. The theoretical analysis\nshows that ATAS converges faster than the commonly adopted non-adaptive\ncounterparts. Empirically, ATAS consistently mitigates catastrophic overfitting\nand achieves higher robust accuracy on CIFAR10, CIFAR100 and ImageNet when\nevaluated on various adversarial budgets.",
    "descriptor": "",
    "authors": [
      "Zhichao Huang",
      "Yanbo Fan",
      "Chen Liu",
      "Weizhong Zhang",
      "Yong Zhang",
      "Mathieu Salzmann",
      "Sabine S\u00fcsstrunk",
      "Jue Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02417"
  },
  {
    "id": "arXiv:2206.02419",
    "title": "Towards Responsible AI for Financial Transactions",
    "abstract": "The application of AI in finance is increasingly dependent on the principles\nof responsible AI. These principles - explainability, fairness, privacy,\naccountability, transparency and soundness form the basis for trust in future\nAI systems. In this study, we address the first principle by providing an\nexplanation for a deep neural network that is trained on a mixture of\nnumerical, categorical and textual inputs for financial transaction\nclassification. The explanation is achieved through (1) a feature importance\nanalysis using Shapley additive explanations (SHAP) and (2) a hybrid approach\nof text clustering and decision tree classifiers. We then test the robustness\nof the model by exposing it to a targeted evasion attack, leveraging the\nknowledge we gained about the model through the extracted explanation.",
    "descriptor": "",
    "authors": [
      "Charl Maree",
      "Jan Erik Modal",
      "Christian W. Omlin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02419"
  },
  {
    "id": "arXiv:2206.02421",
    "title": "MorisienMT: A Dataset for Mauritian Creole Machine Translation",
    "abstract": "In this paper, we describe MorisienMT, a dataset for benchmarking machine\ntranslation quality of Mauritian Creole. Mauritian Creole (Morisien) is the\nlingua franca of the Republic of Mauritius and is a French-based creole\nlanguage. MorisienMT consists of a parallel corpus between English and\nMorisien, French and Morisien and a monolingual corpus for Morisien. We first\ngive an overview of Morisien and then describe the steps taken to create the\ncorpora and, from it, the training and evaluation splits. Thereafter, we\nestablish a variety of baseline models using the created parallel corpora as\nwell as large French--English corpora for transfer learning. We release our\ndatasets publicly for research purposes and hope that this spurs research for\nMorisien machine translation.",
    "descriptor": "\nComments: Work in progress! (obviously) Dataset is here: this https URL\n",
    "authors": [
      "Raj Dabre",
      "Aneerav Sukhoo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.02421"
  },
  {
    "id": "arXiv:2206.02422",
    "title": "Ego Network Structure in Online Social Networks and its Impact on  Information Diffusion",
    "abstract": "In the last few years, Online Social Networks (OSNs) attracted the interest\nof a large number of researchers, thanks to their central role in the society.\nThrough the analysis of OSNs, many social phenomena have been studied, such as\nthe viral diffusion of information amongst people. What is still unclear is the\nrelation between micro-level structural properties of OSNs (i.e. the properties\nof the personal networks of the users, also known as ego networks) and the\nemergence of such phenomena. A better knowledge of this relation could be\nessential for the creation of services for the Future Internet, such as highly\npersonalised advertisements fitted on users' needs and characteristics. In this\npaper, we contribute to bridge this gap by analysing the ego networks of a\nlarge sample of Facebook and Twitter users. Our results indicate that\nmicro-level structural properties of OSNs are interestingly similar to those\nfound in social networks formed offline. In particular, online ego networks\nshow the same structure found offline, with social contacts arranged in layers\nwith compatible size and composition. From the analysis of Twitter ego\nnetworks, we have been able to find a direct impact of tie strength and ego\nnetwork circles on the diffusion of information in the network. Specifically,\nthere is a high correlation between the frequency of direct contact between\nusers and her friends in Twitter (a proxy for tie strength), and the frequency\nof retweets made by the users from tweets generated by their friends. We\nanalysed the correlation for each ego network layer identified in Twitter,\ndiscovering their role in the diffusion of information.",
    "descriptor": "",
    "authors": [
      "Valerio Arnaboldi",
      "Marco Conti",
      "Massimiliano La Gala",
      "Andrea Passarella",
      "Fabio Pezzoni"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.02422"
  },
  {
    "id": "arXiv:2206.02423",
    "title": "Evaluating the Predictive Performance of Positive-Unlabelled  Classifiers: a brief critical review and practical recommendations for  improvement",
    "abstract": "Positive-Unlabelled (PU) learning is a growing area of machine learning that\naims to learn classifiers from data consisting of labelled positive and\nunlabelled instances. Whilst much work has been done proposing methods for PU\nlearning, little has been written on the subject of evaluating these methods.\nMany popular standard classification metrics cannot be precisely calculated due\nto the absence of fully labelled data, so alternative approaches must be taken.\nThis short commentary paper critically reviews the main PU learning evaluation\napproaches and the choice of predictive accuracy measures in 51 articles\nproposing PU classifiers and provides practical recommendations for\nimprovements in this area.",
    "descriptor": "",
    "authors": [
      "Jack D. Saunders",
      "Alex",
      "A. Freitas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.02423"
  },
  {
    "id": "arXiv:2206.02424",
    "title": "Slim-neck by GSConv: A better design paradigm of detector architectures  for autonomous vehicles",
    "abstract": "Object detection is a difficult downstream task in computer vision. For the\non-board edge computing platforms, a giant model is difficult to achieve the\nreal-time detection requirement. And, a lightweight model built from a large\nnumber of the depth-wise separable convolutional layers cannot achieve the\nsufficient accuracy. We introduce a new method, GSConv, to lighten the model\nbut maintain the accuracy. The GSConv balances the model's accuracy and speed\nbetter. And, we provide a design paradigm, slim-neck, to achieve a higher\ncomputational cost-effectiveness of the detectors. In experiments, our method\nobtains state-of-the-art results (e.g. 70.9% mAP0.5 for the SO-DA10M at a speed\nof ~100FPS on a Tesla T4) compared with the original networks. Code will be\nopen source.",
    "descriptor": "\nComments: 10 pages, 11 figures\n",
    "authors": [
      "Hulin Li",
      "Jun Li",
      "Hanbing Wei",
      "Zheng Liu",
      "Zhenfei Zhan",
      "Qiliang Ren"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02424"
  },
  {
    "id": "arXiv:2206.02428",
    "title": "Domain-specific Language Pre-training for Dialogue Comprehension on  Clinical Inquiry-Answering Conversations",
    "abstract": "There is growing interest in the automated extraction of relevant information\nfrom clinical dialogues. However, it is difficult to collect and construct\nlarge annotated resources for clinical dialogue tasks. Recent developments in\nnatural language processing suggest that large-scale pre-trained language\nbackbones could be leveraged for such machine comprehension and information\nextraction tasks. Yet, due to the gap between pre-training and downstream\nclinical domains, it remains challenging to exploit the generic backbones for\ndomain-specific applications. Therefore, in this work, we propose a\ndomain-specific language pre-training, to improve performance on downstream\ntasks like dialogue comprehension. Aside from the common token-level masking\npre-training method, according to the nature of human conversations and\ninteractive flow of multi-topic inquiry-answering dialogues, we further propose\nsample generation strategies with speaker and utterance manipulation. The\nconversational pre-training guides the language backbone to reconstruct the\nutterances coherently based on the remaining context, thus bridging the gap\nbetween general and specific domains. Experiments are conducted on a clinical\nconversation dataset for symptom checking, where nurses inquire and discuss\nsymptom information with patients. We empirically show that the neural model\nwith our proposed approach brings improvement in the dialogue comprehension\ntask, and can achieve favorable results in the low resource training scenario.",
    "descriptor": "\nComments: W3PHIAI-2022\n",
    "authors": [
      "Zhengyuan Liu",
      "Pavitra Krishnaswamy",
      "Nancy F. Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.02428"
  },
  {
    "id": "arXiv:2206.02433",
    "title": "Continuous and Distribution-free Probabilistic Wind Power Forecasting: A  Conditional Normalizing Flow Approach",
    "abstract": "We present a data-driven approach for probabilistic wind power forecasting\nbased on conditional normalizing flow (CNF). In contrast with the existing,\nthis approach is distribution-free (as for non-parametric and quantile-based\napproaches) and can directly yield continuous probability densities, hence\navoiding quantile crossing. It relies on a base distribution and a set of\nbijective mappings. Both the shape parameters of the base distribution and the\nbijective mappings are approximated with neural networks. Spline-based\nconditional normalizing flow is considered owing to its non-affine\ncharacteristics. Over the training phase, the model sequentially maps input\nexamples onto samples of base distribution, given the conditional contexts,\nwhere parameters are estimated through maximum likelihood. To issue\nprobabilistic forecasts, one eventually maps samples of the base distribution\ninto samples of a desired distribution. Case studies based on open datasets\nvalidate the effectiveness of the proposed model, and allows us to discuss its\nadvantages and caveats with respect to the state of the art.",
    "descriptor": "\nComments: The second revision to IEEE Transactions on Sustainable Energy\n",
    "authors": [
      "Honglin Wen",
      "Pierre Pinson",
      "Jinghuan Ma",
      "Jie Gu",
      "Zhijian Jin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2206.02433"
  },
  {
    "id": "arXiv:2206.02436",
    "title": "Detecting Interlocutor Confusion in Situated Human-Avatar Dialogue: A  Pilot Study",
    "abstract": "In order to enhance levels of engagement with conversational systems, our\nlong term research goal seeks to monitor the confusion state of a user and\nadapt dialogue policies in response to such user confusion states. To this end,\nin this paper, we present our initial research centred on a user-avatar\ndialogue scenario that we have developed to study the manifestation of\nconfusion and in the long term its mitigation. We present a new definition of\nconfusion that is particularly tailored to the requirements of intelligent\nconversational system development for task-oriented dialogue. We also present\nthe details of our Wizard-of-Oz based data collection scenario wherein users\ninteracted with a conversational avatar and were presented with stimuli that\nwere in some cases designed to invoke a confused state in the user. Post study\nanalysis of this data is also presented. Here, three pre-trained deep learning\nmodels were deployed to estimate base emotion, head pose and eye gaze. Despite\na small pilot study group, our analysis demonstrates a significant relationship\nbetween these indicators and confusion states. We understand this as a useful\nstep forward in the automated analysis of the pragmatics of dialogue.",
    "descriptor": "\nComments: 8 figures, 10pages including 2pages reference. Conference: this https URL, Paper link:this https URL\n",
    "authors": [
      "Na Li",
      "John D. Kelleher",
      "Robert Ross"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02436"
  },
  {
    "id": "arXiv:2206.02437",
    "title": "Information-theoretic Inducing Point Placement for High-throughput  Bayesian Optimisation",
    "abstract": "Sparse Gaussian Processes are a key component of high-throughput Bayesian\noptimisation (BO) loops -- an increasingly common setting where evaluation\nbudgets are large and highly parallelised. By using representative subsets of\nthe available data to build approximate posteriors, sparse models dramatically\nreduce the computational costs of surrogate modelling by relying on a small set\nof pseudo-observations, the so-called inducing points, in lieu of the full data\nset. However, current approaches to design inducing points are not appropriate\nwithin BO loops as they seek to reduce global uncertainty in the objective\nfunction. Thus, the high-fidelity modelling of promising and data-dense regions\nrequired for precise optimisation is sacrificed and computational resources are\ninstead wasted on modelling areas of the space already known to be sub-optimal.\nInspired by entropy-based BO methods, we propose a novel inducing point design\nthat uses a principled information-theoretic criterion to select inducing\npoints. By choosing inducing points to maximally reduce both global uncertainty\nand uncertainty in the maximum value of the objective function, we build\nsurrogate models able to support high-precision high-throughput BO.",
    "descriptor": "",
    "authors": [
      "Henry B. Moss",
      "Sebastian W. Ober",
      "Victor Picheny"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.02437"
  },
  {
    "id": "arXiv:2206.02440",
    "title": "A computational psycholinguistic evaluation of the syntactic abilities  of Galician BERT models at the interface of dependency resolution and  training time",
    "abstract": "This paper explores the ability of Transformer models to capture subject-verb\nand noun-adjective agreement dependencies in Galician. We conduct a series of\nword prediction experiments in which we manipulate dependency length together\nwith the presence of an attractor noun that acts as a lure. First, we evaluate\nthe overall performance of the existing monolingual and multilingual models for\nGalician. Secondly, to observe the effects of the training process, we compare\nthe different degrees of achievement of two monolingual BERT models at\ndifferent training points. We also release their checkpoints and propose an\nalternative evaluation metric. Our results confirm previous findings by similar\nworks that use the agreement prediction task and provide interesting insights\ninto the number of training steps required by a Transformer model to solve\nlong-distance dependencies.",
    "descriptor": "\nComments: Accepted in the journal Procesamiento del Lenguaje Natural (69)\n",
    "authors": [
      "Iria de-Dios-Flores",
      "Marcos Garcia"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.02440"
  },
  {
    "id": "arXiv:2206.02443",
    "title": "Spam Detection Using BERT",
    "abstract": "Emails and SMSs are the most popular tools in today communications, and as\nthe increase of emails and SMSs users are increase, the number of spams is also\nincreases. Spam is any kind of unwanted, unsolicited digital communication that\ngets sent out in bulk, spam emails and SMSs are causing major resource wastage\nby unnecessarily flooding the network links. Although most spam mail originate\nwith advertisers looking to push their products, some are much more malicious\nin their intent like phishing emails that aims to trick victims into giving up\nsensitive information like website logins or credit card information this type\nof cybercrime is known as phishing. To countermeasure spams, many researches\nand efforts are done to build spam detectors that are able to filter out\nmessages and emails as spam or ham. In this research we build a spam detector\nusing BERT pre-trained model that classifies emails and messages by\nunderstanding to their context, and we trained our spam detector model using\nmultiple corpuses like SMS collection corpus, Enron corpus, SpamAssassin\ncorpus, Ling-Spam corpus and SMS spam collection corpus, our spam detector\nperformance was 98.62%, 97.83%, 99.13% and 99.28% respectively. Keywords: Spam\nDetector, BERT, Machine learning, NLP, Transformer, Enron Corpus, SpamAssassin\nCorpus, SMS Spam Detection Corpus, Ling-Spam Corpus.",
    "descriptor": "\nComments: 6 pages, 8 figures and 2 tabels\n",
    "authors": [
      "Thaer Sahmoud",
      "Dr. Mohammad Mikki"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02443"
  },
  {
    "id": "arXiv:2206.02445",
    "title": "A ghost perturbation scheme to solve ordinary differential equations",
    "abstract": "We propose an algebraic method that finds a sequence of functions that\nexponentially approach the solution of any second-order ordinary differential\nequation (ODE) with any boundary conditions. We define an extended ODE (eODE)\ncomposed of a linear generic differential operator that depends on free\nparameters, $p$, plus an $\\epsilon$ perturbation formed by the original ODE\nminus the same linear term. After the eODE's formal $\\epsilon$ expansion of the\nsolution, we can solve order by order a hierarchy of linear ODEs, and we get a\nsequence of functions $y_n(x;\\epsilon,p)$ where $n$ indicates the number of\nterms that we keep in the $\\epsilon$-expansion. We fix the parameters to the\noptimal values $p^*(n)$ by minimizing a distance function of $y_n$ to the ODE's\nsolution, $y$, over a given $x$-interval. We see that the eODE's perturbative\nsolution converges exponentially fast in $n$ to the ODE solution when\n$\\epsilon=1$: $\\vert y_n(x;\\epsilon=1,p^*(n))-y(x)\\vert<C\\delta^{n+1}$ with\n$\\delta<1$. The method permits knowing the number of solutions for Boundary\nValue Problems just by looking at the number of minima of the distance function\nat each order in $n$, $p^{*,\\alpha}(n)$, where each $\\alpha$ defines a sequence\nof functions $y_n$ that converges to one of the ODE's solutions. We present the\nmethod by its application to several cases where we discuss its properties,\nbenefits and shortcomings, and some practical algorithmic improvements.",
    "descriptor": "\nComments: 57 pages and 68 figures\n",
    "authors": [
      "Pedro L. Garrido"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.02445"
  },
  {
    "id": "arXiv:2206.02447",
    "title": "Model predictive eco-driving control for heavy-duty trucks using Branch  and Bound optimization",
    "abstract": "Eco-driving (ED) can be used for fuel savings in existing vehicles, requiring\nonly a few hardware modifications. For this technology to be successful in a\ndynamic environment, ED requires an online real-time implementable policy. In\nthis work, a dedicated Branch and Bound (BnB) model predictive control (MPC)\nalgorithm is proposed to solve the optimization part of an ED optimal control\nproblem. The developed MPC solution for ED is based on the following\ningredients. As a prediction model, the velocity dynamics as a function of\ndistance is modeled by a finite number of driving modes and gear positions.\nThen we formulate an optimization problem that minimizes a cost function with\ntwo terms: one penalizing the fuel consumption and one penalizing the trip\nduration. We exploit contextual elements and use a warm-started solution to\nmake the BnB solver run in real-time. The results are evaluated in numerical\nsimulations on two routes in Israel and France and the long haul cycle of the\nVehicle Energy consumption Calculation Tool (VECTO). In comparison with a human\ndriver and a Pontryagin's Minimum Principle (PMP) solution, 25.8% and 12.9%\nfuel savings, respectively, are achieved on average.",
    "descriptor": "",
    "authors": [
      "B. Wingelaar",
      "G. R. Gon\u00e7alves da Silva",
      "M. Lazar"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.02447"
  },
  {
    "id": "arXiv:2206.02450",
    "title": "Optimization-based Block Coordinate Gradient Coding for Mitigating  Partial Stragglers in Distributed Learning",
    "abstract": "Gradient coding schemes effectively mitigate full stragglers in distributed\nlearning by introducing identical redundancy in coded local partial derivatives\ncorresponding to all model parameters. However, they are no longer effective\nfor partial stragglers as they cannot utilize incomplete computation results\nfrom partial stragglers. This paper aims to design a new gradient coding scheme\nfor mitigating partial stragglers in distributed learning. Specifically, we\nconsider a distributed system consisting of one master and N workers,\ncharacterized by a general partial straggler model and focuses on solving a\ngeneral large-scale machine learning problem with L model parameters using\ngradient coding. First, we propose a coordinate gradient coding scheme with L\ncoding parameters representing L possibly different diversities for the L\ncoordinates, which generates most gradient coding schemes. Then, we consider\nthe minimization of the expected overall runtime and the maximization of the\ncompletion probability with respect to the L coding parameters for coordinates,\nwhich are challenging discrete optimization problems. To reduce computational\ncomplexity, we first transform each to an equivalent but much simpler discrete\nproblem with N\\llL variables representing the partition of the L coordinates\ninto N blocks, each with identical redundancy. This indicates an equivalent but\nmore easily implemented block coordinate gradient coding scheme with N coding\nparameters for blocks. Then, we adopt continuous relaxation to further reduce\ncomputational complexity. For the resulting minimization of expected overall\nruntime, we develop an iterative algorithm of computational complexity O(N^2)\nto obtain an optimal solution and derive two closed-form approximate solutions\nboth with computational complexity O(N). For the resultant maximization of the\ncompletion probability, we develop an iterative algorithm of...",
    "descriptor": "\nComments: 16 pages, 7 figures, submitted to IEEE Trans. Signal Process. arXiv admin note: text overlap with arXiv:2109.08933\n",
    "authors": [
      "Qi Wang",
      "Ying Cui",
      "Chenglin Li",
      "Junni Zou",
      "Hongkai Xiong"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02450"
  },
  {
    "id": "arXiv:2206.02452",
    "title": "Universal Photometric Stereo Network using Global Lighting Contexts",
    "abstract": "This paper tackles a new photometric stereo task, named universal photometric\nstereo. Unlike existing tasks that assumed specific physical lighting models;\nhence, drastically limited their usability, a solution algorithm of this task\nis supposed to work for objects with diverse shapes and materials under\narbitrary lighting variations without assuming any specific models. To solve\nthis extremely challenging task, we present a purely data-driven method, which\neliminates the prior assumption of lighting by replacing the recovery of\nphysical lighting parameters with the extraction of the generic lighting\nrepresentation, named global lighting contexts. We use them like lighting\nparameters in a calibrated photometric stereo network to recover surface normal\nvectors pixelwisely. To adapt our network to a wide variety of shapes,\nmaterials and lightings, it is trained on a new synthetic dataset which\nsimulates the appearance of objects in the wild. Our method is compared with\nother state-of-the-art uncalibrated photometric stereo methods on our test data\nto demonstrate the significance of our method.",
    "descriptor": "\nComments: Accepted to CVPR2022. Code and Dataset at this https URL\n",
    "authors": [
      "Satoshi Ikehata"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.02452"
  },
  {
    "id": "arXiv:2206.02454",
    "title": "Why do CNNs Learn Consistent Representations in their First Layer  Independent of Labels and Architecture?",
    "abstract": "It has previously been observed that the filters learned in the first layer\nof a CNN are qualitatively similar for different networks and tasks. We extend\nthis finding and show a high quantitative similarity between filters learned by\ndifferent networks. We consider the CNN filters as a filter bank and measure\nthe sensitivity of the filter bank to different frequencies. We show that the\nsensitivity profile of different networks is almost identical, yet far from\ninitialization. Remarkably, we show that it remains the same even when the\nnetwork is trained with random labels. To understand this effect, we derive an\nanalytic formula for the sensitivity of the filters in the first layer of a\nlinear CNN. We prove that when the average patch in images of the two classes\nis identical, the sensitivity profile of the filters in the first layer will be\nidentical in expectation when using the true labels or random labels and will\nonly depend on the second-order statistics of image patches. We empirically\ndemonstrate that the average patch assumption holds for realistic datasets.\nFinally we show that the energy profile of filters in nonlinear CNNs is highly\ncorrelated with the energy profile of linear CNNs and that our analysis of\nlinear networks allows us to predict when representations learned by\nstate-of-the-art networks trained on benchmark classification tasks will depend\non the labels.",
    "descriptor": "",
    "authors": [
      "Rhea Chowers",
      "Yair Weiss"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02454"
  },
  {
    "id": "arXiv:2206.02457",
    "title": "Improving Contrastive Learning of Sentence Embeddings with  Case-Augmented Positives and Retrieved Negatives",
    "abstract": "Following SimCSE, contrastive learning based methods have achieved the\nstate-of-the-art (SOTA) performance in learning sentence embeddings. However,\nthe unsupervised contrastive learning methods still lag far behind the\nsupervised counterparts. We attribute this to the quality of positive and\nnegative samples, and aim to improve both. Specifically, for positive samples,\nwe propose switch-case augmentation to flip the case of the first letter of\nrandomly selected words in a sentence. This is to counteract the intrinsic bias\nof pre-trained token embeddings to frequency, word cases and subwords. For\nnegative samples, we sample hard negatives from the whole dataset based on a\npre-trained language model. Combining the above two methods with SimCSE, our\nproposed Contrastive learning with Augmented and Retrieved Data for Sentence\nembedding (CARDS) method significantly surpasses the current SOTA on STS\nbenchmarks in the unsupervised setting.",
    "descriptor": "\nComments: 7 pages, 3 figures, 6 tables. Accepted to SIGIR 22. Code at this https URL\n",
    "authors": [
      "Wei Wang",
      "Liangzhu Ge",
      "Jingqiao Zhang",
      "Cheng Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.02457"
  },
  {
    "id": "arXiv:2206.02462",
    "title": "Effects of Reward Shaping on Curriculum Learning in Goal Conditioned  Tasks",
    "abstract": "Real-time control for robotics is a popular research area in the\nreinforcement learning (RL) community. Through the use of techniques such as\nreward shaping, researchers have managed to train online agents across a\nmultitude of domains. Despite these advances, solving goal-oriented tasks still\nrequire complex architectural changes or heavy constraints to be placed on the\nproblem. To address this issue, recent works have explored how curriculum\nlearning can be used to separate a complex task into sequential sub-goals,\nhence enabling the learning of a problem that may otherwise be too difficult to\nlearn from scratch. In this article, we present how curriculum learning, reward\nshaping, and a high number of efficiently parallelized environments can be\ncoupled together to solve the problem of multiple cube stacking. Finally, we\nextend the best configuration identified on a higher complexity environment\nwith differently shaped objects.",
    "descriptor": "\nComments: Submitted to IEEE Robotics and Automation Letters 2022\n",
    "authors": [
      "Mihai Anca",
      "Matthew Studley",
      "Mark Hansen",
      "Jonathan D. Thomas",
      "Dabal Pedamonti"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.02462"
  },
  {
    "id": "arXiv:2206.02465",
    "title": "Virtual Homogeneity Learning: Defending against Data Heterogeneity in  Federated Learning",
    "abstract": "In federated learning (FL), model performance typically suffers from client\ndrift induced by data heterogeneity, and mainstream works focus on correcting\nclient drift. We propose a different approach named virtual homogeneity\nlearning (VHL) to directly \"rectify\" the data heterogeneity. In particular, VHL\nconducts FL with a virtual homogeneous dataset crafted to satisfy two\nconditions: containing no private information and being separable. The virtual\ndataset can be generated from pure noise shared across clients, aiming to\ncalibrate the features from the heterogeneous clients. Theoretically, we prove\nthat VHL can achieve provable generalization performance on the natural\ndistribution. Empirically, we demonstrate that VHL endows FL with drastically\nimproved convergence speed and generalization performance. VHL is the first\nattempt towards using a virtual dataset to address data heterogeneity, offering\nnew and effective means to FL.",
    "descriptor": "",
    "authors": [
      "Zhenheng Tang",
      "Yonggang Zhang",
      "Shaohuai Shi",
      "Xin He",
      "Bo Han",
      "Xiaowen Chu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.02465"
  },
  {
    "id": "arXiv:2206.02468",
    "title": "An Optimal Transport Approach to Personalized Federated Learning",
    "abstract": "Federated learning is a distributed machine learning paradigm, which aims to\ntrain a model using the local data of many distributed clients. A key challenge\nin federated learning is that the data samples across the clients may not be\nidentically distributed. To address this challenge, personalized federated\nlearning with the goal of tailoring the learned model to the data distribution\nof every individual client has been proposed. In this paper, we focus on this\nproblem and propose a novel personalized Federated Learning scheme based on\nOptimal Transport (FedOT) as a learning algorithm that learns the optimal\ntransport maps for transferring data points to a common distribution as well as\nthe prediction model under the applied transport map. To formulate the FedOT\nproblem, we extend the standard optimal transport task between two probability\ndistributions to multi-marginal optimal transport problems with the goal of\ntransporting samples from multiple distributions to a common probability\ndomain. We then leverage the results on multi-marginal optimal transport\nproblems to formulate FedOT as a min-max optimization problem and analyze its\ngeneralization and optimization properties. We discuss the results of several\nnumerical experiments to evaluate the performance of FedOT under heterogeneous\ndata distributions in federated learning problems.",
    "descriptor": "",
    "authors": [
      "Farzan Farnia",
      "Amirhossein Reisizadeh",
      "Ramtin Pedarsani",
      "Ali Jadbabaie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.02468"
  },
  {
    "id": "arXiv:2206.02470",
    "title": "Offline Evaluation of Ranked Lists using Parametric Estimation of  Propensities",
    "abstract": "Search engines and recommendation systems attempt to continually improve the\nquality of the experience they afford to their users. Refining the ranker that\nproduces the lists displayed in response to user requests is an important\ncomponent of this process. A common practice is for the service providers to\nmake changes (e.g. new ranking features, different ranking models) and A/B test\nthem on a fraction of their users to establish the value of the change. An\nalternative approach estimates the effectiveness of the proposed changes\noffline, utilising previously collected clickthrough data on the old ranker to\nposit what the user behaviour on ranked lists produced by the new ranker would\nhave been. A majority of offline evaluation approaches invoke the well studied\ninverse propensity weighting to adjust for biases inherent in logged data. In\nthis paper, we propose the use of parametric estimates for these propensities.\nSpecifically, by leveraging well known learning-to-rank methods as subroutines,\nwe show how accurate offline evaluation can be achieved when the new rankings\nto be evaluated differ from the logged ones.",
    "descriptor": "\nComments: Accepted as a full paper at SIGIR 2022\n",
    "authors": [
      "Vishwa Vinay",
      "Manoj Kilaru",
      "David Arbour"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.02470"
  },
  {
    "id": "arXiv:2206.02472",
    "title": "Imperative process algebra and models of parallel computation",
    "abstract": "In the theory of computation, a model of computation is used to study issues\nrelated to computability and computational complexity. Central in such a model\nare the computational processes considered. Processes of this kind can be\ndescribed using an existing imperative process algebra based on ACP (Algebra of\nCommunicating Processes). This paper studies whether this process algebra can\nplay a role in the field of models of computation, in particular in the field\nof models of parallel computation.",
    "descriptor": "\nComments: 40 pages; in Section 2, portions of the material presented in Sections 2--7 of arXiv:2103.07863 have been copied near verbatim or slightly modified\n",
    "authors": [
      "C.A. Middelburg"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2206.02472"
  },
  {
    "id": "arXiv:2206.02479",
    "title": "Easy, adaptable and high-quality Modelling with domain-specific  Constraint Patterns",
    "abstract": "Domain-specific constraint patterns are introduced, which form the\ncounterpart to design patterns in software engineering for the constraint\nprogramming setting. These patterns describe the expert knowledge and\nbest-practice solution to recurring problems and include example\nimplementations. We aim to reach a stage where, for common problems, the\nmodelling process consists of simply picking the applicable patterns from a\nlibrary of patterns and combining them in a model. This vastly simplifies the\nmodelling process and makes the models simple to adapt. By making the patterns\ndomain-specific we can further include problem-specific modelling ideas,\nincluding specific global constraints and search strategies that are known for\nthe problem, into the pattern description. This ensures that the model we\nobtain from patterns is not only correct but also of high quality. We introduce\ndomain-specific constraint patterns on the example of job shop and flow shop,\ndiscuss their advantages and show how the occurrence of patterns can\nautomatically be checked in an event log.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Sophia Saller",
      "Jana Koehler"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02479"
  },
  {
    "id": "arXiv:2206.02480",
    "title": "Subspace Phase Retrieval",
    "abstract": "In this paper, we propose a novel algorithm, termed Subspace Phase Retrieval\n(SPR), which can accurately recover any $n$-dimensional $k$-sparse complex\nsignal from $\\mathcal O(k\\log n)$ magnitude-only samples. This offers a\nsignificant improvement over some existing results that require $\\mathcal O(k^2\n\\log n)$ samples. We also present a favorable geometric property for the\nsubproblem where we are concerned with the recovery of a sparse signal given\nthat at least one support index of the signal is known already. Specifically,\n$\\mathcal O(k\\log k)$ magnitude-only samples ensure i) that all local minima\nare clustered around the expected global minimum within arbitrarily small\ndistances, and ii) that all the critical points outside of this region have at\nleast one negative curvature. When the input signal is nonsparse (i.e., $k =\nn$), our result indicates an analogous geometric property under $\\mathcal O(n\n\\log n)$. This affirmatively answers the open question by Sun-Qu-Wright~[1].",
    "descriptor": "\nComments: Three figures\n",
    "authors": [
      "Mengchu Xu",
      "Dekuan Dong",
      "Jian Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2206.02480"
  },
  {
    "id": "arXiv:2206.02483",
    "title": "Multi-model assessment of heat decarbonisation options in the UK using  electricity and hydrogen",
    "abstract": "Delivering low-carbon heat will require the substitution of natural gas with\nlow-carbon alternatives such as electricity and hydrogen. The objective of this\npaper is to develop a method to soft-link two advanced, investment-optimising\nenergy system models, RTN (Resource-Technology Network) and WeSIM\n(Whole-electricity System Investment Model), in order to assess cost-efficient\nheat decarbonisation pathways for the UK while utilising the respective\nstrengths of the two models. The linking procedure included passing on hourly\nelectricity prices from WeSIM as input to RTN, and returning capacities and\nlocations of hydrogen generation and shares of electricity and hydrogen in heat\nsupply from RTN to WeSIM. The outputs demonstrate that soft-linking can improve\nthe quality of the solution, while providing useful insights into the\ncost-efficient pathways for zero-carbon heating. Quantitative results point to\nthe cost-effectiveness of using a mix of electricity and hydrogen technologies\nfor delivering zero-carbon heat, also demonstrating a high level of interaction\nbetween electricity and hydrogen infrastructure in a zero-carbon system.\nHydrogen from gas reforming with carbon capture and storage can play a\nsignificant role in the medium term, while remaining a cost-efficient option\nfor supplying peak heat demand in the longer term, with the bulk of heat demand\nbeing supplied by electric heat pumps.",
    "descriptor": "",
    "authors": [
      "Marko Aunedi",
      "Maria Yliruka",
      "Shahab Dehghan",
      "Antonio Marco Pantaleo",
      "Nilay Shah",
      "Goran Strbac"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.02483"
  },
  {
    "id": "arXiv:2206.02485",
    "title": "Automatically Drafting Ontologies from Competency Questions with FrODO",
    "abstract": "We present the Frame-based ontology Design Outlet (FrODO), a novel method and\ntool for drafting ontologies from competency questions automatically.\nCompetency questions are expressed as natural language and are a common\nsolution for representing requirements in a number of agile ontology\nengineering methodologies, such as the eXtreme Design (XD) or SAMOD. FrODO\nbuilds on top of FRED. In fact, it leverages the frame semantics for drawing\ndomain-relevant boundaries around the RDF produced by FRED from a competency\nquestion, thus drafting domain ontologies. We carried out a user-based study\nfor assessing FrODO in supporting engineers for ontology design tasks. The\nstudy shows that FrODO is effective in this and the resulting ontology drafts\nare qualitative.",
    "descriptor": "",
    "authors": [
      "Aldo Gangemi",
      "Anna Sofia Lippolis",
      "Giorgia Lodi",
      "Andrea Giovanni Nuzzolese"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2206.02485"
  },
  {
    "id": "arXiv:2206.02491",
    "title": "A finite-difference ghost-point multigrid method for multi-scale  modelling of sorption kinetics of a surfactant past an oscillating bubble",
    "abstract": "We propose a method for the numerical solution of a multiscale model\ndescribing sorption kinetics of a surfactant around an oscillating bubble. The\nevolution of the particles is governed by a convection-diffusion equation for\nthe surfactant concentration $c$, with suitable boundary condition on the\nbubble surface, which models the action of the short range attractive-repulsive\npotential acting on them when they get sufficiently close to the surface\n\\cite{multiscale_mod}. In the domain occupied by the fluid, the particles are\ntransported by the fluid motion generated by the bubble oscillations. The\nmethod adopted to solve the equation for $c$ is based on a finite-difference\nscheme on a uniform Cartesian grid and implemented in 2D and 3D axisymmetric\ndomains. We use a level-set function to define the region occupied by the\nbubble, while the boundary conditions are discretized by a ghost-point\ntechnique to guarantee second order accuracy at the curved boundary. The sparse\nlinear system is finally solved with a geometric multigrid technique designed\n\\textit{ad-hoc\\/} for this specific problem. Several accuracy tests are\nprovided to prove second order accuracy in space and time.\nThe fluid dynamics generated by the oscillating bubble is governed by the\nStokes equation solved with a second order accurate method based on a\nmonolithic approach, where the momentum and continuity equations are solved\nsimultaneously. Since the amplitude of the bubble oscillations are very small,\na simplified model is presented where the computational bubble is actually\nsteady and its oscillations are represented purely with time-dependent boundary\nconditions. A numerical comparison with the moving domain model confirms that\nthis simplification is perfectly reasonable for the class of problems\ninvestigated in this paper.",
    "descriptor": "",
    "authors": [
      "Clarissa Astuto",
      "Armando Coco",
      "Giovanni Russo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.02491"
  },
  {
    "id": "arXiv:2206.02492",
    "title": "Terms-we-Serve-with: a feminist-inspired social imaginary for improved  transparency and engagement in AI",
    "abstract": "Power and information asymmetries between people and digital technology\ncompanies have predominantly been legitimized through contractual agreements\nthat have failed to provide diverse people with meaningful consent and\ncontestability. We offer an interdisciplinary multidimensional perspective on\nthe future of regulatory frameworks - the Terms-we-Serve-with (TwSw) social,\ncomputational, and legal contract for restructuring power asymmetries and\ncenter-periphery dynamics to enable improved human agency in individual and\ncollective experiences of algorithmic harms.",
    "descriptor": "\nComments: 5 pages, to be presented at Connected Life 2022: Designing Digital Futures, Oxford Internet Institute\n",
    "authors": [
      "Bogdana Rakova",
      "Megan Ma",
      "Renee Shelby"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.02492"
  },
  {
    "id": "arXiv:2206.02495",
    "title": "A Resource-efficient Spiking Neural Network Accelerator Supporting  Emerging Neural Encoding",
    "abstract": "Spiking neural networks (SNNs) recently gained momentum due to their\nlow-power multiplication-free computing and the closer resemblance of\nbiological processes in the nervous system of humans. However, SNNs require\nvery long spike trains (up to 1000) to reach an accuracy similar to their\nartificial neural network (ANN) counterparts for large models, which offsets\nefficiency and inhibits its application to low-power systems for real-world use\ncases. To alleviate this problem, emerging neural encoding schemes are proposed\nto shorten the spike train while maintaining the high accuracy. However,\ncurrent accelerators for SNN cannot well support the emerging encoding schemes.\nIn this work, we present a novel hardware architecture that can efficiently\nsupport SNN with emerging neural encoding. Our implementation features energy\nand area efficient processing units with increased parallelism and reduced\nmemory accesses. We verified the accelerator on FPGA and achieve 25% and 90%\nimprovement over previous work in power consumption and latency, respectively.\nAt the same time, high area efficiency allows us to scale for large neural\nnetwork models. To the best of our knowledge, this is the first work to deploy\nthe large neural network model VGG on physical FPGA-based neuromorphic\nhardware.",
    "descriptor": "",
    "authors": [
      "Daniel Gerlinghoff",
      "Zhehui Wang",
      "Xiaozhe Gu",
      "Rick Siow Mong Goh",
      "Tao Luo"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.02495"
  },
  {
    "id": "arXiv:2206.02498",
    "title": "NORPPA: NOvel Ringed seal re-identification by Pelage Pattern  Aggregation",
    "abstract": "We propose a method for Saimaa ringed seal (Pusa hispida saimensis)\nre-identification. Access to large image volumes through camera trapping and\ncrowdsourcing provides novel possibilities for animal monitoring and\nconservation and calls for automatic methods for analysis, in particular, when\nre-identifying individual animals from the images. The proposed method NOvel\nRinged seal re-identification by Pelage Pattern Aggregation (NORPPA) utilizes\nthe permanent and unique pelage pattern of Saimaa ringed seals and\ncontent-based image retrieval techniques. First, the query image is\npreprocessed, and each seal instance is segmented. Next, the seal's pelage\npattern is extracted using a U-net encoder-decoder based method. Then,\nCNN-based affine invariant features are embedded and aggregated into Fisher\nVectors. Finally, the cosine distance between the Fisher Vectors is used to\nfind the best match from a database of known individuals. We perform extensive\nexperiments of various modifications of the method on a new challenging Saimaa\nringed seals re-identification dataset. The proposed method is shown to produce\nthe best re-identification accuracy on our dataset in comparisons with\nalternative approaches.",
    "descriptor": "\nComments: 22 pages, 13 figures, 5 tables\n",
    "authors": [
      "Ekaterina Nepovinnykh",
      "Ilia Chelak",
      "Tuomas Eerola",
      "Heikki K\u00e4lvi\u00e4inen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02498"
  },
  {
    "id": "arXiv:2206.02502",
    "title": "BehavePassDB: Benchmarking Mobile Behavioral Biometrics",
    "abstract": "Mobile behavioral biometrics have become a popular topic of research,\nreaching promising results in terms of authentication, exploiting a multimodal\ncombination of touchscreen and background sensor data. However, there is no way\nof knowing whether state-of-the-art classifiers in the literature can\ndistinguish between the notion of user and device. In this article, we present\na new database, BehavePassDB, structured into separate acquisition sessions and\ntasks to mimic the most common aspects of mobile Human-Computer Interaction\n(HCI). BehavePassDB is acquired through a dedicated mobile app installed on the\nsubjects' devices, also including the case of different users on the same\ndevice for evaluation. We propose a standard experimental protocol and\nbenchmark for the research community to perform a fair comparison of novel\napproaches with the state of the art. We propose and evaluate a system based on\nLong-Short Term Memory (LSTM) architecture with triplet loss and modality\nfusion at score level.",
    "descriptor": "\nComments: 11 pages, 3 figures\n",
    "authors": [
      "Giuseppe Stragapede",
      "Ruben Vera-Rodriguez",
      "Ruben Tolosana",
      "Aythami Morales"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02502"
  },
  {
    "id": "arXiv:2206.02507",
    "title": "Learning to Control under Time-Varying Environment",
    "abstract": "This paper investigates the problem of regret minimization in linear\ntime-varying (LTV) dynamical systems. Due to the simultaneous presence of\nuncertainty and non-stationarity, designing online control algorithms for\nunknown LTV systems remains a challenging task. At a cost of NP-hard offline\nplanning, prior works have introduced online convex optimization algorithms,\nalthough they suffer from nonparametric rate of regret.\nIn this paper, we propose the first computationally tractable online\nalgorithm with regret guarantees that avoids offline planning over the state\nlinear feedback policies. Our algorithm is based on the optimism in the face of\nuncertainty (OFU) principle in which we optimistically select the best model in\na high confidence region. Our algorithm is then more explorative when compared\nto previous approaches. To overcome non-stationarity, we propose either a\nrestarting strategy (R-OFU) or a sliding window (SW-OFU) strategy. With proper\nconfiguration, our algorithm is attains sublinear regret $O(T^{2/3})$. These\nalgorithms utilize data from the current phase for tracking variations on the\nsystem dynamics. We corroborate our theoretical findings with numerical\nexperiments, which highlight the effectiveness of our methods. To the best of\nour knowledge, our study establishes the first model-based online algorithm\nwith regret guarantees under LTV dynamical systems.",
    "descriptor": "",
    "authors": [
      "Yuzhen Han",
      "Ruben Solozabal",
      "Jing Dong",
      "Xingyu Zhou",
      "Martin Takac",
      "Bin Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.02507"
  },
  {
    "id": "arXiv:2206.02511",
    "title": "Transfer Learning based Search Space Design for Hyperparameter Tuning",
    "abstract": "The tuning of hyperparameters becomes increasingly important as machine\nlearning (ML) models have been extensively applied in data mining applications.\nAmong various approaches, Bayesian optimization (BO) is a successful\nmethodology to tune hyper-parameters automatically. While traditional methods\noptimize each tuning task in isolation, there has been recent interest in\nspeeding up BO by transferring knowledge across previous tasks. In this work,\nwe introduce an automatic method to design the BO search space with the aid of\ntuning history from past tasks. This simple yet effective approach can be used\nto endow many existing BO methods with transfer learning capabilities. In\naddition, it enjoys the three advantages: universality, generality, and\nsafeness. The extensive experiments show that our approach considerably boosts\nBO by designing a promising and compact search space instead of using the\nentire space, and outperforms the state-of-the-arts on a wide range of\nbenchmarks, including machine learning and deep learning tuning tasks, and\nneural architecture search.",
    "descriptor": "\nComments: 9 pages and 2 extra pages for appendix\n",
    "authors": [
      "Yang Li",
      "Yu Shen",
      "Huaijun Jiang",
      "Tianyi Bai",
      "Wentao Zhang",
      "Ce Zhang",
      "Bin Cui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02511"
  },
  {
    "id": "arXiv:2206.02518",
    "title": "A Surface Energy Balance Model for Predicting Temperature Evolution of  Random-Shaped Smoldering Objects in Open Environments",
    "abstract": "In this paper, a new computational model, Temperature Evolution of\nRandom-shaped Smoldering Objects (TERSO), is developed to predict the\ntemperature evolution of objects with any complex shapes under variable\nenvironmental conditions. The model is applicable to natural and manmade\nrandom-shaped objects (or a collection of objects) in an open atmosphere under\nthe influence of local diurnal solar radiation and/or smoldering heat. In this\nregard, a detailed surface energy balance analysis is performed in high\nspatiotemporal resolution over three-dimensional objects of any shape. The\nmodel performance was validated against several existing measured data in the\nliterature. TERSO provides temperature modeling capabilities for several\napplications that involve arbitrary-shaped objects of any size, whether\nsmoldering or non-smoldering, that are hanging (e.g., fruits), in-flight (e.g.,\nfirebrands), or surface-mounted (e.g., buildings). The discrete,\nhigh-resolution surface temperature information obtained from the model can\nalso provide unsteady thermal boundary conditions for computational fluid\ndynamics simulations when coupled physics is desired.",
    "descriptor": "",
    "authors": [
      "Saurabh Saxena",
      "Neda Yaghoobian"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2206.02518"
  },
  {
    "id": "arXiv:2206.02521",
    "title": "Stochastic estimation of Green's functions with application to diffusion  and advection-diffusion-reaction problems",
    "abstract": "A stochastic method is described for estimating Green's functions (GF's),\nappropriate to linear advection-diffusion-reaction transport problems, evolving\nin arbitrary geometries. By allowing straightforward construction of\napproximate, though high-accuracy GF's, within any geometry, the technique\nsolves the central challenge in obtaining Green's function solutions. In\ncontrast to Monte Carlo solutions of individual transport problems, subject to\nspecific sets of conditions and forcing, the proposed technique produces\napproximate GF's that can be used: a) to obtain (infinite) sets of solutions,\nsubject to any combination of (random and deterministic) boundary, initial, and\ninternal forcing, b) as high fidelity direct models in inverse problems, and c)\nas high quality process models in thermal and mass transport design,\noptimization, and process control problems.",
    "descriptor": "\nComments: 47 pages, 8 figures\n",
    "authors": [
      "Russell G. Keanini",
      "Jerry Dahlberg",
      "Philip Brown",
      "Mehdi Morovati",
      "Hamidreza Moradi",
      "Donald Jacobs",
      "Peter T. Tkacik"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.02521"
  },
  {
    "id": "arXiv:2206.02525",
    "title": "Dynamic DNNs Meet Runtime Resource Management on Mobile and Embedded  Platforms",
    "abstract": "Deep neural network (DNN) inference is increasingly being executed on mobile\nand embedded platforms due to low latency and better privacy. However,\nefficient deployment on these platforms is challenging due to the intensive\ncomputation and memory access. We propose a holistic system design for DNN\nperformance and energy optimisation, combining the trade-off opportunities in\nboth algorithms and hardware. The system can be viewed as three abstract\nlayers: the device layer contains heterogeneous computing resources; the\napplication layer has multiple concurrent workloads; and the runtime resource\nmanagement layer monitors the dynamically changing algorithms' performance\ntargets as well as hardware resources and constraints, and tries to meet them\nby tuning the algorithm and hardware at the same time. Moreover, We illustrate\nthe runtime approach through a dynamic version of 'once-for-all network'\n(namely Dynamic-OFA), which can scale the ConvNet architecture to fit\nheterogeneous computing resources efficiently and has good generalisation for\ndifferent model architectures such as Transformer. Compared to the\nstate-of-the-art Dynamic DNNs, our experimental results using ImageNet on a\nJetson Xavier NX show that the Dynamic-OFA is up to 3.5x (CPU), 2.4x (GPU)\nfaster for similar ImageNet Top-1 accuracy, or 3.8% (CPU), 5.1% (GPU) higher\naccuracy at similar latency. Furthermore, compared with Linux governor (e.g.\nperformance, schedutil), our runtime approach reduces the energy consumption by\n16.5% at similar latency.",
    "descriptor": "\nComments: Accepted as a presentation at Fourth UK Mobile, Wearable and Ubiquitous Systems Research Symposium (MobiUK 2022)\n",
    "authors": [
      "Lei Xun",
      "Bashir M. Al-Hashimi",
      "Jonathon Hare",
      "Geoff V. Merrett"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2206.02525"
  },
  {
    "id": "arXiv:2206.02531",
    "title": "3D-Augmented Contrastive Knowledge Distillation for Image-based Object  Pose Estimation",
    "abstract": "Image-based object pose estimation sounds amazing because in real\napplications the shape of object is oftentimes not available or not easy to\ntake like photos. Although it is an advantage to some extent, un-explored shape\ninformation in 3D vision learning problem looks like \"flaws in jade\". In this\npaper, we deal with the problem in a reasonable new setting, namely 3D shape is\nexploited in the training process, and the testing is still purely image-based.\nWe enhance the performance of image-based methods for category-agnostic object\npose estimation by exploiting 3D knowledge learned by a multi-modal method.\nSpecifically, we propose a novel contrastive knowledge distillation framework\nthat effectively transfers 3D-augmented image representation from a multi-modal\nmodel to an image-based model. We integrate contrastive learning into the\ntwo-stage training procedure of knowledge distillation, which formulates an\nadvanced solution to combine these two approaches for cross-modal tasks. We\nexperimentally report state-of-the-art results compared with existing\ncategory-agnostic image-based methods by a large margin (up to +5% improvement\non ObjectNet3D dataset), demonstrating the effectiveness of our method.",
    "descriptor": "\nComments: Accepted for presentation at International Conference on Multimedia Retrieval (ICMR '22)\n",
    "authors": [
      "Zhidan Liu",
      "Zhen Xing",
      "Xiangdong Zhou",
      "Yijiang Chen",
      "Guichun Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02531"
  },
  {
    "id": "arXiv:2206.02535",
    "title": "Certified Robustness in Federated Learning",
    "abstract": "Federated learning has recently gained significant attention and popularity\ndue to its effectiveness in training machine learning models on distributed\ndata privately. However, as in the single-node supervised learning setup,\nmodels trained in federated learning suffer from vulnerability to imperceptible\ninput transformations known as adversarial attacks, questioning their\ndeployment in security-related applications. In this work, we study the\ninterplay between federated training, personalization, and certified\nrobustness. In particular, we deploy randomized smoothing, a widely-used and\nscalable certification method, to certify deep networks trained on a federated\nsetup against input perturbations and transformations. We find that the simple\nfederated averaging technique is effective in building not only more accurate,\nbut also more certifiably-robust models, compared to training solely on local\ndata. We further analyze personalization, a popular technique in federated\ntraining that increases the model's bias towards local data, on robustness. We\nshow several advantages of personalization over both~(that is, only training on\nlocal data and federated training) in building more robust models with faster\ntraining. Finally, we explore the robustness of mixtures of global and\nlocal~(\\ie personalized) models, and find that the robustness of local models\ndegrades as they diverge from the global model",
    "descriptor": "\nComments: 17 pages, 10 figures. Code available at this https URL\n",
    "authors": [
      "Motasem Alfarra",
      "Juan C. P\u00e9rez",
      "Egor Shulgin",
      "Peter Richt\u00e1rik",
      "Bernard Ghanem"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02535"
  },
  {
    "id": "arXiv:2206.02539",
    "title": "Robustness Evaluation and Adversarial Training of an Instance  Segmentation Model",
    "abstract": "To evaluate the robustness of non-classifier models, we propose probabilistic\nlocal equivalence, based on the notion of randomized smoothing, as a way to\nquantitatively evaluate the robustness of an arbitrary function. In addition,\nto understand the effect of adversarial training on non-classifiers and to\ninvestigate the level of robustness that can be obtained without degrading\nperformance on the training distribution, we apply Fast is Better than Free\nadversarial training together with the TRADES robust loss to the training of an\ninstance segmentation network. In this direction, we were able to achieve a\nsymmetric best dice score of 0.85 on the TuSimple lane detection challenge,\noutperforming the standardly-trained network's score of 0.82. Additionally, we\nwere able to obtain an F-measure of 0.49 on manipulated inputs, in contrast to\nthe standardly-trained network's score of 0. We show that probabilisitic local\nequivalence is able to successfully distinguish between standardly-trained and\nadversarially-trained models, providing another view of the improved robustness\nof the adversarially-trained models.",
    "descriptor": "\nComments: 15 pages, 10 figures\n",
    "authors": [
      "Jacob Bond",
      "Andrew Lingg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02539"
  },
  {
    "id": "arXiv:2206.02541",
    "title": "PCPT and ACPT: Copyright Protection and Traceability Scheme for DNN  Model",
    "abstract": "Deep neural networks (DNNs) have achieved tremendous success in artificial\nintelligence (AI) fields. However, DNN models can be easily illegally copied,\nredistributed, or abused by criminals, seriously damaging the interests of\nmodel inventers. Currently, the copyright protection of DNN models by neural\nnetwork watermarking has been studied, but the establishment of a traceability\nmechanism for determining the authorized users of a leaked model is a new\nproblem driven by the demand for AI services. Because the existing traceability\nmechanisms are used for models without watermarks, a small number of false\npositives is generated. Existing black-box active protection schemes have loose\nauthorization control and are vulnerable to forgery attacks. Therefore, based\non the idea of black-box neural network watermarking with the video framing and\nimage perceptual hash algorithm, this study proposes a passive copyright\nprotection and traceability framework PCPT using an additional class of DNN\nmodels, improving the existing traceability mechanism that yields a small\nnumber of false positives. Based on the authorization control strategy and\nimage perceptual hash algorithm, using the authorization control center\nconstructed using the detector and verifier, a DNN model active copyright\nprotection and traceability framework ACPT is proposed. It realizes stricter\nauthorization control, which establishes a strong connection between users and\nmodel owners, and improves the framework security. The key sample that is\nsimultaneously generated does not affect the quality of the original image and\nsupports traceability verification.",
    "descriptor": "",
    "authors": [
      "Xuefeng Fan",
      "Hangyu Gui",
      "Xiaoyi Zhou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02541"
  },
  {
    "id": "arXiv:2206.02544",
    "title": "RLSS: A Deep Reinforcement Learning Algorithm for Sequential Scene  Generation",
    "abstract": "We present RLSS: a reinforcement learning algorithm for sequential scene\ngeneration. This is based on employing the proximal policy optimization (PPO)\nalgorithm for generative problems. In particular, we consider how to\neffectively reduce the action space by including a greedy search algorithm in\nthe learning process. Our experiments demonstrate that our method converges for\na relatively large number of actions and learns to generate scenes with\npredefined design objectives. This approach is placing objects iteratively in\nthe virtual scene. In each step, the network chooses which objects to place and\nselects positions which result in maximal reward. A high reward is assigned if\nthe last action resulted in desired properties whereas the violation of\nconstraints is penalized. We demonstrate the capability of our method to\ngenerate plausible and diverse scenes efficiently by solving indoor planning\nproblems and generating Angry Birds levels.",
    "descriptor": "\nComments: Accepted at the IEEE Winter Conference on Applications of Computer Vision, WACV 2022\n",
    "authors": [
      "Azimkhon Ostonov",
      "Peter Wonka",
      "Dominik L. Michels"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02544"
  },
  {
    "id": "arXiv:2206.02547",
    "title": "Towards retrieving dispersion profiles using quantum-mimic Optical  Coherence Tomography and Machine Learnin",
    "abstract": "Artefacts in quantum-mimic Optical Coherence Tomography are considered\ndetrimental because they scramble the images even for the simplest objects.\nThey are a side effect of autocorrelation which is used in the quantum\nentanglement mimicking algorithm behind this method. Interestingly, the\nautocorrelation imprints certain characteristics onto an artefact - it makes\nits shape and characteristics depend on the amount of dispersion exhibited by\nthe layer that artefact corresponds to. This unique relationship between the\nartefact and the layer's dispersion can be used to determine Group Velocity\nDispersion (GVD) values of object layers and, based on them, build a\ndispersion-contrasted depth profile. The retrieval of GVD profiles is achieved\nvia Machine Learning. During training, a neural network learns the relationship\nbetween GVD and the artefacts' shape and characteristics, and consequently, it\nis able to provide a good qualitative representation of object's dispersion\nprofile for never-seen-before data: computer-generated single dispersive layers\nand experimental pieces of glass.",
    "descriptor": "\nComments: 11 pages, 5 figures\n",
    "authors": [
      "Krzysztof A. Maliszewski",
      "Piotr Kolenderski",
      "Varvara Vetrova",
      "Sylwia M. Kolenderska"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2206.02547"
  },
  {
    "id": "arXiv:2206.02554",
    "title": "Complete Performance Analysis of Underwater VLC Diffusion Adaptive  Networks",
    "abstract": "In this paper, we simulated a diffusion adaptive network in the underwater\nenvironment. The communication method between the nodes of this network is\nassumed to be the visible light communication technology (VLC) which in the\nunderwater condition is known as the UVLC. The links between the nodes in this\ncase are contaminated with the optical noise and turbulence. These\ncontaminations are modeled with the proper statistical distributions depending\non the underwater conditions. The optical turbulence modeling link coefficients\nare shown to be following the Log-normal distribution which its mean and\nvariance are directly dependent on the temperature and the salinity of the\nsimulated water and the assumed distance between the diffusion network nodes.\nThe performance of the diffusion network in using UVLC technology is then\nanalyzed both with simulations and theoretical calculations and the results are\npresented using the steady-state error metrics. Our analysis showed that the\ndiffusion network can be implemented underwater with the VLC technology\nproviding that the distance between the network nodes is less than 10 meters.\nAlso, in order to guarantee the convergence of the adaptive network, the water\nsalinity level and temperature must not exceed the values that are presented in\nour simulations.",
    "descriptor": "\nComments: 16 Pages\n",
    "authors": [
      "Hossein Abdavinejad",
      "Hadi Baghali",
      "Javad Ostadieh",
      "Ehsan Mostafapour",
      "Changiz Ghobadi",
      "Javad Nourinia"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.02554"
  },
  {
    "id": "arXiv:2206.02555",
    "title": "Dynaformer: A Deep Learning Model for Ageing-aware Battery Discharge  Prediction",
    "abstract": "Electrochemical batteries are ubiquitous devices in our society. When they\nare employed in mission-critical applications, the ability to precisely predict\nthe end of discharge under highly variable environmental and operating\nconditions is of paramount importance in order to support operational\ndecision-making. While there are accurate predictive models of the processes\nunderlying the charge and discharge phases of batteries, the modelling of\nageing and its effect on performance remains poorly understood. Such a lack of\nunderstanding often leads to inaccurate models or the need for time-consuming\ncalibration procedures whenever the battery ages or its conditions change\nsignificantly. This represents a major obstacle to the real-world deployment of\nefficient and robust battery management systems. In this paper, we propose for\nthe first time an approach that can predict the voltage discharge curve for\nbatteries of any degradation level without the need for calibration. In\nparticular, we introduce Dynaformer, a novel Transformer-based deep learning\narchitecture which is able to simultaneously infer the ageing state from a\nlimited number of voltage/current samples and predict the full voltage\ndischarge curve for real batteries with high precision. Our experiments show\nthat the trained model is effective for input current profiles of different\ncomplexities and is robust to a wide range of degradation levels. In addition\nto evaluating the performance of the proposed framework on simulated data, we\ndemonstrate that a minimal amount of fine-tuning allows the model to bridge the\nsimulation-to-real gap between simulations and real data collected from a set\nof batteries. The proposed methodology enables the utilization of\nbattery-powered systems until the end of discharge in a controlled and\npredictable way, thereby significantly prolonging the operating cycles and\nreducing costs.",
    "descriptor": "",
    "authors": [
      "Luca Biggio",
      "Tommaso Bendinelli",
      "Chetan Kulkarni",
      "Olga Fink"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02555"
  },
  {
    "id": "arXiv:2206.02559",
    "title": "Conversation Group Detection With Spatio-Temporal Context",
    "abstract": "In this work, we propose an approach for detecting conversation groups in\nsocial scenarios like cocktail parties and networking events, from overhead\ncamera recordings. We posit the detection of conversation groups as a learning\nproblem that could benefit from leveraging the spatial context of the\nsurroundings, and the inherent temporal context in interpersonal dynamics which\nis reflected in the temporal dynamics in human behavior signals, an aspect that\nhas not been addressed in recent prior works. This motivates our approach which\nconsists of a dynamic LSTM-based deep learning model that predicts continuous\npairwise affinity values indicating how likely two people are in the same\nconversation group. These affinity values are also continuous in time, since\nrelationships and group membership do not occur instantaneously, even though\nthe ground truths of group membership are binary. Using the predicted affinity\nvalues, we apply a graph clustering method based on Dominant Set extraction to\nidentify the conversation groups. We benchmark the proposed method against\nestablished methods on multiple social interaction datasets. Our results showed\nthat the proposed method improves group detection performance in data that has\nmore temporal granularity in conversation group labels. Additionally, we\nprovide an analysis in the predicted affinity values in relation to the\nconversation group detection. Finally, we demonstrate the usability of the\npredicted affinity values in a forecasting framework to predict group\nmembership for a given forecast horizon.",
    "descriptor": "",
    "authors": [
      "Stephanie Tan",
      "David M.J. Tax",
      "Hayley Hung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02559"
  },
  {
    "id": "arXiv:2206.02562",
    "title": "floodlight -- A high-level, data-driven sports analytics framework",
    "abstract": "The present work introduces floodlight, an open source Python package built\nto support and automate team sport data analysis. It is specifically designed\nfor the scientific analysis of spatiotemporal tracking data, event data, and\ngame codes in disciplines such as match and performance analysis, exercise\nphysiology, training science, and collective movement behavior analysis. It is\ncompletely provider- and sports-independent and includes a high-level interface\nsuitable for programming beginners. The package includes routines for most\naspects of the data analysis process, including dedicated data classes, file\nparsing functionality, public dataset APIs, pre-processing routines, common\ndata models and several standard analysis algorithms previously used in the\nliterature, as well as basic visualization functionality. The package is\nintended to make team sport data analysis more accessible to sport scientists,\nfoster collaborations between sport and computer scientists, and strengthen the\ncommunity's culture of open science and inclusion of previous works in future\nworks.",
    "descriptor": "\nComments: 5 pages, 1 figure. For associated package, see this https URL For source code, see this https URL . For documentation, see this https URL\n",
    "authors": [
      "Dominik Raabe",
      "Henrik Biermann",
      "Manuel Bassek",
      "Martin Wohlan",
      "Rumena Komitova",
      "Robert Rein",
      "Tobias Kuppens Groot",
      "Daniel Memmert"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.02562"
  },
  {
    "id": "arXiv:2206.02564",
    "title": "Machine Learning for Detection of 3D Features using sparse X-ray data",
    "abstract": "In many inertial confinement fusion experiments, the neutron yield and other\nparameters cannot be completely accounted for with one and two dimensional\nmodels. This discrepancy suggests that there are three dimensional effects\nwhich may be significant. Sources of these effects include defects in the\nshells and shell interfaces, the fill tube of the capsule, and the joint\nfeature in double shell targets. Due to their ability to penetrate materials,\nX-rays are used to capture the internal structure of objects. Methods such as\nComputational Tomography use X-ray radiographs from hundreds of projections in\norder to reconstruct a three dimensional model of the object. In experimental\nenvironments, such as the National Ignition Facility and Omega-60, the\navailability of these views is scarce and in many cases only consist of a\nsingle line of sight. Mathematical reconstruction of a 3D object from sparse\nviews is an ill-posed inverse problem. These types of problems are typically\nsolved by utilizing prior information. Neural networks have been used for the\ntask of 3D reconstruction as they are capable of encoding and leveraging this\nprior information. We utilize half a dozen different convolutional neural\nnetworks to produce different 3D representations of ICF implosions from the\nexperimental data. We utilize deep supervision to train a neural network to\nproduce high resolution reconstructions. We use these representations to track\n3D features of the capsules such as the ablator, inner shell, and the joint\nbetween shell hemispheres. Machine learning, supplemented by different priors,\nis a promising method for 3D reconstructions in ICF and X-ray radiography in\ngeneral.",
    "descriptor": "",
    "authors": [
      "Bradley T. Wolfe",
      "Michael J. Falato",
      "Xinhua Zhang",
      "Nga T. T. Nguyen-Fotiadis",
      "J.P. Sauppe",
      "P. M. Kozlowski",
      "P. A. Keiter",
      "R. E. Reinovsky",
      "S. A. Batha",
      "Zhehui Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2206.02564"
  },
  {
    "id": "arXiv:2206.02566",
    "title": "Towards Group Learning: Distributed Weighting of Experts",
    "abstract": "Aggregating signals from a collection of noisy sources is a fundamental\nproblem in many domains including crowd-sourcing, multi-agent planning, sensor\nnetworks, signal processing, voting, ensemble learning, and federated learning.\nThe core question is how to aggregate signals from multiple sources (e.g.\nexperts) in order to reveal an underlying ground truth. While a full answer\ndepends on the type of signal, correlation of signals, and desired output, a\nproblem common to all of these applications is that of differentiating sources\nbased on their quality and weighting them accordingly. It is often assumed that\nthis differentiation and aggregation is done by a single, accurate central\nmechanism or agent (e.g. judge). We complicate this model in two ways. First,\nwe investigate the setting with both a single judge, and one with multiple\njudges. Second, given this multi-agent interaction of judges, we investigate\nvarious constraints on the judges' reporting space. We build on known results\nfor the optimal weighting of experts and prove that an ensemble of sub-optimal\nmechanisms can perform optimally under certain conditions. We then show\nempirically that the ensemble approximates the performance of the optimal\nmechanism under a broader range of conditions.",
    "descriptor": "",
    "authors": [
      "Ben Abramowitz",
      "Nicholas Mattei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2206.02566"
  },
  {
    "id": "arXiv:2206.02571",
    "title": "Wigner-Smith Time Delay Matrix for Electromagnetics: Guiding and  Periodic Systems with Evanescent Modes",
    "abstract": "The Wigner-Smith (WS) time delay matrix relates an electromagnetic system's\nscattering matrix and its frequency derivative. Previous work showed that the\nentries of WS time delay matrices of systems excited by propagating waves\nconsist of volume integrals of energy-like field quantities. This paper\nintroduces a generalized WS relationship that applies to systems excited by\nmixtures of propagating and evanescent fields. Just like its predecessor, the\ngeneralized WS relationship allows for the identification of so-called WS modes\nthat interact with the system with well-defined time delays. Furthermore, a\ntechnique is developed to compute the WS time delay matrix of a composite\nsystem from the WS time delay matrices of its subsystems. Numerical examples\ndemonstrate the usefulness of the generalized WS method when characterizing\ntime delays experienced by fields interacting with guiding and periodic\nstructures that have ports supporting evanescent modes.",
    "descriptor": "",
    "authors": [
      "Yiqian Mao",
      "Utkarsh R. Patel",
      "Eric Michielssen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.02571"
  },
  {
    "id": "arXiv:2206.02573",
    "title": "Team VI-I2R Technical Report on EPIC-KITCHENS-100 Unsupervised Domain  Adaptation Challenge for Action Recognition 2021",
    "abstract": "In this report, we present the technical details of our approach to the\nEPIC-KITCHENS-100 Unsupervised Domain Adaptation (UDA) Challenge for Action\nRecognition. The EPIC-KITCHENS-100 dataset consists of daily kitchen activities\nfocusing on the interaction between human hands and their surrounding objects.\nIt is very challenging to accurately recognize these fine-grained activities,\ndue to the presence of distracting objects and visually similar action classes,\nespecially in the unlabelled target domain. Based on an existing method for\nvideo domain adaptation, i.e., TA3N, we propose to learn hand-centric features\nby leveraging the hand bounding box information for UDA on fine-grained action\nrecognition. This helps reduce the distraction from background as well as\nfacilitate the learning of domain-invariant features. To achieve high quality\nhand localization, we adopt an uncertainty-aware domain adaptation network,\ni.e., MEAA, to train a domain-adaptive hand detector, which only uses very\nlimited hand bounding box annotations in the source domain but can generalize\nwell to the unlabelled target domain. Our submission achieved the 1st place in\nterms of top-1 action recognition accuracy, using only RGB and optical flow\nmodalities as input.",
    "descriptor": "",
    "authors": [
      "Yi Cheng",
      "Fen Fang",
      "Ying Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02573"
  },
  {
    "id": "arXiv:2206.02574",
    "title": "On the duality between contrastive and non-contrastive self-supervised  learning",
    "abstract": "Recent approaches in self-supervised learning of image representations can be\ncategorized into different families of methods and, in particular, can be\ndivided into contrastive and non-contrastive approaches. While differences\nbetween the two families have been thoroughly discussed to motivate new\napproaches, we focus more on the theoretical similarities between them. By\ndesigning contrastive and non-contrastive criteria that can be related\nalgebraically and shown to be equivalent under limited assumptions, we show how\nclose those families can be. We further study popular methods and introduce\nvariations of them, allowing us to relate this theoretical result to current\npractices and show how design choices in the criterion can influence the\noptimization process and downstream performance. We also challenge the popular\nassumptions that contrastive and non-contrastive methods, respectively, need\nlarge batch sizes and output dimensions. Our theoretical and quantitative\nresults suggest that the numerical gaps between contrastive and noncontrastive\nmethods in certain regimes can be significantly reduced given better network\ndesign choice and hyperparameter tuning.",
    "descriptor": "",
    "authors": [
      "Quentin Garrido",
      "Yubei Chen",
      "Adrien Bardes",
      "Laurent Najman",
      "Yann Lecun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02574"
  },
  {
    "id": "arXiv:2206.02575",
    "title": "Constraints on parameter choices for successful reservoir computing",
    "abstract": "Echo-state networks are simple models of discrete dynamical systems driven by\na time series. By selecting network parameters such that the dynamics of the\nnetwork is contractive, characterized by a negative maximal Lyapunov exponent,\nthe network may synchronize with the driving signal. Exploiting this\nsynchronization, the echo-state network may be trained to autonomously\nreproduce the input dynamics, enabling time-series prediction. However, while\nsynchronization is a necessary condition for prediction, it is not sufficient.\nHere, we study what other conditions are necessary for successful time-series\nprediction. We identify two key parameters for prediction performance, and\nconduct a parameter sweep to find regions where prediction is successful. These\nregions differ significantly depending on whether full or partial phase space\ninformation about the input is provided to the network during training. We\nexplain how these regions emerge.",
    "descriptor": "\nComments: 16 pages, 4 figures\n",
    "authors": [
      "L. Storm",
      "K. Gustavsson",
      "B. Mehlig"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2206.02575"
  },
  {
    "id": "arXiv:2206.02577",
    "title": "Effects of Auxiliary Knowledge on Continual Learning",
    "abstract": "In Continual Learning (CL), a neural network is trained on a stream of data\nwhose distribution changes over time. In this context, the main problem is how\nto learn new information without forgetting old knowledge (i.e., Catastrophic\nForgetting). Most existing CL approaches focus on finding solutions to preserve\nacquired knowledge, so working on the past of the model. However, we argue that\nas the model has to continually learn new tasks, it is also important to put\nfocus on the present knowledge that could improve following tasks learning. In\nthis paper we propose a new, simple, CL algorithm that focuses on solving the\ncurrent task in a way that might facilitate the learning of the next ones. More\nspecifically, our approach combines the main data stream with a secondary,\ndiverse and uncorrelated stream, from which the network can draw auxiliary\nknowledge. This helps the model from different perspectives, since auxiliary\ndata may contain useful features for the current and the next tasks and\nincoming task classes can be mapped onto auxiliary classes. Furthermore, the\naddition of data to the current task is implicitly making the classifier more\nrobust as we are forcing the extraction of more discriminative features. Our\nmethod can outperform existing state-of-the-art models on the most common CL\nImage Classification benchmarks.",
    "descriptor": "",
    "authors": [
      "Giovanni Bellitto",
      "Matteo Pennisi",
      "Simone Palazzo",
      "Lorenzo Bonicelli",
      "Matteo Boschini",
      "Simone Calderara",
      "Concetto Spampinato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02577"
  },
  {
    "id": "arXiv:2206.02578",
    "title": "Operative and Procedural Cooperative Training in Marine Ports",
    "abstract": "This article faces the problem of operative and procedural cooperative\ntraining in marine ports with particular attention to harbour pilots and port\ntraffic controller. The design and development of an advanced system, equipped\nwith dedicated hardware in the loop, for cooperative training of operators\ninvolved in the last mile of navigation is presented. Indeed, the article\ndescribes the software and hardware development of a distributed and\ninteroperable system composed by two simulators (the bridge ship simulator and\ncontrol tower simulator). Multiple problems are faced and solved including (i)\nthe motion of the ship at sea that is based on a 6 Degree Of Freedom (DOF)\nmodel for surge, sway and yaw and closed form expressions for pitch, roll and\nheave and its validation; (ii) the development of the 3D geometric models and\nrelated virtual environments of a real marine port and vessel (to provide the\ntrainees with the sensation to experience a real port and ship environment);\n(iii) the design of a bridge ship replica, the bridge hardware integration and\nthe design of the visualization system; (iv) the design and development of the\ncontrol tower simulator; (v) the integration of the bridge ship simulator and\ncontrol tower simulator through the IEEE 1516 High Level Architecture standard\nfor distributed simulation.",
    "descriptor": "\nComments: 21 pages, 22 figures\n",
    "authors": [
      "Francesco Longo",
      "Alessandro Chiurco",
      "Roberto Musmanno",
      "Letizia Nicoletti"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.02578"
  },
  {
    "id": "arXiv:2206.02583",
    "title": "Consensus Learning for Cooperative Multi-Agent Reinforcement Learning",
    "abstract": "Almost all multi-agent reinforcement learning algorithms without\ncommunication follow the principle of centralized training with decentralized\nexecution. During centralized training, agents can be guided by the same\nsignals, such as the global state. During decentralized execution, however,\nagents lack the shared signal. Inspired by viewpoint invariance and contrastive\nlearning, we propose consensus learning for cooperative multi-agent\nreinforcement learning in this paper. Although based on local observations,\ndifferent agents can infer the same consensus in discrete space. During\ndecentralized execution, we feed the inferred consensus as an explicit input to\nthe network of agents, thereby developing their spirit of cooperation. Our\nproposed method can be extended to various multi-agent reinforcement learning\nalgorithms. Moreover, we carry out them on some fully cooperative tasks and get\nconvincing results.",
    "descriptor": "\nComments: Preliminary version\n",
    "authors": [
      "Zhiwei Xu",
      "Bin Zhang",
      "Dapeng Li",
      "Zeren Zhang",
      "Guangchong Zhou",
      "Guoliang Fan"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02583"
  },
  {
    "id": "arXiv:2206.02585",
    "title": "On the Origins of Objects by Means of Careful Selection",
    "abstract": "We introduce a taxonomy of objects for EO programming language. This taxonomy\nis designed with a few principles in mind: non-redundancy, simplicity, and so\non. The taxonomy is supposed to be used as a navigation map by EO programmers.\nIt may also be helpful as a guideline for designers of other object-oriented\nlanguages or libraries for them.",
    "descriptor": "",
    "authors": [
      "Yegor Bugayenko"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2206.02585"
  },
  {
    "id": "arXiv:2206.02593",
    "title": "Pessimistic Off-Policy Optimization for Learning to Rank",
    "abstract": "Off-policy learning is a framework for optimizing policies without deploying\nthem, using data collected by another policy. In recommender systems, this is\nespecially challenging due to the imbalance in logged data: some items are\nrecommended and thus logged much more frequently than others. This is further\nperpetuated when recommending a list of items, as the action space is\ncombinatorial. To address this challenge, we study pessimistic off-policy\noptimization for learning to rank. The key idea is to compute lower confidence\nbounds on parameters of click models and then return the list with the highest\npessimistic estimate of its value. This approach is computationally efficient\nand we analyze it. We study its Bayesian and frequentist variants, and overcome\nthe limitation of unknown prior by incorporating empirical Bayes. To show the\nempirical effectiveness of our approach, we compare it to off-policy optimizers\nthat use inverse propensity scores or neglect uncertainty. Our approach\noutperforms all baselines, is robust, and is also general.",
    "descriptor": "",
    "authors": [
      "Matej Cief",
      "Branislav Kveton",
      "Michal Kompan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.02593"
  },
  {
    "id": "arXiv:2206.02597",
    "title": "No GPU? No problem: an ultra fast 3D detection of road users with a  simple proposal generator and energy-based out-of-distribution PointNets",
    "abstract": "This paper presents a novel architecture for point cloud road user detection,\nwhich is based on a classical point cloud proposal generator approach, that\nutilizes simple geometrical rules. New methods are coupled with this technique\nto achieve extremely small computational requirement, and mAP that is\ncomparable to the state-of-the-art. The idea is to specifically exploit\ngeometrical rules in hopes of faster performance. The typical downsides of this\napproach, e.g. global context loss, are tackled in this paper, and solutions\nare presented. This approach allows real-time performance on a single core CPU,\nwhich is not the case with end-to-end solutions presented in the\nstate-of-the-art. We have evaluated the performance of the method with the\npublic KITTI dataset, and with our own annotated dataset collected with a small\nmobile robot platform. Moreover, we also present a novel ground segmentation\nmethod, which is evaluated with the public SemanticKITTI dataset.",
    "descriptor": "",
    "authors": [
      "Alvari Sepp\u00e4nen",
      "Eerik Alamikkotervo",
      "Risto Ojala",
      "Giacomo Dario",
      "Kari Tammi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.02597"
  },
  {
    "id": "arXiv:2206.02598",
    "title": "[Reproducibility Report] Explainable Deep One-Class Classification",
    "abstract": "Fully Convolutional Data Description (FCDD), an explainable version of the\nHypersphere Classifier (HSC), directly addresses image anomaly detection (AD)\nand pixel-wise AD without any post-hoc explainer methods. The authors claim\nthat FCDD achieves results comparable with the state-of-the-art in sample-wise\nAD on Fashion-MNIST and CIFAR-10 and exceeds the state-of-the-art on the\npixel-wise task on MVTec-AD. We reproduced the main results of the paper using\nthe author's code with minor changes and provide runtime requirements to\nachieve if (CPU memory, GPU memory, and training time). We propose another\nanalysis methodology using a critical difference diagram, and further\ninvestigate the test performance of the model during the training phase.",
    "descriptor": "\nComments: Submitted to the ML Reproducibility Challenge 2021 Fall\n",
    "authors": [
      "Joao P. C. Bertoldo",
      "Etienne Decenci\u00e8re"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.02598"
  },
  {
    "id": "arXiv:2206.02599",
    "title": "Essential convergence rate of ordinary differential equations appearing  in optimization",
    "abstract": "Some continuous optimization methods can be connected to ordinary\ndifferential equations (ODEs) by taking continuous limits, and their\nconvergence rates can be explained by the ODEs. However, since such ODEs can\nachieve any convergence rate by time scaling, the correspondence is not as\nstraightforward as usually expected, and deriving new methods through ODEs is\nnot quite direct. In this letter, we pay attention to stability restriction in\ndiscretizing ODEs and show that acceleration by time scaling always implies\ndeceleration in discretization; they balance out so that we can define an\nattainable unique convergence rate which we call an \"essential convergence\nrate\".",
    "descriptor": "",
    "authors": [
      "Kansei Ushiyama",
      "Shun Sato",
      "Takayasu Matsuo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.02599"
  },
  {
    "id": "arXiv:2206.02602",
    "title": "LIN-MM: Multiplexed Message Authentication Code for Local Interconnect  Network message authentication in road vehicles",
    "abstract": "The automotive market is profitable for cyberattacks with the constant shift\ntoward interconnected vehicles. Electronic Control Units (ECUs) installed on\ncars often operate in a critical and hostile environment. Hence, both carmakers\nand governments have supported initiatives to mitigate risks and threats\nbelonging to the automotive domain. The Local Interconnect Network (LIN) is one\nof the most used communication protocols in the automotive field. Today's LIN\nbuses have just a few light security mechanisms to assure integrity through\nMessage Authentication Codes (MAC). However, several limitations with strong\nconstraints make applying those techniques to LIN networks challenging, leaving\nseveral vehicles still unprotected. This paper presents LIN Multiplexed MAC\n(LINMM), a new approach for exploiting signal modulation to multiplex MAC data\nwith standard LIN communication. LINMM allows for transmitting MAC payloads,\nmaintaining fullback compatibility with all versions of the standard LIN\nprotocol.",
    "descriptor": "",
    "authors": [
      "Franco Oberti",
      "Ernesto Sanchez",
      "Alessandro Savino",
      "Filippo Parisi",
      "Mirco Brero",
      "Stefano Di Carlo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.02602"
  },
  {
    "id": "arXiv:2206.02603",
    "title": "CAN-MM: Multiplexed Message Authentication Code for Controller Area  Network message authentication in road vehicles",
    "abstract": "The automotive market is increasingly profitable for cyberattacks with the\nconstant shift toward fully interconnected vehicles. Electronic Control Units\n(ECUs) installed on cars often operate in a critical and hostile environment.\nHence, both carmakers and governments have decided to support a series of\ninitiatives to mitigate risks and threats belonging to the automotive domain.\nThe Controller Area Network (CAN) is the primary communication protocol in the\nautomotive field, and the integrity of the communication over this network is\nassured through Message Authentication Codes (MAC). However, limitations in\nthroughput and frame size limit the application of this technique to specific\nversions of the CAN protocol, leaving several vehicles still unprotected. This\npaper presents CAN Multiplexed MAC (CAN-MM), a new approach exploiting\nfrequency modulation to multiplex MAC data with standard CAN communication.\nCAN-MM allows transmitting MAC payloads maintaining full-back compatibility\nwith all versions of the standard CAN protocol. Moreover, multiplexing allows\nsending DATA and MAC simultaneously.",
    "descriptor": "",
    "authors": [
      "Franco Oberti",
      "Ernesto Sanchez",
      "Alessandro Savino",
      "Filippo Parisi",
      "Stefano Di Carlo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.02603"
  },
  {
    "id": "arXiv:2206.02606",
    "title": "Verifying generalised and structural soundness of workflow nets via  relaxations",
    "abstract": "Workflow nets are a well-established mathematical formalism for the analysis\nof business processes arising from either modeling tools or process mining. The\ncentral decision problems for workflow nets are $k$-soundness, generalised\nsoundness and structural soundness. Most existing tools focus on $k$-soundness.\nIn this work, we propose novel scalable semi-procedures for generalised and\nstructural soundness. This is achieved via integral and continuous Petri net\nreachability relaxations. We show that our approach is competitive against\nstate-of-the-art tools.",
    "descriptor": "\nComments: Accepted at CAV 2022\n",
    "authors": [
      "Michael Blondin",
      "Filip Mazowiecki",
      "Philip Offtermatt"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.02606"
  },
  {
    "id": "arXiv:2206.02607",
    "title": "CROM: Continuous Reduced-Order Modeling of PDEs Using Implicit Neural  Representations",
    "abstract": "The excessive runtime of high-fidelity partial differential equation (PDE)\nsolvers makes them unsuitable for time-critical applications. We propose to\naccelerate PDE solvers using reduced-order modeling (ROM). Whereas prior ROM\napproaches reduce the dimensionality of discretized vector fields, our\ncontinuous reduced-order modeling (CROM) approach builds a smooth,\nlow-dimensional manifold of the continuous vector fields themselves, not their\ndiscretization. We represent this reduced manifold using neural fields, relying\non their continuous and differentiable nature to efficiently solve the PDEs.\nCROM may train on any and all available numerical solutions of the continuous\nsystem, even when they are obtained using diverse methods or discretizations.\nAfter the low-dimensional manifolds are built, solving PDEs requires\nsignificantly less computational resources. Since CROM is\ndiscretization-agnostic, CROM-based PDE solvers may optimally adapt\ndiscretization resolution over time to economize computation. We validate our\napproach on an extensive range of PDEs with training data from voxel grids,\nmeshes, and point clouds. Large-scale experiments demonstrate that our approach\nobtains speed, memory, and accuracy advantages over prior ROM approaches while\ngaining 109$\\times$ wall-clock speedup over full-order models on CPUs and\n89$\\times$ speedup on GPUs.",
    "descriptor": "",
    "authors": [
      "Peter Yichen Chen",
      "Jinxu Xiang",
      "Dong Heon Cho",
      "G A Pershing",
      "Henrique Teles Maia",
      "Maurizio Chiaramonte",
      "Kevin Carlberg",
      "Eitan Grinspun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Graphics (cs.GR)",
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.02607"
  },
  {
    "id": "arXiv:2206.02608",
    "title": "What do tokens know about their characters and how do they know it?",
    "abstract": "Pre-trained language models (PLMs) that use subword tokenization schemes can\nsucceed at a variety of language tasks that require character-level\ninformation, despite lacking explicit access to the character composition of\ntokens. Here, studying a range of models (e.g., GPT- J, BERT, RoBERTa, GloVe),\nwe probe what word pieces encode about character-level information by training\nclassifiers to predict the presence or absence of a particular alphabetical\ncharacter in a token, based on its embedding (e.g., probing whether the model\nembedding for \"cat\" encodes that it contains the character \"a\"). We find that\nthese models robustly encode character-level information and, in general,\nlarger models perform better at the task. We show that these results generalize\nto characters from non-Latin alphabets (Arabic, Devanagari, and Cyrillic).\nThen, through a series of experiments and analyses, we investigate the\nmechanisms through which PLMs acquire English-language character information\nduring training and argue that this knowledge is acquired through multiple\nphenomena, including a systematic relationship between particular characters\nand particular parts of speech, as well as natural variability in the\ntokenization of related strings.",
    "descriptor": "",
    "authors": [
      "Ayush Kaushal",
      "Kyle Mahowald"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.02608"
  },
  {
    "id": "arXiv:2206.02609",
    "title": "Real-World Image Super-Resolution by Exclusionary Dual-Learning",
    "abstract": "Real-world image super-resolution is a practical image restoration problem\nthat aims to obtain high-quality images from in-the-wild input, has recently\nreceived considerable attention with regard to its tremendous application\npotentials. Although deep learning-based methods have achieved promising\nrestoration quality on real-world image super-resolution datasets, they ignore\nthe relationship between L1- and perceptual- minimization and roughly adopt\nauxiliary large-scale datasets for pre-training. In this paper, we discuss the\nimage types within a corrupted image and the property of perceptual- and\nEuclidean- based evaluation protocols. Then we propose a method, Real-World\nimage Super-Resolution by Exclusionary Dual-Learning (RWSR-EDL) to address the\nfeature diversity in perceptual- and L1- based cooperative learning. Moreover,\na noise-guidance data collection strategy is developed to address the training\ntime consumption in multiple datasets optimization. When an auxiliary dataset\nis incorporated, RWSR-EDL achieves promising results and repulses any training\ntime increment by adopting the noise-guidance data collection strategy.\nExtensive experiments show that RWSR-EDL achieves competitive performance over\nstate-of-the-art methods on four in-the-wild image super-resolution datasets.",
    "descriptor": "\nComments: IEEE TMM 2022; Considering large volume of RealSR datasets, a multi-dataset sampling scheme is developed\n",
    "authors": [
      "Hao Li",
      "Jinghui Qin",
      "Zhijing Yang",
      "Pengxu Wei",
      "Jinshan Pan",
      "Liang Lin",
      "Yukai Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.02609"
  },
  {
    "id": "arXiv:2206.02617",
    "title": "Per-Instance Privacy Accounting for Differentially Private Stochastic  Gradient Descent",
    "abstract": "Differentially private stochastic gradient descent (DP-SGD) is the workhorse\nalgorithm for recent advances in private deep learning. It provides a single\nprivacy guarantee to all datapoints in the dataset. We propose an efficient\nalgorithm to compute per-instance privacy guarantees for individual examples\nwhen running DP-SGD. We use our algorithm to investigate per-instance privacy\nlosses across a number of datasets. We find that most examples enjoy stronger\nprivacy guarantees than the worst-case bounds. We further discover that the\nloss and the privacy loss on an example are well-correlated. This implies\ngroups that are underserved in terms of model utility are simultaneously\nunderserved in terms of privacy loss. For example, on CIFAR-10, the average\n$\\epsilon$ of the class with the highest loss (Cat) is 32% higher than that of\nthe class with the lowest loss (Ship). We also run membership inference attacks\nto show this reflects disparate empirical privacy risks.",
    "descriptor": "",
    "authors": [
      "Da Yu",
      "Gautam Kamath",
      "Janardhan Kulkarni",
      "Jian Yin",
      "Tie-Yan Liu",
      "Huishuai Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.02617"
  },
  {
    "id": "arXiv:2206.02618",
    "title": "Generalized Federated Learning via Sharpness Aware Minimization",
    "abstract": "Federated Learning (FL) is a promising framework for performing\nprivacy-preserving, distributed learning with a set of clients. However, the\ndata distribution among clients often exhibits non-IID, i.e., distribution\nshift, which makes efficient optimization difficult. To tackle this problem,\nmany FL algorithms focus on mitigating the effects of data heterogeneity across\nclients by increasing the performance of the global model. However, almost all\nalgorithms leverage Empirical Risk Minimization (ERM) to be the local\noptimizer, which is easy to make the global model fall into a sharp valley and\nincrease a large deviation of parts of local clients. Therefore, in this paper,\nwe revisit the solutions to the distribution shift problem in FL with a focus\non local learning generality. To this end, we propose a general, effective\nalgorithm, \\texttt{FedSAM}, based on Sharpness Aware Minimization (SAM) local\noptimizer, and develop a momentum FL algorithm to bridge local and global\nmodels, \\texttt{MoFedSAM}. Theoretically, we show the convergence analysis of\nthese two algorithms and demonstrate the generalization bound of\n\\texttt{FedSAM}. Empirically, our proposed algorithms substantially outperform\nexisting FL studies and significantly decrease the learning deviation.",
    "descriptor": "",
    "authors": [
      "Zhe Qu",
      "Xingyu Li",
      "Rui Duan",
      "Yao Liu",
      "Bo Tang",
      "Zhuo Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02618"
  },
  {
    "id": "arXiv:2206.02619",
    "title": "VPIT: Real-time Embedded Single Object 3D Tracking Using Voxel Pseudo  Images",
    "abstract": "In this paper, we propose a novel voxel-based 3D single object tracking (3D\nSOT) method called Voxel Pseudo Image Tracking (VPIT). VPIT is the first method\nthat uses voxel pseudo images for 3D SOT. The input point cloud is structured\nby pillar-based voxelization, and the resulting pseudo image is used as an\ninput to a 2D-like Siamese SOT method. The pseudo image is created in the\nBird's-eye View (BEV) coordinates, and therefore the objects in it have\nconstant size. Thus, only the object rotation can change in the new coordinate\nsystem and not the object scale. For this reason, we replace multi-scale search\nwith a multi-rotation search, where differently rotated search regions are\ncompared against a single target representation to predict both position and\nrotation of the object. Experiments on KITTI Tracking dataset show that VPIT is\nthe fastest 3D SOT method and maintains competitive Success and Precision\nvalues. Application of a SOT method in a real-world scenario meets with\nlimitations such as lower computational capabilities of embedded devices and a\nlatency-unforgiving environment, where the method is forced to skip certain\ndata frames if the inference speed is not high enough. We implement a real-time\nevaluation protocol and show that other methods lose most of their performance\non embedded devices, while VPIT maintains its ability to track the object.",
    "descriptor": "\nComments: 10 pages, 5 figures, 4 tables. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Illia Oleksiienko",
      "Paraskevi Nousi",
      "Nikolaos Passalis",
      "Anastasios Tefas",
      "Alexandros Iosifidis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02619"
  },
  {
    "id": "arXiv:2206.02620",
    "title": "ResAct: Reinforcing Long-term Engagement in Sequential Recommendation  with Residual Actor",
    "abstract": "Long-term engagement is preferred over immediate engagement in sequential\nrecommendation as it directly affects product operational metrics such as daily\nactive users (DAUs) and dwell time. Meanwhile, reinforcement learning (RL) is\nwidely regarded as a promising framework for optimizing long-term engagement in\nsequential recommendation. However, due to expensive online interactions, it is\nvery difficult for RL algorithms to perform state-action value estimation,\nexploration and feature extraction when optimizing long-term engagement. In\nthis paper, we propose ResAct which seeks a policy that is close to, but better\nthan, the online-serving policy. In this way, we can collect sufficient data\nnear the learned policy so that state-action values can be properly estimated,\nand there is no need to perform online exploration. Directly optimizing this\npolicy is difficult due to the huge policy space. ResAct instead solves it by\nfirst reconstructing the online behaviors and then improving it. Our main\ncontributions are fourfold. First, we design a generative model which\nreconstructs behaviors of the online-serving policy by sampling multiple action\nestimators. Second, we design an effective learning paradigm to train the\nresidual actor which can output the residual for action improvement. Third, we\nfacilitate the extraction of features with two information theoretical\nregularizers to confirm the expressiveness and conciseness of features. Fourth,\nwe conduct extensive experiments on a real world dataset consisting of millions\nof sessions, and our method significantly outperforms the state-of-the-art\nbaselines in various of long term engagement optimization tasks.",
    "descriptor": "",
    "authors": [
      "Wanqi Xue",
      "Qingpeng Cai",
      "Ruohan Zhan",
      "Dong Zheng",
      "Peng Jiang",
      "Bo An"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02620"
  },
  {
    "id": "arXiv:2206.02622",
    "title": "Hardware-accelerated Mars Sample Localization via deep transfer learning  from photorealistic simulations",
    "abstract": "The goal of the Mars Sample Return campaign is to collect soil samples from\nthe surface of Mars and return them to Earth for further study. The samples\nwill be acquired and stored in metal tubes by the Perseverance rover and\ndeposited on the Martian surface. As part of this campaign, it is expected the\nSample Fetch Rover will be in charge of localizing and gathering up to 35\nsample tubes over 150 Martian sols. Autonomous capabilities are critical for\nthe success of the overall campaign and for the Sample Fetch Rover in\nparticular. This work proposes a novel approach for the autonomous detection\nand pose estimation of the sample tubes. For the detection stage, a Deep Neural\nNetwork and transfer learning from a synthetic dataset are proposed. The\ndataset is created from photorealistic 3D simulations of Martian scenarios.\nAdditionally, Computer Vision techniques are used to estimate the detected\nsample tubes poses. Finally, laboratory tests of the Sample Localization\nprocedure are performed using the ExoMars Testing Rover on a Mars-like testbed.\nThese tests validate the proposed approach in different hardware architectures,\nproviding promising results related to the sample detection and pose\nestimation.",
    "descriptor": "",
    "authors": [
      "Ra\u00fal Castilla-Arquillo",
      "Carlos Jes\u00fas P\u00e9rez-del-Pulgar",
      "Gonzalo Jes\u00fas Paz-Delgado",
      "Levin Gerdes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.02622"
  },
  {
    "id": "arXiv:2206.02626",
    "title": "Infinite Recommendation Networks: A Data-Centric Approach",
    "abstract": "We leverage the Neural Tangent Kernel and its equivalence to training\ninfinitely-wide neural networks to devise $\\infty$-AE: an autoencoder with\ninfinitely-wide bottleneck layers. The outcome is a highly expressive yet\nsimplistic recommendation model with a single hyper-parameter and a closed-form\nsolution. Leveraging $\\infty$-AE's simplicity, we also develop Distill-CF for\nsynthesizing tiny, high-fidelity data summaries which distill the most\nimportant knowledge from the extremely large and sparse user-item interaction\nmatrix for efficient and accurate subsequent data-usage like model training,\ninference, architecture search, etc. This takes a data-centric approach to\nrecommendation, where we aim to improve the quality of logged user-feedback\ndata for subsequent modeling, independent of the learning algorithm. We\nparticularly utilize the concept of differentiable Gumbel-sampling to handle\nthe inherent data heterogeneity, sparsity, and semi-structuredness, while being\nscalable to datasets with hundreds of millions of user-item interactions. Both\nof our proposed approaches significantly outperform their respective\nstate-of-the-art and when used together, we observe 96-105% of $\\infty$-AE's\nperformance on the full dataset with as little as 0.1% of the original dataset\nsize, leading us to explore the counter-intuitive question: Is more data what\nyou need for better recommendation?",
    "descriptor": "\nComments: 22 pages, 14 figures, submitted to NeurIPS'22\n",
    "authors": [
      "Noveen Sachdeva",
      "Mehak Preet Dhaliwal",
      "Carole-Jean Wu",
      "Julian McAuley"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02626"
  },
  {
    "id": "arXiv:2206.02627",
    "title": "DCAN: Diversified News Recommendation with Coverage-Attentive Networks",
    "abstract": "Self-attention based models are widely used in news recommendation tasks.\nHowever, previous Attention architecture does not constrain repeated\ninformation in the user's historical behavior, which limits the power of hidden\nrepresentation and leads to some problems such as information redundancy and\nfilter bubbles. To solve this problem, we propose a personalized news\nrecommendation model called DCAN.It captures multi-grained user-news matching\nsignals through news encoders and user encoders. We keep updating a coverage\nvector to track the history of news attention and augment the vector in 4 types\nof ways. Then we fed the augmented Coverage vector into the Multi-headed\nSelf-attention model to help adjust the future attention and added the Coverage\nregulation to the loss function(CRL), which enabled the recommendation system\nto consider more about differentiated information. Extensive experiments on\nMicrosoft News Recommendation Dataset (MIND) show that our model significantly\nimprove the diversity of news recommendations with minimal sacrifice in\naccuracy.",
    "descriptor": "\nComments: 9 pages, 6 figures\n",
    "authors": [
      "Hao Shi",
      "Zi-Jiao Wang",
      "Lan-Ru Zhai"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.02627"
  },
  {
    "id": "arXiv:2206.02628",
    "title": "HYCEDIS: HYbrid Confidence Engine for Deep Document Intelligence System",
    "abstract": "Measuring the confidence of AI models is critical for safely deploying AI in\nreal-world industrial systems. One important application of confidence\nmeasurement is information extraction from scanned documents. However, there\nexists no solution to provide reliable confidence score for current\nstate-of-the-art deep-learning-based information extractors. In this paper, we\npropose a complete and novel architecture to measure confidence of current deep\nlearning models in document information extraction task. Our architecture\nconsists of a Multi-modal Conformal Predictor and a Variational\nCluster-oriented Anomaly Detector, trained to faithfully estimate its\nconfidence on its outputs without the need of host models modification. We\nevaluate our architecture on real-wold datasets, not only outperforming\ncompeting confidence estimators by a huge margin but also demonstrating\ngeneralization ability to out-of-distribution data.",
    "descriptor": "\nComments: Document Intelligence @ KDD 2021 Workshop\n",
    "authors": [
      "Bao-Sinh Nguyen",
      "Quang-Bach Tran",
      "Tuan-Anh Nguyen Dang",
      "Duc Nguyen",
      "Hung Le"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.02628"
  },
  {
    "id": "arXiv:2206.02629",
    "title": "Backpropagation at the Infinitesimal Inference Limit of Energy-Based  Models: Unifying Predictive Coding, Equilibrium Propagation, and Contrastive  Hebbian Learning",
    "abstract": "How the brain performs credit assignment is a fundamental unsolved problem in\nneuroscience. Many `biologically plausible' algorithms have been proposed,\nwhich compute gradients that approximate those computed by backpropagation\n(BP), and which operate in ways that more closely satisfy the constraints\nimposed by neural circuitry. Many such algorithms utilize the framework of\nenergy-based models (EBMs), in which all free variables in the model are\noptimized to minimize a global energy function. However, in the literature,\nthese algorithms exist in isolation and no unified theory exists linking them\ntogether. Here, we provide a comprehensive theory of the conditions under which\nEBMs can approximate BP, which lets us unify many of the BP approximation\nresults in the literature (namely, predictive coding, equilibrium propagation,\nand contrastive Hebbian learning) and demonstrate that their approximation to\nBP arises from a simple and general mathematical property of EBMs at free-phase\nequilibrium. This property can then be exploited in different ways with\ndifferent energy functions, and these specific choices yield a family of\nBP-approximating algorithms, which both includes the known results in the\nliterature and can be used to derive new ones.",
    "descriptor": "\nComments: 31/05/22 initial upload\n",
    "authors": [
      "Beren Millidge",
      "Yuhang Song",
      "Tommaso Salvatori",
      "Thomas Lukasiewicz",
      "Rafal Bogacz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2206.02629"
  },
  {
    "id": "arXiv:2206.02630",
    "title": "Improving Ads-Profitability Using Traffic-Fingerprints",
    "abstract": "This paper introduces the concept of traffic-fingerprints, i.e., normalized\n24-dimensional vectors representing a distribution of daily traffic on a web\npage. Using k-means clustering we show that similarity of traffic-fingerprints\nis related to the similarity of profitability time patterns for ads shown on\nthese pages. In other words, these fingerprints are correlated with the\nconversions rates, thus allowing us to argue about conversion rates on pages\nwith negligible traffic. By blocking or unblocking whole clusters of pages we\nwere able to increase the revenue of online campaigns by more than 50%.",
    "descriptor": "",
    "authors": [
      "Adam Gabriel Dobrakowski",
      "Andrzej Pacuk",
      "Piotr Sankowski",
      "Marcin Mucha",
      "Pawe\u0142 Brach"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02630"
  },
  {
    "id": "arXiv:2206.02631",
    "title": "A Survey on Modern Recommendation System based on Big Data",
    "abstract": "Recommendation systems have become very popular in recent years and are used\nin various web applications. Modern recommendation systems aim at providing\nusers with personalized recommendations of online products or services. Various\nrecommendation techniques, such as content-based, collaborative\nfiltering-based, knowledge-based, and hybrid-based recommendation systems, have\nbeen developed to fulfill the needs in different scenarios. This paper presents\na comprehensive review of historical and recent state-of-the-art recommendation\napproaches, followed by an in-depth analysis of groundbreaking advances in\nmodern recommendation systems based on big data. Furthermore, this paper\nreviews the issues faced in modern recommendation systems such as sparsity,\nscalability, and diversity and illustrates how these challenges can be\ntransformed into prolific future research avenues.",
    "descriptor": "",
    "authors": [
      "Yuanzhe Peng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.02631"
  },
  {
    "id": "arXiv:2206.02632",
    "title": "Contextualization for the Organization of Text Documents Streams",
    "abstract": "There has been a significant effort by the research community to address the\nproblem of providing methods to organize documentation with the help of\ninformation Retrieval methods. In this report paper, we present several\nexperiments with some stream analysis methods to explore streams of text\ndocuments. We use only dynamic algorithms to explore, analyze, and organize the\nflux of text documents. This document shows a case study with developed\narchitectures of a Text Document Stream Organization, using incremental\nalgorithms like Incremental TextRank, and IS-TFIDF. Both these algorithms are\nbased on the assumption that the mapping of text documents and their\ndocument-term matrix in lower-dimensional evolving networks provides faster\nprocessing when compared to batch algorithms. With this architecture, and by\nusing FastText Embedding to retrieve similarity between documents, we compare\nmethods with large text datasets and ground truth evaluation of clustering\ncapacities. The datasets used were Reuters and COVID-19 emotions. The results\nprovide a new view for the contextualization of similarity when approaching\nflux of documents organization tasks, based on the similarity between documents\nin the flux, and by using mentioned algorithms.",
    "descriptor": "",
    "authors": [
      "Rui Portocarrero Sarmento",
      "Douglas O. Cardoso",
      "Jo\u00e3o Gama",
      "Pavel Brazdil"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2206.02632"
  },
  {
    "id": "arXiv:2206.02633",
    "title": "Towards Fair Federated Recommendation Learning: Characterizing the  Inter-Dependence of System and Data Heterogeneity",
    "abstract": "Federated learning (FL) is an effective mechanism for data privacy in\nrecommender systems by running machine learning model training on-device. While\nprior FL optimizations tackled the data and system heterogeneity challenges\nfaced by FL, they assume the two are independent of each other. This\nfundamental assumption is not reflective of real-world, large-scale recommender\nsystems -- data and system heterogeneity are tightly intertwined. This paper\ntakes a data-driven approach to show the inter-dependence of data and system\nheterogeneity in real-world data and quantifies its impact on the overall model\nquality and fairness. We design a framework, RF^2, to model the\ninter-dependence and evaluate its impact on state-of-the-art model optimization\ntechniques for federated recommendation tasks. We demonstrate that the impact\non fairness can be severe under realistic heterogeneity scenarios, by up to\n15.8--41x compared to a simple setup assumed in most (if not all) prior work.\nIt means when realistic system-induced data heterogeneity is not properly\nmodeled, the fairness impact of an optimization can be downplayed by up to 41x.\nThe result shows that modeling realistic system-induced data heterogeneity is\nessential to achieving fair federated recommendation learning. We plan to\nopen-source RF^2 to enable future design and evaluation of FL innovations.",
    "descriptor": "",
    "authors": [
      "Kiwan Maeng",
      "Haiyu Lu",
      "Luca Melis",
      "John Nguyen",
      "Mike Rabbat",
      "Carole-Jean Wu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02633"
  },
  {
    "id": "arXiv:2206.02640",
    "title": "Policy Optimization for Markov Games: Unified Framework and Faster  Convergence",
    "abstract": "This paper studies policy optimization algorithms for multi-agent\nreinforcement learning. We begin by proposing an algorithm framework for\ntwo-player zero-sum Markov Games in the full-information setting, where each\niteration consists of a policy update step at each state using a certain matrix\ngame algorithm, and a value update step with a certain learning rate. This\nframework unifies many existing and new policy optimization algorithms. We show\nthat the state-wise average policy of this algorithm converges to an\napproximate Nash equilibrium (NE) of the game, as long as the matrix game\nalgorithms achieve low weighted regret at each state, with respect to weights\ndetermined by the speed of the value updates. Next, we show that this framework\ninstantiated with the Optimistic Follow-The-Regularized-Leader (OFTRL)\nalgorithm at each state (and smooth value updates) can find an\n$\\mathcal{\\widetilde{O}}(T^{-5/6})$ approximate NE in $T$ iterations, which\nimproves over the current best $\\mathcal{\\widetilde{O}}(T^{-1/2})$ rate of\nsymmetric policy optimization type algorithms. We also extend this algorithm to\nmulti-player general-sum Markov Games and show an\n$\\mathcal{\\widetilde{O}}(T^{-3/4})$ convergence rate to Coarse Correlated\nEquilibria (CCE). Finally, we provide a numerical example to verify our theory\nand investigate the importance of smooth value updates, and find that using\n\"eager\" value updates instead (equivalent to the independent natural policy\ngradient algorithm) may significantly slow down the convergence, even on a\nsimple game with $H=2$ layers.",
    "descriptor": "",
    "authors": [
      "Runyu Zhang",
      "Qinghua Liu",
      "Huan Wang",
      "Caiming Xiong",
      "Na Li",
      "Yu Bai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.02640"
  },
  {
    "id": "arXiv:2206.02647",
    "title": "Scaling Vision Transformers to Gigapixel Images via Hierarchical  Self-Supervised Learning",
    "abstract": "Vision Transformers (ViTs) and their multi-scale and hierarchical variations\nhave been successful at capturing image representations but their use has been\ngenerally studied for low-resolution images (e.g. - 256x256, 384384). For\ngigapixel whole-slide imaging (WSI) in computational pathology, WSIs can be as\nlarge as 150000x150000 pixels at 20X magnification and exhibit a hierarchical\nstructure of visual tokens across varying resolutions: from 16x16 images\ncapture spatial patterns among cells, to 4096x4096 images characterizing\ninteractions within the tissue microenvironment. We introduce a new ViT\narchitecture called the Hierarchical Image Pyramid Transformer (HIPT), which\nleverages the natural hierarchical structure inherent in WSIs using two levels\nof self-supervised learning to learn high-resolution image representations.\nHIPT is pretrained across 33 cancer types using 10,678 gigapixel WSIs, 408,218\n4096x4096 images, and 104M 256x256 images. We benchmark HIPT representations on\n9 slide-level tasks, and demonstrate that: 1) HIPT with hierarchical\npretraining outperforms current state-of-the-art methods for cancer subtyping\nand survival prediction, 2) self-supervised ViTs are able to model important\ninductive biases about the hierarchical structure of phenotypes in the tumor\nmicroenvironment.",
    "descriptor": "\nComments: Accepted to CVPR 2022 (Oral)\n",
    "authors": [
      "Richard J. Chen",
      "Chengkuan Chen",
      "Yicong Li",
      "Tiffany Y. Chen",
      "Andrew D. Trister",
      "Rahul G. Krishnan",
      "Faisal Mahmood"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02647"
  },
  {
    "id": "arXiv:2206.02653",
    "title": "Abstraction-Refinement for Hierarchical Probabilistic Models",
    "abstract": "Markov decision processes are a ubiquitous formalism for modelling systems\nwith non-deterministic and probabilistic behavior. Verification of these models\nis subject to the famous state space explosion problem. We alleviate this\nproblem by exploiting a hierarchical structure with repetitive parts. This\nstructure not only occurs naturally in robotics, but also in probabilistic\nprograms describing, e.g., network protocols. Such programs often repeatedly\ncall a subroutine with similar behavior. In this paper, we focus on a local\ncase, in which the subroutines have a limited effect on the overall system\nstate. The key ideas to accelerate analysis of such programs are (1) to treat\nthe behavior of the subroutine as uncertain and only remove this uncertainty by\na detailed analysis if needed, and (2) to abstract similar subroutines into a\nparametric template, and then analyse this template. These two ideas are\nembedded into an abstraction-refinement loop that analyses hierarchical MDPs. A\nprototypical implementation shows the efficacy of the approach.",
    "descriptor": "\nComments: Extended submitted version for CAV 2022\n",
    "authors": [
      "Sebastian Junges",
      "Matthijs T. J. Spaan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.02653"
  },
  {
    "id": "arXiv:2206.02656",
    "title": "A Regret-Variance Trade-Off in Online Learning",
    "abstract": "We consider prediction with expert advice for strongly convex and bounded\nlosses, and investigate trade-offs between regret and \"variance\" (i.e., squared\ndifference of learner's predictions and best expert predictions). With $K$\nexperts, the Exponentially Weighted Average (EWA) algorithm is known to achieve\n$O(\\log K)$ regret. We prove that a variant of EWA either achieves a negative\nregret (i.e., the algorithm outperforms the best expert), or guarantees a\n$O(\\log K)$ bound on both variance and regret. Building on this result, we show\nseveral examples of how variance of predictions can be exploited in learning.\nIn the online to batch analysis, we show that a large empirical variance allows\nto stop the online to batch conversion early and outperform the risk of the\nbest predictor in the class. We also recover the optimal rate of model\nselection aggregation when we do not consider early stopping. In online\nprediction with corrupted losses, we show that the effect of corruption on the\nregret can be compensated by a large variance. In online selective sampling, we\ndesign an algorithm that samples less when the variance is large, while\nguaranteeing the optimal regret bound in expectation. In online learning with\nabstention, we use a similar term as the variance to derive the first\nhigh-probability $O(\\log K)$ regret bound in this setting. Finally, we extend\nour results to the setting of online linear regression.",
    "descriptor": "",
    "authors": [
      "Dirk van der Hoeven",
      "Nikita Zhivotovskiy",
      "Nicol\u00f2 Cesa-Bianchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.02656"
  },
  {
    "id": "arXiv:2206.02658",
    "title": "Longitudinal Analysis of Privacy Labels in the Apple App Store",
    "abstract": "In December of 2020, Apple started to require app developers to annotate\ntheir apps with privacy labels that indicate what data is collected and how it\nis used. We collected and analyzed 36 weekly snapshots of 1.6 million apps\nbetween July 15, 2021 and March 17, 2022 to better understand the privacy label\necosystem, the categories and types of data collected, and the purposes that\ndevelopers used to justify that collection. Nearly two years after privacy\nlabels launched, only 60.5% of apps have privacy labels, increasing by an\naverage of 0.5% per week, mostly driven by new apps rather than older apps\ncoming into compliance. Of apps with labels, 17.3% collect data used to track\nusers, 37.6% collect data that is linked to a user identity, and 41.9% collect\ndata that is not linked. Only 42.1% of apps with labels indicate that they do\nnot collect any data. We find that because many apps indicate that they do not\ncollect any data, even apps that would seem likely to collect or link data,\ntrusting the veracity of privacy labels is still an open question.",
    "descriptor": "",
    "authors": [
      "David G. Balash",
      "Mir Masood Ali",
      "Xiaoyuan Wu",
      "Chris Kanich",
      "Adam J. Aviv"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.02658"
  },
  {
    "id": "arXiv:2206.02659",
    "title": "Robust Fine-Tuning of Deep Neural Networks with Hessian-based  Generalization Guarantees",
    "abstract": "We consider transfer learning approaches that fine-tune a pretrained deep\nneural network on a target task. We investigate generalization properties of\nfine-tuning to understand the problem of overfitting, which often happens in\npractice. Previous works have shown that constraining the distance from the\ninitialization of fine-tuning improves generalization. Using a PAC-Bayesian\nanalysis, we observe that besides distance from initialization, Hessians affect\ngeneralization through the noise stability of deep neural networks against\nnoise injections. Motivated by the observation, we develop Hessian\ndistance-based generalization bounds for a wide range of fine-tuning methods.\nNext, we investigate the robustness of fine-tuning with noisy labels. We design\nan algorithm that incorporates consistent losses and distance-based\nregularization for fine-tuning. Additionally, we prove a generalization error\nbound of our algorithm under class conditional independent noise in the\ntraining dataset labels. We perform a detailed empirical study of our algorithm\non various noisy environments and architectures. For example, on six image\nclassification tasks whose training labels are generated with programmatic\nlabeling, we show a 3.26% accuracy improvement over prior methods. Meanwhile,\nthe Hessian distance measure of the fine-tuned network using our algorithm\ndecreases by six times more than existing approaches.",
    "descriptor": "\nComments: 36 pages, 5 figures, 7 tables\n",
    "authors": [
      "Haotian Ju",
      "Dongyue Li",
      "Hongyang R. Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.02659"
  },
  {
    "id": "arXiv:2206.02660",
    "title": "Port-Hamiltonian Neural Networks with State Dependent Ports",
    "abstract": "Hybrid machine learning based on Hamiltonian formulations has recently been\nsuccessfully demonstrated for simple mechanical systems. In this work, we\nstress-test the method on both simple mass-spring systems and more complex and\nrealistic systems with several internal and external forces, including a system\nwith multiple connected tanks. We quantify performance under various conditions\nand show that imposing different assumptions greatly affect the performance\nduring training presenting advantages and limitations of the method. We\ndemonstrate that port-Hamiltonian neural networks can be extended to larger\ndimensions with state-dependent ports. We consider learning on systems with\nknown and unknown external forces and show how it can be used to detect\ndeviations in a system and still provide a valid model when the deviations are\nremoved. Finally, we propose a symmetric high-order integrator for improved\ntraining on sparse and noisy data.",
    "descriptor": "\nComments: 23 pages, 12 figures\n",
    "authors": [
      "S\u00f8lve Eidnes",
      "Alexander J. Stasik",
      "Camilla Sterud",
      "Eivind B\u00f8hn",
      "Signe Riemer-S\u00f8rensen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.02660"
  },
  {
    "id": "arXiv:2206.02661",
    "title": "Evaluating Deep Taylor Decomposition for Reliability Assessment in the  Wild",
    "abstract": "We argue that we need to evaluate model interpretability methods 'in the\nwild', i.e., in situations where professionals make critical decisions, and\nmodels can potentially assist them. We present an in-the-wild evaluation of\ntoken attribution based on Deep Taylor Decomposition, with professional\njournalists performing reliability assessments. We find that using this method\nin conjunction with RoBERTa-Large, fine-tuned on the Gossip Corpus, led to\nfaster and better human decision-making, as well as a more critical attitude\ntoward news sources among the journalists. We present a comparison of human and\nmodel rationales, as well as a qualitative analysis of the journalists'\nexperiences with machine-in-the-loop decision making.",
    "descriptor": "\nComments: ICWSM 2022\n",
    "authors": [
      "Stephanie Brandl",
      "Daniel Hershcovich",
      "Anders S\u00f8gaard"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.02661"
  },
  {
    "id": "arXiv:2206.02662",
    "title": "Medical Coding with Biomedical Transformer Ensembles and Zero/Few-shot  Learning",
    "abstract": "Medical coding (MC) is an essential pre-requisite for reliable data retrieval\nand reporting. Given a free-text reported term (RT) such as \"pain of right\nthigh to the knee\", the task is to identify the matching lowest-level term\n(LLT) - in this case \"unilateral leg pain\" - from a very large and continuously\ngrowing repository of standardized medical terms. However, automating this task\nis challenging due to a large number of LLT codes (as of writing over 80,000),\nlimited availability of training data for long tail/emerging classes, and the\ngeneral high accuracy demands of the medical domain. With this paper, we\nintroduce the MC task, discuss its challenges, and present a novel approach\ncalled xTARS that combines traditional BERT-based classification with a recent\nzero/few-shot learning approach (TARS). We present extensive experiments that\nshow that our combined approach outperforms strong baselines, especially in the\nfew-shot regime. The approach is developed and deployed at Bayer, live since\nNovember 2021. As we believe our approach potentially promising beyond MC, and\nto ensure reproducibility, we release the code to the research community.",
    "descriptor": "\nComments: NAACL-HLT 2022 Industry Track\n",
    "authors": [
      "Angelo Ziletti",
      "Alan Akbik",
      "Christoph Berns",
      "Thomas Herold",
      "Marion Legler",
      "Martina Viell"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02662"
  },
  {
    "id": "arXiv:2206.02663",
    "title": "TransBO: Hyperparameter Optimization via Two-Phase Transfer Learning",
    "abstract": "With the extensive applications of machine learning models, automatic\nhyperparameter optimization (HPO) has become increasingly important. Motivated\nby the tuning behaviors of human experts, it is intuitive to leverage auxiliary\nknowledge from past HPO tasks to accelerate the current HPO task. In this\npaper, we propose TransBO, a novel two-phase transfer learning framework for\nHPO, which can deal with the complementary nature among source tasks and\ndynamics during knowledge aggregation issues simultaneously. This framework\nextracts and aggregates source and target knowledge jointly and adaptively,\nwhere the weights can be learned in a principled manner. The extensive\nexperiments, including static and dynamic transfer learning settings and neural\narchitecture search, demonstrate the superiority of TransBO over the\nstate-of-the-arts.",
    "descriptor": "\nComments: 9 pages and 2 extra pages of appendix\n",
    "authors": [
      "Yang Li",
      "Yu Shen",
      "Huaijun Jiang",
      "Wentao Zhang",
      "Zhi Yang",
      "Ce Zhang",
      "Bin Cui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02663"
  },
  {
    "id": "arXiv:2206.02664",
    "title": "Learning with Capsules: A Survey",
    "abstract": "Capsule networks were proposed as an alternative approach to Convolutional\nNeural Networks (CNNs) for learning object-centric representations, which can\nbe leveraged for improved generalization and sample complexity. Unlike CNNs,\ncapsule networks are designed to explicitly model part-whole hierarchical\nrelationships by using groups of neurons to encode visual entities, and learn\nthe relationships between those entities. Promising early results achieved by\ncapsule networks have motivated the deep learning community to continue trying\nto improve their performance and scalability across several application areas.\nHowever, a major hurdle for capsule network research has been the lack of a\nreliable point of reference for understanding their foundational ideas and\nmotivations. The aim of this survey is to provide a comprehensive overview of\nthe capsule network research landscape, which will serve as a valuable resource\nfor the community going forward. To that end, we start with an introduction to\nthe fundamental concepts and motivations behind capsule networks, such as\nequivariant inference in computer vision. We then cover the technical advances\nin the capsule routing mechanisms and the various formulations of capsule\nnetworks, e.g. generative and geometric. Additionally, we provide a detailed\nexplanation of how capsule networks relate to the popular attention mechanism\nin Transformers, and highlight non-trivial conceptual similarities between them\nin the context of representation learning. Afterwards, we explore the extensive\napplications of capsule networks in computer vision, video and motion, graph\nrepresentation learning, natural language processing, medical imaging and many\nothers. To conclude, we provide an in-depth discussion regarding the main\nhurdles in capsule network research, and highlight promising research\ndirections for future work.",
    "descriptor": "\nComments: 29 pages, 43 figures\n",
    "authors": [
      "Fabio De Sousa Ribeiro",
      "Kevin Duarte",
      "Miles Everett",
      "Georgios Leontidis",
      "Mubarak Shah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02664"
  },
  {
    "id": "arXiv:2206.02666",
    "title": "Robust Pareto Set Identification with Contaminated Bandit Feedback",
    "abstract": "We consider the Pareto set identification (PSI) problem in multi-objective\nmulti-armed bandits (MO-MAB) with contaminated reward observations. At each arm\npull, with some probability, the true reward samples are replaced with the\nsamples from an arbitrary contamination distribution chosen by the adversary.\nWe propose a median-based MO-MAB algorithm for robust PSI that abides by the\naccuracy requirements set by the user via an accuracy parameter. We prove that\nthe sample complexity of this algorithm depends on the accuracy parameter\ninverse squarely. We compare the proposed algorithm with a mean-based method\nfrom MO-MAB literature on Gaussian reward distributions. Our numerical results\nverify our theoretical expectations and show the necessity for robust algorithm\ndesign in the adversarial setting.",
    "descriptor": "\nComments: 10 pages. Submitted to IEEE Transactions on Neural Networks and Learning Systems\n",
    "authors": [
      "Kerem Bozgan",
      "Cem Tekin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.02666"
  },
  {
    "id": "arXiv:2206.02667",
    "title": "Multi-learner risk reduction under endogenous participation dynamics",
    "abstract": "Prediction systems face exogenous and endogenous distribution shift -- the\nworld constantly changes, and the predictions the system makes change the\nenvironment in which it operates. For example, a music recommender observes\nexogeneous changes in the user distribution as different communities have\nincreased access to high speed internet. If users under the age of 18 enjoy\ntheir recommendations, the proportion of the user base comprised of those under\n18 may endogeneously increase. Most of the study of endogenous shifts has\nfocused on the single decision-maker setting, where there is one learner that\nusers either choose to use or not.\nThis paper studies participation dynamics between sub-populations and\npossibly many learners. We study the behavior of systems with\n\\emph{risk-reducing} learners and sub-populations. A risk-reducing learner\nupdates their decision upon observing a mixture distribution of the\nsub-populations $\\mathcal{D}$ in such a way that it decreases the risk of the\nlearner on that mixture. A risk reducing sub-population updates its\napportionment amongst learners in a way which reduces its overall loss.\nPrevious work on the single learner case shows that myopic risk minimization\ncan result in high overall loss~\\citep{perdomo2020performative,\nmiller2021outside} and representation disparity~\\citep{hashimoto2018fairness,\nzhang2019group}. Our work analyzes the outcomes of multiple myopic learners and\nmarket forces, often leading to better global loss and less representation\ndisparity.",
    "descriptor": "",
    "authors": [
      "Sarah Dean",
      "Mihaela Curmei",
      "Lillian J. Ratliff",
      "Jamie Morgenstern",
      "Maryam Fazel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.02667"
  },
  {
    "id": "arXiv:2206.02670",
    "title": "Robust Adversarial Attacks Detection based on Explainable Deep  Reinforcement Learning For UAV Guidance and Planning",
    "abstract": "The danger of adversarial attacks to unprotected Uncrewed Aerial Vehicle\n(UAV) agents operating in public is growing. Adopting AI-based techniques and\nmore specifically Deep Learning (DL) approaches to control and guide these UAVs\ncan be beneficial in terms of performance but add more concerns regarding the\nsafety of those techniques and their vulnerability against adversarial attacks\ncausing the chances of collisions going up as the agent becomes confused. This\npaper proposes an innovative approach based on the explainability of DL methods\nto build an efficient detector that will protect these DL schemes and thus the\nUAVs adopting them from potential attacks. The agent is adopting a Deep\nReinforcement Learning (DRL) scheme for guidance and planning. It is formed and\ntrained with a Deep Deterministic Policy Gradient (DDPG) with Prioritised\nExperience Replay (PER) DRL scheme that utilises Artificial Potential Field\n(APF) to improve training times and obstacle avoidance performance. The\nadversarial attacks are generated by Fast Gradient Sign Method (FGSM) and Basic\nIterative Method (BIM) algorithms and reduced obstacle course completion rates\nfrom 80\\% to 35\\%. A Realistic Synthetic environment for UAV explainable DRL\nbased planning and guidance including obstacles and adversarial attacks is\nbuilt. Two adversarial attack detectors are proposed. The first one adopts a\nConvolutional Neural Network (CNN) architecture and achieves an accuracy in\ndetection of 80\\%. The second detector is developed based on a Long Short Term\nMemory (LSTM) network and achieves an accuracy of 91\\% with much faster\ncomputing times when compared to the CNN based detector.",
    "descriptor": "\nComments: 13 pages, 20 figures\n",
    "authors": [
      "Thomas Hickling",
      "Nabil Aouf",
      "Phillippa Spencer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.02670"
  },
  {
    "id": "arXiv:2206.02671",
    "title": "Canonical Cortical Graph Neural Networks and its Application for Speech  Enhancement in Future Audio-Visual Hearing Aids",
    "abstract": "Despite the recent success of machine learning algorithms, most of these\nmodels still face several drawbacks when considering more complex tasks\nrequiring interaction between different sources, such as multimodal input data\nand logical time sequence. On the other hand, the biological brain is highly\nsharpened in this sense, empowered to automatically manage and integrate such a\nstream of information through millions of years of evolution. In this context,\nthis paper finds inspiration from recent discoveries on cortical circuits in\nthe brain to propose a more biologically plausible self-supervised machine\nlearning approach that combines multimodal information using intra-layer\nmodulations together with canonical correlation analysis (CCA), as well as a\nmemory mechanism to keep track of temporal data, the so-called Canonical\nCortical Graph Neural networks. The approach outperformed recent\nstate-of-the-art results considering both better clean audio reconstruction and\nenergy efficiency, described by a reduced and smother neuron firing rate\ndistribution, suggesting the model as a suitable approach for speech\nenhancement in future audio-visual hearing aid devices.",
    "descriptor": "",
    "authors": [
      "Leandro A. Passos",
      "Jo\u00e3o Paulo Papa",
      "Ahsan Adeel"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.02671"
  },
  {
    "id": "arXiv:2206.02675",
    "title": "Enhancing Safe Exploration Using Safety State Augmentation",
    "abstract": "Safe exploration is a challenging and important problem in model-free\nreinforcement learning (RL). Often the safety cost is sparse and unknown, which\nunavoidably leads to constraint violations -- a phenomenon ideally to be\navoided in safety-critical applications. We tackle this problem by augmenting\nthe state-space with a safety state, which is nonnegative if and only if the\nconstraint is satisfied. The value of this state also serves as a distance\ntoward constraint violation, while its initial value indicates the available\nsafety budget. This idea allows us to derive policies for scheduling the safety\nbudget during training. We call our approach Simmer (Safe policy IMproveMEnt\nfor RL) to reflect the careful nature of these schedules. We apply this idea to\ntwo safe RL problems: RL with constraints imposed on an average cost, and RL\nwith constraints imposed on a cost with probability one. Our experiments\nsuggest that simmering a safe algorithm can improve safety during training for\nboth settings. We further show that Simmer can stabilize training and improve\nthe performance of safe RL with average constraints.",
    "descriptor": "",
    "authors": [
      "Aivar Sootla",
      "Alexander I. Cowen-Rivers",
      "Jun Wang",
      "Haitham Bou Ammar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02675"
  },
  {
    "id": "arXiv:2206.02676",
    "title": "The structured distance to singularity of a symmetric tridiagonal  Toeplitz matrix",
    "abstract": "This paper is concerned with the distance of a symmetric tridiagonal Toeplitz\nmatrix $T$ to the variety of similarly structured singular matrices, and with\ndetermining the closest matrix to $T$ in this variety. Explicit formulas are\npresented, that exploit the analysis of the sensitivity of the smallest\neigenvalue in magnitude of $T$ with respect to structure-preserving\nperturbations of its entries. Also, in case $T$ is positive definite,\nmonotonicity properties of the entries of its Cholesky factor are shown.",
    "descriptor": "\nComments: 15 pages, 5 Figures\n",
    "authors": [
      "Silvia Noschese"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.02676"
  },
  {
    "id": "arXiv:2206.02678",
    "title": "Risk-Sensitive Reinforcement Learning: Iterated CVaR and the Worst Path",
    "abstract": "In this paper, we study a novel episodic risk-sensitive Reinforcement\nLearning (RL) problem, named Iterated CVaR RL, where the objective is to\nmaximize the tail of the reward-to-go at each step. Different from existing\nrisk-aware RL formulations, Iterated CVaR RL focuses on safety-at-all-time, by\nenabling the agent to tightly control the risk of getting into catastrophic\nsituations at each stage, and is applicable to important risk-sensitive tasks\nthat demand strong safety guarantees throughout the decision process, such as\nautonomous driving, clinical treatment planning and robotics. We investigate\nIterated CVaR RL with two performance metrics, i.e., Regret Minimization and\nBest Policy Identification. For both metrics, we design efficient algorithms\nICVaR-RM and ICVaR-BPI, respectively, and provide matching upper and lower\nbounds with respect to the number of episodes $K$. We also investigate an\ninteresting limiting case of Iterated CVaR RL, called Worst Path RL, where the\nobjective becomes to maximize the minimum possible cumulative reward, and\npropose an efficient algorithm with constant upper and lower bounds. Finally,\nthe techniques we develop for bounding the change of CVaR due to the value\nfunction shift and decomposing the regret via a distorted visitation\ndistribution are novel and can find applications in other risk-sensitive online\nlearning problems.",
    "descriptor": "",
    "authors": [
      "Yihan Du",
      "Siwei Wang",
      "Longbo Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02678"
  },
  {
    "id": "arXiv:2206.02679",
    "title": "Real2Sim or Sim2Real: Robotics Visual Insertion using Deep Reinforcement  Learning and Real2Sim Policy Adaptation",
    "abstract": "Reinforcement learning has shown a wide usage in robotics tasks, such as\ninsertion and grasping. However, without a practical sim2real strategy, the\npolicy trained in simulation could fail on the real task. There are also wide\nresearches in the sim2real strategies, but most of those methods rely on heavy\nimage rendering, domain randomization training, or tuning. In this work, we\nsolve the insertion task using a pure visual reinforcement learning solution\nwith minimum infrastructure requirement. We also propose a novel sim2real\nstrategy, Real2Sim, which provides a novel and easier solution in policy\nadaptation. We discuss the advantage of Real2Sim compared with Sim2Real.",
    "descriptor": "",
    "authors": [
      "Yiwen Chen",
      "Xue Li",
      "Sheng Guo",
      "Xian Yao Ng",
      "Marcelo Ang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02679"
  },
  {
    "id": "arXiv:2206.02680",
    "title": "Separable Self-attention for Mobile Vision Transformers",
    "abstract": "Mobile vision transformers (MobileViT) can achieve state-of-the-art\nperformance across several mobile vision tasks, including classification and\ndetection. Though these models have fewer parameters, they have high latency as\ncompared to convolutional neural network-based models. The main efficiency\nbottleneck in MobileViT is the multi-headed self-attention (MHA) in\ntransformers, which requires $O(k^2)$ time complexity with respect to the\nnumber of tokens (or patches) $k$. Moreover, MHA requires costly operations\n(e.g., batch-wise matrix multiplication) for computing self-attention,\nimpacting latency on resource-constrained devices. This paper introduces a\nseparable self-attention method with linear complexity, i.e. $O(k)$. A simple\nyet effective characteristic of the proposed method is that it uses\nelement-wise operations for computing self-attention, making it a good choice\nfor resource-constrained devices. The improved model, MobileViTv2, is\nstate-of-the-art on several mobile vision tasks, including ImageNet object\nclassification and MS-COCO object detection. With about three million\nparameters, MobileViTv2 achieves a top-1 accuracy of 75.6% on the ImageNet\ndataset, outperforming MobileViT by about 1% while running $3.2\\times$ faster\non a mobile device.\nOur source code is available at: \\url{https://github.com/apple/ml-cvnets}",
    "descriptor": "\nComments: Technical report\n",
    "authors": [
      "Sachin Mehta",
      "Mohammad Rastegari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02680"
  },
  {
    "id": "arXiv:2206.02687",
    "title": "Multi-Behavior Sequential Recommendation with Temporal Graph Transformer",
    "abstract": "Modeling time-evolving preferences of users with their sequential item\ninteractions, has attracted increasing attention in many online applications.\nHence, sequential recommender systems have been developed to learn the dynamic\nuser interests from the historical interactions for suggesting items. However,\nthe interaction pattern encoding functions in most existing sequential\nrecommender systems have focused on single type of user-item interactions. In\nmany real-life online platforms, user-item interactive behaviors are often\nmulti-typed (e.g., click, add-to-favorite, purchase) with complex cross-type\nbehavior inter-dependencies. Learning from informative representations of users\nand items based on their multi-typed interaction data, is of great importance\nto accurately characterize the time-evolving user preference. In this work, we\ntackle the dynamic user-item relation learning with the awareness of\nmulti-behavior interactive patterns. Towards this end, we propose a new\nTemporal Graph Transformer (TGT) recommendation framework to jointly capture\ndynamic short-term and long-range user-item interactive patterns, by exploring\nthe evolving correlations across different types of behaviors. The new TGT\nmethod endows the sequential recommendation architecture to distill dedicated\nknowledge for type-specific behavior relational context and the implicit\nbehavior dependencies. Experiments on the real-world datasets indicate that our\nmethod TGT consistently outperforms various state-of-the-art recommendation\nmethods. Our model implementation codes are available at\nhttps://github.com/akaxlh/TGT.",
    "descriptor": "\nComments: This paper has been published as a research paper at TKDE 2022\n",
    "authors": [
      "Lianghao Xia",
      "Chao Huang",
      "Yong Xu",
      "Jian Pei"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02687"
  },
  {
    "id": "arXiv:2206.02690",
    "title": "A Survey on Sentence Embedding Models Performance for Patent Analysis",
    "abstract": "Patent data is an important source of knowledge for innovation research.\nWhile the technological similarity between pairs of patents is a key enabling\nindicator for patent analysis. Recently researchers have been using patent\nvector space models based on different NLP embeddings models to calculate\ntechnological similarity between pairs of patents to help better understand\ninnovations, patent landscaping, technology mapping, and patent quality\nevaluation. To the best of our knowledge, there is not a comprehensive survey\nthat builds a big picture of embedding models' performance for calculating\npatent similarity indicators. Therefore, in this study, we provide an overview\nof the accuracy of these algorithms based on patent classification performance.\nIn a detailed discussion, we report the performance of the top 3 algorithms at\nsection, class, and subclass levels. The results based on the first claim of\npatents show that PatentSBERTa, Bert-for-patents, and TF-IDF Weighted Word\nEmbeddings have the best accuracy for computing sentence embeddings at the\nsubclass level. According to the first results, the performance of the models\nin different classes varies which shows researchers in patent analysis can\nutilize the results of this study for choosing the best proper model based on\nthe specific section of patent data they used.",
    "descriptor": "\nComments: 17 pages, 4 figures\n",
    "authors": [
      "Hamid Bekamiri",
      "Daniel S. Hain",
      "Roman Jurowetzki"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.02690"
  },
  {
    "id": "arXiv:2206.02696",
    "title": "Learning to Ask Like a Physician",
    "abstract": "Existing question answering (QA) datasets derived from electronic health\nrecords (EHR) are artificially generated and consequently fail to capture\nrealistic physician information needs. We present Discharge Summary Clinical\nQuestions (DiSCQ), a newly curated question dataset composed of 2,000+\nquestions paired with the snippets of text (triggers) that prompted each\nquestion. The questions are generated by medical experts from 100+ MIMIC-III\ndischarge summaries. We analyze this dataset to characterize the types of\ninformation sought by medical experts. We also train baseline models for\ntrigger detection and question generation (QG), paired with unsupervised answer\nretrieval over EHRs. Our baseline model is able to generate high quality\nquestions in over 62% of cases when prompted with human selected triggers. We\nrelease this dataset (and all code to reproduce baseline model results) to\nfacilitate further research into realistic clinical QA and QG:\nhttps://github.com/elehman16/discq.",
    "descriptor": "",
    "authors": [
      "Eric Lehman",
      "Vladislav Lialin",
      "Katelyn Y. Legaspi",
      "Anne Janelle R. Sy",
      "Patricia Therese S. Pile",
      "Nicole Rose I. Alberto",
      "Richard Raymund R. Ragasa",
      "Corinna Victoria M. Puyat",
      "Isabelle Rose I. Alberto",
      "Pia Gabrielle I. Alfonso",
      "Marianne Tali\u00f1o",
      "Dana Moukheiber",
      "Byron C. Wallace",
      "Anna Rumshisky",
      "Jenifer J. Liang",
      "Preethi Raghavan",
      "Leo Anthony Celi",
      "Peter Szolovits"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.02696"
  },
  {
    "id": "arXiv:2206.02700",
    "title": "Forbidding Edges between Points in the Plane to Disconnect the  Triangulation Flip Graph",
    "abstract": "The flip graph for a set $P$ of points in the plane has a vertex for every\ntriangulation of $P$, and an edge when two triangulations differ by one flip\nthat replaces one triangulation edge by another. The flip graph is known to\nhave some connectivity properties: (1) the flip graph is connected; (2)\nconnectivity still holds when restricted to triangulations containing some\nconstrained edges between the points; (3) for $P$ in general position of size\n$n$, the flip graph is $\\lceil \\frac{n}{2} -2 \\rceil$-connected, a recent\nresult of Wagner and Welzl (SODA 2020).\nWe introduce the study of connectivity properties of the flip graph when some\nedges between points are forbidden. An edge $e$ between two points is a flip\ncut edge if eliminating triangulations containing $e$ results in a disconnected\nflip graph. More generally, a set $X$ of edges between points of $P$ is a flip\ncut set if eliminating all triangulations that contain edges of $X$ results in\na disconnected flip graph. The flip cut number of $P$ is the minimum size of a\nflip cut set.\nWe give a characterization of flip cut edges that leads to an $O(n \\log n)$\ntime algorithm to test if an edge is a flip cut edge and, with that as\npreprocessing, an $O(n)$ time algorithm to test if two triangulations are in\nthe same connected component of the flip graph. For a set of $n$ points in\nconvex position (whose flip graph is the 1-skeleton of the associahedron) we\nprove that the flip cut number is $n-3$.",
    "descriptor": "",
    "authors": [
      "Reza Bigdeli",
      "Anna Lubiw"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2206.02700"
  },
  {
    "id": "arXiv:2206.02704",
    "title": "Perturbation Learning Based Anomaly Detection",
    "abstract": "This paper presents a simple yet effective method for anomaly detection. The\nmain idea is to learn small perturbations to perturb normal data and learn a\nclassifier to classify the normal data and the perturbed data into two\ndifferent classes. The perturbator and classifier are jointly learned using\ndeep neural networks. Importantly, the perturbations should be as small as\npossible but the classifier is still able to recognize the perturbed data from\nunperturbed data. Therefore, the perturbed data are regarded as abnormal data\nand the classifier provides a decision boundary between the normal data and\nabnormal data, although the training data do not include any abnormal data.\nCompared with the state-of-the-art of anomaly detection, our method does not\nrequire any assumption about the shape (e.g. hypersphere) of the decision\nboundary and has fewer hyper-parameters to determine. Empirical studies on\nbenchmark datasets verify the effectiveness and superiority of our method.",
    "descriptor": "",
    "authors": [
      "Jinyu Cai",
      "Jicong Fan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02704"
  },
  {
    "id": "arXiv:2206.02712",
    "title": "Curriculum-Based Self-Training Makes Better Few-Shot Learners for  Data-to-Text Generation",
    "abstract": "Despite the success of text-to-text pre-trained models in various natural\nlanguage generation (NLG) tasks, the generation performance is largely\nrestricted by the number of labeled data in downstream tasks, particularly in\ndata-to-text generation tasks. Existing works mostly utilize abundant unlabeled\nstructured data to conduct unsupervised pre-training for task adaption, which\nfail to model the complex relationship between source structured data and\ntarget texts. Thus, we introduce self-training as a better few-shot learner\nthan task-adaptive pre-training, which explicitly captures this relationship\nvia pseudo-labeled data generated by the pre-trained model. To alleviate the\nside-effect of low-quality pseudo-labeled data during self-training, we propose\na novel method called Curriculum-Based Self-Training (CBST) to effectively\nleverage unlabeled data in a rearranged order determined by the difficulty of\ntext generation. Experimental results show that our method can outperform\nfine-tuning and task-adaptive pre-training methods, and achieve\nstate-of-the-art performance in the few-shot setting of data-to-text\ngeneration.",
    "descriptor": "\nComments: Accepted by IJCAI 2022\n",
    "authors": [
      "Pei Ke",
      "Haozhe Ji",
      "Zhenyu Yang",
      "Yi Huang",
      "Junlan Feng",
      "Xiaoyan Zhu",
      "Minlie Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.02712"
  },
  {
    "id": "arXiv:2206.02713",
    "title": "Is a Modular Architecture Enough?",
    "abstract": "Inspired from human cognition, machine learning systems are gradually\nrevealing advantages of sparser and more modular architectures. Recent work\ndemonstrates that not only do some modular architectures generalize well, but\nthey also lead to better out-of-distribution generalization, scaling\nproperties, learning speed, and interpretability. A key intuition behind the\nsuccess of such systems is that the data generating system for most real-world\nsettings is considered to consist of sparsely interacting parts, and endowing\nmodels with similar inductive biases will be helpful. However, the field has\nbeen lacking in a rigorous quantitative assessment of such systems because\nthese real-world data distributions are complex and unknown. In this work, we\nprovide a thorough assessment of common modular architectures, through the lens\nof simple and known modular data distributions. We highlight the benefits of\nmodularity and sparsity and reveal insights on the challenges faced while\noptimizing modular systems. In doing so, we propose evaluation metrics that\nhighlight the benefits of modularity, the regimes in which these benefits are\nsubstantial, as well as the sub-optimality of current end-to-end learned\nmodular systems as opposed to their claimed potential.",
    "descriptor": "",
    "authors": [
      "Sarthak Mittal",
      "Yoshua Bengio",
      "Guillaume Lajoie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02713"
  },
  {
    "id": "arXiv:2206.02714",
    "title": "FuSS: Fusing Superpixels for Improved Segmentation Consistency",
    "abstract": "In this work, we propose two different approaches to improve the semantic\nconsistency of Open Set Semantic Segmentation. First, we propose a method\ncalled OpenGMM that extends the OpenPCS framework using a Gaussian Mixture of\nModels to model the distribution of pixels for each class in a multimodal\nmanner. The second approach is a post-processing which uses superpixels to\nenforce highly homogeneous regions to behave equally, rectifying erroneous\nclassified pixels within these regions, we also proposed a novel superpixel\nmethod called FuSS. All tests were performed on ISPRS Vaihingen and Potsdam\ndatasets, and both methods were capable to improve quantitative and qualitative\nresults for both datasets. Besides that, the post-process with FuSS achieved\nstate-of-the-art results for both datasets. The official implementation is\navailable at: \\url{https://github.com/iannunes/FuSS}.",
    "descriptor": "\nComments: submitted to IEEEACCESS. 19 pages\n",
    "authors": [
      "Ian Nunes",
      "Matheus B. Pereira",
      "Hugo Oliveira",
      "Jefersson A. Dos Santos",
      "Marcus Poggi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02714"
  },
  {
    "id": "arXiv:2206.02715",
    "title": "Day-to-Night Image Synthesis for Training Nighttime Neural ISPs",
    "abstract": "Many flagship smartphone cameras now use a dedicated neural image signal\nprocessor (ISP) to render noisy raw sensor images to the final processed\noutput. Training nightmode ISP networks relies on large-scale datasets of image\npairs with: (1) a noisy raw image captured with a short exposure and a high ISO\ngain; and (2) a ground truth low-noise raw image captured with a long exposure\nand low ISO that has been rendered through the ISP. Capturing such image pairs\nis tedious and time-consuming, requiring careful setup to ensure alignment\nbetween the image pairs. In addition, ground truth images are often prone to\nmotion blur due to the long exposure. To address this problem, we propose a\nmethod that synthesizes nighttime images from daytime images. Daytime images\nare easy to capture, exhibit low-noise (even on smartphone cameras) and rarely\nsuffer from motion blur. We outline a processing framework to convert daytime\nraw images to have the appearance of realistic nighttime raw images with\ndifferent levels of noise. Our procedure allows us to easily produce aligned\nnoisy and clean nighttime image pairs. We show the effectiveness of our\nsynthesis framework by training neural ISPs for nightmode rendering.\nFurthermore, we demonstrate that using our synthetic nighttime images together\nwith small amounts of real data (e.g., 5% to 10%) yields performance almost on\npar with training exclusively on real nighttime images. Our dataset and code\nare available at https://github.com/SamsungLabs/day-to-night.",
    "descriptor": "",
    "authors": [
      "Abhijith Punnappurath",
      "Abdullah Abuolaim",
      "Abdelrahman Abdelhamed",
      "Alex Levinshtein",
      "Michael S. Brown"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.02715"
  },
  {
    "id": "arXiv:2206.02716",
    "title": "Stacked unsupervised learning with a network architecture found by  supervised meta-learning",
    "abstract": "Stacked unsupervised learning (SUL) seems more biologically plausible than\nbackpropagation, because learning is local to each layer. But SUL has fallen\nfar short of backpropagation in practical applications, undermining the idea\nthat SUL can explain how brains learn. Here we show an SUL algorithm that can\nperform completely unsupervised clustering of MNIST digits with comparable\naccuracy relative to unsupervised algorithms based on backpropagation. Our\nalgorithm is exceeded only by self-supervised methods requiring training data\naugmentation by geometric distortions. The only prior knowledge in our\nunsupervised algorithm is implicit in the network architecture. Multiple\nconvolutional \"energy layers\" contain a sum-of-squares nonlinearity, inspired\nby \"energy models\" of primary visual cortex. Convolutional kernels are learned\nwith a fast minibatch implementation of the K-Subspaces algorithm. High\naccuracy requires preprocessing with an initial whitening layer,\nrepresentations that are less sparse during inference than learning, and\nrescaling for gain control. The hyperparameters of the network architecture are\nfound by supervised meta-learning, which optimizes unsupervised clustering\naccuracy. We regard such dependence of unsupervised learning on prior knowledge\nimplicit in network architecture as biologically plausible, and analogous to\nthe dependence of brain architecture on evolutionary history.",
    "descriptor": "\nComments: Under review at Neurips 2022\n",
    "authors": [
      "Kyle Luther",
      "H. Sebastian Seung"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2206.02716"
  },
  {
    "id": "arXiv:2206.02717",
    "title": "Scene Aware Person Image Generation through Global Contextual  Conditioning",
    "abstract": "Person image generation is an intriguing yet challenging problem. However,\nthis task becomes even more difficult under constrained situations. In this\nwork, we propose a novel pipeline to generate and insert contextually relevant\nperson images into an existing scene while preserving the global semantics.\nMore specifically, we aim to insert a person such that the location, pose, and\nscale of the person being inserted blends in with the existing persons in the\nscene. Our method uses three individual networks in a sequential pipeline. At\nfirst, we predict the potential location and the skeletal structure of the new\nperson by conditioning a Wasserstein Generative Adversarial Network (WGAN) on\nthe existing human skeletons present in the scene. Next, the predicted skeleton\nis refined through a shallow linear network to achieve higher structural\naccuracy in the generated image. Finally, the target image is generated from\nthe refined skeleton using another generative network conditioned on a given\nimage of the target person. In our experiments, we achieve high-resolution\nphoto-realistic generation results while preserving the general context of the\nscene. We conclude our paper with multiple qualitative and quantitative\nbenchmarks on the results.",
    "descriptor": "\nComments: Accepted in The International Conference on Pattern Recognition (ICPR) 2022\n",
    "authors": [
      "Prasun Roy",
      "Subhankar Ghosh",
      "Saumik Bhattacharya",
      "Umapada Pal",
      "Michael Blumenstein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2206.02717"
  },
  {
    "id": "arXiv:2206.02721",
    "title": "Revisiting Realistic Test-Time Training: Sequential Inference and  Adaptation by Anchored Clustering",
    "abstract": "Deploying models on target domain data subject to distribution shift requires\nadaptation. Test-time training (TTT) emerges as a solution to this adaptation\nunder a realistic scenario where access to full source domain data is not\navailable and instant inference on target domain is required. Despite many\nefforts into TTT, there is a confusion over the experimental settings, thus\nleading to unfair comparisons. In this work, we first revisit TTT assumptions\nand categorize TTT protocols by two key factors. Among the multiple protocols,\nwe adopt a realistic sequential test-time training (sTTT) protocol, under which\nwe further develop a test-time anchored clustering (TTAC) approach to enable\nstronger test-time feature learning. TTAC discovers clusters in both source and\ntarget domain and match the target clusters to the source ones to improve\ngeneralization. Pseudo label filtering and iterative updating are developed to\nimprove the effectiveness and efficiency of anchored clustering. We demonstrate\nthat under all TTT protocols TTAC consistently outperforms the state-of-the-art\nmethods on five TTT datasets. We hope this work will provide a fair\nbenchmarking of TTT methods and future research should be compared within\nrespective protocols. A demo code is available at\nhttps://github.com/Gorilla-Lab-SCUT/TTAC.",
    "descriptor": "",
    "authors": [
      "Yongyi Su",
      "Xun Xu",
      "Kui Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02721"
  },
  {
    "id": "arXiv:2206.02731",
    "title": "Robust and Fast Data-Driven Power System State Estimator Using Graph  Neural Networks",
    "abstract": "The power system state estimation (SE) algorithm estimates the complex bus\nvoltages based on the available set of measurements. Because phasor measurement\nunits (PMUs) are becoming more widely employed in transmission power systems, a\nfast SE solver capable of exploiting PMUs' high sample rates is required. To\naccomplish this, we present a method for training a model based on graph neural\nnetworks (GNNs) to learn estimates from PMU voltage and current measurements,\nwhich, once it is trained, has a linear computational complexity with respect\nto the number of nodes in the power system. We propose an original GNN\nimplementation over the power system's factor graph to simplify the\nincorporation of various types and numbers of measurements both on power system\nbuses and branches. Furthermore, we augment the factor graph to improve the\nrobustness of GNN predictions. Training and test examples were generated by\nrandomly sampling sets of power system measurements and annotated with the\nexact solutions of linear SE with PMUs. The numerical results demonstrate that\nthe GNN model provides an accurate approximation of the SE solutions.\nAdditionally, errors caused by PMU malfunctions or the communication failures\nthat make the SE problem unobservable have a local effect and do not\ndeteriorate the results in the rest of the power system.",
    "descriptor": "\nComments: 8 pages. arXiv admin note: substantial text overlap with arXiv:2201.04056\n",
    "authors": [
      "Ognjen Kundacina",
      "Mirsad Cosovic",
      "Dejan Vukobratovic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02731"
  },
  {
    "id": "arXiv:2206.02732",
    "title": "Energy-Time Optimal Control of Wheeled Mobile Robots",
    "abstract": "This paper focuses on the energy-time optimal control of wheeled mobile\nrobots undergoing point-to-point transitions in an obstacles free space. Two\ninterchangeable models are used to arrive at the necessary conditions for\noptimality. The first formulation exploits the Hamiltonian, while the second\nformulation considers the first variation of the augmented cost to derive the\nnecessary conditions for optimality. Jacobi elliptic functions are shown to\nparameterize the closed form solutions for the states, control and costates.\nAnalysis of the optimal control reveal that they are constrained to lie on a\ncylinder whose circular cross-section is a function of the weight penalizing\nthe relative costs of time and energy. The evolving optimal costates for the\nsecond formulation are shown to lie on the intersection of two cylinders. The\noptimal control for the wheeled mobile robot undergoing point-to-point motion\nis also developed where the linear velocity is constrained to be\ntime-invariant. It is shown that the costates are constrained to lie on the\nintersection of a cylinder and an extruded parabola. Numerical results for\nvarious point-to-point maneuvers are presented to illustrate the change in the\nstructure of the optimal trajectories as a function of the relative location of\nthe terminal and initial states.",
    "descriptor": "\nComments: 36 pages,6 figures, 3 appendices\n",
    "authors": [
      "Youngjin Kim",
      "Tarunraj Singh"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.02732"
  },
  {
    "id": "arXiv:2206.02733",
    "title": "Deep Reinforcement Learning for Cybersecurity Threat Detection and  Protection: A Review",
    "abstract": "The cybersecurity threat landscape has lately become overly complex. Threat\nactors leverage weaknesses in the network and endpoint security in a very\ncoordinated manner to perpetuate sophisticated attacks that could bring down\nthe entire network and many critical hosts in the network. Increasingly\nadvanced deep and machine learning-based solutions have been used in threat\ndetection and protection. The application of these techniques has been reviewed\nwell in the scientific literature. Deep Reinforcement Learning has shown great\npromise in developing AI-based solutions for areas that had earlier required\nadvanced human cognizance. Different techniques and algorithms under deep\nreinforcement learning have shown great promise in applications ranging from\ngames to industrial processes, where it is claimed to augment systems with\ngeneral AI capabilities. These algorithms have recently also been used in\ncybersecurity, especially in threat detection and endpoint protection, where\nthese are showing state-of-the-art results. Unlike supervised machines and deep\nlearning, deep reinforcement learning is used in more diverse ways and is\nempowering many innovative applications in the threat defense landscape.\nHowever, there does not exist any comprehensive review of these unique\napplications and accomplishments. Therefore, in this paper, we intend to fill\nthis gap and provide a comprehensive review of the different applications of\ndeep reinforcement learning in cybersecurity threat detection and protection.",
    "descriptor": "",
    "authors": [
      "Mohit Sewak",
      "Sanjay K. Sahay",
      "Hemant Rathore"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02733"
  },
  {
    "id": "arXiv:2206.02734",
    "title": "Global Mixup: Eliminating Ambiguity with Clustering",
    "abstract": "Data augmentation with \\textbf{Mixup} has been proven an effective method to\nregularize the current deep neural networks. Mixup generates virtual samples\nand corresponding labels at once through linear interpolation. However, this\none-stage generation paradigm and the use of linear interpolation have the\nfollowing two defects: (1) The label of the generated sample is directly\ncombined from the labels of the original sample pairs without reasonable\njudgment, which makes the labels likely to be ambiguous. (2) linear combination\nsignificantly limits the sampling space for generating samples. To tackle these\nproblems, we propose a novel and effective augmentation method based on global\nclustering relationships named \\textbf{Global Mixup}. Specifically, we\ntransform the previous one-stage augmentation process into two-stage,\ndecoupling the process of generating virtual samples from the labeling. And for\nthe labels of the generated samples, relabeling is performed based on\nclustering by calculating the global relationships of the generated samples. In\naddition, we are no longer limited to linear relationships but generate more\nreliable virtual samples in a larger sampling space. Extensive experiments for\n\\textbf{CNN}, \\textbf{LSTM}, and \\textbf{BERT} on five tasks show that Global\nMixup significantly outperforms previous state-of-the-art baselines. Further\nexperiments also demonstrate the advantage of Global Mixup in low-resource\nscenarios.",
    "descriptor": "",
    "authors": [
      "Xiangjin Xie",
      "Yangning Li",
      "Wang Chen",
      "Kai Ouyang",
      "Li Jiang",
      "Haitao Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02734"
  },
  {
    "id": "arXiv:2206.02735",
    "title": "People Tracking in Panoramic Video for Guiding Robots",
    "abstract": "A guiding robot aims to effectively bring people to and from specific places\nwithin environments that are possibly unknown to them. During this operation\nthe robot should be able to detect and track the accompanied person, trying\nnever to lose sight of her/him. A solution to minimize this event is to use an\nomnidirectional camera: its 360{\\deg} Field of View (FoV) guarantees that any\nframed object cannot leave the FoV if not occluded or very far from the sensor.\nHowever, the acquired panoramic videos introduce new challenges in perception\ntasks such as people detection and tracking, including the large size of the\nimages to be processed, the distortion effects introduced by the cylindrical\nprojection and the periodic nature of panoramic images. In this paper, we\npropose a set of targeted methods that allow to effectively adapt to panoramic\nvideos a standard people detection and tracking pipeline originally designed\nfor perspective cameras. Our methods have been implemented and tested inside a\ndeep learning-based people detection and tracking framework with a commercial\n360{\\deg} camera. Experiments performed on datasets specifically acquired for\nguiding robot applications and on a real service robot show the effectiveness\nof the proposed approach over other state-of-the-art systems. We release with\nthis paper the acquired and annotated datasets and the open-source\nimplementation of our method.",
    "descriptor": "\nComments: Accepted to 17th International Conference on Intelligent Autonomous Systems (IAS-17)\n",
    "authors": [
      "Alberto Bacchin",
      "Filippo Berno",
      "Emanuele Menegatti",
      "Alberto Pretto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.02735"
  },
  {
    "id": "arXiv:2206.02736",
    "title": "Comparing modern techniques for querying data starting from top-k and  skyline queries",
    "abstract": "To make intelligent decisions over complex data by discovering a set of\ninteresting options is something that has become very important for users of\nmodern applications. Consequently, researchers are studying new techniques to\novercome limitations of traditional ways of querying data from databases as\ntop-k queries and skyline queries. Over the past few years new methods have\nbeen developed as Flexible Skylines, Regret Minimization and Skyline\nordering/ranking. The aim of this survey is to describe these techniques and\nsome their possible variants comparing them and explaining how they improve\ntraditional methods.",
    "descriptor": "",
    "authors": [
      "Fabio Patella"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2206.02736"
  },
  {
    "id": "arXiv:2206.02737",
    "title": "Investigating the use of Paraphrase Generation for Question  Reformulation in the FRANK QA system",
    "abstract": "We present a study into the ability of paraphrase generation methods to\nincrease the variety of natural language questions that the FRANK Question\nAnswering system can answer. We first evaluate paraphrase generation methods on\nthe LC-QuAD 2.0 dataset using both automatic metrics and human judgement, and\ndiscuss their correlation. Error analysis on the dataset is also performed\nusing both automatic and manual approaches, and we discuss how paraphrase\ngeneration and evaluation is affected by data points which contain error. We\nthen simulate an implementation of the best performing paraphrase generation\nmethod (an English-French backtranslation) into FRANK in order to test our\noriginal hypothesis, using a small challenge dataset. Our two main conclusions\nare that cleaning of LC-QuAD 2.0 is required as the errors present can affect\nevaluation; and that, due to limitations of FRANK's parser, paraphrase\ngeneration is not a method which we can rely on to improve the variety of\nnatural language questions that FRANK can answer.",
    "descriptor": "\nComments: 14 pages, 6 figures\n",
    "authors": [
      "Nick Ferguson",
      "Liane Guillou",
      "Kwabena Nuamah",
      "Alan Bundy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.02737"
  },
  {
    "id": "arXiv:2206.02739",
    "title": "Predicting and Understanding Human Action Decisions during Skillful  Joint-Action via Machine Learning and Explainable-AI",
    "abstract": "This study uses supervised machine learning (SML) and explainable artificial\nintelligence (AI) to model, predict and understand human decision-making during\nskillful joint-action. Long short-term memory networks were trained to predict\nthe target selection decisions of expert and novice actors completing a dyadic\nherding task. Results revealed that the trained models were expertise specific\nand could not only accurately predict the target selection decisions of expert\nand novice herders but could do so at timescales that preceded an actor's\nconscious intent. To understand what differentiated the target selection\ndecisions of expert and novice actors, we then employed the explainable-AI\ntechnique, SHapley Additive exPlanation, to identify the importance of\ninformational features (variables) on model predictions. This analysis revealed\nthat experts were more influenced by information about the state of their\nco-herders compared to novices. The utility of employing SML and explainable-AI\ntechniques for investigating human decision-making is discussed.",
    "descriptor": "",
    "authors": [
      "Fabrizia Auletta",
      "Rachel W. Kallen",
      "Mario di Bernardo",
      "Micheal J. Richardson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2206.02739"
  },
  {
    "id": "arXiv:2206.02742",
    "title": "Understanding Self-Directed Learning in an Online Laboratory",
    "abstract": "We described a study on the use of an online laboratory for self-directed\nlearning by constructing and simulating conceptual models of ecological\nsystems. In this study, we could observe only the modeling behaviors and\noutcomes; the learning goals and outcomes were unknown. We used machine\nlearning techniques to analyze the modeling behaviors of 315 learners and 822\nconceptual models they generated. We derive three main conclusions from the\nresults. First, learners manifest three types of modeling behaviors:\nobservation (simulation focused), construction (construction focused), and full\nexploration (model construction, evaluation and revision). Second, while\nobservation was the most common behavior among all learners, construction\nwithout evaluation was more common for less engaged learners and full\nexploration occurred mostly for more engaged learners. Third, learners who\nexplored the full cycle of model construction, evaluation and revision\ngenerated models of higher quality. These modeling behaviors provide insights\ninto self-directed learning at large.",
    "descriptor": "",
    "authors": [
      "Sungeun An",
      "Spencer Rugaber",
      "Jennifer Hammock",
      "Ashok K. Goel"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02742"
  },
  {
    "id": "arXiv:2206.02743",
    "title": "A Neural Corpus Indexer for Document Retrieval",
    "abstract": "Current state-of-the-art document retrieval solutions mainly follow an\nindex-retrieve paradigm, where the index is hard to be optimized for the final\nretrieval target. In this paper, we aim to show that an end-to-end deep neural\nnetwork unifying training and indexing stages can significantly improve the\nrecall performance of traditional methods. To this end, we propose Neural\nCorpus Indexer (NCI), a sequence-to-sequence network that generates relevant\ndocument identifiers directly for a designated query. To optimize the recall\nperformance of NCI, we invent a prefix-aware weight-adaptive decoder\narchitecture, and leverage tailored techniques including query generation,\nsemantic document identifiers and consistency-based regularization. Empirical\nstudies demonstrated the superiority of NCI on a commonly used academic\nbenchmark, achieving +51.9% relative improvement on NQ320k dataset compared to\nthe best baseline.",
    "descriptor": "\nComments: 18 pages, 4 figures\n",
    "authors": [
      "Yujing Wang",
      "Yingyan Hou",
      "Haonan Wang",
      "Ziming Miao",
      "Shibin Wu",
      "Hao Sun",
      "Qi Chen",
      "Yuqing Xia",
      "Chengmin Chi",
      "Guoshuai Zhao",
      "Zheng Liu",
      "Xing Xie",
      "Hao Allen Sun",
      "Weiwei Deng",
      "Qi Zhang",
      "Mao Yang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.02743"
  },
  {
    "id": "arXiv:2206.02749",
    "title": "CORE: Consistent Representation Learning for Face Forgery Detection",
    "abstract": "Face manipulation techniques develop rapidly and arouse widespread public\nconcerns. Despite that vanilla convolutional neural networks achieve acceptable\nperformance, they suffer from the overfitting issue. To relieve this issue,\nthere is a trend to introduce some erasing-based augmentations. We find that\nthese methods indeed attempt to implicitly induce more consistent\nrepresentations for different augmentations via assigning the same label for\ndifferent augmented images. However, due to the lack of explicit\nregularization, the consistency between different representations is less\nsatisfactory. Therefore, we constrain the consistency of different\nrepresentations explicitly and propose a simple yet effective framework,\nCOnsistent REpresentation Learning (CORE). Specifically, we first capture the\ndifferent representations with different augmentations, then regularize the\ncosine distance of the representations to enhance the consistency. Extensive\nexperiments (in-dataset and cross-dataset) demonstrate that CORE performs\nfavorably against state-of-the-art face forgery detection methods.",
    "descriptor": "\nComments: Accepted by CVPRW 2022\n",
    "authors": [
      "Yunsheng Ni",
      "Depu Meng",
      "Changqian Yu",
      "Chengbin Quan",
      "Dongchun Ren",
      "Youjian Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.02749"
  },
  {
    "id": "arXiv:2206.02757",
    "title": "Robust Calibration with Multi-domain Temperature Scaling",
    "abstract": "Uncertainty quantification is essential for the reliable deployment of\nmachine learning models to high-stakes application domains. Uncertainty\nquantification is all the more challenging when training distribution and test\ndistribution are different, even the distribution shifts are mild. Despite the\nubiquity of distribution shifts in real-world applications, existing\nuncertainty quantification approaches mainly study the in-distribution setting\nwhere the train and test distributions are the same. In this paper, we develop\na systematic calibration model to handle distribution shifts by leveraging data\nfrom multiple domains. Our proposed method -- multi-domain temperature scaling\n-- uses the heterogeneity in the domains to improve calibration robustness\nunder distribution shift. Through experiments on three benchmark data sets, we\nfind our proposed method outperforms existing methods as measured on both\nin-distribution and out-of-distribution test sets.",
    "descriptor": "",
    "authors": [
      "Yaodong Yu",
      "Stephen Bates",
      "Yi Ma",
      "Michael I. Jordan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.02757"
  },
  {
    "id": "arXiv:2206.02760",
    "title": "Blockchain for the Cybersecurity of Smart City Applications",
    "abstract": "Cybersecurity is an inherent characteristic that should be addressed before\nthe large deployment of smart city applications. Recently, Blockchain appears\nas a promising technology to provide several cybersecurity aspects of smart\ncity applications. This paper provides a comprehensive review of the existing\nblockchain-based solutions for the cybersecurity of the main smart city\napplications, namely smart healthcare, smart transportation, smart agriculture,\nsupply chain management, smart grid, and smart homes. We describe the existing\nsolutions and we discuss their merits and limits. Moreover, we define the\nsecurity requirements of each smart city application and we give a mapping of\nthe studied solutions to these defined requirements. Additionally, future\ndirections are given. We believe that the present survey is a good starting\npoint for every researcher in the fields of cybersecurity, blockchain, and\nsmart cities.",
    "descriptor": "\nComments: 65 pages, 6 figures, 37 tables\n",
    "authors": [
      "Omar Cheikhrouhou",
      "Ichrak Amdouni",
      "Khaleel Mershad",
      "Maryem Ammi",
      "Tuan Nguyen Gia"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.02760"
  },
  {
    "id": "arXiv:2206.02761",
    "title": "Dual Decomposition of Convex Optimization Layers for Consistent  Attention in Medical Images",
    "abstract": "A key concern in integrating machine learning models in medicine is the\nability to interpret their reasoning. Popular explainability methods have\ndemonstrated satisfactory results in natural image recognition, yet in medical\nimage analysis, many of these approaches provide partial and noisy\nexplanations. Recently, attention mechanisms have shown compelling results both\nin their predictive performance and in their interpretable qualities. A\nfundamental trait of attention is that it leverages salient parts of the input\nwhich contribute to the model's prediction. To this end, our work focuses on\nthe explanatory value of attention weight distributions. We propose a\nmulti-layer attention mechanism that enforces consistent interpretations\nbetween attended convolutional layers using convex optimization. We apply\nduality to decompose the consistency constraints between the layers by\nreparameterizing their attention probability distributions. We further suggest\nlearning the dual witness by optimizing with respect to our objective; thus,\nour implementation uses standard back-propagation, hence it is highly\nefficient. While preserving predictive performance, our proposed method\nleverages weakly annotated medical imaging data and provides complete and\nfaithful explanations to the model's prediction.",
    "descriptor": "\nComments: 12 pages, 5 figures. In Proceedings of the 39th International Conference on Machine Learning, Baltimore, Maryland, USA, PMLR 162, 2022. Copyright 2022 by the author(s)\n",
    "authors": [
      "Tom Ron",
      "Michal Weiler-Sagie",
      "Tamir Hazan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02761"
  },
  {
    "id": "arXiv:2206.02767",
    "title": "Quantum Complexity of Weighted Diameter and Radius in CONGEST Networks",
    "abstract": "This paper studies the round complexity of computing the weighted diameter\nand radius of a graph in the quantum CONGEST model. We present a quantum\nalgorithm that $(1+o(1))$-approximates the diameter and radius with round\ncomplexity $\\widetilde O\\left(\\min\\left\\{n^{9/10}D^{3/10},n\\right\\}\\right)$,\nwhere $D$ denotes the unweighted diameter. This exhibits the advantages of\nquantum communication over classical communication since computing a\n$(3/2-\\varepsilon)$-approximation of the diameter and radius in a classical\nCONGEST network takes $\\widetilde\\Omega(n)$ rounds, even if $D$ is constant\n[Abboud, Censor-Hillel, and Khoury, DISC '16]. We also prove a lower bound of\n$\\widetilde\\Omega(n^{2/3})$ for $(3/2-\\varepsilon)$-approximating the weighted\ndiameter/radius in quantum CONGEST networks, even if $D=\\Theta(\\log n)$. Thus,\nin quantum CONGEST networks, computing weighted diameter and weighted radius of\ngraphs with small $D$ is strictly harder than unweighted ones due to Le Gall\nand Magniez's $\\widetilde O\\left(\\sqrt{nD}\\right)$-round algorithm for\nunweighted diameter/radius [PODC '18].",
    "descriptor": "\nComments: 24 pages. accepted by PODC 2022\n",
    "authors": [
      "Xudong Wu",
      "Penghui Yao"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.02767"
  },
  {
    "id": "arXiv:2206.02770",
    "title": "Multimodal Contrastive Learning with LIMoE: the Language-Image Mixture  of Experts",
    "abstract": "Large sparsely-activated models have obtained excellent performance in\nmultiple domains. However, such models are typically trained on a single\nmodality at a time. We present the Language-Image MoE, LIMoE, a sparse mixture\nof experts model capable of multimodal learning. LIMoE accepts both images and\ntext simultaneously, while being trained using a contrastive loss. MoEs are a\nnatural fit for a multimodal backbone, since expert layers can learn an\nappropriate partitioning of modalities. However, new challenges arise; in\nparticular, training stability and balanced expert utilization, for which we\npropose an entropy-based regularization scheme. Across multiple scales, we\ndemonstrate remarkable performance improvement over dense models of equivalent\ncomputational cost. LIMoE-L/16 trained comparably to CLIP-L/14 achieves 78.6%\nzero-shot ImageNet accuracy (vs. 76.2%), and when further scaled to H/14 (with\nadditional data) it achieves 84.1%, comparable to state-of-the-art methods\nwhich use larger custom per-modality backbones and pre-training schemes. We\nanalyse the quantitative and qualitative behavior of LIMoE, and demonstrate\nphenomena such as differing treatment of the modalities and the organic\nemergence of modality-specific experts.",
    "descriptor": "",
    "authors": [
      "Basil Mustafa",
      "Carlos Riquelme",
      "Joan Puigcerver",
      "Rodolphe Jenatton",
      "Neil Houlsby"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02770"
  },
  {
    "id": "arXiv:2206.02771",
    "title": "Neuro CROSS exchange: Learning to CROSS exchange to solve realistic  vehicle routing problems",
    "abstract": "CROSS exchange (CE), a meta-heuristic that solves various vehicle routing\nproblems (VRPs), improves the solutions of VRPs by swapping the sub-tours of\nthe vehicles. Inspired by CE, we propose Neuro CE (NCE), a fundamental operator\nof learned meta-heuristic, to solve various VRPs while overcoming the\nlimitations of CE (i.e., the expensive $\\mathcal{O}(n^4)$ search cost). NCE\nemploys a graph neural network to predict the cost-decrements (i.e., results of\nCE searches) and utilizes the predicted cost-decrements as guidance for search\nto decrease the search cost to $\\mathcal{O}(n^2)$. As the learning objective of\nNCE is to predict the cost-decrement, the training can be simply done in a\nsupervised fashion, whose training samples can be prepared effortlessly.\nDespite the simplicity of NCE, numerical results show that the NCE trained with\nflexible multi-depot VRP (FMDVRP) outperforms the meta-heuristic baselines.\nMore importantly, it significantly outperforms the neural baselines when\nsolving distinctive special cases of FMDVRP (e.g., MDVRP, mTSP, CVRP) without\nadditional training.",
    "descriptor": "\nComments: 9 pages, 2 figures\n",
    "authors": [
      "Minjun Kim",
      "Junyoung Park",
      "Jinkyoo Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02771"
  },
  {
    "id": "arXiv:2206.02775",
    "title": "Randomized Synthesis for Diversity and Cost Constraints with Control  Improvisation",
    "abstract": "In many synthesis problems, it can be essential to generate implementations\nwhich not only satisfy functional constraints but are also randomized to\nimprove variety, robustness, or unpredictability. The recently-proposed\nframework of control improvisation (CI) provides techniques for the\ncorrect-by-construction synthesis of randomized systems subject to hard and\nsoft constraints. However, prior work on CI has focused on qualitative\nspecifications, whereas in robotic planning and other areas we often have\nquantitative quality metrics which can be traded against each other. For\nexample, a designer of a patrolling security robot might want to know by how\nmuch the average patrol time needs to be increased in order to ensure that a\nparticular aspect of the robot's route is sufficiently diverse and hence\nunpredictable. In this paper, we enable this type of application by\ngeneralizing the CI problem to support quantitative soft constraints which\nbound the expected value of a given cost function, and randomness constraints\nwhich enforce diversity of the generated traces with respect to a given label\nfunction. We establish the basic theory of labelled quantitative CI problems,\nand develop efficient algorithms for solving them when the specifications are\nencoded by finite automata. We also provide an approximate improvisation\nalgorithm based on constraint solving for any specifications encodable as\nBoolean formulas. We demonstrate the utility of our problem formulation and\nalgorithms with experiments applying them to generate diverse near-optimal\nplans for robotic planning problems.",
    "descriptor": "\nComments: 35 pages, 3 figures. Full version (including appendices) of a CAV 2022 paper, to appear in the Springer Lecture Notes in Computer Science series\n",
    "authors": [
      "Andreas Gittis",
      "Eric Vin",
      "Daniel J. Fremont"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.02775"
  },
  {
    "id": "arXiv:2206.02776",
    "title": "Volumetric Disentanglement for 3D Scene Manipulation",
    "abstract": "Recently, advances in differential volumetric rendering enabled significant\nbreakthroughs in the photo-realistic and fine-detailed reconstruction of\ncomplex 3D scenes, which is key for many virtual reality applications. However,\nin the context of augmented reality, one may also wish to effect semantic\nmanipulations or augmentations of objects within a scene. To this end, we\npropose a volumetric framework for (i) disentangling or separating, the\nvolumetric representation of a given foreground object from the background, and\n(ii) semantically manipulating the foreground object, as well as the\nbackground. Our framework takes as input a set of 2D masks specifying the\ndesired foreground object for training views, together with the associated 2D\nviews and poses, and produces a foreground-background disentanglement that\nrespects the surrounding illumination, reflections, and partial occlusions,\nwhich can be applied to both training and novel views. Our method enables the\nseparate control of pixel color and depth as well as 3D similarity\ntransformations of both the foreground and background objects. We subsequently\ndemonstrate the applicability of our framework on a number of downstream\nmanipulation tasks including object camouflage, non-negative 3D object\ninpainting, 3D object translation, 3D object inpainting, and 3D text-based\nobject manipulation. Full results are given in our project webpage at\nhttps://sagiebenaim.github.io/volumetric-disentanglement/",
    "descriptor": "",
    "authors": [
      "Sagie Benaim",
      "Frederik Warburg",
      "Peter Ebert Christensen",
      "Serge Belongie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02776"
  },
  {
    "id": "arXiv:2206.02777",
    "title": "Mask DINO: Towards A Unified Transformer-based Framework for Object  Detection and Segmentation",
    "abstract": "In this paper we present Mask DINO, a unified object detection and\nsegmentation framework. Mask DINO extends DINO (DETR with Improved Denoising\nAnchor Boxes) by adding a mask prediction branch which supports all image\nsegmentation tasks (instance, panoptic, and semantic). It makes use of the\nquery embeddings from DINO to dot-product a high-resolution pixel embedding map\nto predict a set of binary masks. Some key components in DINO are extended for\nsegmentation through a shared architecture and training process. Mask DINO is\nsimple, efficient, scalable, and benefits from joint large-scale detection and\nsegmentation datasets. Our experiments show that Mask DINO significantly\noutperforms all existing specialized segmentation methods, both on a ResNet-50\nbackbone and a pre-trained model with SwinL backbone. Notably, Mask DINO\nestablishes the best results to date on instance segmentation (54.5 AP on\nCOCO), panoptic segmentation (59.4 PQ on COCO), and semantic segmentation (60.8\nmIoU on ADE20K). Code will be avaliable at\n\\url{https://github.com/IDEACVR/MaskDINO}.",
    "descriptor": "",
    "authors": [
      "Feng Li",
      "Hao Zhang",
      "Huaizhe xu",
      "Shilong Liu",
      "Lei Zhang",
      "Lionel M. Ni",
      "Heung-Yeung Shum"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02777"
  },
  {
    "id": "arXiv:2206.02779",
    "title": "Blended Latent Diffusion",
    "abstract": "The tremendous progress in neural image generation, coupled with the\nemergence of seemingly omnipotent vision-language models has finally enabled\ntext-based interfaces for creating and editing images. Handling generic images\nrequires a diverse underlying generative model, hence the latest works utilize\ndiffusion models, which were shown to surpass GANs in terms of diversity. One\nmajor drawback of diffusion models, however, is their relatively slow inference\ntime. In this paper, we present an accelerated solution to the task of local\ntext-driven editing of generic images, where the desired edits are confined to\na user-provided mask. Our solution leverages a recent text-to-image Latent\nDiffusion Model (LDM), which speeds up diffusion by operating in a\nlower-dimensional latent space. We first convert the LDM into a local image\neditor by incorporating Blended Diffusion into it. Next we propose an\noptimization-based solution for the inherent inability of this LDM to\naccurately reconstruct images. Finally, we address the scenario of performing\nlocal edits using thin masks. We evaluate our method against the available\nbaselines both qualitatively and quantitatively and demonstrate that in\naddition to being faster, our method achieves better precision than the\nbaselines while mitigating some of their artifacts. Project page is available\nat https://omriavrahami.com/blended-latent-diffusion-page/",
    "descriptor": "\nComments: Project page is available at this https URL\n",
    "authors": [
      "Omri Avrahami",
      "Ohad Fried",
      "Dani Lischinski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02779"
  },
  {
    "id": "arXiv:2206.02780",
    "title": "GenSDF: Two-Stage Learning of Generalizable Signed Distance Functions",
    "abstract": "We investigate the generalization capabilities of neural signed distance\nfunctions (SDFs) for learning 3D object representations for unseen and\nunlabeled point clouds. Existing methods can fit SDFs to a handful of object\nclasses and boast fine detail or fast inference speeds, but do not generalize\nwell to unseen shapes. We introduce a two-stage semi-supervised meta-learning\napproach that transfers shape priors from labeled to unlabeled data to\nreconstruct unseen object categories. The first stage uses an episodic training\nscheme to simulate training on unlabeled data and meta-learns initial shape\npriors. The second stage then introduces unlabeled data with disjoint classes\nin a semi-supervised scheme to diversify these priors and achieve\ngeneralization. We assess our method on both synthetic data and real collected\npoint clouds. Experimental results and analysis validate that our approach\noutperforms existing neural SDF methods and is capable of robust zero-shot\ninference on 100+ unseen classes. Code can be found at\nhttps://github.com/princeton-computational-imaging/gensdf.",
    "descriptor": "",
    "authors": [
      "Gene Chou",
      "Ilya Chugunov",
      "Felix Heide"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02780"
  },
  {
    "id": "arXiv:2108.06932",
    "title": "Polyp-PVT: Polyp Segmentation with Pyramid Vision Transformers",
    "abstract": "Most polyp segmentation methods use CNNs as their backbone, leading to two\nkey issues when exchanging information between the encoder and decoder: 1)\ntaking into account the differences in contribution between different-level\nfeatures; and 2) designing an effective mechanism for fusing these features.\nDifferent from existing CNN-based methods, we adopt a transformer encoder,\nwhich learns more powerful and robust representations. In addition, considering\nthe image acquisition influence and elusive properties of polyps, we introduce\nthree novel modules, including a cascaded fusion module (CFM), a camouflage\nidentification module (CIM), a and similarity aggregation module (SAM). Among\nthese, the CFM is used to collect the semantic and location information of\npolyps from high-level features, while the CIM is applied to capture polyp\ninformation disguised in low-level features. With the help of the SAM, we\nextend the pixel features of the polyp area with high-level semantic position\ninformation to the entire polyp area, thereby effectively fusing cross-level\nfeatures. The proposed model, named Polyp-PVT, effectively suppresses noises in\nthe features and significantly improves their expressive capabilities.\nExtensive experiments on five widely adopted datasets show that the proposed\nmodel is more robust to various challenging situations (e.g., appearance\nchanges, small objects) than existing methods, and achieves the new\nstate-of-the-art performance. The proposed model is available at\nhttps://github.com/DengPingFan/Polyp-PVT.",
    "descriptor": "\nComments: Technical Report\n",
    "authors": [
      "Bo Dong",
      "Wenhai Wang",
      "Deng-Ping Fan",
      "Jinpeng Li",
      "Huazhu Fu",
      "Ling Shao"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.06932"
  },
  {
    "id": "arXiv:2206.01728",
    "title": "A review of machine learning approaches, challenges and prospects for  computational tumor pathology",
    "abstract": "Computational pathology is part of precision oncology medicine. The\nintegration of high-throughput data including genomics, transcriptomics,\nproteomics, metabolomics, pathomics, and radiomics into clinical practice\nimproves cancer treatment plans, treatment cycles, and cure rates, and helps\ndoctors open up innovative approaches to patient prognosis. In the past decade,\nrapid advances in artificial intelligence, chip design and manufacturing, and\nmobile computing have facilitated research in computational pathology and have\nthe potential to provide better-integrated solutions for whole-slide images,\nmulti-omics data, and clinical informatics. However, tumor computational\npathology now brings some challenges to the application of tumour screening,\ndiagnosis and prognosis in terms of data integration, hardware processing,\nnetwork sharing bandwidth and machine learning technology. This review\ninvestigates image preprocessing methods in computational pathology from a\npathological and technical perspective, machine learning-based methods, and\napplications of computational pathology in breast, colon, prostate, lung, and\nvarious tumour disease scenarios. Finally, the challenges and prospects of\nmachine learning in computational pathology applications are discussed.",
    "descriptor": "",
    "authors": [
      "Liangrui Pan",
      "Zhichao Feng",
      "Shaoliang Peng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2206.01728"
  },
  {
    "id": "arXiv:2206.01729",
    "title": "Torsional Diffusion for Molecular Conformer Generation",
    "abstract": "Molecular conformer generation is a fundamental task in computational\nchemistry. Several machine learning approaches have been developed, but none\nhave outperformed state-of-the-art cheminformatics methods. We propose\ntorsional diffusion, a novel diffusion framework that operates on the space of\ntorsion angles via a diffusion process on the hypertorus and an\nextrinsic-to-intrinsic score model. On a standard benchmark of drug-like\nmolecules, torsional diffusion generates superior conformer ensembles compared\nto machine learning and cheminformatics methods in terms of both RMSD and\nchemical properties, and is orders of magnitude faster than previous\ndiffusion-based models. Moreover, our model provides exact likelihoods, which\nwe employ to build the first generalizable Boltzmann generator. Code is\navailable at https://github.com/gcorso/torsional-diffusion.",
    "descriptor": "",
    "authors": [
      "Bowen Jing",
      "Gabriele Corso",
      "Jeffrey Chang",
      "Regina Barzilay",
      "Tommi Jaakkola"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2206.01729"
  },
  {
    "id": "arXiv:2206.01731",
    "title": "Empirical Study of Quality Image Assessment for Synthesis of Fetal Head  Ultrasound Imaging with DCGANs",
    "abstract": "In this work, we present an empirical study of DCGANs for synthetic\ngeneration of fetal head ultrasound, consisting of hyperparameter heuristics\nand image quality assessment. We present experiments to show the impact of\ndifferent image sizes, epochs, data size input, and learning rates for quality\nimage assessment on four metrics: mutual information (MI), fr\\'echet inception\ndistance (FID), peak-signal-to-noise ratio (PSNR), and local binary pattern\nvector (LBPv). The results show that FID and LBPv have stronger relationship\nwith clinical image quality scores. The resources to reproduce this work are\navailable at \\url{https://github.com/xfetus/miua2022}.",
    "descriptor": "",
    "authors": [
      "Thea Bautista",
      "Jacqueline Matthew",
      "Hamideh Kerdegari",
      "Laura Peralta Pereira",
      "Miguel Xochicale"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.01731"
  },
  {
    "id": "arXiv:2206.01735",
    "title": "Examining the behaviour of state-of-the-art convolutional neural  networks for brain tumor detection with and without transfer learning",
    "abstract": "Distinguishing normal from malignant and determining the tumor type are\ncritical components of brain tumor diagnosis. Two different kinds of dataset\nare investigated using state-of-the-art CNN models in this research work. One\ndataset(binary) has images of normal and tumor types, while\nanother(multi-class) provides all images of tumors classified as glioma,\nmeningioma, or pituitary. The experiments were conducted in these dataset with\ntransfer learning from pre-trained weights from ImageNet as well as\ninitializing the weights randomly. The experimental environment is equivalent\nfor all models in this study in order to make a fair comparison. For both of\nthe dataset, the validation set are same for all the models where train data is\n60% while the rest is 40% for validation. With the proposed techniques in this\nresearch, the EfficientNet-B5 architecture outperforms all the state-of-the-art\nmodels in the binary-classification dataset with the accuracy of 99.75% and\n98.61% accuracy for the multi-class dataset. This research also demonstrates\nthe behaviour of convergence of validation loss in different weight\ninitialization techniques.",
    "descriptor": "",
    "authors": [
      "Md. Atik Ahamed",
      "Rabeya Tus Sadia"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01735"
  },
  {
    "id": "arXiv:2206.01736",
    "title": "Adaptive Adversarial Training to Improve Adversarial Robustness of DNNs  for Medical Image Segmentation and Detection",
    "abstract": "Recent methods based on Deep Neural Networks (DNNs) have reached high\naccuracy for medical image analysis, including the three basic tasks:\nsegmentation, landmark detection, and object detection. It is known that DNNs\nare vulnerable to adversarial attacks, and the adversarial robustness of DNNs\ncould be improved by adding adversarial noises to training data (i.e.,\nadversarial training). In this study, we show that the standard adversarial\ntraining (SAT) method has a severe issue that limits its practical use: it\ngenerates a fixed level of noise for DNN training, and it is difficult for the\nuser to choose an appropriate noise level, because a high noise level may lead\nto a large reduction in model performance, and a low noise level may have\nlittle effect. To resolve this issue, we have designed a novel adaptive-margin\nadversarial training (AMAT) method that generates adaptive adversarial noises\nfor DNN training, which are dynamically tailored for each individual training\nsample. We have applied our AMAT method to state-of-the-art DNNs for the three\nbasic tasks, using five publicly available datasets. The experimental results\ndemonstrate that our AMAT method outperforms the SAT method in adversarial\nrobustness on noisy data and prediction accuracy on clean data. Please contact\nthe author for the source code.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Linhai Ma",
      "Liang Liang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01736"
  },
  {
    "id": "arXiv:2206.01737",
    "title": "MaxStyle: Adversarial Style Composition for Robust Medical Image  Segmentation",
    "abstract": "Convolutional neural networks (CNNs) have achieved remarkable segmentation\naccuracy on benchmark datasets where training and test sets are from the same\ndomain, yet their performance can degrade significantly on unseen domains,\nwhich hinders the deployment of CNNs in many clinical scenarios. Most existing\nworks improve model out-of-domain (OOD) robustness by collecting multi-domain\ndatasets for training, which is expensive and may not always be feasible due to\nprivacy and logistical issues. In this work, we focus on improving model\nrobustness using a single-domain dataset only. We propose a novel data\naugmentation framework called MaxStyle, which maximizes the effectiveness of\nstyle augmentation for model OOD performance. It attaches an auxiliary\nstyle-augmented image decoder to a segmentation network for robust feature\nlearning and data augmentation. Importantly, MaxStyle augments data with\nimproved image style diversity and hardness, by expanding the style space with\nnoise and searching for the worst-case style composition of latent features via\nadversarial training. With extensive experiments on multiple public cardiac and\nprostate MR datasets, we demonstrate that MaxStyle leads to significantly\nimproved out-of-distribution robustness against unseen corruptions as well as\ncommon distribution shifts across multiple, different, unseen sites and unknown\nimage sequences under both low- and high-training data settings. The code can\nbe found at https://github.com/cherise215/MaxStyle.",
    "descriptor": "\nComments: Early accepted by MICCAI 2022\n",
    "authors": [
      "Chen Chen",
      "Zeju Li",
      "Cheng Ouyang",
      "Matt Sinclair",
      "Wenjia Bai",
      "Daniel Rueckert"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2206.01737"
  },
  {
    "id": "arXiv:2206.01738",
    "title": "RIDDLE: Lidar Data Compression with Range Image Deep Delta Encoding",
    "abstract": "Lidars are depth measuring sensors widely used in autonomous driving and\naugmented reality. However, the large volume of data produced by lidars can\nlead to high costs in data storage and transmission. While lidar data can be\nrepresented as two interchangeable representations: 3D point clouds and range\nimages, most previous work focus on compressing the generic 3D point clouds. In\nthis work, we show that directly compressing the range images can leverage the\nlidar scanning pattern, compared to compressing the unprojected point clouds.\nWe propose a novel data-driven range image compression algorithm, named RIDDLE\n(Range Image Deep DeLta Encoding). At its core is a deep model that predicts\nthe next pixel value in a raster scanning order, based on contextual laser\nshots from both the current and past scans (represented as a 4D point cloud of\nspherical coordinates and time). The deltas between predictions and original\nvalues can then be compressed by entropy encoding. Evaluated on the Waymo Open\nDataset and KITTI, our method demonstrates significant improvement in the\ncompression rate (under the same distortion) compared to widely used point\ncloud and range image compression algorithms as well as recent deep methods.",
    "descriptor": "\nComments: 14 pages, 10 figures; CVPR 2022\n",
    "authors": [
      "Xuanyu Zhou",
      "Charles R. Qi",
      "Yin Zhou",
      "Dragomir Anguelov"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01738"
  },
  {
    "id": "arXiv:2206.01739",
    "title": "Mutual- and Self- Prototype Alignment for Semi-supervised Medical Image  Segmentation",
    "abstract": "Semi-supervised learning methods have been explored in medical image\nsegmentation tasks due to the scarcity of pixel-level annotation in the real\nscenario. Proto-type alignment based consistency constraint is an intuitional\nand plausible solu-tion to explore the useful information in the unlabeled\ndata. In this paper, we propose a mutual- and self- prototype alignment (MSPA)\nframework to better utilize the unlabeled data. In specific, mutual-prototype\nalignment enhances the information interaction between labeled and unlabeled\ndata. The mutual-prototype alignment imposes two consistency constraints in\nreverse directions between the unlabeled and labeled data, which enables the\nconsistent embedding and model discriminability on unlabeled data. The proposed\nself-prototype alignment learns more stable region-wise features within\nunlabeled images, which optimizes the classification margin in semi-supervised\nsegmentation by boosting the intra-class compactness and inter-class separation\non the feature space. Extensive experimental results on three medical datasets\ndemonstrate that with a small amount of labeled data, MSPA achieves large\nimprovements by leveraging the unlabeled data. Our method also outperforms\nseven state-of-the-art semi-supervised segmentation methods on all three\ndatasets.",
    "descriptor": "\nComments: 11 pages, 3 figures\n",
    "authors": [
      "Zhenxi Zhang",
      "Chunna Tian",
      "Zhicheng Jiao"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01739"
  },
  {
    "id": "arXiv:2206.01740",
    "title": "Denoising Fast X-Ray Fluorescence Raster Scans of Paintings",
    "abstract": "Macro x-ray fluorescence (XRF) imaging of cultural heritage objects, while a\npopular non-invasive technique for providing elemental distribution maps, is a\nslow acquisition process in acquiring high signal-to-noise ratio XRF volumes.\nTypically on the order of tenths of a second per pixel, a raster scanning probe\ncounts the number of photons at different energies emitted by the object under\nx-ray illumination. In an effort to reduce the scan times without sacrificing\nelemental map and XRF volume quality, we propose using dictionary learning with\na Poisson noise model as well as a color image-based prior to restore noisy,\nrapidly acquired XRF data.",
    "descriptor": "",
    "authors": [
      "Henry Chopp",
      "Alicia McGeachy",
      "Matthias Alfeld",
      "Oliver Cossairt",
      "Marc Walton",
      "Aggelos Katsaggelos"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01740"
  },
  {
    "id": "arXiv:2206.01741",
    "title": "Patcher: Patch Transformers with Mixture of Experts for Precise Medical  Image Segmentation",
    "abstract": "We present a new encoder-decoder Vision Transformer architecture, Patcher,\nfor medical image segmentation. Unlike standard Vision Transformers, it employs\nPatcher blocks that segment an image into large patches, each of which is\nfurther divided into small patches. Transformers are applied to the small\npatches within a large patch, which constrains the receptive field of each\npixel. We intentionally make the large patches overlap to enhance intra-patch\ncommunication. The encoder employs a cascade of Patcher blocks with increasing\nreceptive fields to extract features from local to global levels. This design\nallows Patcher to benefit from both the coarse-to-fine feature extraction\ncommon in CNNs and the superior spatial relationship modeling of Transformers.\nWe also propose a new mixture-of-experts (MoE) based decoder, which treats the\nfeature maps from the encoder as experts and selects a suitable set of expert\nfeatures to predict the label for each pixel. The use of MoE enables better\nspecializations of the expert features and reduces interference between them\nduring inference. Extensive experiments demonstrate that Patcher outperforms\nstate-of-the-art Transformer- and CNN-based approaches significantly on stroke\nlesion segmentation and polyp segmentation. Code for Patcher will be released\nwith publication to facilitate future research.",
    "descriptor": "\nComments: MICCAI 2022\n",
    "authors": [
      "Yanglan Ou",
      "Ye Yuan",
      "Xiaolei Huang",
      "Stephen T.C. Wong",
      "John Volpi",
      "James Z. Wang",
      "Kelvin Wong"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01741"
  },
  {
    "id": "arXiv:2206.01742",
    "title": "Learning Probabilistic Structural Representation for Biomedical Image  Segmentation",
    "abstract": "Accurate segmentation of various fine-scale structures from biomedical images\nis a very important yet challenging problem. Existing methods use topological\ninformation as an additional training loss, but are ultimately learning a\npixel-wise representation. In this paper, we propose the first deep learning\nmethod to learn a structural representation. We use discrete Morse theory and\npersistent homology to construct an one-parameter family of structures as the\nstructural representation space. Furthermore, we learn a probabilistic model\nthat can do inference tasks on such a structural representation space. We\nempirically demonstrate the strength of our method, i.e., generating true\nstructures rather than pixel-maps with better topological integrity, and\nfacilitating a human-in-the-loop annotation pipeline using the sampling of\nstructures and structure-aware uncertainty.",
    "descriptor": "\nComments: 16 pages, 11 figures\n",
    "authors": [
      "Xiaoling Hu",
      "Dimitris Samaras",
      "Chao Chen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01742"
  },
  {
    "id": "arXiv:2206.01743",
    "title": "Orthogonal Transform based Generative Adversarial Network for Image  Dehazing",
    "abstract": "Image dehazing has become one of the crucial preprocessing steps for any\ncomputer vision task. Most of the dehazing methods try to estimate the\ntransmission map along with the atmospheric light to get the dehazed image in\nthe image domain. In this paper, we propose a novel end-to-end architecture\nthat directly estimates dehazed image in Krawtchouk transform domain. For this\na customized Krawtchouk Convolution Layer (KCL) in the architecture is added.\nKCL is constructed using Krawtchouk basis functions which converts the image\nfrom the spatial domain to the Krawtchouk transform domain. Another convolution\nlayer is added at the end of the architecture named as Inverse Krawtchouk\nConvolution Layer (IKCL) which converts the image back to the spatial domain\nfrom the transform domain. It has been observed that the haze is mainly present\nin lower frequencies of hazy images, wherein the Krawtchouk transform helps to\nanalyze the high and low frequencies of the images separately. We have divided\nour architecture into two branches, the upper branch deals with the higher\nfrequencies while the lower branch deals with the lower frequencies of the\nimage. The lower branch is made deeper in terms of the layers as compared to\nthe upper branch to address the haze present in the lower frequencies. Using\nthe proposed Orthogonal Transform based Generative Adversarial Network (OTGAN)\narchitecture for image dehazing, we were able to achieve competitive results\nwhen compared to the present state-of-the-art methods.",
    "descriptor": "\nComments: 12 pages, 14 figures\n",
    "authors": [
      "Ahlad Kumar",
      "Mantra Sanathra",
      "Manish Khare",
      "Vijeta Khare"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01743"
  },
  {
    "id": "arXiv:2206.01745",
    "title": "Detection of Fibrosis in Cine Magnetic Resonance Images Using Artificial  Intelligence Techniques",
    "abstract": "Background: Artificial intelligence techniques have demonstrated great\npotential in cardiology, especially to detect imperceptible patterns for the\nhuman eye. In this sense, these techniques seem to be adequate to identify\npatterns in the myocardial texture which could lead to characterize and\nquantify fibrosis. Purpose: The aim of this study was to postulate a new\nartificial intelligence method to identify fibrosis in cine cardiac magnetic\nresonance (CMR) imaging. Methods: A retrospective observational study was\ncarried out in a population of 75 subjects from a clinical center of San Carlos\nde Bariloche. The proposed method analyzes the myocardial texture in cine CMR\nimages using a convolutional neural network to determine local myocardial\ntissue damage. Results: An accuracy of 89% for quantifying local tissue damage\nwas observed for the validation data set and 70% for the test set. In addition,\nthe qualitative analysis showed a high spatial correlation in lesion location.\nConclusions: The postulated method enables to spatially identify fibrosis using\nonly the information from cine nuclear magnetic resonance studies,\ndemonstrating the potential of this technique to quantify myocardial viability\nin the future or to study the lesions etiology",
    "descriptor": "",
    "authors": [
      "Ariel. H. Curiale",
      "Facundo Cabrera",
      "Pablo Jimenez",
      "Jorgelina Medus",
      "Germ\u00c1n Mato",
      "Mat\u00cdas E. Calandrelli"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01745"
  },
  {
    "id": "arXiv:2206.01746",
    "title": "Automatic Quantification of Volumes and Biventricular Function in  Cardiac Resonance. Validation of a New Artificial Intelligence Approach",
    "abstract": "Background: Artificial intelligence techniques have shown great potential in\ncardiology, especially in quantifying cardiac biventricular function, volume,\nmass, and ejection fraction (EF). However, its use in clinical practice is not\nstraightforward due to its poor reproducibility with cases from daily practice,\namong other reasons. Objectives: To validate a new artificial intelligence tool\nin order to quantify the cardiac biventricular function (volume, mass, and EF).\nTo analyze its robustness in the clinical area, and the computational times\ncompared with conventional methods. Methods: A total of 189 patients were\nanalyzed: 89 from a regional center and 100 from a public center. The method\nproposes two convolutional networks that include anatomical information of the\nheart to reduce classification errors. Results: A high concordance (Pearson\ncoefficient) was observed between manual quantification and the proposed\nquantification of cardiac function (0.98, 0.92, 0.96 and 0.8 for volumes and\nbiventricular EF) in about 5 seconds per study. Conclusions: This method\nquantifies biventricular function and volumes in seconds with an accuracy\nequivalent to that of a specialist.",
    "descriptor": "",
    "authors": [
      "Ariel H. Curiale",
      "Mat\u00cdas E. Calandrelli",
      "Lucca Dellazoppa",
      "Mariano Trevisan",
      "Jorge Luis Boci\u00c1n",
      "Juan Pablo Bonifacio",
      "Germ\u00c1n Mato"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.01746"
  },
  {
    "id": "arXiv:2206.01766",
    "title": "Advantages and limitations of quantum routing",
    "abstract": "The Swap gate is a ubiquitous tool for moving information on quantum\nhardware, yet it can be considered a classical operation because it does not\nentangle product states. Genuinely quantum operations could outperform Swap for\nthe task of permuting qubits within an architecture, which we call routing. We\nconsider quantum routing in two models: (1) allowing arbitrary two-qubit\nunitaries, or (2) allowing Hamiltonians with norm-bounded interactions. We\nlower bound the circuit depth or time of quantum routing in terms of spectral\nproperties of graphs representing the architecture interaction constraints, and\ngive a generalized upper bound for all simple connected $n$-vertex graphs. In\nparticular, we give conditions for a superpolynomial classical-quantum routing\nseparation, which exclude graphs with a small spectral gap and graphs of\nbounded degree. Finally, we provide examples of a quadratic separation between\ngate-based and Hamiltonian routing models with a constant number of local\nancillas per qubit and of an $\\Omega(n)$ speedup if we also allow fast local\ninteractions.",
    "descriptor": "\nComments: 45 pages, 7 figures\n",
    "authors": [
      "Aniruddha Bapat",
      "Andrew M. Childs",
      "Alexey V. Gorshkov",
      "Eddie Schoute"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.01766"
  },
  {
    "id": "arXiv:2206.01774",
    "title": "Monkeypox Image Data collection",
    "abstract": "This paper explains the initial Monkeypox Open image data collection\nprocedure. It was created by assembling images collected from websites,\nnewspapers, and online portals and currently contains around 1905 images after\ndata augmentation.",
    "descriptor": "\nComments: This is the attempt of creating monkeypox image dataset collected from various sources and it will continue to update by collectiong samples from journals and other public access domains\n",
    "authors": [
      "Md Manjurul Ahsan",
      "Muhammad Ramiz Uddin",
      "Shahana Akter Luna"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01774"
  },
  {
    "id": "arXiv:2206.01782",
    "title": "Optimal Competitive-Ratio Control",
    "abstract": "Inspired by competitive policy designs approaches in online learning, new\ncontrol paradigms such as competitive-ratio and regret-optimal control have\nbeen recently proposed as alternatives to the classical $\\mathcal{H}_2$ and\n$\\mathcal{H}_\\infty$ approaches. These competitive metrics compare the control\ncost of the designed controller against the cost of a clairvoyant controller,\nwhich has access to past, present, and future disturbances in terms of ratio\nand difference, respectively. While prior work provided the optimal solution\nfor the regret-optimal control problem, in competitive-ratio control, the\nsolution is only provided for the sub-optimal problem. In this work, we derive\nthe optimal solution to the competitive-ratio control problem. We show that the\noptimal competitive ratio formula can be computed as the maximal eigenvalue of\na simple matrix, and provide a state-space controller that achieves the optimal\ncompetitive ratio. We conduct an extensive numerical study to verify this\nanalytical solution, and demonstrate that the optimal competitive-ratio\ncontroller outperforms other controllers on several large scale practical\nsystems. The key techniques that underpin our explicit solution is a reduction\nof the control problem to a Nehari problem, along with a novel factorization of\nthe clairvoyant controller's cost. We reveal an interesting relation between\nthe explicit solutions that now exist for both competitive control paradigms by\nformulating a regret-optimal control framework with weight functions that can\nalso be utilized for practical purposes.",
    "descriptor": "",
    "authors": [
      "Oron Sabag",
      "Sahin Lale",
      "Babak Hassibi"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.01782"
  },
  {
    "id": "arXiv:2206.01793",
    "title": "R2U++: A Multiscale Recurrent Residual U-Net with Dense Skip Connections  for Medical Image Segmentation",
    "abstract": "U-Net is a widely adopted neural network in the domain of medical image\nsegmentation. Despite its quick embracement by the medical imaging community,\nits performance suffers on complicated datasets. The problem can be ascribed to\nits simple feature extracting blocks: encoder/decoder, and the semantic gap\nbetween encoder and decoder. Variants of U-Net (such as R2U-Net) have been\nproposed to address the problem of simple feature extracting blocks by making\nthe network deeper, but it does not deal with the semantic gap problem. On the\nother hand, another variant UNET++ deals with the semantic gap problem by\nintroducing dense skip connections but has simple feature extraction blocks. To\novercome these issues, we propose a new U-Net based medical image segmentation\narchitecture R2U++. In the proposed architecture, the adapted changes from\nvanilla U-Net are: (1) the plain convolutional backbone is replaced by a deeper\nrecurrent residual convolution block. The increased field of view with these\nblocks aids in extracting crucial features for segmentation which is proven by\nimprovement in the overall performance of the network. (2) The semantic gap\nbetween encoder and decoder is reduced by dense skip pathways. These pathways\naccumulate features coming from multiple scales and apply concatenation\naccordingly. The modified architecture has embedded multi-depth models, and an\nensemble of outputs taken from varying depths improves the performance on\nforeground objects appearing at various scales in the images. The performance\nof R2U++ is evaluated on four distinct medical imaging modalities: electron\nmicroscopy (EM), X-rays, fundus, and computed tomography (CT). The average gain\nachieved in IoU score is 1.5+-0.37% and in dice score is 0.9+-0.33% over\nUNET++, whereas, 4.21+-2.72 in IoU and 3.47+-1.89 in dice score over R2U-Net\nacross different medical imaging segmentation datasets.",
    "descriptor": "\nComments: Paper accepted in Neural Computing and Applications (2022). Please cite the final version available from Springer website this https URL\n",
    "authors": [
      "Mehreen Mubashar",
      "Hazrat Ali",
      "Christer Gronlund",
      "Shoaib Azmat"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01793"
  },
  {
    "id": "arXiv:2206.01795",
    "title": "Robust Topological Inference in the Presence of Outliers",
    "abstract": "The distance function to a compact set plays a crucial role in the paradigm\nof topological data analysis. In particular, the sublevel sets of the distance\nfunction are used in the computation of persistent homology -- a backbone of\nthe topological data analysis pipeline. Despite its stability to perturbations\nin the Hausdorff distance, persistent homology is highly sensitive to outliers.\nIn this work, we develop a framework of statistical inference for persistent\nhomology in the presence of outliers. Drawing inspiration from recent\ndevelopments in robust statistics, we propose a $\\textit{median-of-means}$\nvariant of the distance function ($\\textsf{MoM Dist}$), and establish its\nstatistical properties. In particular, we show that, even in the presence of\noutliers, the sublevel filtrations and weighted filtrations induced by\n$\\textsf{MoM Dist}$ are both consistent estimators of the true underlying\npopulation counterpart, and their rates of convergence in the bottleneck metric\nare controlled by the fraction of outliers in the data. Finally, we demonstrate\nthe advantages of the proposed methodology through simulations and\napplications.",
    "descriptor": "\nComments: 50 pages, 10 figures\n",
    "authors": [
      "Siddharth Vishwanath",
      "Bharath K. Sriperumbudur",
      "Kenji Fukumizu",
      "Satoshi Kuriki"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Computational Geometry (cs.CG)",
      "Machine Learning (cs.LG)",
      "Algebraic Topology (math.AT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.01795"
  },
  {
    "id": "arXiv:2206.01825",
    "title": "Debiased Machine Learning without Sample-Splitting for Stable Estimators",
    "abstract": "Estimation and inference on causal parameters is typically reduced to a\ngeneralized method of moments problem, which involves auxiliary functions that\ncorrespond to solutions to a regression or classification problem. Recent line\nof work on debiased machine learning shows how one can use generic machine\nlearning estimators for these auxiliary problems, while maintaining asymptotic\nnormality and root-$n$ consistency of the target parameter of interest, while\nonly requiring mean-squared-error guarantees from the auxiliary estimation\nalgorithms. The literature typically requires that these auxiliary problems are\nfitted on a separate sample or in a cross-fitting manner. We show that when\nthese auxiliary estimation algorithms satisfy natural leave-one-out stability\nproperties, then sample splitting is not required. This allows for sample\nre-use, which can be beneficial in moderately sized sample regimes. For\ninstance, we show that the stability properties that we propose are satisfied\nfor ensemble bagged estimators, built via sub-sampling without replacement, a\npopular technique in machine learning practice.",
    "descriptor": "",
    "authors": [
      "Qizhao Chen",
      "Vasilis Syrgkanis",
      "Morgane Austern"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2206.01825"
  },
  {
    "id": "arXiv:2206.01826",
    "title": "The Gamma Generalized Normal Distribution: A Descriptor of SAR Imagery",
    "abstract": "We propose a new four-parameter distribution for modeling synthetic aperture\nradar (SAR) imagery named the gamma generalized normal (GGN) by combining the\ngamma and generalized normal distributions. A mathematical characterization of\nthe new distribution is provided by identifying the limit behavior and by\ncalculating the density and moment expansions. The GGN model performance is\nevaluated on both synthetic and actual data and, for that, maximum likelihood\nestimation and random number generation are discussed. The proposed\ndistribution is compared with the beta generalized normal distribution (BGN),\nwhich has already shown to appropriately represent SAR imagery. The performance\nof these two distributions are measured by means of statistics which provide\nevidence that the GGN can outperform the BGN distribution in some contexts.",
    "descriptor": "\nComments: 21 pages, 6 figures, 6 tables\n",
    "authors": [
      "G. M. Cordeiro",
      "R. J. Cintra",
      "L. C. R\u00eago",
      "A. D. C. Nascimento"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Statistics Theory (math.ST)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2206.01826"
  },
  {
    "id": "arXiv:2206.01827",
    "title": "A particle system with mean-field interaction: Large-scale limit of  stationary distributions",
    "abstract": "We consider a system consisting of $n$ particles, moving forward in jumps on\nthe real line. System state is the empirical distribution of particle\nlocations. Each particle ``jumps forward'' at some time points, with the\ninstantaneous rate of jumps given by a decreasing function of the particle's\nlocation quantile within the current state (empirical distribution). Previous\nwork on this model established, under certain conditions, the convergence, as\n$n\\to\\infty$, of the system random dynamics to that of a deterministic\nmean-field model (MFM), which is a solution to an integro-differential\nequation. Another line of previous work established the existence of MFMs that\nare traveling waves, as well as the attraction of MFM trajectories to traveling\nwaves. The main results of this paper are: (a) We prove that, as $n\\to\\infty$,\nthe stationary distributions of (re-centered) states concentrate on a\n(re-centered) traveling wave; (b) We obtain a uniform across $n$ moment bound\non the stationary distributions of (re-centered) states; (c) We prove a\nconvergence-to-MFM result, which is substantially more general than that in\nprevious work. Results (b) and (c) serve as ``ingredients'' of the proof of\n(a), but also are of independent interest.",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Alexander Stolyar"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2206.01827"
  },
  {
    "id": "arXiv:2206.01847",
    "title": "gcd-Pairs in $\\mathbb{Z}_{n}$ and their graph representations",
    "abstract": "This research introduces a gcd-pair in $\\mathbb{Z}_n$ which is an unordered\npair $\\{[a]_n, [b]_n\\}$ of elements in $ \\mathbb{Z}_n $ such that $0\\leq a,b <\nn$ and the greatest common divisor $\\gcd(a,b)$ divides $ n $. The properties of\ngcd-pairs in $ \\mathbb{Z}_n $ and their graph representations are investigated.\nWe also provide the counting formula of gcd-pairs in $ \\mathbb{Z}_n $ and its\nsubsets. The algorithms to find, count and check gcd-pairs in $ \\mathbb{Z}_{n}$\nare included.",
    "descriptor": "\nComments: 11 pages, 5 figures\n",
    "authors": [
      "Wanchai Tapanyo",
      "Tanyaton Tongpikul",
      "Suphansa Kaewpradit"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2206.01847"
  },
  {
    "id": "arXiv:2206.01862",
    "title": "Image Data collection and implementation of deep learning-based model in  detecting Monkeypox disease using modified VGG16",
    "abstract": "While the world is still attempting to recover from the damage caused by the\nbroad spread of COVID-19, the Monkeypox virus poses a new threat of becoming a\nglobal pandemic. Although the Monkeypox virus itself is not deadly and\ncontagious as COVID-19, still every day, new patients case has been reported\nfrom many nations. Therefore, it will be no surprise if the world ever faces\nanother global pandemic due to the lack of proper precautious steps. Recently,\nMachine learning (ML) has demonstrated huge potential in image-based diagnoses\nsuch as cancer detection, tumor cell identification, and COVID-19 patient\ndetection. Therefore, a similar application can be adopted to diagnose the\nMonkeypox-related disease as it infected the human skin, which image can be\nacquired and further used in diagnosing the disease. Considering this\nopportunity, in this work, we introduce a newly developed \"Monkeypox2022\"\ndataset that is publicly available to use and can be obtained from our shared\nGitHub repository. The dataset is created by collecting images from multiple\nopen-source and online portals that do not impose any restrictions on use, even\nfor commercial purposes, hence giving a safer path to use and disseminate such\ndata when constructing and deploying any type of ML model. Further, we propose\nand evaluate a modified VGG16 model, which includes two distinct studies: Study\nOne and Two. Our exploratory computational results indicate that our suggested\nmodel can identify Monkeypox patients with an accuracy of $97\\pm1.8\\%$\n(AUC=97.2) and $88\\pm0.8\\%$ (AUC=0.867) for Study One and Two, respectively.\nAdditionally, we explain our model's prediction and feature extraction\nutilizing Local Interpretable Model-Agnostic Explanations (LIME) help to a\ndeeper insight into specific features that characterize the onset of the\nMonkeypox virus.",
    "descriptor": "",
    "authors": [
      "Md Manjurul Ahsan",
      "Muhammad Ramiz Uddin",
      "Mithila Farjana",
      "Ahmed Nazmus Sakib",
      "Khondhaker Al Momin",
      "Shahana Akter Luna"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01862"
  },
  {
    "id": "arXiv:2206.01890",
    "title": "A numerical stability analysis of mean curvature flow of noncompact  hypersurfaces with Type-II curvature blowup: II",
    "abstract": "In previous work [GIKW21], we have presented evidence from numerical\nsimulations that the Type-II singularities of mean curvature flow (MCF) of\nrotationally-symmetric, complete, noncompact embedded hypersurfaces constructed\nin [IW19, IWZ21] are stable. More precisely, it is shown in that paper that for\nsmall rotationally-symmetric perturbations of initial embeddings near the\n\"tip\", numerical simulations of MCF of such initial embeddings develop the same\nType-II singularities with the same \"bowl soliton\" blowup behaviors in a\nneighborhood of the singularity. It is also shown in that work that for small\nrotationally-symmetric perturbations of the initial embeddings that are\nsufficiently far away from the tip, MCF develops Type-I \"neckpinch\"\nsingularities.\nIn this work, we again use numerical simulations to show that MCF subject to\ninitial perturbations that are not rotationally symmetric behaves\nasymptotically like it does for rotationally-symmetric perturbations. In\nparticular, if we impose sinusoidal angular dependence on the initial\nembeddings, we find that for perturbations near the tip, evolutions by MCF\nasymptotically lose their angular dependence -- becoming round -- and develop\nType-II bowl soliton singularities. As well, if we impose sinusoidal angular\ndependence on the initial embeddings for perturbations sufficiently far from\nthe tip, the angular dependence again disappears as Type-I neckpinch\nsingularities develop. The numerical analysis carried out in this work is an\nadaptation of the \"overlap\" method introduced in [GIKW21] and permits angular\ndependence.",
    "descriptor": "\nComments: 17 pages, 13 figures. Comments are welcome!\n",
    "authors": [
      "David Garfinkle",
      "James Isenberg",
      "Dan Knopf",
      "Haotian Wu"
    ],
    "subjectives": [
      "Differential Geometry (math.DG)",
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.01890"
  },
  {
    "id": "arXiv:2206.01897",
    "title": "Modeling of Textures to Predict Immune Cell Status and Survival of Brain  Tumour Patients",
    "abstract": "Radiomics has shown a capability for different types of cancers such as\nglioma to predict the clinical outcome. It can have a non-invasive means of\nevaluating the immunotherapy response prior to treatment. However, the use of\ndeep convolutional neural networks (CNNs)-based radiomics requires large\ntraining image sets. To avoid this problem, we investigate a new imaging\nfeatures that model distribution with a Gaussian mixture model (GMM) of learned\n3D CNN features. Using these deep radiomic features (DRFs), we aim to predict\nthe immune marker status (low versus high) and overall survival for glioma\npatients. We extract the DRFs by aggregating the activation maps of a\npre-trained 3D-CNN within labeled tumor regions of MRI scans that corresponded\nimmune markers of 151 patients. Our experiments are performed to assess the\nrelationship between the proposed DRFs, three immune cell markers (Macrophage\nM1, Neutrophils and T Cells Follicular Helper), and measure their association\nwith overall survival. Using the random forest (RF) model, DRFs was able to\npredict the immune marker status with area under the ROC curve (AUC) of 78.67,\n83.93 and 75.67\\% for Macrophage M1, Neutrophils and T Cells Follicular Helper,\nrespectively. Combined the immune markers with DRFs and clinical variables,\nKaplan-Meier estimator and Log-rank test achieved the most significant\ndifference between predicted groups of patients (short-term versus long-term\nsurvival) with p\\,=\\,4.31$\\times$10$^{-7}$ compared to p\\,=\\,0.03 for Immune\ncell markers, p\\,=\\,0.07 for clinical variables , and\np\\,=\\,1.45$\\times$10$^{-5}$ for DRFs. Our findings indicate that the proposed\nfeatures (DRFs) used in RF models may significantly consider prognosticating\npatients with brain tumour prior to surgery through regularly acquired imaging\ndata.",
    "descriptor": "",
    "authors": [
      "Ahmad Chaddad",
      "Mingli Zhang",
      "Lama Hassan",
      "Tamim Niazi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Genomics (q-bio.GN)",
      "Quantitative Methods (q-bio.QM)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2206.01897"
  },
  {
    "id": "arXiv:2206.01903",
    "title": "Deep Radiomic Analysis for Predicting Coronavirus Disease 2019 in  Computerized Tomography and X-ray Images",
    "abstract": "This paper proposes to encode the distribution of features learned from a\nconvolutional neural network using a Gaussian Mixture Model. These parametric\nfeatures, called GMM-CNN, are derived from chest computed tomography and X-ray\nscans of patients with Coronavirus Disease 2019. We use the proposed GMM-CNN\nfeatures as input to a robust classifier based on random forests to\ndifferentiate between COVID-19 and other pneumonia cases. Our experiments\nassess the advantage of GMM-CNN features compared to standard CNN\nclassification on test images. Using a random forest classifier (80\\% samples\nfor training; 20\\% samples for testing), GMM-CNN features encoded with two\nmixture components provided a significantly better performance than standard\nCNN classification (p\\,$<$\\,0.05). Specifically, our method achieved an\naccuracy in the range of 96.00\\,--\\,96.70\\% and an area under the ROC curve in\nthe range of 99.29\\,--\\,99.45\\%, with the best performance obtained by\ncombining GMM-CNN features from both computed tomography and X-ray images. Our\nresults suggest that the proposed GMM-CNN features could improve the prediction\nof COVID-19 in chest computed tomography and X-ray scans.",
    "descriptor": "",
    "authors": [
      "Ahmad Chaddad",
      "Lama Hassan",
      "Christian Desrosiers"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2206.01903"
  },
  {
    "id": "arXiv:2206.01930",
    "title": "Investigating Brain Connectivity with Graph Neural Networks and  GNNExplainer",
    "abstract": "Functional connectivity plays an essential role in modern neuroscience. The\nmodality sheds light on the brain's functional and structural aspects,\nincluding mechanisms behind multiple pathologies. One such pathology is\nschizophrenia which is often followed by auditory verbal hallucinations. The\nlatter is commonly studied by observing functional connectivity during speech\nprocessing. In this work, we have made a step toward an in-depth examination of\nfunctional connectivity during a dichotic listening task via deep learning for\nthree groups of people: schizophrenia patients with and without auditory verbal\nhallucinations and healthy controls. We propose a graph neural network-based\nframework within which we represent EEG data as signals in the graph domain.\nThe framework allows one to 1) predict a brain mental disorder based on EEG\nrecording, 2) differentiate the listening state from the resting state for each\ngroup and 3) recognize characteristic task-depending connectivity. Experimental\nresults show that the proposed model can differentiate between the above groups\nwith state-of-the-art performance. Besides, it provides a researcher with\nmeaningful information regarding each group's functional connectivity, which we\nvalidated on the current domain knowledge.",
    "descriptor": "\nComments: Submitted to ICPR 2022\n",
    "authors": [
      "Maksim Zhdanov",
      "Saskia Steinmann",
      "Nico Hoffmann"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01930"
  },
  {
    "id": "arXiv:2206.01948",
    "title": "STARSS22: A dataset of spatial recordings of real scenes with  spatiotemporal annotations of sound events",
    "abstract": "This report presents the Sony-TAu Realistic Spatial Soundscapes 2022\n(STARS22) dataset for sound event localization and detection, comprised of\nspatial recordings of real scenes collected in various interiors of two\ndifferent sites. The dataset is captured with a high resolution spherical\nmicrophone array and delivered in two 4-channel formats, first-order Ambisonics\nand tetrahedral microphone array. Sound events in the dataset belonging to 13\ntarget sound classes are annotated both temporally and spatially through a\ncombination of human annotation and optical tracking. The dataset serves as the\ndevelopment and evaluation dataset for the Task 3 of the DCASE2022 Challenge on\nSound Event Localization and Detection and introduces significant new\nchallenges for the task compared to the previous iterations, which were based\non synthetic spatialized sound scene recordings. Dataset specifications are\ndetailed including recording and annotation process, target classes and their\npresence, and details on the development and evaluation splits. Additionally,\nthe report presents the baseline system that accompanies the dataset in the\nchallenge with emphasis on the differences with the baseline of the previous\niterations; namely, introduction of the multi-ACCDOA representation to handle\nmultiple simultaneous occurences of events of the same class, and support for\nadditional improved input features for the microphone array format. Results of\nthe baseline indicate that with a suitable training strategy a reasonable\ndetection and localization performance can be achieved on real sound scene\nrecordings. The dataset is available in https://zenodo.org/record/6387880.",
    "descriptor": "",
    "authors": [
      "Archontis Politis",
      "Kazuki Shimada",
      "Parthasaarathy Sudarsanam",
      "Sharath Adavanne",
      "Daniel Krause",
      "Yuichiro Koyama",
      "Naoya Takahashi",
      "Shusuke Takahashi",
      "Yuki Mitsufuji",
      "Tuomas Virtanen"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2206.01948"
  },
  {
    "id": "arXiv:2206.01981",
    "title": "Evaluation of Xilinx Deep Learning Processing Unit under Neutron  Irradiation",
    "abstract": "This paper studies the dependability of the Xilinx Deep-Learning Processing\nUnit (DPU) under neutron irradiation. It analyses the impact of Single Event\nEffects (SEEs) on the accuracy of the DPU running the resnet50 model on a\nXilinx Ultrascale+ MPSoC.",
    "descriptor": "\nComments: 4 pages\n",
    "authors": [
      "D. Agiakatsikas",
      "N. Foutris",
      "A. Sari",
      "V. Vlagkoulis",
      "I. Souvatzoglou",
      "M. Psarakis",
      "M. Luj\u00e1n",
      "M. Kastriotou",
      "C. Cazzaniga"
    ],
    "subjectives": [
      "Instrumentation and Detectors (physics.ins-det)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2206.01981"
  },
  {
    "id": "arXiv:2206.02026",
    "title": "Efficient Approximation of Multiparameter Persistence Modules",
    "abstract": "Topological Data Analysis is a growing area of data science, which aims at\ncomputing and characterizing the geometry and topology of data sets, in order\nto produce useful descriptors for subsequent statistical and machine learning\ntasks. Its main computational tool is persistent homology, which amounts to\ntrack the topological changes in growing families of subsets of the data set\nitself, called filtrations, and encode them in an algebraic object, called\npersistence module. Even though algorithms and theoretical properties of\nmodules are now well-known in the single-parameter case, that is, when there is\nonly one filtration to study, much less is known in the multi-parameter case,\nwhere several filtrations are given at once. Though more complicated, the\nresulting persistence modules are usually richer and encode more information,\nmaking them better descriptors for data science. In this article, we present\nthe first approximation scheme, which is based on fibered barcodes and exact\nmatchings, two constructions that stem from the theory of single-parameter\npersistence, for computing and decomposing general multi-parameter persistence\nmodules. Our algorithm has controlled complexity and running time, and works in\narbitrary dimension, i.e., with an arbitrary number of filtrations. Moreover,\nwhen restricting to specific classes of multi-parameter persistence modules,\nnamely the ones that can be decomposed into intervals, we establish theoretical\nresults about the approximation error between our estimate and the true module\nin terms of interleaving distance. Finally, we present empirical evidence\nvalidating output quality and speed-up on several data sets.",
    "descriptor": "",
    "authors": [
      "David Loiseaux",
      "Mathieu Carri\u00e8re",
      "Andrew J. Blumberg"
    ],
    "subjectives": [
      "Algebraic Topology (math.AT)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2206.02026"
  },
  {
    "id": "arXiv:2206.02040",
    "title": "MetaNOR: A Meta-Learnt Nonlocal Operator Regression Approach for  Metamaterial Modeling",
    "abstract": "We propose MetaNOR, a meta-learnt approach for transfer-learning operators\nbased on the nonlocal operator regression. The overall goal is to efficiently\nprovide surrogate models for new and unknown material-learning tasks with\ndifferent microstructures. The algorithm consists of two phases: (1) learning a\ncommon nonlocal kernel representation from existing tasks; (2) transferring the\nlearned knowledge and rapidly learning surrogate operators for unseen tasks\nwith a different material, where only a few test samples are required. We apply\nMetaNOR to model the wave propagation within 1D metamaterials, showing\nsubstantial improvements on the sampling efficiency for new materials.",
    "descriptor": "",
    "authors": [
      "Lu Zhang",
      "Huaiqian You",
      "Yue Yu"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.02040"
  },
  {
    "id": "arXiv:2206.02041",
    "title": "First-Order Algorithms for Min-Max Optimization in Geodesic Metric  Spaces",
    "abstract": "From optimal transport to robust dimensionality reduction, a plethora of\nmachine learning applications can be cast into the min-max optimization\nproblems over Riemannian manifolds. Though many min-max algorithms have been\nanalyzed in the Euclidean setting, it has proved elusive to translate these\nresults to the Riemannian case. Zhang et al. [2022] have recently shown that\ngeodesic convex concave Riemannian problems always admit saddle-point\nsolutions. Inspired by this result, we study whether a performance gap between\nRiemannian and optimal Euclidean space convex-concave algorithms is necessary.\nWe answer this question in the negative-we prove that the Riemannian corrected\nextragradient (RCEG) method achieves last-iterate convergence at a linear rate\nin the geodesically strongly-convex-concave case, matching the Euclidean\nresult. Our results also extend to the stochastic or non-smooth case where RCEG\nand Riemanian gradient ascent descent (RGDA) achieve near-optimal convergence\nrates up to factors depending on curvature of the manifold.",
    "descriptor": "\nComments: 39 pages, 12 figures, under submission\n",
    "authors": [
      "Michael I. Jordan",
      "Tianyi Lin",
      "Emmanouil-Vasileios Vlatakis-Gkaragkounis"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Differential Geometry (math.DG)"
    ],
    "url": "https://arxiv.org/abs/2206.02041"
  },
  {
    "id": "arXiv:2206.02058",
    "title": "When Personalization Harms: Reconsidering the Use of Group Attributes in  Prediction",
    "abstract": "The standard approach to personalization in machine learning consists of\ntraining a model with group attributes like sex, age group, and blood type. In\nthis work, we show that this approach to personalization fails to improve\nperformance for all groups who provide personal data. We discuss how this\neffect inflicts harm in applications where models assign predictions on the\nbasis of group membership. We propose collective preference guarantees to\nensure the fair use of group attributes in prediction. We characterize how\ncommon approaches to personalization violate fair use due to failures in model\ndevelopment and deployment. We conduct a comprehensive empirical study of\npersonalization in clinical prediction models. Our results highlight the\nprevalence of fair use violations, demonstrate actionable interventions to\nmitigate harm and underscore the need to measure the gains of personalization\nfor all groups who provide personal data.",
    "descriptor": "",
    "authors": [
      "Vinith M. Suriyakumar",
      "Marzyeh Ghassemi",
      "Berk Ustun"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02058"
  },
  {
    "id": "arXiv:2206.02061",
    "title": "Low Power Neuromorphic EMG Gesture Classification",
    "abstract": "EMG (Electromyograph) signal based gesture recognition can prove vital for\napplications such as smart wearables and bio-medical neuro-prosthetic control.\nSpiking Neural Networks (SNNs) are promising for low-power, real-time EMG\ngesture recognition, owing to their inherent spike/event driven spatio-temporal\ndynamics. In literature, there are limited demonstrations of neuromorphic\nhardware implementation (at full chip/board/system scale) for EMG gesture\nclassification. Moreover, most literature attempts exploit primitive SNNs based\non LIF (Leaky Integrate and Fire) neurons. In this work, we address the\naforementioned gaps with following key contributions: (1) Low-power, high\naccuracy demonstration of EMG-signal based gesture recognition using\nneuromorphic Recurrent Spiking Neural Networks (RSNN). In particular, we\npropose a multi-time scale recurrent neuromorphic system based on special\ndouble-exponential adaptive threshold (DEXAT) neurons. Our network achieves\nstate-of-the-art classification accuracy (90%) while using ~53% lesser neurons\nthan best reported prior art on Roshambo EMG dataset. (2) A new multi-channel\nspike encoder scheme for efficient processing of real-valued EMG data on\nneuromorphic systems. (3) Unique multi-compartment methodology to implement\ncomplex adaptive neurons on Intel's dedicated neuromorphic Loihi chip is shown.\n(4) RSNN implementation on Loihi (Nahuku 32) achieves significant\nenergy/latency benefits of ~983X/19X compared to GPU for batch size as 50.",
    "descriptor": "\nComments: 3 Pages, 5 figures, 1 table\n",
    "authors": [
      "Sai Sukruth Bezugam",
      "Ahmed Shaban",
      "Manan Suri"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.02061"
  },
  {
    "id": "arXiv:2206.02088",
    "title": "Inference for Interpretable Machine Learning: Fast, Model-Agnostic  Confidence Intervals for Feature Importance",
    "abstract": "In order to trust machine learning for high-stakes problems, we need models\nto be both reliable and interpretable. Recently, there has been a growing body\nof work on interpretable machine learning which generates human understandable\ninsights into data, models, or predictions. At the same time, there has been\nincreased interest in quantifying the reliability and uncertainty of machine\nlearning predictions, often in the form of confidence intervals for predictions\nusing conformal inference. Yet, there has been relatively little attention\ngiven to the reliability and uncertainty of machine learning interpretations,\nwhich is the focus of this paper. Our goal is to develop confidence intervals\nfor a widely-used form of machine learning interpretation: feature importance.\nWe specifically seek to develop universal model-agnostic and assumption-light\nconfidence intervals for feature importance that will be valid for any machine\nlearning model and for any regression or classification task. We do so by\nleveraging a form of random observation and feature subsampling called\nminipatch ensembles and show that our approach provides assumption-light\nasymptotic coverage for the feature importance score of any model. Further, our\napproach is fast as computations needed for inference come nearly for free as\npart of the ensemble learning process. Finally, we also show that our same\nprocedure can be leveraged to provide valid confidence intervals for\npredictions, hence providing fast, simultaneous quantification of the\nuncertainty of both model predictions and interpretations. We validate our\nintervals on a series of synthetic and real data examples, showing that our\napproach detects the correct important features and exhibits many computational\nand statistical advantages over existing methods.",
    "descriptor": "",
    "authors": [
      "Luqin Gan",
      "Lili Zheng",
      "Genevera I. Allen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2206.02088"
  },
  {
    "id": "arXiv:2206.02124",
    "title": "Sampling Frequency Independent Dialogue Separation",
    "abstract": "In some DNNs for audio source separation, the relevant model parameters are\nindependent of the sampling frequency of the audio used for training.\nConsidering the application of dialogue separation, this is shown for two DNN\narchitectures: a U-Net and a fully-convolutional model. The models are trained\nwith audio sampled at 8 kHz. The learned parameters are transferred to models\nfor processing audio at 48 kHz. The separated audio sources are compared with\nthe ones produced by the same model architectures trained with 48 kHz versions\nof the same training data. A listening test and computational measures show\nthat there is no significant perceptual difference between the models trained\nwith 8 kHz or with 48 kHz. This transferability of the learned parameters\nallows for a faster and computationally less costly training. It also enables\nusing training datasets available at a lower sampling frequency than the one\nneeded by the application at hand, or using data collections with multiple\nsampling frequencies.",
    "descriptor": "\nComments: accepted into EUSIPCO 2022\n",
    "authors": [
      "Jouni Paulus",
      "Matteo Torcoli"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2206.02124"
  },
  {
    "id": "arXiv:2206.02125",
    "title": "Geometrically-Motivated Primary-Ambient Decomposition With  Center-Channel Extraction",
    "abstract": "A geometrically-motivated method for primary-ambient decomposition is\nproposed and evaluated in an up-mixing application. The method consists of two\nsteps, accommodating a particularly intuitive explanation. The first step\nconsists of signal-adaptive rotations applied on the input stereo scene, which\ntranslate the primary sound sources into the center of the rotated scene. The\nsecond step applies a center-channel extraction method, based on a simple\nsignal model and optimal in the mean-squared-error sense. The performance is\nevaluated by using the estimated ambient component to enable surround sound\nstarting from real-world stereo signals. The participants in the reported\nlistening test are asked to adjust the audio scene envelopment and find the\naudio settings that pleases them the most. The possibility for up-mixing\nenabled by the proposed method is used extensively, and the user satisfaction\nis significantly increased compared to the original stereo mix.",
    "descriptor": "\nComments: accepted into EUSIPCO 2022\n",
    "authors": [
      "Jouni Paulus",
      "Matteo Torcoli"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2206.02125"
  },
  {
    "id": "arXiv:2206.02134",
    "title": "Toward Sustainable Transportation: Accelerating Vehicle Electrification  with Dynamic Charging Deployment",
    "abstract": "Electric vehicles (EVs) are being actively adopted as a solution to\nsustainable transportation. However, a bottleneck remains with charging, where\ntwo of the main problems are the long charging time and the range anxiety of EV\ndrivers. In this research, we investigate the deployment of dynamic charging\nsystems, i.e., electrified roads that wirelessly charge EVs on the go, with a\nview to accelerating EVs adoption rate. We propose a traffic-based deployment\nstrategy, statistically quantify its impact, and apply the strategy to two case\nstudies of real traffic in New York City (USA) and Xi'an (China). We find that\nour analytical estimates not only closely match the real data, but they also\nsuggest that dynamic charging considerably extends the driving range of popular\nEV models in urban mobility. For example, when only 5% of the existing roads in\nNew York City are equipped with this technology, an EV model such as the Nissan\nLeaf will approximately maintain its battery level without stopping to\nrecharge. If the percentage of charging roads is increased to 10%, then the\nLeaf will gain nearly 10% of its battery after every 40 kilometers of driving.\nOur framework provides a solution to public and private organizations that\nsupport and facilitate vehicle electrification through charging infrastructure.",
    "descriptor": "\nComments: 14 pages, accepted to IEEE Transactions on Vehicular Technology\n",
    "authors": [
      "Duc Minh Nguyen",
      "Mustafa A. Kishk",
      "Mohamed-Slim Alouini"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.02134"
  },
  {
    "id": "arXiv:2206.02142",
    "title": "Collaborative search and autonomous task allocation in organizations of  learning agents",
    "abstract": "This paper introduces a model of multi-unit organizations with either static\nstructures, i.e., they are designed top-down following classical approaches to\norganizational design, or dynamic structures, i.e., the structures emerge over\ntime from micro-level decisions. In the latter case, the units are capable of\nlearning about the technical interdependencies of the task they face, and they\nuse their knowledge by adapting the task allocation from time to time. In both\nstatic and dynamic organizations, searching for actions to increase the\nperformance can either be carried out individually or collaboratively. The\nresults indicate that (i) collaborative search processes can help overcome the\nadverse effects of inefficient task allocations as long as there is an internal\nfit with other organizational design elements, and (ii) for dynamic\norganizations, the emergent task allocation does not necessarily mirror the\ntechnical interdependencies of the task the organizations face, even though the\nsame (or even higher) performances are achieved.",
    "descriptor": "\nComments: 12 pages, 4 figures, 1 table. arXiv admin note: text overlap with arXiv:2105.04514\n",
    "authors": [
      "Stephan Leitner"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Multiagent Systems (cs.MA)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ],
    "url": "https://arxiv.org/abs/2206.02142"
  },
  {
    "id": "arXiv:2206.02147",
    "title": "Dict-TTS: Learning to Pronounce with Prior Dictionary Knowledge for  Text-to-Speech",
    "abstract": "Polyphone disambiguation aims to capture accurate pronunciation knowledge\nfrom natural text sequences for reliable Text-to-speech (TTS) systems. However,\nprevious approaches require substantial annotated training data and additional\nefforts from language experts, making it difficult to extend high-quality\nneural TTS systems to out-of-domain daily conversations and countless languages\nworldwide. This paper tackles the polyphone disambiguation problem from a\nconcise and novel perspective: we propose Dict-TTS, a semantic-aware generative\ntext-to-speech model with an online website dictionary (the existing prior\ninformation in the natural language). Specifically, we design a\nsemantics-to-pronunciation attention (S2PA) module to match the semantic\npatterns between the input text sequence and the prior semantics in the\ndictionary and obtain the corresponding pronunciations; The S2PA module can be\neasily trained with the end-to-end TTS model without any annotated phoneme\nlabels. Experimental results in three languages show that our model outperforms\nseveral strong baseline models in terms of pronunciation accuracy and improves\nthe prosody modeling of TTS systems. Further extensive analyses with different\nlinguistic encoders demonstrate that each design in Dict-TTS is effective.\nAudio samples are available at \\url{https://dicttts.github.io/DictTTS-Demo/}.",
    "descriptor": "",
    "authors": [
      "Ziyue Jiang",
      "Su Zhe",
      "Zhou Zhao",
      "Qian Yang",
      "Yi Ren",
      "Jinglin Liu",
      "Zhenhui Ye"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2206.02147"
  },
  {
    "id": "arXiv:2206.02173",
    "title": "Efficient Frozen Gaussian Sampling Algorithms for Nonadiabatic Quantum  Dynamics at Metal Surfaces",
    "abstract": "In this article, we propose a Frozen Gaussian Sampling (FGS) algorithm for\nsimulating nonadiabatic quantum dynamics at metal surfaces with a continuous\nspectrum. This method consists of a Monte-Carlo algorithm for sampling the\ninitial wave packets on the phase space and a surface-hopping type stochastic\ntime propagation scheme for the wave packets. We prove that to reach a certain\naccuracy threshold, the sample size required is independent of both the\nsemiclassical parameter $\\varepsilon$ and the number of metal orbitals $N$,\nwhich makes it one of the most promising methods to study the nonadiabatic\ndynamics. The algorithm and its convergence properties are also validated\nnumerically. Furthermore, we carry out numerical experiments including\nexploring the nuclei dynamics, electron transfer and finite-temperature\neffects, and demonstrate that our method captures the physics which can not be\ncaptured by classical surface hopping trajectories.",
    "descriptor": "\nComments: 41 pages, 10 figures\n",
    "authors": [
      "Zhen Huang",
      "Limin Xu",
      "Zhennan Zhou"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.02173"
  },
  {
    "id": "arXiv:2206.02176",
    "title": "Development of research network on Quantum Annealing Computation and  Information using Google Scholar data",
    "abstract": "We build and analyze the network of hundred top cited nodes (research papers\nand books from Google Scholar; strength or citation of the nodes range from\nabout 44000 upto 100) starting early 1980 to till last year. These searched\npublications (papers, books) are based on Quantum Annealing Computation and\nInformation categorized in four different sets: A) Quantum/Transverse Field\nSpin Glass Model, B) Quantum Annealing, C) Quantum Adiabatic Computation and D)\nQuantum Computation Information in the title or abstract of the searched\npublications. We fitted the growth in the annual number of publication ($n_p$)\nin each of these four categories A to D to the form $n_p \\sim\\exp{(t/\\tau)}$\nwhere $t$ denotes the time in year. We found the scaling time $\\tau$ to be of\norder about 10 years for category A and C whereas $\\tau$ is order of about 5\nyears for category B and D.",
    "descriptor": "\nComments: Submitted in Philosophical Transactions A\n",
    "authors": [
      "Antika Sinha"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2206.02176"
  },
  {
    "id": "arXiv:2206.02218",
    "title": "Statistical Deep Learning for Spatial and Spatio-Temporal Data",
    "abstract": "Deep neural network models have become ubiquitous in recent years, and have\nbeen applied to nearly all areas of science, engineering, and industry. These\nmodels are particularly useful for data that have strong dependencies in space\n(e.g., images) and time (e.g., sequences). Indeed, deep models have also been\nextensively used by the statistical community to model spatial and\nspatio-temporal data through, for example, the use of multi-level Bayesian\nhierarchical models and deep Gaussian processes. In this review, we first\npresent an overview of traditional statistical and machine learning\nperspectives for modeling spatial and spatio-temporal data, and then focus on a\nvariety of hybrid models that have recently been developed for latent process,\ndata, and parameter specifications. These hybrid models integrate statistical\nmodeling ideas with deep neural network models in order to take advantage of\nthe strengths of each modeling paradigm. We conclude by giving an overview of\ncomputational technologies that have proven useful for these hybrid models, and\nwith a brief discussion on future research directions.",
    "descriptor": "\nComments: 27 pages, 1 figure\n",
    "authors": [
      "Christopher K. Wikle",
      "Andrew Zammit-Mangion"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2206.02218"
  },
  {
    "id": "arXiv:2206.02222",
    "title": "How does a Rational Agent Act in an Epidemic?",
    "abstract": "Evolution of disease in a large population is a function of the top-down\npolicy measures from a centralized planner, as well as the self-interested\ndecisions (to be socially active) of individual agents in a large heterogeneous\npopulation. This paper is concerned with understanding the latter based on a\nmean-field type optimal control model. Specifically, the model is used to\ninvestigate the role of partial information on an agent's decision-making, and\nstudy the impact of such decisions by a large number of agents on the spread of\nthe virus in the population. The motivation comes from the presymptomatic and\nasymptomatic spread of the COVID-19 virus where an agent unwittingly spreads\nthe virus. We show that even in a setting with fully rational agents, limited\ninformation on the viral state can result in an epidemic growth.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2111.10422\n",
    "authors": [
      "S. Yagiz Olmez",
      "Shubham Aggarwal",
      "Jin Won Kim",
      "Erik Miehling",
      "Tamer Ba\u015far",
      "Matthew West",
      "Prashant G. Mehta"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.02222"
  },
  {
    "id": "arXiv:2206.02225",
    "title": "Physically Inspired Constraint for Unsupervised Regularized Ultrasound  Elastography",
    "abstract": "Displacement estimation is a critical step of virtually all Ultrasound\nElastography (USE) techniques. Two main features make this task unique compared\nto the general optical flow problem: the high-frequency nature of ultrasound\nradio-frequency (RF) data and the governing laws of physics on the displacement\nfield. Recently, the architecture of the optical flow networks has been\nmodified to be able to use RF data. Also, semi-supervised and unsupervised\ntechniques have been employed for USE by considering prior knowledge of\ndisplacement continuity in the form of the first- and second-derivative\nregularizers. Despite these attempts, no work has considered the tissue\ncompression pattern, and displacements in axial and lateral directions have\nbeen assumed to be independent. However, tissue motion pattern is governed by\nlaws of physics in USE, rendering the axial and the lateral displacements\nhighly correlated. In this paper, we propose Physically Inspired ConsTraint for\nUnsupervised Regularized Elastography (PICTURE), where we impose constraints on\nthe Poisson's ratio to improve lateral displacement estimates. Experiments on\nphantom and in vivo data show that PICTURE substantially improves the quality\nof the lateral displacement estimation.",
    "descriptor": "\nComments: Accepted in MICCAI 2022\n",
    "authors": [
      "Ali K. Z. Tehrani",
      "Hassan Rivaz"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02225"
  },
  {
    "id": "arXiv:2206.02249",
    "title": "Rapid Learning of Spatial Representations for Goal-Directed Navigation  Based on a Novel Model of Hippocampal Place Fields",
    "abstract": "The discovery of place cells and other spatially modulated neurons in the\nhippocampal complex of rodents has been crucial to elucidating the neural basis\nof spatial cognition. More recently, the replay of neural sequences encoding\npreviously experienced trajectories has been observed during consummatory\nbehavior potentially with implications for quick memory consolidation and\nbehavioral planning. Several promising models for robotic navigation and\nreinforcement learning have been proposed based on these and previous findings.\nMost of these models, however, use carefully engineered neural networks and are\ntested in simple environments. In this paper, we develop a self-organized model\nincorporating place cells and replay, and demonstrate its utility for rapid\none-shot learning in non-trivial environments with obstacles.",
    "descriptor": "",
    "authors": [
      "Adedapo Alabi",
      "Dieter Vanderelst",
      "Ali Minai"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.02249"
  },
  {
    "id": "arXiv:2206.02266",
    "title": "Information Threshold, Bayesian Inference and Decision-Making",
    "abstract": "We define the information threshold as the point of maximum curvature in the\nprior vs. posterior Bayesian curve, both of which are described as a function\nof the true positive and negative rates of the classification system in\nquestion. The nature of the threshold is such that for sufficiently adequate\nbinary classification systems, retrieving excess information beyond the\nthreshold does not significantly alter the reliability of our classification\nassessment. We hereby introduce the \"marital status thought experiment\" to\nillustrate this idea and report a previously undefined mathematical\nrelationship between the Bayesian prior and posterior, which may have\nsignificant philosophical and epistemological implications in decision theory.\nWhere the prior probability is a scalar between 0 and 1 given by $\\phi$ and the\nposterior is a scalar between 0 and 1 given by $\\rho$, then at the information\nthreshold, $\\phi_e$:\n$\\phi_e + \\rho_e = 1$\nOtherwise stated, given some degree of prior belief, we may assert its\npersuasiveness when sufficient quality evidence yields a posterior so that\ntheir combined sum equals 1. Retrieving further evidence beyond this point does\nnot significantly improve the posterior probability, and may serve as a\nbenchmark for confidence in decision-making.",
    "descriptor": "",
    "authors": [
      "Jacques Balayla"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02266"
  },
  {
    "id": "arXiv:2206.02272",
    "title": "Quantized and Distributed Subgradient Optimization Method with Malicious  Attack",
    "abstract": "This paper considers a distributed optimization problem in a multi-agent\nsystem where a fraction of the agents act in an adversarial manner.\nSpecifically, the malicious agents steer the network of agents away from the\noptimal solution by sending false information to their neighbors and consume\nsignificant bandwidth in the communication process. We propose a distributed\ngradient-based optimization algorithm in which the non-malicious agents\nexchange quantized information with one another. We prove convergence of the\nsolution to a neighborhood of the optimal solution, and characterize the\nsolutions obtained under the communication-constrained environment and presence\nof malicious agents. Numerical simulations to illustrate the results are also\npresented.",
    "descriptor": "",
    "authors": [
      "Iyanuoluwa Emiola",
      "Chinwendu Enyioha"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.02272"
  },
  {
    "id": "arXiv:2206.02278",
    "title": "Autoregressive Model for Multi-Pass SAR Change Detection Based on Image  Stacks",
    "abstract": "Change detection is an important synthetic aperture radar (SAR) application,\nusually used to detect changes on the ground scene measurements in different\nmoments in time. Traditionally, change detection algorithm (CDA) is mainly\ndesigned for two synthetic aperture radar (SAR) images retrieved at different\ninstants. However, more images can be used to improve the algorithms\nperformance, witch emerges as a research topic on SAR change detection. Image\nstack information can be treated as a data series over time and can be modeled\nby autoregressive (AR) models. Thus, we present some initial findings on SAR\nchange detection based on image stack considering AR models. Applying AR model\nfor each pixel position in the image stack, we obtained an estimated image of\nthe ground scene which can be used as a reference image for CDA. The\nexperimental results reveal that ground scene estimates by the AR models is\naccurate and can be used for change detection applications.",
    "descriptor": "\nComments: 9 pages, 10 figures\n",
    "authors": [
      "B. G. Palm",
      "D. I. Alves",
      "V. T. Vu",
      "M. I. Pettersson",
      "F. M. Bayer",
      "R. J. Cintra",
      "R. Machado",
      "P. Dammert",
      "H. Hellsten"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2206.02278"
  },
  {
    "id": "arXiv:2206.02290",
    "title": "A knowledge graph representation learning approach to predict novel  kinase-substrate interactions",
    "abstract": "The human proteome contains a vast network of interacting kinases and\nsubstrates. Even though some kinases have proven to be immensely useful as\ntherapeutic targets, a majority are still understudied. In this work, we\npresent a novel knowledge graph representation learning approach to predict\nnovel interaction partners for understudied kinases. Our approach uses a\nphosphoproteomic knowledge graph constructed by integrating data from iPTMnet,\nProtein Ontology, Gene Ontology and BioKG. The representation of kinases and\nsubstrates in this knowledge graph are learned by performing directed random\nwalks on triples coupled with a modified SkipGram or CBOW model. These\nrepresentations are then used as an input to a supervised classification model\nto predict novel interactions for understudied kinases. We also present a\npost-predictive analysis of the predicted interactions and an ablation study of\nthe phosphoproteomic knowledge graph to gain an insight into the biology of the\nunderstudied kinases.",
    "descriptor": "",
    "authors": [
      "Sachin Gavali",
      "Karen Ross",
      "Chuming Chen",
      "Julie Cowart",
      "Cathy H. Wu"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)",
      "Molecular Networks (q-bio.MN)"
    ],
    "url": "https://arxiv.org/abs/2206.02290"
  },
  {
    "id": "arXiv:2206.02340",
    "title": "Minimizing the Expected Posterior Entropy Yields Optimal Summary  Statistics",
    "abstract": "Extracting low-dimensional summary statistics from large datasets is\nessential for efficient (likelihood-free) inference. We propose obtaining\nsummary statistics by minimizing the expected posterior entropy (EPE) under the\nprior predictive distribution of the model. We show that minimizing the EPE is\nequivalent to learning a conditional density estimator for the posterior as\nwell as other information-theoretic approaches. Further summary extraction\nmethods (including minimizing the $L^2$ Bayes risk, maximizing the Fisher\ninformation, and model selection approaches) are special or limiting cases of\nEPE minimization. We demonstrate that the approach yields high fidelity summary\nstatistics by applying it to both a synthetic benchmark as well as a population\ngenetics problem. We not only offer concrete recommendations for practitioners\nbut also provide a unifying perspective for obtaining informative summary\nstatistics.",
    "descriptor": "\nComments: 26 pages, 5 figures, 1 table\n",
    "authors": [
      "Till Hoffmann",
      "Jukka-Pekka Onnela"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.02340"
  },
  {
    "id": "arXiv:2206.02346",
    "title": "Convergence and sample complexity of natural policy gradient primal-dual  methods for constrained MDPs",
    "abstract": "We study sequential decision making problems aimed at maximizing the expected\ntotal reward while satisfying a constraint on the expected total utility. We\nemploy the natural policy gradient method to solve the discounted\ninfinite-horizon optimal control problem for Constrained Markov Decision\nProcesses (constrained MDPs). Specifically, we propose a new Natural Policy\nGradient Primal-Dual (NPG-PD) method that updates the primal variable via\nnatural policy gradient ascent and the dual variable via projected sub-gradient\ndescent. Although the underlying maximization involves a nonconcave objective\nfunction and a nonconvex constraint set, under the softmax policy\nparametrization we prove that our method achieves global convergence with\nsublinear rates regarding both the optimality gap and the constraint violation.\nSuch convergence is independent of the size of the state-action space, i.e., it\nis~dimension-free. Furthermore, for log-linear and general smooth policy\nparametrizations, we establish sublinear convergence rates up to a function\napproximation error caused by restricted policy parametrization. We also\nprovide convergence and finite-sample complexity guarantees for two\nsample-based NPG-PD algorithms. Finally, we use computational experiments to\nshowcase the merits and the effectiveness of our approach.",
    "descriptor": "\nComments: 63 pages, 4 figures\n",
    "authors": [
      "Dongsheng Ding",
      "Kaiqing Zhang",
      "Jiali Duan",
      "Tamer Ba\u015far",
      "Mihailo R. Jovanovi\u0107"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.02346"
  },
  {
    "id": "arXiv:2206.02348",
    "title": "Finite-Sample Maximum Likelihood Estimation of Location",
    "abstract": "We consider 1-dimensional location estimation, where we estimate a parameter\n$\\lambda$ from $n$ samples $\\lambda + \\eta_i$, with each $\\eta_i$ drawn i.i.d.\nfrom a known distribution $f$. For fixed $f$ the maximum-likelihood estimate\n(MLE) is well-known to be optimal in the limit as $n \\to \\infty$: it is\nasymptotically normal with variance matching the Cram\\'er-Rao lower bound of\n$\\frac{1}{n\\mathcal{I}}$, where $\\mathcal{I}$ is the Fisher information of $f$.\nHowever, this bound does not hold for finite $n$, or when $f$ varies with $n$.\nWe show for arbitrary $f$ and $n$ that one can recover a similar theory based\non the Fisher information of a smoothed version of $f$, where the smoothing\nradius decays with $n$.",
    "descriptor": "\nComments: In submission\n",
    "authors": [
      "Shivam Gupta",
      "Jasper C.H. Lee",
      "Eric Price",
      "Paul Valiant"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Data Structures and Algorithms (cs.DS)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.02348"
  },
  {
    "id": "arXiv:2206.02358",
    "title": "Implementation of a Modified U-Net for Medical Image Segmentation on  Edge Devices",
    "abstract": "Deep learning techniques, particularly convolutional neural networks, have\nshown great potential in computer vision and medical imaging applications.\nHowever, deep learning models are computationally demanding as they require\nenormous computational power and specialized processing hardware for model\ntraining. To make these models portable and compatible for prototyping, their\nimplementation on low-power devices is imperative. In this work, we present the\nimplementation of Modified U-Net on Intel Movidius Neural Compute Stick 2\n(NCS-2) for the segmentation of medical images. We selected U-Net because, in\nmedical image segmentation, U-Net is a prominent model that provides improved\nperformance for medical image segmentation even if the dataset size is small.\nThe modified U-Net model is evaluated for performance in terms of dice score.\nExperiments are reported for segmentation task on three medical imaging\ndatasets: BraTs dataset of brain MRI, heart MRI dataset, and Ziehl-Neelsen\nsputum smear microscopy image (ZNSDB) dataset. For the proposed model, we\nreduced the number of parameters from 30 million in the U-Net model to 0.49\nmillion in the proposed architecture. Experimental results show that the\nmodified U-Net provides comparable performance while requiring significantly\nlower resources and provides inference on the NCS-2. The maximum dice scores\nrecorded are 0.96 for the BraTs dataset, 0.94 for the heart MRI dataset, and\n0.74 for the ZNSDB dataset.",
    "descriptor": "\nComments: Preprint of paper accepted in IEEE Transactions on Circuits and Systems II: Express Brief\n",
    "authors": [
      "Owais Ali",
      "Hazrat Ali",
      "Syed Ayaz Ali Shah",
      "Aamir Shahzad"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.02358"
  },
  {
    "id": "arXiv:2206.02395",
    "title": "Product structure of graph classes with bounded treewidth",
    "abstract": "We show that many graphs with bounded treewidth can be described as subgraphs\nof the strong product of a graph with smaller treewidth and a bounded-size\ncomplete graph. To this end, define the \"underlying treewidth\" of a graph class\n$\\mathcal{G}$ to be the minimum non-negative integer $c$ such that, for some\nfunction $f$, for every graph ${G \\in \\mathcal{G}}$ there is a graph $H$ with\n${\\text{tw}(H) \\leq c}$ such that $G$ is isomorphic to a subgraph of ${H\n\\boxtimes K_{f(\\text{tw}(G))}}$. We introduce disjointed coverings of graphs\nand show they determine the underlying treewidth of any graph class. Using this\nresult, we prove that the class of planar graphs has underlying treewidth 3;\nthe class of $K_{s,t}$-minor-free graphs has underlying treewidth $s$ (for ${t\n\\geq \\max\\{s,3\\}}$); and the class of $K_t$-minor-free graphs has underlying\ntreewidth ${t-2}$. In general, we prove that a monotone class has bounded\nunderlying treewidth if and only if it excludes some fixed topological minor.\nWe also study the underlying treewidth of graph classes defined by an excluded\nsubgraph or excluded induced subgraph. We show that the class of graphs with no\n$H$ subgraph has bounded underlying treewidth if and only if every component of\n$H$ is a subdivided star, and that the class of graphs with no induced $H$\nsubgraph has bounded underlying treewidth if and only if every component of $H$\nis a star.",
    "descriptor": "",
    "authors": [
      "Rutger Campbell",
      "Katie Clinch",
      "Marc Distel",
      "J. Pascal Gollin",
      "Kevin Hendrey",
      "Robert Hickingbotham",
      "Tony Huynh",
      "Freddie Illingworth",
      "Youri Tamitegama",
      "Jane Tan",
      "David R. Wood"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2206.02395"
  },
  {
    "id": "arXiv:2206.02398",
    "title": "Interference Management for Over-the-Air Federated Learning in  Multi-Cell Wireless Networks",
    "abstract": "Federated learning (FL) over resource-constrained wireless networks has\nrecently attracted much attention. However, most existing studies consider one\nFL task in single-cell wireless networks and ignore the impact of\ndownlink/uplink inter-cell interference on the learning performance. In this\npaper, we investigate FL over a multi-cell wireless network, where each cell\nperforms a different FL task and over-the-air computation (AirComp) is adopted\nto enable fast uplink gradient aggregation. We conduct convergence analysis of\nAirComp-assisted FL systems, taking into account the inter-cell interference in\nboth the downlink and uplink model/gradient transmissions, which reveals that\nthe distorted model/gradient exchanges induce a gap to hinder the convergence\nof FL. We characterize the Pareto boundary of the error-induced gap region to\nquantify the learning performance trade-off among different FL tasks, based on\nwhich we formulate an optimization problem to minimize the sum of error-induced\ngaps in all cells. To tackle the coupling between the downlink and uplink\ntransmissions as well as the coupling among multiple cells, we propose a\ncooperative multi-cell FL optimization framework to achieve efficient\ninterference management for downlink and uplink transmission design. Results\ndemonstrate that our proposed algorithm achieves much better average learning\nperformance over multiple cells than non-cooperative baseline schemes.",
    "descriptor": "\nComments: This work has been accepted by IEEE Journal on Selected Areas in Communications\n",
    "authors": [
      "Zhibin Wang",
      "Yong Zhou",
      "Yuanming Shi",
      "Weihua Zhuang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02398"
  },
  {
    "id": "arXiv:2206.02416",
    "title": "Embrace the Gap: VAEs Perform Independent Mechanism Analysis",
    "abstract": "Variational autoencoders (VAEs) are a popular framework for modeling complex\ndata distributions; they can be efficiently trained via variational inference\nby maximizing the evidence lower bound (ELBO), at the expense of a gap to the\nexact (log-)marginal likelihood. While VAEs are commonly used for\nrepresentation learning, it is unclear why ELBO maximization would yield useful\nrepresentations, since unregularized maximum likelihood estimation cannot\ninvert the data-generating process. Yet, VAEs often succeed at this task. We\nseek to elucidate this apparent paradox by studying nonlinear VAEs in the limit\nof near-deterministic decoders. We first prove that, in this regime, the\noptimal encoder approximately inverts the decoder -- a commonly used but\nunproven conjecture -- which we refer to as {\\em self-consistency}. Leveraging\nself-consistency, we show that the ELBO converges to a regularized\nlog-likelihood. This allows VAEs to perform what has recently been termed\nindependent mechanism analysis (IMA): it adds an inductive bias towards\ndecoders with column-orthogonal Jacobians, which helps recovering the true\nlatent factors. The gap between ELBO and log-likelihood is therefore welcome,\nsince it bears unanticipated benefits for nonlinear representation learning. In\nexperiments on synthetic and image data, we show that VAEs uncover the true\nlatent factors when the data generating process satisfies the IMA assumption.",
    "descriptor": "\nComments: 41 pages, under review\n",
    "authors": [
      "Patrik Reizinger",
      "Luigi Gresele",
      "Jack Brady",
      "Julius von K\u00fcgelgen",
      "Dominik Zietlow",
      "Bernhard Sch\u00f6lkopf",
      "Georg Martius",
      "Wieland Brendel",
      "Michel Besserve"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02416"
  },
  {
    "id": "arXiv:2206.02425",
    "title": "mmFormer: Multimodal Medical Transformer for Incomplete Multimodal  Learning of Brain Tumor Segmentation",
    "abstract": "Accurate brain tumor segmentation from Magnetic Resonance Imaging (MRI) is\ndesirable to joint learning of multimodal images. However, in clinical\npractice, it is not always possible to acquire a complete set of MRIs, and the\nproblem of missing modalities causes severe performance degradation in existing\nmultimodal segmentation methods. In this work, we present the first attempt to\nexploit the Transformer for multimodal brain tumor segmentation that is robust\nto any combinatorial subset of available modalities. Concretely, we propose a\nnovel multimodal Medical Transformer (mmFormer) for incomplete multimodal\nlearning with three main components: the hybrid modality-specific encoders that\nbridge a convolutional encoder and an intra-modal Transformer for both local\nand global context modeling within each modality; an inter-modal Transformer to\nbuild and align the long-range correlations across modalities for\nmodality-invariant features with global semantics corresponding to tumor\nregion; a decoder that performs a progressive up-sampling and fusion with the\nmodality-invariant features to generate robust segmentation. Besides, auxiliary\nregularizers are introduced in both encoder and decoder to further enhance the\nmodel's robustness to incomplete modalities. We conduct extensive experiments\non the public BraTS $2018$ dataset for brain tumor segmentation. The results\ndemonstrate that the proposed mmFormer outperforms the state-of-the-art methods\nfor incomplete multimodal brain tumor segmentation on almost all subsets of\nincomplete modalities, especially by an average 19.07% improvement of Dice on\ntumor segmentation with only one available modality. The code is available at\nhttps://github.com/YaoZhang93/mmFormer.",
    "descriptor": "\nComments: Accepted to MICCAI 2022\n",
    "authors": [
      "Yao Zhang",
      "Nanjun He",
      "Jiawei Yang",
      "Yuexiang Li",
      "Dong Wei",
      "Yawen Huang",
      "Yang Zhang",
      "Zhiqiang He",
      "Yefeng Zheng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02425"
  },
  {
    "id": "arXiv:2206.02432",
    "title": "Online Neural Diarization of Unlimited Numbers of Speakers",
    "abstract": "A method to perform offline and online speaker diarization for an unlimited\nnumber of speakers is described in this paper. End-to-end neural diarization\n(EEND) has achieved overlap-aware speaker diarization by formulating it as a\nmulti-label classification problem. It has also been extended for a flexible\nnumber of speakers by introducing speaker-wise attractors. However, the output\nnumber of speakers of attractor-based EEND is empirically capped; it cannot\ndeal with cases where the number of speakers appearing during inference is\nhigher than that during training because its speaker counting is trained in a\nfully supervised manner. Our method, EEND-GLA, solves this problem by\nintroducing unsupervised clustering into attractor-based EEND. In the method,\nthe input audio is first divided into short blocks, then attractor-based\ndiarization is performed for each block, and finally the results of each blocks\nare clustered on the basis of the similarity between locally-calculated\nattractors. While the number of output speakers is limited within each block,\nthe total number of speakers estimated for the entire input can be higher than\nthe limitation. To use EEND-GLA in an online manner, our method also extends\nthe speaker-tracing buffer, which was originally proposed to enable online\ninference of conventional EEND. We introduces a block-wise buffer update to\nmake the speaker-tracing buffer compatible with EEND-GLA. Finally, to improve\nonline diarization, our method improves the buffer update method and revisits\nthe variable chunk-size training of EEND. The experimental results demonstrate\nthat EEND-GLA can perform speaker diarization of an unseen number of speakers\nin both offline and online inferences.",
    "descriptor": "",
    "authors": [
      "Shota Horiguchi",
      "Shinji Watanabe",
      "Paola Garcia",
      "Yuki Takashima",
      "Yohei Kawaguchi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2206.02432"
  },
  {
    "id": "arXiv:2206.02435",
    "title": "Tackling covariate shift with node-based Bayesian neural networks",
    "abstract": "Bayesian neural networks (BNNs) promise improved generalization under\ncovariate shift by providing principled probabilistic representations of\nepistemic uncertainty. However, weight-based BNNs often struggle with high\ncomputational complexity of large-scale architectures and datasets. Node-based\nBNNs have recently been introduced as scalable alternatives, which induce\nepistemic uncertainty by multiplying each hidden node with latent random\nvariables, while learning a point-estimate of the weights. In this paper, we\ninterpret these latent noise variables as implicit representations of simple\nand domain-agnostic data perturbations during training, producing BNNs that\nperform well under covariate shift due to input corruptions. We observe that\nthe diversity of the implicit corruptions depends on the entropy of the latent\nvariables, and propose a straightforward approach to increase the entropy of\nthese variables during training. We evaluate the method on out-of-distribution\nimage classification benchmarks, and show improved uncertainty estimation of\nnode-based BNNs under covariate shift due to input perturbations. As a side\neffect, the method also provides robustness against noisy training labels.",
    "descriptor": "\nComments: Published at ICML 2022. Code is available at this https URL\n",
    "authors": [
      "Trung Trinh",
      "Markus Heinonen",
      "Luigi Acerbi",
      "Samuel Kaski"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02435"
  },
  {
    "id": "arXiv:2206.02449",
    "title": "Class Prior Estimation under Covariate Shift -- no Problem?",
    "abstract": "We show that in the context of classification the property of source and\ntarget distributions to be related by covariate shift may break down when the\ninformation content captured in the covariates is reduced, for instance by\ndiscretization of the covariates, dropping some of them, or by any\ntransformation of the covariates even if it is domain-invariant. The\nconsequences of this observation for class prior estimation under covariate\nshift are discussed. A probing algorithm as alternative approach to class prior\nestimation under covariate shift is proposed.",
    "descriptor": "\nComments: 16 pages, 2 figures\n",
    "authors": [
      "Dirk Tasche"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2206.02449"
  },
  {
    "id": "arXiv:2206.02455",
    "title": "Mean Estimation in High-Dimensional Binary Markov Gaussian Mixture  Models",
    "abstract": "We consider a high-dimensional mean estimation problem over a binary hidden\nMarkov model, which illuminates the interplay between memory in data, sample\nsize, dimension, and signal strength in statistical inference. In this model,\nan estimator observes $n$ samples of a $d$-dimensional parameter vector\n$\\theta_{*}\\in\\mathbb{R}^{d}$, multiplied by a random sign $ S_i $ ($1\\le i\\le\nn$), and corrupted by isotropic standard Gaussian noise. The sequence of signs\n$\\{S_{i}\\}_{i\\in[n]}\\in\\{-1,1\\}^{n}$ is drawn from a stationary homogeneous\nMarkov chain with flip probability $\\delta\\in[0,1/2]$. As $\\delta$ varies, this\nmodel smoothly interpolates two well-studied models: the Gaussian Location\nModel for which $\\delta=0$ and the Gaussian Mixture Model for which\n$\\delta=1/2$. Assuming that the estimator knows $\\delta$, we establish a nearly\nminimax optimal (up to logarithmic factors) estimation error rate, as a\nfunction of $\\|\\theta_{*}\\|,\\delta,d,n$. We then provide an upper bound to the\ncase of estimating $\\delta$, assuming a (possibly inaccurate) knowledge of\n$\\theta_{*}$. The bound is proved to be tight when $\\theta_{*}$ is an\naccurately known constant. These results are then combined to an algorithm\nwhich estimates $\\theta_{*}$ with $\\delta$ unknown a priori, and theoretical\nguarantees on its error are stated.",
    "descriptor": "",
    "authors": [
      "Yihan Zhang",
      "Nir Weinberger"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02455"
  },
  {
    "id": "arXiv:2206.02477",
    "title": "Optimal Stopping Theory for a Distributionally Robust Seller",
    "abstract": "Sellers in online markets face the challenge of determining the right time to\nsell in view of uncertain future offers. Classical stopping theory assumes that\nsellers have full knowledge of the value distributions, and leverage this\nknowledge to determine stopping rules that maximize expected welfare. In\npractice, however, stopping rules must often be determined under partial\ninformation, based on scarce data or expert predictions. Consider a seller that\nhas one item for sale and receives successive offers drawn from some value\ndistributions. The decision on whether or not to accept an offer is\nirrevocable, and the value distributions are only partially known. We therefore\nlet the seller adopt a robust maximin strategy, assuming that value\ndistributions are chosen adversarially by nature to minimize the value of the\naccepted offer. We provide a general maximin solution to this stopping problem\nthat identifies the optimal (threshold-based) stopping rule for the seller for\nall statistical information structures. We then perform a detailed analysis for\nwhen the seller knows the common mean, dispersion (variance or mean absolute\ndeviation) and support of the distributions. We show for this information\nstructure that the seller's stopping rule consists of decreasing thresholds\nconverging to the common mean, and that nature's adversarial response, in the\nlong run, is to always create an all-or-nothing scenario. The maximin solutions\nalso reveal what happens as dispersion or the number of offers grows large.",
    "descriptor": "",
    "authors": [
      "Pieter Kleer",
      "Johan van Leeuwaarden"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.02477"
  },
  {
    "id": "arXiv:2206.02510",
    "title": "Single pixel imaging at high pixel resolutions",
    "abstract": "The usually reported pixel resolution of single pixel imaging (SPI) varies\nbetween $32 \\times 32$ and $256 \\times 256$ pixels falling far below imaging\nstandards with classical methods. Low resolution results from the trade-off\nbetween the acceptable compression ratio, the limited DMD modulation frequency,\nand reasonable reconstruction time, and has not improved significantly during\nthe decade of intensive research on SPI. In this paper we show that image\nmeasurement at the full resolution of the DMD, which lasts only a fraction of a\nsecond, is possible for sparse images or in a situation when the field of view\nis limited but is a priori unknown. We propose the sampling and reconstruction\nstrategies that enable us to reconstruct sparse images at the resolution of\n$1024 \\times 768$ within the time of $0.3~$s. Non-sparse images are\nreconstructed with less details. The compression ratio is on the order of $0.4\n\\%$ which corresponds to an acquisition frequency of $7~$Hz. Sampling is\ndifferential, binary, and non-adaptive, and includes information on multiple\npartitioning of the image which later allows us to determine the actual field\nof view. Reconstruction is based on the differential Fourier domain regularized\ninversion (D-FDRI). The proposed SPI framework is an alternative to both\nadaptive SPI, which is challenging to implement in real time, and to classical\ncompressive sensing image recovery methods, which are very slow at high\nresolutions.",
    "descriptor": "\nComments: Paper accepted to Optics Express on 23/05/2022\n",
    "authors": [
      "Rafa\u0142 Stojek",
      "Anna Pastuszczak",
      "Piotr Wr\u00f3bel",
      "Rafa\u0142 Koty\u0144ski"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.02510"
  },
  {
    "id": "arXiv:2206.02512",
    "title": "UTTS: Unsupervised TTS with Conditional Disentangled Sequential  Variational Auto-encoder",
    "abstract": "In this paper, we propose a novel unsupervised text-to-speech (UTTS)\nframework which does not require text-audio pairs for the TTS acoustic modeling\n(AM). UTTS is a multi-speaker speech synthesizer developed from the perspective\nof disentangled speech representation learning. The framework offers a flexible\nchoice of a speaker's duration model, timbre feature (identity) and content for\nTTS inference. We leverage recent advancements in self-supervised speech\nrepresentation learning as well as speech synthesis front-end techniques for\nthe system development. Specifically, we utilize a lexicon to map input text to\nthe phoneme sequence, which is expanded to the frame-level forced alignment\n(FA) with a speaker-dependent duration model. Then, we develop an alignment\nmapping module that converts the FA to the unsupervised alignment (UA).\nFinally, a Conditional Disentangled Sequential Variational Auto-encoder\n(C-DSVAE), serving as the self-supervised TTS AM, takes the predicted UA and a\ntarget speaker embedding to generate the mel spectrogram, which is ultimately\nconverted to waveform with a neural vocoder. We show how our method enables\nspeech synthesis without using a paired TTS corpus. Experiments demonstrate\nthat UTTS can synthesize speech of high naturalness and intelligibility\nmeasured by human and objective evaluations.",
    "descriptor": "",
    "authors": [
      "Jiachen Lian",
      "Chunlei Zhang",
      "Gopala Krishna Anumanchipalli",
      "Dong Yu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2206.02512"
  },
  {
    "id": "arXiv:2206.02519",
    "title": "Programming molecular systems to emulate a learning spiking neuron",
    "abstract": "Hebbian theory seeks to explain how the neurons in the brain adapt to\nstimuli, to enable learning. An interesting feature of Hebbian learning is that\nit is an unsupervised method and as such, does not require feedback, making it\nsuitable in contexts where systems have to learn autonomously. This paper\nexplores how molecular systems can be designed to show such proto-intelligent\nbehaviours, and proposes the first chemical reaction network (CRN) that can\nexhibit autonomous Hebbian learning across arbitrarily many input channels. The\nsystem emulates a spiking neuron, and we demonstrate that it can learn\nstatistical biases of incoming inputs. The basic CRN is a minimal,\nthermodynamically plausible set of micro-reversible chemical equations that can\nbe analysed with respect to their energy requirements. However, to explore how\nsuch chemical systems might be engineered de novo, we also propose an extended\nversion based on enzyme-driven compartmentalised reactions. Finally, we also\nshow how a purely DNA system, built upon the paradigm of DNA strand\ndisplacement, can realise neuronal dynamics. Our analysis provides a compelling\nblueprint for exploring autonomous learning in biological settings, bringing us\ncloser to realising real synthetic biological intelligence.",
    "descriptor": "\nComments: Submitted to ACS Synthetic Biology. arXiv admin note: substantial text overlap with arXiv:2009.13207\n",
    "authors": [
      "Jakub Fil",
      "Neil Dalchau",
      "Dominique Chu"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.02519"
  },
  {
    "id": "arXiv:2206.02523",
    "title": "Sparse Bayesian Learning for Complex-Valued Rational Approximations",
    "abstract": "Surrogate models are used to alleviate the computational burden in\nengineering tasks, which require the repeated evaluation of computationally\ndemanding models of physical systems, such as the efficient propagation of\nuncertainties. For models that show a strongly non-linear dependence on their\ninput parameters, standard surrogate techniques, such as polynomial chaos\nexpansion, are not sufficient to obtain an accurate representation of the\noriginal model response. Through applying a rational approximation instead, the\napproximation error can be efficiently reduced for models whose non-linearity\nis accurately described through a rational function. Specifically, our aim is\nto approximate complex-valued models. A common approach to obtain the\ncoefficients in the surrogate is to minimize the sample-based error between\nmodel and surrogate in the least-square sense. In order to obtain an accurate\nrepresentation of the original model and to avoid overfitting, the sample set\nhas be two to three times the number of polynomial terms in the expansion. For\nmodels that require a high polynomial degree or are high-dimensional in terms\nof their input parameters, this number often exceeds the affordable\ncomputational cost. To overcome this issue, we apply a sparse Bayesian learning\napproach to the rational approximation. Through a specific prior distribution\nstructure, sparsity is induced in the coefficients of the surrogate model. The\ndenominator polynomial coefficients as well as the hyperparameters of the\nproblem are determined through a type-II-maximum likelihood approach. We apply\na quasi-Newton gradient-descent algorithm in order to find the optimal\ndenominator coefficients and derive the required gradients through application\nof $\\mathbb{CR}$-calculus.",
    "descriptor": "\nComments: 27 pages, 13 figures, submitted to Journal of Computational Physics\n",
    "authors": [
      "Felix Schneider",
      "Iason Papaioannou",
      "Gerhard M\u00fcller"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02523"
  },
  {
    "id": "arXiv:2206.02530",
    "title": "Persistent Homology of Coarse Grained State Space Networks",
    "abstract": "This work is dedicated to the topological analysis of complex transitional\nnetworks for dynamic state detection. Transitional networks are formed from\ntime series data and they leverage graph theory tools to reveal information\nabout the underlying dynamic system. However, traditional tools can fail to\nsummarize the complex topology present in such graphs. In this work, we\nleverage persistent homology from topological data analysis to study the\nstructure of these networks. We contrast dynamic state detection from time\nseries using CGSSN and TDA to two state of the art approaches: Ordinal\nPartition Networks (OPNs) combined with TDA, and the standard application of\npersistent homology to the time-delay embedding of the signal. We show that the\nCGSSN captures rich information about the dynamic state of the underlying\ndynamical system as evidenced by a significant improvement in dynamic state\ndetection and noise robustness in comparison to OPNs. We also show that because\nthe computational time of CGSSN is not linearly dependent on the signal's\nlength, it is more computationally efficient than applying TDA to the\ntime-delay embedding of the time series.",
    "descriptor": "",
    "authors": [
      "Audun D. Myers",
      "Firas A. Khasawneh",
      "Elizabeth Munch"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Algebraic Topology (math.AT)"
    ],
    "url": "https://arxiv.org/abs/2206.02530"
  },
  {
    "id": "arXiv:2206.02534",
    "title": "Scan4CFU: Low-cost, open-source bacterial colony tracking over large  areas and extended incubation times",
    "abstract": "A hallmark of bacterial populations cultured in vitro is their homogeneity of\ngrowth, where the majority of cells display identical growth rate, cell size\nand content. Recent insights, however, have revealed that even cells growing in\nexponential growth phase can be heterogeneous with respect to variables\ntypically used to measure cell growth. Bacterial heterogeneity has important\nimplications for how bacteria respond to environmental stresses, such as\nantibiotics. The phenomenon of antimicrobial persistence, for example, has been\nlinked to a small subpopulation of cells that have entered into a state of\ndormancy where antibiotics are no longer effective. While methods have been\ndeveloped for identifying individual non-growing cells in bacterial cultures,\nthere has been less attention paid to how these cells may influence growth in\ncolonies on a solid surface. In response, we have developed a low-cost,\nopen-source platform to perform automated image capture and image analysis of\nbacterial colony growth on multiple nutrient agar plates simultaneously. The\ndescriptions of the hardware and software are included, along with details\nabout the temperature-controlled growth chamber, high-resolution scanner, and\ngraphical interface to extract and plot the colony lag time and growth\nkinetics. Experiments were conducted using a wild type strain of Escherichia\ncoli K12 to demonstrate the feasibility and operation of our setup. By\nautomated tracking of bacterial growth kinetics in colonies, the system holds\nthe potential to reveal new insights into understanding the impact of microbial\nheterogeneity on antibiotic resistance and persistence.",
    "descriptor": "",
    "authors": [
      "Santosh Pandey",
      "Yunsoo Park",
      "Ankita Ankita",
      "Gregory J.Phillips"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Image and Video Processing (eess.IV)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.02534"
  },
  {
    "id": "arXiv:2206.02536",
    "title": "Interpretable travel distance on the county-wise COVID-19 by sequence to  sequence with attention",
    "abstract": "Background: Travel restrictions as a means of intervention in the COVID-19\nepidemic have reduced the spread of outbreaks using epidemiological models. We\nintroduce the attention module in the sequencing model to assess the effects of\nthe different classes of travel distances.\nObjective: To establish a direct relationship between the number of travelers\nfor various travel distances and the COVID-19 trajectories. To improve the\nprediction performance of sequencing model.\nSetting: Counties from all over the United States.\nParticipants: New confirmed cases and deaths have been reported in 3158\ncounties across the United States.\nMeasurements: Outcomes included new confirmed cases and deaths in the 30 days\npreceding November 13, 2021. The daily number of trips taken by the population\nfor various classes of travel distances and the geographical information of\ninfected counties are assessed.\nResults: There is a spatial pattern of various classes of travel distances\nacross the country. The varying geographical effects of the number of people\ntravelling for different distances on the epidemic spread are demonstrated.\nLimitation: We examined data up to November 13, 2021, and the weights of each\nclass of travel distances may change accordingly as the data evolves.\nConclusion: Given the weights of people taking trips for various classes of\ntravel distances, the epidemics could be mitigated by reducing the\ncorresponding class of travellers.",
    "descriptor": "\nComments: 25 pages, 7 figures\n",
    "authors": [
      "Ting Tian",
      "Yukang Jiang",
      "Huajun Xie",
      "Xueqin Wang",
      "Hailiang Guo"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Artificial Intelligence (cs.AI)",
      "Populations and Evolution (q-bio.PE)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2206.02536"
  },
  {
    "id": "arXiv:2206.02538",
    "title": "Agent-based model using GPS analysis for infection spread and inhibition  mechanism of SARS-CoV-2 in Tokyo",
    "abstract": "Analyzing the SARS-CoV-2 pandemic outbreak based on actual data while\nreflecting the characteristics of the real city provides beneficial information\nfor taking reasonable infection control measures in the future. We demonstrate\nagent-based modeling for Tokyo based on GPS information and official national\nstatistics and perform a spatiotemporal analysis of the infection situation in\nTokyo. As a result of the simulation during the first wave of SARS-CoV-2 in\nTokyo using real GPS data, the infection occurred in the service industry, such\nas restaurants, in the city center, and then the infected people brought back\nthe virus to the residential area; the infection spread in each area in Tokyo.\nThis phenomenon clarifies that the spread of infection can be curbed by\nsuppressing going out or strengthening infection prevention measures in service\nfacilities. It was shown that pandemic measures in Tokyo could be achieved not\nonly by strong control, such as the lockdown of cities, but also by thorough\ninfection prevention measures in service facilities, which explains the curb\nphenomena in real Tokyo.",
    "descriptor": "\nComments: 9 pages, 6 figures\n",
    "authors": [
      "Taishu Murakami",
      "Shunsuke Sakuragi",
      "Hiroshi Deguchi",
      "Masaru Nakata"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Multiagent Systems (cs.MA)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2206.02538"
  },
  {
    "id": "arXiv:2206.02549",
    "title": "Mathematical Operations and Equation Solving with Reconfigurable  Metadevices",
    "abstract": "Performing analog computations with metastructures is an emerging wave-based\nparadigm for solving mathematical problems. For such devices, one major\nchallenge is their reconfigurability, especially without the need for a priori\nmathematical computations or computationally-intensive optimization. Their\nequation-solving capabilities are applied only to matrices with special\nspectral (eigenvalue) distribution. Here we report the theory and design of\nwave-based metastructures using tunable elements capable of solving\nintegral/differential equations in a fully-reconfigurable fashion. We consider\ntwo architectures: the Miller architecture, which requires the singular-value\ndecomposition, and an alternative intuitive direct-complex-matrix (DCM)\narchitecture introduced here, which does not require a priori mathematical\ndecomposition. As examples, we demonstrate, using system-level simulation\ntools, the solutions of integral and differential equations. We then expand the\nmatrix inverting capabilities of both architectures toward evaluating the\ngeneralized Moore-Penrose matrix inversion. Therefore, we provide evidence that\nmetadevices can implement generalized matrix inversions and act as the basis\nfor the gradient descent method for solutions to a wide variety of problems.\nFinally, a general upper bound of the solution convergence time reveals the\nrich potential that such metadevices can offer for stationary iterative\nschemes.",
    "descriptor": "",
    "authors": [
      "Dimitrios Tzarouchis",
      "Mario Junior Mencagli",
      "Brian Edwards",
      "Nader Engheta"
    ],
    "subjectives": [
      "Applied Physics (physics.app-ph)",
      "Numerical Analysis (math.NA)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2206.02549"
  },
  {
    "id": "arXiv:2206.02558",
    "title": "Binding Dancers Into Attractors",
    "abstract": "To effectively perceive and process observations in our environment, feature\nbinding and perspective taking are crucial cognitive abilities. Feature binding\ncombines observed features into one entity, called a Gestalt. Perspective\ntaking transfers the percept into a canonical, observer-centered frame of\nreference. Here we propose a recurrent neural network model that solves both\nchallenges. We first train an LSTM to predict 3D motion dynamics from a\ncanonical perspective. We then present similar motion dynamics with novel\nviewpoints and feature arrangements. Retrospective inference enables the\ndeduction of the canonical perspective. Combined with a robust mutual-exclusive\nsoftmax selection scheme, random feature arrangements are reordered and\nprecisely bound into known Gestalt percepts. To corroborate evidence for the\narchitecture's cognitive validity, we examine its behavior on the silhouette\nillusion, which elicits two competitive Gestalt interpretations of a rotating\ndancer. Our system flexibly binds the information of the rotating figure into\nthe alternative attractors resolving the illusion's ambiguity and imagining the\nrespective depth interpretation and the corresponding direction of rotation. We\nfinally discuss the potential universality of the proposed mechanisms.",
    "descriptor": "",
    "authors": [
      "Franziska Kaltenberger",
      "Sebastian Otte",
      "Martin V. Butz"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02558"
  },
  {
    "id": "arXiv:2206.02563",
    "title": "Learning \"best\" kernels from data in Gaussian process regression. With  application to aerodynamics",
    "abstract": "This paper introduces algorithms to select/design kernels in Gaussian process\nregression/kriging surrogate modeling techniques. We adopt the setting of\nkernel method solutions in ad hoc functional spaces, namely Reproducing Kernel\nHilbert Spaces (RKHS), to solve the problem of approximating a regular target\nfunction given observations of it, i.e. supervised learning. A first class of\nalgorithms is kernel flow, which was introduced in a context of classification\nin machine learning. It can be seen as a nested cross-validation procedure\nwhereby a \"best\" kernel is selected such that the loss of accuracy incurred by\nremoving some part of the dataset (typically half of it) is minimized. A second\nclass of algorithms is called spectral kernel ridge regression, and aims at\nselecting a \"best\" kernel such that the norm of the function to be approximated\nis minimal in the associated RKHS. Within Mercer's theorem framework, we obtain\nan explicit construction of that \"best\" kernel in terms of the main features of\nthe target function. Both approaches of learning kernels from data are\nillustrated by numerical examples on synthetic test functions, and on a\nclassical test case in turbulence modeling validation for transonic flows about\na two-dimensional airfoil.",
    "descriptor": "",
    "authors": [
      "Jean-Luc Akian",
      "Luc Bonnet",
      "Houman Owhadi",
      "\u00c9ric Savin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02563"
  },
  {
    "id": "arXiv:2206.02568",
    "title": "A Deep Reinforcement Learning Framework For Column Generation",
    "abstract": "Column Generation (CG) is an iterative algorithm for solving linear programs\n(LPs) with an extremely large number of variables (columns). CG is the\nworkhorse for tackling large-scale integer linear programs, which rely on CG to\nsolve LP relaxations within a branch and bound algorithm. Two canonical\napplications are the Cutting Stock Problem (CSP) and Vehicle Routing Problem\nwith Time Windows (VRPTW). In VRPTW, for example, each binary variable\nrepresents the decision to include or exclude a route, of which there are\nexponentially many; CG incrementally grows the subset of columns being used,\nultimately converging to an optimal solution. We propose RLCG, the first\nReinforcement Learning (RL) approach for CG. Unlike typical column selection\nrules which myopically select a column based on local information at each\niteration, we treat CG as a sequential decision-making problem, as the column\nselected in an iteration affects subsequent iterations of the algorithm. This\nperspective lends itself to a Deep Reinforcement Learning approach that uses\nGraph Neural Networks (GNNs) to represent the variable-constraint structure in\nthe LP of interest. We perform an extensive set of experiments using the\npublicly available BPPLIB benchmark for CSP and Solomon benchmark for VRPTW.\nRLCG converges faster and reduces the number of CG iterations by 22.4% for CSP\nand 40.9% for VRPTW on average compared to a commonly used greedy policy.",
    "descriptor": "",
    "authors": [
      "Cheng Chi",
      "Amine Mohamed Aboussalah",
      "Elias B. Khalil",
      "Juyoung Wang",
      "Zoha Sherkat-Masoumi"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02568"
  },
  {
    "id": "arXiv:2206.02570",
    "title": "RODIAN: Robustified Median",
    "abstract": "We propose a robust method for averaging numbers contaminated by a large\nproportion of outliers. Our method, dubbed RODIAN, is inspired by the key idea\nof MINPRAN [1]: We assume that the outliers are uniformly distributed within\nthe range of the data and we search for the region that is least likely to\ncontain outliers only. The median of the data within this region is then taken\nas RODIAN. Our approach can accurately estimate the true mean of data with more\nthan 50% outliers and runs in time $O(n\\log n)$. Unlike other robust\ntechniques, it is completely deterministic and does not rely on a known inlier\nerror bound. Our extensive evaluation shows that RODIAN is much more robust\nthan the median and the least-median-of-squares. This result also holds in the\ncase of non-uniform outlier distributions.",
    "descriptor": "",
    "authors": [
      "Seong Hun Lee",
      "Javier Civera"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Data Structures and Algorithms (cs.DS)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2206.02570"
  },
  {
    "id": "arXiv:2206.02572",
    "title": "Automated visual inspection of silicon detectors in CMS experiment",
    "abstract": "In the CMS experiment at CERN, Geneva, a large number of HGCAL sensor modules\nare fabricated in advanced laboratories around the world. Each sensor module\ncontains about 700 checkpoints for visual inspection thus making it almost\nimpossible to carry out such inspection manually. As artificial intelligence is\nmore and more widely used in manufacturing, traditional detection technologies\nare gradually being intelligent. In order to more accurately evaluate the\ncheckpoints, we propose to use deep learning-based object detection techniques\nto detect manufacturing defects in testing large numbers of modules\nautomatically.",
    "descriptor": "",
    "authors": [
      "Dr. Nupur Giri",
      "Dr. Shashi Dugad",
      "Amit Chhabria",
      "Rashmi Manwani",
      "Priyanka Asrani"
    ],
    "subjectives": [
      "Instrumentation and Detectors (physics.ins-det)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02572"
  },
  {
    "id": "arXiv:2206.02588",
    "title": "Coding of volumetric content with MIV using VVC subpictures",
    "abstract": "Storage and transport of six degrees of freedom (6DoF) dynamic volumetric\nvisual content for immersive applications requires efficient compression.\nISO/IEC MPEG has recently been working on a standard that aims to efficiently\ncode and deliver 6DoF immersive visual experiences. This standard is called the\nMIV. MIV uses regular 2D video codecs to code the visual data. MPEG jointly\nwith ITU-T VCEG, has also specified the VVC standard. VVC introduced recently\nthe concept of subpicture. This tool was specifically designed to provide\nindependent accessibility and decodability of sub-bitstreams for\nomnidirectional applications. This paper shows the benefit of using subpictures\nin the MIV use-case. While different ways in which subpictures could be used in\nMIV are discussed, a particular case study is selected. Namely, subpictures are\nused for parallel encoding and to reduce the number of decoder instances.\nExperimental results show that the cost of using subpictures in terms of\nbitrate overhead is negligible (0.1% to 0.4%), when compared to the overall\nbitrate. The number of decoder instances on the other hand decreases by a\nfactor of two.",
    "descriptor": "\nComments: 6 pages, 3 figures\n",
    "authors": [
      "Maria Santamaria",
      "Vinod Kumar Malamal Vadakital",
      "Lukasz Kondrad",
      "Antti Hallapuro",
      "Miska M. Hannuksela"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2206.02588"
  },
  {
    "id": "arXiv:2206.02604",
    "title": "Rate-Distortion Theoretic Bounds on Generalization Error for Distributed  Learning",
    "abstract": "In this paper, we use tools from rate-distortion theory to establish new\nupper bounds on the generalization error of statistical distributed learning\nalgorithms. Specifically, there are $K$ clients whose individually chosen\nmodels are aggregated by a central server. The bounds depend on the\ncompressibility of each client's algorithm while keeping other clients'\nalgorithms un-compressed, and leverage the fact that small changes in each\nlocal model change the aggregated model by a factor of only $1/K$. Adopting a\nrecently proposed approach by Sefidgaran et al., and extending it suitably to\nthe distributed setting, this enables smaller rate-distortion terms which are\nshown to translate into tighter generalization bounds. The bounds are then\napplied to the distributed support vector machines (SVM), suggesting that the\ngeneralization error of the distributed setting decays faster than that of the\ncentralized one with a factor of $\\mathcal{O}(\\log(K)/\\sqrt{K})$. This finding\nis validated also experimentally. A similar conclusion is obtained for a\nmultiple-round federated learning setup where each client uses stochastic\ngradient Langevin dynamics (SGLD).",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Milad Sefidgaran",
      "Romain Chor",
      "Abdellatif Zaidi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02604"
  },
  {
    "id": "arXiv:2206.02639",
    "title": "Continuous-Time Analog Filters for Audio Edge Intelligence: Review and  Analysis on Design Techniques",
    "abstract": "Silicon cochlea designs capture the functionality of the biological cochlea.\nTheir use has been explored for cochlea prosthesis applications and more\nrecently in edge audio devices which are required to support always-on\noperation. As their stringent power constraints pose several design challenges,\nIC designers are forced to look for solutions that use low standby power. One\npromising bio-inspired approach is to combine the continuous-time analog filter\nchannels of the silicon cochlea with a small memory footprint deep neural\nnetwork that is trained on edge tasks such as keyword spotting, thereby\nallowing all blocks to be embedded in an IC. This paper reviews the analog\nfilter circuits used as feature extractors for current edge audio devices,\nstarting with the original biquad filter circuits proposed for the silicon\ncochlea. Our analysis starts from the interpretation of a basic biquad filter\nas a two-integrator-loop topology and reviews the progression in the design of\nsecond-order low-pass and band-pass filters ranging from OTA-based to\nsource-follower-based architectures. We also derive and analyze the\nsmall-signal transfer function and discuss performance aspects of these\nfilters. The analysis of these different filter configurations can be applied\nto other application domains such as biomedical devices which employ a\nfront-end bandpass filter.",
    "descriptor": "\nComments: 16 pages, 17 figures\n",
    "authors": [
      "Kwantae Kim",
      "Shih-Chii Liu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Hardware Architecture (cs.AR)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2206.02639"
  },
  {
    "id": "arXiv:2206.02652",
    "title": "Crust Macrofracturing as the Evidence of the Last Deglaciation",
    "abstract": "Machine learning methods were applied to reconsider the results of several\npassive seismic experiments in Finland. We created datasets from different\nstages of the receiver function technique and processed them with one of basic\nmachine learning algorithms. All the results were obtained uniformly with the\n$k$-nearest neighbors algorithm. The first result is the Moho depth map of the\nregion. Another result is the delineation of the near-surface low $S$-wave\nvelocity layer. There are three such areas in the Northern, Southern, and\ncentral parts of the region. The low $S$-wave velocity in the Northern and\nSouthern areas can be linked to the geological structure. However, we attribute\nthe central low $S$-wave velocity area to a large number of water-saturated\ncracks in the upper 1-5 km. Analysis of the structure of this area leads us to\nthe conclusion that macrofracturing was caused by the last deglaciation.",
    "descriptor": "",
    "authors": [
      "Igor Aleshin",
      "Kirill Kholodkov",
      "Elena Kozlovskaya",
      "Ivan Malygin"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02652"
  },
  {
    "id": "arXiv:2206.02702",
    "title": "Stochastic Variance-Reduced Newton: Accelerating Finite-Sum Minimization  with Large Batches",
    "abstract": "Stochastic variance reduction has proven effective at accelerating\nfirst-order algorithms for solving convex finite-sum optimization tasks such as\nempirical risk minimization. Incorporating additional second-order information\nhas proven helpful in further improving the performance of these first-order\nmethods. However, comparatively little is known about the benefits of using\nvariance reduction to accelerate popular stochastic second-order methods such\nas Subsampled Newton. To address this, we propose Stochastic Variance-Reduced\nNewton (SVRN), a finite-sum minimization algorithm which enjoys all the\nbenefits of second-order methods: simple unit step size, easily parallelizable\nlarge-batch operations, and fast local convergence, while at the same time\ntaking advantage of variance reduction to achieve improved convergence rates\n(per data pass) for smooth and strongly convex problems. We show that SVRN can\naccelerate many stochastic second-order methods (such as Subsampled Newton) as\nwell as iterative least squares solvers (such as Iterative Hessian Sketch), and\nit compares favorably to popular first-order methods with variance reduction.",
    "descriptor": "",
    "authors": [
      "Micha\u0142 Derezi\u0144ski"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.02702"
  },
  {
    "id": "arXiv:2206.02705",
    "title": "Human Behavior Recognition Method Based on CEEMD-ES Radar Selection",
    "abstract": "In recent years, the millimeter-wave radar to identify human behavior has\nbeen widely used in medical,security, and other fields. When multiple radars\nare performing detection tasks, the validity of the features contained in each\nradar is difficult to guarantee. In addition, processing multiple radar data\nalso requires a lot of time and computational cost. The Complementary Ensemble\nEmpirical Mode Decomposition-Energy Slice (CEEMD-ES) multistatic radar\nselection method is proposed to solve these problems. First, this method\ndecomposes and reconstructs the radar signal according to the difference in the\nreflected echo frequency between the limbs and the trunk of the human body.\nThen, the radar is selected according to the difference between the ratio of\necho energy of limbs and trunk and the theoretical value. The time domain,\nfrequency domain and various entropy features of the selected radar are\nextracted. Finally, the Extreme Learning Machine (ELM) recognition model of the\nReLu core is established. Experiments show that this method can effectively\nselect the radar, and the recognition rate of three kinds of human actions is\n98.53%.",
    "descriptor": "\nComments: 4 pages, 5 figures\n",
    "authors": [
      "Zhaolin Zhang",
      "Mingqi Song",
      "Wugang Meng",
      "Yuhan Liu",
      "Fengcong Li",
      "Xiang Feng",
      "Yinan Zhao"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02705"
  },
  {
    "id": "arXiv:2206.02748",
    "title": "Compound Multi-branch Feature Fusion for Real Image Restoration",
    "abstract": "Image restoration is a challenging and ill-posed problem which also has been\na long-standing issue. However, most of learning based restoration methods are\nproposed to target one degradation type which means they are lack of\ngeneralization. In this paper, we proposed a multi-branch restoration model\ninspired from the Human Visual System (i.e., Retinal Ganglion Cells) which can\nachieve multiple restoration tasks in a general framework. The experiments show\nthat the proposed multi-branch architecture, called CMFNet, has competitive\nperformance results on four datasets, including image dehazing, deraindrop, and\ndeblurring, which are very common applications for autonomous cars. The source\ncode and pretrained models of three restoration tasks are available at\nhttps://github.com/FanChiMao/CMFNet.",
    "descriptor": "",
    "authors": [
      "Chi-Mao Fan",
      "Tsung-Jung Liu",
      "Kuan-Hsien Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02748"
  },
  {
    "id": "arXiv:2206.02755",
    "title": "New lower bounds on crossing numbers of $K_{m,n}$ from permutation  modules and semidefinite programming",
    "abstract": "In this paper, we use semidefinite programming and representation theory to\ncompute new lower bounds on the crossing number of the complete bipartite graph\n$K_{m,n}$, extending a method from de Klerk et al. [SIAM J. Discrete Math. 20\n(2006), 189-202] and the subsequent reduction by De Klerk, Pasechnik and\nSchrijver [Math. Prog. Ser. A and B, 109 (2007) 613-624].\nWe exploit the full symmetry of the problem by developing a\nblock-diagonalization of the underlying matrix algebra and use it to improve\nbounds on several concrete instances. Our results imply that\n$\\text{cr}(K_{10,n}) \\geq 4.87057 n^2 - 10n$, $\\text{cr}(K_{11,n}) \\geq 5.99939\nn^2-12.5n$, $ \\text{cr}(K_{12,n}) \\geq 7.25579 n^2 - 15n$, $\\text{cr}(K_{13,n})\n\\geq 8.65675 n^2-18n$ for all $n$. The latter three bounds are computed using a\nnew relaxation of the original semidefinite programming bound, by only\nrequiring one small matrix block to be positive semidefinite. Our lower bound\non $K_{13,n}$ implies that for each fixed $m \\geq 13$, $\\lim_{n \\to \\infty}\n\\text{cr}(K_{m,n})/Z(m,n) \\geq 0.8878 m/(m-1)$. Here $Z(m,n)$ is the\nZarankiewicz number: the conjectured crossing number of $K_{m,n}$.",
    "descriptor": "\nComments: 15 pages, 3 figures, 3 tables\n",
    "authors": [
      "Daniel Brosch",
      "Sven Polak"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Optimization and Control (math.OC)",
      "Representation Theory (math.RT)"
    ],
    "url": "https://arxiv.org/abs/2206.02755"
  },
  {
    "id": "arXiv:2206.02763",
    "title": "On Crossover Distance for Optical Wireless Satellite Networks and  Optical Fiber Terrestrial Networks",
    "abstract": "Optical wireless satellite networks (OWSNs) can provide lower latency data\ncommunications compared to optical fiber terrestrial networks (OFTNs). The\ncrossover function enables to calculate the crossover distance for an OWSN and\nan OFTN. If the distance between two points on Earth is greater than the\ncrossover distance, then switching or crossing over from the OFTN to the OWSN\nresults in lower latency for data communications between these points. In this\nwork, we extend the previously proposed crossover function for a scenario such\nthat intermediate satellites (or hops) are incorporated between ingress and\negress satellites in the OWSN for a more realistic calculation of the crossover\ndistance in this scenario. We consider different OWSNs with different satellite\naltitudes and different OFTNs with different optical fiber refractive indexes,\nand we study the effect of the number of hops on crossover distance and length\nof a laser inter-satellite link (LISL). It is observed from numerical results\nthat crossover distance increases with number of hops, and this increase is\nhigher at higher satellite altitudes in OWSNs and lower refractive indexes in\nOFTNs. Furthermore, an inverse relationship between crossover distance and\nlength of a LISL is observed. With increase in number of hops, the length of a\nLISL decreases as opposed to the crossover distance.",
    "descriptor": "\nComments: Submitted for possible publication in proceedings of IEEE GLOBECOM 2022\n",
    "authors": [
      "Aizaz U. Chaudhry",
      "Halim Yanikomeroglu"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.02763"
  },
  {
    "id": "arXiv:2206.02765",
    "title": "Communication-constrained hypothesis testing: Optimality, robustness,  and reverse data processing inequalities",
    "abstract": "We study hypothesis testing under communication constraints, where each\nsample is quantized before being revealed to a statistician. Without\ncommunication constraints, it is well known that the sample complexity of\nsimple binary hypothesis testing is characterized by the Hellinger distance\nbetween the distributions. We show that the sample complexity of simple binary\nhypothesis testing under communication constraints is at most a logarithmic\nfactor larger than in the unconstrained setting and this bound is tight. We\ndevelop a polynomial-time algorithm that achieves the aforementioned sample\ncomplexity. Our framework extends to robust hypothesis testing, where the\ndistributions are corrupted in the total variation distance. Our proofs rely on\na new reverse data processing inequality and a reverse Markov inequality, which\nmay be of independent interest. For simple $M$-ary hypothesis testing, the\nsample complexity in the absence of communication constraints has a logarithmic\ndependence on $M$. We show that communication constraints can cause an\nexponential blow-up leading to $\\Omega(M)$ sample complexity even for adaptive\nalgorithms.",
    "descriptor": "\nComments: A shorter version of this article will appear in ISIT 2022\n",
    "authors": [
      "Ankit Pensia",
      "Varun Jog",
      "Po-Ling Loh"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Data Structures and Algorithms (cs.DS)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.02765"
  },
  {
    "id": "arXiv:2206.02766",
    "title": "Complexity of Eccentricities and All-Pairs Shortest Paths in the Quantum  CONGEST Model",
    "abstract": "Computing the distance parameters of a network, including the diameter,\nradius, eccentricities and the all-pairs shortest paths (APSP) is a central\nproblem in distributed computing. This paper investigates he dtistance\nparameters in the quantum CONGEST models and establishes almost linear lower\nbounds on eccentricities and APSP, which match the classical upper bounds. Our\nresults imply that there is not quantum speedup for these two problems. In\ncontrast with the diameter and radius, exchanging quantum messages is able to\nsave the communication when the networks have low diameters [Le Gall and\nMagniez, PODC 2018]. We obtain the lower bounds via a reduction from the\ntwo-way quantum communication complexity of the set intersection [Razborov,\nIzvestiya Mathematics 2003].",
    "descriptor": "\nComments: 16 pages. invited paper on SPIN, Special Issue on Quantum Algorithms and Software\n",
    "authors": [
      "ChengSheng Wang",
      "Xudong Wu",
      "Penghui Yao"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.02766"
  },
  {
    "id": "arXiv:2206.02768",
    "title": "The Neural Covariance SDE: Shaped Infinite Depth-and-Width Networks at  Initialization",
    "abstract": "The logit outputs of a feedforward neural network at initialization are\nconditionally Gaussian, given a random covariance matrix defined by the\npenultimate layer. In this work, we study the distribution of this random\nmatrix. Recent work has shown that shaping the activation function as network\ndepth grows large is necessary for this covariance matrix to be non-degenerate.\nHowever, the current infinite-width-style understanding of this shaping method\nis unsatisfactory for large depth: infinite-width analyses ignore the\nmicroscopic fluctuations from layer to layer, but these fluctuations accumulate\nover many layers.\nTo overcome this shortcoming, we study the random covariance matrix in the\nshaped infinite-depth-and-width limit. We identify the precise scaling of the\nactivation function necessary to arrive at a non-trivial limit, and show that\nthe random covariance matrix is governed by a stochastic differential equation\n(SDE) that we call the Neural Covariance SDE. Using simulations, we show that\nthe SDE closely matches the distribution of the random covariance matrix of\nfinite networks. Additionally, we recover an if-and-only-if condition for\nexploding and vanishing norms of large shaped networks based on the activation\nfunction.",
    "descriptor": "",
    "authors": [
      "Mufan Bill Li",
      "Mihai Nica",
      "Daniel M. Roy"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02768"
  },
  {
    "id": "arXiv:1202.2934",
    "title": "Numerical Analysis of Target Enumeration via Euler Characteristic  Integrals",
    "abstract": "Comments: 32 pages, 12 figures, 2 tables. This is the author's master's thesis from 2013, put on the arXiv for completeness and posterity",
    "descriptor": "\nComments: 32 pages, 12 figures, 2 tables. This is the author's master's thesis from 2013, put on the arXiv for completeness and posterity\n",
    "authors": [
      "Sam G. Krupa"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Algebraic Topology (math.AT)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1202.2934"
  },
  {
    "id": "arXiv:1708.05853",
    "title": "Convergence of HX Preconditioner for Maxwell's Equations with Jump  Coefficients (ii): The Main Results",
    "abstract": "Comments: with 25 pages, 2 figures",
    "descriptor": "\nComments: with 25 pages, 2 figures\n",
    "authors": [
      "Qiya Hu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1708.05853"
  },
  {
    "id": "arXiv:1904.08576",
    "title": "On Low-rank Trace Regression under General Sampling Distribution",
    "abstract": "Comments: 41 pages, 6 figure2",
    "descriptor": "\nComments: 41 pages, 6 figure2\n",
    "authors": [
      "Nima Hamidi",
      "Mohsen Bayati"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1904.08576"
  },
  {
    "id": "arXiv:1905.09570",
    "title": "Gravity-Inspired Graph Autoencoders for Directed Link Prediction",
    "abstract": "Comments: ACM International Conference on Information and Knowledge Management (CIKM 2019)",
    "descriptor": "\nComments: ACM International Conference on Information and Knowledge Management (CIKM 2019)\n",
    "authors": [
      "Guillaume Salha",
      "Stratis Limnios",
      "Romain Hennequin",
      "Viet Anh Tran",
      "Michalis Vazirgiannis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1905.09570"
  },
  {
    "id": "arXiv:1906.01337",
    "title": "SoK: Differential Privacies",
    "abstract": "Comments: This is the full version of the SoK paper with the same title, accepted at PETS (Privacy Enhancing Technologies Symposium) 2020",
    "descriptor": "\nComments: This is the full version of the SoK paper with the same title, accepted at PETS (Privacy Enhancing Technologies Symposium) 2020\n",
    "authors": [
      "Damien Desfontaines",
      "Bal\u00e1zs Pej\u00f3"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/1906.01337"
  },
  {
    "id": "arXiv:1909.09934",
    "title": "Structured Binary Neural Networks for Image Recognition",
    "abstract": "Comments: Accepted to Int. J. Comp. Vision (IJCV). Extended version of the conference version arXiv:1811.10413",
    "descriptor": "\nComments: Accepted to Int. J. Comp. Vision (IJCV). Extended version of the conference version arXiv:1811.10413\n",
    "authors": [
      "Bohan Zhuang",
      "Chunhua Shen",
      "Mingkui Tan",
      "Peng Chen",
      "Lingqiao Liu",
      "Ian Reid"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1909.09934"
  },
  {
    "id": "arXiv:2001.02299",
    "title": "The LDBC Social Network Benchmark",
    "abstract": "Comments: For the repository containing the source code of this technical report, see this https URL",
    "descriptor": "\nComments: For the repository containing the source code of this technical report, see this https URL\n",
    "authors": [
      "Renzo Angles",
      "J\u00e1nos Benjamin Antal",
      "Alex Averbuch",
      "Altan Birler",
      "Peter Boncz",
      "M\u00e1rton B\u00far",
      "Orri Erling",
      "Andrey Gubichev",
      "Vlad Haprian",
      "Moritz Kaufmann",
      "Josep Llu\u00eds Larriba Pey",
      "Norbert Mart\u00ednez",
      "J\u00f3zsef Marton",
      "Marcus Paradies",
      "Minh-Duc Pham",
      "Arnau Prat-P\u00e9rez",
      "Mirko Spasi\u0107",
      "Benjamin A. Steer",
      "D\u00e1vid Szak\u00e1llas",
      "G\u00e1bor Sz\u00e1rnyas",
      "Jack Waudby",
      "Mingxi Wu",
      "Yuchen Zhang"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Performance (cs.PF)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2001.02299"
  },
  {
    "id": "arXiv:2002.00080",
    "title": "Convergence rate analysis and improved iterations for numerical radius  computation",
    "abstract": "Comments: Revision #3",
    "descriptor": "\nComments: Revision #3\n",
    "authors": [
      "Tim Mitchell"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2002.00080"
  },
  {
    "id": "arXiv:2002.04753",
    "title": "RFN: A Random-Feature Based Newton Method for Empirical Risk  Minimization in Reproducing Kernel Hilbert Spaces",
    "abstract": "RFN: A Random-Feature Based Newton Method for Empirical Risk  Minimization in Reproducing Kernel Hilbert Spaces",
    "descriptor": "",
    "authors": [
      "Ting-Jui Chang",
      "Shahin Shahrampour"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.04753"
  },
  {
    "id": "arXiv:2004.12574",
    "title": "Single- and Multi-Objective Evolutionary Algorithms for the Knapsack  Problem with Dynamically Changing Constraints",
    "abstract": "Single- and Multi-Objective Evolutionary Algorithms for the Knapsack  Problem with Dynamically Changing Constraints",
    "descriptor": "",
    "authors": [
      "Vahid Roostapour",
      "Aneta Neumann",
      "Frank Neumann"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2004.12574"
  },
  {
    "id": "arXiv:2005.01344",
    "title": "How to Train Your Dragon: Tamed Warping Network for Semantic Video  Segmentation",
    "abstract": "Comments: The paper is under consideration at Pattern Recognition Letters",
    "descriptor": "\nComments: The paper is under consideration at Pattern Recognition Letters\n",
    "authors": [
      "Junyi Feng",
      "Songyuan Li",
      "Yifeng Chen",
      "Fuxian Huang",
      "Jiabao Cui",
      "Xi Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2005.01344"
  },
  {
    "id": "arXiv:2005.07225",
    "title": "SAGE: Sequential Attribute Generator for Analyzing Glioblastomas using  Limited Dataset",
    "abstract": "SAGE: Sequential Attribute Generator for Analyzing Glioblastomas using  Limited Dataset",
    "descriptor": "",
    "authors": [
      "Padmaja Jonnalagedda",
      "Brent Weinberg",
      "Jason Allen",
      "Taejin L. Min",
      "Shiv Bhanu",
      "Bir Bhanu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2005.07225"
  },
  {
    "id": "arXiv:2006.00664",
    "title": "Beamforming Design and Performance Evaluation for Reconfigurable  Intelligent Surface Assisted Wireless Communication Systems With Non-Ideal  Hardware",
    "abstract": "Beamforming Design and Performance Evaluation for Reconfigurable  Intelligent Surface Assisted Wireless Communication Systems With Non-Ideal  Hardware",
    "descriptor": "",
    "authors": [
      "Yiming Liu",
      "Erwu Liu",
      "Rui Wang",
      "Binyu Lu",
      "Zhu Han"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2006.00664"
  },
  {
    "id": "arXiv:2006.10012",
    "title": "Robust Persistence Diagrams using Reproducing Kernels",
    "abstract": "Robust Persistence Diagrams using Reproducing Kernels",
    "descriptor": "",
    "authors": [
      "Siddharth Vishwanath",
      "Kenji Fukumizu",
      "Satoshi Kuriki",
      "Bharath Sriperumbudur"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Computational Geometry (cs.CG)",
      "Machine Learning (cs.LG)",
      "Algebraic Topology (math.AT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.10012"
  },
  {
    "id": "arXiv:2008.03325",
    "title": "Approximating Two-Stage Stochastic Supplier Problems",
    "abstract": "Approximating Two-Stage Stochastic Supplier Problems",
    "descriptor": "",
    "authors": [
      "Brian Brubach",
      "Nathaniel Grammel",
      "David G. Harris",
      "Aravind Srinivasan",
      "Leonidas Tsepenekas",
      "Anil Vullikanti"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2008.03325"
  },
  {
    "id": "arXiv:2008.08973",
    "title": "Exposures Exposed: A Measurement and User Study to Assess Mobile Data  Privacy in Context",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:1803.01261",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1803.01261\n",
    "authors": [
      "Evita Bakopoulou",
      "Anastasia Shuba",
      "Athina Markopoulou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Human-Computer Interaction (cs.HC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2008.08973"
  },
  {
    "id": "arXiv:2010.00721",
    "title": "Using Unlabeled Data for Increasing Low-Shot Classification Accuracy of  Relevant and Open-Set Irrelevant Images",
    "abstract": "Using Unlabeled Data for Increasing Low-Shot Classification Accuracy of  Relevant and Open-Set Irrelevant Images",
    "descriptor": "",
    "authors": [
      "Spiridon Kasapis",
      "Geng Zhang",
      "Jonathon Smereka",
      "Nickolas Vlahopoulos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.00721"
  },
  {
    "id": "arXiv:2011.03085",
    "title": "RealAnt: An Open-Source Low-Cost Quadruped for Education and Research in  Real-World Reinforcement Learning",
    "abstract": "RealAnt: An Open-Source Low-Cost Quadruped for Education and Research in  Real-World Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Rinu Boney",
      "Jussi Sainio",
      "Mikko Kaivola",
      "Arno Solin",
      "Juho Kannala"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2011.03085"
  },
  {
    "id": "arXiv:2011.07633",
    "title": "Almost Tight L0-norm Certified Robustness of Top-k Predictions against  Adversarial Perturbations",
    "abstract": "Comments: Published as a conference paper at ICLR 2022",
    "descriptor": "\nComments: Published as a conference paper at ICLR 2022\n",
    "authors": [
      "Jinyuan Jia",
      "Binghui Wang",
      "Xiaoyu Cao",
      "Hongbin Liu",
      "Neil Zhenqiang Gong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.07633"
  },
  {
    "id": "arXiv:2011.09208",
    "title": "Whale: Efficient Giant Model Training over Heterogeneous GPUs",
    "abstract": "Whale: Efficient Giant Model Training over Heterogeneous GPUs",
    "descriptor": "",
    "authors": [
      "Xianyan Jia",
      "Le Jiang",
      "Ang Wang",
      "Wencong Xiao",
      "Ziji Shi",
      "Jie Zhang",
      "Xinyuan Li",
      "Langshi Chen",
      "Yong Li",
      "Zhen Zheng",
      "Xiaoyong Liu",
      "Wei Lin"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2011.09208"
  },
  {
    "id": "arXiv:2011.09644",
    "title": "RADAR-X: An Interactive Mixed Initiative Planning Interface Pairing  Contrastive Explanations and Revised Plan Suggestions",
    "abstract": "Comments: Accepted at ICAPS 2022",
    "descriptor": "\nComments: Accepted at ICAPS 2022\n",
    "authors": [
      "Karthik Valmeekam",
      "Sarath Sreedharan",
      "Sailik Sengupta",
      "Subbarao Kambhampati"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2011.09644"
  },
  {
    "id": "arXiv:2011.12468",
    "title": "Nudge: Accelerating Overdue Pull Requests Towards Completion",
    "abstract": "Nudge: Accelerating Overdue Pull Requests Towards Completion",
    "descriptor": "",
    "authors": [
      "Chandra Maddila",
      "Sai Surya Upadrasta",
      "Chetan Bansal",
      "Nachiappan Nagappan",
      "Georgios Gousios",
      "Arie van Deursen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2011.12468"
  },
  {
    "id": "arXiv:2012.07296",
    "title": "Compositional Construction of Control Barrier Functions for  Continuous-Time Stochastic Hybrid Systems",
    "abstract": "Compositional Construction of Control Barrier Functions for  Continuous-Time Stochastic Hybrid Systems",
    "descriptor": "",
    "authors": [
      "Ameneh Nejati",
      "Sadegh Soudjani",
      "Majid Zamani"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2012.07296"
  },
  {
    "id": "arXiv:2012.11793",
    "title": "Optimum Reconfigurable Intelligent Surface Selection for Wireless  Networks",
    "abstract": "Comments: 34 pages; submitted for possible IEEE publications",
    "descriptor": "\nComments: 34 pages; submitted for possible IEEE publications\n",
    "authors": [
      "Yuting Fang",
      "Saman Atapattu",
      "Hazer Inaltekin",
      "Jamie Evans"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2012.11793"
  },
  {
    "id": "arXiv:2012.13292",
    "title": "Understanding and Predicting Characteristics of Test Collections in  Information Retrieval",
    "abstract": "Comments: Accepted as a full paper at iConference 2022",
    "descriptor": "\nComments: Accepted as a full paper at iConference 2022\n",
    "authors": [
      "Md Mustafizur Rahman",
      "Mucahid Kutlu",
      "Matthew Lease"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2012.13292"
  },
  {
    "id": "arXiv:2012.13965",
    "title": "Efficient Jacobian-Based Inverse Kinematics with Sim-to-Real Transfer of  Soft Robots by Learning",
    "abstract": "Efficient Jacobian-Based Inverse Kinematics with Sim-to-Real Transfer of  Soft Robots by Learning",
    "descriptor": "",
    "authors": [
      "Guoxin Fang",
      "Yingjun Tian",
      "Zhi-Xin Yang",
      "Jo M.P. Geraedts",
      "Charlie C.L. Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2012.13965"
  },
  {
    "id": "arXiv:2012.14426",
    "title": "How Far Can We Get with Neural Networks Straight from JPEG?",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2012.13726",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2012.13726\n",
    "authors": [
      "Samuel Felipe dos Santos",
      "Nicu Sebe",
      "Jurandy Almeida"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.14426"
  },
  {
    "id": "arXiv:2101.02916",
    "title": "Accelerating Training of Batch Normalization: A Manifold Perspective",
    "abstract": "Comments: Published in UAI 2022",
    "descriptor": "\nComments: Published in UAI 2022\n",
    "authors": [
      "Mingyang Yi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.02916"
  },
  {
    "id": "arXiv:2101.02994",
    "title": "Quotients, inductive types, and quotient inductive types",
    "abstract": "Quotients, inductive types, and quotient inductive types",
    "descriptor": "",
    "authors": [
      "Marcelo P. Fiore",
      "Andrew M. Pitts",
      "S. C. Steenkamp"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2101.02994"
  },
  {
    "id": "arXiv:2101.06224",
    "title": "Multi-point dimensionality reduction to improve projection layout  reliability",
    "abstract": "Multi-point dimensionality reduction to improve projection layout  reliability",
    "descriptor": "",
    "authors": [
      "Farshad Barahimi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.06224"
  },
  {
    "id": "arXiv:2101.08688",
    "title": "On $L^q$ Convergence of the Hamiltonian Monte Carlo",
    "abstract": "On $L^q$ Convergence of the Hamiltonian Monte Carlo",
    "descriptor": "",
    "authors": [
      "Soumyadip Ghosh",
      "Yingdong Lu",
      "Tomasz Nowicki"
    ],
    "subjectives": [
      "Classical Analysis and ODEs (math.CA)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Functional Analysis (math.FA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2101.08688"
  },
  {
    "id": "arXiv:2101.09592",
    "title": "Point-hyperplane incidence geometry and the log-rank conjecture",
    "abstract": "Comments: 14 pages, no figures; revised discussion, to appear in ACM Transactions on Computation Theory",
    "descriptor": "\nComments: 14 pages, no figures; revised discussion, to appear in ACM Transactions on Computation Theory\n",
    "authors": [
      "Noah Singer",
      "Madhu Sudan"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2101.09592"
  },
  {
    "id": "arXiv:2102.01249",
    "title": "Blockchain-based Transparency Framework for Privacy Preserving  Third-party Services",
    "abstract": "Comments: 12 pages",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Runhua Xu",
      "Chao Li",
      "James Joshi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2102.01249"
  },
  {
    "id": "arXiv:2102.02675",
    "title": "Observability of the relative motion from inertial data in kinematic  chains",
    "abstract": "Comments: 17 pages, 8 figures",
    "descriptor": "\nComments: 17 pages, 8 figures\n",
    "authors": [
      "Manon Kok",
      "Karsten Eckhoff",
      "Ive Weygers",
      "Thomas Seel"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2102.02675"
  },
  {
    "id": "arXiv:2102.04999",
    "title": "Adaptive Pairwise Weights for Temporal Credit Assignment",
    "abstract": "Comments: AAAI 2022. The first two authors contributed equally",
    "descriptor": "\nComments: AAAI 2022. The first two authors contributed equally\n",
    "authors": [
      "Zeyu Zheng",
      "Risto Vuorio",
      "Richard Lewis",
      "Satinder Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.04999"
  },
  {
    "id": "arXiv:2102.05320",
    "title": "An Adaptive Stochastic Sequential Quadratic Programming with  Differentiable Exact Augmented Lagrangians",
    "abstract": "Comments: 60 pages, 24 figures",
    "descriptor": "\nComments: 60 pages, 24 figures\n",
    "authors": [
      "Sen Na",
      "Mihai Anitescu",
      "Mladen Kolar"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.05320"
  },
  {
    "id": "arXiv:2102.07148",
    "title": "A New Look and Convergence Rate of Federated Multi-Task Learning with  Laplacian Regularization",
    "abstract": "A New Look and Convergence Rate of Federated Multi-Task Learning with  Laplacian Regularization",
    "descriptor": "",
    "authors": [
      "Canh T. Dinh",
      "Tung T. Vu",
      "Nguyen H. Tran",
      "Minh N. Dao",
      "Hongyu Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2102.07148"
  },
  {
    "id": "arXiv:2102.08581",
    "title": "Efficient Scheduling of Data Augmentation for Deep Reinforcement  Learning",
    "abstract": "Efficient Scheduling of Data Augmentation for Deep Reinforcement  Learning",
    "descriptor": "",
    "authors": [
      "Byungchan Ko",
      "Jungseul Ok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.08581"
  },
  {
    "id": "arXiv:2103.05684",
    "title": "Monotonic Alpha-divergence Minimisation for Variational Inference",
    "abstract": "Monotonic Alpha-divergence Minimisation for Variational Inference",
    "descriptor": "",
    "authors": [
      "Kam\u00e9lia Daudel",
      "Randal Douc",
      "Fran\u00e7ois Roueff"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2103.05684"
  },
  {
    "id": "arXiv:2103.05734",
    "title": "Dependence of integrated, instantaneous, and fluctuating entropy  production on the initial state in quantum and classical processes",
    "abstract": "Comments: Fix some line breaking issues in the appendix",
    "descriptor": "\nComments: Fix some line breaking issues in the appendix\n",
    "authors": [
      "Artemy Kolchinsky",
      "David H. Wolpert"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2103.05734"
  },
  {
    "id": "arXiv:2103.12209",
    "title": "Monocular Depth Estimation through Virtual-world Supervision and  Real-world SfM Self-Supervision",
    "abstract": "Comments: Published in IEEE-Transactions on Intelligent Transportation Systems, 2021 15 pages, 12 figures",
    "descriptor": "\nComments: Published in IEEE-Transactions on Intelligent Transportation Systems, 2021 15 pages, 12 figures\n",
    "authors": [
      "Akhil Gurram",
      "Ahmet Faruk Tuna",
      "Fengyi Shen",
      "Onay Urfalioglu",
      "Antonio M. L\u00f3pez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.12209"
  },
  {
    "id": "arXiv:2103.12236",
    "title": "Instance-level Image Retrieval using Reranking Transformers",
    "abstract": "Comments: ICCV 2021, Table-3 corrected",
    "descriptor": "\nComments: ICCV 2021, Table-3 corrected\n",
    "authors": [
      "Fuwen Tan",
      "Jiangbo Yuan",
      "Vicente Ordonez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.12236"
  },
  {
    "id": "arXiv:2103.12991",
    "title": "MLAN: Multi-Level Adversarial Network for Domain Adaptive Semantic  Segmentation",
    "abstract": "Comments: Accepted to Pattern Recognition, 2022",
    "descriptor": "\nComments: Accepted to Pattern Recognition, 2022\n",
    "authors": [
      "Jiaxing Huang",
      "Dayan Guan",
      "Shijian Lu",
      "Aoran Xiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.12991"
  },
  {
    "id": "arXiv:2103.13059",
    "title": "Towards Optimal Algorithms for Multi-Player Bandits without Collision  Sensing Information",
    "abstract": "Comments: 24 pages, COLT 2022",
    "descriptor": "\nComments: 24 pages, COLT 2022\n",
    "authors": [
      "Wei Huang",
      "Richard Combes",
      "Cindy Trinh"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.13059"
  },
  {
    "id": "arXiv:2103.16156",
    "title": "Uniform Envelopes",
    "abstract": "Uniform Envelopes",
    "descriptor": "",
    "authors": [
      "Eike Neumann"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/2103.16156"
  },
  {
    "id": "arXiv:2104.01943",
    "title": "A Minimum-Footprint Implementation of Discrete-Time ADRC",
    "abstract": "A Minimum-Footprint Implementation of Discrete-Time ADRC",
    "descriptor": "",
    "authors": [
      "Gernot Herbst"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2104.01943"
  },
  {
    "id": "arXiv:2104.02904",
    "title": "Multimodal Object Detection via Probabilistic Ensembling",
    "abstract": "Comments: this https URL",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Yi-Ting Chen",
      "Jinghao Shi",
      "Zelin Ye",
      "Christoph Mertz",
      "Shu Kong",
      "Deva Ramanan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.02904"
  },
  {
    "id": "arXiv:2104.02963",
    "title": "The art of defense: letting networks fool the attacker",
    "abstract": "The art of defense: letting networks fool the attacker",
    "descriptor": "",
    "authors": [
      "Jinlai Zhang",
      "Yinpeng Dong",
      "Binbin Liu",
      "Bo Ouyang",
      "Jihong Zhu",
      "Minchi Kuang",
      "Houqing Wang",
      "Yanmei Meng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.02963"
  },
  {
    "id": "arXiv:2104.04846",
    "title": "Congruence and Plausibility, not Presence?! Pivotal Conditions for XR  Experiences and Effects, a Novel Model",
    "abstract": "Comments: 10 pages,2 figures",
    "descriptor": "\nComments: 10 pages,2 figures\n",
    "authors": [
      "Marc Erich Latoschik",
      "Carolin Wienrich"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2104.04846"
  },
  {
    "id": "arXiv:2104.06279",
    "title": "Very Lightweight Photo Retouching Network with Conditional Sequential  Modulation",
    "abstract": "Comments: Accepted by TMM. arXiv admin note: substantial text overlap with arXiv:2009.10390",
    "descriptor": "\nComments: Accepted by TMM. arXiv admin note: substantial text overlap with arXiv:2009.10390\n",
    "authors": [
      "Yihao Liu",
      "Jingwen He",
      "Xiangyu Chen",
      "Zhengwen Zhang",
      "Hengyuan Zhao",
      "Chao Dong",
      "Yu Qiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.06279"
  },
  {
    "id": "arXiv:2104.06970",
    "title": "Understanding the Eluder Dimension",
    "abstract": "Understanding the Eluder Dimension",
    "descriptor": "",
    "authors": [
      "Gene Li",
      "Pritish Kamath",
      "Dylan J. Foster",
      "Nathan Srebro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2104.06970"
  },
  {
    "id": "arXiv:2104.13209",
    "title": "Parallel K-Clique Counting on GPUs",
    "abstract": "Parallel K-Clique Counting on GPUs",
    "descriptor": "",
    "authors": [
      "Mohammad Almasri",
      "Izzat El Hajj",
      "Rakesh Nagi",
      "Jinjun Xiong",
      "Wen-mei Hwu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2104.13209"
  },
  {
    "id": "arXiv:2104.13971",
    "title": "SMLSOM: The shrinking maximum likelihood self-organizing map",
    "abstract": "SMLSOM: The shrinking maximum likelihood self-organizing map",
    "descriptor": "",
    "authors": [
      "Ryosuke Motegi",
      "Yoichi Seki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2104.13971"
  },
  {
    "id": "arXiv:2105.09592",
    "title": "Distribution Agnostic Symbolic Representations for Time Series  Dimensionality Reduction and Online Anomaly Detection",
    "abstract": "Comments: Accepted for publication in IEEE Transactions on Knowledge and Data Engineering. Compared to the previous version, now the cSAX symbolic representation is also used for discord discovery",
    "descriptor": "\nComments: Accepted for publication in IEEE Transactions on Knowledge and Data Engineering. Compared to the previous version, now the cSAX symbolic representation is also used for discord discovery\n",
    "authors": [
      "Konstantinos Bountrogiannis",
      "George Tzagkarakis",
      "Panagiotis Tsakalides"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.09592"
  },
  {
    "id": "arXiv:2105.13302",
    "title": "Characterizing the SLOPE Trade-off: A Variational Perspective and the  Donoho-Tanner Limit",
    "abstract": "Characterizing the SLOPE Trade-off: A Variational Perspective and the  Donoho-Tanner Limit",
    "descriptor": "",
    "authors": [
      "Zhiqi Bu",
      "Jason Klusowski",
      "Cynthia Rush",
      "Weijie J. Su"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.13302"
  },
  {
    "id": "arXiv:2105.14508",
    "title": "Some hypersurfaces over finite fields, minimal codes and secret sharing  schemes",
    "abstract": "Comments: 20 pages; fully revised version",
    "descriptor": "\nComments: 20 pages; fully revised version\n",
    "authors": [
      "Angela Aguglia",
      "Michela Ceria",
      "Luca Giuzzi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2105.14508"
  },
  {
    "id": "arXiv:2106.02172",
    "title": "Learning from Counterfactual Links for Link Prediction",
    "abstract": "Comments: Accepted by ICML 2022",
    "descriptor": "\nComments: Accepted by ICML 2022\n",
    "authors": [
      "Tong Zhao",
      "Gang Liu",
      "Daheng Wang",
      "Wenhao Yu",
      "Meng Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02172"
  },
  {
    "id": "arXiv:2106.03485",
    "title": "Redundant representations help generalization in wide neural networks",
    "abstract": "Redundant representations help generalization in wide neural networks",
    "descriptor": "",
    "authors": [
      "Diego Doimo",
      "Aldo Glielmo",
      "Sebastian Goldt",
      "Alessandro Laio"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.03485"
  },
  {
    "id": "arXiv:2106.06112",
    "title": "Spectral Unsupervised Domain Adaptation for Visual Recognition",
    "abstract": "Comments: Accepted to CVPR2022",
    "descriptor": "\nComments: Accepted to CVPR2022\n",
    "authors": [
      "Jingyi Zhang",
      "Jiaxing Huang",
      "Zichen Tian",
      "Shijian Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.06112"
  },
  {
    "id": "arXiv:2106.07995",
    "title": "Learning of feature points without additional supervision improves  reinforcement learning from images",
    "abstract": "Learning of feature points without additional supervision improves  reinforcement learning from images",
    "descriptor": "",
    "authors": [
      "Rinu Boney",
      "Alexander Ilin",
      "Juho Kannala"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.07995"
  },
  {
    "id": "arXiv:2106.13516",
    "title": "Multi-Domain Active Learning: Literature Review and Comparative Study",
    "abstract": "Multi-Domain Active Learning: Literature Review and Comparative Study",
    "descriptor": "",
    "authors": [
      "Rui He",
      "Shengcai Liu",
      "Shan He",
      "Ke Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.13516"
  },
  {
    "id": "arXiv:2106.16078",
    "title": "Identification of Linear Systems with Multiplicative Noise from Multiple  Trajectory Data",
    "abstract": "Identification of Linear Systems with Multiplicative Noise from Multiple  Trajectory Data",
    "descriptor": "",
    "authors": [
      "Yu Xing",
      "Benjamin Gravell",
      "Xingkang He",
      "Karl Henrik Johansson",
      "Tyler Summers"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.16078"
  },
  {
    "id": "arXiv:2107.04245",
    "title": "Private Graph Data Release: A Survey",
    "abstract": "Private Graph Data Release: A Survey",
    "descriptor": "",
    "authors": [
      "Yang Li",
      "Michael Purcell",
      "Thierry Rakotoarivelo",
      "David Smith",
      "Thilina Ranbaduge",
      "Kee Siong Ng"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.04245"
  },
  {
    "id": "arXiv:2107.07791",
    "title": "Graph Representation Learning for Road Type Classification",
    "abstract": "Graph Representation Learning for Road Type Classification",
    "descriptor": "",
    "authors": [
      "Zahra Gharaee",
      "Shreyas Kowshik",
      "Oliver Stromann",
      "Michael Felsberg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.07791"
  },
  {
    "id": "arXiv:2107.14079",
    "title": "Density of binary disc packings: lower and upper bounds",
    "abstract": "Comments: C++ code and sagemath worksheet in ancillary files. Relies on results provided in arXiv:2002.07168",
    "descriptor": "\nComments: C++ code and sagemath worksheet in ancillary files. Relies on results provided in arXiv:2002.07168\n",
    "authors": [
      "Thomas Fernique"
    ],
    "subjectives": [
      "Metric Geometry (math.MG)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2107.14079"
  },
  {
    "id": "arXiv:2108.04798",
    "title": "Pointwise distance distributions of periodic point sets",
    "abstract": "Comments: 26 pages, 12 figures, the latest version is available at this http URL",
    "descriptor": "\nComments: 26 pages, 12 figures, the latest version is available at this http URL\n",
    "authors": [
      "Daniel Widdowson",
      "Vitaliy Kurlin"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Metric Geometry (math.MG)"
    ],
    "url": "https://arxiv.org/abs/2108.04798"
  },
  {
    "id": "arXiv:2108.06630",
    "title": "Convergence study of IB methods for Stokes equations with no-slip  boundary conditions",
    "abstract": "Comments: 20 pages, 4 figures",
    "descriptor": "\nComments: 20 pages, 4 figures\n",
    "authors": [
      "Zhilin Li",
      "Kejia Pan",
      "Juan Ruiz-\u00c1lvarez"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2108.06630"
  },
  {
    "id": "arXiv:2108.08874",
    "title": "Towards A Fairer Landmark Recognition Dataset",
    "abstract": "Comments: Please cite the full detailed version of the paper instead: Improving Fairness in Large-Scale Object Recognition by CrowdSourced Demographic Information arXiv:2206.01326",
    "descriptor": "\nComments: Please cite the full detailed version of the paper instead: Improving Fairness in Large-Scale Object Recognition by CrowdSourced Demographic Information arXiv:2206.01326\n",
    "authors": [
      "Zu Kim",
      "Andr\u00e9 Araujo",
      "Bingyi Cao",
      "Cam Askew",
      "Jack Sim",
      "Mike Green",
      "N'Mah Fodiatu Yilla",
      "Tobias Weyand"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.08874"
  },
  {
    "id": "arXiv:2108.10831",
    "title": "LLVIP: A Visible-infrared Paired Dataset for Low-light Vision",
    "abstract": "Comments: 10 pages, 11 figures, ICCV workshop",
    "descriptor": "\nComments: 10 pages, 11 figures, ICCV workshop\n",
    "authors": [
      "Xinyu Jia",
      "Chuang Zhu",
      "Minzhen Li",
      "Wenqi Tang",
      "Shengjie Liu",
      "Wenli Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.10831"
  },
  {
    "id": "arXiv:2108.11896",
    "title": "A Survey on Automated Fact-Checking",
    "abstract": "Comments: Accepted at TACL 2022, 28 pages",
    "descriptor": "\nComments: Accepted at TACL 2022, 28 pages\n",
    "authors": [
      "Zhijiang Guo",
      "Michael Schlichtkrull",
      "Andreas Vlachos"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.11896"
  },
  {
    "id": "arXiv:2108.13327",
    "title": "N24News: A New Dataset for Multimodal News Classification",
    "abstract": "N24News: A New Dataset for Multimodal News Classification",
    "descriptor": "",
    "authors": [
      "Zhen Wang",
      "Xu Shan",
      "Xiangxie Zhang",
      "Jie Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.13327"
  },
  {
    "id": "arXiv:2109.04786",
    "title": "Wi-Fi Meets ML: A Survey on Improving IEEE 802.11 Performance with  Machine Learning",
    "abstract": "Comments: 54 pages, 23 figures, 384 references, accepted for publication in IEEE Communications Surveys & Tutorials",
    "descriptor": "\nComments: 54 pages, 23 figures, 384 references, accepted for publication in IEEE Communications Surveys & Tutorials\n",
    "authors": [
      "Szymon Szott",
      "Katarzyna Kosek-Szott",
      "Piotr Gaw\u0142owicz",
      "Jorge Torres G\u00f3mez",
      "Boris Bellalta",
      "Anatolij Zubow",
      "Falko Dressler"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2109.04786"
  },
  {
    "id": "arXiv:2109.05638",
    "title": "High order compact schemes for flux type BCs",
    "abstract": "Comments: 24 pages, 7 figures, 7 tables",
    "descriptor": "\nComments: 24 pages, 7 figures, 7 tables\n",
    "authors": [
      "Zhilin Li",
      "Kejia Pan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.05638"
  },
  {
    "id": "arXiv:2109.07868",
    "title": "The Influence of Human Aspects on Requirements Engineering-related  Activities: Software Practitioners Perspective",
    "abstract": "Comments: Accepted in ACM Transactions on Software Engineering and Methodology, 37 pages, 8 figures, 7 tables",
    "descriptor": "\nComments: Accepted in ACM Transactions on Software Engineering and Methodology, 37 pages, 8 figures, 7 tables\n",
    "authors": [
      "Dulaji Hidellaarachchi",
      "John Grundy",
      "Rashina Hoda",
      "Ingo Mueller"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2109.07868"
  },
  {
    "id": "arXiv:2109.08965",
    "title": "PCNN: A physics-constrained neural network for multiphase flows",
    "abstract": "Comments: 28 pages, 9 figures",
    "descriptor": "\nComments: 28 pages, 9 figures\n",
    "authors": [
      "Haoyang Zheng",
      "Ziyang Huang",
      "Guang Lin"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.08965"
  },
  {
    "id": "arXiv:2109.10581",
    "title": "DA-MUSIC: Data-Driven DoA Estimation via Deep Augmented MUSIC Algorithm",
    "abstract": "Comments: Submitted to TSP",
    "descriptor": "\nComments: Submitted to TSP\n",
    "authors": [
      "Julian P. Merkofer",
      "Guy Revach",
      "Nir Shlezinger",
      "Tirza Routtenberg",
      "Ruud J. G. van Sloun"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.10581"
  },
  {
    "id": "arXiv:2109.10781",
    "title": "Introducing Symmetries to Black Box Meta Reinforcement Learning",
    "abstract": "Comments: AAAI 2022",
    "descriptor": "\nComments: AAAI 2022\n",
    "authors": [
      "Louis Kirsch",
      "Sebastian Flennerhag",
      "Hado van Hasselt",
      "Abram Friesen",
      "Junhyuk Oh",
      "Yutian Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.10781"
  },
  {
    "id": "arXiv:2109.11828",
    "title": "A multiple criteria approach for constructing a pandemic impact  assessment composite indicator: The case of Covid-19 in Portugal",
    "abstract": "Comments: 47 pages, 18 Figures",
    "descriptor": "\nComments: 47 pages, 18 Figures\n",
    "authors": [
      "Jos\u00e9 Rui Figueira",
      "Henrique M. Oliveira",
      "Ana Paula Serro",
      "Rog\u00e9rio Cola\u00e7o",
      "Filipe Froes",
      "Carlos Robalo Cordeiro",
      "Ant\u00f3nio Diniz",
      "Miguel Guimar\u00e3es"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2109.11828"
  },
  {
    "id": "arXiv:2110.00275",
    "title": "SALSA: Spatial Cue-Augmented Log-Spectrogram Features for Polyphonic  Sound Event Localization and Detection",
    "abstract": "Comments: (c) 2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works",
    "descriptor": "\nComments: (c) 2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works\n",
    "authors": [
      "Thi Ngoc Tho Nguyen",
      "Karn N. Watcharasupat",
      "Ngoc Khanh Nguyen",
      "Douglas L. Jones",
      "Woon-Seng Gan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.00275"
  },
  {
    "id": "arXiv:2110.01036",
    "title": "Numerical computation of Neumann controls for the heat equation on a  finite interval",
    "abstract": "Comments: 24 pages, 11 figures, 4 tables",
    "descriptor": "\nComments: 24 pages, 11 figures, 4 tables\n",
    "authors": [
      "Konstantinos Kalimeris",
      "T\u00fcrker \u00d6zsar\u0131",
      "Nikolaos Dikaios"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.01036"
  },
  {
    "id": "arXiv:2110.03324",
    "title": "Structured Channel Covariance Estimation from Limited Samples for Large  Antenna Arrays",
    "abstract": "Comments: 36 pages, 24 figures",
    "descriptor": "\nComments: 36 pages, 24 figures\n",
    "authors": [
      "Tianyu Yang",
      "Mahdi Barzegar Khalilsarai",
      "Saeid Haghighatshoar",
      "Giuseppe Caire"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.03324"
  },
  {
    "id": "arXiv:2110.03506",
    "title": "Run Time Assurance for Safety-Critical Systems: An Introduction to  Safety Filtering Approaches for Complex Control Systems",
    "abstract": "Run Time Assurance for Safety-Critical Systems: An Introduction to  Safety Filtering Approaches for Complex Control Systems",
    "descriptor": "",
    "authors": [
      "Kerianne Hobbs",
      "Mark Mote",
      "Matthew Abate",
      "Samuel Coogan",
      "Eric Feron"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.03506"
  },
  {
    "id": "arXiv:2110.04126",
    "title": "3D Infomax improves GNNs for Molecular Property Prediction",
    "abstract": "Comments: 39th International Conference on Machine Learning (ICML 2022). Also accepted at NeurIPS 2021 ML4PH, AI4S, and SSL workshops and as oral at ELLIS ML4Molecules. 24 pages, 7 figures, 18 tables",
    "descriptor": "\nComments: 39th International Conference on Machine Learning (ICML 2022). Also accepted at NeurIPS 2021 ML4PH, AI4S, and SSL workshops and as oral at ELLIS ML4Molecules. 24 pages, 7 figures, 18 tables\n",
    "authors": [
      "Hannes St\u00e4rk",
      "Dominique Beaini",
      "Gabriele Corso",
      "Prudencio Tossou",
      "Christian Dallago",
      "Stephan G\u00fcnnemann",
      "Pietro Li\u00f2"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2110.04126"
  },
  {
    "id": "arXiv:2110.04151",
    "title": "Text analysis and deep learning: A network approach",
    "abstract": "Text analysis and deep learning: A network approach",
    "descriptor": "",
    "authors": [
      "Ingo Marquart"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.04151"
  },
  {
    "id": "arXiv:2110.04156",
    "title": "Showing Your Offline Reinforcement Learning Work: Online Evaluation  Budget Matters",
    "abstract": "Comments: ICML 2022, Spotlight; this https URL",
    "descriptor": "\nComments: ICML 2022, Spotlight; this https URL\n",
    "authors": [
      "Vladislav Kurenkov",
      "Sergey Kolesnikov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04156"
  },
  {
    "id": "arXiv:2110.04330",
    "title": "KG-FiD: Infusing Knowledge Graph in Fusion-in-Decoder for Open-Domain  Question Answering",
    "abstract": "Comments: Accepted by ACL 2022",
    "descriptor": "\nComments: Accepted by ACL 2022\n",
    "authors": [
      "Donghan Yu",
      "Chenguang Zhu",
      "Yuwei Fang",
      "Wenhao Yu",
      "Shuohang Wang",
      "Yichong Xu",
      "Xiang Ren",
      "Yiming Yang",
      "Michael Zeng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04330"
  },
  {
    "id": "arXiv:2110.04474",
    "title": "A Mutual learning framework for Few-shot Sound Event Detection",
    "abstract": "Comments: Accepted by ICASSP2022. arXiv admin note: text overlap with arXiv:2106.12252 by other authors",
    "descriptor": "\nComments: Accepted by ICASSP2022. arXiv admin note: text overlap with arXiv:2106.12252 by other authors\n",
    "authors": [
      "Dongchao Yang",
      "Helin Wang",
      "Yuexian Zou",
      "Zhongjie Ye",
      "Wenwu Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.04474"
  },
  {
    "id": "arXiv:2110.04627",
    "title": "Vector-quantized Image Modeling with Improved VQGAN",
    "abstract": "Comments: Accepted in ICLR 2022",
    "descriptor": "\nComments: Accepted in ICLR 2022\n",
    "authors": [
      "Jiahui Yu",
      "Xin Li",
      "Jing Yu Koh",
      "Han Zhang",
      "Ruoming Pang",
      "James Qin",
      "Alexander Ku",
      "Yuanzhong Xu",
      "Jason Baldridge",
      "Yonghui Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04627"
  },
  {
    "id": "arXiv:2110.04886",
    "title": "Multi-Class Cell Detection Using Spatial Context Representation",
    "abstract": "Multi-Class Cell Detection Using Spatial Context Representation",
    "descriptor": "",
    "authors": [
      "Shahira Abousamra",
      "David Belinsky",
      "John Van Arnam",
      "Felicia Allard",
      "Eric Yee",
      "Rajarsi Gupta",
      "Tahsin Kurc",
      "Dimitris Samaras",
      "Joel Saltz",
      "Chao Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04886"
  },
  {
    "id": "arXiv:2110.05038",
    "title": "Recurrent Model-Free RL Can Be a Strong Baseline for Many POMDPs",
    "abstract": "Comments: ICML 2022 camera ready version. Code: this https URL Project site: this https URL",
    "descriptor": "\nComments: ICML 2022 camera ready version. Code: this https URL Project site: this https URL\n",
    "authors": [
      "Tianwei Ni",
      "Benjamin Eysenbach",
      "Ruslan Salakhutdinov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.05038"
  },
  {
    "id": "arXiv:2110.07004",
    "title": "On the Convergence Theory for Hessian-Free Bilevel Algorithms",
    "abstract": "Comments: Submitted for publication",
    "descriptor": "\nComments: Submitted for publication\n",
    "authors": [
      "Daouda Sow",
      "Kaiyi Ji",
      "Yingbin Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.07004"
  },
  {
    "id": "arXiv:2110.08394",
    "title": "Adapt to Adaptation: Learning Personalization for Cross-Silo Federated  Learning",
    "abstract": "Comments: Accepted by IJCAI 2022",
    "descriptor": "\nComments: Accepted by IJCAI 2022\n",
    "authors": [
      "Jun Luo",
      "Shandong Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08394"
  },
  {
    "id": "arXiv:2110.09405",
    "title": "Capacity Region Bounds for the K user Dispersive Nonlinear Optical WDM  Channel with Peak Power Constraints",
    "abstract": "Comments: Revised version, 12 pages, 10 figures",
    "descriptor": "\nComments: Revised version, 12 pages, 10 figures\n",
    "authors": [
      "Viswanathan Ramachandran",
      "Gabriele Liga",
      "Astrid Barreiro",
      "Alex Alvarado"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.09405"
  },
  {
    "id": "arXiv:2110.10219",
    "title": "Power Line Communication and Sensing Using Time Series Forecasting",
    "abstract": "Power Line Communication and Sensing Using Time Series Forecasting",
    "descriptor": "",
    "authors": [
      "Yinjia Huo",
      "Gautham Prasad",
      "Lutz Lampe",
      "Victor C. M. Leung"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.10219"
  },
  {
    "id": "arXiv:2110.11048",
    "title": "K-Lane: Lidar Lane Dataset and Benchmark for Urban Roads and Highways",
    "abstract": "Comments: 20 pages, 20 figures, 11 tables",
    "descriptor": "\nComments: 20 pages, 20 figures, 11 tables\n",
    "authors": [
      "Donghee Paek",
      "Seung-Hyun Kong",
      "Kevin Tirta Wijaya"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.11048"
  },
  {
    "id": "arXiv:2110.12372",
    "title": "Uncertainty-Guided Lung Nodule Segmentation with Feature-Aware Attention",
    "abstract": "Comments: 10 pages, 4 figures, 30 references",
    "descriptor": "\nComments: 10 pages, 4 figures, 30 references\n",
    "authors": [
      "Han Yang",
      "Lu Shen",
      "Mengke Zhang",
      "Qiuli Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12372"
  },
  {
    "id": "arXiv:2110.14051",
    "title": "A Unified Survey on Anomaly, Novelty, Open-Set, and Out-of-Distribution  Detection: Solutions and Future Challenges",
    "abstract": "A Unified Survey on Anomaly, Novelty, Open-Set, and Out-of-Distribution  Detection: Solutions and Future Challenges",
    "descriptor": "",
    "authors": [
      "Mohammadreza Salehi",
      "Hossein Mirzaei",
      "Dan Hendrycks",
      "Yixuan Li",
      "Mohammad Hossein Rohban",
      "Mohammad Sabokrou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14051"
  },
  {
    "id": "arXiv:2111.00314",
    "title": "ECG synthesis with Neural ODE and GAN models",
    "abstract": "Comments: Proc. of the International Conference on Electrical, Computer and Energy Technologies (ICECET), 9-10 December 2021, Cape Town-South Africa",
    "descriptor": "\nComments: Proc. of the International Conference on Electrical, Computer and Energy Technologies (ICECET), 9-10 December 2021, Cape Town-South Africa\n",
    "authors": [
      "Mansura Habiba",
      "Eoin Brophy",
      "Barak A. Pearlmutter",
      "Tomas Ward"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00314"
  },
  {
    "id": "arXiv:2111.01340",
    "title": "Adapting to the Long Tail: A Meta-Analysis of Transfer Learning Research  for Language Understanding Tasks",
    "abstract": "Comments: To appear in TACL 2022. This is a pre-MIT Press publication version",
    "descriptor": "\nComments: To appear in TACL 2022. This is a pre-MIT Press publication version\n",
    "authors": [
      "Aakanksha Naik",
      "Jill Lehman",
      "Carolyn Rose"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.01340"
  },
  {
    "id": "arXiv:2111.05300",
    "title": "Double Control Variates for Gradient Estimation in Discrete Latent  Variable Models",
    "abstract": "Comments: AISTATS 2022. Source code: this https URL",
    "descriptor": "\nComments: AISTATS 2022. Source code: this https URL\n",
    "authors": [
      "Michalis K. Titsias",
      "Jiaxin Shi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.05300"
  },
  {
    "id": "arXiv:2111.05791",
    "title": "Distribution-Invariant Differential Privacy",
    "abstract": "Distribution-Invariant Differential Privacy",
    "descriptor": "",
    "authors": [
      "Xuan Bi",
      "Xiaotong Shen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2111.05791"
  },
  {
    "id": "arXiv:2111.06069",
    "title": "CodEx: A Modular Framework for Joint Temporal De-blurring and  Tomographic Reconstruction",
    "abstract": "CodEx: A Modular Framework for Joint Temporal De-blurring and  Tomographic Reconstruction",
    "descriptor": "",
    "authors": [
      "Soumendu Majee",
      "Selin Aslan",
      "Doga Gursoy",
      "Charles A. Bouman"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.06069"
  },
  {
    "id": "arXiv:2111.06799",
    "title": "Deciphering Speech: a Zero-Resource Approach to Cross-Lingual Transfer  in ASR",
    "abstract": "Comments: Submitted to Interspeech 2022",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Ondrej Klejch",
      "Electra Wallington",
      "Peter Bell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.06799"
  },
  {
    "id": "arXiv:2111.08282",
    "title": "Self-supervised Re-renderable Facial Albedo Reconstruction from Single  Image",
    "abstract": "Self-supervised Re-renderable Facial Albedo Reconstruction from Single  Image",
    "descriptor": "",
    "authors": [
      "Mingxin Yang",
      "Jianwei Guo",
      "Zhanglin Cheng",
      "Xiaopeng Zhang",
      "Dong-Ming Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2111.08282"
  },
  {
    "id": "arXiv:2111.08708",
    "title": "Exploring dual-attention mechanism with multi-scale feature extraction  scheme for skin lesion segmentation",
    "abstract": "Exploring dual-attention mechanism with multi-scale feature extraction  scheme for skin lesion segmentation",
    "descriptor": "",
    "authors": [
      "G Jignesh Chowdary",
      "G V S N Durga Yathisha",
      "Suganya G",
      "Premalatha M"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.08708"
  },
  {
    "id": "arXiv:2111.11656",
    "title": "Few-Shot Object Detection via Association and DIscrimination",
    "abstract": "Comments: NeurIPS 2021 Camera Ready",
    "descriptor": "\nComments: NeurIPS 2021 Camera Ready\n",
    "authors": [
      "Yuhang Cao",
      "Jiaqi Wang",
      "Ying Jin",
      "Tong Wu",
      "Kai Chen",
      "Ziwei Liu",
      "Dahua Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.11656"
  },
  {
    "id": "arXiv:2111.12790",
    "title": "Temporal Effects on Pre-trained Models for Language Processing Tasks",
    "abstract": "Comments: TACL, pre-MIT press publication version",
    "descriptor": "\nComments: TACL, pre-MIT press publication version\n",
    "authors": [
      "Oshin Agarwal",
      "Ani Nenkova"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.12790"
  },
  {
    "id": "arXiv:2111.14460",
    "title": "A new method for estimating the real roots of real differentiable  functions",
    "abstract": "Comments: 11 pages",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Hassan Khandani",
      "Farshid Khojasteh"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.14460"
  },
  {
    "id": "arXiv:2111.14819",
    "title": "Point-BERT: Pre-training 3D Point Cloud Transformers with Masked Point  Modeling",
    "abstract": "Comments: Accepted to CVPR 2022, Project page: this https URL",
    "descriptor": "\nComments: Accepted to CVPR 2022, Project page: this https URL\n",
    "authors": [
      "Xumin Yu",
      "Lulu Tang",
      "Yongming Rao",
      "Tiejun Huang",
      "Jie Zhou",
      "Jiwen Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.14819"
  },
  {
    "id": "arXiv:2111.14844",
    "title": "Evaluation of Machine Learning Techniques for Forecast Uncertainty  Quantification",
    "abstract": "Comments: preprint",
    "descriptor": "\nComments: preprint\n",
    "authors": [
      "Maximiliano A. Sacco",
      "Juan J. Ruiz",
      "Manuel Pulido",
      "Pierre Tandeo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2111.14844"
  },
  {
    "id": "arXiv:2112.00733",
    "title": "Efficient Symptom Inquiring and Diagnosis via Adaptive Alignment of  Reinforcement Learning and Classification",
    "abstract": "Efficient Symptom Inquiring and Diagnosis via Adaptive Alignment of  Reinforcement Learning and Classification",
    "descriptor": "",
    "authors": [
      "Hongyi Yuan",
      "Sheng Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.00733"
  },
  {
    "id": "arXiv:2112.01077",
    "title": "Blind Super-resolution of Point Sources via Projected Gradient Descent",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2110.02478",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2110.02478\n",
    "authors": [
      "Sihan Mao",
      "Jinchi Chen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.01077"
  },
  {
    "id": "arXiv:2112.02249",
    "title": "Dual-Flow Transformation Network for Deformable Image Registration with  Region Consistency Constraint",
    "abstract": "Comments: This paper have some errors for experiment results, thus we want to withdraw this paper. We will update the revised paper. This paper is not published in any journal or conference",
    "descriptor": "\nComments: This paper have some errors for experiment results, thus we want to withdraw this paper. We will update the revised paper. This paper is not published in any journal or conference\n",
    "authors": [
      "Xinke Ma",
      "Yibo Yang",
      "Yong Xia",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.02249"
  },
  {
    "id": "arXiv:2112.02505",
    "title": "Causal Distillation for Language Models",
    "abstract": "Comments: 7 pages, 2 figures",
    "descriptor": "\nComments: 7 pages, 2 figures\n",
    "authors": [
      "Zhengxuan Wu",
      "Atticus Geiger",
      "Josh Rozner",
      "Elisa Kreiss",
      "Hanson Lu",
      "Thomas Icard",
      "Christopher Potts",
      "Noah D. Goodman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.02505"
  },
  {
    "id": "arXiv:2112.03860",
    "title": "Differentiable Gaussianization Layers for Inverse Problems Regularized  by Deep Generative Models",
    "abstract": "Comments: 26 pages, 15 figures, 9 tables",
    "descriptor": "\nComments: 26 pages, 15 figures, 9 tables\n",
    "authors": [
      "Dongzhuo Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03860"
  },
  {
    "id": "arXiv:2112.05965",
    "title": "Parallelized Robust Distributed Model Predictive Control in the Presence  of Coupled State Constraints",
    "abstract": "Parallelized Robust Distributed Model Predictive Control in the Presence  of Coupled State Constraints",
    "descriptor": "",
    "authors": [
      "Adrian Wiltz",
      "Fei Chen",
      "Dimos V. Dimarogonas"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.05965"
  },
  {
    "id": "arXiv:2112.06164",
    "title": "An extended MMP algorithm: wavefront and cut-locus on a convex  polyhedron",
    "abstract": "Comments: To appear in International Journal of Computational Geometry & Applications",
    "descriptor": "\nComments: To appear in International Journal of Computational Geometry & Applications\n",
    "authors": [
      "Kazuma Tateiri",
      "Toru Ohmoto"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2112.06164"
  },
  {
    "id": "arXiv:2112.06398",
    "title": "Shaping Visual Representations with Attributes for Few-Shot Recognition",
    "abstract": "Comments: accepted by IEEE Signal Process. Lett",
    "descriptor": "\nComments: accepted by IEEE Signal Process. Lett\n",
    "authors": [
      "Haoxing Chen",
      "Huaxiong Li",
      "Yaohui Li",
      "Chunlin Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.06398"
  },
  {
    "id": "arXiv:2112.07120",
    "title": "Simple Coding Techniques for Many-Hop Relaying",
    "abstract": "Comments: IEEE Transactions on Information Theory",
    "descriptor": "\nComments: IEEE Transactions on Information Theory\n",
    "authors": [
      "Yan Hao Ling",
      "Jonathan Scarlett"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.07120"
  },
  {
    "id": "arXiv:2112.07812",
    "title": "Structure-Aware Image Segmentation with Homotopy Warping",
    "abstract": "Comments: 19 pages, 11 figures",
    "descriptor": "\nComments: 19 pages, 11 figures\n",
    "authors": [
      "Xiaoling Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2112.07812"
  },
  {
    "id": "arXiv:2112.08935",
    "title": "MVSS-Net: Multi-View Multi-Scale Supervised Networks for Image  Manipulation Detection",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2104.06832 Accepted by T-PAMI",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2104.06832 Accepted by T-PAMI\n",
    "authors": [
      "Chengbo Dong",
      "Xinru Chen",
      "Ruohan Hu",
      "Juan Cao",
      "Xirong Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08935"
  },
  {
    "id": "arXiv:2112.10769",
    "title": "Logarithmic Unbiased Quantization: Simple 4-bit Training in Deep  Learning",
    "abstract": "Comments: Main Changes: 1) FNT learning rate (sec 4.2) 2) Implementation details (sec 4.3), including solving data movement bottleneck. 3) Additional experiments",
    "descriptor": "\nComments: Main Changes: 1) FNT learning rate (sec 4.2) 2) Implementation details (sec 4.3), including solving data movement bottleneck. 3) Additional experiments\n",
    "authors": [
      "Brian Chmiel",
      "Ron Banner",
      "Elad Hoffer",
      "Hilla Ben Yaacov",
      "Daniel Soudry"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.10769"
  },
  {
    "id": "arXiv:2112.13279",
    "title": "On quantum algorithms for the Schr\u00f6dinger equation in the  semi-classical regime",
    "abstract": "On quantum algorithms for the Schr\u00f6dinger equation in the  semi-classical regime",
    "descriptor": "",
    "authors": [
      "Shi Jin",
      "Xiantao Li",
      "Nana Liu"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.13279"
  },
  {
    "id": "arXiv:2112.15217",
    "title": "VisRecall: Quantifying Information Visualisation Recallability via  Question Answering",
    "abstract": "Comments: 10 pages, 10 figures",
    "descriptor": "\nComments: 10 pages, 10 figures\n",
    "authors": [
      "Yao Wang",
      "Chuhan Jiao",
      "Mihai B\u00e2ce",
      "Andreas Bulling"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2112.15217"
  },
  {
    "id": "arXiv:2112.15287",
    "title": "Distributed Random Reshuffling over Networks",
    "abstract": "Comments: 17 pages, 7 figures",
    "descriptor": "\nComments: 17 pages, 7 figures\n",
    "authors": [
      "Kun Huang",
      "Xiao Li",
      "Andre Milzarek",
      "Shi Pu",
      "Junwen Qiu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2112.15287"
  },
  {
    "id": "arXiv:2201.00402",
    "title": "A General Framework for Evaluating Robustness of Combinatorial  Optimization Solvers on Graphs",
    "abstract": "A General Framework for Evaluating Robustness of Combinatorial  Optimization Solvers on Graphs",
    "descriptor": "",
    "authors": [
      "Han Lu",
      "Zenan Li",
      "Runzhong Wang",
      "Qibing Ren",
      "Junchi Yan",
      "Xiaokang Yang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.00402"
  },
  {
    "id": "arXiv:2201.01337",
    "title": "ZeroBERTo: Leveraging Zero-Shot Text Classification by Topic Modeling",
    "abstract": "Comments: Accepted at PROPOR 2022: 15th International Conference on Computational Processing of Portuguese",
    "descriptor": "\nComments: Accepted at PROPOR 2022: 15th International Conference on Computational Processing of Portuguese\n",
    "authors": [
      "Alexandre Alcoforado",
      "Thomas Palmeira Ferraz",
      "Rodrigo Gerber",
      "Enzo Bustos",
      "Andr\u00e9 Seidel Oliveira",
      "Bruno Miguel Veloso",
      "Fabio Levy Siqueira",
      "Anna Helena Reali Costa"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.01337"
  },
  {
    "id": "arXiv:2201.01385",
    "title": "DR-STRaNGe: End-to-End System Design for DRAM-based True Random Number  Generators",
    "abstract": "DR-STRaNGe: End-to-End System Design for DRAM-based True Random Number  Generators",
    "descriptor": "",
    "authors": [
      "F. Nisa Bostanc\u0131",
      "Ataberk Olgun",
      "Lois Orosa",
      "A. Giray Ya\u011fl\u0131k\u00e7\u0131",
      "Jeremie S. Kim",
      "Hasan Hassan",
      "O\u011fuz Ergin",
      "Onur Mutlu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2201.01385"
  },
  {
    "id": "arXiv:2201.01749",
    "title": "Integrability and geometry of the Wynn recurrence",
    "abstract": "Comments: 17 pages, 7 figures; v2 presentation improved +2 pages",
    "descriptor": "\nComments: 17 pages, 7 figures; v2 presentation improved +2 pages\n",
    "authors": [
      "Adam Doliwa",
      "Artur Siemaszko"
    ],
    "subjectives": [
      "Exactly Solvable and Integrable Systems (nlin.SI)",
      "Mathematical Physics (math-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2201.01749"
  },
  {
    "id": "arXiv:2201.02006",
    "title": "A comparison of different methods of identifying publications related to  the United Nations Sustainable Development Goals: Case Study of SDG 13:  Climate Action",
    "abstract": "A comparison of different methods of identifying publications related to  the United Nations Sustainable Development Goals: Case Study of SDG 13:  Climate Action",
    "descriptor": "",
    "authors": [
      "Philip James Purnell"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2201.02006"
  },
  {
    "id": "arXiv:2201.03229",
    "title": "Wind Park Power Prediction: Attention-Based Graph Networks and Deep  Learning to Capture Wake Losses",
    "abstract": "Comments: 12 pages, 7 figures, 1 appendix, in review process",
    "descriptor": "\nComments: 12 pages, 7 figures, 1 appendix, in review process\n",
    "authors": [
      "Lars \u00d8degaard Bentsen",
      "Narada Dilp Warakagoda",
      "Roy Stenbro",
      "Paal Engelstad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.03229"
  },
  {
    "id": "arXiv:2201.04038",
    "title": "DDG-DA: Data Distribution Generation for Predictable Concept Drift  Adaptation",
    "abstract": "Comments: Accepted by AAAI'22",
    "descriptor": "\nComments: Accepted by AAAI'22\n",
    "authors": [
      "Wendi Li",
      "Xiao Yang",
      "Weiqing Liu",
      "Yingce Xia",
      "Jiang Bian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "General Finance (q-fin.GN)"
    ],
    "url": "https://arxiv.org/abs/2201.04038"
  },
  {
    "id": "arXiv:2201.06686",
    "title": "Unpaired Referring Expression Grounding via Bidirectional Cross-Modal  Matching",
    "abstract": "Comments: 9 pages, 7 figures",
    "descriptor": "\nComments: 9 pages, 7 figures\n",
    "authors": [
      "Hengcan Shi",
      "Munawar Hayat",
      "Jianfei Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.06686"
  },
  {
    "id": "arXiv:2201.08363",
    "title": "Physics-informed neural networks for modeling rate- and  temperature-dependent plasticity",
    "abstract": "Physics-informed neural networks for modeling rate- and  temperature-dependent plasticity",
    "descriptor": "",
    "authors": [
      "Rajat Arora",
      "Pratik Kakkar",
      "Biswadip Dey",
      "Amit Chakraborty"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08363"
  },
  {
    "id": "arXiv:2201.09050",
    "title": "Scheduling Policies for Stability and Optimal Server Running Cost in  Cloud Computing Platforms",
    "abstract": "Scheduling Policies for Stability and Optimal Server Running Cost in  Cloud Computing Platforms",
    "descriptor": "",
    "authors": [
      "Haritha K",
      "Chandramani Singh"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2201.09050"
  },
  {
    "id": "arXiv:2201.10053",
    "title": "Learning Resource Allocation Policies from Observational Data with an  Application to Homeless Services Delivery",
    "abstract": "Comments: 20 pages, 13 figures, Accepted at ACM Conference on Fairness, Accountability, and Transparency (ACM FAccT)",
    "descriptor": "\nComments: 20 pages, 13 figures, Accepted at ACM Conference on Fairness, Accountability, and Transparency (ACM FAccT)\n",
    "authors": [
      "Aida Rahmattalabi",
      "Phebe Vayanos",
      "Kathryn Dullerud",
      "Eric Rice"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2201.10053"
  },
  {
    "id": "arXiv:2201.10129",
    "title": "Convergence of Invariant Graph Networks",
    "abstract": "Comments: 28 pages, 11 figures",
    "descriptor": "\nComments: 28 pages, 11 figures\n",
    "authors": [
      "Chen Cai",
      "Yusu Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.10129"
  },
  {
    "id": "arXiv:2201.11542",
    "title": "An improved judgement algorithm of point in-out convex polygons",
    "abstract": "Comments: in Chinese language. Problem of font was fixed",
    "descriptor": "\nComments: in Chinese language. Problem of font was fixed\n",
    "authors": [
      "Sun Yixuan",
      "Zhu Zhehao"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2201.11542"
  },
  {
    "id": "arXiv:2201.12032",
    "title": "Neural Approximation of Extended Persistent Homology on Graphs",
    "abstract": "Neural Approximation of Extended Persistent Homology on Graphs",
    "descriptor": "",
    "authors": [
      "Zuoyu Yan",
      "Tengfei Ma",
      "Liangcai Gao",
      "Zhi Tang",
      "Yusu Wang",
      "Chao Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12032"
  },
  {
    "id": "arXiv:2201.12204",
    "title": "From data to functa: Your data point is a function and you can treat it  like one",
    "abstract": "From data to functa: Your data point is a function and you can treat it  like one",
    "descriptor": "",
    "authors": [
      "Emilien Dupont",
      "Hyunjik Kim",
      "S. M. Ali Eslami",
      "Danilo Rezende",
      "Dan Rosenbaum"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12204"
  },
  {
    "id": "arXiv:2201.12795",
    "title": "Training Thinner and Deeper Neural Networks: Jumpstart Regularization",
    "abstract": "Comments: CPAIOR 2022 (to appear)",
    "descriptor": "\nComments: CPAIOR 2022 (to appear)\n",
    "authors": [
      "Carles Riera",
      "Camilo Rey",
      "Thiago Serra",
      "Eloi Puertas",
      "Oriol Pujol"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2201.12795"
  },
  {
    "id": "arXiv:2202.00048",
    "title": "Single Time-scale Actor-critic Method to Solve the Linear Quadratic  Regulator with Convergence Guarantees",
    "abstract": "Comments: 4 figures",
    "descriptor": "\nComments: 4 figures\n",
    "authors": [
      "Mo Zhou",
      "Jianfeng Lu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00048"
  },
  {
    "id": "arXiv:2202.00667",
    "title": "Deep Kernelized Dense Geometric Matching",
    "abstract": "Deep Kernelized Dense Geometric Matching",
    "descriptor": "",
    "authors": [
      "Johan Edstedt",
      "M\u00e5rten Wadenb\u00e4ck",
      "Michael Felsberg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00667"
  },
  {
    "id": "arXiv:2202.02142",
    "title": "Deep invariant networks with differentiable augmentation layers",
    "abstract": "Deep invariant networks with differentiable augmentation layers",
    "descriptor": "",
    "authors": [
      "C\u00e9dric Rommel",
      "Thomas Moreau",
      "Alexandre Gramfort"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02142"
  },
  {
    "id": "arXiv:2202.02163",
    "title": "COIL: Constrained Optimization in Learned Latent Space: Learning  Representations for Valid Solutions",
    "abstract": "Comments: Genetic and Evolutionary Computation Conference Companion (GECCO '22 Companion). ACM, Boston, USA, 8 pages",
    "descriptor": "\nComments: Genetic and Evolutionary Computation Conference Companion (GECCO '22 Companion). ACM, Boston, USA, 8 pages\n",
    "authors": [
      "Peter J Bentley",
      "Soo Ling Lim",
      "Adam Gaier",
      "Linh Tran"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02163"
  },
  {
    "id": "arXiv:2202.02387",
    "title": "Automatic Identification of Self-Admitted Technical Debt from Four  Different Sources",
    "abstract": "Automatic Identification of Self-Admitted Technical Debt from Four  Different Sources",
    "descriptor": "",
    "authors": [
      "Yikun Li",
      "Mohamed Soliman",
      "Paris Avgeriou"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02387"
  },
  {
    "id": "arXiv:2202.04139",
    "title": "Simplified Graph Convolution with Heterophily",
    "abstract": "Simplified Graph Convolution with Heterophily",
    "descriptor": "",
    "authors": [
      "Sudhanshu Chanpuriya",
      "Cameron Musco"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2202.04139"
  },
  {
    "id": "arXiv:2202.04433",
    "title": "Co-WIN: Really Winning? Analysing Inequity in India's Vaccination  Response",
    "abstract": "Co-WIN: Really Winning? Analysing Inequity in India's Vaccination  Response",
    "descriptor": "",
    "authors": [
      "Tanvi Karandikar",
      "Avinash Prabhu",
      "Mehul Mathur",
      "Megha Arora",
      "Hemank Lamba",
      "Ponnurangam Kumaraguru"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.04433"
  },
  {
    "id": "arXiv:2202.04514",
    "title": "A Model-Agnostic Causal Learning Framework for Recommendation using  Search Data",
    "abstract": "Comments: accepted by The Web Conference 2022",
    "descriptor": "\nComments: accepted by The Web Conference 2022\n",
    "authors": [
      "Zihua Si",
      "Xueran Han",
      "Xiao Zhang",
      "Jun Xu",
      "Yue Yin",
      "Yang Song",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.04514"
  },
  {
    "id": "arXiv:2202.05146",
    "title": "EquiBind: Geometric Deep Learning for Drug Binding Structure Prediction",
    "abstract": "Comments: 39th International Conference on Machine Learning (ICML 2022). Also accepted at ICLR 2022 GTRL and at ICLR 2022 MLDD as spotlight",
    "descriptor": "\nComments: 39th International Conference on Machine Learning (ICML 2022). Also accepted at ICLR 2022 GTRL and at ICLR 2022 MLDD as spotlight\n",
    "authors": [
      "Hannes St\u00e4rk",
      "Octavian-Eugen Ganea",
      "Lagnajit Pattanaik",
      "Regina Barzilay",
      "Tommi Jaakkola"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05146"
  },
  {
    "id": "arXiv:2202.05189",
    "title": "Understanding Rare Spurious Correlations in Neural Networks",
    "abstract": "Understanding Rare Spurious Correlations in Neural Networks",
    "descriptor": "",
    "authors": [
      "Yao-Yuan Yang",
      "Chi-Ning Chou",
      "Kamalika Chaudhuri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.05189"
  },
  {
    "id": "arXiv:2202.06123",
    "title": "How accurate models of human behavior are needed for human-robot  interaction? For automated driving?",
    "abstract": "Comments: Accepted for publication in IEEE Robotics & Automation Magazine. In press",
    "descriptor": "\nComments: Accepted for publication in IEEE Robotics & Automation Magazine. In press\n",
    "authors": [
      "Gustav Markkula",
      "Mehmet Dogar"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.06123"
  },
  {
    "id": "arXiv:2202.06385",
    "title": "Sample-Efficient Reinforcement Learning with loglog(T) Switching Cost",
    "abstract": "Comments: 44 pages, 1 figure",
    "descriptor": "\nComments: 44 pages, 1 figure\n",
    "authors": [
      "Dan Qiao",
      "Ming Yin",
      "Ming Min",
      "Yu-Xiang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.06385"
  },
  {
    "id": "arXiv:2202.07720",
    "title": "Active Uncertainty Reduction for Human-Robot Interaction: An Implicit  Dual Control Approach",
    "abstract": "Comments: Workshop on the Algorithmic Foundations of Robotics (WAFR) 2022",
    "descriptor": "\nComments: Workshop on the Algorithmic Foundations of Robotics (WAFR) 2022\n",
    "authors": [
      "Haimin Hu",
      "Jaime F. Fisac"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.07720"
  },
  {
    "id": "arXiv:2202.09497",
    "title": "Gradient Estimation with Discrete Stein Operators",
    "abstract": "Gradient Estimation with Discrete Stein Operators",
    "descriptor": "",
    "authors": [
      "Jiaxin Shi",
      "Yuhao Zhou",
      "Jessica Hwang",
      "Michalis K. Titsias",
      "Lester Mackey"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.09497"
  },
  {
    "id": "arXiv:2202.09550",
    "title": "Student Dangerous Behavior Detection in School",
    "abstract": "Comments: 5 pages, 3 figures",
    "descriptor": "\nComments: 5 pages, 3 figures\n",
    "authors": [
      "Huayi Zhou",
      "Fei Jiang",
      "Hongtao Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.09550"
  },
  {
    "id": "arXiv:2202.09724",
    "title": "Bayes-Optimal Classifiers under Group Fairness",
    "abstract": "Bayes-Optimal Classifiers under Group Fairness",
    "descriptor": "",
    "authors": [
      "Xianli Zeng",
      "Edgar Dobriban",
      "Guang Cheng"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.09724"
  },
  {
    "id": "arXiv:2202.11857",
    "title": "Complexity Results on Untangling Red-Blue Matchings",
    "abstract": "Comments: 26 pages, 25 figures, accepted at EuroCG 2022",
    "descriptor": "\nComments: 26 pages, 25 figures, accepted at EuroCG 2022\n",
    "authors": [
      "Arun Kumar Das",
      "Sandip Das",
      "Guilherme D. da Fonseca",
      "Yan Gerard",
      "Bastien Rivier"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2202.11857"
  },
  {
    "id": "arXiv:2202.12165",
    "title": "Transformers in Medical Image Analysis: A Review",
    "abstract": "Transformers in Medical Image Analysis: A Review",
    "descriptor": "",
    "authors": [
      "Kelei He",
      "Chen Gan",
      "Zhuoyuan Li",
      "Islem Rekik",
      "Zihao Yin",
      "Wen Ji",
      "Yang Gao",
      "Qian Wang",
      "Junfeng Zhang",
      "Dinggang Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.12165"
  },
  {
    "id": "arXiv:2202.13252",
    "title": "The Quest for a Common Model of the Intelligent Decision Maker",
    "abstract": "Comments: Will appear as an extended abstract at the fifth Multi-disciplinary Conference on Reinforcement Learning and Decision Making, held in Providence, Rhode Island, June 8-11, 2022",
    "descriptor": "\nComments: Will appear as an extended abstract at the fifth Multi-disciplinary Conference on Reinforcement Learning and Decision Making, held in Providence, Rhode Island, June 8-11, 2022\n",
    "authors": [
      "Richard S. Sutton"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.13252"
  },
  {
    "id": "arXiv:2202.13589",
    "title": "Unsupervised Point Cloud Representation Learning with Deep Neural  Networks: A Survey",
    "abstract": "Comments: 16 pages",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Aoran Xiao",
      "Jiaxing Huang",
      "Dayan Guan",
      "Xiaoqin Zhang",
      "Shijian Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.13589"
  },
  {
    "id": "arXiv:2203.00553",
    "title": "Global-Local Regularization Via Distributional Robustness",
    "abstract": "Comments: 29 pages, 7 figures",
    "descriptor": "\nComments: 29 pages, 7 figures\n",
    "authors": [
      "Hoang Phan",
      "Trung Le",
      "Trung Phung",
      "Tuan Anh Bui",
      "Nhat Ho",
      "Dinh Phung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.00553"
  },
  {
    "id": "arXiv:2203.01502",
    "title": "NeW CRFs: Neural Window Fully-connected CRFs for Monocular Depth  Estimation",
    "abstract": "Comments: Accepted by CVPR 2022",
    "descriptor": "\nComments: Accepted by CVPR 2022\n",
    "authors": [
      "Weihao Yuan",
      "Xiaodong Gu",
      "Zuozhuo Dai",
      "Siyu Zhu",
      "Ping Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.01502"
  },
  {
    "id": "arXiv:2203.03317",
    "title": "Depth-Independent Depth Completion via Least Square Estimation",
    "abstract": "Depth-Independent Depth Completion via Least Square Estimation",
    "descriptor": "",
    "authors": [
      "Xianze Fang",
      "Yunkai Wang",
      "Zexi Chen",
      "Yue Wang",
      "Rong Xiong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.03317"
  },
  {
    "id": "arXiv:2203.04163",
    "title": "Localization Schemes: A Framework for Proving Mixing Bounds for Markov  Chains",
    "abstract": "Comments: 62 pages, 1 figure, fixed mistakes in an earlier version",
    "descriptor": "\nComments: 62 pages, 1 figure, fixed mistakes in an earlier version\n",
    "authors": [
      "Yuansi Chen",
      "Ronen Eldan"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Data Structures and Algorithms (cs.DS)",
      "Mathematical Physics (math-ph)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2203.04163"
  },
  {
    "id": "arXiv:2203.05585",
    "title": "End-to-End Learning to Grasp via Sampling from Object Point Clouds",
    "abstract": "Comments: 8 pages, under review for RA-L/IROS 2022",
    "descriptor": "\nComments: 8 pages, under review for RA-L/IROS 2022\n",
    "authors": [
      "Antonio Alliegro",
      "Martin Rudorfer",
      "Fabio Frattin",
      "Ale\u0161 Leonardis",
      "Tatiana Tommasi"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.05585"
  },
  {
    "id": "arXiv:2203.05646",
    "title": "Koopman Methods for Estimation of Animal Motions over Unknown  Submanifolds",
    "abstract": "Koopman Methods for Estimation of Animal Motions over Unknown  Submanifolds",
    "descriptor": "",
    "authors": [
      "Nathan Powell",
      "Bowei Liu",
      "Jia Guo",
      "Sai Tej Parachuri",
      "Andrew J. Kurdila"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.05646"
  },
  {
    "id": "arXiv:2203.07411",
    "title": "On Connecting Deep Trigonometric Networks with Deep Gaussian Processes:  Covariance, Expressivity, and Neural Tangent Kernel",
    "abstract": "Comments: 22 pages; version 2 contains new analysis on finite width effect on kernel and NTK, and more connection to other works",
    "descriptor": "\nComments: 22 pages; version 2 contains new analysis on finite width effect on kernel and NTK, and more connection to other works\n",
    "authors": [
      "Chi-Ken Lu",
      "Patrick Shafto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.07411"
  },
  {
    "id": "arXiv:2203.07831",
    "title": "Graph Neural Network Sensitivity Under Probabilistic Error Model",
    "abstract": "Comments: 7 pages, 3 figures",
    "descriptor": "\nComments: 7 pages, 3 figures\n",
    "authors": [
      "Xinjue Wang",
      "Esa Ollila",
      "Sergiy A. Vorobyov"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07831"
  },
  {
    "id": "arXiv:2203.09257",
    "title": "Contrastive Learning for Cross-Domain Open World Recognition",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Francesco Cappio Borlino",
      "Silvia Bucci",
      "Tatiana Tommasi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.09257"
  },
  {
    "id": "arXiv:2203.10036",
    "title": "On the Generalization Mystery in Deep Learning",
    "abstract": "On the Generalization Mystery in Deep Learning",
    "descriptor": "",
    "authors": [
      "Satrajit Chatterjee",
      "Piotr Zielinski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.10036"
  },
  {
    "id": "arXiv:2203.10365",
    "title": "Domain Representative Keywords Selection: A Probabilistic Approach",
    "abstract": "Domain Representative Keywords Selection: A Probabilistic Approach",
    "descriptor": "",
    "authors": [
      "Pritom Saha Akash",
      "Jie Huang",
      "Kevin Chen-Chuan Chang",
      "Yunyao Li",
      "Lucian Popa",
      "ChengXiang Zhai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2203.10365"
  },
  {
    "id": "arXiv:2203.10991",
    "title": "Optimal Fine-Grained N:M sparsity for Activations and Neural Gradients",
    "abstract": "Comments: Main changes: 1) Experiments (see also experiments in the appendix). 2) Overhead analysis (Tab 3)",
    "descriptor": "\nComments: Main changes: 1) Experiments (see also experiments in the appendix). 2) Overhead analysis (Tab 3)\n",
    "authors": [
      "Brian Chmiel",
      "Itay Hubara",
      "Ron Banner",
      "Daniel Soudry"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.10991"
  },
  {
    "id": "arXiv:2203.11156",
    "title": "Operator Sketching for Deep Unrolling Networks",
    "abstract": "Operator Sketching for Deep Unrolling Networks",
    "descriptor": "",
    "authors": [
      "Junqi Tang",
      "Subhadip Mukherjee",
      "Carola-Bibiane Sch\u00f6nlieb"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.11156"
  },
  {
    "id": "arXiv:2203.11387",
    "title": "Privacy Rarely Considered: Exploring Considerations in the Adoption of  Third-Party Services by Websites",
    "abstract": "Comments: 24 pages, 8 figures, 7 tables",
    "descriptor": "\nComments: 24 pages, 8 figures, 7 tables\n",
    "authors": [
      "Christine Utz",
      "Sabrina Amft",
      "Martin Degeling",
      "Thorsten Holz",
      "Sascha Fahl",
      "Florian Schaub"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.11387"
  },
  {
    "id": "arXiv:2203.12000",
    "title": "Text Transformations in Contrastive Self-Supervised Learning: A Review",
    "abstract": "Comments: Camera-ready version for IJCAI'22 Survey Track",
    "descriptor": "\nComments: Camera-ready version for IJCAI'22 Survey Track\n",
    "authors": [
      "Amrita Bhattacharjee",
      "Mansooreh Karami",
      "Huan Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.12000"
  },
  {
    "id": "arXiv:2203.12245",
    "title": "Quantitative Evaluation Approach for Translation of Perceptual  Soundscape Attributes: Initial Application to the Thai Language",
    "abstract": "Comments: Under review for Applied Acoustics (Special Issue on Soundscape Attributes Translation: Current Projects and Challenges)",
    "descriptor": "\nComments: Under review for Applied Acoustics (Special Issue on Soundscape Attributes Translation: Current Projects and Challenges)\n",
    "authors": [
      "Karn N. Watcharasupat",
      "Sureenate Jaratjarungkiat",
      "Bhan Lam",
      "Sujinat Jitwiriyanont",
      "Kanyanut Akaratham",
      "Kenneth Ooi",
      "Zhen-Ting Ong",
      "Titima Suthiwan",
      "Nitipong Pichetpan",
      "Monthita Rojtinnakorn",
      "Woon-Seng Gan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2203.12245"
  },
  {
    "id": "arXiv:2203.12483",
    "title": "Geometry of finite-time thermodynamic cycles with anisotropic thermal  fluctuations",
    "abstract": "Comments: 6 pages, 2 figures. arXiv admin note: text overlap with arXiv:2108.00334",
    "descriptor": "\nComments: 6 pages, 2 figures. arXiv admin note: text overlap with arXiv:2108.00334\n",
    "authors": [
      "Olga Movilla Miangolarra",
      "Amirhossein Taghvaei",
      "Yongxin Chen",
      "Tryphon T. Georgiou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Statistical Mechanics (cond-mat.stat-mech)"
    ],
    "url": "https://arxiv.org/abs/2203.12483"
  },
  {
    "id": "arXiv:2203.12667",
    "title": "Vision-and-Language Navigation: A Survey of Tasks, Methods, and Future  Directions",
    "abstract": "Comments: 19 pages. Accepted to ACL 2022",
    "descriptor": "\nComments: 19 pages. Accepted to ACL 2022\n",
    "authors": [
      "Jing Gu",
      "Eliana Stefani",
      "Qi Wu",
      "Jesse Thomason",
      "Xin Eric Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.12667"
  },
  {
    "id": "arXiv:2203.13517",
    "title": "Sparse Federated Learning with Hierarchical Personalized Models",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2107.05330",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2107.05330\n",
    "authors": [
      "Xiaofeng Liu",
      "Yinchuan Li",
      "Yunfeng Shao",
      "Qing Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13517"
  },
  {
    "id": "arXiv:2203.14601",
    "title": "Bribes to Miners: Evidence from Ethereum",
    "abstract": "Bribes to Miners: Evidence from Ethereum",
    "descriptor": "",
    "authors": [
      "Xiaotong Sun"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computational Finance (q-fin.CP)"
    ],
    "url": "https://arxiv.org/abs/2203.14601"
  },
  {
    "id": "arXiv:2203.15118",
    "title": "LiDAR Snowfall Simulation for Robust 3D Object Detection",
    "abstract": "Comments: Oral at CVPR 2022",
    "descriptor": "\nComments: Oral at CVPR 2022\n",
    "authors": [
      "Martin Hahner",
      "Christos Sakaridis",
      "Mario Bijelic",
      "Felix Heide",
      "Fisher Yu",
      "Dengxin Dai",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15118"
  },
  {
    "id": "arXiv:2203.16616",
    "title": "Knowledge-based Entity Prediction for Improved Machine Perception in  Autonomous Systems",
    "abstract": "Comments: 6 pages, 4 figures",
    "descriptor": "\nComments: 6 pages, 4 figures\n",
    "authors": [
      "Ruwan Wickramarachchi",
      "Cory Henson",
      "Amit Sheth"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.16616"
  },
  {
    "id": "arXiv:2203.16894",
    "title": "Analysis and Optimization of A Double-IRS Cooperatively Assisted System  with A Quasi-Static Phase Shift Design",
    "abstract": "Comments: 44 pages, 10 figures. To appear in SPAWC 2022;This work is submitted to IEEE Trans.Wireless Commun. (under major revision)",
    "descriptor": "\nComments: 44 pages, 10 figures. To appear in SPAWC 2022;This work is submitted to IEEE Trans.Wireless Commun. (under major revision)\n",
    "authors": [
      "Gengfa Ding",
      "Feng Yang",
      "Lianghui Ding",
      "Ying Cui"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.16894"
  },
  {
    "id": "arXiv:2203.17259",
    "title": "To ArXiv or not to ArXiv: A Study Quantifying Pros and Cons of Posting  Preprints Online",
    "abstract": "Comments: 17 pages, 3 figures",
    "descriptor": "\nComments: 17 pages, 3 figures\n",
    "authors": [
      "Charvi Rastogi",
      "Ivan Stelmakh",
      "Xinwei Shen",
      "Marina Meila",
      "Federico Echenique",
      "Shuchi Chawla",
      "Nihar B. Shah"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2203.17259"
  },
  {
    "id": "arXiv:2204.00833",
    "title": "PixelFolder: An Efficient Progressive Pixel Synthesis Network for Image  Generation",
    "abstract": "Comments: 11 pages, 7 figures",
    "descriptor": "\nComments: 11 pages, 7 figures\n",
    "authors": [
      "Jing He",
      "Yiyi Zhou",
      "Qi Zhang",
      "Jun Peng",
      "Yunhang Shen",
      "Xiaoshuai Sun",
      "Chao Chen",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2204.00833"
  },
  {
    "id": "arXiv:2204.00898",
    "title": "Hierarchical Reinforcement Learning under Mixed Observability",
    "abstract": "Comments: Accepted at the 15th International Workshop on the Algorithmic Foundations of Robotics (WAFR) 2022, University of Maryland, College Park. The first two authors contributed equally",
    "descriptor": "\nComments: Accepted at the 15th International Workshop on the Algorithmic Foundations of Robotics (WAFR) 2022, University of Maryland, College Park. The first two authors contributed equally\n",
    "authors": [
      "Hai Nguyen",
      "Zhihan Yang",
      "Andrea Baisero",
      "Xiao Ma",
      "Robert Platt",
      "Christopher Amato"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.00898"
  },
  {
    "id": "arXiv:2204.02948",
    "title": "Guaranteed Bounds for Posterior Inference in Universal Probabilistic  Programming",
    "abstract": "Comments: Extended version of the PLDI 2022 article, including proofs and other supplementary material",
    "descriptor": "\nComments: Extended version of the PLDI 2022 article, including proofs and other supplementary material\n",
    "authors": [
      "Raven Beutner",
      "Luke Ong",
      "Fabian Zaiser"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.02948"
  },
  {
    "id": "arXiv:2204.03703",
    "title": "Physics-assisted Generative Adversarial Network for X-Ray Tomography",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2111.08011",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2111.08011\n",
    "authors": [
      "Zhen Guo",
      "Jung Ki Song",
      "George Barbastathis",
      "Michael E. Glinsky",
      "Courtenay T. Vaughan",
      "Kurt W. Larson",
      "Bradley K. Alpert",
      "Zachary H. Levine"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2204.03703"
  },
  {
    "id": "arXiv:2204.04213",
    "title": "Structure-aware Protein Self-supervised Learning",
    "abstract": "Comments: 7 pages and 4 figures",
    "descriptor": "\nComments: 7 pages and 4 figures\n",
    "authors": [
      "Can Chen",
      "Jingbo Zhou",
      "Fan Wang",
      "Xue Liu",
      "Dejing Dou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2204.04213"
  },
  {
    "id": "arXiv:2204.04416",
    "title": "E^2TAD: An Energy-Efficient Tracking-based Action Detector",
    "abstract": "E^2TAD: An Energy-Efficient Tracking-based Action Detector",
    "descriptor": "",
    "authors": [
      "Xin Hu",
      "Zhenyu Wu",
      "Hao-Yu Miao",
      "Siqi Fan",
      "Taiyu Long",
      "Zhenyu Hu",
      "Pengcheng Pi",
      "Yi Wu",
      "Zhou Ren",
      "Zhangyang Wang",
      "Gang Hua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04416"
  },
  {
    "id": "arXiv:2204.04874",
    "title": "Augmentation-Free Graph Contrastive Learning with Performance Guarantee",
    "abstract": "Augmentation-Free Graph Contrastive Learning with Performance Guarantee",
    "descriptor": "",
    "authors": [
      "Haonan Wang",
      "Jieyu Zhang",
      "Qi Zhu",
      "Wei Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2204.04874"
  },
  {
    "id": "arXiv:2204.07281",
    "title": "Pricing and Remunerating Electricity Storage Flexibility Using Virtual  Links",
    "abstract": "Comments: 28 pages, 8 figures",
    "descriptor": "\nComments: 28 pages, 8 figures\n",
    "authors": [
      "Weiqi Zhang",
      "Philip A. Tominac",
      "Victor M. Zavala"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2204.07281"
  },
  {
    "id": "arXiv:2204.08651",
    "title": "Evolving Programmable Computational Metamaterials",
    "abstract": "Comments: Accepted to the Genetic and Evolutionary Computation Conference 2022 (GECCO '22)",
    "descriptor": "\nComments: Accepted to the Genetic and Evolutionary Computation Conference 2022 (GECCO '22)\n",
    "authors": [
      "Atoosa Parsa",
      "Dong Wang",
      "Corey S. O'Hern",
      "Mark D. Shattuck",
      "Rebecca Kramer-Bottiglio",
      "Josh Bongard"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2204.08651"
  },
  {
    "id": "arXiv:2204.09109",
    "title": "From Spoken Thoughts to Automated Driving Commentary: Predicting and  Explaining Intelligent Vehicles' Actions",
    "abstract": "Comments: Presented in the 2022 IEEE Intelligent Vehicles Symposium",
    "descriptor": "\nComments: Presented in the 2022 IEEE Intelligent Vehicles Symposium\n",
    "authors": [
      "Daniel Omeiza",
      "Sule Anjomshoae",
      "Helena Webb",
      "Marina Jirotka",
      "Lars Kunze"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.09109"
  },
  {
    "id": "arXiv:2204.09781",
    "title": "Multi-label classification for biomedical literature: an overview of the  BioCreative VII LitCovid Track for COVID-19 literature topic annotations",
    "abstract": "Multi-label classification for biomedical literature: an overview of the  BioCreative VII LitCovid Track for COVID-19 literature topic annotations",
    "descriptor": "",
    "authors": [
      "Qingyu Chen",
      "Alexis Allot",
      "Robert Leaman",
      "Rezarta Islamaj Do\u011fan",
      "Jingcheng Du",
      "Li Fang",
      "Kai Wang",
      "Shuo Xu",
      "Yuefu Zhang",
      "Parsa Bagherzadeh",
      "Sabine Bergler",
      "Aakash Bhatnagar",
      "Nidhir Bhavsar",
      "Yung-Chun Chang",
      "Sheng-Jie Lin",
      "Wentai Tang",
      "Hongtong Zhang",
      "Ilija Tavchioski",
      "Senja Pollak",
      "Shubo Tian",
      "Jinfeng Zhang",
      "Yulia Otmakhova",
      "Antonio Jimeno Yepes",
      "Hang Dong",
      "Honghan Wu",
      "Richard Dufour",
      "Yanis Labrak",
      "Niladri Chatterjee",
      "Kushagri Tandon",
      "Fr\u00e9jus Laleye",
      "Lo\u00efc Rakotoson",
      "Emmanuele Chersoni",
      "Jinghang Gu",
      "Annemarie Friedrich",
      "Subhash Chandra Pujari",
      "Mariia Chizhikova",
      "Naveen Sivadasan",
      "Naveen Sivadasan",
      "Zhiyong Lu"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.09781"
  },
  {
    "id": "arXiv:2204.09914",
    "title": "CPGNet: Cascade Point-Grid Fusion Network for Real-Time LiDAR Semantic  Segmentation",
    "abstract": "Comments: Accepted in the 2022 IEEE International Conference on Robotics and Automation (ICRA 2022)",
    "descriptor": "\nComments: Accepted in the 2022 IEEE International Conference on Robotics and Automation (ICRA 2022)\n",
    "authors": [
      "Xiaoyan Li",
      "Gang Zhang",
      "Hongyu Pan",
      "Zhenhua Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.09914"
  },
  {
    "id": "arXiv:2204.10022",
    "title": "Scalable Sensitivity and Uncertainty Analysis for Causal-Effect  Estimates of Continuous-Valued Interventions",
    "abstract": "Comments: 28 pages",
    "descriptor": "\nComments: 28 pages\n",
    "authors": [
      "Andrew Jesson",
      "Alyson Douglas",
      "Peter Manshausen",
      "Nicolai Meinshausen",
      "Philip Stier",
      "Yarin Gal",
      "Uri Shalit"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.10022"
  },
  {
    "id": "arXiv:2204.10897",
    "title": "Welfare effects of strategic voting under scoring rules",
    "abstract": "Welfare effects of strategic voting under scoring rules",
    "descriptor": "",
    "authors": [
      "Egor Ianovski",
      "Daria Teplova",
      "Valeriia Kuka"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2204.10897"
  },
  {
    "id": "arXiv:2204.10962",
    "title": "Visual Attention Emerges from Recurrent Sparse Reconstruction",
    "abstract": "Comments: Released code: this https URL",
    "descriptor": "\nComments: Released code: this https URL\n",
    "authors": [
      "Baifeng Shi",
      "Yale Song",
      "Neel Joshi",
      "Trevor Darrell",
      "Xin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.10962"
  },
  {
    "id": "arXiv:2204.11116",
    "title": "Human-Robot Shared Control for Surgical Robot Based on Context-Aware  Sim-to-Real Adaptation",
    "abstract": "Comments: Accepted by 2022ICRA",
    "descriptor": "\nComments: Accepted by 2022ICRA\n",
    "authors": [
      "Dandan Zhang",
      "Zicong Wu",
      "Junhong Chen",
      "Ruiqi Zhu",
      "Adnan Munawar",
      "Bo Xiao",
      "Yuan Guan",
      "Hang Su",
      "Wuzhou Hong",
      "Yao Guo",
      "Gregory S. Fischer",
      "Benny Lo",
      "Guang-Zhong Yang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.11116"
  },
  {
    "id": "arXiv:2204.11159",
    "title": "Explainable Fairness in Recommendation",
    "abstract": "Comments: In Proceedings of SIGIR 2022",
    "descriptor": "\nComments: In Proceedings of SIGIR 2022\n",
    "authors": [
      "Yingqiang Ge",
      "Juntao Tan",
      "Yan Zhu",
      "Yinglong Xia",
      "Jiebo Luo",
      "Shuchang Liu",
      "Zuohui Fu",
      "Shijie Geng",
      "Zelong Li",
      "Yongfeng Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2204.11159"
  },
  {
    "id": "arXiv:2204.11927",
    "title": "Fractional Graph Coloring for Functional Compression with Side  Information",
    "abstract": "Comments: Note: The author fully agrees with the independent set-based definition in Theorem 21.2 in \"Network Information Theory\", El Gamal and Kim",
    "descriptor": "\nComments: Note: The author fully agrees with the independent set-based definition in Theorem 21.2 in \"Network Information Theory\", El Gamal and Kim\n",
    "authors": [
      "Derya Malak"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.11927"
  },
  {
    "id": "arXiv:2204.12281",
    "title": "Data-Efficient Backdoor Attacks",
    "abstract": "Comments: Accepted to IJCAI 2022 Long Oral",
    "descriptor": "\nComments: Accepted to IJCAI 2022 Long Oral\n",
    "authors": [
      "Pengfei Xia",
      "Ziqiang Li",
      "Wei Zhang",
      "Bin Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.12281"
  },
  {
    "id": "arXiv:2204.12796",
    "title": "Supervised Contrastive CSI Representation Learning for Massive MIMO  Positioning",
    "abstract": "Comments: 5 pages,7 figures,accepted to IEEE Communications Letter",
    "descriptor": "\nComments: 5 pages,7 figures,accepted to IEEE Communications Letter\n",
    "authors": [
      "Junquan Deng",
      "Wei Shi",
      "Jianzhao Zhang",
      "Xianyu Zhang",
      "Chuan Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.12796"
  },
  {
    "id": "arXiv:2204.13217",
    "title": "Understanding User Perceptions, Collaborative Experience and User  Engagement in Different Human-AI Interaction Designs for Co-Creative Systems",
    "abstract": "Comments: This paper appears in the ACM Creativity and Cognition 2022. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission from permissions@acm.org",
    "descriptor": "\nComments: This paper appears in the ACM Creativity and Cognition 2022. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission from permissions@acm.org\n",
    "authors": [
      "Jeba Rezwana",
      "Mary Lou Maher"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.13217"
  },
  {
    "id": "arXiv:2205.00286",
    "title": "Learning Effective SDEs from Brownian Dynamics Simulations of Colloidal  Particles",
    "abstract": "Comments: 14 pages, 11 figures, 1 table",
    "descriptor": "\nComments: 14 pages, 11 figures, 1 table\n",
    "authors": [
      "Nikolaos Evangelou",
      "Felix Dietrich",
      "Juan M. Bello-Rivas",
      "Alex Yeh",
      "Rachel Stein",
      "Michael A. Bevan",
      "Ioannis G. Kevrekidis"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.00286"
  },
  {
    "id": "arXiv:2205.00570",
    "title": "Budgeted Classification with Rejection: An Evolutionary Method with  Multiple Objectives",
    "abstract": "Comments: IEEE WCCI 2022. arXiv admin note: substantial text overlap with arXiv:2110.13067",
    "descriptor": "\nComments: IEEE WCCI 2022. arXiv admin note: substantial text overlap with arXiv:2110.13067\n",
    "authors": [
      "Nolan H. Hamilton",
      "Errin Fulp"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2205.00570"
  },
  {
    "id": "arXiv:2205.01306",
    "title": "CANShield: Signal-based Intrusion Detection for Controller Area Networks",
    "abstract": "Comments: 15 pages, 6 figures, A version of this paper is accepted by escar USA 2022",
    "descriptor": "\nComments: 15 pages, 6 figures, A version of this paper is accepted by escar USA 2022\n",
    "authors": [
      "Md Hasan Shahriar",
      "Yang Xiao",
      "Pablo Moriano",
      "Wenjing Lou",
      "Y. Thomas Hou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01306"
  },
  {
    "id": "arXiv:2205.01970",
    "title": "Nonstationary Bandit Learning via Predictive Sampling",
    "abstract": "Nonstationary Bandit Learning via Predictive Sampling",
    "descriptor": "",
    "authors": [
      "Yueyang Liu",
      "Benjamin Van Roy",
      "Kuang Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.01970"
  },
  {
    "id": "arXiv:2205.01997",
    "title": "Attention-based Knowledge Distillation in Multi-attention Tasks: The  Impact of a DCT-driven Loss",
    "abstract": "Comments: Preprint under review in TCSVT Journal",
    "descriptor": "\nComments: Preprint under review in TCSVT Journal\n",
    "authors": [
      "Alejandro L\u00f3pez-Cifuentes",
      "Marcos Escudero-Vi\u00f1olo",
      "Jes\u00fas Besc\u00f3s",
      "Juan C. SanMiguel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01997"
  },
  {
    "id": "arXiv:2205.02418",
    "title": "Quasi-SMC based on MPC for a constrained continuous-time nonlinear  system with external disturbances",
    "abstract": "Quasi-SMC based on MPC for a constrained continuous-time nonlinear  system with external disturbances",
    "descriptor": "",
    "authors": [
      "Huan Meng"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.02418"
  },
  {
    "id": "arXiv:2205.03056",
    "title": "Generative Evolutionary Strategy For Black-Box Optimizations",
    "abstract": "Generative Evolutionary Strategy For Black-Box Optimizations",
    "descriptor": "",
    "authors": [
      "Changhwi Park",
      "Seong Ryeol Kim",
      "Young-Gu Kim",
      "Dae Sin Kim"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2205.03056"
  },
  {
    "id": "arXiv:2205.03743",
    "title": "End-to-End Rubbing Restoration Using Generative Adversarial Networks",
    "abstract": "Comments: 8 pages, 11 figures, the work has been accepted to the AI for content creation workshop at CVPR 2022",
    "descriptor": "\nComments: 8 pages, 11 figures, the work has been accepted to the AI for content creation workshop at CVPR 2022\n",
    "authors": [
      "Gongbo Sun",
      "Zijie Zheng",
      "Ming Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.03743"
  },
  {
    "id": "arXiv:2205.03860",
    "title": "Zero and R2D2: A Large-scale Chinese Cross-modal Benchmark and A  Vision-Language Framework",
    "abstract": "Zero and R2D2: A Large-scale Chinese Cross-modal Benchmark and A  Vision-Language Framework",
    "descriptor": "",
    "authors": [
      "Chunyu Xie",
      "Heng Cai",
      "Jianfei Song",
      "Jincheng Li",
      "Fanjing Kong",
      "Xiaoyu Wu",
      "Henrique Morimitsu",
      "Lin Yao",
      "Dexin Wang",
      "Dawei Leng",
      "Xiangyang Ji",
      "Yafeng Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.03860"
  },
  {
    "id": "arXiv:2205.04090",
    "title": "Approaches and Challenges in Robotic Perception for Table-top  Rearrangement and Planning",
    "abstract": "Comments: 5 pages including references, 3 figures",
    "descriptor": "\nComments: 5 pages including references, 3 figures\n",
    "authors": [
      "Aditya Agarwal",
      "Bipasha Sen",
      "Shankara Narayanan V",
      "Vishal Reddy Mandadi",
      "Brojeshwar Bhowmick",
      "K Madhava Krishna"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.04090"
  },
  {
    "id": "arXiv:2205.04275",
    "title": "Long Document Re-ranking with Modular Re-ranker",
    "abstract": "Comments: SIGIR 22",
    "descriptor": "\nComments: SIGIR 22\n",
    "authors": [
      "Luyu Gao",
      "Jamie Callan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.04275"
  },
  {
    "id": "arXiv:2205.04771",
    "title": "Domain Invariant Masked Autoencoders for Self-supervised Learning from  Multi-domains",
    "abstract": "Domain Invariant Masked Autoencoders for Self-supervised Learning from  Multi-domains",
    "descriptor": "",
    "authors": [
      "Haiyang Yang",
      "Meilin Chen",
      "Yizhou Wang",
      "Shixiang Tang",
      "Feng Zhu",
      "Lei Bai",
      "Rui Zhao",
      "Wanli Ouyang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.04771"
  },
  {
    "id": "arXiv:2205.05760",
    "title": "Co-generation of Collision-Free Shapes for Arbitrary One-Parametric  Motion",
    "abstract": "Comments: Special Issue on symposium on Solid and Physical Modeling (SPM'2022)",
    "descriptor": "\nComments: Special Issue on symposium on Solid and Physical Modeling (SPM'2022)\n",
    "authors": [
      "Clinton B. Morris",
      "Morad Behandish"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Graphics (cs.GR)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.05760"
  },
  {
    "id": "arXiv:2205.06470",
    "title": "A class of few-Lee weight $\\mathbb{Z}_2[u]$-linear codes using  simplicial complexes and minimal codes via Gray map",
    "abstract": "Comments: 12 pages, size of code is changed in Theorem 3.2, proposition 4.1 is added, some examples are added in both section 3 and 4",
    "descriptor": "\nComments: 12 pages, size of code is changed in Theorem 3.2, proposition 4.1 is added, some examples are added in both section 3 and 4\n",
    "authors": [
      "Pramod Kumar Kewat",
      "Nilay Kumar Mondal"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.06470"
  },
  {
    "id": "arXiv:2205.06872",
    "title": "LASSO reloaded: a variational analysis perspective with applications to  compressed sensing",
    "abstract": "LASSO reloaded: a variational analysis perspective with applications to  compressed sensing",
    "descriptor": "",
    "authors": [
      "Aaron Berk",
      "Simone Brugiapaglia",
      "Tim Hoheisel"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Information Theory (cs.IT)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.06872"
  },
  {
    "id": "arXiv:2205.07182",
    "title": "Fair Bayes-Optimal Classifiers Under Predictive Parity",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2202.09724",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2202.09724\n",
    "authors": [
      "Xianli Zeng",
      "Edgar Dobriban",
      "Guang Cheng"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.07182"
  },
  {
    "id": "arXiv:2205.08210",
    "title": "Towards Robotic Laboratory Automation Plug & Play: Teaching-free Robot  Integration with the LAPP Digital Twin",
    "abstract": "Towards Robotic Laboratory Automation Plug & Play: Teaching-free Robot  Integration with the LAPP Digital Twin",
    "descriptor": "",
    "authors": [
      "\u00c1d\u00e1m Wolf",
      "Stefan Romeder-Finger",
      "K\u00e1roly Sz\u00e9ll",
      "P\u00e9ter Galambos"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.08210"
  },
  {
    "id": "arXiv:2205.10255",
    "title": "Tower: Data Structures in Quantum Superposition",
    "abstract": "Comments: 24 pages, 15 figures. [v2] add discussion of concurrent work in Sec 1.4 and add acknowledgements section",
    "descriptor": "\nComments: 24 pages, 15 figures. [v2] add discussion of concurrent work in Sec 1.4 and add acknowledgements section\n",
    "authors": [
      "Charles Yuan",
      "Michael Carbin"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2205.10255"
  },
  {
    "id": "arXiv:2205.10312",
    "title": "ClusterEA: Scalable Entity Alignment with Stochastic Training and  Normalized Mini-batch Similarities",
    "abstract": "Comments: KDD 2022",
    "descriptor": "\nComments: KDD 2022\n",
    "authors": [
      "Yunjun Gao",
      "Xiaoze Liu",
      "Junyang Wu",
      "Tianyi Li",
      "Pengfei Wang",
      "Lu Chen"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.10312"
  },
  {
    "id": "arXiv:2205.10330",
    "title": "A Review of Safe Reinforcement Learning: Methods, Theory and  Applications",
    "abstract": "A Review of Safe Reinforcement Learning: Methods, Theory and  Applications",
    "descriptor": "",
    "authors": [
      "Shangding Gu",
      "Long Yang",
      "Yali Du",
      "Guang Chen",
      "Florian Walter",
      "Jun Wang",
      "Yaodong Yang",
      "Alois Knoll"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.10330"
  },
  {
    "id": "arXiv:2205.10667",
    "title": "Individual Topology Structure of Eye Movement Trajectories",
    "abstract": "Individual Topology Structure of Eye Movement Trajectories",
    "descriptor": "",
    "authors": [
      "Arsenii Onuchin",
      "Oleg Kachan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.10667"
  },
  {
    "id": "arXiv:2205.11087",
    "title": "MetaSlicing: A Novel Resource Allocation Framework for Metaverse",
    "abstract": "MetaSlicing: A Novel Resource Allocation Framework for Metaverse",
    "descriptor": "",
    "authors": [
      "Nam H.Chu",
      "Dinh Thai Hoang",
      "Diep N. Nguyen",
      "Khoa T. Phan",
      "Eryk Dutkiewicz"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2205.11087"
  },
  {
    "id": "arXiv:2205.11252",
    "title": "Exploring the stimulative effect on following drivers in a consecutive  lane-change using microscopic vehicle trajectory data",
    "abstract": "Comments: 22 PAGES",
    "descriptor": "\nComments: 22 PAGES\n",
    "authors": [
      "Ruifeng Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2205.11252"
  },
  {
    "id": "arXiv:2205.12755",
    "title": "An Evolutionary Approach to Dynamic Introduction of Tasks in Large-scale  Multitask Learning Systems",
    "abstract": "An Evolutionary Approach to Dynamic Introduction of Tasks in Large-scale  Multitask Learning Systems",
    "descriptor": "",
    "authors": [
      "Andrea Gesmundo",
      "Jeff Dean"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2205.12755"
  },
  {
    "id": "arXiv:2205.12816",
    "title": "P4Filter: A two level defensive mechanism against attacks in SDN using  P4",
    "abstract": "P4Filter: A two level defensive mechanism against attacks in SDN using  P4",
    "descriptor": "",
    "authors": [
      "Ananya Saxena",
      "Ritvik Muttreja",
      "Shivam Upadhyay",
      "K. Shiv Kumar",
      "Venkanna U"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2205.12816"
  },
  {
    "id": "arXiv:2205.12959",
    "title": "Uniform Generalization Bound on Time and Inverse Temperature for  Gradient Descent Algorithm and its Application to Analysis of Simulated  Annealing",
    "abstract": "Comments: 16 pages, typos in (1.1), (1.2) and (4.1) have been fixed",
    "descriptor": "\nComments: 16 pages, typos in (1.1), (1.2) and (4.1) have been fixed\n",
    "authors": [
      "Keisuke Suzuki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.12959"
  },
  {
    "id": "arXiv:2205.12986",
    "title": "Transcormer: Transformer for Sentence Scoring with Sliding Language  Modeling",
    "abstract": "Transcormer: Transformer for Sentence Scoring with Sliding Language  Modeling",
    "descriptor": "",
    "authors": [
      "Kaitao Song",
      "Yichong Leng",
      "Xu Tan",
      "Yicheng Zou",
      "Tao Qin",
      "Dongsheng Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.12986"
  },
  {
    "id": "arXiv:2205.13342",
    "title": "Leveraging Causal Inference for Explainable Automatic Program Repair",
    "abstract": "Comments: This paper has been accepted by IJCNN2022",
    "descriptor": "\nComments: This paper has been accepted by IJCNN2022\n",
    "authors": [
      "Jianzong Wang",
      "Shijing Si",
      "Zhitao Zhu",
      "Xiaoyang Qu",
      "Zhenhou Hong",
      "Jing Xiao"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.13342"
  },
  {
    "id": "arXiv:2205.13958",
    "title": "Machine Learning-Based User Scheduling in Integrated  Satellite-HAPS-Ground Networks",
    "abstract": "Machine Learning-Based User Scheduling in Integrated  Satellite-HAPS-Ground Networks",
    "descriptor": "",
    "authors": [
      "Shasha Liu",
      "Hayssam Dahrouj",
      "Mohamed-Slim Alouini"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.13958"
  },
  {
    "id": "arXiv:2205.14139",
    "title": "Learning Markovian Homogenized Models in Viscoelasticity",
    "abstract": "Learning Markovian Homogenized Models in Viscoelasticity",
    "descriptor": "",
    "authors": [
      "Kaushik Bhattacharya",
      "Burigede Liu",
      "Andrew M. Stuart",
      "Margaret Trautner"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.14139"
  },
  {
    "id": "arXiv:2205.14189",
    "title": "Optimizing Objective Functions from Trained ReLU Neural Networks via  Sampling",
    "abstract": "Comments: Review 2: Fixed typo in Table 1 and page 7. Bold values in Tables 2 and 4",
    "descriptor": "\nComments: Review 2: Fixed typo in Table 1 and page 7. Bold values in Tables 2 and 4\n",
    "authors": [
      "Georgia Perakis",
      "Asterios Tsiourvas"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.14189"
  },
  {
    "id": "arXiv:2205.14284",
    "title": "Provably Auditing Ordinary Least Squares in Low Dimensions",
    "abstract": "Comments: 32 pages, 4 figures. Added acknowledgments/funding",
    "descriptor": "\nComments: 32 pages, 4 figures. Added acknowledgments/funding\n",
    "authors": [
      "Ankur Moitra",
      "Dhruv Rohatgi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)"
    ],
    "url": "https://arxiv.org/abs/2205.14284"
  },
  {
    "id": "arXiv:2205.14321",
    "title": "Automatic Expert Selection for Multi-Scenario and Multi-Task Search",
    "abstract": "Comments: Accepted by SIGIR 2022; 10 pages, 8 figures",
    "descriptor": "\nComments: Accepted by SIGIR 2022; 10 pages, 8 figures\n",
    "authors": [
      "Xinyu Zou",
      "Zhi Hu",
      "Yiming Zhao",
      "Xuchu Ding",
      "Zhongyi Liu",
      "Chenliang Li",
      "Aixin Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2205.14321"
  },
  {
    "id": "arXiv:2205.14405",
    "title": "Strengthening Skeletal Action Recognizers via Leveraging Temporal  Patterns",
    "abstract": "Strengthening Skeletal Action Recognizers via Leveraging Temporal  Patterns",
    "descriptor": "",
    "authors": [
      "Zhenyue Qin",
      "Pan Ji",
      "Dongwoo Kim",
      "Yang Liu",
      "Saeed Anwar",
      "Tom Gedeon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.14405"
  },
  {
    "id": "arXiv:2205.14421",
    "title": "Approximation of Functionals by Neural Network without Curse of  Dimensionality",
    "abstract": "Approximation of Functionals by Neural Network without Curse of  Dimensionality",
    "descriptor": "",
    "authors": [
      "Yahong Yang",
      "Yang Xiang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2205.14421"
  },
  {
    "id": "arXiv:2205.14528",
    "title": "Measuring the Monetary Value of Online Volunteer Work",
    "abstract": "Comments: This is a preprint. The paper will be presented at the 2022 International Conference on Web and Social Media (ICWSM'22)",
    "descriptor": "\nComments: This is a preprint. The paper will be presented at the 2022 International Conference on Web and Social Media (ICWSM'22)\n",
    "authors": [
      "Hanlin Li",
      "Brent Hecht",
      "Stevie Chancellor"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2205.14528"
  },
  {
    "id": "arXiv:2205.14529",
    "title": "All That's Happening behind the Scenes: Putting the Spotlight on  Volunteer Moderator Labor in Reddit",
    "abstract": "Comments: This is a preprint. The paper will be presented at the 2022 International Conference on Web and Social Media (ICWSM'22)",
    "descriptor": "\nComments: This is a preprint. The paper will be presented at the 2022 International Conference on Web and Social Media (ICWSM'22)\n",
    "authors": [
      "Hanlin Li",
      "Brent Hecht",
      "Stevie Chancellor"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2205.14529"
  },
  {
    "id": "arXiv:2205.14550",
    "title": "Machine Learning for Microcontroller-Class Hardware -- A Review",
    "abstract": "Comments: Under Review at IEEE Sensors Journal",
    "descriptor": "\nComments: Under Review at IEEE Sensors Journal\n",
    "authors": [
      "Swapnil Sayan Saha",
      "Sandeep Singh Sandha",
      "Mani Srivastava"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.14550"
  },
  {
    "id": "arXiv:2205.14651",
    "title": "Contributions to Representation Learning with Graph Autoencoders and  Applications to Music Recommendation",
    "abstract": "Comments: Ph.D. thesis defended at \\'Ecole Polytechnique (IPP) in March 2022. As mentioned in this thesis, several chapters present results also published in scientific articles written with co-authors",
    "descriptor": "\nComments: Ph.D. thesis defended at \\'Ecole Polytechnique (IPP) in March 2022. As mentioned in this thesis, several chapters present results also published in scientific articles written with co-authors\n",
    "authors": [
      "Guillaume Salha-Galvan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2205.14651"
  },
  {
    "id": "arXiv:2205.14818",
    "title": "Excess Risk of Two-Layer ReLU Neural Networks in Teacher-Student  Settings and its Superiority to Kernel Methods",
    "abstract": "Comments: 29 pages, 1 figure",
    "descriptor": "\nComments: 29 pages, 1 figure\n",
    "authors": [
      "Shunta Akiyama",
      "Taiji Suzuki"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.14818"
  },
  {
    "id": "arXiv:2205.14969",
    "title": "Guided Diffusion Model for Adversarial Purification",
    "abstract": "Guided Diffusion Model for Adversarial Purification",
    "descriptor": "",
    "authors": [
      "Jinyi Wang",
      "Zhaoyang Lyu",
      "Dahua Lin",
      "Bo Dai",
      "Hongfei Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.14969"
  },
  {
    "id": "arXiv:2205.15424",
    "title": "Connecting adversarial attacks and optimal transport for domain  adaptation",
    "abstract": "Connecting adversarial attacks and optimal transport for domain  adaptation",
    "descriptor": "",
    "authors": [
      "Arip Asadulaev",
      "Vitaly Shutov",
      "Alexander Korotin",
      "Alexander Panfilov",
      "Andrey Filchenkov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15424"
  },
  {
    "id": "arXiv:2205.15623",
    "title": "k-Means Maximum Entropy Exploration",
    "abstract": "k-Means Maximum Entropy Exploration",
    "descriptor": "",
    "authors": [
      "Alexander Nedergaard",
      "Matthew Cook"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15623"
  },
  {
    "id": "arXiv:2205.15631",
    "title": "Computational and Descriptional Power of Nondeterministic Iterated  Uniform Finite-State Transducers",
    "abstract": "Computational and Descriptional Power of Nondeterministic Iterated  Uniform Finite-State Transducers",
    "descriptor": "",
    "authors": [
      "Martin Kutrib",
      "Andreas Malcher",
      "Carlo Mereghetti",
      "Beatrice Palano"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2205.15631"
  },
  {
    "id": "arXiv:2205.15659",
    "title": "The CLRS Algorithmic Reasoning Benchmark",
    "abstract": "Comments: To appear in ICML 2022. 19 pages, 4 figures",
    "descriptor": "\nComments: To appear in ICML 2022. 19 pages, 4 figures\n",
    "authors": [
      "Petar Veli\u010dkovi\u0107",
      "Adri\u00e0 Puigdom\u00e8nech Badia",
      "David Budden",
      "Razvan Pascanu",
      "Andrea Banino",
      "Misha Dashevskiy",
      "Raia Hadsell",
      "Charles Blundell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.15659"
  },
  {
    "id": "arXiv:2205.15723",
    "title": "DeVRF: Fast Deformable Voxel Radiance Fields for Dynamic Scenes",
    "abstract": "Comments: Project page: this https URL",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Jia-Wei Liu",
      "Yan-Pei Cao",
      "Weijia Mao",
      "Wenqiao Zhang",
      "David Junhao Zhang",
      "Jussi Keppo",
      "Ying Shan",
      "Xiaohu Qie",
      "Mike Zheng Shou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15723"
  },
  {
    "id": "arXiv:2205.15953",
    "title": "Timing is Everything: Learning to Act Selectively with Costly Actions  and Budgetary Constraints",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2112.02618, arXiv:2103.09159, arXiv:2205.15064",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2112.02618, arXiv:2103.09159, arXiv:2205.15064\n",
    "authors": [
      "David Mguni",
      "Aivar Sootla",
      "Juliusz Ziomek",
      "Oliver Slumbers",
      "Zipeng Dai",
      "Kun Shao",
      "Jun Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15953"
  },
  {
    "id": "arXiv:2206.00181",
    "title": "Labeling Where Adapting Fails: Cross-Domain Semantic Segmentation with  Point Supervision via Active Selection",
    "abstract": "Labeling Where Adapting Fails: Cross-Domain Semantic Segmentation with  Point Supervision via Active Selection",
    "descriptor": "",
    "authors": [
      "Fei Pan",
      "Francois Rameau",
      "Junsik Kim",
      "In So Kweon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.00181"
  },
  {
    "id": "arXiv:2206.00516",
    "title": "Feature Selection for Discovering Distributional Treatment Effect  Modifiers",
    "abstract": "Comments: 18 pages, Accepted to UAI2022",
    "descriptor": "\nComments: 18 pages, Accepted to UAI2022\n",
    "authors": [
      "Yoichi Chikahara",
      "Makoto Yamada",
      "Hisashi Kashima"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.00516"
  },
  {
    "id": "arXiv:2206.00747",
    "title": "SolarGAN: Synthetic Annual Solar Irradiance Time Series on Urban  Building Facades via Deep Generative Networks",
    "abstract": "Comments: fix layout issues & typos",
    "descriptor": "\nComments: fix layout issues & typos\n",
    "authors": [
      "Yufei Zhang",
      "Arno Schl\u00fcter",
      "Christoph Waibel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00747"
  },
  {
    "id": "arXiv:2206.00770",
    "title": "Winning the 3rd Japan Automotive AI Challenge -- Autonomous Racing with  the Autoware.Auto Open Source Software Stack",
    "abstract": "Comments: Accepted at Autoware Workshop at IV 2022",
    "descriptor": "\nComments: Accepted at Autoware Workshop at IV 2022\n",
    "authors": [
      "Zirui Zang",
      "Renukanandan Tumu",
      "Johannes Betz",
      "Hongrui Zheng",
      "Rahul Mangharam"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.00770"
  },
  {
    "id": "arXiv:2206.00851",
    "title": "Finite Element Complexes in Two Dimensions",
    "abstract": "Comments: 35 pages",
    "descriptor": "\nComments: 35 pages\n",
    "authors": [
      "Long Chen",
      "Xuehai Huang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.00851"
  },
  {
    "id": "arXiv:2206.01409",
    "title": "Hybrid Models for Mixed Variables in Bayesian Optimization",
    "abstract": "Comments: 56 pages, 22 Figures",
    "descriptor": "\nComments: 56 pages, 22 Figures\n",
    "authors": [
      "Hengrui Luo",
      "Younghyun Cho",
      "James W. Demmel",
      "Xiaoye S. Li",
      "Yang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.01409"
  },
  {
    "id": "arXiv:2206.01524",
    "title": "Anomaly detection in surveillance videos using transformer based  attention model",
    "abstract": "Anomaly detection in surveillance videos using transformer based  attention model",
    "descriptor": "",
    "authors": [
      "Kapil Deshpande",
      "Narinder Singh Punn",
      "Sanjay Kumar Sonbhadra",
      "Sonali Agarwal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01524"
  },
  {
    "id": "arXiv:2206.01604",
    "title": "Non-Intrusive Reduced Models based on Operator Inference for Chaotic  Systems",
    "abstract": "Comments: 16 pages, 37 figures, submitted to IEEE-TAI-PIML",
    "descriptor": "\nComments: 16 pages, 37 figures, submitted to IEEE-TAI-PIML\n",
    "authors": [
      "Jo\u00e3o Lucas de Sousa Almeida",
      "Arthur Cancellieri Pires",
      "Klaus Feine Vaz Cid",
      "Alberto Costa Nogueira Junior"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2206.01604"
  },
  {
    "id": "arXiv:2206.01612",
    "title": "OmniXAI: A Library for Explainable AI",
    "abstract": "Comments: Wait for the Github release. The name of the library may need to be changed due to legal concerns",
    "descriptor": "\nComments: Wait for the Github release. The name of the library may need to be changed due to legal concerns\n",
    "authors": [
      "Wenzhuo Yang",
      "Hung Le",
      "Silvio Savarese",
      "Steven C.H. Hoi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01612"
  }
]
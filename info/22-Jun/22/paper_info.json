[
  {
    "id": "arXiv:2206.08930",
    "title": "Wearable Haptic Device for Individuals with Congenital Absence of  Proprioception",
    "abstract": "A rare genetic condition, PIEZO2 loss of function (LOF) is characterized by\nabsence of proprioception and light touch, which makes functional tasks (e.g.,\nwalking, manipulation) difficult. There are no pharmacological treatments or\nassistive technologies available for individuals with PIEZO2-LOF. We propose a\nsensory substitution device that communicates proprioceptive feedback via\ndetectable haptic stimuli. We created a wearable prototype that maps\nmeasurements of elbow movement to deep pressure applied to the forearm. The\nprototype applies up to 18 N, includes an embedded force sensor, and is\nprogrammable to allow for various angle-to-pressure mappings. Future work\nincludes comparing proprioceptive acuity and movement ability with and without\nthe device in healthy and PIEZO2-LOF individuals, developing low-profile\ndevices using soft robotics, providing sensory substitution for multiple joints\nsimultaneously, and encoding additional aspects of joint dynamics.",
    "descriptor": "",
    "authors": [
      "Sreela Kodali",
      "Allison M. Okamura",
      "Thomas C. Bulea",
      "Alexander T. Chesler",
      "Carsten G. B\u00f6nnemann"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.08930"
  },
  {
    "id": "arXiv:2206.08931",
    "title": "CrowdWorkSheets: Accounting for Individual and Collective Identities  Underlying Crowdsourced Dataset Annotation",
    "abstract": "Human annotated data plays a crucial role in machine learning (ML) research\nand development. However, the ethical considerations around the processes and\ndecisions that go into dataset annotation have not received nearly enough\nattention. In this paper, we survey an array of literature that provides\ninsights into ethical considerations around crowdsourced dataset annotation. We\nsynthesize these insights, and lay out the challenges in this space along two\nlayers: (1) who the annotator is, and how the annotators' lived experiences can\nimpact their annotations, and (2) the relationship between the annotators and\nthe crowdsourcing platforms, and what that relationship affords them. Finally,\nwe introduce a novel framework, CrowdWorkSheets, for dataset developers to\nfacilitate transparent documentation of key decisions points at various stages\nof the data annotation pipeline: task formulation, selection of annotators,\nplatform and infrastructure choices, dataset analysis and evaluation, and\ndataset release and maintenance.",
    "descriptor": "\nComments: 11 pages, Accepted at 2022 ACM Conference on Fairness, Accountability, and Transparency (FAccT). arXiv admin note: text overlap with arXiv:2112.04554\n",
    "authors": [
      "Mark Diaz",
      "Ian D. Kivlichan",
      "Rachel Rosen",
      "Dylan K. Baker",
      "Razvan Amironesei",
      "Vinodkumar Prabhakaran",
      "Emily Denton"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.08931"
  },
  {
    "id": "arXiv:2206.08932",
    "title": "Putting GPT-3's Creativity to the (Alternative Uses) Test",
    "abstract": "AI large language models have (co-)produced amazing written works from\nnewspaper articles to novels and poetry. These works meet the standards of the\nstandard definition of creativity: being original and useful, and sometimes\neven the additional element of surprise. But can a large language model\ndesigned to predict the next text fragment provide creative, out-of-the-box,\nresponses that still solve the problem at hand? We put Open AI's generative\nnatural language model, GPT-3, to the test. Can it provide creative solutions\nto one of the most commonly used tests in creativity research? We assessed\nGPT-3's creativity on Guilford's Alternative Uses Test and compared its\nperformance to previously collected human responses on expert ratings of\noriginality, usefulness and surprise of responses, flexibility of each set of\nideas as well as an automated method to measure creativity based on the\nsemantic distance between a response and the AUT object in question. Our\nresults show that -- on the whole -- humans currently outperform GPT-3 when it\ncomes to creative output. But, we believe it is only a matter of time before\nGPT-3 catches up on this particular task. We discuss what this work reveals\nabout human and AI creativity, creativity testing and our definition of\ncreativity.",
    "descriptor": "\nComments: 5 pages, 6 figures, accepted at the International Conference on Computational Creativity (ICCC) 2022 as a Short Paper. See this https URL for data, analyses and code\n",
    "authors": [
      "Claire Stevenson",
      "Iris Smal",
      "Matthijs Baas",
      "Raoul Grasman",
      "Han van der Maas"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.08932"
  },
  {
    "id": "arXiv:2206.08934",
    "title": "Experimental determination of Lamb wave dispersion diagrams over large  frequency ranges in fiber metal laminates",
    "abstract": "Fiber metal laminates (FML) are of high interest for lightweight structures\nas they combine the advantageous material properties of metals and\nfiber-reinforced polymers. However, low-velocity impacts can lead to complex\ninternal damage. Therefore, structural health monitoring (SHM) with guided\nultrasonic waves, in this case, referred to as Lamb waves, is an approach to\nidentify such damage. Numerical simulations form the basis for corresponding\ninvestigations, but experimental validation of propagation diagrams over a wide\nfrequency range is hardly found in the literature. In this work the dispersive\nrelation of Lamb waves is experimentally determined for an FML made of carbon\nfiber-reinforced polymer and steel. For this purpose, a multi-frequency\nexcitation is used to generate Lamb waves and the resulting wave field is\nmeasured via laser scanning vibrometry. The data are processed by means of a\nnon-uniform discrete 2d Fourier transform and analyzed in the\nfrequency-wavenumber domain. The experimental data are in good agreement with\ndata from a numerical solution of the analytical framework. In conclusion, this\nwork presents a highly automatable method to experimentally determine\ndispersion diagrams of Lamb waves in FML over large frequency ranges with high\naccuracy and reproducibility.",
    "descriptor": "",
    "authors": [
      "Tilmann Barth",
      "Johannes Wiedemann",
      "Thomas Roloff",
      "Tim Behrens",
      "Natalie Rauter",
      "Christian H\u00fchne",
      "Michael Sinapius",
      "Rolf Lammering"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2206.08934"
  },
  {
    "id": "arXiv:2206.08935",
    "title": "Programs and algorithms for the shell decomposition of oscillating  functions in space",
    "abstract": "Real-space refinement of atomic models in macromolecular crystallography or\nin cryo electron microscopy fits a model to a map obtained experimentally. This\nrequires generating model maps of a limited resolution which moreover may vary\nfrom one molecular region to another. Calculating such map as a sum of atomic\ncontributions requires that these contributions reflect the local resolution of\nthe experimental map. A possibility to refine the parameters of these\ncontribution means to express it as a function of atomic coordinates,\ndisplacement factor and eventually of resolution. Recently, Urzhumtsev & Lunin\n(BioRxiv, 10.1101/2022.03.28.486044) suggested to decompose finite-resolution\natomic images, and more generally spherically symmetric oscillating functions\nin space, into a sum of specially designed terms analytically dependent on all\natomic parameters. Each term is a spherically symmetric function concentrated\nin a spherical shell. Here we describe the software and respective algorithms\nto carry out such shell decomposition of oscillating functions.",
    "descriptor": "",
    "authors": [
      "Ludmila Urzhumtseva",
      "Vladimir Y. Lunin",
      "Alexandre Urzhumtsev"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Biological Physics (physics.bio-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.08935"
  },
  {
    "id": "arXiv:2206.08948",
    "title": "CMT-DeepLab: Clustering Mask Transformers for Panoptic Segmentation",
    "abstract": "We propose Clustering Mask Transformer (CMT-DeepLab), a transformer-based\nframework for panoptic segmentation designed around clustering. It rethinks the\nexisting transformer architectures used in segmentation and detection;\nCMT-DeepLab considers the object queries as cluster centers, which fill the\nrole of grouping the pixels when applied to segmentation. The clustering is\ncomputed with an alternating procedure, by first assigning pixels to the\nclusters by their feature affinity, and then updating the cluster centers and\npixel features. Together, these operations comprise the Clustering Mask\nTransformer (CMT) layer, which produces cross-attention that is denser and more\nconsistent with the final segmentation task. CMT-DeepLab improves the\nperformance over prior art significantly by 4.4% PQ, achieving a new\nstate-of-the-art of 55.7% PQ on the COCO test-dev set.",
    "descriptor": "\nComments: CVPR 2022 Oral\n",
    "authors": [
      "Qihang Yu",
      "Huiyu Wang",
      "Dahun Kim",
      "Siyuan Qiao",
      "Maxwell Collins",
      "Yukun Zhu",
      "Hartwig Adam",
      "Alan Yuille",
      "Liang-Chieh Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.08948"
  },
  {
    "id": "arXiv:2206.08950",
    "title": "Photoelectric Factor Prediction Using Automated Learning and Uncertainty  Quantification",
    "abstract": "The photoelectric factor (PEF) is an important well logging tool to\ndistinguish between different types of reservoir rocks because PEF measurement\nis sensitive to elements with high atomic number. Furthermore, the ratio of\nrock minerals could be determined by combining PEF log with other well logs.\nHowever, PEF log could be missing in some cases such as in old well logs and\nwells drilled with barite-based mud. Therefore, developing models for\nestimating missing PEF log is essential in those circumstances. In this work,\nwe developed various machine learning models to predict PEF values using the\nfollowing well logs as inputs: bulk density (RHOB), neutron porosity (NPHI),\ngamma ray (GR), compressional and shear velocity.\nThe predictions of PEF values using adaptive-network-fuzzy inference system\n(ANFIS) and artificial neural network (ANN) models have errors of about 16% and\n14% average absolute percentage error (AAPE) in the testing dataset,\nrespectively. Thus, a different approach was proposed that is based on the\nconcept of automated machine learning. It works by automatically searching for\nthe optimal model type and optimizes its hyperparameters for the dataset under\ninvestigation. This approach selected a Gaussian process regression (GPR) model\nfor accurate estimation of PEF values. The developed GPR model decreases the\nAAPE of the predicted PEF values in the testing dataset to about 10% AAPE. This\nerror could be further decreased to about 2% by modeling the potential noise in\nthe measurements using the GPR model.",
    "descriptor": "",
    "authors": [
      "Khalid L. Alsamadony",
      "Ahmed Farid Ibrahim",
      "Salaheldin Elkatatny",
      "Abdulazeez Abdulraheem"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Geophysics (physics.geo-ph)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2206.08950"
  },
  {
    "id": "arXiv:2206.08952",
    "title": "The Impact of Variable Ordering on Bayesian Network Structure Learning",
    "abstract": "Causal Bayesian Networks provide an important tool for reasoning under\nuncertainty with potential application to many complex causal systems.\nStructure learning algorithms that can tell us something about the causal\nstructure of these systems are becoming increasingly important. In the\nliterature, the validity of these algorithms is often tested for sensitivity\nover varying sample sizes, hyper-parameters, and occasionally objective\nfunctions. In this paper, we show that the order in which the variables are\nread from data can have much greater impact on the accuracy of the algorithm\nthan these factors. Because the variable ordering is arbitrary, any significant\neffect it has on learnt graph accuracy is concerning, and this raises questions\nabout the validity of the results produced by algorithms that are sensitive to,\nbut have not been assessed against, different variable orderings.",
    "descriptor": "",
    "authors": [
      "Neville K Kitson",
      "Anthony C Constantinou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.08952"
  },
  {
    "id": "arXiv:2206.08954",
    "title": "Intra-Instance VICReg: Bag of Self-Supervised Image Patch Embedding",
    "abstract": "Recently, self-supervised learning (SSL) has achieved tremendous empirical\nadvancements in learning image representation. However, our understanding and\nknowledge of the representation are still limited. This work shows that the\nsuccess of the SOTA siamese-network-based SSL approaches is primarily based on\nlearning a representation of image patches. Particularly, we show that when we\nlearn a representation only for fixed-scale image patches and aggregate\ndifferent patch representations linearly for an image (instance), it can\nachieve on par or even better results than the baseline methods on several\nbenchmarks. Further, we show that the patch representation aggregation can also\nimprove various SOTA baseline methods by a large margin. We also establish a\nformal connection between the SSL objective and the image patches co-occurrence\nstatistics modeling, which supplements the prevailing invariance perspective.\nBy visualizing the nearest neighbors of different image patches in the\nembedding space and projection space, we show that while the projection has\nmore invariance, the embedding space tends to preserve more equivariance and\nlocality. Finally, we propose a hypothesis for the future direction based on\nthe discovery of this work.",
    "descriptor": "",
    "authors": [
      "Yubei Chen",
      "Adrien Bardes",
      "Zengyi Li",
      "Yann LeCun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.08954"
  },
  {
    "id": "arXiv:2206.08955",
    "title": "Making first order linear logic a generating grammar",
    "abstract": "It is known that different categorial grammars have surface representation in\na fragment of first order multiplicative linear logic. We show that the\nfragment of interest is equivalent to the recently introduced {\\it extended\ntensor type calculus}. This provides the former not only with some alternative\nsyntax and intuitive geometric representation, but also with an intrinsic\ndeductive system, which has been absent.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2112.15253\n",
    "authors": [
      "Sergey Slavnov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.08955"
  },
  {
    "id": "arXiv:2206.08959",
    "title": "Is my transaction done yet? An empirical study of transaction processing  times in the Ethereum Blockchain Platform",
    "abstract": "Ethereum is one of the most popular platforms for the development of\nblockchain-powered applications. These applications are known as Dapps. When\nengineering Dapps, developers need to translate requests captured in the\nfront-end of their application into one or more smart contract transactions.\nDevelopers need to pay for these transactions and, the more they pay (i.e., the\nhigher the gas price), the faster the transaction is likely to be processed.\nTherefore developers need to optimize the balance between cost (transaction\nfees) and user experience (transaction processing times). Online services have\nbeen developed to provide transaction issuers (e.g., Dapp developers) with an\nestimate of how long transactions will take to be processed given a certain gas\nprice. These estimation services are crucial in the Ethereum domain and several\npopular wallets such as Metamask rely on them. However, their accuracy has not\nbeen empirically investigated so far. In this paper, we quantify the\ntransaction processing times in Ethereum, investigate the relationship between\nprocessing times and gas prices, and determine the accuracy of\nstate-of-the-practice estimation services. We find that transactions are\nprocessed in a median of 57s and that 90% of the transactions are processed\nwithin 8m. The higher gas prices result in faster transaction processing times\nwith diminishing returns. In particular, we observe no practical difference in\nprocessing time between expensive and very expensive transactions. In terms of\naccuracy of processing time estimation services, we note that they are\nequivalent. However, when stratifying transactions by gas prices, Etherscan's\nGas Tracker is the most accurate estimation service for very cheap and cheap\ntransaction. EthGasStation's Gas Price API, in turn, is the most accurate\nestimation service for regular, expensive, and very expensive transactions.",
    "descriptor": "\nComments: Under review in Transactions of Software Engineering and Methodology journal\n",
    "authors": [
      "Michael Pacheco",
      "Gustavo A. Oliva",
      "Gopi Krishnan Rajbahadur",
      "Ahmed E. Hassan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.08959"
  },
  {
    "id": "arXiv:2206.08961",
    "title": "Design of Multi-model Linear Inferential Sensors with SVM-based  Switching Logic",
    "abstract": "We study the problem of data-based design of multi-model linear inferential\n(soft) sensors. The multi-model linear inferential sensors promise increased\nprediction accuracy yet simplicity of the model structure and training. The\nstandard approach to the multi-model inferential sensor design consists in\nthree separate steps: 1) data labeling (establishing training subsets for\nindividual models), 2) data classification (creating a switching logic for the\nmodels), and 3) training of individual models. There are two main issues with\nthis concept: a) as steps 2) & 3) are separate, discontinuities can occur when\nswitching between the models; b) as steps 1) & 3) are separate, data labelling\ndisregards the quality of the resulting model. Our contribution aims at both\nthe mentioned problems, where, for the problem a), we introduce a novel\nSVM-based model training coupled with switching logic identification and, for\nthe problem b), we propose a direct optimization of data labelling. We\nillustrate the proposed methodology and its benefits on an example from the\nchemical engineering domain.",
    "descriptor": "\nComments: 6 pages, 8 figures, 1 table\n",
    "authors": [
      "Martin Mojto",
      "Miroslav Fikar",
      "Radoslav Paulen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.08961"
  },
  {
    "id": "arXiv:2206.08963",
    "title": "Efficient Constrained Multi-Agent Interactive Planning using Constrained  Dynamic Potential Games",
    "abstract": "Although dynamic games provide a rich paradigm for modeling agents'\ninteractions, solving these games for real-world applications is often\nchallenging. Many real-wold interactive settings involve general nonlinear\nstate and input constraints which couple agents' decisions with one another. In\nthis work, we develop an efficient and fast planner for interactive planning in\nconstrained setups using a constrained game-theoretical framework. Our key\ninsight is to leverage the special structure of agents' objective and\nconstraint functions that are common in multi-agent interactions for fast and\nreliable planning. More precisely, we identify the structure of agents' cost\nfunctions under which the resulting dynamic game is an instance of a\nconstrained potential dynamic game. Constrained potential dynamic games are a\nclass of games for which instead of solving a set of coupled constrained\noptimal control problems, a Nash equilibrium can be found by solving a single\nconstrained optimal control problem. This simplifies constrained interactive\ntrajectory planning significantly. We compare the performance of our method in\na navigation setup involving four planar agents and show that our method is on\naverage 20 times faster than the state-of-the-art. We further provide\nexperimental validation of our proposed method in a navigation setup involving\none quadrotor and two humans.",
    "descriptor": "",
    "authors": [
      "Maulik Bhatt",
      "Ayberk Yaraneri",
      "Negar Mehr"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.08963"
  },
  {
    "id": "arXiv:2206.08965",
    "title": "KitBit: A New AI Model for Solving Intelligence Tests and Numerical  Series",
    "abstract": "The resolution of intelligence tests, in particular numerical sequences, has\nbeen of great interest in the evaluation of AI systems. We present a new\ncomputational model called KitBit that uses a reduced set of algorithms and\ntheir combinations to build a predictive model that finds the underlying\npattern in numerical sequences, such as those included in IQ tests and others\nof much greater complexity. We present the fundamentals of the model and its\napplication in different cases. First, the system is tested on a set of number\nseries used in IQ tests collected from various sources. Next, our model is\nsuccessfully applied on the sequences used to evaluate the models reported in\nthe literature. In both cases, the system is capable of solving these types of\nproblems in less than a second using standard computing power. Finally,\nKitBit's algorithms have been applied for the first time to the complete set of\nentire sequences of the well-known OEIS database. We find a pattern in the form\nof a list of algorithms and predict the following terms in the largest number\nof series to date. These results demonstrate the potential of KitBit to solve\ncomplex problems that could be represented numerically.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "V\u00edctor Corsino",
      "Jos\u00e9 Manuel Gilp\u00e9rez",
      "Luis Herrera"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.08965"
  },
  {
    "id": "arXiv:2206.08966",
    "title": "Actionable Guidance for High-Consequence AI Risk Management: Towards  Standards Addressing AI Catastrophic Risks",
    "abstract": "Artificial intelligence (AI) systems can provide many beneficial capabilities\nbut also risks of adverse events. Some AI systems could present risks of events\nwith very high or catastrophic consequences at societal scale. The US National\nInstitute of Standards and Technology (NIST) is developing the NIST Artificial\nIntelligence Risk Management Framework (AI RMF) as voluntary guidance on AI\nrisk assessment and management for AI developers and others. For addressing\nrisks of events with catastrophic consequences, NIST indicated a need to\ntranslate from high level principles to actionable risk management guidance.\nIn this document, we provide detailed actionable-guidance recommendations\nfocused on identifying and managing risks of events with very high or\ncatastrophic consequences, intended as a risk management practices resource for\nNIST for AI RMF version 1.0 (scheduled for release in early 2023), or for AI\nRMF users, or for other AI risk management guidance and standards as\nappropriate. We also provide our methodology for our recommendations.\nWe provide actionable-guidance recommendations for AI RMF 1.0 on: identifying\nrisks from potential unintended uses and misuses of AI systems; including\ncatastrophic-risk factors within the scope of risk assessments and impact\nassessments; identifying and mitigating human rights harms; and reporting\ninformation on AI risk factors including catastrophic-risk factors.\nIn addition, we provide recommendations on additional issues for a roadmap\nfor later versions of the AI RMF or supplementary publications. These include:\nproviding an AI RMF Profile with supplementary guidance for cutting-edge\nincreasingly multi-purpose or general-purpose AI.\nWe aim for this work to be a concrete risk-management practices contribution,\nand to stimulate constructive dialogue on how to address catastrophic risks and\nassociated issues in AI standards.",
    "descriptor": "\nComments: 56 pages\n",
    "authors": [
      "Anthony M. Barrett",
      "Dan Hendrycks",
      "Jessica Newman",
      "Brandie Nonnecke"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.08966"
  },
  {
    "id": "arXiv:2206.08967",
    "title": "Random Forest of Epidemiological Models for Influenza Forecasting",
    "abstract": "Forecasting the hospitalizations caused by the Influenza virus is vital for\npublic health planning so that hospitals can be better prepared for an influx\nof patients. Many forecasting methods have been used in real-time during the\nInfluenza seasons and submitted to the CDC for public communication. The\nforecasting models range from mechanistic models, and auto-regression models to\nmachine learning models. We hypothesize that we can improve forecasting by\nusing multiple mechanistic models to produce potential trajectories and use\nmachine learning to learn how to combine those trajectories into an improved\nforecast. We propose a Tree Ensemble model design that utilizes the individual\npredictors of our baseline model SIkJalpha to improve its performance. Each\npredictor is generated by changing a set of hyper-parameters. We compare our\nprospective forecasts deployed for the FluSight challenge (2022) to all the\nother submitted approaches. Our approach is fully automated and does not\nrequire any manual tuning. We demonstrate that our Random Forest-based approach\nis able to improve upon the forecasts of the individual predictors in terms of\nmean absolute error, coverage, and weighted interval score. Our method\noutperforms all other models in terms of the mean absolute error and the\nweighted interval score based on the mean across all weekly submissions in the\ncurrent season (2022). Explainability of the Random Forest (through analysis of\nthe trees) enables us to gain insights into how it improves upon the individual\npredictors.",
    "descriptor": "",
    "authors": [
      "Majd Al Aawar",
      "Ajitesh Srivastava"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.08967"
  },
  {
    "id": "arXiv:2206.08970",
    "title": "MultiEarth 2022 -- The Champion Solution for the Matrix Completion  Challenge via Multimodal Regression and Generation",
    "abstract": "Earth observation satellites have been continuously monitoring the earth\nenvironment for years at different locations and spectral bands with different\nmodalities. Due to complex satellite sensing conditions (e.g., weather, cloud,\natmosphere, orbit), some observations for certain modalities, bands, locations,\nand times may not be available. The MultiEarth Matrix Completion Challenge in\nCVPR 2022 [1] provides the multimodal satellite data for addressing such data\nsparsity challenges with the Amazon Rainforest as the region of interest. This\nwork proposes an adaptive real-time multimodal regression and generation\nframework and achieves superior performance on unseen test queries in this\nchallenge with an LPIPS of 0.2226, a PSNR of 123.0372, and an SSIM of 0.6347.",
    "descriptor": "\nComments: CVPR 2022, MultiEarth 2022, Matrix Completion Challenge\n",
    "authors": [
      "Bo Peng",
      "Hongchen Liu",
      "Hang Zhou",
      "Yuchuan Gou",
      "Jui-Hsin Lai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.08970"
  },
  {
    "id": "arXiv:2206.08971",
    "title": "Capture the Flag for Team Construction in Cybersecurity",
    "abstract": "Team collaboration among individuals with diverse sets of expertise and\nskills is essential for solving complex problems. As part of an\ninterdisciplinary effort, we studied the effects of Capture the Flag (CTF)\ngame, a popular and engaging education/training tool in cybersecurity and\nengineering, in enhancing team construction and collaboration. We developed a\nframework to incorporate CTF as part of a computer-human process for expertise\nrecognition and role assignment and evaluated and tested its effectiveness\nthrough a study with cybersecurity students enrolled in a Virtual Teams course.\nIn our computer-human process framework, the post-CTF algorithm using the CTF\noutcomes assembles the team (assigning individuals to teams) and provides the\ninitial role assignments, which then gets updated by human-based team\ndiscussions. This paper shares our insights, design choices/rationales, and\nanalyses of our CTF-incorporated computer-human process framework. The\nstudents' evaluations revealed that the computer-human process framework was\nhelpful in learning about their team members' backgrounds and expertise and\nassigning roles accordingly made a positive impact on the learning outcomes for\nthe team collaboration skills in the course. This experience report showcases\nthe utility of CTF as a tool for expertise recognition and role assignments in\nteams and highlights the complementary roles of CTF-based and discussion-based\nprocesses for an effective team collaboration among engineering students.",
    "descriptor": "\nComments: 7 pages, including 6 figures and 1 table\n",
    "authors": [
      "Sang-Yoon Chang",
      "Kay Yoon",
      "Simeon Wuthier",
      "Kelei Zhang"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.08971"
  },
  {
    "id": "arXiv:2206.08974",
    "title": "DPDR: A novel machine learning method for the Decision Process for  Dimensionality Reduction",
    "abstract": "This paper discusses the critical decision process of extracting or selecting\nthe features in a supervised learning context. It is often confusing to find a\nsuitable method to reduce dimensionality. There are pros and cons to deciding\nbetween a feature selection and feature extraction according to the data's\nnature and the user's preferences. Indeed, the user may want to emphasize the\nresults toward integrity or interpretability and a specific data resolution.\nThis paper proposes a new method to choose the best dimensionality reduction\nmethod in a supervised learning context. It also helps to drop or reconstruct\nthe features until a target resolution is reached. This target resolution can\nbe user-defined, or it can be automatically defined by the method. The method\napplies a regression or a classification, evaluates the results, and gives a\ndiagnosis about the best dimensionality reduction process in this specific\nsupervised learning context. The main algorithms used are the Random Forest\nalgorithms (RF), the Principal Component Analysis (PCA) algorithm, and the\nmultilayer perceptron (MLP) neural network algorithm. Six use cases are\npresented, and every one is based on some well-known technique to generate\nsynthetic data. This research discusses each choice that can be made in the\nprocess, aiming to clarify the issues about the entire decision process of\nselecting or extracting the features.",
    "descriptor": "",
    "authors": [
      "Jean-S\u00e9bastien Dessureault",
      "Daniel Massicotte"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.08974"
  },
  {
    "id": "arXiv:2206.08977",
    "title": "BN-HTRd: A Benchmark Dataset for Document Level Offline Bangla  Handwritten Text Recognition (HTR) and Line Segmentation",
    "abstract": "We introduce a new dataset for offline Handwritten Text Recognition (HTR)\nfrom images of Bangla scripts comprising words, lines, and document-level\nannotations. The BN-HTRd dataset is based on the BBC Bangla News corpus, meant\nto act as ground truth texts. These texts were subsequently used to generate\nthe annotations that were filled out by people with their handwriting. Our\ndataset includes 788 images of handwritten pages produced by approximately 150\ndifferent writers. It can be adopted as a basis for various handwriting\nclassification tasks such as end-to-end document recognition, word-spotting,\nword or line segmentation, and so on. We also propose a scheme to segment\nBangla handwritten document images into corresponding lines in an unsupervised\nmanner. Our line segmentation approach takes care of the variability involved\nin different writing styles, accurately segmenting complex handwritten text\nlines of curvilinear nature. Along with a bunch of pre-processing and\nmorphological operations, both Hough line and circle transforms were employed\nto distinguish different linear components. In order to arrange those\ncomponents into their corresponding lines, we followed an unsupervised\nclustering approach. The average success rate of our segmentation technique is\n81.57% in terms of FM metrics (similar to F-measure) with a mean Average\nPrecision (mAP) of 0.547.",
    "descriptor": "",
    "authors": [
      "Md. Ataur Rahman",
      "Nazifa Tabassum",
      "Mitu Paul",
      "Riya Pal",
      "Mohammad Khairul Islam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.08977"
  },
  {
    "id": "arXiv:2206.08978",
    "title": "Towards a Deep Multi-layered Dialectal Language Analysis: A Case Study  of African-American English",
    "abstract": "Currently, natural language processing (NLP) models proliferate language\ndiscrimination leading to potentially harmful societal impacts as a result of\nbiased outcomes. For example, part-of-speech taggers trained on Mainstream\nAmerican English (MAE) produce non-interpretable results when applied to\nAfrican American English (AAE) as a result of language features not seen during\ntraining. In this work, we incorporate a human-in-the-loop paradigm to gain a\nbetter understanding of AAE speakers' behavior and their language use, and\nhighlight the need for dialectal language inclusivity so that native AAE\nspeakers can extensively interact with NLP systems while reducing feelings of\ndisenfranchisement.",
    "descriptor": "\nComments: Accepted to the NAACL 2022 (HCI+NLP) Workshop\n",
    "authors": [
      "Jamell Dacon"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.08978"
  },
  {
    "id": "arXiv:2206.08980",
    "title": "Explainable Global Error Weighted on Feature Importance: The xGEWFI  metric to evaluate the error of data imputation and data augmentation",
    "abstract": "Evaluating the performance of an algorithm is crucial. Evaluating the\nperformance of data imputation and data augmentation can be similar since both\ngenerated data can be compared with an original distribution. Although, the\ntypical evaluation metrics have the same flaw: They calculate the feature's\nerror and the global error on the generated data without weighting the error\nwith the feature importance. The result can be good if all of the feature's\nimportance is similar. However, in most cases, the importance of the features\nis imbalanced, and it can induce an important bias on the features and global\nerrors. This paper proposes a novel metric named \"Explainable Global Error\nWeighted on Feature Importance\"(xGEWFI). This new metric is tested in a whole\npreprocessing method that 1. detects the outliers and replaces them with a null\nvalue. 2. imputes the data missing, and 3. augments the data. At the end of the\nprocess, the xGEWFI error is calculated. The distribution error between the\noriginal and generated data is calculated using a Kolmogorov-Smirnov test (KS\ntest) for each feature. Those results are multiplied by the importance of the\nrespective features, calculated using a Random Forest (RF) algorithm. The\nmetric result is expressed in an explainable format, aiming for an ethical AI.",
    "descriptor": "",
    "authors": [
      "Jean-S\u00e9bastien Dessureault",
      "Daniel Massicotte"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.08980"
  },
  {
    "id": "arXiv:2206.08982",
    "title": "ck-means, a novel unsupervised learning method that combines fuzzy and  crispy clustering methods to extract intersecting data",
    "abstract": "Clustering data is a popular feature in the field of unsupervised machine\nlearning. Most algorithms aim to find the best method to extract consistent\nclusters of data, but very few of them intend to cluster data that share the\nsame intersections between two features or more. This paper proposes a method\nto do so. The main idea of this novel method is to generate fuzzy clusters of\ndata using a Fuzzy C-Means (FCM) algorithm. The second part involves applying a\nfilter that selects a range of minimum and maximum membership values,\nemphasizing the border data. A {\\mu} parameter defines the amplitude of this\nrange. It finally applies a k-means algorithm using the membership values\ngenerated by the FCM. Naturally, the data having similar membership values will\nregroup in a new crispy cluster. The algorithm is also able to find the optimal\nnumber of clusters for the FCM and the k-means algorithm, according to the\nconsistency of the clusters given by the Silhouette Index (SI). The result is a\nlist of data and clusters that regroup data sharing the same intersection,\nintersecting two features or more. ck-means allows extracting the very similar\ndata that does not naturally fall in the same cluster but at the intersection\nof two clusters or more. The algorithm also always finds itself the optimal\nnumber of clusters.",
    "descriptor": "",
    "authors": [
      "Jean-S\u00e9bastien Dessureault",
      "Daniel Massicotte"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.08982"
  },
  {
    "id": "arXiv:2206.08990",
    "title": "Shadows Shed Light on 3D Objects",
    "abstract": "3D reconstruction is a fundamental problem in computer vision, and the task\nis especially challenging when the object to reconstruct is partially or fully\noccluded. We introduce a method that uses the shadows cast by an unobserved\nobject in order to infer the possible 3D volumes behind the occlusion. We\ncreate a differentiable image formation model that allows us to jointly infer\nthe 3D shape of an object, its pose, and the position of a light source. Since\nthe approach is end-to-end differentiable, we are able to integrate learned\npriors of object geometry in order to generate realistic 3D shapes of different\nobject categories. Experiments and visualizations show that the method is able\nto generate multiple possible solutions that are consistent with the\nobservation of the shadow. Our approach works even when the position of the\nlight source and object pose are both unknown. Our approach is also robust to\nreal-world images where ground-truth shadow mask is unknown.",
    "descriptor": "\nComments: 19 pages, 10 figures\n",
    "authors": [
      "Ruoshi Liu",
      "Sachit Menon",
      "Chengzhi Mao",
      "Dennis Park",
      "Simon Stent",
      "Carl Vondrick"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2206.08990"
  },
  {
    "id": "arXiv:2206.08991",
    "title": "Efficient Order-Optimal Preconditioners for Implicit Runge-Kutta and  Runge-Kutta-Nystr\u00f6m Methods Applicable to a Large Class of Parabolic and  Hyperbolic PDEs",
    "abstract": "We generalize previous work by Mardal, Nilssen, and Staff (2007, SIAM J. Sci.\nComp. v. 29, pp. 361-375) and Rana, Howle, Long, Meek, and Milestone (2021,\nSIAM J. Sci. Comp. v. 43, p. 475-495) on order-optimal preconditioners for\nparabolic PDEs to a larger class of differential equations and methods. The\nproblems considered are those of the forms $u_{t}=-\\mathcal{K}u+g$ and\n$u_{tt}=-\\mathcal{{K}}u+g$, where the operator $\\mathcal{{K}}$ is defined by\n$\\mathcal{{K}}u:=-\\nabla\\cdot\\left(\\alpha\\nabla u\\right)+\\beta u$ and the\nfunctions $\\alpha$ and $\\beta$ are restricted so that $\\alpha>0$, and\n$\\beta\\ge0$. The methods considered are A-stable implicit Runge--Kutta methods\nfor the parabolic equation and implicit Runge--Kutta--Nystr\\\"om methods for the\nhyperbolic equation. We prove the order optimality of a class of block\npreconditioners for the stage equation system arising from these problems, and\nfurthermore we show that the LD and DU preconditioners of Rana et al. are in\nthis class. We carry out numerical experiments on several test problems in this\nclass -- the 2D diffusion equation, Pennes bioheat equation, the wave equation,\nand the Klein--Gordon equation, with both constant and variable coefficients.\nOur experiments show that these preconditioners, particularly the LD\npreconditioner, are successful at reducing the condition number of the systems\nas well as improving the convergence rate and solve time for GMRES applied to\nthe stage equations.",
    "descriptor": "\nComments: 20 pages, 2 figures\n",
    "authors": [
      "Michael R. Clines",
      "Victoria E. Howle",
      "Katharine R. Long"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.08991"
  },
  {
    "id": "arXiv:2206.08996",
    "title": "Towards Consensus: Reducing Polarization by Perturbing Social Networks",
    "abstract": "This paper studies how a centralized planner can modify the structure of a\nsocial or information network to reduce polarization. First, polarization is\nfound to be highly dependent on degree and structural properties of the\nnetwork. We then formulate the planner's problem under full information, and\nmotivate disagreement-seeking and coordinate descent heuristics. A novel\nsetting for the planner in which the population's innate opinions are\nadversarially chosen is introduced, and shown to be equivalent to maximization\nof the Laplacian's spectral gap. We prove bounds for the effectiveness of a\nstrategy that adds edges between vertices on opposite sides of the cut induced\nby the spectral gap's eigenvector. Finally, these strategies are evaluated on\nsix real-world and synthetic networks. In several networks, we find that\npolarization can be significantly reduced through the addition of a small\nnumber of edges.",
    "descriptor": "\nComments: 29 pages, 12 figures\n",
    "authors": [
      "Miklos Z. Racz",
      "Daniel E. Rigobon"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Structures and Algorithms (cs.DS)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2206.08996"
  },
  {
    "id": "arXiv:2206.08998",
    "title": "A review of machine learning concepts and methods for addressing  challenges in probabilistic hydrological post-processing and forecasting",
    "abstract": "Probabilistic forecasting is receiving growing attention nowadays in a\nvariety of applied fields, including hydrology. Several machine learning\nconcepts and methods are notably relevant to formalizing and optimizing\nprobabilistic forecasting implementations by addressing the relevant\nchallenges. Nonetheless, practically-oriented reviews focusing on such concepts\nand methods are currently missing from the probabilistic hydrological\nforecasting literature. This absence holds despite the pronounced\nintensification in the research efforts for benefitting from machine learning\nin this same literature, and despite the substantial relevant progress that has\nrecently emerged, especially in the field of probabilistic hydrological\npost-processing, which traditionally provides the hydrologists with\nprobabilistic hydrological forecasting implementations. Herein, we aim to fill\nthis specific gap. In our review, we emphasize key ideas and information that\ncan lead to effective popularizations of the studied concepts and methods, as\nsuch an emphasis can support successful future implementations and further\nscientific developments in the field. In the same forward-looking direction, we\nidentify open research questions and propose ideas to be explored in the\nfuture.",
    "descriptor": "",
    "authors": [
      "Georgia Papacharalampous",
      "Hristos Tyralis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2206.08998"
  },
  {
    "id": "arXiv:2206.09004",
    "title": "Towards Efficient Active Learning of PDFA",
    "abstract": "We propose a new active learning algorithm for PDFA based on three main\naspects: a congruence over states which takes into account next-symbol\nprobability distributions, a quantization that copes with differences in\ndistributions, and an efficient tree-based data structure. Experiments showed\nsignificant performance gains with respect to reference implementations.",
    "descriptor": "\nComments: 11 pages, 7 figures, workshop paper\n",
    "authors": [
      "Franz Mayr",
      "Sergio Yovine",
      "Federico Pan",
      "Nicolas Basset",
      "Thao Dang"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09004"
  },
  {
    "id": "arXiv:2206.09008",
    "title": "Orthogonal Rational Approximation of Transfer Functions for  High-Frequency Circuits",
    "abstract": "Rational function approximations find applications in many areas including\nmacro-modeling of high-frequency circuits, model order reduction for controller\ndesign, interpolation and extrapolation of system responses, surrogate models\nfor high-energy physics, and approximation of elementary mathematical\nfunctions. The unknown denominator polynomial of the model results in a\nnon-linear problem, which can be replaced with successive solutions of\nlinearized problems following the Sanathanan-Koerner (SK) iteration. An\northogonal basis can be obtained based on Arnoldi resulting in a stabilized SK\niteration. We present an extension of the stabilized SK, called Orthogonal\nRational Approximation (ORA), which ensures real polynomial coefficients and\nstable poles for realizability of electrical networks. We also introduce an\nefficient implementation of ORA for multi-port networks based on a block QR\ndecomposition.",
    "descriptor": "",
    "authors": [
      "Andrew Ma",
      "Arif Ege Engin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.09008"
  },
  {
    "id": "arXiv:2206.09009",
    "title": "Intelligent Blockchain-based Edge Computing via Deep Reinforcement  Learning: Solutions and Challenges",
    "abstract": "The convergence of mobile edge computing (MEC) and blockchain is transforming\nthe current computing services in wireless Internet-of-Things networks, by\nenabling task offloading with security enhancement based on blockchain mining.\nYet the existing approaches for these enabling technologies are isolated,\nproviding only tailored solutions for specific services and scenarios. To fill\nthis gap, we propose a novel cooperative task offloading and blockchain mining\n(TOBM) scheme for a blockchain-based MEC system, where each edge device not\nonly handles computation tasks but also deals with block mining for improving\nsystem utility. To address the latency issues caused by the blockchain\noperation in MEC, we develop a new Proof-of-Reputation consensus mechanism\nbased on a lightweight block verification strategy. To accommodate the highly\ndynamic environment and high-dimensional system state space, we apply a novel\ndistributed deep reinforcement learning-based approach by using a multi-agent\ndeep deterministic policy gradient algorithm. Experimental results demonstrate\nthe superior performance of the proposed TOBM scheme in terms of enhanced\nsystem reward, improved offloading utility with lower blockchain mining\nlatency, and better system utility, compared to the existing cooperative and\nnon-cooperative schemes. The paper concludes with key technical challenges and\npossible directions for future blockchain-based MEC research.",
    "descriptor": "\nComments: Accepted at IEEE Network Magazine, 8 pages. arXiv admin note: substantial text overlap with arXiv:2109.14263\n",
    "authors": [
      "Dinh C. Nguyen",
      "Van-Dinh Nguyen",
      "Ming Ding",
      "Symeon Chatzinotas",
      "Pubudu N. Pathirana",
      "Aruna Seneviratne",
      "Octavia Dobre",
      "Albert Y. Zomaya"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.09009"
  },
  {
    "id": "arXiv:2206.09010",
    "title": "LIMO: Latent Inceptionism for Targeted Molecule Generation",
    "abstract": "Generation of drug-like molecules with high binding affinity to target\nproteins remains a difficult and resource-intensive task in drug discovery.\nExisting approaches primarily employ reinforcement learning, Markov sampling,\nor deep generative models guided by Gaussian processes, which can be\nprohibitively slow when generating molecules with high binding affinity\ncalculated by computationally-expensive physics-based methods. We present\nLatent Inceptionism on Molecules (LIMO), which significantly accelerates\nmolecule generation with an inceptionism-like technique. LIMO employs a\nvariational autoencoder-generated latent space and property prediction by two\nneural networks in sequence to enable faster gradient-based\nreverse-optimization of molecular properties. Comprehensive experiments show\nthat LIMO performs competitively on benchmark tasks and markedly outperforms\nstate-of-the-art techniques on the novel task of generating drug-like compounds\nwith high binding affinity, reaching nanomolar range against two protein\ntargets. We corroborate these docking-based results with more accurate\nmolecular dynamics-based calculations of absolute binding free energy and show\nthat one of our generated drug-like compounds has a predicted $K_D$ (a measure\nof binding affinity) of $6 \\cdot 10^{-14}$ M against the human estrogen\nreceptor, well beyond the affinities of typical early-stage drug candidates and\nmost FDA-approved drugs to their respective targets. Code is available at\nhttps://github.com/Rose-STL-Lab/LIMO.",
    "descriptor": "\nComments: 16 pages, 5 figures, ICML 2022\n",
    "authors": [
      "Peter Eckmann",
      "Kunyang Sun",
      "Bo Zhao",
      "Mudong Feng",
      "Michael K. Gilson",
      "Rose Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09010"
  },
  {
    "id": "arXiv:2206.09011",
    "title": "Evolutionary Random Graph for Bitcoin Overlay and Blockchain Mining  Networks",
    "abstract": "The world economy is experiencing the novel adoption of distributed\ncurrencies that are free from the control of central banks. Distributed\ncurrencies suffer from extreme volatility, and this can lead to catastrophic\nimplications during future economic crisis. Understanding the dynamics of this\nnew type of currencies is vital for empowering supervisory bodies from current\nreactive and manual incident responders to more proactive and well-informed\nplanners. Bitcoin, the first and dominant distributed cryptocurrency, is still\nnotoriously vague, especially for a financial instrument with market value\nexceeding 1 trillion. Modeling of bitcoin overlay network poses a number of\nimportant theoretical and methodological challenges. Current measuring\napproaches, for example, fail to identify the real network size of bitcoin\nminers. This drastically undermines the ability to predict forks, the suitable\nmining difficulty and most importantly the resilience of the network supporting\nbitcoin. In this work, we developed Evolutionary Random Graph, a theoretical\nmodel that describes the network of bitcoin miners. The correctness of this\nmodel has been validated using simulated and measure real bitcoin data. We then\npredicted forking, optimal mining difficulty, network size and consequently the\nnetwork's inability to stand a drastic drop in bitcoin price using the current\nmining configuration.",
    "descriptor": "\nComments: 12 pages, 12 figures, 13 equations\n",
    "authors": [
      "Jacques Bou Abdo",
      "Shuvalaxmi Dass",
      "Basheer Qolomany",
      "Liaquat Hossain"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.09011"
  },
  {
    "id": "arXiv:2206.09012",
    "title": "Diffusion models as plug-and-play priors",
    "abstract": "We consider the problem of inferring high-dimensional data $\\mathbf{x}$ in a\nmodel that consists of a prior $p(\\mathbf{x})$ and an auxiliary constraint\n$c(\\mathbf{x},\\mathbf{y})$. In this paper, the prior is an independently\ntrained denoising diffusion generative model. The auxiliary constraint is\nexpected to have a differentiable form, but can come from diverse sources. The\npossibility of such inference turns diffusion models into plug-and-play\nmodules, thereby allowing a range of potential applications in adapting models\nto new domains and tasks, such as conditional generation or image segmentation.\nThe structure of diffusion models allows us to perform approximate inference by\niterating differentiation through the fixed denoising network enriched with\ndifferent amounts of noise at each step. Considering many noised versions of\n$\\mathbf{x}$ in evaluation of its fitness is a novel search mechanism that may\nlead to new algorithms for solving combinatorial optimization problems.",
    "descriptor": "\nComments: code: this https URL\n",
    "authors": [
      "Alexandros Graikos",
      "Nikolay Malkin",
      "Nebojsa Jojic",
      "Dimitris Samaras"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09012"
  },
  {
    "id": "arXiv:2206.09016",
    "title": "Path-Gradient Estimators for Continuous Normalizing Flows",
    "abstract": "Recent work has established a path-gradient estimator for simple variational\nGaussian distributions and has argued that the path-gradient is particularly\nbeneficial in the regime in which the variational distribution approaches the\nexact target distribution. In many applications, this regime can however not be\nreached by a simple Gaussian variational distribution. In this work, we\novercome this crucial limitation by proposing a path-gradient estimator for the\nconsiderably more expressive variational family of continuous normalizing\nflows. We outline an efficient algorithm to calculate this estimator and\nestablish its superior performance empirically.",
    "descriptor": "\nComments: 8 pages, 5 figures, 39th International Conference on Machine Learning\n",
    "authors": [
      "Lorenz Vaitl",
      "Kim A. Nicoli",
      "Shinichi Nakajima",
      "Pan Kessel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.09016"
  },
  {
    "id": "arXiv:2206.09020",
    "title": "Uniform and Modular Sequent Systems for Description Logics",
    "abstract": "We introduce a framework that allows for the construction of sequent systems\nfor expressive description logics extending ALC. Our framework not only covers\na wide array of common description logics, but also allows for sequent systems\nto be obtained for extensions of description logics with special formulae that\nwe call \"role relational axioms.\" All sequent systems are sound, complete, and\npossess favorable properties such as height-preserving admissibility of common\nstructural rules and height-preserving invertibility of rules.",
    "descriptor": "\nComments: Accepted to the 35th International Workshop on Description Logics (DL 2022). Appended version\n",
    "authors": [
      "Tim Lyon",
      "Jonas Karge"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.09020"
  },
  {
    "id": "arXiv:2206.09022",
    "title": "Designing MacPherson Suspension Architectures using Bayesian  Optimization",
    "abstract": "Engineering design is traditionally performed by hand: an expert makes design\nproposals based on past experience, and these proposals are then tested for\ncompliance with certain target specifications. Testing for compliance is\nperformed first by computer simulation using what is called a discipline model.\nSuch a model can be implemented by a finite element analysis, multibody systems\napproach, etc. Designs passing this simulation are then considered for physical\nprototyping. The overall process may take months, and is a significant cost in\npractice. We have developed a Bayesian optimization system for partially\nautomating this process by directly optimizing compliance with the target\nspecification with respect to the design parameters. The proposed method is a\ngeneral framework for computing a generalized inverse of a high-dimensional\nnon-linear function that does not require e.g. gradient information, which is\noften unavailable from discipline models. We furthermore develop a two-tier\nconvergence criterion based on (i) convergence to a solution optimally\nsatisfying all specified design criteria, or (ii) convergence to a minimum-norm\nsolution. We demonstrate the proposed approach on a vehicle chassis design\nproblem motivated by an industry setting using a state-of-the-art commercial\ndiscipline model. We show that the proposed approach is general, scalable, and\nefficient, and that the novel convergence criteria can be implemented\nstraightforwardly based on existing concepts and subroutines in popular\nBayesian optimization software packages.",
    "descriptor": "\nComments: 15 pages, 16 figures\n",
    "authors": [
      "Sinnu Susan Thomas",
      "Jacopo Palandri",
      "Mohsen Lakehal-ayat",
      "Punarjay Chakravarty",
      "Friedrich Wolf-Monheim",
      "Matthew B. Blaschko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.09022"
  },
  {
    "id": "arXiv:2206.09023",
    "title": "Efficient Object Manipulation Planning with Monte Carlo Tree Search",
    "abstract": "This paper presents an efficient approach to object manipulation planning\nusing Monte Carlo Tree Search (MCTS) to find contact sequences and an efficient\nADMM-based trajectory optimization algorithm to evaluate the dynamic\nfeasibility of candidate contact sequences. To accelerate MCTS, we propose a\nmethodology to learn a goal-conditioned policy-value network used to direct the\nsearch towards promising nodes. Further, manipulation-specific heuristics\nenable to drastically reduce the search space. Systematic object manipulation\nexperiments in a physics simulator demonstrate the efficiency of our approach.\nIn particular, our approach scales favorably for long manipulation sequences\nthanks to the learned policy-value network, significantly improving planning\nsuccess rate.",
    "descriptor": "",
    "authors": [
      "Huaijiang Zhu",
      "Ludovic Righetti"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.09023"
  },
  {
    "id": "arXiv:2206.09024",
    "title": "Partisan US News Media Representations of Syrian Refugees",
    "abstract": "We investigate how representations of Syrian refugees (2011-2021) differ\nacross US partisan news outlets. We analyze 47,388 articles from the online US\nmedia about Syrian refugees to detail differences in reporting between left-\nand right-leaning media. We use various NLP techniques to understand these\ndifferences. Our polarization and question answering results indicated that\nleft-leaning media tended to represent refugees as child victims, welcome in\nthe US, and right-leaning media cast refugees as Islamic terrorists. We noted\nsimilar results with our sentiment and offensive speech scores over time, which\ndetail possibly unfavorable representations of refugees in right-leaning media.\nA strength of our work is how the different techniques we have applied validate\neach other. Based on our results, we provide several recommendations.\nStakeholders may utilize our findings to intervene around refugee\nrepresentations, and design communications campaigns that improve the way\nsociety sees refugees and possibly aid refugee outcomes.",
    "descriptor": "",
    "authors": [
      "Keyu Chen",
      "Marzieh Babaeianjelodar",
      "Yiwen Shi",
      "Kamila Janmohamed",
      "Rupak Sarkar",
      "Ingmar Weber",
      "Thomas Davidson",
      "Munmun De Choudhury",
      "jonathan huang",
      "Shweta Yadav",
      "Ashique Khudabukhsh",
      "Preslav Ivanov Nakov",
      "Chris bauch",
      "Orestis Papakyriakopoulos",
      "Kaveh Khoshnood",
      "Navin Kumar"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.09024"
  },
  {
    "id": "arXiv:2206.09027",
    "title": "Landscape Learning for Neural Network Inversion",
    "abstract": "Many machine learning methods operate by inverting a neural network at\ninference time, which has become a popular technique for solving inverse\nproblems in computer vision, robotics, and graphics. However, these methods\noften involve gradient descent through a highly non-convex loss landscape,\ncausing the optimization process to be unstable and slow. We introduce a method\nthat learns a loss landscape where gradient descent is efficient, bringing\nmassive improvement and acceleration to the inversion process. We demonstrate\nthis advantage on a number of methods for both generative and discriminative\ntasks, including GAN inversion, adversarial defense, and 3D human pose\nreconstruction.",
    "descriptor": "\nComments: 15 pages, 9 figures\n",
    "authors": [
      "Ruoshi Liu",
      "Chengzhi Mao",
      "Purva Tendulkar",
      "Hao Wang",
      "Carl Vondrick"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09027"
  },
  {
    "id": "arXiv:2206.09029",
    "title": "Binary Early-Exit Network for Adaptive Inference on Low-Resource Devices",
    "abstract": "Deep neural networks have significantly improved performance on a range of\ntasks with the increasing demand for computational resources, leaving\ndeployment on low-resource devices (with limited memory and battery power)\ninfeasible. Binary neural networks (BNNs) tackle the issue to an extent with\nextreme compression and speed-up gains compared to real-valued models. We\npropose a simple but effective method to accelerate inference through unifying\nBNNs with an early-exiting strategy. Our approach allows simple instances to\nexit early based on a decision threshold and utilizes output layers added to\ndifferent intermediate layers to avoid executing the entire binary model. We\nextensively evaluate our method on three audio classification tasks and across\nfour BNNs architectures. Our method demonstrates favorable quality-efficiency\ntrade-offs while being controllable with an entropy-based threshold specified\nby the system user. It also results in better speed-ups (latency less than 6ms)\nwith a single model based on existing BNN architectures without retraining for\ndifferent efficiency levels. It also provides a straightforward way to estimate\nsample difficulty and better understanding of uncertainty around certain\nclasses within the dataset.",
    "descriptor": "\nComments: Interspeech 2022\n",
    "authors": [
      "Aaqib Saeed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09029"
  },
  {
    "id": "arXiv:2206.09030",
    "title": "Responsibility-associated Multi-agent Collision Avoidance with Social  Preferences",
    "abstract": "This paper introduces a novel social preference-aware decentralized safe\ncontrol framework to address the responsibility allocation problem in\nmulti-agent collision avoidance. Considering that agents do not necessarily\ncooperate in symmetric ways, this paper focuses on semi-cooperative behavior\namong heterogeneous agents with varying cooperation levels. Drawing upon the\nidea of Social Value Orientation (SVO) for quantifying the individual\nselfishness, we propose a novel concept of Responsibility-associated Social\nValue Orientation (R-SVO) to express the intended relative social implications\nbetween pairwise agents. This is used to redefine each agent's social\npreferences or personalities in terms of corresponding responsibility shares in\ncontributing to the coordination scenario, such as semi-cooperative collision\navoidance where all agents interact in an asymmetric way. By incorporating such\nrelative social implications through proposed Local Pairwise Responsibility\nWeights, we develop a Responsibility-associated Control Barrier Function-based\nsafe control framework for individual agents, and multi-agent collision\navoidance is achieved with formally provable safety guarantees. Simulations are\nprovided to demonstrate the effectiveness and efficiency of the proposed\nframework in several multi-agent navigation tasks, such as a position-swapping\ngame, a self-driving car highway ramp merging scenario, and a circular position\nswapping game.",
    "descriptor": "\nComments: accepted at the 25th IEEE International Conference on Intelligent Transportation Systems (ITSC 2022)\n",
    "authors": [
      "Yiwei Lyu",
      "Wenhao Luo",
      "John M. Dolan"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.09030"
  },
  {
    "id": "arXiv:2206.09032",
    "title": "Conjunctive Queries with Output Access Patterns under Updates",
    "abstract": "We study the dynamic evaluation of conjunctive queries with output access\npatterns. An access pattern is a partition of the free variables of the query\ninto input and output.The query returns tuples over the output variables given\na tuple over the input variables.\nOur contribution is threefold. First, we give a syntactic characterisation of\nqueries that admit constant time per single-tuple update and whose output\ntuples can be enumerated with constant delay given an input tuple. Second, we\ndefine a class of queries that admit optimal, albeit non-constant, update time\nand delay. Their optimality is predicated on the Online Matrix-Vector\nMultiplication conjecture. Third, we chart the complexity trade-off between\npreprocessing, update time and enumeration delay for such queries. Our results\nrecover prior work on the dynamic evaluation of conjunctive queries without\naccess patterns.",
    "descriptor": "",
    "authors": [
      "Ahmet Kara",
      "Milos Nikolic",
      "Dan Olteanu",
      "Haozhe Zhang"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2206.09032"
  },
  {
    "id": "arXiv:2206.09034",
    "title": "Stop Overcomplicating Selective Classification: Use Max-Logit",
    "abstract": "We tackle the problem of Selective Classification where the goal is to\nachieve the best performance on the desired coverages of the dataset. Recent\nstate-of-the-art selective methods come with architectural changes either via\nintroducing a separate selection head or an extra abstention logit. In this\npaper, we present surprising results for Selective Classification by confirming\nthat the superior performance of state-of-the-art methods is owed to training a\nmore generalizable classifier; however, their selection mechanism is\nsuboptimal. We argue that the selection mechanism should be rooted in the\nobjective function instead of a separately calculated score. Accordingly, in\nthis paper, we motivate an alternative selection strategy that is based on the\ncross entropy loss for the classification settings, namely, max of the logits.\nOur proposed selection strategy achieves better results by a significant\nmargin, consistently, across all coverages and all datasets, without any\nadditional computation. Finally, inspired by our superior selection mechanism,\nwe propose to further regularize the objective function with\nentropy-minimization. Our proposed max-logit selection with the modified loss\nfunction achieves new state-of-the-art results for Selective Classification.",
    "descriptor": "\nComments: 18 pages, 5 figures, 9 tables\n",
    "authors": [
      "Leo Feng",
      "Mohamed Osama Ahmed",
      "Hossein Hajimirsadeghi",
      "Amir Abdi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09034"
  },
  {
    "id": "arXiv:2206.09037",
    "title": "Assessing transportation accessibility equity via open data",
    "abstract": "We propose a methodology to assess transportation accessibility inequity in\nmetropolitan areas. The methodology is based on the classic analysis tools of\nLorenz curves and Gini indices, but the novelty resides in the fact that it can\nbe easily applied in an automated way to several cities around the World, with\nno need for customized data treatment. Indeed, our equity metrics can be\ncomputed solely relying on open data, publicly available in standardized form.\nWe showcase our method and study transp",
    "descriptor": "",
    "authors": [
      "Amirhesam Badeanlou",
      "Andrea Araldo",
      "Marco Diana"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "General Economics (econ.GN)"
    ],
    "url": "https://arxiv.org/abs/2206.09037"
  },
  {
    "id": "arXiv:2206.09038",
    "title": "Validation of Vector Data using Oblique Images",
    "abstract": "Oblique images are aerial photographs taken at oblique angles to the earth's\nsurface. Projections of vector and other geospatial data in these images depend\non camera parameters, positions of the geospatial entities, surface terrain,\nocclusions, and visibility. This paper presents a robust and scalable algorithm\nto detect inconsistencies in vector data using oblique images. The algorithm\nuses image descriptors to encode the local appearance of a geospatial entity in\nimages. These image descriptors combine color, pixel-intensity gradients,\ntexture, and steerable filter responses. A Support Vector Machine classifier is\ntrained to detect image descriptors that are not consistent with underlying\nvector data, digital elevation maps, building models, and camera parameters. In\nthis paper, we train the classifier on visible road segments and non-road data.\nThereafter, the trained classifier detects inconsistencies in vectors, which\ninclude both occluded and misaligned road segments. The consistent road\nsegments validate our vector, DEM, and 3-D model data for those areas while\ninconsistent segments point out errors. We further show that a search for\ndescriptors that are consistent with visible road segments in the neighborhood\nof a misaligned road yields the desired road alignment that is consistent with\npixels in the image.",
    "descriptor": "\nComments: In Proceedings of 16th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems (ACM GIS'08)\n",
    "authors": [
      "Pragyana Mishra",
      "Eyal Ofek",
      "Gur Kimchi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09038"
  },
  {
    "id": "arXiv:2206.09044",
    "title": "Universal Complexity Bounds Based on Value Iteration and Application to  Entropy Games",
    "abstract": "We develop value iteration-based algorithms to solve in a unified manner\ndifferent classes of combinatorial zero-sum games with mean-payoff type\nrewards. These algorithms rely on an oracle, evaluating the dynamic programming\noperator up to a given precision. We show that the number of calls to the\noracle needed to determine exact optimal (positional) strategies is, up to a\nfactor polynomial in the dimension, of order R/sep, where the \"separation\" sep\nis defined as the minimal difference between distinct values arising from\nstrategies, and R is a metric estimate, involving the norm of approximate sub\nand super-eigenvectors of the dynamic programming operator. We illustrate this\nmethod by two applications. The first one is a new proof, leading to improved\ncomplexity estimates, of a theorem of Boros, Elbassioni, Gurvich and Makino,\nshowing that turn-based mean-payoff games with a fixed number of random\npositions can be solved in pseudo-polynomial time. The second one concerns\nentropy games, a model introduced by Asarin, Cervelle, Degorre, Dima, Horn and\nKozyakin. The rank of an entropy game is defined as the maximal rank among all\nthe ambiguity matrices determined by strategies of the two players. We show\nthat entropy games with a fixed rank, in their original formulation, can be\nsolved in polynomial time, and that an extension of entropy games incorporating\nweights can be solved in pseudo-polynomial time under the same fixed rank\ncondition.",
    "descriptor": "\nComments: 41 pages, 7 figures\n",
    "authors": [
      "Xavier Allamigeon",
      "St\u00e9phane Gaubert",
      "Ricardo D. Katz",
      "Mateusz Skomra"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2206.09044"
  },
  {
    "id": "arXiv:2206.09045",
    "title": "Enabling Undergrounding of Long-Distance Transmission Lines with Low  Frequency AC Technology",
    "abstract": "With increasing prevalence of severe natural hazards and the ignition of\nwildfires by power lines, many power system planners are considering converting\noverhead lines to underground cables to mitigate risks related to these events.\nSystems with a large proportion of underground cables can bring challenges due\nto the capacitance and losses of the cables, factors which may limit the\npotential for hardening in critical areas. Low frequency AC (LFAC) transmission\nsolves these problems, as lowering the frequency decreases both the effects of\ncapacitance and the losses. This paper presents a tractable frequency-dependent\nmodel for underground cables and incorporates it into the open source optimal\npower flow tool VariableFrequencyOPF.jl. The model and implementation are used\nto demonstrate the benefits of LFAC in a case study involving two\nmulti-terminal cable upgrades with LFAC, including a comparison with HVDC. The\nresults demonstrate the value of LFAC systems for both power flow control and\nreduction of losses.",
    "descriptor": "\nComments: Accepted for presentation in 11th Bulk Power Systems Dynamics and Control Symposium (IREP 2022)\n",
    "authors": [
      "David K. Sehloff",
      "Line A. Roald"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.09045"
  },
  {
    "id": "arXiv:2206.09046",
    "title": "Beyond Rewards: a Hierarchical Perspective on Offline Multiagent  Behavioral Analysis",
    "abstract": "Each year, expert-level performance is attained in increasingly-complex\nmultiagent domains, notable examples including Go, Poker, and StarCraft II.\nThis rapid progression is accompanied by a commensurate need to better\nunderstand how such agents attain this performance, to enable their safe\ndeployment, identify limitations, and reveal potential means of improving them.\nIn this paper we take a step back from performance-focused multiagent learning,\nand instead turn our attention towards agent behavior analysis. We introduce a\nmodel-agnostic method for discovery of behavior clusters in multiagent domains,\nusing variational inference to learn a hierarchy of behaviors at the joint and\nlocal agent levels. Our framework makes no assumption about agents' underlying\nlearning algorithms, does not require access to their latent states or models,\nand can be trained using entirely offline observational data. We illustrate the\neffectiveness of our method for enabling the coupled understanding of behaviors\nat the joint and local agent level, detection of behavior changepoints\nthroughout training, discovery of core behavioral concepts (e.g., those that\nfacilitate higher returns), and demonstrate the approach's scalability to a\nhigh-dimensional multiagent MuJoCo control domain.",
    "descriptor": "",
    "authors": [
      "Shayegan Omidshafiei",
      "Andrei Kapishnikov",
      "Yannick Assogba",
      "Lucas Dixon",
      "Been Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2206.09046"
  },
  {
    "id": "arXiv:2206.09048",
    "title": "ICLR 2022 Challenge for Computational Geometry and Topology: Design and  Results",
    "abstract": "This paper presents the computational challenge on differential geometry and\ntopology that was hosted within the ICLR 2022 workshop ``Geometric and\nTopological Representation Learning\". The competition asked participants to\nprovide implementations of machine learning algorithms on manifolds that would\nrespect the API of the open-source software Geomstats (manifold part) and\nScikit-Learn (machine learning part) or PyTorch. The challenge attracted seven\nteams in its two month duration. This paper describes the design of the\nchallenge and summarizes its main findings.",
    "descriptor": "",
    "authors": [
      "Adele Myers",
      "Saiteja Utpala",
      "Shubham Talbar",
      "Sophia Sanborn",
      "Christian Shewmake",
      "Claire Donnat",
      "Johan Mathe",
      "Umberto Lupo",
      "Rishi Sonthalia",
      "Xinyue Cui",
      "Tom Szwagier",
      "Arthur Pignet",
      "Andri Bergsson",
      "Soren Hauberg",
      "Dmitriy Nielsen",
      "Stefan Sommer",
      "David Klindt",
      "Erik Hermansen",
      "Melvin Vaupel",
      "Benjamin Dunn",
      "Jeffrey Xiong",
      "Noga Aharony",
      "Itsik Pe'er",
      "Felix Ambellan",
      "Martin Hanik",
      "Esfandiar Nava-Yazdani",
      "Christoph von Tycowicz",
      "Nina Miolane"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2206.09048"
  },
  {
    "id": "arXiv:2206.09053",
    "title": "An imminent collision monitoring system with safe stopping interventions  for autonomous aerial flights",
    "abstract": "Collision avoidance requires tradeoffs in planning time horizons. Depending\non the planner, safety cannot always be guaranteed in uncertain environments\ngiven map updates. To mitigate situations where the planner leads the vehicle\ninto a state of collision or the vehicle reaches a point where no trajectories\nare feasible, we propose a continuous collision checking algorithm. The\nimminent collision checking system continuously monitors vehicle safety, and\nplans a safe trajectory that leads the vehicle to a stop within the observed\nmap. We test our proposed pipeline alongside a teleoperated navigation in\nreal-life experiments, and in simulated random-forest and warehouse\nenvironments where we show that with our method, we are able to mitigate\ncollisions with a success rate of at least 90\\%.",
    "descriptor": "",
    "authors": [
      "Jasmine Cheng",
      "Xuning Yang",
      "Nathan Michael"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.09053"
  },
  {
    "id": "arXiv:2206.09054",
    "title": "Learning the parameters of a differential equation from its trajectory  via the adjoint equation",
    "abstract": "The paper contributes to strengthening the relation between machine learning\nand the theory of differential equations. In this context, the inverse problem\nof fitting the parameters, and the initial condition of a differential equation\nto some measurements constitutes a key issue. The paper explores an abstraction\nthat can be used to construct a family of loss functions with the aim of\nfitting the solution of an initial value problem to a set of discrete or\ncontinuous measurements. It is shown, that an extension of the adjoint equation\ncan be used to derive the gradient of the loss function as a continuous\nanalogue of backpropagation in machine learning. Numerical evidence is\npresented that under reasonably controlled circumstances the gradients obtained\nthis way can be used in a gradient descent to fit the solution of an initial\nvalue problem to a set of continuous noisy measurements, and a set of discrete\nnoisy measurements that are recorded at uncertain times.",
    "descriptor": "",
    "authors": [
      "Imre Fekete",
      "Andr\u00e1s Moln\u00e1r",
      "P\u00e9ter L. Simon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.09054"
  },
  {
    "id": "arXiv:2206.09055",
    "title": "Augmented Imagefication: A Data-driven Fault Detection Method for  Aircraft Air Data Sensors",
    "abstract": "In this paper, a novel data-driven approach named Augmented Imagefication for\nFault detection (FD) of aircraft air data sensors (ADS) is proposed.\nExemplifying the FD problem of aircraft air data sensors, an online FD scheme\non edge device based on deep neural network (DNN) is developed. First, the\naircraft inertial reference unit measurements is adopted as equivalent inputs,\nwhich is scalable to different aircraft/flight cases. Data associated with 6\ndifferent aircraft/flight conditions are collected to provide diversity\n(scalability) in the training/testing database. Then Augmented Imagefication is\nproposed for the DNN-based prediction of flying conditions. The raw data are\nreshaped as a grayscale image for convolutional operation, and the necessity of\naugmentation is analyzed and pointed out. Different kinds of augmented method,\ni.e. Flip, Repeat, Tile and their combinations are discussed, the result shows\nthat the All Repeat operation in both axes of image matrix leads to the best\nperformance of DNN. The interpretability of DNN is studied based on Grad-CAM,\nwhich provide a better understanding and further solidifies the robustness of\nDNN. Next the DNN model, VGG-16 with augmented imagefication data is optimized\nfor mobile hardware deployment. After pruning of DNN, a lightweight model\n(98.79% smaller than original VGG-16) with high accuracy (slightly up by 0.27%)\nand fast speed (time delay is reduced by 87.54%) is obtained. And the\nhyperparameters optimization of DNN based on TPE is implemented and the best\ncombination of hyperparameters is determined (learning rate 0.001, iterative\nepochs 600, and batch size 100 yields the highest accuracy at 0.987). Finally,\na online FD deployment based on edge device, Jetson Nano, is developed and the\nreal time monitoring of aircraft is achieved. We believe that this method is\ninstructive for addressing the FD problems in other similar fields.",
    "descriptor": "",
    "authors": [
      "Hang Zhao",
      "Jinyi Ma",
      "Zhongzhi Li",
      "Yiqun Dong",
      "Jianliang Ai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.09055"
  },
  {
    "id": "arXiv:2206.09059",
    "title": "CLiMB: A Continual Learning Benchmark for Vision-and-Language Tasks",
    "abstract": "Current state-of-the-art vision-and-language models are evaluated on tasks\neither individually or in a multi-task setting, overlooking the challenges of\ncontinually learning (CL) tasks as they arrive. Existing CL benchmarks have\nfacilitated research on task adaptation and mitigating \"catastrophic\nforgetting\", but are limited to vision-only and language-only tasks. We present\nCLiMB, a benchmark to study the challenge of learning multimodal tasks in a CL\nsetting, and to systematically evaluate how upstream continual learning can\nrapidly generalize to new multimodal and unimodal tasks. CLiMB includes\nimplementations of several CL algorithms and a modified Vision-Language\nTransformer (ViLT) model that can be deployed on both multimodal and unimodal\ntasks. We find that common CL methods can help mitigate forgetting during\nmultimodal task learning, but do not enable cross-task knowledge transfer. We\nenvision that CLiMB will facilitate research on a new class of CL algorithms\nfor this challenging multimodal setting.",
    "descriptor": "",
    "authors": [
      "Tejas Srinivasan",
      "Ting-Yun Chang",
      "Leticia Leonor Pinto Alva",
      "Georgios Chochlakis",
      "Mohammad Rostami",
      "Jesse Thomason"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09059"
  },
  {
    "id": "arXiv:2206.09061",
    "title": "Design of Supervision-Scalable Learning Systems: Methodology and  Performance Benchmarking",
    "abstract": "The design of robust learning systems that offer stable performance under a\nwide range of supervision degrees is investigated in this work. We choose the\nimage classification problem as an illustrative example and focus on the design\nof modularized systems that consist of three learning modules: representation\nlearning, feature learning and decision learning. We discuss ways to adjust\neach module so that the design is robust with respect to different training\nsample numbers. Based on these ideas, we propose two families of learning\nsystems. One adopts the classical histogram of oriented gradients (HOG)\nfeatures while the other uses successive-subspace-learning (SSL) features. We\ntest their performance against LeNet-5, which is an end-to-end optimized neural\nnetwork, for MNIST and Fashion-MNIST datasets. The number of training samples\nper image class goes from the extremely weak supervision condition (i.e., 1\nlabeled sample per class) to the strong supervision condition (i.e., 4096\nlabeled sample per class) with gradual transition in between (i.e., $2^n$,\n$n=0, 1, \\cdots, 12$). Experimental results show that the two families of\nmodularized learning systems have more robust performance than LeNet-5. They\nboth outperform LeNet-5 by a large margin for small $n$ and have performance\ncomparable with that of LeNet-5 for large $n$.",
    "descriptor": "\nComments: 16 pages, 12 figures, 2 tables, under consideration at Pattern Recognition\n",
    "authors": [
      "Yijing Yang",
      "Hongyu Fu",
      "C.-C. Jay Kuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09061"
  },
  {
    "id": "arXiv:2206.09068",
    "title": "Attention-based Dynamic Subspace Learners for Medical Image Analysis",
    "abstract": "Learning similarity is a key aspect in medical image analysis, particularly\nin recommendation systems or in uncovering the interpretation of anatomical\ndata in images. Most existing methods learn such similarities in the embedding\nspace over image sets using a single metric learner. Images, however, have a\nvariety of object attributes such as color, shape, or artifacts. Encoding such\nattributes using a single metric learner is inadequate and may fail to\ngeneralize. Instead, multiple learners could focus on separate aspects of these\nattributes in subspaces of an overarching embedding. This, however, implies the\nnumber of learners to be found empirically for each new dataset. This work,\nDynamic Subspace Learners, proposes to dynamically exploit multiple learners by\nremoving the need of knowing apriori the number of learners and aggregating new\nsubspace learners during training. Furthermore, the visual interpretability of\nsuch subspace learning is enforced by integrating an attention module into our\nmethod. This integrated attention mechanism provides a visual insight of\ndiscriminative image features that contribute to the clustering of image sets\nand a visual explanation of the embedding features. The benefits of our\nattention-based dynamic subspace learners are evaluated in the application of\nimage clustering, image retrieval, and weakly supervised segmentation. Our\nmethod achieves competitive results with the performances of multiple learners\nbaselines and significantly outperforms the classification network in terms of\nclustering and retrieval scores on three different public benchmark datasets.\nMoreover, our attention maps offer a proxy-labels, which improves the\nsegmentation accuracy up to 15% in Dice scores when compared to\nstate-of-the-art interpretation techniques.",
    "descriptor": "",
    "authors": [
      "Sukesh Adiga V",
      "Jose Dolz",
      "Herve Lombaert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09068"
  },
  {
    "id": "arXiv:2206.09071",
    "title": "Analysis & Computational Complexity Reduction of Monocular and Stereo  Depth Estimation Techniques",
    "abstract": "Accurate depth estimation with lowest compute and energy cost is a crucial\nrequirement for unmanned and battery operated autonomous systems. Robotic\napplications require real time depth estimation for navigation and decision\nmaking under rapidly changing 3D surroundings. A high accuracy algorithm may\nprovide the best depth estimation but may consume tremendous compute and energy\nresources. A general trade-off is to choose less accurate methods for initial\ndepth estimate and a more accurate yet compute intensive method when needed.\nPrevious work has shown this trade-off can be improved by developing a\nstate-of-the-art method (AnyNet) to improve stereo depth estimation.\nWe studied both the monocular and stereo vision depth estimation methods and\ninvestigated methods to reduce computational complexity of these methods. This\nwas our baseline. Consequently, our experiments show reduction of monocular\ndepth estimation model size by ~75% reduces accuracy by less than 2% (SSIM\nmetric). Our experiments with the novel stereo vision method (AnyNet) show that\naccuracy of depth estimation does not degrade more than 3% (three pixel error\nmetric) in spite of reduction in model size by ~20%. We have shown that smaller\nmodels can indeed perform competitively.",
    "descriptor": "",
    "authors": [
      "Rajeev Patwari",
      "Varo Ly"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.09071"
  },
  {
    "id": "arXiv:2206.09074",
    "title": "Weakly Supervised Classification of Vital Sign Alerts as Real or  Artifact",
    "abstract": "A significant proportion of clinical physiologic monitoring alarms are false.\nThis often leads to alarm fatigue in clinical personnel, inevitably\ncompromising patient safety. To combat this issue, researchers have attempted\nto build Machine Learning (ML) models capable of accurately adjudicating Vital\nSign (VS) alerts raised at the bedside of hemodynamically monitored patients as\nreal or artifact. Previous studies have utilized supervised ML techniques that\nrequire substantial amounts of hand-labeled data. However, manually harvesting\nsuch data can be costly, time-consuming, and mundane, and is a key factor\nlimiting the widespread adoption of ML in healthcare (HC). Instead, we explore\nthe use of multiple, individually imperfect heuristics to automatically assign\nprobabilistic labels to unlabeled training data using weak supervision. Our\nweakly supervised models perform competitively with traditional supervised\ntechniques and require less involvement from domain experts, demonstrating\ntheir use as efficient and practical alternatives to supervised learning in HC\napplications of ML.",
    "descriptor": "\nComments: Accepted at American Medical Informatics Association (AMIA) Annual Symposium 2022. 10 pages, 4 figures and 2 tables\n",
    "authors": [
      "Arnab Dey",
      "Mononito Goswami",
      "Joo Heung Yoon",
      "Gilles Clermont",
      "Michael Pinsky",
      "Marilyn Hravnak",
      "Artur Dubrawski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.09074"
  },
  {
    "id": "arXiv:2206.09075",
    "title": "Comment on Transferability and Input Transformation with Additive Noise",
    "abstract": "Adversarial attacks have verified the existence of the vulnerability of\nneural networks. By adding small perturbations to a benign example, adversarial\nattacks successfully generate adversarial examples that lead misclassification\nof deep learning models. More importantly, an adversarial example generated\nfrom a specific model can also deceive other models without modification. We\ncall this phenomenon ``transferability\". Here, we analyze the relationship\nbetween transferability and input transformation with additive noise by\nmathematically proving that the modified optimization can produce more\ntransferable adversarial examples.",
    "descriptor": "",
    "authors": [
      "Hoki Kim",
      "Jinseong Park",
      "Jaewook Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.09075"
  },
  {
    "id": "arXiv:2206.09082",
    "title": "Context-aware Proposal Network for Temporal Action Detection",
    "abstract": "This technical report presents our first place winning solution for temporal\naction detection task in CVPR-2022 AcitivityNet Challenge. The task aims to\nlocalize temporal boundaries of action instances with specific classes in long\nuntrimmed videos. Recent mainstream attempts are based on dense boundary\nmatchings and enumerate all possible combinations to produce proposals. We\nargue that the generated proposals contain rich contextual information, which\nmay benefits detection confidence prediction. To this end, our method mainly\nconsists of the following three steps: 1) action classification and feature\nextraction by Slowfast, CSN, TimeSformer, TSP, I3D-flow, VGGish-audio, TPN and\nViViT; 2) proposal generation. Our proposed Context-aware Proposal Network\n(CPN) builds on top of BMN, GTAD and PRN to aggregate contextual information by\nrandomly masking some proposal features. 3) action detection. The final\ndetection prediction is calculated by assigning the proposals with\ncorresponding video-level classifcation results. Finally, we ensemble the\nresults under different feature combination settings and achieve 45.8%\nperformance on the test set, which improves the champion result in CVPR-2021\nActivityNet Challenge by 1.1% in terms of average mAP.",
    "descriptor": "\nComments: First place winning solution for temporal action detection task in CVPR-2022 AcitivityNet Challenge. arXiv admin note: substantial text overlap with arXiv:2106.11812\n",
    "authors": [
      "Xiang Wang",
      "Huaxin Zhang",
      "Shiwei Zhang",
      "Changxin Gao",
      "Yuanjie Shao",
      "Nong Sang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09082"
  },
  {
    "id": "arXiv:2206.09089",
    "title": "A Dynamic Data Driven Approach for Explainable Scene Understanding",
    "abstract": "Scene-understanding is an important topic in the area of Computer Vision, and\nillustrates computational challenges with applications to a wide range of\ndomains including remote sensing, surveillance, smart agriculture, robotics,\nautonomous driving, and smart cities. We consider the active explanation-driven\nunderstanding and classification of scenes. Suppose that an agent utilizing one\nor more sensors is placed in an unknown environment, and based on its sensory\ninput, the agent needs to assign some label to the perceived scene. The agent\ncan adjust its sensor(s) to capture additional details about the scene, but\nthere is a cost associated with sensor manipulation, and as such, it is\nimportant for the agent to understand the scene in a fast and efficient manner.\nIt is also important that the agent understand not only the global state of a\nscene (e.g., the category of the scene or the major events taking place in the\nscene) but also the characteristics/properties of the scene that support\ndecisions and predictions made about the global state of the scene. Finally,\nwhen the agent encounters an unknown scene category, it must be capable of\nrefusing to assign a label to the scene, requesting aid from a human, and\nupdating its underlying knowledge base and machine learning models based on\nfeedback provided by the human. We introduce a dynamic data driven framework\nfor the active explanation-driven classification of scenes. Our framework is\nentitled ACUMEN: Active Classification and Understanding Method by\nExplanation-driven Networks. To demonstrate the utility of the proposed ACUMEN\napproach and show how it can be adapted to a domain-specific application, we\nfocus on an example case study involving the classification of indoor scenes\nusing an active robotic agent with vision-based sensors, i.e., an\nelectro-optical camera.",
    "descriptor": "\nComments: Unpublished draft of book chapter\n",
    "authors": [
      "Zachary A Daniels",
      "Dimitris Metaxas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09089"
  },
  {
    "id": "arXiv:2206.09090",
    "title": "From Understanding Genetic Drift to a Smart-Restart Mechanism for  Estimation-of-Distribution Algorithms",
    "abstract": "Estimation-of-distribution algorithms (EDAs) are optimization algorithms that\nlearn a distribution on the search space from which good solutions can be\nsampled easily. A key parameter of most EDAs is the sample size (population\nsize). If the population size is too small, the update of the probabilistic\nmodel builds on few samples, leading to the undesired effect of genetic drift.\nToo large population sizes avoid genetic drift, but slow down the process.\nBuilding on a recent quantitative analysis of how the population size leads\nto genetic drift, we design a smart-restart mechanism for EDAs. By stopping\nruns when the risk for genetic drift is high, it automatically runs the EDA in\ngood parameter regimes.\nVia a mathematical runtime analysis, we prove a general performance guarantee\nfor this smart-restart scheme. This in particular shows that in many situations\nwhere the optimal (problem-specific) parameter values are known, the restart\nscheme automatically finds these, leading to the asymptotically optimal\nperformance.\nWe also conduct an extensive experimental analysis. On four classic benchmark\nproblems, we clearly observe the critical influence of the population size on\nthe performance, and we find that the smart-restart scheme leads to a\nperformance close to the one obtainable with optimal parameter values. Our\nresults also show that previous theory-based suggestions for the optimal\npopulation size can be far from the optimal ones, leading to a performance\nclearly inferior to the one obtained via the smart-restart scheme. We also\nconduct experiments with PBIL (cross-entropy algorithm) on two combinatorial\noptimization problems from the literature, the max-cut problem and the\nbipartition problem. Again, we observe that the smart-restart mechanism finds\nmuch better values for the population size than those suggested in the\nliterature, leading to a much better performance.",
    "descriptor": "\nComments: Extended version of one GECCO 2020 paper. arXiv admin note: text overlap with arXiv:2004.07141\n",
    "authors": [
      "Weijie Zheng",
      "Benjamin Doerr"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.09090"
  },
  {
    "id": "arXiv:2206.09097",
    "title": "Fully Privacy-Preserving Federated Representation Learning via Secure  Embedding Aggregation",
    "abstract": "We consider a federated representation learning framework, where with the\nassistance of a central server, a group of $N$ distributed clients train\ncollaboratively over their private data, for the representations (or\nembeddings) of a set of entities (e.g., users in a social network). Under this\nframework, for the key step of aggregating local embeddings trained at the\nclients in a private manner, we develop a secure embedding aggregation protocol\nnamed SecEA, which provides information-theoretical privacy guarantees for the\nset of entities and the corresponding embeddings at each client\n$simultaneously$, against a curious server and up to $T < N/2$ colluding\nclients. As the first step of SecEA, the federated learning system performs a\nprivate entity union, for each client to learn all the entities in the system\nwithout knowing which entities belong to which clients. In each aggregation\nround, the local embeddings are secretly shared among the clients using\nLagrange interpolation, and then each client constructs coded queries to\nretrieve the aggregated embeddings for the intended entities. We perform\ncomprehensive experiments on various representation learning tasks to evaluate\nthe utility and efficiency of SecEA, and empirically demonstrate that compared\nwith embedding aggregation protocols without (or with weaker) privacy\nguarantees, SecEA incurs negligible performance loss (within 5%); and the\nadditional computation latency of SecEA diminishes for training deeper models\non larger datasets.",
    "descriptor": "",
    "authors": [
      "Jiaxiang Tang",
      "Jinbao Zhu",
      "Songze Li",
      "Kai Zhang",
      "Lichao Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.09097"
  },
  {
    "id": "arXiv:2206.09098",
    "title": "Existence and Minimax Theorems for Adversarial Surrogate Risks in Binary  Classification",
    "abstract": "Adversarial training is one of the most popular methods for training methods\nrobust to adversarial attacks, however, it is not well-understood from a\ntheoretical perspective. We prove and existence, regularity, and minimax\ntheorems for adversarial surrogate risks. Our results explain some empirical\nobservations on adversarial robustness from prior work and suggest new\ndirections in algorithm development. Furthermore, our results extend previously\nknown existence and minimax theorems for the adversarial classification risk to\nsurrogate risks.",
    "descriptor": "\nComments: 37 pages, 1 Figure\n",
    "authors": [
      "Natalie S. Frank"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2206.09098"
  },
  {
    "id": "arXiv:2206.09099",
    "title": "The Consistency of Adversarial Training for Binary Classification",
    "abstract": "Robustness to adversarial perturbations is of paramount concern in modern\nmachine learning. One of the state-of-the-art methods for training robust\nclassifiers is adversarial training, which involves minimizing a supremum-based\nsurrogate risk. The statistical consistency of surrogate risks is well\nunderstood in the context of standard machine learning, but not in the\nadversarial setting. In this paper, we characterize which supremum-based\nsurrogates are consistent for distributions absolutely continuous with respect\nto Lebesgue measure in binary classification. Furthermore, we obtain\nquantitative bounds relating adversarial surrogate risks to the adversarial\nclassification risk. Lastly, we discuss implications for the $\\cH$-consistency\nof adversarial training.",
    "descriptor": "\nComments: 15 pages, submitted to NeurIps\n",
    "authors": [
      "Natalie S. Frank",
      "Jonathan Niles-Weed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2206.09099"
  },
  {
    "id": "arXiv:2206.09100",
    "title": "Closed-form Error Propagation on the SE_n(3) Group for Invariant  Extended Kalman Filtering with Applications to VINS",
    "abstract": "Pose estimation is important for robotic perception, path planning, etc.\nRobot poses can be modeled on matrix Lie groups and are usually estimated via\nfilter-based methods. In this paper, we establish the closed-form formula for\nthe error propagation for the Invariant extended Kalman filter (IEKF) in the\npresence of random noises and apply it to vision-aided inertial navigation. We\nevaluate our algorithm via numerical simulations and experiments on the\nOPENVINS platform. Both simulations and the experiments performed on the public\nEuRoC MAV datasets demonstrate that our algorithm outperforms some state-of-art\nfilter-based methods such as the quaternion-based EKF, first estimates Jacobian\nEKF, etc.",
    "descriptor": "",
    "authors": [
      "Xinghan Li",
      "Haodong Jiang",
      "Xingyu Chen",
      "He Kong",
      "Junfeng Wu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.09100"
  },
  {
    "id": "arXiv:2206.09104",
    "title": "Score-Guided Intermediate Layer Optimization: Fast Langevin Mixing for  Inverse Problem",
    "abstract": "We prove fast mixing and characterize the stationary distribution of the\nLangevin Algorithm for inverting random weighted DNN generators. This result\nextends the work of Hand and Voroninski from efficient inversion to efficient\nposterior sampling. In practice, to allow for increased expressivity, we\npropose to do posterior sampling in the latent space of a pre-trained\ngenerative model. To achieve that, we train a score-based model in the latent\nspace of a StyleGAN-2 and we use it to solve inverse problems. Our framework,\nScore-Guided Intermediate Layer Optimization (SGILO), extends prior work by\nreplacing the sparsity regularization with a generative prior in the\nintermediate layer. Experimentally, we obtain significant improvements over the\nprevious state-of-the-art, especially in the low measurement regime.",
    "descriptor": "\nComments: Accepted to ICML 2022. 32 pages, 9 Figures\n",
    "authors": [
      "Giannis Daras",
      "Yuval Dagan",
      "Alexandros G. Dimakis",
      "Constantinos Daskalakis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.09104"
  },
  {
    "id": "arXiv:2206.09106",
    "title": "Embodied Scene-aware Human Pose Estimation",
    "abstract": "We propose embodied scene-aware human pose estimation where we estimate 3D\nposes based on a simulated agent's proprioception and scene awareness, along\nwith external third-person observations. Unlike prior methods that often resort\nto multistage optimization, non-causal inference, and complex contact modeling\nto estimate human pose and human scene interactions, our method is one stage,\ncausal, and recovers global 3D human poses in a simulated environment. Since 2D\nthird-person observations are coupled with the camera pose, we propose to\ndisentangle the camera pose and use a multi-step projection gradient defined in\nthe global coordinate frame as the movement cue for our embodied agent.\nLeveraging a physics simulation and prescanned scenes (e.g., 3D mesh), we\nsimulate our agent in everyday environments (libraries, offices, bedrooms,\netc.) and equip our agent with environmental sensors to intelligently navigate\nand interact with scene geometries. Our method also relies only on 2D keypoints\nand can be trained on synthetic datasets derived from popular human motion\ndatabases. To evaluate, we use the popular H36M and PROX datasets and, for the\nfirst time, achieve a success rate of 96.7% on the challenging PROX dataset\nwithout ever using PROX motion sequences for training.",
    "descriptor": "\nComments: Project website: this https URL\n",
    "authors": [
      "Zhengyi Luo",
      "Shun Iwase",
      "Ye Yuan",
      "Kris Kitani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09106"
  },
  {
    "id": "arXiv:2206.09107",
    "title": "Tree-Guided Rare Feature Selection and Logic Aggregation with Electronic  Health Records Data",
    "abstract": "Statistical learning with a large number of rare binary features is commonly\nencountered in analyzing electronic health records (EHR) data, especially in\nthe modeling of disease onset with prior medical diagnoses and procedures.\nDealing with the resulting highly sparse and large-scale binary feature matrix\nis notoriously challenging as conventional methods may suffer from a lack of\npower in testing and inconsistency in model fitting while machine learning\nmethods may suffer from the inability of producing interpretable results or\nclinically-meaningful risk factors. To improve EHR-based modeling and utilize\nthe natural hierarchical structure of disease classification, we propose a\ntree-guided feature selection and logic aggregation approach for large-scale\nregression with rare binary features, in which dimension reduction is achieved\nthrough not only a sparsity pursuit but also an aggregation promoter with the\nlogic operator of ``or''. We convert the combinatorial problem into a convex\nlinearly-constrained regularized estimation, which enables scalable computation\nwith theoretical guarantees. In a suicide risk study with EHR data, our\napproach is able to select and aggregate prior mental health diagnoses as\nguided by the diagnosis hierarchy of the International Classification of\nDiseases. By balancing the rarity and specificity of the EHR diagnosis records,\nour strategy improves both prediction and model interpretation. We identify\nimportant higher-level categories and subcategories of mental health conditions\nand simultaneously determine the level of specificity needed for each of them\nin predicting suicide risk.",
    "descriptor": "",
    "authors": [
      "Jianmin Chen",
      "Robert H. Aseltine",
      "Fei Wang",
      "Kun Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.09107"
  },
  {
    "id": "arXiv:2206.09111",
    "title": "VReBERT: A Simple and Flexible Transformer for Visual Relationship  Detection",
    "abstract": "Visual Relationship Detection (VRD) impels a computer vision model to 'see'\nbeyond an individual object instance and 'understand' how different objects in\na scene are related. The traditional way of VRD is first to detect objects in\nan image and then separately predict the relationship between the detected\nobject instances. Such a disjoint approach is prone to predict redundant\nrelationship tags (i.e., predicate) between the same object pair with similar\nsemantic meaning, or incorrect ones that have a similar meaning to the ground\ntruth but are semantically incorrect. To remedy this, we propose to jointly\ntrain a VRD model with visual object features and semantic relationship\nfeatures. To this end, we propose VReBERT, a BERT-like transformer model for\nVisual Relationship Detection with a multi-stage training strategy to jointly\nprocess visual and semantic features. We show that our simple BERT-like model\nis able to outperform the state-of-the-art VRD models in predicate prediction.\nFurthermore, we show that by using the pre-trained VReBERT model, our model\npushes the state-of-the-art zero-shot predicate prediction by a significant\nmargin (+8.49 R@50 and +8.99 R@100).",
    "descriptor": "\nComments: Published at International Conference on Pattern Recognition (ICPR) 2022, Montreal Quebec\n",
    "authors": [
      "Yu Cui",
      "Moshiur Farazi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.09111"
  },
  {
    "id": "arXiv:2206.09112",
    "title": "Decoupled Dynamic Spatial-Temporal Graph Neural Network for Traffic  Forecasting",
    "abstract": "We all depend on mobility, and vehicular transportation affects the daily\nlives of most of us. Thus, the ability to forecast the state of traffic in a\nroad network is an important functionality and a challenging task. Traffic data\nis often obtained from sensors deployed in a road network. Recent proposals on\nspatial-temporal graph neural networks have achieved great progress at modeling\ncomplex spatial-temporal correlations in traffic data, by modeling traffic data\nas a diffusion process. However, intuitively, traffic data encompasses two\ndifferent kinds of hidden time series signals, namely the diffusion signals and\ninherent signals. Unfortunately, nearly all previous works coarsely consider\ntraffic signals entirely as the outcome of the diffusion, while neglecting the\ninherent signals, which impacts model performance negatively. To improve\nmodeling performance, we propose a novel Decoupled Spatial-Temporal Framework\n(DSTF) that separates the diffusion and inherent traffic information in a\ndata-driven manner, which encompasses a unique estimation gate and a residual\ndecomposition mechanism. The separated signals can be handled subsequently by\nthe diffusion and inherent modules separately. Further, we propose an\ninstantiation of DSTF, Decoupled Dynamic Spatial-Temporal Graph Neural Network\n(D2STGNN), that captures spatial-temporal correlations and also features a\ndynamic graph learning module that targets the learning of the dynamic\ncharacteristics of traffic networks. Extensive experiments with four real-world\ntraffic datasets demonstrate that the framework is capable of advancing the\nstate-of-the-art.",
    "descriptor": "\nComments: PVLDB 2022\n",
    "authors": [
      "Zezhi Shao",
      "Zhao Zhang",
      "Wei Wei",
      "Fei Wang",
      "Yongjun Xu",
      "Xin Cao",
      "Christian S. Jensen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09112"
  },
  {
    "id": "arXiv:2206.09113",
    "title": "Pre-training Enhanced Spatial-temporal Graph Neural Network for  Multivariate Time Series Forecasting",
    "abstract": "Multivariate Time Series (MTS) forecasting plays a vital role in a wide range\nof applications. Recently, Spatial-Temporal Graph Neural Networks (STGNNs) have\nbecome increasingly popular MTS forecasting methods. STGNNs jointly model the\nspatial and temporal patterns of MTS through graph neural networks and\nsequential models, significantly improving the prediction accuracy. But limited\nby model complexity, most STGNNs only consider short-term historical MTS data,\nsuch as data over the past one hour. However, the patterns of time series and\nthe dependencies between them (i.e., the temporal and spatial patterns) need to\nbe analyzed based on long-term historical MTS data. To address this issue, we\npropose a novel framework, in which STGNN is Enhanced by a scalable time series\nPre-training model (STEP). Specifically, we design a pre-training model to\nefficiently learn temporal patterns from very long-term history time series\n(e.g., the past two weeks) and generate segment-level representations. These\nrepresentations provide contextual information for short-term time series input\nto STGNNs and facilitate modeling dependencies between time series. Experiments\non three public real-world datasets demonstrate that our framework is capable\nof significantly enhancing downstream STGNNs, and our pre-training model aptly\ncaptures temporal patterns.",
    "descriptor": "\nComments: SIGKDD 2022\n",
    "authors": [
      "Zezhi Shao",
      "Zhao Zhang",
      "Fei Wang",
      "Yongjun Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09113"
  },
  {
    "id": "arXiv:2206.09114",
    "title": "Bear the Query in Mind: Visual Grounding with Query-conditioned  Convolution",
    "abstract": "Visual grounding is a task that aims to locate a target object according to a\nnatural language expression. As a multi-modal task, feature interaction between\ntextual and visual inputs is vital. However, previous solutions mainly handle\neach modality independently before fusing them together, which does not take\nfull advantage of relevant textual information while extracting visual\nfeatures. To better leverage the textual-visual relationship in visual\ngrounding, we propose a Query-conditioned Convolution Module (QCM) that\nextracts query-aware visual features by incorporating query information into\nthe generation of convolutional kernels. With our proposed QCM, the downstream\nfusion module receives visual features that are more discriminative and focused\non the desired object described in the expression, leading to more accurate\npredictions. Extensive experiments on three popular visual grounding datasets\ndemonstrate that our method achieves state-of-the-art performance. In addition,\nthe query-aware visual features are informative enough to achieve comparable\nperformance to the latest methods when directly used for prediction without\nfurther multi-modal fusion.",
    "descriptor": "",
    "authors": [
      "Chonghan Chen",
      "Qi Jiang1",
      "Chih-Hao Wang",
      "Noel Chen",
      "Haohan Wang",
      "Xiang Li",
      "Bhiksha Raj"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09114"
  },
  {
    "id": "arXiv:2206.09116",
    "title": "Person-job fit estimation from candidate profile and related recruitment  history with co-attention neural networks",
    "abstract": "Existing online recruitment platforms depend on automatic ways of conducting\nthe person-job fit, whose goal is matching appropriate job seekers with job\npositions. Intuitively, the previous successful recruitment records contain\nimportant information, which should be helpful for the current person-job fit.\nExisting studies on person-job fit, however, mainly focus on calculating the\nsimilarity between the candidate resumes and the job postings on the basis of\ntheir contents, without taking the recruiters' experience (i.e., historical\nsuccessful recruitment records) into consideration. In this paper, we propose a\nnovel neural network approach for person-job fit, which estimates person-job\nfit from candidate profile and related recruitment history with co-attention\nneural networks (named PJFCANN). Specifically, given a target resume-job post\npair, PJFCANN generates local semantic representations through co-attention\nneural networks and global experience representations via graph neural\nnetworks. The final matching degree is calculated by combining these two\nrepresentations. In this way, the historical successful recruitment records are\nintroduced to enrich the features of resumes and job postings and strengthen\nthe current matching process. Extensive experiments conducted on a large-scale\nrecruitment dataset verify the effectiveness of PJFCANN compared with several\nstate-of-the-art baselines. The codes are released at:\nhttps://github.com/CCIIPLab/PJFCANN.",
    "descriptor": "",
    "authors": [
      "Ziyang Wang",
      "Wei Wei",
      "Chenwei Xu",
      "Jun Xu",
      "Xian-Ling Mao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.09116"
  },
  {
    "id": "arXiv:2206.09117",
    "title": "NISPA: Neuro-Inspired Stability-Plasticity Adaptation for Continual  Learning in Sparse Networks",
    "abstract": "The goal of continual learning (CL) is to learn different tasks over time.\nThe main desiderata associated with CL are to maintain performance on older\ntasks, leverage the latter to improve learning of future tasks, and to\nintroduce minimal overhead in the training process (for instance, to not\nrequire a growing model or retraining). We propose the Neuro-Inspired\nStability-Plasticity Adaptation (NISPA) architecture that addresses these\ndesiderata through a sparse neural network with fixed density. NISPA forms\nstable paths to preserve learned knowledge from older tasks. Also, NISPA uses\nconnection rewiring to create new plastic paths that reuse existing knowledge\non novel tasks. Our extensive evaluation on EMNIST, FashionMNIST, CIFAR10, and\nCIFAR100 datasets shows that NISPA significantly outperforms representative\nstate-of-the-art continual learning baselines, and it uses up to ten times\nfewer learnable parameters compared to baselines. We also make the case that\nsparsity is an essential ingredient for continual learning. The NISPA code is\navailable at https://github.com/BurakGurbuz97/NISPA.",
    "descriptor": "\nComments: International Conference on Machine Learning 2022\n",
    "authors": [
      "Mustafa Burak Gurbuz",
      "Constantine Dovrolis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09117"
  },
  {
    "id": "arXiv:2206.09122",
    "title": "Measuring Lower Bounds of Local Differential Privacy via Adversary  Instantiations in Federated Learning",
    "abstract": "Local differential privacy (LDP) gives a strong privacy guarantee to be used\nin a distributed setting like federated learning (FL). LDP mechanisms in FL\nprotect a client's gradient by randomizing it on the client; however, how can\nwe interpret the privacy level given by the randomization? Moreover, what types\nof attacks can we mitigate in practice? To answer these questions, we introduce\nan empirical privacy test by measuring the lower bounds of LDP. The privacy\ntest estimates how an adversary predicts if a reported randomized gradient was\ncrafted from a raw gradient $g_1$ or $g_2$. We then instantiate six adversaries\nin FL under LDP to measure empirical LDP at various attack surfaces, including\na worst-case attack that reaches the theoretical upper bound of LDP. The\nempirical privacy test with the adversary instantiations enables us to\ninterpret LDP more intuitively and discuss relaxation of the privacy parameter\nuntil a particular instantiated attack surfaces. We also demonstrate numerical\nobservations of the measured privacy in these adversarial settings, and the\nworst-case attack is not realistic in FL. In the end, we also discuss the\npossible relaxation of privacy levels in FL under LDP.",
    "descriptor": "\nComments: 15 pages, 7 figures\n",
    "authors": [
      "Marin Matsumoto",
      "Tsubasa Takahashi",
      "Seng Pei Liew",
      "Masato Oguchi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.09122"
  },
  {
    "id": "arXiv:2206.09123",
    "title": "POD-ROMs for incompressible flows including snapshots of the temporal  derivative of the full order solution",
    "abstract": "In this paper we study the influence of including snapshots that approach the\nvelocity time derivative in the numerical approximation of the incompressible\nNavier-Stokes equations by means of proper orthogonal decomposition (POD)\nmethods. Our set of snapshots includes the velocity approximation at the\ninitial time from a full order mixed finite element method (FOM) together with\napproximations to the time derivative at different times. The approximation at\nthe initial velocity can be replaced by the mean value of the velocities at the\ndifferent times so that implementing the method to the fluctuations, as done\nmostly in practice, only approximations to the time derivatives are included in\nthe set of snapshots. For the POD method we study the differences between\nprojecting onto $L^2$ and $H^1$. In both cases pointwise in time error bounds\ncan be proved. Including grad-div stabilization both in the FOM and POD methods\nerror bounds with constants independent on inverse powers of the viscosity can\nbe obtained.",
    "descriptor": "",
    "authors": [
      "Bosco Garc\u00eda-Archilla",
      "Volker John",
      "Julia Novo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.09123"
  },
  {
    "id": "arXiv:2206.09131",
    "title": "Tackling Spoofing-Aware Speaker Verification with Multi-Model Fusion",
    "abstract": "Recent years have witnessed the extraordinary development of automatic\nspeaker verification (ASV). However, previous works show that state-of-the-art\nASV models are seriously vulnerable to voice spoofing attacks, and the recently\nproposed high-performance spoofing countermeasure (CM) models only focus solely\non the standalone anti-spoofing tasks, and ignore the subsequent speaker\nverification process. How to integrate the CM and ASV together remains an open\nquestion. A spoofing aware speaker verification (SASV) challenge has recently\ntaken place with the argument that better performance can be delivered when\nboth CM and ASV subsystems are optimized jointly. Under the challenge's\nscenario, the integrated systems proposed by the participants are required to\nreject both impostor speakers and spoofing attacks from target speakers, which\nintuitively and effectively matches the expectation of a reliable,\nspoofing-robust ASV system. This work focuses on fusion-based SASV solutions\nand proposes a multi-model fusion framework to leverage the power of multiple\nstate-of-the-art ASV and CM models. The proposed framework vastly improves the\nSASV-EER from 8.75% to 1.17\\%, which is 86% relative improvement compared to\nthe best baseline system in the SASV challenge.",
    "descriptor": "\nComments: Accepted by Odyssey 2022\n",
    "authors": [
      "Haibin Wu",
      "Jiawen Kang",
      "Lingwei Meng",
      "Yang Zhang",
      "Xixin Wu",
      "Zhiyong Wu",
      "Hung-yi Lee",
      "Helen Meng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.09131"
  },
  {
    "id": "arXiv:2206.09132",
    "title": "Replacing Labeled Real-image Datasets with Auto-generated Contours",
    "abstract": "In the present work, we show that the performance of formula-driven\nsupervised learning (FDSL) can match or even exceed that of ImageNet-21k\nwithout the use of real images, human-, and self-supervision during the\npre-training of Vision Transformers (ViTs). For example, ViT-Base pre-trained\non ImageNet-21k shows 81.8% top-1 accuracy when fine-tuned on ImageNet-1k and\nFDSL shows 82.7% top-1 accuracy when pre-trained under the same conditions\n(number of images, hyperparameters, and number of epochs). Images generated by\nformulas avoid the privacy/copyright issues, labeling cost and errors, and\nbiases that real images suffer from, and thus have tremendous potential for\npre-training general models. To understand the performance of the synthetic\nimages, we tested two hypotheses, namely (i) object contours are what matter in\nFDSL datasets and (ii) increased number of parameters to create labels affects\nperformance improvement in FDSL pre-training. To test the former hypothesis, we\nconstructed a dataset that consisted of simple object contour combinations. We\nfound that this dataset can match the performance of fractals. For the latter\nhypothesis, we found that increasing the difficulty of the pre-training task\ngenerally leads to better fine-tuning accuracy.",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Hirokatsu Kataoka",
      "Ryo Hayamizu",
      "Ryosuke Yamada",
      "Kodai Nakashima",
      "Sora Takashima",
      "Xinyu Zhang",
      "Edgar Josafat Martinez-Noriega",
      "Nakamasa Inoue",
      "Rio Yokota"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09132"
  },
  {
    "id": "arXiv:2206.09133",
    "title": "Efficacy of Asynchronous GPS Spoofing Against High Volume Consumer GNSS  Receivers",
    "abstract": "The vulnerability of the Global Positioning System (GPS) against spoofing is\nknown for quite some time. Also, the positioning and navigation of most\nsemi-autonomous and autonomous drones are dependent on Global Navigation\nSatellite System (GNSS) signals. In prior work, simplistic or asynchronous GPS\nspoofing was found to be a simple, efficient, and effective cyber attack\nagainst L1 GPS or GNSS dependent commercial drones. In this paper, first we\nmake some important observations on asynchronous GPS spoofing attacks on drones\npresented in prior research literature. Then, we design an asynchronous GPS\nspoofing attack plan. Next, we test the effectiveness of this attack against\nGNSS receivers (high volume consumer devices based on Android mobile phones) of\ndifferent capabilities and a commercial drone (DJI Mavic 2 Pro) under various\nconditions. Finally, we present several novel insights based on the results of\nthe tests.",
    "descriptor": "\nComments: 10 pages,\n",
    "authors": [
      "M. Surendra Kumar",
      "Gaurav S. Kasbekar",
      "Arnab Maity"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.09133"
  },
  {
    "id": "arXiv:2206.09136",
    "title": "Provable Generalization of Overparameterized Meta-learning Trained with  SGD",
    "abstract": "Despite the superior empirical success of deep meta-learning, theoretical\nunderstanding of overparameterized meta-learning is still limited. This paper\nstudies the generalization of a widely used meta-learning approach,\nModel-Agnostic Meta-Learning (MAML), which aims to find a good initialization\nfor fast adaptation to new tasks. Under a mixed linear regression model, we\nanalyze the generalization properties of MAML trained with SGD in the\noverparameterized regime. We provide both upper and lower bounds for the excess\nrisk of MAML, which captures how SGD dynamics affect these generalization\nbounds. With such sharp characterizations, we further explore how various\nlearning parameters impact the generalization capability of overparameterized\nMAML, including explicitly identifying typical data and task distributions that\ncan achieve diminishing generalization error with overparameterization, and\ncharacterizing the impact of adaptation learning rate on both excess risk and\nthe early stopping time. Our theoretical findings are further validated by\nexperiments.",
    "descriptor": "\nComments: 45 pages, 3 figures\n",
    "authors": [
      "Yu Huang",
      "Yingbin Liang",
      "Longbo Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2206.09136"
  },
  {
    "id": "arXiv:2206.09140",
    "title": "Certified Graph Unlearning",
    "abstract": "Graph-structured data is ubiquitous in practice and often processed using\ngraph neural networks (GNNs). With the adoption of recent laws ensuring the\n``right to be forgotten'', the problem of graph data removal has become of\nsignificant importance. To address the problem, we introduce the first known\nframework for \\emph{certified graph unlearning} of GNNs. In contrast to\nstandard machine unlearning, new analytical and heuristic unlearning challenges\narise when dealing with complex graph data. First, three different types of\nunlearning requests need to be considered, including node feature, edge and\nnode unlearning. Second, to establish provable performance guarantees, one\nneeds to address challenges associated with feature mixing during propagation.\nThe underlying analysis is illustrated on the example of simple graph\nconvolutions (SGC) and their generalized PageRank (GPR) extensions, thereby\nlaying the theoretical foundation for certified unlearning of GNNs. Our\nempirical studies on six benchmark datasets demonstrate excellent\nperformance-complexity trade-offs when compared to complete retraining methods\nand approaches that do not leverage graph information. For example, when\nunlearning $20\\%$ of the nodes on the Cora dataset, our approach suffers only a\n$0.1\\%$ loss in test accuracy while offering a $4$-fold speed-up compared to\ncomplete retraining. Our scheme also outperforms unlearning methods that do not\nleverage graph information with a $12\\%$ increase in test accuracy for a\ncomparable time complexity.",
    "descriptor": "",
    "authors": [
      "Eli Chien",
      "Chao Pan",
      "Olgica Milenkovic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09140"
  },
  {
    "id": "arXiv:2206.09141",
    "title": "ToolTango: Common sense Generalization in Predicting Sequential Tool  Interactions for Robot Plan Synthesis",
    "abstract": "Robots assisting us in environments such as factories or homes must learn to\nmake use of objects as tools to perform tasks, for instance using a tray to\ncarry objects. We consider the problem of learning commonsense knowledge of\nwhen a tool may be useful and how its use may be composed with other tools to\naccomplish a high-level task instructed by a human. Specifically, we introduce\na novel neural model, termed TOOLTANGO, that first predicts the next tool to be\nused, and then uses this information to predict the next action. We show that\nthis joint model can inform learning of a fine-grained policy enabling the\nrobot to use a particular tool in sequence and adds a significant value in\nmaking the model more accurate. TOOLTANGO encodes the world state, comprising\nobjects and symbolic relationships between them, using a graph neural network\nand is trained using demonstrations from human teachers instructing a virtual\nrobot in a physics simulator. The model learns to attend over the scene using\nknowledge of the goal and the action history, finally decoding the symbolic\naction to execute. Crucially, we address generalization to unseen environments\nwhere some known tools are missing, but alternative unseen tools are present.\nWe show that by augmenting the representation of the environment with\npre-trained embeddings derived from a knowledge-base, the model can generalize\neffectively to novel environments. Experimental results show at least\n48.8-58.1% absolute improvement over the baselines in predicting successful\nsymbolic plans for a simulated mobile manipulator in novel environments with\nunseen objects. This work takes a step in the direction of enabling robots to\nrapidly synthesize robust plans for complex tasks, particularly in novel\nsettings",
    "descriptor": "\nComments: Accepted in Journal of AI Research. arXiv admin note: substantial text overlap with arXiv:2105.04556\n",
    "authors": [
      "Shreshth Tuli",
      "Rajas Bansal",
      "Rohan Paul",
      "Mausam"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.09141"
  },
  {
    "id": "arXiv:2206.09142",
    "title": "Redundancy Reduction Twins Network: A Training framework for  Multi-output Emotion Regression",
    "abstract": "In this paper, we propose the Redundancy Reduction Twins Network (RRTN), a\nredundancy reduction training framework that minimizes redundancy by measuring\nthe cross-correlation matrix between the outputs of the same network fed with\ndistorted versions of a sample and bringing it as close to the identity matrix\nas possible. RRTN also applies a new loss function, the Barlow Twins loss\nfunction, to help maximize the similarity of representations obtained from\ndifferent distorted versions of a sample. However, as the distribution of\nlosses can cause performance fluctuations in the network, we also propose the\nuse of a Restrained Uncertainty Weight Loss (RUWL) or joint training to\nidentify the best weights for the loss function. Our best approach on CNN14\nwith the proposed methodology obtains a CCC over emotion regression of 0.678 on\nthe ExVo Multi-task dev set, a 4.8% increase over a vanilla CNN 14 CCC of\n0.647, which achieves a significant difference at the 95% confidence interval\n(2-tailed).",
    "descriptor": "\nComments: 5 pages, accepted by ICML Exvo workshop\n",
    "authors": [
      "Xin Jing",
      "Meishu Song",
      "Andreas Triantafyllopoulos",
      "Zijiang Yang",
      "Bj\u00f6rn W. Schuller"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.09142"
  },
  {
    "id": "arXiv:2206.09144",
    "title": "Beyond Real-world Benchmark Datasets: An Empirical Study of Node  Classification with GNNs",
    "abstract": "Graph Neural Networks (GNNs) have achieved great success on a node\nclassification task. Despite the broad interest in developing and evaluating\nGNNs, they have been assessed with limited benchmark datasets. As a result, the\nexisting evaluation of GNNs lacks fine-grained analysis from various\ncharacteristics of graphs. Motivated by this, we conduct extensive experiments\nwith a synthetic graph generator that can generate graphs having controlled\ncharacteristics for fine-grained analysis. Our empirical studies clarify the\nstrengths and weaknesses of GNNs from four major characteristics of real-world\ngraphs with class labels of nodes, i.e., 1) class size distributions (balanced\nvs. imbalanced), 2) edge connection proportions between classes (homophilic vs.\nheterophilic), 3) attribute values (biased vs. random), and 4) graph sizes\n(small vs. large). In addition, to foster future research on GNNs, we publicly\nrelease our codebase that allows users to evaluate various GNNs with various\ngraphs. We hope this work offers interesting insights for future research.",
    "descriptor": "\nComments: 17 pages, 10 figures\n",
    "authors": [
      "Seiji Maekawa",
      "Koki Noda",
      "Yuya Sasaki",
      "Makoto Onizuka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09144"
  },
  {
    "id": "arXiv:2206.09148",
    "title": "Deep Compatible Learning for Partially-Supervised Medical Image  Segmentation",
    "abstract": "Partially-supervised learning can be challenging for segmentation due to the\nlack of supervision for unlabeled structures, and the methods directly applying\nfully-supervised learning could lead to incompatibility, meaning ground truth\nis not in the solution set of the optimization problem given the loss function.\nTo address the challenge, we propose a deep compatible learning (DCL)\nframework, which trains a single multi-label segmentation network using images\nwith only partial structures annotated. We first formulate the\npartially-supervised segmentation as an optimization problem compatible with\nmissing labels, and prove its compatibility. Then, we equip the model with a\nconditional segmentation strategy, to propagate labels from multiple\npartially-annotated images to the target. Additionally, we propose a dual\nlearning strategy, which learns two opposite mappings of label propagation\nsimultaneously, to provide substantial supervision for unlabeled structures.\nThe two strategies are formulated into compatible forms, termed as conditional\ncompatibility and dual compatibility, respectively. We show this framework is\ngenerally applicable for conventional loss functions. The approach attains\nsignificant performance improvement over existing methods, especially in the\nsituation where only a small training dataset is available. Results on three\nsegmentation tasks have shown that the proposed framework could achieve\nperformance matching fully-supervised models.",
    "descriptor": "\nComments: 16 pages, 13 figures\n",
    "authors": [
      "Ke Zhang",
      "Xiahai Zhuang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09148"
  },
  {
    "id": "arXiv:2206.09149",
    "title": "Piecewise Linear Neural Networks and Deep Learning",
    "abstract": "As a powerful modelling method, PieceWise Linear Neural Networks (PWLNNs)\nhave proven successful in various fields, most recently in deep learning. To\napply PWLNN methods, both the representation and the learning have long been\nstudied. In 1977, the canonical representation pioneered the works of shallow\nPWLNNs learned by incremental designs, but the applications to large-scale data\nwere prohibited. In 2010, the Rectified Linear Unit (ReLU) advocated the\nprevalence of PWLNNs in deep learning. Ever since, PWLNNs have been\nsuccessfully applied to extensive tasks and achieved advantageous performances.\nIn this Primer, we systematically introduce the methodology of PWLNNs by\ngrouping the works into shallow and deep networks. Firstly, different PWLNN\nrepresentation models are constructed with elaborated examples. With PWLNNs,\nthe evolution of learning algorithms for data is presented and fundamental\ntheoretical analysis follows up for in-depth understandings. Then,\nrepresentative applications are introduced together with discussions and\noutlooks.",
    "descriptor": "\nComments: 23 pages, 6 figures\n",
    "authors": [
      "Qinghua Tao",
      "Li Li",
      "Xiaolin Huang",
      "Xiangming Xi",
      "Shuning Wang",
      "Johan A.K. Suykens"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09149"
  },
  {
    "id": "arXiv:2206.09150",
    "title": "Thompson Sampling for (Combinatorial) Pure Exploration",
    "abstract": "Existing methods of combinatorial pure exploration mainly focus on the UCB\napproach. To make the algorithm efficient, they usually use the sum of upper\nconfidence bounds within arm set $S$ to represent the upper confidence bound of\n$S$, which can be much larger than the tight upper confidence bound of $S$ and\nleads to a much higher complexity than necessary, since the empirical means of\ndifferent arms in $S$ are independent. To deal with this challenge, we explore\nthe idea of Thompson Sampling (TS) that uses independent random samples instead\nof the upper confidence bounds, and design the first TS-based algorithm\nTS-Explore for (combinatorial) pure exploration. In TS-Explore, the sum of\nindependent random samples within arm set $S$ will not exceed the tight upper\nconfidence bound of $S$ with high probability. Hence it solves the above\nchallenge, and achieves a lower complexity upper bound than existing efficient\nUCB-based algorithms in general combinatorial pure exploration. As for pure\nexploration of classic multi-armed bandit, we show that TS-Explore achieves an\nasymptotically optimal complexity upper bound.",
    "descriptor": "",
    "authors": [
      "Siwei Wang",
      "Jun Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09150"
  },
  {
    "id": "arXiv:2206.09153",
    "title": "Markov Chain Approaches to Payoff Optimization in the Self-Organizing  Network Coloring Game",
    "abstract": "The model of Network Coloring Game (NCG) is used to simulate conflict\nresolving and consensus reaching procedures in social science. In this work, we\nadopted some Markov Chain Techniques into the investigation of NCG. Firstly,\nwith no less than $\\Delta + 2$ colors provided, we proposed and proved that the\nconflict resolving time has its expectation to be $O(\\log n)$ and the variance\n$O((\\log n)^2)$, thus is $O_p(\\log n)$, where $n$ is the number of vertices and\n$\\Delta$ is the maximum degree of the network. This was done by introducing an\nabsorbing Markov Chain into NCG. Secondly, we developed an algorithms to reduce\nthe network in post-conflict-resolution adjustments when a Borda rule is\napplied among players. Markov Chain Monte Carlo methods were employed to\nestimate both local and global optimal payoffs. Supporting experimental results\nwere given to illustrate the corresponding procedures.",
    "descriptor": "\nComments: 10 Pages; 5 Figures; For Python code, see this https URL\n",
    "authors": [
      "Zeyi Chen"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Computer Science and Game Theory (cs.GT)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.09153"
  },
  {
    "id": "arXiv:2206.09157",
    "title": "Off-Network Communications For Future Railway Mobile Communication  Systems: Challenges and Opportunities",
    "abstract": "GSM-R is predicted to be obsoleted by 2030, and a suitable successor is\nneeded. Defined by the International Union of Railways (UIC), the Future\nRailway Mobile Communication System (FRMCS) contains many future use cases with\nstrict requirements. These use cases should ensure regular communication not\nonly in network coverage but also uncovered scenarios. There is still a lack of\nstandards on off-network communication in FRMCS, so this article focuses on\noff-network communication and intends to provide reference and direction for\nstandardization. We first provide a comprehensive summary and analysis of\noff-network use cases in FRMCS. Then we give an overview of existing\ntechnologies (GSM-R, TETRA, DMR, LTE-V2X, and NR-V2X) that may support\noff-network communication. In addition, we simulate and evaluate the\nperformance of existing technologies. Simulation results show that it is\npossible to satisfy the off-network communication requirements in FRMCS with\nenhancements based on LTE-V2X or NR-V2X. Finally, we give some future research\ndirections to provide insights for industry and academia.",
    "descriptor": "",
    "authors": [
      "Jiewen Hu",
      "Gang Liu",
      "Yongbo Li",
      "Zheng Ma",
      "Wei Wang",
      "Chengchao Liang",
      "F. Richard Yu",
      "Pingzhi Fan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.09157"
  },
  {
    "id": "arXiv:2206.09158",
    "title": "A Double-Graph Based Framework for Frame Semantic Parsing",
    "abstract": "Frame semantic parsing is a fundamental NLP task, which consists of three\nsubtasks: frame identification, argument identification and role\nclassification. Most previous studies tend to neglect relations between\ndifferent subtasks and arguments and pay little attention to ontological frame\nknowledge defined in FrameNet. In this paper, we propose a Knowledge-guided\nIncremental semantic parser with Double-graph (KID). We first introduce Frame\nKnowledge Graph (FKG), a heterogeneous graph containing both frames and FEs\n(Frame Elements) built on the frame knowledge so that we can derive\nknowledge-enhanced representations for frames and FEs. Besides, we propose\nFrame Semantic Graph (FSG) to represent frame semantic structures extracted\nfrom the text with graph structures. In this way, we can transform frame\nsemantic parsing into an incremental graph construction problem to strengthen\ninteractions between subtasks and relations between arguments. Our experiments\nshow that KID outperforms the previous state-of-the-art method by up to 1.7\nF1-score on two FrameNet datasets. Our code is availavle at\nhttps://github.com/PKUnlp-icler/KID.",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Ce Zheng",
      "Xudong Chen",
      "Runxin Xu",
      "Baobao Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.09158"
  },
  {
    "id": "arXiv:2206.09161",
    "title": "A Marriage between Adversarial Team Games and 2-player Games: Enabling  Abstractions, No-regret Learning, and Subgame Solving",
    "abstract": "\\emph{Ex ante} correlation is becoming the mainstream approach for\n\\emph{sequential adversarial team games}, where a team of players faces another\nteam in a zero-sum game. It is known that team members' asymmetric information\nmakes both equilibrium computation \\textsf{APX}-hard and team's strategies not\ndirectly representable on the game tree. This latter issue prevents the\nadoption of successful tools for huge 2-player zero-sum games such as,\n\\emph{e.g.}, abstractions, no-regret learning, and subgame solving. This work\nshows that we can recover from this weakness by bridging the gap between\nsequential adversarial team games and 2-player games. In particular, we propose\na new, suitable game representation that we call\n\\emph{team-public-information}, in which a team is represented as a single\ncoordinator who only knows information common to the whole team and prescribes\nto each member an action for any possible private state. The resulting\nrepresentation is highly \\emph{explainable}, being a 2-player tree in which the\nteam's strategies are behavioral with a direct interpretation and more\nexpressive than the original extensive form when designing abstractions.\nFurthermore, we prove payoff equivalence of our representation, and we provide\ntechniques that, starting directly from the extensive form, generate\ndramatically more compact representations without information loss. Finally, we\nexperimentally evaluate our techniques when applied to a standard testbed,\ncomparing their performance with the current state of the art.",
    "descriptor": "\nComments: 20 pages; Accepted for publication at ICML 2022\n",
    "authors": [
      "Luca Carminati",
      "Federico Cacciamani",
      "Marco Ciccone",
      "Nicola Gatti"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2206.09161"
  },
  {
    "id": "arXiv:2206.09166",
    "title": "NAS-Bench-Graph: Benchmarking Graph Neural Architecture Search",
    "abstract": "Graph neural architecture search (GraphNAS) has recently aroused considerable\nattention in both academia and industry. However, two key challenges seriously\nhinder the further research of GraphNAS. First, since there is no consensus for\nthe experimental setting, the empirical results in different research papers\nare often not comparable and even not reproducible, leading to unfair\ncomparisons. Secondly, GraphNAS often needs extensive computations, which makes\nit highly inefficient and inaccessible to researchers without access to\nlarge-scale computation. To solve these challenges, we propose NAS-Bench-Graph,\na tailored benchmark that supports unified, reproducible, and efficient\nevaluations for GraphNAS. Specifically, we construct a unified, expressive yet\ncompact search space, covering 26,206 unique graph neural network (GNN)\narchitectures and propose a principled evaluation protocol. To avoid\nunnecessary repetitive training, we have trained and evaluated all of these\narchitectures on nine representative graph datasets, recording detailed metrics\nincluding train, validation, and test performance in each epoch, the latency,\nthe number of parameters, etc. Based on our proposed benchmark, the performance\nof GNN architectures can be directly obtained by a look-up table without any\nfurther computation, which enables fair, fully reproducible, and efficient\ncomparisons. To demonstrate its usage, we make in-depth analyses of our\nproposed NAS-Bench-Graph, revealing several interesting findings for GraphNAS.\nWe also showcase how the benchmark can be easily compatible with GraphNAS open\nlibraries such as AutoGL and NNI. To the best of our knowledge, our work is the\nfirst benchmark for graph neural architecture search.",
    "descriptor": "",
    "authors": [
      "Yijian Qin",
      "Ziwei Zhang",
      "Xin Wang",
      "Zeyang Zhang",
      "Wenwu Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09166"
  },
  {
    "id": "arXiv:2206.09167",
    "title": "MANorm: A Normalization Dictionary for Moroccan Arabic Dialect Written  in Latin Script",
    "abstract": "Social media user-generated text is actually the main resource for many NLP\ntasks. This text however, does not follow the standard rules of writing.\nMoreover, the use of dialect such as Moroccan Arabic in written communications\nincreases further NLP tasks complexity. A dialect is a verbal language that\ndoes not have a standard orthography, which leads users to improvise spelling\nwhile writing. Thus, for the same word we can find multiple forms of\ntransliterations. Subsequently, it is mandatory to normalize these different\ntransliterations to one canonical word form. To reach this goal, we have\nexploited the powerfulness of word embedding models generated with a corpus of\nYouTube comments. Besides, using a Moroccan Arabic dialect dictionary that\nprovides the canonical forms, we have built a normalization dictionary that we\nrefer to as MANorm. We have conducted several experiments to demonstrate the\nefficiency of MANorm, which have shown its usefulness in dialect normalization.",
    "descriptor": "\nComments: The Fifth Arabic Natural Language Processing Workshop/COLING 2020\n",
    "authors": [
      "Randa Zarnoufi",
      "Walid Bachri",
      "Hamid Jaafar",
      "Mounia Abik"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.09167"
  },
  {
    "id": "arXiv:2206.09169",
    "title": "Validation of two-wire power line UAV localization based on the magnetic  field strength",
    "abstract": "In this paper we extend our previous work on UAV localization based on the\nmagnetic field strength. The method is based on a magnetic flux density\ndistribution in vicinity of two very long, thin and parallel transmission\nlines. An UAV is equipped with 4 magnetometers, positioned so that obtained\nmeasurements give unique solution to an optimization problem used to find\nrelative position and orientation of the UAV with respect to conductors.\nSeveral sets of experiments, undertaken on a laboratory setup, confirmed\nvalidity of the method for both solutions - analytical and numerical\noptimization. Obtained results, compared with high precision motion capture\nsystem, are within range of standard RTK positioning.",
    "descriptor": "\nComments: ICUAS 2022, The 2022 International Conference on Unmanned Aircraft Systems\n",
    "authors": [
      "Goran Vasiljevic",
      "Dean Martinovic",
      "Matko Batos",
      "Stjepan Bogdan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.09169"
  },
  {
    "id": "arXiv:2206.09178",
    "title": "REVECA -- Rich Encoder-decoder framework for Video Event CAptioner",
    "abstract": "We describe an approach used in the Generic Boundary Event Captioning\nchallenge at the Long-Form Video Understanding Workshop held at CVPR 2022. We\ndesigned a Rich Encoder-decoder framework for Video Event CAptioner (REVECA)\nthat utilizes spatial and temporal information from the video to generate a\ncaption for the corresponding the event boundary. REVECA uses frame position\nembedding to incorporate information before and after the event boundary.\nFurthermore, it employs features extracted using the temporal segment network\nand temporal-based pairwise difference method to learn temporal information. A\nsemantic segmentation mask for the attentional pooling process is adopted to\nlearn the subject of an event. Finally, LoRA is applied to fine-tune the image\nencoder to enhance the learning efficiency. REVECA yielded an average score of\n50.97 on the Kinetics-GEBC test data, which is an improvement of 10.17 over the\nbaseline method. Our code is available in https://github.com/TooTouch/REVECA.",
    "descriptor": "\nComments: The IEEE/CVF Computer Vision and Pattern Recognition Conference (CVPR). LOng-form VidEo Understanding (LOVEU) workshop\n",
    "authors": [
      "Jaehyuk Heo",
      "YongGi Jeong",
      "Sunwoo Kim",
      "Jaehee Kim",
      "Pilsung Kang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.09178"
  },
  {
    "id": "arXiv:2206.09182",
    "title": "Coin Flipping Neural Networks",
    "abstract": "We show that neural networks with access to randomness can outperform\ndeterministic networks by using amplification. We call such networks\nCoin-Flipping Neural Networks, or CFNNs. We show that a CFNN can approximate\nthe indicator of a $d$-dimensional ball to arbitrary accuracy with only 2\nlayers and $\\mathcal{O}(1)$ neurons, where a 2-layer deterministic network was\nshown to require $\\Omega(e^d)$ neurons, an exponential improvement\n(arXiv:1610.09887 [cs.LG]). We prove a highly non-trivial result, that for\nalmost any classification problem, there exists a trivially simple network that\nsolves it given a sufficiently powerful generator for the network's weights.\nCombining these results we conjecture that for most classification problems,\nthere is a CFNN which solves them with higher accuracy or fewer neurons than\nany deterministic network. Finally, we verify our proofs experimentally using\nnovel CFNN architectures on CIFAR10 and CIFAR100, reaching an improvement of\n9.25\\% from the baseline.",
    "descriptor": "",
    "authors": [
      "Yuval Sieradzki",
      "Nitzan Hodos",
      "Gal Yehuda",
      "Assaf Schuster"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09182"
  },
  {
    "id": "arXiv:2206.09184",
    "title": "PHN: Parallel heterogeneous network with soft gating for CTR prediction",
    "abstract": "The Click-though Rate (CTR) prediction task is a basic task in recommendation\nsystem. Most of the previous researches of CTR models built based on Wide \\&\ndeep structure and gradually evolved into parallel structures with different\nmodules. However, the simple accumulation of parallel structures can lead to\nhigher structural complexity and longer training time. Based on the Sigmoid\nactivation function of output layer, the linear addition activation value of\nparallel structures in the training process is easy to make the samples fall\ninto the weak gradient interval, resulting in the phenomenon of weak gradient,\nand reducing the effectiveness of training. To this end, this paper proposes a\nParallel Heterogeneous Network (PHN) model, which constructs a network with\nparallel structure through three different interaction analysis methods, and\nuses Soft Selection Gating (SSG) to feature heterogeneous data with different\nstructure. Finally, residual link with trainable parameters are used in the\nnetwork to mitigate the influence of weak gradient phenomenon. Furthermore, we\ndemonstrate the effectiveness of PHN in a large number of comparative\nexperiments, and visualize the performance of the model in training process and\nstructure.",
    "descriptor": "",
    "authors": [
      "Ri Su",
      "Alphonse Houssou Hounye",
      "Cong Cao",
      "Muzhou Hou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.09184"
  },
  {
    "id": "arXiv:2206.09185",
    "title": "Human-Robot Handovers using Task-Space Quadratic Programming",
    "abstract": "Bidirectional object handover between a human and a robot enables an\nimportant functionality skill in robotic human-centered manufacturing or\nservices. The problem in achieving this skill lies in the capacity of any\nsolution to deal with three important aspects: (i) synchronized timing for the\nhanding over phases; (ii) the handling of object pose constraints; and (iii)\nunderstanding the haptic exchanging to seamlessly achieve some steps of the\n(i). We propose a new approach for (i) and (ii) consisting in explicitly\nformulating the handover process as constraints in a task-space quadratic\nprogramming control framework to achieve implicit time and trajectory\nencounters. Our method is implemented on Panda robotic arm taking objects from\na human operator.",
    "descriptor": "\nComments: 6 pages, 7 figures, Accepted in 2022 31st IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)\n",
    "authors": [
      "Mohamed Djeha",
      "Antonin Dallard",
      "Ahmed Zermane",
      "Pierre Gergondet",
      "Abderrahmane Kheddar"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.09185"
  },
  {
    "id": "arXiv:2206.09186",
    "title": "Causal Inference with Treatment Measurement Error: A Nonparametric  Instrumental Variable Approach",
    "abstract": "We propose a kernel-based nonparametric estimator for the causal effect when\nthe cause is corrupted by error. We do so by generalizing estimation in the\ninstrumental variable setting. Despite significant work on regression with\nmeasurement error, additionally handling unobserved confounding in the\ncontinuous setting is non-trivial: we have seen little prior work. As a\nby-product of our investigation, we clarify a connection between mean\nembeddings and characteristic functions, and how learning one simultaneously\nallows one to learn the other. This opens the way for kernel method research to\nleverage existing results in characteristic function estimation. Finally, we\nempirically show that our proposed method, MEKIV, improves over baselines and\nis robust under changes in the strength of measurement error and to the type of\nerror distributions.",
    "descriptor": "\nComments: UAI 2022 (Oral)\n",
    "authors": [
      "Yuchen Zhu",
      "Limor Gultchin",
      "Arthur Gretton",
      "Matt Kusner",
      "Ricardo Silva"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2206.09186"
  },
  {
    "id": "arXiv:2206.09191",
    "title": "Gender Artifacts in Visual Datasets",
    "abstract": "Gender biases are known to exist within large-scale visual datasets and can\nbe reflected or even amplified in downstream models. Many prior works have\nproposed methods for mitigating gender biases, often by attempting to remove\ngender expression information from images. To understand the feasibility and\npracticality of these approaches, we investigate what $\\textit{gender\nartifacts}$ exist within large-scale visual datasets. We define a\n$\\textit{gender artifact}$ as a visual cue that is correlated with gender,\nfocusing specifically on those cues that are learnable by a modern image\nclassifier and have an interpretable human corollary. Through our analyses, we\nfind that gender artifacts are ubiquitous in the COCO and OpenImages datasets,\noccurring everywhere from low-level information (e.g., the mean value of the\ncolor channels) to the higher-level composition of the image (e.g., pose and\nlocation of people). Given the prevalence of gender artifacts, we claim that\nattempts to remove gender artifacts from such datasets are largely infeasible.\nInstead, the responsibility lies with researchers and practitioners to be aware\nthat the distribution of images within datasets is highly gendered and hence\ndevelop methods which are robust to these distributional shifts across groups.",
    "descriptor": "",
    "authors": [
      "Nicole Meister",
      "Dora Zhao",
      "Angelina Wang",
      "Vikram V. Ramaswamy",
      "Ruth Fong",
      "Olga Russakovsky"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09191"
  },
  {
    "id": "arXiv:2206.09195",
    "title": "EEML: Ensemble Embedded Meta-learning",
    "abstract": "To accelerate learning process with few samples, meta-learning resorts to\nprior knowledge from previous tasks. However, the inconsistent task\ndistribution and heterogeneity is hard to be handled through a global sharing\nmodel initialization. In this paper, based on gradient-based meta-learning, we\npropose an ensemble embedded meta-learning algorithm (EEML) that explicitly\nutilizes multi-model-ensemble to organize prior knowledge into diverse specific\nexperts. We rely on a task embedding cluster mechanism to deliver diverse tasks\nto matching experts in training process and instruct how experts collaborate in\ntest phase. As a result, the multi experts can focus on their own area of\nexpertise and cooperate in upcoming task to solve the task heterogeneity. The\nexperimental results show that the proposed method outperforms recent\nstate-of-the-arts easily in few-shot learning problem, which validates the\nimportance of differentiation and cooperation.",
    "descriptor": "",
    "authors": [
      "Geng Li",
      "Boyuan Ren",
      "Hongzhi Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.09195"
  },
  {
    "id": "arXiv:2206.09202",
    "title": "Camera Adaptation for Fundus-Image-Based CVD Risk Estimation",
    "abstract": "Recent studies have validated the association between cardiovascular disease\n(CVD) risk and retinal fundus images. Combining deep learning (DL) and portable\nfundus cameras will enable CVD risk estimation in various scenarios and improve\nhealthcare democratization. However, there are still significant issues to be\nsolved. One of the top priority issues is the different camera differences\nbetween the databases for research material and the samples in the production\nenvironment. Most high-quality retinography databases ready for research are\ncollected from high-end fundus cameras, and there is a significant domain\ndiscrepancy between different cameras. To fully explore the domain discrepancy\nissue, we first collect a Fundus Camera Paired (FCP) dataset containing\npair-wise fundus images captured by the high-end Topcon retinal camera and the\nlow-end Mediwork portable fundus camera of the same patients. Then, we propose\na cross-laterality feature alignment pre-training scheme and a self-attention\ncamera adaptor module to improve the model robustness. The cross-laterality\nfeature alignment training encourages the model to learn common knowledge from\nthe same patient's left and right fundus images and improve model\ngeneralization. Meanwhile, the device adaptation module learns feature\ntransformation from the target domain to the source domain. We conduct\ncomprehensive experiments on both the UK Biobank database and our FCP data. The\nexperimental results show that the CVD risk regression accuracy and the result\nconsistency over two cameras are improved with our proposed method. The code is\navailable here:\n\\url{https://github.com/linzhlalala/CVD-risk-based-on-retinal-fundus-images}",
    "descriptor": "\nComments: This preprint has not undergone peer review (when applicable) or any post-submission improvements or corrections. The Version of Record of this contribution will be added soon\n",
    "authors": [
      "Zhihong Lin",
      "Danli Shi",
      "Donghao Zhang",
      "Xianwen Shang",
      "Mingguang He",
      "Zongyuan Ge"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09202"
  },
  {
    "id": "arXiv:2206.09203",
    "title": "EST: Evaluating Scientific Thinking in Artificial Agents",
    "abstract": "Theoretical ideas and empirical research have shown us a seemingly surprising\nresult: children, even very young toddlers, demonstrate learning and thinking\nin a strikingly similar manner to scientific reasoning in formal research.\nEncountering a novel phenomenon, children make hypotheses against data, conduct\ncausal inference from observation, test their theory via experimentation, and\ncorrect the proposition if inconsistency arises. Rounds of such processes\ncontinue until the underlying mechanism is found. Towards building machines\nthat can learn and think like people, one natural question for us to ask is:\nwhether the intelligence we achieve today manages to perform such a scientific\nthinking process, and if any, at what level. In this work, we devise the EST\nenvironment for evaluating the scientific thinking ability in artificial\nagents. Motivated by the stream of research on causal discovery, we build our\ninteractive EST environment based on Blicket detection. Specifically, in each\nepisode of EST, an agent is presented with novel observations and asked to\nfigure out all objects' Blicketness. At each time step, the agent proposes new\nexperiments to validate its hypothesis and updates its current belief. By\nevaluating Reinforcement Learning (RL) agents on both a symbolic and visual\nversion of this task, we notice clear failure of today's learning methods in\nreaching a level of intelligence comparable to humans. Such inefficacy of\nlearning in scientific thinking calls for future research in building humanlike\nintelligence.",
    "descriptor": "",
    "authors": [
      "Manjie Xu",
      "Guangyuan Jiang",
      "Chi Zhang",
      "Song-Chun Zhu",
      "Yixin Zhu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09203"
  },
  {
    "id": "arXiv:2206.09204",
    "title": "Approximating Max-Cut on Bounded Degree Graphs: Tighter Analysis of the  FKL Algorithm",
    "abstract": "In this note, we describe a $\\alpha_{GW} + \\tilde{\\Omega}(1/d^2)$-factor\napproximation algorithm for Max-Cut on weighted graphs of degree $\\leq d$.\nHere, $\\alpha_{GW}\\approx 0.878$ is the worst-case approximation ratio of the\nGoemans-Williamson rounding for Max-Cut. This improves on previous results for\nunweighted graphs by Feige, Karpinski, and Langberg and Flor\\'en. Our guarantee\nis obtained by a tighter analysis of the solution obtained by applying a\nnatural local improvement procedure to the Goemans-Williamson rounding of the\nbasic SDP strengthened with triangle inequalities.",
    "descriptor": "",
    "authors": [
      "Jun-Ting Hsieh",
      "Pravesh K. Kothari"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.09204"
  },
  {
    "id": "arXiv:2206.09206",
    "title": "Fusing Industry and Academia at GitHub (Experience Report)",
    "abstract": "GitHub hosts hundreds of millions of code repositories written in hundreds of\ndifferent programming languages. In addition to its hosting services, GitHub\nprovides data and insights into code, such as vulnerability analysis and code\nnavigation, with which users can improve and understand their software\ndevelopment process. GitHub has built Semantic, a program analysis tool capable\nof parsing and extracting detailed information from source code. The\ndevelopment of Semantic has relied extensively on the functional programming\nliterature; this paper describes how connections to academic research inspired\nand informed the development of an industrial-scale program analysis toolkit.",
    "descriptor": "\nComments: 14 pages, 2 figures, submitted to ICFP 2022\n",
    "authors": [
      "Patrick Thomson",
      "Rob Rix",
      "Nicolas Wu",
      "Tom Schrijvers"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.09206"
  },
  {
    "id": "arXiv:2206.09207",
    "title": "Comparative study of Three Numerical Schemes for Fractional Integro  differential Equations",
    "abstract": "This paper presents a comparative study three numerical schemes such as\nLinear, Quadratic and Quadratic-Linear scheme for the fractional\nintegro-differential equations defined in terms of the Caputo fractional\nderivatives. The error estimates of the respective approximations are also\nestablished. Numerical tests of the discussed schemes show that all schemes\nwork well, and when the number of terms approximating the solution are\nincreased, the desired solution is achieved. The accuracy of the numerical\nschemes with respect to the step size h is analyzed and illustrated through\nvarious tables. Finally, comparative performances of the schemes are discussed.",
    "descriptor": "\nComments: 27 pages\n",
    "authors": [
      "Kamlesh Kumar",
      "Rajesh K. Pandey",
      "Shiva Sharma"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.09207"
  },
  {
    "id": "arXiv:2206.09211",
    "title": "New LP-based Upper Bounds in the Rate-vs.-Distance Problem for Linear  Codes",
    "abstract": "We develop a new family of linear programs, that yield upper bounds on the\nrate of codes of a given distance. Our bounds apply {\\em only to linear codes.}\nDelsarte's LP is the weakest member of this family and our LP yields\nincreasingly tighter upper bounds on the rate as its control parameter\nincreases. Numerical experiments show significant improvement compared to\nDelsarte. These convincing numerical results, and the large variety of tools\navailable for asymptotic analysis, give us hope that our work will lead to new\nimproved asymptotic upper bounds on the possible rate of linear codes.",
    "descriptor": "",
    "authors": [
      "Elyassaf Loyfer",
      "Nati Linial"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.09211"
  },
  {
    "id": "arXiv:2206.09214",
    "title": "An Invertible Graph Diffusion Neural Network for Source Localization",
    "abstract": "Localizing the source of graph diffusion phenomena, such as misinformation\npropagation, is an important yet extremely challenging task. Existing source\nlocalization models typically are heavily dependent on the hand-crafted rules.\nUnfortunately, a large portion of the graph diffusion process for many\napplications is still unknown to human beings so it is important to have\nexpressive models for learning such underlying rules automatically. This paper\naims to establish a generic framework of invertible graph diffusion models for\nsource localization on graphs, namely Invertible Validity-aware Graph Diffusion\n(IVGD), to handle major challenges including 1) Difficulty to leverage\nknowledge in graph diffusion models for modeling their inverse processes in an\nend-to-end fashion, 2) Difficulty to ensure the validity of the inferred\nsources, and 3) Efficiency and scalability in source inference. Specifically,\nfirst, to inversely infer sources of graph diffusion, we propose a graph\nresidual scenario to make existing graph diffusion models invertible with\ntheoretical guarantees; second, we develop a novel error compensation mechanism\nthat learns to offset the errors of the inferred sources. Finally, to ensure\nthe validity of the inferred sources, a new set of validity-aware layers have\nbeen devised to project inferred sources to feasible regions by flexibly\nencoding constraints with unrolled optimization techniques. A linearization\ntechnique is proposed to strengthen the efficiency of our proposed layers. The\nconvergence of the proposed IVGD is proven theoretically. Extensive experiments\non nine real-world datasets demonstrate that our proposed IVGD outperforms\nstate-of-the-art comparison methods significantly. We have released our code at\nhttps://github.com/xianggebenben/IVGD.",
    "descriptor": "\nComments: WWW 2022\n",
    "authors": [
      "Junxiang Wang",
      "Junji Jiang",
      "Liang Zhao"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09214"
  },
  {
    "id": "arXiv:2206.09215",
    "title": "Mind the Gap: Norm-Aware Adaptive Robust Loss for Multivariate  Least-Squares Problems",
    "abstract": "Measurement outliers are unavoidable when solving real-world robot state\nestimation problems. A large family of robust loss functions (RLFs) exists to\nmitigate the effects of outliers, including newly developed adaptive methods\nthat do not require parameter tuning. All of these methods assume that\nresiduals follow a zero-mean Gaussian-like distribution. However, in\nmultivariate problems the residual is often defined as a norm, and norms follow\na Chi-like distribution with a non-zero mode value. This produces a ''mode\ngap'' that impacts the convergence rate and accuracy of existing RLFs. The\nproposed approach, ''Adaptive MB,'' accounts for this gap by first estimating\nthe mode of the residuals using an adaptive Chi-like distribution. Applying an\nexisting adaptive weighting scheme only to residuals greater than the mode\nleads to more robust performance and faster convergence times in two\nfundamental state estimation problems, point cloud alignment and pose\naveraging.",
    "descriptor": "\nComments: 8 pages, 4 figures. This paper has been accepted for publication in IEEE Robotics and Automation Letters\n",
    "authors": [
      "Thomas Hitchcox",
      "James Richard Forbes"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.09215"
  },
  {
    "id": "arXiv:2206.09221",
    "title": "3D Face Parsing via Surface Parameterization and 2D Semantic  Segmentation Network",
    "abstract": "Face parsing assigns pixel-wise semantic labels as the face representation\nfor computers, which is the fundamental part of many advanced face\ntechnologies. Compared with 2D face parsing, 3D face parsing shows more\npotential to achieve better performance and further application, but it is\nstill challenging due to 3D mesh data computation. Recent works introduced\ndifferent methods for 3D surface segmentation, while the performance is still\nlimited. In this paper, we propose a method based on the \"3D-2D-3D\" strategy to\naccomplish 3D face parsing. The topological disk-like 2D face image containing\nspatial and textural information is transformed from the sampled 3D face data\nthrough the face parameterization algorithm, and a specific 2D network called\nCPFNet is proposed to achieve the semantic segmentation of the 2D parameterized\nface data with multi-scale technologies and feature aggregation. The 2D\nsemantic result is then inversely re-mapped to 3D face data, which finally\nachieves the 3D face parsing. Experimental results show that both CPFNet and\nthe \"3D-2D-3D\" strategy accomplish high-quality 3D face parsing and outperform\nstate-of-the-art 2D networks as well as 3D methods in both qualitative and\nquantitative comparisons.",
    "descriptor": "",
    "authors": [
      "Wenyuan Sun",
      "Ping Zhou",
      "Yangang Wang",
      "Zongpu Yu",
      "Jing Jin",
      "Guangquan Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09221"
  },
  {
    "id": "arXiv:2206.09229",
    "title": "Digital Surveillance Networks of 2014 Ebola Epidemics and Lessons for  COVID-19",
    "abstract": "2014 Ebola outbreaks can offer lessons for the COVOID-19 and the ongoing\nvariant surveillance and the use of multi method approach to detect public\nhealth preparedness. We are increasingly seeing a delay and disconnect of the\ntransmission of locally situated information to the hierarchical system for\nmaking the overall preparedness and response more proactive than reactive for\ndealing with emergencies such as 2014 Ebola. For our COVID-19, it is timely to\nconsider whether digital surveillance networks and support systems can be used\nto bring the formal and community based ad hoc networks required for\nfacilitating the transmission of both strong (i.e., infections, confirmed\ncases, deaths in hospital or clinic settings) and weak alters from the\ncommunity. This will allow timely detection of symptoms of isolated suspected\ncases for making the overall surveillance and intervention strategy far more\neffective. The use of digital surveillance networks can further contribute to\nthe development of global awareness of complex emergencies such as Ebola for\nconstructing information infrastructure required to develop, monitor and\nanalysis of community based global emergency surveillance in developed and\ndeveloping countries. In this study, a systematic analysis of the spread during\nthe months of March to October 2014 was performed using data from the Program\nfor Monitoring Emerging Diseases (ProMED) and the Factiva database. Using\ndigital surveillance networks, we aim to draw network connections of\nindividuals/groups from a localized to a globalized transmission of Ebola using\nreported suspected/probable/confirmed cases at different locations around the\nworld. We argue that public health preparedness and response can be\nstrengthened by understanding the social network connections between responders\n(such as local health authorities) and spreaders (infected individuals and\ngroups).",
    "descriptor": "\nComments: 17 pages, 18 figures\n",
    "authors": [
      "Liaquat Hossain",
      "Fiona Kong",
      "Derek Kham"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.09229"
  },
  {
    "id": "arXiv:2206.09236",
    "title": "Model-Agnostic Few-Shot Open-Set Recognition",
    "abstract": "We tackle the Few-Shot Open-Set Recognition (FSOSR) problem, i.e. classifying\ninstances among a set of classes for which we only have few labeled samples,\nwhile simultaneously detecting instances that do not belong to any known class.\nDeparting from existing literature, we focus on developing model-agnostic\ninference methods that can be plugged into any existing model, regardless of\nits architecture or its training procedure. Through evaluating the embedding's\nquality of a variety of models, we quantify the intrinsic difficulty of\nmodel-agnostic FSOSR. Furthermore, a fair empirical evaluation suggests that\nthe naive combination of a kNN detector and a prototypical classifier ranks\nbefore specialized or complex methods in the inductive setting of FSOSR. These\nobservations motivated us to resort to transduction, as a popular and practical\nrelaxation of standard few-shot learning problems. We introduce an Open Set\nTransductive Information Maximization method OSTIM, which hallucinates an\noutlier prototype while maximizing the mutual information between extracted\nfeatures and assignments. Through extensive experiments spanning 5 datasets, we\nshow that OSTIM surpasses both inductive and existing transductive methods in\ndetecting open-set instances while competing with the strongest transductive\nmethods in classifying closed-set instances. We further show that OSTIM's model\nagnosticity allows it to successfully leverage the strong expressive abilities\nof the latest architectures and training strategies without any hyperparameter\nmodification, a promising sign that architectural advances to come will\ncontinue to positively impact OSTIM's performances.",
    "descriptor": "\nComments: Under review. Code available at this https URL\n",
    "authors": [
      "Malik Boudiaf",
      "Etienne Bennequin",
      "Myriam Tami",
      "Celine Hudelot",
      "Antoine Toubhans",
      "Pablo Piantanida",
      "Ismail Ben Ayed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09236"
  },
  {
    "id": "arXiv:2206.09237",
    "title": "Systematic Analysis and Comparison of Security Advice Datasets",
    "abstract": "A long list of documents have been offered as security advice, codes of\npractice, and security guidelines for building and using security products,\nincluding Internet of Things (IoT) devices. To date, little or no systematic\nanalysis has been carried out on the advice datasets themselves. Contributing\nin this direction, we begin with an informal analysis of two documents offering\nadvice related to IoT security -- the ETSI Provisions and the UK DCMS\nGuidelines -- and then carry out what we believe is the first systematic\nanalysis of these advice datasets. Our analysis explains in what ways the ETSI\nProvisions are a positive evolution of the UK DCMS Guidelines. We also suggest\naspects of security advice that might be given special attention by those\noffering security advice.",
    "descriptor": "",
    "authors": [
      "Christopher Bellman",
      "Paul C. van Oorschot"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.09237"
  },
  {
    "id": "arXiv:2206.09238",
    "title": "On the Role of Generalization in Transferability of Adversarial Examples",
    "abstract": "Black-box adversarial attacks designing adversarial examples for unseen\nneural networks (NNs) have received great attention over the past years. While\nseveral successful black-box attack schemes have been proposed in the\nliterature, the underlying factors driving the transferability of black-box\nadversarial examples still lack a thorough understanding. In this paper, we aim\nto demonstrate the role of the generalization properties of the substitute\nclassifier used for generating adversarial examples in the transferability of\nthe attack scheme to unobserved NN classifiers. To do this, we apply the\nmax-min adversarial example game framework and show the importance of the\ngeneralization properties of the substitute NN in the success of the black-box\nattack scheme in application to different NN classifiers. We prove theoretical\ngeneralization bounds on the difference between the attack transferability\nrates on training and test samples. Our bounds suggest that a substitute NN\nwith better generalization behavior could result in more transferable\nadversarial examples. In addition, we show that standard operator norm-based\nregularization methods could improve the transferability of the designed\nadversarial examples. We support our theoretical results by performing several\nnumerical experiments showing the role of the substitute network's\ngeneralization in generating transferable adversarial examples. Our empirical\nresults indicate the power of Lipschitz regularization methods in improving the\ntransferability of adversarial examples.",
    "descriptor": "",
    "authors": [
      "Yilin Wang",
      "Farzan Farnia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.09238"
  },
  {
    "id": "arXiv:2206.09242",
    "title": "GaLeNet: Multimodal Learning for Disaster Prediction, Management and  Relief",
    "abstract": "After a natural disaster, such as a hurricane, millions are left in need of\nemergency assistance. To allocate resources optimally, human planners need to\naccurately analyze data that can flow in large volumes from several sources.\nThis motivates the development of multimodal machine learning frameworks that\ncan integrate multiple data sources and leverage them efficiently. To date, the\nresearch community has mainly focused on unimodal reasoning to provide granular\nassessments of the damage. Moreover, previous studies mostly rely on\npost-disaster images, which may take several days to become available. In this\nwork, we propose a multimodal framework (GaLeNet) for assessing the severity of\ndamage by complementing pre-disaster images with weather data and the\ntrajectory of the hurricane. Through extensive experiments on data from two\nhurricanes, we demonstrate (i) the merits of multimodal approaches compared to\nunimodal methods, and (ii) the effectiveness of GaLeNet at fusing various\nmodalities. Furthermore, we show that GaLeNet can leverage pre-disaster images\nin the absence of post-disaster images, preventing substantial delays in\ndecision making.",
    "descriptor": "\nComments: Accepted to CVPR 2022 Workshop on Multimodal Learning for Earth and Environment\n",
    "authors": [
      "Rohit Saha",
      "Mengyi Fang",
      "Angeline Yasodhara",
      "Kyryl Truskovskyi",
      "Azin Asgarian",
      "Daniel Homola",
      "Raahil Shah",
      "Frederik Dieleman",
      "Jack Weatheritt",
      "Thomas Rogers"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09242"
  },
  {
    "id": "arXiv:2206.09243",
    "title": "Structured Light with Redundancy Codes",
    "abstract": "Structured light (SL) systems acquire high-fidelity 3D geometry with active\nillumination projection. Conventional systems exhibit challenges when working\nin environments with strong ambient illumination, global illumination and\ncross-device interference. This paper proposes a general-purposed technique to\nimprove the robustness of SL by projecting redundant optical signals in\naddition to the native SL patterns. In this way, projected signals become more\ndistinguishable from errors. Thus the geometry information can be more easily\nrecovered using simple signal processing and the ``coding gain\" in performance\nis obtained. We propose three applications using our redundancy codes: (1) Self\nerror-correction for SL imaging under strong ambient light, (2) Error detection\nfor adaptive reconstruction under global illumination, and (3) Interference\nfiltering with device-specific projection sequence encoding, especially for\nevent camera-based SL and light curtain devices. We systematically analyze the\ndesign rules and signal processing algorithms in these applications.\nCorresponding hardware prototypes are built for evaluations on real-world\ncomplex scenes. Experimental results on the synthetic and real data demonstrate\nthe significant performance improvements in SL systems with our redundancy\ncodes.",
    "descriptor": "",
    "authors": [
      "Zhanghao Sun",
      "Yu Zhang",
      "Yicheng Wu",
      "Dong Huo",
      "Yiming Qian",
      "Jian Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.09243"
  },
  {
    "id": "arXiv:2206.09244",
    "title": "GAN2X: Non-Lambertian Inverse Rendering of Image GANs",
    "abstract": "2D images are observations of the 3D physical world depicted with the\ngeometry, material, and illumination components. Recovering these underlying\nintrinsic components from 2D images, also known as inverse rendering, usually\nrequires a supervised setting with paired images collected from multiple\nviewpoints and lighting conditions, which is resource-demanding. In this work,\nwe present GAN2X, a new method for unsupervised inverse rendering that only\nuses unpaired images for training. Unlike previous Shape-from-GAN approaches\nthat mainly focus on 3D shapes, we take the first attempt to also recover\nnon-Lambertian material properties by exploiting the pseudo paired data\ngenerated by a GAN. To achieve precise inverse rendering, we devise a\nspecularity-aware neural surface representation that continuously models the\ngeometry and material properties. A shading-based refinement technique is\nadopted to further distill information in the target image and recover more\nfine details. Experiments demonstrate that GAN2X can accurately decompose 2D\nimages to 3D shape, albedo, and specular properties for different object\ncategories, and achieves the state-of-the-art performance for unsupervised\nsingle-view 3D face reconstruction. We also show its applications in downstream\ntasks including real image editing and lifting 2D GANs to decomposed 3D GANs.",
    "descriptor": "\nComments: The video demo is available at the project page: this https URL\n",
    "authors": [
      "Xingang Pan",
      "Ayush Tewari",
      "Lingjie Liu",
      "Christian Theobalt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09244"
  },
  {
    "id": "arXiv:2206.09247",
    "title": "Reduced Robust Random Cut Forest for Out-Of-Distribution detection in  machine learning models",
    "abstract": "Most machine learning-based regressors extract information from data\ncollected via past observations of limited length to make predictions in the\nfuture. Consequently, when input to these trained models is data with\nsignificantly different statistical properties from data used for training,\nthere is no guarantee of accurate prediction. Consequently, using these models\non out-of-distribution input data may result in a completely different\npredicted outcome from the desired one, which is not only erroneous but can\nalso be hazardous in some cases. Successful deployment of these machine\nlearning models in any system requires a detection system, which should be able\nto distinguish between out-of-distribution and in-distribution data (i.e.\nsimilar to training data). In this paper, we introduce a novel approach for\nthis detection process using a Reduced Robust Random Cut Forest (RRRCF) data\nstructure, which can be used on both small and large data sets. Similar to the\nRobust Random Cut Forest (RRCF), RRRCF is a structured, but a reduced\nrepresentation of the training data sub-space in form of cut trees. Empirical\nresults of this method on both low and high-dimensional data showed that\ninference about data being in/out of training distribution can be made\nefficiently and the model is easy to train with no difficult hyper-parameter\ntuning. The paper discusses two different use-cases for testing and validating\nresults.",
    "descriptor": "",
    "authors": [
      "Harsh Vardhan",
      "Janos Sztipanovits"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.09247"
  },
  {
    "id": "arXiv:2206.09248",
    "title": "Collocation2Text: Controllable Text Generation from Guide Phrases in  Russian",
    "abstract": "Large pre-trained language models are capable of generating varied and fluent\ntexts. Starting from the prompt, these models generate a narrative that can\ndevelop unpredictably. The existing methods of controllable text generation,\nwhich guide the narrative in the text in the user-specified direction, require\ncreating a training corpus and an additional time-consuming training procedure.\nThe paper proposes and investigates Collocation2Text, a plug-and-play method\nfor automatic controllable text generation in Russian, which does not require\nfine-tuning. The method is based on two interacting models: the autoregressive\nlanguage ruGPT-3 model and the autoencoding language ruRoBERTa model. The idea\nof the method is to shift the output distribution of the autoregressive model\naccording to the output distribution of the autoencoding model in order to\nensure a coherent transition of the narrative in the text towards the guide\nphrase, which can contain single words or collocations. The autoencoding model,\nwhich is able to take into account the left and right contexts of the token,\n\"tells\" the autoregressive model which tokens are the most and least logical at\nthe current generation step, increasing or decreasing the probabilities of the\ncorresponding tokens. The experiments on generating news articles using the\nproposed method showed its effectiveness for automatically generated fluent\ntexts which contain coherent transitions between user-specified phrases.",
    "descriptor": "\nComments: Accepted by Dialogue-2022 conference\n",
    "authors": [
      "Sergey Vychegzhanin",
      "Evgeny Kotelnikov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.09248"
  },
  {
    "id": "arXiv:2206.09249",
    "title": "RuArg-2022: Argument Mining Evaluation",
    "abstract": "Argumentation analysis is a field of computational linguistics that studies\nmethods for extracting arguments from texts and the relationships between them,\nas well as building argumentation structure of texts. This paper is a report of\nthe organizers on the first competition of argumentation analysis systems\ndealing with Russian language texts within the framework of the Dialogue\nconference. During the competition, the participants were offered two tasks:\nstance detection and argument classification. A corpus containing 9,550\nsentences (comments on social media posts) on three topics related to the\nCOVID-19 pandemic (vaccination, quarantine, and wearing masks) was prepared,\nannotated, and used for training and testing. The system that won the first\nplace in both tasks used the NLI (Natural Language Inference) variant of the\nBERT architecture, automatic translation into English to apply a specialized\nBERT model, retrained on Twitter posts discussing COVID-19, as well as\nadditional masking of target entities. This system showed the following\nresults: for the stance detection task an F1-score of 0.6968, for the argument\nclassification task an F1-score of 0.7404. We hope that the prepared dataset\nand baselines will help to foster further research on argument mining for the\nRussian language.",
    "descriptor": "\nComments: Accepted by Dialogue-2022 conference\n",
    "authors": [
      "Evgeny Kotelnikov",
      "Natalia Loukachevitch",
      "Irina Nikishina",
      "Alexander Panchenko"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.09249"
  },
  {
    "id": "arXiv:2206.09250",
    "title": "Robin Milner's Work on Concurrency: An Appreciation",
    "abstract": "We give a short appreciation of Robin Milner's seminal contributions to the\ntheory of concurrency.",
    "descriptor": "\nComments: Text of a talk given at MFPS 2010\n",
    "authors": [
      "Samson Abramsky"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.09250"
  },
  {
    "id": "arXiv:2206.09251",
    "title": "Argumentative Text Generation in Economic Domain",
    "abstract": "The development of large and super-large language models, such as GPT-3, T5,\nSwitch Transformer, ERNIE, etc., has significantly improved the performance of\ntext generation. One of the important research directions in this area is the\ngeneration of texts with arguments. The solution of this problem can be used in\nbusiness meetings, political debates, dialogue systems, for preparation of\nstudent essays. One of the main domains for these applications is the economic\nsphere. The key problem of the argument text generation for the Russian\nlanguage is the lack of annotated argumentation corpora. In this paper, we use\ntranslated versions of the Argumentative Microtext, Persuasive Essays and UKP\nSentential corpora to fine-tune RuBERT model. Further, this model is used to\nannotate the corpus of economic news by argumentation. Then the annotated\ncorpus is employed to fine-tune the ruGPT-3 model, which generates argument\ntexts. The results show that this approach improves the accuracy of the\nargument generation by more than 20 percentage points (63.2\\% vs. 42.5\\%)\ncompared to the original ruGPT-3 model.",
    "descriptor": "\nComments: Accepted by Dialogue-2022 conference\n",
    "authors": [
      "Irina Fishcheva",
      "Dmitriy Osadchiy",
      "Klavdiya Bochenina",
      "Evgeny Kotelnikov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.09251"
  },
  {
    "id": "arXiv:2206.09253",
    "title": "Automatic Summarization of Russian Texts: Comparison of Extractive and  Abstractive Methods",
    "abstract": "The development of large and super-large language models, such as GPT-3, T5,\nSwitch Transformer, ERNIE, etc., has significantly improved the performance of\ntext generation. One of the important research directions in this area is the\ngeneration of texts with arguments. The solution of this problem can be used in\nbusiness meetings, political debates, dialogue systems, for preparation of\nstudent essays. One of the main domains for these applications is the economic\nsphere. The key problem of the argument text generation for the Russian\nlanguage is the lack of annotated argumentation corpora. In this paper, we use\ntranslated versions of the Argumentative Microtext, Persuasive Essays and UKP\nSentential corpora to fine-tune RuBERT model. Further, this model is used to\nannotate the corpus of economic news by argumentation. Then the annotated\ncorpus is employed to fine-tune the ruGPT-3 model, which generates argument\ntexts. The results show that this approach improves the accuracy of the\nargument generation by more than 20 percentage points (63.2% vs. 42.5%)\ncompared to the original ruGPT-3 model.",
    "descriptor": "\nComments: Accepted by Dialogue-2022 conference\n",
    "authors": [
      "Valeriya Goloviznina",
      "Evgeny Kotelnikov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.09253"
  },
  {
    "id": "arXiv:2206.09254",
    "title": "Mutation-Driven Follow the Regularized Leader for Last-Iterate  Convergence in Zero-Sum Games",
    "abstract": "In this study, we consider a variant of the Follow the Regularized Leader\n(FTRL) dynamics in two-player zero-sum games. FTRL is guaranteed to converge to\na Nash equilibrium when time-averaging the strategies, while a lot of variants\nsuffer from the issue of limit cycling behavior, i.e., lack the last-iterate\nconvergence guarantee. To this end, we propose mutant FTRL (M-FTRL), an\nalgorithm that introduces mutation for the perturbation of action\nprobabilities. We then investigate the continuous-time dynamics of M-FTRL and\nprovide the strong convergence guarantees toward stationary points that\napproximate Nash equilibria under full-information feedback. Furthermore, our\nsimulation demonstrates that M-FTRL can enjoy faster convergence rates than\nFTRL and optimistic FTRL under full-information feedback and surprisingly\nexhibits clear convergence under bandit feedback.",
    "descriptor": "\nComments: Accepted in UAI 2022\n",
    "authors": [
      "Kenshi Abe",
      "Mitsuki Sakamoto",
      "Atsushi Iwasaki"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.09254"
  },
  {
    "id": "arXiv:2206.09256",
    "title": "Multistream Gaze Estimation with Anatomical Eye Region Isolation by  Synthetic to Real Transfer Learning",
    "abstract": "We propose a novel neural pipeline, MSGazeNet, that learns gaze\nrepresentations by taking advantage of the eye anatomy information through a\nmultistream framework. Our proposed solution comprises two components, first a\nnetwork for isolating anatomical eye regions, and a second network for\nmultistream gaze estimation. The eye region isolation is performed with a U-Net\nstyle network which we train using a synthetic dataset that contains eye region\nmasks for the visible eyeball and the iris region. The synthetic dataset used\nin this stage is a new dataset consisting of 60,000 eye images, which we create\nusing an eye-gaze simulator, UnityEyes. Successive to training, the eye region\nisolation network is then transferred to the real domain for generating masks\nfor the real-world eye images. In order to successfully make the transfer, we\nexploit domain randomization in the training process, which allows for the\nsynthetic images to benefit from a larger variance with the help of\naugmentations that resemble artifacts. The generated eye region masks along\nwith the raw eye images are then used together as a multistream input to our\ngaze estimation network. We evaluate our framework on three benchmark gaze\nestimation datasets, MPIIGaze, Eyediap, and UTMultiview, where we set a new\nstate-of-the-art on Eyediap and UTMultiview datasets by obtaining a performance\ngain of 7.57% and 1.85% respectively, while achieving competitive performance\non MPIIGaze. We also study the robustness of our method with respect to the\nnoise in the data and demonstrate that our model is less sensitive to noisy\ndata. Lastly, we perform a variety of experiments including ablation studies to\nevaluate the contribution of different components and design choices in our\nsolution.",
    "descriptor": "\nComments: 14 pages, 10 figures, 12 tables. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice\n",
    "authors": [
      "Zunayed Mahmud",
      "Paul Hungler",
      "Ali Etemad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09256"
  },
  {
    "id": "arXiv:2206.09257",
    "title": "Optimal Dynamic Regret in LQR Control",
    "abstract": "We consider the problem of nonstochastic control with a sequence of quadratic\nlosses, i.e., LQR control. We provide an efficient online algorithm that\nachieves an optimal dynamic (policy) regret of $\\tilde{O}(\\text{max}\\{n^{1/3}\n\\mathcal{TV}(M_{1:n})^{2/3}, 1\\})$, where $\\mathcal{TV}(M_{1:n})$ is the total\nvariation of any oracle sequence of Disturbance Action policies parameterized\nby $M_1,...,M_n$ -- chosen in hindsight to cater to unknown nonstationarity.\nThe rate improves the best known rate of $\\tilde{O}(\\sqrt{n\n(\\mathcal{TV}(M_{1:n})+1)} )$ for general convex losses and we prove that it is\ninformation-theoretically optimal for LQR. Main technical components include\nthe reduction of LQR to online linear regression with delayed feedback due to\nFoster and Simchowitz (2020), as well as a new proper learning algorithm with\nan optimal $\\tilde{O}(n^{1/3})$ dynamic regret on a family of ``minibatched''\nquadratic losses, which could be of independent interest.",
    "descriptor": "",
    "authors": [
      "Dheeraj Baby",
      "Yu-Xiang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.09257"
  },
  {
    "id": "arXiv:2206.09258",
    "title": "Machine Learning in Sports: A Case Study on Using Explainable Models for  Predicting Outcomes of Volleyball Matches",
    "abstract": "Machine Learning has become an integral part of engineering design and\ndecision making in several domains, including sports. Deep Neural Networks\n(DNNs) have been the state-of-the-art methods for predicting outcomes of\nprofessional sports events. However, apart from getting highly accurate\npredictions on these sports events outcomes, it is necessary to answer\nquestions such as \"Why did the model predict that Team A would win Match X\nagainst Team B?\" DNNs are inherently black-box in nature. Therefore, it is\nrequired to provide high-quality interpretable, and understandable explanations\nfor a model's prediction in sports. This paper explores a two-phased\nExplainable Artificial Intelligence(XAI) approach to predict outcomes of\nmatches in the Brazilian volleyball League (SuperLiga). In the first phase, we\ndirectly use the interpretable rule-based ML models that provide a global\nunderstanding of the model's behaviors based on Boolean Rule Column Generation\n(BRCG; extracts simple AND-OR classification rules) and Logistic Regression\n(LogReg; allows to estimate the feature importance scores). In the second\nphase, we construct non-linear models such as Support Vector Machine (SVM) and\nDeep Neural Network (DNN) to obtain predictive performance on the volleyball\nmatches' outcomes. We construct the \"post-hoc\" explanations for each data\ninstance using ProtoDash, a method that finds prototypes in the training\ndataset that are most similar to the test instance, and SHAP, a method that\nestimates the contribution of each feature on the model's prediction. We\nevaluate the SHAP explanations using the faithfulness metric. Our results\ndemonstrate the effectiveness of the explanations for the model's predictions.",
    "descriptor": "\nComments: 9 pages, 1 figure, accepted to 2nd International Conference on Sports Engineering (ICSE 2021)\n",
    "authors": [
      "Abhinav Lalwani",
      "Aman Saraiya",
      "Apoorv Singh",
      "Aditya Jain",
      "Tirtharaj Dash"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.09258"
  },
  {
    "id": "arXiv:2206.09259",
    "title": "Can Language Models Capture Graph Semantics? From Graphs to Language  Model and Vice-Versa",
    "abstract": "Knowledge Graphs are a great resource to capture semantic knowledge in terms\nof entities and relationships between the entities. However, current deep\nlearning models takes as input distributed representations or vectors. Thus,\nthe graph is compressed in a vectorized representation. We conduct a study to\nexamine if the deep learning model can compress a graph and then output the\nsame graph with most of the semantics intact. Our experiments show that\nTransformer models are not able to express the full semantics of the input\nknowledge graph. We find that this is due to the disparity between the\ndirected, relationship and type based information contained in a Knowledge\nGraph and the fully connected token-token undirected graphical interpretation\nof the Transformer Attention matrix.",
    "descriptor": "",
    "authors": [
      "Tarun Garg",
      "Kaushik Roy",
      "Amit Sheth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.09259"
  },
  {
    "id": "arXiv:2206.09262",
    "title": "Motley: Benchmarking Heterogeneity and Personalization in Federated  Learning",
    "abstract": "Personalized federated learning considers learning models unique to each\nclient in a heterogeneous network. The resulting client-specific models have\nbeen purported to improve metrics such as accuracy, fairness, and robustness in\nfederated networks. However, despite a plethora of work in this area, it\nremains unclear: (1) which personalization techniques are most effective in\nvarious settings, and (2) how important personalization truly is for realistic\nfederated applications. To better answer these questions, we propose Motley, a\nbenchmark for personalized federated learning. Motley consists of a suite of\ncross-device and cross-silo federated datasets from varied problem domains, as\nwell as thorough evaluation metrics for better understanding the possible\nimpacts of personalization. We establish baselines on the benchmark by\ncomparing a number of representative personalized federated learning methods.\nThese initial results highlight strengths and weaknesses of existing\napproaches, and raise several open questions for the community. Motley aims to\nprovide a reproducible means with which to advance developments in personalized\nand heterogeneity-aware federated learning, as well as the related areas of\ntransfer learning, meta-learning, and multi-task learning.",
    "descriptor": "\nComments: 35 pages, 9 figures, 5 tables. Code: this https URL\n",
    "authors": [
      "Shanshan Wu",
      "Tian Li",
      "Zachary Charles",
      "Yu Xiao",
      "Ziyu Liu",
      "Zheng Xu",
      "Virginia Smith"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.09262"
  },
  {
    "id": "arXiv:2206.09264",
    "title": "Pisces: Efficient Federated Learning via Guided Asynchronous Training",
    "abstract": "Federated learning (FL) is typically performed in a synchronous parallel\nmanner, where the involvement of a slow client delays a training iteration.\nCurrent FL systems employ a participant selection strategy to select fast\nclients with quality data in each iteration. However, this is not always\npossible in practice, and the selection strategy often has to navigate an\nunpleasant trade-off between the speed and the data quality of clients.\nIn this paper, we present Pisces, an asynchronous FL system with intelligent\nparticipant selection and model aggregation for accelerated training. To avoid\nincurring excessive resource cost and stale training computation, Pisces uses a\nnovel scoring mechanism to identify suitable clients to participate in a\ntraining iteration. It also adapts the pace of model aggregation to dynamically\nbound the progress gap between the selected clients and the server, with a\nprovable convergence guarantee in a smooth non-convex setting. We have\nimplemented Pisces in an open-source FL platform called Plato, and evaluated\nits performance in large-scale experiments with popular vision and language\nmodels. Pisces outperforms the state-of-the-art synchronous and asynchronous\nschemes, accelerating the time-to-accuracy by up to 2.0x and 1.9x,\nrespectively.",
    "descriptor": "\nComments: 15 pages, 15 figures, under anonymous submission\n",
    "authors": [
      "Zhifeng Jiang",
      "Wei Wang",
      "Baochun Li",
      "Bo Li"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09264"
  },
  {
    "id": "arXiv:2206.09265",
    "title": "SAViR-T: Spatially Attentive Visual Reasoning with Transformers",
    "abstract": "We present a novel computational model, \"SAViR-T\", for the family of visual\nreasoning problems embodied in the Raven's Progressive Matrices (RPM). Our\nmodel considers explicit spatial semantics of visual elements within each image\nin the puzzle, encoded as spatio-visual tokens, and learns the intra-image as\nwell as the inter-image token dependencies, highly relevant for the visual\nreasoning task. Token-wise relationship, modeled through a transformer-based\nSAViR-T architecture, extract group (row or column) driven representations by\nleveraging the group-rule coherence and use this as the inductive bias to\nextract the underlying rule representations in the top two row (or column) per\ntoken in the RPM. We use this relation representations to locate the correct\nchoice image that completes the last row or column for the RPM. Extensive\nexperiments across both synthetic RPM benchmarks, including RAVEN, I-RAVEN,\nRAVEN-FAIR, and PGM, and the natural image-based \"V-PROM\" demonstrate that\nSAViR-T sets a new state-of-the-art for visual reasoning, exceeding prior\nmodels' performance by a considerable margin.",
    "descriptor": "",
    "authors": [
      "Pritish Sahu",
      "Kalliopi Basioti",
      "Vladimir Pavlovic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09265"
  },
  {
    "id": "arXiv:2206.09269",
    "title": "Automatic Self-Adaptive Local Voltage Control Under Limited Reactive  Power",
    "abstract": "Increasing proliferation of distributed energy resources has posed new\nchallenges to Volt/VAr control problems in distribution networks. To this end,\nthis paper proposes an automatic self-adaptive local voltage control (ASALVC)\nby locally controlling VAr outputs of distributed energy resources. In this\nASALVC strategy, each bus agent can locally and dynamically adjust its voltage\ndroop function in accordance with time-varying system changes. The voltage\ndroop function is associated with the bus-specific time-varying slope and\nintercept, which can be locally updated, merely based on local voltage\nmeasurements, without requiring communications. Stability, convergence and\noptimality properties of this local voltage control are analytically\nestablished. Numerical test cases are performed to validate and demonstrate the\neffectiveness and superiority of ASALVC.",
    "descriptor": "",
    "authors": [
      "Rui Cheng",
      "Naihao Shi",
      "Salish Maharjan",
      "Zhaoyu Wang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.09269"
  },
  {
    "id": "arXiv:2206.09272",
    "title": "DECK: Model Hardening for Defending Pervasive Backdoors",
    "abstract": "Pervasive backdoors are triggered by dynamic and pervasive input\nperturbations. They can be intentionally injected by attackers or naturally\nexist in normally trained models. They have a different nature from the\ntraditional static and localized backdoors that can be triggered by perturbing\na small input area with some fixed pattern, e.g., a patch with solid color.\nExisting defense techniques are highly effective for traditional backdoors.\nHowever, they may not work well for pervasive backdoors, especially regarding\nbackdoor removal and model hardening. In this paper, we propose a novel model\nhardening technique against pervasive backdoors, including both natural and\ninjected backdoors. We develop a general pervasive attack based on an\nencoder-decoder architecture enhanced with a special transformation layer. The\nattack can model a wide range of existing pervasive backdoor attacks and\nquantify them by class distances. As such, using the samples derived from our\nattack in adversarial training can harden a model against these backdoor\nvulnerabilities. Our evaluation on 9 datasets with 15 model structures shows\nthat our technique can enlarge class distances by 59.65% on average with less\nthan 1% accuracy degradation and no robustness loss, outperforming five\nhardening techniques such as adversarial training, universal adversarial\ntraining, MOTH, etc. It can reduce the attack success rate of six pervasive\nbackdoor attacks from 99.06% to 1.94%, surpassing seven state-of-the-art\nbackdoor removal techniques.",
    "descriptor": "",
    "authors": [
      "Guanhong Tao",
      "Yingqi Liu",
      "Siyuan Cheng",
      "Shengwei An",
      "Zhuo Zhang",
      "Qiuling Xu",
      "Guangyu Shen",
      "Xiangyu Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09272"
  },
  {
    "id": "arXiv:2206.09273",
    "title": "High Resolution Point Clouds from mmWave Radar",
    "abstract": "This paper explores a machine learning approach for generating high\nresolution point clouds from a single-chip mmWave radar. Unlike lidar and\nvision-based systems, mmWave radar can operate in harsh environments and see\nthrough occlusions like smoke, fog, and dust. Unfortunately, current mmWave\nprocessing techniques offer poor spatial resolution compared to lidar point\nclouds. This paper presents RadarHD, an end-to-end neural network that\nconstructs lidar-like point clouds from low resolution radar input. Enhancing\nradar images is challenging due to the presence of specular and spurious\nreflections. Radar data also doesn't map well to traditional image processing\ntechniques due to the signal's sinc-like spreading pattern. We overcome these\nchallenges by training RadarHD on a large volume of raw I/Q radar data paired\nwith lidar point clouds across diverse indoor settings. Our experiments show\nthe ability to generate rich point clouds even in scenes unobserved during\ntraining and in the presence of heavy smoke occlusion. Further, RadarHD's point\nclouds are high-quality enough to work with existing lidar odometry and mapping\nworkflows.",
    "descriptor": "",
    "authors": [
      "Akarsh Prabhakara",
      "Tao Jin",
      "Arnav Das",
      "Gantavya Bhatt",
      "Lilly Kumari",
      "Elahe Soltanaghaei",
      "Jeff Bilmes",
      "Swarun Kumar",
      "Anthony Rowe"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.09273"
  },
  {
    "id": "arXiv:2206.09274",
    "title": "Scalable Classifier-Agnostic Channel Selection for MTSC",
    "abstract": "Accuracy is a key focus of current work in time series classification.\nHowever, speed and data reduction in many applications is equally important,\nespecially when the data scale and storage requirements increase rapidly.\nCurrent MTSC algorithms need hundreds of compute hours to complete training and\nprediction. This is due to the nature of multivariate time series data, which\ngrows with the number of time series, their length and the number of channels.\nIn many applications, not all the channels are useful for the classification\ntask; hence we require methods that can efficiently select useful channels and\nthus save computational resources. We propose and evaluate two methods for\nchannel selection. Our techniques work by representing each class by a\nprototype time series and performing channel selection based on the prototype\ndistance between classes. The main hypothesis is that useful channels enable\nbetter separation between classes; hence, channels with the higher distance\nbetween class prototypes are more useful. On the UEA Multivariate Time Series\nClassification (MTSC) benchmark, we show that these techniques achieve\nsignificant data reduction and classifier speedup for similar levels of\nclassification accuracy. Channel selection is applied as a pre-processing step\nbefore training state-of-the-art MTSC algorithms and saves about 70\\% of\ncomputation time and data storage, with preserved accuracy. Furthermore, our\nmethods enable even efficient classifiers, such as ROCKET, to achieve better\naccuracy than using no channel selection or forward channel selection. To\nfurther study the impact of our techniques, we present experiments on\nclassifying synthetic multivariate time series datasets with more than 100\nchannels, as well as a real-world case study on a dataset with 50 channels. Our\nchannel selection methods lead to significant data reduction with preserved or\nimproved accuracy.",
    "descriptor": "",
    "authors": [
      "Bhaskar Dhariyal",
      "Thach Le Nguyen",
      "Georgiana Ifrim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09274"
  },
  {
    "id": "arXiv:2206.09275",
    "title": "Anticipated emotions associated with trust in autonomous vehicles",
    "abstract": "Trust in automation has been mainly studied in the cognitive perspective,\nthough some researchers have shown that trust is also influenced by emotion.\nTherefore, it is essential to investigate the relationships between emotions\nand trust. In this study, we explored the pattern of 19 anticipated emotions\nassociated with two levels of trust (i.e., low vs. high levels of trust)\nelicited from two levels of autonomous vehicles (AVs) performance (i.e.,\nfailure and non-failure) from 105 participants from Amazon Mechanical Turk\n(AMT). Trust was assessed at three layers i.e., dispositional, initial learned,\nand situational trust. The study was designed to measure how emotions are\naffected with low and high levels of trust. Situational trust was significantly\ncorrelated with emotions that a high level of trust significantly improved\nparticipants' positive emotions, and vice versa. We also identified the\nunderlying factors of emotions associated with situational trust. Our results\noffered important implications on anticipated emotions associated with trust in\nAVs.",
    "descriptor": "",
    "authors": [
      "Lilit Avetisian",
      "Jackie Ayoub",
      "Feng Zhou"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.09275"
  },
  {
    "id": "arXiv:2206.09276",
    "title": "Neural Shape-from-Shading for Survey-Scale Self-Consistent Bathymetry  from Sidescan",
    "abstract": "Sidescan sonar is a small and cost-effective sensing solution that can be\neasily mounted on most vessels. Historically, it has been used to produce\nhigh-definition images that experts may use to identify targets on the seafloor\nor in the water column. While solutions have been proposed to produce\nbathymetry solely from sidescan, or in conjunction with multibeam, they have\nhad limited impact. This is partly a result of mostly being limited to single\nsidescan lines. In this paper, we propose a modern, salable solution to create\nhigh quality survey-scale bathymetry from many sidescan lines. By incorporating\nmultiple observations of the same place, results can be improved as the\nestimates reinforce each other. Our method is based on sinusoidal\nrepresentation networks, a recent advance in neural representation learning. We\ndemonstrate the scalability of the approach by producing bathymetry from a\nlarge sidescan survey. The resulting quality is demonstrated by comparing to\ndata collected with a high-precision multibeam sensor.",
    "descriptor": "\nComments: Submitted to IEEE Journal of Oceanic Engineering (IEEE-JOE), under review as of June 2022\n",
    "authors": [
      "Nils Bore",
      "John Folkesson"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.09276"
  },
  {
    "id": "arXiv:2206.09280",
    "title": "AutoGML: Fast Automatic Model Selection for Graph Machine Learning",
    "abstract": "Given a graph learning task, such as link prediction, on a new graph dataset,\nhow can we automatically select the best method as well as its hyperparameters\n(collectively called a model)? Model selection for graph learning has been\nlargely ad hoc. A typical approach has been to apply popular methods to new\ndatasets, but this is often suboptimal. On the other hand, systematically\ncomparing models on the new graph quickly becomes too costly, or even\nimpractical. In this work, we develop the first meta-learning approach for\nautomatic graph machine learning, called AutoGML, which capitalizes on the\nprior performances of a large body of existing methods on benchmark graph\ndatasets, and carries over this prior experience to automatically select an\neffective model to use for the new graph, without any model training or\nevaluations. To capture the similarity across graphs from different domains, we\nintroduce specialized meta-graph features that quantify the structural\ncharacteristics of a graph. Then we design a meta-graph that represents the\nrelations among models and graphs, and develop a graph meta-learner operating\non the meta-graph, which estimates the relevance of each model to different\ngraphs. Through extensive experiments, we show that using AutoGML to select a\nmethod for the new graph significantly outperforms consistently applying\npopular methods as well as several existing meta-learners, while being\nextremely fast at test time.",
    "descriptor": "",
    "authors": [
      "Namyong Park",
      "Ryan Rossi",
      "Nesreen Ahmed",
      "Christos Faloutsos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.09280"
  },
  {
    "id": "arXiv:2206.09286",
    "title": "From Universal Humanoid Control to Automatic Physically Valid Character  Creation",
    "abstract": "Automatically designing virtual humans and humanoids holds great potential in\naiding the character creation process in games, movies, and robots. In some\ncases, a character creator may wish to design a humanoid body customized for\ncertain motions such as karate kicks and parkour jumps. In this work, we\npropose a humanoid design framework to automatically generate physically valid\nhumanoid bodies conditioned on sequence(s) of pre-specified human motions.\nFirst, we learn a generalized humanoid controller trained on a large-scale\nhuman motion dataset that features diverse human motion and body shapes.\nSecond, we use a design-and-control framework to optimize a humanoid's physical\nattributes to find body designs that can better imitate the pre-specified human\nmotion sequence(s). Leveraging the pre-trained humanoid controller and physics\nsimulation as guidance, our method is able to discover new humanoid designs\nthat are customized to perform pre-specified human motions.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Zhengyi Luo",
      "Ye Yuan",
      "Kris M. Kitani"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09286"
  },
  {
    "id": "arXiv:2206.09293",
    "title": "Rethinking Bayesian Deep Learning Methods for Semi-Supervised Volumetric  Medical Image Segmentation",
    "abstract": "Recently, several Bayesian deep learning methods have been proposed for\nsemi-supervised medical image segmentation. Although they have achieved\npromising results on medical benchmarks, some problems are still existing.\nFirstly, their overall architectures belong to the discriminative models, and\nhence, in the early stage of training, they only use labeled data for training,\nwhich might make them overfit to the labeled data. Secondly, in fact, they are\nonly partially based on Bayesian deep learning, as their overall architectures\nare not designed under the Bayesian framework. However, unifying the overall\narchitecture under the Bayesian perspective can make the architecture have a\nrigorous theoretical basis, so that each part of the architecture can have a\nclear probabilistic interpretation. Therefore, to solve the problems, we\npropose a new generative Bayesian deep learning (GBDL) architecture. GBDL\nbelongs to the generative models, whose target is to estimate the joint\ndistribution of input medical volumes and their corresponding labels.\nEstimating the joint distribution implicitly involves the distribution of data,\nso both labeled and unlabeled data can be utilized in the early stage of\ntraining, which alleviates the potential overfitting problem. Besides, GBDL is\ncompletely designed under the Bayesian framework, and thus we give its full\nBayesian formulation, which lays a theoretical probabilistic foundation for our\narchitecture. Extensive experiments show that our GBDL outperforms previous\nstate-of-the-art methods in terms of four commonly used evaluation indicators\non three public medical datasets.",
    "descriptor": "\nComments: To appear at CVPR 2022, and the supplementary material can be found at the official site. The source codes are at this https URL\n",
    "authors": [
      "Jianfeng Wang",
      "Thomas Lukasiewicz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09293"
  },
  {
    "id": "arXiv:2206.09298",
    "title": "GMM based multi-stage Wiener filtering for low SNR speech enhancement",
    "abstract": "This paper proposes a single-channel speech enhancement method to reduce the\nnoise and enhance speech at low signal-to-noise ratio (SNR) levels and\nnon-stationary noise conditions. Specifically, we focus on modeling the noise\nusing a Gaussian mixture model (GMM) based on a multi-stage process with a\nparametric Wiener filter. The proposed noise model estimates a more accurate\nnoise power spectral density (PSD), and allows for better generalization under\nvarious noise conditions compared to traditional Wiener filtering methods.\nSimulations show that the proposed approach can achieve better performance in\nterms of speech quality (PESQ) and intelligibility (STOI) at low SNR levels.",
    "descriptor": "\nComments: 5 pages, 3 figures, submitted to a conference\n",
    "authors": [
      "Wageesha Manamperi",
      "Prasanga N. Samarasinghe",
      "Thushara D. Abhayapala",
      "Jihui Zhang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Robotics (cs.RO)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.09298"
  },
  {
    "id": "arXiv:2206.09299",
    "title": "Enforcing Continuous Physical Symmetries in Deep Learning Network for  Solving Partial Differential Equations",
    "abstract": "As a typical {application} of deep learning, physics-informed neural network\n(PINN) {has been} successfully used to find numerical solutions of partial\ndifferential equations (PDEs), but how to improve the limited accuracy is still\na great challenge for PINN. In this work, we introduce a new method,\nsymmetry-enhanced physics informed neural network (SPINN) where the invariant\nsurface conditions induced by the Lie symmetries of PDEs are embedded into the\nloss function of PINN, for improving the accuracy of PINN. We test the\neffectiveness of SPINN via two groups of ten independent numerical experiments\nfor the heat equation, Korteweg-de Vries (KdV) equation and potential Burgers\n{equations} respectively, which shows that SPINN performs better than PINN with\nfewer training points and simpler architecture of neural network. Furthermore,\nwe discuss the computational overhead of SPINN in terms of the relative\ncomputational cost to PINN and show that the training time of SPINN has no\nobvious increases, even less than PINN for some cases.",
    "descriptor": "",
    "authors": [
      "Zhi-Yong Zhang",
      "Hui Zhang",
      "Li-Sheng Zhang",
      "Lei-Lei Guo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09299"
  },
  {
    "id": "arXiv:2206.09302",
    "title": "Delay-aware Multiple Access Design for Intelligent Reflecting Surface  Aided Uplink Transmission",
    "abstract": "In this paper, we develop a novel multiple access (MA) protocol for an\nintelligent reflecting (IRS) aided uplink transmission network by incorporating\nthe IRS-aided time-division MA (I-TDMA) protocol and the IRS-aided\nnon-orthogonal MA protocol (I-NOMA) protocol as special cases. Two typical\ncommunication scenarios, namely the transmit power limited case and the\ntransmit energy limited case are considered, where the device's rearranged\norder, time and power allocation, as well as dynamic IRS beamforming patterns\nover time are jointly optimized to minimize the sum transmission delay. To shed\nlight on the superiority of the proposed IRS-aided hybrid MA (I-HMA) protocol\nover conventional protocols, the conditions under which I-HMA outperforms\nI-TDMA and I-NOMA are revealed by characterizing their corresponding optimal\nsolution. Then, a computationally efficient algorithm is proposed to obtain the\nhigh-quality solution to the corresponding optimization problems. Simulation\nresults validate our theoretical findings, demonstrate the superiority of the\nproposed design, and draw some useful insights. Specifically, it is found that\nthe proposed protocol can significantly reduce the sum delay by combining the\nadditional gain of dynamic IRS beamforming with the high spectral efficiency of\nNOMA, which thus reveals that integrating IRS into the proposed HMA protocol is\nan effective solution for delay-aware optimization. Furthermore, it reveals\nthat the proposed design reduces the time consumption not only from the\nsystem-centric view, but also from the device-centric view.",
    "descriptor": "\nComments: Submitted to TCOM\n",
    "authors": [
      "Piao Zeng",
      "Guangji Chen",
      "Qingqing Wu",
      "Deli Qiao"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.09302"
  },
  {
    "id": "arXiv:2206.09303",
    "title": "The Framework For The Discipline Of Software Engineering in Connection  to Information Technology Discipline",
    "abstract": "This paper represents preliminary work in identifying the foundation for the\ndiscipline of Software Engineering and discovering the links between the\ndomains of Software Engineering and Information Technology (IT). Our research\nutilized IEEE Transactions on Software Engineering (IEEE-TSE), ACM Transactions\non Software Engineering and Methodology (ACM-TOSEM), Automated Software\nEngineering (ASE), the International Conference on Software Engineering(ICSE),\nand other related journal publication in the software engineering domain to\naddress our research questions. We explored existing frameworks and described\nthe need for software engineering as an academic discipline. We went further to\nclarify the distinction difference between Software Engineering and Computer\nScience. Through this efforts we contribute to an understanding of how evidence\nfrom IT research can be used to improve Software Engineering as a discipline.",
    "descriptor": "",
    "authors": [
      "Jones Yeboah",
      "Izunna Okpala",
      "Sylvia Azumah",
      "Victor Adewopo",
      "Hazem Said"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.09303"
  },
  {
    "id": "arXiv:2206.09305",
    "title": "Adversarial Scrutiny of Evidentiary Statistical Software",
    "abstract": "The U.S. criminal legal system increasingly relies on software output to\nconvict and incarcerate people. In a large number of cases each year, the\ngovernment makes these consequential decisions based on evidence from\nstatistical software -- such as probabilistic genotyping, environmental audio\ndetection, and toolmark analysis tools -- that defense counsel cannot fully\ncross-examine or scrutinize. This undermines the commitments of the adversarial\ncriminal legal system, which relies on the defense's ability to probe and test\nthe prosecution's case to safeguard individual rights.\nResponding to this need to adversarially scrutinize output from such\nsoftware, we propose robust adversarial testing as an audit framework to\nexamine the validity of evidentiary statistical software. We define and\noperationalize this notion of robust adversarial testing for defense use by\ndrawing on a large body of recent work in robust machine learning and\nalgorithmic fairness. We demonstrate how this framework both standardizes the\nprocess for scrutinizing such tools and empowers defense lawyers to examine\ntheir validity for instances most relevant to the case at hand. We further\ndiscuss existing structural and institutional challenges within the U.S.\ncriminal legal system that may create barriers for implementing this and other\nsuch audit frameworks and close with a discussion on policy changes that could\nhelp address these concerns.",
    "descriptor": "",
    "authors": [
      "Rediet Abebe",
      "Moritz Hardt",
      "Angela Jin",
      "John Miller",
      "Ludwig Schmidt",
      "Rebecca Wexler"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09305"
  },
  {
    "id": "arXiv:2206.09310",
    "title": "Vehicle-to-Vehicle Charging Coordination over Information Centric  Networking",
    "abstract": "Cities around the world are increasingly promoting electric vehicles (EV) to\nreduce and ultimately eliminate greenhouse gas emissions. For example, the city\nof San Francisco aims to increase the number of EVs from tens of thousands to\nover quarter of a million by 2025. This huge number of EVs will put\nunprecedented stress on the power grid. To efficiently serve the increased\ncharging load, these EVs need to be charged in a coordinated fashion. One\npromising coordination strategy is vehicle-to-vehicle (V2V) charging\ncoordination, enabling EVs to sell their surplus energy in an ad-hoc, peer to\npeer manner.\nEnabling V2V charging coordination requires new communication network\nprotocols that can facilitate such charging coordination in a peer-to-peer\nfashion. This paper introduces an Information Centric Networking (ICN)-based\nprotocol to support ad-hoc V2V charging coordination (V2V-CC). Our evaluations\ndemonstrate that V2V-CC can provide added flexibility, fault tolerance, and\nreduced communication latency than a conventional centralized cloud based\napproach. We show that V2V-CC can achieve a 93\\% reduction in protocol\ncompletion time compared to a conventional approach. We also show that V2V-CC\nalso works well under extreme packet loss, making it ideal for V2V charging\ncoordination.",
    "descriptor": "",
    "authors": [
      "Robert Thompson",
      "Muhammad Ismail",
      "Susmit Shannigrahi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.09310"
  },
  {
    "id": "arXiv:2206.09311",
    "title": "Primal Estimated Subgradient Solver for SVM for Imbalanced  Classification",
    "abstract": "We aim to demonstrate in experiments that our cost sensitive PEGASOS SVM\nbalances achieve good performance on imbalanced data sets with a Majority to\nMinority Ratio ranging from 8.6 to one through 130 to one. We evaluate the\nperformance by examining the learning curves. We will also examine the effect\nof varying the hyperparameters via validation curves. We compare our PEGASOS\nCost-Sensitive SVM's results on three of the datasets Ding analyzed using his\nLINEAR SVM DECIDL method. We will use Python rather than MATLAB as python has\ndictionaries for storing mixed data types during multi-parameter\ncross-validation.",
    "descriptor": "\nComments: 10 pages, 4 tables, 3 figures\n",
    "authors": [
      "John Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2206.09311"
  },
  {
    "id": "arXiv:2206.09313",
    "title": "Laziness, Barren Plateau, and Noise in Machine Learning",
    "abstract": "We define \\emph{laziness} to describe a large suppression of variational\nparameter updates for neural networks, classical or quantum. In the quantum\ncase, the suppression is exponential in the number of qubits for randomized\nvariational quantum circuits. We discuss the difference between laziness and\n\\emph{barren plateau} in quantum machine learning created by quantum physicists\nin \\cite{mcclean2018barren} for the flatness of the loss function landscape\nduring gradient descent. We address a novel theoretical understanding of those\ntwo phenomena in light of the theory of neural tangent kernels. For noiseless\nquantum circuits, without the measurement noise, the loss function landscape is\ncomplicated in the overparametrized regime with a large number of trainable\nvariational angles. Instead, around a random starting point in optimization,\nthere are large numbers of local minima that are good enough and could minimize\nthe mean square loss function, where we still have quantum laziness, but we do\nnot have barren plateaus. However, the complicated landscape is not visible\nwithin a limited number of iterations, and low precision in quantum control and\nquantum sensing. Moreover, we look at the effect of noises during optimization\nby assuming intuitive noise models, and show that variational quantum\nalgorithms are noise-resilient in the overparametrization regime. Our work\nprecisely reformulates the quantum barren plateau statement towards a precision\nstatement and justifies the statement in certain noise models, injects new hope\ntoward near-term variational quantum algorithms, and provides theoretical\nconnections toward classical machine learning. Our paper provides conceptual\nperspectives about quantum barren plateaus, together with discussions about the\ngradient descent dynamics in \\cite{together}.",
    "descriptor": "\nComments: 18 pages, 3 figures\n",
    "authors": [
      "Junyu Liu",
      "Zexi Lin",
      "Liang Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Quantum Physics (quant-ph)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.09313"
  },
  {
    "id": "arXiv:2206.09314",
    "title": "Robust Imitation Learning against Variations in Environment Dynamics",
    "abstract": "In this paper, we propose a robust imitation learning (IL) framework that\nimproves the robustness of IL when environment dynamics are perturbed. The\nexisting IL framework trained in a single environment can catastrophically fail\nwith perturbations in environment dynamics because it does not capture the\nsituation that underlying environment dynamics can be changed. Our framework\neffectively deals with environments with varying dynamics by imitating multiple\nexperts in sampled environment dynamics to enhance the robustness in general\nvariations in environment dynamics. In order to robustly imitate the multiple\nsample experts, we minimize the risk with respect to the Jensen-Shannon\ndivergence between the agent's policy and each of the sample experts. Numerical\nresults show that our algorithm significantly improves robustness against\ndynamics perturbations compared to conventional IL baselines.",
    "descriptor": "\nComments: Accepted to ICML 2022\n",
    "authors": [
      "Jongseong Chae",
      "Seungyul Han",
      "Whiyoung Jung",
      "Myungsik Cho",
      "Sungho Choi",
      "Youngchul Sung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.09314"
  },
  {
    "id": "arXiv:2206.09315",
    "title": "Knowledge Learning with Crowdsourcing: A Brief Review and Systematic  Perspective",
    "abstract": "Big data have the characteristics of enormous volume, high velocity,\ndiversity, value-sparsity, and uncertainty, which lead the knowledge learning\nfrom them full of challenges. With the emergence of crowdsourcing, versatile\ninformation can be obtained on-demand so that the wisdom of crowds is easily\ninvolved to facilitate the knowledge learning process. During the past thirteen\nyears, researchers in the AI community made great efforts to remove the\nobstacles in the field of learning from crowds. This concentrated survey paper\ncomprehensively reviews the technical progress in crowdsourcing learning from a\nsystematic perspective that includes three dimensions of data, models, and\nlearning processes. In addition to reviewing existing important work, the paper\nplaces a particular emphasis on providing some promising blueprints on each\ndimension as well as discussing the lessons learned from our past research\nwork, which will light up the way for new researchers and encourage them to\npursue new contributions.",
    "descriptor": "",
    "authors": [
      "Jing Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.09315"
  },
  {
    "id": "arXiv:2206.09316",
    "title": "FRAPPE: $\\underline{\\text{F}}$ast $\\underline{\\text{Ra}}$nk  $\\underline{\\text{App}}$roximation with $\\underline{\\text{E}}$xplainable  Features for Tensors",
    "abstract": "Tensor decompositions have proven to be effective in analyzing the structure\nof multidimensional data. However, most of these methods require a key\nparameter: the number of desired components. In the case of the\nCANDECOMP/PARAFAC decomposition (CPD), this value is known as the canonical\nrank and greatly affects the quality of the results. Existing methods use\nheuristics or Bayesian methods to estimate this value by repeatedly calculating\nthe CPD, making them extremely computationally expensive. In this work, we\npropose FRAPPE and Self-FRAPPE: a cheaply supervised and a self-supervised\nmethod to estimate the canonical rank of a tensor without ever having to\ncompute the CPD. We call FRAPPE cheaply supervised because it uses a fully\nsynthetic training set without requiring real-world examples. We evaluate these\nmethods on synthetic tensors, real tensors of known rank, and the weight tensor\nof a convolutional neural network. We show that FRAPPE and Self-FRAPPE offer\nlarge improvements in both effectiveness and speed, with a respective $15\\%$\nand $10\\%$ improvement in MAPE and an $4000\\times$ and $13\\times$ improvement\nin evaluation speed over the best-performing baseline.",
    "descriptor": "",
    "authors": [
      "William Shiao",
      "Evangelos E. Papalexakis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.09316"
  },
  {
    "id": "arXiv:2206.09319",
    "title": "TrafficFlowGAN: Physics-informed Flow based Generative Adversarial  Network for Uncertainty Quantification",
    "abstract": "This paper proposes the TrafficFlowGAN, a physics-informed flow based\ngenerative adversarial network (GAN), for uncertainty quantification (UQ) of\ndynamical systems. TrafficFlowGAN adopts a normalizing flow model as the\ngenerator to explicitly estimate the data likelihood. This flow model is\ntrained to maximize the data likelihood and to generate synthetic data that can\nfool a convolutional discriminator. We further regularize this training process\nusing prior physics information, so-called physics-informed deep learning\n(PIDL). To the best of our knowledge, we are the first to propose an\nintegration of flow, GAN and PIDL for the UQ problems. We take the traffic\nstate estimation (TSE), which aims to estimate the traffic variables (e.g.\ntraffic density and velocity) using partially observed data, as an example to\ndemonstrate the performance of our proposed model. We conduct numerical\nexperiments where the proposed model is applied to learn the solutions of\nstochastic differential equations. The results demonstrate the robustness and\naccuracy of the proposed model, together with the ability to learn a machine\nlearning surrogate model. We also test it on a real-world dataset, the Next\nGeneration SIMulation (NGSIM), to show that the proposed TrafficFlowGAN can\noutperform the baselines, including the pure flow model, the physics-informed\nflow model, and the flow based GAN model.",
    "descriptor": "",
    "authors": [
      "Zhaobin Mo",
      "Yongjie Fu",
      "Daran Xu",
      "Xuan Di"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09319"
  },
  {
    "id": "arXiv:2206.09320",
    "title": "An unfiltered low-regularity integrator for the KdV equation with  solutions below ${\\bf H^1}$",
    "abstract": "This article is concerned with the construction and analysis of new time\ndiscretizations for the KdV equation on a torus for low-regularity solutions\nbelow $H^1$. New harmonic analysis tools, including new averaging\napproximations to the exponential phase functions, new frequency decomposition\ntechniques, and new trilinear estimates of the KdV operator, are established\nfor the construction and analysis of time discretizations with higher\nconvergence orders under low-regularity conditions. In addition, new techniques\nare introduced to establish stability estimates of time discretizations under\nlow-regularity conditions without using filters when the energy techniques\nfail. The proposed method is proved to be convergent with order $\\gamma$ (up to\na logarithmic factor) in $L^2$ under the regularity condition $u\\in\nC([0,T];H^\\gamma)$ for $\\gamma\\in(0,1]$.",
    "descriptor": "\nComments: 42 pages, 4 figures\n",
    "authors": [
      "Buyang Li",
      "Yifei Wu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2206.09320"
  },
  {
    "id": "arXiv:2206.09321",
    "title": "Mitigating Learning Complexity in Physics and Equality Constrained  Artificial Neural Networks",
    "abstract": "Physics-informed neural networks (PINNs) have been proposed to learn the\nsolution of partial differential equations (PDE). In PINNs, the residual form\nof the PDE of interest and its boundary conditions are lumped into a composite\nobjective function as soft penalties. Here, we show that this specific way of\nformulating the objective function is the source of severe limitations in the\nPINN approach when applied to different kinds of PDEs. To address these\nlimitations, we propose a versatile framework based on a constrained\noptimization problem formulation, where we use the augmented Lagrangian method\n(ALM) to constrain the solution of a PDE with its boundary conditions and any\nhigh-fidelity data that may be available. Our approach is adept at forward and\ninverse problems with multi-fidelity data fusion. We demonstrate the efficacy\nand versatility of our physics- and equality-constrained deep-learning\nframework by applying it to several forward and inverse problems involving\nmulti-dimensional PDEs.Our framework achieves orders of magnitude improvements\nin accuracy levels in comparison with state-of-the-art physics-informed neural\nnetworks.",
    "descriptor": "",
    "authors": [
      "Shamsulhaq Basir",
      "Inanc Senocak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2206.09321"
  },
  {
    "id": "arXiv:2206.09325",
    "title": "EATFormer: Improving Vision Transformer Inspired by Evolutionary  Algorithm",
    "abstract": "Motivated by biological evolution, this paper explains the rationality of\nVision Transformer by analogy with the proven practical Evolutionary Algorithm\n(EA) and derives that both have consistent mathematical formulation. Then\ninspired by effective EA variants, we propose a novel pyramid EATFormer\nbackbone that only contains the proposed \\emph{EA-based Transformer} (EAT)\nblock, which consists of three residual parts, \\ie, \\emph{Multi-Scale Region\nAggregation} (MSRA), \\emph{Global and Local Interaction} (GLI), and\n\\emph{Feed-Forward Network} (FFN) modules, to model multi-scale, interactive,\nand individual information separately. Moreover, we design a \\emph{Task-Related\nHead} (TRH) docked with transformer backbone to complete final information\nfusion more flexibly and \\emph{improve} a \\emph{Modulated Deformable MSA}\n(MD-MSA) to dynamically model irregular locations. Massive quantitative and\nquantitative experiments on image classification, downstream tasks, and\nexplanatory experiments demonstrate the effectiveness and superiority of our\napproach over State-Of-The-Art (SOTA) methods. \\Eg, our Mobile (1.8M), Tiny\n(6.1M), Small (24.3M), and Base (49.0M) models achieve 69.4, 78.4, 83.1, and\n83.9 Top-1 only trained on ImageNet-1K with naive training recipe;\nEATFormer-Tiny/Small/Base armed Mask-R-CNN obtain 45.4/47.4/49.0 box AP and\n41.4/42.9/44.2 mask AP on COCO detection, surpassing contemporary MPViT-T,\nSwin-T, and Swin-S by 0.6/1.4/0.5 box AP and 0.4/1.3/0.9 mask AP separately\nwith less FLOPs; Our EATFormer-Small/Base achieve 47.3/49.3 mIoU on ADE20K by\nUpernet that exceeds Swin-T/S by 2.8/1.7. Code will be available at\n\\url{https://https://github.com/zhangzjn/EATFormer}.",
    "descriptor": "",
    "authors": [
      "Jiangning Zhang",
      "Xiangtai Li",
      "Yabiao Wang",
      "Chengjie Wang",
      "Yibo Yang",
      "Yong Liu",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2206.09325"
  },
  {
    "id": "arXiv:2206.09328",
    "title": "A Survey on Model-based Reinforcement Learning",
    "abstract": "Reinforcement learning (RL) solves sequential decision-making problems via a\ntrial-and-error process interacting with the environment. While RL achieves\noutstanding success in playing complex video games that allow huge\ntrial-and-error, making errors is always undesired in the real world. To\nimprove the sample efficiency and thus reduce the errors, model-based\nreinforcement learning (MBRL) is believed to be a promising direction, which\nbuilds environment models in which the trial-and-errors can take place without\nreal costs. In this survey, we take a review of MBRL with a focus on the recent\nprogress in deep RL. For non-tabular environments, there is always a\ngeneralization error between the learned environment model and the real\nenvironment. As such, it is of great importance to analyze the discrepancy\nbetween policy training in the environment model and that in the real\nenvironment, which in turn guides the algorithm design for better model\nlearning, model usage, and policy training. Besides, we also discuss the recent\nadvances of model-based techniques in other forms of RL, including offline RL,\ngoal-conditioned RL, multi-agent RL, and meta-RL. Moreover, we discuss the\napplicability and advantages of MBRL in real-world tasks. Finally, we end this\nsurvey by discussing the promising prospects for the future development of\nMBRL. We think that MBRL has great potential and advantages in real-world\napplications that were overlooked, and we hope this survey could attract more\nresearch on MBRL.",
    "descriptor": "",
    "authors": [
      "Fan-Ming Luo",
      "Tian Xu",
      "Hang Lai",
      "Xiong-Hui Chen",
      "Weinan Zhang",
      "Yang Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09328"
  },
  {
    "id": "arXiv:2206.09330",
    "title": "Multi-period Optimal Control for Mobile Agents Considering State  Unpredictability",
    "abstract": "The optimal control for mobile agents is an important and challenging\nresearch issue. Recent work shows that using randomized mechanism in agents'\ncontrol can make the state unpredictable, and thus ensure the security of\nagents. However, the unpredictable design is only considered in single period,\nwhich can lead to intolerable control performance in long time horizon. This\npaper aims at the trade-off between the control performance and state\nunpredictability of mobile agents in long time horizon. Utilizing random\nperturbations consistent with uniform distributions to maximize the attackers'\nprediction errors of future states, we formulate the problem as a multi-period\nconvex stochastic optimization problem and solve it through dynamic\nprogramming. Specifically, we design the optimal control strategy considering\nboth unconstrained and input constrained systems. The analytical iterative\nexpressions of the control are further provided. Simulation illustrates that\nthe algorithm increases the prediction errors under Kalman filter while\nachieving the control performance requirements successfully.",
    "descriptor": "",
    "authors": [
      "Chendi Qu",
      "Jianping He",
      "Jialun Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.09330"
  },
  {
    "id": "arXiv:2206.09333",
    "title": "LogGENE: A smooth alternative to check loss for Deep Healthcare  Inference Tasks",
    "abstract": "High-throughput Genomics is ushering a new era in personalized health care,\nand targeted drug design and delivery. Mining these large datasets, and\nobtaining calibrated predictions is of immediate relevance and utility. In our\nwork, we develop methods for Gene Expression Inference based on Deep neural\nnetworks. However, unlike typical Deep learning methods, our inferential\ntechnique, while achieving state-of-the-art performance in terms of accuracy,\ncan also provide explanations, and report uncertainty estimates. We adopt the\nQuantile Regression framework to predict full conditional quantiles for a given\nset of house keeping gene expressions. Conditional quantiles, in addition to\nbeing useful in providing rich interpretations of the predictions, are also\nrobust to measurement noise. However, check loss, used in quantile regression\nto drive the estimation process is not differentiable. We propose log-cosh as a\nsmooth-alternative to the check loss. We apply our methods on GEO microarray\ndataset. We also extend the method to binary classification setting.\nFurthermore, we investigate other consequences of the smoothness of the loss in\nfaster convergence.",
    "descriptor": "",
    "authors": [
      "Aryaman Jeendgar",
      "Aditya Pola",
      "Soma S Dhavala",
      "Snehanshu Saha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.09333"
  },
  {
    "id": "arXiv:2206.09336",
    "title": "Efficient Checking of Timed Order Compliance Rules over Graph-encoded  Event Logs",
    "abstract": "Validation of compliance rules against process data is a fundamental\nfunctionality for business process management. Over the years, the problem has\nbeen addressed for different types of process data, i.e., process models,\nprocess event data at runtime, and event logs representing historical\nexecution. Several approaches have been proposed to tackle compliance checking\nover process logs. These approaches have been based on different data models\nand storage technologies including relational databases, graph databases, and\nproprietary formats. Graph-based encoding of event logs is a promising\ndirection that turns several process analytics tasks into queries on the\nunderlying graph. Compliance checking is one class of such analysis tasks. In\nthis paper, we argue that encoding log data as graphs alone is not enough to\nguarantee efficient processing of queries on this data. Efficiency is important\ndue to the interactive nature of compliance checking. Thus, compliance checking\nwould benefit from sub-linear scanning of the data. Moreover, as more data are\nadded, e.g., new batches of logs arrive, the data size should grow sub-linearly\nto optimize both the space of storage and time for querying. We propose two\nencoding methods using graph representation, realized in Neo4J, and show the\nbenefits of these encoding on a special class of queries, namely timed order\ncompliance rules. Compared to a baseline encoding, our experiments show up to\n5x speed up in the querying time as well as a 3x reduction in the graph size.",
    "descriptor": "\nComments: 18 pages, 5 figures, 6 tables\n",
    "authors": [
      "Nesma M. Zaki",
      "Iman M. A. Helal",
      "Ahmed Awad",
      "Ehab E. Hassanein"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2206.09336"
  },
  {
    "id": "arXiv:2206.09337",
    "title": "Learning Multiscale Transformer Models for Sequence Generation",
    "abstract": "Multiscale feature hierarchies have been witnessed the success in the\ncomputer vision area. This further motivates researchers to design multiscale\nTransformer for natural language processing, mostly based on the self-attention\nmechanism. For example, restricting the receptive field across heads or\nextracting local fine-grained features via convolutions. However, most of\nexisting works directly modeled local features but ignored the word-boundary\ninformation. This results in redundant and ambiguous attention distributions,\nwhich lacks of interpretability. In this work, we define those scales in\ndifferent linguistic units, including sub-words, words and phrases. We built a\nmultiscale Transformer model by establishing relationships among scales based\non word-boundary information and phrase-level prior knowledge. The proposed\n\\textbf{U}niversal \\textbf{M}ulti\\textbf{S}cale \\textbf{T}ransformer, namely\n\\textsc{Umst}, was evaluated on two sequence generation tasks. Notably, it\nyielded consistent performance gains over the strong baseline on several test\nsets without sacrificing the efficiency.",
    "descriptor": "\nComments: accepted by ICML2022\n",
    "authors": [
      "Bei Li",
      "Tong Zheng",
      "Yi Jing",
      "Chengbo Jiao",
      "Tong Xiao",
      "Jingbo Zhu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.09337"
  },
  {
    "id": "arXiv:2206.09338",
    "title": "Rank-$1$ matrix differential equations for structured eigenvalue  optimization",
    "abstract": "A new approach to solving eigenvalue optimization problems for large\nstructured matrices is proposed and studied. The class of optimization problems\nconsidered is related to computing structured pseudospectra and their extremal\npoints, and to structured matrix nearness problems such as computing the\nstructured distance to instability or to singularity. The structure can be a\ngeneral linear structure and includes, for example, large matrices with a given\nsparsity pattern, matrices with given range and co-range, and Hamiltonian\nmatrices. Remarkably, the eigenvalue optimization can be performed on the\nmanifold of complex (or real) rank-1 matrices, which yields a significant\nreduction of storage and in some cases of the computational cost. The method\nrelies on a constrained gradient system and the projection of the gradient onto\nthe tangent space of the manifold of complex rank-$1$ matrices. It is shown\nthat near a local minimizer this projection is very close to the identity map,\nand so the computationally favorable rank-1 projected system behaves locally\nlike the %computationally expensive gradient system.",
    "descriptor": "",
    "authors": [
      "Nicola Guglielmi",
      "Christian Lubich",
      "Stefano Sicilia"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Dynamical Systems (math.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.09338"
  },
  {
    "id": "arXiv:2206.09339",
    "title": "Channel Estimation for Delay Alignment Modulation",
    "abstract": "Delay alignment modulation (DAM) is a promising technology to eliminate\ninter-symbol interference (ISI) without relying on sophisticated equalization\nor multi-carrier transmissions. The key ideas of DAM are delay pre-compensation\nand path based beamforming, so that the multi-path signal components will\narrive at the receiver simultaneously and constructively, rather than causing\nthe detrimental ISI. However, the practical implementation of DAM requires\nchannel state information (CSI) at the transmitter side. Therefore, in this\nletter, we propose an efficient channel estimation method for DAM based on\nblock orthogonal matching pursuit (BOMP) algorithm, by exploiting the block\nsparsity of the channel impulse response (CIR) vector. Based on the imperfectly\nestimated CSI, the delay pre-compensations and path-based beamforming are\ndesigned for DAM, and the resulting performance is studied. Simulation results\ndemonstrate that with the proposed channel estimation method, the CSI can be\neffectively acquired with low training overhead, and the performance of DAM\nbased on estimated CSI is comparable to the ideal case with perfect CSI.",
    "descriptor": "",
    "authors": [
      "Dingyang Ding",
      "Yong Zeng"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.09339"
  },
  {
    "id": "arXiv:2206.09340",
    "title": "A Note on Comparator-Overdrive-Delay Conditioning for Current-Mode  Control",
    "abstract": "Comparator-overdrive-delay conditioning is a new control conditioning\napproach for high-frequency current-mode control. No existing literature\nrigorously studies the effect of the comparator overdrive delay on the\ncurrent-mode control. The results in this paper provide insights into the\nmechanism of comparator-overdrive-delay conditioning.",
    "descriptor": "",
    "authors": [
      "Xiaofan Cui",
      "Al-Thaddeus Avestruz"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.09340"
  },
  {
    "id": "arXiv:2206.09341",
    "title": "Bayesian Optimization under Stochastic Delayed Feedback",
    "abstract": "Bayesian optimization (BO) is a widely-used sequential method for\nzeroth-order optimization of complex and expensive-to-compute black-box\nfunctions. The existing BO methods assume that the function evaluation\n(feedback) is available to the learner immediately or after a fixed delay. Such\nassumptions may not be practical in many real-life problems like online\nrecommendations, clinical trials, and hyperparameter tuning where feedback is\navailable after a random delay. To benefit from the experimental\nparallelization in these problems, the learner needs to start new function\nevaluations without waiting for delayed feedback. In this paper, we consider\nthe BO under stochastic delayed feedback problem. We propose algorithms with\nsub-linear regret guarantees that efficiently address the dilemma of selecting\nnew function queries while waiting for randomly delayed feedback. Building on\nour results, we also make novel contributions to batch BO and contextual\nGaussian process bandits. Experiments on synthetic and real-life datasets\nverify the performance of our algorithms.",
    "descriptor": "\nComments: Accepted to ICML 2022\n",
    "authors": [
      "Arun Verma",
      "Zhongxiang Dai",
      "Bryan Kian Hsiang Low"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.09341"
  },
  {
    "id": "arXiv:2206.09343",
    "title": "Analysis of curvature approximations via covariant curl and  incompatibility for Regge metrics",
    "abstract": "The metric tensor of a Riemannian manifold can be approximated using Regge\nfinite elements and such approximations can be used to compute approximations\nto the Gauss curvature and the Levi-Civita connection of the manifold. It is\nshown that certain Regge approximations yield curvature and connection\napproximations that converge at a higher rate than previously known. The\nanalysis is based on covariant (distributional) curl and incompatibility\noperators which can be applied to piecewise smooth matrix fields whose\ntangential-tangential component is continuous across element interfaces. Using\nthe properties of the canonical interpolant of the Regge space, we obtain\nsuperconvergence of approximations of these covariant operators. Numerical\nexperiments further illustrate the results from the error analysis.",
    "descriptor": "",
    "authors": [
      "Jay Gopalakrishnan",
      "Michael Neunteufel",
      "Joachim Sch\u00f6berl",
      "Max Wardetzky"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.09343"
  },
  {
    "id": "arXiv:2206.09345",
    "title": "Finding Diverse and Predictable Subgraphs for Graph Domain  Generalization",
    "abstract": "This paper focuses on out-of-distribution generalization on graphs where\nperformance drops due to the unseen distribution shift. Previous graph domain\ngeneralization works always resort to learning an invariant predictor among\ndifferent source domains. However, they assume sufficient source domains are\navailable during training, posing huge challenges for realistic applications.\nBy contrast, we propose a new graph domain generalization framework, dubbed as\nDPS, by constructing multiple populations from the source domains.\nSpecifically, DPS aims to discover multiple \\textbf{D}iverse and\n\\textbf{P}redictable \\textbf{S}ubgraphs with a set of generators, namely,\nsubgraphs are different from each other but all the them share the same\nsemantics with the input graph. These generated source domains are exploited to\nlearn an \\textit{equi-predictive} graph neural network (GNN) across domains,\nwhich is expected to generalize well to unseen target domains. Generally, DPS\nis model-agnostic that can be incorporated with various GNN backbones.\nExtensive experiments on both node-level and graph-level benchmarks shows that\nthe proposed DPS achieves impressive performance for various graph domain\ngeneralization tasks.",
    "descriptor": "",
    "authors": [
      "Junchi Yu",
      "Jian Liang",
      "Ran He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.09345"
  },
  {
    "id": "arXiv:2206.09346",
    "title": "Fairness-aware Model-agnostic Positive and Unlabeled Learning",
    "abstract": "With the increasing application of machine learning in high-stake\ndecision-making problems, potential algorithmic bias towards people from\ncertain social groups poses negative impacts on individuals and our society at\nlarge. In the real-world scenario, many such problems involve positive and\nunlabeled data such as medical diagnosis, criminal risk assessment and\nrecommender systems. For instance, in medical diagnosis, only the diagnosed\ndiseases will be recorded (positive) while others will not (unlabeled). Despite\nthe large amount of existing work on fairness-aware machine learning in the\n(semi-)supervised and unsupervised settings, the fairness issue is largely\nunder-explored in the aforementioned Positive and Unlabeled Learning (PUL)\ncontext, where it is usually more severe. In this paper, to alleviate this\ntension, we propose a fairness-aware PUL method named FairPUL. In particular,\nfor binary classification over individuals from two populations, we aim to\nachieve similar true positive rates and false positive rates in both\npopulations as our fairness metric. Based on the analysis of the optimal fair\nclassifier for PUL, we design a model-agnostic post-processing framework,\nleveraging both the positive examples and unlabeled ones. Our framework is\nproven to be statistically consistent in terms of both the classification error\nand the fairness metric. Experiments on the synthetic and real-world data sets\ndemonstrate that our framework outperforms state-of-the-art in both PUL and\nfair classification.",
    "descriptor": "",
    "authors": [
      "Ziwei Wu",
      "Jingrui He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.09346"
  },
  {
    "id": "arXiv:2206.09348",
    "title": "Nested bandits",
    "abstract": "In many online decision processes, the optimizing agent is called to choose\nbetween large numbers of alternatives with many inherent similarities; in turn,\nthese similarities imply closely correlated losses that may confound standard\ndiscrete choice models and bandit algorithms. We study this question in the\ncontext of nested bandits, a class of adversarial multi-armed bandit problems\nwhere the learner seeks to minimize their regret in the presence of a large\nnumber of distinct alternatives with a hierarchy of embedded\n(non-combinatorial) similarities. In this setting, optimal algorithms based on\nthe exponential weights blueprint (like Hedge, EXP3, and their variants) may\nincur significant regret because they tend to spend excessive amounts of time\nexploring irrelevant alternatives with similar, suboptimal costs. To account\nfor this, we propose a nested exponential weights (NEW) algorithm that performs\na layered exploration of the learner's set of alternatives based on a nested,\nstep-by-step selection method. In so doing, we obtain a series of tight bounds\nfor the learner's regret showing that online learning problems with a high\ndegree of similarity between alternatives can be resolved efficiently, without\na red bus / blue bus paradox occurring.",
    "descriptor": "\nComments: 35 pages, 14 figures; to appear in ICML 2022\n",
    "authors": [
      "Matthieu Martin",
      "Panayotis Mertikopoulos",
      "Thibaud Rahier",
      "Houssam Zenati"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.09348"
  },
  {
    "id": "arXiv:2206.09349",
    "title": "Quantifying Uncertainty In Traffic State Estimation Using Generative  Adversarial Networks",
    "abstract": "This paper aims to quantify uncertainty in traffic state estimation (TSE)\nusing the generative adversarial network based physics-informed deep learning\n(PIDL). The uncertainty of the focus arises from fundamental diagrams, in other\nwords, the mapping from traffic density to velocity. To quantify uncertainty\nfor the TSE problem is to characterize the robustness of predicted traffic\nstates. Since its inception, generative adversarial networks (GAN) have become\na popular probabilistic machine learning framework. In this paper, we will\ninform the GAN based predictions using stochastic traffic flow models and\ndevelop a GAN based PIDL framework for TSE, named ``PhysGAN-TSE\". By conducting\nexperiments on a real-world dataset, the Next Generation SIMulation (NGSIM)\ndataset, this method is shown to be more robust for uncertainty quantification\nthan the pure GAN model or pure traffic flow models. Two physics models, the\nLighthill-Whitham-Richards (LWR) and the Aw-Rascle-Zhang (ARZ) models, are\ncompared as the physics components for the PhysGAN, and results show that the\nARZ-based PhysGAN achieves a better performance than the LWR-based one.",
    "descriptor": "",
    "authors": [
      "Zhaobin Mo",
      "Yongjie Fu",
      "Xuan Di"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09349"
  },
  {
    "id": "arXiv:2206.09353",
    "title": "Learning Grasp Ability Enhancement through Deep Shape Generation",
    "abstract": "Data-driven especially deep learning-based approaches have become a dominant\nparadigm for robotic grasp planning during the past decade. However, the\nperformance of these methods is greatly influenced by the quality of the\ntraining dataset available. In this paper, we propose a framework to generate\nobject shapes to augment the grasping dataset and thus can improve the grasp\nability of a pre-designed deep neural network. First, the object shapes are\nembedded into a low dimensional feature space using an encoder-decoder\nstructure network. Then, the rarity and graspness scores are computed for each\nobject shape using outlier detection and grasp quality criteria. Finally, new\nobjects are generated in feature space leveraging the original high rarity and\ngraspness score objects' feature. Experimental results show that the grasp\nability of a deep-learning-based grasp planning network can be effectively\nimproved with the generated object shapes.",
    "descriptor": "",
    "authors": [
      "Junnan Jiang",
      "Xiaohui Xiao",
      "Fei Chen",
      "Miao Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.09353"
  },
  {
    "id": "arXiv:2206.09355",
    "title": "A Unified Understanding of Deep NLP Models for Text Classification",
    "abstract": "The rapid development of deep natural language processing (NLP) models for\ntext classification has led to an urgent need for a unified understanding of\nthese models proposed individually. Existing methods cannot meet the need for\nunderstanding different models in one framework due to the lack of a unified\nmeasure for explaining both low-level (e.g., words) and high-level (e.g.,\nphrases) features. We have developed a visual analysis tool, DeepNLPVis, to\nenable a unified understanding of NLP models for text classification. The key\nidea is a mutual information-based measure, which provides quantitative\nexplanations on how each layer of a model maintains the information of input\nwords in a sample. We model the intra- and inter-word information at each layer\nmeasuring the importance of a word to the final prediction as well as the\nrelationships between words, such as the formation of phrases. A multi-level\nvisualization, which consists of a corpus-level, a sample-level, and a\nword-level visualization, supports the analysis from the overall training set\nto individual samples. Two case studies on classification tasks and comparison\nbetween models demonstrate that DeepNLPVis can help users effectively identify\npotential problems caused by samples and model architectures and then make\ninformed improvements.",
    "descriptor": "\nComments: 14 pages, 10 figures\n",
    "authors": [
      "Zhen Li",
      "Xiting Wang",
      "Weikai Yang",
      "Jing Wu",
      "Zhengyan Zhang",
      "Zhiyuan Liu",
      "Maosong Sun",
      "Hui Zhang",
      "Shixia Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09355"
  },
  {
    "id": "arXiv:2206.09357",
    "title": "Automatic Map Generation for Autonomous Driving System Testing",
    "abstract": "High-definition (HD) maps are essential in testing autonomous driving systems\n(ADSs). HD maps essentially determine the potential diversity of the testing\nscenarios. However, the current HD maps suffer from two main limitations: lack\nof junction diversity in the publicly available HD maps and cost-consuming to\nbuild a new HD map. Hence, in this paper, we propose, FEAT2MAP, to\nautomatically generate concise HD maps with scenario diversity guarantees.\nFEAT2MAP focuses on junctions as they significantly influence scenario\ndiversity, especially in urban road networks. FEAT2MAP first defines a set of\nfeatures to characterize junctions. Then, FEAT2MAP extracts and samples\nconcrete junction features from a list of input HD maps or user-defined\nrequirements. Each junction feature generates a junction. Finally, FEAT2MAP\nbuilds a map by connecting the junctions in a grid layout. To demonstrate the\neffectiveness of FEAT2MAP, we conduct experiments with the public HD maps from\nSVL and the open-source ADS Apollo. The results show that FEAT2MAP can (1)\ngenerate new maps of reduced size while maintaining scenario diversity in terms\nof the code coverage and motion states of the ADS under test, and (2) generate\nnew maps of increased scenario diversity by merging intersection features from\nmultiple maps or taking user inputs.",
    "descriptor": "\nComments: 7 pages, 7 figures\n",
    "authors": [
      "Yun Tang",
      "Yuan Zhou",
      "Kairui Yang",
      "Ziyuan Zhong",
      "Baishakhi Ray",
      "Yang Liu",
      "Ping Zhang",
      "Junbo Chen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.09357"
  },
  {
    "id": "arXiv:2206.09358",
    "title": "What is Where by Looking: Weakly-Supervised Open-World Phrase-Grounding  without Text Inputs",
    "abstract": "Given an input image, and nothing else, our method returns the bounding boxes\nof objects in the image and phrases that describe the objects. This is achieved\nwithin an open world paradigm, in which the objects in the input image may not\nhave been encountered during the training of the localization mechanism.\nMoreover, training takes place in a weakly supervised setting, where no\nbounding boxes are provided. To achieve this, our method combines two\npre-trained networks: the CLIP image-to-text matching score and the BLIP image\ncaptioning tool. Training takes place on COCO images and their captions and is\nbased on CLIP. Then, during inference, BLIP is used to generate a hypothesis\nregarding various regions of the current image. Our work generalizes weakly\nsupervised segmentation and phrase grounding and is shown empirically to\noutperform the state of the art in both domains. It also shows very convincing\nresults in the novel task of weakly-supervised open-world purely visual\nphrase-grounding presented in our work. For example, on the datasets used for\nbenchmarking phrase-grounding, our method results in a very modest degradation\nin comparison to methods that employ human captions as an additional input. Our\ncode is available at https://github.com/talshaharabany/what-is-where-by-looking\nand a live demo can be found at\nhttps://talshaharabany/what-is-where-by-looking.",
    "descriptor": "",
    "authors": [
      "Tal Shaharabany",
      "Yoad Tewel",
      "Lior Wolf"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09358"
  },
  {
    "id": "arXiv:2206.09359",
    "title": "Productive Reproducible Workflows for DNNs: A Case Study for Industrial  Defect Detection",
    "abstract": "As Deep Neural Networks (DNNs) have become an increasingly ubiquitous\nworkload, the range of libraries and tooling available to aid in their\ndevelopment and deployment has grown significantly. Scalable, production\nquality tools are freely available under permissive licenses, and are\naccessible enough to enable even small teams to be very productive. However\nwithin the research community, awareness and usage of said tools is not\nnecessarily widespread, and researchers may be missing out on potential\nproductivity gains from exploiting the latest tools and workflows. This paper\npresents a case study where we discuss our recent experience producing an\nend-to-end artificial intelligence application for industrial defect detection.\nWe detail the high level deep learning libraries, containerized workflows,\ncontinuous integration/deployment pipelines, and open source code templates we\nleveraged to produce a competitive result, matching the performance of other\nranked solutions to our three target datasets. We highlight the value that\nexploiting such systems can bring, even for research, and detail our solution\nand present our best results in terms of accuracy and inference time on a\nserver class GPU, as well as inference times on a server class CPU, and a\nRaspberry Pi 4.",
    "descriptor": "\nComments: 7 pages, 5 figures, AccML 2022\n",
    "authors": [
      "Perry Gibson",
      "Jos\u00e9 Cano"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Performance (cs.PF)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.09359"
  },
  {
    "id": "arXiv:2206.09360",
    "title": "Modeling Transformative AI Risks (MTAIR) Project -- Summary Report",
    "abstract": "This report outlines work by the Modeling Transformative AI Risk (MTAIR)\nproject, an attempt to map out the key hypotheses, uncertainties, and\ndisagreements in debates about catastrophic risks from advanced AI, and the\nrelationships between them. This builds on an earlier diagram by Ben Cottier\nand Rohin Shah which laid out some of the crucial disagreements (\"cruxes\")\nvisually, with some explanation. Based on an extensive literature review and\nengagement with experts, the report explains a model of the issues involved,\nand the initial software-based implementation that can incorporate probability\nestimates or other quantitative factors to enable exploration, planning, and/or\ndecision support. By gathering information from various debates and discussions\ninto a single more coherent presentation, we hope to enable better discussions\nand debates about the issues involved.\nThe model starts with a discussion of reasoning via analogies and general\nprior beliefs about artificial intelligence. Following this, it lays out a\nmodel of different paths and enabling technologies for high-level machine\nintelligence, and a model of how advances in the capabilities of these systems\nmight proceed, including debates about self-improvement, discontinuous\nimprovements, and the possibility of distributed, non-agentic high-level\nintelligence or slower improvements. The model also looks specifically at the\nquestion of learned optimization, and whether machine learning systems will\ncreate mesa-optimizers. The impact of different safety research on the previous\nsets of questions is then examined, to understand whether and how research\ncould be useful in enabling safer systems. Finally, we discuss a model of\ndifferent failure modes and loss of control or takeover scenarios.",
    "descriptor": "\nComments: Chapters were written by authors independently. All authors are listed alphabetically\n",
    "authors": [
      "Sam Clarke",
      "Ben Cottier",
      "Aryeh Englander",
      "Daniel Eth",
      "David Manheim",
      "Samuel Dylan Martin",
      "Issa Rice"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.09360"
  },
  {
    "id": "arXiv:2206.09362",
    "title": "Towards Generalizable Person Re-identification with a Bi-stream  Generative Model",
    "abstract": "Generalizable person re-identification (re-ID) has attracted growing\nattention due to its powerful adaptation capability in the unseen data domain.\nHowever, existing solutions often neglect either crossing cameras (e.g.,\nillumination and resolution differences) or pedestrian misalignments (e.g.,\nviewpoint and pose discrepancies), which easily leads to poor generalization\ncapability when adapted to the new domain. In this paper, we formulate these\ndifficulties as: 1) Camera-Camera (CC) problem, which denotes the various human\nappearance changes caused by different cameras; 2) Camera-Person (CP) problem,\nwhich indicates the pedestrian misalignments caused by the same identity person\nunder different camera viewpoints or changing pose. To solve the above issues,\nwe propose a Bi-stream Generative Model (BGM) to learn the fine-grained\nrepresentations fused with camera-invariant global feature and\npedestrian-aligned local feature, which contains an encoding network and two\nstream decoding sub-networks. Guided by original pedestrian images, one stream\nis employed to learn a camera-invariant global feature for the CC problem via\nfiltering cross-camera interference factors. For the CP problem, another stream\nlearns a pedestrian-aligned local feature for pedestrian alignment using\ninformation-complete densely semantically aligned part maps. Moreover, a\npart-weighted loss function is presented to reduce the influence of missing\nparts on pedestrian alignment. Extensive experiments demonstrate that our\nmethod outperforms the state-of-the-art methods on the large-scale\ngeneralizable re-ID benchmarks, involving domain generalization setting and\ncross-domain setting.",
    "descriptor": "",
    "authors": [
      "Xin Xu",
      "Wei Liu",
      "Zheng Wang",
      "Ruiming Hu",
      "Qi Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09362"
  },
  {
    "id": "arXiv:2206.09363",
    "title": "Towards Unified Conversational Recommender Systems via  Knowledge-Enhanced Prompt Learning",
    "abstract": "Conversational recommender systems (CRS) aim to proactively elicit user\npreference and recommend high-quality items through natural language\nconversations. Typically, a CRS consists of a recommendation module to predict\npreferred items for users and a conversation module to generate appropriate\nresponses. To develop an effective CRS, it is essential to seamlessly integrate\nthe two modules. Existing works either design semantic alignment strategies, or\nshare knowledge resources and representations between the two modules. However,\nthese approaches still rely on different architectures or techniques to develop\nthe two modules, making it difficult for effective module integration.\nTo address this problem, we propose a unified CRS model named UniCRS based on\nknowledge-enhanced prompt learning. Our approach unifies the recommendation and\nconversation subtasks into the prompt learning paradigm, and utilizes\nknowledge-enhanced prompts based on a fixed pre-trained language model (PLM) to\nfulfill both subtasks in a unified approach. In the prompt design, we include\nfused knowledge representations, task-specific soft tokens, and the dialogue\ncontext, which can provide sufficient contextual information to adapt the PLM\nfor the CRS task. Besides, for the recommendation subtask, we also incorporate\nthe generated response template as an important part of the prompt, to enhance\nthe information interaction between the two subtasks. Extensive experiments on\ntwo public CRS datasets have demonstrated the effectiveness of our approach.",
    "descriptor": "\nComments: Accepted by KDD 2022. Code: this https URL\n",
    "authors": [
      "Xiaolei Wang",
      "Kun Zhou",
      "Ji-Rong Wen",
      "Wayne Xin Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.09363"
  },
  {
    "id": "arXiv:2206.09365",
    "title": "Semi-supervised Change Detection of Small Water Bodies Using RGB and  Multispectral Images in Peruvian Rainforests",
    "abstract": "Artisanal and Small-scale Gold Mining (ASGM) is an important source of income\nfor many households, but it can have large social and environmental effects,\nespecially in rainforests of developing countries. The Sentinel-2 satellites\ncollect multispectral images that can be used for the purpose of detecting\nchanges in water extent and quality which indicates the locations of mining\nsites. This work focuses on the recognition of ASGM activities in Peruvian\nAmazon rainforests. We tested several semi-supervised classifiers based on\nSupport Vector Machines (SVMs) to detect the changes of water bodies from 2019\nto 2021 in the Madre de Dios region, which is one of the global hotspots of\nASGM activities. Experiments show that SVM-based models can achieve reasonable\nperformance for both RGB (using Cohen's $\\kappa$ 0.49) and 6-channel images\n(using Cohen's $\\kappa$ 0.71) with very limited annotations. The efficacy of\nincorporating Lab color space for change detection is analyzed as well.",
    "descriptor": "\nComments: 8 pages, 5 figures. Accepted to Proceedings of IEEE WHISPERS 2022\n",
    "authors": [
      "Kangning Cui",
      "Seda Camalan",
      "Ruoning Li",
      "Victor P. Pauca",
      "Sarra Alqahtani",
      "Robert J. Plemmons",
      "Miles Silman",
      "Evan N. Dethier",
      "David Lutz",
      "Raymond H. Chan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2206.09365"
  },
  {
    "id": "arXiv:2206.09372",
    "title": "mvHOTA: A multi-view higher order tracking accuracy metric to measure  spatial and temporal associations in multi-point detection",
    "abstract": "Multi-object tracking (MOT) is a challenging task that involves detecting\nobjects in the scene and tracking them across a sequence of frames. Evaluating\nthis task is difficult due to temporal occlusions, and varying trajectories\nacross a sequence of images. The main evaluation metric to benchmark MOT\nmethods on datasets such as KITTI has recently become the higher order tracking\naccuracy (HOTA) metric, which is capable of providing a better description of\nthe performance over metrics such as MOTA, DetA, and IDF1. Point detection and\ntracking is a closely related task, which could be regarded as a special case\nof object detection. However, there are differences in evaluating the detection\ntask itself (point distances vs. bounding box overlap). When including the\ntemporal dimension and multi-view scenarios, the evaluation task becomes even\nmore complex. In this work, we propose a multi-view higher order tracking\nmetric (mvHOTA) to determine the accuracy of multi-point (multi-instance and\nmulti-class) detection, while taking into account temporal and spatial\nassociations. mvHOTA can be interpreted as the geometric mean of the detection,\nassociation, and correspondence accuracies, thereby providing equal weighting\nto each of the factors. We demonstrate a use-case through a publicly available\nendoscopic point detection dataset from a previously organised medical\nchallenge. Furthermore, we compare with other adjusted MOT metrics for this\nuse-case, discuss the properties of mvHOTA, and show how the proposed\ncorrespondence accuracy and the Occlusion index facilitate analysis of methods\nwith respect to handling of occlusions. The code will be made publicly\navailable.",
    "descriptor": "\nComments: 12 pages, 6 figures\n",
    "authors": [
      "Lalith Sharan",
      "Halvar Kelm",
      "Gabriele Romano",
      "Matthias Karck",
      "Raffaele De Simone",
      "Sandy Engelhardt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.09372"
  },
  {
    "id": "arXiv:2206.09374",
    "title": "A robust and conservative dynamical low-rank algorithm",
    "abstract": "Dynamical low-rank approximation, as has been demonstrated recently, can be\nextremely efficient in solving kinetic equations. However, a major deficiency\nis that they do not preserve the structure of the underlying physical problem.\nFor example, the classic dynamical low-rank methods violate mass, momentum, and\nenergy conservation. In [L. Einkemmer, I. Joseph, J. Comput. Phys. 443:110495,\n2021] a conservative dynamical low-rank approach has been proposed. However,\ndirectly integrating the resulting equations of motion, similar to the classic\ndynamical low-rank approach, results in an ill-posed scheme. In this work we\npropose a robust, i.e.~well-posed, integrator for the conservative dynamical\nlow-rank approach that conserves mass and momentum (up to machine precision)\nand significantly improves energy conservation. We also report improved\nqualitative results for some problems and show how the approach can be combined\nwith a rank adaptive scheme.",
    "descriptor": "",
    "authors": [
      "Lukas Einkemmer",
      "Alexander Ostermann",
      "Carmen Scalone"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.09374"
  },
  {
    "id": "arXiv:2206.09375",
    "title": "Gray Learning from Non-IID Data with Out-of-distribution Samples",
    "abstract": "The quality of the training data annotated by experts cannot be guaranteed,\neven more so for non-IID data consisting of both in- and out-of-distribution\nsamples (i.e., in-distribution and out-of-distribution samples hold different\ndistributions). Experts may mistakenly annotate out-of-distribution samples the\nsame as in-distribution samples, incurring untrustworthy ground-truth labels.\nLearning such non-IID data mixing in- and out-of-distribution samples with\nuntrustworthy labels significantly challenges both shallow and deep learning,\nwith no relevant work reported. It would be possible to identify trustworthy\ncomplementary labels of a sample indicating which classes it does not belong\nto, because both in- and out-of-distribution samples do not belong to the\nclasses except those corresponding to the ground-truth label. With this\ninsight, we propose a novel \\textit{gray learning} approach to robustly learn\nfrom non-IID data with both in- and out-of-distribution samples. Due to the\nuncertain distributions of training samples, we reject the complementary labels\nfor low-confidence inputs while mapping high-confidence inputs to the\nground-truth labels in training. Building on the statistical learning theory,\nwe derive the generalization error which shows that gray learning achieves a\ntight bound on the non-IID data. Extensive experiments show that our method\nprovides significant improvement over alternative methods from robust\nstatistics.",
    "descriptor": "",
    "authors": [
      "Zhilin Zhao",
      "Longbing Cao",
      "Chang-Dong Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09375"
  },
  {
    "id": "arXiv:2206.09378",
    "title": "A Self-Guided Framework for Radiology Report Generation",
    "abstract": "Automatic radiology report generation is essential to computer-aided\ndiagnosis. Through the success of image captioning, medical report generation\nhas been achievable. However, the lack of annotated disease labels is still the\nbottleneck of this area. In addition, the image-text data bias problem and\ncomplex sentences make it more difficult to generate accurate reports. To\naddress these gaps, we pre-sent a self-guided framework (SGF), a suite of\nunsupervised and supervised deep learning methods to mimic the process of human\nlearning and writing. In detail, our framework obtains the domain knowledge\nfrom medical reports with-out extra disease labels and guides itself to extract\nfined-grain visual features as-sociated with the text. Moreover, SGF\nsuccessfully improves the accuracy and length of medical report generation by\nincorporating a similarity comparison mechanism that imitates the process of\nhuman self-improvement through compar-ative practice. Extensive experiments\ndemonstrate the utility of our SGF in the majority of cases, showing its\nsuperior performance over state-of-the-art meth-ods. Our results highlight the\ncapacity of the proposed framework to distinguish fined-grained visual details\nbetween words and verify its advantage in generating medical reports.",
    "descriptor": "\nComments: 11 pages, 3 figures, accepted by Medical Image Computing and Computer Assisted Intervention 2022(MICCAI 2022)\n",
    "authors": [
      "Jun Li",
      "Shibo Li",
      "Ying Hu",
      "Huiren Tao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09378"
  },
  {
    "id": "arXiv:2206.09379",
    "title": "0/1 Deep Neural Networks via Block Coordinate Descent",
    "abstract": "The step function is one of the simplest and most natural activation\nfunctions for deep neural networks (DNNs). As it counts 1 for positive\nvariables and 0 for others, its intrinsic characteristics (e.g., discontinuity\nand no viable information of subgradients) impede its development for several\ndecades. Even if there is an impressive body of work on designing DNNs with\ncontinuous activation functions that can be deemed as surrogates of the step\nfunction, it is still in the possession of some advantageous properties, such\nas complete robustness to outliers and being capable of attaining the best\nlearning-theoretic guarantee of predictive accuracy. Hence, in this paper, we\naim to train DNNs with the step function used as an activation function (dubbed\nas 0/1 DNNs). We first reformulate 0/1 DNNs as an unconstrained optimization\nproblem and then solve it by a block coordinate descend (BCD) method. Moreover,\nwe acquire closed-form solutions for sub-problems of BCD as well as its\nconvergence properties. Furthermore, we also integrate\n$\\ell_{2,0}$-regularization into 0/1 DNN to accelerate the training process and\ncompress the network scale. As a result, the proposed algorithm has a high\nperformance on classifying MNIST and Fashion-MNIST datasets.",
    "descriptor": "",
    "authors": [
      "Hui Zhang",
      "Shenglong Zhou",
      "Geoffrey Ye Li",
      "Naihua Xiu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09379"
  },
  {
    "id": "arXiv:2206.09380",
    "title": "Supervision Adaptation Balances In-Distribution Generalization and  Out-of-Distribution Detection",
    "abstract": "When there is a discrepancy between in-distribution (ID) samples and\nout-of-distribution (OOD) samples, deep neural networks trained on ID samples\nsuffer from high-confidence prediction on OOD samples. This is primarily caused\nby unavailable OOD samples to constrain the networks in the training process.\nTo improve the OOD sensitivity of deep networks, several state-of-the-art\nmethods introduce samples from other real-world datasets as OOD samples to the\ntraining process and assign manually-determined labels to these OOD samples.\nHowever, they sacrifice the classification accuracy because the unreliable\nlabeling of OOD samples would disrupt ID classification. To balance ID\ngeneralization and OOD detection, a major challenge to tackle is to make OOD\nsamples compatible with ID ones, which is addressed by our proposed\n\\textit{supervision adaptation} method in this paper to define adaptive\nsupervision information for OOD samples. First, by measuring the dependency\nbetween ID samples and their labels through mutual information, we reveal the\nform of the supervision information in terms of the negative probabilities of\nall classes. Second, after exploring the data correlations between ID and OOD\nsamples by solving multiple binary regression problems, we estimate the\nsupervision information to make ID classes more separable. We perform\nexperiments on four advanced network architectures with two ID datasets and\neleven OOD datasets to demonstrate the balancing effect of our supervision\nadaptation method in achieving both the ID classification ability and the OOD\ndetection capacity.",
    "descriptor": "",
    "authors": [
      "Zhilin Zhao",
      "Longbing Cao",
      "Kun-Yu Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09380"
  },
  {
    "id": "arXiv:2206.09382",
    "title": "Coverage Analysis of LEO Satellite Downlink Networks: Orbit Geometry  Dependent Approach",
    "abstract": "The low-earth-orbit (LEO) satellite network with mega-constellations can\nprovide global coverage while supporting the high-data rates. The coverage\nperformance of such a network is highly dependent on orbit geometry parameters,\nincluding satellite altitude and inclination angle. Traditionally,\nsimulation-based coverage analysis dominates because of the lack of analytical\napproaches. This paper presents a novel systematic analysis framework for the\nLEO satellite network by highlighting orbit geometric parameters. Specifically,\nwe assume that satellite locations are placed on a circular orbit according to\na one-dimensional Poisson point process. Then, we derive the distribution of\nthe nearest distance between the satellite and a fixed user's location on the\nEarth in terms of the orbit-geometry parameters. Leveraging this distribution,\nwe characterize the coverage probability of the single-orbit LEO network as a\nfunction of the network geometric parameters in conjunction with small and\nlarge-scale fading effects. Finally, we extend our coverage analysis to\nmulti-orbit networks and verify the synergistic gain of harnessing multi-orbit\nsatellite networks in terms of the coverage probability. Simulation results are\nprovided to validate the mathematical derivations and the accuracy of the\nproposed model.",
    "descriptor": "\nComments: 30 pages, 12 figures, Submitted to IEEE Transactions on Wireless Communications\n",
    "authors": [
      "Junse Lee",
      "Song Noh",
      "Sooyeob Jeong",
      "Namyoon Lee"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.09382"
  },
  {
    "id": "arXiv:2206.09384",
    "title": "Faster Sampling from Log-Concave Distributions over Polytopes via a  Soft-Threshold Dikin Walk",
    "abstract": "We consider the problem of sampling from a $d$-dimensional log-concave\ndistribution $\\pi(\\theta) \\propto e^{-f(\\theta)}$ constrained to a polytope $K$\ndefined by $m$ inequalities. Our main result is a \"soft-threshold'' variant of\nthe Dikin walk Markov chain that requires at most $O((md + d L^2 R^2) \\times\nmd^{\\omega-1}) \\log(\\frac{w}{\\delta}))$ arithmetic operations to sample from\n$\\pi$ within error $\\delta>0$ in the total variation distance from a $w$-warm\nstart, where $L$ is the Lipschitz-constant of $f$, $K$ is contained in a ball\nof radius $R$ and contains a ball of smaller radius $r$, and $\\omega$ is the\nmatrix-multiplication constant. When a warm start is not available, it implies\nan improvement of $\\tilde{O}(d^{3.5-\\omega})$ arithmetic operations on the\nprevious best bound for sampling from $\\pi$ within total variation error\n$\\delta$, which was obtained with the hit-and-run algorithm, in the setting\nwhere $K$ is a polytope given by $m=O(d)$ inequalities and $LR = O(\\sqrt{d})$.\nWhen a warm start is available, our algorithm improves by a factor of $d^2$\narithmetic operations on the best previous bound in this setting, which was\nobtained for a different version of the Dikin walk algorithm. Plugging our\nDikin walk Markov chain into the post-processing algorithm of Mangoubi and\nVishnoi (2021), we achieve further improvements in the dependence of the\nrunning time for the problem of generating samples from $\\pi$ with infinity\ndistance bounds in the special case when $K$ is a polytope.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2111.04089\n",
    "authors": [
      "Oren Mangoubi",
      "Nisheeth K. Vishnoi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.09384"
  },
  {
    "id": "arXiv:2206.09385",
    "title": "Out-of-distribution Detection by Cross-class Vicinity Distribution of  In-distribution Data",
    "abstract": "Deep neural networks only learn to map in-distribution inputs to their\ncorresponding ground truth labels in the training phase without differentiating\nout-of-distribution samples from in-distribution ones. This results from the\nassumption that all samples are independent and identically distributed without\ndistributional distinction. Therefore, a pretrained network learned from the\nin-distribution samples treats out-of-distribution samples as in-distribution\nand makes high-confidence predictions on them in the test phase. To address\nthis issue, we draw out-of-distribution samples from the vicinity distribution\nof training in-distribution samples for learning to reject the prediction on\nout-of-distribution inputs. A \\textit{Cross-class Vicinity Distribution} is\nintroduced by assuming that an out-of-distribution sample generated by mixing\nmultiple in-distribution samples does not share the same classes of its\nconstituents. We thus improve the discriminability of a pretrained network by\nfinetuning it with out-of-distribution samples drawn from the cross-class\nvicinity distribution, where each out-of-distribution input corresponds to a\ncomplementary label. Experiments on various in-/out-of-distribution datasets\nshow that the proposed method significantly outperforms existing methods in\nimproving the capacity of discriminating between in- and out-of-distribution\nsamples.",
    "descriptor": "",
    "authors": [
      "Zhilin Zhao",
      "Longbing Cao",
      "Kun-Yu Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09385"
  },
  {
    "id": "arXiv:2206.09386",
    "title": "Scalable Neural Data Server: A Data Recommender for Transfer Learning",
    "abstract": "Absence of large-scale labeled data in the practitioner's target domain can\nbe a bottleneck to applying machine learning algorithms in practice. Transfer\nlearning is a popular strategy for leveraging additional data to improve the\ndownstream performance, but finding the most relevant data to transfer from can\nbe challenging. Neural Data Server (NDS), a search engine that recommends\nrelevant data for a given downstream task, has been previously proposed to\naddress this problem. NDS uses a mixture of experts trained on data sources to\nestimate similarity between each source and the downstream task. Thus, the\ncomputational cost to each user grows with the number of sources. To address\nthese issues, we propose Scalable Neural Data Server (SNDS), a large-scale\nsearch engine that can theoretically index thousands of datasets to serve\nrelevant ML data to end users. SNDS trains the mixture of experts on\nintermediary datasets during initialization, and represents both data sources\nand downstream tasks by their proximity to the intermediary datasets. As such,\ncomputational cost incurred by SNDS users remains fixed as new datasets are\nadded to the server. We validate SNDS on a plethora of real world tasks and\nfind that data recommended by SNDS improves downstream task performance over\nbaselines. We also demonstrate the scalability of SNDS by showing its ability\nto select relevant data for transfer outside of the natural image setting.",
    "descriptor": "\nComments: Neurips 2021\n",
    "authors": [
      "Tianshi Cao",
      "Sasha Doubov",
      "David Acuna",
      "Sanja Fidler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09386"
  },
  {
    "id": "arXiv:2206.09387",
    "title": "Label and Distribution-discriminative Dual Representation Learning for  Out-of-Distribution Detection",
    "abstract": "To classify in-distribution samples, deep neural networks learn\nlabel-discriminative representations, which, however, are not necessarily\ndistribution-discriminative according to the information bottleneck. Therefore,\ntrained networks could assign unexpected high-confidence predictions to\nout-of-distribution samples drawn from distributions differing from that of\nin-distribution samples. Specifically, networks extract the strongly\nlabel-related information from in-distribution samples to learn the\nlabel-discriminative representations but discard the weakly label-related\ninformation. Accordingly, networks treat out-of-distribution samples with\nminimum label-sensitive information as in-distribution samples. According to\nthe different informativeness properties of in- and out-of-distribution\nsamples, a Dual Representation Learning (DRL) method learns\ndistribution-discriminative representations that are weakly related to the\nlabeling of in-distribution samples and combines label- and\ndistribution-discriminative representations to detect out-of-distribution\nsamples. For a label-discriminative representation, DRL constructs the\ncomplementary distribution-discriminative representation by an implicit\nconstraint, i.e., integrating diverse intermediate representations where an\nintermediate representation less similar to the label-discriminative\nrepresentation owns a higher weight. Experiments show that DRL outperforms the\nstate-of-the-art methods for out-of-distribution detection.",
    "descriptor": "",
    "authors": [
      "Zhilin Zhao",
      "Longbing Cao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09387"
  },
  {
    "id": "arXiv:2206.09388",
    "title": "Privacy-Preserving Analytics on Decentralized Social Graphs: The Case of  Eigendecomposition",
    "abstract": "Analytics over social graphs allows to extract valuable knowledge and\ninsights for many fields like community detection, fraud detection, and\ninterest mining. In practice, decentralized social graphs frequently arise,\nwhere the social graph is not available to a single entity and is decentralized\namong a large number of users, each holding only a limited local view about the\nwhole graph. Collecting the local views for analytics of decentralized social\ngraphs raises critical privacy concerns, as they encode private information\nabout the social interactions among individuals. In this paper, we design,\nimplement, and evaluate PrivGED, a new system aimed at privacy-preserving\nanalytics over decentralized social graphs. PrivGED focuses on the support for\neigendecomposition, one popular and fundamental graph analytics task producing\neigenvalues/eigenvectors over the adjacency matrix of a social graph and\nbenefits various practical applications. PrivGED is built from a delicate\nsynergy of insights on graph analytics, lightweight cryptography, and\ndifferential privacy, allowing users to securely contribute their local views\non a decentralized social graph for a cloud-based eigendecomposition analytics\nservice while gaining strong privacy protection. Extensive experiments over\nreal-world social graph datasets demonstrate that PrivGED achieves accuracy\ncomparable to the plaintext domain, with practically affordable performance\nsuperior to prior art.",
    "descriptor": "\nComments: Accepted in IEEE Transactions on Knowledge and Data Engineering (TKDE)\n",
    "authors": [
      "Songlei Wang",
      "Yifeng Zheng",
      "Xiaohua Jia",
      "Xun Yi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.09388"
  },
  {
    "id": "arXiv:2206.09389",
    "title": "Two Results on Separation Logic With Theory Reasoning",
    "abstract": "Two results are presented concerning the entailment problem in Separation\nLogic with inductively defined predicate symbols and theory reasoning. First,\nwe show that the entailment problem is undecidable for rules with bounded\ntree-width, if theory reasoning is considered. The result holds for a wide\nclass of theories, even with a very low expressive power. For instance it\napplies to the natural numbers with the successor function, or with the usual\norder. Second, we show that every entailment problem can be reduced to an\nentailment problem containing no equality (neither in the formulas nor in the\nrecursive rules defining the semantics of the predicate symbols).",
    "descriptor": "\nComments: ASL 2022 - Workshop on Advancing Separation Logic. arXiv admin note: substantial text overlap with arXiv:2201.13227\n",
    "authors": [
      "Mnacho Echenim",
      "Nicolas Peltier"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.09389"
  },
  {
    "id": "arXiv:2206.09390",
    "title": "Deterministic Finite-Memory Bias Estimation",
    "abstract": "In this paper we consider the problem of estimating a Bernoulli parameter\nusing finite memory. Let $X_1,X_2,\\ldots$ be a sequence of independent\nidentically distributed Bernoulli random variables with expectation $\\theta$,\nwhere $\\theta \\in [0,1]$. Consider a finite-memory deterministic machine with\n$S$ states, that updates its state $M_n \\in \\{1,2,\\ldots,S\\}$ at each time\naccording to the rule $M_n = f(M_{n-1},X_n)$, where $f$ is a deterministic\ntime-invariant function. Assume that the machine outputs an estimate at each\ntime point according to some fixed mapping from the state space to the unit\ninterval. The quality of the estimation procedure is measured by the asymptotic\nrisk, which is the long-term average of the instantaneous quadratic risk. The\nmain contribution of this paper is an upper bound on the smallest worst-case\nasymptotic risk any such machine can attain. This bound coincides with a lower\nbound derived by Leighton and Rivest, to imply that $\\Theta(1/S)$ is the\nminimax asymptotic risk for deterministic $S$-state machines. In particular,\nour result disproves a longstanding $\\Theta(\\log S/S)$ conjecture for this\nquantity, also posed by Leighton and Rivest.",
    "descriptor": "\nComments: Presented in COLT 2021\n",
    "authors": [
      "Tomer Berg",
      "Or Ordentlich",
      "Ofer Shayevitz"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2206.09390"
  },
  {
    "id": "arXiv:2206.09391",
    "title": "Towards Adversarial Attack on Vision-Language Pre-training Models",
    "abstract": "While vision-language pre-training model (VLP) has shown revolutionary\nimprovements on various vision-language (V+L) tasks, the studies regarding its\nadversarial robustness remain largely unexplored. This paper studied the\nadversarial attack on popular VLP models and V+L tasks. First, we analyzed the\nperformance of adversarial attacks under different settings. By examining the\ninfluence of different perturbed objects and attack targets, we concluded some\nkey observations as guidance on both designing strong multimodal adversarial\nattack and constructing robust VLP models. Second, we proposed a novel\nmultimodal attack method on the VLP models called Collaborative Multimodal\nAdversarial Attack (Co-Attack), which collectively carries out the attacks on\nthe image modality and the text modality. Experimental results demonstrated\nthat the proposed method achieves improved attack performances on different V+L\ndownstream tasks and VLP models. The analysis observations and novel attack\nmethod hopefully provide new understanding into the adversarial robustness of\nVLP models, so as to contribute their safe and reliable deployment in more\nreal-world scenarios.",
    "descriptor": "",
    "authors": [
      "Jiaming Zhang",
      "Qi Yi",
      "Jitao Sang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2206.09391"
  },
  {
    "id": "arXiv:2206.09395",
    "title": "On The Memory Complexity of Uniformity Testing",
    "abstract": "In this paper we consider the problem of uniformity testing with limited\nmemory. We observe a sequence of independent identically distributed random\nvariables drawn from a distribution $p$ over $[n]$, which is either uniform or\nis $\\varepsilon$-far from uniform under the total variation distance, and our\ngoal is to determine the correct hypothesis. At each time point we are allowed\nto update the state of a finite-memory machine with $S$ states, where each\nstate of the machine is assigned one of the hypotheses, and we are interested\nin obtaining an asymptotic probability of error at most $0<\\delta<1/2$\nuniformly under both hypotheses.\nThe main contribution of this paper is deriving upper and lower bounds on the\nnumber of states $S$ needed in order to achieve a constant error probability\n$\\delta$, as a function of $n$ and $\\varepsilon$, where our upper bound is\n$O(\\frac{n\\log n}{\\varepsilon})$ and our lower bound is $\\Omega\n(n+\\frac{1}{\\varepsilon})$. Prior works in the field have almost exclusively\nused collision counting for upper bounds, and the Paninski mixture for lower\nbounds. Somewhat surprisingly, in the limited memory with unlimited samples\nsetup, the optimal solution does not involve counting collisions, and the\nPaninski prior is not hard. Thus, different proof techniques are needed in\norder to attain our bounds.",
    "descriptor": "\nComments: To be presented in COLT 2022\n",
    "authors": [
      "Tomer Berg",
      "Or Ordentlich",
      "Ofer Shayevitz"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.09395"
  },
  {
    "id": "arXiv:2206.09397",
    "title": "Data-Driven Synthesis of Symbolic Abstractions with Guaranteed  Confidence",
    "abstract": "In this work, we propose a data-driven approach for the construction of\nfinite abstractions (a.k.a., symbolic models) for discrete-time deterministic\ncontrol systems with unknown dynamics. We leverage notions of so-called\nalternating bisimulation functions (ABF), as a relation between each unknown\nsystem and its symbolic model, to quantify the mismatch between state behaviors\nof two systems. Accordingly, one can employ our proposed results to perform\nformal verification and synthesis over symbolic models and then carry the\nresults back over unknown original systems. In our data-driven setting, we\nfirst cast the required conditions for constructing ABF as a robust\noptimization program (ROP). Solving the provided ROP is not tractable due to\nthe existence of unknown models in the constraints of ROP. To tackle this\ndifficulty, we collect finite numbers of data from trajectories of unknown\nsystems and propose a scenario optimization program (SOP) corresponding to the\noriginal ROP. By establishing a probabilistic relation between optimal values\nof SOP and ROP, we formally construct ABF between unknown systems and their\nsymbolic models based on the number of data and a required confidence level. We\nverify the effectiveness of our data-driven results over two physical case\nstudies with unknown models including (i) a DC motor and (ii) a nonlinear jet\nengine compressor. We construct symbolic models from data as appropriate\nsubstitutes of original systems and synthesize policies maintaining states of\nunknown systems in a safe set within infinite time horizons with some\nguaranteed confidence levels.",
    "descriptor": "\nComments: This work has been accepted at IEEE Control Systems Letters (L-CSS)\n",
    "authors": [
      "Abolfazl Lavaei",
      "Emilio Frazzoli"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.09397"
  },
  {
    "id": "arXiv:2206.09399",
    "title": "Hierarchical coded elastic computing",
    "abstract": "Elasticity is offered by cloud service providers to exploit under-utilized\ncomputing resources. The low-cost elastic nodes can leave and join any time\nduring the computation cycle. The possibility of elastic events occurring\ntogether with the problem of slow nodes, referred to as stragglers, increases\nthe uncertainty of the system, leading to computation delay. Recent results\nhave shown that coded computing can be used to reduce the negative effect of\nelasticity and stragglers. In this paper, we propose two hierarchical coded\nelastic computing schemes that can further speed up the system by exploiting\nstragglers and effectively allocating tasks among available nodes. In our\nsimulations, our scheme realizes 45% improvement in average finishing time\ncompared to the state-of-the-art coded elastic computing scheme.",
    "descriptor": "",
    "authors": [
      "Shahrzad Kiani",
      "Tharindu Adikari",
      "Stark C. Draper"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.09399"
  },
  {
    "id": "arXiv:2206.09403",
    "title": "MME-CRS: Multi-Metric Evaluation Based on Correlation Re-Scaling for  Evaluating Open-Domain Dialogue",
    "abstract": "Automatic open-domain dialogue evaluation is a crucial component of dialogue\nsystems. Recently, learning-based evaluation metrics have achieved\nstate-of-the-art performance in open-domain dialogue evaluation. However, these\nmetrics, which only focus on a few qualities, are hard to evaluate dialogue\ncomprehensively. Furthermore, these metrics lack an effective score composition\napproach for diverse evaluation qualities. To address the above problems, we\npropose a Multi-Metric Evaluation based on Correlation Re-Scaling (MME-CRS) for\nevaluating open-domain dialogue. Firstly, we build an evaluation metric\ncomposed of 5 groups of parallel sub-metrics called Multi-Metric Evaluation\n(MME) to evaluate the quality of dialogue comprehensively. Furthermore, we\npropose a novel score composition method called Correlation Re-Scaling (CRS) to\nmodel the relationship between sub-metrics and diverse qualities. Our approach\nMME-CRS ranks first on the final test data of DSTC10 track5 subtask1 Automatic\nOpen-domain Dialogue Evaluation Challenge with a large margin, which proved the\neffectiveness of our proposed approach.",
    "descriptor": "\nComments: 7 pages, 1 figure, 6 tables\n",
    "authors": [
      "Pengfei Zhang",
      "Xiaohui Hu",
      "Kaidong Yu",
      "Jian Wang",
      "Song Han",
      "Cao Liu",
      "Chunyang Yuan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.09403"
  },
  {
    "id": "arXiv:2206.09406",
    "title": "Coded Caching via Federated Deep Reinforcement Learning in Fog Radio  Access Networks",
    "abstract": "In this paper, the placement strategy design of coded caching in fog-radio\naccess networks (F-RANs) is investigated. By considering time-variant content\npopularity, federated deep reinforcement learning is exploited to learn the\nplacement strategy for our coded caching scheme. Initially, the placement\nproblem is modeled as a Markov decision process (MDP) to capture the popularity\nvariations and minimize the long-term content access delay. The reformulated\nsequential decision problem is solved by dueling double deep Q-learning\n(dueling DDQL). Then, federated learning is applied to learn the relatively\nlow-dimensional local decision models and aggregate the global decision model,\nwhich alleviates over-consumption of bandwidth resources and avoids direct\nlearning of a complex coded caching decision model with high-dimensional state\nspace. Simulation results show that our proposed scheme outperforms the\nbenchmarks in reducing the content access delay, keeping the performance\nstable, and trading off between the local caching gain and the global\nmulticasting gain.",
    "descriptor": "\nComments: 6 pages, 6 figures\n",
    "authors": [
      "Yingqi Chen",
      "Yanxiang Jiang",
      "Fu-Chun Zheng",
      "Mehdi Bennis",
      "Xiaohu You"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.09406"
  },
  {
    "id": "arXiv:2206.09410",
    "title": "JPEG Compression-Resistant Low-Mid Adversarial Perturbation against  Unauthorized Face Recognition System",
    "abstract": "It has been observed that the unauthorized use of face recognition system\nraises privacy problems. Using adversarial perturbations provides one possible\nsolution to address this issue. A critical issue to exploit adversarial\nperturbation against unauthorized face recognition system is that: The images\nuploaded to the web need to be processed by JPEG compression, which weakens the\neffectiveness of adversarial perturbation. Existing JPEG compression-resistant\nmethods fails to achieve a balance among compression resistance,\ntransferability, and attack effectiveness. To this end, we propose a more\nnatural solution called low frequency adversarial perturbation (LFAP). Instead\nof restricting the adversarial perturbations, we turn to regularize the source\nmodel to employing more low-frequency features by adversarial training.\nMoreover, to better influence model in different frequency components, we\nproposed the refined low-mid frequency adversarial perturbation (LMFAP)\nconsidering the mid frequency components as the productive complement. We\ndesigned a variety of settings in this study to simulate the real-world\napplication scenario, including cross backbones, supervisory heads, training\ndatasets and testing datasets. Quantitative and qualitative experimental\nresults validate the effectivenss of proposed solutions.",
    "descriptor": "",
    "authors": [
      "Jiaming Zhang",
      "Qi Yi",
      "Jitao Sang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.09410"
  },
  {
    "id": "arXiv:2206.09414",
    "title": "Terrain Classification using Transfer Learning on Hyperspectral Images:  A Comparative study",
    "abstract": "A Hyperspectral image contains much more number of channels as compared to a\nRGB image, hence containing more information about entities within the image.\nThe convolutional neural network (CNN) and the Multi-Layer Perceptron (MLP)\nhave been proven to be an effective method of image classification. However,\nthey suffer from the issues of long training time and requirement of large\namounts of the labeled data, to achieve the expected outcome. These issues\nbecome more complex while dealing with hyperspectral images. To decrease the\ntraining time and reduce the dependence on large labeled dataset, we propose\nusing the method of transfer learning. The hyperspectral dataset is\npreprocessed to a lower dimension using PCA, then deep learning models are\napplied to it for the purpose of classification. The features learned by this\nmodel are then used by the transfer learning model to solve a new\nclassification problem on an unseen dataset. A detailed comparison of CNN and\nmultiple MLP architectural models is performed, to determine an optimum\narchitecture that suits best the objective. The results show that the scaling\nof layers not always leads to increase in accuracy but often leads to\noverfitting, and also an increase in the training time.The training time is\nreduced to greater extent by applying the transfer learning approach rather\nthan just approaching the problem by directly training a new model on large\ndatasets, without much affecting the accuracy.",
    "descriptor": "",
    "authors": [
      "Uphar Singh",
      "Kumar Saurabh",
      "Neelaksh Trehan",
      "Ranjana Vyas",
      "O.P. Vyas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09414"
  },
  {
    "id": "arXiv:2206.09418",
    "title": "LordNet: Learning to Solve Parametric Partial Differential Equations  without Simulated Data",
    "abstract": "Neural operators, as a powerful approximation to the non-linear operators\nbetween infinite-dimensional function spaces, have proved to be promising in\naccelerating the solution of partial differential equations (PDE). However, it\nrequires a large amount of simulated data which can be costly to collect,\nresulting in a chicken-egg dilemma and limiting its usage in solving PDEs. To\njump out of the dilemma, we propose a general data-free paradigm where the\nneural network directly learns physics from the mean squared residual (MSR)\nloss constructed by the discretized PDE. We investigate the physical\ninformation in the MSR loss and identify the challenge that the neural network\nmust have the capacity to model the long range entanglements in the spatial\ndomain of the PDE, whose patterns vary in different PDEs. Therefore, we propose\nthe low-rank decomposition network (LordNet) which is tunable and also\nefficient to model various entanglements. Specifically, LordNet learns a\nlow-rank approximation to the global entanglements with simple fully connected\nlayers, which extracts the dominant pattern with reduced computational cost.\nThe experiments on solving Poisson's equation and Navier-Stokes equation\ndemonstrate that the physical constraints by the MSR loss can lead to better\naccuracy and generalization ability of the neural network. In addition, LordNet\noutperforms other modern neural network architectures in both PDEs with the\nfewest parameters and the fastest inference speed. For Navier-Stokes equation,\nthe learned operator is over 50 times faster than the finite difference\nsolution with the same computational resources.",
    "descriptor": "",
    "authors": [
      "Wenlei Shi",
      "Xinquan Huang",
      "Xiaotian Gao",
      "Xinran Wei",
      "Jia Zhang",
      "Jiang Bian",
      "Mao Yang",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09418"
  },
  {
    "id": "arXiv:2206.09420",
    "title": "Agricultural Plantation Classification using Transfer Learning Approach  based on CNN",
    "abstract": "Hyper-spectral images are images captured from a satellite that gives spatial\nand spectral information of specific region.A Hyper-spectral image contains\nmuch more number of channels as compared to a RGB image, hence containing more\ninformation about entities within the image. It makes them well suited for the\nclassification of objects in a snap. In the past years, the efficiency of\nhyper-spectral image recognition has increased significantly with deep\nlearning. The Convolution Neural Network(CNN) and Multi-Layer Perceptron(MLP)\nhas demonstrated to be an excellent process of classifying images. However,\nthey suffer from the issues of long training time and requirement of large\namounts of the labeled data, to achieve the expected outcome. These issues\nbecome more complex while dealing with hyper-spectral images. To decrease the\ntraining time and reduce the dependence on large labeled data-set, we propose\nusing the method of transfer learning.The features learned by CNN and MLP\nmodels are then used by the transfer learning model to solve a new\nclassification problem on an unseen dataset. A detailed comparison of CNN and\nmultiple MLP architectural models is performed, to determine an optimum\narchitecture that suits best the objective. The results show that the scaling\nof layers not always leads to increase in accuracy but often leads to\nover-fitting, and also an increase in the training time.The training time is\nreduced to greater extent by applying the transfer learning approach rather\nthan just approaching the problem by directly training a new model on large\ndata-sets, without much affecting the accuracy.",
    "descriptor": "",
    "authors": [
      "Uphar Singh",
      "Tushar Musale",
      "Ranjana Vyas",
      "O.P.Vyas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09420"
  },
  {
    "id": "arXiv:2206.09421",
    "title": "Guarantees for Epsilon-Greedy Reinforcement Learning with Function  Approximation",
    "abstract": "Myopic exploration policies such as epsilon-greedy, softmax, or Gaussian\nnoise fail to explore efficiently in some reinforcement learning tasks and yet,\nthey perform well in many others. In fact, in practice, they are often selected\nas the top choices, due to their simplicity. But, for what tasks do such\npolicies succeed? Can we give theoretical guarantees for their favorable\nperformance? These crucial questions have been scarcely investigated, despite\nthe prominent practical importance of these policies. This paper presents a\ntheoretical analysis of such policies and provides the first regret and\nsample-complexity bounds for reinforcement learning with myopic exploration.\nOur results apply to value-function-based algorithms in episodic MDPs with\nbounded Bellman Eluder dimension. We propose a new complexity measure called\nmyopic exploration gap, denoted by alpha, that captures a structural property\nof the MDP, the exploration policy and the given value function class. We show\nthat the sample-complexity of myopic exploration scales quadratically with the\ninverse of this quantity, 1 / alpha^2. We further demonstrate through concrete\nexamples that myopic exploration gap is indeed favorable in several tasks where\nmyopic exploration succeeds, due to the corresponding dynamics and reward\nstructure.",
    "descriptor": "\nComments: to appear at ICML 2022\n",
    "authors": [
      "Christoph Dann",
      "Yishay Mansour",
      "Mehryar Mohri",
      "Ayush Sekhari",
      "Karthik Sridharan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09421"
  },
  {
    "id": "arXiv:2206.09422",
    "title": "Phantom Artifacts & Code Review Coverage in Dependency Updates",
    "abstract": "The goal of this study is to aid developers in securely accepting dependency\nupdates by measuring if the code changes in an update have passed through a\ncode review process. We implement DepDive, an update audit tool for packages in\nCrates.io, npm, PyPI, and RubyGems registry. DepDive first (i) identifies the\nfiles and the code changes in an update that cannot be traced back to the\npackage's source repository, i.e., phantom artifacts; and then (ii) measures\nwhat portion of changes in the update, excluding the phantom artifacts, has\npassed through a code review process, i.e., code review coverage.\nUsing DepDive, we present an empirical study across the latest ten updates of\nthe most downloaded 1000 packages in each of the four registries. Our study\nunveils interesting insights while also providing an evaluation of our proposed\napproach. We find that phantom artifacts are not uncommon in the updates\n(20.1\\% of the analyzed updates had at least one phantom file). The phantoms\ncan appear either due to legitimate reasons, such as in the case of\nprogrammatically generated files, or from accidental inclusion, such as in the\ncase of files that are ignored in the repository. However, without provenance\ntracking, we cannot audit if the changes in these phantom artifacts were\ncode-reviewed or not.\nRegarding code review coverage (\\textit{CRC)}, we find the updates are\ntypically only partially code-reviewed (52.5\\% of the time). Further, only\n9.0\\% of the packages had all their updates in our data set fully\ncode-reviewed, indicating that even the most used packages can introduce\nnon-reviewed code in the software supply chain. We also observe that updates\neither tend to have very high \\textit{CRC} or very low \\textit{CRC}, suggesting\nthat packages at the opposite end of the spectrum may require a separate set of\ntreatments.",
    "descriptor": "",
    "authors": [
      "Nasif Imtiaz",
      "Laurie Williams"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.09422"
  },
  {
    "id": "arXiv:2206.09423",
    "title": "Efficient End-to-End AutoML via Scalable Search Space Decomposition",
    "abstract": "End-to-end AutoML has attracted intensive interests from both academia and\nindustry which automatically searches for ML pipelines in a space induced by\nfeature engineering, algorithm/model selection, and hyper-parameter tuning.\nExisting AutoML systems, however, suffer from scalability issues when applying\nto application domains with large, high-dimensional search spaces. We present\nVolcanoML, a scalable and extensible framework that facilitates systematic\nexploration of large AutoML search spaces. VolcanoML introduces and implements\nbasic building blocks that decompose a large search space into smaller ones,\nand allows users to utilize these building blocks to compose an execution plan\nfor the AutoML problem at hand. VolcanoML further supports a Volcano-style\nexecution model -- akin to the one supported by modern database systems -- to\nexecute the plan constructed. Our evaluation demonstrates that, not only does\nVolcanoML raise the level of expressiveness for search space decomposition in\nAutoML, it also leads to actual findings of decomposition strategies that are\nsignificantly more efficient than the ones employed by state-of-the-art AutoML\nsystems such as auto-sklearn.",
    "descriptor": "\nComments: extended paper for VolcanoML (li et al. VLDB 2021)/Mindware. arXiv admin note: substantial text overlap with arXiv:2107.08861\n",
    "authors": [
      "Yang Li",
      "Yu Shen",
      "Wentao Zhang",
      "Ce Zhang",
      "Bin Cui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09423"
  },
  {
    "id": "arXiv:2206.09424",
    "title": "Construction and Optimization of TRNG Based Substitution Boxes for Block  Encryption Algorithms",
    "abstract": "Internet of Things is an ecosystem of interconnected devices that are\naccessible through the internet. The recent research focuses on adding more\nsmartness and intelligence to these edge devices. This makes them susceptible\nto various kinds of security threats. These edge devices rely on cryptographic\ntechniques to encrypt the pre-processed data collected from the sensors\ndeployed in the field. In this regard, block cipher has been one of the most\nreliable options through which data security is accomplished. The strength of\nblock encryption algorithms against different attacks is dependent on its\nnonlinear primitive which is called Substitution Boxes. For the design of\nS-boxes mainly algebraic and chaos-based techniques are used but researchers\nalso found various weaknesses in these techniques. On the other side,\nliterature endorse the true random numbers for information security due to the\nreason that, true random numbers are purely non-deterministic. In this paper\nfirstly a natural dynamical phenomenon is utilized for the generation of true\nrandom numbers based S-boxes. Secondly, a systematic literature review was\nconducted to know which metaheuristic optimization technique is highly adopted\nin the current decade for the optimization of S-boxes. Based on the outcome of\nSystematic Literature Review (SLR), genetic algorithm is chosen for the\noptimization of s-boxes. The results of our method validate that the proposed\ndynamic S-boxes are effective for the block ciphers. Moreover, our results\nshowed that the proposed substitution boxes achieve better",
    "descriptor": "\nComments: 15 pages, 3 figuers, Journal Paper\n",
    "authors": [
      "Muhammad Fahad Khan",
      "Khalid Saleem",
      "Mohammed Alotaibi",
      "Mohammad Mazyad Hazzazi",
      "Eid Rehman",
      "Aaqif Afzaal Abbasi",
      "Muhammad Asif Gondal"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.09424"
  },
  {
    "id": "arXiv:2206.09425",
    "title": "Semi-implicit high resolution numerical scheme for conservation laws",
    "abstract": "We present novel semi-implicit schemes for numerical solution of\ntime-dependant conservation laws. The core idea of the presented method\nconsists of exploiting and approximating mixed partial derivatives of the\nsolution that occur naturally when deriving higher-order accurate schemes. Such\napproach can be introduced, e.g., in the context of Lax-Wendroff (or\nCauchy-Kowalevski) procedure when the time derivatives are not replaced\ncompletely by space derivatives using the PDE, but some mixed derivatives are\nallowed. If approximated conveniently, algebraic systems are obtained that have\na more convenient structure than the systems derived by standard fully implicit\nschemes. We derive high-resolution TVD form of the scheme for simple\nrepresentative hyperbolic equations in one-dimensional case including\nillustrative numerical experiments.",
    "descriptor": "",
    "authors": [
      "Peter Frolkovi\u010d",
      "Michal \u017derav\u00fd"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.09425"
  },
  {
    "id": "arXiv:2206.09426",
    "title": "ADBench: Anomaly Detection Benchmark",
    "abstract": "Given a long list of anomaly detection algorithms developed in the last few\ndecades, how do they perform with regard to (i) varying levels of supervision,\n(ii) different types of anomalies, and (iii) noisy and corrupted data? In this\nwork, we answer these key questions by conducting (to our best knowledge) the\nmost comprehensive anomaly detection benchmark with 30 algorithms on 55\nbenchmark datasets, named ADBench. Our extensive experiments (93,654 in total)\nidentify meaningful insights into the role of supervision and anomaly types,\nand unlock future directions for researchers in algorithm selection and design.\nWith ADBench, researchers can easily conduct comprehensive and fair evaluations\nfor newly proposed methods on the datasets (including our contributed ones from\nnatural language and computer vision domains) against the existing baselines.\nTo foster accessibility and reproducibility, we fully open-source ADBench and\nthe corresponding results.",
    "descriptor": "\nComments: All authors contribute equally and are listed alphabetically. Code available at this https URL\n",
    "authors": [
      "Songqiao Han",
      "Xiyang Hu",
      "Hailiang Huang",
      "Mingqi Jiang",
      "Yue Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.09426"
  },
  {
    "id": "arXiv:2206.09427",
    "title": "QuDASH: Quantum-inspired rate adaptation approach for DASH video  streaming",
    "abstract": "Internet traffic is dramatically increasing with the development of network\ntechnologies. Within the total traffic, video streaming traffic accounts for a\nlarge amount, which reveals the importance to guarantee the quality of content\ndelivery service. Based on the network conditions, adaptive bitrate (ABR)\ncontrol is utilized as a common technique which can choose the proper bitrate\nto ensure the video streaming quality. In this paper, a new bitrate control\nmethod, QuDASH is proposed by taking advantage of the emerging quantum\ntechnology. In QuDASH, the adaptive control model is developed using the\nquadratic unconstrained binary optimization (QUBO), which aims at increasing\nthe average bitrate and decreasing the video rebuffering events to maximize the\nuser quality of experience (QoE). Then, the control model is solved by Digital\nAnnealer, which is a quantum-Inspired computing technology. The evaluation of\nthe proposed method is carried out by simulation with the measured throughput\ntraces in real world. Experiment results demonstrated that the proposed QuDASH\nmethod has better performance in terms of QoE compared with other advanced ABR\nmethods. In 68.2% of the examined cases, QuDASH achieves the highest QoE\nresults, which shows the superiority of the QuDASH over conventional methods.",
    "descriptor": "",
    "authors": [
      "Bo Wei",
      "Hang Song",
      "Makoto Nakamura",
      "Koichi Kimura",
      "Nozomu Togawa",
      "Jiro Katto"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Multimedia (cs.MM)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.09427"
  },
  {
    "id": "arXiv:2206.09428",
    "title": "Reputation, Risk, and Trust on User Adoption of Internet Search Engines:  The Case of DuckDuckGo",
    "abstract": "This paper investigates the determinants of end-user adoption of the\nDuckDuckGo search engine coupling the standard UTAUT model with factors to\nreflect reputation, risk, and trust. An experimental approach was taken to\nvalidate our model, where participants were exposed to the DuckDuckGo product\nusing a vignette. Subsequently, answering questions on their perception of the\ntechnology. The data was analyzed using the partial least squares-structural\nequation modeling (PLS-SEM) approach. From the nine distinct factors studied,\nwe found that 'Performance Expectancy' played the greatest role in user\ndecisions on adoption, followed by 'Firm Reputation', 'Initial Trust in\nTechnology', 'Social Influence', and 'Individual Disposition to Trust'. We\nconclude by exploring how these findings can explain DuckDuckGo's rising\nprominence as a search engine.",
    "descriptor": "",
    "authors": [
      "Antonios Saravanos",
      "Stavros Zervoudakis",
      "Dongnanzi Zheng",
      "Amarpreet Nanda",
      "Georgios Shaheen",
      "Charles Hornat",
      "Jeremiah Konde Chaettle",
      "Alassane Yoda",
      "Hyeree Park",
      "Will Ang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.09428"
  },
  {
    "id": "arXiv:2206.09430",
    "title": "Meta-Analysis of the Accuracy of Syndromic Surveillance",
    "abstract": "We present the first meta-analysis of co-evolutionary learning networks for\ndigital disease surveillance research over last 10 years. In doing so, we show\nthe co-evolution and dynamical changes that occurred in academic research\nrelated to digital disease surveillance for improving accuracy, approach and\nresults. Using dynamic network analysis, we are able to show the incorporation\nof social media-based analytics and algorithms which have been proposed and\nlater improved by other researchers as co-evolutionary learning networks. This\nessentially demonstrates how we improve our research and increase accuracy\nthrough feedback loop for correcting the behaviour of an open system and\nperhaps infer learning patterns, reliability and validity using 10 years\nscientific research in digital disease surveillance.",
    "descriptor": "\nComments: 11 papers, 8 figures\n",
    "authors": [
      "Liaquat Hossain",
      "Derek Kham"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.09430"
  },
  {
    "id": "arXiv:2206.09432",
    "title": "Object Localization Assistive System Based on CV and Vibrotactile  Encoding",
    "abstract": "Intelligent assistive systems can navigate blind people, but most of them\ncould only give non-intuitive cues or inefficient guidance. Based on computer\nvision and vibrotactile encoding, this paper presents an interactive system\nthat provides blind people with intuitive spatial cognition. Different from the\ntraditional auditory feedback strategy based on speech cues, this paper firstly\nintroduces a vibration-encoded feedback method that leverages the haptic neural\npathway and enables the users to interact with objects other than manipulating\nan assistance device. Based on this strategy, a wearable visual module based on\nan RGB-D camera is adopted for 3D spatial object localization, which\ncontributes to accurate perception and quick object localization in the real\nenvironment. The experimental results on target blind individuals indicate that\nvibrotactile feedback reduces the task completion time by over 25% compared\nwith the mainstream voice prompt feedback scheme. The proposed object\nlocalization system provides a more intuitive spatial navigation and\ncomfortable wearability for blindness assistance.",
    "descriptor": "",
    "authors": [
      "Zhikai Wei",
      "Xuhui Hu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.09432"
  },
  {
    "id": "arXiv:2206.09449",
    "title": "SNN2ANN: A Fast and Memory-Efficient Training Framework for Spiking  Neural Networks",
    "abstract": "Spiking neural networks are efficient computation models for low-power\nenvironments. Spike-based BP algorithms and ANN-to-SNN (ANN2SNN) conversions\nare successful techniques for SNN training. Nevertheless, the spike-base BP\ntraining is slow and requires large memory costs. Though ANN2NN provides a\nlow-cost way to train SNNs, it requires many inference steps to mimic the\nwell-trained ANN for good performance. In this paper, we propose a SNN-to-ANN\n(SNN2ANN) framework to train the SNN in a fast and memory-efficient way. The\nSNN2ANN consists of 2 components: a) a weight sharing architecture between ANN\nand SNN and b) spiking mapping units. Firstly, the architecture trains the\nweight-sharing parameters on the ANN branch, resulting in fast training and low\nmemory costs for SNN. Secondly, the spiking mapping units ensure that the\nactivation values of the ANN are the spiking features. As a result, the\nclassification error of the SNN can be optimized by training the ANN branch.\nBesides, we design an adaptive threshold adjustment (ATA) algorithm to address\nthe noisy spike problem. Experiment results show that our SNN2ANN-based models\nperform well on the benchmark datasets (CIFAR10, CIFAR100, and Tiny-ImageNet).\nMoreover, the SNN2ANN can achieve comparable accuracy under 0.625x time steps,\n0.377x training time, 0.27x GPU memory costs, and 0.33x spike activities of the\nSpike-based BP model.",
    "descriptor": "",
    "authors": [
      "Jianxiong Tang",
      "Jianhuang Lai",
      "Xiaohua Xie",
      "Lingxiao Yang",
      "Wei-Shi Zheng"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09449"
  },
  {
    "id": "arXiv:2206.09450",
    "title": "Data Augmentation vs. Equivariant Networks: A Theory of Generalization  on Dynamics Forecasting",
    "abstract": "Exploiting symmetry in dynamical systems is a powerful way to improve the\ngeneralization of deep learning. The model learns to be invariant to\ntransformation and hence is more robust to distribution shift. Data\naugmentation and equivariant networks are two major approaches to injecting\nsymmetry into learning. However, their exact role in improving generalization\nis not well understood. In this work, we derive the generalization bounds for\ndata augmentation and equivariant networks, characterizing their effect on\nlearning in a unified framework. Unlike most prior theories for the i.i.d.\nsetting, we focus on non-stationary dynamics forecasting with complex temporal\ndependencies.",
    "descriptor": "",
    "authors": [
      "Rui Wang",
      "Robin Walters",
      "Rose Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09450"
  },
  {
    "id": "arXiv:2206.09453",
    "title": "Bounding Evidence and Estimating Log-Likelihood in VAE",
    "abstract": "Many crucial problems in deep learning and statistics are caused by a\nvariational gap, i.e., a difference between evidence and evidence lower bound\n(ELBO). As a consequence, in the classical VAE model, we obtain only the lower\nbound on the log-likelihood since ELBO is used as a cost function, and\ntherefore we cannot compare log-likelihood between models. In this paper, we\npresent a general and effective upper bound of the variational gap, which\nallows us to efficiently estimate the true evidence. We provide an extensive\ntheoretical study of the proposed approach. Moreover, we show that by applying\nour estimation, we can easily obtain lower and upper bounds for the\nlog-likelihood of VAE models.",
    "descriptor": "",
    "authors": [
      "\u0141ukasz Struski",
      "Marcin Mazur",
      "Pawe\u0142 Batorski",
      "Przemys\u0142aw Spurek",
      "Jacek Tabor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.09453"
  },
  {
    "id": "arXiv:2206.09457",
    "title": "All you need is feedback: Communication with block attention feedback  codes",
    "abstract": "Deep learning based channel code designs have recently gained interest as an\nalternative to conventional coding algorithms, particularly for channels for\nwhich existing codes do not provide effective solutions. Communication over a\nfeedback channel is one such problem, for which promising results have recently\nbeen obtained by employing various deep learning architectures. In this paper,\nwe introduce a novel learning-aided code design for feedback channels, called\ngeneralized block attention feedback (GBAF) codes, which i) employs a modular\narchitecture that can be implemented using different neural network\narchitectures; ii) provides order-of-magnitude improvements in the probability\nof error compared to existing designs; and iii) can transmit at desired code\nrates.",
    "descriptor": "",
    "authors": [
      "Emre Ozfatura",
      "Yulin Shao",
      "Alberto Perotti",
      "Branislav Popovic",
      "Deniz Gunduz"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.09457"
  },
  {
    "id": "arXiv:2206.09458",
    "title": "A Universal Adversarial Policy for Text Classifiers",
    "abstract": "Discovering the existence of universal adversarial perturbations had large\ntheoretical and practical impacts on the field of adversarial learning. In the\ntext domain, most universal studies focused on adversarial prefixes which are\nadded to all texts. However, unlike the vision domain, adding the same\nperturbation to different inputs results in noticeably unnatural inputs.\nTherefore, we introduce a new universal adversarial setup - a universal\nadversarial policy, which has many advantages of other universal attacks but\nalso results in valid texts - thus making it relevant in practice. We achieve\nthis by learning a single search policy over a predefined set of semantics\npreserving text alterations, on many texts. This formulation is universal in\nthat the policy is successful in finding adversarial examples on new texts\nefficiently. Our approach uses text perturbations which were extensively shown\nto produce natural attacks in the non-universal setup (specific synonym\nreplacements). We suggest a strong baseline approach for this formulation which\nuses reinforcement learning. It's ability to generalise (from as few as 500\ntraining texts) shows that universal adversarial patterns exist in the text\ndomain as well.",
    "descriptor": "\nComments: Accepted for publication in Neural Networks (2022), see this https URL\n",
    "authors": [
      "Gallil Maimon",
      "Lior Rokach"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.09458"
  },
  {
    "id": "arXiv:2206.09463",
    "title": "RF-LIO: Removal-First Tightly-coupled Lidar Inertial Odometry in High  Dynamic Environments",
    "abstract": "Simultaneous Localization and Mapping (SLAM) is considered to be an essential\ncapability for intelligent vehicles and mobile robots. However, most of the\ncurrent lidar SLAM approaches are based on the assumption of a static\nenvironment. Hence the localization in a dynamic environment with multiple\nmoving objects is actually unreliable. The paper proposes a dynamic SLAM\nframework RF-LIO, building on LIO-SAM, which adds adaptive multi-resolution\nrange images and uses tightly-coupled lidar inertial odometry to first remove\nmoving objects, and then match lidar scan to the submap. Thus, it can obtain\naccurate poses even in high dynamic environments. The proposed RF-LIO is\nevaluated on both self-collected datasets and open Urbanloco datasets. The\nexperimental results in high dynamic environments demonstrate that, compared\nwith LOAM and LIO-SAM, the absolute trajectory accuracy of the proposed RF-LIO\ncan be improved by 90% and 70%, respectively. RF-LIO is one of the\nstate-of-the-art SLAM systems in high dynamic environments.",
    "descriptor": "",
    "authors": [
      "Chenglong Qian",
      "Zhaohong Xiang",
      "Zhuoran Wu",
      "Hongbin Sun"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.09463"
  },
  {
    "id": "arXiv:2206.09465",
    "title": "Cyber Threats Jurisdiction and Authority",
    "abstract": "Cybersecurity threats affect all aspects of society; critical infrastructures\n(such as networks, corporate systems, water supply systems, and intelligent\ntransportation systems) are especially prone to attacks and can have tangible\nnegative consequences on society. However, these critical cyber systems are\ngenerally governed by multiple jurisdictions, for instance the Metro in the\nWashington, D.C. area is managed by the states of Virginia and Maryland, as\nwell as the District of Columbia (DC) through Washington Metropolitan Area\nTransit Authority (WMATA). Additionally, the water treatment infrastructure\nmanaged by DC Water consists of waste water input from Fairfax and Arlington\ncounties, and the district (i.e. DC). Additionally, cyber attacks usually\nlaunch from unknown sources, through unknown switches and servers, and end up\nat the destination without much knowledge on their source or path. Certain\ninfrastructures are shared amongst multiple countries, another idiosyncrasy\nthat exacerbates the issue of governance. This law paper however, is not\nconcerned with the general governance of these infrastructures, rather with the\nambiguity in the relevant laws or doctrines about which authority would prevail\nin the context of a cyber threat or a cyber-attack, with a focus on federal vs.\nstate issues, international law involvement, federal preemption, technical\naspects that could affect lawmaking, and conflicting responsibilities in cases\nof cyber crime. A legal analysis of previous cases is presented, as well as an\nextended discussion addressing different sides of the argument.",
    "descriptor": "\nComments: This report is developed for partial fulfillment of the requirements for the degree of Juris Masters of Law at GMU's Antonin Scalia Law School\n",
    "authors": [
      "Feras A. Batarseh"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.09465"
  },
  {
    "id": "arXiv:2206.09474",
    "title": "3D Object Detection for Autonomous Driving: A Review and New Outlooks",
    "abstract": "Autonomous driving, in recent years, has been receiving increasing attention\nfor its potential to relieve drivers' burdens and improve the safety of\ndriving. In modern autonomous driving pipelines, the perception system is an\nindispensable component, aiming to accurately estimate the status of\nsurrounding environments and provide reliable observations for prediction and\nplanning. 3D object detection, which intelligently predicts the locations,\nsizes, and categories of the critical 3D objects near an autonomous vehicle, is\nan important part of a perception system. This paper reviews the advances in 3D\nobject detection for autonomous driving. First, we introduce the background of\n3D object detection and discuss the challenges in this task. Second, we conduct\na comprehensive survey of the progress in 3D object detection from the aspects\nof models and sensory inputs, including LiDAR-based, camera-based, and\nmulti-modal detection approaches. We also provide an in-depth analysis of the\npotentials and challenges in each category of methods. Additionally, we\nsystematically investigate the applications of 3D object detection in driving\nsystems. Finally, we conduct a performance analysis of the 3D object detection\napproaches, and we further summarize the research trends over the years and\nprospect the future directions of this area.",
    "descriptor": "\nComments: A survey on 3D object detection for autonomous driving. Project page is at this https URL\n",
    "authors": [
      "Jiageng Mao",
      "Shaoshuai Shi",
      "Xiaogang Wang",
      "Hongsheng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.09474"
  },
  {
    "id": "arXiv:2206.09476",
    "title": "The Game of Tumbleweed is PSPACE-complete",
    "abstract": "Tumbleweed is a popular two-player perfect-information new territorial game\nplayed at the prestigious Mind Sport Olympiad. We define a generalized version\nof the game, where the board size is arbitrary and so is the possible number of\nneutral stones.\nOur result: the complexity of deciding for a given configuration which of the\nplayers has a winning strategy is PSPACE-complete. The proof is by a log-space\nreduction from a Boolean formula game of T.J. Schaefer, known to be\nPSPACE-complete.\nWe embed the non-planar Schaefer game within the planar Tumbleweed board\nwithout using proper \"bridges\", that are impossible due to the board's\ntopology. Instead, our new technique uses a one-move tight race that forces the\nplayers to move only according to the protocol of playing the embedded 4-CNF\ngame.",
    "descriptor": "",
    "authors": [
      "Lear Bahack"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2206.09476"
  },
  {
    "id": "arXiv:2206.09477",
    "title": "Geometric Matrix Completion via Sylvester Multi-Graph Neural Network",
    "abstract": "Despite the success of the Sylvester equation empowered methods on various\ngraph mining applications, such as semi-supervised label learning and network\nalignment, there also exists several limitations. The Sylvester equation's\ninability of modeling non-linear relations and the inflexibility of tuning\ntowards different tasks restrict its performance. In this paper, we propose an\nend-to-end neural framework, SYMGNN, which consists of a multi-network neural\naggregation module and a prior multi-network association incorporation learning\nmodule. The proposed framework inherits the key ideas of the Sylvester\nequation, and meanwhile generalizes it to overcome aforementioned limitations.\nEmpirical evaluations on real-world datasets show that the instantiations of\nSYMGNN overall outperform the baselines in geometric matrix completion task,\nand its low-rank instantiation could further reduce the memory consumption by\n16.98\\% on average.",
    "descriptor": "",
    "authors": [
      "Boxin Du",
      "Changhe Yuan",
      "Fei Wang",
      "Hanghang Tong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09477"
  },
  {
    "id": "arXiv:2206.09479",
    "title": "StudioGAN: A Taxonomy and Benchmark of GANs for Image Synthesis",
    "abstract": "Generative Adversarial Network (GAN) is one of the state-of-the-art\ngenerative models for realistic image synthesis. While training and evaluating\nGAN becomes increasingly important, the current GAN research ecosystem does not\nprovide reliable benchmarks for which the evaluation is conducted consistently\nand fairly. Furthermore, because there are few validated GAN implementations,\nresearchers devote considerable time to reproducing baselines. We study the\ntaxonomy of GAN approaches and present a new open-source library named\nStudioGAN. StudioGAN supports 7 GAN architectures, 9 conditioning methods, 4\nadversarial losses, 13 regularization modules, 3 differentiable augmentations,\n7 evaluation metrics, and 5 evaluation backbones. With our training and\nevaluation protocol, we present a large-scale benchmark using various datasets\n(CIFAR10, ImageNet, AFHQv2, FFHQ, and Baby/Papa/Granpa-ImageNet) and 3\ndifferent evaluation backbones (InceptionV3, SwAV, and Swin Transformer).\nUnlike other benchmarks used in the GAN community, we train representative\nGANs, including BigGAN, StyleGAN2, and StyleGAN3, in a unified training\npipeline and quantify generation performance with 7 evaluation metrics. The\nbenchmark evaluates other cutting-edge generative models(e.g., StyleGAN-XL,\nADM, MaskGIT, and RQ-Transformer). StudioGAN provides GAN implementations,\ntraining, and evaluation scripts with the pre-trained weights. StudioGAN is\navailable at https://github.com/POSTECH-CVLab/PyTorch-StudioGAN.",
    "descriptor": "\nComments: 30 pages, Submitted to journal\n",
    "authors": [
      "Minguk Kang",
      "Joonghyuk Shin",
      "Jaesik Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.09479"
  },
  {
    "id": "arXiv:2206.09480",
    "title": "Predicting Human Performance in Vertical Hierarchical Menu Selection in  Immersive AR Using Hand-gesture and Head-gaze",
    "abstract": "There are currently limited guidelines on designing user interfaces (UI) for\nimmersive augmented reality (AR) applications. Designers must reflect on their\nexperience designing UI for desktop and mobile applications and conjecture how\na UI will influence AR users' performance. In this work, we introduce a\npredictive model for determining users' performance for a target UI without the\nsubsequent involvement of participants in user studies. The model is trained on\nparticipants' responses to objective performance measures such as consumed\nendurance (CE) and pointing time (PT) using hierarchical drop-down menus. Large\nvariability in the depth and context of the menus is ensured by randomly and\ndynamically creating the hierarchical drop-down menus and associated user tasks\nfrom words contained in the lexical database WordNet. Subjective performance\nbias is reduced by incorporating the users' non-verbal standard performance\nWAIS-IV during the model training. The semantic information of the menu is\nencoded using the Universal Sentence Encoder. We present the results of a user\nstudy that demonstrates that the proposed predictive model achieves high\naccuracy in predicting the CE on hierarchical menus of users with various\ncognitive abilities. To the best of our knowledge, this is the first work on\npredicting CE in designing UI for immersive AR applications.",
    "descriptor": "",
    "authors": [
      "Majid Pourmemar",
      "Yashas Joshi",
      "Charalambos Poullis"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.09480"
  },
  {
    "id": "arXiv:2206.09483",
    "title": "An Analysis of the Admissibility of the Objective Functions Applied in  Evolutionary Multi-objective Clustering",
    "abstract": "A variety of clustering criteria has been applied as an objective function in\nEvolutionary Multi-Objective Clustering approaches (EMOCs). However, most EMOCs\ndo not provide detailed analysis regarding the choice and usage of the\nobjective functions. Aiming to support a better choice and definition of the\nobjectives in the EMOCs, this paper proposes an analysis of the admissibility\nof the clustering criteria in evolutionary optimization by examining the search\ndirection and its potential in finding optimal results. As a result, we\ndemonstrate how the admissibility of the objective functions can influence the\noptimization. Furthermore, we provide insights regarding the combinations and\nusage of the clustering criteria in the EMOCs.",
    "descriptor": "\nComments: Preprint submitted to Information Sciences\n",
    "authors": [
      "Cristina Y. Morimoto",
      "Aurora Pozo",
      "Marc\u00edlio C. P. de Souto"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09483"
  },
  {
    "id": "arXiv:2206.09484",
    "title": "A Critical Review of Communications in Multi-Robot Systems",
    "abstract": "Purpose of Review. This review summarizes the broad roles that communication\nformats and technologies have played in enabling multi-robot systems. We\napproach this field from two perspectives: of robotic applications that need\ncommunication capabilities in order to accomplish tasks, and of networking\ntechnologies that have enabled newer and more advanced multi-robot systems.\nRecent Findings. Through this review, we identify a dearth of work that\nholistically tackles the problem of co-design and co-optimization of robots and\nthe networks they employ. We also highlight the role that data-driven and\nmachine learning approaches play in evolving communication pipelines for\nmulti-robot systems. In particular, we refer to recent work that diverges from\nhand-designed communication patterns, and also discuss the \"sim-to-real\" gap in\nthis context.\nSummary. We present a critical view of the way robotic algorithms and their\nnetworking systems have evolved, and make the case for a more synergistic\napproach. Finally, we also identify four broad Open Problems for research and\ndevelopment, while offering a data-driven perspective for solving some of them.",
    "descriptor": "\nComments: 9 pages excl. bibliography, 2 figures\n",
    "authors": [
      "Jennifer Gielis",
      "Ajay Shankar",
      "Amanda Prorok"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2206.09484"
  },
  {
    "id": "arXiv:2206.09485",
    "title": "Video frame interpolation for high dynamic range sequences captured with  dual-exposure sensors",
    "abstract": "Video frame interpolation (VFI) enables many important applications that\nmight involve the temporal domain, such as slow motion playback, or the spatial\ndomain, such as stop motion sequences. We are focusing on the former task,\nwhere one of the key challenges is handling high dynamic range (HDR) scenes in\nthe presence of complex motion. To this end, we explore possible advantages of\ndual-exposure sensors that readily provide sharp short and blurry long\nexposures that are spatially registered and whose ends are temporally aligned.\nThis way, motion blur registers temporally continuous information on the scene\nmotion that, combined with the sharp reference, enables more precise motion\nsampling within a single camera shot. We demonstrate that this facilitates a\nmore complex motion reconstruction in the VFI task, as well as HDR frame\nreconstruction that so far has been considered only for the originally captured\nframes, not in-between interpolated frames. We design a neural network trained\nin these tasks that clearly outperforms existing solutions. We also propose a\nmetric for scene motion complexity that provides important insights into the\nperformance of VFI methods at the test time.",
    "descriptor": "\nComments: 13 pages, 7 figures\n",
    "authors": [
      "Ugur Cogalan",
      "Mojtaba Bemana",
      "Hans-Peter Seidel",
      "Karol Myszkowski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09485"
  },
  {
    "id": "arXiv:2206.09491",
    "title": "On the Limitations of Stochastic Pre-processing Defenses",
    "abstract": "Defending against adversarial examples remains an open problem. A common\nbelief is that randomness at inference increases the cost of finding\nadversarial inputs. An example of such a defense is to apply a random\ntransformation to inputs prior to feeding them to the model. In this paper, we\nempirically and theoretically investigate such stochastic pre-processing\ndefenses and demonstrate that they are flawed. First, we show that most\nstochastic defenses are weaker than previously thought; they lack sufficient\nrandomness to withstand even standard attacks like projected gradient descent.\nThis casts doubt on a long-held assumption that stochastic defenses invalidate\nattacks designed to evade deterministic defenses and force attackers to\nintegrate the Expectation over Transformation (EOT) concept. Second, we show\nthat stochastic defenses confront a trade-off between adversarial robustness\nand model invariance; they become less effective as the defended model acquires\nmore invariance to their randomization. Future work will need to decouple these\ntwo effects. Our code is available in the supplementary material.",
    "descriptor": "",
    "authors": [
      "Yue Gao",
      "Ilia Shumailov",
      "Kassem Fawaz",
      "Nicolas Papernot"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.09491"
  },
  {
    "id": "arXiv:2206.09494",
    "title": "Adaptive coupling peridynamic least-square minimization with finite  element method for fracture analysis",
    "abstract": "This study presents an adaptive coupling peridynamic least-square\nminimization with the finite element method (PDLSM-FEM) for fracture analysis.\nThe presented method utilizes the PDLSM modeling discontinuities while\nmaximizing the FEM region for computational efficiency. Within the presented\nadaptive PDLSM-FEM, only elements intersecting with the crack path and their\nneighboring elements are defined as PD elements, whose stiffness matrices are\nderived based on PDLSM equations. The remaining elements are conventional\nfinite elements. Numerical integration of interaction integral is proposed and\nimplemented to evaluate the stress intensity factors (SIFs) for 2-D problems.\nThe criterion of maximum hoop tensile stress is employed for failure\nprediction. New contributions of this work include the adaptive coupling of\nPDLSM with FEM for minimizing the PD region and the application of the adaptive\nPDLSM-FEM to quasi-static crack propagation analysis. Simulations of three 2-D\nplane stress plates and one 3-D block with static or quasi-static cracks\npropagation are performed. Results show the proposed method improves\ncomputational efficiency substantially and has reasonable accuracy and good\ncapability of crack propagation prediction.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Qibang Liu",
      "X.J. Xin",
      "Jeff Ma"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.09494"
  },
  {
    "id": "arXiv:2206.09495",
    "title": "The Power of Regularization in Solving Extensive-Form Games",
    "abstract": "In this paper, we investigate the power of regularization, a common technique\nin reinforcement learning and optimization, in solving extensive-form games\n(EFGs). We propose a series of new algorithms based on regularizing the payoff\nfunctions of the game, and establish a set of convergence results that strictly\nimprove over the existing ones, with either weaker assumptions or stronger\nconvergence guarantees. In particular, we first show that dilated optimistic\nmirror descent (DOMD), an efficient variant of OMD for solving EFGs, with\nadaptive regularization can achieve a fast $\\tilde O(1/T)$ last-iterate\nconvergence in terms of duality gap without the uniqueness assumption of the\nNash equilibrium (NE). Moreover, regularized dilated optimistic multiplicative\nweights update (Reg-DOMWU), an instance of Reg-DOMD, further enjoys the $\\tilde\nO(1/T)$ last-iterate convergence rate of the distance to the set of NE. This\naddresses an open question on whether iterate convergence can be obtained for\nOMWU algorithms without the uniqueness assumption in both the EFG and\nnormal-form game literature. Second, we show that regularized counterfactual\nregret minimization (Reg-CFR), with a variant of optimistic mirror descent\nalgorithm as regret-minimizer, can achieve $O(1/T^{1/4})$ best-iterate, and\n$O(1/T^{3/4})$ average-iterate convergence rate for finding NE in EFGs.\nFinally, we show that Reg-CFR can achieve asymptotic last-iterate convergence,\nand optimal $O(1/T)$ average-iterate convergence rate, for finding the NE of\nperturbed EFGs, which is useful for finding approximate extensive-form perfect\nequilibria (EFPE). To the best of our knowledge, they constitute the first\nlast-iterate convergence results for CFR-type algorithms, while matching the\nSOTA average-iterate convergence rate in finding NE for non-perturbed EFGs. We\nalso provide numerical results to corroborate the advantages of our algorithms.",
    "descriptor": "",
    "authors": [
      "Mingyang Liu",
      "Asuman Ozdaglar",
      "Tiancheng Yu",
      "Kaiqing Zhang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09495"
  },
  {
    "id": "arXiv:2206.09496",
    "title": "Integrated Weak Learning",
    "abstract": "We introduce Integrated Weak Learning, a principled framework that integrates\nweak supervision into the training process of machine learning models. Our\napproach jointly trains the end-model and a label model that aggregates\nmultiple sources of weak supervision. We introduce a label model that can learn\nto aggregate weak supervision sources differently for different datapoints and\ntakes into consideration the performance of the end-model during training. We\nshow that our approach outperforms existing weak learning techniques across a\nset of 6 benchmark classification datasets. When both a small amount of labeled\ndata and weak supervision are present the increase in performance is both\nconsistent and large, reliably getting a 2-5 point test F1 score gain over\nnon-integrated methods.",
    "descriptor": "\nComments: 14 pages, 4 figures\n",
    "authors": [
      "Peter Hayes",
      "Mingtian Zhang",
      "Raza Habib",
      "Jordan Burgess",
      "Emine Yilmaz",
      "David Barber"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09496"
  },
  {
    "id": "arXiv:2206.09498",
    "title": "Learning Multi-Task Transferable Rewards via Variational Inverse  Reinforcement Learning",
    "abstract": "Many robotic tasks are composed of a lot of temporally correlated sub-tasks\nin a highly complex environment. It is important to discover situational\nintentions and proper actions by deliberating on temporal abstractions to solve\nproblems effectively. To understand the intention separated from changing task\ndynamics, we extend an empowerment-based regularization technique to situations\nwith multiple tasks based on the framework of a generative adversarial network.\nUnder the multitask environments with unknown dynamics, we focus on learning a\nreward and policy from the unlabeled expert examples. In this study, we define\nsituational empowerment as the maximum of mutual information representing how\nan action conditioned on both a certain state and sub-task affects the future.\nOur proposed method derives the variational lower bound of the situational\nmutual information to optimize it. We simultaneously learn the transferable\nmulti-task reward function and policy by adding an induced term to the\nobjective function. By doing so, the multi-task reward function helps to learn\na robust policy for environmental change. We validate the advantages of our\napproach on multi-task learning and multi-task transfer learning. We\ndemonstrate our proposed method has the robustness of both randomness and\nchanging task dynamics. Finally, we prove that our method has significantly\nbetter performance and data efficiency than existing imitation learning methods\non various benchmarks.",
    "descriptor": "\nComments: Accepted in ICRA 2022\n",
    "authors": [
      "Se-Wook Yoo",
      "Seung-Woo Seo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.09498"
  },
  {
    "id": "arXiv:2206.09500",
    "title": "Unbiased Teacher v2: Semi-supervised Object Detection for Anchor-free  and Anchor-based Detectors",
    "abstract": "With the recent development of Semi-Supervised Object Detection (SS-OD)\ntechniques, object detectors can be improved by using a limited amount of\nlabeled data and abundant unlabeled data. However, there are still two\nchallenges that are not addressed: (1) there is no prior SS-OD work on\nanchor-free detectors, and (2) prior works are ineffective when pseudo-labeling\nbounding box regression. In this paper, we present Unbiased Teacher v2, which\nshows the generalization of SS-OD method to anchor-free detectors and also\nintroduces Listen2Student mechanism for the unsupervised regression loss.\nSpecifically, we first present a study examining the effectiveness of existing\nSS-OD methods on anchor-free detectors and find that they achieve much lower\nperformance improvements under the semi-supervised setting. We also observe\nthat box selection with centerness and the localization-based labeling used in\nanchor-free detectors cannot work well under the semi-supervised setting. On\nthe other hand, our Listen2Student mechanism explicitly prevents misleading\npseudo-labels in the training of bounding box regression; we specifically\ndevelop a novel pseudo-labeling selection mechanism based on the Teacher and\nStudent's relative uncertainties. This idea contributes to favorable\nimprovement in the regression branch in the semi-supervised setting. Our\nmethod, which works for both anchor-free and anchor-based methods, consistently\nperforms favorably against the state-of-the-art methods in VOC, COCO-standard,\nand COCO-additional.",
    "descriptor": "\nComments: Project Page is at this http URL\n",
    "authors": [
      "Yen-Cheng Liu",
      "Chih-Yao Ma",
      "Zsolt Kira"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09500"
  },
  {
    "id": "arXiv:2206.09504",
    "title": "A Parallel Implementation of Computing Mean Average Precision",
    "abstract": "Mean Average Precision (mAP) has been widely used for evaluating the quality\nof object detectors, but an efficient implementation is still absent. Current\nimplementations can only count true positives (TP's) and false positives (FP's)\nfor one class at a time by looping through every detection of that class\nsequentially. Not only are these approaches inefficient, but they are also\ninconvenient for reporting validation mAP during training. We propose a\nparallelized alternative that can process mini-batches of detected bounding\nboxes (DTBB's) and ground truth bounding boxes (GTBB's) as inference goes such\nthat mAP can be instantly calculated after inference is finished. Loops and\ncontrol statements in sequential implementations are replaced with extensive\nuses of broadcasting, masking, and indexing. All operators involved are\nsupported by popular machine learning frameworks such as PyTorch and\nTensorFlow. As a result, our implementation is much faster and can easily fit\ninto typical training routines. A PyTorch version of our implementation is\navailable at https://github.com/bwangca/fast-map.",
    "descriptor": "",
    "authors": [
      "Beinan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.09504"
  },
  {
    "id": "arXiv:2206.09506",
    "title": "Log-GPIS-MOP: A Unified Representation for Mapping, Odometry and  Planning",
    "abstract": "Whereas dedicated scene representations are required for each different tasks\nin conventional robotic systems, this paper demonstrates that a unified\nrepresentation can be used directly for multiple key tasks. We propose the\nLog-Gaussian Process Implicit Surface for Mapping, Odometry and Planning\n(Log-GPIS-MOP): a probabilistic framework for surface reconstruction,\nlocalisation and navigation based on a unified representation. Our framework\napplies a logarithmic transformation to a Gaussian Process Implicit Surface\n(GPIS) formulation to recover a global representation that accurately captures\nthe Euclidean distance field with gradients and, at the same time, the implicit\nsurface. By directly estimate the distance field and its gradient through\nLog-GPIS inference, the proposed incremental odometry technique computes the\noptimal alignment of an incoming frame, and fuses it globally to produce a map.\nConcurrently, an optimisation-based planner computes a safe collision-free path\nusing the same Log-GPIS surface representation. We validate the proposed\nframework on simulated and real datasets in 2D and 3D and benchmark against the\nstate-of-the-art approaches. Our experiments show that Log-GPIS-MOP produces\ncompetitive results in sequential odometry, surface mapping and obstacle\navoidance.",
    "descriptor": "",
    "authors": [
      "Lan Wu",
      "Ki Myung Brian Lee",
      "Teresa Vidal-Calleja"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.09506"
  },
  {
    "id": "arXiv:2206.09509",
    "title": "Hybrid Facial Expression Recognition (FER2013) Model for Real-Time  Emotion Classification and Prediction",
    "abstract": "Facial Expression Recognition is a vital research topic in most fields\nranging from artificial intelligence and gaming to Human-Computer Interaction\n(HCI) and Psychology. This paper proposes a hybrid model for Facial Expression\nrecognition, which comprises a Deep Convolutional Neural Network (DCNN) and\nHaar Cascade deep learning architectures. The objective is to classify\nreal-time and digital facial images into one of the seven facial emotion\ncategories considered. The DCNN employed in this research has more\nconvolutional layers, ReLU Activation functions, and multiple kernels to\nenhance filtering depth and facial feature extraction. In addition, a haar\ncascade model was also mutually used to detect facial features in real-time\nimages and video frames. Grayscale images from the Kaggle repository (FER-2013)\nand then exploited Graphics Processing Unit (GPU) computation to expedite the\ntraining and validation process. Pre-processing and data augmentation\ntechniques are applied to improve training efficiency and classification\nperformance. The experimental results show a significantly improved\nclassification performance compared to state-of-the-art (SoTA) experiments and\nresearch. Also, compared to other conventional models, this paper validates\nthat the proposed architecture is superior in classification performance with\nan improvement of up to 6%, totaling up to 70% accuracy, and with less\nexecution time of 2098.8s.",
    "descriptor": "\nComments: 8 Pages, 8 figures\n",
    "authors": [
      "Ozioma Collins Oguine",
      "Kaleab Alamayehu Kinfu",
      "Kanyifeechukwu Jane Oguine",
      "Hashim Ibrahim Bisallah",
      "Daniel Ofuani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.09509"
  },
  {
    "id": "arXiv:2206.09511",
    "title": "The Fallacy of AI Functionality",
    "abstract": "Deployed AI systems often do not work. They can be constructed haphazardly,\ndeployed indiscriminately, and promoted deceptively. However, despite this\nreality, scholars, the press, and policymakers pay too little attention to\nfunctionality. This leads to technical and policy solutions focused on\n\"ethical\" or value-aligned deployments, often skipping over the prior question\nof whether a given system functions, or provides any benefits at all.To\ndescribe the harms of various types of functionality failures, we analyze a set\nof case studies to create a taxonomy of known AI functionality issues. We then\npoint to policy and organizational responses that are often overlooked and\nbecome more readily available once functionality is drawn into focus. We argue\nthat functionality is a meaningful AI policy challenge, operating as a\nnecessary first step towards protecting affected communities from algorithmic\nharm.",
    "descriptor": "",
    "authors": [
      "Inioluwa Deborah Raji",
      "I. Elizabeth Kumar",
      "Aaron Horowitz",
      "Andrew D. Selbst"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09511"
  },
  {
    "id": "arXiv:2206.09514",
    "title": "Ethics in AI through the Developer's Prism: A Socio-Technical Grounded  Theory Literature Review and Guidelines",
    "abstract": "The term 'ethics' is widely used, explored, and debated in the context of\ndeveloping Artificial Intelligence (AI) systems. In recent years, there have\nbeen numerous incidents that have raised the profile of ethical issues in AI\ndevelopment and led to public concerns about the proliferation of AI technology\nin our everyday lives. But what do we know about the views and experiences of\nthose who develop these systems - the AI developers? We conducted a\nSocio-Technical Grounded Theory Literature Review (ST-GTLR) of 30 primary\nempirical studies that included AI developers' views on ethics in AI to derive\nfive categories that discuss AI developers' views on AI ethics: developer's\nawareness, perception, needs, challenges, and approach. These are underpinned\nby multiple codes and concepts that we explain with evidence from the included\nstudies. Through the steps of advanced theory development, we also derived a\nset of relationships between these categories and presented them as five\nhypotheses, leading to the 'theory of ethics in AI through the developer's\nprism' which explains that developers' awareness of AI ethics directly leads to\ntheir perception about AI ethics and its implementation as well as to\nidentifying their needs, and indirectly leads to identifying their challenges\nand coming up with approaches (applied and potential strategies) to overcome\nthem. The theory provides a landscape view of the key aspects that concern AI\ndevelopers when it comes to ethics in AI. We also share an agenda for future\nresearch studies and recommendations for developers, managers, and\norganisations to help in their efforts to better implement ethics in AI.",
    "descriptor": "\nComments: 23 pages, 5 figures, 3 tables\n",
    "authors": [
      "Aastha Pant",
      "Rashina Hoda",
      "Chakkrit Tantithamthavorn",
      "Burak Turhan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.09514"
  },
  {
    "id": "arXiv:2206.09519",
    "title": "Walking to Hide: Privacy Amplification via Random Message Exchanges in  Network",
    "abstract": "The *shuffle model* is a powerful tool to amplify the privacy guarantees of\nthe *local model* of differential privacy. In contrast to the fully\ndecentralized manner of guaranteeing privacy in the local model, the shuffle\nmodel requires a central, trusted shuffler. To avoid this central shuffler,\nrecent work of Liew et al. (2022) proposes shuffling locally randomized data in\na decentralized manner, via random walks on the communication network\nconstituted by the clients. The privacy amplification bound it thus provides\ndepends on the topology of the underlying communication network, even for\ninfinitely long random walks. It does not match the state-of-the-art privacy\namplification bound for the shuffle model (Feldman et al., 2021).\nIn this work, we prove that the output of~$n$ clients' data, each perturbed\nby an ${\\epsilon}_0$-local randomizer, and shuffled by random walks with a\nlogarithmic number of steps, is $( {O} ( (1 - e^{-\\epsilon_0} ) \\sqrt{ (\ne^{\\epsilon_0} / n ) \\ln (1 / \\delta ) } ), O(\\delta) )$-differentially\nprivate. Importantly, this bound is independent of the topology of the\ncommunication network, and asymptotically closes the gap between the privacy\namplification bounds for the network shuffle model (Liew et al., 2022) and the\nshuffle model (Feldman et al., 2021). Our proof is based on a reduction to the\nshuffle model, and an analysis of the distribution of random walks of finite\nlength. Building on this, we further show that if each client is sampled\nindependently with probability~$p$, the privacy guarantee of the network\nshuffle model can be further improved to $( {O} ( (1 - e^{-\\epsilon_0} )\n\\sqrt{p ( e^{\\epsilon_0} / n ) \\ln (1 / \\delta ) } ) , O(\\delta) )$.\nImportantly, the subsampling is also performed in a fully decentralized manner\nthat does not require a trusted central entity; compared with related bounds in\nprior work, our bound is stronger.",
    "descriptor": "",
    "authors": [
      "Hao Wu",
      "Olga Ohrimenko",
      "Anthony Wirth"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.09519"
  },
  {
    "id": "arXiv:2206.09520",
    "title": "ILX: Intelligent \"Location+X\" Data Systems (Vision Paper)",
    "abstract": "Due to the ubiquity of mobile phones and location-detection devices, location\ndata is being generated in very large volumes. Queries and operations that are\nperformed on location data warrant the use of database systems. Despite that,\nlocation data is being supported in data systems as an afterthought. Typically,\nrelational or NoSQL data systems that are mostly designed with non-location\ndata in mind get extended with spatial or spatiotemporal indexes, some query\noperators, and higher level syntactic sugar in order to support location data.\nThe ubiquity of location data and location data services calls for systems that\nare solely designed and optimized for the efficient support of location data.\nThis paper envisions designing intelligent location+X data systems, ILX for\nshort, where in ILX, location is treated as a first-class citizen type. ILX is\ntailored with location data as the main data type (location-first). Because\nlocation data is typically augmented with other data types X, e.g., graphs,\ntext data, click streams, annotations, etc., ILX needs to be extensible to\nsupport other data types X along with location. This paper envisions the main\nfeatures that ILX should support, some research challenges related to realizing\nand supporting ILX.",
    "descriptor": "",
    "authors": [
      "Walid G. Aref",
      "Yeasir Rayhan",
      "Libin Zhou",
      "Anas Daghistani"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2206.09520"
  },
  {
    "id": "arXiv:2206.09525",
    "title": "Finite Element de Rham and Stokes Complexes in Three Dimensions",
    "abstract": "Finite element de Rham complexes and finite element Stokes complexes with\nvarious smoothness in three dimensions are systematically constructed. First\nsmooth scalar finite elements in three dimensions are derived through a\nnon-overlapping decomposition of the simplicial lattice. Based on the smooth\nscalar finite elements, both H(div)-conforming finite elements and\nH(curl)-conforming finite elements with various smoothness are devised, which\ninduce the finite element de Rham complexes with various smoothness and the\nassociated commutative diagrams. The div stability is established for the\nH(div)-conforming finite elements, and the exactness of these finite element\ncomplexes.",
    "descriptor": "\nComments: 44 pages. arXiv admin note: text overlap with arXiv:2111.10712\n",
    "authors": [
      "Long Chen",
      "Xuehai Huang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.09525"
  },
  {
    "id": "arXiv:2206.09526",
    "title": "Robust One Round Federated Learning with Predictive Space Bayesian  Inference",
    "abstract": "Making predictions robust is an important challenge. A separate challenge in\nfederated learning (FL) is to reduce the number of communication rounds,\nparticularly since doing so reduces performance in heterogeneous data settings.\nTo tackle both issues, we take a Bayesian perspective on the problem of\nlearning a global model. We show how the global predictive posterior can be\napproximated using client predictive posteriors. This is unlike other works\nwhich aggregate the local model space posteriors into the global model space\nposterior, and are susceptible to high approximation errors due to the\nposterior's high dimensional multimodal nature. In contrast, our method\nperforms the aggregation on the predictive posteriors, which are typically\neasier to approximate owing to the low-dimensionality of the output space. We\npresent an algorithm based on this idea, which performs MCMC sampling at each\nclient to obtain an estimate of the local posterior, and then aggregates these\nin one round to obtain a global ensemble model. Through empirical evaluation on\nseveral classification and regression tasks, we show that despite using one\nround of communication, the method is competitive with other FL techniques, and\noutperforms them on heterogeneous settings. The code is publicly available at\nhttps://github.com/hasanmohsin/FedPredSpace_1Round.",
    "descriptor": "\nComments: 7 pages, 1 figure. Code is publicly available at this https URL\n",
    "authors": [
      "Mohsin Hasan",
      "Zehao Zhang",
      "Kaiyang Guo",
      "Mahdi Karami",
      "Guojun Zhang",
      "Xi Chen",
      "Pascal Poupart"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.09526"
  },
  {
    "id": "arXiv:2206.09527",
    "title": "Simultaneous approximation of a smooth function and its derivatives by  deep neural networks with piecewise-polynomial activations",
    "abstract": "This paper investigates the approximation properties of deep neural networks\nwith piecewise-polynomial activation functions. We derive the required depth,\nwidth, and sparsity of a deep neural network to approximate any H\\\"{o}lder\nsmooth function up to a given approximation error in H\\\"{o}lder norms in such a\nway that all weights of this neural network are bounded by $1$. The latter\nfeature is essential to control generalization errors in many statistical and\nmachine learning applications.",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Denis Belomestny",
      "Alexey Naumov",
      "Nikita Puchkin",
      "Sergey Samsonov"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.09527"
  },
  {
    "id": "arXiv:2206.09529",
    "title": "Temporal Link Prediction via Adjusted Sigmoid Function and 2-Simplex  Sructure",
    "abstract": "Temporal network link prediction is an important task in the field of network\nscience, and has a wide range of applications in practical scenarios. Revealing\nthe evolutionary mechanism of the network is essential for link prediction, and\nhow to effectively utilize the historical information for temporal links and\nefficiently extract the high-order patterns of network structure remains a\nvital challenge. To address these issues, in this paper, we propose a novel\ntemporal link prediction model with adjusted sigmoid function and 2-simplex\nstructure (TLPSS). The adjusted sigmoid decay mode takes the active, decay and\nstable states of edges into account, which properly fits the life cycle of\ninformation. Moreover, the latent matrix sequence is introduced, which is\ncomposed of simplex high-order structure, to enhance the performance of link\nprediction method since it is highly feasible in sparse network. Combining the\nlife cycle of information and simplex high-order structure, the overall\nperformance of TLPSS is achieved by satisfying the consistency of temporal and\nstructural information in dynamic networks. Experimental results on six\nreal-world datasets demonstrate the effectiveness of TLPSS, and our proposed\nmodel improves the performance of link prediction by an average of 15% compared\nto other baseline methods.",
    "descriptor": "",
    "authors": [
      "Ruizhi Zhang",
      "Qiaozi Wang",
      "Qiming Yang",
      "Wei Wei"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.09529"
  },
  {
    "id": "arXiv:2206.09534",
    "title": "Proceedings Ninth Workshop on Mathematically Structured Functional  Programming",
    "abstract": "This volume contains the proceedings of the Ninth Workshop on Mathematically\nStructured Functional Programming (MSFP 2022). The meeting took place on the\n2nd of April as a satellite of European Joint Conferences on Theory & Practice\nof Software (ETAPS 2022). The MSFP workshop highlights applications of\nmathematical structures to programming applications. We promote the use of\ncategory theory, type theory, and formal language semantics to the development\nof simple and reasonable programs. As the range of papers presented in this\nyear's workshop shows, this continues to be a fruitful interface.",
    "descriptor": "",
    "authors": [
      "Jeremy Gibbons",
      "Max S. New"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2206.09534"
  },
  {
    "id": "arXiv:2206.09535",
    "title": "Extracting Fast and Slow: User-Action Embedding with Inter-temporal  Information",
    "abstract": "With the recent development of technology, data on detailed human temporal\nbehaviors has become available. Many methods have been proposed to mine those\nhuman dynamic behavior data and revealed valuable insights for research and\nbusinesses. However, most methods analyze only sequence of actions and do not\nstudy the inter-temporal information such as the time intervals between actions\nin a holistic manner. While actions and action time intervals are\ninterdependent, it is challenging to integrate them because they have different\nnatures: time and action. To overcome this challenge, we propose a unified\nmethod that analyzes user actions with intertemporal information (time\ninterval). We simultaneously embed the user's action sequence and its time\nintervals to obtain a low-dimensional representation of the action along with\nintertemporal information. The paper demonstrates that the proposed method\nenables us to characterize user actions in terms of temporal context, using\nthree real-world data sets. This paper demonstrates that explicit modeling of\naction sequences and inter-temporal user behavior information enable successful\ninterpretable analysis.",
    "descriptor": "",
    "authors": [
      "Akira Matsui",
      "Emilio Ferrara"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.09535"
  },
  {
    "id": "arXiv:2206.09539",
    "title": "Numerical reconstruction for 3D nonlinear SAR imaging via a version of  the convexification method",
    "abstract": "This work extends the applicability of our recent convexification-based\nalgorithm for constructing images of the dielectric constant of buried or\noccluded target. We are orientated towards the detection of explosive-like\ntargets such as antipersonnel land mines and improvised explosive devices in\nthe non-invasive inspections of buildings. In our previous work, the method is\nposed in the perspective that we use multiple source locations running along a\nline of source to get a 2D image of the dielectric function. Mathematically, we\nsolve a 1D coefficient inverse problem for a hyperbolic equation for each\nsource location. Different from any conventional Born approximation-based\ntechnique for synthetic-aperture radar, this method does not need any\nlinearization. In this paper, we attempt to verify the method using several 3D\nnumerical tests with simulated data. We revisit the global convergence of the\ngradient descent method of our computational approach.",
    "descriptor": "\nComments: 23 pages, 11 figures\n",
    "authors": [
      "Vo Anh Khoa",
      "Michael Victor Klibanov",
      "William Grayson Powell",
      "Loc Hoang Nguyen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.09539"
  },
  {
    "id": "arXiv:2206.09541",
    "title": "DualCoOp: Fast Adaptation to Multi-Label Recognition with Limited  Annotations",
    "abstract": "Solving multi-label recognition (MLR) for images in the low-label regime is a\nchallenging task with many real-world applications. Recent work learns an\nalignment between textual and visual spaces to compensate for insufficient\nimage labels, but loses accuracy because of the limited amount of available MLR\nannotations. In this work, we utilize the strong alignment of textual and\nvisual features pretrained with millions of auxiliary image-text pairs and\npropose Dual Context Optimization (DualCoOp) as a unified framework for\npartial-label MLR and zero-shot MLR. DualCoOp encodes positive and negative\ncontexts with class names as part of the linguistic input (i.e. prompts). Since\nDualCoOp only introduces a very light learnable overhead upon the pretrained\nvision-language framework, it can quickly adapt to multi-label recognition\ntasks that have limited annotations and even unseen classes. Experiments on\nstandard multi-label recognition benchmarks across two challenging low-label\nsettings demonstrate the advantages of our approach over state-of-the-art\nmethods.",
    "descriptor": "",
    "authors": [
      "Ximeng Sun",
      "Ping Hu",
      "Kate Saenko"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09541"
  },
  {
    "id": "arXiv:2206.09542",
    "title": "Visual Guidance for Remote Interaction in Avatar-Mediated Mixed-Reality  Telepresence",
    "abstract": "Rapid advances in technology gradually realize immersive mixed-reality\ntelepresence between distant spaces. In this paper, we present a novel visual\nguidance method to support interaction between remote users in an MR\ntelepresence environment. Representing the spatial relationship between the\nuser/avatar and interaction targets with angle-based interaction features, we\nassign recommendation scores of possible local placements as similarities\nbetween the interaction features of optimal remote pairs. The scores are\nvisualized with 2D colored circular sectors. In addition, we overlap\ntransparent virtual models of the remote space on the local space with respect\nto the shared interaction target for the users to better understand the\nrecommendations. We examine whether the proposed score measure agrees with\nactual user perception on context preservation and find a score threshold for\nrecommendation through user experiments in virtual reality. Another user study\ninvestigates the effectiveness of different combinations of visualizations and\nthe degrees of perceptual overload of visual guides. A qualitative survey using\na prototype MR telepresence system validates our visual guidance in the target\nscenario of MR remote collaboration.",
    "descriptor": "",
    "authors": [
      "Dongseok Yang",
      "Jiho Kang",
      "Taehei Kim",
      "Sung-Hee Lee"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2206.09542"
  },
  {
    "id": "arXiv:2206.09546",
    "title": "Policy Optimization with Linear Temporal Logic Constraints",
    "abstract": "We study the problem of policy optimization (PO) with linear temporal logic\n(LTL) constraints. The language of LTL allows flexible description of tasks\nthat may be unnatural to encode as a scalar cost function. We consider\nLTL-constrained PO as a systematic framework, decoupling task specification\nfrom policy selection, and an alternative to the standard of cost shaping. With\naccess to a generative model, we develop a model-based approach that enjoys a\nsample complexity analysis for guaranteeing both task satisfaction and cost\noptimality (through a reduction to a reachability problem). Empirically, our\nalgorithm can achieve strong performance even in low sample regimes.",
    "descriptor": "\nComments: Under Review at Neurips\n",
    "authors": [
      "Cameron Voloshin",
      "Hoang M. Le",
      "Swarat Chaudhuri",
      "Yisong Yue"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.09546"
  },
  {
    "id": "arXiv:2206.09548",
    "title": "Variational Distillation for Multi-View Learning",
    "abstract": "Information Bottleneck (IB) based multi-view learning provides an information\ntheoretic principle for seeking shared information contained in heterogeneous\ndata descriptions. However, its great success is generally attributed to\nestimate the multivariate mutual information which is intractable when the\nnetwork becomes complicated. Moreover, the representation learning tradeoff,\n{\\it i.e.}, prediction-compression and sufficiency-consistency tradeoff, makes\nthe IB hard to satisfy both requirements simultaneously. In this paper, we\ndesign several variational information bottlenecks to exploit two key\ncharacteristics ({\\it i.e.}, sufficiency and consistency) for multi-view\nrepresentation learning. Specifically, we propose a Multi-View Variational\nDistillation (MV$^2$D) strategy to provide a scalable, flexible and analytical\nsolution to fitting MI by giving arbitrary input of viewpoints but without\nexplicitly estimating it. Under rigorously theoretical guarantee, our approach\nenables IB to grasp the intrinsic correlation between observations and semantic\nlabels, producing predictive and compact representations naturally. Also, our\ninformation-theoretic constraint can effectively neutralize the sensitivity to\nheterogeneous data by eliminating both task-irrelevant and view-specific\ninformation, preventing both tradeoffs in multiple view cases. To verify our\ntheoretically grounded strategies, we apply our approaches to various\nbenchmarks under three different applications. Extensive experiments to\nquantitatively and qualitatively demonstrate the effectiveness of our approach\nagainst state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Xudong Tian",
      "Zhizhong Zhang",
      "Cong Wang",
      "Wensheng Zhang",
      "Yanyun Qu",
      "Lizhuang Ma",
      "Zongze Wu",
      "Yuan Xie",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09548"
  },
  {
    "id": "arXiv:2206.09549",
    "title": "Cooperative Edge Caching via Multi Agent Reinforcement Learning in Fog  Radio Access Networks",
    "abstract": "In this paper, the cooperative edge caching problem in fog radio access\nnetworks (F-RANs) is investigated. To minimize the content transmission delay,\nwe formulate the cooperative caching optimization problem to find the globally\noptimal caching strategy.By considering the non-deterministic polynomial hard\n(NP-hard) property of this problem, a Multi Agent Reinforcement Learning\n(MARL)-based cooperative caching scheme is proposed.Our proposed scheme applies\ndouble deep Q-network (DDQN) in every fog access point (F-AP), and introduces\nthe communication process in multi-agent system. Every F-AP records the\nhistorical caching strategies of its associated F-APs as the observations of\ncommunication procedure.By exchanging the observations, F-APs can leverage the\ncooperation and make the globally optimal caching strategy.Simulation results\nshow that the proposed MARL-based cooperative caching scheme has remarkable\nperformance compared with the benchmark schemes in minimizing the content\ntransmission delay.",
    "descriptor": "\nComments: This paper has been accepted by IEEE ICC 2022\n",
    "authors": [
      "Qi Chang",
      "Yanxiang Jiang",
      "Fu-Chun Zheng",
      "Mehdi Bennis",
      "Xiaohu You"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2206.09549"
  },
  {
    "id": "arXiv:2206.09551",
    "title": "Eliminating The Impossible, Whatever Remains Must Be True",
    "abstract": "The rise of AI methods to make predictions and decisions has led to a\npressing need for more explainable artificial intelligence (XAI) methods. One\ncommon approach for XAI is to produce a post-hoc explanation, explaining why a\nblack box ML model made a certain prediction. Formal approaches to post-hoc\nexplanations provide succinct reasons for why a prediction was made, as well as\nwhy not another prediction was made. But these approaches assume that features\nare independent and uniformly distributed. While this means that \"why\"\nexplanations are correct, they may be longer than required. It also means the\n\"why not\" explanations may be suspect as the counterexamples they rely on may\nnot be meaningful. In this paper, we show how one can apply background\nknowledge to give more succinct \"why\" formal explanations, that are presumably\neasier to interpret by humans, and give more accurate \"why not\" explanations.\nFurthermore, we also show how to use existing rule induction techniques to\nefficiently extract background information from a dataset, and also how to\nreport which background information was used to make an explanation, allowing a\nhuman to examine it if they doubt the correctness of the explanation.",
    "descriptor": "",
    "authors": [
      "Jinqiang Yu",
      "Alexey Ignatiev",
      "Peter J. Stuckey",
      "Nina Narodytska",
      "Joao Marques-Silva"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.09551"
  },
  {
    "id": "arXiv:2206.09552",
    "title": "Dynamic Message Propagation Network for RGB-D Salient Object Detection",
    "abstract": "This paper presents a novel deep neural network framework for RGB-D salient\nobject detection by controlling the message passing between the RGB images and\ndepth maps on the feature level and exploring the long-range semantic contexts\nand geometric information on both RGB and depth features to infer salient\nobjects. To achieve this, we formulate a dynamic message propagation (DMP)\nmodule with the graph neural networks and deformable convolutions to\ndynamically learn the context information and to automatically predict filter\nweights and affinity matrices for message propagation control. We further embed\nthis module into a Siamese-based network to process the RGB image and depth map\nrespectively and design a multi-level feature fusion (MFF) module to explore\nthe cross-level information between the refined RGB and depth features.\nCompared with 17 state-of-the-art methods on six benchmark datasets for RGB-D\nsalient object detection, experimental results show that our method outperforms\nall the others, both quantitatively and visually.",
    "descriptor": "\nComments: 12 pages, 8 figures\n",
    "authors": [
      "Baian Chen",
      "Zhilei Chen",
      "Xiaowei Hu",
      "Jun Xu",
      "Haoran Xie",
      "Mingqiang Wei",
      "Jing Qin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09552"
  },
  {
    "id": "arXiv:2206.09553",
    "title": "Capturing and Inferring Dense Full-Body Human-Scene Contact",
    "abstract": "Inferring human-scene contact (HSC) is the first step toward understanding\nhow humans interact with their surroundings. While detecting 2D human-object\ninteraction (HOI) and reconstructing 3D human pose and shape (HPS) have enjoyed\nsignificant progress, reasoning about 3D human-scene contact from a single\nimage is still challenging. Existing HSC detection methods consider only a few\ntypes of predefined contact, often reduce body and scene to a small number of\nprimitives, and even overlook image evidence. To predict human-scene contact\nfrom a single image, we address the limitations above from both data and\nalgorithmic perspectives. We capture a new dataset called RICH for \"Real\nscenes, Interaction, Contact and Humans.\" RICH contains multiview\noutdoor/indoor video sequences at 4K resolution, ground-truth 3D human bodies\ncaptured using markerless motion capture, 3D body scans, and high resolution 3D\nscene scans. A key feature of RICH is that it also contains accurate\nvertex-level contact labels on the body. Using RICH, we train a network that\npredicts dense body-scene contacts from a single RGB image. Our key insight is\nthat regions in contact are always occluded so the network needs the ability to\nexplore the whole image for evidence. We use a transformer to learn such\nnon-local relationships and propose a new Body-Scene contact TRansfOrmer\n(BSTRO). Very few methods explore 3D contact; those that do focus on the feet\nonly, detect foot contact as a post-processing step, or infer contact from body\npose without looking at the scene. To our knowledge, BSTRO is the first method\nto directly estimate 3D body-scene contact from a single image. We demonstrate\nthat BSTRO significantly outperforms the prior art. The code and dataset are\navailable at https://rich.is.tue.mpg.de.",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Chun-Hao P. Huang",
      "Hongwei Yi",
      "Markus H\u00f6schle",
      "Matvey Safroshkin",
      "Tsvetelina Alexiadis",
      "Senya Polikovsky",
      "Daniel Scharstein",
      "Michael J. Black"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09553"
  },
  {
    "id": "arXiv:2206.09554",
    "title": "Saliency Guided Inter- and Intra-Class Relation Constraints for Weakly  Supervised Semantic Segmentation",
    "abstract": "Weakly supervised semantic segmentation with only image-level labels aims to\nreduce annotation costs for the segmentation task. Existing approaches\ngenerally leverage class activation maps (CAMs) to locate the object regions\nfor pseudo label generation. However, CAMs can only discover the most\ndiscriminative parts of objects, thus leading to inferior pixel-level pseudo\nlabels. To address this issue, we propose a saliency guided Inter- and\nIntra-Class Relation Constrained (I$^2$CRC) framework to assist the expansion\nof the activated object regions in CAMs. Specifically, we propose a saliency\nguided class-agnostic distance module to pull the intra-category features\ncloser by aligning features to their class prototypes. Further, we propose a\nclass-specific distance module to push the inter-class features apart and\nencourage the object region to have a higher activation than the background.\nBesides strengthening the capability of the classification network to activate\nmore integral object regions in CAMs, we also introduce an object guided label\nrefinement module to take a full use of both the segmentation prediction and\nthe initial labels for obtaining superior pseudo-labels. Extensive experiments\non PASCAL VOC 2012 and COCO datasets demonstrate well the effectiveness of\nI$^2$CRC over other state-of-the-art counterparts. The source codes, models,\nand data have been made available at\n\\url{https://github.com/NUST-Machine-Intelligence-Laboratory/I2CRC}.",
    "descriptor": "\nComments: TMM2022, 11 pages, 5 figures\n",
    "authors": [
      "Tao Chen",
      "Yazhou Yao",
      "Lei Zhang",
      "Qiong Wang",
      "Guo-Sen Xie",
      "Fumin Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09554"
  },
  {
    "id": "arXiv:2206.09557",
    "title": "nuQmm: Quantized MatMul for Efficient Inference of Large-Scale  Generative Language Models",
    "abstract": "The recent advance of self-supervised learning associated with the\nTransformer architecture enables natural language processing (NLP) to exhibit\nextremely low perplexity. Such powerful models demand ever-increasing model\nsize, and thus, large amounts of computations and memory footprints. In this\npaper, we propose an efficient inference framework for large-scale generative\nlanguage models. As the key to reducing model size, we quantize weights by a\nnon-uniform quantization method. Then, quantized matrix multiplications are\naccelerated by our proposed kernel, called nuQmm, which allows a wide trade-off\nbetween compression ratio and accuracy. Our proposed nuQmm reduces the latency\nof not only each GPU but also the entire inference of large LMs because a high\ncompression ratio (by low-bit quantization) mitigates the minimum required\nnumber of GPUs. We demonstrate that nuQmm can accelerate the inference speed of\nthe GPT-3 (175B) model by about 14.4 times and save energy consumption by 93%.",
    "descriptor": "\nComments: 13 pages (including 2 pages of References), 13 figures, 5 tables\n",
    "authors": [
      "Gunho Park",
      "Baeseong Park",
      "Se Jung Kwon",
      "Byeongwook Kim",
      "Youngjoo Lee",
      "Dongsoo Lee"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.09557"
  },
  {
    "id": "arXiv:2206.09563",
    "title": "DASH: Distributed Adaptive Sequencing Heuristic for Submodular  Maximization",
    "abstract": "The development of parallelizable algorithms for monotone, submodular\nmaximization subject to cardinality constraint (SMCC) has resulted in two\nseparate research directions: centralized algorithms with low adaptive\ncomplexity, which require random access to the entire dataset; and distributed\nMapReduce (MR) model algorithms, that use a small number of MR rounds of\ncomputation. Currently, no MR model algorithm is known to use sublinear number\nof adaptive rounds which limits their practical performance. We study the SMCC\nproblem in a distributed setting and present three separate MR model algorithms\nthat introduce sublinear adaptivity in a distributed setup. Our primary\nalgorithm, DASH achieves an approximation of $\\frac{1}{2}(1-1/e-\\varepsilon)$\nusing one MR round, while its multi-round variant METADASH enables MR model\nalgorithms to be run on large cardinality constraints that were previously not\npossible. The two additional algorithms, T-DASH and G-DASH provide an improved\nratio of ($\\frac{3}{8}-\\varepsilon$) and ($1-1/e-\\varepsilon$) respectively\nusing one and $(1/\\varepsilon)$ MR rounds . All our proposed algorithms have\nsublinear adaptive complexity and we provide extensive empirical evidence to\nestablish: DASH is orders of magnitude faster than the state-of-the-art\ndistributed algorithms while producing nearly identical solution values; and\nvalidate the versatility of DASH in obtaining feasible solutions on both\ncentralized and distributed data.",
    "descriptor": "",
    "authors": [
      "Tonmoy Dey",
      "Yixin Chen",
      "Alan Kuhnle"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09563"
  },
  {
    "id": "arXiv:2206.09564",
    "title": "A Novel Long-term Iterative Mining Scheme for Video Salient Object  Detection",
    "abstract": "The existing state-of-the-art (SOTA) video salient object detection (VSOD)\nmodels have widely followed short-term methodology, which dynamically\ndetermines the balance between spatial and temporal saliency fusion by solely\nconsidering the current consecutive limited frames. However, the short-term\nmethodology has one critical limitation, which conflicts with the real\nmechanism of our visual system -- a typical long-term methodology. As a result,\nfailure cases keep showing up in the results of the current SOTA models, and\nthe short-term methodology becomes the major technical bottleneck. To solve\nthis problem, this paper proposes a novel VSOD approach, which performs VSOD in\na complete long-term way. Our approach converts the sequential VSOD, a\nsequential task, to a data mining problem, i.e., decomposing the input video\nsequence to object proposals in advance and then mining salient object\nproposals as much as possible in an easy-to-hard way. Since all object\nproposals are simultaneously available, the proposed approach is a complete\nlong-term approach, which can alleviate some difficulties rooted in\nconventional short-term approaches. In addition, we devised an online updating\nscheme that can grasp the most representative and trustworthy pattern profile\nof the salient objects, outputting framewise saliency maps with rich details\nand smoothing both spatially and temporally. The proposed approach outperforms\nalmost all SOTA models on five widely used benchmark datasets.",
    "descriptor": "",
    "authors": [
      "Chenglizhao Chen",
      "Hengsen Wang",
      "Yuming Fang",
      "Chong Peng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09564"
  },
  {
    "id": "arXiv:2206.09567",
    "title": "Two-Dimensional Weisfeiler-Lehman Graph Neural Networks for Link  Prediction",
    "abstract": "Link prediction is one important application of graph neural networks (GNNs).\nMost existing GNNs for link prediction are based on one-dimensional\nWeisfeiler-Lehman (1-WL) test. 1-WL-GNNs first compute node representations by\niteratively passing neighboring node features to the center, and then obtain\nlink representations by aggregating the pairwise node representations. As\npointed out by previous works, this two-step procedure results in low\ndiscriminating power, as 1-WL-GNNs by nature learn node-level representations\ninstead of link-level. In this paper, we study a completely different approach\nwhich can directly obtain node pair (link) representations based on\n\\textit{two-dimensional Weisfeiler-Lehman (2-WL) tests}. 2-WL tests directly\nuse links (2-tuples) as message passing units instead of nodes, and thus can\ndirectly obtain link representations. We theoretically analyze the expressive\npower of 2-WL tests to discriminate non-isomorphic links, and prove their\nsuperior link discriminating power than 1-WL. Based on different 2-WL variants,\nwe propose a series of novel 2-WL-GNN models for link prediction. Experiments\non a wide range of real-world datasets demonstrate their competitive\nperformance to state-of-the-art baselines and superiority over plain 1-WL-GNNs.",
    "descriptor": "",
    "authors": [
      "Yang Hu",
      "Xiyuan Wang",
      "Zhouchen Lin",
      "Pan Li",
      "Muhan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09567"
  },
  {
    "id": "arXiv:2206.09568",
    "title": "Monolithic parabolic regularization of the MHD equations and entropy  principles",
    "abstract": "We show at the PDE level that the monolithic parabolic regularization of the\nequations of ideal magnetohydrodynamics (MHD) is compatible with all the\ngeneralized entropies, fulfills the minimum entropy principle, and preserves\nthe positivity of density and internal energy. We then numerically investigate\nthis regularization for the MHD equations using continuous finite elements in\nspace and explicit strong stability preserving Runge-Kuta methods in time. The\nartificial viscosity coefficient of the regularization term is constructed to\nbe proportional to the entropy residual of MHD. It is shown that the method has\na high order of accuracy for smooth problems and captures strong shocks and\ndiscontinuities accurately for non-smooth problems.",
    "descriptor": "",
    "authors": [
      "Tuan Anh Dao",
      "Murtazo Nazarov"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.09568"
  },
  {
    "id": "arXiv:2206.09569",
    "title": "Shuffle Gaussian Mechanism for Differential Privacy",
    "abstract": "We study Gaussian mechanism in the shuffle model of differential privacy\n(DP). Particularly, we characterize the mechanism's R\\'enyi differential\nprivacy (RDP), showing that it is of the form: $$ \\epsilon(\\lambda) \\leq\n\\frac{1}{\\lambda-1}\\log\\left(\\frac{e^{-\\lambda/2\\sigma^2}}{n^\\lambda}\\sum_{\\substack{k_1+\\dotsc+k_n=\\lambda;\\\\k_1,\\dotsc,k_n\\geq\n0}}\\binom{\\lambda!}{k_1,\\dotsc,k_n}e^{\\sum_{i=1}^nk_i^2/2\\sigma^2}\\right) $$ We\nfurther prove that the RDP is strictly upper-bounded by the Gaussian RDP\nwithout shuffling. The shuffle Gaussian RDP is advantageous in composing\nmultiple DP mechanisms, where we demonstrate its improvement over the\nstate-of-the-art approximate DP composition theorems in privacy guarantees of\nthe shuffle model. Moreover, we extend our study to the subsampled shuffle\nmechanism and the recently proposed shuffled check-in mechanism, which are\nprotocols geared towards distributed/federated learning. Finally, an empirical\nstudy of these mechanisms is given to demonstrate the efficacy of employing\nshuffle Gaussian mechanism under the distributed learning framework to\nguarantee rigorous user privacy.",
    "descriptor": "\nComments: The source code of our implementation is available at this http URL\n",
    "authors": [
      "Seng Pei Liew",
      "Tsubasa Takahashi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.09569"
  },
  {
    "id": "arXiv:2206.09570",
    "title": "Guardian Angel: A Novel Walking Aid for the Visually Impaired",
    "abstract": "This work introduces Guardian Angel, an Android App that assists visually\nimpaired people to avoid danger in complex traffic environment. The system,\nconsisting of object detection by pretrained YOLO model, distance estimation\nand moving direction estimation, provides information about surrounding\nvehicles and alarms users of potential danger without expensive special purpose\ndevice. With an experiment of 8 subjects, we corroborate that in terms of\nsatisfaction score in pedestrian-crossing experiment with the assistance of our\nApp using a smartphone is better than when without under 99% confidence level.\nThe time needed to cross a road is shorter on average with the assistance of\nour system, however, not reaching significant difference by our experiment. The\nApp has been released in Google Play Store, open to the public for free.",
    "descriptor": "\nComments: 2 pages, 1 figure\n",
    "authors": [
      "Ko-Wei Tai",
      "HuaYen Lee",
      "Hsin-Huei Chen",
      "Jeng-Sheng Yeh",
      "Ming Ouhyoung"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09570"
  },
  {
    "id": "arXiv:2206.09572",
    "title": "Efficient Decoders for Short Block Length Codes in 6G URLLC",
    "abstract": "This paper reviews the potential channel decoding techniques for\nultra-reliable low-latency communications (URLLC). URLLC is renowned for its\nstringent requirements including ultra-reliability, low end-to-end transmission\nlatency, and packet-size flexibility. These requirements exacerbate the\ndifficulty of the physical-layer design, particularly for the channel coding\nand decoding schemes. To satisfy the requirements of URLLC, decoders must\nexhibit superior error-rate performance, low decoding complexity, and\nuniversality to accommodate various coding schemes. This paper provides a\ncomprehensive review and comparison of different candidate decoding techniques\nfor URLLC in terms of their error-rate performance and computational complexity\nfor structured and random short codes. We further make recommendations of the\ndecoder selections and suggest several potential research directions.",
    "descriptor": "\nComments: 6 figures\n",
    "authors": [
      "Chentao Yue",
      "Vera Miloslavskaya",
      "Mahyar Shirvanimoghaddam",
      "Branka Vucetic",
      "Yonghui Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.09572"
  },
  {
    "id": "arXiv:2206.09575",
    "title": "C-SENN: Contrastive Self-Explaining Neural Network",
    "abstract": "In this study, we use a self-explaining neural network (SENN), which learns\nunsupervised concepts, to acquire concepts that are easy for people to\nunderstand automatically. In concept learning, the hidden layer retains\nverbalizable features relevant to the output, which is crucial when adapting to\nreal-world environments where explanations are required. However, it is known\nthat the interpretability of concepts output by SENN is reduced in general\nsettings, such as autonomous driving scenarios. Thus, this study combines\ncontrastive learning with concept learning to improve the readability of\nconcepts and the accuracy of tasks. We call this model Contrastive\nSelf-Explaining Neural Network (C-SENN).",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Yoshihide Sawada",
      "Keigo Nakamura"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09575"
  },
  {
    "id": "arXiv:2206.09576",
    "title": "FedSSO: A Federated Server-Side Second-Order Optimization Algorithm",
    "abstract": "In this work, we propose FedSSO, a server-side second-order optimization\nmethod for federated learning (FL). In contrast to previous works in this\ndirection, we employ a server-side approximation for the Quasi-Newton method\nwithout requiring any training data from the clients. In this way, we not only\nshift the computation burden from clients to server, but also eliminate the\nadditional communication for second-order updates between clients and server\nentirely. We provide theoretical guarantee for convergence of our novel method,\nand empirically demonstrate our fast convergence and communication savings in\nboth convex and non-convex settings.",
    "descriptor": "",
    "authors": [
      "Xin Ma",
      "Renyi Bao",
      "Jinpeng Jiang",
      "Yang Liu",
      "Arthur Jiang",
      "Jun Yan",
      "Xin Liu",
      "Zhisong Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.09576"
  },
  {
    "id": "arXiv:2206.09578",
    "title": "Performance-Oriented Design for Intelligent Reflecting Surface Assisted  Federated Learning",
    "abstract": "To efficiently exploit the massive raw data that is pervading generated at\nmobile edge networks, federated learning (FL) has emerged as a promising\ndistributed learning technique that was regarded as a substitute for\ncentralized learning operations. By collaboratively training a shared learning\nmodel at edge devices, the raw data transmission and storage are bypassed via\nthe local computed parameters/gradients exchange in FL. Hence, FL can overcome\nhigh communication latency and privacy issues. While the high dimensionality in\niterative updates (millions of parameters/gradients may be included in the\nmodel training) still conflicts with the scarcity of communication resources.\nOver-the-air computation (AirComp) has come into the spotlight recently which\nprofitably leverages the inherent superposition property of wireless channels\nto perform efficient model aggeration. However, the model aggregation accuracy\nis still severely damaged by the unfavorable wireless propagation channels. In\nthis paper, we harness the intelligent reflecting surface (IRS) to program the\nwireless channel, thus acquiring a satisfying learning performance.\nSpecifically, a performance-oriented design scheme that directly minimizes the\noptimality gap of the loss function is proposed to accelerate the convergence\nof AirComp based FL. Firstly, we analyze the convergence behavior of the FL\nprocedure. Then, both offline and online design approaches are proposed based\non the obtained optimality gap. We adopt the block coordinate descent (BCD)\nmethod to tackle the highly-intractable problem. Simulation results demonstrate\nthat such a performance-oriented design strategy can achieve higher test\naccuracy than the conventional isolated mean square error (MSE) minimization\napproach in FL.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication\n",
    "authors": [
      "Yapeng Zhao",
      "Qingqing Wu",
      "Wen Chen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.09578"
  },
  {
    "id": "arXiv:2206.09581",
    "title": "Explicit and implicit models in infrared and visible image fusion",
    "abstract": "Infrared and visible images, as multi-modal image pairs, show significant\ndifferences in the expression of the same scene. The image fusion task is faced\nwith two problems: one is to maintain the unique features between different\nmodalities, and the other is to maintain features at various levels like local\nand global features. This paper discusses the limitations of deep learning\nmodels in image fusion and the corresponding optimization strategies. Based on\nartificially designed structures and constraints, we divide models into\nexplicit models, and implicit models that adaptively learn high-level features\nor can establish global pixel associations. Ten models for comparison\nexperiments on 21 test sets were screened. The qualitative and quantitative\nresults show that the implicit models have more comprehensive ability to learn\nimage features. At the same time, the stability of them needs to be improved.\nAiming at the advantages and limitations to be solved by existing algorithms,\nwe discuss the main problems of multi-modal image fusion and future research\ndirections.",
    "descriptor": "\nComments: 8 pages, 5 figures, 2 tables\n",
    "authors": [
      "Zixuan Wang",
      "Bin Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09581"
  },
  {
    "id": "arXiv:2206.09582",
    "title": "Analysis of Electric Vehicle Charging Station Usage and Profitability in  Germany based on Empirical Data",
    "abstract": "Electric vehicles are booming and with them the required public charging\nstations. Knowing how charging stations are used is crucial for operators of\nthe charging stations themselves, navigation systems, electricity grids, and\nmany more. Given that there are now 2.5 as many vehicles per charging station\ncompared to 2017, the system needs to allocate charging points intelligently\nand efficiently. This paper presents representative data on energy consumption,\narrival times, occupation, and profitability of charging stations in Germany by\ncombining usage data of 27,800 installations. Charging happens mainly during\nthe day and on weekdays for AC charging stations while DC fast-charging\nstations are more popular on the weekend. Fast-chargers service approximately 3\ntimes as many vehicles per connection point while also being substantially more\nprofitable due to higher achieved margins. For AC chargers, up to 20 kWh of\nenergy are charged in an average charge event while DC fast-chargers supply\napproximately 40 kWh.",
    "descriptor": "\nComments: Paper currently under review. Please check if full paper is available before citing. Accompanying data will be published alongside the full paper\n",
    "authors": [
      "Christopher Hecht",
      "Jan Figgener",
      "Dirk Uwe Sauer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.09582"
  },
  {
    "id": "arXiv:2206.09585",
    "title": "5th Place Solution for YouTube-VOS Challenge 2022: Video Object  Segmentation",
    "abstract": "Video object segmentation (VOS) has made significant progress with the rise\nof deep learning. However, there still exist some thorny problems, for example,\nsimilar objects are easily confused and tiny objects are difficult to be found.\nTo solve these problems and further improve the performance of VOS, we propose\na simple yet effective solution for this task. In the solution, we first\nanalyze the distribution of the Youtube-VOS dataset and supplement the dataset\nby introducing public static and video segmentation datasets. Then, we improve\nthree network architectures with different characteristics and train several\nnetworks to learn the different characteristics of objects in videos. After\nthat, we use a simple way to integrate all results to ensure that different\nmodels complement each other. Finally, subtle post-processing is carried out to\nensure accurate video object segmentation with precise boundaries. Extensive\nexperiments on Youtube-VOS dataset show that the proposed solution achieves the\nstate-of-the-art performance with an 86.1% overall score on the YouTube-VOS\n2022 test set, which is 5th place on the video object segmentation track of the\nYoutube-VOS Challenge 2022.",
    "descriptor": "\nComments: 5th Place Solution for Video Object Segmentation in the 4th Large-scale Video Object Segmentation Challenge, CVPR 2022 Workshop\n",
    "authors": [
      "Wangwang Yang",
      "Jinming Su",
      "Yiting Duan",
      "Tingyi Guo",
      "Junfeng Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.09585"
  },
  {
    "id": "arXiv:2206.09590",
    "title": "From Multi-agent to Multi-robot: A Scalable Training and Evaluation  Platform for Multi-robot Reinforcement Learning",
    "abstract": "Multi-agent reinforcement learning (MARL) has been gaining extensive\nattention from academia and industries in the past few decades. One of the\nfundamental problems in MARL is how to evaluate different approaches\ncomprehensively. Most existing MARL methods are evaluated in either video games\nor simplistic simulated scenarios. It remains unknown how these methods perform\nin real-world scenarios, especially multi-robot systems. This paper introduces\na scalable emulation platform for multi-robot reinforcement learning (MRRL)\ncalled SMART to meet this need. Precisely, SMART consists of two components: 1)\na simulation environment that provides a variety of complex interaction\nscenarios for training and 2) a real-world multi-robot system for realistic\nperformance evaluation. Besides, SMART offers agent-environment APIs that are\nplug-and-play for algorithm implementation. To illustrate the practicality of\nour platform, we conduct a case study on the cooperative driving lane change\nscenario. Building off the case study, we summarize several unique challenges\nof MRRL, which are rarely considered previously. Finally, we open-source the\nsimulation environments, associated benchmark tasks, and state-of-the-art\nbaselines to encourage and empower MRRL research.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Zhiuxan Liang",
      "Jiannong Cao",
      "Shan Jiang",
      "Divya Saxena",
      "Jinlin Chen",
      "Huafeng Xu"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.09590"
  },
  {
    "id": "arXiv:2206.09591",
    "title": "Domain-Adaptive Text Classification with Structured Knowledge from  Unlabeled Data",
    "abstract": "Domain adaptive text classification is a challenging problem for the\nlarge-scale pretrained language models because they often require expensive\nadditional labeled data to adapt to new domains. Existing works usually fails\nto leverage the implicit relationships among words across domains. In this\npaper, we propose a novel method, called Domain Adaptation with Structured\nKnowledge (DASK), to enhance domain adaptation by exploiting word-level\nsemantic relationships. DASK first builds a knowledge graph to capture the\nrelationship between pivot terms (domain-independent words) and non-pivot terms\nin the target domain. Then during training, DASK injects pivot-related\nknowledge graph information into source domain texts. For the downstream task,\nthese knowledge-injected texts are fed into a BERT variant capable of\nprocessing knowledge-injected textual data. Thanks to the knowledge injection,\nour model learns domain-invariant features for non-pivots according to their\nrelationships with pivots. DASK ensures the pivots to have domain-invariant\nbehaviors by dynamically inferring via the polarity scores of candidate pivots\nduring training with pseudo-labels. We validate DASK on a wide range of\ncross-domain sentiment classification tasks and observe up to 2.9% absolute\nperformance improvement over baselines for 20 different domain pairs. Code will\nbe made available at https://github.com/hikaru-nara/DASK.",
    "descriptor": "",
    "authors": [
      "Tian Li",
      "Xiang Chen",
      "Zhen Dong",
      "Weijiang Yu",
      "Yijun Yan",
      "Kurt Keutzer",
      "Shanghang Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.09591"
  },
  {
    "id": "arXiv:2206.09592",
    "title": "DALL-E for Detection: Language-driven Context Image Synthesis for Object  Detection",
    "abstract": "Object cut-and-paste has become a promising approach to efficiently generate\nlarge sets of labeled training data. It involves compositing foreground object\nmasks onto background images. The background images, when congruent with the\nobjects, provide helpful context information for training object recognition\nmodels. While the approach can easily generate large labeled data, finding\ncongruent context images for downstream tasks has remained an elusive problem.\nIn this work, we propose a new paradigm for automatic context image generation\nat scale. At the core of our approach lies utilizing an interplay between\nlanguage description of context and language-driven image generation. Language\ndescription of a context is provided by applying an image captioning method on\na small set of images representing the context. These language descriptions are\nthen used to generate diverse sets of context images using the language-based\nDALL-E image generation framework. These are then composited with objects to\nprovide an augmented training set for a classifier. We demonstrate the\nadvantages of our approach over the prior context image generation approaches\non four object detection datasets. Furthermore, we also highlight the\ncompositional nature of our data generation approach on out-of-distribution and\nzero-shot data generation scenarios.",
    "descriptor": "\nComments: 28 pages (including appendix), 13 figures\n",
    "authors": [
      "Yunhao Ge",
      "Jiashu Xu",
      "Brian Nlong Zhao",
      "Laurent Itti",
      "Vibhav Vineet"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09592"
  },
  {
    "id": "arXiv:2206.09596",
    "title": "Efficient and Flexible Sublabel-Accurate Energy Minimization",
    "abstract": "We address the problem of minimizing a class of energy functions consisting\nof data and smoothness terms that commonly occur in machine learning, computer\nvision, and pattern recognition. While discrete optimization methods are able\nto give theoretical optimality guarantees, they can only handle a finite number\nof labels and therefore suffer from label discretization bias. Existing\ncontinuous optimization methods can find sublabel-accurate solutions, but they\nare not efficient for large label spaces. In this work, we propose an efficient\nsublabel-accurate method that utilizes the best properties of both continuous\nand discrete models. We separate the problem into two sequential steps: (i)\nglobal discrete optimization for selecting the label range, and (ii) efficient\ncontinuous sublabel-accurate local refinement of a convex approximation of the\nenergy function in the chosen range. Doing so allows us to achieve a boost in\ntime and memory efficiency while practically keeping the accuracy at the same\nlevel as continuous convex relaxation methods, and in addition, providing\ntheoretical optimality guarantees at the level of discrete methods. Finally, we\nshow the flexibility of the proposed approach to general pairwise smoothness\nterms, so that it is applicable to a wide range of regularizations. Experiments\non the illustrating example of the image denoising problem demonstrate the\nproperties of the proposed method. The code reproducing experiments is\navailable at\n\\url{https://github.com/nurlanov-zh/sublabel-accurate-alpha-expansion}.",
    "descriptor": "\nComments: To be published at ICPR 2022, Copyright 2022 IEEE\n",
    "authors": [
      "Zhakshylyk Nurlanov",
      "Daniel Cremers",
      "Florian Bernard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.09596"
  },
  {
    "id": "arXiv:2206.09597",
    "title": "Winning the CVPR'2022 AQTC Challenge: A Two-stage Function-centric  Approach",
    "abstract": "Affordance-centric Question-driven Task Completion for Egocentric\nAssistant(AQTC) is a novel task which helps AI assistant learn from\ninstructional videos and scripts and guide the user step-by-step. In this\npaper, we deal with the AQTC via a two-stage Function-centric approach, which\nconsists of Question2Function Module to ground the question with the related\nfunction and Function2Answer Module to predict the action based on the\nhistorical steps. We evaluated several possible solutions in each module and\nobtained significant gains compared to the given baselines. Our code is\navailable at \\url{https://github.com/starsholic/LOVEU-CVPR22-AQTC}.",
    "descriptor": "",
    "authors": [
      "Shiwei Wu",
      "Weidong He",
      "Tong Xu",
      "Hao Wang",
      "Enhong Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2206.09597"
  },
  {
    "id": "arXiv:2206.09599",
    "title": "Examining the Robustness of Spiking Neural Networks on Non-ideal  Memristive Crossbars",
    "abstract": "Spiking Neural Networks (SNNs) have recently emerged as the low-power\nalternative to Artificial Neural Networks (ANNs) owing to their asynchronous,\nsparse, and binary information processing. To improve the energy-efficiency and\nthroughput, SNNs can be implemented on memristive crossbars where\nMultiply-and-Accumulate (MAC) operations are realized in the analog domain\nusing emerging Non-Volatile-Memory (NVM) devices. Despite the compatibility of\nSNNs with memristive crossbars, there is little attention to study on the\neffect of intrinsic crossbar non-idealities and stochasticity on the\nperformance of SNNs. In this paper, we conduct a comprehensive analysis of the\nrobustness of SNNs on non-ideal crossbars. We examine SNNs trained via learning\nalgorithms such as, surrogate gradient and ANN-SNN conversion. Our results show\nthat repetitive crossbar computations across multiple time-steps induce error\naccumulation, resulting in a huge performance drop during SNN inference. We\nfurther show that SNNs trained with a smaller number of time-steps achieve\nbetter accuracy when deployed on memristive crossbars.",
    "descriptor": "\nComments: Accepted in ACM/IEEE International Symposium on Low Power Electronics and Design (ISLPED), 2022\n",
    "authors": [
      "Abhiroop Bhattacharjee",
      "Youngeun Kim",
      "Abhishek Moitra",
      "Priyadarshini Panda"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.09599"
  },
  {
    "id": "arXiv:2206.09600",
    "title": "SPBERTQA: A Two-Stage Question Answering System Based on Sentence  Transformers for Medical Texts",
    "abstract": "Question answering (QA) systems have gained explosive attention in recent\nyears. However, QA tasks in Vietnamese do not have many datasets.\nSignificantly, there is mostly no dataset in the medical domain. Therefore, we\nbuilt a Vietnamese Healthcare Question Answering dataset (ViHealthQA),\nincluding 10,015 question-answer passage pairs for this task, in which\nquestions from health-interested users were asked on prestigious health\nwebsites and answers from highly qualified experts. This paper proposes a\ntwo-stage QA system based on Sentence-BERT (SBERT) using multiple negatives\nranking (MNR) loss combined with BM25. Then, we conduct diverse experiments\nwith many bag-of-words models to assess our system's performance. With the\nobtained results, this system achieves better performance than traditional\nmethods.",
    "descriptor": "",
    "authors": [
      "Nhung Thi-Hong Nguyen",
      "Phuong Phan-Dieu Ha",
      "Luan Thanh Nguyen",
      "Kiet Van Nguyen",
      "Ngan Luu-Thuy Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.09600"
  },
  {
    "id": "arXiv:2206.09603",
    "title": "Constrained Reinforcement Learning for Robotics via Scenario-Based  Programming",
    "abstract": "Deep reinforcement learning (DRL) has achieved groundbreaking successes in a\nwide variety of robotic applications. A natural consequence is the adoption of\nthis paradigm for safety-critical tasks, where human safety and expensive\nhardware can be involved. In this context, it is crucial to optimize the\nperformance of DRL-based agents while providing guarantees about their\nbehavior. This paper presents a novel technique for incorporating domain-expert\nknowledge into a constrained DRL training loop. Our technique exploits the\nscenario-based programming paradigm, which is designed to allow specifying such\nknowledge in a simple and intuitive way. We validated our method on the popular\nrobotic mapless navigation problem, in simulation, and on the actual platform.\nOur experiments demonstrate that using our approach to leverage expert\nknowledge dramatically improves the safety and the performance of the agent.",
    "descriptor": "",
    "authors": [
      "Davide Corsi",
      "Raz Yerushalmi",
      "Guy Amir",
      "Alessandro Farinelli",
      "David Harel",
      "Guy Katz"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09603"
  },
  {
    "id": "arXiv:2206.09604",
    "title": "Distortion-Aware Network Pruning and Feature Reuse for Real-time Video  Segmentation",
    "abstract": "Real-time video segmentation is a crucial task for many real-world\napplications such as autonomous driving and robot control. Since\nstate-of-the-art semantic segmentation models are often too heavy for real-time\napplications despite their impressive performance, researchers have proposed\nlightweight architectures with speed-accuracy trade-offs, achieving real-time\nspeed at the expense of reduced accuracy. In this paper, we propose a novel\nframework to speed up any architecture with skip-connections for real-time\nvision tasks by exploiting the temporal locality in videos. Specifically, at\nthe arrival of each frame, we transform the features from the previous frame to\nreuse them at specific spatial bins. We then perform partial computation of the\nbackbone network on the regions of the current frame that captures temporal\ndifferences between the current and previous frame. This is done by dynamically\ndropping out residual blocks using a gating mechanism which decides which\nblocks to drop based on inter-frame distortion. We validate our\nSpatial-Temporal Mask Generator (STMG) on video semantic segmentation\nbenchmarks with multiple backbone networks, and show that our method largely\nspeeds up inference with minimal loss of accuracy.",
    "descriptor": "",
    "authors": [
      "Hyunsu Rhee",
      "Dongchan Min",
      "Sunil Hwang",
      "Bruno Andreis",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.09604"
  },
  {
    "id": "arXiv:2206.09606",
    "title": "Interpretable machine learning optimization (InterOpt) for operational  parameters: a case study of highly-efficient shale gas development",
    "abstract": "An algorithm named InterOpt for optimizing operational parameters is proposed\nbased on interpretable machine learning, and is demonstrated via optimization\nof shale gas development. InterOpt consists of three parts: a neural network is\nused to construct an emulator of the actual drilling and hydraulic fracturing\nprocess in the vector space (i.e., virtual environment); the Sharpley value\nmethod in interpretable machine learning is applied to analyzing the impact of\ngeological and operational parameters in each well (i.e., single well feature\nimpact analysis); and ensemble randomized maximum likelihood (EnRML) is\nconducted to optimize the operational parameters to comprehensively improve the\nefficiency of shale gas development and reduce the average cost. In the\nexperiment, InterOpt provides different drilling and fracturing plans for each\nwell according to its specific geological conditions, and finally achieved an\naverage cost reduction of 9.7% for a case study with 104 wells.",
    "descriptor": "\nComments: 29 pages, 12 figures, 3 tables, 5 appendices\n",
    "authors": [
      "Yuntian Chen",
      "Dongxiao Zhang",
      "Qun Zhao",
      "Dexun Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09606"
  },
  {
    "id": "arXiv:2206.09607",
    "title": "NLOS Ranging Mitigation with Neural Network Model for UWB Localization",
    "abstract": "Localization of robots is vital for navigation and path planning, such as in\ncases where a map of the environment is needed. Ultra-Wideband (UWB) for indoor\nlocation systems has been gaining popularity over the years with the\nintroduction of low-cost UWB modules providing centimetre-level accuracy.\nHowever, in the presence of obstacles in the environment, Non-Line-Of-Sight\n(NLOS) measurements from the UWB will produce inaccurate results. As low-cost\nUWB devices do not provide channel information, we propose an approach to\ndecide if a measurement is within Line-Of-Sight (LOS) or not by using some\nsignal strength information provided by low-cost UWB modules through a Neural\nNetwork (NN) model. The result of this model is the probability of a ranging\nmeasurement being LOS which was used for localization through the\nWeighted-Least-Square (WLS) method. Our approach improves localization accuracy\nby 16.93% on the lobby testing data and 27.97% on the corridor testing data\nusing the NN model trained with all extracted inputs from the office training\ndata.",
    "descriptor": "\nComments: Accepted by 2020 IEEE International Conference on Automation Science and Engineering (CASE)\n",
    "authors": [
      "Muhammad Shalihan",
      "Ran Liu",
      "Chau Yuen"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.09607"
  },
  {
    "id": "arXiv:2206.09613",
    "title": "Keep on Running! An Analysis of Running Tracking Application Features  and their Potential Impact on Recreational Runner's Intrinsic Motivation",
    "abstract": "Physical activity is known to help improve and maintain one's health. In\nparticular, recreational running has become increasingly popular in recent\nyears. Yet, lack of motivation often interferes with people's routines and thus\nmay prohibit regular uptake. This is where running tracking applications are\nfrequently used to overcome one's weaker self and offer support. While\ntechnology artifacts, such as sport watches or running applications, usually\ncount as extrinsic drivers, they can also impact one's intrinsic motivation\nlevels. The aim of this study was thus to investigate upon the motivational\nimpact of distinct features found within applications specifically used for\nrunning. Focusing on the 22 most famous running applications, a\nsemi-structured, problem-centered interview study with $n=15$ recreational\nrunners showed that intrinsic motivation is stimulated from diverting runners,\naiding them in their goal setting, decreasing their efforts, improving and\nsharing their run performance, allowing them to receive acknowledgements, as\nwell as providing them with guidance, information, and an overall variety in\ntheir training routines.",
    "descriptor": "\nComments: 16 pages, 4 figures, conference\n",
    "authors": [
      "Dorothea Gute",
      "Stephan Schl\u00f6gl",
      "Aleksander Groth"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.09613"
  },
  {
    "id": "arXiv:2206.09616",
    "title": "Revisiting lp-constrained Softmax Loss: A Comprehensive Study",
    "abstract": "Normalization is a vital process for any machine learning task as it controls\nthe properties of data and affects model performance at large. The impact of\nparticular forms of normalization, however, has so far been investigated in\nlimited domain-specific classification tasks and not in a general fashion.\nMotivated by the lack of such a comprehensive study, in this paper we\ninvestigate the performance of lp-constrained softmax loss classifiers across\ndifferent norm orders, magnitudes, and data dimensions in both proof-of-concept\nclassification problems and real-world popular image classification tasks.\nExperimental results suggest collectively that lp-constrained softmax loss\nclassifiers not only can achieve more accurate classification results but, at\nthe same time, appear to be less prone to overfitting. The core findings hold\nacross the three popular deep learning architectures tested and eight datasets\nexamined, and suggest that lp normalization is a recommended data\nrepresentation practice for image classification in terms of performance and\nconvergence, and against overfitting.",
    "descriptor": "",
    "authors": [
      "Chintan Trivedi",
      "Konstantinos Makantasis",
      "Antonios Liapis",
      "Georgios N. Yannakakis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09616"
  },
  {
    "id": "arXiv:2206.09617",
    "title": "Time integration of finite element models with nonlinear frequency  dependencies",
    "abstract": "The analysis of sound and vibrations is often performed in the frequency\ndomain, implying the assumption of steady-state behaviour and time-harmonic\nexcitation. External excitations, however, may be transient rather than\ntime-harmonic, requiring time-domain analysis. Some material properties, e.g.\\\noften used to represent for damping treatments, are still described in the\nfrequency domain, which complicates simulation in time. In this paper, we\npresent a method for the linearization of finite element models with nonlinear\nfrequency dependencies. The linearization relies on the rational approximation\nof the finite element matrices by the AAA method. We introduce the Extended AAA\nmethod, which is classical AAA combined with a degree two polynomial term to\ncapture the second order behaviour of the models. A filtering step is added for\nremoving unstable poles.",
    "descriptor": "",
    "authors": [
      "Elke Deckers",
      "Stijn Jonckheere",
      "Karl Meerbergen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.09617"
  },
  {
    "id": "arXiv:2206.09618",
    "title": "A reduced order model for domain decompositions with non-conforming  interfaces",
    "abstract": "In this paper we propose a reduced order modeling strategy for two-way\nDirichlet-Neumann parametric coupled problems solved with domain-decomposition\n(DD) sub-structuring methods. We split the original coupled differential\nproblem into two sub-problems with Dirichlet and Neumann interface conditions,\nrespectively. After discretization by (e.g.) the finite element method, the\nfull-order model (FOM) is solved by Dirichlet-Neumann iterations between the\ntwo sub-problems until interface convergence is reached. We, then, apply the\nreduced basis (RB) method to obtain a low-dimensional representation of the\nsolution of each sub-problem. Furthermore, we use the discrete empirical\ninterpolation method (DEIM) applied at the interface level to achieve a fully\nreduced-order representation of the DD techniques implemented. To deal with\ninterface data when non-conforming FE interface discretizations are considered,\nwe employ the INTERNODES method combined with the interface DEIM reduction. The\nreduced-order model (ROM) is then solved by sub-iterating between the two\nreduced-order sub-problems until convergence of the approximated high-fidelity\ninterface solutions. The ROM scheme is numerically verified on both steady and\nunsteady coupled problems, in the case of non-conforming FE interfaces.",
    "descriptor": "\nComments: 24 pages, 11 figures, 2 tables, 4 algorithms\n",
    "authors": [
      "Elena Zappon",
      "Andrea Manzoni",
      "Paola Gervasio",
      "Alfio Quarteroni"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.09618"
  },
  {
    "id": "arXiv:2206.09619",
    "title": "Analyzing B\u00fcchi Automata with Graph Neural Networks",
    "abstract": "B\\\"uchi Automata on infinite words present many interesting problems and are\nused frequently in program verification and model checking. A lot of these\nproblems on B\\\"uchi automata are computationally hard, raising the question if\na learning-based data-driven analysis might be more efficient than using\ntraditional algorithms. Since B\\\"uchi automata can be represented by graphs,\ngraph neural networks are a natural choice for such a learning-based analysis.\nIn this paper, we demonstrate how graph neural networks can be used to reliably\npredict basic properties of B\\\"uchi automata when trained on automatically\ngenerated random automata datasets.",
    "descriptor": "\nComments: Accepted for presentation at Workshop LearnAut 2022 (this https URL)\n",
    "authors": [
      "Christophe Stammet",
      "Prisca Dotti",
      "Ulrich Ultes-Nitsche",
      "Andreas Fischer"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09619"
  },
  {
    "id": "arXiv:2206.09620",
    "title": "Asymptotic Nash Equilibrium for the $M$-ary Sequential Adversarial  Hypothesis Testing Game",
    "abstract": "In this paper, we consider a novel $M$-ary sequential hypothesis testing\nproblem in which an adversary is present and perturbs the distributions of the\nsamples before the decision maker observes them. This problem is formulated as\na sequential adversarial hypothesis testing game played between the decision\nmaker and the adversary. This game is a zero-sum and strategic one. We assume\nthe adversary is active under \\emph{all} hypotheses and knows the underlying\ndistribution of observed samples. We adopt this framework as it is the\nworst-case scenario from the perspective of the decision maker. The goal of the\ndecision maker is to minimize the expectation of the stopping time to ensure\nthat the test is as efficient as possible; the adversary's goal is, instead, to\nmaximize the stopping time. We derive a pair of strategies under which the\nasymptotic Nash equilibrium of the game is attained. We also consider the case\nin which the adversary is not aware of the underlying hypothesis and hence is\nconstrained to apply the same strategy regardless of which hypothesis is in\neffect. Numerical results corroborate our theoretical findings.",
    "descriptor": "\nComments: The paper was presented in part at the 2022 International Symposium on Information Theory (ISIT). It has been submitted to IEEE Transactions on Information Forensics and Security\n",
    "authors": [
      "Jiachun Pan",
      "Yonglong Li",
      "Vincent Y. F. Tan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.09620"
  },
  {
    "id": "arXiv:2206.09623",
    "title": "MDS Codes Based Group Coded Caching in Fog Radio Access Networks",
    "abstract": "In this paper, we investigate maximum distance separable (MDS) codes based\ngroup coded caching in fog radio access networks (F-RANs). The goal is to\nminimize the average fronthaul rate under nonuniform file popularity. Firstly,\nan MDS codes and file grouping based coded placement scheme is proposed to\nprovide coded packets and allocate more cache to the most popular files\nsimultaneously. Next, a fog access point (F-AP) grouping based coded delivery\nscheme is proposed to meet the requests for files from different groups.\nFurthermore, a closed-form expression of the average fronthaul rate is derived.\nFinally, the parameters related to the proposed coded caching scheme are\noptimized to fully utilize the gains brought by MDS codes and file grouping.\nSimulation results show that our proposed scheme obtains significant\nperformance improvement over several existing caching schemes in terms of\nfronthaul rate reduction.",
    "descriptor": "\nComments: 6 pages,5 figures\n",
    "authors": [
      "Qianli Tan",
      "Yanxiang Jiang",
      "Fu-Chun Zheng",
      "Mehdi Bennis",
      "Xiaohu You"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2206.09623"
  },
  {
    "id": "arXiv:2206.09627",
    "title": "Sampling Efficient Deep Reinforcement Learning through Preference-Guided  Stochastic Exploration",
    "abstract": "Massive practical works addressed by Deep Q-network (DQN) algorithm have\nindicated that stochastic policy, despite its simplicity, is the most\nfrequently used exploration approach. However, most existing stochastic\nexploration approaches either explore new actions heuristically regardless of\nQ-values or inevitably introduce bias into the learning process to couple the\nsampling with Q-values. In this paper, we propose a novel preference-guided\n$\\epsilon$-greedy exploration algorithm that can efficiently learn the action\ndistribution in line with the landscape of Q-values for DQN without introducing\nadditional bias. Specifically, we design a dual architecture consisting of two\nbranches, one of which is a copy of DQN, namely the Q-branch. The other branch,\nwhich we call the preference branch, learns the action preference that the DQN\nimplicit follows. We theoretically prove that the policy improvement theorem\nholds for the preference-guided $\\epsilon$-greedy policy and experimentally\nshow that the inferred action preference distribution aligns with the landscape\nof corresponding Q-values. Consequently, preference-guided $\\epsilon$-greedy\nexploration motivates the DQN agent to take diverse actions, i.e., actions with\nlarger Q-values can be sampled more frequently whereas actions with smaller\nQ-values still have a chance to be explored, thus encouraging the exploration.\nWe assess the proposed method with four well-known DQN variants in nine\ndifferent environments. Extensive results confirm the superiority of our\nproposed method in terms of performance and convergence speed.\nIndex Terms- Preference-guided exploration, stochastic policy, data\nefficiency, deep reinforcement learning, deep Q-learning.",
    "descriptor": "",
    "authors": [
      "Wenhui Huang",
      "Cong Zhang",
      "Jingda Wu",
      "Xiangkun He",
      "Jie Zhang",
      "Chen Lv"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.09627"
  },
  {
    "id": "arXiv:2206.09628",
    "title": "Diversified Adversarial Attacks based on Conjugate Gradient Method",
    "abstract": "Deep learning models are vulnerable to adversarial examples, and adversarial\nattacks used to generate such examples have attracted considerable research\ninterest. Although existing methods based on the steepest descent have achieved\nhigh attack success rates, ill-conditioned problems occasionally reduce their\nperformance. To address this limitation, we utilize the conjugate gradient (CG)\nmethod, which is effective for this type of problem, and propose a novel attack\nalgorithm inspired by the CG method, named the Auto Conjugate Gradient (ACG)\nattack. The results of large-scale evaluation experiments conducted on the\nlatest robust models show that, for most models, ACG was able to find more\nadversarial examples with fewer iterations than the existing SOTA algorithm\nAuto-PGD (APGD). We investigated the difference in search performance between\nACG and APGD in terms of diversification and intensification, and define a\nmeasure called Diversity Index (DI) to quantify the degree of diversity. From\nthe analysis of the diversity using this index, we show that the more diverse\nsearch of the proposed method remarkably improves its attack success rate.",
    "descriptor": "",
    "authors": [
      "Keiichiro Yamamura",
      "Haruki Sato",
      "Nariaki Tateiwa",
      "Nozomi Hata",
      "Toru Mitsutake",
      "Issa Oe",
      "Hiroki Ishikura",
      "Katsuki Fujisawa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09628"
  },
  {
    "id": "arXiv:2206.09638",
    "title": "A Symbolic Approach for Counterfactual Explanations",
    "abstract": "In this paper titled A Symbolic Approach for Counterfactual Explanations we\npropose a novel symbolic approach to provide counterfactual explanations for a\nclassifier predictions. Contrary to most explanation approaches where the goal\nis to understand which and to what extent parts of the data helped to give a\nprediction, counterfactual explanations indicate which features must be changed\nin the data in order to change this classifier prediction. Our approach is\nsymbolic in the sense that it is based on encoding the decision function of a\nclassifier in an equivalent CNF formula. In this approach, counterfactual\nexplanations are seen as the Minimal Correction Subsets (MCS), a well-known\nconcept in knowledge base reparation. Hence, this approach takes advantage of\nthe strengths of already existing and proven solutions for the generation of\nMCS. Our preliminary experimental studies on Bayesian classifiers show the\npotential of this approach on several datasets.",
    "descriptor": "",
    "authors": [
      "Ryma Boumazouza",
      "Fahima Cheikh-Alili",
      "Bertrand Mazure",
      "Karim Tabia"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.09638"
  },
  {
    "id": "arXiv:2206.09642",
    "title": "Beyond IID: data-driven decision-making in heterogeneous environments",
    "abstract": "In this work, we study data-driven decision-making and depart from the\nclassical identically and independently distributed (i.i.d.) assumption. We\npresent a new framework in which historical samples are generated from unknown\nand different distributions, which we dub heterogeneous environments. These\ndistributions are assumed to lie in a heterogeneity ball with known radius and\ncentered around the (also) unknown future (out-of-sample) distribution on which\nthe performance of a decision will be evaluated. We quantify the asymptotic\nworst-case regret that is achievable by central data-driven policies such as\nSample Average Approximation, but also by rate-optimal ones, as a function of\nthe radius of the heterogeneity ball. Our work shows that the type of\nachievable performance varies considerably across different combinations of\nproblem classes and notions of heterogeneity. We demonstrate the versatility of\nour framework by comparing achievable guarantees for the heterogeneous version\nof widely studied data-driven problems such as pricing, ski-rental, and\nnewsvendor. En route, we establish a new connection between data-driven\ndecision-making and distributionally robust optimization.",
    "descriptor": "",
    "authors": [
      "Omar Besbes",
      "Will Ma",
      "Omar Mouchtaki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.09642"
  },
  {
    "id": "arXiv:2206.09648",
    "title": "Euclidean Steiner Spanners: Light and Sparse",
    "abstract": "Lightness and sparsity are two natural parameters for Euclidean\n$(1+\\varepsilon)$-spanners. Classical results show that, when the dimension\n$d\\in \\mathbb{N}$ and $\\varepsilon>0$ are constant, every set $S$ of $n$ points\nin $d$-space admits an $(1+\\varepsilon)$-spanners with $O(n)$ edges and weight\nproportional to that of the Euclidean MST of $S$. In a recent breakthrough, Le\nand Solomon (2019) established the precise dependencies on $\\varepsilon>0$, for\nconstant $d\\in \\mathbb{N}$, of the minimum lightness and sparsity of\n$(1+\\varepsilon)$-spanners, and observed that Steiner points can substantially\nimprove the lightness and sparsity of a $(1+\\varepsilon)$-spanner. They gave\nupper bounds of $\\tilde{O}(\\varepsilon^{-(d+1)/2})$ for the minimum lightness\nin dimensions $d\\geq 3$, and $\\tilde{O}(\\varepsilon^{-(d-1)/2})$ for the\nminimum sparsity in $d$-space for all $d\\geq 1$.\nIn this work, we improve several bounds on the lightness and sparsity of\nEuclidean Steiner $(1+\\varepsilon)$-spanners. We establish lower bounds of\n$\\Omega(\\varepsilon^{-d/2})$ for the lightness and\n$\\Omega(\\varepsilon^{-(d-1)/2})$ for the sparsity of such spanners in Euclidean\n$d$-space for all constant $d\\geq 2$. Our lower bound constructions generalize\nprevious constructions by Le and Solomon, but the analysis substantially\nsimplifies previous work, using new geometric insight, focusing on the\ndirections of edges. Next, we show that for every finite set of points in the\nplane and every $\\varepsilon\\in (0,1]$, there exists a Euclidean Steiner\n$(1+\\varepsilon)$-spanner of lightness $O(\\varepsilon^{-1})$; this matches the\nlower bound for $d=2$. We generalize the notion of shallow light trees, which\nmay be of independent interest, and use directional spanners and a modified\nwindow partitioning scheme to achieve a tight weight analysis.",
    "descriptor": "\nComments: This combines two previous papers appeared in STACS'21 (arXiv:2010.02908) and SoCG'21 (arXiv:2012.02216), and is to appear in SIAM Journal on Discrete Mathematics\n",
    "authors": [
      "Sujoy Bhore",
      "Csaba D. Toth"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2206.09648"
  },
  {
    "id": "arXiv:2206.09654",
    "title": "Performance Prediction in Major League Baseball by Long Short-Term  Memory Networks",
    "abstract": "Player performance prediction is a serious problem in every sport since it\nbrings valuable future information for managers to make important decisions. In\nbaseball industries, there already existed variable prediction systems and many\ntypes of researches that attempt to provide accurate predictions and help\ndomain users. However, it is a lack of studies about the predicting method or\nsystems based on deep learning. Deep learning models had proven to be the\ngreatest solutions in different fields nowadays, so we believe they could be\ntried and applied to the prediction problem in baseball. Hence, the predicting\nabilities of deep learning models are set to be our research problem in this\npaper. As a beginning, we select numbers of home runs as the target because it\nis one of the most critical indexes to understand the power and the talent of\nbaseball hitters. Moreover, we use the sequential model Long Short-Term Memory\nas our main method to solve the home run prediction problem in Major League\nBaseball. We compare models' ability with several machine learning models and a\nwidely used baseball projection system, sZymborski Projection System. Our\nresults show that Long Short-Term Memory has better performance than others and\nhas the ability to make more exact predictions. We conclude that Long\nShort-Term Memory is a feasible way for performance prediction problems in\nbaseball and could bring valuable information to fit users' needs.",
    "descriptor": "\nComments: 25 pages, 1 figures, 18 tables\n",
    "authors": [
      "Hsuan-Cheng Sun",
      "Tse-Yu Lin",
      "Yen-Lung Tsai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.09654"
  },
  {
    "id": "arXiv:2206.09664",
    "title": "What Can be Seen is What You Get: Structure Aware Point Cloud  Augmentation",
    "abstract": "To train a well performing neural network for semantic segmentation, it is\ncrucial to have a large dataset with available ground truth for the network to\ngeneralize on unseen data. In this paper we present novel point cloud\naugmentation methods to artificially diversify a dataset. Our sensor-centric\nmethods keep the data structure consistent with the lidar sensor capabilities.\nDue to these new methods, we are able to enrich low-value data with high-value\ninstances, as well as create entirely new scenes. We validate our methods on\nmultiple neural networks with the public SemanticKITTI dataset and demonstrate\nthat all networks improve compared to their respective baseline. In addition,\nwe show that our methods enable the use of very small datasets, saving\nannotation time, training time and the associated costs.",
    "descriptor": "\nComments: Published in IEEE IV 2022\n",
    "authors": [
      "Frederik Hasecke",
      "Martin Alsfasser",
      "Anton Kummert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09664"
  },
  {
    "id": "arXiv:2206.09667",
    "title": "MSANet: Multi-Similarity and Attention Guidance for Boosting Few-Shot  Segmentation",
    "abstract": "Few-shot segmentation aims to segment unseen-class objects given only a\nhandful of densely labeled samples. Prototype learning, where the support\nfeature yields a singleor several prototypes by averaging global and local\nobject information, has been widely used in FSS. However, utilizing only\nprototype vectors may be insufficient to represent the features for all\ntraining data. To extract abundant features and make more precise predictions,\nwe propose a Multi-Similarity and Attention Network (MSANet) including two\nnovel modules, a multi-similarity module and an attention module. The\nmulti-similarity module exploits multiple feature-maps of support images and\nquery images to estimate accurate semantic relationships. The attention module\ninstructs the network to concentrate on class-relevant information. The network\nis tested on standard FSS datasets, PASCAL-5i 1-shot, PASCAL-5i 5-shot,\nCOCO-20i 1-shot, and COCO-20i 5-shot. The MSANet with the backbone of\nResNet-101 achieves the state-of-the-art performance for all 4-benchmark\ndatasets with mean intersection over union (mIoU) of 69.13%, 73.99%, 51.09%,\n56.80%, respectively. Code is available at\nhttps://github.com/AIVResearch/MSANet",
    "descriptor": "",
    "authors": [
      "Ehtesham Iqbal",
      "Sirojbek Safarov",
      "Seongdeok Bang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09667"
  },
  {
    "id": "arXiv:2206.09670",
    "title": "Benchmarking Constraint Inference in Inverse Reinforcement Learning",
    "abstract": "When deploying Reinforcement Learning (RL) agents into a physical system, we\nmust ensure that these agents are well aware of the underlying constraints. In\nmany real-world problems, however, the constraints followed by expert agents\n(e.g., humans) are often hard to specify mathematically and unknown to the RL\nagents. To tackle these issues, Constraint Inverse Reinforcement Learning\n(CIRL) considers the formalism of Constrained Markov Decision Processes (CMDPs)\nand estimates constraints from expert demonstrations by learning a constraint\nfunction. As an emerging research topic, CIRL does not have common benchmarks,\nand previous works tested their algorithms with hand-crafted environments\n(e.g., grid worlds). In this paper, we construct a CIRL benchmark in the\ncontext of two major application domains: robot control and autonomous driving.\nWe design relevant constraints for each environment and empirically study the\nability of different algorithms to recover those constraints based on expert\ntrajectories that respect those constraints. To handle stochastic dynamics, we\npropose a variational approach that infers constraint distributions, and we\ndemonstrate its performance by comparing it with other CIRL baselines on our\nbenchmark. The benchmark, including the information for reproducing the\nperformance of CIRL algorithms, is publicly available at\nhttps://github.com/Guiliang/CIRL-benchmarks-public",
    "descriptor": "",
    "authors": [
      "Guiliang Liu",
      "Yudong Luo",
      "Ashish Gaurav",
      "Kasra Rezaee",
      "Pascal Poupart"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09670"
  },
  {
    "id": "arXiv:2206.09672",
    "title": "Adaptive Domain Interest Network for Multi-domain Recommendation",
    "abstract": "Industrial recommender systems usually hold data from multiple business\nscenarios and are expected to provide recommendation services for these\nscenarios simultaneously. In the retrieval step, the topK high-quality items\nselected from a large number of corpus usually need to be various for multiple\nscenarios. Take Alibaba display advertising system for example, not only\nbecause the behavior patterns of Taobao users are diverse, but also\ndifferentiated scenarios' bid prices assigned by advertisers vary\nsignificantly. Traditional methods either train models for each scenario\nseparately, ignoring the cross-domain overlapping of user groups and items, or\nsimply mix all samples and maintain a shared model which makes it difficult to\ncapture significant diversities between scenarios. In this paper, we present\nAdaptive Domain Interest network that adaptively handles the commonalities and\ndiversities across scenarios, making full use of multi-scenarios data during\ntraining. Then the proposed method is able to improve the performance of each\nbusiness domain by giving various topK candidates for different scenarios\nduring online inference. Specifically, our proposed ADI models the\ncommonalities and diversities for different domains by shared networks and\ndomain-specific networks, respectively. In addition, we apply the\ndomain-specific batch normalization and design the domain interest adaptation\nlayer for feature-level domain adaptation. A self training strategy is also\nincorporated to capture label-level connections across domains.ADI has been\ndeployed in the display advertising system of Alibaba, and obtains 1.8%\nimprovement on advertising revenue.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Yuchen Jiang",
      "Qi Li",
      "Han Zhu",
      "Jinbei Yu",
      "Jin Li",
      "Ziru Xu",
      "Huihui Dong",
      "Bo Zheng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.09672"
  },
  {
    "id": "arXiv:2206.09674",
    "title": "EAGER: Asking and Answering Questions for Automatic Reward Shaping in  Language-guided RL",
    "abstract": "Reinforcement learning (RL) in long horizon and sparse reward tasks is\nnotoriously difficult and requires a lot of training steps. A standard solution\nto speed up the process is to leverage additional reward signals, shaping it to\nbetter guide the learning process. In the context of language-conditioned RL,\nthe abstraction and generalisation properties of the language input provide\nopportunities for more efficient ways of shaping the reward. In this paper, we\nleverage this idea and propose an automated reward shaping method where the\nagent extracts auxiliary objectives from the general language goal. These\nauxiliary objectives use a question generation (QG) and question answering (QA)\nsystem: they consist of questions leading the agent to try to reconstruct\npartial information about the global goal using its own trajectory. When it\nsucceeds, it receives an intrinsic reward proportional to its confidence in its\nanswer. This incentivizes the agent to generate trajectories which\nunambiguously explain various aspects of the general language goal. Our\nexperimental study shows that this approach, which does not require engineer\nintervention to design the auxiliary objectives, improves sample efficiency by\neffectively directing exploration.",
    "descriptor": "\nComments: 19 pages, 10 figures, 4 tables\n",
    "authors": [
      "Thomas Carta",
      "Sylvain Lamprier",
      "Pierre-Yves Oudeyer",
      "Olivier Sigaud"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09674"
  },
  {
    "id": "arXiv:2206.09676",
    "title": "Studying the role of named entities for content preservation in text  style transfer",
    "abstract": "Text style transfer techniques are gaining popularity in Natural Language\nProcessing, finding various applications such as text detoxification,\nsentiment, or formality transfer. However, the majority of the existing\napproaches were tested on such domains as online communications on public\nplatforms, music, or entertainment yet none of them were applied to the domains\nwhich are typical for task-oriented production systems, such as personal plans\narrangements (e.g. booking of flights or reserving a table in a restaurant). We\nfill this gap by studying formality transfer in this domain.\nWe noted that the texts in this domain are full of named entities, which are\nvery important for keeping the original sense of the text. Indeed, if for\nexample, someone communicates the destination city of a flight it must not be\naltered. Thus, we concentrate on the role of named entities in content\npreservation for formality text style transfer.\nWe collect a new dataset for the evaluation of content similarity measures in\ntext style transfer. It is taken from a corpus of task-oriented dialogues and\ncontains many important entities related to realistic requests that make this\ndataset particularly useful for testing style transfer models before using them\nin production. Besides, we perform an error analysis of a pre-trained formality\ntransfer model and introduce a simple technique to use information about named\nentities to enhance the performance of baseline content similarity measures\nused in text style transfer.",
    "descriptor": "",
    "authors": [
      "Nikolay Babakov",
      "David Dale",
      "Varvara Logacheva",
      "Irina Krotova",
      "Alexander Panchenko"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.09676"
  },
  {
    "id": "arXiv:2206.09677",
    "title": "GraphFramEx: Towards Systematic Evaluation of Explainability Methods for  Graph Neural Networks",
    "abstract": "As one of the most popular machine learning models today, graph neural\nnetworks (GNNs) have attracted intense interest recently, and so does their\nexplainability. Users are increasingly interested in a better understanding of\nGNN models and their outcomes. Unfortunately, today's evaluation frameworks for\nGNN explainability often rely on synthetic datasets, leading to conclusions of\nlimited scope due to a lack of complexity in the problem instances. As GNN\nmodels are deployed to more mission-critical applications, we are in dire need\nfor a common evaluation protocol of explainability methods of GNNs. In this\npaper, we propose, to our best knowledge, the first systematic evaluation\nframework for GNN explainability, considering explainability on three different\n\"user needs:\" explanation focus, mask nature, and mask transformation. We\npropose a unique metric that combines the fidelity measures and classify\nexplanations based on their quality of being sufficient or necessary. We scope\nourselves to node classification tasks and compare the most representative\ntechniques in the field of input-level explainability for GNNs. For the widely\nused synthetic benchmarks, surprisingly shallow techniques such as personalized\nPageRank have the best performance for a minimum computation time. But when the\ngraph structure is more complex and nodes have meaningful features,\ngradient-based methods, in particular Saliency, are the best according to our\nevaluation criteria. However, none dominates the others on all evaluation\ndimensions and there is always a trade-off. We further apply our evaluation\nprotocol in a case study on eBay graphs to reflect the production environment.",
    "descriptor": "\nComments: Submitted to Neurips 2022 Conference\n",
    "authors": [
      "Kenza Amara",
      "Rex Ying",
      "Zitao Zhang",
      "Zhihao Han",
      "Yinan Shan",
      "Ulrik Brandes",
      "Sebastian Schemm",
      "Ce Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.09677"
  },
  {
    "id": "arXiv:2206.09679",
    "title": "Phoebe: QoS-Aware Distributed Stream Processing through Anticipating  Dynamic Workloads",
    "abstract": "Distributed Stream Processing systems have become an essential part of big\ndata processing platforms. They are characterized by the high-throughput\nprocessing of near to real-time event streams with the goal of delivering\nlow-latency results and thus enabling time-sensitive decision making. At the\nsame time, results are expected to be consistent even in the presence of\npartial failures where exactly-once processing guarantees are required for\ncorrectness. Stream processing workloads are oftentimes dynamic in nature which\nmakes static configurations highly inefficient as time goes by. Static resource\nallocations will almost certainly either negatively impact upon the Quality of\nService and/or result in higher operational costs.\nIn this paper we present Phoebe, a proactive approach to system auto-tuning\nfor Distributed Stream Processing jobs executing on dynamic workloads. Our\napproach makes use of parallel profiling runs, QoS modeling, and runtime\noptimization to provide a general solution whereby configuration parameters are\nautomatically tuned to ensure a stable service as well as alignment with\nrecovery time Quality of Service targets. Phoebe makes use of Time Series\nForecasting to gain an insight into future workload requirements thereby\ndelivering scaling decisions which are accurate, long-lived, and reliable. Our\nexperiments demonstrate that Phoebe is able to deliver a stable service while\nat the same time reducing resource over-provisioning.",
    "descriptor": "\nComments: 10 pages, ICWS2022\n",
    "authors": [
      "Morgan K. Geldenhuys",
      "Dominik Scheinert",
      "Odej Kao",
      "Lauritz Thamsen"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.09679"
  },
  {
    "id": "arXiv:2206.09680",
    "title": "Misspelling Semantics In Thai",
    "abstract": "User-generated content is full of misspellings. Rather than being just random\nnoise, we hypothesise that many misspellings contain hidden semantics that can\nbe leveraged for language understanding tasks. This paper presents a\nfine-grained annotated corpus of misspelling in Thai, together with an analysis\nof misspelling intention and its possible semantics to get a better\nunderstanding of the misspelling patterns observed in the corpus. In addition,\nwe introduce two approaches to incorporate the semantics of misspelling:\nMisspelling Average Embedding (MAE) and Misspelling Semantic Tokens (MST).\nExperiments on a sentiment analysis task confirm our overall hypothesis:\nadditional semantics from misspelling can boost the micro F1 score up to\n0.4-2%, while blindly normalising misspelling is harmful and suboptimal.",
    "descriptor": "\nComments: To be published in LREC2022\n",
    "authors": [
      "Pakawat Nakwijit",
      "Matthew Purver"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.09680"
  },
  {
    "id": "arXiv:2206.09682",
    "title": "SafeBench: A Benchmarking Platform for Safety Evaluation of Autonomous  Vehicles",
    "abstract": "As shown by recent studies, machine intelligence-enabled systems are\nvulnerable to test cases resulting from either adversarial manipulation or\nnatural distribution shifts. This has raised great concerns about deploying\nmachine learning algorithms for real-world applications, especially in the\nsafety-critical domains such as autonomous driving (AD). On the other hand,\ntraditional AD testing on naturalistic scenarios requires hundreds of millions\nof driving miles due to the high dimensionality and rareness of the\nsafety-critical scenarios in the real world. As a result, several approaches\nfor autonomous driving evaluation have been explored, which are usually,\nhowever, based on different simulation platforms, types of safety-critical\nscenarios, scenario generation algorithms, and driving route variations. Thus,\ndespite a large amount of effort in autonomous driving testing, it is still\nchallenging to compare and understand the effectiveness and efficiency of\ndifferent testing scenario generation algorithms and testing mechanisms under\nsimilar conditions. In this paper, we aim to provide the first unified platform\nSafeBench to integrate different types of safety-critical testing scenarios,\nscenario generation algorithms, and other variations such as driving routes and\nenvironments. Meanwhile, we implement 4 deep reinforcement learning-based AD\nalgorithms with 4 types of input (e.g., bird's-eye view, camera) to perform\nfair comparisons on SafeBench. We find our generated testing scenarios are\nindeed more challenging and observe the trade-off between the performance of AD\nagents under benign and safety-critical testing scenarios. We believe our\nunified platform SafeBench for large-scale and effective autonomous driving\ntesting will motivate the development of new testing scenario generation and\nsafe AD algorithms. SafeBench is available at https://safebench.github.io.",
    "descriptor": "",
    "authors": [
      "Chejian Xu",
      "Wenhao Ding",
      "Weijie Lyu",
      "Zuxin Liu",
      "Shuai Wang",
      "Yihan He",
      "Hanjiang Hu",
      "Ding Zhao",
      "Bo Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.09682"
  },
  {
    "id": "arXiv:2206.09683",
    "title": "Distribution Regularized Self-Supervised Learning for Domain Adaptation  of Semantic Segmentation",
    "abstract": "This paper proposes a novel pixel-level distribution regularization scheme\n(DRSL) for self-supervised domain adaptation of semantic segmentation. In a\ntypical setting, the classification loss forces the semantic segmentation model\nto greedily learn the representations that capture inter-class variations in\norder to determine the decision (class) boundary. Due to the domain shift, this\ndecision boundary is unaligned in the target domain, resulting in noisy pseudo\nlabels adversely affecting self-supervised domain adaptation. To overcome this\nlimitation, along with capturing inter-class variation, we capture pixel-level\nintra-class variations through class-aware multi-modal distribution learning\n(MMDL). Thus, the information necessary for capturing the intra-class\nvariations is explicitly disentangled from the information necessary for\ninter-class discrimination. Features captured thus are much more informative,\nresulting in pseudo-labels with low noise. This disentanglement allows us to\nperform separate alignments in discriminative space and multi-modal\ndistribution space, using cross-entropy based self-learning for the former. For\nlater, we propose a novel stochastic mode alignment method, by explicitly\ndecreasing the distance between the target and source pixels that map to the\nsame mode. The distance metric learning loss, computed over pseudo-labels and\nbackpropagated from multi-modal modeling head, acts as the regularizer over the\nbase network shared with the segmentation head. The results from comprehensive\nexperiments on synthetic to real domain adaptation setups, i.e., GTA-V/SYNTHIA\nto Cityscapes, show that DRSL outperforms many existing approaches (a minimum\nmargin of 2.3% and 2.5% in mIoU for SYNTHIA to Cityscapes).",
    "descriptor": "\nComments: Accepted for publication at Image and Vision Computing\n",
    "authors": [
      "Javed Iqbal",
      "Hamza Rawal",
      "Rehan Hafiz",
      "Yu-Tseh Chi",
      "Mohsen Ali"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09683"
  },
  {
    "id": "arXiv:2206.09689",
    "title": "GiDR-DUN; Gradient Dimensionality Reduction -- Differences and  Unification",
    "abstract": "TSNE and UMAP are two of the most popular dimensionality reduction algorithms\ndue to their speed and interpretable low-dimensional embeddings. However, while\nattempts have been made to improve on TSNE's computational complexity, no\nexisting method can obtain TSNE embeddings at the speed of UMAP. In this work,\nwe show that this is indeed possible by combining the two approaches into a\nsingle method. We theoretically and experimentally evaluate the full space of\nparameters in the TSNE and UMAP algorithms and observe that a single parameter,\nthe normalization, is responsible for switching between them. This, in turn,\nimplies that a majority of the algorithmic differences can be toggled without\naffecting the embeddings. We discuss the implications this has on several\ntheoretic claims underpinning the UMAP framework, as well as how to reconcile\nthem with existing TSNE interpretations. Based on our analysis, we propose a\nnew dimensionality reduction algorithm, GDR, that combines previously\nincompatible techniques from TSNE and UMAP and can replicate the results of\neither algorithm by changing the normalization. As a further advantage, GDR\nperforms the optimization faster than available UMAP methods and thus an order\nof magnitude faster than available TSNE methods. Our implementation is\nplug-and-play with the traditional UMAP and TSNE libraries and can be found at\ngithub.com/Andrew-Draganov/GiDR-DUN.",
    "descriptor": "",
    "authors": [
      "Andrew Draganov",
      "Tyrus Berry",
      "Jakob R\u00f8dsgaard J\u00f8rgensen",
      "Katrine Scheel Nellemann",
      "Ira Assent",
      "Davide Mottin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09689"
  },
  {
    "id": "arXiv:2206.09697",
    "title": "Technical Report: Combining knowledge from Transfer Learning during  training and Wide Resnets",
    "abstract": "In this report, we combine the idea of Wide ResNets and transfer learning to\noptimize the architecture of deep neural networks. The first improvement of the\narchitecture is the use of all layers as information source for the last layer.\nThis idea comes from transfer learning, which uses networks pre-trained on\nother data and extracts different levels of the network as input for the new\ntask. The second improvement is the use of deeper layers instead of deeper\nsequences of blocks. This idea comes from Wide ResNets. Using both\noptimizations, both high data augmentation and standard data augmentation can\nproduce better results for different models.\nLink:\nhttps://github.com/wolfgangfuhl/PublicationStuff/tree/master/TechnicalReport1/Supp",
    "descriptor": "",
    "authors": [
      "Wolfgang Fuhl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09697"
  },
  {
    "id": "arXiv:2206.09699",
    "title": "FoR$^2$M: Recognition and Repair of Foldings in Mesh Surfaces.  Application to 3D Object Degradation",
    "abstract": "Triangular meshes are the most popular representations of 3D objects, but\nmany mesh surfaces contain topological singularities that represent a challenge\nfor displaying or further processing them properly. One such singularity is the\nself-intersections that may be present in mesh surfaces that have been created\nby a scanning procedure or by a deformation transformation, such as\noff-setting.\nMesh foldings comprise a special case of mesh surface self-intersections,\nwhere the faces of the 3D model intersect and become reversed, with respect to\nthe unfolded part of the mesh surface. A novel method for the recognition and\nrepair of mesh surface foldings is presented, which exploits the structural\ncharacteristics of the foldings in order to efficiently detect the folded\nregions. Following detection, the foldings are removed and any gaps so created\nare filled based on the geometry of the 3D model. The proposed method is\ndirectly applicable to simple mesh surface representations while it does not\nperform any embedding of the 3D mesh (i.e. voxelization, projection). Target of\nthe proposed method is to facilitate mesh degradation procedures in a fashion\nthat retains the original structure, given the operator, in the most efficient\nmanner.",
    "descriptor": "",
    "authors": [
      "K. Sfikas",
      "P. Perakis",
      "T. Theoharis"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2206.09699"
  },
  {
    "id": "arXiv:2206.09707",
    "title": "The Role of Machine Learning in Cybersecurity",
    "abstract": "Machine Learning (ML) represents a pivotal technology for current and future\ninformation systems, and many domains already leverage the capabilities of ML.\nHowever, deployment of ML in cybersecurity is still at an early stage,\nrevealing a significant discrepancy between research and practice. Such\ndiscrepancy has its root cause in the current state-of-the-art, which does not\nallow to identify the role of ML in cybersecurity. The full potential of ML\nwill never be unleashed unless its pros and cons are understood by a broad\naudience.\nThis paper is the first attempt to provide a holistic understanding of the\nrole of ML in the entire cybersecurity domain -- to any potential reader with\nan interest in this topic. We highlight the advantages of ML with respect to\nhuman-driven detection methods, as well as the additional tasks that can be\naddressed by ML in cybersecurity. Moreover, we elucidate various intrinsic\nproblems affecting real ML deployments in cybersecurity. Finally, we present\nhow various stakeholders can contribute to future developments of ML in\ncybersecurity, which is essential for further progress in this field. Our\ncontributions are complemented with two real case studies describing industrial\napplications of ML as defense against cyber-threats.",
    "descriptor": "",
    "authors": [
      "Giovanni Apruzzese",
      "Pavel Laskov",
      "Edgardo Montes de Oca",
      "Wissam Mallouli",
      "Luis Burdalo Rapa",
      "Athanasios Vasileios Grammatopoulos",
      "Fabio Di Franco"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09707"
  },
  {
    "id": "arXiv:2206.09708",
    "title": "Great Expectations: Unsupervised Inference of Suspense, Surprise and  Salience in Storytelling",
    "abstract": "Stories interest us not because they are a sequence of mundane and\npredictable events but because they have drama and tension. Crucial to creating\ndramatic and exciting stories are surprise and suspense. The thesis trains a\nseries of deep learning models via only reading stories, a self-supervised (or\nunsupervised) system. Narrative theory methods (rules and procedures) are\napplied to the knowledge built into deep learning models to directly infer\nsalience, surprise, and salience in stories. Extensions add memory and external\nknowledge from story plots and from Wikipedia to infer salience on novels such\nas Great Expectations and plays such as Macbeth. Other work adapts the models\nas a planning system for generating original stories.\nThe thesis finds that applying the narrative theory to deep learning models\ncan align with the typical reader. In follow-up work, the insights could help\nimprove computer models for tasks such as automatic story writing and\nassistance for writing, summarising or editing stories. Moreover, the approach\nof applying narrative theory to the inherent qualities built in a system that\nlearns itself (self-supervised) from reading from books, watching videos, and\nlistening to audio is much cheaper and more adaptable to other domains and\ntasks. Progress is swift in improving self-supervised systems. As such, the\nthesis's relevance is that applying domain expertise with these systems may be\na more productive approach for applying machine learning in many areas of\ninterest.",
    "descriptor": "\nComments: PhD thesis, total 362 pages, main body 277 pages\n",
    "authors": [
      "David Wilmot"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09708"
  },
  {
    "id": "arXiv:2206.09714",
    "title": "Analysis and numerics of the propagation speed for hyperbolic  reaction-diffusion models",
    "abstract": "In this paper, we analyse propagating fronts in the context of hyperbolic\ntheories of dissipative processes. These can be considered as a natural\nalternative to the more classical parabolic models. Emphasis is given toward\nthe numerical computation of the invasion velocity.",
    "descriptor": "\nComments: 30 pages, 5 figures, 4 tables\n",
    "authors": [
      "Corrado Lattanzio",
      "Corrado Mascia",
      "Ramon G. Plaza",
      "Chiara Simeoni"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2206.09714"
  },
  {
    "id": "arXiv:2206.09731",
    "title": "Semantic Labeling of High Resolution Images Using EfficientUNets and  Transformers",
    "abstract": "Semantic segmentation necessitates approaches that learn high-level\ncharacteristics while dealing with enormous amounts of data. Convolutional\nneural networks (CNNs) can learn unique and adaptive features to achieve this\naim. However, due to the large size and high spatial resolution of remote\nsensing images, these networks cannot analyze an entire scene efficiently.\nRecently, deep transformers have proven their capability to record global\ninteractions between different objects in the image. In this paper, we propose\na new segmentation model that combines convolutional neural networks with\ntransformers, and show that this mixture of local and global feature extraction\ntechniques provides significant advantages in remote sensing segmentation. In\naddition, the proposed model includes two fusion layers that are designed to\nrepresent multi-modal inputs and output of the network efficiently. The input\nfusion layer extracts feature maps summarizing the relationship between image\ncontent and elevation maps (DSM). The output fusion layer uses a novel\nmulti-task segmentation strategy where class labels are identified using\nclass-specific feature extraction layers and loss functions. Finally, a\nfast-marching method is used to convert all unidentified class labels to their\nclosest known neighbors. Our results demonstrate that the proposed methodology\nimproves segmentation accuracy compared to state-of-the-art techniques.",
    "descriptor": "",
    "authors": [
      "Hasan AlMarzouqi",
      "Lyes Saad Saoud"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.09731"
  },
  {
    "id": "arXiv:2206.09733",
    "title": "HORSES3D: a high-order discontinuous Galerkin solver for flow  simulations and multi-physics applications",
    "abstract": "We present the latest developments of our High-Order Spectral Element Solver\n(HORSES3D), an open source high-order discontinuous Galerkin framework, capable\nof solving a variety of flow applications, including compressible flows (with\nor without shocks), incompressible flows, various RANS and LES turbulence\nmodels, particle dynamics, multiphase flows, and aeroacoustics. We provide an\noverview of the high-order spatial discretisation (including energy/entropy\nstable schemes) and anisotropic p-adaptation capabilities. The solver is\nparallelised using MPI and OpenMP showing good scalability for up to 1000\nprocessors. Temporal discretisations include explicit, implicit, multigrid, and\ndual time-stepping schemes with efficient preconditioners. Additionally, we\nfacilitate meshing and simulating complex geometries through a mesh-free\nimmersed boundary technique. We detail the available documentation and the test\ncases included in the GitHub repository.",
    "descriptor": "",
    "authors": [
      "E. Ferrer",
      "G. Rubio",
      "G. Ntoukas",
      "W. Laskowski",
      "O.A. Mari\u00f1o",
      "S. Colombo",
      "A. Mateo-Gab\u00edn",
      "F. Manrique de Lara",
      "D. Huergo",
      "J. Manzanero",
      "A.M. Rueda-Ram\u00edrez",
      "D.A. Kopriva",
      "E. Valero"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.09733"
  },
  {
    "id": "arXiv:2206.09734",
    "title": "The Cost of the GDPR for Apps? Nearly Impossible to Study without  Platform Data",
    "abstract": "A recently published pre-print titled 'GDPR and the Lost Generation of\nInnovative Apps' by Jan{\\ss}en et al. observes that a third of apps on the\nGoogle Play Store disappeared from this app store around the introduction of\nthe GDPR in May 2018. The authors deduce 'that GDPR is the cause'. The effects\nof the GDPR on the app economy are an important field to study. Unfortunately,\nthe paper currently lacks a control condition and a key variable. As a result,\nthe effects on app exits reported in the paper are likely overestimated, as we\nwill discuss. We believe there are other factors which may better explain these\nchanges in the Play Store aside from the GDPR.",
    "descriptor": "\nComments: Response to NBER preprint 'GDPR and the Lost Generation of Innovative Apps'\n",
    "authors": [
      "Konrad Kollnig",
      "Reuben Binns"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.09734"
  },
  {
    "id": "arXiv:2206.09735",
    "title": "A Safe Control Architecture Based on Robust Model Predictive Control for  Autonomous Driving",
    "abstract": "This paper proposes a Robust Safe Control Architecture (RSCA) for\nsafe-decision making. The system to be controlled is a vehicle in the presence\nof bounded disturbances. The RSCA consists of two parts: a Supervisor MPC and a\nController MPC. Both the Supervisor and the Controller are tube MPCs (TMPCs).\nThe Supervisor MPC provides a safety certificate for an operating controller\nand a backup control input in every step. After an unsafe action by the\noperating controller is predicted, the Controller MPC takes over the system. In\nthis paper, a method for the computation of a terminal set is proposed, which\nis robust against changes in road curvature and forces the vehicle to reach a\nsafe reference. Moreover, two important proofs are provided in this paper.\nFirst, it is shown that the backup control input is safe to be applied to the\nsystem to lead the vehicle to a safe state. Next, the recursive feasibility of\nthe RSCA is proven. By simulating some obstacle avoidance scenarios, the\neffectiveness of the proposed RSCA is confirmed.",
    "descriptor": "",
    "authors": [
      "Maryam Nezami",
      "Ngoc Thinh Nguyen",
      "Georg M\u00e4nnel",
      "Hossam Seddik Abbas",
      "Georg Schildbach"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.09735"
  },
  {
    "id": "arXiv:2206.09736",
    "title": "Geo-NI: Geometry-aware Neural Interpolation for Light Field Rendering",
    "abstract": "In this paper, we present a Geometry-aware Neural Interpolation (Geo-NI)\nframework for light field rendering. Previous learning-based approaches either\nrely on the capability of neural networks to perform direct interpolation,\nwhich we dubbed Neural Interpolation (NI), or explore scene geometry for novel\nview synthesis, also known as Depth Image-Based Rendering (DIBR). Instead, we\nincorporate the ideas behind these two kinds of approaches by launching the NI\nwith a novel DIBR pipeline. Specifically, the proposed Geo-NI first performs NI\nusing input light field sheared by a set of depth hypotheses. Then the DIBR is\nimplemented by assigning the sheared light fields with a novel reconstruction\ncost volume according to the reconstruction quality under different depth\nhypotheses. The reconstruction cost is interpreted as a blending weight to\nrender the final output light field by blending the reconstructed light fields\nalong the dimension of depth hypothesis. By combining the superiorities of NI\nand DIBR, the proposed Geo-NI is able to render views with large disparity with\nthe help of scene geometry while also reconstruct non-Lambertian effect when\ndepth is prone to be ambiguous. Extensive experiments on various datasets\ndemonstrate the superior performance of the proposed geometry-aware light field\nrendering framework.",
    "descriptor": "\nComments: 13 pages, 8 figures, 4 tables\n",
    "authors": [
      "Gaochang Wu",
      "Yuemei Zhou",
      "Yebin Liu",
      "Lu Fang",
      "Tianyou Chai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.09736"
  },
  {
    "id": "arXiv:2206.09742",
    "title": "Developing a Free and Open-source Automated Building Exterior Crack  Inspection Software for Construction and Facility Managers",
    "abstract": "Inspection of cracks is an important process for properly monitoring and\nmaintaining a building. However, manual crack inspection is time-consuming,\ninconsistent, and dangerous (e.g., in tall buildings). Due to the development\nof open-source AI technologies, the increase in available Unmanned Aerial\nVehicles (UAVs) and the availability of smartphone cameras, it has become\npossible to automate the building crack inspection process. This study presents\nthe development of an easy-to-use, free and open-source Automated Building\nExterior Crack Inspection Software (ABECIS) for construction and facility\nmanagers, using state-of-the-art segmentation algorithms to identify concrete\ncracks and generate a quantitative and qualitative report. ABECIS was tested\nusing images collected from a UAV and smartphone cameras in real-world\nconditions and a controlled laboratory environment. From the raw output of the\nalgorithm, the median Intersection over Unions for the test experiments is (1)\n0.686 for indoor crack detection experiment in a controlled lab environment\nusing a commercial drone, (2) 0.186 for indoor crack detection at a\nconstruction site using a smartphone and (3) 0.958 for outdoor crack detection\non university campus using a commercial drone. These IoU results can be\nimproved significantly to over 0.8 when a human operator selectively removes\nthe false positives. In general, ABECIS performs best for outdoor drone images,\nand combining the algorithm predictions with human verification/intervention\noffers very accurate crack detection results. The software is available\npublicly and can be downloaded for out-of-the-box use at:\nhttps://github.com/SMART-NYUAD/ABECIS",
    "descriptor": "",
    "authors": [
      "Pi Ko",
      "Samuel A. Prieto",
      "Borja Garcia de Soto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.09742"
  },
  {
    "id": "arXiv:2206.09743",
    "title": "Guided Safe Shooting: model based reinforcement learning with safety  constraints",
    "abstract": "In the last decade, reinforcement learning successfully solved complex\ncontrol tasks and decision-making problems, like the Go board game. Yet, there\nare few success stories when it comes to deploying those algorithms to\nreal-world scenarios. One of the reasons is the lack of guarantees when dealing\nwith and avoiding unsafe states, a fundamental requirement in critical control\nengineering systems. In this paper, we introduce Guided Safe Shooting (GuSS), a\nmodel-based RL approach that can learn to control systems with minimal\nviolations of the safety constraints. The model is learned on the data\ncollected during the operation of the system in an iterated batch fashion, and\nis then used to plan for the best action to perform at each time step. We\npropose three different safe planners, one based on a simple random shooting\nstrategy and two based on MAP-Elites, a more advanced divergent-search\nalgorithm. Experiments show that these planners help the learning agent avoid\nunsafe situations while maximally exploring the state space, a necessary aspect\nwhen learning an accurate model of the system. Furthermore, compared to\nmodel-free approaches, learning a model allows GuSS reducing the number of\ninteractions with the real-system while still reaching high rewards, a\nfundamental requirement when handling engineering systems.",
    "descriptor": "",
    "authors": [
      "Giuseppe Paolo",
      "Jonas Gonzalez-Billandon",
      "Albert Thomas",
      "Bal\u00e1zs K\u00e9gl"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.09743"
  },
  {
    "id": "arXiv:2206.09744",
    "title": "Parameterisation of lane-change scenarios from real-world data",
    "abstract": "Recent Autonomous Vehicles (AV) technology includes machine learning and\nprobabilistic techniques that add significant complexity to the traditional\nverification and validation methods. The research community and industry have\nwidely accepted scenario-based testing in the last few years. As it is focused\ndirectly on the relevant crucial road situations, it can reduce the effort\nrequired in testing. Encoding real-world traffic participants' behaviour is\nessential to efficiently assess the System Under Test (SUT) in scenario-based\ntesting. So, it is necessary to capture the scenario parameters from the\nreal-world data that can model scenarios realistically in simulation. The\nprimary emphasis of the paper is to identify the list of meaningful parameters\nthat adequately model real-world lane-change scenarios. With these parameters,\nit is possible to build a parameter space capable of generating a range of\nchallenging scenarios for AV testing efficiently. We validate our approach\nusing Root Mean Square Error(RMSE) to compare the scenarios generated using the\nproposed parameters against the real-world trajectory data. In addition to\nthat, we demonstrate that adding a slight disturbance to a few scenario\nparameters can generate different scenarios and utilise\nResponsibility-Sensitive Safety (RSS) metric to measure the scenarios' risk.",
    "descriptor": "\nComments: Accepted to IEEE ITSC 2022 conference\n",
    "authors": [
      "Dhanoop Karunakaran",
      "Julie Stephany Berrio",
      "Stewart Worrall",
      "Eduardo Nebot"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.09744"
  },
  {
    "id": "arXiv:2206.09750",
    "title": "List Colouring Trees in Logarithmic Space",
    "abstract": "We show that List Colouring can be solved on $n$-vertex trees by a\ndeterministic Turing machine using $O(\\log n)$ bits on the worktape. Given an\n$n$-vertex graph $G=(V,E)$ and a list $L(v)\\subseteq\\{1,\\dots,n\\}$ of available\ncolours for each $v\\in V$, a list colouring for $G$ is a proper colouring $c$\nsuch that $c(v)\\in L(v)$ for all $v$.",
    "descriptor": "\nComments: 18 pages, accepted to ESA\n",
    "authors": [
      "Hans L. Bodlaender",
      "Carla Groenland",
      "Hugo Jacob"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.09750"
  },
  {
    "id": "arXiv:2206.09752",
    "title": "A Comparative Study on Application of Class-Imbalance Learning for  Severity Prediction of Adverse Events Following Immunization",
    "abstract": "In collaboration with the Liaoning CDC, China, we propose a prediction system\nto predict the subsequent hospitalization of children with adverse reactions\nbased on data on adverse events following immunization. We extracted multiple\nfeatures from the data, and selected \"hospitalization or not\" as the target for\nclassification. Since the data are imbalanced, we used various class-imbalance\nlearning methods for training and improved the RUSBoost algorithm. Experimental\nresults show that the improved RUSBoost has the highest Area Under the ROC\nCurve on the target among these algorithms. Additionally, we compared these\nclass-imbalance learning methods with some common machine learning algorithms.\nWe combined the improved RUSBoost with dynamic web resource development\ntechniques to build an evaluation system with information entry and vaccination\nresponse prediction capabilities for relevant medical practitioners.",
    "descriptor": "",
    "authors": [
      "Ning Chen",
      "Zhengke Sun",
      "Tong Jia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09752"
  },
  {
    "id": "arXiv:2206.09753",
    "title": "Visualizing and Understanding Self-Supervised Vision Learning",
    "abstract": "Self-Supervised vision learning has revolutionized deep learning, becoming\nthe next big challenge in the domain and rapidly closing the gap with\nsupervised methods on large computer vision benchmarks. With current models and\ntraining data exponentially growing, explaining and understanding these models\nbecomes pivotal. We study the problem of explainable artificial intelligence in\nthe domain of self-supervised learning for vision tasks, and present methods to\nunderstand networks trained with self-supervision and their inner workings.\nGiven the huge diversity of self-supervised vision pretext tasks, we narrow our\nfocus on understanding paradigms which learn from two views of the same image,\nand mainly aim to understand the pretext task. Our work focuses on explaining\nsimilarity learning, and is easily extendable to all other pretext tasks. We\nstudy two popular self-supervised vision models: SimCLR and Barlow Twins. We\ndevelop a total of six methods for visualizing and understanding these models:\nPerturbation-based methods (conditional occlusion, context-agnostic conditional\nocclusion and pairwise occlusion), Interaction-CAM, Feature Visualization,\nModel Difference Visualization, Averaged Transforms and Pixel Invaraince.\nFinally, we evaluate these explanations by translating well-known evaluation\nmetrics tailored towards supervised image classification systems involving a\nsingle image, into the domain of self-supervised learning where two images are\ninvolved. Code is at: https://github.com/fawazsammani/xai-ssl",
    "descriptor": "",
    "authors": [
      "Fawaz Sammani",
      "Boris Joukovsky",
      "Nikos Deligiannis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09753"
  },
  {
    "id": "arXiv:2206.09755",
    "title": "Square One Bias in NLP: Towards a Multi-Dimensional Exploration of the  Research Manifold",
    "abstract": "The prototypical NLP experiment trains a standard architecture on labeled\nEnglish data and optimizes for accuracy, without accounting for other\ndimensions such as fairness, interpretability, or computational efficiency. We\nshow through a manual classification of recent NLP research papers that this is\nindeed the case and refer to it as the square one experimental setup. We\nobserve that NLP research often goes beyond the square one setup, e.g, focusing\nnot only on accuracy, but also on fairness or interpretability, but typically\nonly along a single dimension. Most work targeting multilinguality, for\nexample, considers only accuracy; most work on fairness or interpretability\nconsiders only English; and so on. We show this through manual classification\nof recent NLP research papers and ACL Test-of-Time award recipients. Such\none-dimensionality of most research means we are only exploring a fraction of\nthe NLP research search space. We provide historical and recent examples of how\nthe square one bias has led researchers to draw false conclusions or make\nunwise choices, point to promising yet unexplored directions on the research\nmanifold, and make practical recommendations to enable more multi-dimensional\nresearch. We open-source the results of our annotations to enable further\nanalysis at https://github.com/google-research/url-nlp",
    "descriptor": "\nComments: Findings of ACL 2022\n",
    "authors": [
      "Sebastian Ruder",
      "Ivan Vuli\u0107",
      "Anders S\u00f8gaard"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09755"
  },
  {
    "id": "arXiv:2206.09756",
    "title": "Time Gated Convolutional Neural Networks for Crop Classification",
    "abstract": "This paper presented a state-of-the-art framework, Time Gated Convolutional\nNeural Network (TGCNN) that takes advantage of temporal information and gating\nmechanisms for the crop classification problem. Besides, several vegetation\nindices were constructed to expand dimensions of input data to take advantage\nof spectral information. Both spatial (channel-wise) and temporal (step-wise)\ncorrelation are considered in TGCNN. Specifically, our preliminary analysis\nindicates that step-wise information is of greater importance in this data set.\nLastly, the gating mechanism helps capture high-order relationship. Our TGCNN\nsolution achieves $0.973$ F1 score, $0.977$ AUC ROC and $0.948$ IoU,\nrespectively. In addition, it outperforms three other benchmarks in different\nlocal tasks (Kenya, Brazil and Togo). Overall, our experiments demonstrate that\nTGCNN is advantageous in this earth observation time series classification\ntask.",
    "descriptor": "",
    "authors": [
      "Longlong Weng",
      "Yashu Kang",
      "Kezhao Jiang",
      "Chunlei Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.09756"
  },
  {
    "id": "arXiv:2206.09758",
    "title": "Finding Good Proofs for Answers to Conjunctive Queries Mediated by  Lightweight Ontologies (Technical Report)",
    "abstract": "In ontology-mediated query answering, access to incomplete data sources is\nmediated by a conceptual layer constituted by an ontology. To correctly compute\nanswers to queries, it is necessary to perform complex reasoning over the\nconstraints expressed by the ontology. In the literature, there exists a\nmultitude of techniques incorporating the ontological knowledge into queries.\nHowever, few of these approaches were designed for comprehensibility of the\nquery answers. In this article, we try to bridge these two qualities by\nadapting a proof framework originally applied to axiom entailment for\nconjunctive query answering. We investigate the data and combined complexity of\ndetermining the existence of a proof below a given quality threshold, which can\nbe measured in different ways. By distinguishing various parameters such as the\nshape of a query, we obtain an overview of the complexity of this problem for\nthe lightweight ontology languages DL-Lite_R and EL, and also have a brief look\nat temporal query answering.",
    "descriptor": "\nComments: Extended version of a paper accepted at 35th International Workshop on Description Logics (DL 2022)\n",
    "authors": [
      "Christian Alrabbaa",
      "Stefan Borgwardt",
      "Patrick Koopmann",
      "Alisa Kovtunova"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.09758"
  },
  {
    "id": "arXiv:2206.09759",
    "title": "An Input-Queueing TSN Switching Architecture to Achieve Zero Packet Loss  for Timely Traffic",
    "abstract": "Zero packet loss with bounded latency is a must for many applications such as\nindustrial control networks, automotive Ethernet, and aircraft communication\nsystems. Traditional networks cannot meet such strict requirement and thus\nTime-Sensitive Networking (TSN) emerges. TSN is a set of standards proposed by\nIEEE 802 for providing deterministic connectivity in terms of low packet loss,\nlow packet delay variation, and guaranteed packet transport. However, to the\nbest of our knowledge, few of existing TSN solutions can deterministically\nachieve zero packet loss with bounded latency. This paper fills in this blank\nby proposing a novel input-queueing TSN switching architecture, under which we\ndesign a TDMA-like scheduling policy (called M-TDMA) along with a sufficient\ncondition, and an EDF-like scheduling policy (called M-EDF) along with a\ndifferent sufficient condition to achieve zero packet loss with bounded\nlatency.",
    "descriptor": "",
    "authors": [
      "Ming Li",
      "Lei Deng"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.09759"
  },
  {
    "id": "arXiv:2206.09760",
    "title": "Towards Perspective-Based Specification of Machine Learning-Enabled  Systems",
    "abstract": "Machine learning (ML) teams often work on a project just to realize the\nperformance of the model is not good enough. Indeed, the success of ML-enabled\nsystems involves aligning data with business problems, translating them into ML\ntasks, experimenting with algorithms, evaluating models, capturing data from\nusers, among others. Literature has shown that ML-enabled systems are rarely\nbuilt based on precise specifications for such concerns, leading ML teams to\nbecome misaligned due to incorrect assumptions, which may affect the quality of\nsuch systems and overall project success. In order to help addressing this\nissue, this paper describes our work towards a perspective-based approach for\nspecifying ML-enabled systems. The approach involves analyzing a set of 45 ML\nconcerns grouped into five perspectives: objectives, user experience,\ninfrastructure, model, and data. The main contribution of this paper is to\nprovide two new artifacts that can be used to help specifying ML-enabled\nsystems: (i) the perspective-based ML task and concern diagram and (ii) the\nperspective-based ML specification template.",
    "descriptor": "\nComments: Accepted for publication as short paper - 2022 48th Euromicro Conference on Software Engineering and Advanced Applications (SEAA). arXiv admin note: substantial text overlap with arXiv:2204.07662\n",
    "authors": [
      "Hugo Villamizar",
      "Marcos Kalinowski",
      "Helio Lopes"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09760"
  },
  {
    "id": "arXiv:2206.09762",
    "title": "A Systematic Mapping Study Addressing the Reliability of Mobile  Applications: The Need to Move Beyond Testing Reliability",
    "abstract": "Intense competition in the mobile apps market means it is important to\nmaintain high levels of app reliability to avoid losing users. Yet despite its\nimportance, app reliability is underexplored in the research literature. To\naddress this need, we identify, analyse, and classify the state-of-the-art in\nthe field of mobile apps' reliability through a systematic mapping study. From\nthe results of such a study, researchers in the field can identify pressing\nresearch gaps, and developers can gain knowledge about existing solutions, to\npotentially leverage them in practice. We found 87 relevant papers which were\nthen analysed and classified based on their research focus, research type,\ncontribution, research method, study settings, data, quality attributes and\nmetrics used. Results indicate that there is a lack of research on\nunderstanding reliability with regard to context-awareness, self-healing,\nageing and rejuvenation, and runtime event handling. These aspects have rarely\nbeen studied, or if studied, there is limited evaluation. We also identified\nseveral other research gaps including the need to conduct more research in\nreal-world industrial projects. Furthermore, little attention has been paid\ntowards quality standards while conducting research. Outcomes here show\nnumerous opportunities for greater research depth and breadth on mobile app\nreliability.",
    "descriptor": "\nComments: Journal paper, 29 pages, 12 tables, 7 figures\n",
    "authors": [
      "Chathrie Wimalasooriya",
      "Sherlock A. Licorish",
      "Daniel Alencar da Costa",
      "Stephen G. MacDonell"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.09762"
  },
  {
    "id": "arXiv:2206.09765",
    "title": "Bilingual by default: Voice Assistants and the role of code-switching in  creating a bilingual user experience",
    "abstract": "Conversational User Interfaces such as Voice Assistants are hugely popular.\nYet they are designed to be monolingual by default, lacking support for, or\nsensitivity to, the bilingual dialogue experience. In this provocation paper,\nwe highlight the language production challenges faced in VA interaction for\nbilingual users. We argue that, by facilitating phenomena seen in bilingual\ninteraction, such as code-switching, we can foster a more inclusive and\nimproved user experience for bilingual users. We also explore ways that this\nmight be achieved, through the support of multiple language recognition as well\nas being sensitive to the preferences of code-switching in speech output.",
    "descriptor": "",
    "authors": [
      "Helin Cihan",
      "Yunhan Wu",
      "Paola Pe\u00f1a",
      "Justin Edwards",
      "Benjamin Cowan"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.09765"
  },
  {
    "id": "arXiv:2206.09769",
    "title": "Test-time image-to-image translation ensembling improves  out-of-distribution generalization in histopathology",
    "abstract": "Histopathology whole slide images (WSIs) can reveal significant\ninter-hospital variability such as illumination, color or optical artifacts.\nThese variations, caused by the use of different scanning protocols across\nmedical centers (staining, scanner), can strongly harm algorithms\ngeneralization on unseen protocols. This motivates development of new methods\nto limit such drop of performances. In this paper, to enhance robustness on\nunseen target protocols, we propose a new test-time data augmentation based on\nmulti domain image-to-image translation. It allows to project images from\nunseen protocol into each source domain before classifying them and ensembling\nthe predictions. This test-time augmentation method results in a significant\nboost of performances for domain generalization. To demonstrate its\neffectiveness, our method has been evaluated on 2 different histopathology\ntasks where it outperforms conventional domain generalization, standard H&E\nspecific color augmentation/normalization and standard test-time augmentation\ntechniques. Our code is publicly available at\nhttps://gitlab.com/vitadx/articles/test-time-i2i-translation-ensembling.",
    "descriptor": "\nComments: MICCAI2022 conference\n",
    "authors": [
      "Marin Scalbert",
      "Maria Vakalopoulou",
      "Florent Couzini\u00e9-Devy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09769"
  },
  {
    "id": "arXiv:2206.09770",
    "title": "Real-time Full-stack Traffic Scene Perception for Autonomous Driving  with Roadside Cameras",
    "abstract": "We propose a novel and pragmatic framework for traffic scene perception with\nroadside cameras. The proposed framework covers a full-stack of roadside\nperception pipeline for infrastructure-assisted autonomous driving, including\nobject detection, object localization, object tracking, and multi-camera\ninformation fusion. Unlike previous vision-based perception frameworks rely\nupon depth offset or 3D annotation at training, we adopt a modular decoupling\ndesign and introduce a landmark-based 3D localization method, where the\ndetection and localization can be well decoupled so that the model can be\neasily trained based on only 2D annotations. The proposed framework applies to\neither optical or thermal cameras with pinhole or fish-eye lenses. Our\nframework is deployed at a two-lane roundabout located at Ellsworth Rd. and\nState St., Ann Arbor, MI, USA, providing 7x24 real-time traffic flow monitoring\nand high-precision vehicle trajectory extraction. The whole system runs\nefficiently on a low-power edge computing device with all-component end-to-end\ndelay of less than 20ms.",
    "descriptor": "\nComments: This paper is accepted and presented in ICRA 2022\n",
    "authors": [
      "Zhengxia Zou",
      "Rusheng Zhang",
      "Shengyin Shen",
      "Gaurav Pandey",
      "Punarjay Chakravarty",
      "Armin Parchami",
      "Henry X. Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.09770"
  },
  {
    "id": "arXiv:2206.09777",
    "title": "Actively learning to learn causal relationships",
    "abstract": "How do people actively learn to learn? That is, how and when do people choose\nactions that facilitate long-term learning and choosing future actions that are\nmore informative? We explore these questions in the domain of active causal\nlearning. We propose a hierarchical Bayesian model that goes beyond past models\nby predicting that people pursue information not only about the causal\nrelationship at hand but also about causal\noverhypotheses$\\unicode{x2014}$abstract beliefs about causal relationships that\nspan multiple situations and constrain how we learn the specifics in each\nsituation. In two active \"blicket detector\" experiments with 14\nbetween-subjects manipulations, our model was supported by both qualitative\ntrends in participant behavior and an individual-differences-based model\ncomparison. Our results suggest when there are abstract similarities across\nactive causal learning problems, people readily learn and transfer\noverhypotheses about these similarities. Moreover, people exploit these\noverhypotheses to facilitate long-term active learning.",
    "descriptor": "",
    "authors": [
      "Chentian Jiang",
      "Christopher G. Lucas"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09777"
  },
  {
    "id": "arXiv:2206.09779",
    "title": "The Story of $1/e$: ALOHA-based and Reinforcement-Learning-based Random  Access for Delay-Constrained Communications",
    "abstract": "Motivated by the proliferation of real-time applications in multimedia\ncommunication systems, tactile Internet, networked controlled systems, and\ncyber-physical systems, supporting delay-constrained traffic becomes critical\nfor such systems. In delay-constrained traffic, each packet has a hard\ndeadline; when it is not delivered before its deadline is up, it becomes\nuseless and will be removed from the system. In this work, we focus on\ndesigning the random access schemes for delay-constrained wireless\ncommunications. We first investigate three ALOHA-based random access schemes\nand prove that the system timely throughput of all three schemes under\ncorresponding optimal transmission probabilities asymptotically converges to\n$1/e$, same as the well-know throughput limit for delay-unconstrained ALOHA\nsystems. The fundamental reason why ALOHA-based schemes cannot achieve\nasymptotical system timely throughput beyond $1/e$ is that all active ALOHA\nstations access the channel with the same probability in any slot. Therefore,\nto go beyond $1/e$, we have to differentiate active stations' transmission\nprobabilities to reduce the competition level. However, since all stations work\nin a distributed manner without any coordination, we should deploy the same\npolicy (i.e., same piece of codes in practice) to all stations under which they\nwill automatically differentiate their transmission probabilities. Toward that\nend, we propose a Reinforcement-Learning-based Random Access scheme for\nDelay-Constrained communications, called RLRA-DC, under which different\nstations collaboratively attain different transmission probabilities by only\ninteracting with the access point. Our numerical result shows that the system\ntimely throughput of RLRA-DC can be as high as 0.8 for tens of stations and can\nstill reach 0.6 even for thousands of stations, much larger than $1/e$.",
    "descriptor": "",
    "authors": [
      "Lei Deng",
      "Danzhou Wu",
      "Jing Deng",
      "Po-Ning Chen",
      "Yunghsiang S. Han"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.09779"
  },
  {
    "id": "arXiv:2206.09782",
    "title": "Entanglement-Assisted and Subsystem Quantum Codes: New Propagation Rules  and Constructions",
    "abstract": "This paper proposes new propagation rules on quantum codes in the\nentanglement-assisted and in quantum subsystem scenarios. The rules lead to new\nfamilies of such quantum codes whose parameters are demonstrably optimal. To\nobtain the results, we devise tools to puncture and shorten codes in ways that\nensure their Hermitian hulls have certain desirable properties. More\nspecifically, we give a general framework to construct $k$-dimensional\ngeneralized Reed-Solomon codes whose Hermitian hulls are $(k-1)$-dimensional\nmaximum distance separable codes.",
    "descriptor": "",
    "authors": [
      "Gaojun Luo",
      "Martianus Frederic Ezerman",
      "San Ling"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.09782"
  },
  {
    "id": "arXiv:2206.09790",
    "title": "The Makerere Radio Speech Corpus: A Luganda Radio Corpus for Automatic  Speech Recognition",
    "abstract": "Building a usable radio monitoring automatic speech recognition (ASR) system\nis a challenging task for under-resourced languages and yet this is paramount\nin societies where radio is the main medium of public communication and\ndiscussions. Initial efforts by the United Nations in Uganda have proved how\nunderstanding the perceptions of rural people who are excluded from social\nmedia is important in national planning. However, these efforts are being\nchallenged by the absence of transcribed speech datasets. In this paper, The\nMakerere Artificial Intelligence research lab releases a Luganda radio speech\ncorpus of 155 hours. To our knowledge, this is the first publicly available\nradio dataset in sub-Saharan Africa. The paper describes the development of the\nvoice corpus and presents baseline Luganda ASR performance results using Coqui\nSTT toolkit, an open source speech recognition toolkit.",
    "descriptor": "\nComments: Proceedings of the 13th Conference on Language Resources and Evaluation (LREC 2022), pages 1945 to 1954 Marseille, 20 to 25 June 2022\n",
    "authors": [
      "Jonathan Mukiibi",
      "Andrew Katumba",
      "Joyce Nakatumba-Nabende",
      "Ali Hussein",
      "Josh Meyer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.09790"
  },
  {
    "id": "arXiv:2206.09793",
    "title": "Consensus ADMM-Based Distributed Simultaneous Imaging & Communication",
    "abstract": "This paper takes the first steps toward enabling wireless networks to perform\nboth imaging and communication in a distributed manner. We propose Distributed\nSimultaneous Imaging and Symbol Detection (DSISD), a provably convergent\ndistributed simultaneous imaging and communication scheme based on the\nalternating direction method of multipliers. We show that DSISD achieves\nsimilar imaging and communication performance as centralized schemes, with\norder-wise reduction in computational complexity. We evaluate the performance\nof DSISD via 2.4 GHz Wi-Fi simulations.",
    "descriptor": "\nComments: 9th IFAC Workshop on Distributed Estimation and Control in Networked Systems (NECSYS 2022)\n",
    "authors": [
      "Nishant Mehrotra",
      "Ashutosh Sabharwal",
      "C\u00e9sar A. Uribe"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.09793"
  },
  {
    "id": "arXiv:2206.09796",
    "title": "Knowledge Distillation for Oriented Object Detection on Aerial Images",
    "abstract": "Deep convolutional neural network with increased number of parameters has\nachieved improved precision in task of object detection on natural images,\nwhere objects of interests are annotated with horizontal boundary boxes. On\naerial images captured from the bird-view perspective, these improvements on\nmodel architecture and deeper convolutional layers can also boost the\nperformance on oriented object detection task. However, it is hard to directly\napply those state-of-the-art object detectors on the devices with limited\ncomputation resources, which necessitates lightweight models through model\ncompression. In order to address this issue, we present a model compression\nmethod for rotated object detection on aerial images by knowledge distillation,\nnamely KD-RNet. With a well-trained teacher oriented object detector with a\nlarge number of parameters, the obtained object category and location\ninformation are both transferred to a compact student network in KD-RNet by\ncollaborative training strategy. Transferring the category information is\nachieved by knowledge distillation on predicted probability distribution, and a\nsoft regression loss is adopted for handling displacement in location\ninformation transfer. The experimental result on a large-scale aerial object\ndetection dataset (DOTA) demonstrates that the proposed KD-RNet model can\nachieve improved mean-average precision (mAP) with reduced number of\nparameters, at the same time, KD-RNet boost the performance on providing high\nquality detections with higher overlap with groundtruth annotations.",
    "descriptor": "",
    "authors": [
      "Yicheng Xiao",
      "Junpeng Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09796"
  },
  {
    "id": "arXiv:2206.09798",
    "title": "Actively Learning Deep Neural Networks with Uncertainty Sampling Based  on Sum-Product Networks",
    "abstract": "Active learning is popular approach for reducing the amount of data in\ntraining deep neural network model. Its success hinges on the choice of an\neffective acquisition function, which ranks not yet labeled data points\naccording to their expected informativeness. In uncertainty sampling, the\nuncertainty that the current model has about a point's class label is the main\ncriterion for this type of ranking. This paper proposes a new approach to\nuncertainty sampling in training a Convolutional Neural Network (CNN). The main\nidea is to use feature representation extracted extracted by the CNN as data\nfor training a Sum-Product Network (SPN). Since SPNs are typically used for\nestimating the distribution of a dataset, they are well suited to the task of\nestimating class probabilities that can be used directly by standard\nacquisition functions such as max entropy and variational ratio. Moreover, we\nenhance these acquisition functions by weights calculated with the help of the\nSPN model; these weights make the acquisition function more sensitive to the\ndiversity of conceivable class labels for data points. The effectiveness of our\nmethod is demonstrated in an experimental study on the MNIST, Fashion-MNIST and\nCIFAR-10 datasets, where we compare it to the state-of-the-art methods MC\nDropout and Bayesian Batch.",
    "descriptor": "\nComments: 15 pages,9 figures, 4 tables\n",
    "authors": [
      "Mohamadsadegh Khosravani",
      "Sandra Zilles"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.09798"
  },
  {
    "id": "arXiv:2206.09805",
    "title": "Asymptotic Preserving Discontinuous Galerkin Methods for a Linear  Boltzmann Semiconductor Model",
    "abstract": "A key property of the linear Boltzmann semiconductor model is that as the\ncollision frequency tends to infinity, the phase space density $f = f(x,v,t)$\nconverges to an isotropic function $M(v)\\rho(x,t)$, called the drift-diffusion\nlimit, where $M$ is a Maxwellian and the physical density $\\rho$ satisfies a\nsecond-order parabolic PDE known as the drift-diffusion equation. Numerical\napproximations that mirror this property are said to be asymptotic preserving.\nIn this paper we build two discontinuous Galerkin methods to the semiconductor\nmodel: one with the standard upwinding flux and the other with a\n$\\varepsilon$-scaled Lax-Friedrichs flux, where 1/$\\varepsilon$ is the scale of\nthe collision frequency. We show that these schemes are uniformly stable in\n$\\varepsilon$ and are asymptotic preserving. In particular, we discuss what\nproperties the discrete Maxwellian must satisfy in order for the schemes to\nconverge in $\\varepsilon$ to an accurate $h$-approximation of the drift\ndiffusion limit. Discrete versions of the drift-diffusion equation and error\nestimates in several norms with respect to $\\varepsilon$ and the spacial\nresolution are also included.",
    "descriptor": "",
    "authors": [
      "Victor DeCaria",
      "Cory Hauck",
      "Stefan Schnake"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.09805"
  },
  {
    "id": "arXiv:2206.09806",
    "title": "Self-Supervised Consistent Quantization for Fully Unsupervised Image  Retrieval",
    "abstract": "Unsupervised image retrieval aims to learn an efficient retrieval system\nwithout expensive data annotations, but most existing methods rely heavily on\nhandcrafted feature descriptors or pre-trained feature extractors. To minimize\nhuman supervision, recent advance proposes deep fully unsupervised image\nretrieval aiming at training a deep model from scratch to jointly optimize\nvisual features and quantization codes. However, existing approach mainly\nfocuses on instance contrastive learning without considering underlying\nsemantic structure information, resulting in sub-optimal performance. In this\nwork, we propose a novel self-supervised consistent quantization approach to\ndeep fully unsupervised image retrieval, which consists of part consistent\nquantization and global consistent quantization. In part consistent\nquantization, we devise part neighbor semantic consistency learning with\ncodeword diversity regularization. This allows to discover underlying neighbor\nstructure information of sub-quantized representations as self-supervision. In\nglobal consistent quantization, we employ contrastive learning for both\nembedding and quantized representations and fuses these representations for\nconsistent contrastive regularization between instances. This can make up for\nthe loss of useful representation information during quantization and\nregularize consistency between instances. With a unified learning objective of\npart and global consistent quantization, our approach exploits richer\nself-supervision cues to facilitate model learning. Extensive experiments on\nthree benchmark datasets show the superiority of our approach over the\nstate-of-the-art methods.",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Guile Wu",
      "Chao Zhang",
      "Stephan Liwicki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09806"
  },
  {
    "id": "arXiv:2206.09811",
    "title": "Shapley-NAS: Discovering Operation Contribution for Neural Architecture  Search",
    "abstract": "In this paper, we propose a Shapley value based method to evaluate operation\ncontribution (Shapley-NAS) for neural architecture search. Differentiable\narchitecture search (DARTS) acquires the optimal architectures by optimizing\nthe architecture parameters with gradient descent, which significantly reduces\nthe search cost. However, the magnitude of architecture parameters updated by\ngradient descent fails to reveal the actual operation importance to the task\nperformance and therefore harms the effectiveness of obtained architectures. By\ncontrast, we propose to evaluate the direct influence of operations on\nvalidation accuracy. To deal with the complex relationships between supernet\ncomponents, we leverage Shapley value to quantify their marginal contributions\nby considering all possible combinations. Specifically, we iteratively optimize\nthe supernet weights and update the architecture parameters by evaluating\noperation contributions via Shapley value, so that the optimal architectures\nare derived by selecting the operations that contribute significantly to the\ntasks. Since the exact computation of Shapley value is NP-hard, the Monte-Carlo\nsampling based algorithm with early truncation is employed for efficient\napproximation, and the momentum update mechanism is adopted to alleviate\nfluctuation of the sampling process. Extensive experiments on various datasets\nand various search spaces show that our Shapley-NAS outperforms the\nstate-of-the-art methods by a considerable margin with light search cost. The\ncode is available at https://github.com/Euphoria16/Shapley-NAS.git",
    "descriptor": "\nComments: Accepted to CVPR2022\n",
    "authors": [
      "Han Xiao",
      "Ziwei Wang",
      "Zheng Zhu",
      "Jie Zhou",
      "Jiwen Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09811"
  },
  {
    "id": "arXiv:2206.09812",
    "title": "Convex space learning improves deep-generative oversampling for tabular  imbalanced classification on smaller datasets",
    "abstract": "Data is commonly stored in tabular format. Several fields of research (e.g.,\nbiomedical, fault/fraud detection), are prone to small imbalanced tabular data.\nSupervised Machine Learning on such data is often difficult due to class\nimbalance, adding further to the challenge. Synthetic data generation i.e.\noversampling is a common remedy used to improve classifier performance.\nState-of-the-art linear interpolation approaches, such as LoRAS and ProWRAS can\nbe used to generate synthetic samples from the convex space of the minority\nclass to improve classifier performance in such cases. Generative Adversarial\nNetworks (GANs) are common deep learning approaches for synthetic sample\ngeneration. Although GANs are widely used for synthetic image generation, their\nscope on tabular data in the context of imbalanced classification is not\nadequately explored. In this article, we show that existing deep generative\nmodels perform poorly compared to linear interpolation approaches generating\nsynthetic samples from the convex space of the minority class, for imbalanced\nclassification problems on tabular datasets of small size. We propose a deep\ngenerative model, ConvGeN combining the idea of convex space learning and deep\ngenerative models. ConVGeN learns the coefficients for the convex combinations\nof the minority class samples, such that the synthetic data is distinct enough\nfrom the majority class. We demonstrate that our proposed model ConvGeN\nimproves imbalanced classification on such small datasets, as compared to\nexisting deep generative models while being at par with the existing linear\ninterpolation approaches. Moreover, we discuss how our model can be used for\nsynthetic tabular data generation in general, even outside the scope of data\nimbalance, and thus, improves the overall applicability of convex space\nlearning.",
    "descriptor": "",
    "authors": [
      "Kristian Schultz",
      "Saptarshi Bej",
      "Waldemar Hahn",
      "Markus Wolfien",
      "Prashant Srivastava",
      "Olaf Wolkenhauer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09812"
  },
  {
    "id": "arXiv:2206.09824",
    "title": "The Carleman convexification method for Hamilton-Jacobi equations on the  whole space",
    "abstract": "We propose a new globally convergent numerical method to solve\nHamilton-Jacobi equations in $\\mathbb{R}^d$, $d \\geq 1$. This method is named\nas the Carleman convexification method. By Carleman convexification, we mean\nthat we use a Carleman weight function to convexify the conventional least\nsquares mismatch functional. We will prove a new version of the convexification\ntheorem guaranteeing that the mismatch functional involving the Carleman weight\nfunction is strictly convex and, therefore, has a unique minimizer. Moreover, a\nconsequence of our convexification theorem guarantees that the minimizer of the\nCarleman weighted mismatch functional is an approximation of the viscosity\nsolution we want to compute. Some numerical results in 1D and 2D will be\npresented.",
    "descriptor": "",
    "authors": [
      "Huynh P. N. Le",
      "Thuy T. Le",
      "Loc H. Nguyen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2206.09824"
  },
  {
    "id": "arXiv:2206.09827",
    "title": "A Distributional Approach for Soft Clustering Comparison and Evaluation",
    "abstract": "The development of external evaluation criteria for soft clustering (SC) has\nreceived limited attention: existing methods do not provide a general approach\nto extend comparison measures to SC, and are unable to account for the\nuncertainty represented in the results of SC algorithms. In this article, we\npropose a general method to address these limitations, grounding on a novel\ninterpretation of SC as distributions over hard clusterings, which we call\n\\emph{distributional measures}. We provide an in-depth study of complexity- and\nmetric-theoretic properties of the proposed approach, and we describe\napproximation techniques that can make the calculations tractable. Finally, we\nillustrate our approach through a simple but illustrative experiment.",
    "descriptor": "\nComments: This is the extended version of article \"A Distributional Approach for Soft Clustering Comparison and Evaluation\", accepted at BELIEF 2022 (this http URL). Please cite the proceedings version of the article\n",
    "authors": [
      "Andrea Campagner",
      "Davide Ciucci",
      "Thierry Den\u0153ux"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.09827"
  },
  {
    "id": "arXiv:2206.09829",
    "title": "Stabilized Single Current Inverse Source Formulations Based on  Steklov-Poincar\u00e9 Mappings",
    "abstract": "The inverse source problem in electromagnetics has proved quite relevant for\na large class of applications. In antenna diagnostics in particular, Love\nsolutions are often sought at the cost of an increase of the dimension of the\nlinear system to be solved. In this work, instead, we present a reduced-in-size\nsingle current formulation of the inverse source problem that obtains one of\nthe Love currents via a stable discretization of the Steklov-Poincar\\'e\nboundary operator leveraging dual functions. The new approach is enriched by\ntheoretical treatments and by a further low-frequency stabilization of the\nSteklov-Poincar\\'e operator based on the quasi-Helmholtz projectors that is the\nfirst of its kind in this field. The effectiveness and practical relevance of\nthe new schemes are demonstrated via both theoretical and numerical results.",
    "descriptor": "",
    "authors": [
      "Paolo Ricci",
      "Ermanno Citraro",
      "Adrien Merlini",
      "Francesco P. Andriulli"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.09829"
  },
  {
    "id": "arXiv:2206.09834",
    "title": "The Greater The Power, The More Dangerous The Abuse: Facing Malicious  Insiders in The Cloud",
    "abstract": "The financial crisis made companies around the world search for cheaper and\nmore efficient solutions to cover their needs in terms of computational power\nand storage. Their quest came to end with the birth of Cloud Computing\ninfrastructures. However, along with the new promising technology, new attack\nvectors were born, and one old and known threat, that of Malicious Insiders\nreappeared. Insiders can use their privileged position inside the Cloud\ninfrastructure to accomplish or help in attacks against a Cloud infrastructure.\nIn this paper, we propose a practical and efficient intrusion detection system\nsolution for Cloud infrastructures based on Graphical Processing Unit (GPU)\nacceleration. Our solution monitors the deployed virtual machines' operations\nand especially those of the host Operating System, known as Dom0, correlating\nthe collected information to detect uncommon behavior based on the\nSmith-Waterman algorithm. Our proposal makes possible the cooperation of a\nvariety of known hypervisors along with every known GPU acceleration unit used,\nthus offering the maximum of security mechanics while at the same time\nminimizing the imposed overhead in terms of Central Processing Unit (CPU)\nusage.",
    "descriptor": "",
    "authors": [
      "Nikolaos Pitropakis",
      "Christos Lyvas",
      "Costas Lambrinoudakis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.09834"
  },
  {
    "id": "arXiv:2206.09839",
    "title": "Bandwidth-Efficient Multi-video Prefetching for Short Video Streaming",
    "abstract": "Short video applications, with its attractive content, are becoming popular\namong users in recent years. In a typical short video application, a user may\nslide away the current video being watched and continue watching the next\nvideo. Such user interface causes significant bandwidth waste if users\nfrequently slide a video away before finishing watching. Solutions to reduce\nbandwidth waste without impairing the Quality of Experience (QoE) are needed.\nSolving the problem requires adaptively prefetching of short video chunks,\nwhich is challenging as the download strategy needs to match unknown user\nviewing behavior and network conditions. In this paper, firstly, we formulate\nthe problem of adaptive multi-video prefetching in short video streaming.\nSecondly, to facilitate the integration and comparison of researchers'\nalgorithms, we design and implement a discrete-event simulator and release it\nas open source. Finally, based on the organization of the Short Video Streaming\nGrand Challenge at ACM Multimedia 2022, we analyze and summarize the algorithms\nof the contestants, with the hope of promoting the research community towards\naddressing this problem.",
    "descriptor": "",
    "authors": [
      "Xutong Zuo",
      "Yishu Li",
      "Mohan Xu",
      "Wei Tsang Ooi",
      "Jiangchuan Liu",
      "Junchen Jiang",
      "Xinggong Zhang",
      "Kai Zheng",
      "Yong Cui"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.09839"
  },
  {
    "id": "arXiv:2206.09842",
    "title": "Practical Deepfake Detection: Vulnerabilities in Global Contexts",
    "abstract": "Recent advances in deep learning have enabled realistic digital alterations\nto videos, known as deepfakes. This technology raises important societal\nconcerns regarding disinformation and authenticity, galvanizing the development\nof numerous deepfake detection algorithms. At the same time, there are\nsignificant differences between training data and in-the-wild video data, which\nmay undermine their practical efficacy. We simulate data corruption techniques\nand examine the performance of a state-of-the-art deepfake detection algorithm\non corrupted variants of the FaceForensics++ dataset.\nWhile deepfake detection models are robust against video corruptions that\nalign with training-time augmentations, we find that they remain vulnerable to\nvideo corruptions that simulate decreases in video quality. Indeed, in the\ncontroversial case of the video of Gabonese President Bongo's new year address,\nthe algorithm, which confidently authenticates the original video, judges\nhighly corrupted variants of the video to be fake. Our work opens up both\ntechnical and ethical avenues of exploration into practical deepfake detection\nin global contexts.",
    "descriptor": "\nComments: 6 pages, 6 figures, presented as a workshop paper at Responsible AI @ ICLR 2021\n",
    "authors": [
      "Yang A. Chuming",
      "Daniel J. Wu",
      "Ken Hong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.09842"
  },
  {
    "id": "arXiv:2206.09843",
    "title": "Contextual Squeeze-and-Excitation for Efficient Few-Shot Image  Classification",
    "abstract": "Recent years have seen a growth in user-centric applications that require\neffective knowledge transfer across tasks in the low-data regime. An example is\npersonalization, where a pretrained system is adapted by learning on small\namounts of labeled data belonging to a specific user. This setting requires\nhigh accuracy under low computational complexity, therefore the Pareto frontier\nof accuracy vs.~adaptation cost plays a crucial role. In this paper we push\nthis Pareto frontier in the few-shot image classification setting with two key\ncontributions: (i) a new adaptive block called Contextual\nSqueeze-and-Excitation (CaSE) that adjusts a pretrained neural network on a new\ntask to significantly improve performance with a single forward pass of the\nuser data (context), and (ii) a hybrid training protocol based on\nCoordinate-Descent called UpperCaSE that exploits meta-trained CaSE blocks and\nfine-tuning routines for efficient adaptation. UpperCaSE achieves a new\nstate-of-the-art accuracy relative to meta-learners on the 26 datasets of\nVTAB+MD and on a challenging real-world personalization benchmark (ORBIT),\nnarrowing the gap with leading fine-tuning methods with the benefit of orders\nof magnitude lower adaptation cost.",
    "descriptor": "",
    "authors": [
      "Massimiliano Patacchiola",
      "John Bronskill",
      "Aliaksandra Shysheya",
      "Katja Hofmann",
      "Sebastian Nowozin",
      "Richard E. Turner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09843"
  },
  {
    "id": "arXiv:2206.09847",
    "title": "Quaternion variational integration for inertial manoeuvring in a  biomimetic UAV",
    "abstract": "Biological flying, gliding, and falling creatures are capable of\nextraordinary forms of inertial manoeuvring: free-space manoeuvring based on\nfine control of their multi-body dynamics, as typified by the self-righting\nreflexes of cats. However, designing inertial manoeuvring capability into\nbiomimetic robots, such as biomimetic unmanned aerial vehicles (UAVs) is\nchallenging. Accurately simulating the coupled multibody dynamics of these UAVs\nin a singularity-free context requires numerical integrators that can ensure\nboth singularity-free integration, and momentum and energy conservation, in a\nstrongly coupled system - properties unavailable in existing conventional\nintegrators. In this work, we develop a pair of novel quaternion variational\nintegrators (QVI) showing these properties, and demonstrate their capability\nfor simulating inertial manoeuvring in a biomimetic UAV showing complex\nmultibody-dynamics coupling. Being quaternion-valued, these QVIs are innately\nsingularity-free; and being variational, they can show excellent energy and\nmomentum conservation properties. We explore the effect of variational\nintegration order (left-rectangle vs. midpoint) on the conservation properties\nof integrator, and conclude that, in complex coupled systems in which canonical\nmomenta may be time-varying, the midpoint integrator is required. The resulting\nmidpoint QVI is well-suited to the analysis of inertial manoeuvring in a\nbiomimetic UAV - a feature that we demonstrate in simulation - and of other\ncomplex dynamical systems.",
    "descriptor": "",
    "authors": [
      "Arion Pons",
      "Fehmi Cirak"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.09847"
  },
  {
    "id": "arXiv:2206.09848",
    "title": "A Surgical Platform for Intracerebral Hemorrhage Robotic Evacuation  (ASPIHRE): A Non-metallic MR-guided Concentric Tube Robot",
    "abstract": "Intracerebral hemorrhage (ICH) is the deadliest stroke sub-type, with a\none-month mortality rate as high as 52%. Due to the potential cortical\ndisruption caused by craniotomy, conservative management (watchful waiting) has\nhistorically been a common method of treatment. Minimally invasive evacuation\nhas recently become an accepted method of treatment for patients with\ndeep-seated hematoma 30-50 mL in volume, but proper visualization and tool\ndexterity remain constrained in conventional endoscopic approaches,\nparticularly with larger hematoma volumes (> 50 mL). In this article we\ndescribe the development of ASPIHRE (A Surgical Platform for Intracerebral\nHemorrhage Robotic Evacuation), the first-ever concentric tube robot that uses\noff-the-shelf plastic tubes for MR-guided ICH evacuation, improving tool\ndexterity and procedural visualization. The robot kinematics model is developed\nbased on a calibration-based method and tube mechanics modeling, allowing the\nmodels to consider both variable curvature and torsional deflection. The\nMR-safe pneumatic motors are controlled using a variable gain PID algorithm\nproducing a rotational accuracy of 0.317 +/- 0.3 degrees. The hardware and\ntheoretical models are validated in a series of systematic bench-top and MRI\nexperiments resulting in positional accuracy of the tube tip of 1.39 +\\- 0.54\nmm. Following validation of targeting accuracy, the evacuation efficacy of the\nrobot was tested in an MR-guided phantom clot evacuation experiment. The robot\nwas able to evacuate an initially 38.36 mL clot in 5 minutes, leaving a\nresidual hematoma of 8.14 mL, well below the 15 mL guideline suggesting good\npost-ICH evacuation clinical outcomes.",
    "descriptor": "\nComments: 19 pages, 20 figures, 3 tables\n",
    "authors": [
      "Anthony L. Gunderman",
      "Saikat Sengupta",
      "Eleni Siampli",
      "Dimitri Sigounas",
      "Christopher Kellner",
      "Chima Oluigbo",
      "Karun Sharma",
      "Isuru Godage",
      "Kevin Cleary",
      "Yue Chen"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.09848"
  },
  {
    "id": "arXiv:2206.09852",
    "title": "M&M Mix: A Multimodal Multiview Transformer Ensemble",
    "abstract": "This report describes the approach behind our winning solution to the 2022\nEpic-Kitchens Action Recognition Challenge. Our approach builds upon our recent\nwork, Multiview Transformer for Video Recognition (MTV), and adapts it to\nmultimodal inputs. Our final submission consists of an ensemble of Multimodal\nMTV (M&M) models varying backbone sizes and input modalities. Our approach\nachieved 52.8% Top-1 accuracy on the test set in action classes, which is 4.1%\nhigher than last year's winning entry.",
    "descriptor": "\nComments: Technical report for Epic-Kitchens challenge 2022\n",
    "authors": [
      "Xuehan Xiong",
      "Anurag Arnab",
      "Arsha Nagrani",
      "Cordelia Schmid"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09852"
  },
  {
    "id": "arXiv:2206.09853",
    "title": "DisCoVQA: Temporal Distortion-Content Transformers for Video Quality  Assessment",
    "abstract": "The temporal relationships between frames and their influences on video\nquality assessment (VQA) are still under-studied in existing works. These\nrelationships lead to two important types of effects for video quality.\nFirstly, some temporal variations (such as shaking, flicker, and abrupt scene\ntransitions) are causing temporal distortions and lead to extra quality\ndegradations, while other variations (e.g. those related to meaningful\nhappenings) do not. Secondly, the human visual system often has different\nattention to frames with different contents, resulting in their different\nimportance to the overall video quality. Based on prominent time-series\nmodeling ability of transformers, we propose a novel and effective\ntransformer-based VQA method to tackle these two issues. To better\ndifferentiate temporal variations and thus capture the temporal distortions, we\ndesign a transformer-based Spatial-Temporal Distortion Extraction (STDE)\nmodule. To tackle with temporal quality attention, we propose the\nencoder-decoder-like temporal content transformer (TCT). We also introduce the\ntemporal sampling on features to reduce the input length for the TCT, so as to\nimprove the learning effectiveness and efficiency of this module. Consisting of\nthe STDE and the TCT, the proposed Temporal Distortion-Content Transformers for\nVideo Quality Assessment (DisCoVQA) reaches state-of-the-art performance on\nseveral VQA benchmarks without any extra pre-training datasets and up to 10%\nbetter generalization ability than existing methods. We also conduct extensive\nablation experiments to prove the effectiveness of each part in our proposed\nmodel, and provide visualizations to prove that the proposed modules achieve\nour intention on modeling these temporal issues. We will publish our codes and\npretrained weights later.",
    "descriptor": "",
    "authors": [
      "Haoning Wu",
      "Chaofeng Chen",
      "Liang Liao",
      "Jingwen Hou",
      "Wenxiu Sun",
      "Qiong Yan",
      "Weisi Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2206.09853"
  },
  {
    "id": "arXiv:2206.09859",
    "title": "Work-loop techniques for optimising nonlinear forced oscillators",
    "abstract": "Linear and nonlinear resonant states can be restrictive: they exist at\nparticular discrete states in frequency and/or elasticity, under particular\n(e.g., simple-harmonic) waveforms. In forced oscillators, this restrictiveness\nis an obstacle to system design and control modulation: altering the system\nelasticity, or modulating the response, would both appear to necessarily incur\na penalty to efficiency. In this work, we describe an approach for bypassing\nthis obstacle. Using novel work-loop techniques, we prove and illustrate how\ncertain classes of resonant optimisation problem lead to non-unique solutions.\nIn a structural optimisation context, several categories of\nenergetically-optimal elasticity are non-unique. In an optimal control context,\nseveral categories of energetically-optimal frequency are non-unique. For these\nclasses of non-unique optimum, we can derive simple bounds defining the optimal\nregion. These novel theoretical results have practical implications for the\ndesign and control of a range of biomimetic propulsion systems, including\nflapping-wing micro-air-vehicles: using these results, we can generate\nefficient forms of wingbeat modulation for flight control.",
    "descriptor": "",
    "authors": [
      "Arion Pons",
      "Tsevi Beatus"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.09859"
  },
  {
    "id": "arXiv:2206.09860",
    "title": "Fewer Errors, but More Stereotypes? The Effect of Model Size on Gender  Bias",
    "abstract": "The size of pretrained models is increasing, and so is their performance on a\nvariety of NLP tasks. However, as their memorization capacity grows, they might\npick up more social biases. In this work, we examine the connection between\nmodel size and its gender bias (specifically, occupational gender bias). We\nmeasure bias in three masked language model families (RoBERTa, DeBERTa, and T5)\nin two setups: directly using prompt based method, and using a downstream task\n(Winogender). We find on the one hand that larger models receive higher bias\nscores on the former task, but when evaluated on the latter, they make fewer\ngender errors. To examine these potentially conflicting results, we carefully\ninvestigate the behavior of the different models on Winogender. We find that\nwhile larger models outperform smaller ones, the probability that their\nmistakes are caused by gender bias is higher. Moreover, we find that the\nproportion of stereotypical errors compared to anti-stereotypical ones grows\nwith the model size. Our findings highlight the potential risks that can arise\nfrom increasing model size.",
    "descriptor": "",
    "authors": [
      "Yarden Tal",
      "Inbal Magar",
      "Roy Schwartz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.09860"
  },
  {
    "id": "arXiv:2206.09864",
    "title": "Towards Using Promises for Multi-Agent Cooperation in Goal Reasoning",
    "abstract": "Reasoning and planning for mobile robots is a challenging problem, as the\nworld evolves over time and thus the robot's goals may change. One technique to\ntackle this problem is goal reasoning, where the agent not only reasons about\nits actions, but also about which goals to pursue. While goal reasoning for\nsingle agents has been researched extensively, distributed, multi-agent goal\nreasoning comes with additional challenges, especially in a distributed\nsetting. In such a context, some form of coordination is necessary to allow for\ncooperative behavior. Previous goal reasoning approaches share the agent's\nworld model with the other agents, which already enables basic cooperation.\nHowever, the agent's goals, and thus its intentions, are typically not shared.\nIn this paper, we present a method to tackle this limitation. Extending an\nexisting goal reasoning framework, we propose enabling cooperative behavior\nbetween multiple agents through promises, where an agent may promise that\ncertain facts will be true at some point in the future. Sharing these promises\nallows other agents to not only consider the current state of the world, but\nalso the intentions of other agents when deciding on which goal to pursue next.\nWe describe how promises can be incorporated into the goal life cycle, a\ncommonly used goal refinement mechanism. We then show how promises can be used\nwhen planning for a particular goal by connecting them to timed initial\nliterals (TILs) from PDDL planning. Finally, we evaluate our prototypical\nimplementation in a simplified logistics scenario.",
    "descriptor": "\nComments: Presented at the ICAPS'22 Workshop on Planning and Robotics (PlanRob)\n",
    "authors": [
      "Daniel Swoboda",
      "Till Hofmann",
      "Tarik Viehmann",
      "Gerhard Lakemeyer"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.09864"
  },
  {
    "id": "arXiv:2206.09868",
    "title": "Understanding Robust Learning through the Lens of Representation  Similarities",
    "abstract": "Representation learning, i.e. the generation of representations useful for\ndownstream applications, is a task of fundamental importance that underlies\nmuch of the success of deep neural networks (DNNs). Recently, robustness to\nadversarial examples has emerged as a desirable property for DNNs, spurring the\ndevelopment of robust training methods that account for adversarial examples.\nIn this paper, we aim to understand how the properties of representations\nlearned by robust training differ from those obtained from standard, non-robust\ntraining. This is critical to diagnosing numerous salient pitfalls in robust\nnetworks, such as, degradation of performance on benign inputs, poor\ngeneralization of robustness, and increase in over-fitting. We utilize a\npowerful set of tools known as representation similarity metrics, across three\nvision datasets, to obtain layer-wise comparisons between robust and non-robust\nDNNs with different architectures, training procedures and adversarial\nconstraints. Our experiments highlight hitherto unseen properties of robust\nrepresentations that we posit underlie the behavioral differences of robust\nnetworks. We discover a lack of specialization in robust networks'\nrepresentations along with a disappearance of `block structure'. We also find\noverfitting during robust training largely impacts deeper layers. These, along\nwith other findings, suggest ways forward for the design and training of better\nrobust networks.",
    "descriptor": "\nComments: 35 pages, 29 figures\n",
    "authors": [
      "Christian Cianfarani",
      "Arjun Nitin Bhagoji",
      "Vikash Sehwag",
      "Ben Zhao",
      "Prateek Mittal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09868"
  },
  {
    "id": "arXiv:2206.09870",
    "title": "Privacy-aware Secure Region-based Handover for Small Cell Networks in  5G-enabled Mobile Communication",
    "abstract": "The 5G mobile communication network provides seamless communications between\nusers and service providers and promises to achieve several stringent\nrequirements, such as seamless mobility and massive connectivity. Although 5G\ncan offer numerous benefits, security and privacy issues still need to be\naddressed. For example, the inclusion of small cell networks (SCN) into 5G\nbrings the network closer to the connected users, providing a better quality of\nservices (QoS), resulting in a significant increase in the number of Handover\nprocedures (HO), which will affect the security, latency and efficiency of the\nnetwork. It is then crucial to design a scheme that supports seamless handovers\nthrough secure authentication to avoid the consequences of SCN. To address this\nissue, this article proposes a secure region-based handover scheme with user\nanonymity and an efficient revocation mechanism that supports seamless\nconnectivity for SCNs in 5G. In this context, we introduce three\nprivacy-preserving authentication protocols, i.e., initial authentication\nprotocol, intra-region handover protocol and inter-region handover protocol,\nfor dealing with three communication scenarios. To the best of our knowledge,\nthis is the first paper to consider the privacy and security in both the\nintra-region and inter-region handover scenarios in 5G communication. Detailed\nsecurity and performance analysis of our proposed scheme is presented to show\nthat it is resilient against many security threats, is cost-effective in\ncomputation and provides an efficient solution for the 5G enabled mobile\ncommunication.",
    "descriptor": "",
    "authors": [
      "Rabiah Alnashwan",
      "Prosanta Gope",
      "Benjamin Dowling"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.09870"
  },
  {
    "id": "arXiv:2206.09875",
    "title": "Algorithmic Fairness and Vertical Equity: Income Fairness with IRS Tax  Audit Models",
    "abstract": "This study examines issues of algorithmic fairness in the context of systems\nthat inform tax audit selection by the United States Internal Revenue Service\n(IRS). While the field of algorithmic fairness has developed primarily around\nnotions of treating like individuals alike, we instead explore the concept of\nvertical equity -- appropriately accounting for relevant differences across\nindividuals -- which is a central component of fairness in many public policy\nsettings. Applied to the design of the U.S. individual income tax system,\nvertical equity relates to the fair allocation of tax and enforcement burdens\nacross taxpayers of different income levels. Through a unique collaboration\nwith the Treasury Department and IRS, we use access to anonymized individual\ntaxpayer microdata, risk-selected audits, and random audits from 2010-14 to\nstudy vertical equity in tax administration. In particular, we assess how the\nuse of modern machine learning methods for selecting audits may affect vertical\nequity. First, we show how the use of more flexible machine learning\n(classification) methods -- as opposed to simpler models -- shifts audit\nburdens from high to middle-income taxpayers. Second, we show that while\nexisting algorithmic fairness techniques can mitigate some disparities across\nincome, they can incur a steep cost to performance. Third, we show that the\nchoice of whether to treat risk of underreporting as a classification or\nregression problem is highly consequential. Moving from classification to\nregression models to predict underreporting shifts audit burden substantially\ntoward high income individuals, while increasing revenue. Last, we explore the\nrole of differential audit cost in shaping the audit distribution. We show that\na narrow focus on return-on-investment can undermine vertical equity. Our\nresults have implications for the design of algorithmic tools across the public\nsector.",
    "descriptor": "",
    "authors": [
      "Emily Black",
      "Hadi Elzayn",
      "Alexandra Chouldechova",
      "Jacob Goldin",
      "Daniel E. Ho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.09875"
  },
  {
    "id": "arXiv:2206.09880",
    "title": "Breaking Down Out-of-Distribution Detection: Many Methods Based on OOD  Training Data Estimate a Combination of the Same Core Quantities",
    "abstract": "It is an important problem in trustworthy machine learning to recognize\nout-of-distribution (OOD) inputs which are inputs unrelated to the\nin-distribution task. Many out-of-distribution detection methods have been\nsuggested in recent years. The goal of this paper is to recognize common\nobjectives as well as to identify the implicit scoring functions of different\nOOD detection methods. We focus on the sub-class of methods that use surrogate\nOOD data during training in order to learn an OOD detection score that\ngeneralizes to new unseen out-distributions at test time. We show that binary\ndiscrimination between in- and (different) out-distributions is equivalent to\nseveral distinct formulations of the OOD detection problem. When trained in a\nshared fashion with a standard classifier, this binary discriminator reaches an\nOOD detection performance similar to that of Outlier Exposure. Moreover, we\nshow that the confidence loss which is used by Outlier Exposure has an implicit\nscoring function which differs in a non-trivial fashion from the theoretically\noptimal scoring function in the case where training and test out-distribution\nare the same, which again is similar to the one used when training an\nEnergy-Based OOD detector or when adding a background class. In practice, when\ntrained in exactly the same way, all these methods perform similarly.",
    "descriptor": "",
    "authors": [
      "Julian Bitterwolf",
      "Alexander Meinke",
      "Maximilian Augustin",
      "Matthias Hein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09880"
  },
  {
    "id": "arXiv:2206.09884",
    "title": "Finding $k$-Secluded Trees Faster",
    "abstract": "We revisit the \\textsc{$k$-Secluded Tree} problem. Given a vertex-weighted\nundirected graph $G$, its objective is to find a maximum-weight induced subtree\n$T$ whose open neighborhood has size at most $k$. We present a fixed-parameter\ntractable algorithm that solves the problem in time $2^{\\mathcal{O}(k \\log\nk)}\\cdot n^{\\mathcal{O}(1)}$, improving on a double-exponential running time\nfrom earlier work by Golovach, Heggernes, Lima, and Montealegre. Starting from\na single vertex, our algorithm grows a $k$-secluded tree by branching on\nvertices in the open neighborhood of the current tree $T$. To bound the\nbranching depth, we prove a structural result that can be used to identify a\nvertex that belongs to the neighborhood of any $k$-secluded supertree $T'\n\\supseteq T$ once the open neighborhood of $T$ becomes sufficiently large. We\nextend the algorithm to enumerate compact descriptions of all maximum-weight\n$k$-secluded trees, which allows us to count the number of maximum-weight\n$k$-secluded trees containing a specified vertex in the same running time.",
    "descriptor": "",
    "authors": [
      "Huib Donkers",
      "Bart M.P. Jansen",
      "Jari J.H. de Kroon"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2206.09884"
  },
  {
    "id": "arXiv:2206.09885",
    "title": "KOLOMVERSE: KRISO open large-scale image dataset for object detection in  the maritime universe",
    "abstract": "Over the years, datasets have been developed for various object detection\ntasks. Object detection in the maritime domain is essential for the safety and\nnavigation of ships. However, there is still a lack of publicly available\nlarge-scale datasets in the maritime domain. To overcome this challenge, we\npresent KOLOMVERSE, an open large-scale image dataset for object detection in\nthe maritime domain by KRISO (Korea Research Institute of Ships and Ocean\nEngineering). We collected 5,845 hours of video data captured from 21\nterritorial waters of South Korea. Through an elaborate data quality assessment\nprocess, we gathered around 2,151,470 4K resolution images from the video data.\nThis dataset considers various environments: weather, time, illumination,\nocclusion, viewpoint, background, wind speed, and visibility. The KOLOMVERSE\nconsists of five classes (ship, buoy, fishnet buoy, lighthouse and wind farm)\nfor maritime object detection. The dataset has images of 3840$\\times$2160\npixels and to our knowledge, it is by far the largest publicly available\ndataset for object detection in the maritime domain. We performed object\ndetection experiments and evaluated our dataset on several pre-trained\nstate-of-the-art architectures to show the effectiveness and usefulness of our\ndataset. The dataset is available at:\n\\url{https://github.com/MaritimeDataset/KOLOMVERSE}.",
    "descriptor": "\nComments: 13 Pages, 12 figures, submitted to NeurIPS 2022 Datasets and Benchmarks Track (Under Review)\n",
    "authors": [
      "Abhilasha Nanda",
      "Sung Won Cho",
      "Hyeopwoo Lee",
      "Jin Hyoung Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09885"
  },
  {
    "id": "arXiv:2206.09887",
    "title": "How to Assess Trustworthy AI in Practice",
    "abstract": "This report is a methodological reflection on Z-Inspection. Z-Inspection is a\nholistic process used to evaluate the trustworthiness of AI-based technologies\nat different stages of the AI lifecycle. It focuses, in particular, on the\nidentification and discussion of ethical issues and tensions through the\nelaboration of socio-technical scenarios. It uses the general European Union's\nHigh-Level Expert Group's (EU HLEG) guidelines for trustworthy AI. This report\nillustrates for both AI researchers and AI practitioners how the EU HLEG\nguidelines for trustworthy AI can be applied in practice. We share the lessons\nlearned from conducting a series of independent assessments to evaluate the\ntrustworthiness of AI systems in healthcare. We also share key recommendations\nand practical suggestions on how to ensure a rigorous trustworthy AI assessment\nthroughout the life-cycle of an AI system.",
    "descriptor": "",
    "authors": [
      "Roberto V. Zicari",
      "Julia Amann",
      "Fr\u00e9d\u00e9rick Bruneault",
      "Megan Coffee",
      "Boris D\u00fcdder",
      "Eleanore Hickman",
      "Alessio Gallucci",
      "Thomas Krendl Gilbert",
      "Thilo Hagendorff",
      "Irmhild van Halem",
      "Elisabeth Hildt",
      "Georgios Kararigas",
      "Pedro Kringen",
      "Vince I. Madai",
      "Emilie Wiinblad Mathez",
      "Jesmin Jahan Tithi",
      "Dennis Vetter",
      "Magnus Westerlund",
      "Renee Wurth"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.09887"
  },
  {
    "id": "arXiv:2206.09888",
    "title": "SoteriaFL: A Unified Framework for Private Federated Learning with  Communication Compression",
    "abstract": "To enable large-scale machine learning in bandwidth-hungry environments such\nas wireless networks, significant progress has been made recently in designing\ncommunication-efficient federated learning algorithms with the aid of\ncommunication compression. On the other end, privacy-preserving, especially at\nthe client level, is another important desideratum that has not been addressed\nsimultaneously in the presence of advanced communication compression techniques\nyet. In this paper, we propose a unified framework that enhances the\ncommunication efficiency of private federated learning with communication\ncompression. Exploiting both general compression operators and local\ndifferential privacy, we first examine a simple algorithm that applies\ncompression directly to differentially-private stochastic gradient descent, and\nidentify its limitations. We then propose a unified framework SoteriaFL for\nprivate federated learning, which accommodates a general family of local\ngradient estimators including popular stochastic variance-reduced gradient\nmethods and the state-of-the-art shifted compression scheme. We provide a\ncomprehensive characterization of its performance trade-offs in terms of\nprivacy, utility, and communication complexity, where SoteraFL is shown to\nachieve better communication complexity without sacrificing privacy nor utility\nthan other private federated learning algorithms without communication\ncompression.",
    "descriptor": "\nComments: 38 pages\n",
    "authors": [
      "Zhize Li",
      "Haoyu Zhao",
      "Boyue Li",
      "Yuejie Chi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.09888"
  },
  {
    "id": "arXiv:2206.09889",
    "title": "Nocturne: a scalable driving benchmark for bringing multi-agent learning  one step closer to the real world",
    "abstract": "We introduce \\textit{Nocturne}, a new 2D driving simulator for investigating\nmulti-agent coordination under partial observability. The focus of Nocturne is\nto enable research into inference and theory of mind in real-world multi-agent\nsettings without the computational overhead of computer vision and feature\nextraction from images. Agents in this simulator only observe an obstructed\nview of the scene, mimicking human visual sensing constraints. Unlike existing\nbenchmarks that are bottlenecked by rendering human-like observations directly\nusing a camera input, Nocturne uses efficient intersection methods to compute a\nvectorized set of visible features in a C++ back-end, allowing the simulator to\nrun at $2000+$ steps-per-second. Using open-source trajectory and map data, we\nconstruct a simulator to load and replay arbitrary trajectories and scenes from\nreal-world driving data. Using this environment, we benchmark\nreinforcement-learning and imitation-learning agents and demonstrate that the\nagents are quite far from human-level coordination ability and deviate\nsignificantly from the expert trajectories.",
    "descriptor": "",
    "authors": [
      "Eugene Vinitsky",
      "Nathan Lichtl\u00e9",
      "Xiaomeng Yang",
      "Brandon Amos",
      "Jakob Foerster"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.09889"
  },
  {
    "id": "arXiv:2206.09891",
    "title": "Latent Variable Modelling Using Variational Autoencoders: A survey",
    "abstract": "A probability distribution allows practitioners to uncover hidden structure\nin the data and build models to solve supervised learning problems using\nlimited data. The focus of this report is on Variational autoencoders, a method\nto learn the probability distribution of large complex datasets. The report\nprovides a theoretical understanding of variational autoencoders and\nconsolidates the current research in the field.\nThe report is divided into multiple chapters, the first chapter introduces\nthe problem, describes variational autoencoders and identifies key research\ndirections in the field. Chapters 2, 3, 4 and 5 dive into the details of each\nof the key research areas. Chapter 6 concludes the report and suggests\ndirections for future work.\nA reader who has a basic idea of machine learning but wants to learn about\ngeneral themes in machine learning research can benefit from the report. The\nreport explains central ideas on learning probability distributions, what\npeople did to make this tractable and goes into details around how deep\nlearning is currently applied. The report also serves a gentle introduction for\nsomeone looking to contribute to this sub-field.",
    "descriptor": "",
    "authors": [
      "Vasanth Kalingeri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.09891"
  },
  {
    "id": "arXiv:2206.09894",
    "title": "NoteG: A Computational Notebook to Facilitate Rapid Game Prototyping",
    "abstract": "Game development-based approaches are increasingly used to design curricula\nthat can engage students, as these can help them apply and practice learnt\ncomputer science concepts. However, it can become complex to develop a minimum\nworking game or a prototype with the help of high-end game engines. Game\nprototyping is one of the most essential parts of the game design and\ndevelopment cycle as it allows developers to continuously test and improve\ntheir ideas. In recent years, computational notebooks have gained widespread\npopularity among developers. They can help run individual code snippets,\nvisualize the output, consolidate the source code, and share live code easily.\nHowever, its use has not been explored in the field of game development and\nprototyping. In this paper, we propose NoteG, a computational notebook towards\nrapid game prototyping. We evaluated the tool with 18 novice game developers\nthrough a questionnaire-based user survey. A majority of the volunteers (66%)\nfound it easy to use and were of the opinion that it saves time. A few of the\nparticipants successfully extended the existing framework to implement new game\nmechanics within their prototypes.",
    "descriptor": "",
    "authors": [
      "Noble Saji Mathews",
      "Sridhar Chimalakonda"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.09894"
  },
  {
    "id": "arXiv:2206.09895",
    "title": "Multiple Fairness and Cardinality constraints for Students-Topics  Grouping Problem",
    "abstract": "Group work is a prevalent activity in educational settings, where students\nare often divided into topic-specific groups based on their preferences. The\ngrouping should reflect the students' aspirations as much as possible. Usually,\nthe resulting groups should also be balanced in terms of protected attributes\nlike gender or race since studies indicate that students might learn better in\na diverse group. Moreover, balancing the group cardinalities is also an\nessential requirement for fair workload distribution across the groups. In this\npaper, we introduce the multi-fair capacitated (MFC) grouping problem that\nfairly partitions students into non-overlapping groups while ensuring balanced\ngroup cardinalities (with a lower bound and an upper bound), and maximizing the\ndiversity of members in terms of protected attributes. We propose two\napproaches: a heuristic method and a knapsack-based method to obtain the MFC\ngrouping. The experiments on a real dataset and a semi-synthetic dataset show\nthat our proposed methods can satisfy students' preferences well and deliver\nbalanced and diverse groups regarding cardinality and the protected attribute,\nrespectively.",
    "descriptor": "\nComments: 15 pages, 4 figures, 1 table\n",
    "authors": [
      "Tai Le Quy",
      "Gunnar Friege",
      "Eirini Ntoutsi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.09895"
  },
  {
    "id": "arXiv:2206.09900",
    "title": "Voxel-MAE: Masked Autoencoders for Pre-training Large-scale Point Clouds",
    "abstract": "Mask-based pre-training has achieved great success for self-supervised\nlearning in image, video and language, without manually annotated supervision.\nHowever, as information redundant data, it has not yet been studied in the\nfield of 3D object detection. As the point clouds in 3D object detection is\nlarge-scale, it is impossible to reconstruct the input point clouds. In this\npaper, we propose a mask voxel classification network for large-scale point\nclouds pre-training. Our key idea is to divide the point clouds into voxel\nrepresentations and classify whether the voxel contains point clouds. This\nsimple strategy makes the network to be voxel-aware of the object shape, thus\nimproving the performance of 3D object detection. Extensive experiments show\ngreat effectiveness of our pre-trained model with 3D object detectors (SECOND,\nCenterPoint, and PV-RCNN) on three popular datasets (KITTI, Waymo, and\nnuScenes). Codes are publicly available at https:\n//github.com/chaytonmin/Voxel-MAE.",
    "descriptor": "\nComments: 8 pages, 1 figures\n",
    "authors": [
      "Chen Min",
      "Dawei Zhao",
      "Liang Xiao",
      "Yiming Nie",
      "Bin Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09900"
  },
  {
    "id": "arXiv:2206.09906",
    "title": "Achieving Dexterous Bidirectional Interaction in Uncertain Conditions  for Medical Robotics",
    "abstract": "Medical robotics can help improve and extend the reach of healthcare\nservices. A major challenge for medical robots is the complex physical\ninteraction between the robot and the patients which is required to be safe.\nThis work presents the preliminary evaluation of a recently introduced control\narchitecture based on the Fractal Impedance Control (FIC) in medical\napplications. The deployed FIC architecture is robust to delay between the\nmaster and the replica robots. It can switch online between an admittance and\nimpedance behaviour, and it is robust to interaction with unstructured\nenvironments. Our experiments analyse three scenarios: teleoperated surgery,\nrehabilitation, and remote ultrasound scan. The experiments did not require any\nadjustment of the robot tuning, which is essential in medical applications\nwhere the operators do not have an engineering background required to tune the\ncontroller. Our results show that is possible to teleoperate the robot to cut\nusing a scalpel, do an ultrasound scan, and perform remote occupational\ntherapy. However, our experiments also highlighted the need for a better robots\nembodiment to precisely control the system in 3D dynamic tasks.",
    "descriptor": "\nComments: video: this https URL\n",
    "authors": [
      "Carlo Tiseo",
      "Quentin Rouxel",
      "Martin Asenov",
      "Keyhan Kouhkiloui Babarahmati",
      "Subramanian Ramamoorthy",
      "Zhibin Li",
      "Michael Mistry"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.09906"
  },
  {
    "id": "arXiv:2206.09907",
    "title": "ORFD: A Dataset and Benchmark for Off-Road Freespace Detection",
    "abstract": "Freespace detection is an essential component of autonomous driving\ntechnology and plays an important role in trajectory planning. In the last\ndecade, deep learning-based free space detection methods have been proved\nfeasible. However, these efforts were focused on urban road environments and\nfew deep learning-based methods were specifically designed for off-road free\nspace detection due to the lack of off-road benchmarks. In this paper, we\npresent the ORFD dataset, which, to our knowledge, is the first off-road free\nspace detection dataset. The dataset was collected in different scenes\n(woodland, farmland, grassland, and countryside), different weather conditions\n(sunny, rainy, foggy, and snowy), and different light conditions (bright light,\ndaylight, twilight, darkness), which totally contains 12,198 LiDAR point cloud\nand RGB image pairs with the traversable area, non-traversable area and\nunreachable area annotated in detail. We propose a novel network named OFF-Net,\nwhich unifies Transformer architecture to aggregate local and global\ninformation, to meet the requirement of large receptive fields for free space\ndetection tasks. We also propose the cross-attention to dynamically fuse LiDAR\nand RGB image information for accurate off-road free space detection. Dataset\nand code are publicly available athttps://github.com/chaytonmin/OFF-Net.",
    "descriptor": "\nComments: 8 pages, 8 figures\n",
    "authors": [
      "Chen Min",
      "Weizhong Jiang",
      "Dawei Zhao",
      "Jiaolong Xu",
      "Liang Xiao",
      "Yiming Nie",
      "Bin Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09907"
  },
  {
    "id": "arXiv:2206.09909",
    "title": "Low-Precision Stochastic Gradient Langevin Dynamics",
    "abstract": "While low-precision optimization has been widely used to accelerate deep\nlearning, low-precision sampling remains largely unexplored. As a consequence,\nsampling is simply infeasible in many large-scale scenarios, despite providing\nremarkable benefits to generalization and uncertainty estimation for neural\nnetworks. In this paper, we provide the first study of low-precision Stochastic\nGradient Langevin Dynamics (SGLD), showing that its costs can be significantly\nreduced without sacrificing performance, due to its intrinsic ability to handle\nsystem noise. We prove that the convergence of low-precision SGLD with\nfull-precision gradient accumulators is less affected by the quantization error\nthan its SGD counterpart in the strongly convex setting. To further enable\nlow-precision gradient accumulators, we develop a new quantization function for\nSGLD that preserves the variance in each update step. We demonstrate that\nlow-precision SGLD achieves comparable performance to full-precision SGLD with\nonly 8 bits on a variety of deep learning tasks.",
    "descriptor": "\nComments: Published at ICML 2022\n",
    "authors": [
      "Ruqi Zhang",
      "Andrew Gordon Wilson",
      "Christopher De Sa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.09909"
  },
  {
    "id": "arXiv:2206.09910",
    "title": "Timeline Design Space for Immersive Exploration of Time-Varying Spatial  3D Data",
    "abstract": "Timelines are common visualizations to represent and manipulate temporal\ndata, from historical events storytelling to animation authoring. However,\ntimeline visualizations rarely consider spatio-temporal 3D data (e.g. mesh or\nvolumetric models) directly, which are typically explored using 3D visualizers\nonly displaying one time-step at a time. In this paper, leveraging the\nincreased workspace and 3D interaction capabilities of virtual reality, we\npropose to use timelines for the visualization of 3D temporal data to support\nexploration and analysis. First, we propose a timeline design space for 3D\ntemporal data extending the timeline design space proposed by Brehmer et al.\nThe proposed design space adapts the scale, layout and representation\ndimensions to account for the depth dimension and how 3D temporal data can be\npartitioned and structured. In our approach, an additional dimension is\nintroduced, the support, which further characterizes the 3D dimension of the\nvisualization. To complement the design space and the interaction capabilities\nof VR systems, we discuss the interaction methods required for the efficient\nvisualization of 3D timelines. Then, to evaluate the benefits of 3D timelines,\nwe conducted a formal evaluation with two main objectives: comparing the\nproposed visualization with a traditional visualization method; exploring how\nusers interact with different 3D timeline designs. Our results showed that\ntime-related tasks can be achieved more comfortably using timelines, and more\nefficiently for specific tasks requiring the analysis of the surrounding\ntemporal context. Though the comparison between the different timeline designs\nwere inconclusive, participants reported a clear preference towards the\ntimeline design that did not occupy the vertical space. Finally, we illustrate\nthe use of the 3D timelines to a real use-case on the analysis of biological 3D\ntemporal datasets.",
    "descriptor": "\nComments: 11 pages, 6 figures\n",
    "authors": [
      "Gwendal Fouch\u00e9",
      "Ferran Argelaguet",
      "Emmanuel Faure",
      "Charles Kervrann"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2206.09910"
  },
  {
    "id": "arXiv:2206.09912",
    "title": "A Dense Representation Framework for Lexical and Semantic Matching",
    "abstract": "Lexical and semantic matching capture different successful approaches to text\nretrieval and the fusion of their results has proven to be more effective and\nrobust than either alone. Prior work performs hybrid retrieval by conducting\nlexical and semantic text matching using different systems (e.g., Lucene and\nFaiss, respectively) and then fusing their model outputs. In contrast, our work\nintegrates lexical representations with dense semantic representations by\ndensifying high-dimensional lexical representations into what we call\nlow-dimensional dense lexical representations (DLRs). Our experiments show that\nDLRs can effectively approximate the original lexical representations,\npreserving effectiveness while improving query latency. Furthermore, we can\ncombine dense lexical and semantic representations to generate dense hybrid\nrepresentations (DHRs) that are more flexible and yield faster retrieval\ncompared to existing hybrid techniques. Finally, we explore {\\it jointly}\ntraining lexical and semantic representations in a single model and empirically\nshow that the resulting DHRs are able to combine the advantages of each\nindividual component. Our best DHR model is competitive with state-of-the-art\nsingle-vector and multi-vector dense retrievers in both in-domain and zero-shot\nevaluation settings. Furthermore, our model is both faster and requires smaller\nindexes, making our dense representation framework an attractive approach to\ntext retrieval. Our code is available at https://github.com/castorini/dhr.",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Sheng-Chieh Lin",
      "Jimmy Lin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.09912"
  },
  {
    "id": "arXiv:2206.09914",
    "title": "A Langevin-like Sampler for Discrete Distributions",
    "abstract": "We propose discrete Langevin proposal (DLP), a simple and scalable\ngradient-based proposal for sampling complex high-dimensional discrete\ndistributions. In contrast to Gibbs sampling-based methods, DLP is able to\nupdate all coordinates in parallel in a single step and the magnitude of\nchanges is controlled by a stepsize. This allows a cheap and efficient\nexploration in the space of high-dimensional and strongly correlated variables.\nWe prove the efficiency of DLP by showing that the asymptotic bias of its\nstationary distribution is zero for log-quadratic distributions, and is small\nfor distributions that are close to being log-quadratic. With DLP, we develop\nseveral variants of sampling algorithms, including unadjusted,\nMetropolis-adjusted, stochastic and preconditioned versions. DLP outperforms\nmany popular alternatives on a wide variety of tasks, including Ising models,\nrestricted Boltzmann machines, deep energy-based models, binary neural networks\nand language generation.",
    "descriptor": "\nComments: Published at ICML 2022\n",
    "authors": [
      "Ruqi Zhang",
      "Xingchao Liu",
      "Qiang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.09914"
  },
  {
    "id": "arXiv:2206.09917",
    "title": "Multilingual HateCheck: Functional Tests for Multilingual Hate Speech  Detection Models",
    "abstract": "Hate speech detection models are typically evaluated on held-out test sets.\nHowever, this risks painting an incomplete and potentially misleading picture\nof model performance because of increasingly well-documented systematic gaps\nand biases in hate speech datasets. To enable more targeted diagnostic\ninsights, recent research has thus introduced functional tests for hate speech\ndetection models. However, these tests currently only exist for\nEnglish-language content, which means that they cannot support the development\nof more effective models in other languages spoken by billions across the\nworld. To help address this issue, we introduce Multilingual HateCheck (MHC), a\nsuite of functional tests for multilingual hate speech detection models. MHC\ncovers 34 functionalities across ten languages, which is more languages than\nany other hate speech dataset. To illustrate MHC's utility, we train and test a\nhigh-performing multilingual hate speech detection model, and reveal critical\nmodel weaknesses for monolingual and cross-lingual applications.",
    "descriptor": "\nComments: Accepted at WOAH (NAACL 2022)\n",
    "authors": [
      "Paul R\u00f6ttger",
      "Haitham Seelawi",
      "Debora Nozza",
      "Zeerak Talat",
      "Bertie Vidgen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.09917"
  },
  {
    "id": "arXiv:2206.09920",
    "title": "WOLONet: Wave Outlooker for Efficient and High Fidelity Speech Synthesis",
    "abstract": "Recently, GAN-based neural vocoders such as Parallel WaveGAN, MelGAN,\nHiFiGAN, and UnivNet have become popular due to their lightweight and parallel\nstructure, resulting in a real-time synthesized waveform with high fidelity,\neven on a CPU. HiFiGAN and UnivNet are two SOTA vocoders. Despite their high\nquality, there is still room for improvement. In this paper, motivated by the\nstructure of Vision Outlooker from computer vision, we adopt a similar idea and\npropose an effective and lightweight neural vocoder called WOLONet. In this\nnetwork, we develop a novel lightweight block that uses a location-variable,\nchannel-independent, and depthwise dynamic convolutional kernel with\nsinusoidally activated dynamic kernel weights. To demonstrate the effectiveness\nand generalizability of our method, we perform an ablation study to verify our\nnovel design and make a subjective and objective comparison with typical\nGAN-based vocoders. The results show that our WOLONet achieves the best\ngeneration quality while requiring fewer parameters than the two neural SOTA\nvocoders, HiFiGAN and UnivNet.",
    "descriptor": "",
    "authors": [
      "Yi Wang",
      "Yi Si"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.09920"
  },
  {
    "id": "arXiv:2206.09945",
    "title": "Sparse Representations of Dynamical Networks: A Coprime Factorization  Approach",
    "abstract": "We study a general class of dynamical networks modeled by linear and\ntime-invariant systems, described by state-space realizations. For these\nnetworks, we investigate the relations between various types of factorizations\nwhich preserve the structure of their component subsystems' interconnection. In\ndoing so, we provide tractable means of shifting between different types of\nsparsity-preserving representations and we show how to employ these\nfactorizations to obtain distributed implementations for stabilizing and\npossibly stable controllers. By formulating all the aforementioned results for\nboth discrete- and continuous-time systems, we develop specialized distributed\nimplementations that, up to this point, were only available for networks\nmodeled as discrete-time systems.",
    "descriptor": "\nComments: 16 pages, 5 figures, 1 table\n",
    "authors": [
      "\u015eerban Sab\u0103u",
      "Andrei Speril\u0103",
      "Cristian Oar\u0103",
      "Ali Jadbabaie"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.09945"
  },
  {
    "id": "arXiv:2206.09946",
    "title": "Short Video Uprising: How #BlackLivesMatter Content on TikTok Challenges  the Protest Paradigm",
    "abstract": "This study uses TikTok (N = 8,173) to examine how short-form video platforms\nchallenge the protest paradigm in the recent Black Lives Matter movement. A\ncomputer-mediated visual analysis, computer vision, is employed to identify the\npresence of four visual frames of protest (riot, confrontation, spectacle, and\ndebate) in multimedia content. Results of descriptive statistics and the t-test\nindicate that the three delegitimizing frames - riot, confrontation, and\nspectacle - are rarely found on TikTok, whereas the debate frame, that empowers\nmarginalized communities, dominates the public sphere. However, although the\nthree delegitimizing frames receive lower social media visibility, as measured\nby views, likes, shares, followers, and durations, legitimizing elements, such\nas the debate frame, minority identities, and unofficial sources, are not\ngenerally favored by TikTok audiences. This study concludes that while\nshort-form video platforms could potentially challenge the protest paradigm on\nthe content creators' side, the audiences' preference as measured by social\nmedia visibility might still be moderately associated with the protest\nparadigm.",
    "descriptor": "\nComments: Workshop Proceedings of the 16th International AAAI Conference on Web and Social Media\n",
    "authors": [
      "Yanru Jiang",
      "Xin Jin",
      "Qinhao Deng"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09946"
  },
  {
    "id": "arXiv:2206.09951",
    "title": "Seizure Detection and Prediction by Parallel Memristive Convolutional  Neural Networks",
    "abstract": "During the past two decades, epileptic seizure detection and prediction\nalgorithms have evolved rapidly. However, despite significant performance\nimprovements, their hardware implementation using conventional technologies,\nsuch as Complementary Metal-Oxide-Semiconductor (CMOS), in power and\narea-constrained settings remains a challenging task; especially when many\nrecording channels are used. In this paper, we propose a novel low-latency\nparallel Convolutional Neural Network (CNN) architecture that has between\n2-2,800x fewer network parameters compared to SOTA CNN architectures and\nachieves 5-fold cross validation accuracy of 99.84% for epileptic seizure\ndetection, and 99.01% and 97.54% for epileptic seizure prediction, when\nevaluated using the University of Bonn Electroencephalogram (EEG), CHB-MIT and\nSWEC-ETHZ seizure datasets, respectively. We subsequently implement our network\nonto analog crossbar arrays comprising Resistive Random-Access Memory (RRAM)\ndevices, and provide a comprehensive benchmark by simulating, laying out, and\ndetermining hardware requirements of the CNN component of our system. To the\nbest of our knowledge, we are the first to parallelize the execution of\nconvolution layer kernels on separate analog crossbars to enable 2 orders of\nmagnitude reduction in latency compared to SOTA hybrid Memristive-CMOS DL\naccelerators. Furthermore, we investigate the effects of non-idealities on our\nsystem and investigate Quantization Aware Training (QAT) to mitigate the\nperformance degradation due to low ADC/DAC resolution. Finally, we propose a\nstuck weight offsetting methodology to mitigate performance degradation due to\nstuck RON/ROFF memristor weights, recovering up to 32% accuracy, without\nrequiring retraining. The CNN component of our platform is estimated to consume\napproximately 2.791W of power while occupying an area of 31.255mm$^2$ in a 22nm\nFDSOI CMOS process.",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Biomedical Circuits and Systems\n",
    "authors": [
      "Chenqi Li",
      "Corey Lammie",
      "Xuening Dong",
      "Amirali Amirsoleimani",
      "Mostafa Rahimi Azghadi",
      "Roman Genov"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2206.09951"
  },
  {
    "id": "arXiv:2206.09959",
    "title": "Global Context Vision Transformers",
    "abstract": "We propose global context vision transformer (GC ViT), a novel architecture\nthat enhances parameter and compute utilization. Our method leverages global\ncontext self-attention modules, joint with local self-attention, to effectively\nyet efficiently model both long and short-range spatial interactions, without\nthe need for expensive operations such as computing attention masks or shifting\nlocal windows. In addition, we address the issue of lack of the inductive bias\nin ViTs via proposing to use a modified fused inverted residual blocks in our\narchitecture. Our proposed GC ViT achieves state-of-the-art results across\nimage classification, object detection and semantic segmentation tasks. On\nImageNet-1K dataset for classification, the base, small and tiny variants of GC\nViT with $28$M, $51$M and $90$M parameters achieve $\\textbf{83.2\\%}$,\n$\\textbf{83.9\\%}$ and $\\textbf{84.4\\%}$ Top-1 accuracy, respectively,\nsurpassing comparably-sized prior art such as CNN-based ConvNeXt and ViT-based\nSwin Transformer by a large margin. Pre-trained GC ViT backbones in downstream\ntasks of object detection, instance segmentation, and semantic segmentation\nusing MS COCO and ADE20K datasets outperform prior work consistently, sometimes\nby large margins. Code available at https://github.com/NVlabs/GCViT.",
    "descriptor": "\nComments: Tech. Report\n",
    "authors": [
      "Ali Hatamizadeh",
      "Hongxu Yin",
      "Jan Kautz",
      "Pavlo Molchanov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09959"
  },
  {
    "id": "arXiv:2206.09960",
    "title": "A Fast Algorithm for Ranking Users by their Influence in Online Social  Platforms",
    "abstract": "Measuring the influence of users in social networks is key for numerous\napplications. A recently proposed influence metric, coined as $\\psi$-score,\nallows to go beyond traditional centrality metrics, which only assess\nstructural graph importance, by further incorporating the rich information\nprovided by the posting and re-posting activity of users. The $\\psi$-score is\nshown in fact to generalize PageRank for non-homogeneous node activity. Despite\nits significance, it scales poorly to large datasets; for a network of $N$\nusers it requires to solve $N$ linear systems of equations of size $N$. To\naddress this problem, this work introduces a novel scalable algorithm for the\nfast approximation of $\\psi$-score, named Power-$\\psi$. The proposed algorithm\nis based on a novel equation indicating that it suffices to solve one system of\nequations of size $N$ to compute the $\\psi$-score. Then, our algorithm exploits\nthe fact that such system can be recursively and distributedly approximated to\nany desired error. This permits the $\\psi$-score, summarizing both structural\nand behavioral information for the nodes, to run as fast as PageRank. We\nvalidate the effectiveness of the proposed algorithm on several real-world\ndatasets.",
    "descriptor": "\nComments: To be published in the 2022 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)\n",
    "authors": [
      "Nouamane Arhachoui",
      "Esteban Bautista",
      "Maximilien Danisch",
      "Anastasios Giovanidis"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.09960"
  },
  {
    "id": "arXiv:2206.09961",
    "title": "Critical Investigation of Failure Modes in Physics-informed Neural  Networks",
    "abstract": "Several recent works in scientific machine learning have revived interest in\nthe application of neural networks to partial differential equations (PDEs). A\npopular approach is to aggregate the residual form of the governing PDE and its\nboundary conditions as soft penalties into a composite objective/loss function\nfor training neural networks, which is commonly referred to as physics-informed\nneural networks (PINNs). In the present study, we visualize the loss landscapes\nand distributions of learned parameters and explain the ways this particular\nformulation of the objective function may hinder or even prevent convergence\nwhen dealing with challenging target solutions. We construct a purely\ndata-driven loss function composed of both the boundary loss and the domain\nloss. Using this data-driven loss function and, separately, a physics-informed\nloss function, we then train two neural network models with the same\narchitecture. We show that incomparable scales between boundary and domain loss\nterms are the culprit behind the poor performance. Additionally, we assess the\nperformance of both approaches on two elliptic problems with increasingly\ncomplex target solutions. Based on our analysis of their loss landscapes and\nlearned parameter distributions, we observe that a physics-informed neural\nnetwork with a composite objective function formulation produces highly\nnon-convex loss surfaces that are difficult to optimize and are more prone to\nthe problem of vanishing gradients.",
    "descriptor": "",
    "authors": [
      "Shamsulhaq Basir",
      "Inanc Senocak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.09961"
  },
  {
    "id": "arXiv:2206.09962",
    "title": "Model-Free Optimal Control of Inverter for Dynamic Voltage Support",
    "abstract": "Inverter-based resources (IBRs) are required to provide dynamic voltage\nsupport (DVS) during voltage dips to enhance the low-voltage ride-through\ncapability. In this paper, we develop a model-free control method to achieve\nthe optimal DVS (ODVS) without relying on the knowledge of grid parameters.\nDelving into the optimum trajectory of the ODVS problem, it is found that\neither the current constraint and the maximum active power constraint of IBRs\nare binding or one of the constraints is binding. This inspires us to search\nfor the optimum in a closed-loop way by a perturb-and-observe (P&O)-based\noptimum seeking (OS) controller with either the power factor angle or the\nreactive current being the manipulated (perturbed) variable. The system is\nguaranteed to converge asymptotically to the optimum provided the stepsize\nsequence is diminishing and non-summable. The proposed model-free optimal\ncontrol is finally implemented within a single-stage photovoltaic (PV) system,\nwhere dynamic simulations demonstrate the optimal and fast DVS performance",
    "descriptor": "",
    "authors": [
      "Yifei Guo",
      "Bikash C. Pal",
      "Rabih A. Jabr"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.09962"
  },
  {
    "id": "arXiv:2206.09967",
    "title": "PR-SZZ: How pull requests can support the tracing of defects in software  repositories",
    "abstract": "The SZZ algorithm represents a standard way to identify bug fixing commits as\nwell as inducing counterparts. It forms the basis for data sets used in\nnumerous empirical studies. Since its creation, multiple extensions have been\nproposed to enhance its performance. For historical reasons, related work\nrelies on commit messages to map bug tickets to possibly related code with no\nadditional data used to trace inducing commits from these fixes. Therefore, we\npresent an updated version of SZZ utilizing pull requests, which are widely\nadopted today. We evaluate our approach in comparison to existing SZZ variants\nby conducting experiments and analyzing the usage of pull requests, inner\ncommits, and merge strategies. We base our results on 6 open-source projects\nwith more than 50k commits and 35k pull requests. With respect to bug fixing\ncommits, on average 18% of bug tickets can be additionally mapped to a fixing\ncommit, resulting in an overall F-score of 0.75, an improvement of 40\npercentage points. By selecting an inducing commit, we manage to reduce the\nfalse-positives and increase precision by on average 16 percentage points in\ncomparison to existing approaches.",
    "descriptor": "\nComments: 12 pages, 3 figures, accepted at 29th edition of the IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER'22)\n",
    "authors": [
      "Peter Bludau",
      "Alexander Pretschner"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.09967"
  },
  {
    "id": "arXiv:2206.09973",
    "title": "Two-sided Robustly Testable Codes",
    "abstract": "We show that the tensor product of two random linear codes is robustly\ntestable with high probability. This implies that one can obtain pairs of\nlinear codes such that their product and the product of their dual codes are\nsimultaneously robustly testable. Such two-sided robustly testable codes (with\na much weaker form of robustness) were the key ingredient in the recent\nconstructions of asymptotically good quantum LDPC codes, which ensured their\nlinear minimum distance. We hope that the existence of such codes with a\nstronger form of robustness, shown here, can be used to simplify the proofs and\nprovide better distance bounds in these constructions. We also give new very\nsimple examples of non-robustly testable codes. We show that if the\nparity-checks of two codes are mutually orthogonal, then their product is not\nrobustly testable. In particular, this implies that the product of a code with\nits dual code is not robustly testable. We also study a property of a\ncollection of linear codes called product-expansion, which can be viewed as a\ncoboundary expansion of the cochain complex naturally associated with the\nproduct of these codes. We show that this property is related with the robust\ntestability and the agreement testability of the products of codes.",
    "descriptor": "\nComments: 21 pages, 3 figures\n",
    "authors": [
      "Gleb Kalachev",
      "Pavel Panteleev"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.09973"
  },
  {
    "id": "arXiv:2206.09976",
    "title": "Noise Estimation in Gaussian Process Regression",
    "abstract": "We develop a computational procedure to estimate the covariance\nhyperparameters for semiparametric Gaussian process regression models with\nadditive noise. Namely, the presented method can be used to efficiently\nestimate the variance of the correlated error, and the variance of the noise\nbased on maximizing a marginal likelihood function. Our method involves\nsuitably reducing the dimensionality of the hyperparameter space to simplify\nthe estimation procedure to a univariate root-finding problem. Moreover, we\nderive bounds and asymptotes of the marginal likelihood function and its\nderivatives, which are useful to narrowing the initial range of the\nhyperparameter search. Using numerical examples, we demonstrate the\ncomputational advantages and robustness of the presented approach compared to\ntraditional parameter optimization.",
    "descriptor": "",
    "authors": [
      "Siavash Ameli",
      "Shawn C. Shadden"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.09976"
  },
  {
    "id": "arXiv:2206.09977",
    "title": "Thompson Sampling Efficiently Learns to Control Diffusion Processes",
    "abstract": "Diffusion processes that evolve according to linear stochastic differential\nequations are an important family of continuous-time dynamic decision-making\nmodels. Optimal policies are well-studied for them, under full certainty about\nthe drift matrices. However, little is known about data-driven control of\ndiffusion processes with uncertain drift matrices as conventional discrete-time\nanalysis techniques are not applicable. In addition, while the task can be\nviewed as a reinforcement learning problem involving exploration and\nexploitation trade-off, ensuring system stability is a fundamental component of\ndesigning optimal policies. We establish that the popular Thompson sampling\nalgorithm learns optimal actions fast, incurring only a square-root of time\nregret, and also stabilizes the system in a short time period. To the best of\nour knowledge, this is the first such result for Thompson sampling in a\ndiffusion process control problem. We validate our theoretical results through\nempirical simulations with real parameter matrices from two settings of\nairplane and blood glucose control. Moreover, we observe that Thompson sampling\nsignificantly improves (worst-case) regret, compared to the state-of-the-art\nalgorithms, suggesting Thompson sampling explores in a more guarded fashion.\nOur theoretical analysis involves characterization of a certain optimality\nmanifold that ties the local geometry of the drift parameters to the optimal\ncontrol of the diffusion process. We expect this technique to be of broader\ninterest.",
    "descriptor": "",
    "authors": [
      "Mohamad Kazem Shirani Faradonbeh",
      "Mohamad Sadegh Shirani Faradonbeh",
      "Mohsen Bayati"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.09977"
  },
  {
    "id": "arXiv:2206.09978",
    "title": "German AI Start-Ups and AI Ethics: Using A Social Practice Lens for  Assessing and Implementing Socio-Technical Innovation",
    "abstract": "Within the current AI ethics discourse, there is a gap in empirical research\non understanding how AI practitioners understand ethics and socially organize\nto operationalize ethical concerns, particularly in the context of AI\nstart-ups. This gap intensifies the risk of a disconnect between scholarly\nresearch, innovation, and application. This risk materializes acutely as\nmounting pressures to identify and mitigate the potential harms of AI systems\nhave created an urgent need to assess and implement socio-technical innovation\nfor fairness, accountability, and transparency. Building on social practice\ntheory, we address this need via a framework that allows AI researchers,\npractitioners, and regulators to systematically analyze existing cultural\nunderstandings, histories, and social practices of ethical AI to define\nappropriate strategies for effectively implementing socio-technical\ninnovations. Our contributions are threefold: 1) we introduce a practice-based\napproach for understanding ethical AI; 2) we present empirical findings from\nour study on the operationalization of ethics in German AI start-ups to\nunderline that AI ethics and social practices must be understood in their\nspecific cultural and historical contexts; and 3) based on our empirical\nfindings, we suggest that ethical AI practices can be broken down into\nprinciples, needs, narratives, materializations, and cultural genealogies to\nform a useful backdrop for considering socio-technical innovations.",
    "descriptor": "",
    "authors": [
      "Mona Sloane",
      "Janina Zakrzewski"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.09978"
  },
  {
    "id": "arXiv:2206.09979",
    "title": "Mitigating Data Heterogeneity in Federated Learning with Data  Augmentation",
    "abstract": "Federated Learning (FL) is a prominent framework that enables training a\ncentralized model while securing user privacy by fusing local, decentralized\nmodels. In this setting, one major obstacle is data heterogeneity, i.e., each\nclient having non-identically and independently distributed (non-IID) data.\nThis is analogous to the context of Domain Generalization (DG), where each\nclient can be treated as a different domain. However, while many approaches in\nDG tackle data heterogeneity from the algorithmic perspective, recent evidence\nsuggests that data augmentation can induce equal or greater performance.\nMotivated by this connection, we present federated versions of popular DG\nalgorithms, and show that by applying appropriate data augmentation, we can\nmitigate data heterogeneity in the federated setting, and obtain higher\naccuracy on unseen clients. Equipped with data augmentation, we can achieve\nstate-of-the-art performance using even the most basic Federated Averaging\nalgorithm, with much sparser communication.",
    "descriptor": "\nComments: 18 pages, 5 figures\n",
    "authors": [
      "Artur Back de Luca",
      "Guojun Zhang",
      "Xi Chen",
      "Yaoliang Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09979"
  },
  {
    "id": "arXiv:2206.09980",
    "title": "Semantic preservation for a type directed translation scheme of  Featherweight Go",
    "abstract": "Featherweight Go (FG) is a minimal core calculus that includes essential Go\nfeatures such as overloaded methods and interface types. The most\nstraightforward semantic description of the dynamic behavior of FG programs is\nto resolve method calls based on run-time type information. A more efficient\napproach is to apply a type-directed translation scheme where interface-values\nare replaced by dictionaries that contain concrete method definitions. Thus,\nmethod calls can be resolved by a simple lookup of the method definition in the\ndictionary. Establishing that the target program obtained via the type-directed\ntranslation scheme preserves the semantics of the original FG program is an\nimportant task. To establish this property we employ logical relations that are\nindexed by types to relate source and target programs. We provide rigorous\nproofs and give a detailed discussion of the many subtle corners that we have\nencountered including the need for a step index due to recursive interfaces and\nmethod definitions.",
    "descriptor": "\nComments: 38 pages, includes appendix with full proofs\n",
    "authors": [
      "Martin Sulzmann",
      "Stefan Wehr"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2206.09980"
  },
  {
    "id": "arXiv:2206.09981",
    "title": "Measuring Class-Imbalance Sensitivity of Deterministic Performance  Evaluation Metrics",
    "abstract": "The class-imbalance issue is intrinsic to many real-world machine learning\ntasks, particularly to the rare-event classification problems. Although the\nimpact and treatment of imbalanced data is widely known, the magnitude of a\nmetric's sensitivity to class imbalance has attracted little attention. As a\nresult, often the sensitive metrics are dismissed while their sensitivity may\nonly be marginal. In this paper, we introduce an intuitive evaluation framework\nthat quantifies metrics' sensitivity to the class imbalance. Moreover, we\nreveal an interesting fact that there is a logarithmic behavior in metrics'\nsensitivity meaning that the higher imbalance ratios are associated with the\nlower sensitivity of metrics. Our framework builds an intuitive understanding\nof the class-imbalance impact on metrics. We believe this can help avoid many\ncommon mistakes, specially the less-emphasized and incorrect assumption that\nall metrics' quantities are comparable under different class-imbalance ratios.",
    "descriptor": "\nComments: The 29th IEEE International Conference on Image Processing, IEEE ICIP 2022\n",
    "authors": [
      "Azim Ahmadzadeh",
      "Rafal A. Angryk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09981"
  },
  {
    "id": "arXiv:2206.09983",
    "title": "Mnemonic: A Parallel Subgraph Matching System for Streaming Graphs",
    "abstract": "Finding patterns in large highly connected datasets is critical for value\ndiscovery in business development and scientific research. This work focuses on\nthe problem of subgraph matching on streaming graphs, which provides utility in\na myriad of real-world applications ranging from social network analysis to\ncybersecurity. Each application poses a different set of control parameters,\nincluding the restrictions for a match, type of data stream, and search\ngranularity. The problem-driven design of existing subgraph matching systems\nmakes them challenging to apply for different problem domains. This paper\npresents Mnemonic, a programmable system that provides a high-level API and\ndemocratizes the development of a wide variety of subgraph matching solutions.\nImportantly, Mnemonic also delivers key data management capabilities and\noptimizations to support real-time processing on long-running, high-velocity\nmulti-relational graph streams. The experiments demonstrate the versatility of\nMnemonic, as it outperforms several state-of-the-art systems by up to two\norders of magnitude.",
    "descriptor": "",
    "authors": [
      "Bibek Bhattarai",
      "Howie Huang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.09983"
  },
  {
    "id": "arXiv:2206.09987",
    "title": "Measuring Gender Bias in Educational Videos: A Case Study on YouTube",
    "abstract": "Students are increasingly using online materials to learn new subjects or to\nsupplement their learning process in educational institutions. Issues regarding\ngender bias have been raised in the context of formal education and some\nmeasures have been proposed to mitigate them. However, online educational\nmaterials in terms of possible gender bias and stereotypes which may appear in\ndifferent forms are yet to be investigated in the context of search bias in a\nwidely-used search platform. As a first step towards measuring possible gender\nbias in online platforms, we have investigated YouTube educational videos in\nterms of the perceived gender of their narrators. We adopted bias measures for\nranked search results to evaluate educational videos returned by YouTube in\nresponse to queries related to STEM (Science, Technology, Engineering, and\nMathematics) and NON-STEM fields of education. Gender is a research area by\nitself in social sciences which is beyond the scope of this work. In this\nrespect, for annotating the perceived gender of the narrator of an\ninstructional video we used only a crude classification of gender into Male,\nand Female. Then, for analysing perceived gender bias we utilised bias measures\nthat have been inspired by search platforms and further incorporated rank\ninformation into our analysis. Our preliminary results demonstrate that there\nis a significant bias towards the male gender on the returned YouTube\neducational videos, and the degree of bias varies when we compare STEM and\nNON-STEM queries. Finally, there is a strong evidence that rank information\nmight affect the results.",
    "descriptor": "",
    "authors": [
      "Gizem Gezici",
      "Yucel Saygin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.09987"
  },
  {
    "id": "arXiv:2206.09991",
    "title": "Model Optimization in Imbalanced Regression",
    "abstract": "Imbalanced domain learning aims to produce accurate models in predicting\ninstances that, though underrepresented, are of utmost importance for the\ndomain. Research in this field has been mainly focused on classification tasks.\nComparatively, the number of studies carried out in the context of regression\ntasks is negligible. One of the main reasons for this is the lack of loss\nfunctions capable of focusing on minimizing the errors of extreme (rare)\nvalues. Recently, an evaluation metric was introduced: Squared Error Relevance\nArea (SERA). This metric posits a bigger emphasis on the errors committed at\nextreme values while also accounting for the performance in the overall target\nvariable domain, thus preventing severe bias. However, its effectiveness as an\noptimization metric is unknown. In this paper, our goal is to study the impacts\nof using SERA as an optimization criterion in imbalanced regression tasks.\nUsing gradient boosting algorithms as proof of concept, we perform an\nexperimental study with 36 data sets of different domains and sizes. Results\nshow that models that used SERA as an objective function are practically better\nthan the models produced by their respective standard boosting algorithms at\nthe prediction of extreme values. This confirms that SERA can be embedded as a\nloss function into optimization-based learning algorithms for imbalanced\nregression scenarios.",
    "descriptor": "",
    "authors": [
      "An\u00edbal Silva",
      "Rita P. Ribeiro",
      "Nuno Moniz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.09991"
  },
  {
    "id": "arXiv:2206.09999",
    "title": "Understanding RowHammer Under Reduced Wordline Voltage: An Experimental  Study Using Real DRAM Devices",
    "abstract": "RowHammer is a circuit-level DRAM vulnerability, where repeatedly activating\nand precharging a DRAM row, and thus alternating the voltage of a row's\nwordline between low and high voltage levels, can cause bit flips in physically\nnearby rows. Recent DRAM chips are more vulnerable to RowHammer: with\ntechnology node scaling, the minimum number of activate-precharge cycles to\ninduce a RowHammer bit flip reduces and the RowHammer bit error rate increases.\nTherefore, it is critical to develop effective and scalable approaches to\nprotect modern DRAM systems against RowHammer. To enable such solutions, it is\nessential to develop a deeper understanding of the RowHammer vulnerability of\nmodern DRAM chips. However, even though the voltage toggling on a wordline is a\nkey determinant of RowHammer vulnerability, no prior work experimentally\ndemonstrates the effect of wordline voltage (VPP) on the RowHammer\nvulnerability. Our work closes this gap in understanding.\nThis is the first work to experimentally demonstrate on 272 real DRAM chips\nthat lowering VPP reduces a DRAM chip's RowHammer vulnerability. We show that\nlowering VPP 1) increases the number of activate-precharge cycles needed to\ninduce a RowHammer bit flip by up to 85.8% with an average of 7.4% across all\ntested chips and 2) decreases the RowHammer bit error rate by up to 66.9% with\nan average of 15.2% across all tested chips. At the same time, reducing VPP\nmarginally worsens a DRAM cell's access latency, charge restoration, and data\nretention time within the guardbands of system-level nominal timing parameters\nfor 208 out of 272 tested chips. We conclude that reducing VPP is a promising\nstrategy for reducing a DRAM chip's RowHammer vulnerability without requiring\nmodifications to DRAM chips.",
    "descriptor": "\nComments: To appear in DSN 2022\n",
    "authors": [
      "A. Giray Ya\u011fl\u0131k\u00e7\u0131",
      "Haocong Luo",
      "Geraldo F. de Oliviera",
      "Ataberk Olgun",
      "Minesh Patel",
      "Jisung Park",
      "Hasan Hassan",
      "Jeremie S. Kim",
      "Lois Orosa",
      "Onur Mutlu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.09999"
  },
  {
    "id": "arXiv:2206.10007",
    "title": "Building Blocks for Network-Accelerated Distributed File Systems",
    "abstract": "High-performance clusters and datacenters pose increasingly demanding\nrequirements on storage systems. If these systems do not operate at scale,\napplications are doomed to become I/O bound and waste compute cycles. To\naccelerate the data path to remote storage nodes, remote direct memory access\n(RDMA) has been embraced by storage systems to let data flow from the network\nto storage targets, reducing overall latency and CPU utilization. Yet, this\napproach still involves CPUs on the data path to enforce storage policies such\nas authentication, replication, and erasure coding. We show how storage\npolicies can be offloaded to fully programmable SmartNICs, without involving\nhost CPUs. By using PsPIN, an open-hardware SmartNIC, we show latency\nimprovements for writes (up to 2x), data replication (up to 2x), and erasure\ncoding (up to 2x), when compared to respective CPU- and RDMA-based\nalternatives.",
    "descriptor": "",
    "authors": [
      "Salvatore Di Girolamo",
      "Daniele De Sensi",
      "Konstantin Taranov",
      "Milos Malesevic",
      "Maciej Besta",
      "Timo Schneider",
      "Severin Kistler",
      "Torsten Hoefler"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.10007"
  },
  {
    "id": "arXiv:2206.10009",
    "title": "Event-Case Correlation for Process Mining using Probabilistic  Optimization",
    "abstract": "Process mining supports the analysis of the actual behavior and performance\nof business processes using event logs. % such as, e.g., sales transactions\nrecorded by an ERP system. An essential requirement is that every event in the\nlog must be associated with a unique case identifier (e.g., the order ID of an\norder-to-cash process). In reality, however, this case identifier may not\nalways be present, especially when logs are acquired from different systems or\nextracted from non-process-aware information systems. In such settings, the\nevent log needs to be pre-processed by grouping events into cases -- an\noperation known as event correlation. Existing techniques for correlating\nevents have worked with assumptions to make the problem tractable: some assume\nthe generative processes to be acyclic, while others require heuristic\ninformation or user input. Moreover, %these techniques' primary assumption is\nthat they abstract the log to activities and timestamps, and miss the\nopportunity to use data attributes. % In this paper, we lift these assumptions\nand propose a new technique called EC-SA-Data based on probabilistic\noptimization. The technique takes as inputs a sequence of timestamped events\n(the log without case IDs), a process model describing the underlying business\nprocess, and constraints over the event attributes. Our approach returns an\nevent log in which every event is associated with a case identifier. The\ntechnique allows users to incorporate rules on process knowledge and data\nconstraints flexibly. The approach minimizes the misalignment between the\ngenerated log and the input process model, maximizes the support of the given\ndata constraints over the correlated log, and the variance between activity\ndurations across cases. Our experiments with various real-life datasets show\nthe advantages of our approach over the state of the art.",
    "descriptor": "",
    "authors": [
      "Dina Bayomie",
      "Claudio Di Ciccio",
      "Jan Mendling"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2206.10009"
  },
  {
    "id": "arXiv:2206.10011",
    "title": "When Does Re-initialization Work?",
    "abstract": "Re-initializing a neural network during training has been observed to improve\ngeneralization in recent works. Yet it is neither widely adopted in deep\nlearning practice nor is it often used in state-of-the-art training protocols.\nThis raises the question of when re-initialization works, and whether it should\nbe used together with regularization techniques such as data augmentation,\nweight decay and learning rate schedules. In this work, we conduct an extensive\nempirical comparison of standard training with a selection of re-initialization\nmethods to answer this question, training over 15,000 models on a variety of\nimage classification benchmarks. We first establish that such methods are\nconsistently beneficial for generalization in the absence of any other\nregularization. However, when deployed alongside other carefully tuned\nregularization techniques, re-initialization methods offer little to no added\nbenefit for generalization, although optimal generalization performance becomes\nless sensitive to the choice of learning rate and weight decay hyperparameters.\nTo investigate the impact of re-initialization methods on noisy data, we also\nconsider learning under label noise. Surprisingly, in this case,\nre-initialization significantly improves upon standard training, even in the\npresence of other carefully tuned regularization techniques.",
    "descriptor": "",
    "authors": [
      "Sheheryar Zaidi",
      "Tudor Berariu",
      "Hyunjik Kim",
      "J\u00f6rg Bornschein",
      "Claudia Clopath",
      "Yee Whye Teh",
      "Razvan Pascanu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.10011"
  },
  {
    "id": "arXiv:2206.10012",
    "title": "Limitations of the NTK for Understanding Generalization in Deep Learning",
    "abstract": "The ``Neural Tangent Kernel'' (NTK) (Jacot et al 2018), and its empirical\nvariants have been proposed as a proxy to capture certain behaviors of real\nneural networks. In this work, we study NTKs through the lens of scaling laws,\nand demonstrate that they fall short of explaining important aspects of neural\nnetwork generalization. In particular, we demonstrate realistic settings where\nfinite-width neural networks have significantly better data scaling exponents\nas compared to their corresponding empirical and infinite NTKs at\ninitialization. This reveals a more fundamental difference between the real\nnetworks and NTKs, beyond just a few percentage points of test accuracy.\nFurther, we show that even if the empirical NTK is allowed to be pre-trained on\na constant number of samples, the kernel scaling does not catch up to the\nneural network scaling. Finally, we show that the empirical NTK continues to\nevolve throughout most of the training, in contrast with prior work which\nsuggests that it stabilizes after a few epochs of training. Altogether, our\nwork establishes concrete limitations of the NTK approach in understanding\ngeneralization of real networks on natural datasets.",
    "descriptor": "",
    "authors": [
      "Nikhil Vyas",
      "Yamini Bansal",
      "Preetum Nakkiran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.10012"
  },
  {
    "id": "arXiv:2206.10013",
    "title": "Measuring the Effect of Training Data on Deep Learning Predictions via  Randomized Experiments",
    "abstract": "We develop a new, principled algorithm for estimating the contribution of\ntraining data points to the behavior of a deep learning model, such as a\nspecific prediction it makes. Our algorithm estimates the AME, a quantity that\nmeasures the expected (average) marginal effect of adding a data point to a\nsubset of the training data, sampled from a given distribution. When subsets\nare sampled from the uniform distribution, the AME reduces to the well-known\nShapley value. Our approach is inspired by causal inference and randomized\nexperiments: we sample different subsets of the training data to train multiple\nsubmodels, and evaluate each submodel's behavior. We then use a LASSO\nregression to jointly estimate the AME of each data point, based on the subset\ncompositions. Under sparsity assumptions ($k \\ll N$ datapoints have large AME),\nour estimator requires only $O(k\\log N)$ randomized submodel trainings,\nimproving upon the best prior Shapley value estimators.",
    "descriptor": "\nComments: ICML 2022\n",
    "authors": [
      "Jinkun Lin",
      "Anqi Zhang",
      "Mathias Lecuyer",
      "Jinyang Li",
      "Aurojit Panda",
      "Siddhartha Sen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10013"
  },
  {
    "id": "arXiv:2206.10015",
    "title": "An interval-valued recursive estimation framework for linearly  parameterized systems",
    "abstract": "This paper proposes a recursive interval-valued estimation framework for\nidentifying the parameters of linearly parameterized systems which may be\nslowly time-varying. It is assumed that the model error (which may consist in\nmeasurement noise or model mismatch or both) is unknown but lies at each time\ninstant in a known interval. In this context, the proposed method relies on\nbounding the error generated by a given reference point-valued recursive\nestimator, for example, the well-known recursive least squares algorithm. We\ndiscuss the trade-off between computational complexity and tightness of the\nestimated parametric interval.",
    "descriptor": "\nComments: 11 pages, 4 figures\n",
    "authors": [
      "Laurent Bako",
      "Seydi Ndiaye",
      "Eric Blanco"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.10015"
  },
  {
    "id": "arXiv:2206.10019",
    "title": "flow-based clustering and spectral clustering: a comparison",
    "abstract": "We propose and study a novel graph clustering method for data with an\nintrinsic network structure. Similar to spectral clustering, we exploit an\nintrinsic network structure of data to construct Euclidean feature vectors.\nThese feature vectors can then be fed into basic clustering methods such as\nk-means or Gaussian mixture model (GMM) based soft clustering. What sets our\napproach apart from spectral clustering is that we do not use the eigenvectors\nof a graph Laplacian to construct the feature vectors. Instead, we use the\nsolutions of total variation minimization problems to construct feature vectors\nthat reflect connectivity between data points. Our motivation is that the\nsolutions of total variation minimization are piece-wise constant around a\ngiven set of seed nodes. These seed nodes can be obtained from domain knowledge\nor by simple heuristics that are based on the network structure of data. Our\nresults indicate that our clustering methods can cope with certain graph\nstructures that are challenging for spectral clustering methods.",
    "descriptor": "",
    "authors": [
      "Y. SarcheshmehPour",
      "Y. Tian",
      "L. Zhang",
      "A. Jung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10019"
  },
  {
    "id": "arXiv:2206.10022",
    "title": "Stochastic Online Learning with Feedback Graphs: Finite-Time and  Asymptotic Optimality",
    "abstract": "We revisit the problem of stochastic online learning with feedback graphs,\nwith the goal of devising algorithms that are optimal, up to constants, both\nasymptotically and in finite time. We show that, surprisingly, the notion of\noptimal finite-time regret is not a uniquely defined property in this context\nand that, in general, it is decoupled from the asymptotic rate. We discuss\nalternative choices and propose a notion of finite-time optimality that we\nargue is \\emph{meaningful}. For that notion, we give an algorithm that admits\nquasi-optimal regret both in finite-time and asymptotically.",
    "descriptor": "",
    "authors": [
      "Teodor V. Marinov",
      "Mehryar Mohri",
      "Julian Zimmert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10022"
  },
  {
    "id": "arXiv:2206.10025",
    "title": "Learning from Positive and Negative Examples: New Proof for Binary  Alphabets",
    "abstract": "One of the most fundamental problems in computational learning theory is the\nthe problem of learning a finite automaton $A$ consistent with a finite set $P$\nof positive examples and with a finite set $N$ of negative examples. By\nconsistency, we mean that $A$ accepts all strings in $P$ and rejects all\nstrings in $N$. It is well known that this problem is NP-complete. In the\nliterature, it is stated that this NP-hardness holds even in the case of a\nbinary alphabet. As a standard reference for this theorem, the work of Gold\nfrom 1978 is either cited or adapted. But as a crucial detail, the work of Gold\nactually considered Mealy machines and not deterministic finite state automata\n(DFAs) as they are considered nowadays. As Mealy automata are equipped with an\noutput function, they can be more compact than DFAs which accept the same\nlanguage. We show that the adaptions of Gold's construction for Mealy machines\nstated in the literature have some issues and give a new construction for DFAs\nwith a binary alphabet ourselves.",
    "descriptor": "",
    "authors": [
      "Jonas Lingg",
      "Mateus de Oliveira Oliveira",
      "Petra Wolf"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2206.10025"
  },
  {
    "id": "arXiv:2206.10027",
    "title": "DNA: Proximal Policy Optimization with a Dual Network Architecture",
    "abstract": "This paper explores the problem of simultaneously learning a value function\nand policy in deep actor-critic reinforcement learning models. We find that the\ncommon practice of learning these functions jointly is sub-optimal, due to an\norder-of-magnitude difference in noise levels between these two tasks. Instead,\nwe show that learning these tasks independently, but with a constrained\ndistillation phase, significantly improves performance. Furthermore, we find\nthat the policy gradient noise levels can be decreased by using a lower\n\\textit{variance} return estimate. Whereas, the value learning noise level\ndecreases with a lower \\textit{bias} estimate. Together these insights inform\nan extension to Proximal Policy Optimization we call \\textit{Dual Network\nArchitecture} (DNA), which significantly outperforms its predecessor. DNA also\nexceeds the performance of the popular Rainbow DQN algorithm on four of the\nfive environments tested, even under more difficult stochastic control\nsettings.",
    "descriptor": "",
    "authors": [
      "Mathew Aitchison",
      "Penny Sweetser"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.10027"
  },
  {
    "id": "arXiv:2206.10028",
    "title": "Intention-Aware Navigation in Crowds with Extended-Space POMDP Planning",
    "abstract": "This paper presents a hybrid online Partially Observable Markov Decision\nProcess (POMDP) planning system that addresses the problem of autonomous\nnavigation in the presence of multi-modal uncertainty introduced by other\nagents in the environment. As a particular example, we consider the problem of\nautonomous navigation in dense crowds of pedestrians and among obstacles.\nPopular approaches to this problem first generate a path using a complete\nplanner (e.g., Hybrid A*) with ad-hoc assumptions about uncertainty, then use\nonline tree-based POMDP solvers to reason about uncertainty with control over a\nlimited aspect of the problem (i.e. speed along the path). We present a more\ncapable and responsive real-time approach enabling the POMDP planner to control\nmore degrees of freedom (e.g., both speed AND heading) to achieve more flexible\nand efficient solutions. This modification greatly extends the region of the\nstate space that the POMDP planner must reason over, significantly increasing\nthe importance of finding effective roll-out policies within the limited\ncomputational budget that real time control affords. Our key insight is to use\nmulti-query motion planning techniques (e.g., Probabilistic Roadmaps or Fast\nMarching Method) as priors for rapidly generating efficient roll-out policies\nfor every state that the POMDP planning tree might reach during its limited\nhorizon search. Our proposed approach generates trajectories that are safe and\nsignificantly more efficient than the previous approach, even in densely\ncrowded dynamic environments with long planning horizons.",
    "descriptor": "",
    "authors": [
      "Himanshu Gupta",
      "Bradley Hayes",
      "Zachary Sunberg"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.10028"
  },
  {
    "id": "arXiv:2206.10029",
    "title": "SynWMD: Syntax-aware Word Mover's Distance for Sentence Similarity  Evaluation",
    "abstract": "Word Mover's Distance (WMD) computes the distance between words and models\ntext similarity with the moving cost between words in two text sequences. Yet,\nit does not offer good performance in sentence similarity evaluation since it\ndoes not incorporate word importance and fails to take inherent contextual and\nstructural information in a sentence into account. An improved WMD method using\nthe syntactic parse tree, called Syntax-aware Word Mover's Distance (SynWMD),\nis proposed to address these two shortcomings in this work. First, a weighted\ngraph is built upon the word co-occurrence statistics extracted from the\nsyntactic parse trees of sentences. The importance of each word is inferred\nfrom graph connectivities. Second, the local syntactic parsing structure of\nwords is considered in computing the distance between words. To demonstrate the\neffectiveness of the proposed SynWMD, we conduct experiments on 6 textual\nsemantic similarity (STS) datasets and 4 sentence classification datasets.\nExperimental results show that SynWMD achieves state-of-the-art performance on\nSTS tasks. It also outperforms other WMD-based methods on sentence\nclassification tasks.",
    "descriptor": "",
    "authors": [
      "Chengwei Wei",
      "Bin Wang",
      "C.-C. Jay Kuo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.10029"
  },
  {
    "id": "arXiv:2206.10032",
    "title": "QuAFL: Federated Averaging Can Be Both Asynchronous and  Communication-Efficient",
    "abstract": "Federated Learning (FL) is an emerging paradigm to enable the large-scale\ndistributed training of machine learning models, while still providing privacy\nguarantees.\nIn this work, we jointly address two of the main practical challenges when\nscaling federated optimization to large node counts: the need for tight\nsynchronization between the central authority and individual computing nodes,\nand the large communication cost of transmissions between the central server\nand clients.\nSpecifically, we present a new variant of the classic federated averaging\n(FedAvg) algorithm, which supports both asynchronous communication and\ncommunication compression. We provide a new analysis technique showing that, in\nspite of these system relaxations, our algorithm essentially matches the best\nknown bounds for FedAvg, under reasonable parameter settings.\nOn the experimental side, we show that our algorithm ensures fast practical\nconvergence for standard federated tasks.",
    "descriptor": "",
    "authors": [
      "Hossein Zakerinia",
      "Shayan Talaei",
      "Giorgi Nadiradze",
      "Dan Alistarh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10032"
  },
  {
    "id": "arXiv:2206.10033",
    "title": "Test Time Transform Prediction for Open Set Histopathological Image  Recognition",
    "abstract": "Tissue typology annotation in Whole Slide histological images is a complex\nand tedious, yet necessary task for the development of computational pathology\nmodels. We propose to address this problem by applying Open Set Recognition\ntechniques to the task of jointly classifying tissue that belongs to a set of\nannotated classes, e.g. clinically relevant tissue categories, while rejecting\nin test time Open Set samples, i.e. images that belong to categories not\npresent in the training set. To this end, we introduce a new approach for Open\nSet histopathological image recognition based on training a model to accurately\nidentify image categories and simultaneously predict which data augmentation\ntransform has been applied. In test time, we measure model confidence in\npredicting this transform, which we expect to be lower for images in the Open\nSet. We carry out comprehensive experiments in the context of colorectal cancer\nassessment from histological images, which provide evidence on the strengths of\nour approach to automatically identify samples from unknown categories. Code is\nreleased at https://github.com/agaldran/t3po .",
    "descriptor": "\nComments: Accepted to MICCAI 2022\n",
    "authors": [
      "Adrian Galdran. Katherine J. Hewitt",
      "Narmin L. Ghaffari",
      "Jakob N. Kather",
      "Gustavo Carneiro",
      "Miguel A. Gonz\u00e1lez Ballester"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10033"
  },
  {
    "id": "arXiv:2206.10034",
    "title": "Deep Learning Models on CPUs: A Methodology for Efficient Training",
    "abstract": "GPUs have been favored for training deep learning models due to their highly\nparallelized architecture. As a result, most studies on training optimization\nfocus on GPUs. There is often a trade-off, however, between cost and efficiency\nwhen deciding on how to choose the proper hardware for training. In particular,\nCPU servers can be beneficial if training on CPUs was more efficient, as they\nincur fewer hardware update costs and better utilizing existing infrastructure.\nThis paper makes several contributions to research on training deep learning\nmodels using CPUs. First, it presents a method for optimizing the training of\ndeep learning models on Intel CPUs and a toolkit called ProfileDNN, which we\ndeveloped to improve performance profiling. Second, we describe a generic\ntraining optimization method that guides our workflow and explores several case\nstudies where we identified performance issues and then optimized the Intel\nExtension for PyTorch, resulting in an overall 2x training performance increase\nfor the RetinaNet-ResNext50 model. Third, we show how to leverage the\nvisualization capabilities of ProfileDNN, which enabled us to pinpoint\nbottlenecks and create a custom focal loss kernel that was two times faster\nthan the official reference PyTorch implementation.",
    "descriptor": "",
    "authors": [
      "Quchen Fu",
      "Ramesh Chukka",
      "Keith Achorn",
      "Thomas Atta-fosu",
      "Deepak R. Canchi",
      "Zhongwei Teng",
      "Jules White",
      "Douglas C. Schmidt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.10034"
  },
  {
    "id": "arXiv:2206.10036",
    "title": "Assessment of the Center of Inertia and Regional Inertia with Load  Contribution via a Fully Data-Driven Method",
    "abstract": "This paper proposes a new comprehensive and fully data-driven methodology to\nestimate the center of inertia (COI) and the regional inertia, considering the\ndisplacement of the COI due to disturbances and load inertial contributions.\nThe strategy uses the typicality-based data analysis (TDA) technique to detect\nthe right pilot-bus that represents the COI. In the TDA, a compound of\ncorrelation and cosine similarities is implemented to approximate the actual\ndistribution of the data and find the point (bus) closest to the mean which is\nelected as the pilot-bus. Then, the frequency response at the pilot-bus and the\nactive power deviations are embedded into an autoregressive moving average\nexogenous input (ARMAX)-based approach to determine the regional inertia\nrepresented by an equivalent machine, whose inertia constant corresponds to the\ninertial contribution in the Region. % the This is done in order to perform the\ninertial estimation of the region using the frequency response of the pilot-bus\nand the active power of the region interconnections to model the region as and\nequivalent machine whose inertial constant is estimated using ARMAX\nidentification technique. The methodology is tested using the IEEE 68-bus\nbenchmark test system and an adapted version with aggregated dynamical loads,\ncorroborating the method effectiveness.",
    "descriptor": "",
    "authors": [
      "Lucas Lugnani",
      "Mario Paternina",
      "Daniel Dotta"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.10036"
  },
  {
    "id": "arXiv:2206.10038",
    "title": "Understanding a Robot's Guiding Ethical Principles via Automatically  Generated Explanations",
    "abstract": "The continued development of robots has enabled their wider usage in human\nsurroundings. Robots are more trusted to make increasingly important decisions\nwith potentially critical outcomes. Therefore, it is essential to consider the\nethical principles under which robots operate. In this paper we examine how\ncontrastive and non-contrastive explanations can be used in understanding the\nethics of robot action plans. We build upon an existing ethical framework to\nallow users to make suggestions about plans and receive automatically generated\ncontrastive explanations. Results of a user study indicate that the generated\nexplanations help humans to understand the ethical principles that underlie a\nrobot's plan.",
    "descriptor": "\nComments: 8 pages, 2 figures, 2022 IEEE 18th International Conference on Automation Science and Engineering\n",
    "authors": [
      "Benjamin Krarup",
      "Felix Lindner",
      "Senka Krivic",
      "Derek Long"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.10038"
  },
  {
    "id": "arXiv:2206.10041",
    "title": "MPA: MultiPath++ Based Architecture for Motion Prediction",
    "abstract": "Autonomous driving technology is developing rapidly and nowadays first\nautonomous rides are being provided in city areas. This requires the highest\nstandards for the safety and reliability of the technology. Motion prediction\npart of the general self-driving pipeline plays a crucial role in providing\nthese qualities. In this work we present one of the solutions for Waymo Motion\nPrediction Challenge 2022 based on MultiPath++ ranked the 3rd as of May, 26\n2022. Our source code is publicly available on GitHub.",
    "descriptor": "\nComments: CVPR 2022, Workshop on Autonomous Driving\n",
    "authors": [
      "Stepan Konev"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10041"
  },
  {
    "id": "arXiv:2206.10043",
    "title": "Achieving Utility, Fairness, and Compactness via Tunable Information  Bottleneck Measures",
    "abstract": "Designing machine learning algorithms that are accurate yet fair, not\ndiscriminating based on any sensitive attribute, is of paramount importance for\nsociety to accept AI for critical applications. In this article, we propose a\nnovel fair representation learning method termed the R\\'enyi Fair Information\nBottleneck Method (RFIB) which incorporates constraints for utility, fairness,\nand compactness of representation, and apply it to image classification. A key\nattribute of our approach is that we consider - in contrast to most prior work\n- both demographic parity and equalized odds as fairness constraints, allowing\nfor a more nuanced satisfaction of both criteria. Leveraging a variational\napproach, we show that our objectives yield a loss function involving classical\nInformation Bottleneck (IB) measures and establish an upper bound in terms of\nthe R\\'enyi divergence of order $\\alpha$ on the mutual information IB term\nmeasuring compactness between the input and its encoded embedding.\nExperimenting on three different image datasets (EyePACS, CelebA, and\nFairFace), we study the influence of the $\\alpha$ parameter as well as two\nother tunable IB parameters on achieving utility/fairness trade-off goals, and\nshow that the $\\alpha$ parameter gives an additional degree of freedom that can\nbe used to control the compactness of the representation. We evaluate the\nperformance of our method using various utility, fairness, and compound\nutility/fairness metrics, showing that RFIB outperforms current\nstate-of-the-art approaches.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2203.04950\n",
    "authors": [
      "Adam Gronowski",
      "William Paul",
      "Fady Alajaji",
      "Bahman Gharesifard",
      "Philippe Burlina"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.10043"
  },
  {
    "id": "arXiv:2206.10044",
    "title": "Identifiability of deep generative models under mixture priors without  auxiliary information",
    "abstract": "We prove identifiability of a broad class of deep latent variable models that\n(a) have universal approximation capabilities and (b) are the decoders of\nvariational autoencoders that are commonly used in practice. Unlike existing\nwork, our analysis does not require weak supervision, auxiliary information, or\nconditioning in the latent space. Recently, there has been a surge of works\nstudying identifiability of such models. In these works, the main assumption is\nthat along with the data, an auxiliary variable $u$ (also known as side\ninformation) is observed as well. At the same time, several works have\nempirically observed that this doesn't seem to be necessary in practice. In\nthis work, we explain this behavior by showing that for a broad class of\ngenerative (i.e. unsupervised) models with universal approximation\ncapabilities, the side information $u$ is not necessary: We prove\nidentifiability of the entire generative model where we do not observe $u$ and\nonly observe the data $x$. The models we consider are tightly connected with\nautoencoder architectures used in practice that leverage mixture priors in the\nlatent space and ReLU/leaky-ReLU activations in the encoder. Our main result is\nan identifiability hierarchy that significantly generalizes previous work and\nexposes how different assumptions lead to different \"strengths\" of\nidentifiability. For example, our weakest result establishes (unsupervised)\nidentifiability up to an affine transformation, which already improves existing\nwork. It's well known that these models have universal approximation\ncapabilities and moreover, they have been extensively used in practice to learn\nrepresentations of data.",
    "descriptor": "\nComments: 31 pages, 9 figures\n",
    "authors": [
      "Bohdan Kivva",
      "Goutham Rajendran",
      "Pradeep Ravikumar",
      "Bryon Aragam"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.10044"
  },
  {
    "id": "arXiv:2206.10048",
    "title": "Decentralized Distributed Learning with Privacy-Preserving Data  Synthesis",
    "abstract": "In the medical field, multi-center collaborations are often sought to yield\nmore generalizable findings by leveraging the heterogeneity of patient and\nclinical data. However, recent privacy regulations hinder the possibility to\nshare data, and consequently, to come up with machine learning-based solutions\nthat support diagnosis and prognosis. Federated learning (FL) aims at\nsidestepping this limitation by bringing AI-based solutions to data owners and\nonly sharing local AI models, or parts thereof, that need then to be\naggregated. However, most of the existing federated learning solutions are\nstill at their infancy and show several shortcomings, from the lack of a\nreliable and effective aggregation scheme able to retain the knowledge learned\nlocally to weak privacy preservation as real data may be reconstructed from\nmodel updates. Furthermore, the majority of these approaches, especially those\ndealing with medical data, relies on a centralized distributed learning\nstrategy that poses robustness, scalability and trust issues. In this paper we\npresent a decentralized distributed method that, exploiting concepts from\nexperience replay and generative adversarial research, effectively integrates\nfeatures from local nodes, providing models able to generalize across multiple\ndatasets while maintaining privacy. The proposed approach is tested on two\ntasks - tuberculosis and melanoma classification - using multiple datasets in\norder to simulate realistic non-i.i.d. data scenarios. Results show that our\napproach achieves performance comparable to both standard (non-federated)\nlearning and federated methods in their centralized (thus, more favourable)\nformulation.",
    "descriptor": "\nComments: Paper submitted to TMI\n",
    "authors": [
      "Matteo Pennisi",
      "Federica Proietto Salanitri",
      "Giovanni Bellitto",
      "Bruno Casella",
      "Marco Aldinucci",
      "Simone Palazzo",
      "Concetto Spampinato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.10048"
  },
  {
    "id": "arXiv:2206.10049",
    "title": "The Capacity of 3 User Linear Computation Broadcast",
    "abstract": "The $K$ User Linear Computation Broadcast (LCBC) problem is comprised of $d$\ndimensional data (from $\\mathbb{F}_q$), that is fully available to a central\nserver, and $K$ users, who require various linear computations of the data, and\nhave prior knowledge of various linear functions of the data as\nside-information. The optimal broadcast cost is the minimum number of $q$-ary\nsymbols to be broadcast by the server per computation instance, for every user\nto retrieve its desired computation. The reciprocal of the optimal broadcast\ncost is called the capacity. The main contribution of this paper is the exact\ncapacity characterization for the $K=3$ user LCBC for all cases, i.e., for\narbitrary finite fields $\\mathbb{F}_q$, arbitrary data dimension $d$, and\narbitrary linear side-informations and demands at each user. A remarkable\naspect of the converse is that unlike the $2$ user LCBC whose capacity was\ndetermined previously, the entropic formulation (where the entropies of demands\nand side-informations are specified, but not their functional forms) is\ninsufficient to obtain a tight converse for the $3$ user LCBC. Instead, the\nconverse exploits functional submodularity. Notable aspects of achievability\ninclude a decomposition of the users' collective signal space into subspaces\nthat allow different degrees of efficiency in broadcast cost, revealing a\ntradeoff that leads to a constrained water-filling solution. Random coding\narguments are invoked to resolve compatibility issues that arise as each user\nhas a different view of these subspaces, conditioned on its own\nside-information.",
    "descriptor": "",
    "authors": [
      "Yuhang Yao",
      "Syed A. Jafar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.10049"
  },
  {
    "id": "arXiv:2206.10050",
    "title": "Better Incentives for Proof-of-Work",
    "abstract": "This work proposes a novel proof-of-work blockchain incentive scheme such\nthat, barring exogenous motivations, following the protocol is guaranteed to be\nthe optimal strategy for miners. Our blockchain takes the form of a directed\nacyclic graph, resulting in improvements with respect to throughput and speed.\nMore importantly, for our blockchain to function, it is not expected that the\nminers conform to some presupposed protocol in the interest of the system's\noperability. Instead, our system works if miners act selfishly, trying to get\nthe maximum possible rewards, with no consideration for the overall health of\nthe blockchain.",
    "descriptor": "",
    "authors": [
      "Jakub Sliwinski",
      "Roger Wattenhofer"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.10050"
  },
  {
    "id": "arXiv:2206.10057",
    "title": "Robust Deep Reinforcement Learning through Bootstrapped Opportunistic  Curriculum",
    "abstract": "Despite considerable advances in deep reinforcement learning, it has been\nshown to be highly vulnerable to adversarial perturbations to state\nobservations. Recent efforts that have attempted to improve adversarial\nrobustness of reinforcement learning can nevertheless tolerate only very small\nperturbations, and remain fragile as perturbation size increases. We propose\nBootstrapped Opportunistic Adversarial Curriculum Learning (BCL), a novel\nflexible adversarial curriculum learning framework for robust reinforcement\nlearning. Our framework combines two ideas: conservatively bootstrapping each\ncurriculum phase with highest quality solutions obtained from multiple runs of\nthe previous phase, and opportunistically skipping forward in the curriculum.\nIn our experiments we show that the proposed BCL framework enables dramatic\nimprovements in robustness of learned policies to adversarial perturbations.\nThe greatest improvement is for Pong, where our framework yields robustness to\nperturbations of up to 25/255; in contrast, the best existing approach can only\ntolerate adversarial noise up to 5/255. Our code is available at:\nhttps://github.com/jlwu002/BCL.",
    "descriptor": "\nComments: ICML 2022\n",
    "authors": [
      "Junlin Wu",
      "Yevgeniy Vorobeychik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10057"
  },
  {
    "id": "arXiv:2206.10059",
    "title": "Bypass Network for Semantics Driven Image Paragraph Captioning",
    "abstract": "Image paragraph captioning aims to describe a given image with a sequence of\ncoherent sentences. Most existing methods model the coherence through the topic\ntransition that dynamically infers a topic vector from preceding sentences.\nHowever, these methods still suffer from immediate or delayed repetitions in\ngenerated paragraphs because (i) the entanglement of syntax and semantics\ndistracts the topic vector from attending pertinent visual regions; (ii) there\nare few constraints or rewards for learning long-range transitions. In this\npaper, we propose a bypass network that separately models semantics and\nlinguistic syntax of preceding sentences. Specifically, the proposed model\nconsists of two main modules, i.e. a topic transition module and a sentence\ngeneration module. The former takes previous semantic vectors as queries and\napplies attention mechanism on regional features to acquire the next topic\nvector, which reduces immediate repetition by eliminating linguistics. The\nlatter decodes the topic vector and the preceding syntax state to produce the\nfollowing sentence. To further reduce delayed repetition in generated\nparagraphs, we devise a replacement-based reward for the REINFORCE training.\nComprehensive experiments on the widely used benchmark demonstrate the\nsuperiority of the proposed model over the state of the art for coherence while\nmaintaining high accuracy.",
    "descriptor": "\nComments: Under consideration at Computer Vision and Image Understanding\n",
    "authors": [
      "Qi Zheng",
      "Chaoyue Wang",
      "Dadong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10059"
  },
  {
    "id": "arXiv:2206.10061",
    "title": "Improving numerical accuracy for the viscous-plastic formulation of sea  ice",
    "abstract": "Accurate modeling of sea ice dynamics is critical for predicting\nenvironmental variables and is important in applications such as navigating ice\nbreaker ships. Research for both modeling and simulating sea ice dynamics is\nongoing, with the most widely accepted model based on the viscous-plastic (VP)\nformulation introduced by Hibler in 1979. Due to its highly nonlinear features,\nthis model is intrinsically challenging for computational solvers. In\nparticular, sea ice simulations often significantly differ from satellite\nobservations. This study therefore focuses on improving the numerical accuracy\nof the VP sea ice model. Since the poor convergence observed in existing\nnumerical simulations stems from the nonlinear nature of the VP formulation,\nthis investigation proposes using the celebrated weighted essentially\nnon-oscillatory (WENO) scheme -- as opposed to the frequently employed centered\ndifference (CD) scheme -- for the spatial derivatives in the VP sea ice model.\nWe then proceed to numerically demonstrate that WENO yields higher-order\nconvergence for smooth solutions, and that furthermore it is able to resolve\nthe discontinuities in the sharp features of sea ice covers -- something that\nis not possible using CD methods. Finally, our proposed framework integrates a\npotential function method that utilizes the phase field method to naturally\nincorporates the physical restrictions of ice thickness and ice concentration\nin transport equations, resulting in a modified transport equations which\nincludes additional forcing terms. Our method does not require post-processing,\nthereby avoiding the possible introduction of discontinuities and corresponding\nnegative impact on the solution behavior. Numerical experiments are provided to\ndemonstrate the efficacy of our new methodology.",
    "descriptor": "",
    "authors": [
      "Tongtong Li",
      "Anne Gelb",
      "Yoonsang Lee"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.10061"
  },
  {
    "id": "arXiv:2206.10062",
    "title": "Early Recall, Late Precision: Multi-Robot Semantic Object Mapping under  Operational Constraints in Perceptually-Degraded Environments",
    "abstract": "Semantic object mapping in uncertain, perceptually degraded environments\nduring long-range multi-robot autonomous exploration tasks such as\nsearch-and-rescue is important and challenging. During such missions, high\nrecall is desirable to avoid missing true target objects and high precision is\nalso critical to avoid wasting valuable operational time on false positives.\nGiven recent advancements in visual perception algorithms, the former is\nlargely solvable autonomously, but the latter is difficult to address without\nthe supervision of a human operator. However, operational constraints such as\nmission time, computational requirements, mesh network bandwidth and so on, can\nmake the operator's task infeasible unless properly managed. We propose the\nEarly Recall, Late Precision (EaRLaP) semantic object mapping pipeline to solve\nthis problem. EaRLaP was used by Team CoSTAR in DARPA Subterranean Challenge,\nwhere it successfully detected all the artifacts encountered by the team of\nrobots. We will discuss these results and performance of the EaRLaP on various\ndatasets.",
    "descriptor": "",
    "authors": [
      "Xianmei Lei",
      "Taeyeon Kim",
      "Nicolas Marchal",
      "Daniel Pastor",
      "Barry Ridge",
      "Frederik Sch\u00f6ller",
      "Edward Terry",
      "Fernando Chavez",
      "Thomas Touma",
      "Kyohei Otsu",
      "Ali Agha"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.10062"
  },
  {
    "id": "arXiv:2206.10064",
    "title": "Fast and Safe Aerial Payload Transport in Urban Areas",
    "abstract": "This paper studies the problem of fast and safe aerial payload transport by a\nsingle quadcopter in urban areas. The quadcopter payload system (QPS) is\nconsidered as a rigid body and modeled with a nonlinear dynamics. The urban\narea is modeled as an obstacle-laden environment with obstacle geometries\nobtained by incorporating realistic LIDAR data. Our approach for payload\ntransport is decomposed into high-level motion planning and low-level\ntrajectory control. For the low-level trajectory tracking, a feedback\nlinearization control is applied to stably track the desired trajectory of the\nquadcopter. For high-level motion planning, we integrate A* search and\npolynomial planning to define a safe trajectory for the quadcopter assuring\ncollision avoidance, boundedness of the quadcopter rotor speeds and tracking\nerror, and fast arrival to a target destination from an arbitrary initial\nlocation.",
    "descriptor": "",
    "authors": [
      "Aeris El Asslouj",
      "Harshvardhan Uppaluru",
      "Hossein Rastgoftar"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.10064"
  },
  {
    "id": "arXiv:2206.10066",
    "title": "RendNet: Unified 2D/3D Recognizer With Latent Space Rendering",
    "abstract": "Vector graphics (VG) have been ubiquitous in our daily life with vast\napplications in engineering, architecture, designs, etc. The VG recognition\nprocess of most existing methods is to first render the VG into raster graphics\n(RG) and then conduct recognition based on RG formats. However, this procedure\ndiscards the structure of geometries and loses the high resolution of VG.\nRecently, another category of algorithms is proposed to recognize directly from\nthe original VG format. But it is affected by the topological errors that can\nbe filtered out by RG rendering. Instead of looking at one format, it is a good\nsolution to utilize the formats of VG and RG together to avoid these\nshortcomings. Besides, we argue that the VG-to-RG rendering process is\nessential to effectively combine VG and RG information. By specifying the rules\non how to transfer VG primitives to RG pixels, the rendering process depicts\nthe interaction and correlation between VG and RG. As a result, we propose\nRendNet, a unified architecture for recognition on both 2D and 3D scenarios,\nwhich considers both VG/RG representations and exploits their interaction by\nincorporating the VG-to-RG rasterization process. Experiments show that RendNet\ncan achieve state-of-the-art performance on 2D and 3D object recognition tasks\non various VG datasets.",
    "descriptor": "\nComments: CVPR 2022 Oral\n",
    "authors": [
      "Ruoxi Shi",
      "Xinyang Jiang",
      "Caihua Shan",
      "Yansen Wang",
      "Dongsheng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10066"
  },
  {
    "id": "arXiv:2206.10071",
    "title": "Benchmarking Node Outlier Detection on Graphs",
    "abstract": "Graph outlier detection is an emerging but crucial machine learning task with\nnumerous applications. Despite the proliferation of algorithms developed in\nrecent years, the lack of a standard and unified setting for performance\nevaluation limits their advancement and usage in real-world applications. To\ntap the gap, we present, (to our best knowledge) the first comprehensive\nunsupervised node outlier detection benchmark for graphs called UNOD, with the\nfollowing highlights: (1) evaluating fourteen methods with backbone spanning\nfrom classical matrix factorization to the latest graph neural networks; (2)\nbenchmarking the method performance with different types of injected outliers\nand organic outliers on real-world datasets; (3) comparing the efficiency and\nscalability of the algorithms by runtime and GPU memory usage on synthetic\ngraphs at different scales. Based on the analyses of extensive experimental\nresults, we discuss the pros and cons of current UNOD methods, and point out\nmultiple crucial and promising future research directions.",
    "descriptor": "\nComments: Preprint. Under review. Benchmark available at this https URL\n",
    "authors": [
      "Kay Liu",
      "Yingtong Dou",
      "Yue Zhao",
      "Xueying Ding",
      "Xiyang Hu",
      "Ruitong Zhang",
      "Kaize Ding",
      "Canyu Chen",
      "Hao Peng",
      "Kai Shu",
      "Lichao Sun",
      "Jundong Li",
      "George H. Chen",
      "Zhihao Jia",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.10071"
  },
  {
    "id": "arXiv:2206.10075",
    "title": "Counting Varying Density Crowds Through Density Guided Adaptive  Selection CNN and Transformer Estimation",
    "abstract": "In real-world crowd counting applications, the crowd densities in an image\nvary greatly. When facing with density variation, human tend to locate and\ncount the target in low-density regions, and reason the number in high-density\nregions. We observe that CNN focus on the local information correlation using a\nfixed-size convolution kernel and the Transformer could effectively extract the\nsemantic crowd information by using the global self-attention mechanism. Thus,\nCNN could locate and estimate crowd accurately in low-density regions, while it\nis hard to properly perceive density in high-density regions. On the contrary,\nTransformer, has a high reliability in high-density regions, but fails to\nlocate the target in sparse regions. Neither CNN or Transformer can well deal\nwith this kind of density variations. To address this problem, we propose a CNN\nand Transformer Adaptive Selection Network (CTASNet) which can adaptively\nselect the appropriate counting branch for different density regions. Firstly,\nCTASNet generates the prediction results of CNN and Transformer. Then,\nconsidering that CNN/Transformer are appropriate for low/high-density regions,\na density guided Adaptive Selection Module is designed to automatically combine\nthe predictions of CNN and Transformer. Moreover, to reduce the influences of\nannotation noise, we introduce a Correntropy based Optimal Transport loss.\nExtensive experiments on four challenging crowd counting datasets have\nvalidated the proposed method.",
    "descriptor": "",
    "authors": [
      "Yuehai Chen",
      "Jing Yang",
      "Badong Chen",
      "Shaoyi Du"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10075"
  },
  {
    "id": "arXiv:2206.10078",
    "title": "The Manifold Scattering Transform for High-Dimensional Point Cloud Data",
    "abstract": "The manifold scattering transform is a deep feature extractor for data\ndefined on a Riemannian manifold. It is one of the first examples of extending\nconvolutional neural network-like operators to general manifolds. The initial\nwork on this model focused primarily on its theoretical stability and\ninvariance properties but did not provide methods for its numerical\nimplementation except in the case of two-dimensional surfaces with predefined\nmeshes. In this work, we present practical schemes, based on the theory of\ndiffusion maps, for implementing the manifold scattering transform to datasets\narising in naturalistic systems, such as single cell genetics, where the data\nis a high-dimensional point cloud modeled as lying on a low-dimensional\nmanifold. We show that our methods are effective for signal classification and\nmanifold classification tasks.",
    "descriptor": "\nComments: Accepted for publication in the TAG in DS Workshop at ICML\n",
    "authors": [
      "Joyce Chew",
      "Holly R. Steach",
      "Siddharth Viswanath",
      "Hau-Tieng Wu",
      "Matthew Hirn",
      "Deanna Needell",
      "Smita Krishnaswamy",
      "Michael Perlmutter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.10078"
  },
  {
    "id": "arXiv:2206.10080",
    "title": "One-stage Action Detection Transformer",
    "abstract": "In this work, we introduce our solution to the EPIC-KITCHENS-100 2022 Action\nDetection challenge. One-stage Action Detection Transformer (OADT) is proposed\nto model the temporal connection of video segments. With the help of OADT, both\nthe category and time boundary can be recognized simultaneously. After\nensembling multiple OADT models trained from different features, our model can\nreach 21.28\\% action mAP and ranks the 1st on the test-set of the Action\ndetection challenge.",
    "descriptor": "",
    "authors": [
      "Lijun Li",
      "Li'an Zhuo",
      "Bang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.10080"
  },
  {
    "id": "arXiv:2206.10082",
    "title": "Optimally Controllable Perceptual Lossy Compression",
    "abstract": "Recent studies in lossy compression show that distortion and perceptual\nquality are at odds with each other, which put forward the tradeoff between\ndistortion and perception (D-P). Intuitively, to attain different perceptual\nquality, different decoders have to be trained. In this paper, we present a\nnontrivial finding that only two decoders are sufficient for optimally\nachieving arbitrary (an infinite number of different) D-P tradeoff. We prove\nthat arbitrary points of the D-P tradeoff bound can be achieved by a simple\nlinear interpolation between the outputs of a minimum MSE decoder and a\nspecifically constructed perfect perceptual decoder. Meanwhile, the perceptual\nquality (in terms of the squared Wasserstein-2 distance metric) can be\nquantitatively controlled by the interpolation factor. Furthermore, to\nconstruct a perfect perceptual decoder, we propose two theoretically optimal\ntraining frameworks. The new frameworks are different from the\ndistortion-plus-adversarial loss based heuristic framework widely used in\nexisting methods, which are not only theoretically optimal but also can yield\nstate-of-the-art performance in practical perceptual decoding. Finally, we\nvalidate our theoretical finding and demonstrate the superiority of our\nframeworks via experiments. Code is available at:\nhttps://github.com/ZeyuYan/Controllable-Perceptual-Compression",
    "descriptor": "\nComments: ICML 2022\n",
    "authors": [
      "Zeyu Yan",
      "Fei Wen",
      "Peilin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.10082"
  },
  {
    "id": "arXiv:2206.10087",
    "title": "Bio-inspired Neural Network-based Optimal Path Planning for UUVs under  the Effect of Ocean Currents",
    "abstract": "To eliminate the effect of ocean currents when addressing the optimal path in\nthe underwater environment, an intelligent algorithm designed for the unmanned\nunderwater vehicle (UUV) is proposed in this paper. The algorithm consists of\ntwo parts: a neural network-based algorithm that deducts the shortest path and\navoids all possible collisions; and an adjusting component that balances off\nthe deviation brought by the effect of ocean currents. The optimization results\nof the proposed algorithm are presented in detail, and compared with the path\nplanning algorithm that does not consider the effect of currents. Results of\nthe comparison prove the effectiveness of the path planning method when\nencountering currents of different directions and velocities.",
    "descriptor": "",
    "authors": [
      "Danjie Zhu",
      "Simon X. Yang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.10087"
  },
  {
    "id": "arXiv:2206.10088",
    "title": "Renormalized Sparse Neural Network Pruning",
    "abstract": "Large neural networks are heavily over-parameterized. This is done because it\nimproves training to optimality. However once the network is trained, this\nmeans many parameters can be zeroed, or pruned, leaving an equivalent sparse\nneural network. We propose renormalizing sparse neural networks in order to\nimprove accuracy. We prove that our method's error converges to 0 as network\nparameters cluster or concentrate. We prove that without renormalizing, the\nerror does not converge to zero in general. We experiment with our method on\nreal world datasets MNIST, Fashion MNIST, and CIFAR-10 and confirm a large\nimprovement in accuracy with renormalization versus standard pruning.",
    "descriptor": "",
    "authors": [
      "Michael G. Rawson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.10088"
  },
  {
    "id": "arXiv:2206.10090",
    "title": "KTN: Knowledge Transfer Network for Learning Multi-person 2D-3D  Correspondences",
    "abstract": "Human densepose estimation, aiming at establishing dense correspondences\nbetween 2D pixels of human body and 3D human body template, is a key technique\nin enabling machines to have an understanding of people in images. It still\nposes several challenges due to practical scenarios where real-world scenes are\ncomplex and only partial annotations are available, leading to incompelete or\nfalse estimations. In this work, we present a novel framework to detect the\ndensepose of multiple people in an image. The proposed method, which we refer\nto Knowledge Transfer Network (KTN), tackles two main problems: 1) how to\nrefine image representation for alleviating incomplete estimations, and 2) how\nto reduce false estimation caused by the low-quality training labels (i.e.,\nlimited annotations and class-imbalance labels). Unlike existing works directly\npropagating the pyramidal features of regions for densepose estimation, the KTN\nuses a refinement of pyramidal representation, where it simultaneously\nmaintains feature resolution and suppresses background pixels, and this\nstrategy results in a substantial increase in accuracy. Moreover, the KTN\nenhances the ability of 3D based body parsing with external knowledges, where\nit casts 2D based body parsers trained from sufficient annotations as a 3D\nbased body parser through a structural body knowledge graph. In this way, it\nsignificantly reduces the adverse effects caused by the low-quality\nannotations. The effectiveness of KTN is demonstrated by its superior\nperformance to the state-of-the-art methods on DensePose-COCO dataset.\nExtensive ablation studies and experimental results on representative tasks\n(e.g., human body segmentation, human part segmentation and keypoints\ndetection) and two popular densepose estimation pipelines (i.e., RCNN and\nfully-convolutional frameworks), further indicate the generalizability of the\nproposed method.",
    "descriptor": "",
    "authors": [
      "Xuanhan Wang",
      "Lianli Gao",
      "Yixuan Zhou",
      "Jingkuan Song",
      "Meng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10090"
  },
  {
    "id": "arXiv:2206.10092",
    "title": "BEVDepth: Acquisition of Reliable Depth for Multi-view 3D Object  Detection",
    "abstract": "In this research, we propose a new 3D object detector with a trustworthy\ndepth estimation, dubbed BEVDepth, for camera-based Bird's-Eye-View (BEV) 3D\nobject detection. By a thorough analysis of recent approaches, we discover that\nthe depth estimation is implicitly learned without camera information, making\nit the de-facto fake-depth for creating the following pseudo point cloud.\nBEVDepth gets explicit depth supervision utilizing encoded intrinsic and\nextrinsic parameters. A depth correction sub-network is further introduced to\ncounteract projecting-induced disturbances in depth ground truth. To reduce the\nspeed bottleneck while projecting features from image-view into BEV using\nestimated depth, a quick view-transform operation is also proposed. Besides,\nour BEVDepth can be easily extended with input from multi-frame. Without any\nbells and whistles, BEVDepth achieves the new state-of-the-art 60.0% NDS on the\nchallenging nuScenes test set while maintaining high efficiency. For the first\ntime, the performance gap between the camera and LiDAR is largely reduced\nwithin 10% NDS.",
    "descriptor": "",
    "authors": [
      "Yinhao Li",
      "Zheng Ge",
      "Guanyi Yu",
      "Jinrong Yang",
      "Zengran Wang",
      "Yukang Shi",
      "Jianjian Sun",
      "Zeming Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10092"
  },
  {
    "id": "arXiv:2206.10095",
    "title": "Pyramid Region-based Slot Attention Network for Temporal Action Proposal  Generation",
    "abstract": "It has been found that temporal action proposal generation, which aims to\ndiscover the temporal action instances within the range of the start and end\nframes in the untrimmed videos, can largely benefit from proper temporal and\nsemantic context exploitation. The latest efforts were dedicated to considering\nthe temporal context and similarity-based semantic contexts through\nself-attention modules. However, they still suffer from cluttered background\ninformation and limited contextual feature learning. In this paper, we propose\na novel Pyramid Region-based Slot Attention (PRSlot) module to address these\nissues. Instead of using the similarity computation, our PRSlot module directly\nlearns the local relations in an encoder-decoder manner and generates the\nrepresentation of a local region enhanced based on the attention over input\nfeatures called \\textit{slot}. Specifically, upon the input snippet-level\nfeatures, PRSlot module takes the target snippet as \\textit{query}, its\nsurrounding region as \\textit{key} and then generates slot representations for\neach \\textit{query-key} slot by aggregating the local snippet context with a\nparallel pyramid strategy. Based on PRSlot modules, we present a novel Pyramid\nRegion-based Slot Attention Network termed PRSA-Net to learn a unified visual\nrepresentation with rich temporal and semantic context for better proposal\ngeneration. Extensive experiments are conducted on two widely adopted THUMOS14\nand ActivityNet-1.3 benchmarks. Our PRSA-Net outperforms other state-of-the-art\nmethods. In particular, we improve the AR@100 from the previous best 50.67% to\n56.12% for proposal generation and raise the mAP under 0.5 tIoU from 51.9\\% to\n58.7\\% for action detection on THUMOS14. \\textit{Code is available at}\n\\url{https://github.com/handhand123/PRSA-Net}",
    "descriptor": "",
    "authors": [
      "Shuaicheng Li",
      "Feng Zhang",
      "Rui-Wei Zhao",
      "Rui Feng",
      "Kunlin Yang",
      "Lingbo Liu",
      "Jun Hou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10095"
  },
  {
    "id": "arXiv:2206.10096",
    "title": "Transformers Improve Breast Cancer Diagnosis from Unregistered  Multi-View Mammograms",
    "abstract": "Deep convolutional neural networks (CNNs) have been widely used in various\nmedical imaging tasks. However, due to the intrinsic locality of convolution\noperation, CNNs generally cannot model long-range dependencies well, which are\nimportant for accurately identifying or mapping corresponding breast lesion\nfeatures computed from unregistered multiple mammograms. This motivates us to\nleverage the architecture of Multi-view Vision Transformers to capture\nlong-range relationships of multiple mammograms from the same patient in one\nexamination. For this purpose, we employ local Transformer blocks to separately\nlearn patch relationships within four mammograms acquired from two-view\n(CC/MLO) of two-side (right/left) breasts. The outputs from different views and\nsides are concatenated and fed into global Transformer blocks, to jointly learn\npatch relationships between four images representing two different views of the\nleft and right breasts. To evaluate the proposed model, we retrospectively\nassembled a dataset involving 949 sets of mammograms, which include 470\nmalignant cases and 479 normal or benign cases. We trained and evaluated the\nmodel using a five-fold cross-validation method. Without any arduous\npreprocessing steps (e.g., optimal window cropping, chest wall or pectoral\nmuscle removal, two-view image registration, etc.), our four-image\n(two-view-two-side) Transformer-based model achieves case classification\nperformance with an area under ROC curve (AUC = 0.818), which significantly\noutperforms AUC = 0.784 achieved by the state-of-the-art multi-view CNNs (p =\n0.009). It also outperforms two one-view-two-side models that achieve AUC of\n0.724 (CC view) and 0.769 (MLO view), respectively. The study demonstrates the\npotential of using Transformers to develop high-performing computer-aided\ndiagnosis schemes that combine four mammograms.",
    "descriptor": "",
    "authors": [
      "Xuxin Chen",
      "Ke Zhang",
      "Neman Abdoli",
      "Patrik W. Gilley",
      "Ximin Wang",
      "Hong Liu",
      "Bin Zheng",
      "Yuchen Qiu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.10096"
  },
  {
    "id": "arXiv:2206.10098",
    "title": "Reconstruct from Top View: A 3D Lane Detection Approach based on  Geometry Structure Prior",
    "abstract": "In this paper, we propose an advanced approach in targeting the problem of\nmonocular 3D lane detection by leveraging geometry structure underneath the\nprocess of 2D to 3D lane reconstruction. Inspired by previous methods, we first\nanalyze the geometry heuristic between the 3D lane and its 2D representation on\nthe ground and propose to impose explicit supervision based on the structure\nprior, which makes it achievable to build inter-lane and intra-lane\nrelationships to facilitate the reconstruction of 3D lanes from local to\nglobal. Second, to reduce the structure loss in 2D lane representation, we\ndirectly extract top view lane information from front view images, which\ntremendously eases the confusion of distant lane features in previous methods.\nFurthermore, we propose a novel task-specific data augmentation method by\nsynthesizing new training data for both segmentation and reconstruction tasks\nin our pipeline, to counter the imbalanced data distribution of camera pose and\nground slope to improve generalization on unseen data. Our work marks the first\nattempt to employ the geometry prior information into DNN-based 3D lane\ndetection and makes it achievable for detecting lanes in an extra-long\ndistance, doubling the original detection range. The proposed method can be\nsmoothly adopted by other frameworks without extra costs. Experimental results\nshow that our work outperforms state-of-the-art approaches by 3.8% F-Score on\nApollo 3D synthetic dataset at real-time speed of 82 FPS without introducing\nextra parameters.",
    "descriptor": "",
    "authors": [
      "Chenguang Li",
      "Jia Shi",
      "Ya Wang",
      "Guangliang Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10098"
  },
  {
    "id": "arXiv:2206.10099",
    "title": "Electrochemical Parameter Identification for Lithium-ion Batteries on  Separated Time-scales",
    "abstract": "Lithium-ion batteries (LIBs) play an essential role in the energy sector and\nhave been widely deployed in recent years. Generally, LIBs are managed in\nmodel-driven manners, leading to the need for parameter identification.\nHowever, as an electrochemical system, the battery contains various parameters\nwhile the measurements are mainly the current and voltage, inducing an inherent\nill-conditioned identification problem. A flexible and lightweight parameter\nidentification framework, including the test, model, and algorithm, is proposed\nin this work. Electrochemical parameters are grouped by time-variant features\nand identified on separated time-scales. Parameters with slow dynamics are\nidentified in a hybrid data-driven and model-driven approach based on the data\nof a quasi-static test covering the partial SOC range. Parameters with fast\ndynamics are identified using a specifically designed sensitivity-oriented\nstepwise optimization algorithm based on the data of a dynamic test consisting\nof a series of constant current (CC) pulses. The mixed impacts of different\nparameters can be decoupled and the time costs of the test and computation can\nbe reduced. Specifically, it takes a few hours to identify slow dynamic\nparameters and a few minutes to identify fast dynamic parameters. Numerical\nexperiments on a typical \\ce{LiNCM} battery at different life stages are\nconducted. The results show that the identification accuracy of crucial\nparameters can reach over 95\\%, and the battery model error is reduced below\n2$\\times$10$^{-3}$V.",
    "descriptor": "",
    "authors": [
      "Yuxuan Gu",
      "Jianxiao Wang",
      "Yuanbo Chen",
      "Wei Xiao",
      "Zhongwei Deng",
      "Qixin Chen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.10099"
  },
  {
    "id": "arXiv:2206.10101",
    "title": "Model-Based Imitation Learning Using Entropy Regularization of Model and  Policy",
    "abstract": "Approaches based on generative adversarial networks for imitation learning\nare promising because they are sample efficient in terms of expert\ndemonstrations. However, training a generator requires many interactions with\nthe actual environment because model-free reinforcement learning is adopted to\nupdate a policy. To improve the sample efficiency using model-based\nreinforcement learning, we propose model-based Entropy-Regularized Imitation\nLearning (MB-ERIL) under the entropy-regularized Markov decision process to\nreduce the number of interactions with the actual environment. MB-ERIL uses two\ndiscriminators. A policy discriminator distinguishes the actions generated by a\nrobot from expert ones, and a model discriminator distinguishes the\ncounterfactual state transitions generated by the model from the actual ones.\nWe derive the structured discriminators so that the learning of the policy and\nthe model is efficient. Computer simulations and real robot experiments show\nthat MB-ERIL achieves a competitive performance and significantly improves the\nsample efficiency compared to baseline methods.",
    "descriptor": "\nComments: 8 pages, 7 figures\n",
    "authors": [
      "Eiji Uchibe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.10101"
  },
  {
    "id": "arXiv:2206.10103",
    "title": "Automatic Controllable Product Copywriting for E-Commerce",
    "abstract": "Automatic product description generation for e-commerce has witnessed\nsignificant advancement in the past decade. Product copywriting aims to attract\nusers' interest and improve user experience by highlighting product\ncharacteristics with textual descriptions. As the services provided by\ne-commerce platforms become diverse, it is necessary to adapt the patterns of\nautomatically-generated descriptions dynamically. In this paper, we report our\nexperience in deploying an E-commerce Prefix-based Controllable Copywriting\nGeneration (EPCCG) system into the JD.com e-commerce product recommendation\nplatform. The development of the system contains two main components: 1)\ncopywriting aspect extraction; 2) weakly supervised aspect labeling; 3) text\ngeneration with a prefix-based language model; 4) copywriting quality control.\nWe conduct experiments to validate the effectiveness of the proposed EPCCG. In\naddition, we introduce the deployed architecture which cooperates with the\nEPCCG into the real-time JD.com e-commerce recommendation platform and the\nsignificant payoff since deployment.",
    "descriptor": "\nComments: This paper has been accepted by KDD 2022 ADS\n",
    "authors": [
      "Xiaojie Guo",
      "Qingkai Zeng",
      "Meng Jiang",
      "Yun Xiao",
      "Bo Long",
      "Lingfei Wu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10103"
  },
  {
    "id": "arXiv:2206.10107",
    "title": "Sensitivity of Average Precision to Bounding Box Perturbations",
    "abstract": "Object detection is a fundamental vision task. It has been highly researched\nin academia and has been widely adopted in industry. Average Precision (AP) is\nthe standard score for evaluating object detectors. Our understanding of the\nsubtleties of this score, however, is limited. Here, we quantify the\nsensitivity of AP to bounding box perturbations and show that AP is very\nsensitive to small translations. Only one pixel shift is enough to drop the mAP\nof a model by 8.4%. The mAP drop over small objects with only one pixel shift\nis 23.1%. The corresponding numbers when ground-truth (GT) boxes are used as\npredictions are 23% and 41.7%, respectively. These results explain why\nachieving higher mAP becomes increasingly harder as models get better. We also\ninvestigate the effect of box scaling on AP. Code and data is available at\nhttps://github.com/aliborji/AP_Box_Perturbation.",
    "descriptor": "",
    "authors": [
      "Ali Borji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10107"
  },
  {
    "id": "arXiv:2206.10110",
    "title": "ProML: A Decentralised Platform for Provenance Management of Machine  Learning Software Systems",
    "abstract": "Large-scale Machine Learning (ML) based Software Systems are increasingly\ndeveloped by distributed teams situated in different trust domains. Insider\nthreats can launch attacks from any domain to compromise ML assets (models and\ndatasets). Therefore, practitioners require information about how and by whom\nML assets were developed to assess their quality attributes such as security,\nsafety, and fairness. Unfortunately, it is challenging for ML teams to access\nand reconstruct such historical information of ML assets (ML provenance)\nbecause it is generally fragmented across distributed ML teams and threatened\nby the same adversaries that attack ML assets. This paper proposes ProML, a\ndecentralised platform that leverages blockchain and smart contracts to empower\ndistributed ML teams to jointly manage a single source of truth about\ncirculated ML assets' provenance without relying on a third party, which is\nvulnerable to insider threats and presents a single point of failure. We\npropose a novel architectural approach called Artefact-as-a-State-Machine to\nleverage blockchain transactions and smart contracts for managing ML provenance\ninformation and introduce a user-driven provenance capturing mechanism to\nintegrate existing scripts and tools to ProML without compromising\nparticipants' control over their assets and toolchains. We evaluate the\nperformance and overheads of ProML by benchmarking a proof-of-concept system on\na global blockchain. Furthermore, we assessed ProML's security against a threat\nmodel of a distributed ML workflow.",
    "descriptor": "\nComments: Accepted as full paper in ECSA 2022 conference. To be presented\n",
    "authors": [
      "Nguyen Khoi Tran",
      "Bushra Sabir",
      "M. Ali Babar",
      "Nini Cui",
      "Mehran Abolhasan",
      "Justin Lipman"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.10110"
  },
  {
    "id": "arXiv:2206.10112",
    "title": "General Framework for Reversible Data Hiding in Texts Based on Masked  Language Modeling",
    "abstract": "With the fast development of natural language processing, recent advances in\ninformation hiding focus on covertly embedding secret information into texts.\nThese algorithms either modify a given cover text or directly generate a text\ncontaining secret information, which, however, are not reversible, meaning that\nthe original text not carrying secret information cannot be perfectly recovered\nunless much side information are shared in advance. To tackle with this\nproblem, in this paper, we propose a general framework to embed secret\ninformation into a given cover text, for which the embedded information and the\noriginal cover text can be perfectly retrieved from the marked text. The main\nidea of the proposed method is to use a masked language model to generate such\na marked text that the cover text can be reconstructed by collecting the words\nof some positions and the words of the other positions can be processed to\nextract the secret information. Our results show that the original cover text\nand the secret information can be successfully embedded and extracted.\nMeanwhile, the marked text carrying secret information has good fluency and\nsemantic quality, indicating that the proposed method has satisfactory\nsecurity, which has been verified by experimental results. Furthermore, there\nis no need for the data hider and data receiver to share the language model,\nwhich significantly reduces the side information and thus has good potential in\napplications.",
    "descriptor": "\nComments: this https URL&hl=en\n",
    "authors": [
      "Xiaoyan Zheng",
      "Yurun Fang",
      "Hanzhou Wu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.10112"
  },
  {
    "id": "arXiv:2206.10118",
    "title": "HOPE: Hierarchical Spatial-temporal Network for Occupancy Flow  Prediction",
    "abstract": "In this report, we introduce our solution to the Occupancy and Flow\nPrediction challenge in the Waymo Open Dataset Challenges at CVPR 2022, which\nranks 1st on the leaderboard. We have developed a novel hierarchical\nspatial-temporal network featured with spatial-temporal encoders, a multi-scale\naggregator enriched with latent variables, and a recursive hierarchical 3D\ndecoder. We use multiple losses including focal loss and modified flow trace\nloss to efficiently guide the training process. Our method achieves a\nFlow-Grounded Occupancy AUC of 0.8389 and outperforms all the other teams on\nthe leaderboard.",
    "descriptor": "\nComments: 1st Ranking Solution for the Occupancy and Flow Prediction of the Waymo Open Dataset Challenges 2022 (this http URL)\n",
    "authors": [
      "Yihan Hu",
      "Wenxin Shao",
      "Bo Jiang",
      "Jiajie Chen",
      "Siqi Chai",
      "Zhening Yang",
      "Jingyu Qian",
      "Helong Zhou",
      "Qiang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10118"
  },
  {
    "id": "arXiv:2206.10119",
    "title": "Optimization simulation of reflow welding based on prediction of  regional center temperature field",
    "abstract": "Before reflow soldering of integrated electronic products, the numerical\nsimulation of temperature control curve of reflow furnace is crucial for\nselecting proper parameters and improving the overall efficiency of reflow\nsoldering process and product quality. According to the heat conduction law and\nthe specific heat capacity formula, the first-order ordinary differential\nequation of the central temperature curve of the welding area with respect to\nthe temperature distribution function in the furnace on the conveyor belt\ndisplacement is obtained. For the gap with small temperature difference, the\nsigmoid function is used to obtain a smooth interval temperature transition\ncurve; For the gap with large temperature difference, the linear combination of\nexponential function and primary function is used to approach the actual\nconcave function, so as to obtain the complete temperature distribution\nfunction in the furnace. The welding parameters are obtained by solving the\nordinary differential equation, and a set of optimal process parameters\nconsistent with the process boundary are obtained by calculating the mean\nsquare error between the predicted temperature field and the real temperature\ndistribution. At the same time, a set of reflow optimization strategies are\ndesigned for speed interval prediction strategy, minimum parameter interval\nprediction strategy, and the most symmetrical parameter interval prediction of\nsolder paste melting reflow area. The simulation results show that the\ntemperature field prediction results obtained by this method are highly\nconsistent with the actual sensor data, and have strong correlation. This\nmethod can help to select appropriate process parameters, optimize the\nproduction process, reduce equipment commissioning practice and optimize the\nsolder joint quality of production products.",
    "descriptor": "\nComments: in Chinese language. Journal of Computer Simulation\n",
    "authors": [
      "Yuan Sui",
      "Fan-yang Bu",
      "Zi-long Shao",
      "Wei Yan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.10119"
  },
  {
    "id": "arXiv:2206.10121",
    "title": "Finite Expression Method for Solving High-Dimensional Partial  Differential Equations",
    "abstract": "Designing efficient and accurate numerical solvers for high-dimensional\npartial differential equations (PDEs) remains a challenging and important topic\nin computational science and engineering, mainly due to the ``curse of\ndimensionality\" in designing numerical schemes that scale in dimension. This\npaper introduces a new methodology that seeks an approximate PDE solution in\nthe space of functions with finitely many analytic expressions and, hence, this\nmethodology is named the finite expression method (FEX). It is proved in\napproximation theory that FEX can avoid the curse of dimensionality. As a proof\nof concept, a deep reinforcement learning method is proposed to implement FEX\nfor various high-dimensional PDEs in different dimensions, achieving high and\neven machine accuracy with a memory complexity polynomial in dimension and an\namenable time complexity. An approximate solution with finite analytic\nexpressions also provides interpretable insights into the ground truth PDE\nsolution, which can further help to advance the understanding of physical\nsystems and design postprocessing techniques for a refined solution.",
    "descriptor": "",
    "authors": [
      "Senwei Liang",
      "Haizhao Yang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10121"
  },
  {
    "id": "arXiv:2206.10122",
    "title": "Safe and Psychologically Pleasant Traffic Signal Control with  Reinforcement Learning using Action Masking",
    "abstract": "Reinforcement learning (RL) for traffic signal control (TSC) has shown better\nperformance in simulation for controlling the traffic flow of intersections\nthan conventional approaches. However, due to several challenges, no RL-based\nTSC has been deployed in the field yet. One major challenge for real-world\ndeployment is to ensure that all safety requirements are met at all times\nduring operation. We present an approach to ensure safety in a real-world\nintersection by using an action space that is safe by design. The action space\nencompasses traffic phases, which represent the combination of non-conflicting\nsignal colors of the intersection. Additionally, an action masking mechanism\nmakes sure that only appropriate phase transitions are carried out. Another\nchallenge for real-world deployment is to ensure a control behavior that avoids\nstress for road users. We demonstrate how to achieve this by incorporating\ndomain knowledge through extending the action masking mechanism. We test and\nverify our approach in a realistic simulation scenario. By ensuring safety and\npsychologically pleasant control behavior, our approach drives development\ntowards real-world deployment of RL for TSC.",
    "descriptor": "\nComments: Paper was accepted by the ITSC 2022 (25th IEEE International Conference on Intelligent Transportation Systems)\n",
    "authors": [
      "Arthur M\u00fcller",
      "Matthia Sabatelli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10122"
  },
  {
    "id": "arXiv:2206.10123",
    "title": "Codebook Mismatch Can Be Fully Compensated by Mismatched Decoding",
    "abstract": "We consider an ensemble of constant composition codes that are subsets of\nlinear codes: while the encoder uses only the constant-composition subcode, the\ndecoder operates as if the full linear code was used, with the motivation of\nsimultaneously benefiting both from the probabilistic shaping of the channel\ninput and from the linear structure of the code. We prove that the codebook\nmismatch can be fully compensated by using a mismatched additive decoding\nmetric that achieves the random coding error exponent of (non-linear) constant\ncomposition codes. As the coding rate tends to the mutual information, the\noptimal mismatched metric approaches the maximum a posteriori probability (MAP)\nmetric, showing that codebook mismatch with mismatched MAP metric is\ncapacity-achieving for the optimal input assignment.",
    "descriptor": "\nComments: 25 pages, one figure, submitted for publication\n",
    "authors": [
      "Neri Merhav",
      "Georg Bocherer"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.10123"
  },
  {
    "id": "arXiv:2206.10125",
    "title": "Supervision-Guided Codebooks for Masked Prediction in Speech  Pre-training",
    "abstract": "Recently, masked prediction pre-training has seen remarkable progress in\nself-supervised learning (SSL) for speech recognition. It usually requires a\ncodebook obtained in an unsupervised way, making it less accurate and difficult\nto interpret. We propose two supervision-guided codebook generation approaches\nto improve automatic speech recognition (ASR) performance and also the\npre-training efficiency, either through decoding with a hybrid ASR system to\ngenerate phoneme-level alignments (named PBERT), or performing clustering on\nthe supervised speech features extracted from an end-to-end CTC model (named\nCTC clustering). Both the hybrid and CTC models are trained on the same small\namount of labeled speech as used in fine-tuning. Experiments demonstrate\nsignificant superiority of our methods to various SSL and self-training\nbaselines, with up to 17.0% relative WER reduction. Our pre-trained models also\nshow good transferability in a non-ASR speech task.",
    "descriptor": "\nComments: To appear in Proc. Interspeech 2022\n",
    "authors": [
      "Chengyi Wang",
      "Yiming Wang",
      "Yu Wu",
      "Sanyuan Chen",
      "Jinyu Li",
      "Shujie Liu",
      "Furu Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.10125"
  },
  {
    "id": "arXiv:2206.10128",
    "title": "Bridging the Gap Between Indexing and Retrieval for Differentiable  Search Index with Query Generation",
    "abstract": "The Differentiable Search Index (DSI) is a new, emerging paradigm for\ninformation retrieval. Unlike traditional retrieval architectures where index\nand retrieval are two different and separate components, DSI uses a single\ntransformer model to perform both indexing and retrieval. In this paper, we\nidentify and tackle an important issue of current DSI models: the data\ndistribution mismatch that occurs between the DSI indexing and retrieval\nprocesses. Specifically, we argue that, at indexing, current DSI methods learn\nto build connections between long document texts and their identifies, but then\nat retrieval, short query texts are provided to DSI models to perform the\nretrieval of the document identifiers. This problem is further exacerbated when\nusing DSI for cross-lingual retrieval, where document text and query text are\nin different languages. To address this fundamental problem of current DSI\nmodels we propose a simple yet effective indexing framework for DSI called\nDSI-QG. In DSI-QG, documents are represented by a number of relevant queries\ngenerated by a query generation model at indexing time. This allows DSI models\nto connect a document identifier to a set of query texts when indexing, hence\nmitigating data distribution mismatches present between the indexing and the\nretrieval phases. Empirical results on popular mono-lingual and cross-lingual\npassage retrieval benchmark datasets show that DSI-QG significantly outperforms\nthe original DSI model.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Shengyao Zhuang",
      "Houxing Ren",
      "Linjun Shou",
      "Jian Pei",
      "Ming Gong",
      "Guido Zuccon",
      "Daxin Jiang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.10128"
  },
  {
    "id": "arXiv:2206.10129",
    "title": "Automatic Concept Extraction for Concept Bottleneck-based Video  Classification",
    "abstract": "Recent efforts in interpretable deep learning models have shown that\nconcept-based explanation methods achieve competitive accuracy with standard\nend-to-end models and enable reasoning and intervention about extracted\nhigh-level visual concepts from images, e.g., identifying the wing color and\nbeak length for bird-species classification. However, these concept bottleneck\nmodels rely on a necessary and sufficient set of predefined concepts-which is\nintractable for complex tasks such as video classification. For complex tasks,\nthe labels and the relationship between visual elements span many frames, e.g.,\nidentifying a bird flying or catching prey-necessitating concepts with various\nlevels of abstraction. To this end, we present CoDEx, an automatic Concept\nDiscovery and Extraction module that rigorously composes a necessary and\nsufficient set of concept abstractions for concept-based video classification.\nCoDEx identifies a rich set of complex concept abstractions from natural\nlanguage explanations of videos-obviating the need to predefine the amorphous\nset of concepts. To demonstrate our method's viability, we construct two new\npublic datasets that combine existing complex video classification datasets\nwith short, crowd-sourced natural language explanations for their labels. Our\nmethod elicits inherent complex concept abstractions in natural language to\ngeneralize concept-bottleneck methods to complex tasks.",
    "descriptor": "\nComments: 10 pages, Appendix: 2 pages\n",
    "authors": [
      "Jeya Vikranth Jeyakumar",
      "Luke Dickens",
      "Luis Garcia",
      "Yu-Hsi Cheng",
      "Diego Ramirez Echavarria",
      "Joseph Noor",
      "Alessandra Russo",
      "Lance Kaplan",
      "Erik Blasch",
      "Mani Srivastava"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10129"
  },
  {
    "id": "arXiv:2206.10130",
    "title": "Maximal automatic complexity and context-free languages",
    "abstract": "Let $A_N$ denote nondeterministic automatic complexity and \\[\nL_{k,c}=\\{x\\in [k]^* : A_N(x)> |x|/c\\}. \\] In particular, $L_{k,2}$ is the\nlanguage of all $k$-ary words for which $A_N$ is maximal, while $L_{k,3}$ gives\na rough dividing line between complex and simple. Let $\\mathbf{CFL}$ denote the\ncomplexity class consisting of all context-free languages. While it is not\nknown that $L_{2,2}$ is infinite, Kjos-Hanssen (2017) showed that $L_{3,2}$ is\n$\\mathbf{CFL}$-immune but not $\\mathbf{coCFL}$-immune. We complete the picture\nby showing that $L_{3,2}\\not\\in\\mathbf{coCFL}$.\nTurning to Boolean circuit complexity, we show that $L_{2,3}$ is\n$\\mathbf{SAC}^0$-immune and $\\mathbf{SAC}^0$-coimmune. Here $\\mathbf{SAC}^0$\ndenotes the complexity class consisting of all languages computed by\n(non-uniform) constant-depth circuits with semi-unbounded fanin.\nAs for arithmetic circuits, we show that\n$\\{x:A_N(x)>1\\}\\not\\in\\oplus\\mathbf{SAC}^0$. In particular,\n$\\mathbf{SAC}^0\\not\\subseteq\\oplus \\mathbf{SAC}^0$, which resolves an open\nimplication from the Complexity Zoo.",
    "descriptor": "\nComments: Automata Theory and Applications: Games, Learning and Structures (20-24 Sep 2021). Lecture Notes Series, Institute for Mathematical Sciences, National University of Singapore\n",
    "authors": [
      "Bj\u00f8rn Kjos-Hanssen"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.10130"
  },
  {
    "id": "arXiv:2206.10131",
    "title": "An Integrated Representation & Compression Scheme Based on Convolutional  Autoencoders with 4D DCT Perceptual Encoding for High Dynamic Range Light  Fields",
    "abstract": "The emerging and existing light field displays are highly capable of\nrealistic presentation of 3D scenes on auto-stereoscopic glasses-free\nplatforms. The light field size is a major drawback while utilising 3D displays\nand streaming purposes. When a light field is of high dynamic range, the size\nincreases drastically. In this paper, we propose a novel compression algorithm\nfor a high dynamic range light field which yields a perceptually lossless\ncompression. The algorithm exploits the inter and intra view correlations of\nthe HDR light field by interpreting it to be a four-dimension volume. The HDR\nlight field compression is based on a novel 4DDCT-UCS (4D-DCT Uniform Colour\nSpace) algorithm. Additional encoding of 4DDCT-UCS acquired images by HEVC\neliminates intra-frame, inter-frame and intrinsic redundancies in HDR light\nfield data. Comparison with state-of-the-art coders like JPEG-XL and HDR video\ncoding algorithm exhibits superior compression performance of the proposed\nscheme for real-world light fields.",
    "descriptor": "",
    "authors": [
      "Sally Khaidem",
      "Mansi Sharma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.10131"
  },
  {
    "id": "arXiv:2206.10137",
    "title": "Few-Max: Few-Shot Domain Adaptation for Unsupervised Contrastive  Representation Learning",
    "abstract": "Contrastive self-supervised learning methods learn to map data points such as\nimages into non-parametric representation space without requiring labels. While\nhighly successful, current methods require a large amount of data in the\ntraining phase. In situations where the target training set is limited in size,\ngeneralization is known to be poor. Pretraining on a large source data set and\nfine-tuning on the target samples is prone to overfitting in the few-shot\nregime, where only a small number of target samples are available. Motivated by\nthis, we propose a domain adaption method for self-supervised contrastive\nlearning, termed Few-Max, to address the issue of adaptation to a target\ndistribution under few-shot learning. To quantify the representation quality,\nwe evaluate Few-Max on a range of source and target datasets, including\nImageNet, VisDA, and fastMRI, on which Few-Max consistently outperforms other\napproaches.",
    "descriptor": "",
    "authors": [
      "Ali Lotfi Rezaabad",
      "Sidharth Kumar",
      "Sriram Vishwanath",
      "Jonathan I. Tamir"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10137"
  },
  {
    "id": "arXiv:2206.10139",
    "title": "Insights into Pre-training via Simpler Synthetic Tasks",
    "abstract": "Pre-training produces representations that are effective for a wide range of\ndownstream tasks, but it is still unclear what properties of pre-training are\nnecessary for effective gains. Notably, recent work shows that even\npre-training on synthetic tasks can achieve significant gains in downstream\ntasks. In this work, we perform three experiments that iteratively simplify\npre-training and show that the simplifications still retain much of its gains.\nFirst, building on prior work, we perform a systematic evaluation of three\nexisting synthetic pre-training methods on six downstream tasks. We find the\nbest synthetic pre-training method, LIME, attains an average of $67\\%$ of the\nbenefits of natural pre-training. Second, to our surprise, we find that\npre-training on a simple and generic synthetic task defined by the Set function\nachieves $65\\%$ of the benefits, almost matching LIME. Third, we find that\n$39\\%$ of the benefits can be attained by using merely the parameter statistics\nof synthetic pre-training. We release the source code at\nhttps://github.com/felixzli/synthetic_pretraining.",
    "descriptor": "\nComments: 30 pages\n",
    "authors": [
      "Yuhuai Wu",
      "Felix Li",
      "Percy Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.10139"
  },
  {
    "id": "arXiv:2206.10140",
    "title": "Comprehensive Analysis of Negative Sampling in Knowledge Graph  Representation Learning",
    "abstract": "Negative sampling (NS) loss plays an important role in learning knowledge\ngraph embedding (KGE) to handle a huge number of entities. However, the\nperformance of KGE degrades without hyperparameters such as the margin term and\nnumber of negative samples in NS loss being appropriately selected. Currently,\nempirical hyperparameter tuning addresses this problem at the cost of\ncomputational time. To solve this problem, we theoretically analyzed NS loss to\nassist hyperparameter tuning and understand the better use of the NS loss in\nKGE learning. Our theoretical analysis showed that scoring methods with\nrestricted value ranges, such as TransE and RotatE, require appropriate\nadjustment of the margin term or the number of negative samples different from\nthose without restricted value ranges, such as RESCAL, ComplEx, and DistMult.\nWe also propose subsampling methods specialized for the NS loss in KGE studied\nfrom a theoretical aspect. Our empirical analysis on the FB15k-237, WN18RR, and\nYAGO3-10 datasets showed that the results of actually trained models agree with\nour theoretical findings.",
    "descriptor": "\nComments: Accepted at ICML2022\n",
    "authors": [
      "Hidetaka Kamigaito",
      "Katsuhiko Hayashi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.10140"
  },
  {
    "id": "arXiv:2206.10142",
    "title": "Propagation with Adaptive Mask then Training for Node Classification on  Attributed Networks",
    "abstract": "Node classification on attributed networks is a semi-supervised task that is\ncrucial for network analysis. By decoupling two critical operations in Graph\nConvolutional Networks (GCNs), namely feature transformation and neighborhood\naggregation, some recent works of decoupled GCNs could support the information\nto propagate deeper and achieve advanced performance. However, they follow the\ntraditional structure-aware propagation strategy of GCNs, making it hard to\ncapture the attribute correlation of nodes and sensitive to the structure noise\ndescribed by edges whose two endpoints belong to different categories. To\naddress these issues, we propose a new method called the itshape Propagation\nwith Adaptive Mask then Training (PAMT). The key idea is to integrate the\nattribute similarity mask into the structure-aware propagation process. In this\nway, PAMT could preserve the attribute correlation of adjacent nodes during the\npropagation and effectively reduce the influence of structure noise. Moreover,\nwe develop an iterative refinement mechanism to update the similarity mask\nduring the training process for improving the training performance. Extensive\nexperiments on four real-world datasets demonstrate the superior performance\nand robustness of PAMT.",
    "descriptor": "",
    "authors": [
      "Jinsong Chen",
      "Boyu Li",
      "Qiuting He",
      "Kun He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.10142"
  },
  {
    "id": "arXiv:2206.10144",
    "title": "Open-Source Framework for Encrypted Internet and Malicious Traffic  Classification",
    "abstract": "Internet traffic classification plays a key role in network visibility,\nQuality of Services (QoS), intrusion detection, Quality of Experience (QoE) and\ntraffic-trend analyses. In order to improve privacy, integrity,\nconfidentiality, and protocol obfuscation, the current traffic is based on\nencryption protocols, e.g., SSL/TLS. With the increased use of Machine-Learning\n(ML) and Deep-Learning (DL) models in the literature, comparison between\ndifferent models and methods has become cumbersome and difficult due to a lack\nof a standardized framework. In this paper, we propose an open-source\nframework, named OSF-EIMTC, which can provide the full pipeline of the learning\nprocess. From the well-known datasets to extracting new and well-known\nfeatures, it provides implementations of well-known ML and DL models (from the\ntraffic classification literature) as well as evaluations. Such a framework can\nfacilitate research in traffic classification domains, so that it will be more\nrepeatable, reproducible, easier to execute, and will allow a more accurate\ncomparison of well-known and novel features and models. As part of our\nframework evaluation, we demonstrate a variety of cases where the framework can\nbe of use, utilizing multiple datasets, models, and feature sets. We show\nanalyses of publicly available datasets and invite the community to participate\nin our open challenges using the OSF-EIMTC.",
    "descriptor": "",
    "authors": [
      "Ofek Bader",
      "Adi Lichy",
      "Amit Dvir",
      "Ran Dubin",
      "Chen Hajaj"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10144"
  },
  {
    "id": "arXiv:2206.10145",
    "title": "Deep Learning Eliminates Massive Dust Storms from Images of Tianwen-1",
    "abstract": "Dust storms may remarkably degrade the imaging quality of Martian orbiters\nand delay the progress of mapping the global topography and geomorphology. To\naddress this issue, this paper presents an approach that reuses the image\ndehazing knowledge obtained on Earth to resolve the dust-removal problem on\nMars. In this approach, we collect remote-sensing images captured by Tianwen-1\nand manually select hundreds of clean and dusty images. Inspired by the haze\nformation process on Earth, we formulate a similar visual degradation process\non clean images and synthesize dusty images sharing a similar feature\ndistribution with realistic dusty images. These realistic clean and synthetic\ndusty image pairs are used to train a deep model that inherently encodes dust\nirrelevant features and decodes them into dust-free images. Qualitative and\nquantitative results show that dust storms can be effectively eliminated by the\nproposed approach, leading to obviously improved topographical and\ngeomorphological details of Mars.",
    "descriptor": "",
    "authors": [
      "Hongyu Li",
      "Jia Li",
      "Xin Ren",
      "Long Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.10145"
  },
  {
    "id": "arXiv:2206.10146",
    "title": "KE-RCNN: Unifying Knowledge based Reasoning into Part-level Attribute  Parsing",
    "abstract": "Part-level attribute parsing is a fundamental but challenging task, which\nrequires the region-level visual understanding to provide explainable details\nof body parts. Most existing approaches address this problem by adding a\nregional convolutional neural network (RCNN) with an attribute prediction head\nto a two-stage detector, in which attributes of body parts are identified from\nlocal-wise part boxes. However, local-wise part boxes with limit visual clues\n(i.e., part appearance only) lead to unsatisfying parsing results, since\nattributes of body parts are highly dependent on comprehensive relations among\nthem. In this article, we propose a Knowledge Embedded RCNN (KE-RCNN) to\nidentify attributes by leveraging rich knowledges, including implicit knowledge\n(e.g., the attribute ``above-the-hip'' for a shirt requires visual/geometry\nrelations of shirt-hip) and explicit knowledge (e.g., the part of ``shorts''\ncannot have the attribute of ``hoodie'' or ``lining''). Specifically, the\nKE-RCNN consists of two novel components, i.e., Implicit Knowledge based\nEncoder (IK-En) and Explicit Knowledge based Decoder (EK-De). The former is\ndesigned to enhance part-level representation by encoding part-part relational\ncontexts into part boxes, and the latter one is proposed to decode attributes\nwith a guidance of prior knowledge about \\textit{part-attribute} relations. In\nthis way, the KE-RCNN is plug-and-play, which can be integrated into any\ntwo-stage detectors, e.g., Attribute-RCNN, Cascade-RCNN, HRNet based RCNN and\nSwinTransformer based RCNN. Extensive experiments conducted on two challenging\nbenchmarks, e.g., Fashionpedia and Kinetics-TPS, demonstrate the effectiveness\nand generalizability of the KE-RCNN. In particular, it achieves higher\nimprovements over all existing methods, reaching around 3% of AP on\nFashionpedia and around 4% of Acc on Kinetics-TPS.",
    "descriptor": "",
    "authors": [
      "Xuanhan Wang",
      "Jingkuan Song",
      "Xiaojia Chen",
      "Lechao Cheng",
      "Lianli Gao",
      "Heng Tao Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10146"
  },
  {
    "id": "arXiv:2206.10148",
    "title": "Resource Allocation and Computation Offloading in a Millimeter-Wave  Train-Ground Network",
    "abstract": "In this paper, we consider an mmWave-based trainground communication system\nin the high-speed railway (HSR) scenario, where the computation tasks of users\ncan be partially offloaded to the rail-side base station (BS) or the mobile\nrelays (MRs) deployed on the roof of the train. The MRs operate in the\nfull-duplex (FD) mode to achieve high spectrum utilization. We formulate the\nproblem of minimizing the average task execution latency of all users, under\nlocal device and MRs energy consumption constraints. We propose a joint\nresource allocation and computation offloading scheme (JRACO) to solve the\nproblem. It consists of a resource allocation and computation offloading (RACO)\nalgorithm and an MR Energy constraint algorithm. RACO utilizes the matching\ngame theory to iterate between two subproblems, i.e., data segmentation and\nuser association and sub-channel allocation. With the RACO results, the MR\nenergy constraint algorithm ensures that the MR energy consumption constraint\nis satisfied. Extensive simulations validate that JRACO can effectively reduce\nthe average latency and increase the number of served users compared with three\nbaseline schemes.",
    "descriptor": "\nComments: 15 pages, 7 figures, IEEE TVT\n",
    "authors": [
      "Linqian Li",
      "Yong Niu",
      "Shiwen Mao",
      "Bo Ai",
      "Zhangdui Zhong",
      "Ning Wang",
      "Yali Chen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.10148"
  },
  {
    "id": "arXiv:2206.10155",
    "title": "Review Neural Networks about Image Transformation Based on IGC Learning  Framework with Annotated Information",
    "abstract": "Image transformation, a class of vision and graphics problems whose goal is\nto learn the mapping between an input image and an output image, develops\nrapidly in the context of deep neural networks. In Computer Vision (CV), many\nproblems can be regarded as the image transformation task, e.g., semantic\nsegmentation and style transfer. These works have different topics and\nmotivations, making the image transformation task flourishing. Some surveys\nonly review the research on style transfer or image-to-image translation, all\nof which are just a branch of image transformation. However, none of the\nsurveys summarize those works together in a unified framework to our best\nknowledge. This paper proposes a novel learning framework including Independent\nlearning, Guided learning, and Cooperative learning, called the IGC learning\nframework. The image transformation we discuss mainly involves the general\nimage-to-image translation and style transfer about deep neural networks. From\nthe perspective of this framework, we review those subtasks and give a unified\ninterpretation of various scenarios. We categorize related subtasks about the\nimage transformation according to similar development trends. Furthermore,\nexperiments have been performed to verify the effectiveness of IGC learning.\nFinally, new research directions and open problems are discussed for future\nresearch.",
    "descriptor": "",
    "authors": [
      "Yuanjie Yan",
      "Suorong Yang",
      "Yan Wang",
      "Jian Zhao",
      "Furao Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10155"
  },
  {
    "id": "arXiv:2206.10157",
    "title": "Probing Visual-Audio Representation for Video Highlight Detection via  Hard-Pairs Guided Contrastive Learning",
    "abstract": "Video highlight detection is a crucial yet challenging problem that aims to\nidentify the interesting moments in untrimmed videos. The key to this task lies\nin effective video representations that jointly pursue two goals,\n\\textit{i.e.}, cross-modal representation learning and fine-grained feature\ndiscrimination. In this paper, these two challenges are tackled by not only\nenriching intra-modality and cross-modality relations for representation\nmodeling but also shaping the features in a discriminative manner. Our proposed\nmethod mainly leverages the intra-modality encoding and cross-modality\nco-occurrence encoding for fully representation modeling. Specifically,\nintra-modality encoding augments the modality-wise features and dampens\nirrelevant modality via within-modality relation learning in both audio and\nvisual signals. Meanwhile, cross-modality co-occurrence encoding focuses on the\nco-occurrence inter-modality relations and selectively captures effective\ninformation among multi-modality. The multi-modal representation is further\nenhanced by the global information abstracted from the local context. In\naddition, we enlarge the discriminative power of feature embedding with a\nhard-pairs guided contrastive learning (HPCL) scheme. A hard-pairs sampling\nstrategy is further employed to mine the hard samples for improving feature\ndiscrimination in HPCL. Extensive experiments conducted on two benchmarks\ndemonstrate the effectiveness and superiority of our proposed methods compared\nto other state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Shuaicheng Li",
      "Feng Zhang",
      "Kunlin Yang",
      "Lingbo Liu",
      "Shinan Liu",
      "Jun Hou",
      "Shuai Yi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10157"
  },
  {
    "id": "arXiv:2206.10158",
    "title": "Certifiably Robust Policy Learning against Adversarial Communication in  Multi-agent Systems",
    "abstract": "Communication is important in many multi-agent reinforcement learning (MARL)\nproblems for agents to share information and make good decisions. However, when\ndeploying trained communicative agents in a real-world application where noise\nand potential attackers exist, the safety of communication-based policies\nbecomes a severe issue that is underexplored. Specifically, if communication\nmessages are manipulated by malicious attackers, agents relying on\nuntrustworthy communication may take unsafe actions that lead to catastrophic\nconsequences. Therefore, it is crucial to ensure that agents will not be misled\nby corrupted communication, while still benefiting from benign communication.\nIn this work, we consider an environment with $N$ agents, where the attacker\nmay arbitrarily change the communication from any $C<\\frac{N-1}{2}$ agents to a\nvictim agent. For this strong threat model, we propose a certifiable defense by\nconstructing a message-ensemble policy that aggregates multiple randomly\nablated message sets. Theoretical analysis shows that this message-ensemble\npolicy can utilize benign communication while being certifiably robust to\nadversarial communication, regardless of the attacking algorithm. Experiments\nin multiple environments verify that our defense significantly improves the\nrobustness of trained policies against various types of attacks.",
    "descriptor": "",
    "authors": [
      "Yanchao Sun",
      "Ruijie Zheng",
      "Parisa Hassanzadeh",
      "Yongyuan Liang",
      "Soheil Feizi",
      "Sumitra Ganesh",
      "Furong Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2206.10158"
  },
  {
    "id": "arXiv:2206.10160",
    "title": "Predicting Parking Lot Availability by Graph-to-Sequence Model: A Case  Study with SmartSantander",
    "abstract": "Nowadays, so as to improve services and urban areas livability, multiple\nsmart city initiatives are being carried out throughout the world.\nSmartSantander is a smart city project in Santander, Spain, which has relied on\nwireless sensor network technologies to deploy heterogeneous sensors within the\ncity to measure multiple parameters, including outdoor parking information. In\nthis paper, we study the prediction of parking lot availability using\nhistorical data from more than 300 outdoor parking sensors with SmartSantander.\nWe design a graph-to-sequence model to capture the periodical fluctuation and\ngeographical proximity of parking lots. For developing and evaluating our\nmodel, we use a 3-year dataset of parking lot availability in the city of\nSantander. Our model achieves a high accuracy compared with existing\nsequence-to-sequence models, which is accurate enough to provide a parking\ninformation service in the city. We apply our model to a smartphone application\nto be widely used by citizens and tourists.",
    "descriptor": "",
    "authors": [
      "Yuya Sasaki",
      "Junya Takayama",
      "Juan Ram\u00f3n Santana",
      "Shohei Yamasaki",
      "Tomoya Okuno",
      "Makoto Onizuka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10160"
  },
  {
    "id": "arXiv:2206.10162",
    "title": "Complex Network Analysis of a Graphic Novel: The Case of the Bande  Dessin{\u00e9}e Thorgal",
    "abstract": "The task of extracting and analyzing character networks from works of\nfiction, such as novels and movies, has been the object of a number of recent\npublications. However, only a very few of them focus on graphic novels, and\neven fewer on European graphic novels. In this article, we focus on Thorgal, a\nbande dessin{\\'e}e, i.e. a comic of the French-Belgian tradition. We manually\nannotate all the volumes of this series, in order to constitute a corpus\nallowing us to extract its character network. We perform a descriptive analysis\nof the network structure and compare it to real-world and fictional social\nnetworks. We also study the effect of character filtering over the network\nstructure. Finally, we leverage complex network analysis tools to answer two\nresearch questions from the literature, related to the similarity between\nThorgal and the Saga of Icelanders; and to the position of women in the series.\nOur data and source code are both publicly available online.",
    "descriptor": "",
    "authors": [
      "Vincent Labatut"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2206.10162"
  },
  {
    "id": "arXiv:2206.10164",
    "title": "Efficient scheduling in redundancy systems with general service times",
    "abstract": "We characterize the impact of scheduling policies on the mean response time\nin nested systems with cancel-on-complete redundancy. We consider not only\nredundancy-oblivious policies, such as FCFS and ROS, but also redundancy-aware\npolicies of the form $\\Pi_1-\\Pi_2$, where $\\Pi_1$ discriminates among job\nclasses (e.g., least-redundant-first (LRF), most-redundant-first (MRF)) and\n$\\Pi_2$ discriminates among jobs of the same class. Assuming that jobs have\nindependent and identically distributed (i.i.d.) copies, we prove the\nfollowing: (i) When jobs have exponential service times, LRF policies\noutperform any other policy. (ii) When service times are New-Worse-than-Used,\nMRF-FCFS outperforms LRF-FCFS as the variability of the service time grows\ninfinitely large. (iii) When service times are New-Better-than-Used, LRF-ROS\n(resp. MRF-ROS) outperforms LRF-FCFS (resp. MRF-FCFS) in a two-server system.\nStatement (iii) also holds when job sizes follow a general distribution and\nhave identical copies (all the copies of a job have the same size). Moreover,\nwe show via simulation that, for a large class of redundancy systems,\nredundancy-aware policies can considerably improve the mean response time\ncompared to redundancy-oblivious policies. We also explore the effect of\nredundancy on the stability region.",
    "descriptor": "",
    "authors": [
      "Elene Anton",
      "Rhonda Righter",
      "Ina Maria Verloop"
    ],
    "subjectives": [
      "Performance (cs.PF)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2206.10164"
  },
  {
    "id": "arXiv:2206.10175",
    "title": "A Multi-grained based Attention Network for Semi-supervised Sound Event  Detection",
    "abstract": "Sound event detection (SED) is an interesting but challenging task due to the\nscarcity of data and diverse sound events in real life. This paper presents a\nmulti-grained based attention network (MGA-Net) for semi-supervised sound event\ndetection. To obtain the feature representations related to sound events, a\nresidual hybrid convolution (RH-Conv) block is designed to boost the vanilla\nconvolution's ability to extract the time-frequency features. Moreover, a\nmulti-grained attention (MGA) module is designed to learn temporal resolution\nfeatures from coarse-level to fine-level. With the MGA module,the network could\ncapture the characteristics of target events with short- or long-duration,\nresulting in more accurately determining the onset and offset of sound events.\nFurthermore, to effectively boost the performance of the Mean Teacher (MT)\nmethod, a spatial shift (SS) module as a data perturbation mechanism is\nintroduced to increase the diversity of data. Experimental results show that\nthe MGA-Net outperforms the published state-of-the-art competitors, achieving\n53.27% and 56.96% event-based macro F1 (EB-F1) score, 0.709 and 0.739\npolyphonic sound detection score (PSDS) on the validation and public set\nrespectively.",
    "descriptor": "",
    "authors": [
      "Ying Hu",
      "Xiujuan Zhu",
      "Yunlong Li",
      "Hao Huang",
      "Liang He"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.10175"
  },
  {
    "id": "arXiv:2206.10177",
    "title": "TCJA-SNN: Temporal-Channel Joint Attention for Spiking Neural Networks",
    "abstract": "Spiking Neural Networks (SNNs) is a practical approach toward more\ndata-efficient deep learning by simulating neurons leverage on temporal\ninformation. In this paper, we propose the Temporal-Channel Joint Attention\n(TCJA) architectural unit, an efficient SNN technique that depends on attention\nmechanisms, by effectively enforcing the relevance of spike sequence along both\nspatial and temporal dimensions. Our essential technical contribution lies on:\n1) compressing the spike stream into an average matrix by employing the squeeze\noperation, then using two local attention mechanisms with an efficient 1-D\nconvolution to establish temporal-wise and channel-wise relations for feature\nextraction in a flexible fashion. 2) utilizing the Cross Convolutional Fusion\n(CCF) layer for modeling inter-dependencies between temporal and channel scope,\nwhich breaks the independence of the two dimensions and realizes the\ninteraction between features. By virtue of jointly exploring and recalibrating\ndata stream, our method outperforms the state-of-the-art (SOTA) by up to 15.7%\nin terms of top-1 classification accuracy on all tested mainstream static and\nneuromorphic datasets, including Fashion-MNIST, CIFAR10-DVS, N-Caltech 101, and\nDVS128 Gesture.",
    "descriptor": "",
    "authors": [
      "Rui-Jie Zhu",
      "Qihang Zhao",
      "Tianjing Zhang",
      "Haoyu Deng",
      "Yule Duan",
      "Malu Zhang",
      "Liang-Jian Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.10177"
  },
  {
    "id": "arXiv:2206.10185",
    "title": "Federated Reinforcement Learning: Linear Speedup Under Markovian  Sampling",
    "abstract": "Since reinforcement learning algorithms are notoriously data-intensive, the\ntask of sampling observations from the environment is usually split across\nmultiple agents. However, transferring these observations from the agents to a\ncentral location can be prohibitively expensive in terms of the communication\ncost, and it can also compromise the privacy of each agent's local behavior\npolicy. In this paper, we consider a federated reinforcement learning framework\nwhere multiple agents collaboratively learn a global model, without sharing\ntheir individual data and policies. Each agent maintains a local copy of the\nmodel and updates it using locally sampled data. Although having N agents\nenables the sampling of N times more data, it is not clear if it leads to\nproportional convergence speedup. We propose federated versions of on-policy\nTD, off-policy TD and Q-learning, and analyze their convergence. For all these\nalgorithms, to the best of our knowledge, we are the first to consider\nMarkovian noise and multiple local updates, and prove a linear convergence\nspeedup with respect to the number of agents. To obtain these results, we show\nthat federated TD and Q-learning are special cases of a general framework for\nfederated stochastic approximation with Markovian noise, and we leverage this\nframework to provide a unified convergence analysis that applies to all the\nalgorithms.",
    "descriptor": "\nComments: 69 pages, 1 figure, accepted to ICML 2022 for long presentation\n",
    "authors": [
      "Sajad Khodadadian",
      "Pranay Sharma",
      "Gauri Joshi",
      "Siva Theja Maguluri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10185"
  },
  {
    "id": "arXiv:2206.10186",
    "title": "Improving Localization for Semi-Supervised Object Detection",
    "abstract": "Nowadays, Semi-Supervised Object Detection (SSOD) is a hot topic, since,\nwhile it is rather easy to collect images for creating a new dataset, labeling\nthem is still an expensive and time-consuming task. One of the successful\nmethods to take advantage of raw images on a Semi-Supervised Learning (SSL)\nsetting is the Mean Teacher technique, where the operations of pseudo-labeling\nby the Teacher and the Knowledge Transfer from the Student to the Teacher take\nplace simultaneously. However, the pseudo-labeling by thresholding is not the\nbest solution since the confidence value is not strictly related to the\nprediction uncertainty, not permitting to safely filter predictions. In this\npaper, we introduce an additional classification task for bounding box\nlocalization to improve the filtering of the predicted bounding boxes and\nobtain higher quality on Student training. Furthermore, we empirically prove\nthat bounding box regression on the unsupervised part can equally contribute to\nthe training as much as category classification. Our experiments show that our\nIL-net (Improving Localization net) increases SSOD performance by 1.14% AP on\nCOCO dataset in limited-annotation regime. The code is available at\nhttps://github.com/IMPLabUniPr/unbiased-teacher/tree/ilnet",
    "descriptor": "",
    "authors": [
      "Leonardo Rossi",
      "Akbar Karimi",
      "Andrea Prati"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10186"
  },
  {
    "id": "arXiv:2206.10188",
    "title": "Analysis of Self-Supervised Learning and Dimensionality Reduction  Methods in Clustering-Based Active Learning for Speech Emotion Recognition",
    "abstract": "When domain experts are needed to perform data annotation for complex\nmachine-learning tasks, reducing annotation effort is crucial in order to cut\ndown time and expenses. For cases when there are no annotations available, one\napproach is to utilize the structure of the feature space for clustering-based\nactive learning (AL) methods. However, these methods are heavily dependent on\nhow the samples are organized in the feature space and what distance metric is\nused. Unsupervised methods such as contrastive predictive coding (CPC) can\npotentially be used to learn organized feature spaces, but these methods\ntypically create high-dimensional features which might be challenging for\nestimating data density. In this paper, we combine CPC and multiple\ndimensionality reduction methods in search of functioning practices for\nclustering-based AL. Our experiments for simulating speech emotion recognition\nsystem deployment show that both the local and global topology of the feature\nspace can be successfully used for AL, and that CPC can be used to improve\nclustering-based AL performance over traditional signal features. Additionally,\nwe observe that compressing data dimensionality does not harm AL performance\nsubstantially, and that 2-D feature representations achieved similar AL\nperformance as higher-dimensional representations when the number of\nannotations is not very low.",
    "descriptor": "\nComments: To be published in Proc. Interspeech 2022, Incheon, South Korea\n",
    "authors": [
      "Einari Vaaras",
      "Manu Airaksinen",
      "Okko R\u00e4s\u00e4nen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.10188"
  },
  {
    "id": "arXiv:2206.10189",
    "title": "A General Theory for Federated Optimization with Asynchronous and  Heterogeneous Clients Updates",
    "abstract": "We propose a novel framework to study asynchronous federated learning\noptimization with delays in gradient updates. Our theoretical framework extends\nthe standard FedAvg aggregation scheme by introducing stochastic aggregation\nweights to represent the variability of the clients update time, due for\nexample to heterogeneous hardware capabilities. Our formalism applies to the\ngeneral federated setting where clients have heterogeneous datasets and perform\nat least one step of stochastic gradient descent (SGD). We demonstrate\nconvergence for such a scheme and provide sufficient conditions for the related\nminimum to be the optimum of the federated problem. We show that our general\nframework applies to existing optimization schemes including centralized\nlearning, FedAvg, asynchronous FedAvg, and FedBuff. The theory here provided\nallows drawing meaningful guidelines for designing a federated learning\nexperiment in heterogeneous conditions. In particular, we develop in this work\nFedFix, a novel extension of FedAvg enabling efficient asynchronous federated\ntraining while preserving the convergence stability of synchronous aggregation.\nWe empirically demonstrate our theory on a series of experiments showing that\nasynchronous FedAvg leads to fast convergence at the expense of stability, and\nwe finally demonstrate the improvements of FedFix over synchronous and\nasynchronous FedAvg.",
    "descriptor": "",
    "authors": [
      "Yann Fraboni",
      "Richard Vidal",
      "Laetitia Kameni",
      "Marco Lorenzi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10189"
  },
  {
    "id": "arXiv:2206.10192",
    "title": "LDD: A Dataset for Grape Diseases Object Detection and Instance  Segmentation",
    "abstract": "The Instance Segmentation task, an extension of the well-known Object\nDetection task, is of great help in many areas, such as precision agriculture:\nbeing able to automatically identify plant organs and the possible diseases\nassociated with them, allows to effectively scale and automate crop monitoring\nand its diseases control. To address the problem related to early disease\ndetection and diagnosis on vines plants, a new dataset has been created with\nthe goal of advancing the state-of-the-art of diseases recognition via instance\nsegmentation approaches. This was achieved by gathering images of leaves and\nclusters of grapes affected by diseases in their natural context. The dataset\ncontains photos of 10 object types which include leaves and grapes with and\nwithout symptoms of the eight more common grape diseases, with a total of\n17,706 labeled instances in 1,092 images. Multiple statistical measures are\nproposed in order to offer a complete view on the characteristics of the\ndataset. Preliminary results for the object detection and instance segmentation\ntasks reached by the models Mask R-CNN and R^3-CNN are provided as baseline,\ndemonstrating that the procedure is able to reach promising results about the\nobjective of automatic diseases' symptoms recognition.",
    "descriptor": "",
    "authors": [
      "Leonardo Rossi",
      "Marco Valenti",
      "Sara Elisabetta Legler",
      "Andrea Prati"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10192"
  },
  {
    "id": "arXiv:2206.10200",
    "title": "Enabling Capsule Networks at the Edge through Approximate Softmax and  Squash Operations",
    "abstract": "Complex Deep Neural Networks such as Capsule Networks (CapsNets) exhibit high\nlearning capabilities at the cost of compute-intensive operations. To enable\ntheir deployment on edge devices, we propose to leverage approximate computing\nfor designing approximate variants of the complex operations like softmax and\nsquash. In our experiments, we evaluate tradeoffs between area, power\nconsumption, and critical path delay of the designs implemented with the ASIC\ndesign flow, and the accuracy of the quantized CapsNets, compared to the exact\nfunctions.",
    "descriptor": "\nComments: To appear at the ACM/IEEE International Symposium on Low Power Electronics and Design (ISLPED), August 2022, Boston, MA, USA\n",
    "authors": [
      "Alberto Marchisio",
      "Beatrice Bussolino",
      "Edoardo Salvati",
      "Maurizio Martina",
      "Guido Masera",
      "Muhammad Shafique"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10200"
  },
  {
    "id": "arXiv:2206.10206",
    "title": "Personalized Subgraph Federated Learning",
    "abstract": "In real-world scenarios, subgraphs of a larger global graph may be\ndistributed across multiple devices or institutions, and only locally\naccessible due to privacy restrictions, although there may be links between\nthem. Recently proposed subgraph Federated Learning (FL) methods deal with\nthose missing links across private local subgraphs while distributively\ntraining Graph Neural Networks (GNNs) on them. However, they have overlooked\nthe inevitable heterogeneity among subgraphs, caused by subgraphs comprising\ndifferent parts of a global graph. For example, a subgraph may belong to one of\nthe communities within the larger global graph. A naive subgraph FL in such a\ncase will collapse incompatible knowledge from local GNN models trained on\nheterogeneous graph distributions. To overcome such a limitation, we introduce\na new subgraph FL problem, personalized subgraph FL, which focuses on the joint\nimprovement of the interrelated local GNN models rather than learning a single\nglobal GNN model, and propose a novel framework, FEDerated Personalized\nsUBgraph learning (FED-PUB), to tackle it. A crucial challenge in personalized\nsubgraph FL is that the server does not know which subgraph each client has.\nFED-PUB thus utilizes functional embeddings of the local GNNs using random\ngraphs as inputs to compute similarities between them, and use them to perform\nweighted averaging for server-side aggregation. Further, it learns a\npersonalized sparse mask at each client to select and update only the\nsubgraph-relevant subset of the aggregated parameters. We validate FED-PUB for\nits subgraph FL performance on six datasets, considering both non-overlapping\nand overlapping subgraphs, on which ours largely outperforms relevant\nbaselines.",
    "descriptor": "",
    "authors": [
      "Jinheon Baek",
      "Wonyong Jeong",
      "Jiongdao Jin",
      "Jaehong Yoon",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10206"
  },
  {
    "id": "arXiv:2206.10207",
    "title": "SemMAE: Semantic-Guided Masking for Learning Masked Autoencoders",
    "abstract": "Recently, significant progress has been made in masked image modeling to\ncatch up to masked language modeling. However, unlike words in NLP, the lack of\nsemantic decomposition of images still makes masked autoencoding (MAE)\ndifferent between vision and language. In this paper, we explore a potential\nvisual analogue of words, i.e., semantic parts, and we integrate semantic\ninformation into the training process of MAE by proposing a Semantic-Guided\nMasking strategy. Compared to widely adopted random masking, our masking\nstrategy can gradually guide the network to learn various information, i.e.,\nfrom intra-part patterns to inter-part relations. In particular, we achieve\nthis in two steps. 1) Semantic part learning: we design a self-supervised part\nlearning method to obtain semantic parts by leveraging and refining the\nmulti-head attention of a ViT-based encoder. 2) Semantic-guided MAE (SemMAE)\ntraining: we design a masking strategy that varies from masking a portion of\npatches in each part to masking a portion of (whole) parts in an image.\nExtensive experiments on various vision tasks show that SemMAE can learn better\nimage representation by integrating semantic information. In particular, SemMAE\nachieves 84.5% fine-tuning accuracy on ImageNet-1k, which outperforms the\nvanilla MAE by 1.4%. In the semantic segmentation and fine-grained recognition\ntasks, SemMAE also brings significant improvements and yields the\nstate-of-the-art performance.",
    "descriptor": "\nComments: 12 pages, 3 figures\n",
    "authors": [
      "Gang Li",
      "Heliang Zheng",
      "Daqing Liu",
      "Bing Su",
      "Changwen Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10207"
  },
  {
    "id": "arXiv:2206.10210",
    "title": "The Integration of Machine Learning into Automated Test Generation: A  Systematic Literature Review",
    "abstract": "Background: Machine learning (ML) may enable effective automated test\ngeneration.\nAims: We characterize emerging research, examining testing practices,\nresearcher goals, ML techniques applied, evaluation, and challenges.\nMethod: We perform a systematic literature review on a sample of 97\npublications.\nResults: ML generates input for system, GUI, unit, performance, and\ncombinatorial testing or improves the performance of existing generation\nmethods. ML is also used to generate test verdicts, property-based, and\nexpected output oracles. Supervised learning - often based on neural networks -\nand reinforcement learning - often based on Q-learning - are common, and some\npublications also employ unsupervised or semi-supervised learning.\n(Semi-/Un-)Supervised approaches are evaluated using both traditional testing\nmetrics and ML-related metrics (e.g., accuracy), while reinforcement learning\nis often evaluated using testing metrics tied to the reward function.\nConclusions: Work-to-date shows great promise, but there are open challenges\nregarding training data, retraining, scalability, evaluation complexity, ML\nalgorithms employed - and how they are applied - benchmarks, and replicability.\nOur findings can serve as a roadmap and inspiration for researchers in this\nfield.",
    "descriptor": "\nComments: Under submission to Information Software Technology journal. arXiv admin note: text overlap with arXiv:2107.00906\n",
    "authors": [
      "Afonso Fontes",
      "Gregory Gay"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10210"
  },
  {
    "id": "arXiv:2206.10211",
    "title": "FEAT: Fair Coordinated Iterative Water-Filling Algorithm",
    "abstract": "In this paper, we consider a perfect coordinated water-filling game, where\neach user transmits solely on a given carrier. The main goal of the proposed\nalgorithm (which we call FEAT) is to get close to the optimal, while keeping a\ndecent level of fairness. The key idea within FEAT is to minimize the ratio\nbetween the best and the worst utilities of the users. This is done by ensuring\nthat, at each iteration (channel assignment), a user is satisfied with this\nassignment as long as he does not loose much more than other users in the\nsystem. It has been shown that FEAT outperforms most related algorithms in many\naspects, especially in interference-limited systems. Indeed, with FEAT we can\nensure a near-optimal, fair and energy efficient solution with low\ncomputational complexity. In terms of robustness, it turns out that the balance\nbetween being nearly globally optimal and good from individual point of view\nseems hard to sustain with a significant number of users. Also notice that, in\nthis regard, global optimality gets less affected than the individual one,\nwhich offers hope that such an accurate water-filling algorithm can be designed\naround competition in interference-limited systems.",
    "descriptor": "\nComments: 27 PAGES, 14 FIGURES\n",
    "authors": [
      "Majed Haddad",
      "Piotr Wiecek",
      "Oussama Habachi",
      "Samir M. Perlaza",
      "Shahid M. Sha"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2206.10211"
  },
  {
    "id": "arXiv:2206.10212",
    "title": "A Context Model for Personal Data Streams",
    "abstract": "We propose a model of the situational context of a person and show how it can\nbe used to organize and, consequently, reason about massive streams of sensor\ndata and annotations, as they can be collected from mobile devices, e.g.\nsmartphones, smartwatches or fitness trackers. The proposed model is validated\non a very large dataset about the everyday life of one hundred and fifty-eight\npeople over four weeks, twenty-four hours a day.",
    "descriptor": "\nComments: 8 pages, 3 figures, APWeb WAIM Conference\n",
    "authors": [
      "Fausto Giunchiglia",
      "Xiaoyue Li",
      "Matteo Busso",
      "Marcelo Rodas-Britez"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.10212"
  },
  {
    "id": "arXiv:2206.10213",
    "title": "Rethinking Unsupervised Neural Superpixel Segmentation",
    "abstract": "Recently, the concept of unsupervised learning for superpixel segmentation\nvia CNNs has been studied. Essentially, such methods generate superpixels by\nconvolutional neural network (CNN) employed on a single image, and such CNNs\nare trained without any labels or further information. Thus, such approach\nrelies on the incorporation of priors, typically by designing an objective\nfunction that guides the solution towards a meaningful superpixel segmentation.\nIn this paper we propose three key elements to improve the efficacy of such\nnetworks: (i) the similarity of the \\emph{soft} superpixelated image compared\nto the input image, (ii) the enhancement and consideration of object edges and\nboundaries and (iii) a modified architecture based on atrous convolution, which\nallow for a wider field of view, functioning as a multi-scale component in our\nnetwork. By experimenting with the BSDS500 dataset, we find evidence to the\nsignificance of our proposal, both qualitatively and quantitatively.",
    "descriptor": "\nComments: ICIP 2022\n",
    "authors": [
      "Moshe Eliasof",
      "Nir Ben Zikri",
      "Eran Treister"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10213"
  },
  {
    "id": "arXiv:2206.10216",
    "title": "A Hierarchical HAZOP-Like Safety Analysis for Learning-Enabled Systems",
    "abstract": "Hazard and Operability Analysis (HAZOP) is a powerful safety analysis\ntechnique with a long history in industrial process control domain. With the\nincreasing use of Machine Learning (ML) components in cyber physical\nsystems--so called Learning-Enabled Systems (LESs), there is a recent trend of\napplying HAZOP-like analysis to LESs. While it shows a great potential to\nreserve the capability of doing sufficient and systematic safety analysis,\nthere are new technical challenges raised by the novel characteristics of ML\nthat require retrofit of the conventional HAZOP technique. In this regard, we\npresent a new Hierarchical HAZOP-Like method for LESs (HILLS). To deal with the\ncomplexity of LESs, HILLS first does \"divide and conquer\" by stratifying the\nwhole system into three levels, and then proceeds HAZOP on each level to\nidentify (latent-)hazards, causes, security threats and mitigation (with new\nnodes and guide words). Finally, HILLS attempts at linking and propagating the\ncausal relationship among those identified elements within and across the three\nlevels via both qualitative and quantitative methods. We examine and illustrate\nthe utility of HILLS by a case study on Autonomous Underwater Vehicles, with\ndiscussions on assumptions and extensions to real-world applications. HILLS, as\na first HAZOP-like attempt on LESs that explicitly considers ML internal\nbehaviours and its interactions with other components, not only uncovers the\ninherent difficulties of doing safety analysis for LESs, but also demonstrates\na good potential to tackle them.",
    "descriptor": "\nComments: Accepted by the AISafety2022 Workshop at IJCAI2022. To appear in a volume of CEUR Workshop Proceedings\n",
    "authors": [
      "Yi Qi",
      "Philippa Ryan Conmy",
      "Wei Huang",
      "Xingyu Zhao",
      "Xiaowei Huang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.10216"
  },
  {
    "id": "arXiv:2206.10218",
    "title": "WikiDoMiner: Wikipedia Domain-specific Miner",
    "abstract": "We introduce WikiDoMiner, a tool for automatically generating domain-specific\ncorpora by crawling Wikipedia. WikiDoMiner helps requirements engineers create\nan external knowledge resource that is specific to the underlying domain of a\ngiven requirements specification (RS). Being able to build such a resource is\nimportant since domain-specific datasets are scarce. WikiDoMiner generates a\ncorpus by first extracting a set of domain-specific keywords from a given RS,\nand then querying Wikipedia for these keywords. The output of WikiDoMiner is a\nset of Wikipedia articles relevant to the domain of the input RS. Mining\nWikipedia for domain-specific knowledge can be beneficial for multiple\nrequirements engineering tasks, e.g., ambiguity handling, requirements\nclassification, and question answering. WikiDoMiner is publicly available on\nZenodo under an open-source license (DOI: 10.5281/zenodo.6671357).",
    "descriptor": "",
    "authors": [
      "Saad Ezzini",
      "Sallam Abualhaija",
      "Mehrdad Sabetzadeh"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.10218"
  },
  {
    "id": "arXiv:2206.10220",
    "title": "Linear multistep methods and global Richardson extrapolation",
    "abstract": "In this work, we study the application the classical Richardson extrapolation\n(RE) technique to accelerate the convergence of sequences resulting from linear\nmultistep methods (LMMs) for solving initial-value problems of systems of\nordinary differential equations numerically. The advantage of the LMM-RE\napproach is that the combined method possesses higher order and favorable\nlinear stability properties in terms of $A$- or $A(\\alpha)$-stability, and\nexisting LMM codes can be used without any modification.",
    "descriptor": "",
    "authors": [
      "Imre Fekete",
      "Lajos L\u00f3czi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.10220"
  },
  {
    "id": "arXiv:2206.10225",
    "title": "Broken News: Making Newspapers Accessible to Print-Impaired",
    "abstract": "Accessing daily news content still remains a big challenge for people with\nprint-impairment including blind and low-vision due to opacity of printed\ncontent and hindrance from online sources. In this paper, we present our\napproach for digitization of print newspaper into an accessible file format\nsuch as HTML. We use an ensemble of instance segmentation and detection\nframework for newspaper layout analysis and then OCR to recognize text elements\nsuch as headline and article text. Additionally, we propose EdgeMask loss\nfunction for Mask-RCNN framework to improve segmentation mask boundary and\nhence accuracy of downstream OCR task. Empirically, we show that our proposed\nloss function reduces the Word Error Rate (WER) of news article text by 32.5 %.",
    "descriptor": "\nComments: Published at Accessibility, Vision, and Autonomy Meet, CVPR 2022 Workshop\n",
    "authors": [
      "Vishal Agarwal",
      "Tanuja Ganu",
      "Saikat Guha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.10225"
  },
  {
    "id": "arXiv:2206.10226",
    "title": "Fluctuation-driven initialization for spiking neural network training",
    "abstract": "Spiking neural networks (SNNs) underlie low-power, fault-tolerant information\nprocessing in the brain and could constitute a power-efficient alternative to\nconventional deep neural networks when implemented on suitable neuromorphic\nhardware accelerators. However, instantiating SNNs that solve complex\ncomputational tasks in-silico remains a significant challenge. Surrogate\ngradient (SG) techniques have emerged as a standard solution for training SNNs\nend-to-end. Still, their success depends on synaptic weight initialization,\nsimilar to conventional artificial neural networks (ANNs). Yet, unlike in the\ncase of ANNs, it remains elusive what constitutes a good initial state for an\nSNN. Here, we develop a general initialization strategy for SNNs inspired by\nthe fluctuation-driven regime commonly observed in the brain. Specifically, we\nderive practical solutions for data-dependent weight initialization that ensure\nfluctuation-driven firing in the widely used leaky integrate-and-fire (LIF)\nneurons. We empirically show that SNNs initialized following our strategy\nexhibit superior learning performance when trained with SGs. These findings\ngeneralize across several datasets and SNN architectures, including fully\nconnected, deep convolutional, recurrent, and more biologically plausible SNNs\nobeying Dale's law. Thus fluctuation-driven initialization provides a\npractical, versatile, and easy-to-implement strategy for improving SNN training\nperformance on diverse tasks in neuromorphic engineering and computational\nneuroscience.",
    "descriptor": "\nComments: 30 pages, 7 figures, plus supplementary material\n",
    "authors": [
      "Julian Rossbroich",
      "Julia Gygax",
      "Friedemann Zenke"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2206.10226"
  },
  {
    "id": "arXiv:2206.10227",
    "title": "TAPHSIR: Towards AnaPHoric Ambiguity Detection and ReSolution In  Requirements",
    "abstract": "We introduce TAPHSIR, a tool for anaphoric ambiguity detection and anaphora\nresolution in requirements. TAPHSIR facilities reviewing the use of pronouns in\na requirements specification and revising those pronouns that can lead to\nmisunderstandings during the development process. To this end, TAPHSIR detects\nthe requirements which have potential anaphoric ambiguity and further attempts\ninterpreting anaphora occurrences automatically. TAPHSIR employs a hybrid\nsolution composed of an ambiguity detection solution based on machine learning\nand an anaphora resolution solution based on a variant of the BERT language\nmodel. Given a requirements specification, TAPHSIR decides for each pronoun\noccurrence in the specification whether the pronoun is ambiguous or\nunambiguous, and further provides an automatic interpretation for the pronoun.\nThe output generated by TAPHSIR can be easily reviewed and validated by\nrequirements engineers. TAPHSIR is publicly available on Zenodo (DOI:\n10.5281/zenodo.5902117).",
    "descriptor": "",
    "authors": [
      "Saad Ezzini",
      "Sallam Abualhaija",
      "Chetan Arora",
      "Mehrdad Sabetzadeh"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.10227"
  },
  {
    "id": "arXiv:2206.10228",
    "title": "Effective Reductions of Mealy Machines",
    "abstract": "We revisit the problem of reducing incompletely specified Mealy machines with\nreactive synthesis in mind. We propose two techniques: the former is inspired\nby the tool MeMin and solves the minimization problem, the latter is a novel\napproach derived from simulationbased reductions but may not guarantee a\nminimized machine. However, we argue that it offers a good enough compromise\nbetween the size of the resulting Mealy machine and performance. The proposed\nmethods are benchmarked against MeMin on a large collection of test cases made\nof well-known instances as well as new ones.",
    "descriptor": "",
    "authors": [
      "Florian Renkin",
      "Philipp Schlehuber-Caissier",
      "Alexandre Duret-Lutz",
      "Adrien Pommellet"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2206.10228"
  },
  {
    "id": "arXiv:2206.10233",
    "title": "COREQQA -- A COmpliance REQuirements Understanding using Question  Answering Tool",
    "abstract": "We introduce COREQQA, a tool for assisting requirements engineers in\nacquiring a better understanding of compliance requirements by means of\nautomated Question Answering. Extracting compliance-related requirements by\nmanually navigating through a legal document is both time-consuming and\nerror-prone. COREQQA enables requirements engineers to pose questions in\nnatural language about a compliance-related topic given some legal document,\ne.g., asking about data breach. The tool then automatically navigates through\nthe legal document and returns to the requirements engineer a list of text\npassages containing the possible answers to the input question. For better\nreadability, the tool also highlights the likely answers in these passages. The\nengineer can then use this output for specifying compliance requirements.\nCOREQQA is developed using advanced large-scale language models from BERT's\nfamily. COREQQA has been evaluated on four legal documents. The results of this\nevaluation are briefly presented in the paper. The tool is publicly available\non Zenodo (DOI: 10.5281/zenodo.6653514).",
    "descriptor": "",
    "authors": [
      "Sallam Abualhaija",
      "Chetan Arora",
      "Lionel Briand"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.10233"
  },
  {
    "id": "arXiv:2206.10234",
    "title": "The Many-Worlds Calculus: Representing Quantum Control",
    "abstract": "We propose a new typed graphical language for quantum computation, based on\ncompact categories with biproducts. Our language generalizes existing\napproaches such as ZX-calculus and quantum circuits, while offering a natural\nframework to support quantum control: it natively supports \"quantum tests\". The\nlanguage comes equipped with a denotational semantics based on linear\napplications, and an equational theory. Through the use of normal forms for the\ndiagrams, we prove the language to be universal, and the equational theory to\nbe complete with respect to the semantics.",
    "descriptor": "",
    "authors": [
      "Kostia Chardonnet",
      "Marc de Visme",
      "Beno\u00eet Valiron",
      "Renaud Vilmart"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.10234"
  },
  {
    "id": "arXiv:2206.10235",
    "title": "Riemannian data-dependent randomized smoothing for neural networks  certification",
    "abstract": "Certification of neural networks is an important and challenging problem that\nhas been attracting the attention of the machine learning community since few\nyears. In this paper, we focus on randomized smoothing (RS) which is considered\nas the state-of-the-art method to obtain certifiably robust neural networks. In\nparticular, a new data-dependent RS technique called ANCER introduced recently\ncan be used to certify ellipses with orthogonal axis near each input data of\nthe neural network. In this work, we remark that ANCER is not invariant under\nrotation of input data and propose a new rotationally-invariant formulation of\nit which can certify ellipses without constraints on their axis. Our approach\ncalled Riemannian Data Dependant Randomized Smoothing (RDDRS) relies on\ninformation geometry techniques on the manifold of covariance matrices and can\ncertify bigger regions than ANCER based on our experiments on the MNIST\ndataset.",
    "descriptor": "\nComments: Accepted at ICLM 2022 Workshop \"AdvML Frontiers\"\n",
    "authors": [
      "Pol Labarbarie",
      "Hatem Hajri",
      "Marc Arnaudon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10235"
  },
  {
    "id": "arXiv:2206.10241",
    "title": "Deep Active Latent Surfaces for Medical Geometries",
    "abstract": "Shape priors have long been known to be effective when reconstructing 3D\nshapes from noisy or incomplete data. When using a deep-learning based shape\nrepresentation, this often involves learning a latent representation, which can\nbe either in the form of a single global vector or of multiple local ones. The\nlatter allows more flexibility but is prone to overfitting. In this paper, we\nadvocate a hybrid approach representing shapes in terms of 3D meshes with a\nseparate latent vector at each vertex. During training the latent vectors are\nconstrained to have the same value, which avoids overfitting. For inference,\nthe latent vectors are updated independently while imposing spatial\nregularization constraints. We show that this gives us both flexibility and\ngeneralization capabilities, which we demonstrate on several medical image\nprocessing tasks.",
    "descriptor": "\nComments: 14 pages, 9 figures, submitted for review\n",
    "authors": [
      "Patrick M. Jensen",
      "Udaranga Wickramasinghe",
      "Anders B. Dahl",
      "Pascal Fua",
      "Vedrana A. Dahl"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10241"
  },
  {
    "id": "arXiv:2206.10244",
    "title": "Experimental Evaluation of Pose Initialization Methods for Relative  Navigation Between Non-Cooperative Satellites",
    "abstract": "In this work, we have analyzed the problem of relative pose initialization\nbetween two satellites: a chaser and a non-cooperating target. The analysis has\nbeen targeted to two close-range methods based on a monocular camera system:\nthe Sharma-Ventura-D'Amico (SVD) method and the silhouette matching method.\nBoth methods are based on a priori knowledge of the target geometry, but\nneither fiducial markers nor a priori range measurements or state information\nare needed. The tests were carried out using a 2U CubeSat mock-up as target\nattached to a motorized rotary stage to simulate its relative motion with\nrespect to the chaser camera. A motion capture system was used as a reference\ninstrument that provides the fiducial relative motion between the two mock-ups\nand allows to evaluate the performances of the initialization algorithms\nanalyzed.",
    "descriptor": "\nComments: To be presented at the 2022 IEEE INTERNATIONAL WORKSHOP ON Metrology for AeroSpace\n",
    "authors": [
      "Sebastiano Chiodini",
      "Marco Pertile",
      "Pierdomenico Fracchiolla",
      "Andrea Valmorbida",
      "Enrico Lorenzini",
      "Stefano Debei"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10244"
  },
  {
    "id": "arXiv:2206.10245",
    "title": "Digital twin of a MWh-scale grid battery system for efficiency and  degradation analysis",
    "abstract": "Large-scale grid-connected lithium-ion batteries are increasingly being\ndeployed to support renewable energy roll-out on the power grid. These battery\nsystems consist of thousands of individual cells and various ancillary systems\nfor monitoring and control. Although many studies have focused on the behaviour\nof single lithium-ion cells, the impact of system design choices and ancillary\nsystem controls on long-term degradation and efficiency of system, containing\nthousands of cells, has rarely been considered in detail. Here, we simulate a 1\nMWh grid battery system consisting of 18900 individual cells, each represented\nby a separate electrochemical model, as well as the thermal management system\nand power electronic converters. Simulations of the impact of cell-to-cell\nvariability, thermal effects, and degradation effects were run for up to 10000\ncycles and 10 years. It is shown that electrical contact resistances and\ncell-to-cell variations in initial capacity and resistance have a smaller\neffect on performance than previously thought. Instead, the variation in\ndegradation rate of individual cells dominates the system behaviour over the\nlifetime. The importance of careful thermal management system control is\ndemonstrated, with proportional control improving overall efficiency by 5 %-pts\nover on-off methods, also increasing the total usable energy of the battery by\n5 %-pts after 10 years.",
    "descriptor": "",
    "authors": [
      "Jorn M. Reniers",
      "David A. Howey"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.10245"
  },
  {
    "id": "arXiv:2206.10249",
    "title": "Incorporating Voice Instructions in Model-Based Reinforcement Learning  for Self-Driving Cars",
    "abstract": "This paper presents a novel approach that supports natural language voice\ninstructions to guide deep reinforcement learning (DRL) algorithms when\ntraining self-driving cars. DRL methods are popular approaches for autonomous\nvehicle (AV) agents. However, most existing methods are sample- and\ntime-inefficient and lack a natural communication channel with the human\nexpert. In this paper, how new human drivers learn from human coaches motivates\nus to study new ways of human-in-the-loop learning and a more natural and\napproachable training interface for the agents. We propose incorporating\nnatural language voice instructions (NLI) in model-based deep reinforcement\nlearning to train self-driving cars. We evaluate the proposed method together\nwith a few state-of-the-art DRL methods in the CARLA simulator. The results\nshow that NLI can help ease the training process and significantly boost the\nagents' learning speed.",
    "descriptor": "\nComments: NeurIPS 2021 Workshop on Machine Learning for Autonomous Driving\n",
    "authors": [
      "Mingze Wang",
      "Ziyang Zhang",
      "Grace Hui Yang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.10249"
  },
  {
    "id": "arXiv:2206.10253",
    "title": "Document Navigability: A Need for Print-Impaired",
    "abstract": "Printed documents continue to be a challenge for blind, low-vision, and other\nprint-disabled (BLV) individuals. In this paper, we focus on the specific\nproblem of (in-)accessibility of internal references to citations, footnotes,\nfigures, tables and equations. While sighted users can flip to the referenced\ncontent and flip back in seconds, linear audio narration that BLV individuals\nrely on makes following these references extremely hard. We propose a vision\nbased technique to locate the referenced content and extract metadata needed to\n(in subsequent work) inline a content summary into the audio narration. We\napply our technique to citations in scientific documents and find it works well\nboth on born-digital as well as scanned documents.",
    "descriptor": "\nComments: Published at Accessibility, Vision, and Autonomy Meet, CVPR 2022 Workshop\n",
    "authors": [
      "Anukriti Kumar",
      "Tanuja Ganu",
      "Saikat Guha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.10253"
  },
  {
    "id": "arXiv:2206.10254",
    "title": "Towards Optimizing OCR for Accessibility",
    "abstract": "Visual cues such as structure, emphasis, and icons play an important role in\nefficient information foraging by sighted individuals and make for a\npleasurable reading experience. Blind, low-vision and other print-disabled\nindividuals miss out on these cues since current OCR and text-to-speech\nsoftware ignore them, resulting in a tedious reading experience. We identify\nfour semantic goals for an enjoyable listening experience, and identify\nsyntactic visual cues that help make progress towards these goals. Empirically,\nwe find that preserving even one or two visual cues in aural form significantly\nenhances the experience for listening to print content.",
    "descriptor": "\nComments: Published at Accessibility, Vision, and Autonomy Meet, CVPR 2022 Workshop\n",
    "authors": [
      "Peya Mowar",
      "Tanuja Ganu",
      "Saikat Guha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.10254"
  },
  {
    "id": "arXiv:2206.10255",
    "title": "GNN-PMB: A Simple but Effective Online 3D Multi-Object Tracker without  Bells and Whistles",
    "abstract": "Multi-object tracking (MOT) is among crucial applications in modern advanced\ndriver assistance systems (ADAS) and autonomous driving (AD) systems. Most\nsolutions to MOT are based on random vector Bayesian filters like global\nnearest neighbor (GNN) plus rule-based heuristical track maintenance. With the\ndevelopment of random finite set (RFS) theory, the RFS Bayesian filters have\nbeen applied in MOT tasks for ADAS and AD systems recently. However, their\nusefulness in the real traffic is open to doubt due to computational cost and\nimplementation complexity. In this paper, it is revealed that GNN with\nrule-based heuristic track maintenance is insufficient for LiDAR-based MOT\ntasks in ADAS and AD systems. This judgement is illustrated by systematically\ncomparing several different multi-point object filter-based tracking\nframeworks, including traditional random vector Bayesian filters with\nrule-based heuristical track maintenance and RFS Bayesian filters. Moreover, a\nsimple and effective tracker, namely Poisson multi-Bernoulli filter using\nglobal nearest neighbor (GNN-PMB) tracker, is proposed for LiDAR-based MOT\ntasks. The proposed GNN-PMB tracker achieves competitive results in nuScenes\ntest dataset, and shows superior tracking performance over other\nstate-of-the-art LiDAR only trackers and LiDAR and camera fusion-based\ntrackers.",
    "descriptor": "",
    "authors": [
      "Jianan Liu",
      "Liping Bai",
      "Yuxuan Xia",
      "Tao Huang",
      "Bing Zhu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10255"
  },
  {
    "id": "arXiv:2206.10256",
    "title": "Human-in-the-loop Speaker Adaptation for DNN-based Multi-speaker TTS",
    "abstract": "This paper proposes a human-in-the-loop speaker-adaptation method for\nmulti-speaker text-to-speech. With a conventional speaker-adaptation method, a\ntarget speaker's embedding vector is extracted from his/her reference speech\nusing a speaker encoder trained on a speaker-discriminative task. However, this\nmethod cannot obtain an embedding vector for the target speaker when the\nreference speech is unavailable. Our method is based on a human-in-the-loop\noptimization framework, which incorporates a user to explore the\nspeaker-embedding space to find the target speaker's embedding. The proposed\nmethod uses a sequential line search algorithm that repeatedly asks a user to\nselect a point on a line segment in the embedding space. To efficiently choose\nthe best speech sample from multiple stimuli, we also developed a system in\nwhich a user can switch between multiple speakers' voices for each phoneme\nwhile looping an utterance. Experimental results indicate that the proposed\nmethod can achieve comparable performance to the conventional one in objective\nand subjective evaluations even if reference speech is not used as the input of\na speaker encoder directly.",
    "descriptor": "\nComments: 5 pages, 3 figures, Accepted for INTERSPEECH2022\n",
    "authors": [
      "Kenta Udagawa",
      "Yuki Saito",
      "Hiroshi Saruwatari"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Human-Computer Interaction (cs.HC)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.10256"
  },
  {
    "id": "arXiv:2206.10257",
    "title": "Satoshi Nakamoto and the Origins of Bitcoin -- Narratio in Nomine, Datis  et Numeris",
    "abstract": "The mystery about the ingenious creator of Bitcoin concealing behind the\npseudonym Satoshi Nakamoto has been fascinating the global public for more than\na decade. Suddenly jumping out of the dark in 2008, this persona hurled the\nhighly disruptive distributed ledger technology \"blockchain\" that has added the\nmissing native value layer to the internet. Purposely agnostic without\nadvocating any old or fielding new names, this paper first identifies the\ndegrees of freedom Satoshi Nakamoto had available in the design of Bitcoin, and\nin fabricating snippets of personal data. By interweaving the substantial\ncollection of previous and new circumstantial with direct evidence, like\nrelevant locations and happenings in history and at the time, a consistent\nskeleton of Satoshi Nakamoto's biography transpires. The results underpin that\nthe iconic creator of Bitcoin most likely encoded bits of information in his\nself-chosen alias, dates and blockchain parameters, which particularly point to\nthe numbers 21 and 42, and the numeral systems used in Bitcoin's framework.\nMoreover, a psychogram of a reclusive and capricious genius is drawn, which\nsheds new light on Satoshi Nakamoto's background, mindset, pastimes, and\npenchant for puns; this study may also explain the motivation of his abrupt\ndeparture from the public, his continuing abstinence from engaging with the\nBitcoin community, and from reaping the fruits of his mindboggling wealth. From\na history of technology perspective, such an altruistic sacrifice for the\nbenefit of his brainchild is entirely unprecedented.",
    "descriptor": "\nComments: Main text:39 pages Number of references: 503 Appendix: 6 pages\n",
    "authors": [
      "Jens Ducr\u00e9e"
    ],
    "subjectives": [
      "General Literature (cs.GL)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.10257"
  },
  {
    "id": "arXiv:2206.10259",
    "title": "R2-AD2: Detecting Anomalies by Analysing the Raw Gradient",
    "abstract": "Neural networks follow a gradient-based learning scheme, adapting their\nmapping parameters by back-propagating the output loss. Samples unlike the ones\nseen during training cause a different gradient distribution. Based on this\nintuition, we design a novel semi-supervised anomaly detection method called\nR2-AD2. By analysing the temporal distribution of the gradient over multiple\ntraining steps, we reliably detect point anomalies in strict semi-supervised\nsettings. Instead of domain dependent features, we input the raw gradient\ncaused by the sample under test to an end-to-end recurrent neural network\narchitecture. R2-AD2 works in a purely data-driven way, thus is readily\napplicable in a variety of important use cases of anomaly detection.",
    "descriptor": "\nComments: Accepted at ECML-PKDD 2022\n",
    "authors": [
      "Jan-Philipp Schulze",
      "Philip Sperl",
      "Ana R\u0103du\u0163oiu",
      "Carla Sagebiel",
      "Konstantin B\u00f6ttinger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.10259"
  },
  {
    "id": "arXiv:2206.10261",
    "title": "Interpretable Deep Causal Learning for Moderation Effects",
    "abstract": "In this extended abstract paper, we address the problem of interpretability\nand targeted regularization in causal machine learning models. In particular,\nwe focus on the problem of estimating individual causal/treatment effects under\nobserved confounders, which can be controlled for and moderate the effect of\nthe treatment on the outcome of interest. Black-box ML models adjusted for the\ncausal setting perform generally well in this task, but they lack interpretable\noutput identifying the main drivers of treatment heterogeneity and their\nfunctional relationship. We propose a novel deep counterfactual learning\narchitecture for estimating individual treatment effects that can\nsimultaneously: i) convey targeted regularization on, and produce quantify\nuncertainty around the quantity of interest (i.e., the Conditional Average\nTreatment Effect); ii) disentangle baseline prognostic and moderating effects\nof the covariates and output interpretable score functions describing their\nrelationship with the outcome. Finally, we demonstrate the use of the method\nvia a simple simulated experiment.",
    "descriptor": "",
    "authors": [
      "Alberto Caron",
      "Gianluca Baio",
      "Ioanna Manolopoulou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.10261"
  },
  {
    "id": "arXiv:2206.10263",
    "title": "Object Structural Points Representation for Graph-based Semantic  Monocular Localization and Mapping",
    "abstract": "Efficient object level representation for monocular semantic simultaneous\nlocalization and mapping (SLAM) still lacks a widely accepted solution. In this\npaper, we propose the use of an efficient representation, based on structural\npoints, for the geometry of objects to be used as landmarks in a monocular\nsemantic SLAM system based on the pose-graph formulation. In particular, an\ninverse depth parametrization is proposed for the landmark nodes in the\npose-graph to store object position, orientation and size/scale. The proposed\nformulation is general and it can be applied to different geometries; in this\npaper we focus on indoor environments where human-made artifacts commonly share\na planar rectangular shape, e.g., windows, doors, cabinets, etc. The approach\ncan be easily extended to urban scenarios where similar shapes exists as well.\nExperiments in simulation show good performance, particularly in object\ngeometry reconstruction.",
    "descriptor": "\nComments: submitted to IROS 2015 (rejected)\n",
    "authors": [
      "Davide Tateo",
      "Davide Antonio Cucci",
      "Matteo Matteucci",
      "Andrea Bonarini"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10263"
  },
  {
    "id": "arXiv:2206.10265",
    "title": "KnowDA: All-in-One Knowledge Mixture Model for Data Augmentation in  Few-Shot NLP",
    "abstract": "This paper focuses on text data augmentation for few-shot NLP tasks. The\nexisting data augmentation algorithms either leverage task-independent\nheuristic rules (e.g., Synonym Replacement) or fine-tune general-purpose\npre-trained language models (e.g., GPT2) using a small training set to produce\nnew synthetic data. Consequently, these methods have trivial task-specific\nknowledge and are limited to yielding low-quality synthetic data for weak\nbaselines in simple tasks. To combat this issue, we propose the Knowledge\nMixture Data Augmentation Model (KnowDA): an encoder-decoder LM pretrained on a\nmixture of diverse NLP tasks using Knowledge Mixture Training (KoMT). KoMT is a\ntraining procedure that reformulates input examples from various heterogeneous\nNLP tasks into a unified text-to-text format and employs denoising objectives\nin different granularity to learn to generate partial or complete samples. With\nthe aid of KoMT, KnowDA could combine required task-specific knowledge\nimplicitly from the learned mixture of tasks and quickly grasp the inherent\nsynthesis law of the target task through a few given instances. To the best of\nour knowledge, we are the first attempt to scale the number of tasks to 100+ in\nmulti-task co-training for data augmentation. Extensive experiments show that\ni) KnowDA successfully improves the performance of Albert and Deberta by a\nlarge margin on the FewGLUE benchmark, outperforming previous state-of-the-art\ndata augmentation baselines; ii) KnowDA could also improve the model\nperformance on the few-shot NER tasks, a held-out task type not included in\nKoMT.",
    "descriptor": "",
    "authors": [
      "Yufei Wang",
      "Jiayi Zheng",
      "Can Xu",
      "Xiubo Geng",
      "Tao Shen",
      "Chongyang Tao",
      "Daxin Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.10265"
  },
  {
    "id": "arXiv:2206.10272",
    "title": "Identification of Attack Paths Using Kill Chain and Attack Graphs",
    "abstract": "The ever-evolving capabilities of cyber attackers force security\nadministrators to focus on the early identification of emerging threats.\nTargeted cyber attacks usually consist of several phases, from initial\nreconnaissance of the network environment to final impact on objectives. This\npaper investigates the identification of multi-step cyber threat scenarios\nusing kill chain and attack graphs. Kill chain and attack graphs are threat\nmodeling concepts that enable determining weak security defense points. We\npropose a novel kill chain attack graph that merges kill chain and attack\ngraphs together. This approach determines possible chains of attacker's actions\nand their materialization within the protected network. The graph generation\nuses a categorization of threats according to violated security properties. The\ngraph allows determining the kill chain phase the administrator should focus on\nand applicable countermeasures to mitigate possible cyber threats. We\nimplemented the proposed approach for a predefined range of cyber threats,\nespecially vulnerability exploitation and network threats. The approach was\nvalidated on a real-world use case. Publicly available implementation contains\na proof-of-concept kill chain attack graph generator.",
    "descriptor": "\nComments: IEEE/IFIP NOMS 2022 conference, 6 pages\n",
    "authors": [
      "Luk\u00e1\u0161 Sadlek",
      "Pavel \u010celeda",
      "Daniel Tovar\u0148\u00e1k"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.10272"
  },
  {
    "id": "arXiv:2206.10273",
    "title": "Embrace your incompetence! Designing appropriate CUI communication  through an ecological approach",
    "abstract": "People form impressions of their dialogue partners, be they other people or\nmachines, based on cues drawn from their communicative style. Recent work has\nsuggested that the gulf between people's expectations and the reality of CUI\ninteraction widens when these impressions are misaligned with the actual\ncapabilities of conversational user interfaces (CUIs). This has led some to\nrally against a perceived overriding concern for naturalness, calling instead\nfor more representative, or appropriate communicative cues. Indeed, some have\nargued for a move away from naturalness as a goal for CUI design and\ncommunication. We contend that naturalness need not be abandoned, if we instead\naim for ecologically grounded design. We also suggest a way this might be\nachieved and call on CUI designers to embrace incompetence! By letting CUIs\nexpress uncertainty and embarrassment through ecologically valid and\nappropriate cues that are ubiquitous in human communication - CUI designers can\nachieve more appropriate communication without turning away from naturalness\nentirely.",
    "descriptor": "",
    "authors": [
      "Sophie Becker",
      "Philip Doyle",
      "Justin Edwards"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.10273"
  },
  {
    "id": "arXiv:2206.10274",
    "title": "Attention-driven Active Vision for Efficient Reconstruction of Plants  and Targeted Plant Parts",
    "abstract": "Visual reconstruction of tomato plants by a robot is extremely challenging\ndue to the high levels of variation and occlusion in greenhouse environments.\nThe paradigm of active-vision helps overcome these challenges by reasoning\nabout previously acquired information and systematically planning camera\nviewpoints to gather novel information about the plant. However, existing\nactive-vision algorithms cannot perform well on targeted perception objectives,\nsuch as the 3D reconstruction of leaf nodes, because they do not distinguish\nbetween the plant-parts that need to be reconstructed and the rest of the\nplant. In this paper, we propose an attention-driven active-vision algorithm\nthat considers only the relevant plant-parts according to the task-at-hand. The\nproposed approach was evaluated in a simulated environment on the task of 3D\nreconstruction of tomato plants at varying levels of attention, namely the\nwhole plant, the main stem and the leaf nodes. Compared to pre-defined and\nrandom approaches, our approach improves the accuracy of 3D reconstruction by\n9.7% and 5.3% for the whole plant, 14.2% and 7.9% for the main stem, and 25.9%\nand 17.3% for the leaf nodes respectively within the first 3 viewpoints. Also,\ncompared to pre-defined and random approaches, our approach reconstructs 80% of\nthe whole plant and the main stem in 1 less viewpoint and 80% of the leaf nodes\nin 3 less viewpoints. We also demonstrated that the attention-driven NBV\nplanner works effectively despite changes to the plant models, the amount of\nocclusion, the number of candidate viewpoints and the resolutions of\nreconstruction. By adding an attention mechanism to active-vision, it is\npossible to efficiently reconstruct the whole plant and targeted plant parts.\nWe conclude that an attention mechanism for active-vision is necessary to\nsignificantly improve the quality of perception in complex agro-food\nenvironments.",
    "descriptor": "",
    "authors": [
      "Akshay K. Burusa",
      "Eldert J. van Henten",
      "Gert Kootstra"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10274"
  },
  {
    "id": "arXiv:2206.10275",
    "title": "Steady-state nonlinearity of open-loop reset systems",
    "abstract": "In this paper, we introduce a new representation for open-loop reset systems.\nWe show that at steady-state a reset integrator can be modelled as a parallel\ninterconnection of the base-linear system and piece-wise constant nonlinearity.\nFor sinusoidal input signals, this nonlinearity takes a form of a square wave.\nSubsequently, we show how the behaviour of a general open-loop reset system is\nrelated to the nonlinearity of a reset integrator. The proposed approach\nsimplifies the analysis of reset elements in the frequency domain and provides\nnew insights into the behaviour of reset control systems.",
    "descriptor": "\nComments: to be published in the proceedings of the 2022 6th IEEE Conference on Control Technology and Applications\n",
    "authors": [
      "Marcin B. Kaczmarek",
      "Xinxin Zhang",
      "S. Hassan HosseinNia"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.10275"
  },
  {
    "id": "arXiv:2206.10280",
    "title": "muBoost: An Effective Method for Solving Indic Multilingual Text  Classification Problem",
    "abstract": "Text Classification is an integral part of many Natural Language Processing\ntasks such as sarcasm detection, sentiment analysis and many more such\napplications. Many e-commerce websites, social-media/entertainment platforms\nuse such models to enhance user-experience to generate traffic and thus,\nrevenue on their platforms. In this paper, we are presenting our solution to\nMultilingual Abusive Comment Identification Problem on Moj, an Indian\nvideo-sharing social networking service, powered by ShareChat. The problem\ndealt with detecting abusive comments, in 13 regional Indic languages such as\nHindi, Telugu, Kannada etc., on the videos on Moj platform. Our solution\nutilizes the novel muBoost, an ensemble of CatBoost classifier models and\nMultilingual Representations for Indian Languages (MURIL) model, to produce\nSOTA performance on Indic text classification tasks. We were able to achieve a\nmean F1-score of 89.286 on the test data, an improvement over baseline MURIL\nmodel with a F1-score of 87.48.",
    "descriptor": "",
    "authors": [
      "Manish Pathak",
      "Aditya Jain"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10280"
  },
  {
    "id": "arXiv:2206.10287",
    "title": "High Satisfaction in Thin Dynamic Matching Markets",
    "abstract": "Dynamic matching markets are an ubiquitous object of study with applications\nin health, labor, or dating. There exists a rich literature on the formal\nmodeling of such markets. Typically, these models consist of an arrival\nprocedure, governing when and which agents enter the market, and a sojourn\nperiod of agents during which they may leave the market matched with another\npresent agent, or after which they leave the market unmatched. One important\nfocus lies on the design of mechanisms for the matching process aiming at\nmaximizing the quality of the produced matchings or at minimizing waiting\ncosts.\nWe study a dynamic matching procedure where homogeneous agents arrive at\nrandom according to a Poisson process and form edges at random yielding a\nsparse market. Agents leave according to a certain departure distribution and\nmay leave early by forming a pair with a compatible agent. The objective is to\nmaximize the number of matched agents. Our main result is to show that a mild\nguarantee on the maximum sojourn time of agents suffices to get almost optimal\nperformance of instantaneous matching, despite operating in a thin market. This\nhas the additional advantages of avoiding the risk of market congestion and\nguaranteeing short waiting times. We develop new techniques for proving our\nresults going beyond commonly adopted methods for Markov processes.",
    "descriptor": "",
    "authors": [
      "Johannes B\u00e4umler",
      "Martin Bullinger",
      "Stefan Kober",
      "Donghao Zhu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2206.10287"
  },
  {
    "id": "arXiv:2206.10289",
    "title": "Imitation Learning for Nonprehensile Manipulation through  Self-Supervised Learning Considering Motion Speed",
    "abstract": "Robots are expected to replace menial tasks such as housework. Some of these\ntasks include nonprehensile manipulation performed without grasping objects.\nNonprehensile manipulation is very difficult because it requires considering\nthe dynamics of environments and objects. Therefore imitating complex behaviors\nrequires a large number of human demonstrations. In this study, a\nself-supervised learning that considers dynamics to achieve variable speed for\nnonprehensile manipulation is proposed. The proposed method collects and\nfine-tunes only successful action data obtained during autonomous operations.\nBy fine-tuning the successful data, the robot learns the dynamics among itself,\nits environment, and objects. We experimented with the task of scooping and\ntransporting pancakes using the neural network model trained on 24\nhuman-collected training data. The proposed method significantly improved the\nsuccess rate from 40.2% to 85.7%, and succeeded the task more than 75% for\nother objects.",
    "descriptor": "",
    "authors": [
      "Yuki Saigusa",
      "Sho Sakaino",
      "Toshiaki Tsuji"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.10289"
  },
  {
    "id": "arXiv:2206.10290",
    "title": "Discretization and index-robust error analysis for constrained  high-index saddle dynamics on high-dimensional sphere",
    "abstract": "We develop and analyze numerical discretization to the constrained high-index\nsaddle dynamics, the dynamics searching for the high-index saddle points\nconfined on the high-dimensional unit sphere. Compared with the saddle dynamics\nwithout constraints, the constrained high-index saddle dynamics has more\ncomplex dynamical forms, and additional operations such as the retraction and\nvector transport are required due to the constraint, which significantly\ncomplicate the numerical scheme and the corresponding numerical analysis.\nFurthermore, as the existing numerical analysis results usually depend on the\nindex of the saddle points implicitly, the proved numerical accuracy may be\nreduced if the index is high in many applications, which indicates the lack of\nrobustness with respect to the index. To address these issues, we derive the\nerror estimates for numerical discretization of the constrained high-index\nsaddle dynamics on high-dimensional sphere, and then improve it by providing an\nindex-robust error analysis in an averaged norm by adjusting the relaxation\nparameters. The developed results provide mathematical supports for the\naccuracy of numerical computations.",
    "descriptor": "",
    "authors": [
      "Lei Zhang",
      "Pingwen Zhang",
      "Xiangcheng Zheng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.10290"
  },
  {
    "id": "arXiv:2206.10291",
    "title": "Algorithmic Gaussianization through Sketching: Converting Data into  Sub-gaussian Random Designs",
    "abstract": "Algorithmic Gaussianization is a phenomenon that can arise when using\nrandomized sketching or sampling methods to produce smaller representations of\nlarge datasets: For certain tasks, these sketched representations have been\nobserved to exhibit many robust performance characteristics that are known to\noccur when a data sample comes from a sub-gaussian random design, which is a\npowerful statistical model of data distributions. However, this phenomenon has\nonly been studied for specific tasks and metrics, or by relying on\ncomputationally expensive methods. We address this by providing an algorithmic\nframework for gaussianizing data distributions via averaging, proving that it\nis possible to efficiently construct data sketches that are nearly\nindistinguishable (in terms of total variation distance) from sub-gaussian\nrandom designs. In particular, relying on a recently introduced sketching\ntechnique called Leverage Score Sparsified (LESS) embeddings, we show that one\ncan construct an $n\\times d$ sketch of an $N\\times d$ matrix $A$, where $n\\ll\nN$, that is nearly indistinguishable from a sub-gaussian design, in time\n$O(\\text{nnz}(A)\\log N + nd^2)$, where $\\text{nnz}(A)$ is the number of\nnon-zero entries in $A$. As a consequence, strong statistical guarantees and\nprecise asymptotics available for the estimators produced from sub-gaussian\ndesigns (e.g., for least squares and Lasso regression, covariance estimation,\nlow-rank approximation, etc.) can be straightforwardly adapted to our sketching\nframework. We illustrate this with a new approximation guarantee for sketched\nleast squares, among other examples.",
    "descriptor": "",
    "authors": [
      "Micha\u0142 Derezi\u0144ski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.10291"
  },
  {
    "id": "arXiv:2206.10292",
    "title": "Artificial Neural Network evaluation of Poincar\u00e9 constant for Voronoi  polygons",
    "abstract": "We propose a method, based on Artificial Neural Networks, that learns the\ndependence of the constant in the Poincar\\'e inequality on polygonal elements\nof Voronoi meshes, on some geometrical metrics of the element. The cost of this\nkind of algorithms mainly resides in the data preprocessing and learning\nphases, that can be performed offline once and for all, constructing an\nefficient method for computing the constant, which is needed in the design of a\nposteriori error estimates in numerical mesh-based schemes for the solution of\nPartial Differential Equations.",
    "descriptor": "",
    "authors": [
      "Beatrice Crippa",
      "Silvia Bertoluzza",
      "Micol Pennacchio"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.10292"
  },
  {
    "id": "arXiv:2206.10295",
    "title": "Dynamic Reserve Price Design for Lazada Sponsored Search",
    "abstract": "In ecommerce platform, users will be less likely to use organic search if\nsponsored search shows them unexpected advertising items, which will be a\nhidden cost for the platform. In order to incorporate the hidden cost into\nauction mechanism which helps create positive growth for the platform, we turn\nto a reserve price design to decide whether we sell the traffic, as well as\nbuild healthy relationships between revenue and user experience. We propose a\ndynamic reserve price design framework to sell traffic more efficiently with\nminimal cost of user experience while keeping long term incentives to the\nadvertisers to reveal their valuations truthfully. A distributed algorithm is\nalso proposed to compute the reserve price with billion scale data in the\nproduction environment. Experiments with offline evaluations and online AB\ntesting demonstrate that it is a simple and efficient method to be suitably\nused in industrial production. It has already been fully deployed in the\nproduction of Lazada sponsored search.",
    "descriptor": "",
    "authors": [
      "Mang Li"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.10295"
  },
  {
    "id": "arXiv:2206.10298",
    "title": "ViralBERT: A User Focused BERT-Based Approach to Virality Prediction",
    "abstract": "Recently, Twitter has become the social network of choice for sharing and\nspreading information to a multitude of users through posts called 'tweets'.\nUsers can easily re-share these posts to other users through 'retweets', which\nallow information to cascade to many more users, increasing its outreach.\nClearly, being able to know the extent to which a post can be retweeted has\ngreat value in advertising, influencing and other such campaigns. In this paper\nwe propose ViralBERT, which can be used to predict the virality of tweets using\ncontent- and user-based features. We employ a method of concatenating numerical\nfeatures such as hashtags and follower numbers to tweet text, and utilise two\nBERT modules: one for semantic representation of the combined text and\nnumerical features, and another module purely for sentiment analysis of text,\nas both the information within text and it's ability to elicit an emotional\nresponse play a part in retweet proneness. We collect a dataset of 330k tweets\nto train ViralBERT and validate the efficacy of our model using baselines from\ncurrent studies in this field. Our experiments show that our approach\noutperforms these baselines, with a 13% increase in both F1 Score and Accuracy\ncompared to the best performing baseline method. We then undergo an ablation\nstudy to investigate the importance of chosen features, finding that text\nsentiment and follower counts, and to a lesser extent mentions and following\ncounts, are the strongest features for the model, and that hashtag counts are\ndetrimental to the model.",
    "descriptor": "\nComments: UMAP 2022\n",
    "authors": [
      "Rikaz Rameez",
      "Hossein A. Rahmani",
      "Emine Yilmaz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.10298"
  },
  {
    "id": "arXiv:2206.10299",
    "title": "Global Contentious Politics Database (GLOCON) Annotation Manuals",
    "abstract": "The database creation utilized automated text processing tools that detect if\na news article contains a protest event, locate protest information within the\narticle, and extract pieces of information regarding the detected protest\nevents. The basis of training and testing the automated tools is the GLOCON\nGold Standard Corpus (GSC), which contains news articles from multiple sources\nfrom each focus country. The articles in the GSC were manually coded by skilled\nannotators in both classification and extraction tasks with the utmost accuracy\nand consistency that automated tool development demands. In order to assure\nthese, the annotation manuals in this document lay out the rules according to\nwhich annotators code the news articles. Annotators refer to the manuals at all\ntimes for all annotation tasks and apply the rules that they contain. The\ncontent of the annotation manual is built on the general principles and\nstandards of linguistic annotation laid out in other prominent annotation\nmanuals such as ACE, CAMEO, and TimeML. These principles, however, have been\nadapted or rather modified heavily to accommodate the social scientific\nconcepts and variables employed in the EMW project. The manual has been molded\nthroughout a long trial and error process that accompanied the annotation of\nthe GSC. It owes much of its current shape to the meticulous work and\ninvaluable feedback provided by highly specialized teams of annotators, whose\ndiligence and expertise greatly increased the quality of the corpus.",
    "descriptor": "\nComments: Annotation manuals of the Emerging Welfare project\n",
    "authors": [
      "F\u0131rat Duru\u015fan",
      "Ali H\u00fcrriyeto\u011flu",
      "Erdem Y\u00f6r\u00fck",
      "Osman Mutlu",
      "\u00c7a\u011fr\u0131 Yoltar",
      "Burak G\u00fcrel",
      "Alvaro Comin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10299"
  },
  {
    "id": "arXiv:2206.10300",
    "title": "Preference Change in Persuasive Robotics",
    "abstract": "Human-robot interaction exerts influence towards the human, which often\nchanges behavior. This article explores an externality of this changed behavior\n- preference change. It expands on previous work on preference change in AI\nsystems. Specifically, this article will explore how a robot's adaptive\nbehavior, personalized to the user, can exert influence through social\ninteractions, that in turn change a user's preference. It argues that the risk\nof this is high given a robot's unique ability to influence behavior compared\nto other pervasive technologies. Persuasive Robotics thus runs the risk of\nbeing manipulative.",
    "descriptor": "\nComments: in TRAITS Workshop Proceedings (arXiv:2206.08270) held in conjunction with Companion of the 2022 ACM/IEEE International Conference on Human-Robot Interaction, March 2022, Pages Pages 1284-1286\n",
    "authors": [
      "Matija Franklin",
      "Hal Ashton"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.10300"
  },
  {
    "id": "arXiv:2206.10303",
    "title": "Prediction of Maneuvering Status for Aerial Vehicles using Supervised  Learning Methods",
    "abstract": "Aerial Vehicles follow a guided approach based on Latitude, Longitude and\nAltitude. This information can be used for calculating the status of\nmaneuvering for the aerial vehicles along the line of trajectory. This is a\nbinary classification problem and Machine Learning can be leveraged for solving\nsuch problem. In this paper we present a methodology for deriving maneuvering\nstatus and its prediction using Linear, Distance Metric, Discriminant Analysis\nand Boosting Ensemble supervised learning methods. We provide various metrics\nalong the line in the results section that give condensed comparison of the\nappropriate algorithm for prediction of the maneuvering status.",
    "descriptor": "\nComments: 9 pages. To appear in proceedings of 2nd International Conference on Machine Learning and Big Data Analytics (ICMLBDA) 2022\n",
    "authors": [
      "Abhishek Gupta",
      "Sarvesh Thustu",
      "Riti Thakor",
      "Saniya Patil",
      "Raunak Joshi",
      "Ronald Melvin Laban"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10303"
  },
  {
    "id": "arXiv:2206.10304",
    "title": "LayoutXLM vs. GNN: An Empirical Evaluation of Relation Extraction for  Documents",
    "abstract": "This paper investigates the Relation Extraction task in documents by\nbenchmarking two different neural network models: a multi-modal language model\n(LayoutXLM) and a Graph Neural Network: Edge Convolution Network (ECN). For\nthis benchmark, we use the XFUND dataset, released along with LayoutXLM. While\nboth models reach similar results, they both exhibit very different\ncharacteristics. This raises the question on how to integrate various\nmodalities in a neural network: by merging all modalities thanks to additional\npretraining (LayoutXLM), or in a cascaded way (ECN). We conclude by discussing\nsome methodological issues that must be considered for new datasets and task\ndefinition in the domain of Information Extraction with complex documents.",
    "descriptor": "",
    "authors": [
      "Herv\u00e9 D\u00e9jean",
      "St\u00e9phane Clinchant",
      "Jean-Luc Meunier"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.10304"
  },
  {
    "id": "arXiv:2206.10305",
    "title": "Scale-Variant Robust Kernel Optimization for Non-linear Least Squares  Problems",
    "abstract": "In this letter, we present an algorithm for iterative nonlinear least-squares\nwhich increases the adaptive nature of previous methods in the literature. Our\nmethod uses two parameters to learn the best fitting distribution of the\nmeasurement residuals and performs Iterative Re-weighted Least Squares (IRLS)\nbased on these two parameters. This adaptive nature of the weights is shown to\nbe helpful in situations where the noise level varies in the measurements and\nis shown to increase robustness to outliers. We test our algorithm first on the\npoint cloud registration problem with synthetic data sets, where the true\ntransformation is known. Next, we also evaluate the approach with an\nopen-source LiDAR-inertial SLAM package to demonstrate that the proposed\napproach is more effective than constant parameters for the application of\nincremental LiDAR-inertial odometry. This increased adaptivity can help in a\nwide range of estimation problems in robotics by better modeling the\nmeasurement errors.",
    "descriptor": "\nComments: Submitted to Robotics & Automation Letters 2022\n",
    "authors": [
      "Shounak Das",
      "Jason Gross"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.10305"
  },
  {
    "id": "arXiv:2206.10306",
    "title": "Sustainably Grown: The Underdog Robots of the Future",
    "abstract": "It is hard to imagine with the progress in robotics that current approaches\nare lacking somewhere, yet they will not be applicable to the majority of\nrobots in the near future. We are on the verge of two new transitions that will\ntransform robotics. One is already under way -- the miniaturization of robots,\nto the point where invisible, microscopic robots could be around us and inside\nus, performing monitoring or even life-saving functions. We have seen\nsystematic bio-inspired efforts to create microbe-like, microscopic robots. The\ntrend has parallels with miniaturization in the electronics industry, where\nexponentially smaller and more energy efficient units have been produced each\ngeneration. To put this statement in context, examples already include magnetic\nmicroswimmer robots, employing bacterial modes of locomotion, which are\nbiocompatible, potentially ready for integration within our bodies. They\nrequire lithography to create clever microscopic screw-type structures, enough\nto produce the cork-screw swimming movement. Such micro-robots have\nencapsulated, picked, and delivered cells, protecting them from shear forces in\nfluids, while others have captured non-motile sperm, propelled them, and\nultimately fertilized an egg. We explore how such developments in micro-robots\nwill change our world in the relatively near future. The second trend is\nbottom-up robotics, growing robots from a solution medium, as if they were\nbacteria. This field is emerging at the intersection of a number of\ndisciplines, discussed below. An overarching common theme is the creation of\nartificial life from a non-biological starting point.",
    "descriptor": "\nComments: 4 pages + header\n",
    "authors": [
      "Stoyan K. Smoukov"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Soft Condensed Matter (cond-mat.soft)",
      "Emerging Technologies (cs.ET)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.10306"
  },
  {
    "id": "arXiv:2206.10309",
    "title": "Feasibility of Smartphone Vibrations as a Sensory Diagnostic Tool",
    "abstract": "Traditionally, clinicians use tuning forks as a binary measure to assess\nvibrotactile sensory perception. This approach has low measurement resolution,\nand the vibrations are highly variable. Therefore, we propose using vibrations\nfrom a smartphone to deliver a consistent and precise sensory test. First, we\ndemonstrate that a smartphone has more consistent vibrations compared to a\ntuning fork. Then we develop an app and conduct a validation study to show that\nthe smartphone can precisely measure a user's absolute threshold. This finding\nmotivates future work to use smartphones to assess vibrotactile perception,\nallowing for increased monitoring and widespread accessibility.",
    "descriptor": "\nComments: 3 pages, 1 figure, work-in-progress paper published in EuroHaptics Conference, 2022\n",
    "authors": [
      "Rachel A. G. Adenekan",
      "Alexis J. Lowber",
      "Bryce N. Huerta",
      "Allison M. Okamura",
      "Kyle T. Yoshida",
      "Cara M. Nunez"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.10309"
  },
  {
    "id": "arXiv:2206.10310",
    "title": "Modeling Big Data-based Systems through Ontological Trading",
    "abstract": "One of the great challenges the information society faces is dealing with the\nhuge amount of information generated and handled daily on the Internet. Today,\nprogress in Big data proposals attempts to solve this problem, but there are\ncertain limitations to information search and retrieval due basically to the\nlarge volumes handled the heterogeneity of the information, and its dispersion\namong a multitude of sources. In this article, a formal framework is defined to\nfacilitate the design and development of an environmental management\ninformation system, which works with a heterogeneous and large amount of data.\nNevertheless, this framework can be applied to other information systems that\nwork with Big data, because it does not depend on the type of data and can be\nutilized in other domains. The framework is based on an ontological web-trading\nmodel (OntoTrader), which follows model-driven engineering and ontology-driven\nengineering guidelines to separate the system architecture from its\nimplementation. The proposal is accompanied by a case study, SOLERES-KRS, an\nenvironmental knowledge representation system designed and developed using\nsoftware agents and multi-agent systems.",
    "descriptor": "",
    "authors": [
      "Luis Iribarne",
      "Jose A. Asensio",
      "Nicolas Padilla",
      "Javier Criado"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.10310"
  },
  {
    "id": "arXiv:2206.10311",
    "title": "Marginal Tail-Adaptive Normalizing Flows",
    "abstract": "Learning the tail behavior of a distribution is a notoriously difficult\nproblem. By definition, the number of samples from the tail is small, and deep\ngenerative models, such as normalizing flows, tend to concentrate on learning\nthe body of the distribution. In this paper, we focus on improving the ability\nof normalizing flows to correctly capture the tail behavior and, thus, form\nmore accurate models. We prove that the marginal tailedness of an\nautoregressive flow can be controlled via the tailedness of the marginals of\nits base distribution. This theoretical insight leads us to a novel type of\nflows based on flexible base distributions and data-driven linear layers. An\nempirical analysis shows that the proposed method improves on the accuracy --\nespecially on the tails of the distribution -- and is able to generate\nheavy-tailed data. We demonstrate its application on a weather and climate\nexample, in which capturing the tail behavior is essential.",
    "descriptor": "\nComments: Accepted at ICML2022 Thirty-ninth International Conference on Machine Learning\n",
    "authors": [
      "Mike Laszkiewicz",
      "Johannes Lederer",
      "Asja Fischer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.10311"
  },
  {
    "id": "arXiv:2206.10312",
    "title": "SAMPLE-HD: Simultaneous Action and Motion Planning Learning Environment",
    "abstract": "Humans exhibit incredibly high levels of multi-modal understanding -\ncombining visual cues with read, or heard knowledge comes easy to us and allows\nfor very accurate interaction with the surrounding environment. Various\nsimulation environments focus on providing data for tasks related to scene\nunderstanding, question answering, space exploration, visual navigation. In\nthis work, we are providing a solution to encompass both, visual and\nbehavioural aspects of simulation in a new environment for learning interactive\nreasoning in manipulation setup. SAMPLE-HD environment allows to generate\nvarious scenes composed of small household objects, to procedurally generate\nlanguage instructions for manipulation, and to generate ground truth paths\nserving as training data.",
    "descriptor": "\nComments: CVPRW, 2 pages\n",
    "authors": [
      "Michal Nazarczuk",
      "Tony Ng",
      "Krystian Mikolajczyk"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10312"
  },
  {
    "id": "arXiv:2206.10313",
    "title": "Active Inference for Robotic Manipulation",
    "abstract": "Robotic manipulation stands as a largely unsolved problem despite significant\nadvances in robotics and machine learning in the last decades. One of the\ncentral challenges of manipulation is partial observability, as the agent\nusually does not know all physical properties of the environment and the\nobjects it is manipulating in advance. A recently emerging theory that deals\nwith partial observability in an explicit manner is Active Inference. It does\nso by driving the agent to act in a way that is not only goal-directed but also\ninformative about the environment. In this work, we apply Active Inference to a\nhard-to-explore simulated robotic manipulation tasks, in which the agent has to\nbalance a ball into a target zone. Since the reward of this task is sparse, in\norder to explore this environment, the agent has to learn to balance the ball\nwithout any extrinsic feedback, purely driven by its own curiosity. We show\nthat the information-seeking behavior induced by Active Inference allows the\nagent to explore these challenging, sparse environments systematically.\nFinally, we conclude that using an information-seeking objective is beneficial\nin sparse environments and allows the agent to solve tasks in which methods\nthat do not exhibit directed exploration fail.",
    "descriptor": "\nComments: Published at \"The Multi-disciplinary Conference on Reinforcement Learning and Decision Making (RLDM)\" 2022\n",
    "authors": [
      "Tim Schneider",
      "Boris Belousov",
      "Hany Abdulsamad",
      "Jan Peters"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10313"
  },
  {
    "id": "arXiv:2206.10314",
    "title": "Goal-Oriented Adaptive Finite Element Multilevel Monte Carlo with  Convergence Rates",
    "abstract": "We present an adaptive multilevel Monte Carlo (AMLMC) algorithm for\napproximating deterministic, real-valued, bounded linear functionals that\ndepend on the solution of a linear elliptic PDE with a lognormal diffusivity\ncoefficient and geometric singularities in bounded domains of $\\mathbb{R}^d$.\nOur AMLMC algorithm is built on the results of the weak convergence rates in\nthe work [Moon et al., BIT Numer. Math., 46 (2006), 367-407] for an adaptive\nalgorithm using isoparametric d-linear quadrilateral finite element\napproximations and the dual weighted residual error representation in a\ndeterministic setting. Designed to suit the geometric nature of the\nsingularities in the solution, our AMLMC algorithm uses a sequence of\ndeterministic, non-uniform auxiliary meshes as a building block. The\ndeterministic adaptive algorithm generates these meshes, corresponding to a\ngeometrically decreasing sequence of tolerances. For a given realization of the\ndiffusivity coefficient and accuracy level, AMLMC constructs its approximate\nsample using the first mesh in the hierarchy that satisfies the corresponding\nbias accuracy constraint.\nThis adaptive approach is particularly useful for the lognormal case treated\nhere, which lacks uniform coercivity and thus produces functional outputs that\nvary over orders of magnitude when sampled.\nWe discuss iterative solvers and compare their efficiency with direct ones.\nTo reduce computational work, we propose a stopping criterion for the iterative\nsolver with respect to the quantity of interest, the realization of the\ndiffusivity coefficient, and the desired level of AMLMC approximation.\nFrom the numerical experiments, based on a Fourier expansion of the\ncoefficient field, we observe improvements in efficiency compared with both\nstandard Monte Carlo and standard MLMC for a problem with a singularity similar\nto that at the tip of a slit modeling a crack.",
    "descriptor": "",
    "authors": [
      "Joakim Beck",
      "Yang Liu",
      "Erik von Schwerin",
      "Ra\u00fal Tempone"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.10314"
  },
  {
    "id": "arXiv:2206.10318",
    "title": "FabKG: A Knowledge graph of Manufacturing Science domain utilizing  structured and unconventional unstructured knowledge source",
    "abstract": "As the demands for large-scale information processing have grown, knowledge\ngraph-based approaches have gained prominence for representing general and\ndomain knowledge. The development of such general representations is essential,\nparticularly in domains such as manufacturing which intelligent processes and\nadaptive education can enhance. Despite the continuous accumulation of text in\nthese domains, the lack of structured data has created information extraction\nand knowledge transfer barriers. In this paper, we report on work towards\ndeveloping robust knowledge graphs based upon entity and relation data for both\ncommercial and educational uses. To create the FabKG (Manufacturing knowledge\ngraph), we have utilized textbook index words, research paper keywords, FabNER\n(manufacturing NER), to extract a sub knowledge base contained within Wikidata.\nMoreover, we propose a novel crowdsourcing method for KG creation by leveraging\nstudent notes, which contain invaluable information but are not captured as\nmeaningful information, excluding their use in personal preparation for\nlearning and written exams. We have created a knowledge graph containing 65000+\ntriples using all data sources. We have also shown the use case of\ndomain-specific question answering and expression/formula-based question\nanswering for educational purposes.",
    "descriptor": "\nComments: NAACL 2022 Workshop on Structured and Unstructured Knowledge Integration (SUKI)\n",
    "authors": [
      "Aman Kumar",
      "Akshay G Bharadwaj",
      "Binil Starly",
      "Collin Lynch"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2206.10318"
  },
  {
    "id": "arXiv:2206.10324",
    "title": "Online progressive instance-balanced sampling for weakly supervised  object detection",
    "abstract": "Based on multiple instance detection networks (MIDN), plenty of works have\ncontributed tremendous efforts to weakly supervised object detection (WSOD).\nHowever, most methods neglect the fact that the overwhelming negative instances\nexist in each image during the training phase, which would mislead the training\nand make the network fall into local minima. To tackle this problem, an online\nprogressive instance-balanced sampling (OPIS) algorithm based on hard sampling\nand soft sampling is proposed in this paper. The algorithm includes two\nmodules: a progressive instance balance (PIB) module and a progressive instance\nreweighting (PIR) module. The PIB module combining random sampling and\nIoU-balanced sampling progressively mines hard negative instances while\nbalancing positive instances and negative instances. The PIR module further\nutilizes classifier scores and IoUs of adjacent refinements to reweight the\nweights of positive instances for making the network focus on positive\ninstances. Extensive experimental results on the PASCAL VOC 2007 and 2012\ndatasets demonstrate the proposed method can significantly improve the\nbaseline, which is also comparable to many existing state-of-the-art results.\nIn addition, compared to the baseline, the proposed method requires no extra\nnetwork parameters and the supplementary training overheads are small, which\ncould be easily integrated into other methods based on the instance classifier\nrefinement paradigm.",
    "descriptor": "",
    "authors": [
      "M. Chen",
      "Y. Tian",
      "Z. Li",
      "E. Li",
      "Z. Liang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10324"
  },
  {
    "id": "arXiv:2206.10326",
    "title": "Sense The Physical, Walkthrough The Virtual, Manage The Metaverse: A  Data-centric Perspective",
    "abstract": "In the Metaverse, the physical space and the virtual space co-exist, and\ninteract simultaneously. While the physical space is virtually enhanced with\ninformation, the virtual space is continuously refreshed with real-time,\nreal-world information. To allow users to process and manipulate information\nseamlessly between the real and digital spaces, novel technologies must be\ndeveloped. These include smart interfaces, new augmented realities, efficient\nstorage and data management and dissemination techniques. In this paper, we\nfirst discuss some promising co-space applications. These applications offer\nexperiences and opportunities that neither of the spaces can realize on its\nown. We then argue that the database community has much to offer to this field.\nFinally, we present several challenges that we, as a community, can contribute\ntowards managing the Metaverse.",
    "descriptor": "",
    "authors": [
      "Beng Chin Ooi",
      "Kian-Lee Tan",
      "Anthony Tung",
      "Gang Chen",
      "Mike Zheng Shou",
      "Xiaokui Xiao",
      "Meihui Zhang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10326"
  },
  {
    "id": "arXiv:2206.10329",
    "title": "SVG Vector Font Generation for Chinese Characters with Transformer",
    "abstract": "Designing fonts for Chinese characters is highly labor-intensive and\ntime-consuming. While the latest methods successfully generate the English\nalphabet vector font, despite the high demand for automatic font generation,\nChinese vector font generation has been an unsolved problem owing to its\ncomplex shape and numerous characters. This study addressed the problem of\nautomatically generating Chinese vector fonts from only a single style and\ncontent reference. We proposed a novel network architecture with Transformer\nand loss functions to capture structural features without differentiable\nrendering. Although the dataset range was still limited to the sans-serif\nfamily, we successfully generated the Chinese vector font for the first time\nusing the proposed method.",
    "descriptor": "\nComments: Accepted to ICIP 2022\n",
    "authors": [
      "Haruka Aoki",
      "Kiyoharu Aizawa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10329"
  },
  {
    "id": "arXiv:2206.10333",
    "title": "Machine Learning Prescriptive Canvas for Optimizing Business Outcomes",
    "abstract": "Data science has the potential to improve business in a variety of verticals.\nWhile the lion's share of data science projects uses a predictive approach, to\ndrive improvements these predictions should become decisions. However, such a\ntwo-step approach is not only sub-optimal but might even degrade performance\nand fail the project. The alternative is to follow a prescriptive framing,\nwhere actions are \"first citizens\" so that the model produces a policy that\nprescribes an action to take, rather than predicting an outcome. In this paper,\nwe explain why the prescriptive approach is important and provide a\nstep-by-step methodology: the Prescriptive Canvas. The latter aims to improve\nframing and communication across the project stakeholders including project and\ndata science managers towards a successful business impact.",
    "descriptor": "\nComments: accepted to ACMKDD Workshop 2022\n",
    "authors": [
      "Hanan Shteingart",
      "Gerben Oostra",
      "Ohad Levinkron",
      "Naama Parush",
      "Gil Shabat",
      "Daniel Aronovich"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.10333"
  },
  {
    "id": "arXiv:2206.10334",
    "title": "Defending Adversarial Examples by Negative Correlation Ensemble",
    "abstract": "The security issues in DNNs, such as adversarial examples, have attracted\nmuch attention. Adversarial examples refer to the examples which are capable to\ninduce the DNNs return completely predictions by introducing carefully designed\nperturbations. Obviously, adversarial examples bring great security risks to\nthe development of deep learning. Recently, Some defense approaches against\nadversarial examples have been proposed, however, in our opinion, the\nperformance of these approaches are still limited. In this paper, we propose a\nnew ensemble defense approach named the Negative Correlation Ensemble (NCEn),\nwhich achieves compelling results by introducing gradient directions and\ngradient magnitudes of each member in the ensemble negatively correlated and at\nthe same time, reducing the transferability of adversarial examples among them.\nExtensive experiments have been conducted, and the results demonstrate that\nNCEn can improve the adversarial robustness of ensembles effectively.",
    "descriptor": "",
    "authors": [
      "Wenjian Luo",
      "Hongwei Zhang",
      "Linghao Kong",
      "Zhijian Chen",
      "Ke Tang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10334"
  },
  {
    "id": "arXiv:2206.10338",
    "title": "Comparative Analysis of Dynamic Data Race Detection Techniques",
    "abstract": "The consequences of data races can be potentially very problematic [1], and\nit is important to determine what tools and methods are best at detecting them.\nThe following conditions must be met for a data race to occur: two or more\nthreads in a single process access the same memory location concurrently, at\nleast one of the accesses is for writing, and the threads are not using any\nexclusive locks to control their accesses to that memory.\nThis paper reveals the techniques and implementations of the two main methods\nfor dynamic data race detection techniques; the happens-before and lockset\nmethods, and produces an analysis for several tools that employ either ({\\S}4,\n{\\S}5) or of both these methods ({\\S}7.1) for detecting data races. This paper\nalso reveals the extent to which dynamic data race detection (also called\ndynamic analysis) can identify harmful data races, how it can be implemented,\nand how it compares to other forms of data detection in terms of performance\nand accuracy.",
    "descriptor": "",
    "authors": [
      "Danial Entezari"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2206.10338"
  },
  {
    "id": "arXiv:2206.10340",
    "title": "Vehicle Teleoperation: Successive Reference-Pose Tracking",
    "abstract": "Vehicle teleoperation is an interesting feature in many fields. A typical\nproblem of teleoperation is communication time delay which, together with\nactuator saturation and environmental disturbance, can cause a vehicle\ndeviation from the target trajectory imposed by the human operator who imposes\nto the vehicle a steering wheel angle reference and a speed/acceleration\nreference. With predictive techniques, time-delay can be accounted at\nsufficient extent. But, in presence of disturbances, due to the absence of\ninstantaneous haptic and visual feedback, human-operator steering command\ntransmitted to the the vehicle is unaccounted with disturbances observed by the\nvehicle. To improve reference tracking without losing promptness in driving\ncontrol, reference trajectory in the form of successive reference poses can be\ntransmitted instead of steering commands to the vehicle. We introduce this new\nconcept, namely, the 'successive reference-pose tracking (SRPT)' to improve\npath tracking in vehicle teleoperation. This paper discusses feasibility and\nadvantages of this new method, compare to the smith predictor control approach.\nSimulations are performed in SIMULINK environment, where a 14-dof vehicle model\nis being controlled with Smith and SRPT controllers in presence of variable\nnetwork delay. Scenarios for performance comparison are low adhesion ground,\nstrong lateral wind and steer-rate demanding maneuvers. Simulation result shows\nsignificant improvement in reference tracking with SRPT approach.",
    "descriptor": "\nComments: VPPC2022 conference submitted\n",
    "authors": [
      "Jai Prakash",
      "Michele Vignati",
      "Edoardo Sabbioni",
      "Federico Cheli"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.10340"
  },
  {
    "id": "arXiv:2206.10341",
    "title": "Neurotoxin: Durable Backdoors in Federated Learning",
    "abstract": "Due to their decentralized nature, federated learning (FL) systems have an\ninherent vulnerability during their training to adversarial backdoor attacks.\nIn this type of attack, the goal of the attacker is to use poisoned updates to\nimplant so-called backdoors into the learned model such that, at test time, the\nmodel's outputs can be fixed to a given target for certain inputs. (As a simple\ntoy example, if a user types \"people from New York\" into a mobile keyboard app\nthat uses a backdoored next word prediction model, then the model could\nautocomplete the sentence to \"people from New York are rude\"). Prior work has\nshown that backdoors can be inserted into FL models, but these backdoors are\noften not durable, i.e., they do not remain in the model after the attacker\nstops uploading poisoned updates. Thus, since training typically continues\nprogressively in production FL systems, an inserted backdoor may not survive\nuntil deployment. Here, we propose Neurotoxin, a simple one-line modification\nto existing backdoor attacks that acts by attacking parameters that are changed\nless in magnitude during training. We conduct an exhaustive evaluation across\nten natural language processing and computer vision tasks, and we find that we\ncan double the durability of state of the art backdoors.",
    "descriptor": "\nComments: Appears in ICML 2022\n",
    "authors": [
      "Zhengming Zhang",
      "Ashwinee Panda",
      "Linyue Song",
      "Yaoqing Yang",
      "Michael W. Mahoney",
      "Joseph E. Gonzalez",
      "Kannan Ramchandran",
      "Prateek Mittal"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10341"
  },
  {
    "id": "arXiv:2206.10343",
    "title": "Building an Endangered Language Resource in the Classroom: Universal  Dependencies for Kakataibo",
    "abstract": "In this paper, we launch a new Universal Dependencies treebank for an\nendangered language from Amazonia: Kakataibo, a Panoan language spoken in Peru.\nWe first discuss the collaborative methodology implemented, which proved\neffective to create a treebank in the context of a Computational Linguistic\ncourse for undergraduates. Then, we describe the general details of the\ntreebank and the language-specific considerations implemented for the proposed\nannotation. We finally conduct some experiments on part-of-speech tagging and\nsyntactic dependency parsing. We focus on monolingual and transfer learning\nsettings, where we study the impact of a Shipibo-Konibo treebank, another\nPanoan language resource.",
    "descriptor": "\nComments: Accepted to LREC 2022\n",
    "authors": [
      "Roberto Zariquiey",
      "Claudia Alvarado",
      "Ximena Echevarria",
      "Luisa Gomez",
      "Rosa Gonzales",
      "Mariana Illescas",
      "Sabina Oporto",
      "Frederic Blum",
      "Arturo Oncevay",
      "Javier Vera"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.10343"
  },
  {
    "id": "arXiv:2206.10344",
    "title": "Static Analysis of Infrastructure as Code: a Survey",
    "abstract": "The increasing use of Infrastructure as Code (IaC) in DevOps leads to\nbenefits in speed and reliability of deployment operation, but extends to\ninfrastructure challenges typical of software systems. IaC scripts can contain\ndefects that result in security and reliability issues in the deployed\ninfrastructure: techniques for detecting and preventing them are needed. We\nanalyze and survey the current state of research in this respect by conducting\na literature review on static analysis techniques for IaC. We describe analysis\ntechniques, defect categories and platforms targeted by tools in the\nliterature.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Michele Chiari",
      "Michele De Pascalis",
      "Matteo Pradella"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.10344"
  },
  {
    "id": "arXiv:2206.10346",
    "title": "A new stable and avoiding inversion iteration for computing matrix  square root",
    "abstract": "The objective of this research was to compute the principal matrix square\nroot with sparse approximation. A new stable iterative scheme avoiding fully\nmatrix inversion (SIAI) is provided. The analysis on the sparsity and error of\nthe matrices involved during the iterative process is given. Based on the\nbandwidth and error analysis, a more efficient algorithm combining the SIAI\nwith the filtering technique is proposed. The high computational efficiency and\naccuracy of the proposed method are demonstrated by computing the principal\nsquare roots of different matrices to reveal its applicability over the\nexisting methods.",
    "descriptor": "\nComments: 19 pages, 3 figures\n",
    "authors": [
      "Li Zhu",
      "Keqi Ye",
      "Yuelin Zhao",
      "Feng Wu",
      "Jiqiang Hu",
      "Wanxie Zhong"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.10346"
  },
  {
    "id": "arXiv:2206.10349",
    "title": "Joint Analysis of Acoustic Scenes and Sound Events Based on Multitask  Learning with Dynamic Weight Adaptation",
    "abstract": "Acoustic scene classification (ASC) and sound event detection (SED) are major\ntopics in environmental sound analysis. Considering that acoustic scenes and\nsound events are closely related to each other, the joint analysis of acoustic\nscenes and sound events using multitask learning (MTL)-based neural networks\nwas proposed in some previous works. Conventional methods train MTL-based\nmodels using a linear combination of ASC and SED loss functions with constant\nweights. However, the performance of conventional MTL-based methods depends\nstrongly on the weights of the ASC and SED losses, and it is difficult to\ndetermine the appropriate balance between the constant weights of the losses of\nMTL of ASC and SED. In this paper, we thus propose dynamic weight adaptation\nmethods for MTL of ASC and SED based on dynamic weight average and multi--focal\nloss to adjust the learning weights automatically. Evaluation experiments using\nparts of the TUT Acoustic Scenes 2016/2017 and TUT Sound Events 2016/2017 are\nconducted, and we show that the proposed methods improve the scene\nclassification and event detection performance characteristics compared with\nthe conventional MTL-based method. We then investigate how the learning weights\nof ASC and SED tasks dynamically adapt as the model training progresses.",
    "descriptor": "\nComments: Submitted to Acoustical Science and Technology\n",
    "authors": [
      "Kayo Nada",
      "Keisuke Imoto",
      "Takao Tsuchiya"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.10349"
  },
  {
    "id": "arXiv:2206.10351",
    "title": "A total hip surgery robot system based on intelligent positioning and  optical measurement",
    "abstract": "This paper represents the development and experimental evaluation of an\nautonomous navigation surgical robot system for total hip arthroplasty (THA).\nExisting robotic systems used in joint replacement surgery have achieved good\nclinical results, with reported better accuracy. While the surgeon needs to\nlocate the robot arm to the target position during the operation, which is\neasily affected by the doctor of experience. Yet, the hand-hold acetabulum\nreamer is easy to appear with uneven strength and grinding file. Further, the\nlack of steps to measure the femoral neck length may lead to poor results.To\ntackle this challenge, our design contains the real-time traceable optical\npositioning strategy to reduce unnecessary manual adjustments to the robotic\narm during surgery, the intelligent end-effector system to stable the grinding,\nand the optical probe to provide real-time measurement of femoral neck length\nand other parameters to choose the prosthesis. The length of the lower limbs\nwas measured as the prosthesis was installed. Experimental evaluation showed\nthat the robot of precision, execution ability, and robustness are better than\nexpected.",
    "descriptor": "",
    "authors": [
      "Weibo Ning",
      "Jiaqi Zhu",
      "Hongjiang Chen",
      "Weijun Zhou",
      "Shuxing He",
      "Yecheng Tan",
      "Qianrui Xu",
      "Jun Hu",
      "Zhun Fan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.10351"
  },
  {
    "id": "arXiv:2206.10352",
    "title": "Psychologically-Inspired, Unsupervised Inference of Perceptual Groups of  GUI Widgets from GUI Images",
    "abstract": "Graphical User Interface (GUI) is not merely a collection of individual and\nunrelated widgets, but rather partitions discrete widgets into groups by\nvarious visual cues, thus forming higher-order perceptual units such as tab,\nmenu, card or list. The ability to automatically segment a GUI into perceptual\ngroups of widgets constitutes a fundamental component of visual intelligence to\nautomate GUI design, implementation and automation tasks. Although humans can\npartition a GUI into meaningful perceptual groups of widgets in a highly\nreliable way, perceptual grouping is still an open challenge for computational\napproaches. Existing methods rely on ad-hoc heuristics or supervised machine\nlearning that is dependent on specific GUI implementations and runtime\ninformation. Research in psychology and biological vision has formulated a set\nof principles (i.e., Gestalt theory of perception) that describe how humans\ngroup elements in visual scenes based on visual cues like connectivity,\nsimilarity, proximity and continuity. These principles are domain-independent\nand have been widely adopted by practitioners to structure content on GUIs to\nimprove aesthetic pleasant and usability. Inspired by these principles, we\npresent a novel unsupervised image-based method for inferring perceptual groups\nof GUI widgets. Our method requires only GUI pixel images, is independent of\nGUI implementation, and does not require any training data. The evaluation on a\ndataset of 1,091 GUIs collected from 772 mobile apps and 20 UI design mockups\nshows that our method significantly outperforms the state-of-the-art ad-hoc\nheuristics-based baseline. Our perceptual grouping method creates the\nopportunities for improving UI-related software engineering tasks.",
    "descriptor": "\nComments: 12 Pages, accepted to ESEC/FSE '2022\n",
    "authors": [
      "Mulong Xie",
      "Zhenchang Xing",
      "Sidong Feng",
      "Chunyang Chen",
      "Liming Zhu",
      "Xiwei Xu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.10352"
  },
  {
    "id": "arXiv:2206.10358",
    "title": "Open Source Software: An Approach to Controlling Usage and Risk in  Application Ecosystems",
    "abstract": "The Open Source Software movement has been growing exponentially for a number\nof years with no signs of slowing. Driving this growth is the widespread\navailability of libraries and frameworks that provide many functionalities.\nDevelopers are saving time and money incorporating this functionality into\ntheir applications resulting in faster more feature-rich releases. Despite the\ngrowing success and the advantages that open source software provides, there is\na dark side. Due to its community construction and largely unregulated\ndistribution, the majority of open source software contains bugs,\nvulnerabilities and other issues making it highly susceptible to exploits. The\nlack of oversight, in general, hinders the quality of this software resulting\nin a trickle-down effect in the applications that use it. Additionally,\ndevelopers who use open source tend to arbitrarily download the software into\ntheir build systems but rarely keep track of what they have downloaded\nresulting in an excessive amount of open source software in their applications\nand in their ecosystem. This paper discusses processes and practices that users\nof open source software can implement into their environments that can safely\ntrack and control the introduction and usage of open source software into their\napplications, and report on some preliminary results obtained in an industrial\ncontext. We conclude by discussing governance issues related to the disciplined\nuse and reuse of open source and areas for further improvements.",
    "descriptor": "",
    "authors": [
      "Stan Zajdel",
      "Diego Elias Costa",
      "Hafedh Mili"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.10358"
  },
  {
    "id": "arXiv:2206.10360",
    "title": "Enhancing Multi-view Stereo with Contrastive Matching and Weighted Focal  Loss",
    "abstract": "Learning-based multi-view stereo (MVS) methods have made impressive progress\nand surpassed traditional methods in recent years. However, their accuracy and\ncompleteness are still struggling. In this paper, we propose a new method to\nenhance the performance of existing networks inspired by contrastive learning\nand feature matching. First, we propose a Contrast Matching Loss (CML), which\ntreats the correct matching points in depth-dimension as positive sample and\nother points as negative samples, and computes the contrastive loss based on\nthe similarity of features. We further propose a Weighted Focal Loss (WFL) for\nbetter classification capability, which weakens the contribution of\nlow-confidence pixels in unimportant areas to the loss according to predicted\nconfidence. Extensive experiments performed on DTU, Tanks and Temples and\nBlendedMVS datasets show our method achieves state-of-the-art performance and\nsignificant improvement over baseline network.",
    "descriptor": "\nComments: 5 pages, 3 figures; Accepted to ICIP2022\n",
    "authors": [
      "Yikang Ding",
      "Zhenyang Li",
      "Dihe Huang",
      "Zhiheng Li",
      "Kai Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10360"
  },
  {
    "id": "arXiv:2206.10365",
    "title": "A Flexible Diffusion Model",
    "abstract": "Diffusion (score-based) generative models have been widely used for modeling\nvarious types of complex data, including images, audios, and point clouds.\nRecently, the deep connection between forward-backward stochastic differential\nequations (SDEs) and diffusion-based models has been revealed, and several new\nvariants of SDEs are proposed (e.g., sub-VP, critically-damped Langevin) along\nthis line. Despite the empirical success of the hand-crafted fixed forward\nSDEs, a great quantity of proper forward SDEs remain unexplored. In this work,\nwe propose a general framework for parameterizing the diffusion model,\nespecially the spatial part of the forward SDE. An abstract formalism is\nintroduced with theoretical guarantees, and its connection with previous\ndiffusion models is leveraged. We demonstrate the theoretical advantage of our\nmethod from an optimization perspective. Numerical experiments on synthetic\ndatasets, MINIST and CIFAR10 are also presented to validate the effectiveness\nof our framework.",
    "descriptor": "",
    "authors": [
      "Weitao Du",
      "Tao Yang",
      "He Zhang",
      "Yuanqi Du"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10365"
  },
  {
    "id": "arXiv:2206.10368",
    "title": "Real-Time Waveform Matching with a Digitizer at 10 GS/s",
    "abstract": "Side-Channel Analysis (SCA) requires the detection of the specific time frame\nCryptographic Operations (COs) takeplace in the side-channel signal. In\nlaboratory conditions with full control over the Device under Test (DuT),\ndedicated trigger signals can be implemented to indicate the start and end of\nCOs. For real-world scenarios, waveform-matching techniques have been\nestablished which compare the side-channel signal with a template of the CO's\npattern in real time to detect the CO in the side channel. State-of-the-art\napproaches are implemented on Field-Programmable Gate Arrays (FPGAs). However,\ncurrent waveform-matching designs are processing the samples from\nAnalog-to-Digital Converters (ADCs) sequentially and can only work with low\nsampling rates due to the limited clock speed of FPGAs. This makes it\nincreasingly difficult to apply existing techniques on modern DuTs that are\noperating with clock speeds in the GHz range. In this paper, we present a\nparallel waveform-matching architecture that is capable of performing waveform\nmatching at the speed of fast ADCs. We implement the proposed architecture in a\nhigh-end FPGA-based digitizer and apply it to detect AES COs from the side\nchannel of a single-board computer operating at 1 GHz. Our implementation\nallows for waveform matching at 10 GS/s with high accuracy, thus offering a\nspeedup of 50x compared to the fastest state-of-the-art implementation known to\nus.",
    "descriptor": "",
    "authors": [
      "Jens Trautmann",
      "Nikolaos Patsiatzis",
      "Andreas Becher",
      "J\u00fcrgen Teich",
      "Stefan Wildermann"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2206.10368"
  },
  {
    "id": "arXiv:2206.10369",
    "title": "The State of Sparse Training in Deep Reinforcement Learning",
    "abstract": "The use of sparse neural networks has seen rapid growth in recent years,\nparticularly in computer vision. Their appeal stems largely from the reduced\nnumber of parameters required to train and store, as well as in an increase in\nlearning efficiency. Somewhat surprisingly, there have been very few efforts\nexploring their use in Deep Reinforcement Learning (DRL). In this work we\nperform a systematic investigation into applying a number of existing sparse\ntraining techniques on a variety of DRL agents and environments. Our results\ncorroborate the findings from sparse training in the computer vision domain -\nsparse networks perform better than dense networks for the same parameter count\n- in the DRL domain. We provide detailed analyses on how the various components\nin DRL are affected by the use of sparse networks and conclude by suggesting\npromising avenues for improving the effectiveness of sparse training methods,\nas well as for advancing their use in DRL.",
    "descriptor": "\nComments: Proceedings of the 39th International Conference on Machine Learning (ICML'22)\n",
    "authors": [
      "Laura Graesser",
      "Utku Evci",
      "Erich Elsen",
      "Pablo Samuel Castro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.10369"
  },
  {
    "id": "arXiv:2206.10372",
    "title": "Financial Trading Decisions based on Deep Fuzzy Self-Organizing Map",
    "abstract": "The volatility features of financial data would considerably change in\ndifferent periods, that is one of the main factors affecting the applications\nof machine learning in quantitative trading. Therefore, to effectively\ndistinguish fluctuation patterns of financial markets can provide meaningful\ninformation for the trading decision. In this article, a novel intelligent\ntrading system based on deep fuzzy self-organizing map (DFSOM) companied with\nGRU networks is proposed, where DFSOM is utilized for the clustering of\nfinancial data to acquire multiple fluctuation patterns in an unsupervised way.\nFirstly, in order to capture the trend features and evade the effect of high\nnoises in financial data, the images of extended candlestick charts instead of\nraw data are processed and the obtained features are applied for the following\nunsupervised learning, where candlestick charts are produced with both price\nand volume information. Secondly, by using the candlestick features, a\ntwo-layer deep fuzzy self-organizing map is constructed to carry out the\nclustering, where two-layer models carry out the clustering in multiple time\nscales to improve the processing of time-dependent information. Thirdly, GRU\nnetworks are used to implement the prediction task, based on which an\nintelligent trading model is constructed. The feasibility and effectiveness of\nthe proposed method are verified by using various real financial data sets.",
    "descriptor": "",
    "authors": [
      "Pei Dehao",
      "Luo Chao"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2206.10372"
  },
  {
    "id": "arXiv:2206.10375",
    "title": "MEStereo-Du2CNN: A Novel Dual Channel CNN for Learning Robust Depth  Estimates from Multi-exposure Stereo Images for HDR 3D Applications",
    "abstract": "Display technologies have evolved over the years. It is critical to develop\npractical HDR capturing, processing, and display solutions to bring 3D\ntechnologies to the next level. Depth estimation of multi-exposure stereo image\nsequences is an essential task in the development of cost-effective 3D HDR\nvideo content. In this paper, we develop a novel deep architecture for\nmulti-exposure stereo depth estimation. The proposed architecture has two novel\ncomponents. First, the stereo matching technique used in traditional stereo\ndepth estimation is revamped. For the stereo depth estimation component of our\narchitecture, a mono-to-stereo transfer learning approach is deployed. The\nproposed formulation circumvents the cost volume construction requirement,\nwhich is replaced by a ResNet based dual-encoder single-decoder CNN with\ndifferent weights for feature fusion. EfficientNet based blocks are used to\nlearn the disparity. Secondly, we combine disparity maps obtained from the\nstereo images at different exposure levels using a robust disparity feature\nfusion approach. The disparity maps obtained at different exposures are merged\nusing weight maps calculated for different quality measures. The final\npredicted disparity map obtained is more robust and retains best features that\npreserve the depth discontinuities. The proposed CNN offers flexibility to\ntrain using standard dynamic range stereo data or with multi-exposure low\ndynamic range stereo sequences. In terms of performance, the proposed model\nsurpasses state-of-the-art monocular and stereo depth estimation methods, both\nquantitatively and qualitatively, on challenging Scene flow and differently\nexposed Middlebury stereo datasets. The architecture performs exceedingly well\non complex natural scenes, demonstrating its usefulness for diverse 3D HDR\napplications.",
    "descriptor": "",
    "authors": [
      "Rohit Choudhary",
      "Mansi Sharma",
      "Uma T V",
      "Rithvik Anil"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10375"
  },
  {
    "id": "arXiv:2206.10377",
    "title": "Can we trust our energy measurements? A study on the Odroid-XU4",
    "abstract": "IoT devices, edge devices and embedded devices, in general, are ubiquitous.\nThe energy consumption of such devices is important both due to the total\nnumber of devices deployed and because such devices are often battery-powered.\nHence, improving the energy efficiency of such high-performance embedded\nsystems is crucial. The first step to decreasing energy consumption is to\naccurately measure it, as we base our conclusions and decisions on the\nmeasurements. Given the importance of the measurements, it surprised us that\nmost publications dedicate little space and effort to the description of their\nexperimental setup.\nOne variable of importance of the measurement system is the sampling\nfrequency, e.g. how often the continuous signal's voltage and current are\nmeasured per second. In this paper, we systematically explore the impact of the\nsampling frequency on the accuracy of the measurement system. We measure the\nenergy consumption of a Hardkernel Odroid-XU4 board executing nine Rodinia\nbenchmarks with a wide range of runtimes and options at 4kHz, which is the\nstandard sampling frequency of our measurement system. We show that one needs\nto measure at least at 350Hz to achieve equivalent results in comparison to the\noriginal power traces. Sampling at 1Hz (e.g. Hardkernel SmartPower2) results in\na maximum error of 80%.",
    "descriptor": "\nComments: 7 pages, 8 figures, accepted at OSPERT 2022\n",
    "authors": [
      "Julius Roeder",
      "Sebastian Altmeyer",
      "Clemens Grelck"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.10377"
  },
  {
    "id": "arXiv:2206.10379",
    "title": "Can process mining help in anomaly-based intrusion detection?",
    "abstract": "In this paper, we consider the naive applications of process mining in\nnetwork traffic comprehension, traffic anomaly detection, and intrusion\ndetection. We standardise the procedure of transforming packet data into an\nevent log. We mine multiple process models and analyse the process models mined\nwith the inductive miner using ProM and the fuzzy miner using Disco. We compare\nthe two types of process models extracted from event logs of differing sizes.\nWe contrast the process models with the RFC TCP state transition diagram and\nthe diagram by Bishop et al. We analyse the issues and challenges associated\nwith process mining in intrusion detection and explain why naive process mining\nwith network data is ineffective.",
    "descriptor": "",
    "authors": [
      "Yinzheng Zhong",
      "Alexei Lisitsa"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.10379"
  },
  {
    "id": "arXiv:2206.10380",
    "title": "An Energy and Carbon Footprint Analysis of Distributed and Federated  Learning",
    "abstract": "Classical and centralized Artificial Intelligence (AI) methods require moving\ndata from producers (sensors, machines) to energy hungry data centers, raising\nenvironmental concerns due to computational and communication resource demands,\nwhile violating privacy. Emerging alternatives to mitigate such high energy\ncosts propose to efficiently distribute, or federate, the learning tasks across\ndevices, which are typically low-power. This paper proposes a novel framework\nfor the analysis of energy and carbon footprints in distributed and federated\nlearning (FL). The proposed framework quantifies both the energy footprints and\nthe carbon equivalent emissions for vanilla FL methods and consensus-based\nfully decentralized approaches. We discuss optimal bounds and operational\npoints that support green FL designs and underpin their sustainability\nassessment. Two case studies from emerging 5G industry verticals are analyzed:\nthese quantify the environmental footprints of continual and reinforcement\nlearning setups, where the training process is repeated periodically for\ncontinuous improvements. For all cases, sustainability of distributed learning\nrelies on the fulfillment of specific requirements on communication efficiency\nand learner population size. Energy and test accuracy should be also traded off\nconsidering the model and the data footprints for the targeted industrial\napplications.",
    "descriptor": "\nComments: accepted for publication in IEEE Transactions on Green Communications and Networking\n",
    "authors": [
      "Stefano Savazzi",
      "Vittorio Rampa",
      "Sanaz Kianoush",
      "Mehdi Bennis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.10380"
  },
  {
    "id": "arXiv:2206.10381",
    "title": "TabText: a Systematic Approach to Aggregate Knowledge Across Tabular  Data Structures",
    "abstract": "Processing and analyzing tabular data in a productive and efficient way is\nessential for building successful applications of machine learning in fields\nsuch as healthcare. However, the lack of a unified framework for representing\nand standardizing tabular information poses a significant challenge to\nresearchers and professionals alike. In this work, we present TabText, a\nmethodology that leverages the unstructured data format of language to encode\ntabular data from different table structures and time periods efficiently and\naccurately. We show using two healthcare datasets and four prediction tasks\nthat features extracted via TabText outperform those extracted with traditional\nprocessing methods by 2-5%. Furthermore, we analyze the sensitivity of our\nframework against different choices for sentence representations of missing\nvalues, meta information and language descriptiveness, and provide insights\ninto winning strategies that improve performance.",
    "descriptor": "",
    "authors": [
      "Dimitris Bertsimas",
      "Kimberly Villalobos Carballo",
      "Yu Ma",
      "Liangyuan Na",
      "L\u00e9onard Boussioux",
      "Cynthia Zeng",
      "Luis R. Soenksen",
      "Ignacio Fuentes"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10381"
  },
  {
    "id": "arXiv:2206.10383",
    "title": "The Complexity of the Co-Occurrence Problem",
    "abstract": "Let $S$ be a string of length $n$ over an alphabet $\\Sigma$ and let $Q$ be a\nsubset of $\\Sigma$ of size $q \\geq 2$. The 'co-occurrence problem' is to\nconstruct a compact data structure that supports the following query: given an\ninteger $w$ return the number of length-$w$ substrings of $S$ that contain each\ncharacter of $Q$ at least once. This is a natural string problem with\napplications to, e.g., data mining, natural language processing, and DNA\nanalysis. The state of the art is an $O(\\sqrt{nq})$ space data structure that\n$\\unicode{x2014}$ with some minor additions $\\unicode{x2014}$ supports queries\nin $O(\\log\\log n)$ time [CPM 2021].\nOur contributions are as follows. Firstly, we analyze the problem in terms of\na new, natural parameter $d$, giving a simple data structure that uses $O(d)$\nspace and supports queries in $O(\\log\\log n)$ time. The preprocessing algorithm\ndoes a single pass over $S$, runs in expected $O(n)$ time, and uses $O(d)$\nspace in addition to the input. Furthermore, we show that $O(d)$ space is\noptimal and that $O(\\log\\log n)$-time queries are optimal given optimal space.\nSecondly, we bound $d = O(\\sqrt{nq})$, giving clean bounds in terms of $n$ and\n$q$ that match the state of the art. Furthermore, we prove that\n$\\Omega(\\sqrt{nq})$ bits of space is necessary in the worst case, meaning that\nthe $O(\\sqrt{nq})$ upper bound is tight to within polylogarithmic factors. All\nof our results are based on simple and intuitive combinatorial ideas that\nsimplify the state of the art.",
    "descriptor": "",
    "authors": [
      "Philip Bille",
      "Inge Li G\u00f8rtz",
      "Tord Stordalen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.10383"
  },
  {
    "id": "arXiv:2206.10389",
    "title": "Parameterized-NL Completeness of Combinatorial Problems by Short  Logarithmic-Space Reductions and Immediate Consequences of the Linear Space  Hypothesis",
    "abstract": "The concept of space-bounded computability has become significantly important\nin handling vast data sets on memory-limited computing devices. To replenish\nthe existing short list of NL-complete problems whose instance sizes are\ndictated by log-space size parameters, we propose new additions obtained\ndirectly from natural parameterizations of three typical NP-complete problems\n-- the vertex cover problem, the exact cover by 3-sets problem, and the\n3-dimensional matching problem. With appropriate restrictions imposed on their\ninstances, the proposed decision problems parameterized by appropriate size\nparameters are proven to be equivalent in computational complexity to either\nthe parameterized $3$-bounded 2CNF Boolean formula satisfiability problem or\nthe parameterized degree-$3$ directed $s$-$t$ connectivity problem by ``short''\nlogarithmic-space reductions. Under the assumption of the linear space\nhypothesis, furthermore, none of the proposed problems can be solved in\npolynomial time if the memory usage is limited to sub-linear space.",
    "descriptor": "\nComments: (A4, 10pt, 3 figures) A conference version will appear in the Proceedings of the Future Technologies Conference (FTC 2022), October 2022\n",
    "authors": [
      "Tomoyuki Yamakami"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2206.10389"
  },
  {
    "id": "arXiv:2206.10390",
    "title": "The SPACE THEA Project",
    "abstract": "In some situations, no professional human contact can be available.\nAccordingly, one remains alone with one's problems and fears. A manned Mars\nflight is certainly such a situation. A voice assistant that shows empathy and\nassists the astronauts could be a solution. In the SPACE THEA project, a\nprototype with such capabilities was developed using Google Assistant and\nDialogflow Essentials. The voice assistant has a personality based on\ncharacteristics such as functional intelligence, sincerity, creativity, and\nemotional intelligence. It proves itself in seven different scenarios designed\nto represent the daily lives of astronauts, addressing operational crises and\nhuman problems. The paper describes the seven scenarios in detail, and lists\ntechnical and conceptual foundations of the voice assistant. Finally, the most\nimportant results are stated and the chapters are summarized.",
    "descriptor": "\nComments: Accepted paper of the AAAI 2022 Spring Symposium \"How Fair is Fair? Achieving Wellbeing AI\" (Stanford University)\n",
    "authors": [
      "Martin Spathelf",
      "Oliver Bendel"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.10390"
  },
  {
    "id": "arXiv:2206.10397",
    "title": "Neural Moving Horizon Estimation for Robust Flight Control",
    "abstract": "Estimating and reacting to external disturbances is crucial for robust flight\ncontrol of quadrotors. Existing estimators typically require significant tuning\nfor a specific flight scenario or training with extensive real-world data to\nachieve satisfactory performance. In this paper, we propose a neural moving\nhorizon estimator (NeuroMHE) that can automatically tune the MHE parameters\nmodeled by a neural network and adapt to different flight scenarios. We achieve\nthis by deriving the analytical gradient of the MHE estimates with respect to\nthe tunable parameters, enabling a seamless embedding of MHE as a layer into\nthe neural network for highly effective learning. Most interestingly, we show\nthat the gradient can be solved efficiently from a Kalman filter in a recursive\nform. Moreover, we develop a model-based policy gradient algorithm to train\nNeuroMHE directly from the trajectory tracking error without the need for the\nground-truth disturbance. The effectiveness of NeuroMHE is verified extensively\nvia both simulations and physical experiments on a quadrotor in various\nchallenging flights. Notably, NeuroMHE outperforms the state-of-the-art\nestimator with force estimation error reductions of up to 49.4% by using only a\n2.5% amount of parameters. The proposed method is general and can be applied to\nrobust adaptive control for other robotic systems.",
    "descriptor": "",
    "authors": [
      "Bingheng Wang",
      "Zhengtian Ma",
      "Shupeng Lai",
      "Lin Zhao"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.10397"
  },
  {
    "id": "arXiv:2206.10400",
    "title": "Using EBGAN for Anomaly Intrusion Detection",
    "abstract": "As an active network security protection scheme, intrusion detection system\n(IDS) undertakes the important responsibility of detecting network attacks in\nthe form of malicious network traffic. Intrusion detection technology is an\nimportant part of IDS. At present, many scholars have carried out extensive\nresearch on intrusion detection technology. However, developing an efficient\nintrusion detection method for massive network traffic data is still difficult.\nSince Generative Adversarial Networks (GANs) have powerful modeling\ncapabilities for complex high-dimensional data, they provide new ideas for\naddressing this problem. In this paper, we put forward an EBGAN-based intrusion\ndetection method, IDS-EBGAN, that classifies network records as normal traffic\nor malicious traffic. The generator in IDS-EBGAN is responsible for converting\nthe original malicious network traffic in the training set into adversarial\nmalicious examples. This is because we want to use adversarial learning to\nimprove the ability of discriminator to detect malicious traffic. At the same\ntime, the discriminator adopts Autoencoder model. During testing, IDS-EBGAN\nuses reconstruction error of discriminator to classify traffic records.",
    "descriptor": "",
    "authors": [
      "Yi Cui",
      "Wenfeng Shen",
      "Jian Zhang",
      "Weijia Lu",
      "Chuang Liu",
      "Lin Sun",
      "Si Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.10400"
  },
  {
    "id": "arXiv:2206.10407",
    "title": "WrapperFL: A Model Agnostic Plug-in for Industrial Federated Learning",
    "abstract": "Federated learning, as a privacy-preserving collaborative machine learning\nparadigm, has been gaining more and more attention in the industry. With the\nhuge rise in demand, there have been many federated learning platforms that\nallow federated participants to set up and build a federated model from\nscratch. However, exiting platforms are highly intrusive, complicated, and hard\nto integrate with built machine learning models. For many real-world businesses\nthat already have mature serving models, existing federated learning platforms\nhave high entry barriers and development costs. This paper presents a simple\nyet practical federated learning plug-in inspired by ensemble learning, dubbed\nWrapperFL, allowing participants to build/join a federated system with existing\nmodels at minimal costs. The WrapperFL works in a plug-and-play way by simply\nattaching to the input and output interfaces of an existing model, without the\nneed of re-development, significantly reducing the overhead of manpower and\nresources. We verify our proposed method on diverse tasks under heterogeneous\ndata distributions and heterogeneous models. The experimental results\ndemonstrate that WrapperFL can be successfully applied to a wide range of\napplications under practical settings and improves the local model with\nfederated learning at a low cost.",
    "descriptor": "\nComments: FL-IJCAI'22 Accepted Paper\n",
    "authors": [
      "Xueyang Wu",
      "Shengqi Tan",
      "Qian Xu",
      "Qiang Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.10407"
  },
  {
    "id": "arXiv:2206.10411",
    "title": "Audio-video fusion strategies for active speaker detection in meetings",
    "abstract": "Meetings are a common activity in professional contexts, and it remains\nchallenging to endow vocal assistants with advanced functionalities to\nfacilitate meeting management. In this context, a task like active speaker\ndetection can provide useful insights to model interaction between meeting\nparticipants. Motivated by our application context related to advanced meeting\nassistant, we want to combine audio and visual information to achieve the best\npossible performance. In this paper, we propose two different types of fusion\nfor the detection of the active speaker, combining two visual modalities and an\naudio modality through neural networks. For comparison purpose, classical\nunsupervised approaches for audio feature extraction are also used. We expect\nvisual data centered on the face of each participant to be very appropriate for\ndetecting voice activity, based on the detection of lip and facial gestures.\nThus, our baseline system uses visual data and we chose a 3D Convolutional\nNeural Network architecture, which is effective for simultaneously encoding\nappearance and movement. To improve this system, we supplemented the visual\ninformation by processing the audio stream with a CNN or an unsupervised\nspeaker diarization system. We have further improved this system by adding\nvisual modality information using motion through optical flow. We evaluated our\nproposal with a public and state-of-the-art benchmark: the AMI corpus. We\nanalysed the contribution of each system to the merger carried out in order to\ndetermine if a given participant is currently speaking. We also discussed the\nresults we obtained. Besides, we have shown that, for our application context,\nadding motion information greatly improves performance. Finally, we have shown\nthat attention-based fusion improves performance while reducing the standard\ndeviation.",
    "descriptor": "",
    "authors": [
      "Lionel Pibre",
      "Francisco Madrigal",
      "Cyrille Equoy",
      "Fr\u00e9d\u00e9ric Lerasle",
      "Thomas Pellegrini",
      "Julien Pinquier",
      "Isabelle Ferran\u00e9"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.10411"
  },
  {
    "id": "arXiv:2206.10413",
    "title": "Multilayer Block Models for Exploratory Analysis of Computer Event Logs",
    "abstract": "We investigate a graph-based approach to exploratory data analysis in the\ncontext of network security monitoring. Given a possibly large batch of event\nlogs describing ongoing activity, we first represent these events as a\nbipartite multiplex graph. We then apply a model-based biclustering algorithm\nto extract relevant clusters of entities and interactions between these\nclusters, thereby providing a simplified situational picture. We illustrate\nthis methodology through two case studies addressing network flow records and\nauthentication logs, respectively. In both cases, the inferred clusters reveal\nthe functional roles of entities as well as relevant behavioral patterns.\nDisplaying interactions between these clusters also helps uncover malicious\nactivity. Our code is available at\nhttps://github.com/cl-anssi/MultilayerBlockModels.",
    "descriptor": "",
    "authors": [
      "Corentin Larroche"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2206.10413"
  },
  {
    "id": "arXiv:2206.10414",
    "title": "A Single-Timescale Analysis For Stochastic Approximation With Multiple  Coupled Sequences",
    "abstract": "Stochastic approximation (SA) with multiple coupled sequences has found broad\napplications in machine learning such as bilevel learning and reinforcement\nlearning (RL). In this paper, we study the finite-time convergence of nonlinear\nSA with multiple coupled sequences. Different from existing multi-timescale\nanalysis, we seek for scenarios where a fine-grained analysis can provide the\ntight performance guarantee for multi-sequence single-timescale SA (STSA). At\nthe heart of our analysis is the smoothness property of the fixed points in\nmulti-sequence SA that holds in many applications. When all sequences have\nstrongly monotone increments, we establish the iteration complexity of\n$\\mathcal{O}(\\epsilon^{-1})$ to achieve $\\epsilon$-accuracy, which improves the\nexisting $\\mathcal{O}(\\epsilon^{-1.5})$ complexity for two coupled sequences.\nWhen all but the main sequence have strongly monotone increments, we establish\nthe iteration complexity of $\\mathcal{O}(\\epsilon^{-2})$. The merit of our\nresults lies in that applying them to stochastic bilevel and compositional\noptimization problems, as well as RL problems leads to either relaxed\nassumptions or improvements over their existing performance guarantees.",
    "descriptor": "",
    "authors": [
      "Han Shen",
      "Tianyi Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.10414"
  },
  {
    "id": "arXiv:2206.10418",
    "title": "Route to Time and Time to Route: Travel Time Estimation from Sparse  Trajectories",
    "abstract": "Due to the rapid development of Internet of Things (IoT) technologies, many\nonline web apps (e.g., Google Map and Uber) estimate the travel time of\ntrajectory data collected by mobile devices. However, in reality, complex\nfactors, such as network communication and energy constraints, make multiple\ntrajectories collected at a low sampling rate. In this case, this paper aims to\nresolve the problem of travel time estimation (TTE) and route recovery in\nsparse scenarios, which often leads to the uncertain label of travel time and\nroute between continuously sampled GPS points. We formulate this problem as an\ninexact supervision problem in which the training data has coarsely grained\nlabels and jointly solve the tasks of TTE and route recovery. And we argue that\nboth two tasks are complementary to each other in the model-learning procedure\nand hold such a relation: more precise travel time can lead to better inference\nfor routes, in turn, resulting in a more accurate time estimation). Based on\nthis assumption, we propose an EM algorithm to alternatively estimate the\ntravel time of inferred route through weak supervision in E step and retrieve\nthe route based on estimated travel time in M step for sparse trajectories. We\nconducted experiments on three real-world trajectory datasets and demonstrated\nthe effectiveness of the proposed method.",
    "descriptor": "",
    "authors": [
      "Zhiwen Zhang",
      "Hongjun Wang",
      "Zipei Fan",
      "Jiyuan Chen",
      "Xuan Song",
      "Ryosuke Shibasaki"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2206.10418"
  },
  {
    "id": "arXiv:2206.10421",
    "title": "Rethinking Audio-visual Synchronization for Active Speaker Detection",
    "abstract": "Active speaker detection (ASD) systems are important modules for analyzing\nmulti-talker conversations. They aim to detect which speakers or none are\ntalking in a visual scene at any given time. Existing research on ASD does not\nagree on the definition of active speakers. We clarify the definition in this\nwork and require synchronization between the audio and visual speaking\nactivities. This clarification of definition is motivated by our extensive\nexperiments, through which we discover that existing ASD methods fail in\nmodeling the audio-visual synchronization and often classify unsynchronized\nvideos as active speaking. To address this problem, we propose a cross-modal\ncontrastive learning strategy and apply positional encoding in attention\nmodules for supervised ASD models to leverage the synchronization cue.\nExperimental results suggest that our model can successfully detect\nunsynchronized speaking as not speaking, addressing the limitation of current\nmodels.",
    "descriptor": "\nComments: Accepted by IEEE International Workshop on Machine Learning for Signal Processing (MLSP 2022)\n",
    "authors": [
      "Abudukelimu Wuerkaixi",
      "You Zhang",
      "Zhiyao Duan",
      "Changshui Zhang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.10421"
  },
  {
    "id": "arXiv:2206.10425",
    "title": "An Augmented Lagrangian Based Parallelizable Nonconvex Solver for  Bilinear Model Predictive Control",
    "abstract": "Nonlinear model predictive control is widely adopted to manipulate bilinear\nsystems, and bilinear models are ubiquitous in chemical process, mechanical\nsystem and quantum physics, to name a few. Running an MPC controller in\nreal-time requires solving a non-convex optimization problem at step. In this\nwork, we propose a novel parallel augmented Lagrangian based bilinear MPC\nsolver via a novel horizon splitting scheme. The resulting algorithm converts\nthe non-convex MPC control problem into a set parallelizable multi-parametric\nquadratic programming (mpQP) and an equality constrained QP problem. The mpQP\nsolution can be pre-computed offline to enable efficient online compuation. The\nproposed algorithm is validated on a building simulation and is deployed on a\nTI C2000 LaunchPad to emulate the bilinear DC motor speed control.",
    "descriptor": "",
    "authors": [
      "Yingzhao Lian",
      "Yuning Jiang",
      "Daniel F.Opila",
      "Colin N.Jones"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.10425"
  },
  {
    "id": "arXiv:2206.10429",
    "title": "Plug and Play Counterfactual Text Generation for Model Robustness",
    "abstract": "Generating counterfactual test-cases is an important backbone for testing NLP\nmodels and making them as robust and reliable as traditional software. In\ngenerating the test-cases, a desired property is the ability to control the\ntest-case generation in a flexible manner to test for a large variety of\nfailure cases and to explain and repair them in a targeted manner. In this\ndirection, significant progress has been made in the prior works by manually\nwriting rules for generating controlled counterfactuals. However, this approach\nrequires heavy manual supervision and lacks the flexibility to easily introduce\nnew controls. Motivated by the impressive flexibility of the plug-and-play\napproach of PPLM, we propose bringing the framework of plug-and-play to\ncounterfactual test case generation task. We introduce CASPer, a plug-and-play\ncounterfactual generation framework to generate test cases that satisfy goal\nattributes on demand. Our plug-and-play model can steer the test case\ngeneration process given any attribute model without requiring\nattribute-specific training of the model. In experiments, we show that CASPer\neffectively generates counterfactual text that follow the steering provided by\nan attribute model while also being fluent, diverse and preserving the original\ncontent. We also show that the generated counterfactuals from CASPer can be\nused for augmenting the training data and thereby fixing and making the test\nmodel more robust.",
    "descriptor": "",
    "authors": [
      "Nishtha Madaan",
      "Srikanta Bedathur",
      "Diptikalyan Saha"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10429"
  },
  {
    "id": "arXiv:2206.10430",
    "title": "Automatic Pull Request Title Generation",
    "abstract": "Pull requests (PRs) are a mechanism on modern collaborative coding platforms,\nsuch as GitHub. PRs allow developers to tell others that their code changes are\navailable for merging into another branch in a repository. A PR needs to be\nreviewed and approved by the core team of the repository before the changes are\nmerged into the branch. Usually, reviewers need to identify a PR that is in\nline with their interests before providing a review. By default, PRs are\narranged in a list view that shows the titles of PRs. Therefore, it is\ndesirable to have precise and concise titles, which is beneficial for both\nreviewers and other developers. However, it is often the case that developers\ndo not provide good titles; we find that many existing PR titles are either\ninappropriate in length (i.e., too short or too long) or fail to convey useful\ninformation, which may result in PR being ignored or rejected. Therefore, there\nis a need for automatic techniques to help developers draft high-quality\ntitles.\nIn this paper, we introduce the task of automatic generation of PR titles. We\nformulate the task as a one-sentence summarization task. To facilitate the\nresearch on this task, we construct a dataset that consists of 43,816 PRs from\n495 GitHub repositories. We evaluated the state-of-the-art summarization\napproaches for the automatic PR title generation task. We leverage ROUGE\nmetrics to automatically evaluate the summarization approaches and conduct a\nhuman evaluation. The experimental results indicate that BART is the best\ntechnique for generating satisfactory PR titles with ROUGE-1, ROUGE-2, and\nROUGE-L F1 scores of 47.22, 25.27, and 43.12, respectively. The human\nevaluation also shows that the titles generated by BART are preferred.",
    "descriptor": "",
    "authors": [
      "Ting Zhang",
      "Ivana Clairine Irsan",
      "Ferdian Thung",
      "DongGyun Han",
      "David Lo",
      "Lingxiao Jiang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.10430"
  },
  {
    "id": "arXiv:2206.10434",
    "title": "Model Joins: Enabling Analytics Over Joins of Absent Big Tables",
    "abstract": "This work is motivated by two key facts. First, it is highly desirable to be\nable to learn and perform knowledge discovery and analytics (LKD) tasks without\nthe need to access raw-data tables. This may be due to organizations finding it\nincreasingly frustrating and costly to manage and maintain ever-growing tables,\nor for privacy reasons. Hence, compact models can be developed from the raw\ndata and used instead of the tables. Second, oftentimes, LKD tasks are to be\nperformed on a (potentially very large) table which is itself the result of\njoining separate (potentially very large) relational tables. But how can one do\nthis, when the individual to-be-joined tables are absent? Here, we pose the\nfollowing fundamental questions: Q1: How can one \"join models\" of\n(absent/deleted) tables or \"join models with other tables\" in a way that\nenables LKD as if it were performed on the join of the actual raw tables? Q2:\nWhat are appropriate models to use per table? Q3: As the model join would be an\napproximation of the actual data join, how can one evaluate the quality of the\nmodel join result? This work puts forth a framework, Model Join, addressing\nthese challenges. The framework integrates and joins the per-table models of\nthe absent tables and generates a uniform and independent sample that is a\nhigh-quality approximation of a uniform and independent sample of the actual\nraw-data join. The approximation stems from the models, but not from the Model\nJoin framework. The sample obtained by the Model Join can be used to perform\nLKD downstream tasks, such as approximate query processing, classification,\nclustering, regression, association rule mining, visualization, and so on. To\nour knowledge, this is the first work with this agenda and solutions. Detailed\nexperiments with TPC-DS data and synthetic data showcase Model Join's\nusefulness.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Ali Mohammadi Shanghooshabad",
      "Peter Triantafillou"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10434"
  },
  {
    "id": "arXiv:2206.10435",
    "title": "Graphical Join: A New Physical Join Algorithm for RDBMSs",
    "abstract": "Join operations (especially n-way, many-to-many joins) are known to be time-\nand resource-consuming. At large scales, with respect to table and join-result\nsizes, current state of the art approaches (including both binary-join plans\nwhich use Nested-loop/Hash/Sort-merge Join algorithms or, alternatively,\nworst-case optimal join algorithms (WOJAs)), may even fail to produce any\nanswer given reasonable resource and time constraints. In this work, we\nintroduce a new approach for n-way equi-join processing, the Graphical Join\n(GJ). The key idea is two-fold: First, to map the physical join computation\nproblem to PGMs and introduce tweaked inference algorithms which can compute a\nRun-Length Encoding (RLE) based join-result summary, entailing all statistics\nnecessary to materialize the join result. Second, and most importantly, to show\nthat a join algorithm, like GJ, which produces the above join-result summary\nand then desummarizes it, can introduce large performance benefits in time and\nspace. Comprehensive experimentation is undertaken with join queries from the\nJOB, TPCDS, and lastFM datasets, comparing GJ against PostgresQL and MonetDB\nand a state of the art WOJA implemented within the Umbra system. The results\nfor in-memory join computation show performance improvements up to 64X, 388X,\nand 6X faster than PostgreSQL, MonetDB and Umbra, respectively. For on-disk\njoin computation, GJ is faster than PostgreSQL, MonetDB and Umbra by up to\n820X, 717X and 165X, respectively. Furthermore, GJ space needs are up to\n21,488X, 38,333X, and 78,750X smaller than PostgresQL, MonetDB, and Umbra,\nrespectively.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Ali Mohammadi Shanghooshabad",
      "Peter Triantafillou"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.10435"
  },
  {
    "id": "arXiv:2206.10436",
    "title": "Transformer-Based Multi-modal Proposal and Re-Rank for Wikipedia  Image-Caption Matching",
    "abstract": "With the increased accessibility of web and online encyclopedias, the amount\nof data to manage is constantly increasing. In Wikipedia, for example, there\nare millions of pages written in multiple languages. These pages contain images\nthat often lack the textual context, remaining conceptually floating and\ntherefore harder to find and manage. In this work, we present the system we\ndesigned for participating in the Wikipedia Image-Caption Matching challenge on\nKaggle, whose objective is to use data associated with images (URLs and visual\ndata) to find the correct caption among a large pool of available ones. A\nsystem able to perform this task would improve the accessibility and\ncompleteness of multimedia content on large online encyclopedias. Specifically,\nwe propose a cascade of two models, both powered by the recent Transformer\nmodel, able to efficiently and effectively infer a relevance score between the\nquery image data and the captions. We verify through extensive experimentation\nthat the proposed two-model approach is an effective way to handle a large pool\nof images and captions while maintaining bounded the overall computational\ncomplexity at inference time. Our approach achieves remarkable results,\nobtaining a normalized Discounted Cumulative Gain (nDCG) value of 0.53 on the\nprivate leaderboard of the Kaggle challenge.",
    "descriptor": "\nComments: Accepted for publication at the Wiki-M3L workshop, co-located with ICLR 2022\n",
    "authors": [
      "Nicola Messina",
      "Davide Alessandro Coccomini",
      "Andrea Esuli",
      "Fabrizio Falchi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10436"
  },
  {
    "id": "arXiv:2206.10442",
    "title": "Robust Task Representations for Offline Meta-Reinforcement Learning via  Contrastive Learning",
    "abstract": "We study offline meta-reinforcement learning, a practical reinforcement\nlearning paradigm that learns from offline data to adapt to new tasks. The\ndistribution of offline data is determined jointly by the behavior policy and\nthe task. Existing offline meta-reinforcement learning algorithms cannot\ndistinguish these factors, making task representations unstable to the change\nof behavior policies. To address this problem, we propose a contrastive\nlearning framework for task representations that are robust to the distribution\nmismatch of behavior policies in training and test. We design a bi-level\nencoder structure, use mutual information maximization to formalize task\nrepresentation learning, derive a contrastive learning objective, and introduce\nseveral approaches to approximate the true distribution of negative pairs.\nExperiments on a variety of offline meta-reinforcement learning benchmarks\ndemonstrate the advantages of our method over prior methods, especially on the\ngeneralization to out-of-distribution behavior policies. The code is available\nat https://github.com/PKU-AI-Edge/CORRO.",
    "descriptor": "\nComments: ICML 2022\n",
    "authors": [
      "Haoqi Yuan",
      "Zongqing Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10442"
  },
  {
    "id": "arXiv:2206.10443",
    "title": "Secret key generation from Gaussian sources using lattice-based  extractors",
    "abstract": "We propose a lattice-based scheme for secret key generation from Gaussian\nsources in the presence of an eavesdropper, and show that it achieves the\nstrong secret key capacity in the case of degraded source models, as well as\nthe optimal secret key / public communication rate trade-off. The key\ningredients of our scheme are a lattice extractor to extract the channel\nintrinsic randomness, based on the notion of flatness factor, together with a\nrandomized lattice quantization technique to quantize the continuous source.\nCompared to previous works, we introduce two new notions of flatness factor\nbased on $L^1$ distance and KL divergence, respectively, which are of\nindependent interest. We prove the existence of secrecy-good lattices under\n$L^1$ distance and KL divergence, whose $L^1$ and KL flatness factors vanish\nfor volume-to-noise ratios up to $2\\pi e$. This improves upon the\nvolume-to-noise ratio threshold $2\\pi$ of the $L^{\\infty}$ flatness factor.",
    "descriptor": "\nComments: 25 pages, 1 figure. arXiv admin note: text overlap with arXiv:1306.5299\n",
    "authors": [
      "Laura Luzzi",
      "Cong Ling",
      "Matthieu R. Bloch"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.10443"
  },
  {
    "id": "arXiv:2206.10444",
    "title": "Solving linear systems of the form $(A + \u03b3UU^T)\\, {\\bf x} = {\\bf  b}$ by preconditioned iterative methods",
    "abstract": "We consider the iterative solution of large linear systems of equations in\nwhich the coefficient matrix is the sum of two terms, a sparse matrix $A$ and a\npossibly dense, rank deficient matrix of the form $\\gamma UU^T$, where $\\gamma\n> 0$ is a parameter which in some applications may be taken to be 1. The matrix\n$A$ itself can be singular, but we assume that the symmetric part of $A$ is\npositive semidefinite and that $A+\\gamma UU^T$ is nonsingular. Linear systems\nof this form arise frequently in fields like optimization, fluid mechanics,\ncomputational statistics, and others. We investigate preconditioning strategies\nbased on an alternating splitting approach combined with the use of the\nSherman-Morrison-Woodbury matrix identity. The potential of the proposed\napproach is demonstrated by means of numerical experiments on linear systems\nfrom different application areas.",
    "descriptor": "\nComments: 20 pages, 7 figures\n",
    "authors": [
      "Michele Benzi",
      "Chiara Faccio"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.10444"
  },
  {
    "id": "arXiv:2206.10446",
    "title": "Deep dive into Interledger: Understanding the Interledger ecosystem",
    "abstract": "At the technical level, the goal of Interledger is to provide an architecture\nand a minimal set of protocols to enable interoperability between any value\ntransfer systems. The Interledger protocol is a protocol for inter-blockchain\npayments which can also accommodate FIAT currencies. To understand how it is\npossible to achieve this goal, several aspects of the technology require a\ndeeper analysis. For this reason, in our journey to become knowledgeable and\nactive contributors we decided to create our own test-bed on our premises. By\ndoing so, we noticed that some aspects are well documented but we found that\nothers might need more attention and clarification. Despite a large community\neffort, the task to keep information on a fast evolving software ecosystem\nup-to-date is tedious and not always the main priority for such a project. The\npurpose of this tutorial is to guide, through several examples and hands-on\nactivities, community members who want to engage at different levels. The\ntutorial consolidates all the relevant information from generating a simple\npayment to ultimately creating a test-bed with the Interledger protocol suite\nbetween Ripple and other distributed ledger technologies.",
    "descriptor": "\nComments: 65 pages, 28 figures, 4 tables\n",
    "authors": [
      "Lucian Trestioreanu",
      "Cyril Cassagnes",
      "Radu State"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.10446"
  },
  {
    "id": "arXiv:2206.10451",
    "title": "Winning the Lottery Ahead of Time: Efficient Early Network Pruning",
    "abstract": "Pruning, the task of sparsifying deep neural networks, received increasing\nattention recently. Although state-of-the-art pruning methods extract highly\nsparse models, they neglect two main challenges: (1) the process of finding\nthese sparse models is often very expensive; (2) unstructured pruning does not\nprovide benefits in terms of GPU memory, training time, or carbon emissions. We\npropose Early Compression via Gradient Flow Preservation (EarlyCroP), which\nefficiently extracts state-of-the-art sparse models before or early in training\naddressing challenge (1), and can be applied in a structured manner addressing\nchallenge (2). This enables us to train sparse networks on commodity GPUs whose\ndense versions would be too large, thereby saving costs and reducing hardware\nrequirements. We empirically show that EarlyCroP outperforms a rich set of\nbaselines for many tasks (incl. classification, regression) and domains (incl.\ncomputer vision, natural language processing, and reinforcment learning).\nEarlyCroP leads to accuracy comparable to dense training while outperforming\npruning baselines.",
    "descriptor": "",
    "authors": [
      "John Rachwan",
      "Daniel Z\u00fcgner",
      "Bertrand Charpentier",
      "Simon Geisler",
      "Morgane Ayle",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10451"
  },
  {
    "id": "arXiv:2206.10452",
    "title": "Shifted Compression Framework: Generalizations and Improvements",
    "abstract": "Communication is one of the key bottlenecks in the distributed training of\nlarge-scale machine learning models, and lossy compression of exchanged\ninformation, such as stochastic gradients or models, is one of the most\neffective instruments to alleviate this issue. Among the most studied\ncompression techniques is the class of unbiased compression operators with\nvariance bounded by a multiple of the square norm of the vector we wish to\ncompress. By design, this variance may remain high, and only diminishes if the\ninput vector approaches zero. However, unless the model being trained is\noverparameterized, there is no a-priori reason for the vectors we wish to\ncompress to approach zero during the iterations of classical methods such as\ndistributed compressed {\\sf SGD}, which has adverse effects on the convergence\nspeed. Due to this issue, several more elaborate and seemingly very different\nalgorithms have been proposed recently, with the goal of circumventing this\nissue. These methods are based on the idea of compressing the {\\em difference}\nbetween the vector we would normally wish to compress and some auxiliary vector\nwhich changes throughout the iterative process. In this work we take a step\nback, and develop a unified framework for studying such methods, conceptually,\nand theoretically. Our framework incorporates methods compressing both\ngradients and models, using unbiased and biased compressors, and sheds light on\nthe construction of the auxiliary vectors. Furthermore, our general framework\ncan lead to the improvement of several existing algorithms, and can produce new\nalgorithms. Finally, we performed several numerical experiments which\nillustrate and support our theoretical findings.",
    "descriptor": "\nComments: Accepted for the 38th Conference on Uncertainty in Artificial Intelligence (UAI 2022)\n",
    "authors": [
      "Egor Shulgin",
      "Peter Richt\u00e1rik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.10452"
  },
  {
    "id": "arXiv:2206.10454",
    "title": "Driving Digital Engineering Integration and Interoperability Through  Semantic Integration of Models with Ontologies",
    "abstract": "Engineered solutions are becoming more complex and multi-disciplinary in\nnature. This evolution requires new techniques to enhance design and analysis\ntasks that incorporate data integration and interoperability across various\nengineering tool suites spanning multiple domains at different abstraction\nlevels. Semantic Web Technologies (SWT) offer data integration and\ninteroperability benefits as well as other opportunities to enhance reasoning\nacross knowledge represented in multiple disparate models. This paper\nintroduces the Digital Engineering Framework for Integration and\nInteroperability (DEFII) for incorporating SWT into engineering design and\nanalysis tasks. The framework includes three notional interfaces for\ninteracting with ontology-aligned data. It also introduces a novel Model\nInterface Specification Diagram (MISD) that provides a tool-agnostic model\nrepresentation enabled by SWT that exposes data stored for use by external\nusers through standards-based interfaces. Use of the framework results in a\ntool-agnostic authoritative source of truth spanning the entire project,\nsystem, or mission.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Daniel Dunbar",
      "Thomas Hagedorn",
      "Mark Blackburn",
      "John Dzielski",
      "Steven Hespelt",
      "Benjamin Kruse",
      "Dinesh Verma",
      "Zhongyuan Yu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.10454"
  },
  {
    "id": "arXiv:2206.10457",
    "title": "Domain Adaptive 3D Pose Augmentation for In-the-wild Human Mesh Recovery",
    "abstract": "The ability to perceive 3D human bodies from a single image has a multitude\nof applications ranging from entertainment and robotics to neuroscience and\nhealthcare. A fundamental challenge in human mesh recovery is in collecting the\nground truth 3D mesh targets required for training, which requires burdensome\nmotion capturing systems and is often limited to indoor laboratories. As a\nresult, while progress is made on benchmark datasets collected in these\nrestrictive settings, models fail to generalize to real-world ``in-the-wild''\nscenarios due to distribution shifts. We propose Domain Adaptive 3D Pose\nAugmentation (DAPA), a data augmentation method that enhances the model's\ngeneralization ability in in-the-wild scenarios. DAPA combines the strength of\nmethods based on synthetic datasets by getting direct supervision from the\nsynthesized meshes, and domain adaptation methods by using ground truth 2D\nkeypoints from the target dataset. We show quantitatively that finetuning with\nDAPA effectively improves results on benchmarks 3DPW and AGORA. We further\ndemonstrate the utility of DAPA on a challenging dataset curated from videos of\nreal-world parent-child interaction.",
    "descriptor": "",
    "authors": [
      "Zhenzhen Weng",
      "Kuan-Chieh Wang",
      "Angjoo Kanazawa",
      "Serena Yeung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10457"
  },
  {
    "id": "arXiv:2206.10459",
    "title": "Device for measuring the plant physiology and electrophysiology",
    "abstract": "This paper briefly describes the device - the phytosensor - for measuring\nphysiological and electrophysiological parameters of plants. This system is\ndeveloped as a bio-physiological sensor in precise agriculture, as a tool in\nplant research and environmental biology, and for plant enthusiasts in smart\nhome or entertainment applications. The phytosentor measures main physiological\nparameters such as the leaf transpiration rate, sap flow, tissue conductivity\nand frequency response, biopotentials (action potentials and variation\npotentials), and can conduct electrochemical impedance spectroscopy with\norganic tissues. Soil moisture and temperature, air quality (CO2, NO2, O3 and\nother sensors on I2C bus), and general environmental parameters (light,\ntemperature, humidity, air pressure, electromagnetic and magnetic fields) are\nalso recorded in real time. In addition to phytosensing, the device can also\nperform phytoactuation, i.e. execute electrical or light stimulation of plants,\ncontrol irrigation and lighting modes, conduct fully autonomous experiments\nwith complex feedback-based and adaptive scenarios in robotic or biohybrid\nsystems. This article represents the revised and extended version of original\npaper and includes some descriptions and images from the FloraRobotica and\nBioHybrids projects.",
    "descriptor": "",
    "authors": [
      "Serge Kernbach"
    ],
    "subjectives": [
      "Other Computer Science (cs.OH)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.10459"
  },
  {
    "id": "arXiv:2206.10461",
    "title": "An Automatic and Efficient BERT Pruning for Edge AI Systems",
    "abstract": "With the yearning for deep learning democratization, there are increasing\ndemands to implement Transformer-based natural language processing (NLP) models\non resource-constrained devices for low-latency and high accuracy. Existing\nBERT pruning methods require domain experts to heuristically handcraft\nhyperparameters to strike a balance among model size, latency, and accuracy. In\nthis work, we propose AE-BERT, an automatic and efficient BERT pruning\nframework with efficient evaluation to select a \"good\" sub-network candidate\n(with high accuracy) given the overall pruning ratio constraints. Our proposed\nmethod requires no human experts experience and achieves a better accuracy\nperformance on many NLP tasks. Our experimental results on General Language\nUnderstanding Evaluation (GLUE) benchmark show that AE-BERT outperforms the\nstate-of-the-art (SOTA) hand-crafted pruning methods on BERT$_{\\mathrm{BASE}}$.\nOn QNLI and RTE, we obtain 75\\% and 42.8\\% more overall pruning ratio while\nachieving higher accuracy. On MRPC, we obtain a 4.6 higher score than the SOTA\nat the same overall pruning ratio of 0.5. On STS-B, we can achieve a 40\\%\nhigher pruning ratio with a very small loss in Spearman correlation compared to\nSOTA hand-crafted pruning methods. Experimental results also show that after\nmodel compression, the inference time of a single BERT$_{\\mathrm{BASE}}$\nencoder on Xilinx Alveo U200 FPGA board has a 1.83$\\times$ speedup compared to\nIntel(R) Xeon(R) Gold 5218 (2.30GHz) CPU, which shows the reasonableness of\ndeploying the proposed method generated subnets of BERT$_{\\mathrm{BASE}}$ model\non computation restricted devices.",
    "descriptor": "",
    "authors": [
      "Shaoyi Huang",
      "Ning Liu",
      "Yueying Liang",
      "Hongwu Peng",
      "Hongjia Li",
      "Dongkuan Xu",
      "Mimi Xie",
      "Caiwen Ding"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.10461"
  },
  {
    "id": "arXiv:2206.10462",
    "title": "The Digital Twin Landscape at the Crossroads of Predictive Maintenance,  Machine Learning and Physics Based Modeling",
    "abstract": "The concept of a digital twin has exploded in popularity over the past\ndecade, yet confusion around its plurality of definitions, its novelty as a new\ntechnology, and its practical applicability still exists, all despite numerous\nreviews, surveys, and press releases. The history of the term digital twin is\nexplored, as well as its initial context in the fields of product life cycle\nmanagement, asset maintenance, and equipment fleet management, operations, and\nplanning. A definition for a minimally viable framework to utilize a digital\ntwin is also provided based on seven essential elements. A brief tour through\nDT applications and industries where DT methods are employed is also outlined.\nThe application of a digital twin framework is highlighted in the field of\npredictive maintenance, and its extensions utilizing machine learning and\nphysics based modeling. Employing the combination of machine learning and\nphysics based modeling to form hybrid digital twin frameworks, may\nsynergistically alleviate the shortcomings of each method when used in\nisolation. Key challenges of implementing digital twin models in practice are\nadditionally discussed. As digital twin technology experiences rapid growth and\nas it matures, its great promise to substantially enhance tools and solutions\nfor intelligent upkeep of complex equipment, are expected to materialize.",
    "descriptor": "\nComments: 21 pages, 5 figures\n",
    "authors": [
      "Brian Kunzer",
      "Mario Berges",
      "Artur Dubrawski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10462"
  },
  {
    "id": "arXiv:2206.10464",
    "title": "Hybridization of evolutionary algorithm and deep reinforcement learning  for multi-objective orienteering optimization",
    "abstract": "Multi-objective orienteering problems (MO-OPs) are classical multi-objective\nrouting problems and have received a lot of attention in the past decades. This\nstudy seeks to solve MO-OPs through a problem-decomposition framework, that is,\na MO-OP is decomposed into a multi-objective knapsack problem (MOKP) and a\ntravelling salesman problem (TSP). The MOKP and TSP are then solved by a\nmulti-objective evolutionary algorithm (MOEA) and a deep reinforcement learning\n(DRL) method, respectively. While the MOEA module is for selecting cities, the\nDRL module is for planning a Hamiltonian path for these cities. An iterative\nuse of these two modules drives the population towards the Pareto front of\nMO-OPs. The effectiveness of the proposed method is compared against NSGA-II\nand NSGA-III on various types of MO-OP instances. Experimental results show\nthat our method exhibits the best performance on almost all the test instances,\nand has shown strong generalization ability.",
    "descriptor": "",
    "authors": [
      "Wei Liu",
      "Rui Wang",
      "Tao Zhang",
      "Kaiwen Li",
      "Wenhua Li",
      "Hisao Ishibuchi"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.10464"
  },
  {
    "id": "arXiv:2206.10465",
    "title": "An Overview of Privacy-enhancing Technologies in Biometric Recognition",
    "abstract": "Privacy-enhancing technologies are technologies that implement fundamental\ndata protection principles. With respect to biometric recognition, different\ntypes of privacy-enhancing technologies have been introduced for protecting\nstored biometric data which are generally classified as sensitive. In this\nregard, various taxonomies and conceptual categorizations have been proposed\nand standardization activities have been carried out. However, these efforts\nhave mainly been devoted to certain sub-categories of privacy-enhancing\ntechnologies and therefore lack generalization. This work provides an overview\nof concepts of privacy-enhancing technologies for biometrics in a unified\nframework. Key aspects and differences between existing concepts are\nhighlighted in detail at each processing step. Fundamental properties and\nlimitations of existing approaches are discussed and related to data protection\ntechniques and principles. Moreover, scenarios and methods for the assessment\nof privacy-enhancing technologies for biometrics are presented. This paper is\nmeant as a point of entry to the field of biometric data protection and is\ndirected towards experienced researchers as well as non-experts.",
    "descriptor": "\nComments: 12 pages, 2 figures\n",
    "authors": [
      "Pietro Melzi",
      "Christian Rathgeb",
      "Ruben Tolosana",
      "Ruben Vera-Rodriguez",
      "Christoph Busch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10465"
  },
  {
    "id": "arXiv:2206.10469",
    "title": "The Privacy Onion Effect: Memorization is Relative",
    "abstract": "Machine learning models trained on private datasets have been shown to leak\ntheir private data. While recent work has found that the average data point is\nrarely leaked, the outlier samples are frequently subject to memorization and,\nconsequently, privacy leakage. We demonstrate and analyse an Onion Effect of\nmemorization: removing the \"layer\" of outlier points that are most vulnerable\nto a privacy attack exposes a new layer of previously-safe points to the same\nattack. We perform several experiments to study this effect, and understand why\nit occurs. The existence of this effect has various consequences. For example,\nit suggests that proposals to defend against memorization without training with\nrigorous privacy guarantees are unlikely to be effective. Further, it suggests\nthat privacy-enhancing technologies such as machine unlearning could actually\nharm the privacy of other users.",
    "descriptor": "",
    "authors": [
      "Nicholas Carlini",
      "Matthew Jagielski",
      "Nicolas Papernot",
      "Andreas Terzis",
      "Florian Tramer",
      "Chiyuan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.10469"
  },
  {
    "id": "arXiv:2206.10471",
    "title": "Twitter conversations predict the daily confirmed COVID-19 cases",
    "abstract": "As of writing this paper, COVID-19 (Coronavirus disease 2019) has spread to\nmore than 220 countries and territories. Following the outbreak, the pandemic's\nseriousness has made people more active on social media, especially on the\nmicroblogging platforms such as Twitter and Weibo. The pandemic-specific\ndiscourse has remained on-trend on these platforms for months now. Previous\nstudies have confirmed the contributions of such socially generated\nconversations towards situational awareness of crisis events. The early\nforecasts of cases are essential to authorities to estimate the requirements of\nresources needed to cope with the outgrowths of the virus. Therefore, this\nstudy attempts to incorporate the public discourse in the design of forecasting\nmodels particularly targeted for the steep-hill region of an ongoing wave. We\npropose a sentiment-involved topic-based methodology for designing multiple\ntime series from publicly available COVID-19 related Twitter conversations. As\na use case, we implement the proposed methodology on Australian COVID-19 daily\ncases and Twitter conversations generated within the country. Experimental\nresults: (i) show the presence of latent social media variables that\nGranger-cause the daily COVID-19 confirmed cases, and (ii) confirm that those\nvariables offer additional prediction capability to forecasting models.\nFurther, the results show that the inclusion of social media variables for\nmodeling introduces 48.83--51.38% improvements on RMSE over the baseline\nmodels. We also release the large-scale COVID-19 specific geotagged global\ntweets dataset, MegaGeoCOV, to the public anticipating that the geotagged data\nof this scale would aid in understanding the conversational dynamics of the\npandemic through other spatial and temporal contexts.",
    "descriptor": "\nComments: Preprint under review at an Elsevier Journal\n",
    "authors": [
      "Rabindra Lamsal",
      "Aaron Harwood",
      "Maria Rodriguez Read"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.10471"
  },
  {
    "id": "arXiv:2206.10472",
    "title": "NorBERT: NetwOrk Representations through BERT for Network Analysis and  Management",
    "abstract": "Deep neural network models have been very successfully applied to Natural\nLanguage Processing (NLP) and Image based tasks. Their application to network\nanalysis and management tasks is just recently being pursued. Our interest is\nin producing deep models that can be effectively generalized to perform well on\nmultiple network tasks in different environments. A major challenge is that\ntraditional deep models often rely on categorical features, but cannot handle\nunseen categorical values. One method for dealing with such problems is to\nlearn contextual embeddings for categorical variables used by deep networks to\nimprove their performance. In this paper, we adapt the NLP pre-training\ntechnique and associated deep model BERT to learn semantically meaningful\nnumerical representations (embeddings) for Fully Qualified Domain Names (FQDNs)\nused in communication networks. We show through a series of experiments that\nsuch an approach can be used to generate models that maintain their\neffectiveness when applied to environments other than the one in which they\nwere trained.",
    "descriptor": "",
    "authors": [
      "Franck Le",
      "Davis Wertheimer",
      "Seraphin Calo",
      "Erich Nahum"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.10472"
  },
  {
    "id": "arXiv:2206.10473",
    "title": "Securing the Future Internet of Things with Post-Quantum Cryptography",
    "abstract": "Traditional and lightweight cryptography primitives and protocols are\ninsecure against quantum attacks. Thus, a real-time application using\ntraditional or lightweight cryptography primitives and protocols does not\nensure full-proof security. Post-quantum Cryptography is important for the\nInternet of Things (IoT) due to its security against Quantum attacks. This\npaper offers a broad literature analysis of post-quantum cryptography for IoT\nnetworks, including the challenges and research directions to adopt in\nreal-time applications. The work draws focus towards post-quantum cryptosystems\nthat are useful for resource-constraint devices. Further, those quantum attacks\nare surveyed, which may occur over traditional and lightweight cryptographic\nprimitives.",
    "descriptor": "\nComments: Accepted version\n",
    "authors": [
      "Adarsh Kumar",
      "Carlo Ottaviani",
      "Sukhpal Singh Gill",
      "Rajkumar Buyya"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.10473"
  },
  {
    "id": "arXiv:2206.10477",
    "title": "Survival Kernets: Scalable and Interpretable Deep Kernel Survival  Analysis with an Accuracy Guarantee",
    "abstract": "Kernel survival analysis models estimate individual survival distributions\nwith the help of a kernel function, which measures the similarity between any\ntwo data points. Such a kernel function can be learned using deep kernel\nsurvival models. In this paper, we present a new deep kernel survival model\ncalled a survival kernet, which scales to large datasets in a manner that is\namenable to model interpretation and also theoretical analysis. Specifically,\nthe training data are partitioned into clusters based on a recently developed\ntraining set compression scheme for classification and regression called kernel\nnetting that we extend to the survival analysis setting. At test-time, each\ndata point is represented as a weighted combination of these clusters, and each\nsuch cluster can be visualized. For a special case of survival kernets, we\nestablish a finite-sample error bound on predicted survival distributions that\nis, up to a log factor, optimal. Whereas scalability at test time is achieved\nusing the aforementioned kernel netting compression strategy, scalability\nduring training is achieved by a warm-start procedure based on tree ensembles\nsuch as XGBoost and a heuristic approach to accelerating neural architecture\nsearch. On three standard survival analysis datasets of varying sizes (up to\nroughly 3 million data points), we show that survival kernets are highly\ncompetitive with the best of baselines tested in terms of concordance index.\nOur code is available at: https://github.com/georgehc/survival-kernets",
    "descriptor": "",
    "authors": [
      "George H. Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.10477"
  },
  {
    "id": "arXiv:2206.10480",
    "title": "Learning to Estimate and Refine Fluid Motion with Physical Dynamics",
    "abstract": "Extracting information on fluid motion directly from images is challenging.\nFluid flow represents a complex dynamic system governed by the Navier-Stokes\nequations. General optical flow methods are typically designed for rigid body\nmotion, and thus struggle if applied to fluid motion estimation directly.\nFurther, optical flow methods only focus on two consecutive frames without\nutilising historical temporal information, while the fluid motion (velocity\nfield) can be considered a continuous trajectory constrained by time-dependent\npartial differential equations (PDEs). This discrepancy has the potential to\ninduce physically inconsistent estimations. Here we propose an unsupervised\nlearning based prediction-correction scheme for fluid flow estimation. An\nestimate is first given by a PDE-constrained optical flow predictor, which is\nthen refined by a physical based corrector. The proposed approach outperforms\noptical flow methods and shows competitive results compared to existing\nsupervised learning based methods on a benchmark dataset. Furthermore, the\nproposed approach can generalize to complex real-world fluid scenarios where\nground truth information is effectively unknowable. Finally, experiments\ndemonstrate that the physical corrector can refine flow estimates by mimicking\nthe operator splitting method commonly utilised in fluid dynamical simulation.",
    "descriptor": "",
    "authors": [
      "Mingrui Zhang",
      "Jianhong Wang",
      "James Tlhomole",
      "Matthew D. Piggott"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.10480"
  },
  {
    "id": "arXiv:2206.10485",
    "title": "Optimal homotopy reconstruction results \u00e0 la Niyogi, Smale, and  Weinberger",
    "abstract": "In this article we show that the proof of the homotopy reconstruction result\nby Niyogi, Smale, and Weinberger can be streamlined considerably using\nFederer's work on the reach and several geometric observations. While Niyogi,\nSmale, and Weinberger restricted themselves to C2 manifolds with positive\nreach, our proof extends to sets S of positive reach.\nThe sample we consider does not have to lie directly on the set of positive\nreach. Instead, we assume that the two one-sided Hausdorff distances (delta and\nepsilon) -- between the sample P to the set S, are bounded. We provide explicit\nbounds in terms of epsilon and delta, that guarantee that there exists a\nparameter r such that the union of balls of radii r centered on the points of\nthe sample P deformation retracts to S. We provide even better bounds for the\nmanifold case. In both cases, our bounds improve considerably on the\nstate-of-the-art in almost all settings. In fact the bounds are optimal.",
    "descriptor": "\nComments: 21 pages, 12 figures\n",
    "authors": [
      "Dominique Attali",
      "Hana Dal Poz Kou\u0159imsk\u00e1",
      "Christopher Fillmore",
      "Ishika Ghosh",
      "Andr\u00e9 Lieutier",
      "Elizabeth Stephenson",
      "Mathijs Wintraecken"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Algebraic Topology (math.AT)"
    ],
    "url": "https://arxiv.org/abs/2206.10485"
  },
  {
    "id": "arXiv:2206.10491",
    "title": "Bi-Calibration Networks for Weakly-Supervised Video Representation  Learning",
    "abstract": "The leverage of large volumes of web videos paired with the searched queries\nor surrounding texts (e.g., title) offers an economic and extensible\nalternative to supervised video representation learning. Nevertheless, modeling\nsuch weakly visual-textual connection is not trivial due to query polysemy\n(i.e., many possible meanings for a query) and text isomorphism (i.e., same\nsyntactic structure of different text). In this paper, we introduce a new\ndesign of mutual calibration between query and text to boost weakly-supervised\nvideo representation learning. Specifically, we present Bi-Calibration Networks\n(BCN) that novelly couples two calibrations to learn the amendment from text to\nquery and vice versa. Technically, BCN executes clustering on all the titles of\nthe videos searched by an identical query and takes the centroid of each\ncluster as a text prototype. The query vocabulary is built directly on query\nwords. The video-to-text/video-to-query projections over text prototypes/query\nvocabulary then start the text-to-query or query-to-text calibration to\nestimate the amendment to query or text. We also devise a selection scheme to\nbalance the two corrections. Two large-scale web video datasets paired with\nquery and title for each video are newly collected for weakly-supervised video\nrepresentation learning, which are named as YOVO-3M and YOVO-10M, respectively.\nThe video features of BCN learnt on 3M web videos obtain superior results under\nlinear model protocol on downstream tasks. More remarkably, BCN trained on the\nlarger set of 10M web videos with further fine-tuning leads to 1.6%, and 1.8%\ngains in top-1 accuracy on Kinetics-400, and Something-Something V2 datasets\nover the state-of-the-art TDN, and ACTION-Net methods with ImageNet\npre-training. Source code and datasets are available at\n\\url{https://github.com/FuchenUSTC/BCN}.",
    "descriptor": "",
    "authors": [
      "Fuchen Long",
      "Ting Yao",
      "Zhaofan Qiu",
      "Xinmei Tian",
      "Jiebo Luo",
      "Tao Mei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2206.10491"
  },
  {
    "id": "arXiv:2206.10495",
    "title": "Online Coordination: Methods and Comparative Case Studies of Coordinated  Groups across Four Events in the United States",
    "abstract": "Coordinated groups of user accounts working together in online social media\ncan be used to manipulate the online discourse and thus is an important area of\nstudy. In this study, we work towards a general theory of coordination. There\nare many ways to coordinate groups online: semantic, social, referral and many\nmore. Each represents a coordination dimension, where the more dimensions of\ncoordination are present for one event, the stronger the coordination present.\nWe build on existing approaches that detect coordinated groups by identifying\nhigh levels of synchronized actions within a specified time window. A key\nconcern with this approach is the selection of the time window. We propose a\nmethod that selects the optimal window size to accurately capture local\ncoordination while avoiding the capture of coincidental synchronicity. With\nthis enhanced method of coordination detection, we perform a comparative study\nacross four events: US Elections Primaries 2020, Reopen America 2020, Capitol\nRiots 2021 and COVID Vaccine Release 2021. Herein, we explore the following\nthree dimensions of coordination for each event -- semantic, referral and\nsocial coordination -- and perform group and user analysis within and among the\nevents. This allows us to expose different user coordination behavior patterns\nand identify narratives and user support themes, hence estimating the degree\nand theme of coordination.",
    "descriptor": "",
    "authors": [
      "Lynnette Hui Xian Ng",
      "Kathleen M. Carley"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.10495"
  },
  {
    "id": "arXiv:2206.10498",
    "title": "Large Language Models Still Can't Plan (A Benchmark for LLMs on Planning  and Reasoning about Change)",
    "abstract": "The recent advances in large language models (LLMs) have transformed the\nfield of natural language processing (NLP). From GPT-3 to PaLM, the\nstate-of-the-art performance on natural language tasks is being pushed forward\nwith every new large language model. Along with natural language abilities,\nthere has been a significant interest in understanding whether such models,\ntrained on enormous amounts of data, exhibit reasoning capabilities. Hence\nthere has been interest in developing benchmarks for various reasoning tasks\nand the preliminary results from testing LLMs over such benchmarks seem mostly\npositive. However, the current benchmarks are relatively simplistic and the\nperformance over these benchmarks cannot be used as an evidence to support,\nmany a times outlandish, claims being made about LLMs' reasoning capabilities.\nAs of right now, these benchmarks only represent a very limited set of simple\nreasoning tasks and we need to look at more sophisticated reasoning problems if\nwe are to measure the true limits of such LLM-based systems. With this\nmotivation, we propose an extensible assessment framework to test the abilities\nof LLMs on a central aspect of human intelligence, which is reasoning about\nactions and change. We provide multiple test cases that are more involved than\nany of the previously established reasoning benchmarks and each test case\nevaluates a certain aspect of reasoning about actions and change. Initial\nevaluation results on the base version of GPT-3 (Davinci), showcase subpar\nperformance on these benchmarks.",
    "descriptor": "",
    "authors": [
      "Karthik Valmeekam",
      "Alberto Olmo",
      "Sarath Sreedharan",
      "Subbarao Kambhampati"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.10498"
  },
  {
    "id": "arXiv:2206.10503",
    "title": "On a certified VMS-Smagorinsky Reduced Basis model with LPS pressure  stabilisation",
    "abstract": "In this work we introduce a certified Reduced Basis VMS-Smagorinsky\nturbulence model with local projection stabilisation (LPS) on the pressure. We\nprove its stability for Taylor-Hood discretisations of velocity-pressure. We\nconstruct an \\textit{a posteriori} error estimator for the snapshot selection\nthrough a Greedy algorithm, based on the Brezzi-Rappaz-Raviart theory of\napproximation of non-singular branches of non-linear PDEs. The Empirical\nInterpolation Method (EIM) is used for the approximation of the non-linear\nterms. We present some numerical tests in which we show an improved speedup on\nthe computation of the reduced basis problem with the LPS pressure\nstabilisation, with respect to the method of using pressure supremizers.",
    "descriptor": "",
    "authors": [
      "Tom\u00e1s Chac\u00f3n Rebollo",
      "Enrique Delgado \u00c1vila",
      "Macarena G\u00f3mez M\u00e1rmol"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.10503"
  },
  {
    "id": "arXiv:2206.10504",
    "title": "A Theory of Sub-Barcodes",
    "abstract": "From the work of Bauer and Lesnick, it is known that there is no functor from\nthe category of pointwise finite-dimensional persistence modules to the\ncategory of barcodes and overlap matchings. In this work, we introduce\nsub-barcodes and show that there is a functor from the category of\nfactorizations of persistence module homomorphisms to a poset of barcodes\nordered by the sub-barcode relation. Sub-barcodes and factorizations provide a\nlooser alternative to bottleneck matchings and interleavings that can give\nstrong guarantees in a number of settings that arise naturally in topological\ndata analysis. The main use of sub-barcodes is to make strong claims about an\nunknown barcode in the absence of an interleaving. For example, given only\nupper and lower bounds $g\\geq f\\geq \\ell$ of an unknown real-valued function\n$f$, a sub-barcode associated with $f$ can be constructed from $\\ell$ and $g$\nalone. We propose a theory of sub-barcodes and observe that the subobjects in\nthe category of functors from intervals to matchings naturally correspond to\nsub-barcodes.",
    "descriptor": "",
    "authors": [
      "Oliver A. Chubet",
      "Kirk P. Gardner",
      "Donald R. Sheehy"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Algebraic Topology (math.AT)"
    ],
    "url": "https://arxiv.org/abs/2206.10504"
  },
  {
    "id": "arXiv:2206.10516",
    "title": "Roadmap to Autonomous Surgery -- A Framework to Surgical Autonomy",
    "abstract": "Robotic surgery has increased the domain of surgeries possible. Several\nexamples of partial surgical automation have been seen in the past decade. We\nbreak down the path of automation tasks into features required and provide a\nchecklist that can help reach higher levels of surgical automation. Finally, we\ndiscuss the current challenges and advances required to make this happen.",
    "descriptor": "\nComments: 6 Pages, 4 figures, 2 Tables\n",
    "authors": [
      "Amritpal Singh"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.10516"
  },
  {
    "id": "arXiv:2206.10517",
    "title": "What Goes Around: Leveraging a Constant-curvature Motion Constraint in  Radar Odometry",
    "abstract": "This paper presents a method that leverages vehicle motion constraints to\nrefine data associations in a point-based radar odometry system. By using the\nstrong prior on how a non-holonomic robot is constrained to move smoothly\nthrough its environment, we develop the necessary framework to estimate\nego-motion from a single landmark association rather than considering all of\nthese correspondences at once. This allows for informed outlier detection of\npoor matches that are a dominant source of pose estimate error. By refining the\nsubset of matched landmarks, we see an absolute decrease of 2.15% (from 4.68%\nto 2.53%) in translational error, approximately halving the error in odometry\n(reducing by 45.94%) than when using the full set of correspondences. This\ncontribution is relevant to other point-based odometry implementations that\nrely on a range sensor and provides a lightweight and interpretable means of\nincorporating vehicle dynamics for ego-motion estimation.",
    "descriptor": "\nComments: Accepted for RA-L\n",
    "authors": [
      "Roberto Aldera",
      "Matthew Gadd",
      "Daniele De Martini",
      "Paul Newman"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.10517"
  },
  {
    "id": "arXiv:2206.10518",
    "title": "Overcoming High Frequency Limitations of Current-Mode Control Using a  Control Conditioning Approach -- Part I: Modeling and Analysis",
    "abstract": "Current-mode control is one of the most popular controller strategies for\npower converters. With the advent of wide bandgap devices including GaN and\nSiC, higher switching frequencies have become more viable at higher power\nbecause of lower switching losses. However, the advantage of higher switching\nfrequency for faster, higher bandwidth control is squandered because of current\nsensor interference. We present a framework for characterizing and analyzing\nthis interference as uncertainties to the controller model. These uncertainties\nintroduce additional dynamics and nonlinearity that can result in instability\nand poor transient performance of the current control loop. In this paper, we\nprovide a model framework based on a new control conditioning approach that\nguarantees global stability and a strategy for optimizing transient\nperformance. In Part II of this paper series, we present the analysis, design,\nand hardware validation of three effective solutions.",
    "descriptor": "",
    "authors": [
      "Xiaofan Cui",
      "Al-Thaddeus Avestruz"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.10518"
  },
  {
    "id": "arXiv:2206.10520",
    "title": "SFace: Privacy-friendly and Accurate Face Recognition using Synthetic  Data",
    "abstract": "Recent deep face recognition models proposed in the literature utilized\nlarge-scale public datasets such as MS-Celeb-1M and VGGFace2 for training very\ndeep neural networks, achieving state-of-the-art performance on mainstream\nbenchmarks. Recently, many of these datasets, e.g., MS-Celeb-1M and VGGFace2,\nare retracted due to credible privacy and ethical concerns. This motivates this\nwork to propose and investigate the feasibility of using a privacy-friendly\nsynthetically generated face dataset to train face recognition models. Towards\nthis end, we utilize a class-conditional generative adversarial network to\ngenerate class-labeled synthetic face images, namely SFace. To address the\nprivacy aspect of using such data to train a face recognition model, we provide\nextensive evaluation experiments on the identity relation between the synthetic\ndataset and the original authentic dataset used to train the generative model.\nOur reported evaluation proved that associating an identity of the authentic\ndataset to one with the same class label in the synthetic dataset is hardly\npossible. We also propose to train face recognition on our privacy-friendly\ndataset, SFace, using three different learning strategies, multi-class\nclassification, label-free knowledge transfer, and combined learning of\nmulti-class classification and knowledge transfer. The reported evaluation\nresults on five authentic face benchmarks demonstrated that the\nprivacy-friendly synthetic dataset has high potential to be used for training\nface recognition models, achieving, for example, a verification accuracy of\n91.87\\% on LFW using multi-class classification and 99.13\\% using the combined\nlearning strategy.",
    "descriptor": "",
    "authors": [
      "Fadi Boutros",
      "Marco Huber",
      "Patrick Siebke",
      "Tim Rieber",
      "Naser Damer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10520"
  },
  {
    "id": "arXiv:2206.10523",
    "title": "Overcoming High Frequency Limitations of Current-Mode Control Using a  Control Conditioning Approach -- Part II: Implementation and Hardware",
    "abstract": "This article is the second part of a paper series about interference in\nextremum (i.e., peak or valley) current-mode control, which applies to both\nfixed and variable switching frequency power converters. Specifically, this\npart presents three control conditioning methods that mitigate the adverse\neffect of interference. These methods are new ways to use: (i) slope\ncompensation; (ii) low-pass filtering; and (iii) the phenomenon of\ncomparator-overdrive-delay, for control conditioning. The stability criterion,\nclosed-loop dynamics, and transient performance are derived with mathematical\nrigor for each method. The design tradeoffs are illustrated, discussed, and\ncompared. The effectiveness of all three methods are demonstrated and validated\nin hardware using a power converter operating at multi-MHz switching\nfrequencies.",
    "descriptor": "",
    "authors": [
      "Xiaofan Cui",
      "Al-Thaddeus Avestruz"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.10523"
  },
  {
    "id": "arXiv:2206.10524",
    "title": "Lyapunov Density Models: Constraining Distribution Shift in  Learning-Based Control",
    "abstract": "Learned models and policies can generalize effectively when evaluated within\nthe distribution of the training data, but can produce unpredictable and\nerroneous outputs on out-of-distribution inputs. In order to avoid distribution\nshift when deploying learning-based control algorithms, we seek a mechanism to\nconstrain the agent to states and actions that resemble those that it was\ntrained on. In control theory, Lyapunov stability and control-invariant sets\nallow us to make guarantees about controllers that stabilize the system around\nspecific states, while in machine learning, density models allow us to estimate\nthe training data distribution. Can we combine these two concepts, producing\nlearning-based control algorithms that constrain the system to in-distribution\nstates using only in-distribution actions? In this work, we propose to do this\nby combining concepts from Lyapunov stability and density estimation,\nintroducing Lyapunov density models: a generalization of control Lyapunov\nfunctions and density models that provides guarantees on an agent's ability to\nstay in-distribution over its entire trajectory.",
    "descriptor": "",
    "authors": [
      "Katie Kang",
      "Paula Gradu",
      "Jason Choi",
      "Michael Janner",
      "Claire Tomlin",
      "Sergey Levine"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.10524"
  },
  {
    "id": "arXiv:2206.10525",
    "title": "Three-way optimization of privacy and utility of location data",
    "abstract": "With the recent bloom of data and the drive towards an information-based\nsociety, the urge of and the advancements in data analytics is surging like\nnever before. And with this, the risks of privacy violation of various kinds\nare also increasing manifold. Most of the methods to mitigate the privacy risks\nfor location data resort to adding some noise to the location, like the planar\nLaplace used to achieve geo-indistinguishability. However, the noise should be\ncalibrated carefully, taking into account the implications for utility, because\nit is far from ideal for the service providers to completely lose the utility\nof the collected data succumbing to the privacy requirements of the users.\nSimilarly, the quality of service for the users should be optimized with their\npersonalized needs of privacy protection used to shield their sensitive\ninformation. In this paper, we address this age-old battle between privacy and\nutility from three ends: privacy of the users' data, the quality of service\n(QoS) received by them in exchange for sharing their privatized data, and the\nstatistical utility of the privatized data for the service providers who wish\nto perform various kinds of analysis and research on the data collected from\nthe users. We propose a method to produce a geo-indistinguishable\nlocation-privacy mechanism that advances to optimize simultaneously between the\nlevel of privacy attained, the QoS, and the statistical utility achieved by the\nobfuscated data. We illustrate the soundness of this three-way privacy-utility\noptimization mechanism both analytically and with experiments. Apart from the\nnovelty of the proposed method, this work is aimed to engender an analytical\nperspective to bridge between geo-indistinguishable location-privacy, QoS, and\nstatistical utilities used in standard data analytics, from an information\ntheoretical, probabilistic, and statistical perspective.",
    "descriptor": "",
    "authors": [
      "Sayan Biswas",
      "Catuscia Palamidessi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2206.10525"
  },
  {
    "id": "arXiv:2206.10526",
    "title": "QuantFace: Towards Lightweight Face Recognition by Synthetic Data  Low-bit Quantization",
    "abstract": "Deep learning-based face recognition models follow the common trend in deep\nneural networks by utilizing full-precision floating-point networks with high\ncomputational costs. Deploying such networks in use-cases constrained by\ncomputational requirements is often infeasible due to the large memory required\nby the full-precision model. Previous compact face recognition approaches\nproposed to design special compact architectures and train them from scratch\nusing real training data, which may not be available in a real-world scenario\ndue to privacy concerns. We present in this work the QuantFace solution based\non low-bit precision format model quantization. QuantFace reduces the required\ncomputational cost of the existing face recognition models without the need for\ndesigning a particular architecture or accessing real training data. QuantFace\nintroduces privacy-friendly synthetic face data to the quantization process to\nmitigate potential privacy concerns and issues related to the accessibility to\nreal training data. Through extensive evaluation experiments on seven\nbenchmarks and four network architectures, we demonstrate that QuantFace can\nsuccessfully reduce the model size up to 5x while maintaining, to a large\ndegree, the verification performance of the full-precision model without\naccessing real training datasets.",
    "descriptor": "\nComments: Accepted ICPR 2022\n",
    "authors": [
      "Fadi Boutros",
      "Naser Damer",
      "Arjan Kuijper"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10526"
  },
  {
    "id": "arXiv:2206.10531",
    "title": "Neural Transformers for Intraductal Papillary Mucosal Neoplasms (IPMN)  Classification in MRI images",
    "abstract": "Early detection of precancerous cysts or neoplasms, i.e., Intraductal\nPapillary Mucosal Neoplasms (IPMN), in pancreas is a challenging and complex\ntask, and it may lead to a more favourable outcome. Once detected, grading\nIPMNs accurately is also necessary, since low-risk IPMNs can be under\nsurveillance program, while high-risk IPMNs have to be surgically resected\nbefore they turn into cancer. Current standards (Fukuoka and others) for IPMN\nclassification show significant intra- and inter-operator variability, beside\nbeing error-prone, making a proper diagnosis unreliable. The established\nprogress in artificial intelligence, through the deep learning paradigm, may\nprovide a key tool for an effective support to medical decision for pancreatic\ncancer. In this work, we follow this trend, by proposing a novel AI-based IPMN\nclassifier that leverages the recent success of transformer networks in\ngeneralizing across a wide variety of tasks, including vision ones. We\nspecifically show that our transformer-based model exploits pre-training better\nthan standard convolutional neural networks, thus supporting the sought\narchitectural universalism of transformers in vision, including the medical\nimage domain and it allows for a better interpretation of the obtained results.",
    "descriptor": "",
    "authors": [
      "Federica Proietto Salanitri",
      "Giovanni Bellitto",
      "Simone Palazzo",
      "Ismail Irmakci",
      "Michael B. Wallace",
      "Candice W. Bolan",
      "Megan Engels",
      "Sanne Hoogenboom",
      "Marco Aldinucci",
      "Ulas Bagci",
      "Daniela Giordano",
      "Concetto Spampinato"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.10531"
  },
  {
    "id": "arXiv:2206.10532",
    "title": "Terabit Indoor Laser-Based Wireless Communications: LiFi 2.0 for 6G",
    "abstract": "This paper provides a summary of available technologies required for\nimplementing indoor laser-based wireless networks capable of achieving\naggregate data-rates of terabits per second as widely accepted as a sixth\ngeneration (6G) key performance indicator. The main focus of this paper is on\nthe technologies supporting the near infrared region of the optical spectrum.\nThe main challenges in the design of the transmitter and receiver systems and\ncommunication/networking schemes are identified and new insights are provided.\nThis paper also covers the previous and recent standards as well as industrial\napplications for optical wireless communications (OWC) and LiFi.",
    "descriptor": "\nComments: 7 pages, 7 figures\n",
    "authors": [
      "Mohammad Dehghani Soltani",
      "Hossein Kazemi",
      "Elham Sarbazi",
      "Ahmad Adnan Qidan",
      "Barzan Yosuf",
      "Sanaa Mohamed",
      "Ravinder Singh",
      "Bela Berde",
      "Dominique Chiaroni",
      "Bastien B\u00e9chadergue",
      "Fathi Abdeldayem",
      "Hardik Soni",
      "Jose Tabu",
      "Micheline Perrufel",
      "Nikola Serafimovski",
      "Taisir E. H. El-Gorashi",
      "Jaafar Elmirghani",
      "Richard Penty",
      "Ian H. White",
      "Harald Haas",
      "Majid Safari"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.10532"
  },
  {
    "id": "arXiv:2206.10533",
    "title": "RRT and RRT* Using Vehicle Dynamics",
    "abstract": "The trajectory derived from RRT and RRT* is zagged. A holonomic drive is able\nto follow this trajectory. But real-life vehicle which has dynamical\nconstraints cannot follow this trajectory. In this work, we are going to modify\nthe RRT and RRT* algorithm to generate a trajectory that a vehicle with\ndynamical constraint can follow. The continuous nature of steering control and\nacceleration control in a real-world vehicle introduces the complexity in its\nmodel. To introduce constraint in the vehicle's motion, while reducing the\nnumber of control and hence complexity, we are modeling our vehicle as a Dubins\ncar. A Dubins car has only three controls (turning left, turning right, and\nmoving forward) with a fixed velocity which makes our model simple. We use\ndubins curve (path that dubins car can follow) to trace the trajectory in RRT\nand RRT* algorithm.",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Abhish Khanal"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.10533"
  },
  {
    "id": "arXiv:2206.10535",
    "title": "EpiGRAF: Rethinking training of 3D GANs",
    "abstract": "A very recent trend in generative modeling is building 3D-aware generators\nfrom 2D image collections. To induce the 3D bias, such models typically rely on\nvolumetric rendering, which is expensive to employ at high resolutions. During\nthe past months, there appeared more than 10 works that address this scaling\nissue by training a separate 2D decoder to upsample a low-resolution image (or\na feature tensor) produced from a pure 3D generator. But this solution comes at\na cost: not only does it break multi-view consistency (i.e. shape and texture\nchange when the camera moves), but it also learns the geometry in a low\nfidelity. In this work, we show that it is possible to obtain a high-resolution\n3D generator with SotA image quality by following a completely different route\nof simply training the model patch-wise. We revisit and improve this\noptimization scheme in two ways. First, we design a location- and scale-aware\ndiscriminator to work on patches of different proportions and spatial\npositions. Second, we modify the patch sampling strategy based on an annealed\nbeta distribution to stabilize training and accelerate the convergence. The\nresulted model, named EpiGRAF, is an efficient, high-resolution, pure 3D\ngenerator, and we test it on four datasets (two introduced in this work) at\n$256^2$ and $512^2$ resolutions. It obtains state-of-the-art image quality,\nhigh-fidelity geometry and trains ${\\approx} 2.5 \\times$ faster than the\nupsampler-based counterparts. Project website:\nhttps://universome.github.io/epigraf.",
    "descriptor": "\nComments: Project website: this https URL\n",
    "authors": [
      "Ivan Skorokhodov",
      "Sergey Tulyakov",
      "Yiqun Wang",
      "Peter Wonka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10535"
  },
  {
    "id": "arXiv:2206.10536",
    "title": "HealNet -- Self-Supervised Acute Wound Heal-Stage Classification",
    "abstract": "Identifying, tracking, and predicting wound heal-stage progression is a\nfundamental task towards proper diagnosis, effective treatment, facilitating\nhealing, and reducing pain. Traditionally, a medical expert might observe a\nwound to determine the current healing state and recommend treatment. However,\nsourcing experts who can produce such a diagnosis solely from visual indicators\ncan be time-consuming and expensive. In addition, lesions may take several\nweeks to undergo the healing process, demanding resources to monitor and\ndiagnose continually. Automating this task can be challenging; datasets that\nfollow wound progression from onset to maturation are small, rare, and often\ncollected without computer vision in mind. To tackle these challenges, we\nintroduce a self-supervised learning scheme composed of (a) learning embeddings\nof wound's temporal dynamics, (b) clustering for automatic stage discovery, and\n(c) fine-tuned classification. The proposed self-supervised and flexible\nlearning framework is biologically inspired and trained on a small dataset with\nzero human labeling. The HealNet framework achieved high pre-text and\ndownstream classification accuracy; when evaluated on held-out test data,\nHealNet achieved 94.2% pre-text accuracy and 93.8% heal-stage classification\naccuracy.",
    "descriptor": "",
    "authors": [
      "H\u00e9ctor Carri\u00f3n",
      "Mohammad Jafari",
      "Hsin-Ya Yang",
      "Roslyn Rivkah",
      "Marco Rolandi",
      "Marcella Gomez",
      "Narges Norouzi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.10536"
  },
  {
    "id": "arXiv:2206.10540",
    "title": "Rethinking Symbolic Regression Datasets and Benchmarks for Scientific  Discovery",
    "abstract": "This paper revisits datasets and evaluation criteria for Symbolic Regression,\na task of expressing given data using mathematical equations, specifically\nfocused on its potential for scientific discovery. Focused on a set of formulas\nused in the existing datasets based on Feynman Lectures on Physics, we recreate\n120 datasets to discuss the performance of symbolic regression for scientific\ndiscovery (SRSD). For each of the 120 SRSD datasets, we carefully review the\nproperties of the formula and its variables to design reasonably realistic\nsampling range of values so that our new SRSD datasets can be used for\nevaluating the potential of SRSD such as whether or not an SR method con\n(re)discover physical laws from such datasets. As an evaluation metric, we also\npropose to use normalized edit distances between a predicted equation and the\nground-truth equation trees. While existing metrics are either binary or errors\nbetween the target values and an SR model's predicted values for a given input,\nnormalized edit distances evaluate a sort of similarity between the\nground-truth and predicted equation trees. We have conducted experiments on our\nnew SRSD datasets using five state-of-the-art SR methods in SRBench and a\nsimple baseline based on a recent Transformer architecture. The results show\nthat we provide a more realistic performance evaluation and open up a new\nmachine learning-based approach for scientific discovery. Our datasets and code\nrepository are publicly available.",
    "descriptor": "\nComments: Preprint. Code and datasets are available at this https URL this https URL this https URL this https URL\n",
    "authors": [
      "Yoshitomo Matsubara",
      "Naoya Chiba",
      "Ryo Igarashi",
      "Tatsunori Taniai",
      "Yoshitaka Ushiku"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2206.10540"
  },
  {
    "id": "arXiv:2206.10544",
    "title": "Multi-UAV Planning for Cooperative Wildfire Coverage and Tracking with  Quality-of-Service Guarantees",
    "abstract": "In recent years, teams of robot and Unmanned Aerial Vehicles (UAVs) have been\ncommissioned by researchers to enable accurate, online wildfire coverage and\ntracking. While the majority of prior work focuses on the coordination and\ncontrol of such multi-robot systems, to date, these UAV teams have not been\ngiven the ability to reason about a fire's track (i.e., location and\npropagation dynamics) to provide performance guarantee over a time horizon.\nMotivated by the problem of aerial wildfire monitoring, we propose a predictive\nframework which enables cooperation in multi-UAV teams towards collaborative\nfield coverage and fire tracking with probabilistic performance guarantee. Our\napproach enables UAVs to infer the latent fire propagation dynamics for\ntime-extended coordination in safety-critical conditions. We derive a set of\nnovel, analytical temporal, and tracking-error bounds to enable the UAV-team to\ndistribute their limited resources and cover the entire fire area according to\nthe case-specific estimated states and provide a probabilistic performance\nguarantee. Our results are not limited to the aerial wildfire monitoring\ncase-study and are generally applicable to problems, such as search-and-rescue,\ntarget tracking and border patrol. We evaluate our approach in simulation and\nprovide demonstrations of the proposed framework on a physical multi-robot\ntestbed to account for real robot dynamics and restrictions. Our quantitative\nevaluations validate the performance of our method accumulating 7.5x and 9.0x\nsmaller tracking-error than state-of-the-art model-based and reinforcement\nlearning benchmarks, respectively.",
    "descriptor": "\nComments: To appear in the journal of Autonomous Agents and Multi-Agent Systems (AAMAS)\n",
    "authors": [
      "Esmaeil Seraj",
      "Andrew Silva",
      "Matthew Gombolay"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.10544"
  },
  {
    "id": "arXiv:2206.10545",
    "title": "The Impact of Visibility on the Right to Opt-out of Sale under CCPA",
    "abstract": "The California Consumer Protection Act (CCPA) gives users the right to\nopt-out of sale of their personal information, but prior work has found that\nopt-out mechanisms provided under this law result in very low opt-out rates.\nPrivacy signals offer a solution for users who are aware of their rights and\nare willing to proactively take steps to enable privacy-enhancing tools, but\nthis work findsthat many users are not aware of their rights under CCPA and\nthat current opt-out rates are very low. We therefore explore an alternative\napproach to enhancing privacy under CCPA: increasing the visibility of opt-out\nof sale mechanisms. For this purpose, we design and implement CCPA Opt-out\nAssistant (COA), a browser extension that automatically detects when websites\nsell personal information and presents users with a visible, standardized\nbanner that links to the opt-out of sale mechanism for the website. We conduct\nan online user study with 54 participants that finds that these banners\nsignificantly increases the rate at which users opt-out of sale of their\npersonal information. Participants also report less difficulty opting-out and\nmore satisfaction with opt-out mechanisms compared to the native mechanisms\ncurrently provided by websites. Our results suggest that effective privacy\nregulation depends on imposing clear, enforceable visibility standards, and\nthat CCPA's requirements for opt-out of sale mechanisms fall short.",
    "descriptor": "",
    "authors": [
      "Aden Siebel",
      "Eleanor Birrell"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Cryptography and Security (cs.CR)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.10545"
  },
  {
    "id": "arXiv:2206.10546",
    "title": "FedHiSyn: A Hierarchical Synchronous Federated Learning Framework for  Resource and Data Heterogeneity",
    "abstract": "Federated Learning (FL) enables training a global model without sharing the\ndecentralized raw data stored on multiple devices to protect data privacy. Due\nto the diverse capacity of the devices, FL frameworks struggle to tackle the\nproblems of straggler effects and outdated models. In addition, the data\nheterogeneity incurs severe accuracy degradation of the global model in the FL\ntraining process. To address aforementioned issues, we propose a hierarchical\nsynchronous FL framework, i.e., FedHiSyn. FedHiSyn first clusters all available\ndevices into a small number of categories based on their computing capacity.\nAfter a certain interval of local training, the models trained in different\ncategories are simultaneously uploaded to a central server. Within a single\ncategory, the devices communicate the local updated model weights to each other\nbased on a ring topology. As the efficiency of training in the ring topology\nprefers devices with homogeneous resources, the classification based on the\ncomputing capacity mitigates the impact of straggler effects. Besides, the\ncombination of the synchronous update of multiple categories and the device\ncommunication within a single category help address the data heterogeneity\nissue while achieving high accuracy. We evaluate the proposed framework based\non MNIST, EMNIST, CIFAR10 and CIFAR100 datasets and diverse heterogeneous\nsettings of devices. Experimental results show that FedHiSyn outperforms six\nbaseline methods, e.g., FedAvg, SCAFFOLD, and FedAT, in terms of training\naccuracy and efficiency.",
    "descriptor": "\nComments: 10 pages, to appear in ICPP'2022\n",
    "authors": [
      "Guanghao Li",
      "Yue Hu",
      "Miao Zhang",
      "Ji Liu",
      "Quanjun Yin",
      "Yong Peng",
      "Dejing Dou"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.10546"
  },
  {
    "id": "arXiv:2206.10550",
    "title": "(Certified!!) Adversarial Robustness for Free!",
    "abstract": "In this paper we show how to achieve state-of-the-art certified adversarial\nrobustness to 2-norm bounded perturbations by relying exclusively on\noff-the-shelf pretrained models. To do so, we instantiate the denoised\nsmoothing approach of Salman et al. by combining a pretrained denoising\ndiffusion probabilistic model and a standard high-accuracy classifier. This\nallows us to certify 71% accuracy on ImageNet under adversarial perturbations\nconstrained to be within a 2-norm of 0.5, an improvement of 14 percentage\npoints over the prior certified SoTA using any approach, or an improvement of\n30 percentage points over denoised smoothing. We obtain these results using\nonly pretrained diffusion models and image classifiers, without requiring any\nfine tuning or retraining of model parameters.",
    "descriptor": "",
    "authors": [
      "Nicholas Carlini",
      "Florian Tramer",
      "Krishnamurthy",
      "Dvijotham",
      "J. Zico Kolter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.10550"
  },
  {
    "id": "arXiv:2206.10552",
    "title": "Vicinity Vision Transformer",
    "abstract": "Vision transformers have shown great success on numerous computer vision\ntasks. However, its central component, softmax attention, prohibits vision\ntransformers from scaling up to high-resolution images, due to both the\ncomputational complexity and memory footprint being quadratic. Although linear\nattention was introduced in natural language processing (NLP) tasks to mitigate\na similar issue, directly applying existing linear attention to vision\ntransformers may not lead to satisfactory results. We investigate this problem\nand find that computer vision tasks focus more on local information compared\nwith NLP tasks. Based on this observation, we present a Vicinity Attention that\nintroduces a locality bias to vision transformers with linear complexity.\nSpecifically, for each image patch, we adjust its attention weight based on its\n2D Manhattan distance measured by its neighbouring patches. In this case, the\nneighbouring patches will receive stronger attention than far-away patches.\nMoreover, since our Vicinity Attention requires the token length to be much\nlarger than the feature dimension to show its efficiency advantages, we further\npropose a new Vicinity Vision Transformer (VVT) structure to reduce the feature\ndimension without degenerating the accuracy. We perform extensive experiments\non the CIFAR100, ImageNet1K, and ADE20K datasets to validate the effectiveness\nof our method. Our method has a slower growth rate of GFlops than previous\ntransformer-based and convolution-based networks when the input resolution\nincreases. In particular, our approach achieves state-of-the-art image\nclassification accuracy with 50% fewer parameters than previous methods.",
    "descriptor": "",
    "authors": [
      "Weixuan Sun",
      "Zhen Qin",
      "Hui Deng",
      "Jianyuan Wang",
      "Yi Zhang",
      "Kaihao Zhang",
      "Nick Barnes",
      "Stan Birchfield",
      "Lingpeng Kong",
      "Yiran Zhong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10552"
  },
  {
    "id": "arXiv:2206.10553",
    "title": "Uncertainty Quantification for Competency Assessment of Autonomous  Agents",
    "abstract": "For safe and reliable deployment in the real world, autonomous agents must\nelicit appropriate levels of trust from human users. One method to build trust\nis to have agents assess and communicate their own competencies for performing\ngiven tasks. Competency depends on the uncertainties affecting the agent,\nmaking accurate uncertainty quantification vital for competency assessment. In\nthis work, we show how ensembles of deep generative models can be used to\nquantify the agent's aleatoric and epistemic uncertainties when forecasting\ntask outcomes as part of competency assessment.",
    "descriptor": "\nComments: Accepted at the Workshop on Safe and Reliable Robot Autonomy under Uncertainty at ICRA 2022, Philadelphia, USA\n",
    "authors": [
      "Aastha Acharya",
      "Rebecca Russell",
      "Nisar R. Ahmed"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10553"
  },
  {
    "id": "arXiv:2206.10555",
    "title": "Scaling up Kernels in 3D CNNs",
    "abstract": "Recent advances in 2D CNNs and vision transformers (ViTs) reveal that large\nkernels are essential for enough receptive fields and high performance.\nInspired by this literature, we examine the feasibility and challenges of 3D\nlarge-kernel designs. We demonstrate that applying large convolutional kernels\nin 3D CNNs has more difficulties in both performance and efficiency. Existing\ntechniques that work well in 2D CNNs are ineffective in 3D networks, including\nthe popular depth-wise convolutions. To overcome these obstacles, we present\nthe spatial-wise group convolution and its large-kernel module (SW-LK block).\nIt avoids the optimization and efficiency issues of naive 3D large kernels. Our\nlarge-kernel 3D CNN network, i.e., LargeKernel3D, yields non-trivial\nimprovements on various 3D tasks, including semantic segmentation and object\ndetection. Notably, it achieves 73.9% mIoU on the ScanNetv2 semantic\nsegmentation and 72.8% NDS nuScenes object detection benchmarks, ranking 1st on\nthe nuScenes LIDAR leaderboard. It is further boosted to 74.2% NDS with a\nsimple multi-modal fusion. LargeKernel3D attains comparable or superior results\nthan its CNN and transformer counterparts. For the first time, we show that\nlarge kernels are feasible and essential for 3D networks.",
    "descriptor": "\nComments: Code and models will be available at this https URL\n",
    "authors": [
      "Yukang Chen",
      "Jianhui Liu",
      "Xiaojuan Qi",
      "Xiangyu Zhang",
      "Jian Sun",
      "Jiaya Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10555"
  },
  {
    "id": "arXiv:2206.10557",
    "title": "A Study of Weisfeiler-Leman Colorings on Planar Graphs",
    "abstract": "The Weisfeiler-Leman (WL) algorithm is a combinatorial procedure that\ncomputes colorings on graphs, which can often be used to detect their\n(non-)isomorphism. Particularly the 1- and 2-dimensional versions 1-WL and 2-WL\nhave received much attention, due to their numerous links to other areas of\ncomputer science.\nKnowing the expressive power of a certain dimension of the algorithm usually\namounts to understanding the computed colorings. An increase in the dimension\nleads to finer computed colorings and, thus, more graphs can be distinguished.\nFor example, on the class of planar graphs, 3-WL solves the isomorphism\nproblem. However, the expressive power of 2-WL on the class is poorly\nunderstood (and, in particular, it may even well be that it decides\nisomorphism).\nIn this paper, we investigate the colorings computed by 2-WL on planar\ngraphs. Towards this end, we analyze the graphs induced by edge color classes\nin the graph. Based on the obtained classification, we show that for every\n3-connected planar graph, it holds that: a) after coloring all pairs with their\n2-WL color, the graph has fixing number 1 with respect to 1-WL, or b) there is\na 2-WL-definable matching that can be used to transform the graph into a\nsmaller one, or c) 2-WL detects a connected subgraph that is essentially the\ngraph of a Platonic or Archimedean solid, a prism, a cycle, or a bipartite\ngraph K_{2,\\ell}. In particular, the graphs from case (a) are identified by\n2-WL.",
    "descriptor": "\nComments: 53 pages, 15 figures, full version of a paper accepted at ICALP 2022\n",
    "authors": [
      "Sandra Kiefer",
      "Daniel Neuen"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2206.10557"
  },
  {
    "id": "arXiv:2206.10558",
    "title": "EnvPool: A Highly Parallel Reinforcement Learning Environment Execution  Engine",
    "abstract": "There has been significant progress in developing reinforcement learning (RL)\ntraining systems. Past works such as IMPALA, Apex, Seed RL, Sample Factory, and\nothers aim to improve the system's overall throughput. In this paper, we try to\naddress a common bottleneck in the RL training system, i.e., parallel\nenvironment execution, which is often the slowest part of the whole system but\nreceives little attention. With a curated design for paralleling RL\nenvironments, we have improved the RL environment simulation speed across\ndifferent hardware setups, ranging from a laptop, and a modest workstation, to\na high-end machine like NVIDIA DGX-A100. On a high-end machine, EnvPool\nachieves 1 million frames per second for the environment execution on Atari\nenvironments and 3 million frames per second on MuJoCo environments. When\nrunning on a laptop, the speed of EnvPool is 2.8 times of the Python\nsubprocess. Moreover, great compatibility with existing RL training libraries\nhas been demonstrated in the open-sourced community, including CleanRL,\nrl_games, DeepMind Acme, etc. Finally, EnvPool allows researchers to iterate\ntheir ideas at a much faster pace and has the great potential to become the de\nfacto RL environment execution engine. Example runs show that it takes only 5\nminutes to train Atari Pong and MuJoCo Ant, both on a laptop. EnvPool has\nalready been open-sourced at https://github.com/sail-sg/envpool.",
    "descriptor": "",
    "authors": [
      "Jiayi Weng",
      "Min Lin",
      "Shengyi Huang",
      "Bo Liu",
      "Denys Makoviichuk",
      "Viktor Makoviychuk",
      "Zichen Liu",
      "Yufan Song",
      "Ting Luo",
      "Yukun Jiang",
      "Zhongwen Xu",
      "Shuicheng Yan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.10558"
  },
  {
    "id": "arXiv:2206.10559",
    "title": "Low Resource Pipeline for Spoken Language Understanding via Weak  Supervision",
    "abstract": "In Weak Supervised Learning (WSL), a model is trained over noisy labels\nobtained from semantic rules and task-specific pre-trained models. Rules offer\nlimited generalization over tasks and require significant manual efforts while\npre-trained models are available only for limited tasks. In this work, we\npropose to utilize prompt-based methods as weak sources to obtain the noisy\nlabels on unannotated data. We show that task-agnostic prompts are\ngeneralizable and can be used to obtain noisy labels for different Spoken\nLanguage Understanding (SLU) tasks such as sentiment classification, disfluency\ndetection and emotion classification. These prompts could additionally be\nupdated to add task-specific contexts, thus providing flexibility to design\ntask-specific prompts. We demonstrate that prompt-based methods generate\nreliable labels for the above SLU tasks and thus can be used as a universal\nweak source to train a weak-supervised model (WSM) in absence of labeled data.\nOur proposed WSL pipeline trained over prompt-based weak source outperforms\nother competitive low-resource benchmarks on zero and few-shot learning by more\nthan 4% on Macro-F1 on all of the three benchmark SLU datasets. The proposed\nmethod also outperforms a conventional rule based WSL pipeline by more than 5%\non Macro-F1.",
    "descriptor": "",
    "authors": [
      "Ayush Kumar",
      "Rishabh Kumar Tripathi",
      "Jithendra Vepa"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.10559"
  },
  {
    "id": "arXiv:2206.10561",
    "title": "Fair Queuing Aware Congestion Control",
    "abstract": "Fair queuing is becoming increasingly prevalent in the internet and has been\nshown to improve performance in many circumstances. Performance could be\nimproved even more if endpoints could detect the presence of fair queuing on a\ncertain path and adjust their congestion control accordingly. If fair queuing\nis detected, the congestion control would not have to take cross traffic into\naccount, which allows for more flexibility. In this paper, we develop the first\nalgorithm that continuously checks if fair queuing is present on a path, with\nvery high accuracy. When fair queuing is detected, a different congestion\ncontrol can be chosen, which can result in reduced latency. Unlike an algorithm\nproposed in a previous paper of us, the approach presented here does not only\ndetect the presence of fair queuing once at flow startup but it does so\ncontinuously.",
    "descriptor": "",
    "authors": [
      "Maximilian Bachl"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.10561"
  },
  {
    "id": "arXiv:2206.10562",
    "title": "Semantics-Depth-Symbiosis: Deeply Coupled Semi-Supervised Learning of  Semantics and Depth",
    "abstract": "Multi-task learning (MTL) paradigm focuses on jointly learning two or more\ntasks, aiming for significant improvement w.r.t model's generalizability,\nperformance, and training/inference memory footprint. The aforementioned\nbenefits become ever so indispensable in the case of joint training for\nvision-related {\\bf dense} prediction tasks. In this work, we tackle the MTL\nproblem of two dense tasks, \\ie, semantic segmentation and depth estimation,\nand present a novel attention module called Cross-Channel Attention Module\n({CCAM}), which facilitates effective feature sharing along each channel\nbetween the two tasks, leading to mutual performance gain with a negligible\nincrease in trainable parameters. In a true symbiotic spirit, we then formulate\na novel data augmentation for the semantic segmentation task using predicted\ndepth called {AffineMix}, and a simple depth augmentation using predicted\nsemantics called {ColorAug}. Finally, we validate the performance gain of the\nproposed method on the Cityscapes dataset, which helps us achieve\nstate-of-the-art results for a semi-supervised joint model based on depth and\nsemantic segmentation.",
    "descriptor": "",
    "authors": [
      "Nitin Bansal",
      "Pan Ji",
      "Junsong Yuan",
      "Yi Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10562"
  },
  {
    "id": "arXiv:2206.10565",
    "title": "sqSGD: Locally Private and Communication Efficient Federated Learning",
    "abstract": "Federated learning (FL) is a technique that trains machine learning models\nfrom decentralized data sources. We study FL under local notions of privacy\nconstraints, which provides strong protection against sensitive data\ndisclosures via obfuscating the data before leaving the client. We identify two\nmajor concerns in designing practical privacy-preserving FL algorithms:\ncommunication efficiency and high-dimensional compatibility. We then develop a\ngradient-based learning algorithm called \\emph{sqSGD} (selective quantized\nstochastic gradient descent) that addresses both concerns. The proposed\nalgorithm is based on a novel privacy-preserving quantization scheme that uses\na constant number of bits per dimension per client. Then we improve the base\nalgorithm in three ways: first, we apply a gradient subsampling strategy that\nsimultaneously offers better training performance and smaller communication\ncosts under a fixed privacy budget. Secondly, we utilize randomized rotation as\na preprocessing step to reduce quantization error. Thirdly, an adaptive\ngradient norm upper bound shrinkage strategy is adopted to improve accuracy and\nstabilize training. Finally, the practicality of the proposed framework is\ndemonstrated on benchmark datasets. Experiment results show that sqSGD\nsuccessfully learns large models like LeNet and ResNet with local privacy\nconstraints. In addition, with fixed privacy and communication level, the\nperformance of sqSGD significantly dominates that of various baseline\nalgorithms.",
    "descriptor": "",
    "authors": [
      "Yan Feng",
      "Tao Xiong",
      "Ruofan Wu",
      "LingJuan Lv",
      "Leilei Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.10565"
  },
  {
    "id": "arXiv:2206.10567",
    "title": "A nonconforming primal hybrid finite element method for the  two-dimensional vector Laplacian",
    "abstract": "We introduce a nonconforming hybrid finite element method for the\ntwo-dimensional vector Laplacian, based on a primal variational principle for\nwhich conforming methods are known to be inconsistent. Consistency is ensured\nusing penalty terms similar to those used to stabilize hybridizable\ndiscontinuous Galerkin (HDG) methods, with a carefully chosen penalty parameter\ndue to Brenner, Li, and Sung [Math. Comp., 76 (2007), pp. 573-595]. Our method\naccommodates elements of arbitrarily high order and, like HDG methods, it may\nbe implemented efficiently using static condensation. The lowest-order case\nrecovers the $P_1$-nonconforming method of Brenner, Cui, Li, and Sung [Numer.\nMath., 109 (2008), pp. 509-533], and we show that higher-order convergence is\nachieved under appropriate regularity assumptions. The analysis makes novel use\nof a family of weighted Sobolev spaces, due to Kondrat'ev, for domains\nadmitting corner singularities.",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Mary Barker",
      "Shuhao Cao",
      "Ari Stern"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.10567"
  },
  {
    "id": "arXiv:2206.10569",
    "title": "Controllability of Coarsely Measured Networked Linear Dynamical Systems  (Extended Version)",
    "abstract": "We consider the controllability of large-scale linear networked dynamical\nsystems when complete knowledge of network structure is unavailable and\nknowledge is limited to coarse summaries. We provide conditions under which\naverage controllability of the fine-scale system can be well approximated by\naverage controllability of the (synthesized, reduced-order) coarse-scale\nsystem. To this end, we require knowledge of some inherent parametric structure\nof the fine-scale network that makes this type of approximation possible.\nTherefore, we assume that the underlying fine-scale network is generated by the\nstochastic block model (SBM) -- often studied in community detection. We then\nprovide an algorithm that directly estimates the average controllability of the\nfine-scale system using a coarse summary of SBM. Our analysis indicates the\nnecessity of underlying structure (e.g., in-built communities) to be able to\nquantify accurately the controllability from coarsely characterized networked\ndynamics. We also compare our method to that of the reduced-order method and\nhighlight the regimes where both can outperform each other. Finally, we provide\nsimulations to confirm our theoretical results for different scalings of\nnetwork size and density, and the parameter that captures how much\ncommunity-structure is retained in the coarse summary.",
    "descriptor": "",
    "authors": [
      "Nafiseh Ghoroghchian",
      "Rajasekhar Anguluri",
      "Gautam Dasarathy",
      "Stark C. Draper"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.10569"
  },
  {
    "id": "arXiv:2206.10571",
    "title": "Toward Unpaired Multi-modal Medical Image Segmentation via Learning  Structured Semantic Consistency",
    "abstract": "Integrating multi-modal data to improve medical image analysis has received\ngreat attention recently. However, due to the modal discrepancy, how to use a\nsingle model to process the data from multiple modalities is still an open\nissue. In this paper, we propose a novel scheme to achieve better pixel-level\nsegmentation for unpaired multi-modal medical images. Different from previous\nmethods which adopted both modality-specific and modality-shared modules to\naccommodate the appearance variance of different modalities while extracting\nthe common semantic information, our method is based on a single Transformer\nwith a carefully designed External Attention Module (EAM) to learn the\nstructured semantic consistency (i.e. semantic class representations and their\ncorrelations) between modalities in the training phase. In practice, the\nabove-mentioned structured semantic consistency across modalities can be\nprogressively achieved by implementing the consistency regularization at the\nmodality-level and image-level respectively. The proposed EAMs are adopted to\nlearn the semantic consistency for different scale representations and can be\ndiscarded once the model is optimized. Therefore, during the testing phase, we\nonly need to maintain one Transformer for all modal predictions, which nicely\nbalances the model's ease of use and simplicity. To demonstrate the\neffectiveness of the proposed method, we conduct the experiments on two medical\nimage segmentation scenarios: (1) cardiac structure segmentation, and (2)\nabdominal multi-organ segmentation. Extensive results show that the proposed\nmethod outperforms the state-of-the-art methods by a wide margin, and even\nachieves competitive performance with extremely limited training samples (e.g.,\n1 or 3 annotated CT or MRI images) for one specific modality.",
    "descriptor": "",
    "authors": [
      "Jie Yang",
      "Ruimao Zhang",
      "Chaoqun Wang",
      "Zhen Li",
      "Xiang Wan",
      "Lingyan Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10571"
  },
  {
    "id": "arXiv:2206.10573",
    "title": "H&E-based Computational Biomarker Enables Universal EGFR Screening for  Lung Adenocarcinoma",
    "abstract": "Lung cancer is the leading cause of cancer death worldwide, with lung\nadenocarcinoma being the most prevalent form of lung cancer. EGFR positive lung\nadenocarcinomas have been shown to have high response rates to TKI therapy,\nunderlying the essential nature of molecular testing for lung cancers. Despite\ncurrent guidelines consider testing necessary, a large portion of patients are\nnot routinely profiled, resulting in millions of people not receiving the\noptimal treatment for their lung cancer. Sequencing is the gold standard for\nmolecular testing of EGFR mutations, but it can take several weeks for results\nto come back, which is not ideal in a time constrained scenario. The\ndevelopment of alternative screening tools capable of detecting EGFR mutations\nquickly and cheaply while preserving tissue for sequencing could help reduce\nthe amount of sub-optimally treated patients. We propose a multi-modal approach\nwhich integrates pathology images and clinical variables to predict EGFR\nmutational status achieving an AUC of 84% on the largest clinical cohort to\ndate. Such a computational model could be deployed at large at little\nadditional cost. Its clinical application could reduce the number of patients\nwho receive sub-optimal treatments by 53.1% in China, and up to 96.6% in the\nUS.",
    "descriptor": "",
    "authors": [
      "Gabriele Campanella",
      "David Ho",
      "Ida H\u00e4ggstr\u00f6m",
      "Anton S Becker",
      "Jason Chang",
      "Chad Vanderbilt",
      "Thomas J Fuchs"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2206.10573"
  },
  {
    "id": "arXiv:2206.10579",
    "title": "Gradient-Enhanced Physics-Informed Neural Networks for Power Systems  Operational Support",
    "abstract": "The application of deep learning methods to speed up the resolution of\nchallenging power flow problems has recently shown very encouraging results.\nHowever, power system dynamics are not snap-shot, steady-state operations.\nThese dynamics must be considered to ensure that the optimal solutions provided\nby these models adhere to practical dynamical constraints, avoiding frequency\nfluctuations and grid instabilities. Unfortunately, dynamic system models based\non ordinary or partial differential equations are frequently unsuitable for\ndirect application in control or state estimates due to their high\ncomputational costs. To address these challenges, this paper introduces a\nmachine learning method to approximate the behavior of power systems dynamics\nin near real time. The proposed framework is based on gradient-enhanced\nphysics-informed neural networks (gPINNs) and encodes the underlying physical\nlaws governing power systems. A key characteristic of the proposed gPINN is its\nability to train without the need of generating expensive training data. The\npaper illustrates the potential of the proposed approach in both forward and\ninverse problems in a single-machine infinite bus system for predicting rotor\nangles and frequency, and uncertain parameters such as inertia and damping to\nshowcase its potential for a range of power systems applications.",
    "descriptor": "\nComments: 8 pages, 7 figures\n",
    "authors": [
      "Mostafa Mohammadian",
      "Kyri Baker",
      "Ferdinando Fioretto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.10579"
  },
  {
    "id": "arXiv:2206.10581",
    "title": "Nimble GNN Embedding with Tensor-Train Decomposition",
    "abstract": "This paper describes a new method for representing embedding tables of graph\nneural networks (GNNs) more compactly via tensor-train (TT) decomposition. We\nconsider the scenario where (a) the graph data that lack node features, thereby\nrequiring the learning of embeddings during training; and (b) we wish to\nexploit GPU platforms, where smaller tables are needed to reduce host-to-GPU\ncommunication even for large-memory GPUs. The use of TT enables a compact\nparameterization of the embedding, rendering it small enough to fit entirely on\nmodern GPUs even for massive graphs. When combined with judicious schemes for\ninitialization and hierarchical graph partitioning, this approach can reduce\nthe size of node embedding vectors by 1,659 times to 81,362 times on large\npublicly available benchmark datasets, achieving comparable or better accuracy\nand significant speedups on multi-GPU systems. In some cases, our model without\nexplicit node features on input can even match the accuracy of models that use\nnode features.",
    "descriptor": "\nComments: To appear in the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (SIGKDD 22)\n",
    "authors": [
      "Chunxing Yin",
      "Da Zheng",
      "Israt Nisa",
      "Christos Faloutos",
      "George Karypis",
      "Richard Vuduc"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10581"
  },
  {
    "id": "arXiv:2206.10586",
    "title": "D-CIPHER: Discovery of Closed-form PDEs",
    "abstract": "Closed-form differential equations, including partial differential equations\nand higher-order ordinary differential equations, are one of the most important\ntools used by scientists to model and better understand natural phenomena.\nDiscovering these equations directly from data is challenging because it\nrequires modeling relationships between various derivatives that are not\nobserved in the data (\\textit{equation-data mismatch}) and it involves\nsearching across a huge space of possible equations. Current approaches make\nstrong assumptions about the form of the equation and thus fail to discover\nmany well-known systems. Moreover, many of them resolve the equation-data\nmismatch by estimating the derivatives, which makes them inadequate for noisy\nand infrequently sampled systems. To this end, we propose D-CIPHER, which is\nrobust to measurement artifacts and can uncover a new and very general class of\ndifferential equations. We further design a novel optimization procedure,\nCoLLie, to help D-CIPHER search through this class efficiently. Finally, we\ndemonstrate empirically that it can discover many well-known equations that are\nbeyond the capabilities of current methods.",
    "descriptor": "",
    "authors": [
      "Krzysztof Kacprzyk",
      "Zhaozhi Qian",
      "Mihaela van der Schaar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10586"
  },
  {
    "id": "arXiv:2206.10587",
    "title": "Guiding Visual Attention in Deep Convolutional Neural Networks Based on  Human Eye Movements",
    "abstract": "Deep Convolutional Neural Networks (DCNNs) were originally inspired by\nprinciples of biological vision, have evolved into best current computational\nmodels of object recognition, and consequently indicate strong architectural\nand functional parallelism with the ventral visual pathway throughout\ncomparisons with neuroimaging and neural time series data. As recent advances\nin deep learning seem to decrease this similarity, computational neuroscience\nis challenged to reverse-engineer the biological plausibility to obtain useful\nmodels. While previous studies have shown that biologically inspired\narchitectures are able to amplify the human-likeness of the models, in this\nstudy, we investigate a purely data-driven approach. We use human eye tracking\ndata to directly modify training examples and thereby guide the models' visual\nattention during object recognition in natural images either towards or away\nfrom the focus of human fixations. We compare and validate different\nmanipulation types (i.e., standard, human-like, and non-human-like attention)\nthrough GradCAM saliency maps against human participant eye tracking data. Our\nresults demonstrate that the proposed guided focus manipulation works as\nintended in the negative direction and non-human-like models focus on\nsignificantly dissimilar image parts compared to humans. The observed effects\nwere highly category-specific, enhanced by animacy and face presence, developed\nonly after feedforward processing was completed, and indicated a strong\ninfluence on face detection. With this approach, however, no significantly\nincreased human-likeness was found. Possible applications of overt visual\nattention in DCNNs and further implications for theories of face detection are\ndiscussed.",
    "descriptor": "\nComments: 26 pages, 6 figures, 2 supplementary figures\n",
    "authors": [
      "Leonard E. van Dyck",
      "Sebastian J. Denzler",
      "Walter R. Gruber"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10587"
  },
  {
    "id": "arXiv:2206.10588",
    "title": "Robust SDE-Based Variational Formulations for Solving Linear PDEs via  Deep Learning",
    "abstract": "The combination of Monte Carlo methods and deep learning has recently led to\nefficient algorithms for solving partial differential equations (PDEs) in high\ndimensions. Related learning problems are often stated as variational\nformulations based on associated stochastic differential equations (SDEs),\nwhich allow the minimization of corresponding losses using gradient-based\noptimization methods. In respective numerical implementations it is therefore\ncrucial to rely on adequate gradient estimators that exhibit low variance in\norder to reach convergence accurately and swiftly. In this article, we\nrigorously investigate corresponding numerical aspects that appear in the\ncontext of linear Kolmogorov PDEs. In particular, we systematically compare\nexisting deep learning approaches and provide theoretical explanations for\ntheir performances. Subsequently, we suggest novel methods that can be shown to\nbe more robust both theoretically and numerically, leading to substantial\nperformance improvements.",
    "descriptor": "\nComments: Accepted at ICML 2022\n",
    "authors": [
      "Lorenz Richter",
      "Julius Berner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.10588"
  },
  {
    "id": "arXiv:2206.10589",
    "title": "EdgeNeXt: Efficiently Amalgamated CNN-Transformer Architecture for  Mobile Vision Applications",
    "abstract": "In the pursuit of achieving ever-increasing accuracy, large and complex\nneural networks are usually developed. Such models demand high computational\nresources and therefore cannot be deployed on edge devices. It is of great\ninterest to build resource-efficient general purpose networks due to their\nusefulness in several application areas. In this work, we strive to effectively\ncombine the strengths of both CNN and Transformer models and propose a new\nefficient hybrid architecture EdgeNeXt. Specifically in EdgeNeXt, we introduce\nsplit depth-wise transpose attention (SDTA) encoder that splits input tensors\ninto multiple channel groups and utilizes depth-wise convolution along with\nself-attention across channel dimensions to implicitly increase the receptive\nfield and encode multi-scale features. Our extensive experiments on\nclassification, detection and segmentation tasks, reveal the merits of the\nproposed approach, outperforming state-of-the-art methods with comparatively\nlower compute requirements. Our EdgeNeXt model with 1.3M parameters achieves\n71.2\\% top-1 accuracy on ImageNet-1K, outperforming MobileViT with an absolute\ngain of 2.2\\% with 28\\% reduction in FLOPs. Further, our EdgeNeXt model with\n5.6M parameters achieves 79.4\\% top-1 accuracy on ImageNet-1K. The code and\nmodels are publicly available at https://t.ly/_Vu9.",
    "descriptor": "\nComments: Technical Report\n",
    "authors": [
      "Muhammad Maaz",
      "Abdelrahman Shaker",
      "Hisham Cholakkal",
      "Salman Khan",
      "Syed Waqas Zamir",
      "Rao Muhammad Anwer",
      "Fahad Shahbaz Khan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10589"
  },
  {
    "id": "arXiv:2206.10590",
    "title": "Temporally Consistent Semantic Video Editing",
    "abstract": "Generative adversarial networks (GANs) have demonstrated impressive image\ngeneration quality and semantic editing capability of real images, e.g.,\nchanging object classes, modifying attributes, or transferring styles. However,\napplying these GAN-based editing to a video independently for each frame\ninevitably results in temporal flickering artifacts. We present a simple yet\neffective method to facilitate temporally coherent video editing. Our core idea\nis to minimize the temporal photometric inconsistency by optimizing both the\nlatent code and the pre-trained generator. We evaluate the quality of our\nediting on different domains and GAN inversion techniques and show favorable\nresults against the baselines.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Yiran Xu",
      "Badour AlBahar",
      "Jia-Bin Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10590"
  },
  {
    "id": "arXiv:2206.07811",
    "title": "Safety Guarantees for Neural Network Dynamic Systems via Stochastic  Barrier Functions",
    "abstract": "Neural Networks (NNs) have been successfully employed to represent the state\nevolution of complex dynamical systems. Such models, referred to as NN dynamic\nmodels (NNDMs), use iterative noisy predictions of NN to estimate a\ndistribution of system trajectories over time. Despite their accuracy, safety\nanalysis of NNDMs is known to be a challenging problem and remains largely\nunexplored. To address this issue, in this paper, we introduce a method of\nproviding safety guarantees for NNDMs. Our approach is based on stochastic\nbarrier functions, whose relation with safety are analogous to that of Lyapunov\nfunctions with stability. We first show a method of synthesizing stochastic\nbarrier functions for NNDMs via a convex optimization problem, which in turn\nprovides a lower bound on the system's safety probability. A key step in our\nmethod is the employment of the recent convex approximation results for NNs to\nfind piece-wise linear bounds, which allow the formulation of the barrier\nfunction synthesis problem as a sum-of-squares optimization program. If the\nobtained safety probability is above the desired threshold, the system is\ncertified. Otherwise, we introduce a method of generating controls for the\nsystem that robustly maximizes the safety probability in a minimally-invasive\nmanner. We exploit the convexity property of the barrier function to formulate\nthe optimal control synthesis problem as a linear program. Experimental results\nillustrate the efficacy of the method. Namely, they show that the method can\nscale to multi-dimensional NNDMs with multiple layers and hundreds of neurons\nper layer, and that the controller can significantly improve the safety\nprobability.",
    "descriptor": "",
    "authors": [
      "Rayan Mazouz",
      "Karan Muvvala",
      "Akash Ratheesh",
      "Luca Laurenti",
      "Morteza Lahijanian"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.07811"
  },
  {
    "id": "arXiv:2206.08277",
    "title": "A machine-generated catalogue of Charon's craters and implications for  the Kuiper belt",
    "abstract": "In this paper we investigate Charon's craters size distribution using a deep\nlearning model. This is motivated by the recent results of Singer et al. (2019)\nwho, using manual cataloging, found a change in the size distribution slope of\ncraters smaller than 12 km in diameter, translating into a paucity of small\nKuiper Belt objects. These results were corroborated by Robbins and Singer\n(2021), but opposed by Morbidelli et al. (2021), necessitating an independent\nreview. Our MaskRCNN-based ensemble of models was trained on Lunar, Mercurian,\nand Martian crater catalogues and both optical and digital elevation images. We\nuse a robust image augmentation scheme to force the model to generalize and\ntransfer-learn into icy objects. With no prior bias or exposure to Charon, our\nmodel find best fit slopes of q =-1.47+-0.33 for craters smaller than 10 km,\nand q =-2.91+-0.51 for craters larger than 15 km. These values indicate a clear\nchange in slope around 15 km as suggested by Singer et al. (2019) and thus\nindependently confirm their conclusions. Our slopes however are both slightly\nflatter than those found more recently by Robbins and Singer (2021). Our\ntrained models and relevant codes are available online on\ngithub.com/malidib/ACID .",
    "descriptor": "\nComments: 16 pages, 2 figures, accepted for publication in Icarus\n",
    "authors": [
      "Mohamad Ali-Dib"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.08277"
  },
  {
    "id": "arXiv:2206.08933",
    "title": "A theory of learning with constrained weight-distribution",
    "abstract": "A central question in computational neuroscience is how structure determines\nfunction in neural networks. The emerging high-quality large-scale connectomic\ndatasets raise the question of what general functional principles can be\ngleaned from structural information such as the distribution of\nexcitatory/inhibitory synapse types and the distribution of synaptic weights.\nMotivated by this question, we developed a statistical mechanical theory of\nlearning in neural networks that incorporates structural information as\nconstraints. We derived an analytical solution for the memory capacity of the\nperceptron, a basic feedforward model of supervised learning, with constraint\non the distribution of its weights. Our theory predicts that the reduction in\ncapacity due to the constrained weight-distribution is related to the\nWasserstein distance between the imposed distribution and that of the standard\nnormal distribution. To test the theoretical predictions, we use optimal\ntransport theory and information geometry to develop an SGD-based algorithm to\nfind weights that simultaneously learn the input-output task and satisfy the\ndistribution constraint. We show that training in our algorithm can be\ninterpreted as geodesic flows in the Wasserstein space of probability\ndistributions. We further developed a statistical mechanical theory for\nteacher-student perceptron rule learning and ask for the best way for the\nstudent to incorporate prior knowledge of the rule. Our theory shows that it is\nbeneficial for the learner to adopt different prior weight distributions during\nlearning, and shows that distribution-constrained learning outperforms\nunconstrained and sign-constrained learning. Our theory and algorithm provide\nnovel strategies for incorporating prior knowledge about weights into learning,\nand reveal a powerful connection between structure and function in neural\nnetworks.",
    "descriptor": "\nComments: 35 pages, 13 figures\n",
    "authors": [
      "Weishun Zhong",
      "Ben Sorscher",
      "Daniel D Lee",
      "Haim Sompolinsky"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.08933"
  },
  {
    "id": "arXiv:2206.08936",
    "title": "Simultaneous Bone and Shadow Segmentation Network using Task  Correspondence Consistency",
    "abstract": "Segmenting both bone surface and the corresponding acoustic shadow are\nfundamental tasks in ultrasound (US) guided orthopedic procedures. However,\nthese tasks are challenging due to minimal and blurred bone surface response in\nUS images, cross-machine discrepancy, imaging artifacts, and low\nsignal-to-noise ratio. Notably, bone shadows are caused by a significant\nacoustic impedance mismatch between the soft tissue and bone surfaces. To\nleverage this mutual information between these highly related tasks, we propose\na single end-to-end network with a shared transformer-based encoder and task\nindependent decoders for simultaneous bone and shadow segmentation. To share\ncomplementary features, we propose a cross task feature transfer block which\nlearns to transfer meaningful features from decoder of shadow segmentation to\nthat of bone segmentation and vice-versa. We also introduce a correspondence\nconsistency loss which makes sure that network utilizes the inter-dependency\nbetween the bone surface and its corresponding shadow to refine the\nsegmentation. Validation against expert annotations shows that the method\noutperforms the previous state-of-the-art for both bone surface and shadow\nsegmentation.",
    "descriptor": "\nComments: Accepted at MICCAI 2022\n",
    "authors": [
      "Aimon Rahman",
      "Jeya Maria Jose Valanarasu",
      "Ilker Hacihaliloglu",
      "Vishal M Patel"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.08936"
  },
  {
    "id": "arXiv:2206.08953",
    "title": "Bayesian neural networks for the probabilistic forecasting of wind  direction and speed using ocean data",
    "abstract": "Neural networks are increasingly being used in a variety of settings to\npredict wind direction and speed, two of the most important factors for\nestimating the potential power output of a wind farm. However, these\npredictions are arguably of limited value because classical neural networks\nlack the ability to express uncertainty. Here we instead consider the use of\nBayesian Neural Networks (BNNs), for which the weights, biases and outputs are\ndistributions rather than deterministic point values. This allows for the\nevaluation of both epistemic and aleatoric uncertainty and leads to\nwell-calibrated uncertainty predictions of both wind speed and power. Here we\nconsider the application of BNNs to the problem of offshore wind resource\nprediction for renewable energy applications. For our dataset, we use\nobservations recorded at the FINO1 research platform in the North Sea and our\npredictors are ocean data such as water temperature and current direction.\nThe probabilistic forecast predicted by the BNN adds considerable value to\nthe results and, in particular, informs the user of the network's ability to\nmake predictions of out-of-sample datapoints. We use this property of BNNs to\nconclude that the accuracy and uncertainty of the wind speed and direction\npredictions made by our network are unaffected by the construction of the\nnearby Alpha Ventus wind farm. Hence, at this site, networks trained on\npre-farm ocean data can be used to accurately predict wind field information\nfrom ocean data after the wind farm has been constructed.",
    "descriptor": "\nComments: 8 pages, 6 figures\n",
    "authors": [
      "Mariana C A Clare",
      "Matthew D Piggott"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.08953"
  },
  {
    "id": "arXiv:2206.08957",
    "title": "Not-Quite Transcendental Functions and their Applications",
    "abstract": "Transcendental functions, such as exponentials and logarithms, appear in a\nbroad array of computational domains: from simulations in curvilinear\ncoordinates, to interpolation, to machine learning. Unfortunately they are\ntypically expensive to compute accurately. In this note, we argue that in many\ncases, the properties of the function matters more than the exact functional\nform. We present new functions, which are not transcendental, that can be used\nas drop-in replacements for the exponential and logarithm in many settings for\na significant performance boost. We show that for certain applications using\nthese functions result in no drop in the accuracy at all, as they are perfectly\naccurate representations of themselves, if not the original transcendental\nfunctions.",
    "descriptor": "\nComments: Submitted as a short note to the journal of computational physics\n",
    "authors": [
      "Jonah M. Miller",
      "Joshua C. Dolence",
      "Daniel Holladay"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Performance (cs.PF)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.08957"
  },
  {
    "id": "arXiv:2206.08968",
    "title": "A parallel iterative method for variational integration",
    "abstract": "Discrete variational methods show excellent performance in numerical\nsimulations of different mechanical systems. In this paper, we introduce an\niterative procedure for the solution of discrete variational equations for\nboundary value problems. More concretely, we explore a parallelization strategy\nthat leverages the capabilities of multicore CPUs and GPUs (graphics cards). We\nstudy this parallel method for higher-order Lagrangian systems, which appear in\nfully-actuated problems and beyond. The most important part of the paper is\ndevoted to a precise study of different convergence conditions for these\nmethods. We illustrate their excellent behavior in some interesting examples,\nnamely Zermelo's navigation problem, a fuel-optimal navigation problem,\ninterpolation problems or in a fuel optimization problem for a controlled\n4-body problem in astrodynamics showing the potential of our method.",
    "descriptor": "",
    "authors": [
      "Sebasti\u00e1n J. Ferraro",
      "David Mart\u00edn de Diego",
      "Rodrigo Takuro Sato Mart\u00edn de Almagro"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.08968"
  },
  {
    "id": "arXiv:2206.08972",
    "title": "Shallow and Deep Nonparametric Convolutions for Gaussian Processes",
    "abstract": "A key challenge in the practical application of Gaussian processes (GPs) is\nselecting a proper covariance function. The moving average, or process\nconvolutions, construction of GPs allows some additional flexibility, but still\nrequires choosing a proper smoothing kernel, which is non-trivial. Previous\napproaches have built covariance functions by using GP priors over the\nsmoothing kernel, and by extension the covariance, as a way to bypass the need\nto specify it in advance. However, such models have been limited in several\nways: they are restricted to single dimensional inputs, e.g. time; they only\nallow modelling of single outputs and they do not scale to large datasets since\ninference is not straightforward. In this paper, we introduce a nonparametric\nprocess convolution formulation for GPs that alleviates these weaknesses by\nusing a functional sampling approach based on Matheron's rule to perform fast\nsampling using interdomain inducing variables. Furthermore, we propose a\ncomposition of these nonparametric convolutions that serves as an alternative\nto classic deep GP models, and allows the covariance functions of the\nintermediate layers to be inferred from the data. We test the performance of\nour model on benchmarks for single output GPs, multiple output GPs and deep GPs\nand find that in many cases our approach can provide improvements over standard\nGP models.",
    "descriptor": "\nComments: 16 pages, 6 figures\n",
    "authors": [
      "Thomas M. McDonald",
      "Magnus Ross",
      "Michael T. Smith",
      "Mauricio A. \u00c1lvarez"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.08972"
  },
  {
    "id": "arXiv:2206.08984",
    "title": "Multi-scale Super-resolution Magnetic Resonance Spectroscopic Imaging  with Adjustable Sharpness",
    "abstract": "Magnetic Resonance Spectroscopic Imaging (MRSI) is a valuable tool for\nstudying metabolic activities in the human body, but the current applications\nare limited to low spatial resolutions. The existing deep learning-based MRSI\nsuper-resolution methods require training a separate network for each upscaling\nfactor, which is time-consuming and memory inefficient. We tackle this\nmulti-scale super-resolution problem using a Filter Scaling strategy that\nmodulates the convolution filters based on the upscaling factor, such that a\nsingle network can be used for various upscaling factors. Observing that each\nmetabolite has distinct spatial characteristics, we also modulate the network\nbased on the specific metabolite. Furthermore, our network is conditioned on\nthe weight of adversarial loss so that the perceptual sharpness of the\nsuper-resolved metabolic maps can be adjusted within a single network. We\nincorporate these network conditionings using a novel Multi-Conditional Module.\nThe experiments were carried out on a 1H-MRSI dataset from 15 high-grade glioma\npatients. Results indicate that the proposed network achieves the best\nperformance among several multi-scale super-resolution methods and can provide\nsuper-resolved metabolic maps with adjustable sharpness.",
    "descriptor": "\nComments: Accepted by MICCAI 2022\n",
    "authors": [
      "Siyuan Dong",
      "Gilbert Hangel",
      "Wolfgang Bogner",
      "Georg Widhalm",
      "Karl R\u00f6ssler",
      "Siegfried Trattnig",
      "Chenyu You",
      "Robin de Graaf",
      "John Onofrey",
      "James Duncan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.08984"
  },
  {
    "id": "arXiv:2206.08985",
    "title": "TransResU-Net: Transformer based ResU-Net for Real-Time Colonoscopy  Polyp Segmentation",
    "abstract": "Colorectal cancer (CRC) is one of the most common causes of cancer and\ncancer-related mortality worldwide. Performing colon cancer screening in a\ntimely fashion is the key to early detection. Colonoscopy is the primary\nmodality used to diagnose colon cancer. However, the miss rate of polyps,\nadenomas and advanced adenomas remains significantly high. Early detection of\npolyps at the precancerous stage can help reduce the mortality rate and the\neconomic burden associated with colorectal cancer. Deep learning-based\ncomputer-aided diagnosis (CADx) system may help gastroenterologists to identify\npolyps that may otherwise be missed, thereby improving the polyp detection\nrate. Additionally, CADx system could prove to be a cost-effective system that\nimproves long-term colorectal cancer prevention. In this study, we proposed a\ndeep learning-based architecture for automatic polyp segmentation, called\nTransformer ResU-Net (TransResU-Net). Our proposed architecture is built upon\nresidual blocks with ResNet-50 as the backbone and takes the advantage of\ntransformer self-attention mechanism as well as dilated convolution(s). Our\nexperimental results on two publicly available polyp segmentation benchmark\ndatasets showed that TransResU-Net obtained a highly promising dice score and a\nreal-time speed. With high efficacy in our performance metrics, we concluded\nthat TransResU-Net could be a strong benchmark for building a real-time polyp\ndetection system for the early diagnosis, treatment, and prevention of\ncolorectal cancer. The source code of the proposed TransResU-Net is publicly\navailable at https://github.com/nikhilroxtomar/TransResUNet.",
    "descriptor": "",
    "authors": [
      "Nikhil Kumar Tomar",
      "Annie Shergill",
      "Brandon Rieders",
      "Ulas Bagci",
      "Debesh Jha"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.08985"
  },
  {
    "id": "arXiv:2206.08994",
    "title": "Robust Group Synchronization via Quadratic Programming",
    "abstract": "We propose a novel quadratic programming formulation for estimating the\ncorruption levels in group synchronization, and use these estimates to solve\nthis problem. Our objective function exploits the cycle consistency of the\ngroup and we thus refer to our method as detection and estimation of structural\nconsistency (DESC). This general framework can be extended to other algebraic\nand geometric structures. Our formulation has the following advantages: it can\ntolerate corruption as high as the information-theoretic bound, it does not\nrequire a good initialization for the estimates of group elements, it has a\nsimple interpretation, and under some mild conditions the global minimum of our\nobjective function exactly recovers the corruption levels. We demonstrate the\ncompetitive accuracy of our approach on both synthetic and real data\nexperiments of rotation averaging.",
    "descriptor": "\nComments: Accepted to ICML 2022\n",
    "authors": [
      "Yunpeng Shi",
      "Cole Wyeth",
      "Gilad Lerman"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.08994"
  },
  {
    "id": "arXiv:2206.08995",
    "title": "Space-time POD and the Hankel matrix",
    "abstract": "Time-delay embedding is an increasingly popular starting point for\ndata-driven reduced-order modeling efforts. In particular, the singular value\ndecomposition (SVD) of a block Hankel matrix formed from successive delay\nembeddings of the state of a dynamical system lies at the heart of several\npopular reduced-order modeling methods. In this paper, we show that the left\nsingular vectors of this Hankel matrix are a discrete approximation of\nclassical space-time proper orthogonal decomposition (POD) modes, and the\nsingular values are square roots of the POD energies. This connection\nestablishes a clear interpretation of the Hankel modes grounded in classical\ntheory, and we gain insights into the Hankel modes by instead analyzing the\nequivalent discrete space-time POD modes in terms of the correlation matrix\nformed by multiplying the Hankel matrix by its conjugate transpose. These\ninsights include the distinct meaning of rows and columns, the implied norm in\nwhich the modes are optimal, the impact of the time step between snapshots on\nthe modes, and an interpretation of the embedding dimension/height of the\nHankel matrix in terms of the time window on which the modes are optimal.\nMoreover, the connections we establish offer opportunities to improve the\nconvergence and computation time in certain practical cases, and to improve the\naccuracy of the modes with the same data. Finally, popular variants of POD,\nnamely the standard space-only POD and spectral POD, are recovered in the\nlimits that snapshots used to form each column of the Hankel matrix represent\nflow evolution over short and long times, respectively.",
    "descriptor": "\nComments: 28 Pages, 10 figures\n",
    "authors": [
      "Peter Frame",
      "Aaron Towne"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.08995"
  },
  {
    "id": "arXiv:2206.09002",
    "title": "Cluster Generation via Deep Energy-Based Model",
    "abstract": "We present a new approach for the generation of stable structures of\nnanoclusters using deep learning methods. Our method consists in constructing\nan artificial potential energy surface, with local minima corresponding to the\nmost stable structures and which is much smoother than \"real\" potential in the\nintermediate regions of the configuration space. To build the surface, graph\nconvolutional networks are used. The method can extrapolates the potential\nsurface to cases of structures with larger number of atoms than was used in\ntraining. Thus, having a sufficient number of low-energy structures in the\ntraining set, the method allows to generate new candidates for the ground-state\nstructures, including ones with larger number of atoms. We applied the approach\nto silica clusters $(SiO_2)_n$ and for the first time found the stable\nstructures with n=28...51. The method is universal and does not depend on the\natomic composition and number of atoms.",
    "descriptor": "",
    "authors": [
      "A. Yu. Artsukevich",
      "S. V. Lepeshkin"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09002"
  },
  {
    "id": "arXiv:2206.09021",
    "title": "Conditional Permutation Invariant Flows",
    "abstract": "We present a novel, conditional generative probabilistic model of set-valued\ndata with a tractable log density. This model is a continuous normalizing flow\ngoverned by permutation equivariant dynamics. These dynamics are driven by a\nlearnable per-set-element term and pairwise interactions, both parametrized by\ndeep neural networks. We illustrate the utility of this model via applications\nincluding (1) complex traffic scene generation conditioned on visually\nspecified map information, and (2) object bounding box generation conditioned\ndirectly on images. We train our model by maximizing the expected likelihood of\nlabeled conditional data under our flow, with the aid of a penalty that ensures\nthe dynamics are smooth and hence efficiently solvable. Our method\nsignificantly outperforms non-permutation invariant baselines in terms of log\nlikelihood and domain-specific metrics (offroad, collision, and combined\ninfractions), yielding realistic samples that are difficult to distinguish from\nreal data.",
    "descriptor": "\nComments: 20 pages, 10 figures\n",
    "authors": [
      "Berend Zwartsenberg",
      "Adam \u015acibior",
      "Matthew Niedoba",
      "Vasileios Lioutas",
      "Yunpeng Liu",
      "Justice Sefas",
      "Setareh Dabiri",
      "Jonathan Wilder Lavington",
      "Trevor Campbell",
      "Frank Wood"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09021"
  },
  {
    "id": "arXiv:2206.09040",
    "title": "Energy reconstruction for large liquid scintillator detectors with  machine learning techniques: aggregated features approach",
    "abstract": "Large scale detectors consisting of a liquid scintillator (LS) target\nsurrounded by an array of photo-multiplier tubes (PMT) are widely used in\nmodern neutrino experiments: Borexino, KamLAND, Daya Bay, Double Chooz, RENO,\nand upcoming JUNO with its satellite detector TAO. Such apparatuses are able to\nmeasure neutrino energy, which can be derived from the amount of light and its\nspatial and temporal distribution over PMT-channels. However, achieving a fine\nenergy resolution in large scale detectors is challenging. In this work, we\npresent machine learning methods for energy reconstruction in JUNO, the most\nadvanced detector of its type. We focus on positron events in the energy range\nof 0-10 MeV which corresponds to the main signal in JUNO $-$ neutrinos\noriginated from nuclear reactor cores and detected via an inverse beta-decay\nchannel. We consider Boosted Decision Trees and Fully Connected Deep Neural\nNetwork trained on aggregated features, calculated using information collected\nby PMTs. We describe the details of our feature engineering procedure and show\nthat machine learning models can provide energy resolution $\\sigma = 3\\%$ at 1\nMeV using subsets of engineered features. The dataset for model training and\ntesting is generated by the Monte Carlo method with the official JUNO software.\nConsideration of calibration sources for evaluation of the reconstruction\nalgorithms performance on real data is also presented.",
    "descriptor": "",
    "authors": [
      "Arsenii Gavrikov",
      "Yury Malyshkin",
      "Fedor Ratnikov"
    ],
    "subjectives": [
      "Instrumentation and Detectors (physics.ins-det)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09040"
  },
  {
    "id": "arXiv:2206.09041",
    "title": "Accelerating Machine Learning Training Time for Limit Order Book  Prediction",
    "abstract": "Financial firms are interested in simulation to discover whether a given\nalgorithm involving financial machine learning will operate profitably. While\nmany versions of this type of algorithm have been published recently by\nresearchers, the focus herein is on a particular machine learning training\nproject due to the explainable nature and the availability of high frequency\nmarket data. For this task, hardware acceleration is expected to speed up the\ntime required for the financial machine learning researcher to obtain the\nresults. As the majority of the time can be spent in classifier training, there\nis interest in faster training steps. A published Limit Order Book algorithm\nfor predicting stock market direction is our subject, and the machine learning\ntraining process can be time-intensive especially when considering the\niterative nature of model development. To remedy this, we deploy Graphical\nProcessing Units (GPUs) produced by NVIDIA available in the data center where\nthe computer architecture is geared to parallel high-speed arithmetic\noperations. In the studied configuration, this leads to significantly faster\ntraining time allowing more efficient and extensive model development.",
    "descriptor": "",
    "authors": [
      "Mark Joseph Bennett"
    ],
    "subjectives": [
      "Trading and Market Microstructure (q-fin.TR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09041"
  },
  {
    "id": "arXiv:2206.09042",
    "title": "Riemannian CUR Decompositions for Robust Principal Component Analysis",
    "abstract": "Robust Principal Component Analysis (PCA) has received massive attention in\nrecent years. It aims to recover a low-rank matrix and a sparse matrix from\ntheir sum. This paper proposes a novel nonconvex Robust PCA algorithm, coined\nRiemannian CUR (RieCUR), which utilizes the ideas of Riemannian optimization\nand robust CUR decompositions. This algorithm has the same computational\ncomplexity as Iterated Robust CUR, which is currently state-of-the-art, but is\nmore robust to outliers. RieCUR is also able to tolerate a significant amount\nof outliers, and is comparable to Accelerated Alternating Projections, which\nhas high outlier tolerance but worse computational complexity than the proposed\nmethod. Thus, the proposed algorithm achieves state-of-the-art performance on\nRobust PCA both in terms of computational complexity and outlier tolerance.",
    "descriptor": "",
    "authors": [
      "Keaton Hamm",
      "Mohamed Meskini",
      "HanQin Cai"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.09042"
  },
  {
    "id": "arXiv:2206.09058",
    "title": "NASTAR: Noise Adaptive Speech Enhancement with Target-Conditional  Resampling",
    "abstract": "For deep learning-based speech enhancement (SE) systems, the training-test\nacoustic mismatch can cause notable performance degradation. To address the\nmismatch issue, numerous noise adaptation strategies have been derived. In this\npaper, we propose a novel method, called noise adaptive speech enhancement with\ntarget-conditional resampling (NASTAR), which reduces mismatches with only one\nsample (one-shot) of noisy speech in the target environment. NASTAR uses a\nfeedback mechanism to simulate adaptive training data via a noise extractor and\na retrieval model. The noise extractor estimates the target noise from the\nnoisy speech, called pseudo-noise. The noise retrieval model retrieves relevant\nnoise samples from a pool of noise signals according to the noisy speech,\ncalled relevant-cohort. The pseudo-noise and the relevant-cohort set are\njointly sampled and mixed with the source speech corpus to prepare simulated\ntraining data for noise adaptation. Experimental results show that NASTAR can\neffectively use one noisy speech sample to adapt an SE model to a target\ncondition. Moreover, both the noise extractor and the noise retrieval model\ncontribute to model adaptation. To our best knowledge, NASTAR is the first work\nto perform one-shot noise adaptation through noise extraction and retrieval.",
    "descriptor": "\nComments: Accepted to Interspeech 2022\n",
    "authors": [
      "Chi-Chang Lee",
      "Cheng-Hung Hu",
      "Yu-Chen Lin",
      "Chu-Song Chen",
      "Hsin-Min Wang",
      "Yu Tsao"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09058"
  },
  {
    "id": "arXiv:2206.09065",
    "title": "Free-form Lesion Synthesis Using a Partial Convolution Generative  Adversarial Network for Enhanced Deep Learning Liver Tumor Segmentation",
    "abstract": "Automatic deep learning segmentation models has been shown to improve both\nthe segmentation efficiency and the accuracy. However, training a robust\nsegmentation model requires considerably large labeled training samples, which\nmay be impractical. This study aimed to develop a deep learning framework for\ngenerating synthetic lesions that can be used to enhance network training. The\nlesion synthesis network is a modified generative adversarial network (GAN).\nSpecifically, we innovated a partial convolution strategy to construct an\nUnet-like generator. The discriminator is designed using Wasserstein GAN with\ngradient penalty and spectral normalization. A mask generation method based on\nprincipal component analysis was developed to model various lesion shapes. The\ngenerated masks are then converted into liver lesions through a lesion\nsynthesis network. The lesion synthesis framework was evaluated for lesion\ntextures, and the synthetic lesions were used to train a lesion segmentation\nnetwork to further validate the effectiveness of this framework. All the\nnetworks are trained and tested on the public dataset from LITS. The synthetic\nlesions generated by the proposed approach have very similar histogram\ndistributions compared to the real lesions for the two employed texture\nparameters, GLCM-energy and GLCM-correlation. The Kullback-Leibler divergence\nof GLCM-energy and GLCM-correlation were 0.01 and 0.10, respectively. Including\nthe synthetic lesions in the tumor segmentation network improved the\nsegmentation dice performance of U-Net significantly from 67.3% to 71.4%\n(p<0.05). Meanwhile, the volume precision and sensitivity improve from 74.6% to\n76.0% (p=0.23) and 66.1% to 70.9% (p<0.01), respectively. The synthetic data\nsignificantly improves the segmentation performance.",
    "descriptor": "",
    "authors": [
      "Yingao Liu",
      "Fei Yang",
      "Yidong Yang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09065"
  },
  {
    "id": "arXiv:2206.09072",
    "title": "Semi-supervised Time Domain Target Speaker Extraction with Attention",
    "abstract": "In this work, we propose Exformer, a time-domain architecture for target\nspeaker extraction. It consists of a pre-trained speaker embedder network and a\nseparator network based on transformer encoder blocks. We study multiple\nmethods to combine speaker information with the input mixture, and the\nresulting Exformer architecture obtains superior extraction performance\ncompared to prior time-domain networks. Furthermore, we investigate a two-stage\nprocedure to train the model using mixtures without reference signals upon a\npre-trained supervised model. Experimental results show that the proposed\nsemi-supervised learning procedure improves the performance of the supervised\nbaselines.",
    "descriptor": "",
    "authors": [
      "Zhepei Wang",
      "Ritwik Giri",
      "Shrikant Venkataramani",
      "Umut Isik",
      "Jean-Marc Valin",
      "Paris Smaragdis",
      "Mike Goodwin",
      "Arvindh Krishnaswamy"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2206.09072"
  },
  {
    "id": "arXiv:2206.09076",
    "title": "Fair Generalized Linear Models with a Convex Penalty",
    "abstract": "Despite recent advances in algorithmic fairness, methodologies for achieving\nfairness with generalized linear models (GLMs) have yet to be explored in\ngeneral, despite GLMs being widely used in practice. In this paper we introduce\ntwo fairness criteria for GLMs based on equalizing expected outcomes or\nlog-likelihoods. We prove that for GLMs both criteria can be achieved via a\nconvex penalty term based solely on the linear components of the GLM, thus\npermitting efficient optimization. We also derive theoretical properties for\nthe resulting fair GLM estimator. To empirically demonstrate the efficacy of\nthe proposed fair GLM, we compare it with other well-known fair prediction\nmethods on an extensive set of benchmark datasets for binary classification and\nregression. In addition, we demonstrate that the fair GLM can generate fair\npredictions for a range of response variables, other than binary and continuous\noutcomes.",
    "descriptor": "\nComments: Accepted for publication in ICML 2022\n",
    "authors": [
      "Hyungrok Do",
      "Preston Putzel",
      "Axel Martin",
      "Padhraic Smyth",
      "Judy Zhong"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2206.09076"
  },
  {
    "id": "arXiv:2206.09102",
    "title": "Decoupled Federated Learning for ASR with Non-IID Data",
    "abstract": "Automatic speech recognition (ASR) with federated learning (FL) makes it\npossible to leverage data from multiple clients without compromising privacy.\nThe quality of FL-based ASR could be measured by recognition performance,\ncommunication and computation costs. When data among different clients are not\nindependently and identically distributed (non-IID), the performance could\ndegrade significantly. In this work, we tackle the non-IID issue in FL-based\nASR with personalized FL, which learns personalized models for each client.\nConcretely, we propose two types of personalized FL approaches for ASR.\nFirstly, we adapt the personalization layer based FL for ASR, which keeps some\nlayers locally to learn personalization models. Secondly, to reduce the\ncommunication and computation costs, we propose decoupled federated learning\n(DecoupleFL). On one hand, DecoupleFL moves the computation burden to the\nserver, thus decreasing the computation on clients. On the other hand,\nDecoupleFL communicates secure high-level features instead of model parameters,\nthus reducing communication cost when models are large. Experiments demonstrate\ntwo proposed personalized FL-based ASR approaches could reduce WER by 2.3% -\n3.4% compared with FedAvg. Among them, DecoupleFL has only 11.4% communication\nand 75% computation cost compared with FedAvg, which is also significantly less\nthan the personalization layer based FL.",
    "descriptor": "\nComments: Accepted by Interspeech 2022\n",
    "authors": [
      "Han Zhu",
      "Jindong Wang",
      "Gaofeng Cheng",
      "Pengyuan Zhang",
      "Yonghong Yan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2206.09102"
  },
  {
    "id": "arXiv:2206.09103",
    "title": "Identifying Source Speakers for Voice Conversion based Spoofing Attacks  on Speaker Verification Systems",
    "abstract": "An automatic speaker verification system aims to verify the speaker identity\nof a speech signal. However, a voice conversion system manipulates the original\nperson's speech signal to make it sound like the target speaker's voice and\ndeceive the speaker verification system. Most countermeasures for voice\nconversion-based spoofing attacks are designed to discriminate bona fide speech\nfrom spoofed speech for speaker verification systems. In this paper, we\ninvestigate the problem of source speaker identification -- inferring the\nidentity of the source speaker given the voice converted speech. To perform\nsource speaker identification, we simply add voice-converted speech data with\nthe label of source speaker identity to the genuine speech dataset during\nspeaker embedding network training. Experimental results show the feasibility\nof source speaker identification when training and testing with converted\nspeeches from the same voice conversion model(s). When testing on converted\nspeeches from an unseen voice conversion algorithm, the performance of source\nspeaker identification improves when more voice conversion models are used\nduring training.",
    "descriptor": "",
    "authors": [
      "Danwei Cai",
      "Zexin Cai",
      "Ming Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.09103"
  },
  {
    "id": "arXiv:2206.09109",
    "title": "Fast and Provable Tensor Robust Principal Component Analysis via Scaled  Gradient Descent",
    "abstract": "An increasing number of data science and machine learning problems rely on\ncomputation with tensors, which better capture the multi-way relationships and\ninteractions of data than matrices. When tapping into this critical advantage,\na key challenge is to develop computationally efficient and provably correct\nalgorithms for extracting useful information from tensor data that are\nsimultaneously robust to corruptions and ill-conditioning. This paper tackles\ntensor robust principal component analysis (RPCA), which aims to recover a\nlow-rank tensor from its observations contaminated by sparse corruptions, under\nthe Tucker decomposition. To minimize the computation and memory footprints, we\npropose to directly recover the low-dimensional tensor factors -- starting from\na tailored spectral initialization -- via scaled gradient descent (ScaledGD),\ncoupled with an iteration-varying thresholding operation to adaptively remove\nthe impact of corruptions. Theoretically, we establish that the proposed\nalgorithm converges linearly to the true low-rank tensor at a constant rate\nthat is independent with its condition number, as long as the level of\ncorruptions is not too large. Empirically, we demonstrate that the proposed\nalgorithm achieves better and more scalable performance than state-of-the-art\nmatrix and tensor RPCA algorithms through synthetic experiments and real-world\napplications.",
    "descriptor": "",
    "authors": [
      "Harry Dong",
      "Tian Tong",
      "Cong Ma",
      "Yuejie Chi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.09109"
  },
  {
    "id": "arXiv:2206.09120",
    "title": "Pursuit of a Discriminative Representation for Multiple Subspaces via  Sequential Games",
    "abstract": "We consider the problem of learning discriminative representations for data\nin a high-dimensional space with distribution supported on or around multiple\nlow-dimensional linear subspaces. That is, we wish to compute a linear\ninjective map of the data such that the features lie on multiple orthogonal\nsubspaces. Instead of treating this learning problem using multiple PCAs, we\ncast it as a sequential game using the closed-loop transcription (CTRL)\nframework recently proposed for learning discriminative and generative\nrepresentations for general low-dimensional submanifolds. We prove that the\nequilibrium solutions to the game indeed give correct representations. Our\napproach unifies classical methods of learning subspaces with modern deep\nlearning practice, by showing that subspace learning problems may be provably\nsolved using the modern toolkit of representation learning. In addition, our\nwork provides the first theoretical justification for the CTRL framework, in\nthe important case of linear subspaces. We support our theoretical findings\nwith compelling empirical evidence. We also generalize the sequential game\nformulation to more general representation learning problems. Our code,\nincluding methods for easy reproduction of experimental results, is publically\navailable on GitHub.",
    "descriptor": "\nComments: main body is 10 pages and has 4 figures; appendix is 18 pages and has 17 figures; submitted for review at NeurIPS 2022\n",
    "authors": [
      "Druv Pai",
      "Michael Psenka",
      "Chih-Yuan Chiu",
      "Manxi Wu",
      "Edgar Dobriban",
      "Yi Ma"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09120"
  },
  {
    "id": "arXiv:2206.09127",
    "title": "Nonparametric Multi-shape Modeling with Uncertainty Quantification",
    "abstract": "The modeling and uncertainty quantification of closed curves is an important\nproblem in the field of shape analysis, and can have significant ramifications\nfor subsequent statistical tasks. Many of these tasks involve collections of\nclosed curves, which often exhibit structural similarities at multiple levels.\nModeling multiple closed curves in a way that efficiently incorporates such\nbetween-curve dependence remains a challenging problem. In this work, we\npropose and investigate a multiple-output (a.k.a. multi-output),\nmulti-dimensional Gaussian process modeling framework. We illustrate the\nproposed methodological advances, and demonstrate the utility of meaningful\nuncertainty quantification, on several curve and shape-related tasks. This\nmodel-based approach not only addresses the problem of inference on closed\ncurves (and their shapes) with kernel constructions, but also opens doors to\nnonparametric modeling of multi-level dependence for functional objects in\ngeneral.",
    "descriptor": "\nComments: 52 pages, 20 figures\n",
    "authors": [
      "Hengrui Luo",
      "Justin D. Strait"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Differential Geometry (math.DG)",
      "Computation (stat.CO)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2206.09127"
  },
  {
    "id": "arXiv:2206.09128",
    "title": "A Combined PCA-MLP Network for Early Breast Cancer Detection",
    "abstract": "Breast cancer is the second most responsible for all cancer types and has\nbeen the cause of numerous deaths over the years, especially among women. Any\nimprovisation of the existing diagnosis system for the detection of cancer can\ncontribute to minimizing the death ratio. Moreover, cancer detection at an\nearly stage has recently been a prime research area in the scientific community\nto enhance the survival rate. Proper choice of machine learning tools can\nensure early-stage prognosis with high accuracy. In this paper, we have studied\ndifferent machine learning algorithms to detect whether a patient is likely to\nface breast cancer or not. Due to the implicit behavior of early-stage\nfeatures, we have implemented a multilayer perception model with the\nintegration of PCA and suggested it to be more viable than other detection\nalgorithms. Our 4 layers MLP-PCA network has obtained the best accuracy of 100%\nwith a mean of 90.48% accuracy on the BCCD dataset.",
    "descriptor": "",
    "authors": [
      "Md. Wahiduzzaman Khan Arnob",
      "Arunima Dey Pooja",
      "Md. Saif Hassan Onim"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09128"
  },
  {
    "id": "arXiv:2206.09146",
    "title": "Perceptual Optimization of a Biologically-Inspired Tone Mapping Operator",
    "abstract": "With the increasing popularity and accessibility of high dynamic range (HDR)\nphotography, tone mapping operators (TMOs) for dynamic range compression and\nmedium presentation are practically demanding. In this paper, we develop a\ntwo-stage neural network-based HDR image TMO that is biologically-inspired,\ncomputationally efficient, and perceptually optimized. In Stage one, motivated\nby the physiology of the early stages of the human visual system (HVS), we\nfirst decompose an HDR image into a normalized Laplacian pyramid. We then use\ntwo lightweight deep neural networks (DNNs) that take this normalized\nrepresentation as input and estimate the Laplacian pyramid of the corresponding\nLDR image. We optimize the tone mapping network by minimizing the normalized\nLaplacian pyramid distance (NLPD), a perceptual metric calibrated against human\njudgments of tone-mapped image quality. In Stage two, we generate a\npseudo-multi-exposure image stack with different color saturation and detail\nvisibility by inputting an HDR image ``calibrated'' with different maximum\nluminances to the learned tone mapping network. We then train another\nlightweight DNN to fuse the LDR image stack into a desired LDR image by\nmaximizing a variant of MEF-SSIM, another perceptually calibrated metric for\nimage fusion. By doing so, the proposed TMO is fully automatic to tone map\nuncalibrated HDR images. Across an independent set of HDR images, we find that\nour method produces images with consistently better visual quality, and is\namong the fastest local TMOs.",
    "descriptor": "\nComments: 15 pages,13 figures\n",
    "authors": [
      "Peibei Cao",
      "Chenyang Le",
      "Yuming Fang",
      "Kede Ma"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09146"
  },
  {
    "id": "arXiv:2206.09159",
    "title": "Beating the fault-tolerance bound and security loopholes for Byzantine  agreement with a quantum solution",
    "abstract": "Byzantine agreement, the underlying core of blockchain, aims to make every\nnode in a decentralized network reach consensus. However, the classical\nByzantine agreement faces two major problems. One is the $1/3$ fault-tolerance\nbound, which means the system to tolerate $f$ malicious nodes requires at least\n$3f+1$ nodes. The other problem is the security loopholes of its classical\ncryptography methods. Here, we propose a quantum Byzantine agreement that\nexploits the recursion method and quantum digital signatures to break this\nbound with nearly $1/2$ fault-tolerance and provides unconditional security.\nThe consistency check between each pair of rounds ensures the unforgeability\nand nonrepudiation throughout the whole process. Our protocol is highly\npractical for its ability to transmit arbitrarily long messages and mature\ntechniques. For the first time, we experimentally demonstrate three-party and\nfive-party quantum consensus for a digital ledger. Our work suggests an\nimportant avenue for quantum blockchain and quantum consensus networks.",
    "descriptor": "\nComments: 20 pages, 10 figures. All comments are welcome\n",
    "authors": [
      "Chen-Xun Weng",
      "Rui-Qi Gao",
      "Yu Bao",
      "Wen-Bo Liu",
      "Yuan-Mei Xie",
      "Yu-Shuo Lu",
      "Hua-Lei Yin",
      "Zeng-Bing Chen"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.09159"
  },
  {
    "id": "arXiv:2206.09160",
    "title": "Reliable Error Estimates for Optimal Control of Linear Elliptic PDEs  with Random Inputs",
    "abstract": "We discretize a risk-neutral optimal control problem governed by a linear\nelliptic partial differential equation with random inputs using a Monte Carlo\nsample-based approximation and a finite element discretization, yielding finite\ndimensional control problems. We establish an exponential tail bound for the\ndistance between the finite dimensional problems' solutions and the\nrisk-neutral problem's solution. The tail bound implies that solutions to the\nrisk-neutral optimal control problem can be reliably estimated with the\nsolutions to the finite dimensional control problems. Numerical simulations\nillustrate our theoretical findings.",
    "descriptor": "\nComments: 25 pages, 4 figures\n",
    "authors": [
      "Johannes Milz"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.09160"
  },
  {
    "id": "arXiv:2206.09193",
    "title": "Multi-Modality Image Super-Resolution using Generative Adversarial  Networks",
    "abstract": "Over the past few years deep learning-based techniques such as Generative\nAdversarial Networks (GANs) have significantly improved solutions to image\nsuper-resolution and image-to-image translation problems. In this paper, we\npropose a solution to the joint problem of image super-resolution and\nmulti-modality image-to-image translation. The problem can be stated as the\nrecovery of a high-resolution image in a modality, given a low-resolution\nobservation of the same image in an alternative modality. Our paper offers two\nmodels to address this problem and will be evaluated on the recovery of\nhigh-resolution day images given low-resolution night images of the same scene.\nPromising qualitative and quantitative results will be presented for each\nmodel.",
    "descriptor": "",
    "authors": [
      "Aref Abedjooy",
      "Mehran Ebrahimi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09193"
  },
  {
    "id": "arXiv:2206.09194",
    "title": "Efficient Aggregated Kernel Tests using Incomplete $U$-statistics",
    "abstract": "We propose a series of computationally efficient, nonparametric tests for the\ntwo-sample, independence and goodness-of-fit problems, using the Maximum Mean\nDiscrepancy (MMD), Hilbert Schmidt Independence Criterion (HSIC), and Kernel\nStein Discrepancy (KSD), respectively. Our test statistics are incomplete\n$U$-statistics, with a computational cost that interpolates between linear time\nin the number of samples, and quadratic time, as associated with classical\n$U$-statistic tests. The three proposed tests aggregate over several kernel\nbandwidths to detect departures from the null on various scales: we call the\nresulting tests MMDAggInc, HSICAggInc and KSDAggInc. For the test thresholds,\nwe derive a quantile bound for wild bootstrapped incomplete $U$- statistics,\nwhich is of independent interest. We derive uniform separation rates for\nMMDAggInc and HSICAggInc, and quantify exactly the trade-off between\ncomputational efficiency and the attainable rates: this result is novel for\ntests based on incomplete $U$-statistics, to our knowledge. We further show\nthat in the quadratic-time case, the wild bootstrap incurs no penalty to test\npower over more widespread permutation-based approaches, since both attain the\nsame minimax optimal rates (which in turn match the rates that use oracle\nquantiles). We support our claims with numerical experiments on the trade-off\nbetween computational efficiency and test power. In the three testing\nframeworks, we observe that our proposed linear-time aggregated tests obtain\nhigher power than current state-of-the-art linear-time kernel tests.",
    "descriptor": "\nComments: 31 pages\n",
    "authors": [
      "Antonin Schrab",
      "Ilmun Kim",
      "Benjamin Guedj",
      "Arthur Gretton"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2206.09194"
  },
  {
    "id": "arXiv:2206.09209",
    "title": "The Frenet Frame as a Generalization of the Park Transform",
    "abstract": "The paper proposes a generalization of the Park transform based on the Frenet\nframe, which is a special set of coordinates defined in differential geometry\nfor space curves. The proposed geometric transform is first discussed for three\ndimensions, which correspond to the common three-phase circuits. Then, the\nexpression of the time derivative of the proposed transform is discussed and\nthe Frenet-Serret formulas and the Darboux vector are introduced. The change of\nreference frame and its differentiation based on Cartan's moving frames and\nattitude matrices are also described. Finally, the extension to circuits with\nmore than three phases is presented. The features of the Frenet frame are\nillustrated through a variety of examples, including a case study based on the\nIEEE 39-bus system.",
    "descriptor": "\nComments: 10 pages, 2 figures, submitted to the IEEE Transactions on Power Systems\n",
    "authors": [
      "Federico Milano"
    ],
    "subjectives": [
      "Differential Geometry (math.DG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.09209"
  },
  {
    "id": "arXiv:2206.09210",
    "title": "Multi-Modality Image Inpainting using Generative Adversarial Networks",
    "abstract": "Deep learning techniques, especially Generative Adversarial Networks (GANs)\nhave significantly improved image inpainting and image-to-image translation\ntasks over the past few years. To the best of our knowledge, the problem of\ncombining the image inpainting task with the multi-modality image-to-image\ntranslation remains intact. In this paper, we propose a model to address this\nproblem. The model will be evaluated on combined night-to-day image translation\nand inpainting, along with promising qualitative and quantitative results.",
    "descriptor": "",
    "authors": [
      "Aref Abedjooy",
      "Mehran Ebrahimi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09210"
  },
  {
    "id": "arXiv:2206.09222",
    "title": "Bioinspired random projections for robust, sparse classification",
    "abstract": "Inspired by the use of random projections in biological sensing systems, we\npresent a new algorithm for processing data in classification problems. This is\nbased on observations of the human brain and the fruit fly's olfactory system\nand involves randomly projecting data into a space of greatly increased\ndimension before applying a cap operation to truncate the smaller entries. This\nleads to an algorithm that achieves a sparse representation with minimal loss\nin classification accuracy and is also more robust in the sense that\nclassification accuracy is improved when noise is added to the data. This is\ndemonstrated with numerical experiments, which supplement theoretical results\ndemonstrating that the resulting signal transform is continuous and invertible,\nin an appropriate sense.",
    "descriptor": "",
    "authors": [
      "Bryn Davies",
      "Nina Dekoninck Bruhin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2206.09222"
  },
  {
    "id": "arXiv:2206.09230",
    "title": "A Simple Proof of PreciseQMA = PSPACE",
    "abstract": "We give an alternative proof of PreciseQMA = PSPACE, first proved by\nFefferman and Lin (Innov. Theor. Comp. Sci. 2018), where PreciseQMA is the\nclass Quantum Merlin-Arthur with inverse exponential completeness-soundness\ngap. We adapt the proof of Quantum Cook-Levin Theorem to prove the inclusion\nPSPACE in PreciseQMA.",
    "descriptor": "\nComments: 4 pages\n",
    "authors": [
      "Yulong Li"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2206.09230"
  },
  {
    "id": "arXiv:2206.09241",
    "title": "An Empirical Study of Quantum Dynamics as a Ground State Problem with  Neural Quantum States",
    "abstract": "Neural quantum states are variational wave functions parameterised by\nartificial neural networks, a mathematical model studied for decades in the\nmachine learning community. In the context of many-body physics, methods such\nas variational Monte Carlo with neural quantum states as variational wave\nfunctions are successful in approximating, with great accuracy, the\nground-state of a quantum Hamiltonian. However, all the difficulties of\nproposing neural network architectures, along with exploring their expressivity\nand trainability, permeate their application as neural quantum states. In this\npaper, we consider the Feynman-Kitaev Hamiltonian for the transverse field\nIsing model, whose ground state encodes the time evolution of a spin chain at\ndiscrete time steps. We show how this ground state problem specifically\nchallenges the neural quantum state trainability as the time steps increase\nbecause the true ground state becomes more entangled, and the probability\ndistribution starts to spread across the Hilbert space. Our results indicate\nthat the considered neural quantum states are capable of accurately\napproximating the true ground state of the system, i.e., they are expressive\nenough. However, extensive hyper-parameter tuning experiments point towards the\nempirical fact that it is poor trainability--in the variational Monte Carlo\nsetup--that prevents a faithful approximation of the true ground state.",
    "descriptor": "\nComments: 17 pages, 4 figures\n",
    "authors": [
      "Vladimir Vargas-Calder\u00f3n",
      "Herbert Vinck-Posada",
      "Fabio A. Gonz\u00e1lez"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09241"
  },
  {
    "id": "arXiv:2206.09284",
    "title": "Rank-Metric Lattices",
    "abstract": "We introduce the class of rank-metric geometric lattices and initiate the\nstudy of their structural properties. Rank-metric lattices can be seen as the\n$q$-analogues of higher-weight Dowling lattices, defined by Dowling himself in\n1971. We fully characterize the supersolvable rank-metric lattices and compute\ntheir characteristic polynomials. We then concentrate on the smallest\nrank-metric lattice whose characteristic polynomial we cannot compute, and\nprovide a formula for it under a polynomiality assumption on its Whitney\nnumbers of the first kind. The proof relies on computational results and on the\ntheory of vector rank-metric codes, which we review in this paper from the\nperspective of rank-metric lattices. More precisely, we introduce the notion of\nlattice-rank weights of a rank-metric code and investigate their properties as\ncombinatorial invariants and as code distinguishers for inequivalent codes.",
    "descriptor": "",
    "authors": [
      "Giuseppe Cotardo",
      "Alberto Ravagnani"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.09284"
  },
  {
    "id": "arXiv:2206.09285",
    "title": "Q-linear Convergence of Distributed Optimization with Barzilai-Borwein  Step Sizes",
    "abstract": "The growth in sizes of large-scale systems and data in machine learning have\nmade distributed optimization a naturally appealing technique to solve decision\nproblems in different contexts. In such methods, each agent iteratively carries\nout computations on its local objective using information received from its\nneighbors, and shares relevant information with neighboring agents. Though\ngradient-based methods are widely used because of their simplicity, they are\nknown to have slow convergence rates. On the other hand, though Newton-type\nmethods have better convergence properties, they are not as applicable because\nof the enormous computation and memory requirements. In this work, we introduce\na distributed quasi-Newton method with Barzilai-Borwein step-sizes. We prove a\nQ-linear convergence to the optimal solution, present conditions under which\nthe algorithm is superlinearly convergent and validate our results via\nnumerical simulations.",
    "descriptor": "",
    "authors": [
      "Iyanuoluwa Emiola"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.09285"
  },
  {
    "id": "arXiv:2206.09309",
    "title": "TBraTS: Trusted Brain Tumor Segmentation",
    "abstract": "Despite recent improvements in the accuracy of brain tumor segmentation, the\nresults still exhibit low levels of confidence and robustness. Uncertainty\nestimation is one effective way to change this situation, as it provides a\nmeasure of confidence in the segmentation results. In this paper, we propose a\ntrusted brain tumor segmentation network which can generate robust segmentation\nresults and reliable uncertainty estimations without excessive computational\nburden and modification of the backbone network. In our method, uncertainty is\nmodeled explicitly using subjective logic theory, which treats the predictions\nof backbone neural network as subjective opinions by parameterizing the class\nprobabilities of the segmentation as a Dirichlet distribution. Meanwhile, the\ntrusted segmentation framework learns the function that gathers reliable\nevidence from the feature leading to the final segmentation results. Overall,\nour unified trusted segmentation framework endows the model with reliability\nand robustness to out-of-distribution samples. To evaluate the effectiveness of\nour model in robustness and reliability, qualitative and quantitative\nexperiments are conducted on the BraTS 2019 dataset.",
    "descriptor": "\nComments: 11 pages, 4 figures, Accepted by MICCAI 2022\n",
    "authors": [
      "Ke Zou",
      "Xuedong Yuan",
      "Xiaojing Shen",
      "Meng Wang",
      "Huazhu Fu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09309"
  },
  {
    "id": "arXiv:2206.09326",
    "title": "Toward Agile and Robust Supply Chains: A Lesson from Stochastic Job-Shop  Scheduling",
    "abstract": "Motivated by the presence of uncertainties as well as combinatorial\ncomplexity within the links of supply chains, this paper addresses the\noutstanding and timely challenge illustrated through a case study of stochastic\njob-shop scheduling problems arising within low-volume high-variety\nmanufacturing. These problems have been classically formulated as integer\nlinear programs (ILPs), which are known to be NP-hard, and are computationally\nintractable. Yet, optimal or near-optimal solutions must be obtained within\nstrict computational time requirements. While the deterministic cases have been\nefficiently solved by state-of-the-art methods such as branch-and-cut (B&C),\nuncertainties may compromise the entire schedule thereby potentially affecting\nthe entire supply chain downstream, thus, uncertainties must be explicitly\ncaptured to ensure the feasibility of operations. The stochastic nature of the\nresulting problem adds a layer of computational difficulty on top of an already\nintractable problem, as evidenced by the presented case studies with some cases\ntaking hours without being able to find a \"near-optimal\" schedule. To\nefficiently solve the stochastic JSS problem, a recent Surrogate \"Level-Based\"\nLagrangian Relaxation is used to reduce computational effort while efficiently\nexploiting geometric convergence potential inherent to Polyak's step-sizing\nformula thereby leading to fast convergence. Computational results demonstrate\nthat the new method is more than two orders of magnitude faster compared to\nB&C. Moreover, insights based on a small intuitive example are provided through\nsimulations demonstrating an advantage of scholastic scheduling.",
    "descriptor": "",
    "authors": [
      "Mikhail A. Bragin",
      "Matthew E. Wilhelm",
      "Matthew D. Stuber"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.09326"
  },
  {
    "id": "arXiv:2206.09364",
    "title": "Quantum implementation of circulant matrices and its use in quantum  string processing",
    "abstract": "Strings problems in general can be solved faster by using special data\nstructures such as suffixes in many cases structured as trees and arrays. In\nthis paper, we show that suffixes used in those data structures can be obtained\nby using circulant matrices as a quantum operator which can be implemented in\nlogarithmic time. Hence, if the strings are given as quantum states, using the\npresented circuit implementation one can do string processing efficiently on\nquantum computers.",
    "descriptor": "\nComments: 5 pages: Short version for conference\n",
    "authors": [
      "Ammar Daskin"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.09364"
  },
  {
    "id": "arXiv:2206.09370",
    "title": "Frank-Wolfe-based Algorithms for Approximating Tyler's M-estimator",
    "abstract": "Tyler's M-estimator is a well known procedure for robust and heavy-tailed\ncovariance estimation. Tyler himself suggested an iterative fixed-point\nalgorithm for computing his estimator however, it requires super-linear (in the\nsize of the data) runtime per iteration, which may be prohibitive in large\nscale. In this work we propose, to the best of our knowledge, the first\nFrank-Wolfe-based algorithms for computing Tyler's estimator. One variant uses\nstandard Frank-Wolfe steps, the second also considers \\textit{away-steps}\n(AFW), and the third is a \\textit{geodesic} version of AFW (GAFW). AFW provably\nrequires, up to a log factor, only linear time per iteration, while GAFW runs\nin linear time (up to a log factor) in a large $n$ (number of data-points)\nregime. All three variants are shown to provably converge to the optimal\nsolution with sublinear rate, under standard assumptions, despite the fact that\nthe underlying optimization problem is not convex nor smooth. Under an\nadditional fairly mild assumption, that holds with probability 1 when the\n(normalized) data-points are i.i.d. samples from a continuous distribution\nsupported on the entire unit sphere, AFW and GAFW are proved to converge with\nlinear rates. Importantly, all three variants are parameter-free and use\nadaptive step-sizes.",
    "descriptor": "",
    "authors": [
      "Lior Danon",
      "Dan Garber"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.09370"
  },
  {
    "id": "arXiv:2206.09376",
    "title": "Encoding High-level Quantum Programs as SZX-diagrams",
    "abstract": "The Scalable ZX-calculus is a compact graphical language used to reason about\nlinear maps between quantum states. These diagrams have multiple applications,\nbut they frequently have to be constructed in a case-by-case basis. In this\nwork we present a method to encode quantum programs implemented in a fragment\nof the linear dependently typed Proto-Quipper-D language as families of\nSZX-diagrams. We define a subset of translatable Proto-Quipper-D programs and\nshow that our procedure is able to encode non-trivial algorithms as diagrams\nthat grow linearly on the size of the program.",
    "descriptor": "\nComments: Accepted at QPL2022\n",
    "authors": [
      "Agust\u00edn Borgna",
      "Rafael Romero"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2206.09376"
  },
  {
    "id": "arXiv:2206.09381",
    "title": "Graph Neural Network Aided MU-MIMO Detectors",
    "abstract": "Multi-user multiple-input multiple-output (MU-MIMO) systems can be used to\nmeet high throughput requirements of 5G and beyond networks. A base station\nserves many users in an uplink MU-MIMO system, leading to a substantial\nmulti-user interference (MUI). Designing a high-performance detector for\ndealing with a strong MUI is challenging. This paper analyses the performance\ndegradation caused by the posterior distribution approximation used in the\nstate-of-the-art message passing (MP) detectors in the presence of high MUI. We\ndevelop a graph neural network based framework to fine-tune the MP detectors'\ncavity distributions and thus improve the posterior distribution approximation\nin the MP detectors. We then propose two novel neural network based detectors\nwhich rely on the expectation propagation (EP) and Bayesian parallel\ninterference cancellation (BPIC), referred to as the GEPNet and GPICNet\ndetectors, respectively. The GEPNet detector maximizes detection performance,\nwhile GPICNet detector balances the performance and complexity. We provide\nproof of the permutation equivariance property, allowing the detectors to be\ntrained only once, even in the systems with dynamic changes of the number of\nusers. The simulation results show that the proposed GEPNet detector\nperformance approaches maximum likelihood performance in various configurations\nand GPICNet detector doubles the multiplexing gain of BPIC detector.",
    "descriptor": "\nComments: Source Code: this https URL\n",
    "authors": [
      "Alva Kosasih",
      "Vincent Onasis",
      "Vera Miloslavskaya",
      "Wibowo Hardjawana",
      "Victor Andrean",
      "Branka Vucetic"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.09381"
  },
  {
    "id": "arXiv:2206.09396",
    "title": "Transfer Learning for Robust Low-Resource Children's Speech ASR with  Transformers and Source-Filter Warping",
    "abstract": "Automatic Speech Recognition (ASR) systems are known to exhibit difficulties\nwhen transcribing children's speech. This can mainly be attributed to the\nabsence of large children's speech corpora to train robust ASR models and the\nresulting domain mismatch when decoding children's speech with systems trained\non adult data. In this paper, we propose multiple enhancements to alleviate\nthese issues. First, we propose a data augmentation technique based on the\nsource-filter model of speech to close the domain gap between adult and\nchildren's speech. This enables us to leverage the data availability of adult\nspeech corpora by making these samples perceptually similar to children's\nspeech. Second, using this augmentation strategy, we apply transfer learning on\na Transformer model pre-trained on adult data. This model follows the recently\nintroduced XLS-R architecture, a wav2vec 2.0 model pre-trained on several\ncross-lingual adult speech corpora to learn general and robust acoustic\nframe-level representations. Adopting this model for the ASR task using adult\ndata augmented with the proposed source-filter warping strategy and a limited\namount of in-domain children's speech significantly outperforms previous\nstate-of-the-art results on the PF-STAR British English Children's Speech\ncorpus with a 4.86% WER on the official test set.",
    "descriptor": "\nComments: proceedings of INTERSPEECH 2022\n",
    "authors": [
      "Jenthe Thienpondt",
      "Kris Demuynck"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2206.09396"
  },
  {
    "id": "arXiv:2206.09411",
    "title": "A Stirling-type formula for the distribution of the length of longest  increasing subsequences, applied to finite size corrections to the random  matrix limit",
    "abstract": "The discrete distribution of the length of longest increasing subsequences in\nrandom permutations of order $n$ is deeply related to random matrix theory. In\na seminal work, Baik, Deift and Johansson provided an asymptotics in terms of\nthe distribution of the largest level of the large matrix limit of GUE. As a\nnumerical approximation, however, this asymptotics is inaccurate for small\nlengths and has a slow convergence rate, conjectured to be just of order\n$n^{-1/3}$. Here, we suggest a different type of approximation, based on\nHayman's generalization of Stirling's formula. Such a formula gives already a\ncouple of correct digits of the length distribution for $n$ as small as $20$\nbut allows numerical evaluations, with a uniform error of apparent order\n$n^{-3/4}$, for $n$ as large as $10^{12}$; thus closing the gap between tables\nof exact values (that have recently been compiled for $n$ up to $750$) and the\nrandom matrix limit. Being much more efficient and accurate than Monte-Carlo\nsimulations for larger $n$, the Stirling-type formula allows for a precise\nnumerical understanding of the first few finite size correction terms to the\nrandom matrix limit, a study that has recently been initiated by Forrester and\nMays, who visualized the form of the first such term. We display also the\nsecond one, of order $n^{-2/3}$, and derive (heuristically) an expansion of the\nexpected value of the length, exhibiting three more terms than previously\nknown.",
    "descriptor": "\nComments: 24 pages, 6 figures, 3 tables\n",
    "authors": [
      "Folkmar Bornemann"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Mathematical Physics (math-ph)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2206.09411"
  },
  {
    "id": "arXiv:2206.09415",
    "title": "Strong Converse Bounds for Compression of Mixed States",
    "abstract": "We consider many copies of a general mixed-state source $\\rho^{AR}$ shared\nbetween an encoder and an inaccessible reference system $R$. We obtain a strong\nconverse bound for the compression of this source. This immediately implies a\nstrong converse for the blind compression of ensembles of mixed states since\nthis is a special case of the general mixed-state source $\\rho^{AR}$. Moreover,\nwe consider the visible compression of ensembles of mixed states. For a\nbipartite state $\\rho^{AR}$, we define a new quantity\n$E_{\\alpha,p}(A:R)_{\\rho}$ for $\\alpha \\in (0,1)\\cup (1,\\infty)$ as the\n$\\alpha$-R\\'enyi generalization of the entanglement of purification\n$E_{p}(A:R)_{\\rho}$. For $\\alpha=1$, we define\n$E_{1,p}(A:R)_{\\rho}:=E_{p}(A:R)_{\\rho}$. We show that for any rate below the\nregularization $\\lim_{\\alpha \\to\n1^+}E_{\\alpha,p}^{\\infty}(A:R)_{\\rho}:=\\lim_{\\alpha \\to 1^+} \\lim_{n \\to\n\\infty} \\frac{E_{\\alpha,p}(A^n:R^n)_{\\rho^{\\otimes n}}}{n}$ the fidelity for\nthe visible compression of ensembles of mixed states exponentially converges to\nzero. We conclude that if this regularized quantity is continuous with respect\nto $\\alpha$, namely, if $\\lim_{\\alpha \\to\n1^+}E_{\\alpha,p}^{\\infty}(A:R)_{\\rho}=E_{p}^{\\infty}(A:R)_{\\rho}$, then the\nstrong converse holds for the visible compression of ensembles of mixed states.",
    "descriptor": "",
    "authors": [
      "Zahra Baghali Khanian"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.09415"
  },
  {
    "id": "arXiv:2206.09429",
    "title": "A generalized regionalization framework for geographical modelling and  its application in spatial regression",
    "abstract": "In presence of spatial heterogeneity, models applied to geographic data face\na trade-off between producing general results and capturing local variations.\nModelling at a regional scale may allow the identification of solutions that\noptimize both accuracy and generality. However, most current regionalization\nalgorithms assume homogeneity in the attributes to delineate regions without\nconsidering the processes that generate the attributes. In this paper, we\npropose a generalized regionalization framework based on a two-item objective\nfunction which favors solutions with the highest overall accuracy while\nminimizing the number of regions. We introduce three regionalization\nalgorithms, which extend previous methods that account for spatially\nconstrained clustering. The effectiveness of the proposed framework is examined\nin regression experiments on both simulated and real data. The results show\nthat a spatially implicit algorithm extended with an automatic post-processing\nprocedure outperforms spatially explicit approaches. Our suggested framework\ncontributes to better capturing the processes associated with spatial\nheterogeneity with potential applications in a wide range of geographical\nmodels.",
    "descriptor": "\nComments: 28 pages, 12 figures\n",
    "authors": [
      "Hao Guo",
      "Andre Python",
      "Yu Liu"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09429"
  },
  {
    "id": "arXiv:2206.09446",
    "title": "Compression and Data Similarity: Combination of Two Techniques for  Communication-Efficient Solving of Distributed Variational Inequalities",
    "abstract": "Variational inequalities are an important tool, which includes minimization,\nsaddles, games, fixed-point problems. Modern large-scale and computationally\nexpensive practical applications make distributed methods for solving these\nproblems popular. Meanwhile, most distributed systems have a basic problem - a\ncommunication bottleneck. There are various techniques to deal with it. In\nparticular, in this paper we consider a combination of two popular approaches:\ncompression and data similarity. We show that this synergy can be more\neffective than each of the approaches separately in solving distributed smooth\nstrongly monotonic variational inequalities. Experiments confirm the\ntheoretical conclusions.",
    "descriptor": "\nComments: 19 pages, 1 algorithm, 1 figure, 1 table, 1 theorem\n",
    "authors": [
      "Aleksandr Beznosikov",
      "Alexander Gasnikov"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09446"
  },
  {
    "id": "arXiv:2206.09462",
    "title": "Fast Krasnosel'skii-Mann algorithm with a convergence rate of the fixed  point iteration of $o(1/k)$",
    "abstract": "The Krasnosel'skii-Mann (KM) algorithm is the most fundamental iterative\nscheme designed to find a fixed point of an averaged operator in the framework\nof a real Hilbert space, since it lies at the heart of various numerical\nalgorithms for solving monotone inclusions and convex optimization problems. We\nenhance the Krasnosel'skii-Mann algorithm with Nesterov's momentum updates and\nshow that the resulting numerical method exhibits a convergence rate for the\nfixed point residual of $o(1/k)$ while preserving the weak convergence of the\niterates to a fixed point of the operator. Numerical experiments illustrate the\nsuperiority of the resulting so-called Fast KM algorithm over various fixed\npoint iterative schemes, and also its oscillatory behavior, which is a specific\nof Nesterov's momentum optimization algorithms.",
    "descriptor": "",
    "authors": [
      "Radu Ioan Bot",
      "Dang-Khoa Nguyen"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.09462"
  },
  {
    "id": "arXiv:2206.09490",
    "title": "A Bounded-Confidence Model of Opinion Dynamics with Heterogeneous  Node-Activity Levels",
    "abstract": "Agent-based models of opinion dynamics examine the spread of opinions between\nentities and allow one to study phenomena such as consensus, polarization, and\nfragmentation. One examines them on social networks to investigate the effects\nof network structure on these phenomena. In social networks, some individuals\nshare their ideas and opinions more frequently than others. These disparities\ncan arise from heterogeneous sociabilities, heterogeneous activity levels,\ndifferent prevalences to share opinions when engaging in a social-media\nplatform, or something else. To examine the impact of such heterogeneities on\nopinion dynamics, we generalize the Deffuant--Weisbuch (DW) bounded-confidence\nmodel (BCM) of opinion dynamics by incorporating node weights. The node weights\nallow us to model agents with different probabilities of interacting. Using\nnumerical simulations, we systematically investigate (using a variety of\nnetwork structures and node-weight distributions) the effects of node weights,\nwhich we assign uniformly at random to the nodes. We demonstrate that\nintroducing heterogeneous node weights results in longer convergence times and\nmore opinion fragmentation than in a baseline DW model. One can use the node\nweights of our BCM to capture a variety of sociological scenarios in which\nagents have heterogeneous probabilities of interacting with other agents.",
    "descriptor": "",
    "authors": [
      "Grace J. Li",
      "Mason A. Porter"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.09490"
  },
  {
    "id": "arXiv:2206.09507",
    "title": "Resource-Efficient Separation Transformer",
    "abstract": "Transformers have recently achieved state-of-the-art performance in speech\nseparation. These models, however, are computationally-demanding and require a\nlot of learnable parameters. This paper explores Transformer-based speech\nseparation with a reduced computational cost. Our main contribution is the\ndevelopment of the Resource-Efficient Separation Transformer (RE-SepFormer), a\nself-attention-based architecture that reduces the computational burden in two\nways. First, it uses non-overlapping blocks in the latent space. Second, it\noperates on compact latent summaries calculated from each chunk. The\nRE-SepFormer reaches a competitive performance on the popular WSJ0-2Mix and\nWHAM! datasets in both causal and non-causal settings. Remarkably, it scales\nsignificantly better than the previous Transformer and RNN-based architectures\nin terms of memory and inference-time, making it more suitable for processing\nlong mixtures.",
    "descriptor": "\nComments: Submitted to IEEE Signal Processing Letters\n",
    "authors": [
      "Cem Subakan",
      "Mirco Ravanelli",
      "Samuele Cornell",
      "Fr\u00e9d\u00e9ric Lepoutre",
      "Fran\u00e7ois Grondin"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.09507"
  },
  {
    "id": "arXiv:2206.09513",
    "title": "$C^*$-algebra Net: A New Approach Generalizing Neural Network Parameters  to $C^*$-algebra",
    "abstract": "We propose a new framework that generalizes the parameters of neural network\nmodels to $C^*$-algebra-valued ones. $C^*$-algebra is a generalization of the\nspace of complex numbers. A typical example is the space of continuous\nfunctions on a compact space. This generalization enables us to combine\nmultiple models continuously and use tools for functions such as regression and\nintegration. Consequently, we can learn features of data efficiently and adapt\nthe models to problems continuously. We apply our framework to practical\nproblems such as density estimation and few-shot learning and show that our\nframework enables us to learn features of data even with a limited number of\nsamples. Our new framework highlights the potential possibility of applying the\ntheory of $C^*$-algebra to general neural network models.",
    "descriptor": "\nComments: Accepted at ICML 2022\n",
    "authors": [
      "Yuka Hashimoto",
      "Zhao Wang",
      "Tomoko Matsu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09513"
  },
  {
    "id": "arXiv:2206.09522",
    "title": "Multiple Testing Framework for Out-of-Distribution Detection",
    "abstract": "We study the problem of Out-of-Distribution (OOD) detection, that is,\ndetecting whether a learning algorithm's output can be trusted at inference\ntime. While a number of tests for OOD detection have been proposed in prior\nwork, a formal framework for studying this problem is lacking. We propose a\ndefinition for the notion of OOD that includes both the input distribution and\nthe learning algorithm, which provides insights for the construction of\npowerful tests for OOD detection. We propose a multiple hypothesis testing\ninspired procedure to systematically combine any number of different statistics\nfrom the learning algorithm using conformal p-values. We further provide strong\nguarantees on the probability of incorrectly classifying an in-distribution\nsample as OOD. In our experiments, we find that threshold-based tests proposed\nin prior work perform well in specific settings, but not uniformly well across\ndifferent types of OOD instances. In contrast, our proposed method that\ncombines multiple statistics performs uniformly well across different datasets\nand neural networks.",
    "descriptor": "",
    "authors": [
      "Akshayaa Magesh",
      "Venugopal V. Veeravalli",
      "Anirban Roy",
      "Susmit Jha"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09522"
  },
  {
    "id": "arXiv:2206.09523",
    "title": "Towards Trustworthy Edge Intelligence: Insights from Voice-Activated  Services",
    "abstract": "In an age of surveillance capitalism, anchoring the design of emerging smart\nservices in trustworthiness is urgent and important. Edge Intelligence, which\nbrings together the fields of AI and Edge computing, is a key enabling\ntechnology for smart services. Trustworthy Edge Intelligence should thus be a\npriority research concern. However, determining what makes Edge Intelligence\ntrustworthy is not straight forward. This paper examines requirements for\ntrustworthy Edge Intelligence in a concrete application scenario of\nvoice-activated services. We contribute to deepening the understanding of\ntrustworthiness in the emerging Edge Intelligence domain in three ways:\nfirstly, we propose a unified framing for trustworthy Edge Intelligence that\njointly considers trustworthiness attributes of AI and the IoT. Secondly, we\npresent research outputs of a tangible case study in voice-activated services\nthat demonstrates interdependencies between three important trustworthiness\nattributes: privacy, security and fairness. Thirdly, based on the empirical and\nanalytical findings, we highlight challenges and open questions that present\nimportant future research areas for trustworthy Edge Intelligence.",
    "descriptor": "",
    "authors": [
      "W.T. Hutiri",
      "A.Y. Ding"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computers and Society (cs.CY)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2206.09523"
  },
  {
    "id": "arXiv:2206.09543",
    "title": "Meta-learning for Out-of-Distribution Detection via Density Estimation  in Latent Space",
    "abstract": "Many neural network-based out-of-distribution (OoD) detection methods have\nbeen proposed. However, they require many training data for each target task.\nWe propose a simple yet effective meta-learning method to detect OoD with small\nin-distribution data in a target task. With the proposed method, the OoD\ndetection is performed by density estimation in a latent space. A neural\nnetwork shared among all tasks is used to flexibly map instances in the\noriginal space to the latent space. The neural network is meta-learned such\nthat the expected OoD detection performance is improved by using various tasks\nthat are different from the target tasks. This meta-learning procedure enables\nus to obtain appropriate representations in the latent space for OoD detection.\nFor density estimation, we use a Gaussian mixture model (GMM) with full\ncovariance for each class. We can adapt the GMM parameters to in-distribution\ndata in each task in a closed form by maximizing the likelihood. Since the\nclosed form solution is differentiable, we can meta-learn the neural network\nefficiently with a stochastic gradient descent method by incorporating the\nsolution into the meta-learning objective function. In experiments using six\ndatasets, we demonstrate that the proposed method achieves better performance\nthan existing meta-learning and OoD detection methods.",
    "descriptor": "",
    "authors": [
      "Tomoharu Iwata",
      "Atsutoshi Kumagai"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09543"
  },
  {
    "id": "arXiv:2206.09556",
    "title": "An Empirical Analysis on the Vulnerabilities of End-to-End Speech  Segregation Models",
    "abstract": "End-to-end learning models have demonstrated a remarkable capability in\nperforming speech segregation. Despite their wide-scope of real-world\napplications, little is known about the mechanisms they employ to group and\nconsequently segregate individual speakers. Knowing that harmonicity is a\ncritical cue for these networks to group sources, in this work, we perform a\nthorough investigation on ConvTasnet and DPT-Net to analyze how they perform a\nharmonic analysis of the input mixture. We perform ablation studies where we\napply low-pass, high-pass, and band-stop filters of varying pass-bands to\nempirically analyze the harmonics most critical for segregation. We also\ninvestigate how these networks decide which output channel to assign to an\nestimated source by introducing discontinuities in synthetic mixtures. We find\nthat end-to-end networks are highly unstable, and perform poorly when\nconfronted with deformations which are imperceptible to humans. Replacing the\nencoder in these networks with a spectrogram leads to lower overall\nperformance, but much higher stability. This work helps us to understand what\ninformation these network rely on for speech segregation, and exposes two\nsources of generalization-errors. It also pinpoints the encoder as the part of\nthe network responsible for these errors, allowing for a redesign with expert\nknowledge or transfer learning.",
    "descriptor": "\nComments: Accepted at Interspeech 2022\n",
    "authors": [
      "Rahil Parikh",
      "Gaspar Rochette",
      "Carol Espy-Wilson",
      "Shihab Shamma"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.09556"
  },
  {
    "id": "arXiv:2206.09571",
    "title": "Deep Random Vortex Method for Simulation and Inference of Navier-Stokes  Equations",
    "abstract": "Navier-Stokes equations are significant partial differential equations that\ndescribe the motion of fluids such as liquids and air. Due to the importance of\nNavier-Stokes equations, the development on efficient numerical schemes is\nimportant for both science and engineer. Recently, with the development of AI\ntechniques, several approaches have been designed to integrate deep neural\nnetworks in simulating and inferring the fluid dynamics governed by\nincompressible Navier-Stokes equations, which can accelerate the simulation or\ninferring process in a mesh-free and differentiable way. In this paper, we\npoint out that the capability of existing deep Navier-Stokes informed methods\nis limited to handle non-smooth or fractional equations, which are two critical\nsituations in reality. To this end, we propose the \\emph{Deep Random Vortex\nMethod} (DRVM), which combines the neural network with a random vortex dynamics\nsystem equivalent to the Navier-Stokes equation. Specifically, the random\nvortex dynamics motivates a Monte Carlo based loss function for training the\nneural network, which avoids the calculation of derivatives through\nauto-differentiation. Therefore, DRVM not only can efficiently solve\nNavier-Stokes equations involving rough path, non-differentiable initial\nconditions and fractional operators, but also inherits the mesh-free and\ndifferentiable benefits of the deep-learning-based solver. We conduct\nexperiments on the Cauchy problem, parametric solver learning, and the inverse\nproblem of both 2-d and 3-d incompressible Navier-Stokes equations. The\nproposed method achieves accurate results for simulation and inference of\nNavier-Stokes equations. Especially for the cases that include singular initial\nconditions, DRVM significantly outperforms existing PINN method.",
    "descriptor": "",
    "authors": [
      "Rui Zhang",
      "Peiyan Hu",
      "Qi Meng",
      "Yue Wang",
      "Rongchan Zhu",
      "Bingguang Chen",
      "Zhi-Ming Ma",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2206.09571"
  },
  {
    "id": "arXiv:2206.09595",
    "title": "Reconstruction and segmentation from sparse sequential X-ray  measurements of wood logs",
    "abstract": "In industrial applications it is common to scan objects on a moving conveyor\nbelt. If slice-wise 2D computed tomography (CT) measurements of the moving\nobject are obtained we call it a sequential scanning geometry. In this case,\neach slice on its own does not carry sufficient information to reconstruct a\nuseful tomographic image. Thus, here we propose the use of a Dimension reduced\nKalman Filter to accumulate information between slices and allow for\nsufficiently accurate reconstructions for further assessment of the object.\nAdditionally, we propose to use an unsupervised clustering approach known as\nDensity Peak Advanced, to perform a segmentation and spot density anomalies in\nthe internal structure of the reconstructed objects. We evaluate the method in\na proof of concept study for the application of wood log scanning for the\nindustrial sawing process, where the goal is to spot anomalies within the wood\nlog to allow for optimal sawing patterns. Reconstruction and segmentation\nquality is evaluated from experimental measurement data for various scenarios\nof severely undersampled X-measurements. Results show clearly that an\nimprovement of reconstruction quality can be obtained by employing the\nDimension reduced Kalman Filter allowing to robustly obtain the segmented logs.",
    "descriptor": "",
    "authors": [
      "Sebastian Springer",
      "Aldo Glielmo",
      "Angelina Senchukova",
      "Tomi Kauppi",
      "Jarkko Suuronen",
      "Lassi Roininen",
      "Heikki Haario",
      "Andreas Hauptmann"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Optimization and Control (math.OC)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2206.09595"
  },
  {
    "id": "arXiv:2206.09608",
    "title": "MF-OMO: An Optimization Formulation of Mean-Field Games",
    "abstract": "Recently, theory of mean-field games (MFGs) has experienced an exponential\ngrowth. However, existing analytical approaches are by and large restricted to\ncontractive or monotone settings, or with an a priori assumption of the\nuniqueness of the Nash equilibrium (NE) solution for computational feasibility.\nThis paper proposes a new mathematical framework to analyze discrete-time MFGs\nwith none of these restrictions. The key idea is to reformulate the problem of\nfinding NE solutions in MFGs as solving (equivalently) an optimization problem\nwith bounded variables and simple convex constraints. This is built on the\nclassical work of reformulating a Markov decision process (MDP) as a linear\nprogram, and by adding the consistency constraint for MFGs in terms of\noccupation measures, and by exploiting the complementarity structure of the\nlinear program. Under proper regularity conditions for the rewards and the\ndynamics of the game, the corresponding framework, called MF-OMO (Mean-Field\nOccupation Measure Optimization), is shown to provide convergence guarantees\nfor finding multiple (and possibly all) NE solutions of MFGs by popular\nalgorithms such as projected gradient descent. In particular, we show that\nanalyzing the class of MFGs with linear rewards and mean-field independent\ndynamics can be reduced to solving a finite number of linear programs, hence\nsolved in finite time. This optimization framework can be easily extended for\nvariants of MFGs, including but not limited to personalized MFGs and\nmulti-population MFGs.",
    "descriptor": "",
    "authors": [
      "Xin Guo",
      "Anran Hu",
      "Junzi Zhang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Multiagent Systems (cs.MA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2206.09608"
  },
  {
    "id": "arXiv:2206.09611",
    "title": "SJ-HD^2R: Selective Joint High Dynamic Range and Denoising Imaging for  Dynamic Scenes",
    "abstract": "Ghosting artifacts, motion blur, and low fidelity in highlight are the main\nchallenges in High Dynamic Range (HDR) imaging from multiple Low Dynamic Range\n(LDR) images. These issues come from using the medium-exposed image as the\nreference frame in previous methods. To deal with them, we propose to use the\nunder-exposed image as the reference to avoid these issues. However, the heavy\nnoise in dark regions of the under-exposed image becomes a new problem.\nTherefore, we propose a joint HDR and denoising pipeline, containing two\nsub-networks: (i) a pre-denoising network (PreDNNet) to adaptively denoise\ninput LDRs by exploiting exposure priors; (ii) a pyramid cascading fusion\nnetwork (PCFNet), introducing an attention mechanism and cascading structure in\na multi-scale manner. To further leverage these two paradigms, we propose a\nselective and joint HDR and denoising (SJ-HD$^2$R) imaging framework, utilizing\nscenario-specific priors to conduct the path selection with an accuracy of more\nthan 93.3$\\%$. We create the first joint HDR and denoising benchmark dataset,\nwhich contains a variety of challenging HDR and denoising scenes and supports\nthe switching of the reference image. Extensive experiment results show that\nour method achieves superior performance to previous methods.",
    "descriptor": "",
    "authors": [
      "Wei Li",
      "Shuai Xiao",
      "Tianhong Dai",
      "Shanxin Yuan",
      "Tao Wang",
      "Cheng Li",
      "Fenglong Song"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09611"
  },
  {
    "id": "arXiv:2206.09625",
    "title": "Continuous boundary condition at the interface for two coupled fluids",
    "abstract": "We consider two laminar incompressible flows coupled by the continuous law at\na fixed interface. We approach the system by one that satisfies a friction\nNavier law, and we show that when the friction coefficient goes to infinity,\nthe solutions converges to a solution of the initial system. We then write a\nnumerical Schwarz-like coupling algorithm and run 2D-simulations, that yields\nsame convergence result.",
    "descriptor": "",
    "authors": [
      "Fran\u00e7ois Legeais",
      "Roger Lewandowski"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.09625"
  },
  {
    "id": "arXiv:2206.09649",
    "title": "A Machine Learning Data Fusion Model for Soil Moisture Retrieval",
    "abstract": "We develop a deep learning based convolutional-regression model that\nestimates the volumetric soil moisture content in the top ~5 cm of soil. Input\npredictors include Sentinel-1 (active radar), Sentinel-2 (optical imagery), and\nSMAP (passive radar) as well as geophysical variables from SoilGrids and\nmodelled soil moisture fields from GLDAS. The model was trained and evaluated\non data from ~1300 in-situ sensors globally over the period 2015 - 2021 and\nobtained an average per-sensor correlation of 0.727 and ubRMSE of 0.054, and\ncan be used to produce a soil moisture map at a nominal 320m resolution. These\nresults are benchmarked against 13 other soil moisture works at different\nlocations, and an ablation study was used to identify important predictors.",
    "descriptor": "\nComments: 73 pages, 21 tables, 26 figures\n",
    "authors": [
      "Vishal Batchu",
      "Grey Nearing",
      "Varun Gulshan"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09649"
  },
  {
    "id": "arXiv:2206.09662",
    "title": "On approximating the rank of graph divisors",
    "abstract": "Baker and Norine initiated the study of graph divisors as a graph-theoretic\nanalogue of the Riemann-Roch theory for Riemann surfaces. One of the key\nconcepts of graph divisor theory is the {\\it rank} of a divisor on a graph. The\nimportance of the rank is well illustrated by Baker's {\\it Specialization\nlemma}, stating that the dimension of a linear system can only go up under\nspecialization from curves to graphs, leading to a fruitful interaction between\ndivisors on graphs and curves.\nDue to its decisive role, determining the rank is a central problem in graph\ndivisor theory. Kiss and T\\'othm\\'eresz reformulated the problem using\nchip-firing games, and showed that computing the rank of a divisor on a graph\nis NP-hard via reduction from the Minimum Feedback Arc Set problem.\nIn this paper, we strengthen their result by establishing a connection\nbetween chip-firing games and the Minimum Target Set Selection problem. As a\ncorollary, we show that the rank is difficult to approximate to within a factor\nof $O(2^{\\log^{1-\\varepsilon}n})$ for any $\\varepsilon > 0$ unless $P=NP$.\nFurthermore, assuming the Planted Dense Subgraph Conjecture, the rank is\ndifficult to approximate to within a factor of $O(n^{1/4-\\varepsilon})$ for any\n$\\varepsilon>0$.",
    "descriptor": "\nComments: 11 pages, 3 figures\n",
    "authors": [
      "Krist\u00f3f B\u00e9rczi",
      "Hung P. Hoang",
      "Lilla T\u00f3thm\u00e9r\u00e9sz"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2206.09662"
  },
  {
    "id": "arXiv:2206.09709",
    "title": "A Note on the Convergence of Mirrored Stein Variational Gradient Descent  under $(L_0,L_1)-$Smoothness Condition",
    "abstract": "In this note, we establish a descent lemma for the population limit Mirrored\nStein Variational Gradient Method~(MSVGD). This descent lemma does not rely on\nthe path information of MSVGD but rather on a simple assumption for the\nmirrored distribution $\\nabla\\Psi_{\\#}\\pi\\propto\\exp(-V)$. Our analysis\ndemonstrates that MSVGD can be applied to a broader class of constrained\nsampling problems with non-smooth $V$. We also investigate the complexity of\nthe population limit MSVGD in terms of dimension $d$.",
    "descriptor": "\nComments: first draft and will be modified\n",
    "authors": [
      "Lukang Sun",
      "Peter Richt\u00e1rik"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2206.09709"
  },
  {
    "id": "arXiv:2206.09766",
    "title": "Quantitative CT texture-based method to predict diagnosis and prognosis  of fibrosing interstitial lung disease patterns",
    "abstract": "Purpose: To utilize high-resolution quantitative CT (QCT) imaging features\nfor prediction of diagnosis and prognosis in fibrosing interstitial lung\ndiseases (ILD). Approach: 40 ILD patients (20 usual interstitial pneumonia\n(UIP), 20 non-UIP pattern ILD) were classified by expert consensus of 2\nradiologists and followed for 7 years. Clinical variables were recorded.\nFollowing segmentation of the lung field, a total of 26 texture features were\nextracted using a lattice-based approach (TM model). The TM model was compared\nwith previously histogram-based model (HM) for their abilities to classify UIP\nvs non-UIP. For prognostic assessment, survival analysis was performed\ncomparing the expert diagnostic labels versus TM metrics. Results: In the\nclassification analysis, the TM model outperformed the HM method with AUC of\n0.70. While survival curves of UIP vs non-UIP expert labels in Cox regression\nanalysis were not statistically different, TM QCT features allowed\nstatistically significant partition of the cohort. Conclusions: TM model\noutperformed HM model in distinguishing UIP from non-UIP patterns. Most\nimportantly, TM allows for partitioning of the cohort into distinct survival\ngroups, whereas expert UIP vs non-UIP labeling does not. QCT TM models may\nimprove diagnosis of ILD and offer more accurate prognostication, better\nguiding patient management.",
    "descriptor": "",
    "authors": [
      "Babak Haghighi",
      "Warren B. Gefter",
      "Lauren Pantalone",
      "Despina Kontos",
      "Eduardo Mortani Barbosa Jr"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.09766"
  },
  {
    "id": "arXiv:2206.09773",
    "title": "Sufficient Conditions for the Joined Set of Solutions of the  Overdetermined Interval System of Linear Algebraic Equations Membership to  Only One Orthant",
    "abstract": "Interval systems of linear algebraic equations (ISLAE) are considered in the\ncontext of constructing of linear models according to data with interval\nuncertainty. Sufficient conditions for boundedness and convexity of an\nadmissible domain (AD) of ISLAE and its belonging to only one orthant of an\n$n$-dimensional space are proposed, which can be verified in polynomial time by\nthe methods of computational linear algebra. In this case, AD ISLAE turns out\nto be a convex bounded polyhedron, entirely lying in the corresponding ortant.\nThese properties of AD ISLAE allow, firstly, to find solutions to the\ncorresponding ISLAE in polynomial time by linear programming methods (while\nfinding a solution to ISLAE of a general form is an NP-hard problem). Secondly,\nthe coefficients of the linear model obtained by solving the corresponding\nISLAE have an analogue of the significance property of the coefficient of the\nlinear model, since the coefficients of the linear model do not change their\nsign within the limits of the AD. The formulation and proof of the\ncorresponding theorem are presented. The error estimation and convergence of an\narbitrary solution of ISLAE to the normal solution of a hypothetical exact\nsystem of linear algebraic equations are also investigated. An illustrative\nnumerical example is given.",
    "descriptor": "\nComments: 14 pages, 2 figures\n",
    "authors": [
      "Vladimir Erokhin",
      "Vitaly Kakaev",
      "Andrey Kadochnikov",
      "Sergey Sotnikov"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2206.09773"
  },
  {
    "id": "arXiv:2206.09774",
    "title": "Improving Triplet-Based Channel Charting on Distributed Massive MIMO  Measurements",
    "abstract": "The objective of channel charting is to learn a virtual map of the radio\nenvironment from high-dimensional CSI that is acquired by a multi-antenna\nwireless system. Since, in static environments, CSI is a function of the\ntransmitter location, a mapping from CSI to channel chart coordinates can be\nlearned in a self-supervised manner using dimensionality reduction techniques.\nThe state-of-the-art triplet-based approach is evaluated on multiple datasets\nmeasured by a distributed massive MIMO channel sounder, with both co-located\nand distributed antenna setups. The importance of suitable triplet selection is\ninvestigated by comparing results to channel charts learned from a genie-aided\ntriplet generator and learned from triplets on simulated trajectories through\nmeasured data. Finally, the transferability of learned forward charting\nfunctions to similar, but different radio environments is explored.",
    "descriptor": "",
    "authors": [
      "Florian Euchner",
      "Phillip Stephan",
      "Marc Gauger",
      "Sebastian D\u00f6rner",
      "Stephan ten Brink"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.09774"
  },
  {
    "id": "arXiv:2206.09781",
    "title": "Mobility estimation for Langevin dynamics using control variates",
    "abstract": "The scaling of the mobility of two-dimensional Langevin dynamics in a\nperiodic potential as the friction vanishes is not well understood for\nnon-separable potentials. Theoretical results are lacking, and numerical\ncalculation of the mobility in the underdamped regime is challenging because\nthe computational cost of standard Monte Carlo methods is inversely\nproportional to the friction coefficient, while deterministic methods are\nill-conditioned. In this work, we propose a new variance-reduction method based\non control variates for efficiently estimating the mobility of Langevin-type\ndynamics. We provide bounds on the bias and variance of the proposed estimator,\nand illustrate its efficacy through numerical experiments, first in simple\none-dimensional settings and then for two-dimensional Langevin dynamics. Our\nresults corroborate previous numerical evidence on the scaling of the mobility\nin the low friction regime for a simple non-separable potential.",
    "descriptor": "",
    "authors": [
      "G. A. Pavliotis",
      "G. Stoltz",
      "U. Vaes"
    ],
    "subjectives": [
      "Mathematical Physics (math-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.09781"
  },
  {
    "id": "arXiv:2206.09783",
    "title": "Boosting Cross-Domain Speech Recognition with Self-Supervision",
    "abstract": "The cross-domain performance of automatic speech recognition (ASR) could be\nseverely hampered due to the mismatch between training and testing\ndistributions. Since the target domain usually lacks labeled data, and domain\nshifts exist at acoustic and linguistic levels, it is challenging to perform\nunsupervised domain adaptation (UDA) for ASR. Previous work has shown that\nself-supervised learning (SSL) or pseudo-labeling (PL) is effective in UDA by\nexploiting the self-supervisions of unlabeled data. However, these\nself-supervisions also face performance degradation in mismatched domain\ndistributions, which previous work fails to address. This work presents a\nsystematic UDA framework to fully utilize the unlabeled data with\nself-supervision in the pre-training and fine-tuning paradigm. On the one hand,\nwe apply continued pre-training and data replay techniques to mitigate the\ndomain mismatch of the SSL pre-trained model. On the other hand, we propose a\ndomain-adaptive fine-tuning approach based on the PL technique with three\nunique modifications: Firstly, we design a dual-branch PL method to decrease\nthe sensitivity to the erroneous pseudo-labels; Secondly, we devise an\nuncertainty-aware confidence filtering strategy to improve pseudo-label\ncorrectness; Thirdly, we introduce a two-step PL approach to incorporate target\ndomain linguistic knowledge, thus generating more accurate target domain\npseudo-labels. Experimental results on various cross-domain scenarios\ndemonstrate that the proposed approach could effectively boost the cross-domain\nperformance and significantly outperform previous approaches.",
    "descriptor": "",
    "authors": [
      "Han Zhu",
      "Gaofeng Cheng",
      "Jindong Wang",
      "Wenxin Hou",
      "Pengyuan Zhang",
      "Yonghong Yan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2206.09783"
  },
  {
    "id": "arXiv:2206.09808",
    "title": "On the Span of $l$ Distance Coloring of Infinite Hexagonal Grid",
    "abstract": "For a graph $G(V,E)$ and $l \\in \\mathbb{N}$, an $l$ distance coloring is a\ncoloring $f: V \\to \\{1, 2, \\cdots, n\\}$ of $V$ such that $\\forall u,\\;v \\in\nV,\\; u\\neq v,\\; f(u)\\neq f(v)$ when $d(u,v) \\leq l$. Here $d(u,v)$ is the\ndistance between $u$ and $v$ and is equal to the minimum number of edges that\nconnect $u$ and $v$ in $G$. The span of $l$ distance coloring of $G$, $\\lambda\n^{l}(G)$, is the minimum $n$ among all $l$ distance coloring of $G$. A class of\nchannel assignment problem in cellular network can be formulated as a distance\ngraph coloring problem in regular grid graphs. The cellular network is often\nmodelled as an infinite hexagonal grid $T_H$, and hence determining $\\lambda\n^{l}(T_H)$ has relevance from practical point of view. Jacko and Jendrol\n[Discussiones Mathematicae Graph Theory, $2005$] determined the exact value of\n$\\lambda ^{l}(T_H)$ for any odd $l$ and for even $l \\geq 8$, it is conjectured\nthat $\\lambda ^{l}(T_H) = \\left[ \\dfrac{3}{8} \\left( \\, l+\\dfrac{4}{3} \\right)\n^2 \\right]$ where $[x]$ is an integer, $x\\in \\mathbb{R}$ and $x-\\dfrac{1}{2} <\n[x] \\leq x+\\dfrac{1}{2}$. For $l=8$, the conjecture has been proved by Sasthi\nand Subhasis [$22$nd Italian Conference on Theoretical Computer Science,\n$2021$]. In this paper, we prove the conjecture for any $l \\geq 10$.",
    "descriptor": "",
    "authors": [
      "Sasthi C. Ghosh",
      "Subhasis Koley"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2206.09808"
  },
  {
    "id": "arXiv:2206.09818",
    "title": "SMT-DTA: Improving Drug-Target Affinity Prediction with Semi-supervised  Multi-task Training",
    "abstract": "Drug-Target Affinity (DTA) prediction is an essential task for drug discovery\nand pharmaceutical research. Accurate predictions of DTA can greatly benefit\nthe design of new drug. As wet experiments are costly and time consuming, the\nsupervised data for DTA prediction is extremely limited. This seriously hinders\nthe application of deep learning based methods, which require a large scale of\nsupervised data. To address this challenge and improve the DTA prediction\naccuracy, we propose a framework with several simple yet effective strategies\nin this work: (1) a multi-task training strategy, which takes the DTA\nprediction and the masked language modeling (MLM) task on the paired\ndrug-target dataset; (2) a semi-supervised training method to empower the drug\nand target representation learning by leveraging large-scale unpaired molecules\nand proteins in training, which differs from previous pre-training and\nfine-tuning methods that only utilize molecules or proteins in pre-training;\nand (3) a cross-attention module to enhance the interaction between drug and\ntarget representation. Extensive experiments are conducted on three real-world\nbenchmark datasets: BindingDB, DAVIS and KIBA. The results show that our\nframework significantly outperforms existing methods and achieves\nstate-of-the-art performances, e.g., $0.712$ RMSE on BindingDB IC$_{50}$\nmeasurement with more than $5\\%$ improvement than previous best work. In\naddition, case studies on specific drug-target binding activities, drug feature\nvisualizations, and real-world applications demonstrate the great potential of\nour work. The code and data are released at https://github.com/QizhiPei/SMT-DTA",
    "descriptor": "",
    "authors": [
      "Qizhi Pei",
      "Lijun Wu",
      "Jinhua Zhu",
      "Yingce Xia",
      "Shufang Xia",
      "Tao Qin",
      "Haiguang Liu",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09818"
  },
  {
    "id": "arXiv:2206.09821",
    "title": "Exceedance Probability Forecasting via Regression for Significant Wave  Height Forecasting",
    "abstract": "Significant wave height forecasting is a key problem in ocean data analytics.\nPredicting the significant wave height is crucial for estimating the energy\nproduction from waves. Moreover, the timely prediction of large waves is\nimportant to ensure the safety of maritime operations, e.g. passage of vessels.\nWe frame the task of predicting extreme values of significant wave height as an\nexceedance probability forecasting problem. Accordingly, we aim at estimating\nthe probability that the significant wave height will exceed a predefined\nthreshold. This task is usually solved using a probabilistic binary\nclassification model. Instead, we propose a novel approach based on a\nforecasting model. The method leverages the forecasts for the upcoming\nobservations to estimate the exceedance probability according to the cumulative\ndistribution function. We carried out experiments using data from a buoy placed\nin the coast of Halifax, Canada. The results suggest that the proposed\nmethodology is better than state-of-the-art approaches for exceedance\nprobability forecasting.",
    "descriptor": "\nComments: code available, 21 pages\n",
    "authors": [
      "Vitor Cerqueira",
      "Luis Torgo"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09821"
  },
  {
    "id": "arXiv:2206.09823",
    "title": "Multi-criteria optimization and automated network restructuring to  mitigate construction projects delays on-the-run",
    "abstract": "Construction project management requires dynamic mitigation control ensuring\nthe project's timely completion by a best fit for common purpose strategy for\nall stakeholders. Current mitigation approaches are usually performed by an\niterative Monte Carlo (MC) analysis focussing on lowest-cost strategies which\ndo not include (1) the project manager's goal-oriented behaviour, (2) automated\nnetwork restructuring potential, and (3) multi-dimensional optimization\ncriteria for best fitting mitigation strategies-criteria. Therefore, the\ndevelopment statement within this paper is to design a method and\nimplementation tool that properly dissolves all the aforementioned shortcomings\nensuring the project's completion date by finding the most effective and\nefficient mitigation strategy. To fulfill the purpose of this paper, the\nMitigation Controller (MitC) has been developed using an integrative approach\nof non-linear optimization techniques, probabilistic Monte Carlo simulation,\nand preference function modeling. Compared to the conventional way of\nmitigating project delays. The developed MitC allows mitigating potential\ndelays with the least negative consequences on several project criteria, such\nas cost, environmental impact, etc. The application of the model to the\ndemonstrative case study shows the ability of the model to significantly\nincrease the probability of completing the project in the given target\nduration. Embedding the multi-criteria evaluation in the optimization model\nensures that other interests are also represented in finding the optimal\nstrategy for project delays.",
    "descriptor": "",
    "authors": [
      "Nina Prins",
      "Omar Kammouh",
      "A.R.M. Wolfert"
    ],
    "subjectives": [
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.09823"
  },
  {
    "id": "arXiv:2206.09841",
    "title": "Label noise (stochastic) gradient descent implicitly solves the Lasso  for quadratic parametrisation",
    "abstract": "Understanding the implicit bias of training algorithms is of crucial\nimportance in order to explain the success of overparametrised neural networks.\nIn this paper, we study the role of the label noise in the training dynamics of\na quadratically parametrised model through its continuous time version. We\nexplicitly characterise the solution chosen by the stochastic flow and prove\nthat it implicitly solves a Lasso program. To fully complete our analysis, we\nprovide nonasymptotic convergence guarantees for the dynamics as well as\nconditions for support recovery. We also give experimental results which\nsupport our theoretical claims. Our findings highlight the fact that structured\nnoise can induce better generalisation and help explain the greater\nperformances of stochastic dynamics as observed in practice.",
    "descriptor": "",
    "authors": [
      "Loucas Pillaud-Vivien",
      "Julien Reygner",
      "Nicolas Flammarion"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.09841"
  },
  {
    "id": "arXiv:2206.09861",
    "title": "Additive Gaussian Processes Revisited",
    "abstract": "Gaussian Process (GP) models are a class of flexible non-parametric models\nthat have rich representational power. By using a Gaussian process with\nadditive structure, complex responses can be modelled whilst retaining\ninterpretability. Previous work showed that additive Gaussian process models\nrequire high-dimensional interaction terms. We propose the orthogonal additive\nkernel (OAK), which imposes an orthogonality constraint on the additive\nfunctions, enabling an identifiable, low-dimensional representation of the\nfunctional relationship. We connect the OAK kernel to functional ANOVA\ndecomposition, and show improved convergence rates for sparse computation\nmethods. With only a small number of additive low-dimensional terms, we\ndemonstrate the OAK model achieves similar or better predictive performance\ncompared to black-box models, while retaining interpretability.",
    "descriptor": "\nComments: 39th International Conference on Machine Learning (ICML 2022)\n",
    "authors": [
      "Xiaoyu Lu",
      "Alexis Boukouvalas",
      "James Hensman"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09861"
  },
  {
    "id": "arXiv:2206.09867",
    "title": "WiFi-based Spatiotemporal Human Action Perception",
    "abstract": "WiFi-based sensing for human activity recognition (HAR) has recently become a\nhot topic as it brings great benefits when compared with video-based HAR, such\nas eliminating the demands of line-of-sight (LOS) and preserving privacy.\nMaking the WiFi signals to 'see' the action, however, is quite coarse and thus\nstill in its infancy. An end-to-end spatiotemporal WiFi signal neural network\n(STWNN) is proposed to enable WiFi-only sensing in both line-of-sight and\nnon-line-of-sight scenarios. Especially, the 3D convolution module is able to\nexplore the spatiotemporal continuity of WiFi signals, and the feature\nself-attention module can explicitly maintain dominant features. In addition, a\nnovel 3D representation for WiFi signals is designed to preserve multi-scale\nspatiotemporal information. Furthermore, a small wireless-vision dataset (WVAR)\nis synchronously collected to extend the potential of STWNN to 'see' through\nocclusions. Quantitative and qualitative results on WVAR and the other three\npublic benchmark datasets demonstrate the effectiveness of our approach on both\naccuracy and shift consistency.",
    "descriptor": "",
    "authors": [
      "Yanling Hao",
      "Zhiyuan Shi",
      "Yuanwei Liu"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09867"
  },
  {
    "id": "arXiv:2206.09872",
    "title": "A Neural Network Based Method with Transfer Learning for Genetic Data  Analysis",
    "abstract": "Transfer learning has emerged as a powerful technique in many application\nproblems, such as computer vision and natural language processing. However,\nthis technique is largely ignored in application to genetic data analysis. In\nthis paper, we combine transfer learning technique with a neural network based\nmethod(expectile neural networks). With transfer learning, instead of starting\nthe learning process from scratch, we start from one task that have been\nlearned when solving a different task. We leverage previous learnings and avoid\nstarting from scratch to improve the model performance by passing information\ngained in different but related task. To demonstrate the performance, we run\ntwo real data sets. By using transfer learning algorithm, the performance of\nexpectile neural networks is improved compared to expectile neural network\nwithout using transfer learning technique.",
    "descriptor": "",
    "authors": [
      "Jinghang Lin",
      "Shan Zhang",
      "Qing Lu"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Machine Learning (cs.LG)",
      "Genomics (q-bio.GN)"
    ],
    "url": "https://arxiv.org/abs/2206.09872"
  },
  {
    "id": "arXiv:2206.09873",
    "title": "Regression of high dimensional angular momentum states of light",
    "abstract": "The Orbital Angular Momentum (OAM) of light is an infinite-dimensional degree\nof freedom of light with several applications in both classical and quantum\noptics. However, to fully take advantage of the potential of OAM states,\nreliable detection platforms to characterize generated states in experimental\nconditions are needed. Here, we present an approach to reconstruct input OAM\nstates from measurements of the spatial intensity distributions they produce.\nTo obviate issues arising from intrinsic symmetry of Laguerre-Gauss modes, we\nemploy a pair of intensity profiles per state projecting it only on two\ndistinct bases, showing how this allows to uniquely recover input states from\nthe collected data. Our approach is based on a combined application of\ndimensionality reduction via principal component analysis, and linear\nregression, and thus has a low computational cost during both training and\ntesting stages. We showcase our approach in a real photonic setup, generating\nup-to-four-dimensional OAM states through a quantum walk dynamics. The high\nperformances and versatility of the demonstrated approach make it an ideal tool\nto characterize high dimensional states in quantum information protocols.",
    "descriptor": "",
    "authors": [
      "Danilo Zia",
      "Riccardo Checchinato",
      "Alessia Suprano",
      "Taira Giordani",
      "Emanuele Polino",
      "Luca Innocenti",
      "Alessandro Ferraro",
      "Mauro Paternostro",
      "Nicol\u00f2 Spagnolo",
      "Fabio Sciarrino"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2206.09873"
  },
  {
    "id": "arXiv:2206.09876",
    "title": "Dual Linear Programming Bounds for Sphere Packing via Discrete  Reductions",
    "abstract": "The Cohn-Elkies linear program for sphere packing, which was used to solve\nthe 8 and 24 dimensional cases, is conjectured to not be sharp in any other\ndimension $d>2$. By mapping feasible points of this infinite-dimensional linear\nprogram into a finite-dimensional problem via discrete reduction, we provide a\ngeneral method to obtain dual bounds on the Cohn-Elkies linear program. This\nreduces the number of variables to be finite, enabling computer optimization\ntechniques to be applied. Using this method, we prove that the Cohn-Elkies\nbound cannot come close to the best packing densities known in dimensions $3\n\\leq d \\leq 13$ except for the solved case $d=8$. In particular, our dual\nbounds show the Cohn-Elkies bound is unable to solve the 3 and 4 dimensional\nsphere packing problems.",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Rupert Li"
    ],
    "subjectives": [
      "Metric Geometry (math.MG)",
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2206.09876"
  },
  {
    "id": "arXiv:2206.09890",
    "title": "Nonlinear inhomogeneous Fokker-Planck models: energetic-variational  structures and long time behavior",
    "abstract": "Inspired by the modeling of grain growth in polycrystalline materials, we\nconsider a nonlinear Fokker-Plank model, with inhomogeneous diffusion and with\nvariable mobility parameters. We develop large time asymptotic analysis of such\nnonstandard models by reformulating and extending the classical entropy method,\nunder the assumption of periodic boundary condition. In addition, illustrative\nnumerical tests are presented to highlight the essential points of the current\nanalytical results and to motivate future analysis.",
    "descriptor": "",
    "authors": [
      "Yekaterina Epshteyn",
      "Chang Liu",
      "Chun Liu",
      "Masashi Mizuno"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.09890"
  },
  {
    "id": "arXiv:2206.09893",
    "title": "Variational Quantum and Quantum-Inspired Clustering",
    "abstract": "Here we present a quantum algorithm for clustering data based on a\nvariational quantum circuit. The algorithm allows to classify data into many\nclusters, and can easily be implemented in few-qubit Noisy Intermediate-Scale\nQuantum (NISQ) devices. The idea of the algorithm relies on reducing the\nclustering problem to an optimization, and then solving it via a Variational\nQuantum Eigensolver (VQE) combined with non-orthogonal qubit states. In\npractice, the method uses maximally-orthogonal states of the target Hilbert\nspace instead of the usual computational basis, allowing for a large number of\nclusters to be considered even with few qubits. We benchmark the algorithm with\nnumerical simulations using real datasets, showing excellent performance even\nwith one single qubit. Moreover, a tensor network simulation of the algorithm\nimplements, by construction, a quantum-inspired clustering algorithm that can\nrun on current classical hardware.",
    "descriptor": "\nComments: 4 pages, 3 figures\n",
    "authors": [
      "Pablo Bermejo",
      "Roman Orus"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.09893"
  },
  {
    "id": "arXiv:2206.09901",
    "title": "Only Tails Matter: Average-Case Universality and Robustness in the  Convex Regime",
    "abstract": "The recently developed average-case analysis of optimization methods allows a\nmore fine-grained and representative convergence analysis than usual worst-case\nresults. In exchange, this analysis requires a more precise hypothesis over the\ndata generating process, namely assuming knowledge of the expected spectral\ndistribution (ESD) of the random matrix associated with the problem. This work\nshows that the concentration of eigenvalues near the edges of the ESD\ndetermines a problem's asymptotic average complexity. This a priori information\non this concentration is a more grounded assumption than complete knowledge of\nthe ESD. This approximate concentration is effectively a middle ground between\nthe coarseness of the worst-case scenario convergence and the restrictive\nprevious average-case analysis. We also introduce the Generalized Chebyshev\nmethod, asymptotically optimal under a hypothesis on this concentration and\nglobally optimal when the ESD follows a Beta distribution. We compare its\nperformance to classical optimization algorithms, such as gradient descent or\nNesterov's scheme, and we show that, in the average-case context, Nesterov's\nmethod is universally nearly optimal asymptotically.",
    "descriptor": "\nComments: To be published in ICML 2022\n",
    "authors": [
      "Leonardo Cunha",
      "Gauthier Gidel",
      "Fabien Pedregosa",
      "Damien Scieurand Courtney Paquette"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09901"
  },
  {
    "id": "arXiv:2206.09916",
    "title": "The fastest linearly converging discrete-time average consensus using  buffered information",
    "abstract": "In this letter, we study the problem of accelerating reaching average\nconsensus over connected graphs in a discrete-time communication setting.\nLiterature has shown that consensus algorithms can be accelerated by increasing\nthe graph connectivity or optimizing the weights agents place on the\ninformation received from their neighbors. In this letter instead of altering\nthe communication graph, we investigate two methods that use buffered states to\naccelerate reaching average consensus over a given graph. In the first method,\nwe study how convergence rate of the well-known first-order Laplacian average\nconsensus algorithm changes with delayed feedback and obtain a sufficient\ncondition on the ranges of delay that leads to faster convergence. In the\nsecond proposed method, we show how average consensus problem can be cast as a\nconvex optimization problem and solved by first-order accelerated optimization\nalgorithms for strongly-convex cost functions. We construct the fastest\nconverging average consensus algorithm using the so-called Triple Momentum\noptimization algorithm. We demonstrate our results using an in-network linear\nregression problem, which is formulated as two average consensus problems.",
    "descriptor": "\nComments: 6 pages, Europe Control Conference\n",
    "authors": [
      "Amir-Salar Esteki",
      "Solmas S. Kia"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2206.09916"
  },
  {
    "id": "arXiv:2206.09919",
    "title": "Inference-Based Quantum Sensing",
    "abstract": "In a standard Quantum Sensing (QS) task one aims at estimating an unknown\nparameter $\\theta$, encoded into an $n$-qubit probe state, via measurements of\nthe system. The success of this task hinges on the ability to correlate changes\nin the parameter to changes in the system response $\\mathcal{R}(\\theta)$ (i.e.,\nchanges in the measurement outcomes). For simple cases the form of\n$\\mathcal{R}(\\theta)$ is known, but the same cannot be said for realistic\nscenarios, as no general closed-form expression exists. In this work we present\nan inference-based scheme for QS. We show that, for a general class of unitary\nfamilies of encoding, $\\mathcal{R}(\\theta)$ can be fully characterized by only\nmeasuring the system response at $2n+1$ parameters. In turn, this allows us to\ninfer the value of an unknown parameter given the measured response, as well as\nto determine the sensitivity of the sensing scheme, which characterizes its\noverall performance. We show that inference error is, with high probability,\nsmaller than $\\delta$, if one measures the system response with a number of\nshots that scales only as $\\Omega(\\log^3(n)/\\delta^2)$. Furthermore, the\nframework presented can be broadly applied as it remains valid for arbitrary\nprobe states and measurement schemes, and, even holds in the presence of\nquantum noise. We also discuss how to extend our results beyond unitary\nfamilies. Finally, to showcase our method we implement it for a QS task on real\nquantum hardware, and in numerical simulations.",
    "descriptor": "\nComments: 5+10 pages, 3+5 figures\n",
    "authors": [
      "C. Huerta Alderete",
      "Max Hunter Gordon",
      "Frederic Sauvage",
      "Akira Sone",
      "Andrew T. Sornborger",
      "Patrick J. Coles",
      "M. Cerezo"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.09919"
  },
  {
    "id": "arXiv:2206.09933",
    "title": "Quantum machine learning channel discrimination",
    "abstract": "In the problem of quantum channel discrimination, one distinguishes between a\ngiven number of quantum channels, which is done by sending an input state\nthrough a channel and measuring the output state. This work studies\napplications of variational quantum circuits and machine learning techniques\nfor discriminating such channels. In particular, we explore (i) the practical\nimplementation of embedding this task into the framework of variational quantum\ncomputing, (ii) training a quantum classifier based on variational quantum\ncircuits, and (iii) applying the quantum kernel estimation technique. For\ntesting these three channel discrimination approaches, we considered a pair of\nentanglement-breaking channels and the depolarizing channel with two different\ndepolarization factors. For the approach (i), we address solving the quantum\nchannel discrimination problem using widely discussed parallel and sequential\nstrategies. We show the advantage of the latter in terms of better convergence\nwith less quantum resources. Quantum channel discrimination with a variational\nquantum classifier (ii) allows one to operate even with random and mixed input\nstates and simple variational circuits. The kernel-based classification\napproach (iii) is also found effective as it allows one to discriminate\ndepolarizing channels associated not with just fixed values of the\ndepolarization factor, but with ranges of it. Additionally, we discovered that\na simple modification of one of the commonly used kernels significantly\nincreases the efficiency of this approach. Finally, our numerical findings\nreveal that the performance of variational methods of channel discrimination\ndepends on the trace of the product of the output states. These findings\ndemonstrate that quantum machine learning can be used to discriminate channels,\nsuch as those representing physical noise processes.",
    "descriptor": "\nComments: 18 pages; 14 figures; RevTeX\n",
    "authors": [
      "Andrey Kardashin",
      "Anna vlasova",
      "Anastasia Pervishko",
      "Dmitry Yudin",
      "Jacob Biamonte"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09933"
  },
  {
    "id": "arXiv:2206.09942",
    "title": "A globally convergent method to accelerate large-scale optimization  using on-the-fly model hyperreduction: application to shape optimization",
    "abstract": "We present a numerical method to efficiently solve optimization problems\ngoverned by large-scale nonlinear systems of equations, including discretized\npartial differential equations, using projection-based reduced-order models\naccelerated with hyperreduction (empirical quadrature) and embedded in a\ntrust-region framework that guarantees global convergence. The proposed\nframework constructs a hyperreduced model on-the-fly during the solution of the\noptimization problem, which completely avoids an offline training phase. This\nensures all snapshot information is collected along the optimization\ntrajectory, which avoids wasting samples in remote regions of the parameters\nspace that are never visited, and inherently avoids the curse of dimensionality\nof sampling in a high-dimensional parameter space. At each iteration of the\nproposed algorithm, a reduced basis and empirical quadrature weights are\nconstructed precisely to ensure the global convergence criteria of the\ntrust-region method are satisfied, ensuring global convergence to a local\nminimum of the original (unreduced) problem. Numerical experiments are\nperformed on two fluid shape optimization problems to verify the global\nconvergence of the method and demonstrate its computational efficiency;\nspeedups over 18x (accounting for all computational cost, even cost that is\ntraditionally considered \"offline\" such as snapshot collection and data\ncompression) relative to standard optimization approaches that do not leverage\nmodel reduction are shown.",
    "descriptor": "\nComments: 40 pages, 14 figures, 4 tables\n",
    "authors": [
      "Tianshu Wen",
      "Matthew J. Zahr"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.09942"
  },
  {
    "id": "arXiv:2206.09963",
    "title": "Sample Average Approximation for Stochastic Programming with Equality  Constraints",
    "abstract": "We revisit the sample average approximation (SAA) approach for general\nnon-convex stochastic programming. We show that applying the SAA approach to\nproblems with expected value equality constraints does not necessarily result\nin asymptotic optimality guarantees as the number of samples increases. To\naddress this issue, we relax the equality constraints. Then, we prove the\nasymptotic optimality of the modified SAA approach under mild smoothness and\nboundedness conditions on the equality constraint functions. Our analysis uses\nrandom set theory and concentration inequalities to characterize the\napproximation error from the sampling procedure. We apply our approach to the\nproblem of stochastic optimal control for nonlinear dynamical systems subject\nto external disturbances modeled by a Wiener process. We verify our approach on\na rocket-powered descent problem and show that our computed solutions allow for\nsignificant uncertainty reduction.",
    "descriptor": "",
    "authors": [
      "Thomas Lew",
      "Riccardo Bonalli",
      "Marco Pavone"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2206.09963"
  },
  {
    "id": "arXiv:2206.09970",
    "title": "The backward Euler-Maruyama method for invariant measures of stochastic  differential equations with super-linear coefficients",
    "abstract": "The backward Euler-Maruyama (BEM) method is employed to approximate the\ninvariant measure of stochastic differential equations, where both the drift\nand the diffusion coefficient are allowed to grow super-linearly. The existence\nand uniqueness of the invariant measure of the numerical solution generated by\nthe BEM method are proved and the convergence of the numerical invariant\nmeasure to the underlying one is shown. Simulations are provided to illustrate\nthe theoretical results and demonstrate the application of our results in the\narea of system control.",
    "descriptor": "",
    "authors": [
      "Wei Liu",
      "Xuerong Mao",
      "Yue Wu"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.09970"
  },
  {
    "id": "arXiv:2206.09992",
    "title": "Hyperparameter Importance of Quantum Neural Networks Across Small  Datasets",
    "abstract": "As restricted quantum computers are slowly becoming a reality, the search for\nmeaningful first applications intensifies. In this domain, one of the more\ninvestigated approaches is the use of a special type of quantum circuit - a\nso-called quantum neural network -- to serve as a basis for a machine learning\nmodel. Roughly speaking, as the name suggests, a quantum neural network can\nplay a similar role to a neural network. However, specifically for applications\nin machine learning contexts, very little is known about suitable circuit\narchitectures, or model hyperparameters one should use to achieve good learning\nperformance. In this work, we apply the functional ANOVA framework to quantum\nneural networks to analyze which of the hyperparameters were most influential\nfor their predictive performance. We analyze one of the most typically used\nquantum neural network architectures. We then apply this to $7$ open-source\ndatasets from the OpenML-CC18 classification benchmark whose number of features\nis small enough to fit on quantum hardware with less than $20$ qubits. Three\nmain levels of importance were detected from the ranking of hyperparameters\nobtained with functional ANOVA. Our experiment both confirmed expected patterns\nand revealed new insights. For instance, setting well the learning rate is\ndeemed the most critical hyperparameter in terms of marginal contribution on\nall datasets, whereas the particular choice of entangling gates used is\nconsidered the least important except on one dataset. This work introduces new\nmethodologies to study quantum machine learning models and provides new\ninsights toward quantum model selection.",
    "descriptor": "\nComments: Submitted to Discovery Science 2022\n",
    "authors": [
      "Charles Moussa",
      "Jan N. van Rijn",
      "Thomas B\u00e4ck",
      "Vedran Dunjko"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09992"
  },
  {
    "id": "arXiv:2206.10010",
    "title": "Extremal graph realizations and graph Laplacian eigenvalues",
    "abstract": "For a regular polyhedron (or polygon) centered at the origin, the coordinates\nof the vertices are eigenvectors of the graph Laplacian for the skeleton of\nthat polyhedron (or polygon) associated with the first (non-trivial)\neigenvalue. In this paper, we generalize this relationship. For a given graph,\nwe study the eigenvalue optimization problem of maximizing the first\n(non-trivial) eigenvalue of the graph Laplacian over non-negative edge weights.\nWe show that the spectral realization of the graph using the eigenvectors\ncorresponding to the solution of this problem, under certain assumptions, is a\ncentered, unit-distance graph realization that has maximal total variance. This\nresult gives a new method for generating unit-distance graph realizations and\nis based on convex duality. A drawback of this method is that the dimension of\nthe realization is given by the multiplicity of the extremal eigenvalue, which\nis typically unknown prior to solving the eigenvalue optimization problem. Our\nresults are illustrated with a number of examples.",
    "descriptor": "\nComments: 14 pages, 5 figures\n",
    "authors": [
      "Braxton Osting"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2206.10010"
  },
  {
    "id": "arXiv:2206.10014",
    "title": "Deep Partial Least Squares for Empirical Asset Pricing",
    "abstract": "We use deep partial least squares (DPLS) to estimate an asset pricing model\nfor individual stock returns that exploits conditioning information in a\nflexible and dynamic way while attributing excess returns to a small set of\nstatistical risk factors. The novel contribution is to resolve the non-linear\nfactor structure, thus advancing the current paradigm of deep learning in\nempirical asset pricing which uses linear stochastic discount factors under an\nassumption of Gaussian asset returns and factors. This non-linear factor\nstructure is extracted by using projected least squares to jointly project firm\ncharacteristics and asset returns on to a subspace of latent factors and using\ndeep learning to learn the non-linear map from the factor loadings to the asset\nreturns. The result of capturing this non-linear risk factor structure is to\ncharacterize anomalies in asset returns by both linear risk factor exposure and\ninteraction effects. Thus the well known ability of deep learning to capture\noutliers, shed lights on the role of convexity and higher order terms in the\nlatent factor structure on the factor risk premia. On the empirical side, we\nimplement our DPLS factor models and exhibit superior performance to LASSO and\nplain vanilla deep learning models. Furthermore, our network training times are\nsignificantly reduced due to the more parsimonious architecture of DPLS.\nSpecifically, using 3290 assets in the Russell 1000 index over a period of\nDecember 1989 to January 2018, we assess our DPLS factor model and generate\ninformation ratios that are approximately 1.2x greater than deep learning. DPLS\nexplains variation and pricing errors and identifies the most prominent latent\nfactors and firm characteristics.",
    "descriptor": "",
    "authors": [
      "Matthew F. Dixon",
      "Nicholas G. Polson",
      "Kemen Goicoechea"
    ],
    "subjectives": [
      "Pricing of Securities (q-fin.PR)",
      "Machine Learning (cs.LG)",
      "Portfolio Management (q-fin.PM)",
      "Risk Management (q-fin.RM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.10014"
  },
  {
    "id": "arXiv:2206.10073",
    "title": "Finding Optimal Policy for Queueing Models: New Parameterization",
    "abstract": "Queueing systems appear in many important real-life applications including\ncommunication networks, transportation and manufacturing systems. Reinforcement\nlearning (RL) framework is a suitable model for the queueing control problem\nwhere the underlying dynamics are usually unknown and the agent receives little\ninformation from the environment to navigate. In this work, we investigate the\noptimization aspects of the queueing model as a RL environment and provide\ninsight to learn the optimal policy efficiently. We propose a new\nparameterization of the policy by using the intrinsic properties of queueing\nnetwork systems. Experiments show good performance of our methods with various\nload conditions from light to heavy traffic.",
    "descriptor": "",
    "authors": [
      "Trang H. Tran",
      "Lam M. Nguyen",
      "Katya Scheinberg"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10073"
  },
  {
    "id": "arXiv:2206.10074",
    "title": "Statistical network isomorphism",
    "abstract": "Graph isomorphism is a problem for which there is no known polynomial-time\nsolution. Nevertheless, assessing (dis)similarity between two or more networks\nis a key task in many areas, such as image recognition, biology, chemistry,\ncomputer and social networks. Moreover, questions of similarity are typically\nmore general and their answers more widely applicable than the more restrictive\nisomorphism question. In this article, we offer a statistical answer to the\nfollowing questions: a) {\\it ``Are networks $G_1$ and $G_2$ similar?''}, b)\n{\\it ``How different are the networks $G_1$ and $G_2$?''} and c) {\\it ``Is\n$G_3$ more similar to $G_1$ or $G_2$?''}. Our comparisons begin with the\ntransformation of each graph into an all-pairs distance matrix. Our node-node\ndistance, Jaccard distance, has been shown to offer a good reflection of the\ngraph's connectivity structure. We then model these distances as probability\ndistributions. Finally, we use well-established statistical tools to gauge the\n(dis)similarities in terms of probability distribution (dis)similarity. This\ncomparison procedure aims to detect (dis)similarities in connectivity\nstructure, not in easily observable graph characteristics, such as degrees,\nedge counts or density. We validate our hypothesis that graphs can be\nmeaningfully summarized and compared via their node-node distance\ndistributions, using several synthetic and real-world graphs. Empirical results\ndemonstrate its validity and the accuracy of our comparison technique.",
    "descriptor": "\nComments: 11 pages, two figures\n",
    "authors": [
      "Pierre Miasnikof. Alexander Y. Shestopaloff",
      "Cristi\u00e1n Bravo",
      "Yuri Lawryshyn"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Discrete Mathematics (cs.DM)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.10074"
  },
  {
    "id": "arXiv:2206.10093",
    "title": "DeePKS+ABACUS as a Bridge between Expensive Quantum Mechanical Models  and Machine Learning Potentials",
    "abstract": "Recently, the development of machine learning (ML) potentials has made it\npossible to perform large-scale and long-time molecular simulations with the\naccuracy of quantum mechanical (QM) models. However, for high-level QM methods,\nsuch as density functional theory (DFT) at the meta-GGA level and/or with exact\nexchange, quantum Monte Carlo, etc., generating a sufficient amount of data for\ntraining a ML potential has remained computationally challenging due to their\nhigh cost. In this work, we demonstrate that this issue can be largely\nalleviated with Deep Kohn-Sham (DeePKS), a ML-based DFT model. DeePKS employs a\ncomputationally efficient neural network-based functional model to construct a\ncorrection term added upon a cheap DFT model. Upon training, DeePKS offers\nclosely-matched energies and forces compared with high-level QM method, but the\nnumber of training data required is orders of magnitude less than that required\nfor training a reliable ML potential. As such, DeePKS can serve as a bridge\nbetween expensive QM models and ML potentials: one can generate a decent amount\nof high-accuracy QM data to train a DeePKS model, and then use the DeePKS model\nto label a much larger amount of configurations to train a ML potential. This\nscheme for periodic systems is implemented in a DFT package ABACUS, which is\nopen-source and ready for use in various applications.",
    "descriptor": "",
    "authors": [
      "Wenfei Li",
      "Qi Ou",
      "Yixiao Chen",
      "Yu Cao",
      "Renxi Liu",
      "Chunyi Zhang",
      "Daye Zheng",
      "Chun Cai",
      "Xifan Wu",
      "Han Wang",
      "Mohan Chen",
      "Linfeng Zhang"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.10093"
  },
  {
    "id": "arXiv:2206.10143",
    "title": "A Contrastive Approach to Online Change Point Detection",
    "abstract": "We suggest a novel procedure for online change point detection. Our approach\nexpands an idea of maximizing a discrepancy measure between points from\npre-change and post-change distributions. This leads to a flexible procedure\nsuitable for both parametric and nonparametric scenarios. We prove\nnon-asymptotic bounds on the average running length of the procedure and its\nexpected detection delay. The efficiency of the algorithm is illustrated with\nnumerical experiments on synthetic and real-world data sets.",
    "descriptor": "\nComments: 34 pages, 3 figures\n",
    "authors": [
      "Nikita Puchkin",
      "Valeriia Shcherbakova"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2206.10143"
  },
  {
    "id": "arXiv:2206.10152",
    "title": "Diffractive Interconnects: All-Optical Permutation Operation Using  Diffractive Networks",
    "abstract": "Permutation matrices form an important computational building block\nfrequently used in various fields including e.g., communications, information\nsecurity and data processing. Optical implementation of permutation operators\nwith relatively large number of input-output interconnections based on\npower-efficient, fast, and compact platforms is highly desirable. Here, we\npresent diffractive optical networks engineered through deep learning to\nall-optically perform permutation operations that can scale to hundreds of\nthousands of interconnections between an input and an output field-of-view\nusing passive transmissive layers that are individually structured at the\nwavelength scale. Our findings indicate that the capacity of the diffractive\noptical network in approximating a given permutation operation increases\nproportional to the number of diffractive layers and trainable transmission\nelements in the system. Such deeper diffractive network designs can pose\npractical challenges in terms of physical alignment and output diffraction\nefficiency of the system. We addressed these challenges by designing\nmisalignment tolerant diffractive designs that can all-optically perform\narbitrarily-selected permutation operations, and experimentally demonstrated,\nfor the first time, a diffractive permutation network that operates at THz part\nof the spectrum. Diffractive permutation networks might find various\napplications in e.g., security, image encryption and data processing, along\nwith telecommunications; especially with the carrier frequencies in wireless\ncommunications approaching THz-bands, the presented diffractive permutation\nnetworks can potentially serve as channel routing and interconnection panels in\nwireless networks.",
    "descriptor": "\nComments: 22 Pages, 6 Figures\n",
    "authors": [
      "Deniz Mengu",
      "Yifan Zhao",
      "Anika Tabassum",
      "Mona Jarrahi",
      "Aydogan Ozcan"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.10152"
  },
  {
    "id": "arXiv:2206.10166",
    "title": "The heat modulated infinite dimensional Heston model and its numerical  approximation",
    "abstract": "The HEat modulated Infinite DImensional Heston (HEIDIH) model and its\nnumerical approximation are introduced and analyzed. This model falls into the\ngeneral framework of infinite dimensional Heston stochastic volatility models\nof (F.E. Benth, I.C. Simonsen '18), introduced for the pricing of forward\ncontracts. The HEIDIH model consists of a one-dimensional stochastic advection\nequation coupled with a stochastic volatility process, defined as a\nCholesky-type decomposition of the tensor product of a Hilbert-space valued\nOrnstein-Uhlenbeck process, the mild solution to the stochastic heat equation\non the real half-line. The advection and heat equations are driven by\nindependent space-time Gaussian processes which are white in time and colored\nin space, with the latter covariance structure expressed by two different\nkernels. In the first part of the paper, regularity results for the HEIDIH\nmodel in fractional Sobolev spaces are formulated. These are achieved under\nsmoothness conditions on the covariance kernels, which in particular allow for\nweighted Mat\\'ern kernels. In the second part, numerical approximation of the\nmodel is considered. An error decomposition formula, pointwise in space and\ntime, for a semi-explicit finite-difference scheme is proven. For a special\ncase, essentially sharp convergence rates are obtained when this is combined\nwith a fully discrete finite element approximation of the stochastic heat\nequation. The analysis takes into account a localization error, a\npointwise-in-space finite element discretization error and an error stemming\nfrom the noise being sampled pointwise in space. The rates obtained in the\nanalysis are higher than what would be obtained using a standard Sobolev\nembedding technique. Numerical simulations illustrate the results.",
    "descriptor": "\nComments: 34 pages, 7 figures\n",
    "authors": [
      "Fred Espen Benth",
      "Gabriel Lord",
      "Giulia Di Nunno",
      "Andreas Petersson"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.10166"
  },
  {
    "id": "arXiv:2206.10178",
    "title": "Large region targets observation scheduling by multiple satellites using  resampling particle swarm optimization",
    "abstract": "The last decades have witnessed a rapid increase of Earth observation\nsatellites (EOSs), leading to the increasing complexity of EOSs scheduling. On\naccount of the widespread applications of large region observation, this paper\naims to address the EOSs observation scheduling problem for large region\ntargets. A rapid coverage calculation method employing a projection reference\nplane and a polygon clipping technique is first developed. We then formulate a\nnonlinear integer programming model for the scheduling problem, where the\nobjective function is calculated based on the developed coverage calculation\nmethod. A greedy initialization-based resampling particle swarm optimization\n(GI-RPSO) algorithm is proposed to solve the model. The adopted greedy\ninitialization strategy and particle resampling method contribute to generating\nefficient and effective solutions during the evolution process. In the end,\nextensive experiments are conducted to illustrate the effectiveness and\nreliability of the proposed method. Compared to the traditional particle swarm\noptimization and the widely used greedy algorithm, the proposed GI-RPSO can\nimprove the scheduling result by 5.42% and 15.86%, respectively.",
    "descriptor": "\nComments: This work has been submitted to IEEE TAES\n",
    "authors": [
      "Yi Gu",
      "Chao Han",
      "Yuhan Chen",
      "Shenggang Liu",
      "Xinwei Wang"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.10178"
  },
  {
    "id": "arXiv:2206.10183",
    "title": "covEcho Resource constrained lung ultrasound image analysis tool for  faster triaging and active learning",
    "abstract": "Lung ultrasound (LUS) is possibly the only medical imaging modality which\ncould be used for continuous and periodic monitoring of the lung. This is\nextremely useful in tracking the lung manifestations either during the onset of\nlung infection or to track the effect of vaccination on lung as in pandemics\nsuch as COVID-19. There have been many attempts in automating the\nclassification of severity of lung into various classes or automatic\nsegmentation of various LUS landmarks and manifestations. However, all these\napproaches are based on training static machine learning models which require a\nsignificantly clinically annotated large dataset and are computationally heavy\nand most of the time non-real time. In this work, a real-time light weight\nactive learning-based approach is presented for faster triaging in COVID-19\nsubjects in resource constrained settings. The tool, based on the you look only\nonce (YOLO) network, has the capability of providing the quality of images\nbased on the identification of various LUS landmarks, artefacts and\nmanifestations, prediction of severity of lung infection, possibility of active\nlearning based on the feedback from clinicians or on the image quality and a\nsummarization of the significant frames which are having high severity of\ninfection and high image quality for further analysis. The results show that\nthe proposed tool has a mean average precision (mAP) of 66% at an Intersection\nover Union (IoU) threshold of 0.5 for the prediction of LUS landmarks. The 14MB\nlightweight YOLOv5s network achieves 123 FPS while running in a Quadro P4000\nGPU. The tool is available for usage and analysis upon request from the\nauthors.",
    "descriptor": "\nComments: Submitted to Elsevier CMPBUP on Dec 1, 2021\n",
    "authors": [
      "Jinu Joseph",
      "Mahesh Raveendranatha Panicker",
      "Yale Tung Chen",
      "Kesavadas Chandrasekharan",
      "Vimal Chacko Mondy",
      "Anoop Ayyappan",
      "Jineesh Valakkada",
      "Kiran Vishnu Narayan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10183"
  },
  {
    "id": "arXiv:2206.10286",
    "title": "Position-prior Clustering-based Self-attention Module for Knee Cartilage  Segmentation",
    "abstract": "The morphological changes in knee cartilage (especially femoral and tibial\ncartilages) are closely related to the progression of knee osteoarthritis,\nwhich is expressed by magnetic resonance (MR) images and assessed on the\ncartilage segmentation results. Thus, it is necessary to propose an effective\nautomatic cartilage segmentation model for longitudinal research on\nosteoarthritis. In this research, to relieve the problem of inaccurate\ndiscontinuous segmentation caused by the limited receptive field in\nconvolutional neural networks, we proposed a novel position-prior\nclustering-based self-attention module (PCAM). In PCAM, long-range dependency\nbetween each class center and feature point is captured by self-attention\nallowing contextual information re-allocated to strengthen the relative\nfeatures and ensure the continuity of segmentation result. The clutsering-based\nmethod is used to estimate class centers, which fosters intra-class consistency\nand further improves the accuracy of segmentation results. The position-prior\nexcludes the false positives from side-output and makes center estimation more\nprecise. Sufficient experiments are conducted on OAI-ZIB dataset. The\nexperimental results show that the segmentation performance of combination of\nsegmentation network and PCAM obtains an evident improvement compared to\noriginal model, which proves the potential application of PCAM in medical\nsegmentation tasks. The source code is publicly available from link:\nhttps://github.com/LeongDong/PCAMNet",
    "descriptor": "",
    "authors": [
      "Dong Liang",
      "Jun Liu",
      "Kuanquan Wang",
      "Gongning Luo",
      "Wei Wang",
      "Shuo Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10286"
  },
  {
    "id": "arXiv:2206.10294",
    "title": "Using the Polar Transform for Efficient Deep Learning-Based Aorta  Segmentation in CTA Images",
    "abstract": "Medical image segmentation often requires segmenting multiple elliptical\nobjects on a single image. This includes, among other tasks, segmenting vessels\nsuch as the aorta in axial CTA slices. In this paper, we present a general\napproach to improving the semantic segmentation performance of neural networks\nin these tasks and validate our approach on the task of aorta segmentation. We\nuse a cascade of two neural networks, where one performs a rough segmentation\nbased on the U-Net architecture and the other performs the final segmentation\non polar image transformations of the input. Connected component analysis of\nthe rough segmentation is used to construct the polar transformations, and\npredictions on multiple transformations of the same image are fused using\nhysteresis thresholding. We show that this method improves aorta segmentation\nperformance without requiring complex neural network architectures. In\naddition, we show that our approach improves robustness and pixel-level recall\nwhile achieving segmentation performance in line with the state of the art.",
    "descriptor": "\nComments: Accepted to 64th International Symposium ELMAR-2022, Zadar, Croatia\n",
    "authors": [
      "Marin Ben\u010devi\u0107",
      "Marija Habijan",
      "Irena Gali\u0107",
      "Danilo Babin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10294"
  },
  {
    "id": "arXiv:2206.10335",
    "title": "Linear peridynamics Fourier multipliers and eigenvalues",
    "abstract": "A characterization for the Fourier multipliers and eigenvalues of linear\nperidynamic operators is provided. The analysis is presented for state-based\nperidynamic operators for isotropic homogeneous media in any spatial dimension.\nWe provide explicit formulas for the eigenvalues in terms of the space\ndimension, the nonlocal parameters, and the material properties.\nThe approach we follow is based on the Fourier multiplier analysis developed\nfor the nonlocal Laplacian. The Fourier multipliers of linear peridynamic\noperators are second-order tensor fields, which are given through integral\nrepresentations. It is shown that the eigenvalues of the peridynamic operators\ncan be derived directly from the eigenvalues of the Fourier multiplier tensors.\nWe reveal a simple structure for the Fourier multipliers in terms of\nhypergeometric functions, which allows for providing integral representations\nas well as hypergeometric representations of the eigenvalues. These\nrepresentations are utilized to show the convergence of the eigenvalues of\nlinear peridynamics to the eigenvalues of the Navier operator of linear\nelasticity in the limit of vanishing nonlocality. Moreover, the hypergeometric\nrepresentation of the eigenvalues is utilized to compute the spectrum of linear\nperidynamic operators.",
    "descriptor": "",
    "authors": [
      "Bacim Alali",
      "Nathan Albin"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.10335"
  },
  {
    "id": "arXiv:2206.10348",
    "title": "Supervised learning of random quantum circuits via scalable neural  networks",
    "abstract": "Predicting the output of quantum circuits is a hard computational task that\nplays a pivotal role in the development of universal quantum computers. Here we\ninvestigate the supervised learning of output expectation values of random\nquantum circuits. Deep convolutional neural networks (CNNs) are trained to\npredict single-qubit and two-qubit expectation values using databases of\nclassically simulated circuits. These circuits are represented via an\nappropriately designed one-hot encoding of the constituent gates. The\nprediction accuracy for previously unseen circuits is analyzed, also making\ncomparisons with small-scale quantum computers available from the free IBM\nQuantum program. The CNNs often outperform the quantum devices, depending on\nthe circuit depth, on the network depth, and on the training set size. Notably,\nour CNNs are designed to be scalable. This allows us exploiting transfer\nlearning and performing extrapolations to circuits larger than those included\nin the training set. These CNNs also demonstrate remarkable resilience against\nnoise, namely, they remain accurate even when trained on (simulated)\nexpectation values averaged over very few measurements.",
    "descriptor": "\nComments: 17 pages, 18 figures\n",
    "authors": [
      "S. Cantori",
      "D. Vitali",
      "S. Pilati"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10348"
  },
  {
    "id": "arXiv:2206.10357",
    "title": "Confidence-Guided Unsupervised Domain Adaptation for Cerebellum  Segmentation",
    "abstract": "The lack of a comprehensive high-resolution atlas of the cerebellum has\nhampered studies of cerebellar involvement in normal brain function and\ndisease. A good representation of the tightly foliated aspect of the cerebellar\ncortex is difficult to achieve because of the highly convoluted surface and the\ntime it would take for manual delineation. The quality of manual segmentation\nis influenced by human expert judgment, and automatic labelling is constrained\nby the limited robustness of existing segmentation algorithms. The\n20umisotropic BigBrain dataset provides an unprecedented high resolution\nframework for semantic segmentation compared to the 1000um(1mm) resolution\nafforded by magnetic resonance imaging. To dispense with the manual annotation\nrequirement, we propose to train a model to adaptively transfer the annotation\nfrom the cerebellum on the Allen Brain Human Brain Atlas to the BigBrain in an\nunsupervised manner, taking into account the different staining and spacing\nbetween sections. The distinct visual discrepancy between the Allen Brain and\nBigBrain prevents existing approaches to provide meaningful segmentation masks,\nand artifacts caused by sectioning and histological slice preparation in the\nBigBrain data pose an extra challenge. To address these problems, we propose a\ntwo-stage framework where we first transfer the Allen Brain cerebellum to a\nspace sharing visual similarity with the BigBrain. We then introduce a\nself-training strategy with a confidence map to guide the model learning from\nthe noisy pseudo labels iteratively. Qualitative results validate the\neffectiveness of our approach, and quantitative experiments reveal that our\nmethod can achieve over 2.6% loss reduction compared with other approaches.",
    "descriptor": "",
    "authors": [
      "Xuan Li",
      "Paule-J Toussaint",
      "Alan Evans",
      "Xue Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10357"
  },
  {
    "id": "arXiv:2206.10385",
    "title": "Approximate Equivariance SO(3) Needlet Convolution",
    "abstract": "This paper develops a rotation-invariant needlet convolution for rotation\ngroup SO(3) to distill multiscale information of spherical signals. The\nspherical needlet transform is generalized from $\\mathbb{S}^2$ onto the SO(3)\ngroup, which decomposes a spherical signal to approximate and detailed spectral\ncoefficients by a set of tight framelet operators. The spherical signal during\nthe decomposition and reconstruction achieves rotation invariance. Based on\nneedlet transforms, we form a Needlet approximate Equivariance Spherical CNN\n(NES) with multiple SO(3) needlet convolutional layers. The network establishes\na powerful tool to extract geometric-invariant features of spherical signals.\nThe model allows sufficient network scalability with multi-resolution\nrepresentation. A robust signal embedding is learned with wavelet shrinkage\nactivation function, which filters out redundant high-pass representation while\nmaintaining approximate rotation invariance. The NES achieves state-of-the-art\nperformance for quantum chemistry regression and Cosmic Microwave Background\n(CMB) delensing reconstruction, which shows great potential for solving\nscientific challenges with high-resolution and multi-scale spherical signal\nrepresentation.",
    "descriptor": "",
    "authors": [
      "Kai Yi",
      "Jialin Chen",
      "Yu Guang Wang",
      "Bingxin Zhou",
      "Pietro Li\u00f2",
      "Yanan Fan",
      "Jan Hamann"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10385"
  },
  {
    "id": "arXiv:2206.10406",
    "title": "Isogeometric Analysis of Elastic Sheets Exhibiting Combined Bending and  Stretching using Dynamic Relaxation",
    "abstract": "Shells are ubiquitous thin structures that can undergo large nonlinear\nelastic deformations while exhibiting combined modes of bending and stretching,\nand have profound modern applications. In this paper, we have proposed a new\nIsogeometric formulation, based on classical Koiter nonlinear shell theory, to\nstudy instability problems like wrinkling and buckling in thin shells. The use\nof NURBS-basis provides rotation-free, conforming, higher-order spatial\ncontinuity, such that curvatures and membrane strains can be computed directly\nfrom the interpolation of the position vectors of the control points. A pseudo,\ndissipative and discrete, dynamical system is constructed, and static\nequilibrium solutions are obtained by the method of dynamic relaxation (DR). A\nhigh-performance computing-based implementation of the DR is presented, and the\nproposed formulation is benchmarked against several existing numerical, and\nexperimental results. The advantages of this formulation, over traditional\nfinite element approaches, in assessing structural response of the shells are\npresented.",
    "descriptor": "",
    "authors": [
      "Nikhil Padhye",
      "Subodh Kalia"
    ],
    "subjectives": [
      "Soft Condensed Matter (cond-mat.soft)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.10406"
  },
  {
    "id": "arXiv:2206.10428",
    "title": "On the stochastic and asymptotic improvement of First-Come First-Served  and Nudge scheduling",
    "abstract": "Recently it was shown that, contrary to expectations, the\nFirst-Come-First-Served (FCFS) scheduling algorithm can be stochastically\nimproved upon by a scheduling algorithm called {\\it Nudge} for light-tailed job\nsize distributions. Nudge partitions jobs into 4 types based on their size, say\nsmall, medium, large and huge jobs. Nudge operates identical to FCFS, except\nthat whenever a {\\it small} job arrives that finds a {\\it large} job waiting at\nthe back of the queue, Nudge swaps the small job with the large one unless the\nlarge job was already involved in an earlier swap.\nIn this paper, we show that FCFS can be stochastically improved upon under\nfar weaker conditions. We consider a system with $2$ job types and limited\nswapping between type-$1$ and type-$2$ jobs, but where a type-$1$ job is not\nnecessarily smaller than a type-$2$ job. More specifically, we introduce and\nstudy the Nudge-$K$ scheduling algorithm which allows type-$1$ jobs to be\nswapped with up to $K$ type-$2$ jobs waiting at the back of the queue, while\ntype-$2$ jobs can be involved in at most one swap. We present an explicit\nexpression for the response time distribution under Nudge-$K$ when both job\ntypes follow a phase-type distribution. Regarding the asymptotic tail\nimprovement ratio (ATIR) , we derive a simple expression for the ATIR, as well\nas for the $K$ that maximizes the ATIR. We show that the ATIR is positive and\nthe optimal $K$ tends to infinity in heavy traffic as long as the type-$2$ jobs\nare on average longer than the type-$1$ jobs.",
    "descriptor": "",
    "authors": [
      "Benny Van Houdt"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2206.10428"
  },
  {
    "id": "arXiv:2206.10455",
    "title": "Automated Coronary Calcium Scoring using U-Net Models through  Semi-supervised Learning on Non-Gated CT Scans",
    "abstract": "Every year, thousands of innocent people die due to heart attacks. Often\nundiagnosed heart attacks can hit people by surprise since many current medical\nplans don't cover the costs to require the searching of calcification on these\nscans. Only if someone is suspected to have a heart problem, a gated CT scan is\ntaken, otherwise, there's no way for the patient to be aware of a possible\nheart attack/disease. While nongated CT scans are more periodically taken, it\nis harder to detect calcification and is usually taken for a purpose other than\nlocating calcification in arteries. In fact, in real time coronary artery\ncalcification scores are only calculated on gated CT scans, not nongated CT\nscans. After training a unet model on the Coronary Calcium and chest CT's gated\nscans, it received a DICE coefficient of 0.95 on its untouched test set. This\nmodel was used to predict on nongated CT scans, performing with a mean absolute\nerror (MAE) of 674.19 and bucket classification accuracy of 41% (5 classes).\nThrough the analysis of the images and the information stored in the images,\nmathematical equations were derived and used to automatically crop the images\naround the location of the heart. By performing semi-supervised learning the\nnew cropped nongated scans were able to closely resemble gated CT scans,\nimproving the performance by 91% in MAE (62.38) and 23% in accuracy.",
    "descriptor": "\nComments: 7 pages, 11 figs\n",
    "authors": [
      "Sanskriti Singh"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10455"
  },
  {
    "id": "arXiv:2206.10479",
    "title": "Policy learning with asymmetric utilities",
    "abstract": "Data-driven decision making plays an important role even in high stakes\nsettings like medicine and public policy. Learning optimal policies from\nobserved data requires a careful formulation of the utility function whose\nexpected value is maximized across a population. Although researchers typically\nuse utilities that depend on observed outcomes alone, in many settings the\ndecision maker's utility function is more properly characterized by the joint\nset of potential outcomes under all actions. For example, the Hippocratic\nprinciple to ``do no harm'' implies that the cost of causing death to a patient\nwho would otherwise survive without treatment is greater than the cost of\nforgoing life-saving treatment. We consider optimal policy learning with\nasymmetric utility functions of this form. We show that asymmetric utilities\nlead to an unidentifiable social welfare function, and so we first partially\nidentify it. Drawing on statistical decision theory, we then derive minimax\ndecision rules by minimizing the maximum regret relative to alternative\npolicies. We show that one can learn minimax decision rules from observed data\nby solving intermediate classification problems. We also establish that the\nfinite sample regret of this procedure is bounded by the mis-classification\nrate of these intermediate classifiers. We apply this conceptual framework and\nmethodology to the decision about whether or not to use right heart\ncatheterization for patients with possible pulmonary hypertension.",
    "descriptor": "",
    "authors": [
      "Eli Ben-Michael",
      "Kosuke Imai",
      "Zhichao Jiang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2206.10479"
  },
  {
    "id": "arXiv:2206.10543",
    "title": "Faster Diffusion Cardiac MRI with Deep Learning-based breath hold  reduction",
    "abstract": "Diffusion Tensor Cardiac Magnetic Resonance (DT-CMR) enables us to probe the\nmicrostructural arrangement of cardiomyocytes within the myocardium in vivo and\nnon-invasively, which no other imaging modality allows. This innovative\ntechnology could revolutionise the ability to perform cardiac clinical\ndiagnosis, risk stratification, prognosis and therapy follow-up. However,\nDT-CMR is currently inefficient with over six minutes needed to acquire a\nsingle 2D static image. Therefore, DT-CMR is currently confined to research but\nnot used clinically. We propose to reduce the number of repetitions needed to\nproduce DT-CMR datasets and subsequently de-noise them, decreasing the\nacquisition time by a linear factor while maintaining acceptable image quality.\nOur proposed approach, based on Generative Adversarial Networks, Vision\nTransformers, and Ensemble Learning, performs significantly and considerably\nbetter than previous proposed approaches, bringing single breath-hold DT-CMR\ncloser to reality.",
    "descriptor": "\nComments: 15 pages, 1 figures, 2 tables. To be published in MIUA22\n",
    "authors": [
      "Michael Tanzer",
      "Pedro Ferreira",
      "Andrew Scott",
      "Zohya Khalique",
      "Maria Dwornik",
      "Dudley Pennell",
      "Guang Yang",
      "Daniel Rueckert",
      "Sonia Nielles-Vallespin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10543"
  },
  {
    "id": "arXiv:2206.10551",
    "title": "On the effectiveness of persistent homology",
    "abstract": "Persistent homology (PH) is one of the most popular methods in Topological\nData Analysis. While PH has been used in many different types of applications,\nthe reasons behind its success remain elusive. In particular, it is not known\nfor which classes of problems it is most effective, or to what extent it can\ndetect geometric or topological features. The goal of this work is to identify\nsome types of problems on which PH performs well or even better than other\nmethods in data analysis. We consider three fundamental shape-analysis tasks:\nthe detection of the number of holes, curvature and convexity from 2D and 3D\npoint clouds sampled from shapes. Experiments demonstrate that PH is successful\nin these tasks, outperforming several baselines, including PointNet, an\narchitecture inspired precisely by the properties of point clouds. In addition,\nwe observe that PH remains effective for limited computational resources and\nlimited training data, as well as out-of-distribution test data, including\nvarious data transformations and noise.",
    "descriptor": "\nComments: Main text 9 pages; SI 10 pages; 24 figures\n",
    "authors": [
      "Renata Turke\u0161",
      "Guido Mont\u00fafar",
      "Nina Otter"
    ],
    "subjectives": [
      "Algebraic Topology (math.AT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10551"
  },
  {
    "id": "arXiv:2206.10566",
    "title": "Ensembling over Classifiers: a Bias-Variance Perspective",
    "abstract": "Ensembles are a straightforward, remarkably effective method for improving\nthe accuracy,calibration, and robustness of models on classification tasks;\nyet, the reasons that underlie their success remain an active area of research.\nWe build upon the extension to the bias-variance decomposition by Pfau (2013)\nin order to gain crucial insights into the behavior of ensembles of\nclassifiers. Introducing a dual reparameterization of the bias-variance\ntradeoff, we first derive generalized laws of total expectation and variance\nfor nonsymmetric losses typical of classification tasks. Comparing conditional\nand bootstrap bias/variance estimates, we then show that conditional estimates\nnecessarily incur an irreducible error. Next, we show that ensembling in dual\nspace reduces the variance and leaves the bias unchanged, whereas standard\nensembling can arbitrarily affect the bias. Empirically, standard ensembling\nreducesthe bias, leading us to hypothesize that ensembles of classifiers may\nperform well in part because of this unexpected reduction.We conclude by an\nempirical analysis of recent deep learning methods that ensemble over\nhyperparameters, revealing that these techniques indeed favor bias reduction.\nThis suggests that, contrary to classical wisdom, targeting bias reduction may\nbe a promising direction for classifier ensembles.",
    "descriptor": "",
    "authors": [
      "Neha Gupta",
      "Jamie Smith",
      "Ben Adlam",
      "Zelda Mariet"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10566"
  },
  {
    "id": "arXiv:2206.10575",
    "title": "Solving Constrained Variational Inequalities via an Interior Point  Method",
    "abstract": "We develop an interior-point approach to solve constrained variational\ninequality (cVI) problems. Inspired by the efficacy of the alternating\ndirection method of multipliers (ADMM) method in the single-objective context,\nwe generalize ADMM to derive a first-order method for cVIs, that we refer to as\nADMM-based interior point method for constrained VIs (ACVI). We provide\nconvergence guarantees for ACVI in two general classes of problems: (i) when\nthe operator is $\\xi$-monotone, and (ii) when it is monotone, the constraints\nare active and the game is not purely rotational. When the operator is in\naddition L-Lipschitz for the latter case, we match known lower bounds on rates\nfor the gap function of $\\mathcal{O}(1/\\sqrt{K})$ and $\\mathcal{O}(1/K)$ for\nthe last and average iterate, respectively. To the best of our knowledge, this\nis the first presentation of a first-order interior-point method for the\ngeneral cVI problem that has a global convergence guarantee. Moreover, unlike\nprevious work in this setting, ACVI provides a means to solve cVIs when the\nconstraints are nontrivial. Empirical analyses demonstrate clear advantages of\nACVI over common first-order methods. In particular, (i) cyclical behavior is\nnotably reduced as our methods approach the solution from the analytic center,\nand (ii) unlike projection-based methods that oscillate when near a constraint,\nACVI efficiently handles the constraints.",
    "descriptor": "",
    "authors": [
      "Tong Yang",
      "Michael I. Jordan",
      "Tatjana Chavdarova"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.10575"
  },
  {
    "id": "arXiv:1210.3039",
    "title": "Sequential Convex Programming Methods for A Class of Structured  Nonlinear Programming",
    "abstract": "Comments: 18 pages",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Zhaosong Lu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1210.3039"
  },
  {
    "id": "arXiv:1703.04316",
    "title": "Fast Simulation of Vehicles with Non-deformable Tracks",
    "abstract": "Comments: \\c{opyright} 2017 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works",
    "descriptor": "\nComments: \\c{opyright} 2017 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works\n",
    "authors": [
      "Martin Pecka",
      "Karel Zimmermann",
      "Tom\u00e1\u0161 Svoboda"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/1703.04316"
  },
  {
    "id": "arXiv:1709.00084",
    "title": "Behavior Trees in Robotics and AI: An Introduction",
    "abstract": "Behavior Trees in Robotics and AI: An Introduction",
    "descriptor": "",
    "authors": [
      "Michele Colledanchise",
      "Petter \u00d6gren"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/1709.00084"
  },
  {
    "id": "arXiv:1710.05359",
    "title": "Information-Theoretic Representation Learning for Positive-Unlabeled  Classification",
    "abstract": "Information-Theoretic Representation Learning for Positive-Unlabeled  Classification",
    "descriptor": "",
    "authors": [
      "Tomoya Sakai",
      "Gang Niu",
      "Masashi Sugiyama"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1710.05359"
  },
  {
    "id": "arXiv:1802.07024",
    "title": "A General Framework for Abstention Under Label Shift",
    "abstract": "A General Framework for Abstention Under Label Shift",
    "descriptor": "",
    "authors": [
      "Amr M. Alexandari",
      "Anshul Kundaje",
      "Avanti Shrikumar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1802.07024"
  },
  {
    "id": "arXiv:1803.04623",
    "title": "Thompson Sampling for Combinatorial Semi-Bandits",
    "abstract": "Thompson Sampling for Combinatorial Semi-Bandits",
    "descriptor": "",
    "authors": [
      "Siwei Wang",
      "Wei Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1803.04623"
  },
  {
    "id": "arXiv:1804.01953",
    "title": "Data-driven Policy Transfer with Imprecise Perception Simulation",
    "abstract": "Comments: \\c{opyright} 2018 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works",
    "descriptor": "\nComments: \\c{opyright} 2018 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works\n",
    "authors": [
      "Martin Pecka",
      "Karel Zimmermann",
      "Mat\u011bj Petrl\u00edk",
      "Tom\u00e1\u0161 Svoboda"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/1804.01953"
  },
  {
    "id": "arXiv:1810.00803",
    "title": "Large Scale Clustering with Variational EM for Gaussian Mixture Models",
    "abstract": "Large Scale Clustering with Variational EM for Gaussian Mixture Models",
    "descriptor": "",
    "authors": [
      "Florian Hirschberger",
      "Dennis Forster",
      "J\u00f6rg L\u00fccke"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1810.00803"
  },
  {
    "id": "arXiv:1901.06786",
    "title": "On the Capacity Region of Bipartite and Tripartite Entanglement  Switching",
    "abstract": "On the Capacity Region of Bipartite and Tripartite Entanglement  Switching",
    "descriptor": "",
    "authors": [
      "Gayane Vardoyan",
      "Philippe Nain",
      "Saikat Guha",
      "Don Towsley"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Performance (cs.PF)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/1901.06786"
  },
  {
    "id": "arXiv:1902.02804",
    "title": "SiamVGG: Visual Tracking using Deeper Siamese Networks",
    "abstract": "SiamVGG: Visual Tracking using Deeper Siamese Networks",
    "descriptor": "",
    "authors": [
      "Yuhong Li",
      "Xiaofan Zhang",
      "Deming Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1902.02804"
  },
  {
    "id": "arXiv:1902.08813",
    "title": "A Degeneracy Framework for Scalable Graph Autoencoders",
    "abstract": "Comments: International Joint Conference on Artificial Intelligence (IJCAI 2019)",
    "descriptor": "\nComments: International Joint Conference on Artificial Intelligence (IJCAI 2019)\n",
    "authors": [
      "Guillaume Salha",
      "Romain Hennequin",
      "Viet Anh Tran",
      "Michalis Vazirgiannis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1902.08813"
  },
  {
    "id": "arXiv:1906.01786",
    "title": "Global Optimality Guarantees For Policy Gradient Methods",
    "abstract": "Global Optimality Guarantees For Policy Gradient Methods",
    "descriptor": "",
    "authors": [
      "Jalaj Bhandari",
      "Daniel Russo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1906.01786"
  },
  {
    "id": "arXiv:1908.02553",
    "title": "Security measurement of a medical communication scheme based on chaos  and DNA coding",
    "abstract": "Comments: 17 pages, 9 figures, 8 tables",
    "descriptor": "\nComments: 17 pages, 9 figures, 8 tables\n",
    "authors": [
      "Lei Chen",
      "Chengqing Li",
      "Chao Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/1908.02553"
  },
  {
    "id": "arXiv:1908.05672",
    "title": "Towards Making the Most of BERT in Neural Machine Translation",
    "abstract": "Comments: 10pages. the same as AAAI 2020 version, reformated with additional link to github repository",
    "descriptor": "\nComments: 10pages. the same as AAAI 2020 version, reformated with additional link to github repository\n",
    "authors": [
      "Jiacheng Yang",
      "Mingxuan Wang",
      "Hao Zhou",
      "Chengqi Zhao",
      "Yong Yu",
      "Weinan Zhang",
      "Lei Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1908.05672"
  },
  {
    "id": "arXiv:1908.10843",
    "title": "An incompressibility theorem for automatic complexity",
    "abstract": "An incompressibility theorem for automatic complexity",
    "descriptor": "",
    "authors": [
      "Bj\u00f8rn Kjos-Hanssen"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/1908.10843"
  },
  {
    "id": "arXiv:1909.00885",
    "title": "Simplified decision making in the belief space using belief  sparsification",
    "abstract": "Comments: This is a preprint of an article published in the International Journal of Robotics Research (IJRR) [originally submitted December 2018, officially published June 2022]. For citation, please use the official journal version",
    "descriptor": "\nComments: This is a preprint of an article published in the International Journal of Robotics Research (IJRR) [originally submitted December 2018, officially published June 2022]. For citation, please use the official journal version\n",
    "authors": [
      "Khen Elimelech",
      "Vadim Indelman"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computational Complexity (cs.CC)",
      "Information Theory (cs.IT)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/1909.00885"
  },
  {
    "id": "arXiv:1911.01208",
    "title": "Higher Criticism for Discriminating Word-Frequency Tables and Testing  Authorship",
    "abstract": "Higher Criticism for Discriminating Word-Frequency Tables and Testing  Authorship",
    "descriptor": "",
    "authors": [
      "Alon Kipnis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1911.01208"
  },
  {
    "id": "arXiv:1911.11800",
    "title": "TimeCaps: Capturing Time Series Data With Capsule Networks",
    "abstract": "TimeCaps: Capturing Time Series Data With Capsule Networks",
    "descriptor": "",
    "authors": [
      "Hirunima Jayasekara",
      "Vinoj Jayasundara",
      "Mohamed Athif",
      "Jathushan Rajasegaran",
      "Sandaru Jayasekara",
      "Suranga Seneviratne",
      "Ranga Rodrigo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1911.11800"
  },
  {
    "id": "arXiv:1912.01467",
    "title": "Linear Convergence of Frank-Wolfe for Rank-One Matrix Recovery Without  Strong Convexity",
    "abstract": "Comments: Accepted to Mathematical Programming Series A",
    "descriptor": "\nComments: Accepted to Mathematical Programming Series A\n",
    "authors": [
      "Dan Garber"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1912.01467"
  },
  {
    "id": "arXiv:1912.07908",
    "title": "Selecting efficient and reliable preservation strategies: modeling  long-term information integrity using large-scale hierarchical discrete event  simulation",
    "abstract": "Comments: Forthcoming IJDC 2022",
    "descriptor": "\nComments: Forthcoming IJDC 2022\n",
    "authors": [
      "Micah Altman",
      "Richard Landau"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/1912.07908"
  },
  {
    "id": "arXiv:1912.08066",
    "title": "Putting Ridesharing to the Test: Efficient and Scalable Solutions and  the Power of Dynamic Vehicle Relocation",
    "abstract": "Comments: A version of this paper has been published in the Artificial Intelligence Review (this https URL)",
    "descriptor": "\nComments: A version of this paper has been published in the Artificial Intelligence Review (this https URL)\n",
    "authors": [
      "Panayiotis Danassis",
      "Marija Sakota",
      "Aris Filos-Ratsikas",
      "Boi Faltings"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/1912.08066"
  },
  {
    "id": "arXiv:1912.08157",
    "title": "Generalized perron roots and solvability of the absolute value equation",
    "abstract": "Comments: 17 pages, 2 figures",
    "descriptor": "\nComments: 17 pages, 2 figures\n",
    "authors": [
      "Manuel Radons",
      "Josu\u00e9 Tonelli-Cueto"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1912.08157"
  },
  {
    "id": "arXiv:2002.07279",
    "title": "Formal Methods: From Academia to Industrial Practice. A Travel Guide",
    "abstract": "Comments: 22 pages, 0 figures",
    "descriptor": "\nComments: 22 pages, 0 figures\n",
    "authors": [
      "Marieke Huisman",
      "Dilian Gurov",
      "Alexander Malkis"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2002.07279"
  },
  {
    "id": "arXiv:2002.10023",
    "title": "Suboptimal Control of Unknown Second-order Nonlinear Systems with  Guaranteed Global Convergence",
    "abstract": "Comments: 6 pages, 4 figures, accepted for publication in IEEE Control Systems Letters",
    "descriptor": "\nComments: 6 pages, 4 figures, accepted for publication in IEEE Control Systems Letters\n",
    "authors": [
      "Amir Shakouri",
      "M. Reza Emami"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2002.10023"
  },
  {
    "id": "arXiv:2002.11309",
    "title": "Neural Parametric Fokker-Planck Equations",
    "abstract": "Neural Parametric Fokker-Planck Equations",
    "descriptor": "",
    "authors": [
      "Shu Liu",
      "Wuchen Li",
      "Hongyuan Zha",
      "Haomin Zhou"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2002.11309"
  },
  {
    "id": "arXiv:2003.11331",
    "title": "A Formalization of SQL with Nulls",
    "abstract": "A Formalization of SQL with Nulls",
    "descriptor": "",
    "authors": [
      "Wilmer Ricciotti",
      "James Cheney"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2003.11331"
  },
  {
    "id": "arXiv:2003.12197",
    "title": "HERS: Homomorphically Encrypted Representation Search",
    "abstract": "Comments: Published in the Trustworthy Biometrics Special Issue of IEEE Transactions on Biometrics, Behavior, and Identity Science 2021",
    "descriptor": "\nComments: Published in the Trustworthy Biometrics Special Issue of IEEE Transactions on Biometrics, Behavior, and Identity Science 2021\n",
    "authors": [
      "Joshua J. Engelsma",
      "Anil K. Jain",
      "Vishnu Naresh Boddeti"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2003.12197"
  },
  {
    "id": "arXiv:2003.13947",
    "title": "SS-IL: Separated Softmax for Incremental Learning",
    "abstract": "SS-IL: Separated Softmax for Incremental Learning",
    "descriptor": "",
    "authors": [
      "Hongjoon Ahn",
      "Jihwan Kwak",
      "Subin Lim",
      "Hyeonsu Bang",
      "Hyojun Kim",
      "Taesup Moon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2003.13947"
  },
  {
    "id": "arXiv:2004.04344",
    "title": "Revisiting 2-3 Red-Black Trees with a Pedagogically Sound yet Efficient  Deletion Algorithm: The Parity-Seeking Delete Algorithm",
    "abstract": "Revisiting 2-3 Red-Black Trees with a Pedagogically Sound yet Efficient  Deletion Algorithm: The Parity-Seeking Delete Algorithm",
    "descriptor": "",
    "authors": [
      "Kamaledin Ghiasi-Shirazi",
      "Taraneh Ghandi",
      "Ali Taghizadeh",
      "Ali Rahimi-Baigi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2004.04344"
  },
  {
    "id": "arXiv:2004.14911",
    "title": "Recipes for Adapting Pre-trained Monolingual and Multilingual Models to  Machine Translation",
    "abstract": "Comments: Accepted for publication at EACL 2021",
    "descriptor": "\nComments: Accepted for publication at EACL 2021\n",
    "authors": [
      "Asa Cooper Stickland",
      "Xian Li",
      "Marjan Ghazvininejad"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2004.14911"
  },
  {
    "id": "arXiv:2005.03986",
    "title": "Exploiting $\\mathbf{c}$-Closure in Kernelization Algorithms for Graph  Problems",
    "abstract": "Exploiting $\\mathbf{c}$-Closure in Kernelization Algorithms for Graph  Problems",
    "descriptor": "",
    "authors": [
      "Tomohiro Koana",
      "Christian Komusiewicz",
      "Frank Sommer"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2005.03986"
  },
  {
    "id": "arXiv:2005.07662",
    "title": "Guided interactive image segmentation using machine learning and color  based data set clustering",
    "abstract": "Guided interactive image segmentation using machine learning and color  based data set clustering",
    "descriptor": "",
    "authors": [
      "Adrian Friebel",
      "Tim Johann",
      "Dirk Drasdo",
      "Stefan Hoehme"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2005.07662"
  },
  {
    "id": "arXiv:2005.11949",
    "title": "Approximation in shift-invariant spaces with deep ReLU neural networks",
    "abstract": "Approximation in shift-invariant spaces with deep ReLU neural networks",
    "descriptor": "",
    "authors": [
      "Yunfei Yang",
      "Zhen Li",
      "Yang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2005.11949"
  },
  {
    "id": "arXiv:2006.09230",
    "title": "Hessian-Free High-Resolution Nesterov Acceleration for Sampling",
    "abstract": "Hessian-Free High-Resolution Nesterov Acceleration for Sampling",
    "descriptor": "",
    "authors": [
      "Ruilin Li",
      "Hongyuan Zha",
      "Molei Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.09230"
  },
  {
    "id": "arXiv:2006.13448",
    "title": "On Multivariate Singular Spectrum Analysis and its Variants",
    "abstract": "On Multivariate Singular Spectrum Analysis and its Variants",
    "descriptor": "",
    "authors": [
      "Anish Agarwal",
      "Abdullah Alomar",
      "Devavrat Shah"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.13448"
  },
  {
    "id": "arXiv:2006.14591",
    "title": "Bidirectional compression in heterogeneous settings for distributed or  federated learning with partial participation: tight convergence guarantees",
    "abstract": "Comments: 54 pages, 4 theorems, 1 algorithm, code source on GitHub",
    "descriptor": "\nComments: 54 pages, 4 theorems, 1 algorithm, code source on GitHub\n",
    "authors": [
      "Constantin Philippenko",
      "Aymeric Dieuleveut"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.14591"
  },
  {
    "id": "arXiv:2006.15316",
    "title": "Logarithmic regret for episodic continuous-time linear-quadratic  reinforcement learning over a finite-time horizon",
    "abstract": "Comments: In this version, we added some comments and references",
    "descriptor": "\nComments: In this version, we added some comments and references\n",
    "authors": [
      "Matteo Basei",
      "Xin Guo",
      "Anran Hu",
      "Yufei Zhang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.15316"
  },
  {
    "id": "arXiv:2007.01441",
    "title": "Joint Frequency and Image Space Learning for MRI Reconstruction and  Analysis",
    "abstract": "Comments: Accepted for publication at the Journal of Machine Learning for Biomedical Imaging (MELBA) this https URL",
    "descriptor": "\nComments: Accepted for publication at the Journal of Machine Learning for Biomedical Imaging (MELBA) this https URL\n",
    "authors": [
      "Nalini M. Singh",
      "Juan Eugenio Iglesias",
      "Elfar Adalsteinsson",
      "Adrian V. Dalca",
      "Polina Golland"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2007.01441"
  },
  {
    "id": "arXiv:2007.16171",
    "title": "Reversible Debugging in Logic Programming",
    "abstract": "Comments: 15 pages, to appear in \"LNCS Honorary Volume for Manuel Hermenegildo\" [AVERTIS 2019]",
    "descriptor": "\nComments: 15 pages, to appear in \"LNCS Honorary Volume for Manuel Hermenegildo\" [AVERTIS 2019]\n",
    "authors": [
      "Germ\u00e1n Vidal"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2007.16171"
  },
  {
    "id": "arXiv:2008.02269",
    "title": "Computational Barriers to Estimation from Low-Degree Polynomials",
    "abstract": "Comments: v2 adds new results on planted clique",
    "descriptor": "\nComments: v2 adds new results on planted clique\n",
    "authors": [
      "Tselil Schramm",
      "Alexander S. Wein"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2008.02269"
  },
  {
    "id": "arXiv:2008.08798",
    "title": "Existence of EFX for Two Additive Valuations",
    "abstract": "Comments: 14 pages, 2 figures",
    "descriptor": "\nComments: 14 pages, 2 figures\n",
    "authors": [
      "Ryoga Mahara"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2008.08798"
  },
  {
    "id": "arXiv:2008.11600",
    "title": "Estimating Example Difficulty Using Variance of Gradients",
    "abstract": "Comments: Accepted to CVPR 2022",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Chirag Agarwal",
      "Daniel D'souza",
      "Sara Hooker"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2008.11600"
  },
  {
    "id": "arXiv:2009.03825",
    "title": "Optimal training of integer-valued neural networks with mixed integer  programming",
    "abstract": "Comments: To appear in PLOS ONE (2022)",
    "descriptor": "\nComments: To appear in PLOS ONE (2022)\n",
    "authors": [
      "T\u00f3mas Thorbjarnarson",
      "Neil Yorke-Smith"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.03825"
  },
  {
    "id": "arXiv:2009.09993",
    "title": "A Generic Methodology for the Statistically Uniform & Comparable  Evaluation of Automated Trading Platform Components",
    "abstract": "Comments: Associated processing files are available at: this https URL",
    "descriptor": "\nComments: Associated processing files are available at: this https URL\n",
    "authors": [
      "Artur Sokolovsky",
      "Luca Arnaboldi"
    ],
    "subjectives": [
      "Trading and Market Microstructure (q-fin.TR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2009.09993"
  },
  {
    "id": "arXiv:2009.10709",
    "title": "Fast Black-Box Quantum State Preparation",
    "abstract": "Comments: 31 pages, 5 figures, 2 tables; v3: significantly extended proofs. Delineating oracle variants",
    "descriptor": "\nComments: 31 pages, 5 figures, 2 tables; v3: significantly extended proofs. Delineating oracle variants\n",
    "authors": [
      "Johannes Bausch"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2009.10709"
  },
  {
    "id": "arXiv:2009.10761",
    "title": "On the Locality of Nash-Williams Forest Decomposition and Star-Forest  Decomposition",
    "abstract": "On the Locality of Nash-Williams Forest Decomposition and Star-Forest  Decomposition",
    "descriptor": "",
    "authors": [
      "David G. Harris",
      "Hsin-Hao Su",
      "Hoa T. Vu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2009.10761"
  },
  {
    "id": "arXiv:2009.14124",
    "title": "Parsing with Multilingual BERT, a Small Corpus, and a Small Treebank",
    "abstract": "Comments: In Findings of EMNLP 2020",
    "descriptor": "\nComments: In Findings of EMNLP 2020\n",
    "authors": [
      "Ethan C. Chau",
      "Lucy H. Lin",
      "Noah A. Smith"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2009.14124"
  },
  {
    "id": "arXiv:2010.04329",
    "title": "Constructions of MDS symbol-pair codes with minimum distance seven or  eight",
    "abstract": "Constructions of MDS symbol-pair codes with minimum distance seven or  eight",
    "descriptor": "",
    "authors": [
      "Junru Ma",
      "Jinquan Luo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2010.04329"
  },
  {
    "id": "arXiv:2010.08766",
    "title": "Tight Lower Complexity Bounds for Strongly Convex Finite-Sum  Optimization",
    "abstract": "Tight Lower Complexity Bounds for Strongly Convex Finite-Sum  Optimization",
    "descriptor": "",
    "authors": [
      "Min Zhang",
      "Yao Shu",
      "Kun He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.08766"
  },
  {
    "id": "arXiv:2010.11994",
    "title": "Thresholded Lasso Bandit",
    "abstract": "Comments: International Conference on Machine Learning (ICML 2022), Proceedings of Machine Learning Research",
    "descriptor": "\nComments: International Conference on Machine Learning (ICML 2022), Proceedings of Machine Learning Research\n",
    "authors": [
      "Kaito Ariu",
      "Kenshi Abe",
      "Alexandre Prouti\u00e8re"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.11994"
  },
  {
    "id": "arXiv:2010.12742",
    "title": "Text Style Transfer: A Review and Experimental Evaluation",
    "abstract": "Text Style Transfer: A Review and Experimental Evaluation",
    "descriptor": "",
    "authors": [
      "Zhiqiang Hu",
      "Roy Ka-Wei Lee",
      "Charu C. Aggarwal",
      "Aston Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2010.12742"
  },
  {
    "id": "arXiv:2010.13438",
    "title": "Pooling for First and Last Mile: Integrating Carpooling and Transit",
    "abstract": "Pooling for First and Last Mile: Integrating Carpooling and Transit",
    "descriptor": "",
    "authors": [
      "Andrea Araldo",
      "Andr\u00e9 de Palma",
      "Souhila Arib",
      "Vincent Gauthier",
      "Romain Sere",
      "Youssef Chaabouni",
      "Oussama Kharouaa",
      "Ado Adamou Abba Ari"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Computers and Society (cs.CY)",
      "General Economics (econ.GN)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2010.13438"
  },
  {
    "id": "arXiv:2011.00390",
    "title": "A Passive Navigation Planning Algorithm for Collision-free Control of  Mobile Robots",
    "abstract": "A Passive Navigation Planning Algorithm for Collision-free Control of  Mobile Robots",
    "descriptor": "",
    "authors": [
      "Carlo Tiseo",
      "Vladimir Ivan",
      "Wolfgang Merkt",
      "Ioannis Havoutis",
      "Michael Mistry",
      "Sethu Vijayakumar"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2011.00390"
  },
  {
    "id": "arXiv:2011.04555",
    "title": "Multi-Agent Reinforcement Learning for Channel Assignment and Power  Allocation in Platoon-Based C-V2X Systems",
    "abstract": "Comments: 5 pages, 3 figures",
    "descriptor": "\nComments: 5 pages, 3 figures\n",
    "authors": [
      "Hung V. Vu",
      "Mohammad Farzanullah",
      "Zheyu Liu",
      "Duy H. N. Nguyen",
      "Robert Morawski",
      "Tho Le-Ngoc"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.04555"
  },
  {
    "id": "arXiv:2011.05074",
    "title": "Efficient and Transferable Adversarial Examples from Bayesian Neural  Networks",
    "abstract": "Comments: Accepted at UAI 2022",
    "descriptor": "\nComments: Accepted at UAI 2022\n",
    "authors": [
      "Martin Gubri",
      "Maxime Cordy",
      "Mike Papadakis",
      "Yves Le Traon",
      "Koushik Sen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2011.05074"
  },
  {
    "id": "arXiv:2011.07932",
    "title": "Combating the Instability of Mutual Information-based Losses via  Regularization",
    "abstract": "Comments: Kwanghee Choi and Siyeong Lee contributed equally to this paper. Accepted for the 38th Conference on Uncertainty in Artificial Intelligence (UAI 2022)",
    "descriptor": "\nComments: Kwanghee Choi and Siyeong Lee contributed equally to this paper. Accepted for the 38th Conference on Uncertainty in Artificial Intelligence (UAI 2022)\n",
    "authors": [
      "Kwanghee Choi",
      "Siyeong Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2011.07932"
  },
  {
    "id": "arXiv:2011.10076",
    "title": "Optimal Algorithms for Convex Nested Stochastic Composite Optimization",
    "abstract": "Optimal Algorithms for Convex Nested Stochastic Composite Optimization",
    "descriptor": "",
    "authors": [
      "Zhe Zhang",
      "Guanghui Lan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.10076"
  },
  {
    "id": "arXiv:2011.13094",
    "title": "Combinatorial Bayesian Optimization with Random Mapping Functions to  Convex Polytopes",
    "abstract": "Comments: 11 pages, 3 figures. Accepted at the 38th Conference on Uncertainty in Artificial Intelligence (UAI 2022)",
    "descriptor": "\nComments: 11 pages, 3 figures. Accepted at the 38th Conference on Uncertainty in Artificial Intelligence (UAI 2022)\n",
    "authors": [
      "Jungtaek Kim",
      "Seungjin Choi",
      "Minsu Cho"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.13094"
  },
  {
    "id": "arXiv:2011.14033",
    "title": "A Tractable Online Learning Algorithm for the Multinomial Logit  Contextual Bandit",
    "abstract": "Comments: updated version, under review",
    "descriptor": "\nComments: updated version, under review\n",
    "authors": [
      "Priyank Agrawal",
      "Theja Tulabandhula",
      "Vashist Avadhanula"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2011.14033"
  },
  {
    "id": "arXiv:2011.14193",
    "title": "Stability of Finite Horizon Optimisation based Control without Terminal  Weight",
    "abstract": "Comments: Accepted by International Journal of Systems Science, 20/06/2022",
    "descriptor": "\nComments: Accepted by International Journal of Systems Science, 20/06/2022\n",
    "authors": [
      "Wen-Hua Chen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2011.14193"
  },
  {
    "id": "arXiv:2012.11866",
    "title": "Human Action Recognition from Various Data Modalities: A Review",
    "abstract": "Human Action Recognition from Various Data Modalities: A Review",
    "descriptor": "",
    "authors": [
      "Zehua Sun",
      "Qiuhong Ke",
      "Hossein Rahmani",
      "Mohammed Bennamoun",
      "Gang Wang",
      "Jun Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.11866"
  },
  {
    "id": "arXiv:2012.12809",
    "title": "Warping of Radar Data into Camera Image for Cross-Modal Supervision in  Automotive Applications",
    "abstract": "Warping of Radar Data into Camera Image for Cross-Modal Supervision in  Automotive Applications",
    "descriptor": "",
    "authors": [
      "Christopher Grimm",
      "Tai Fei",
      "Ernst Warsitz",
      "Ridha Farhoud",
      "Tobias Breddermann",
      "Reinhold Haeb-Umbach"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2012.12809"
  },
  {
    "id": "arXiv:2101.00903",
    "title": "Data-driven analysis and controller design for discrete-time systems  under aperiodic sampling",
    "abstract": "Comments: 16 pages, 4 figure, 1 table. Accepted for publication in the IEEE TAC",
    "descriptor": "\nComments: 16 pages, 4 figure, 1 table. Accepted for publication in the IEEE TAC\n",
    "authors": [
      "Stefan Wildhagen",
      "Julian Berberich",
      "Michael Hertneck",
      "Frank Allg\u00f6wer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2101.00903"
  },
  {
    "id": "arXiv:2101.07357",
    "title": "Unsupervised Imputation of Non-ignorably Missing Data Using  Importance-Weighted Autoencoders",
    "abstract": "Comments: 31 pages, 4 figures, 2 tables, under review (Biometrics Methodology)",
    "descriptor": "\nComments: 31 pages, 4 figures, 2 tables, under review (Biometrics Methodology)\n",
    "authors": [
      "David K. Lim",
      "Naim U. Rashid",
      "Junier B. Oliva",
      "Joseph G. Ibrahim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2101.07357"
  },
  {
    "id": "arXiv:2101.07681",
    "title": "Hyperspectral Image Denoising via Multi-modal and Double-weighted Tensor  Nuclear Norm",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2106.12489",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2106.12489\n",
    "authors": [
      "Sheng Liu",
      "Xiaozhen Xie",
      "Wenfeng Kong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.07681"
  },
  {
    "id": "arXiv:2101.11212",
    "title": "FGNET-RH: Fine-Grained Named Entity Typing via Refinement in Hyperbolic  Space",
    "abstract": "Comments: Updated the Abstract and title to make it true representative of the paper",
    "descriptor": "\nComments: Updated the Abstract and title to make it true representative of the paper\n",
    "authors": [
      "Muhammad Asif Ali",
      "Yifang Sun",
      "Bing Li",
      "Wei Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2101.11212"
  },
  {
    "id": "arXiv:2102.03497",
    "title": "Weight Rescaling: Effective and Robust Regularization for Deep Neural  Networks with Batch Normalization",
    "abstract": "Comments: Preprint",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Ziquan Liu",
      "Yufei Cui",
      "Jia Wan",
      "Yu Mao",
      "Antoni B. Chan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.03497"
  },
  {
    "id": "arXiv:2102.03679",
    "title": "A Review of Product Safety Regulations in the European Union",
    "abstract": "Comments: International Cybersecurity Law Review",
    "descriptor": "\nComments: International Cybersecurity Law Review\n",
    "authors": [
      "Jukka Ruohonen"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2102.03679"
  },
  {
    "id": "arXiv:2102.04966",
    "title": "Orbital Stabilization of Point-to-Point Maneuvers in Underactuated  Mechanical Systems",
    "abstract": "Orbital Stabilization of Point-to-Point Maneuvers in Underactuated  Mechanical Systems",
    "descriptor": "",
    "authors": [
      "Christian Fredrik S\u00e6tre",
      "Anton Shiriaev"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2102.04966"
  },
  {
    "id": "arXiv:2102.08275",
    "title": "Evaluating Node Embeddings of Complex Networks",
    "abstract": "Comments: 29 pages, 19 figures",
    "descriptor": "\nComments: 29 pages, 19 figures\n",
    "authors": [
      "Arash Dehghan-Kooshkghazi",
      "Bogumi\u0142 Kami\u0144ski",
      "\u0141ukasz Krai\u0144ski",
      "Pawe\u0142 Pra\u0142at",
      "Fran\u00e7ois Th\u00e9berge"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2102.08275"
  },
  {
    "id": "arXiv:2102.09626",
    "title": "A Simple Unified Framework for High Dimensional Bandit Problems",
    "abstract": "A Simple Unified Framework for High Dimensional Bandit Problems",
    "descriptor": "",
    "authors": [
      "Wenjie Li",
      "Adarsh Barik",
      "Jean Honorio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.09626"
  },
  {
    "id": "arXiv:2102.09822",
    "title": "A Higher-Order Generalized Singular Value Decomposition for Rank  Deficient Matrices",
    "abstract": "Comments: 18 pages, 4 figures",
    "descriptor": "\nComments: 18 pages, 4 figures\n",
    "authors": [
      "Idris Kempf",
      "Paul J. Goulart",
      "Stephen R. Duncan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2102.09822"
  },
  {
    "id": "arXiv:2102.10828",
    "title": "Automatic sequences: from rational bases to trees",
    "abstract": "Comments: 26 pages, 16 figures; final version accepted for publication in Discrete Mathematics & Theoretical Computer Science",
    "descriptor": "\nComments: 26 pages, 16 figures; final version accepted for publication in Discrete Mathematics & Theoretical Computer Science\n",
    "authors": [
      "Michel Rigo",
      "Manon Stipulanti"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2102.10828"
  },
  {
    "id": "arXiv:2103.00369",
    "title": "Towards Continual, Online, Self-Supervised Depth",
    "abstract": "Towards Continual, Online, Self-Supervised Depth",
    "descriptor": "",
    "authors": [
      "Muhammad Umar Karim Khan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2103.00369"
  },
  {
    "id": "arXiv:2103.04233",
    "title": "GANav: Efficient Terrain Segmentation for Robot Navigation in  Unstructured Outdoor Environments",
    "abstract": "GANav: Efficient Terrain Segmentation for Robot Navigation in  Unstructured Outdoor Environments",
    "descriptor": "",
    "authors": [
      "Tianrui Guan",
      "Divya Kothandaraman",
      "Rohan Chandra",
      "Adarsh Jagan Sathyamoorthy",
      "Kasun Weerakoon",
      "Dinesh Manocha"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.04233"
  },
  {
    "id": "arXiv:2103.04985",
    "title": "Significance tests of feature relevance for a black-box learner",
    "abstract": "Comments: Accepted for publication in IEEE Transactions on Neural Networks and Learning Systems",
    "descriptor": "\nComments: Accepted for publication in IEEE Transactions on Neural Networks and Learning Systems\n",
    "authors": [
      "Ben Dai",
      "Xiaotong Shen",
      "Wei Pan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2103.04985"
  },
  {
    "id": "arXiv:2103.05109",
    "title": "Highly Efficient Representation and Active Learning Framework and Its  Application to Imbalanced Medical Image Classification",
    "abstract": "Comments: Published in NeurIPs Data-Centric AI workshop",
    "descriptor": "\nComments: Published in NeurIPs Data-Centric AI workshop\n",
    "authors": [
      "Heng Hao",
      "Hankyu Moon",
      "Sima Didari",
      "Jae Oh Woo",
      "Patrick Bangert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2103.05109"
  },
  {
    "id": "arXiv:2103.06914",
    "title": "Simplification Strategies for the Qutrit ZX-Calculus",
    "abstract": "Comments: accepted to QPL 2022",
    "descriptor": "\nComments: accepted to QPL 2022\n",
    "authors": [
      "Alex Townsend-Teague",
      "Konstantinos Meichanetzidis"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2103.06914"
  },
  {
    "id": "arXiv:2103.11676",
    "title": "Continuous mean distance of a weighted graph",
    "abstract": "Continuous mean distance of a weighted graph",
    "descriptor": "",
    "authors": [
      "Delia Garijo",
      "Alberto M\u00e1rquez",
      "Rodrigo I. Silveira"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2103.11676"
  },
  {
    "id": "arXiv:2103.13581",
    "title": "EfficientTDNN: Efficient Architecture Search for Speaker Recognition",
    "abstract": "Comments: 13 pages, 12 figures, accepted to TASLP",
    "descriptor": "\nComments: 13 pages, 12 figures, accepted to TASLP\n",
    "authors": [
      "Rui Wang",
      "Zhihua Wei",
      "Haoran Duan",
      "Shouling Ji",
      "Yang Long",
      "Zhen Hong"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.13581"
  },
  {
    "id": "arXiv:2103.16156",
    "title": "Uniform Envelopes",
    "abstract": "Uniform Envelopes",
    "descriptor": "",
    "authors": [
      "Eike Neumann"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/2103.16156"
  },
  {
    "id": "arXiv:2103.16833",
    "title": "A categorical framework for congruence of applicative bisimilarity in  higher-order languages",
    "abstract": "A categorical framework for congruence of applicative bisimilarity in  higher-order languages",
    "descriptor": "",
    "authors": [
      "Tom Hirschowitz",
      "Ambroise Lafont"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2103.16833"
  },
  {
    "id": "arXiv:2104.01841",
    "title": "Spined categories: generalizing tree-width beyond graphs",
    "abstract": "Comments: 28 pages",
    "descriptor": "\nComments: 28 pages\n",
    "authors": [
      "Benjamin Merlin Bumpus",
      "Zoltan A. Kocsis"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2104.01841"
  },
  {
    "id": "arXiv:2104.06011",
    "title": "Sample-based and Feature-based Federated Learning for Unconstrained and  Constrained Nonconvex Optimization via Mini-batch SSCA",
    "abstract": "Comments: 18 pages, 4 figures. This work is to appear in IEEE Trans. Signal Process. arXiv admin note: substantial text overlap with arXiv:2103.09506",
    "descriptor": "\nComments: 18 pages, 4 figures. This work is to appear in IEEE Trans. Signal Process. arXiv admin note: substantial text overlap with arXiv:2103.09506\n",
    "authors": [
      "Ying Cui",
      "Yangchen Li",
      "Chencheng Ye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.06011"
  },
  {
    "id": "arXiv:2104.06366",
    "title": "Supporting Multiprocessor Resource Synchronization Protocols in RTEMS",
    "abstract": "Comments: 6 pages, 5 figures, presented in 16th annual workshop on Operating Systems Platforms for Embedded Real-Time applications (OSPERT'22)",
    "descriptor": "\nComments: 6 pages, 5 figures, presented in 16th annual workshop on Operating Systems Platforms for Embedded Real-Time applications (OSPERT'22)\n",
    "authors": [
      "Junjie Shi",
      "Jan Duy Thien Pham",
      "Malte M\u00fcnch",
      "Jan Viktor Hafemeister",
      "Jian-Jia Chen",
      "Kuan-Hsun Chen"
    ],
    "subjectives": [
      "Operating Systems (cs.OS)"
    ],
    "url": "https://arxiv.org/abs/2104.06366"
  },
  {
    "id": "arXiv:2104.06444",
    "title": "Going dark? Analysing the impact of end-to-end encryption on the outcome  of Dutch criminal court cases",
    "abstract": "Going dark? Analysing the impact of end-to-end encryption on the outcome  of Dutch criminal court cases",
    "descriptor": "",
    "authors": [
      "Pieter Hartel",
      "Rolf van Wegberg"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2104.06444"
  },
  {
    "id": "arXiv:2104.08690",
    "title": "Rethinking Image-Scaling Attacks: The Interplay Between Vulnerabilities  in Machine Learning Systems",
    "abstract": "Comments: Accepted by Proceedings of the 39th International Conference on Machine Learning",
    "descriptor": "\nComments: Accepted by Proceedings of the 39th International Conference on Machine Learning\n",
    "authors": [
      "Yue Gao",
      "Ilia Shumailov",
      "Kassem Fawaz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2104.08690"
  },
  {
    "id": "arXiv:2104.13312",
    "title": "Multi-fairness under class-imbalance",
    "abstract": "Multi-fairness under class-imbalance",
    "descriptor": "",
    "authors": [
      "Arjun Roy",
      "Vasileios Iosifidis",
      "Eirini Ntoutsi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2104.13312"
  },
  {
    "id": "arXiv:2104.14215",
    "title": "Unleashing the Power of Paying Multiplexing Only Once in Stochastic  Network Calculus",
    "abstract": "Comments: Accepted at ACM SIGMETRICS 2022",
    "descriptor": "\nComments: Accepted at ACM SIGMETRICS 2022\n",
    "authors": [
      "Anne Bouillard",
      "Paul Nikolaus",
      "Jens Schmitt"
    ],
    "subjectives": [
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2104.14215"
  },
  {
    "id": "arXiv:2105.00026",
    "title": "Data Augmentation in High Dimensional Low Sample Size Setting Using a  Geometry-Based Variational Autoencoder",
    "abstract": "Comments: accepted to IEEE transactions on pattern analysis and machine intelligence (TPAMI)",
    "descriptor": "\nComments: accepted to IEEE transactions on pattern analysis and machine intelligence (TPAMI)\n",
    "authors": [
      "Cl\u00e9ment Chadebec",
      "Elina Thibeau-Sutre",
      "Ninon Burgos",
      "St\u00e9phanie Allassonni\u00e8re"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.00026"
  },
  {
    "id": "arXiv:2105.04324",
    "title": "Passivity-based control of mechanical systems with linear damping  identification",
    "abstract": "Comments: Submission for 7th IFAC Workshop on Lagrangian and Hamiltonian Methods for Nonlinear Control. Fixed minor typo. Fixed G1 with correct value",
    "descriptor": "\nComments: Submission for 7th IFAC Workshop on Lagrangian and Hamiltonian Methods for Nonlinear Control. Fixed minor typo. Fixed G1 with correct value\n",
    "authors": [
      "Carmen Chan-Zheng",
      "Pablo Borja",
      "Jacquelien Scherpen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.04324"
  },
  {
    "id": "arXiv:2105.04756",
    "title": "HAPS-ITS: Enabling Future ITS Services in Trans-Continental Highways",
    "abstract": "Comments: 7 pages, 6 figures, accepted for publication in IEEE Communications Magazine (Jun. 2022)",
    "descriptor": "\nComments: 7 pages, 6 figures, accepted for publication in IEEE Communications Magazine (Jun. 2022)\n",
    "authors": [
      "Wael Jaafar",
      "Halim Yanikomeroglu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.04756"
  },
  {
    "id": "arXiv:2105.05432",
    "title": "Discrete-time Contraction-based Control of Nonlinear Systems with  Parametric Uncertainties using Neural Networks",
    "abstract": "Comments: This work has been submitted to Computers & Chemical Engineering for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to Computers & Chemical Engineering for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Lai Wei",
      "Ryan McCloy",
      "Jie Bao"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2105.05432"
  },
  {
    "id": "arXiv:2105.07459",
    "title": "Formal Security Analysis on dBFT Protocol of NEO",
    "abstract": "Comments: Extended version",
    "descriptor": "\nComments: Extended version\n",
    "authors": [
      "Qin Wang",
      "Rujia Li",
      "Shiping Chen",
      "Yang Xiang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.07459"
  },
  {
    "id": "arXiv:2105.11367",
    "title": "FedScale: Benchmarking Model and System Performance of Federated  Learning at Scale",
    "abstract": "FedScale: Benchmarking Model and System Performance of Federated  Learning at Scale",
    "descriptor": "",
    "authors": [
      "Fan Lai",
      "Yinwei Dai",
      "Sanjay S. Singapuram",
      "Jiachen Liu",
      "Xiangfeng Zhu",
      "Harsha V. Madhyastha",
      "Mosharaf Chowdhury"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2105.11367"
  },
  {
    "id": "arXiv:2105.11821",
    "title": "Payment Does Not Imply Consensus (For Distributed Payment Systems)",
    "abstract": "Payment Does Not Imply Consensus (For Distributed Payment Systems)",
    "descriptor": "",
    "authors": [
      "Thomas Orton"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.11821"
  },
  {
    "id": "arXiv:2105.13001",
    "title": "Estimating Instance-dependent Bayes-label Transition Matrix using a Deep  Neural Network",
    "abstract": "Comments: ICML 22 camera ready",
    "descriptor": "\nComments: ICML 22 camera ready\n",
    "authors": [
      "Shuo Yang",
      "Erkun Yang",
      "Bo Han",
      "Yang Liu",
      "Min Xu",
      "Gang Niu",
      "Tongliang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13001"
  },
  {
    "id": "arXiv:2105.13827",
    "title": "Extended Cyclic Codes Sandwiched Between Reed-Muller Codes",
    "abstract": "Comments: 17 pages; minor revision",
    "descriptor": "\nComments: 17 pages; minor revision\n",
    "authors": [
      "Yan Xu",
      "Changjiang Ji",
      "Ran Tao",
      "Sihuang Hu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.13827"
  },
  {
    "id": "arXiv:2105.14826",
    "title": "PF-Net: Personalized Filter for Speaker Recognition from Raw Waveform",
    "abstract": "PF-Net: Personalized Filter for Speaker Recognition from Raw Waveform",
    "descriptor": "",
    "authors": [
      "Wencheng Li",
      "Zhenhua Tan",
      "Jingyu Ning",
      "Zhenche Xia",
      "Danke Wu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2105.14826"
  },
  {
    "id": "arXiv:2106.00776",
    "title": "On Optimizing the Conditional Value-at-Risk of a Maximum Cost for  Risk-Averse Safety Analysis",
    "abstract": "Comments: This is the extended version of an article that has been conditionally accepted by IEEE Transactions on Automatic Control in May 2022",
    "descriptor": "\nComments: This is the extended version of an article that has been conditionally accepted by IEEE Transactions on Automatic Control in May 2022\n",
    "authors": [
      "Margaret P. Chapman",
      "Michael Fauss",
      "Kevin M. Smith"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.00776"
  },
  {
    "id": "arXiv:2106.02496",
    "title": "Quantum Perceptron Revisited: Computational-Statistical Tradeoffs",
    "abstract": "Comments: 13 pages, 4 figures, Published at the Conference on Uncertainty in Artificial Intelligence (UAI) 2022",
    "descriptor": "\nComments: 13 pages, 4 figures, Published at the Conference on Uncertainty in Artificial Intelligence (UAI) 2022\n",
    "authors": [
      "Mathieu Roget",
      "Giuseppe Di Molfetta",
      "Hachem Kadri"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02496"
  },
  {
    "id": "arXiv:2106.04560",
    "title": "Scaling Vision Transformers",
    "abstract": "Comments: Xiaohua, Alex, and Lucas contributed equally; CVPR 2022",
    "descriptor": "\nComments: Xiaohua, Alex, and Lucas contributed equally; CVPR 2022\n",
    "authors": [
      "Xiaohua Zhai",
      "Alexander Kolesnikov",
      "Neil Houlsby",
      "Lucas Beyer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.04560"
  },
  {
    "id": "arXiv:2106.04953",
    "title": "Expectation Programming: Adapting Probabilistic Programming Systems to  Estimate Expectations Efficiently",
    "abstract": "Comments: Accepted for the 38th Conference on Uncertainty in Artificial Intelligence (UAI 2022)",
    "descriptor": "\nComments: Accepted for the 38th Conference on Uncertainty in Artificial Intelligence (UAI 2022)\n",
    "authors": [
      "Tim Reichelt",
      "Adam Goli\u0144ski",
      "Luke Ong",
      "Tom Rainforth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2106.04953"
  },
  {
    "id": "arXiv:2106.05237",
    "title": "Knowledge distillation: A good teacher is patient and consistent",
    "abstract": "Comments: Lucas, Xiaohua, Am\\'elie, Larisa, and Alex contributed equally; CVPR 2022",
    "descriptor": "\nComments: Lucas, Xiaohua, Am\\'elie, Larisa, and Alex contributed equally; CVPR 2022\n",
    "authors": [
      "Lucas Beyer",
      "Xiaohua Zhai",
      "Am\u00e9lie Royer",
      "Larisa Markeeva",
      "Rohan Anil",
      "Alexander Kolesnikov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.05237"
  },
  {
    "id": "arXiv:2106.05481",
    "title": "Tree-Structured Data Clustering-Driven Neural Network for Intra  Prediction in Video Coding",
    "abstract": "Tree-Structured Data Clustering-Driven Neural Network for Intra  Prediction in Video Coding",
    "descriptor": "",
    "authors": [
      "Hengyu Man",
      "Xiaopeng Fan",
      "Ruiqin Xiong",
      "Debin Zhao"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2106.05481"
  },
  {
    "id": "arXiv:2106.05565",
    "title": "Identifiability of interaction kernels in mean-field equations of  interacting particles",
    "abstract": "Identifiability of interaction kernels in mean-field equations of  interacting particles",
    "descriptor": "",
    "authors": [
      "Quanjun Lang",
      "Fei Lu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2106.05565"
  },
  {
    "id": "arXiv:2106.05802",
    "title": "Metric Policy Representations for Opponent Modeling",
    "abstract": "Comments: 9 pages, 7 figures",
    "descriptor": "\nComments: 9 pages, 7 figures\n",
    "authors": [
      "Haobin Jiang",
      "Yifan Yu",
      "Zongqing Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2106.05802"
  },
  {
    "id": "arXiv:2106.06680",
    "title": "Markov Decision Processes with Long-Term Average Constraints",
    "abstract": "Markov Decision Processes with Long-Term Average Constraints",
    "descriptor": "",
    "authors": [
      "Mridul Agarwal",
      "Qinbo Bai",
      "Vaneet Aggarwal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.06680"
  },
  {
    "id": "arXiv:2106.08161",
    "title": "Contrastive Mixture of Posteriors for Counterfactual Inference, Data  Integration and Fairness",
    "abstract": "Comments: Published as a conference paper (long presentation) at ICML 2022",
    "descriptor": "\nComments: Published as a conference paper (long presentation) at ICML 2022\n",
    "authors": [
      "Adam Foster",
      "\u00c1rpi Vez\u00e9r",
      "Craig A Glastonbury",
      "P\u00e1id\u00ed Creed",
      "Sam Abujudeh",
      "Aaron Sim"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Genomics (q-bio.GN)"
    ],
    "url": "https://arxiv.org/abs/2106.08161"
  },
  {
    "id": "arXiv:2106.08261",
    "title": "Physion: Evaluating Physical Prediction from Vision in Humans and  Machines",
    "abstract": "Comments: 28 pages",
    "descriptor": "\nComments: 28 pages\n",
    "authors": [
      "Daniel M. Bear",
      "Elias Wang",
      "Damian Mrowca",
      "Felix J. Binder",
      "Hsiao-Yu Fish Tung",
      "R.T. Pramod",
      "Cameron Holdaway",
      "Sirui Tao",
      "Kevin Smith",
      "Fan-Yun Sun",
      "Li Fei-Fei",
      "Nancy Kanwisher",
      "Joshua B. Tenenbaum",
      "Daniel L.K. Yamins",
      "Judith E. Fan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08261"
  },
  {
    "id": "arXiv:2106.08913",
    "title": "Technical Report: Hardening Code Obfuscation Against Automated Attacks",
    "abstract": "Technical Report: Hardening Code Obfuscation Against Automated Attacks",
    "descriptor": "",
    "authors": [
      "Moritz Schloegel",
      "Tim Blazytko",
      "Moritz Contag",
      "Cornelius Aschermann",
      "Julius Basler",
      "Thorsten Holz",
      "Ali Abbasi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.08913"
  },
  {
    "id": "arXiv:2106.09063",
    "title": "Specializing Multilingual Language Models: An Empirical Study",
    "abstract": "Comments: Workshop on Multilingual Representation Learning (MRL) 2021",
    "descriptor": "\nComments: Workshop on Multilingual Representation Learning (MRL) 2021\n",
    "authors": [
      "Ethan C. Chau",
      "Noah A. Smith"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.09063"
  },
  {
    "id": "arXiv:2106.10558",
    "title": "Rayleigh-Gauss-Newton optimization with enhanced sampling for  variational Monte Carlo",
    "abstract": "Comments: 12 pages, 8 figures",
    "descriptor": "\nComments: 12 pages, 8 figures\n",
    "authors": [
      "Robert J. Webber",
      "Michael Lindsey"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.10558"
  },
  {
    "id": "arXiv:2106.12163",
    "title": "Region-Aware Network: Model Human's Top-Down Visual Perception Mechanism  for Crowd Counting",
    "abstract": "Region-Aware Network: Model Human's Top-Down Visual Perception Mechanism  for Crowd Counting",
    "descriptor": "",
    "authors": [
      "Yuehai Chen",
      "Jing Yang",
      "Dong Zhang",
      "Kun Zhang",
      "Badong Chen",
      "Shaoyi Du"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.12163"
  },
  {
    "id": "arXiv:2106.12489",
    "title": "Multi-modal and frequency-weighted tensor nuclear norm for hyperspectral  image denoising",
    "abstract": "Comments: This version modifies the list of authors, due to the changes of some authors' affiliations and the affiliations' requirements",
    "descriptor": "\nComments: This version modifies the list of authors, due to the changes of some authors' affiliations and the affiliations' requirements\n",
    "authors": [
      "Xiaozhen Xie",
      "Sheng Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.12489"
  },
  {
    "id": "arXiv:2106.14956",
    "title": "Robust Distributed Optimization With Randomly Corrupted Gradients",
    "abstract": "Comments: 21 pages, 5 figures",
    "descriptor": "\nComments: 21 pages, 5 figures\n",
    "authors": [
      "Berkay Turan",
      "Cesar A. Uribe",
      "Hoi-To Wai",
      "Mahnoosh Alizadeh"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.14956"
  },
  {
    "id": "arXiv:2106.15590",
    "title": "The Values Encoded in Machine Learning Research",
    "abstract": "Comments: Data and code available at this https URL arXiv admin note: text overlap with arXiv:2206.04179",
    "descriptor": "\nComments: Data and code available at this https URL arXiv admin note: text overlap with arXiv:2206.04179\n",
    "authors": [
      "Abeba Birhane",
      "Pratyusha Kalluri",
      "Dallas Card",
      "William Agnew",
      "Ravit Dotan",
      "Michelle Bao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.15590"
  },
  {
    "id": "arXiv:2107.00243",
    "title": "Preconditioning for Scalable Gaussian Process Hyperparameter  Optimization",
    "abstract": "Comments: International Conference on Machine Learning (ICML)",
    "descriptor": "\nComments: International Conference on Machine Learning (ICML)\n",
    "authors": [
      "Jonathan Wenger",
      "Geoff Pleiss",
      "Philipp Hennig",
      "John P. Cunningham",
      "Jacob R. Gardner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.00243"
  },
  {
    "id": "arXiv:2107.01360",
    "title": "Supervised Off-Policy Ranking",
    "abstract": "Comments: Accepted by ICML 2022",
    "descriptor": "\nComments: Accepted by ICML 2022\n",
    "authors": [
      "Yue Jin",
      "Yue Zhang",
      "Tao Qin",
      "Xudong Zhang",
      "Jian Yuan",
      "Houqiang Li",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01360"
  },
  {
    "id": "arXiv:2107.01889",
    "title": "OPA: Object Placement Assessment Dataset",
    "abstract": "OPA: Object Placement Assessment Dataset",
    "descriptor": "",
    "authors": [
      "Liu Liu",
      "Zhenchen Liu",
      "Bo Zhang",
      "Jiangtong Li",
      "Li Niu",
      "Qingyang Liu",
      "Liqing Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.01889"
  },
  {
    "id": "arXiv:2107.05516",
    "title": "A Scalable Actor-based Programming System for PGAS Runtimes",
    "abstract": "A Scalable Actor-based Programming System for PGAS Runtimes",
    "descriptor": "",
    "authors": [
      "Sri Raj Paul",
      "Akihiro Hayashi",
      "Kun Chen",
      "Vivek Sarkar"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2107.05516"
  },
  {
    "id": "arXiv:2107.05911",
    "title": "Model Transferability With Responsive Decision Subjects",
    "abstract": "Comments: Preprint under review",
    "descriptor": "\nComments: Preprint under review\n",
    "authors": [
      "Yang Liu",
      "Yatong Chen",
      "Zeyu Tang",
      "Kun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.05911"
  },
  {
    "id": "arXiv:2107.07401",
    "title": "On Hard and Soft Decision Decoding of BCH Codes",
    "abstract": "Comments: To appear in the IEEE Transactions on Information Theory",
    "descriptor": "\nComments: To appear in the IEEE Transactions on Information Theory\n",
    "authors": [
      "Martin Bossert",
      "Rebekka Schulz",
      "Sebastian Bitzer"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.07401"
  },
  {
    "id": "arXiv:2107.08310",
    "title": "Fairer Machine Learning Software on Multiple Sensitive Attributes With  Data Preprocessing",
    "abstract": "Comments: 10 pages",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Zhe Yu",
      "Joymallya Chakraborty",
      "Tim Menzies"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.08310"
  },
  {
    "id": "arXiv:2107.11035",
    "title": "A priori and a posteriori error estimates for the Deep Ritz method  applied to the Laplace and Stokes problem",
    "abstract": "A priori and a posteriori error estimates for the Deep Ritz method  applied to the Laplace and Stokes problem",
    "descriptor": "",
    "authors": [
      "Piotr Minakowski",
      "Thomas Richter"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.11035"
  },
  {
    "id": "arXiv:2107.11191",
    "title": "Regularising Inverse Problems with Generative Machine Learning Models",
    "abstract": "Regularising Inverse Problems with Generative Machine Learning Models",
    "descriptor": "",
    "authors": [
      "Margaret Duff",
      "Neill D. F. Campbell",
      "Matthias J. Ehrhardt"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2107.11191"
  },
  {
    "id": "arXiv:2107.13440",
    "title": "Study on Precoding Optimization Algorithms in Massive MIMO System with  Multi-Antenna Users",
    "abstract": "Comments: 16 pages, 6 figures, 6 tables, the work has been accepted for publication in Optimization Methods and Software, comments are welcome",
    "descriptor": "\nComments: 16 pages, 6 figures, 6 tables, the work has been accepted for publication in Optimization Methods and Software, comments are welcome\n",
    "authors": [
      "Evgeny Bobrov",
      "Dmitry Kropotov",
      "Sergey Troshin",
      "Danila Zaev"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2107.13440"
  },
  {
    "id": "arXiv:2107.14412",
    "title": "Towards Data-Driven Synthesis of Autonomous Vehicle Safety Concepts",
    "abstract": "Towards Data-Driven Synthesis of Autonomous Vehicle Safety Concepts",
    "descriptor": "",
    "authors": [
      "Karen Leung",
      "Andrea Bajcsy",
      "Edward Schmerling",
      "Marco Pavone"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.14412"
  },
  {
    "id": "arXiv:2108.01843",
    "title": "Model-Based Opponent Modeling",
    "abstract": "Comments: 21 pages, 10 figures",
    "descriptor": "\nComments: 21 pages, 10 figures\n",
    "authors": [
      "Xiaopeng Yu",
      "Jiechuan Jiang",
      "Wanpeng Zhang",
      "Haobin Jiang",
      "Zongqing Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2108.01843"
  },
  {
    "id": "arXiv:2108.01975",
    "title": "Deep Anomaly Discovery From Unlabeled Videos via Normality Advantage and  Self-Paced Refinement",
    "abstract": "Comments: Accepted by CVPR 2022",
    "descriptor": "\nComments: Accepted by CVPR 2022\n",
    "authors": [
      "Guang Yu",
      "Siqi Wang",
      "Zhiping Cai",
      "Xinwang Liu",
      "Chuanfu Xu",
      "Chengkun Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.01975"
  },
  {
    "id": "arXiv:2108.02161",
    "title": "Localized Shape Modelling with Global Coherence: An Inverse Spectral  Approach",
    "abstract": "Comments: Accepted at SGP2022",
    "descriptor": "\nComments: Accepted at SGP2022\n",
    "authors": [
      "Marco Pegoraro",
      "Simone Melzi",
      "Umberto Castellani",
      "Riccardo Marin",
      "Emanuele Rodol\u00e0"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.02161"
  },
  {
    "id": "arXiv:2108.02348",
    "title": "Data Acquisition and Preparation for Dual-reference Deep Learning of  Image Super-Resolution",
    "abstract": "Comments: Accepted by IEEE Transactions on Image Processing (TIP)",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Image Processing (TIP)\n",
    "authors": [
      "Yanhui Guo",
      "Xiaolin Wu",
      "Xiao Shu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.02348"
  },
  {
    "id": "arXiv:2108.03429",
    "title": "Enhancing MR Image Segmentation with Realistic Adversarial Data  Augmentation",
    "abstract": "Comments: Under review",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Chen Chen",
      "Chen Qin",
      "Cheng Ouyang",
      "Zeju Li",
      "Shuo Wang",
      "Huaqi Qiu",
      "Liang Chen",
      "Giacomo Tarroni",
      "Wenjia Bai",
      "Daniel Rueckert"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2108.03429"
  },
  {
    "id": "arXiv:2108.03555",
    "title": "Rapid Automated Analysis of Skull Base Tumor Specimens Using  Intraoperative Optical Imaging and Artificial Intelligence",
    "abstract": "Comments: Published as journal article",
    "descriptor": "\nComments: Published as journal article\n",
    "authors": [
      "Cheng Jiang",
      "Abhishek Bhattacharya",
      "Joseph Linzey",
      "Rushikesh S. Joshi",
      "Sung Jik Cha",
      "Sudharsan Srinivasan",
      "Daniel Alber",
      "Akhil Kondepudi",
      "Esteban Urias",
      "Balaji Pandian",
      "Wajd Al-Holou",
      "Steve Sullivan",
      "B. Gregory Thompson",
      "Jason Heth",
      "Chris Freudiger",
      "Siri Khalsa",
      "Donato Pacione",
      "John G. Golfinos",
      "Sandra Camelo-Piragua",
      "Daniel A. Orringer",
      "Honglak Lee",
      "Todd Hollon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.03555"
  },
  {
    "id": "arXiv:2108.05030",
    "title": "DQ-GAT: Towards Safe and Efficient Autonomous Driving with Deep  Q-Learning and Graph Attention Networks",
    "abstract": "Comments: Accepted to IEEE Transactions on Intelligent Transportation Systems (T-ITS), 2022",
    "descriptor": "\nComments: Accepted to IEEE Transactions on Intelligent Transportation Systems (T-ITS), 2022\n",
    "authors": [
      "Peide Cai",
      "Hengli Wang",
      "Yuxiang Sun",
      "Ming Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2108.05030"
  },
  {
    "id": "arXiv:2108.06704",
    "title": "STAR-RIS Aided NOMA in Multi-Cell Networks: A General Analytical  Framework with Gamma Distributed Channel Modeling",
    "abstract": "Comments: Accepted by IEEE Transactions on Communications",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Communications\n",
    "authors": [
      "Ziyi Xie",
      "Wenqiang Yi",
      "Xuanli Wu",
      "Yuanwei Liu",
      "Arumugam Nallanathan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2108.06704"
  },
  {
    "id": "arXiv:2108.07108",
    "title": "How Deep the Theory of Quantum Communications Goes: Superadditivity,  Superactivation and Causal Activation",
    "abstract": "How Deep the Theory of Quantum Communications Goes: Superadditivity,  Superactivation and Causal Activation",
    "descriptor": "",
    "authors": [
      "Seid Koudia",
      "Angela Sara Cacciapuoti",
      "Kyrylo Simonov",
      "Marcello Caleffi"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2108.07108"
  },
  {
    "id": "arXiv:2108.08338",
    "title": "Self-Sovereign Identity: A Systematic Review, Mapping and Taxonomy",
    "abstract": "Self-Sovereign Identity: A Systematic Review, Mapping and Taxonomy",
    "descriptor": "",
    "authors": [
      "Frederico Schardong",
      "Ricardo Cust\u00f3dio"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2108.08338"
  },
  {
    "id": "arXiv:2108.08930",
    "title": "Cross-Silo Federated Learning for Multi-Tier Networks with Vertical and  Horizontal Data Partitioning",
    "abstract": "Comments: Accepted in ACM Transactions on Intelligent Systems and Technology (ACM TIST), 2022. Updated paper organization, algorithm description, figures, numerical experiments. This is the final camera ready version",
    "descriptor": "\nComments: Accepted in ACM Transactions on Intelligent Systems and Technology (ACM TIST), 2022. Updated paper organization, algorithm description, figures, numerical experiments. This is the final camera ready version\n",
    "authors": [
      "Anirban Das",
      "Timothy Castiglia",
      "Shiqiang Wang",
      "Stacy Patterson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2108.08930"
  },
  {
    "id": "arXiv:2108.11791",
    "title": "Ensemble CNN and Uncertainty Modeling to Improve Automatic  Identification/Segmentation of Multiple Sclerosis Lesions in Magnetic  Resonance Imaging",
    "abstract": "Ensemble CNN and Uncertainty Modeling to Improve Automatic  Identification/Segmentation of Multiple Sclerosis Lesions in Magnetic  Resonance Imaging",
    "descriptor": "",
    "authors": [
      "Giuseppe Placidi",
      "Luigi Cinque",
      "Daniela Iacoviello",
      "Filippo Mignosi",
      "Matteo Polsinelli"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.11791"
  },
  {
    "id": "arXiv:2109.01207",
    "title": "Similarity of Sentence Representations in Multilingual LMs: Resolving  Conflicting Literature and Case Study of Baltic Languages",
    "abstract": "Comments: 10 pages, 9 figures",
    "descriptor": "\nComments: 10 pages, 9 figures\n",
    "authors": [
      "Maksym Del",
      "Mark Fishel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.01207"
  },
  {
    "id": "arXiv:2109.02464",
    "title": "Practical and Secure Federated Recommendation with Personalized Masks",
    "abstract": "Comments: 7 pages, International Workshop on Trustworthy Federated Learning in Conjunction with IJCAI 2022 (FL-IJCAI'22)",
    "descriptor": "\nComments: 7 pages, International Workshop on Trustworthy Federated Learning in Conjunction with IJCAI 2022 (FL-IJCAI'22)\n",
    "authors": [
      "Liu Yang",
      "Junxue Zhang",
      "Di Chai",
      "Leye Wang",
      "Kun Guo",
      "Kai Chen",
      "Qiang Yang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.02464"
  },
  {
    "id": "arXiv:2109.04516",
    "title": "Robust Impedance Control for Dexterous Interaction Using Fractal  Impedance Controller with IK-Optimisation",
    "abstract": "Robust Impedance Control for Dexterous Interaction Using Fractal  Impedance Controller with IK-Optimisation",
    "descriptor": "",
    "authors": [
      "Carlo Tiseo",
      "Quentin Rouxel",
      "Zhibin Li",
      "Michael Mistry"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.04516"
  },
  {
    "id": "arXiv:2109.04529",
    "title": "Parameterized inapproximability of Morse matching",
    "abstract": "Comments: Improved exposition in Section 4.3",
    "descriptor": "\nComments: Improved exposition in Section 4.3\n",
    "authors": [
      "Ulrich Bauer",
      "Abhishek Rathod"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2109.04529"
  },
  {
    "id": "arXiv:2109.06375",
    "title": "Adaptive Constrained Kinematic Control using Partial or Complete  Task-Space Measurements",
    "abstract": "Comments: Accepted on T-RO 2022, 16 Pages. Corrected a few typos and adjusted figure placement",
    "descriptor": "\nComments: Accepted on T-RO 2022, 16 Pages. Corrected a few typos and adjusted figure placement\n",
    "authors": [
      "Murilo Marques Marinho",
      "Bruno Vilhena Adorno"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.06375"
  },
  {
    "id": "arXiv:2109.07644",
    "title": "OPV2V: An Open Benchmark Dataset and Fusion Pipeline for Perception with  Vehicle-to-Vehicle Communication",
    "abstract": "Comments: Accepted by ICRA2022",
    "descriptor": "\nComments: Accepted by ICRA2022\n",
    "authors": [
      "Runsheng Xu",
      "Hao Xiang",
      "Xin Xia",
      "Xu Han",
      "Jinlong Li",
      "Jiaqi Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.07644"
  },
  {
    "id": "arXiv:2109.09698",
    "title": "A Multivariate Spline based Collocation Method for Numerical Solution of  Partial Differential Equations",
    "abstract": "A Multivariate Spline based Collocation Method for Numerical Solution of  Partial Differential Equations",
    "descriptor": "",
    "authors": [
      "Ming-Jun Lai",
      "Jinsil Lee"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2109.09698"
  },
  {
    "id": "arXiv:2109.10061",
    "title": "Graph Neural Networks for Graph Drawing",
    "abstract": "Comments: Accepted for publication in Transaction of Neural Networks and Learning Systems (TNNLS), Special Issue on Deep Neural Networks for Graphs: Theory, Models, Algorithms and Applications",
    "descriptor": "\nComments: Accepted for publication in Transaction of Neural Networks and Learning Systems (TNNLS), Special Issue on Deep Neural Networks for Graphs: Theory, Models, Algorithms and Applications\n",
    "authors": [
      "Matteo Tiezzi",
      "Gabriele Ciravegna",
      "Marco Gori"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.10061"
  },
  {
    "id": "arXiv:2109.11316",
    "title": "The Hilti SLAM Challenge Dataset",
    "abstract": "Comments: in IEEE Robotics and Automation Letters, 2022",
    "descriptor": "\nComments: in IEEE Robotics and Automation Letters, 2022\n",
    "authors": [
      "Michael Helmberger",
      "Kristian Morin",
      "Beda Berner",
      "Nitish Kumar",
      "Giovanni Cioffi",
      "Davide Scaramuzza"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.11316"
  },
  {
    "id": "arXiv:2109.11637",
    "title": "Learning Generative Deception Strategies in Combinatorial Masking Games",
    "abstract": "Comments: GameSec 2021",
    "descriptor": "\nComments: GameSec 2021\n",
    "authors": [
      "Junlin Wu",
      "Charles Kamhoua",
      "Murat Kantarcioglu",
      "Yevgeniy Vorobeychik"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.11637"
  },
  {
    "id": "arXiv:2109.12073",
    "title": "A Graph Policy Network Approach for Volt-Var Control in Power  Distribution Systems",
    "abstract": "Comments: Presented at NeurIPS 2021 Deep RL Workshop",
    "descriptor": "\nComments: Presented at NeurIPS 2021 Deep RL Workshop\n",
    "authors": [
      "Xian Yeow Lee",
      "Soumik Sarkar",
      "Yubo Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.12073"
  },
  {
    "id": "arXiv:2109.12508",
    "title": "LINDA: Multi-Agent Local Information Decomposition for Awareness of  Teammates",
    "abstract": "LINDA: Multi-Agent Local Information Decomposition for Awareness of  Teammates",
    "descriptor": "",
    "authors": [
      "Jiahan Cao",
      "Lei Yuan",
      "Jianhao Wang",
      "Shaowei Zhang",
      "Chongjie Zhang",
      "Yang Yu",
      "De-Chuan Zhan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2109.12508"
  },
  {
    "id": "arXiv:2109.13077",
    "title": "A human factors approach to validating driver models for  interaction-aware automated vehicles",
    "abstract": "Comments: Accepted for publication in Transactions on Human-Robot Interaction. In press",
    "descriptor": "\nComments: Accepted for publication in Transactions on Human-Robot Interaction. In press\n",
    "authors": [
      "Olger Siebinga",
      "Arkady Zgonnikov",
      "David Abbink"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.13077"
  },
  {
    "id": "arXiv:2110.00304",
    "title": "Divergence-Regularized Multi-Agent Actor-Critic",
    "abstract": "Comments: ICML 2022, 24 pages, 10 figures",
    "descriptor": "\nComments: ICML 2022, 24 pages, 10 figures\n",
    "authors": [
      "Kefan Su",
      "Zongqing Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.00304"
  },
  {
    "id": "arXiv:2110.02861",
    "title": "8-bit Optimizers via Block-wise Quantization",
    "abstract": "Comments: ICLR2022 spotlight version",
    "descriptor": "\nComments: ICLR2022 spotlight version\n",
    "authors": [
      "Tim Dettmers",
      "Mike Lewis",
      "Sam Shleifer",
      "Luke Zettlemoyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02861"
  },
  {
    "id": "arXiv:2110.03611",
    "title": "Adversarial Retriever-Ranker for dense text retrieval",
    "abstract": "Comments: ICLR 2022",
    "descriptor": "\nComments: ICLR 2022\n",
    "authors": [
      "Hang Zhang",
      "Yeyun Gong",
      "Yelong Shen",
      "Jiancheng Lv",
      "Nan Duan",
      "Weizhu Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.03611"
  },
  {
    "id": "arXiv:2110.04187",
    "title": "SCaLa: Supervised Contrastive Learning for End-to-End Speech Recognition",
    "abstract": "Comments: INTERSPEECH 2022",
    "descriptor": "\nComments: INTERSPEECH 2022\n",
    "authors": [
      "Li Fu",
      "Xiaoxiao Li",
      "Runyu Wang",
      "Lu Fan",
      "Zhengchen Zhang",
      "Meng Chen",
      "Youzheng Wu",
      "Xiaodong He"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.04187"
  },
  {
    "id": "arXiv:2110.05365",
    "title": "Intriguing Properties of Input-dependent Randomized Smoothing",
    "abstract": "Intriguing Properties of Input-dependent Randomized Smoothing",
    "descriptor": "",
    "authors": [
      "Peter S\u00faken\u00edk",
      "Aleksei Kuvshinov",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.05365"
  },
  {
    "id": "arXiv:2110.05721",
    "title": "Action-Sufficient State Representation Learning for Control with  Structural Constraints",
    "abstract": "Action-Sufficient State Representation Learning for Control with  Structural Constraints",
    "descriptor": "",
    "authors": [
      "Biwei Huang",
      "Chaochao Lu",
      "Liu Leqi",
      "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato",
      "Clark Glymour",
      "Bernhard Sch\u00f6lkopf",
      "Kun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05721"
  },
  {
    "id": "arXiv:2110.06212",
    "title": "Global Convergence of Triangularized Orthogonalization-free Method",
    "abstract": "Global Convergence of Triangularized Orthogonalization-free Method",
    "descriptor": "",
    "authors": [
      "Weiguo Gao",
      "Yingzhou Li",
      "Bichen Lu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.06212"
  },
  {
    "id": "arXiv:2110.06283",
    "title": "Detecting Corrupted Labels Without Training a Model to Predict",
    "abstract": "Comments: ICML 2022",
    "descriptor": "\nComments: ICML 2022\n",
    "authors": [
      "Zhaowei Zhu",
      "Zihao Dong",
      "Yang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06283"
  },
  {
    "id": "arXiv:2110.06460",
    "title": "Data-Time Tradeoffs for Optimal k-Thresholding Algorithms in Compressed  Sensing",
    "abstract": "Comments: 13 pages, 2 figures, accepted by IEEE ISIT 2022",
    "descriptor": "\nComments: 13 pages, 2 figures, accepted by IEEE ISIT 2022\n",
    "authors": [
      "Jialiang Xu",
      "Xu Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.06460"
  },
  {
    "id": "arXiv:2110.06765",
    "title": "libdlr: Efficient imaginary time calculations using the discrete Lehmann  representation",
    "abstract": "libdlr: Efficient imaginary time calculations using the discrete Lehmann  representation",
    "descriptor": "",
    "authors": [
      "Jason Kaye",
      "Kun Chen",
      "Hugo U. R. Strand"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Strongly Correlated Electrons (cond-mat.str-el)",
      "Mathematical Software (cs.MS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.06765"
  },
  {
    "id": "arXiv:2110.07631",
    "title": "More Efficient Sampling for Tensor Decomposition With Worst-Case  Guarantees",
    "abstract": "Comments: Accepted to ICML 2022",
    "descriptor": "\nComments: Accepted to ICML 2022\n",
    "authors": [
      "Osman Asif Malik"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.07631"
  },
  {
    "id": "arXiv:2110.08436",
    "title": "Reactive Task Allocation and Planning for Quadrupedal and Wheeled Robot  Teaming",
    "abstract": "Reactive Task Allocation and Planning for Quadrupedal and Wheeled Robot  Teaming",
    "descriptor": "",
    "authors": [
      "Ziyi Zhou",
      "Dong Jae Lee",
      "Yuki Yoshinaga",
      "Stephen Balakirsky",
      "Dejun Guo",
      "Ye Zhao"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.08436"
  },
  {
    "id": "arXiv:2110.08616",
    "title": "GradSign: Model Performance Inference with Theoretical Insights",
    "abstract": "GradSign: Model Performance Inference with Theoretical Insights",
    "descriptor": "",
    "authors": [
      "Zhihao Zhang",
      "Zhihao Jia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08616"
  },
  {
    "id": "arXiv:2110.09150",
    "title": "Tackling the Score Shift in Cross-Lingual Speaker Verification by  Exploiting Language Information",
    "abstract": "Comments: proceedings of ICASSP 2022",
    "descriptor": "\nComments: proceedings of ICASSP 2022\n",
    "authors": [
      "Jenthe Thienpondt",
      "Brecht Desplanques",
      "Kris Demuynck"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.09150"
  },
  {
    "id": "arXiv:2110.09160",
    "title": "DE-RSTC: A rational secure two-party computation protocol based on  direction entropy",
    "abstract": "DE-RSTC: A rational secure two-party computation protocol based on  direction entropy",
    "descriptor": "",
    "authors": [
      "Yuling Chen",
      "Juan Ma",
      "Xianmin Wang",
      "Xinyu Zhang",
      "Huiyu Zhou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.09160"
  },
  {
    "id": "arXiv:2110.09893",
    "title": "Visualizing Collective Idea Generation and Innovation Processes in  Social Networks",
    "abstract": "Comments: in press",
    "descriptor": "\nComments: in press\n",
    "authors": [
      "Yiding Cao",
      "Yingjun Dong",
      "Minjun Kim",
      "Neil G. MacLaren",
      "Sriniwas Pandey",
      "Shelley D. Dionne",
      "Francis J. Yammarino",
      "Hiroki Sayama"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.09893"
  },
  {
    "id": "arXiv:2110.11442",
    "title": "Towards Noise-adaptive, Problem-adaptive (Accelerated) Stochastic  Gradient Descent",
    "abstract": "Comments: ICML 2022",
    "descriptor": "\nComments: ICML 2022\n",
    "authors": [
      "Sharan Vaswani",
      "Benjamin Dubois-Taine",
      "Reza Babanezhad"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.11442"
  },
  {
    "id": "arXiv:2110.11854",
    "title": "Using scientific machine learning for experimental bifurcation analysis  of dynamic systems",
    "abstract": "Comments: Submitted to Mechanical Systems and Singal Processing",
    "descriptor": "\nComments: Submitted to Mechanical Systems and Singal Processing\n",
    "authors": [
      "Sandor Beregi",
      "David A. W. Barton",
      "Djamel Rezgui",
      "Simon A. Neild"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11854"
  },
  {
    "id": "arXiv:2110.13491",
    "title": "Continuous data assimilation for two-phase flow: analysis and  simulations",
    "abstract": "Continuous data assimilation for two-phase flow: analysis and  simulations",
    "descriptor": "",
    "authors": [
      "Yat Tin Chow",
      "Wing Tat Leung",
      "Ali Pakzad"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.13491"
  },
  {
    "id": "arXiv:2110.14007",
    "title": "TOD: GPU-accelerated Outlier Detection via Tensor Operations",
    "abstract": "Comments: Code available at this https URL",
    "descriptor": "\nComments: Code available at this https URL\n",
    "authors": [
      "Yue Zhao",
      "George H. Chen",
      "Zhihao Jia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2110.14007"
  },
  {
    "id": "arXiv:2110.14419",
    "title": "Toward a Theory of Justice for Artificial Intelligence",
    "abstract": "Comments: 12 pages",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Iason Gabriel"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.14419"
  },
  {
    "id": "arXiv:2110.14626",
    "title": "Scalable Bayesian Network Structure Learning with Splines",
    "abstract": "Scalable Bayesian Network Structure Learning with Splines",
    "descriptor": "",
    "authors": [
      "Charupriya Sharma",
      "Peter van Beek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.14626"
  },
  {
    "id": "arXiv:2110.15278",
    "title": "Self-supervised EEG Representation Learning for Automatic Sleep Staging",
    "abstract": "Comments: Preprocessing and Code in Github: this https URL, additional loss analysis can be found: this https URL",
    "descriptor": "\nComments: Preprocessing and Code in Github: this https URL, additional loss analysis can be found: this https URL\n",
    "authors": [
      "Chaoqi Yang",
      "Danica Xiao",
      "M. Brandon Westover",
      "Jimeng Sun"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15278"
  },
  {
    "id": "arXiv:2111.00507",
    "title": "Introduction to probabilistic concurrent systems",
    "abstract": "Comments: Extended version of the Petri Net 2021 conference paper arXiv:2008.07233 \"Deterministic concurrent systems\" by the same author. 33 pages, 9 figures, 17 references",
    "descriptor": "\nComments: Extended version of the Petri Net 2021 conference paper arXiv:2008.07233 \"Deterministic concurrent systems\" by the same author. 33 pages, 9 figures, 17 references\n",
    "authors": [
      "Samy Abbes"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2111.00507"
  },
  {
    "id": "arXiv:2111.01348",
    "title": "Faster Algorithms for Learning Convex Functions",
    "abstract": "Comments: 21 pages, 3 figures. Proceedings of the 39 th International Conference on Machine Learning, Baltimore, Maryland, USA, PMLR 162, 2022. Copy- right 2022 by the author(s)",
    "descriptor": "\nComments: 21 pages, 3 figures. Proceedings of the 39 th International Conference on Machine Learning, Baltimore, Maryland, USA, PMLR 162, 2022. Copy- right 2022 by the author(s)\n",
    "authors": [
      "Ali Siahkamari",
      "Durmus Alp Emre Acar",
      "Christopher Liao",
      "Kelly Geyer",
      "Venkatesh Saligrama",
      "Brian Kulis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01348"
  },
  {
    "id": "arXiv:2111.01356",
    "title": "DeepParticle: learning invariant measure by a deep neural network  minimizing Wasserstein distance on data generated from an interacting  particle method",
    "abstract": "DeepParticle: learning invariant measure by a deep neural network  minimizing Wasserstein distance on data generated from an interacting  particle method",
    "descriptor": "",
    "authors": [
      "Zhongjian Wang",
      "Jack Xin",
      "Zhiwen Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.01356"
  },
  {
    "id": "arXiv:2111.01470",
    "title": "Practical error bounds for properties in plane-wave electronic structure  calculations",
    "abstract": "Practical error bounds for properties in plane-wave electronic structure  calculations",
    "descriptor": "",
    "authors": [
      "Eric Canc\u00e8s",
      "Genevi\u00e8ve Dusson",
      "Gaspard Kemlin",
      "Antoine Levitt"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Materials Science (cond-mat.mtrl-sci)"
    ],
    "url": "https://arxiv.org/abs/2111.01470"
  },
  {
    "id": "arXiv:2111.01717",
    "title": "MixFace: Improving Face Verification Focusing on Fine-grained Conditions",
    "abstract": "Comments: 9 pages, 6 figures",
    "descriptor": "\nComments: 9 pages, 6 figures\n",
    "authors": [
      "Junuk Jung",
      "Sungbin Son",
      "Joochan Park",
      "Yongjun Park",
      "Seonhoon Lee",
      "Heung-Seon Oh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.01717"
  },
  {
    "id": "arXiv:2111.02541",
    "title": "Asymptotic-Preserving Neural Networks for Multiscale Time-Dependent  Linear Transport Equations",
    "abstract": "Asymptotic-Preserving Neural Networks for Multiscale Time-Dependent  Linear Transport Equations",
    "descriptor": "",
    "authors": [
      "Shi Jin",
      "Zheng Ma",
      "Keke Wu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.02541"
  },
  {
    "id": "arXiv:2111.02674",
    "title": "Voice Conversion Can Improve ASR in Very Low-Resource Settings",
    "abstract": "Comments: 5 page, 4 tables, 2 figures. Accepted at Interspeech 2022",
    "descriptor": "\nComments: 5 page, 4 tables, 2 figures. Accepted at Interspeech 2022\n",
    "authors": [
      "Matthew Baas",
      "Herman Kamper"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2111.02674"
  },
  {
    "id": "arXiv:2111.04040",
    "title": "Meta-TTS: Meta-Learning for Few-Shot Speaker Adaptive Text-to-Speech",
    "abstract": "Comments: IEEE/ACM Transactions on Audio, Speech, and Language Processing",
    "descriptor": "\nComments: IEEE/ACM Transactions on Audio, Speech, and Language Processing\n",
    "authors": [
      "Sung-Feng Huang",
      "Chyi-Jiunn Lin",
      "Da-Rong Liu",
      "Yi-Chen Chen",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.04040"
  },
  {
    "id": "arXiv:2111.08872",
    "title": "TorchGeo: Deep Learning With Geospatial Data",
    "abstract": "TorchGeo: Deep Learning With Geospatial Data",
    "descriptor": "",
    "authors": [
      "Adam J. Stewart",
      "Caleb Robinson",
      "Isaac A. Corley",
      "Anthony Ortiz",
      "Juan M. Lavista Ferres",
      "Arindam Banerjee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08872"
  },
  {
    "id": "arXiv:2111.09382",
    "title": "Combining Trajectory Data with Analytical Lyapunov Functions for  Improved Region of Attraction Estimation",
    "abstract": "Comments: 6 pages, 4 figures",
    "descriptor": "\nComments: 6 pages, 4 figures\n",
    "authors": [
      "Lucas Lugnani",
      "Morgan Jones",
      "Lu\u00eds F. C. Alberto",
      "Mathew Peet",
      "Daniel Dotta"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.09382"
  },
  {
    "id": "arXiv:2111.10079",
    "title": "Evaluating Self and Semi-Supervised Methods for Remote Sensing  Segmentation Tasks",
    "abstract": "Evaluating Self and Semi-Supervised Methods for Remote Sensing  Segmentation Tasks",
    "descriptor": "",
    "authors": [
      "Chaitanya Patel",
      "Shashank Sharma",
      "Valerie J. Pasquarella",
      "Varun Gulshan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.10079"
  },
  {
    "id": "arXiv:2111.11044",
    "title": "Exploring Segment-level Semantics for Online Phase Recognition from  Surgical Videos",
    "abstract": "Comments: Appear in IEEE TMI",
    "descriptor": "\nComments: Appear in IEEE TMI\n",
    "authors": [
      "Xinpeng Ding",
      "Xiaomeng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.11044"
  },
  {
    "id": "arXiv:2111.12278",
    "title": "An efficient estimation of nested expectations without conditional  sampling",
    "abstract": "An efficient estimation of nested expectations without conditional  sampling",
    "descriptor": "",
    "authors": [
      "Tomohiko Hironaka",
      "Takashi Goda"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.12278"
  },
  {
    "id": "arXiv:2111.12958",
    "title": "Self-Distilled Self-Supervised Representation Learning",
    "abstract": "Comments: 15 pages",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Jiho Jang",
      "Seonhoon Kim",
      "Kiyoon Yoo",
      "Jangho Kim",
      "Nojun Kwak"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12958"
  },
  {
    "id": "arXiv:2111.13196",
    "title": "SwinBERT: End-to-End Transformers with Sparse Attention for Video  Captioning",
    "abstract": "Comments: CVPR 2022",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Kevin Lin",
      "Linjie Li",
      "Chung-Ching Lin",
      "Faisal Ahmed",
      "Zhe Gan",
      "Zicheng Liu",
      "Yumao Lu",
      "Lijuan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.13196"
  },
  {
    "id": "arXiv:2111.15143",
    "title": "HEAT: Holistic Edge Attention Transformer for Structured Reconstruction",
    "abstract": "Comments: CVPR 2022 camera-ready",
    "descriptor": "\nComments: CVPR 2022 camera-ready\n",
    "authors": [
      "Jiacheng Chen",
      "Yiming Qian",
      "Yasutaka Furukawa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15143"
  },
  {
    "id": "arXiv:2111.15361",
    "title": "Seeking Salient Facial Regions for Cross-Database Micro-Expression  Recognition",
    "abstract": "Seeking Salient Facial Regions for Cross-Database Micro-Expression  Recognition",
    "descriptor": "",
    "authors": [
      "Xingxun Jiang",
      "Yuan Zong",
      "Wenming Zheng",
      "Jiateng Liu",
      "Mengting Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.15361"
  },
  {
    "id": "arXiv:2112.00248",
    "title": "Simulation platform for pattern recognition based on reservoir computing  with memristor networks",
    "abstract": "Comments: 14 pages, 7 figures, 5 supplementary figures",
    "descriptor": "\nComments: 14 pages, 7 figures, 5 supplementary figures\n",
    "authors": [
      "Gouhei Tanaka",
      "Ryosho Nakane"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2112.00248"
  },
  {
    "id": "arXiv:2112.00791",
    "title": "Controlling Conditional Language Models without Catastrophic Forgetting",
    "abstract": "Comments: ICML 2022",
    "descriptor": "\nComments: ICML 2022\n",
    "authors": [
      "Tomasz Korbak",
      "Hady Elsahar",
      "German Kruszewski",
      "Marc Dymetman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.00791"
  },
  {
    "id": "arXiv:2112.00888",
    "title": "The (1+1)-ES Reliably Overcomes Saddle Points",
    "abstract": "The (1+1)-ES Reliably Overcomes Saddle Points",
    "descriptor": "",
    "authors": [
      "Tobias Glasmachers"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2112.00888"
  },
  {
    "id": "arXiv:2112.00999",
    "title": "Contrastive Cross-domain Recommendation in Matching",
    "abstract": "Comments: 11 pages, accepted by KDD-2022",
    "descriptor": "\nComments: 11 pages, accepted by KDD-2022\n",
    "authors": [
      "Ruobing Xie",
      "Qi Liu",
      "Liangdong Wang",
      "Shukai Liu",
      "Bo Zhang",
      "Leyu Lin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.00999"
  },
  {
    "id": "arXiv:2112.01857",
    "title": "Disentangling modes with crossover instantaneous frequencies by  synchrosqueezed chirplet transforms, from theory to application",
    "abstract": "Comments: Fixed typos and added Remark 2",
    "descriptor": "\nComments: Fixed typos and added Remark 2\n",
    "authors": [
      "Ziyu Chen",
      "Hau-Tieng Wu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.01857"
  },
  {
    "id": "arXiv:2112.02976",
    "title": "Lecture Notes on Partially Known MDPs",
    "abstract": "Lecture Notes on Partially Known MDPs",
    "descriptor": "",
    "authors": [
      "Guillermo A. Perez"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2112.02976"
  },
  {
    "id": "arXiv:2112.03432",
    "title": "First-Order Regret in Reinforcement Learning with Linear Function  Approximation: A Robust Estimation Approach",
    "abstract": "First-Order Regret in Reinforcement Learning with Linear Function  Approximation: A Robust Estimation Approach",
    "descriptor": "",
    "authors": [
      "Andrew Wagenmaker",
      "Yifang Chen",
      "Max Simchowitz",
      "Simon S. Du",
      "Kevin Jamieson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.03432"
  },
  {
    "id": "arXiv:2112.03547",
    "title": "Self-Organized Polynomial-Time Coordination Graphs",
    "abstract": "Self-Organized Polynomial-Time Coordination Graphs",
    "descriptor": "",
    "authors": [
      "Qianlan Yang",
      "Weijun Dong",
      "Zhizhou Ren",
      "Jianhao Wang",
      "Tonghan Wang",
      "Chongjie Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2112.03547"
  },
  {
    "id": "arXiv:2112.05477",
    "title": "Modelling DDoS Attacks in IoT Networks using Machine Learning",
    "abstract": "Comments: 20 pages, 13 figures, 5 tables",
    "descriptor": "\nComments: 20 pages, 13 figures, 5 tables\n",
    "authors": [
      "Pheeha Machaka",
      "Olasupo Ajayi",
      "Hloniphani Maluleke",
      "Ferdinand Kahenga",
      "Antoine Bagula",
      "Kyandoghere Kyamakya"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.05477"
  },
  {
    "id": "arXiv:2112.05640",
    "title": "Fast and scalable neuroevolution deep learning architecture search for  multivariate anomaly detection",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2108.03585",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2108.03585\n",
    "authors": [
      "M.Pietro\u0144",
      "D.\u017burek",
      "K.Faber"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.05640"
  },
  {
    "id": "arXiv:2112.07160",
    "title": "A New Perspective on the Effects of Spectrum in Graph Neural Networks",
    "abstract": "A New Perspective on the Effects of Spectrum in Graph Neural Networks",
    "descriptor": "",
    "authors": [
      "Mingqi Yang",
      "Yanming Shen",
      "Rui Li",
      "Heng Qi",
      "Qiang Zhang",
      "Baocai Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.07160"
  },
  {
    "id": "arXiv:2112.07225",
    "title": "Margin Calibration for Long-Tailed Visual Recognition",
    "abstract": "Comments: Technical report; 17 pages",
    "descriptor": "\nComments: Technical report; 17 pages\n",
    "authors": [
      "Yidong Wang",
      "Bowen Zhang",
      "Wenxin Hou",
      "Zhen Wu",
      "Jindong Wang",
      "Takahiro Shinozaki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07225"
  },
  {
    "id": "arXiv:2112.07620",
    "title": "Tree-based Focused Web Crawling with Reinforcement Learning",
    "abstract": "Tree-based Focused Web Crawling with Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Andreas Kontogiannis",
      "Dimitrios Kelesis",
      "Vasilis Pollatos",
      "Georgios Paliouras",
      "George Giannakopoulos"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07620"
  },
  {
    "id": "arXiv:2112.08581",
    "title": "A First Mathematical Runtime Analysis of the Non-Dominated Sorting  Genetic Algorithm II (NSGA-II)",
    "abstract": "Comments: Self-archiving version of one paper accepted in AAAI 2022",
    "descriptor": "\nComments: Self-archiving version of one paper accepted in AAAI 2022\n",
    "authors": [
      "Weijie Zheng",
      "Yufei Liu",
      "Benjamin Doerr"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08581"
  },
  {
    "id": "arXiv:2112.08702",
    "title": "Learning to Share in Multi-Agent Reinforcement Learning",
    "abstract": "Comments: ICLR 2022 Workshop on Gamification and Multiagent Solutions, Best Cooperative AI Paper Award",
    "descriptor": "\nComments: ICLR 2022 Workshop on Gamification and Multiagent Solutions, Best Cooperative AI Paper Award\n",
    "authors": [
      "Yuxuan Yi",
      "Ge Li",
      "Yaowei Wang",
      "Zongqing Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2112.08702"
  },
  {
    "id": "arXiv:2112.08810",
    "title": "Pure Noise to the Rescue of Insufficient Data: Improving Imbalanced  Classification by Training on Random Noise Images",
    "abstract": "Pure Noise to the Rescue of Insufficient Data: Improving Imbalanced  Classification by Training on Random Noise Images",
    "descriptor": "",
    "authors": [
      "Shiran Zada",
      "Itay Benou",
      "Michal Irani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.08810"
  },
  {
    "id": "arXiv:2112.09754",
    "title": "Discrete Probabilistic Inverse Optimal Transport",
    "abstract": "Comments: ICML 2022",
    "descriptor": "\nComments: ICML 2022\n",
    "authors": [
      "Wei-Ting Chiu",
      "Pei Wang",
      "Patrick Shafto"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.09754"
  },
  {
    "id": "arXiv:2112.09763",
    "title": "News-sharing on Twitter reveals emergent fragmentation of media agenda  and persistent polarization",
    "abstract": "News-sharing on Twitter reveals emergent fragmentation of media agenda  and persistent polarization",
    "descriptor": "",
    "authors": [
      "Tomas Cicchini",
      "Sofia Morena del Pozo",
      "Enzo Tagliazucchi",
      "Pablo Balenzuela"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.09763"
  },
  {
    "id": "arXiv:2112.10598",
    "title": "A Closed-Form Bound on the Asymptotic Linear Convergence of Iterative  Methods via Fixed Point Analysis",
    "abstract": "Comments: 14 pages - final version accepted to OPTL22",
    "descriptor": "\nComments: 14 pages - final version accepted to OPTL22\n",
    "authors": [
      "Trung Vu",
      "Raviv Raich"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.10598"
  },
  {
    "id": "arXiv:2112.11760",
    "title": "On Asymptotic Linear Convergence of Projected Gradient Descent for  Constrained Least Squares",
    "abstract": "Comments: 21 pages including Supplementary Material",
    "descriptor": "\nComments: 21 pages including Supplementary Material\n",
    "authors": [
      "Trung Vu",
      "Raviv Raich"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.11760"
  },
  {
    "id": "arXiv:2112.11941",
    "title": "CRASS: A Novel Data Set and Benchmark to Test Counterfactual Reasoning  of Large Language Models",
    "abstract": "Comments: 10 pages including references, plus 5 pages appendix",
    "descriptor": "\nComments: 10 pages including references, plus 5 pages appendix\n",
    "authors": [
      "J\u00f6rg Frohberg",
      "Frank Binder"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.11941"
  },
  {
    "id": "arXiv:2112.12327",
    "title": "Making sense of electrical vehicle discussions using sentiment analysis  on closely related news and user comments",
    "abstract": "Making sense of electrical vehicle discussions using sentiment analysis  on closely related news and user comments",
    "descriptor": "",
    "authors": [
      "Xuan Jiang",
      "Josh Everts"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.12327"
  },
  {
    "id": "arXiv:2112.12331",
    "title": "Flakify: A Black-Box, Language Model-based Predictor for Flaky Tests",
    "abstract": "Flakify: A Black-Box, Language Model-based Predictor for Flaky Tests",
    "descriptor": "",
    "authors": [
      "Sakina Fatima",
      "Taher A. Ghaleb",
      "Lionel Briand"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2112.12331"
  },
  {
    "id": "arXiv:2112.12530",
    "title": "Long-Term Optimal Delivery Planning for Replacing the Liquefied  Petroleum Gas Cylinder",
    "abstract": "Comments: 25 pages",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Akihiro Yoshida",
      "Haruki Sato",
      "Shiori Uchiumi",
      "Nariaki Tateiwa",
      "Daisuke Kataoka",
      "Akira Tanaka",
      "Nozomi Hata",
      "Yousuke Yatsushiro",
      "Ayano Ide",
      "Hiroki Ishikura",
      "Shingo Egi",
      "Miyu Fujii",
      "Hiroki Kai",
      "Katsuki Fujisawa"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2112.12530"
  },
  {
    "id": "arXiv:2112.12591",
    "title": "Black-Box Testing of Deep Neural Networks through Test Case Diversity",
    "abstract": "Black-Box Testing of Deep Neural Networks through Test Case Diversity",
    "descriptor": "",
    "authors": [
      "Zohreh Aghababaeyan",
      "Manel Abdellatif",
      "Lionel Briand",
      "Ramesh S",
      "Mojtaba Bagherzadeh"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12591"
  },
  {
    "id": "arXiv:2112.12808",
    "title": "MISO hierarchical inference engine with fuzzy implication satisfying  I(A(x, y), z) = I(x, I(y, z))",
    "abstract": "MISO hierarchical inference engine with fuzzy implication satisfying  I(A(x, y), z) = I(x, I(y, z))",
    "descriptor": "",
    "authors": [
      "Dechao Li",
      "Qiannan Guo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2112.12808"
  },
  {
    "id": "arXiv:2112.14232",
    "title": "Constrained Gradient Descent: A Powerful and Principled Evasion Attack  Against Neural Networks",
    "abstract": "Constrained Gradient Descent: A Powerful and Principled Evasion Attack  Against Neural Networks",
    "descriptor": "",
    "authors": [
      "Weiran Lin",
      "Keane Lucas",
      "Lujo Bauer",
      "Michael K. Reiter",
      "Mahmood Sharif"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.14232"
  },
  {
    "id": "arXiv:2201.00182",
    "title": "On the representativeness of approximate solutions of discrete  optimization problems with interval objective function",
    "abstract": "Comments: 15 pages (24 pages with the Appendix), 1 figure",
    "descriptor": "\nComments: 15 pages (24 pages with the Appendix), 1 figure\n",
    "authors": [
      "Alexander Prolubnikov"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2201.00182"
  },
  {
    "id": "arXiv:2201.00299",
    "title": "Improving Out-of-Distribution Robustness via Selective Augmentation",
    "abstract": "Comments: Accepted by ICML 2022",
    "descriptor": "\nComments: Accepted by ICML 2022\n",
    "authors": [
      "Huaxiu Yao",
      "Yu Wang",
      "Sai Li",
      "Linjun Zhang",
      "Weixin Liang",
      "James Zou",
      "Chelsea Finn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.00299"
  },
  {
    "id": "arXiv:2201.01439",
    "title": "Construction of extremal Type II $\\mathbb{Z}_{2k}$-codes",
    "abstract": "Comments: 25 pages",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Masaaki Harada"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2201.01439"
  },
  {
    "id": "arXiv:2201.02135",
    "title": "Deep Reinforcement Learning, a textbook",
    "abstract": "Deep Reinforcement Learning, a textbook",
    "descriptor": "",
    "authors": [
      "Aske Plaat"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.02135"
  },
  {
    "id": "arXiv:2201.02609",
    "title": "Generalized Category Discovery",
    "abstract": "Comments: CVPR 22. Changes from pre-print highlighted in GitHub repo",
    "descriptor": "\nComments: CVPR 22. Changes from pre-print highlighted in GitHub repo\n",
    "authors": [
      "Sagar Vaze",
      "Kai Han",
      "Andrea Vedaldi",
      "Andrew Zisserman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.02609"
  },
  {
    "id": "arXiv:2201.03327",
    "title": "TiltedBERT: Resource Adjustable Version of BERT",
    "abstract": "TiltedBERT: Resource Adjustable Version of BERT",
    "descriptor": "",
    "authors": [
      "Sajjad Kachuee",
      "Mohammad Sharifkhani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.03327"
  },
  {
    "id": "arXiv:2201.04351",
    "title": "Diffix Elm: Simple Diffix",
    "abstract": "Diffix Elm: Simple Diffix",
    "descriptor": "",
    "authors": [
      "Paul Francis",
      "Sebastian Probst-Eide",
      "David Wagner",
      "Felix Bauer",
      "Cristian Berneanu",
      "Edon Gashi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2201.04351"
  },
  {
    "id": "arXiv:2201.05654",
    "title": "The Parameterized Complexity of s-Club with Triangle and Seed  Constraints",
    "abstract": "The Parameterized Complexity of s-Club with Triangle and Seed  Constraints",
    "descriptor": "",
    "authors": [
      "Jaroslav Garvardt",
      "Christian Komusiewicz",
      "Frank Sommer"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2201.05654"
  },
  {
    "id": "arXiv:2201.06444",
    "title": "Black-box error diagnosis in deep neural networks for computer vision: a  survey of tools",
    "abstract": "Comments: Submitted to Springer Neural Computing and Applications",
    "descriptor": "\nComments: Submitted to Springer Neural Computing and Applications\n",
    "authors": [
      "Piero Fraternali",
      "Federico Milani",
      "Rocio Nahime Torres",
      "Niccol\u00f2 Zangrando"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2201.06444"
  },
  {
    "id": "arXiv:2201.06564",
    "title": "Sharing Begins at Home",
    "abstract": "Sharing Begins at Home",
    "descriptor": "",
    "authors": [
      "William Dempsey",
      "Ian Foster",
      "Scott Fraser",
      "Carl Kesselman"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2201.06564"
  },
  {
    "id": "arXiv:2201.06674",
    "title": "TYPIC: A Corpus of Template-Based Diagnostic Comments on Argumentation",
    "abstract": "Comments: LREC2022. The dataset is available at this https URL",
    "descriptor": "\nComments: LREC2022. The dataset is available at this https URL\n",
    "authors": [
      "Shoichi Naito",
      "Shintaro Sawada",
      "Chihiro Nakagawa",
      "Naoya Inoue",
      "Kenshi Yamaguchi",
      "Iori Shimizu",
      "Farjana Sultana Mim",
      "Keshav Singh",
      "Kentaro Inui"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.06674"
  },
  {
    "id": "arXiv:2201.07749",
    "title": "Summarising and Comparing Agent Dynamics with Contrastive Spatiotemporal  Abstraction",
    "abstract": "Comments: 13 pages (6 body, 1 references, 6 appendix). Accepted for presentation at XAI-IJCAI22 Workshop, July 2022",
    "descriptor": "\nComments: 13 pages (6 body, 1 references, 6 appendix). Accepted for presentation at XAI-IJCAI22 Workshop, July 2022\n",
    "authors": [
      "Tom Bewley",
      "Jonathan Lawry",
      "Arthur Richards"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.07749"
  },
  {
    "id": "arXiv:2201.08233",
    "title": "Encoding large information structures in linear algebra and statistical  models",
    "abstract": "Encoding large information structures in linear algebra and statistical  models",
    "descriptor": "",
    "authors": [
      "David Banh",
      "Alan Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08233"
  },
  {
    "id": "arXiv:2201.08277",
    "title": "NaijaSenti: A Nigerian Twitter Sentiment Corpus for Multilingual  Sentiment Analysis",
    "abstract": "Comments: Submitted to LREC 2022, 13 pages, 2 figures",
    "descriptor": "\nComments: Submitted to LREC 2022, 13 pages, 2 figures\n",
    "authors": [
      "Shamsuddeen Hassan Muhammad",
      "David Ifeoluwa Adelani",
      "Sebastian Ruder",
      "Ibrahim Said Ahmad",
      "Idris Abdulmumin",
      "Bello Shehu Bello",
      "Monojit Choudhury",
      "Chris Chinenye Emezue",
      "Saheed Salahudeen Abdullahi",
      "Anuoluwapo Aremu",
      "Alipio Jeorge",
      "Pavel Brazdil"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.08277"
  },
  {
    "id": "arXiv:2201.09486",
    "title": "Bias in Automated Speaker Recognition",
    "abstract": "Bias in Automated Speaker Recognition",
    "descriptor": "",
    "authors": [
      "Wiebke Toussaint Hutiri",
      "Aaron Ding"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2201.09486"
  },
  {
    "id": "arXiv:2201.09539",
    "title": "A Blockchain-Based Distributed Computational Resource Trading System for  Industrial Internet of Things Considering Multiple Preferences",
    "abstract": "A Blockchain-Based Distributed Computational Resource Trading System for  Industrial Internet of Things Considering Multiple Preferences",
    "descriptor": "",
    "authors": [
      "Tonghe Wang",
      "Songpu Ai",
      "Junwei Cao"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2201.09539"
  },
  {
    "id": "arXiv:2201.09815",
    "title": "Analytic Mutual Information in Bayesian Neural Networks",
    "abstract": "Analytic Mutual Information in Bayesian Neural Networks",
    "descriptor": "",
    "authors": [
      "Jae Oh Woo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.09815"
  },
  {
    "id": "arXiv:2201.11206",
    "title": "Reward-Free RL is No Harder Than Reward-Aware RL in Linear Markov  Decision Processes",
    "abstract": "Reward-Free RL is No Harder Than Reward-Aware RL in Linear Markov  Decision Processes",
    "descriptor": "",
    "authors": [
      "Andrew Wagenmaker",
      "Yifang Chen",
      "Max Simchowitz",
      "Simon S. Du",
      "Kevin Jamieson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.11206"
  },
  {
    "id": "arXiv:2201.11729",
    "title": "Implicit Regularization in Hierarchical Tensor Factorization and Deep  Convolutional Neural Networks",
    "abstract": "Comments: Accepted to ICML 2022",
    "descriptor": "\nComments: Accepted to ICML 2022\n",
    "authors": [
      "Noam Razin",
      "Asaf Maman",
      "Nadav Cohen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.11729"
  },
  {
    "id": "arXiv:2201.12083",
    "title": "DynaMixer: A Vision MLP Architecture with Dynamic Mixing",
    "abstract": "Comments: icml2022",
    "descriptor": "\nComments: icml2022\n",
    "authors": [
      "Ziyu Wang",
      "Wenhao Jiang",
      "Yiming Zhu",
      "Li Yuan",
      "Yibing Song",
      "Wei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12083"
  },
  {
    "id": "arXiv:2201.12090",
    "title": "Approximate Bayesian Computation with Domain Expert in the Loop",
    "abstract": "Comments: Accepted for publication at ICML 2022. Code available at this https URL",
    "descriptor": "\nComments: Accepted for publication at ICML 2022. Code available at this https URL\n",
    "authors": [
      "Ayush Bharti",
      "Louis Filstroff",
      "Samuel Kaski"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12090"
  },
  {
    "id": "arXiv:2201.12091",
    "title": "Linear Adversarial Concept Erasure",
    "abstract": "Comments: Accepted in ICML 2022",
    "descriptor": "\nComments: Accepted in ICML 2022\n",
    "authors": [
      "Shauli Ravfogel",
      "Michael Twiton",
      "Yoav Goldberg",
      "Ryan Cotterell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.12091"
  },
  {
    "id": "arXiv:2201.12426",
    "title": "A Simple Guard for Learned Optimizers",
    "abstract": "Comments: 8 pages, 9 figures",
    "descriptor": "\nComments: 8 pages, 9 figures\n",
    "authors": [
      "Isabeau Pr\u00e9mont-Schwarz",
      "Jaroslav V\u00edtk\u016f",
      "Jan Feyereisl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2201.12426"
  },
  {
    "id": "arXiv:2201.12498",
    "title": "Investigating Why Contrastive Learning Benefits Robustness Against Label  Noise",
    "abstract": "Investigating Why Contrastive Learning Benefits Robustness Against Label  Noise",
    "descriptor": "",
    "authors": [
      "Yihao Xue",
      "Kyle Whitecross",
      "Baharan Mirzasoleiman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12498"
  },
  {
    "id": "arXiv:2201.12697",
    "title": "Why the Rich Get Richer? On the Balancedness of Random Partition Models",
    "abstract": "Comments: Accepted to 2022 International Conference on Machine Learning (ICML 2022)",
    "descriptor": "\nComments: Accepted to 2022 International Conference on Machine Learning (ICML 2022)\n",
    "authors": [
      "Changwoo J. Lee",
      "Huiyan Sang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2201.12697"
  },
  {
    "id": "arXiv:2201.12857",
    "title": "Fast Relative Entropy Coding with A* coding",
    "abstract": "Fast Relative Entropy Coding with A* coding",
    "descriptor": "",
    "authors": [
      "Gergely Flamich",
      "Stratis Markou",
      "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.12857"
  },
  {
    "id": "arXiv:2201.12990",
    "title": "Lightweight Projective Derivative Codes for Compressed Asynchronous  Gradient Descent",
    "abstract": "Comments: 15 pages, 3 figures, preprint, To appear in Proceedings of ICML 2022",
    "descriptor": "\nComments: 15 pages, 3 figures, preprint, To appear in Proceedings of ICML 2022\n",
    "authors": [
      "Pedro Soto",
      "Ilia Ilmer",
      "Haibin Guan",
      "Jun Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.12990"
  },
  {
    "id": "arXiv:2201.13256",
    "title": "Proximal Denoiser for Convergent Plug-and-Play Optimization with  Nonconvex Regularization",
    "abstract": "Comments: 21 pages. arXiv admin note: text overlap with arXiv:2110.03220",
    "descriptor": "\nComments: 21 pages. arXiv admin note: text overlap with arXiv:2110.03220\n",
    "authors": [
      "Samuel Hurault",
      "Arthur Leclaire",
      "Nicolas Papadakis"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.13256"
  },
  {
    "id": "arXiv:2201.13360",
    "title": "Hydra: A Real-time Spatial Perception System for 3D Scene Graph  Construction and Optimization",
    "abstract": "Comments: 13 pages, 10 figures, published in Robotics Science and Systems (RSS) 2022 proceedings",
    "descriptor": "\nComments: 13 pages, 10 figures, published in Robotics Science and Systems (RSS) 2022 proceedings\n",
    "authors": [
      "Nathan Hughes",
      "Yun Chang",
      "Luca Carlone"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2201.13360"
  },
  {
    "id": "arXiv:2202.00076",
    "title": "Optimal Estimation of Off-Policy Policy Gradient via Double Fitted  Iteration",
    "abstract": "Optimal Estimation of Off-Policy Policy Gradient via Double Fitted  Iteration",
    "descriptor": "",
    "authors": [
      "Chengzhuo Ni",
      "Ruiqi Zhang",
      "Xiang Ji",
      "Xuezhou Zhang",
      "Mengdi Wang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00076"
  },
  {
    "id": "arXiv:2202.00458",
    "title": "Machine learning to assess relatedness: the advantage of using  firm-level data",
    "abstract": "Comments: 14 pages, 4 figures",
    "descriptor": "\nComments: 14 pages, 4 figures\n",
    "authors": [
      "Giambattista Albora",
      "Andrea Zaccaria"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00458"
  },
  {
    "id": "arXiv:2202.00478",
    "title": "NeuraHealth: An Automated Screening Pipeline to Detect Undiagnosed  Cognitive Impairment in Electronic Health Records with Deep Learning and  Natural Language Processing",
    "abstract": "NeuraHealth: An Automated Screening Pipeline to Detect Undiagnosed  Cognitive Impairment in Electronic Health Records with Deep Learning and  Natural Language Processing",
    "descriptor": "",
    "authors": [
      "Tanish Tyagi",
      "Colin G. Magdamo",
      "Ayush Noori",
      "Zhaozhi Li",
      "Xiao Liu",
      "Mayuresh Deodhar",
      "Zhuoqiao Hong",
      "Wendong Ge",
      "Elissa M. Ye",
      "Yi-han Sheu",
      "Haitham Alabsi",
      "Laura Brenner",
      "Gregory K. Robbins",
      "Sahar Zafar",
      "Nicole Benson",
      "Lidia Moura",
      "John Hsu",
      "Alberto Serrano-Pozo",
      "Dimitry Prokopenko",
      "Rudolph E. Tanzi",
      "Bradley T.Hyman",
      "Deborah Blacker",
      "Shibani S. Mukerji",
      "M. Brandon Westover",
      "Sudeshna Das"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.00478"
  },
  {
    "id": "arXiv:2202.00580",
    "title": "Fishing for User Data in Large-Batch Federated Learning via Gradient  Magnification",
    "abstract": "Comments: First three authors contributed equally, order chosen randomly. 21 pages, 9 figures. Published at ICML 2022",
    "descriptor": "\nComments: First three authors contributed equally, order chosen randomly. 21 pages, 9 figures. Published at ICML 2022\n",
    "authors": [
      "Yuxin Wen",
      "Jonas Geiping",
      "Liam Fowl",
      "Micah Goldblum",
      "Tom Goldstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.00580"
  },
  {
    "id": "arXiv:2202.00720",
    "title": "Gradient Based Clustering",
    "abstract": "Comments: Added numerical experiments, fixed typos",
    "descriptor": "\nComments: Added numerical experiments, fixed typos\n",
    "authors": [
      "Aleksandar Armacki",
      "Dragana Bajovic",
      "Dusan Jakovetic",
      "Soummya Kar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.00720"
  },
  {
    "id": "arXiv:2202.00961",
    "title": "Modularity-Aware Graph Autoencoders for Joint Community Detection and  Link Prediction",
    "abstract": "Comments: Accepted for publication in Elsevier's Neural Networks journal in 2022",
    "descriptor": "\nComments: Accepted for publication in Elsevier's Neural Networks journal in 2022\n",
    "authors": [
      "Guillaume Salha-Galvan",
      "Johannes F. Lutzeyer",
      "George Dasoulas",
      "Romain Hennequin",
      "Michalis Vazirgiannis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.00961"
  },
  {
    "id": "arXiv:2202.01144",
    "title": "An Adiabatic Capacitive Artificial Neuron with RRAM-based Threshold  Detection for Energy-Efficient Neuromorphic Computing",
    "abstract": "Comments: This work has been accepted to the IEEE TCAS-I",
    "descriptor": "\nComments: This work has been accepted to the IEEE TCAS-I\n",
    "authors": [
      "Sachin Maheshwari",
      "Alexander Serb",
      "Christos Papavassiliou",
      "Themistoklis Prodromakis"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2202.01144"
  },
  {
    "id": "arXiv:2202.01181",
    "title": "Make Some Noise: Reliable and Efficient Single-Step Adversarial Training",
    "abstract": "Make Some Noise: Reliable and Efficient Single-Step Adversarial Training",
    "descriptor": "",
    "authors": [
      "Pau de Jorge",
      "Adel Bibi",
      "Riccardo Volpi",
      "Amartya Sanyal",
      "Philip H. S. Torr",
      "Gr\u00e9gory Rogez",
      "Puneet K. Dokania"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.01181"
  },
  {
    "id": "arXiv:2202.01273",
    "title": "Beyond Images: Label Noise Transition Matrix Estimation for Tasks with  Lower-Quality Features",
    "abstract": "Comments: ICML 2022",
    "descriptor": "\nComments: ICML 2022\n",
    "authors": [
      "Zhaowei Zhu",
      "Jialu Wang",
      "Yang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.01273"
  },
  {
    "id": "arXiv:2202.01381",
    "title": "ETSformer: Exponential Smoothing Transformers for Time-series  Forecasting",
    "abstract": "ETSformer: Exponential Smoothing Transformers for Time-series  Forecasting",
    "descriptor": "",
    "authors": [
      "Gerald Woo",
      "Chenghao Liu",
      "Doyen Sahoo",
      "Akshat Kumar",
      "Steven Hoi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01381"
  },
  {
    "id": "arXiv:2202.01503",
    "title": "Global sensitivity analysis based on Gaussian-process metamodelling for  complex biomechanical problems",
    "abstract": "Global sensitivity analysis based on Gaussian-process metamodelling for  complex biomechanical problems",
    "descriptor": "",
    "authors": [
      "Barbara Wirthl",
      "Sebastian Brandstaeter",
      "Jonas Nitzler",
      "Bernhard A. Schrefler",
      "Wolfgang A. Wall"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2202.01503"
  },
  {
    "id": "arXiv:2202.01753",
    "title": "m-CUBES An efficient and portable implementation of multi-dimensional  integration for gpus",
    "abstract": "m-CUBES An efficient and portable implementation of multi-dimensional  integration for gpus",
    "descriptor": "",
    "authors": [
      "Ioannis Sakiotis",
      "Kamesh Arumugam",
      "Marc Paterno",
      "Desh Ranjan",
      "Balsa Terzic",
      "Mohammad Zubair"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2202.01753"
  },
  {
    "id": "arXiv:2202.01889",
    "title": "Generalizing to New Physical Systems via Context-Informed Dynamics Model",
    "abstract": "Generalizing to New Physical Systems via Context-Informed Dynamics Model",
    "descriptor": "",
    "authors": [
      "Matthieu Kirchmeyer",
      "yuan yin",
      "J\u00e9r\u00e9mie Don\u00e0",
      "Nicolas Baskiotis",
      "Alain Rakotomamonjy",
      "Patrick Gallinari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.01889"
  },
  {
    "id": "arXiv:2202.02195",
    "title": "Deep End-to-end Causal Inference",
    "abstract": "Deep End-to-end Causal Inference",
    "descriptor": "",
    "authors": [
      "Tomas Geffner",
      "Javier Antoran",
      "Adam Foster",
      "Wenbo Gong",
      "Chao Ma",
      "Emre Kiciman",
      "Amit Sharma",
      "Angus Lamb",
      "Martin Kukla",
      "Nick Pawlowski",
      "Miltiadis Allamanis",
      "Cheng Zhang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02195"
  },
  {
    "id": "arXiv:2202.02433",
    "title": "Versatile Offline Imitation from Observations and Examples via  Regularized State-Occupancy Matching",
    "abstract": "Comments: ICML 2022. Project website: this https URL",
    "descriptor": "\nComments: ICML 2022. Project website: this https URL\n",
    "authors": [
      "Yecheng Jason Ma",
      "Andrew Shen",
      "Dinesh Jayaraman",
      "Osbert Bastani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02433"
  },
  {
    "id": "arXiv:2202.02750",
    "title": "Estimating the Euclidean quantum propagator with deep generative  modeling of Feynman paths",
    "abstract": "Comments: Published version; Updated references",
    "descriptor": "\nComments: Published version; Updated references\n",
    "authors": [
      "Yanming Che",
      "Clemens Gneiting",
      "Franco Nori"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2202.02750"
  },
  {
    "id": "arXiv:2202.02886",
    "title": "Leveraging Approximate Symbolic Models for Reinforcement Learning via  Skill Diversity",
    "abstract": "Leveraging Approximate Symbolic Models for Reinforcement Learning via  Skill Diversity",
    "descriptor": "",
    "authors": [
      "Lin Guan",
      "Sarath Sreedharan",
      "Subbarao Kambhampati"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02886"
  },
  {
    "id": "arXiv:2202.02998",
    "title": "Automatic defect segmentation by unsupervised anomaly learning",
    "abstract": "Automatic defect segmentation by unsupervised anomaly learning",
    "descriptor": "",
    "authors": [
      "Nati Ofir",
      "Ran Yacobi",
      "Omer Granoviter",
      "Boris Levant",
      "Ore Shtalrid"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.02998"
  },
  {
    "id": "arXiv:2202.03418",
    "title": "Diversify and Disambiguate: Learning From Underspecified Data",
    "abstract": "Comments: Code is available at this https URL",
    "descriptor": "\nComments: Code is available at this https URL\n",
    "authors": [
      "Yoonho Lee",
      "Huaxiu Yao",
      "Chelsea Finn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.03418"
  },
  {
    "id": "arXiv:2202.03673",
    "title": "Calibrated Learning to Defer with One-vs-All Classifiers",
    "abstract": "Comments: Accepted at the International Conference on Machine Learning (ICML), 2022",
    "descriptor": "\nComments: Accepted at the International Conference on Machine Learning (ICML), 2022\n",
    "authors": [
      "Rajeev Verma",
      "Eric Nalisnick"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.03673"
  },
  {
    "id": "arXiv:2202.03740",
    "title": "Consistency-Regularized Region-Growing Network for Semantic Segmentation  of Urban Scenes with Point-Level Annotations",
    "abstract": "Consistency-Regularized Region-Growing Network for Semantic Segmentation  of Urban Scenes with Point-Level Annotations",
    "descriptor": "",
    "authors": [
      "Yonghao Xu",
      "Pedram Ghamisi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03740"
  },
  {
    "id": "arXiv:2202.03772",
    "title": "Particle Transformer for Jet Tagging",
    "abstract": "Comments: 12 pages, 3 figures. Accepted to the 39th International Conference on Machine Learning (ICML), 2022",
    "descriptor": "\nComments: 12 pages, 3 figures. Accepted to the 39th International Conference on Machine Learning (ICML), 2022\n",
    "authors": [
      "Huilin Qu",
      "Congqiao Li",
      "Sitian Qian"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2202.03772"
  },
  {
    "id": "arXiv:2202.04005",
    "title": "Improved Convergence Rates for Sparse Approximation Methods in  Kernel-Based Learning",
    "abstract": "Comments: International Conference on Machine Learning (ICML) 2022",
    "descriptor": "\nComments: International Conference on Machine Learning (ICML) 2022\n",
    "authors": [
      "Sattar Vakili",
      "Jonathan Scarlett",
      "Da-shan Shiu",
      "Alberto Bernacchia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.04005"
  },
  {
    "id": "arXiv:2202.04357",
    "title": "Generalized Strategic Classification and the Case of Aligned Incentives",
    "abstract": "Generalized Strategic Classification and the Case of Aligned Incentives",
    "descriptor": "",
    "authors": [
      "Sagi Levanon",
      "Nir Rosenfeld"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.04357"
  },
  {
    "id": "arXiv:2202.04533",
    "title": "NIMBLE: A Non-rigid Hand Model with Bones and Muscles",
    "abstract": "Comments: 16 pages, 18 figures",
    "descriptor": "\nComments: 16 pages, 18 figures\n",
    "authors": [
      "Yuwei Li",
      "Longwen Zhang",
      "Zesong Qiu",
      "Yingwenqi Jiang",
      "Nianyi Li",
      "Yuexin Ma",
      "Yuyao Zhang",
      "Lan Xu",
      "Jingyi Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2202.04533"
  },
  {
    "id": "arXiv:2202.04721",
    "title": "New Projection-free Algorithms for Online Convex Optimization with  Adaptive Regret Guarantees",
    "abstract": "Comments: Accepted to Conference on Learning Theory (COLT), 2022",
    "descriptor": "\nComments: Accepted to Conference on Learning Theory (COLT), 2022\n",
    "authors": [
      "Dan Garber",
      "Ben Kretzu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.04721"
  },
  {
    "id": "arXiv:2202.05244",
    "title": "REvolveR: Continuous Evolutionary Models for Robot-to-robot Policy  Transfer",
    "abstract": "Comments: ICML 2022 (Long Oral)",
    "descriptor": "\nComments: ICML 2022 (Long Oral)\n",
    "authors": [
      "Xingyu Liu",
      "Deepak Pathak",
      "Kris M. Kitani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.05244"
  },
  {
    "id": "arXiv:2202.05441",
    "title": "Invariance Principle Meets Out-of-Distribution Generalization on Graphs",
    "abstract": "Comments: A preprint version",
    "descriptor": "\nComments: A preprint version\n",
    "authors": [
      "Yongqiang Chen",
      "Yonggang Zhang",
      "Yatao Bian",
      "Han Yang",
      "Kaili Ma",
      "Binghui Xie",
      "Tongliang Liu",
      "Bo Han",
      "James Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05441"
  },
  {
    "id": "arXiv:2202.06618",
    "title": "A Differential Entropy Estimator for Training Neural Networks",
    "abstract": "Comments: to be presented at ICML2022 in Baltimore, MD",
    "descriptor": "\nComments: to be presented at ICML2022 in Baltimore, MD\n",
    "authors": [
      "Georg Pichler",
      "Pierre Colombo",
      "Malik Boudiaf",
      "G\u00fcnther Koliander",
      "Pablo Piantanida"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.06618"
  },
  {
    "id": "arXiv:2202.07109",
    "title": "Asymptotics of the quantization errors for Markov-type measures with  complete overlaps",
    "abstract": "Asymptotics of the quantization errors for Markov-type measures with  complete overlaps",
    "descriptor": "",
    "authors": [
      "Sanguo Zhu"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.07109"
  },
  {
    "id": "arXiv:2202.07172",
    "title": "TURF: A Two-factor, Universal, Robust, Fast Distribution Learning  Algorithm",
    "abstract": "Comments: 19 pages, 12 figures",
    "descriptor": "\nComments: 19 pages, 12 figures\n",
    "authors": [
      "Yi Hao",
      "Ayush Jain",
      "Alon Orlitsky",
      "Vaishakh Ravindrakumar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2202.07172"
  },
  {
    "id": "arXiv:2202.07919",
    "title": "HousE: Knowledge Graph Embedding with Householder Parameterization",
    "abstract": "Comments: Accepted by ICML 2022",
    "descriptor": "\nComments: Accepted by ICML 2022\n",
    "authors": [
      "Rui Li",
      "Jianan Zhao",
      "Chaozhuo Li",
      "Di He",
      "Yiqi Wang",
      "Yuming Liu",
      "Hao Sun",
      "Senzhang Wang",
      "Weiwei Deng",
      "Yanming Shen",
      "Xing Xie",
      "Qi Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.07919"
  },
  {
    "id": "arXiv:2202.07960",
    "title": "On a Variance-Reduction Correction for the Temporal-Difference Learning  in the Stochastic Continuous Setting",
    "abstract": "On a Variance-Reduction Correction for the Temporal-Difference Learning  in the Stochastic Continuous Setting",
    "descriptor": "",
    "authors": [
      "Ziad Kobeissi",
      "Francis Bach"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Analysis of PDEs (math.AP)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.07960"
  },
  {
    "id": "arXiv:2202.08396",
    "title": "Augment with Care: Contrastive Learning for Combinatorial Problems",
    "abstract": "Augment with Care: Contrastive Learning for Combinatorial Problems",
    "descriptor": "",
    "authors": [
      "Haonan Duan",
      "Pashootan Vaezipoor",
      "Max B. Paulus",
      "Yangjun Ruan",
      "Chris J. Maddison"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.08396"
  },
  {
    "id": "arXiv:2202.08833",
    "title": "What Functions Can Graph Neural Networks Generate?",
    "abstract": "Comments: 37 pages",
    "descriptor": "\nComments: 37 pages\n",
    "authors": [
      "Mohammad Fereydounian",
      "Hamed Hassani",
      "Amin Karbasi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08833"
  },
  {
    "id": "arXiv:2202.09061",
    "title": "VLP: A Survey on Vision-Language Pre-training",
    "abstract": "Comments: A Survey on Vision-Language Pre-training",
    "descriptor": "\nComments: A Survey on Vision-Language Pre-training\n",
    "authors": [
      "Feilong Chen",
      "Duzhen Zhang",
      "Minglun Han",
      "Xiuyi Chen",
      "Jing Shi",
      "Shuang Xu",
      "Bo Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.09061"
  },
  {
    "id": "arXiv:2202.09338",
    "title": "Signal Decomposition Using Masked Proximal Operators",
    "abstract": "Comments: The manuscript has 60 pages, 22 figures and 2 tables. Also hosted at this https URL For code, see this https URL",
    "descriptor": "\nComments: The manuscript has 60 pages, 22 figures and 2 tables. Also hosted at this https URL For code, see this https URL\n",
    "authors": [
      "Bennet E. Meyers",
      "Stephen P. Boyd"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.09338"
  },
  {
    "id": "arXiv:2202.09876",
    "title": "Performance Analysis of Optimally Coordinated Connected and Automated  Vehicles in a Mixed Traffic Environment",
    "abstract": "Comments: 6 pages conference",
    "descriptor": "\nComments: 6 pages conference\n",
    "authors": [
      "Alejandra Valencia",
      "A M Ishtiaque Mahbub",
      "Andreas A. Malikopoulos"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.09876"
  },
  {
    "id": "arXiv:2202.10610",
    "title": "Knowledge Base Question Answering by Case-based Reasoning over Subgraphs",
    "abstract": "Comments: ICML 2022",
    "descriptor": "\nComments: ICML 2022\n",
    "authors": [
      "Rajarshi Das",
      "Ameya Godbole",
      "Ankita Naik",
      "Elliot Tower",
      "Robin Jia",
      "Manzil Zaheer",
      "Hannaneh Hajishirzi",
      "Andrew McCallum"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.10610"
  },
  {
    "id": "arXiv:2202.10705",
    "title": "PointMatch: A Consistency Training Framework for Weakly Supervised  Semantic Segmentation of 3D Point Clouds",
    "abstract": "Comments: 8 pages, 3 figures",
    "descriptor": "\nComments: 8 pages, 3 figures\n",
    "authors": [
      "Yushuang Wu",
      "Shengcai Cai",
      "Zizheng Yan",
      "Guanbin Li",
      "Yizhou Yu",
      "Xiaoguang Han",
      "Shuguang Cui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.10705"
  },
  {
    "id": "arXiv:2202.12396",
    "title": "Finite-Sum Coupled Compositional Stochastic Optimization: Theory and  Applications",
    "abstract": "Comments: ICML 2022",
    "descriptor": "\nComments: ICML 2022\n",
    "authors": [
      "Bokun Wang",
      "Tianbao Yang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12396"
  },
  {
    "id": "arXiv:2202.12636",
    "title": "Learning Multi-Task Gaussian Process Over Heterogeneous Input Domains",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Haitao Liu",
      "Kai Wu",
      "Yew-Soon Ong",
      "Chao Bian",
      "Xiaomo Jiang",
      "Xiaofang Wang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12636"
  },
  {
    "id": "arXiv:2202.12785",
    "title": "Confidence Calibration for Object Detection and Segmentation",
    "abstract": "Comments: Book chapter in: Tim Fingerscheidt, Hanno Gottschalk, Sebastian Houben (eds.): \"Deep Neural Networks and Data for Automated Driving\", pp. 225--250, Springer Nature, Switzerland, 2022",
    "descriptor": "\nComments: Book chapter in: Tim Fingerscheidt, Hanno Gottschalk, Sebastian Houben (eds.): \"Deep Neural Networks and Data for Automated Driving\", pp. 225--250, Springer Nature, Switzerland, 2022\n",
    "authors": [
      "Fabian K\u00fcppers",
      "Anselm Haselhoff",
      "Jan Kronenberger",
      "Jonas Schneider"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.12785"
  },
  {
    "id": "arXiv:2202.12967",
    "title": "Exploring with Sticky Mittens: Reinforcement Learning with Expert  Interventions via Option Templates",
    "abstract": "Exploring with Sticky Mittens: Reinforcement Learning with Expert  Interventions via Option Templates",
    "descriptor": "",
    "authors": [
      "Souradeep Dutta",
      "Kaustubh Sridhar",
      "Osbert Bastani",
      "Edgar Dobriban",
      "James Weimer",
      "Insup Lee",
      "Julia Parish-Morris"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.12967"
  },
  {
    "id": "arXiv:2202.13059",
    "title": "Variational Inference with Gaussian Mixture by Entropy Approximation",
    "abstract": "Comments: 27 pages, 3 figures",
    "descriptor": "\nComments: 27 pages, 3 figures\n",
    "authors": [
      "Takashi Furuya",
      "Hiroyuki Kusumoto",
      "Koichi Taniguchi",
      "Naoya Kanno",
      "Kazuma Suetake"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.13059"
  },
  {
    "id": "arXiv:2202.13234",
    "title": "Safe Exploration for Efficient Policy Evaluation and Comparison",
    "abstract": "Safe Exploration for Efficient Policy Evaluation and Comparison",
    "descriptor": "",
    "authors": [
      "Runzhe Wan",
      "Branislav Kveton",
      "Rui Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.13234"
  },
  {
    "id": "arXiv:2202.13846",
    "title": "Improved bounds for acyclic coloring parameters",
    "abstract": "Comments: Both the statement and the proof of Lemma 4, which were wrong in the previous version, have been corrected. arXiv admin note: substantial text overlap with arXiv:2111.02352",
    "descriptor": "\nComments: Both the statement and the proof of Lemma 4, which were wrong in the previous version, have been corrected. arXiv admin note: substantial text overlap with arXiv:2111.02352\n",
    "authors": [
      "Lefteris Kirousis",
      "John Livieratos"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2202.13846"
  },
  {
    "id": "arXiv:2202.14000",
    "title": "Resolving label uncertainty with implicit posterior models",
    "abstract": "Comments: UAI 2022; code: this https URL",
    "descriptor": "\nComments: UAI 2022; code: this https URL\n",
    "authors": [
      "Esther Rolf",
      "Nikolay Malkin",
      "Alexandros Graikos",
      "Ana Jojic",
      "Caleb Robinson",
      "Nebojsa Jojic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.14000"
  },
  {
    "id": "arXiv:2203.00199",
    "title": "Equivariant and Stable Positional Encoding for More Powerful Graph  Neural Networks",
    "abstract": "Comments: ICLR 2022; The revised version updates some notation mistakes and discusses on the stability of PE in different settings; code available at this https URL",
    "descriptor": "\nComments: ICLR 2022; The revised version updates some notation mistakes and discusses on the stability of PE in different settings; code available at this https URL\n",
    "authors": [
      "Haorui Wang",
      "Haoteng Yin",
      "Muhan Zhang",
      "Pan Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2203.00199"
  },
  {
    "id": "arXiv:2203.00268",
    "title": "A Pattern Collection for Blockchain Governance",
    "abstract": "A Pattern Collection for Blockchain Governance",
    "descriptor": "",
    "authors": [
      "Yue Liu",
      "Qinghua Lu",
      "Guangsheng Yu",
      "Hye-Young Paik",
      "Harsha Perera",
      "Liming Zhu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.00268"
  },
  {
    "id": "arXiv:2203.00423",
    "title": "Integration of bounded monotone functions: Revisiting the nonsequential  case, with a focus on unbiased Monte Carlo (randomized) methods",
    "abstract": "Integration of bounded monotone functions: Revisiting the nonsequential  case, with a focus on unbiased Monte Carlo (randomized) methods",
    "descriptor": "",
    "authors": [
      "Subhasish Basak",
      "Julien Bect",
      "Emmanuel Vazquez"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2203.00423"
  },
  {
    "id": "arXiv:2203.00517",
    "title": "Multi-task Learning Approach for Modulation and Wireless Signal  Classification for 5G and Beyond: Edge Deployment via Model Compression",
    "abstract": "Comments: Accepted to Physical Communication (Elsevier). Extended version of Conf. Paper: arXiv:2101.10254",
    "descriptor": "\nComments: Accepted to Physical Communication (Elsevier). Extended version of Conf. Paper: arXiv:2101.10254\n",
    "authors": [
      "Anu Jagannath",
      "Jithin Jagannath"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.00517"
  },
  {
    "id": "arXiv:2203.00820",
    "title": "Partial Likelihood Thompson Sampling",
    "abstract": "Partial Likelihood Thompson Sampling",
    "descriptor": "",
    "authors": [
      "Han Wu",
      "Stefan Wager"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.00820"
  },
  {
    "id": "arXiv:2203.01073",
    "title": "Recursively feasible stochastic predictive control using an  interpolating initial state constraint -- extended version",
    "abstract": "Comments: Extended version of accepted paper in IEEE Control Systems Letters, 2022. Contains additional details regarding the proof and an additional example",
    "descriptor": "\nComments: Extended version of accepted paper in IEEE Control Systems Letters, 2022. Contains additional details regarding the proof and an additional example\n",
    "authors": [
      "Johannes K\u00f6hler",
      "Melanie N. Zeilinger"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.01073"
  },
  {
    "id": "arXiv:2203.01137",
    "title": "Self-Supervised Scene Flow Estimation with 4-D Automotive Radar",
    "abstract": "Comments: Copyright 2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works",
    "descriptor": "\nComments: Copyright 2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works\n",
    "authors": [
      "Fangqiang Ding",
      "Zhijun Pan",
      "Yimin Deng",
      "Jianning Deng",
      "Chris Xiaoxuan Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.01137"
  },
  {
    "id": "arXiv:2203.01548",
    "title": "Momentum-Aware Trajectory Optimization and Control for Agile Quadrupedal  Locomotion",
    "abstract": "Momentum-Aware Trajectory Optimization and Control for Agile Quadrupedal  Locomotion",
    "descriptor": "",
    "authors": [
      "Ziyi Zhou",
      "Bruce Wingo",
      "Nathan Boyd",
      "Seth Hutchinson",
      "Ye Zhao"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.01548"
  },
  {
    "id": "arXiv:2203.01720",
    "title": "Topological data analysis of truncated contagion maps",
    "abstract": "Comments: The following article has been accepted by Chaos: An Interdisciplinary Journal of Nonlinear Science",
    "descriptor": "\nComments: The following article has been accepted by Chaos: An Interdisciplinary Journal of Nonlinear Science\n",
    "authors": [
      "Florian Klimm"
    ],
    "subjectives": [
      "Algebraic Topology (math.AT)",
      "Machine Learning (cs.LG)",
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Genomics (q-bio.GN)"
    ],
    "url": "https://arxiv.org/abs/2203.01720"
  },
  {
    "id": "arXiv:2203.01762",
    "title": "NeuroFluid: Fluid Dynamics Grounding with Particle-Driven Neural  Radiance Fields",
    "abstract": "Comments: ICML 2022, the project page: this https URL",
    "descriptor": "\nComments: ICML 2022, the project page: this https URL\n",
    "authors": [
      "Shanyan Guan",
      "Huayu Deng",
      "Yunbo Wang",
      "Xiaokang Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2203.01762"
  },
  {
    "id": "arXiv:2203.02872",
    "title": "The Orthologic of Epistemic Modals",
    "abstract": "Comments: new introduction to Section 2; addition of Figure 5 and Remarks 3.14, 4.10, and 4.30; major updates to Sections 3.2.4, 4.3, and 5; corrections in Section 5 and Figures 11, 12, and 16; strengthening of Example 6.20",
    "descriptor": "\nComments: new introduction to Section 2; addition of Figure 5 and Remarks 3.14, 4.10, and 4.30; major updates to Sections 3.2.4, 4.3, and 5; corrections in Section 5 and Figures 11, 12, and 16; strengthening of Example 6.20\n",
    "authors": [
      "Wesley H. Holliday",
      "Matthew Mandelkern"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2203.02872"
  },
  {
    "id": "arXiv:2203.03673",
    "title": "AgraSSt: Approximate Graph Stein Statistics for Interpretable Assessment  of Implicit Graph Generators",
    "abstract": "AgraSSt: Approximate Graph Stein Statistics for Interpretable Assessment  of Implicit Graph Generators",
    "descriptor": "",
    "authors": [
      "Wenkai Xu",
      "Gesine Reinert"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.03673"
  },
  {
    "id": "arXiv:2203.03677",
    "title": "Object-centric and memory-guided normality reconstruction for video  anomaly detection",
    "abstract": "Comments: Accepted at ICIP 2022",
    "descriptor": "\nComments: Accepted at ICIP 2022\n",
    "authors": [
      "Khalil Bergaoui",
      "Yassine Naji",
      "Aleksandr Setkov",
      "Ang\u00e9lique Loesch",
      "Mich\u00e8le Gouiff\u00e8s",
      "Romaric Audigier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03677"
  },
  {
    "id": "arXiv:2203.03898",
    "title": "Yet another DE-Sinc indefinite integration formula",
    "abstract": "Yet another DE-Sinc indefinite integration formula",
    "descriptor": "",
    "authors": [
      "Tomoaki Okayama",
      "Ken'ichiro Tanaka"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.03898"
  },
  {
    "id": "arXiv:2203.03990",
    "title": "Audio-Visual MLP for Scoring Sport",
    "abstract": "Comments: Our code is available at this https URL",
    "descriptor": "\nComments: Our code is available at this https URL\n",
    "authors": [
      "Jingfei Xia",
      "Mingchen Zhuge",
      "Tiantian Geng",
      "Shun Fan",
      "Yuantai Wei",
      "Zhenyu He",
      "Feng Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03990"
  },
  {
    "id": "arXiv:2203.04294",
    "title": "NaviAirway: a Bronchiole-sensitive Deep Learning-based Airway  Segmentation Pipeline",
    "abstract": "NaviAirway: a Bronchiole-sensitive Deep Learning-based Airway  Segmentation Pipeline",
    "descriptor": "",
    "authors": [
      "Andong Wang",
      "Terence Chi Chun Tam",
      "Ho Ming Poon",
      "Kun-Chang Yu",
      "Wei-Ning Lee"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04294"
  },
  {
    "id": "arXiv:2203.04466",
    "title": "The Combinatorial Brain Surgeon: Pruning Weights That Cancel One Another  in Neural Networks",
    "abstract": "The Combinatorial Brain Surgeon: Pruning Weights That Cancel One Another  in Neural Networks",
    "descriptor": "",
    "authors": [
      "Xin Yu",
      "Thiago Serra",
      "Srikumar Ramalingam",
      "Shandian Zhe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04466"
  },
  {
    "id": "arXiv:2203.04510",
    "title": "ReVar: Strengthening Policy Evaluation via Reduced Variance Sampling",
    "abstract": "Comments: Accepted for the $38^{\\text {th }}$ Conference on Uncertainty in Artificial Intelligence (UAI 2022)",
    "descriptor": "\nComments: Accepted for the $38^{\\text {th }}$ Conference on Uncertainty in Artificial Intelligence (UAI 2022)\n",
    "authors": [
      "Subhojyoti Mukherjee",
      "Josiah P. Hanna",
      "Robert Nowak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.04510"
  },
  {
    "id": "arXiv:2203.04629",
    "title": "A comparison of variational upwinding schemes for geophysical fluids,  and their application to potential enstrophy conserving discretisations",
    "abstract": "A comparison of variational upwinding schemes for geophysical fluids,  and their application to potential enstrophy conserving discretisations",
    "descriptor": "",
    "authors": [
      "David Lee",
      "Alberto F. Mart\u00edn",
      "Christopher Bladwell",
      "Santiago Badia"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.04629"
  },
  {
    "id": "arXiv:2203.04911",
    "title": "DUAL: Discrete Spoken Unit Adaptive Learning for Textless Spoken  Question Answering",
    "abstract": "Comments: Accepted by Interspeech 2022",
    "descriptor": "\nComments: Accepted by Interspeech 2022\n",
    "authors": [
      "Guan-Ting Lin",
      "Yung-Sung Chuang",
      "Ho-Lam Chung",
      "Shu-wen Yang",
      "Hsuan-Jui Chen",
      "Shuyan Dong",
      "Shang-Wen Li",
      "Abdelrahman Mohamed",
      "Hung-yi Lee",
      "Lin-shan Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.04911"
  },
  {
    "id": "arXiv:2203.05028",
    "title": "Dynamic Instance Domain Adaptation",
    "abstract": "Comments: Accepted to IEEE T-IP. Code available at this https URL",
    "descriptor": "\nComments: Accepted to IEEE T-IP. Code available at this https URL\n",
    "authors": [
      "Zhongying Deng",
      "Kaiyang Zhou",
      "Da Li",
      "Junjun He",
      "Yi-Zhe Song",
      "Tao Xiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05028"
  },
  {
    "id": "arXiv:2203.06556",
    "title": "A smoothed particle hydrodynamics approach for phase field modeling of  brittle fracture",
    "abstract": "A smoothed particle hydrodynamics approach for phase field modeling of  brittle fracture",
    "descriptor": "",
    "authors": [
      "Mohammad Naqib Rahimi",
      "Georgios Moutsanidis"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2203.06556"
  },
  {
    "id": "arXiv:2203.06993",
    "title": "Supervised segmentation of NO2 plumes from individual ships using  TROPOMI satellite data",
    "abstract": "Comments: Minor presentation changes in comparison to previous version",
    "descriptor": "\nComments: Minor presentation changes in comparison to previous version\n",
    "authors": [
      "Solomiia Kurchaba",
      "Jasper van Vliet",
      "Fons J. Verbeek",
      "Jacqueline J. Meulman",
      "Cor J. Veenman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.06993"
  },
  {
    "id": "arXiv:2203.07826",
    "title": "Discrete approximations to Dirac operators and norm resolvent  convergence",
    "abstract": "Discrete approximations to Dirac operators and norm resolvent  convergence",
    "descriptor": "",
    "authors": [
      "Horia D. Cornean",
      "Henrik Garde",
      "Arne Jensen"
    ],
    "subjectives": [
      "Mathematical Physics (math-ph)",
      "Numerical Analysis (math.NA)",
      "Spectral Theory (math.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.07826"
  },
  {
    "id": "arXiv:2203.08451",
    "title": "Analysis of Fully Discrete Mixed Finite Element Scheme for Stochastic  Navier-Stokes Equations with Multiplicative Noise",
    "abstract": "Analysis of Fully Discrete Mixed Finite Element Scheme for Stochastic  Navier-Stokes Equations with Multiplicative Noise",
    "descriptor": "",
    "authors": [
      "Hailong Qiu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.08451"
  },
  {
    "id": "arXiv:2203.08553",
    "title": "PMIC: Improving Multi-Agent Reinforcement Learning with Progressive  Mutual Information Collaboration",
    "abstract": "Comments: The paper has been accepted by The Thirty-ninth International Conference on Machine Learning (ICML 2022) and the Cooperative AI Workshop at 35th Conference on Neural Information Processing Systems (NeurIPS 2021)",
    "descriptor": "\nComments: The paper has been accepted by The Thirty-ninth International Conference on Machine Learning (ICML 2022) and the Cooperative AI Workshop at 35th Conference on Neural Information Processing Systems (NeurIPS 2021)\n",
    "authors": [
      "Pengyi Li",
      "Hongyao Tang",
      "Tianpei Yang",
      "Xiaotian Hao",
      "Tong Sang",
      "Yan Zheng",
      "Jianye Hao",
      "Matthew E.Taylor",
      "Wenyuan Tao",
      "Zhen Wang"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.08553"
  },
  {
    "id": "arXiv:2203.08980",
    "title": "Stochastic Simulation Uncertainty Analysis to Accelerate Flexible  Biomanufacturing Process Development",
    "abstract": "Comments: 31 pages, 3 figures. arXiv admin note: substantial text overlap with arXiv:2011.04207",
    "descriptor": "\nComments: 31 pages, 3 figures. arXiv admin note: substantial text overlap with arXiv:2011.04207\n",
    "authors": [
      "Wei Xie",
      "Russell R. Barton",
      "Barry L. Nelson",
      "Keqi Wang"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.08980"
  },
  {
    "id": "arXiv:2203.09023",
    "title": "Measuring Consumer Perceived Warm-Glow for Technology Adoption Modeling",
    "abstract": "Measuring Consumer Perceived Warm-Glow for Technology Adoption Modeling",
    "descriptor": "",
    "authors": [
      "Antonios Saravanos",
      "Dongnanzi Zheng",
      "Stavros Zervoudakis"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.09023"
  },
  {
    "id": "arXiv:2203.09550",
    "title": "Multi-similarity based Hyperrelation Network for few-shot segmentation",
    "abstract": "Multi-similarity based Hyperrelation Network for few-shot segmentation",
    "descriptor": "",
    "authors": [
      "Xiangwen Shi",
      "Zhe Cui",
      "Shaobing Zhang",
      "Miao Cheng",
      "Lian He",
      "Xianghong Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09550"
  },
  {
    "id": "arXiv:2203.09581",
    "title": "SepTr: Separable Transformer for Audio Spectrogram Processing",
    "abstract": "Comments: Accepted at INTERSPEECH 2022",
    "descriptor": "\nComments: Accepted at INTERSPEECH 2022\n",
    "authors": [
      "Nicolae-Catalin Ristea",
      "Radu Tudor Ionescu",
      "Fahad Shahbaz Khan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.09581"
  },
  {
    "id": "arXiv:2203.09672",
    "title": "Deep Multi-Modal Structural Equations For Causal Effect Estimation With  Unstructured Proxies",
    "abstract": "Deep Multi-Modal Structural Equations For Causal Effect Estimation With  Unstructured Proxies",
    "descriptor": "",
    "authors": [
      "Shachi Deshpande",
      "Kaiwen Wang",
      "Dhruv Sreenivas",
      "Zheng Li",
      "Volodymyr Kuleshov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.09672"
  },
  {
    "id": "arXiv:2203.09690",
    "title": "A$^3$T: Alignment-Aware Acoustic and Text Pretraining for Speech  Synthesis and Editing",
    "abstract": "Comments: Accepted by ICML 2022, 12 pages, 10 figures",
    "descriptor": "\nComments: Accepted by ICML 2022, 12 pages, 10 figures\n",
    "authors": [
      "He Bai",
      "Renjie Zheng",
      "Junkun Chen",
      "Xintong Li",
      "Mingbo Ma",
      "Liang Huang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2203.09690"
  },
  {
    "id": "arXiv:2203.10190",
    "title": "Fair Federated Learning via Bounded Group Loss",
    "abstract": "Comments: 19 pages",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Shengyuan Hu",
      "Zhiwei Steven Wu",
      "Virginia Smith"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2203.10190"
  },
  {
    "id": "arXiv:2203.11100",
    "title": "Migrating CUDA to oneAPI: A Smith-Waterman Case Study",
    "abstract": "Comments: Accepted in IWBBIO 2022",
    "descriptor": "\nComments: Accepted in IWBBIO 2022\n",
    "authors": [
      "Manuel Costanzo",
      "Enzo Rucci",
      "Carlos Garcia Sanchez",
      "Marcelo Naiouf",
      "Manuel Prieto-Matias"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2203.11100"
  },
  {
    "id": "arXiv:2203.11556",
    "title": "VQ-Flows: Vector Quantized Local Normalizing Flows",
    "abstract": "Comments: Accepted to The 38th Conference on Uncertainty in Artificial Intelligence (UAI) 2022",
    "descriptor": "\nComments: Accepted to The 38th Conference on Uncertainty in Artificial Intelligence (UAI) 2022\n",
    "authors": [
      "Sahil Sidheekh",
      "Chris B. Dock",
      "Tushar Jain",
      "Radu Balan",
      "Maneesh K. Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.11556"
  },
  {
    "id": "arXiv:2203.11635",
    "title": "Feature Distribution Matching for Federated Domain Generalization",
    "abstract": "Feature Distribution Matching for Federated Domain Generalization",
    "descriptor": "",
    "authors": [
      "Yuwei Sun",
      "Ng Chong",
      "Hideya Ochiai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11635"
  },
  {
    "id": "arXiv:2203.11924",
    "title": "On Supervised Feature Selection from High Dimensional Feature Spaces",
    "abstract": "Comments: 14 pages, 9 figures, 9 tables, under consideration at APSIPA Transactions on Signal and Information Processing",
    "descriptor": "\nComments: 14 pages, 9 figures, 9 tables, under consideration at APSIPA Transactions on Signal and Information Processing\n",
    "authors": [
      "Yijing Yang",
      "Wei Wang",
      "Hongyu Fu",
      "C.-C. Jay Kuo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11924"
  },
  {
    "id": "arXiv:2203.12555",
    "title": "GriTS: Grid table similarity metric for table structure recognition",
    "abstract": "GriTS: Grid table similarity metric for table structure recognition",
    "descriptor": "",
    "authors": [
      "Brandon Smock",
      "Rohith Pesala",
      "Robin Abraham"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.12555"
  },
  {
    "id": "arXiv:2203.12689",
    "title": "Toward Scalable Risk Analysis for Stochastic Systems Using Extreme Value  Theory",
    "abstract": "Comments: IEEE Control Systems Letters, accepted in June 2022",
    "descriptor": "\nComments: IEEE Control Systems Letters, accepted in June 2022\n",
    "authors": [
      "Evan Arsenault",
      "Yuheng Wang",
      "Margaret P. Chapman"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.12689"
  },
  {
    "id": "arXiv:2203.13913",
    "title": "SpeqNets: Sparsity-aware Permutation-equivariant Graph Networks",
    "abstract": "Comments: ICML 2022",
    "descriptor": "\nComments: ICML 2022\n",
    "authors": [
      "Christopher Morris",
      "Gaurav Rattan",
      "Sandra Kiefer",
      "Siamak Ravanbakhsh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.13913"
  },
  {
    "id": "arXiv:2203.14222",
    "title": "Listen, Adapt, Better WER: Source-free Single-utterance Test-time  Adaptation for Automatic Speech Recognition",
    "abstract": "Comments: Accepted by Interspeech 2022",
    "descriptor": "\nComments: Accepted by Interspeech 2022\n",
    "authors": [
      "Guan-Ting Lin",
      "Shang-Wen Li",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2203.14222"
  },
  {
    "id": "arXiv:2203.14565",
    "title": "Style-Guided Domain Adaptation for Face Presentation Attack Detection",
    "abstract": "Comments: With the agreement of all authors, we would like to withdraw the manuscript. For lack of some experiments, a part of important claims cannot stand solidly. We need to further carry out experiments, and reconsider the rationality of these claims",
    "descriptor": "\nComments: With the agreement of all authors, we would like to withdraw the manuscript. For lack of some experiments, a part of important claims cannot stand solidly. We need to further carry out experiments, and reconsider the rationality of these claims\n",
    "authors": [
      "Young-Eun Kim",
      "Woo-Jeoung Nam",
      "Kyungseo Min",
      "Seong-Whan Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.14565"
  },
  {
    "id": "arXiv:2203.15052",
    "title": "Learning Minimum-Time Flight in Cluttered Environments",
    "abstract": "Learning Minimum-Time Flight in Cluttered Environments",
    "descriptor": "",
    "authors": [
      "Robert Penicka",
      "Yunlong Song",
      "Elia Kaufmann",
      "Davide Scaramuzza"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.15052"
  },
  {
    "id": "arXiv:2203.15536",
    "title": "BARC: Learning to Regress 3D Dog Shape from Images by Exploiting Breed  Information",
    "abstract": "Comments: accepted for publication at CVPR 2022",
    "descriptor": "\nComments: accepted for publication at CVPR 2022\n",
    "authors": [
      "Nadine Rueegg",
      "Silvia Zuffi",
      "Konrad Schindler",
      "Michael J. Black"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15536"
  },
  {
    "id": "arXiv:2203.15610",
    "title": "LightHuBERT: Lightweight and Configurable Speech Representation Learning  with Once-for-All Hidden-Unit BERT",
    "abstract": "Comments: 5 pages, 2 figures, accepted to Insterspeech 2022",
    "descriptor": "\nComments: 5 pages, 2 figures, accepted to Insterspeech 2022\n",
    "authors": [
      "Rui Wang",
      "Qibing Bai",
      "Junyi Ao",
      "Long Zhou",
      "Zhixiang Xiong",
      "Zhihua Wei",
      "Yu Zhang",
      "Tom Ko",
      "Haizhou Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2203.15610"
  },
  {
    "id": "arXiv:2203.15980",
    "title": "DELTA: Dynamically Optimizing GPU Memory beyond Tensor Recomputation",
    "abstract": "Comments: 12 pages, 8 figures",
    "descriptor": "\nComments: 12 pages, 8 figures\n",
    "authors": [
      "Yu Tang",
      "Chenyu Wang",
      "Yufan Zhang",
      "Yuliang Liu",
      "Xingcheng Zhang",
      "Linbo Qiao",
      "Zhiquan Lai",
      "Dongsheng Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15980"
  },
  {
    "id": "arXiv:2203.16040",
    "title": "Disentangling the Impacts of Language and Channel Variability on Speech  Separation Networks",
    "abstract": "Comments: Published in Interspeech 2022",
    "descriptor": "\nComments: Published in Interspeech 2022\n",
    "authors": [
      "Fan-Lin Wang",
      "Hung-Shin Lee",
      "Yu Tsao",
      "Hsin-Min Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.16040"
  },
  {
    "id": "arXiv:2203.16155",
    "title": "RICON: A ML framework for real-time and proactive intervention to  prevent customer churn",
    "abstract": "Comments: We are making significant improvements to the paper and hence want to withdraw it for the time being. The updated version will be available shortly",
    "descriptor": "\nComments: We are making significant improvements to the paper and hence want to withdraw it for the time being. The updated version will be available shortly\n",
    "authors": [
      "Arnab Chakraborty",
      "Vikas Raturi",
      "Shrutendra Harsola"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.16155"
  },
  {
    "id": "arXiv:2203.16462",
    "title": "Convergence of gradient descent for deep neural networks",
    "abstract": "Comments: 30 pages, 1 figure. In this revision, I have tried to explain better the main difference between this paper and prior works, which may not have been clear to some readers",
    "descriptor": "\nComments: 30 pages, 1 figure. In this revision, I have tried to explain better the main difference between this paper and prior works, which may not have been clear to some readers\n",
    "authors": [
      "Sourav Chatterjee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.16462"
  },
  {
    "id": "arXiv:2203.16843",
    "title": "A Hybrid Continuity Loss to Reduce Over-Suppression for Time-domain  Target Speaker Extraction",
    "abstract": "Comments: Accepted by Interspeech2022",
    "descriptor": "\nComments: Accepted by Interspeech2022\n",
    "authors": [
      "Zexu Pan",
      "Meng Ge",
      "Haizhou Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2203.16843"
  },
  {
    "id": "arXiv:2203.16944",
    "title": "A data-driven approach for the closure of RANS models by the divergence  of the Reynolds Stress Tensor",
    "abstract": "Comments: 26 pages, 13 figures",
    "descriptor": "\nComments: 26 pages, 13 figures\n",
    "authors": [
      "Stefano Berrone",
      "Davide Oberto"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.16944"
  },
  {
    "id": "arXiv:2203.17113",
    "title": "Pre-Training Transformer Decoder for End-to-End ASR Model with Unpaired  Speech Data",
    "abstract": "Comments: Accepted by Interspeech 2022",
    "descriptor": "\nComments: Accepted by Interspeech 2022\n",
    "authors": [
      "Junyi Ao",
      "Ziqiang Zhang",
      "Long Zhou",
      "Shujie Liu",
      "Haizhou Li",
      "Tom Ko",
      "Lirong Dai",
      "Jinyu Li",
      "Yao Qian",
      "Furu Wei"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.17113"
  },
  {
    "id": "arXiv:2204.00465",
    "title": "Deep Neural Convolutive Matrix Factorization for Articulatory  Representation Decomposition",
    "abstract": "Comments: Accepted to 2022 Interspeech. Code is publicly available at this https URL",
    "descriptor": "\nComments: Accepted to 2022 Interspeech. Code is publicly available at this https URL\n",
    "authors": [
      "Jiachen Lian",
      "Alan W Black",
      "Louis Goldstein",
      "Gopala Krishna Anumanchipalli"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2204.00465"
  },
  {
    "id": "arXiv:2204.01613",
    "title": "SPECTRE: Spectral Conditioning Helps to Overcome the Expressivity Limits  of One-shot Graph Generators",
    "abstract": "Comments: The 39th International Conference on Machine Learning (ICML 2022), 21 pages, 10 figures",
    "descriptor": "\nComments: The 39th International Conference on Machine Learning (ICML 2022), 21 pages, 10 figures\n",
    "authors": [
      "Karolis Martinkus",
      "Andreas Loukas",
      "Nathana\u00ebl Perraudin",
      "Roger Wattenhofer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.01613"
  },
  {
    "id": "arXiv:2204.01787",
    "title": "GWA: A Large High-Quality Acoustic Dataset for Audio Processing",
    "abstract": "GWA: A Large High-Quality Acoustic Dataset for Audio Processing",
    "descriptor": "",
    "authors": [
      "Zhenyu Tang",
      "Rohith Aralikatti",
      "Anton Ratnarajah",
      "Dinesh Manocha"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.01787"
  },
  {
    "id": "arXiv:2204.02602",
    "title": "Distributed Transition Systems with Tags for Privacy Analysis",
    "abstract": "Distributed Transition Systems with Tags for Privacy Analysis",
    "descriptor": "",
    "authors": [
      "Siva Anantharaman",
      "Sabine Frittella",
      "Benjamin Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2204.02602"
  },
  {
    "id": "arXiv:2204.02809",
    "title": "Hammer PDF: An Intelligent PDF Reader for Scientific Papers",
    "abstract": "Hammer PDF: An Intelligent PDF Reader for Scientific Papers",
    "descriptor": "",
    "authors": [
      "Sheng-Fu Wang",
      "Shu-Hang Liu",
      "Tian-Yi Che",
      "Yi-Fan Lu",
      "Song-Xiao Yang",
      "Heyan Huang",
      "Xian-Ling Mao"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2204.02809"
  },
  {
    "id": "arXiv:2204.04263",
    "title": "BioRED: A Rich Biomedical Relation Extraction Dataset",
    "abstract": "Comments: Accepted by Briefings in Bioinformatics",
    "descriptor": "\nComments: Accepted by Briefings in Bioinformatics\n",
    "authors": [
      "Ling Luo",
      "Po-Ting Lai",
      "Chih-Hsuan Wei",
      "Cecilia N Arighi",
      "Zhiyong Lu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.04263"
  },
  {
    "id": "arXiv:2204.04322",
    "title": "Iterative Depth-First Search for Fully Observable Non-Deterministic  Planning",
    "abstract": "Iterative Depth-First Search for Fully Observable Non-Deterministic  Planning",
    "descriptor": "",
    "authors": [
      "Ramon Fraga Pereira",
      "Andr\u00e9 G. Pereira",
      "Frederico Messa",
      "Giuseppe De Giacomo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.04322"
  },
  {
    "id": "arXiv:2204.04483",
    "title": "Why did I fail? A Causal-based Method to Find Explanations for Robot  Failures",
    "abstract": "Comments: accepted at IEEE Robotics and Automation Letters (June 2022)",
    "descriptor": "\nComments: accepted at IEEE Robotics and Automation Letters (June 2022)\n",
    "authors": [
      "Maximilian Diehl",
      "Karinne Ramirez-Amaro"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.04483"
  },
  {
    "id": "arXiv:2204.05224",
    "title": "Performance analysis of WDM in LoS communications with arbitrary  orientation and position",
    "abstract": "Comments: 5 pages, 7 figures, IEEE Wireless Communications Letters",
    "descriptor": "\nComments: 5 pages, 7 figures, IEEE Wireless Communications Letters\n",
    "authors": [
      "Antonio Alberto D'Amico",
      "Luca Sanguinetti",
      "Merouane Debbah"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2204.05224"
  },
  {
    "id": "arXiv:2204.05308",
    "title": "On the Generalization of BasicVSR++ to Video Deblurring and Denoising",
    "abstract": "Comments: Technical report. Extension of arXiv:2104.13371",
    "descriptor": "\nComments: Technical report. Extension of arXiv:2104.13371\n",
    "authors": [
      "Kelvin C.K. Chan",
      "Shangchen Zhou",
      "Xiangyu Xu",
      "Chen Change Loy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.05308"
  },
  {
    "id": "arXiv:2204.06760",
    "title": "HCFL: A High Compression Approach for Communication-Efficient Federated  Learning in Very Large Scale IoT Networks",
    "abstract": "Comments: 14 pages, 12 figures, 3 tables",
    "descriptor": "\nComments: 14 pages, 12 figures, 3 tables\n",
    "authors": [
      "Minh-Duong Nguyen",
      "Sang-Min Lee",
      "Quoc-Viet Pham",
      "Dinh Thai Hoang",
      "Diep N. Nguyen",
      "Won-Joo Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2204.06760"
  },
  {
    "id": "arXiv:2204.06946",
    "title": "Visualization for Epidemiological Modelling: Challenges, Solutions,  Reflections & Recommendations",
    "abstract": "Visualization for Epidemiological Modelling: Challenges, Solutions,  Reflections & Recommendations",
    "descriptor": "",
    "authors": [
      "Jason Dykes",
      "Alfie Abdul-Rahman",
      "Daniel Archambault",
      "Benjamin Bach",
      "Rita Borgo",
      "Min Chen",
      "Jessica Enright",
      "Hui Fang",
      "Elif E. Firat",
      "Euan Freeman",
      "Tuna Gonen",
      "Claire Harris",
      "Radu Jianu",
      "Nigel W. John",
      "Saiful Khan",
      "Andrew Lahiff",
      "Robert S. Laramee",
      "Louise Matthews",
      "Sibylle Mohr",
      "Phong H. Nguyen",
      "Alma A. M. Rahat",
      "Richard Reeve",
      "Panagiotis D. Ritsos",
      "Jonathan C. Roberts",
      "Aidan Slingsby",
      "Ben Swallow",
      "Thomas Torsney-Weir",
      "Cagatay Turkay",
      "Robert Turner",
      "Franck P. Vidal",
      "Qiru Wang",
      "Jo Wood",
      "Kai Xu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2204.06946"
  },
  {
    "id": "arXiv:2204.07919",
    "title": "Cognitive Architecture for Decision-Making Based on Brain Principles  Programming",
    "abstract": "Comments: 13 pages, 5 figures, submitted for presentation at 2022 Annual International Conference on Brain-Inspired Cognitive Architectures for Artificial Intelligence",
    "descriptor": "\nComments: 13 pages, 5 figures, submitted for presentation at 2022 Annual International Conference on Brain-Inspired Cognitive Architectures for Artificial Intelligence\n",
    "authors": [
      "Anton Kolonin",
      "Andrey Kurpatov",
      "Artem Molchanov",
      "Gennadiy Averyanov"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2204.07919"
  },
  {
    "id": "arXiv:2204.08504",
    "title": "CGC: Contrastive Graph Clustering for Community Detection and Tracking",
    "abstract": "Comments: TheWebConf 2022 Research Track",
    "descriptor": "\nComments: TheWebConf 2022 Research Track\n",
    "authors": [
      "Namyong Park",
      "Ryan Rossi",
      "Eunyee Koh",
      "Iftikhar Ahamath Burhanuddin",
      "Sungchul Kim",
      "Fan Du",
      "Nesreen Ahmed",
      "Christos Faloutsos"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.08504"
  },
  {
    "id": "arXiv:2204.08741",
    "title": "Influence of Repetition through Limited Recall",
    "abstract": "Influence of Repetition through Limited Recall",
    "descriptor": "",
    "authors": [
      "Jad Sassine",
      "M. Amin Rahimian",
      "Dean Eckles"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Human-Computer Interaction (cs.HC)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2204.08741"
  },
  {
    "id": "arXiv:2204.08790",
    "title": "ELEVATER: A Benchmark and Toolkit for Evaluating Language-Augmented  Visual Models",
    "abstract": "Comments: Preprint. The first two authors contribute equally. Benchmark page: this https URL",
    "descriptor": "\nComments: Preprint. The first two authors contribute equally. Benchmark page: this https URL\n",
    "authors": [
      "Chunyuan Li",
      "Haotian Liu",
      "Liunian Harold Li",
      "Pengchuan Zhang",
      "Jyoti Aneja",
      "Jianwei Yang",
      "Ping Jin",
      "Yong Jae Lee",
      "Houdong Hu",
      "Zicheng Liu",
      "Jianfeng Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.08790"
  },
  {
    "id": "arXiv:2204.09409",
    "title": "Video Moment Retrieval from Text Queries via Single Frame Annotation",
    "abstract": "Comments: Accepted as full paper in SIGIR 2022",
    "descriptor": "\nComments: Accepted as full paper in SIGIR 2022\n",
    "authors": [
      "Ran Cui",
      "Tianwen Qian",
      "Pai Peng",
      "Elena Daskalaki",
      "Jingjing Chen",
      "Xiaowei Guo",
      "Huyang Sun",
      "Yu-Gang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.09409"
  },
  {
    "id": "arXiv:2204.09826",
    "title": "SimMC: Simple Masked Contrastive Learning of Skeleton Representations  for Unsupervised Person Re-Identification",
    "abstract": "Comments: Accepted at IJCAI 2022 Main Track. The Appendix A for Proof (4 pages) and Appendix B for Experiments (9 pages) are included in the version [v3] at arXiv:2204.09826",
    "descriptor": "\nComments: Accepted at IJCAI 2022 Main Track. The Appendix A for Proof (4 pages) and Appendix B for Experiments (9 pages) are included in the version [v3] at arXiv:2204.09826\n",
    "authors": [
      "Haocong Rao",
      "Chunyan Miao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.09826"
  },
  {
    "id": "arXiv:2204.10049",
    "title": "On Distribution Shift in Learning-based Bug Detectors",
    "abstract": "On Distribution Shift in Learning-based Bug Detectors",
    "descriptor": "",
    "authors": [
      "Jingxuan He",
      "Luca Beurer-Kellner",
      "Martin Vechev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2204.10049"
  },
  {
    "id": "arXiv:2204.10819",
    "title": "Parameterized Sensitivity Oracles and Dynamic Algorithms using Exterior  Algebras",
    "abstract": "Parameterized Sensitivity Oracles and Dynamic Algorithms using Exterior  Algebras",
    "descriptor": "",
    "authors": [
      "Josh Alman",
      "Dean Hirsch"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.10819"
  },
  {
    "id": "arXiv:2204.11011",
    "title": "A Novel Splitting Criterion Inspired by Geometric Mean Metric Learning  for Decision Tree",
    "abstract": "Comments: Accepted by ICPR2022",
    "descriptor": "\nComments: Accepted by ICPR2022\n",
    "authors": [
      "Dan Li",
      "Songcan Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.11011"
  },
  {
    "id": "arXiv:2204.13101",
    "title": "Self-Supervised Learning of Object Parts for Semantic Segmentation",
    "abstract": "Comments: Accepted at CVPR 2022",
    "descriptor": "\nComments: Accepted at CVPR 2022\n",
    "authors": [
      "Adrian Ziegler",
      "Yuki M. Asano"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.13101"
  },
  {
    "id": "arXiv:2204.13902",
    "title": "Fast Sampling of Diffusion Models with Exponential Integrator",
    "abstract": "Comments: 22 pages,16 figures, Code is available at this https URL",
    "descriptor": "\nComments: 22 pages,16 figures, Code is available at this https URL\n",
    "authors": [
      "Qinsheng Zhang",
      "Yongxin Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.13902"
  },
  {
    "id": "arXiv:2205.00102",
    "title": "Manipulating Elections by Changing Voter Perceptions",
    "abstract": "Comments: IJCAI 2022",
    "descriptor": "\nComments: IJCAI 2022\n",
    "authors": [
      "Junlin Wu",
      "Andrew Estornell",
      "Lecheng Kong",
      "Yevgeniy Vorobeychik"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2205.00102"
  },
  {
    "id": "arXiv:2205.00350",
    "title": "Orthogonal Statistical Learning with Self-Concordant Loss",
    "abstract": "Comments: COLT 2022",
    "descriptor": "\nComments: COLT 2022\n",
    "authors": [
      "Lang Liu",
      "Carlos Cinelli",
      "Zaid Harchaoui"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.00350"
  },
  {
    "id": "arXiv:2205.01019",
    "title": "HarmoF0: Logarithmic Scale Dilated Convolution For Pitch Estimation",
    "abstract": "Comments: This paper is accepted by ICME2022",
    "descriptor": "\nComments: This paper is accepted by ICME2022\n",
    "authors": [
      "Weixing Wei",
      "Peilin Li",
      "Yi Yu",
      "Wei Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2205.01019"
  },
  {
    "id": "arXiv:2205.01052",
    "title": "HTTPA/2: a Trusted End-to-End Protocol for Web Services",
    "abstract": "Comments: 24 pages, 6 figures",
    "descriptor": "\nComments: 24 pages, 6 figures\n",
    "authors": [
      "Gordon King",
      "Hans Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.01052"
  },
  {
    "id": "arXiv:2205.01068",
    "title": "OPT: Open Pre-trained Transformer Language Models",
    "abstract": "OPT: Open Pre-trained Transformer Language Models",
    "descriptor": "",
    "authors": [
      "Susan Zhang",
      "Stephen Roller",
      "Naman Goyal",
      "Mikel Artetxe",
      "Moya Chen",
      "Shuohui Chen",
      "Christopher Dewan",
      "Mona Diab",
      "Xian Li",
      "Xi Victoria Lin",
      "Todor Mihaylov",
      "Myle Ott",
      "Sam Shleifer",
      "Kurt Shuster",
      "Daniel Simig",
      "Punit Singh Koura",
      "Anjali Sridhar",
      "Tianlu Wang",
      "Luke Zettlemoyer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01068"
  },
  {
    "id": "arXiv:2205.01265",
    "title": "From {Solution Synthesis} to {Student Attempt Synthesis} for Block-Based  Visual Programming Tasks",
    "abstract": "Comments: Longer version of EDM 2022 paper",
    "descriptor": "\nComments: Longer version of EDM 2022 paper\n",
    "authors": [
      "Adish Singla",
      "Nikitas Theodoropoulos"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01265"
  },
  {
    "id": "arXiv:2205.01449",
    "title": "Does a Program Yield the Right Distribution? Verifying Probabilistic  Programs via Generating Functions",
    "abstract": "Comments: Full version of CAV2022 paper including an appendix with proofs and further material",
    "descriptor": "\nComments: Full version of CAV2022 paper including an appendix with proofs and further material\n",
    "authors": [
      "Mingshuai Chen",
      "Joost-Pieter Katoen",
      "Lutz Klinkenberg",
      "Tobias Winkler"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2205.01449"
  },
  {
    "id": "arXiv:2205.01929",
    "title": "Explain to Not Forget: Defending Against Catastrophic Forgetting with  XAI",
    "abstract": "Comments: 14 pages including appendix, 5 figures, 2 tables, 1 algorithm listing. v2 update increases figure readability, updates Fig 5 caption, adds our collaborators Dario and An as co-authors v3 brings the preprint in line with the final version accepted for peer-reviewed publication at CD-MAKE 2022",
    "descriptor": "\nComments: 14 pages including appendix, 5 figures, 2 tables, 1 algorithm listing. v2 update increases figure readability, updates Fig 5 caption, adds our collaborators Dario and An as co-authors v3 brings the preprint in line with the final version accepted for peer-reviewed publication at CD-MAKE 2022\n",
    "authors": [
      "Sami Ede",
      "Serop Baghdadlian",
      "Leander Weber",
      "An Nguyen",
      "Dario Zanca",
      "Wojciech Samek",
      "Sebastian Lapuschkin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01929"
  },
  {
    "id": "arXiv:2205.01945",
    "title": "Optimal Network Charge for Peer-to-Peer Energy Trading: A Grid  Perspective",
    "abstract": "Comments: 12 pages, 16 figures",
    "descriptor": "\nComments: 12 pages, 16 figures\n",
    "authors": [
      "Yu Yang",
      "Yue Chen",
      "Guoqiang Hu",
      "Costas J. Spanos"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2205.01945"
  },
  {
    "id": "arXiv:2205.01951",
    "title": "Proximal ADMM for Nonconvex and Nonsmooth Optimization",
    "abstract": "Comments: 15 pges, 3 figures",
    "descriptor": "\nComments: 15 pges, 3 figures\n",
    "authors": [
      "Yu Yang",
      "Qing-Shan Jia",
      "Zhanbo Xu",
      "Xiaohong Guan",
      "Costas J. Spanos"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2205.01951"
  },
  {
    "id": "arXiv:2205.02131",
    "title": "Domino Saliency Metrics: Improving Existing Channel Saliency Metrics  with Structural Information",
    "abstract": "Domino Saliency Metrics: Improving Existing Channel Saliency Metrics  with Structural Information",
    "descriptor": "",
    "authors": [
      "Kaveena Persand",
      "Andrew Anderson",
      "David Gregg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.02131"
  },
  {
    "id": "arXiv:2205.02428",
    "title": "HARL: A Novel Hierachical Adversary Reinforcement Learning for  Automoumous Intersection Management",
    "abstract": "HARL: A Novel Hierachical Adversary Reinforcement Learning for  Automoumous Intersection Management",
    "descriptor": "",
    "authors": [
      "Guanzhou Li",
      "Jianping Wu",
      "Yujing He"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.02428"
  },
  {
    "id": "arXiv:2205.02450",
    "title": "Pessimism meets VCG: Learning Dynamic Mechanism Design via Offline  Reinforcement Learning",
    "abstract": "Comments: 52 pages",
    "descriptor": "\nComments: 52 pages\n",
    "authors": [
      "Boxiang Lyu",
      "Zhaoran Wang",
      "Mladen Kolar",
      "Zhuoran Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.02450"
  },
  {
    "id": "arXiv:2205.02931",
    "title": "Spectral Methods for capillary surfaces described by bounded generating  curves",
    "abstract": "Comments: 22 pages, 8 figures, 5 tables",
    "descriptor": "\nComments: 22 pages, 8 figures, 5 tables\n",
    "authors": [
      "Ray Treinen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.02931"
  },
  {
    "id": "arXiv:2205.02976",
    "title": "Variance Reduction based Partial Trajectory Reuse to Accelerate Policy  Gradient Optimization",
    "abstract": "Comments: 12 pages, 5 figures",
    "descriptor": "\nComments: 12 pages, 5 figures\n",
    "authors": [
      "Hua Zheng",
      "Wei Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.02976"
  },
  {
    "id": "arXiv:2205.03068",
    "title": "Characterizing Multi-Domain False News and Underlying User Effects on  Chinese Weibo",
    "abstract": "Comments: 22 pages, 5 figures, and 12 tables. Accepted by Information Processing and Management (IP&M)",
    "descriptor": "\nComments: 22 pages, 5 figures, and 12 tables. Accepted by Information Processing and Management (IP&M)\n",
    "authors": [
      "Qiang Sheng",
      "Juan Cao",
      "H. Russell Bernard",
      "Kai Shu",
      "Jintao Li",
      "Huan Liu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2205.03068"
  },
  {
    "id": "arXiv:2205.03296",
    "title": "Disentangled Learning of Stance and Aspect Topics for Vaccine Attitude  Detection in Social Media",
    "abstract": "Disentangled Learning of Stance and Aspect Topics for Vaccine Attitude  Detection in Social Media",
    "descriptor": "",
    "authors": [
      "Lixing Zhu",
      "Zheng Fang",
      "Gabriele Pergola",
      "Rob Procter",
      "Yulan He"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.03296"
  },
  {
    "id": "arXiv:2205.03433",
    "title": "Vocalsound: A Dataset for Improving Human Vocal Sounds Recognition",
    "abstract": "Comments: Accepted at ICASSP 2022. Dataset and code at this https URL Interactive Colab demo at this https URL",
    "descriptor": "\nComments: Accepted at ICASSP 2022. Dataset and code at this https URL Interactive Colab demo at this https URL\n",
    "authors": [
      "Yuan Gong",
      "Jin Yu",
      "James Glass"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2205.03433"
  },
  {
    "id": "arXiv:2205.03608",
    "title": "UniMorph 4.0: Universal Morphology",
    "abstract": "Comments: LREC 2022; The first two authors made equal contributions",
    "descriptor": "\nComments: LREC 2022; The first two authors made equal contributions\n",
    "authors": [
      "Khuyagbaatar Batsuren",
      "Omer Goldman",
      "Salam Khalifa",
      "Nizar Habash",
      "Witold Kiera\u015b",
      "G\u00e1bor Bella",
      "Brian Leonard",
      "Garrett Nicolai",
      "Kyle Gorman",
      "Yustinus Ghanggo Ate",
      "Maria Ryskina",
      "Sabrina J. Mielke",
      "Elena Budianskaya",
      "Charbel El-Khaissi",
      "Tiago Pimentel",
      "Michael Gasser",
      "William Lane",
      "Mohit Raj",
      "Matt Coler",
      "Jaime Rafael Montoya Samame",
      "Delio Siticonatzi Camaiteri",
      "Beno\u00eet Sagot",
      "Esa\u00fa Zumaeta Rojas",
      "Didier L\u00f3pez Francis",
      "Arturo Oncevay",
      "Juan L\u00f3pez Bautista",
      "Gema Celeste Silva Villegas",
      "Lucas Torroba Hennigen",
      "Adam Ek",
      "David Guriel",
      "Peter Dirix",
      "Jean-Philippe Bernardy",
      "Andrey Scherbakov",
      "Aziyana Bayyr-ool",
      "Antonios Anastasopoulos",
      "Roberto Zariquiey",
      "Karina Sheifer",
      "Sofya Ganieva",
      "Hilaria Cruz",
      "Ritv\u00e1n Karah\u00f3\u01e7a",
      "Stella Markantonatou",
      "George Pavlidis",
      "Matvey Plugaryov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.03608"
  },
  {
    "id": "arXiv:2205.03949",
    "title": "Turing machine interaction problem",
    "abstract": "Comments: in Russian",
    "descriptor": "\nComments: in Russian\n",
    "authors": [
      "Marsel Matdinov"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2205.03949"
  },
  {
    "id": "arXiv:2205.04309",
    "title": "Characterizing Positionality in Games of Infinite Duration over Infinite  Graphs",
    "abstract": "Comments: 43 pages, 20 figures",
    "descriptor": "\nComments: 43 pages, 20 figures\n",
    "authors": [
      "Pierre Ohlmann"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2205.04309"
  },
  {
    "id": "arXiv:2205.04321",
    "title": "Evaluating the Fairness Impact of Differentially Private Synthetic Data",
    "abstract": "Evaluating the Fairness Impact of Differentially Private Synthetic Data",
    "descriptor": "",
    "authors": [
      "Blake Bullwinkel",
      "Kristen Grabarz",
      "Lily Ke",
      "Scarlett Gong",
      "Chris Tanner",
      "Joshua Allen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.04321"
  },
  {
    "id": "arXiv:2205.05227",
    "title": "Towards Improved Zero-shot Voice Conversion with Conditional DSVAE",
    "abstract": "Comments: Accepted to 2022 Interspeech. Demo link is here this https URL",
    "descriptor": "\nComments: Accepted to 2022 Interspeech. Demo link is here this https URL\n",
    "authors": [
      "Jiachen Lian",
      "Chunlei Zhang",
      "Gopala Krishna Anumanchipalli",
      "Dong Yu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2205.05227"
  },
  {
    "id": "arXiv:2205.05282",
    "title": "ReFine: Re-randomization before Fine-tuning for Cross-domain Few-shot  Learning",
    "abstract": "Comments: ICML 2022 Workshop on Updatable Machine Learning; 8 pages, 3 figures, 7 tables",
    "descriptor": "\nComments: ICML 2022 Workshop on Updatable Machine Learning; 8 pages, 3 figures, 7 tables\n",
    "authors": [
      "Jaehoon Oh",
      "Sungnyun Kim",
      "Namgyu Ho",
      "Jin-Hwa Kim",
      "Hwanjun Song",
      "Se-Young Yun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.05282"
  },
  {
    "id": "arXiv:2205.05424",
    "title": "\"If it didn't happen, why would I change my decision?\": How Judges  Respond to Counterfactual Explanations for the Public Safety Assessment",
    "abstract": "Comments: Accepted at CHI'22 Workshop on Human-Centered Perspectives in Explainable AI (HCXAI)",
    "descriptor": "\nComments: Accepted at CHI'22 Workshop on Human-Centered Perspectives in Explainable AI (HCXAI)\n",
    "authors": [
      "Yaniv Yacoby",
      "Ben Green",
      "Christopher L. Griffin",
      "Finale Doshi Velez"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2205.05424"
  },
  {
    "id": "arXiv:2205.05512",
    "title": "Is calibration a fairness requirement? An argument from the point of  view of moral philosophy and decision theory",
    "abstract": "Comments: Changes relative to the Conference version:(a) footnote 9 and 13 revealing a hidden assumption and correcting the expected utility formula for the case in which the assumption does not hold; (b) a mathematical proof of the main thesis for the case in which the assumption is relaxed",
    "descriptor": "\nComments: Changes relative to the Conference version:(a) footnote 9 and 13 revealing a hidden assumption and correcting the expected utility formula for the case in which the assumption does not hold; (b) a mathematical proof of the main thesis for the case in which the assumption is relaxed\n",
    "authors": [
      "Michele Loi",
      "Christoph Heitz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2205.05512"
  },
  {
    "id": "arXiv:2205.06727",
    "title": "The energy return on investment of whole energy systems: application to  Belgium",
    "abstract": "Comments: Paper submitted to Biophysical Economics and Sustainability for possible review",
    "descriptor": "\nComments: Paper submitted to Biophysical Economics and Sustainability for possible review\n",
    "authors": [
      "Jonathan Dumas",
      "Antoine Dubois",
      "Paolo Thiran",
      "Pierre Jacques",
      "Francesco Contino",
      "Bertrand Corn\u00e9lusse",
      "Gauthier Limpens"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.06727"
  },
  {
    "id": "arXiv:2205.07546",
    "title": "Finite-horizon Equilibria for Neuro-symbolic Concurrent Stochastic Games",
    "abstract": "Comments: 14 pages, 7 figures",
    "descriptor": "\nComments: 14 pages, 7 figures\n",
    "authors": [
      "Rui Yan",
      "Gabriel Santos",
      "Xiaoming Duan",
      "David Parker",
      "Marta Kwiatkowska"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2205.07546"
  },
  {
    "id": "arXiv:2205.07709",
    "title": "Polynomial formulations as a barrier for reduction-based hardness proofs",
    "abstract": "Polynomial formulations as a barrier for reduction-based hardness proofs",
    "descriptor": "",
    "authors": [
      "Alexander S. Kulikov",
      "Ivan Mihajlin"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2205.07709"
  },
  {
    "id": "arXiv:2205.07862",
    "title": "A Safety Assurable Human-Inspired Perception Architecture",
    "abstract": "A Safety Assurable Human-Inspired Perception Architecture",
    "descriptor": "",
    "authors": [
      "Rick Salay",
      "Krzysztof Czarnecki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.07862"
  },
  {
    "id": "arXiv:2205.07873",
    "title": "HDR Lighting Dilation for Dynamic Range Reduction on Virtual Production  Stages",
    "abstract": "HDR Lighting Dilation for Dynamic Range Reduction on Virtual Production  Stages",
    "descriptor": "",
    "authors": [
      "Paul Debevec",
      "Chloe LeGendre"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2205.07873"
  },
  {
    "id": "arXiv:2205.08243",
    "title": "IIsy: Practical In-Network Classification",
    "abstract": "Comments: (14 pages body, 19 pages total, 19 figures)",
    "descriptor": "\nComments: (14 pages body, 19 pages total, 19 figures)\n",
    "authors": [
      "Changgang Zheng",
      "Zhaoqi Xiong",
      "Thanh T Bui",
      "Siim Kaupmees",
      "Riyad Bensoussane",
      "Antoine Bernabeu",
      "Shay Vargaftik",
      "Yaniv Ben-Itzhak",
      "Noa Zilberman"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.08243"
  },
  {
    "id": "arXiv:2205.08601",
    "title": "Universal characteristics of deep neural network loss surfaces from  random matrix theory",
    "abstract": "Comments: 42 pages",
    "descriptor": "\nComments: 42 pages\n",
    "authors": [
      "Nicholas P Baskerville",
      "Jonathan P Keating",
      "Francesco Mezzadri",
      "Joseph Najnudel",
      "Diego Granziol"
    ],
    "subjectives": [
      "Mathematical Physics (math-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.08601"
  },
  {
    "id": "arXiv:2205.09198",
    "title": "Macedonian Speech Synthesis for Assistive Technology Applications",
    "abstract": "Comments: 5 pages, 1 figure, EUSIPCO conference 2022",
    "descriptor": "\nComments: 5 pages, 1 figure, EUSIPCO conference 2022\n",
    "authors": [
      "Bojan Sofronievski",
      "Elena Velovska",
      "Martin Velichkovski",
      "Violeta Argirova",
      "Tea Veljkovikj",
      "Risto Chavdarov",
      "Stefan Janev",
      "Kristijan Lazarev",
      "Toni Bachvarovski",
      "Zoran Ivanovski",
      "Dimitar Tashkovski",
      "Branislav Gerazov"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2205.09198"
  },
  {
    "id": "arXiv:2205.09498",
    "title": "Demonstration of fully integrated parity-time-symmetric electronics",
    "abstract": "Comments: 62 pages (29 pages Main Text, 33 pages Supplementary Materials), 27 figures (4 figures Main Text, 23 figures Supplementary Materials), 96 references (50 references Main Text, 46 references Supplementary Materials)",
    "descriptor": "\nComments: 62 pages (29 pages Main Text, 33 pages Supplementary Materials), 27 figures (4 figures Main Text, 23 figures Supplementary Materials), 96 references (50 references Main Text, 46 references Supplementary Materials)\n",
    "authors": [
      "Weidong Cao",
      "Changqing Wang",
      "Weijian Chen",
      "Song Hu",
      "Hua Wang",
      "Lan Yang",
      "Xuan Zhang"
    ],
    "subjectives": [
      "Applied Physics (physics.app-ph)",
      "Hardware Architecture (cs.AR)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2205.09498"
  },
  {
    "id": "arXiv:2205.09923",
    "title": "Stability Enforced Bandit Algorithms for Channel Selection in Remote  State Estimation",
    "abstract": "Comments: Corrected proof of Theorem 4",
    "descriptor": "\nComments: Corrected proof of Theorem 4\n",
    "authors": [
      "Alex S. Leong",
      "Daniel E. Quevedo",
      "Wanchun Liu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.09923"
  },
  {
    "id": "arXiv:2205.10798",
    "title": "PAC-Wrap: Semi-Supervised PAC Anomaly Detection",
    "abstract": "Comments: Accepted by SIGKDD 2022",
    "descriptor": "\nComments: Accepted by SIGKDD 2022\n",
    "authors": [
      "Shuo Li",
      "Xiayan Ji",
      "Edgar Dobriban",
      "Oleg Sokolsky",
      "Insup Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.10798"
  },
  {
    "id": "arXiv:2205.11025",
    "title": "Flexible and Hierarchical Prior for Bayesian Nonnegative Matrix  Factorization",
    "abstract": "Flexible and Hierarchical Prior for Bayesian Nonnegative Matrix  Factorization",
    "descriptor": "",
    "authors": [
      "Jun Lu",
      "Xuanyu Ye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.11025"
  },
  {
    "id": "arXiv:2205.11273",
    "title": "GR-GAN: Gradual Refinement Text-to-image Generation",
    "abstract": "Comments: Accepted by ICME 2022",
    "descriptor": "\nComments: Accepted by ICME 2022\n",
    "authors": [
      "Bo Yang",
      "Fangxiang Feng",
      "Xiaojie Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.11273"
  },
  {
    "id": "arXiv:2205.11809",
    "title": "Learning to Assemble Geometric Shapes",
    "abstract": "Comments: 11 pages, 9 figures, 9 tables. Accepted at the 31st International Joint Conference on Artificial Intelligence (IJCAI 2022). J. Lee and J. Kim equally contributed",
    "descriptor": "\nComments: 11 pages, 9 figures, 9 tables. Accepted at the 31st International Joint Conference on Artificial Intelligence (IJCAI 2022). J. Lee and J. Kim equally contributed\n",
    "authors": [
      "Jinhwi Lee",
      "Jungtaek Kim",
      "Hyunsoo Chung",
      "Jaesik Park",
      "Minsu Cho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11809"
  },
  {
    "id": "arXiv:2205.12711",
    "title": "Service Discovery in Social Internet of Things using Graph Neural  Networks",
    "abstract": "Comments: Accepted for publications in the 65 IEEE International Midwest Symposium on Circuits and Systems (MWSCAS'22) 7 figures, 1 table, 5 pages",
    "descriptor": "\nComments: Accepted for publications in the 65 IEEE International Midwest Symposium on Circuits and Systems (MWSCAS'22) 7 figures, 1 table, 5 pages\n",
    "authors": [
      "Aymen Hamrouni",
      "Hakim Ghazzai",
      "Yehia Massoud"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2205.12711"
  },
  {
    "id": "arXiv:2205.13076",
    "title": "Entropy Maximization with Depth: A Variational Principle for Random  Neural Networks",
    "abstract": "Entropy Maximization with Depth: A Variational Principle for Random  Neural Networks",
    "descriptor": "",
    "authors": [
      "Amir Joudaki",
      "Hadi Daneshmand",
      "Francis Bach"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2205.13076"
  },
  {
    "id": "arXiv:2205.13718",
    "title": "Off-Beat Multi-Agent Reinforcement Learning",
    "abstract": "Comments: Fix typos",
    "descriptor": "\nComments: Fix typos\n",
    "authors": [
      "Wei Qiu",
      "Weixun Wang",
      "Rundong Wang",
      "Bo An",
      "Yujing Hu",
      "Svetlana Obraztsova",
      "Zinovi Rabinovich",
      "Jianye Hao",
      "Yingfeng Chen",
      "Changjie Fan"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.13718"
  },
  {
    "id": "arXiv:2205.14576",
    "title": "Problem-Space Evasion Attacks in the Android OS: a Survey",
    "abstract": "Problem-Space Evasion Attacks in the Android OS: a Survey",
    "descriptor": "",
    "authors": [
      "Harel Berger",
      "Chen Hajaj",
      "Amit Dvir"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.14576"
  },
  {
    "id": "arXiv:2205.14960",
    "title": "FedAUXfdp: Differentially Private One-Shot Federated Distillation",
    "abstract": "FedAUXfdp: Differentially Private One-Shot Federated Distillation",
    "descriptor": "",
    "authors": [
      "Haley Hoech",
      "Roman Rischke",
      "Karsten M\u00fcller",
      "Wojciech Samek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2205.14960"
  },
  {
    "id": "arXiv:2205.15322",
    "title": "Superposing Many Tickets into One: A Performance Booster for Sparse  Neural Network Training",
    "abstract": "Comments: 17 pages, 5 figures, accepted by the 38th Conference on Uncertainty in Artificial Intelligence (UAI)",
    "descriptor": "\nComments: 17 pages, 5 figures, accepted by the 38th Conference on Uncertainty in Artificial Intelligence (UAI)\n",
    "authors": [
      "Lu Yin",
      "Vlado Menkovski",
      "Meng Fang",
      "Tianjin Huang",
      "Yulong Pei",
      "Mykola Pechenizkiy",
      "Decebal Constantin Mocanu",
      "Shiwei Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.15322"
  },
  {
    "id": "arXiv:2205.15670",
    "title": "REF: A Rapid Exploration Framework for Deploying Autonomous MAVs in  Unknown Environments",
    "abstract": "Comments: The paper has major flaws in manuscripts and result sections. Leads to incorrect conclusion. Untill new experiments are conducted and the manuscript is updated, I request the system to let me withdraw the paper because it is not ethical to have flawed manuscript accessable to research community. Thank you for the understanding and consideration",
    "descriptor": "\nComments: The paper has major flaws in manuscripts and result sections. Leads to incorrect conclusion. Untill new experiments are conducted and the manuscript is updated, I request the system to let me withdraw the paper because it is not ethical to have flawed manuscript accessable to research community. Thank you for the understanding and consideration\n",
    "authors": [
      "Akash Patel",
      "Bj\u00f6rn Lindqvist",
      "Christoforos Kanellakis",
      "Ali-akbar Agha-mohammadi",
      "George Nikolakopoulos"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.15670"
  },
  {
    "id": "arXiv:2205.15691",
    "title": "Fast-Spanning Ant Colony Optimisation (FaSACO) for Mobile Robot Coverage  Path Planning",
    "abstract": "Comments: 7 pages",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Christopher Carr",
      "Peng Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.15691"
  },
  {
    "id": "arXiv:2205.15987",
    "title": "Semi-Supervised Cross-Silo Advertising with Partial Knowledge Transfer",
    "abstract": "Comments: Accepted to the Trustworthy Federated Learning workshop of IJCAI2022 (FL-IJCAI22). 6 pages, 3 figures, 3 tables",
    "descriptor": "\nComments: Accepted to the Trustworthy Federated Learning workshop of IJCAI2022 (FL-IJCAI22). 6 pages, 3 figures, 3 tables\n",
    "authors": [
      "Wenjie Li",
      "Qiaolin Xia",
      "Junfeng Deng",
      "Hao Cheng",
      "Jiangming Liu",
      "Kouying Xue",
      "Yong Cheng",
      "Shu-Tao Xia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2205.15987"
  },
  {
    "id": "arXiv:2206.00533",
    "title": "When happy accidents spark creativity: Bringing collaborative  speculation to life with generative AI",
    "abstract": "When happy accidents spark creativity: Bringing collaborative  speculation to life with generative AI",
    "descriptor": "",
    "authors": [
      "Ziv Epstein",
      "Hope Schroeder",
      "Dava Newman"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.00533"
  },
  {
    "id": "arXiv:2206.00790",
    "title": "Efficient Self-supervised Vision Pretraining with Local Masked  Reconstruction",
    "abstract": "Comments: Add code",
    "descriptor": "\nComments: Add code\n",
    "authors": [
      "Jun Chen",
      "Ming Hu",
      "Boyang Li",
      "Mohamed Elhoseiny"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.00790"
  },
  {
    "id": "arXiv:2206.00801",
    "title": "Indeterminacy in Latent Variable Models: Characterization and Strong  Identifiability",
    "abstract": "Comments: 40 pages, 2 figures. Version 2 fixes formatting and equation numbering",
    "descriptor": "\nComments: 40 pages, 2 figures. Version 2 fixes formatting and equation numbering\n",
    "authors": [
      "Quanhan Xi",
      "Benjamin Bloem-Reddy"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00801"
  },
  {
    "id": "arXiv:2206.00934",
    "title": "Deep neural networks can stably solve high-dimensional, noisy,  non-linear inverse problems",
    "abstract": "Deep neural networks can stably solve high-dimensional, noisy,  non-linear inverse problems",
    "descriptor": "",
    "authors": [
      "Andr\u00e9s Felipe Lerma Pineda",
      "Philipp Christian Petersen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.00934"
  },
  {
    "id": "arXiv:2206.01663",
    "title": "Joint Energy Dispatch and Unit Commitment in Microgrids Based on Deep  Reinforcement Learning",
    "abstract": "Comments: Our system model needs to be modified by two time-scale processing. Therefore, the experimental results also need to be updated",
    "descriptor": "\nComments: Our system model needs to be modified by two time-scale processing. Therefore, the experimental results also need to be updated\n",
    "authors": [
      "Jiaju Qi",
      "Lei Lei",
      "Kan Zheng",
      "Simon X. Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2206.01663"
  },
  {
    "id": "arXiv:2206.01737",
    "title": "MaxStyle: Adversarial Style Composition for Robust Medical Image  Segmentation",
    "abstract": "Comments: Early accepted by MICCAI 2022 (Camera-ready version)",
    "descriptor": "\nComments: Early accepted by MICCAI 2022 (Camera-ready version)\n",
    "authors": [
      "Chen Chen",
      "Zeju Li",
      "Cheng Ouyang",
      "Matt Sinclair",
      "Wenjia Bai",
      "Daniel Rueckert"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2206.01737"
  },
  {
    "id": "arXiv:2206.01857",
    "title": "Design and Implementation of an Heuristic-Enhanced Branch-and-Bound  Solver for MILP",
    "abstract": "Comments: 10 pages, 1 figure, 4 tables, MIP 2022 competition",
    "descriptor": "\nComments: 10 pages, 1 figure, 4 tables, MIP 2022 competition\n",
    "authors": [
      "Warley Almeida Silva",
      "Federico Bobbio",
      "Flore Caye",
      "Defeng Liu",
      "Justine Pepin",
      "Carl Perreault-Lafleur",
      "William St-Arnaud"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.01857"
  },
  {
    "id": "arXiv:2206.02498",
    "title": "NORPPA: NOvel Ringed seal re-identification by Pelage Pattern  Aggregation",
    "abstract": "Comments: 22 pages, 13 figures, 5 tables",
    "descriptor": "\nComments: 22 pages, 13 figures, 5 tables\n",
    "authors": [
      "Ekaterina Nepovinnykh",
      "Ilia Chelak",
      "Tuomas Eerola",
      "Heikki K\u00e4lvi\u00e4inen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02498"
  },
  {
    "id": "arXiv:2206.03044",
    "title": "CAISAR: A platform for Characterizing Artificial Intelligence Safety and  Robustness",
    "abstract": "CAISAR: A platform for Characterizing Artificial Intelligence Safety and  Robustness",
    "descriptor": "",
    "authors": [
      "Julien Girard-Satabin",
      "Michele Alberti",
      "Fran\u00e7ois Bobot",
      "Zakaria Chihani",
      "Augustin Lemesle"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.03044"
  },
  {
    "id": "arXiv:2206.03181",
    "title": "Detecting Global Community Structure in a COVID-19 Activity Correlation  Network",
    "abstract": "Comments: 11 pages, 4 figures, 1 table",
    "descriptor": "\nComments: 11 pages, 4 figures, 1 table\n",
    "authors": [
      "Hiroki Sayama"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.03181"
  },
  {
    "id": "arXiv:2206.03192",
    "title": "Generalized Data Distribution Iteration",
    "abstract": "Comments: 82 pages. This article is an extended work of arXiv:2112.04145 and arXiv:2106.06232. This article draws heavily from arXiv:2112.04145 and arXiv:2106.06232. We hope that adding some of the views from arXiv:2112.04145 and arXiv:2106.06232 into the appendix could greatly improve the readability",
    "descriptor": "\nComments: 82 pages. This article is an extended work of arXiv:2112.04145 and arXiv:2106.06232. This article draws heavily from arXiv:2112.04145 and arXiv:2106.06232. We hope that adding some of the views from arXiv:2112.04145 and arXiv:2106.06232 into the appendix could greatly improve the readability\n",
    "authors": [
      "Jiajun Fan",
      "Changnan Xiao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.03192"
  },
  {
    "id": "arXiv:2206.03356",
    "title": "Position Paper: Online Modeling for Offline Planning",
    "abstract": "Position Paper: Online Modeling for Offline Planning",
    "descriptor": "",
    "authors": [
      "Eyal Weiss",
      "Gal A. Kaminka"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.03356"
  },
  {
    "id": "arXiv:2206.03436",
    "title": "A Benchmark for Federated Hetero-Task Learning",
    "abstract": "A Benchmark for Federated Hetero-Task Learning",
    "descriptor": "",
    "authors": [
      "Liuyi Yao",
      "Dawei Gao",
      "Zhen Wang",
      "Yuexiang Xie",
      "Weirui Kuang",
      "Daoyuan Chen",
      "Haohui Wang",
      "Chenhe Dong",
      "Bolin Ding",
      "Yaliang Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03436"
  },
  {
    "id": "arXiv:2206.03761",
    "title": "A Survey on the Fairness of Recommender Systems",
    "abstract": "Comments: Submitted to the Special Section on Trustworthy Recommendation and Search of ACM TOIS on March 27, 2022 and accepted on June 6",
    "descriptor": "\nComments: Submitted to the Special Section on Trustworthy Recommendation and Search of ACM TOIS on March 27, 2022 and accepted on June 6\n",
    "authors": [
      "Yifan Wang",
      "Weizhi Ma",
      "Min Zhang",
      "Yiqun Liu",
      "Shaoping Ma"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.03761"
  },
  {
    "id": "arXiv:2206.03820",
    "title": "SUPER-IVIM-DC: Intra-voxel incoherent motion based Fetal lung maturity  assessment from limited DWI data using supervised learning coupled with  data-consistency",
    "abstract": "SUPER-IVIM-DC: Intra-voxel incoherent motion based Fetal lung maturity  assessment from limited DWI data using supervised learning coupled with  data-consistency",
    "descriptor": "",
    "authors": [
      "Noam Korngut",
      "Elad Rotman",
      "Onur Afacan",
      "Sila Kurugol",
      "Yael Zaffrani-Reznikov",
      "Shira Nemirovsky-Rotman",
      "Simon Warfield",
      "Moti Freiman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.03820"
  },
  {
    "id": "arXiv:2206.03915",
    "title": "Anderson acceleration with approximate calculations: applications to  scientific computing",
    "abstract": "Comments: 21 pages, 3 figures, 1 table",
    "descriptor": "\nComments: 21 pages, 3 figures, 1 table\n",
    "authors": [
      "Massimiliano Lupo Pasini",
      "M. Paul Laiu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.03915"
  },
  {
    "id": "arXiv:2206.03966",
    "title": "FedHPO-B: A Benchmark Suite for Federated Hyperparameter Optimization",
    "abstract": "FedHPO-B: A Benchmark Suite for Federated Hyperparameter Optimization",
    "descriptor": "",
    "authors": [
      "Zhen Wang",
      "Weirui Kuang",
      "Ce Zhang",
      "Bolin Ding",
      "Yaliang Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03966"
  },
  {
    "id": "arXiv:2206.04003",
    "title": "Patch-based Object-centric Transformers for Efficient Video Generation",
    "abstract": "Comments: Project Website: this https URL",
    "descriptor": "\nComments: Project Website: this https URL\n",
    "authors": [
      "Wilson Yan",
      "Ryo Okumura",
      "Stephen James",
      "Pieter Abbeel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04003"
  },
  {
    "id": "arXiv:2206.04502",
    "title": "What is a Good Metric to Study Generalization of Minimax Learners?",
    "abstract": "Comments: 34 pages, 2 figures",
    "descriptor": "\nComments: 34 pages, 2 figures\n",
    "authors": [
      "Asuman Ozdaglar",
      "Sarath Pattathil",
      "Jiawei Zhang",
      "Kaiqing Zhang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.04502"
  },
  {
    "id": "arXiv:2206.04585",
    "title": "Extracting Zero-shot Common Sense from Large Language Models for Robot  3D Scene Understanding",
    "abstract": "Comments: 4 pages (excluding references and appendix), 2 figures, 2 tables. Submitted to Robotics: Science and Systems 2022 2nd Workshop on Scaling Robot Learning. Corrected typos and notation",
    "descriptor": "\nComments: 4 pages (excluding references and appendix), 2 figures, 2 tables. Submitted to Robotics: Science and Systems 2022 2nd Workshop on Scaling Robot Learning. Corrected typos and notation\n",
    "authors": [
      "William Chen",
      "Siyi Hu",
      "Rajat Talak",
      "Luca Carlone"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.04585"
  },
  {
    "id": "arXiv:2206.04827",
    "title": "A Fast Spectral Solver for the Heat Equation, with Applications to  Navier-Stokes",
    "abstract": "Comments: 18 pages, 3 figures. Submitted to SIURO for publication",
    "descriptor": "\nComments: 18 pages, 3 figures. Submitted to SIURO for publication\n",
    "authors": [
      "David Darrow"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2206.04827"
  },
  {
    "id": "arXiv:2206.04959",
    "title": "Merak: An Efficient Distributed DNN Training Framework with Automated 3D  Parallelism for Giant Foundation Models",
    "abstract": "Merak: An Efficient Distributed DNN Training Framework with Automated 3D  Parallelism for Giant Foundation Models",
    "descriptor": "",
    "authors": [
      "Zhiquan Lai",
      "Shengwei Li",
      "Xudong Tang",
      "Keshi Ge",
      "Weijie Liu",
      "Yabo Duan",
      "Linbo Qiao",
      "Dongsheng Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2206.04959"
  },
  {
    "id": "arXiv:2206.05033",
    "title": "Solution of DeBERTaV3 on CommonsenseQA",
    "abstract": "Solution of DeBERTaV3 on CommonsenseQA",
    "descriptor": "",
    "authors": [
      "Letian Peng",
      "Zuchao Li",
      "Hai Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.05033"
  },
  {
    "id": "arXiv:2206.05107",
    "title": "A Reddit Dataset for the Russo-Ukrainian Conflict in 2022",
    "abstract": "A Reddit Dataset for the Russo-Ukrainian Conflict in 2022",
    "descriptor": "",
    "authors": [
      "Yiming Zhu",
      "Ehsan-ul Haq",
      "Lik-Hang Lee",
      "Gareth Tyson",
      "Pan Hui"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.05107"
  },
  {
    "id": "arXiv:2206.05123",
    "title": "REKnow: Enhanced Knowledge for Joint Entity and Relation Extraction",
    "abstract": "REKnow: Enhanced Knowledge for Joint Entity and Relation Extraction",
    "descriptor": "",
    "authors": [
      "Sheng Zhang",
      "Patrick Ng",
      "Zhiguo Wang",
      "Bing Xiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.05123"
  },
  {
    "id": "arXiv:2206.05240",
    "title": "ROI-Constrained Bidding via Curriculum-Guided Bayesian Reinforcement  Learning",
    "abstract": "Comments: Accepted by SIGKDD 2022",
    "descriptor": "\nComments: Accepted by SIGKDD 2022\n",
    "authors": [
      "Haozhe Wang",
      "Chao Du",
      "Panyan Fang",
      "Shuo Yuan",
      "Xuming He",
      "Liang Wang",
      "Bo Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.05240"
  },
  {
    "id": "arXiv:2206.05286",
    "title": "AHD ConvNet for Speech Emotion Classification",
    "abstract": "Comments: Wrong authors quoted",
    "descriptor": "\nComments: Wrong authors quoted\n",
    "authors": [
      "Asfand Ali",
      "Danial Nasir",
      "Mohammad Hassan Jawad"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.05286"
  },
  {
    "id": "arXiv:2206.05483",
    "title": "Bilateral Dependency Optimization: Defending Against Model-inversion  Attacks",
    "abstract": "Comments: Accepted to KDD 2022 (Research Track)",
    "descriptor": "\nComments: Accepted to KDD 2022 (Research Track)\n",
    "authors": [
      "Xiong Peng",
      "Feng Liu",
      "Jingfen Zhang",
      "Long Lan",
      "Junjie Ye",
      "Tongliang Liu",
      "Bo Han"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05483"
  },
  {
    "id": "arXiv:2206.05520",
    "title": "A Two-stage Method for Non-extreme Value Salt-and-Pepper Noise Removal",
    "abstract": "Comments: UESTC course project",
    "descriptor": "\nComments: UESTC course project\n",
    "authors": [
      "Renwei Yang",
      "YiKe Liu",
      "Bing Zeng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.05520"
  },
  {
    "id": "arXiv:2206.05630",
    "title": "Mathematical Theory of Bayesian Statistics for Unknown Information  Source",
    "abstract": "Mathematical Theory of Bayesian Statistics for Unknown Information  Source",
    "descriptor": "",
    "authors": [
      "Sumio Watanabe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2206.05630"
  },
  {
    "id": "arXiv:2206.05649",
    "title": "TileGen: Tileable, Controllable Material Generation and Capture",
    "abstract": "Comments: 18 pages, 19 figures",
    "descriptor": "\nComments: 18 pages, 19 figures\n",
    "authors": [
      "Xilong Zhou",
      "Milo\u0161 Ha\u0161an",
      "Valentin Deschaintre",
      "Paul Guerrero",
      "Kalyan Sunkavalli",
      "Nima Kalantari"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.05649"
  },
  {
    "id": "arXiv:2206.05687",
    "title": "DRNet: Decomposition and Reconstruction Network for Remote Physiological  Measurement",
    "abstract": "DRNet: Decomposition and Reconstruction Network for Remote Physiological  Measurement",
    "descriptor": "",
    "authors": [
      "Yuhang Dong",
      "Gongping Yang",
      "Yilong Yin"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.05687"
  },
  {
    "id": "arXiv:2206.05703",
    "title": "PAC-Net: A Model Pruning Approach to Inductive Transfer Learning",
    "abstract": "Comments: In Proceedings of the 39th International Conference on Machine Learning, Baltimore, Maryland, USA, PMLR 162, 2022",
    "descriptor": "\nComments: In Proceedings of the 39th International Conference on Machine Learning, Baltimore, Maryland, USA, PMLR 162, 2022\n",
    "authors": [
      "Sanghoon Myung",
      "In Huh",
      "Wonik Jang",
      "Jae Myung Choe",
      "Jisu Ryu",
      "Dae Sin Kim",
      "Kee-Eung Kim",
      "Changwook Jeong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Physics (physics.comp-ph)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.05703"
  },
  {
    "id": "arXiv:2206.05807",
    "title": "Over-Generation Cannot Be Rewarded: Length-Adaptive Average Lagging for  Simultaneous Speech Translation",
    "abstract": "Comments: AutoSimTrans Workshop @ NAACL2022",
    "descriptor": "\nComments: AutoSimTrans Workshop @ NAACL2022\n",
    "authors": [
      "Sara Papi",
      "Marco Gaido",
      "Matteo Negri",
      "Marco Turchi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.05807"
  },
  {
    "id": "arXiv:2206.05862",
    "title": "X-Risk Analysis for AI Research",
    "abstract": "X-Risk Analysis for AI Research",
    "descriptor": "",
    "authors": [
      "Dan Hendrycks",
      "Mantas Mazeika"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.05862"
  },
  {
    "id": "arXiv:2206.05952",
    "title": "SIXO: Smoothing Inference with Twisted Objectives",
    "abstract": "Comments: v2: Updates for clarity throughout. Results unchanged",
    "descriptor": "\nComments: v2: Updates for clarity throughout. Results unchanged\n",
    "authors": [
      "Dieterich Lawson",
      "Allan Ravent\u00f3s",
      "Andrew Warrington",
      "Scott Linderman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.05952"
  },
  {
    "id": "arXiv:2206.06258",
    "title": "Featurized Query R-CNN",
    "abstract": "Comments: Tech Report",
    "descriptor": "\nComments: Tech Report\n",
    "authors": [
      "Wenqiang Zhang",
      "Tianheng Cheng",
      "Xinggang Wang",
      "Shaoyu Chen",
      "Qian Zhang",
      "Wenyu Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06258"
  },
  {
    "id": "arXiv:2206.06274",
    "title": "Lalaine: Measuring and Characterizing Non-Compliance of Apple Privacy  Labels at Scale",
    "abstract": "Lalaine: Measuring and Characterizing Non-Compliance of Apple Privacy  Labels at Scale",
    "descriptor": "",
    "authors": [
      "Yue Xiao",
      "Zhengyi Li",
      "Yue Qin",
      "Xiaolong Bai",
      "Jiale Guan",
      "Xiaojing Liao",
      "Luyi Xing"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.06274"
  },
  {
    "id": "arXiv:2206.06468",
    "title": "Stable Relationships",
    "abstract": "Stable Relationships",
    "descriptor": "",
    "authors": [
      "Sam Ganzfried"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.06468"
  },
  {
    "id": "arXiv:2206.06561",
    "title": "FreeKD: Free-direction Knowledge Distillation for Graph Neural Networks",
    "abstract": "Comments: Accepted to KDD 2022",
    "descriptor": "\nComments: Accepted to KDD 2022\n",
    "authors": [
      "Kaituo Feng",
      "Changsheng Li",
      "Ye Yuan",
      "Guoren Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06561"
  },
  {
    "id": "arXiv:2206.06584",
    "title": "Probabilistic Conformal Prediction Using Conditional Random Samples",
    "abstract": "Probabilistic Conformal Prediction Using Conditional Random Samples",
    "descriptor": "",
    "authors": [
      "Zhendong Wang",
      "Ruijiang Gao",
      "Mingzhang Yin",
      "Mingyuan Zhou",
      "David M. Blei"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2206.06584"
  },
  {
    "id": "arXiv:2206.06665",
    "title": "Online Easy Example Mining for Weakly-supervised Gland Segmentation from  Histology Images",
    "abstract": "Comments: MICCAI 2022 Accepeted",
    "descriptor": "\nComments: MICCAI 2022 Accepeted\n",
    "authors": [
      "Yi Li",
      "Yiduo Yu",
      "Yiwen Zou",
      "Tianqi Xiang",
      "Xiaomeng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.06665"
  },
  {
    "id": "arXiv:2206.06677",
    "title": "Abstraction-Based Segmental Simulation of Chemical Reaction Networks",
    "abstract": "Comments: Accepted to Computational Methods in Systems Biology 2022",
    "descriptor": "\nComments: Accepted to Computational Methods in Systems Biology 2022\n",
    "authors": [
      "Martin Helfrich",
      "Milan \u010ce\u0161ka",
      "Jan K\u0159et\u00ednsk\u00fd",
      "\u0160tefan Marti\u010dek"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.06677"
  },
  {
    "id": "arXiv:2206.06680",
    "title": "Exploring speaker enrolment for few-shot personalisation in emotional  vocalisation prediction",
    "abstract": "Comments: Proceedings of the ICML Expressive Vocalizations Workshop and Competition held in conjunction with the $\\mathit{39}^{th}$ International Conference on Machine Learning, Copyright 2022 by the author(s)",
    "descriptor": "\nComments: Proceedings of the ICML Expressive Vocalizations Workshop and Competition held in conjunction with the $\\mathit{39}^{th}$ International Conference on Machine Learning, Copyright 2022 by the author(s)\n",
    "authors": [
      "Andreas Triantafyllopoulos",
      "Meishu Song",
      "Zijiang Yang",
      "Xin Jing",
      "Bj\u00f6rn W. Schuller"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.06680"
  },
  {
    "id": "arXiv:2206.06701",
    "title": "CNN-based Classification Framework for Lung Tissues with Auxiliary  Information",
    "abstract": "CNN-based Classification Framework for Lung Tissues with Auxiliary  Information",
    "descriptor": "",
    "authors": [
      "Huafeng Hu",
      "Ruijie Ye",
      "Jeyarajan Thiyagalingam",
      "Frans Coenen",
      "Jionglong Su"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06701"
  },
  {
    "id": "arXiv:2206.06803",
    "title": "Asymmetric Dual-Decoder U-Net for Joint Rain and Haze Removal",
    "abstract": "Comments: 12 pages, 35 figures",
    "descriptor": "\nComments: 12 pages, 35 figures\n",
    "authors": [
      "Yuan Feng",
      "Yaojun Hu",
      "Pengfei Fang",
      "Yanhong Yang",
      "Sheng Liu",
      "Shengyong Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.06803"
  },
  {
    "id": "arXiv:2206.06811",
    "title": "Adversarial Audio Synthesis with Complex-valued Polynomial Networks",
    "abstract": "Comments: Accepted as oral presentation in Workshop on Machine Learning for Audio Synthesis at ICML 2022",
    "descriptor": "\nComments: Accepted as oral presentation in Workshop on Machine Learning for Audio Synthesis at ICML 2022\n",
    "authors": [
      "Yongtao Wu",
      "Grigorios G Chrysos",
      "Volkan Cevher"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06811"
  },
  {
    "id": "arXiv:2206.06849",
    "title": "On the Gauss-Manin Connection and Real Singularities",
    "abstract": "Comments: Calculation error in the proof of Theorem 5.1",
    "descriptor": "\nComments: Calculation error in the proof of Theorem 5.1\n",
    "authors": [
      "Lars Andersen"
    ],
    "subjectives": [
      "Algebraic Geometry (math.AG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.06849"
  },
  {
    "id": "arXiv:2206.06986",
    "title": "Exploring Representation of Horn Clauses using GNNs (technique report)",
    "abstract": "Exploring Representation of Horn Clauses using GNNs (technique report)",
    "descriptor": "",
    "authors": [
      "Chencheng Liang",
      "Philipp R\u00fcmmer",
      "Marc Brockschmidt"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06986"
  },
  {
    "id": "arXiv:2206.07038",
    "title": "AnimeSR: Learning Real-World Super-Resolution Models for Animation  Videos",
    "abstract": "Comments: Tech Report. Codes and a high-resolution version of this paper will be available at this https URL",
    "descriptor": "\nComments: Tech Report. Codes and a high-resolution version of this paper will be available at this https URL\n",
    "authors": [
      "Yanze Wu",
      "Xintao Wang",
      "Gen Li",
      "Ying Shan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.07038"
  },
  {
    "id": "arXiv:2206.07095",
    "title": "Elementary remarks about Pisano periods",
    "abstract": "Elementary remarks about Pisano periods",
    "descriptor": "",
    "authors": [
      "G\u00e9rard Henry Edmond Duchamp",
      "Pierre Simonnet"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2206.07095"
  },
  {
    "id": "arXiv:2206.07104",
    "title": "Most, And Least, Compact Spanning Trees of a Graph",
    "abstract": "Most, And Least, Compact Spanning Trees of a Graph",
    "descriptor": "",
    "authors": [
      "Gyan Ranjan",
      "Nishant Saurabh",
      "Amit Ashutosh"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2206.07104"
  },
  {
    "id": "arXiv:2206.07161",
    "title": "GraphFM: Improving Large-Scale GNN Training via Feature Momentum",
    "abstract": "Comments: ICML 2022",
    "descriptor": "\nComments: ICML 2022\n",
    "authors": [
      "Haiyang Yu",
      "Limei Wang",
      "Bokun Wang",
      "Meng Liu",
      "Tianbao Yang",
      "Shuiwang Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.07161"
  },
  {
    "id": "arXiv:2206.07269",
    "title": "Resource-Constrained Edge AI with Early Exit Prediction",
    "abstract": "Comments: 26 pages, 16 figures, 6 tables. This paper is accepted by Journal of Communications and Information Networks",
    "descriptor": "\nComments: 26 pages, 16 figures, 6 tables. This paper is accepted by Journal of Communications and Information Networks\n",
    "authors": [
      "Rongkang Dong",
      "Yuyi Mao",
      "Jun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.07269"
  },
  {
    "id": "arXiv:2206.07823",
    "title": "An Investigation of Kripke-style Modal Type Theories",
    "abstract": "An Investigation of Kripke-style Modal Type Theories",
    "descriptor": "",
    "authors": [
      "Jason Z. S. Hu",
      "Brigitte Pientka"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2206.07823"
  },
  {
    "id": "arXiv:2206.07912",
    "title": "Double Sampling Randomized Smoothing",
    "abstract": "Comments: ICML 2022; minor typos fixed compared to carema-ready version",
    "descriptor": "\nComments: ICML 2022; minor typos fixed compared to carema-ready version\n",
    "authors": [
      "Linyi Li",
      "Jiawei Zhang",
      "Tao Xie",
      "Bo Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2206.07912"
  },
  {
    "id": "arXiv:2206.07934",
    "title": "Technical Report for Argoverse2 Challenge 2022 -- Motion Forecasting  Task",
    "abstract": "Technical Report for Argoverse2 Challenge 2022 -- Motion Forecasting  Task",
    "descriptor": "",
    "authors": [
      "Chen Zhang",
      "Honglin Sun",
      "Chen Chen",
      "Yandong Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.07934"
  },
  {
    "id": "arXiv:2206.07940",
    "title": "PROFHIT: Probabilistic Robust Forecasting for Hierarchical Time-series",
    "abstract": "Comments: 15 pages",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Harshavardhan Kamarthi",
      "Lingkai Kong",
      "Alexander Rodr\u00edguez",
      "Chao Zhang",
      "B. Aditya Prakash"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.07940"
  },
  {
    "id": "arXiv:2206.07998",
    "title": "Differentially Private Multi-Party Data Release for Linear Regression",
    "abstract": "Comments: UAI 2022",
    "descriptor": "\nComments: UAI 2022\n",
    "authors": [
      "Ruihan Wu",
      "Xin Yang",
      "Yuanshun Yao",
      "Jiankai Sun",
      "Tianyi Liu",
      "Kilian Q. Weinberger",
      "Chong Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.07998"
  },
  {
    "id": "arXiv:2206.08006",
    "title": "Energy-Grade Double Pricing Rule in the Heating Market",
    "abstract": "Energy-Grade Double Pricing Rule in the Heating Market",
    "descriptor": "",
    "authors": [
      "Xinyi Yi",
      "Ye Guo",
      "Hongbin Sun"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.08006"
  },
  {
    "id": "arXiv:2206.08065",
    "title": "Neural tangent kernel analysis of shallow $\u03b1$-Stable ReLU neural  networks",
    "abstract": "Comments: 33 pages",
    "descriptor": "\nComments: 33 pages\n",
    "authors": [
      "Stefano Favaro",
      "Sandra Fortini",
      "Stefano Peluchetti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.08065"
  },
  {
    "id": "arXiv:2206.08126",
    "title": "Channel Importance Matters in Few-Shot Image Classification",
    "abstract": "Comments: Accepted to ICML 2022; code available at this https URL",
    "descriptor": "\nComments: Accepted to ICML 2022; code available at this https URL\n",
    "authors": [
      "Xu Luo",
      "Jing Xu",
      "Zenglin Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.08126"
  },
  {
    "id": "arXiv:2206.08132",
    "title": "Adaptive versus Static Multi-oracle Algorithms, and Quantum Security of  a Split-key PRF",
    "abstract": "Adaptive versus Static Multi-oracle Algorithms, and Quantum Security of  a Split-key PRF",
    "descriptor": "",
    "authors": [
      "Jelle Don",
      "Serge Fehr",
      "Yu-Hsuan Huang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.08132"
  },
  {
    "id": "arXiv:2206.08317",
    "title": "Paraformer: Fast and Accurate Parallel Transformer for  Non-autoregressive End-to-End Speech Recognition",
    "abstract": "Comments: 5 pages, 3 figures, accepted by INTERSPEECH 2022",
    "descriptor": "\nComments: 5 pages, 3 figures, accepted by INTERSPEECH 2022\n",
    "authors": [
      "Zhifu Gao",
      "Shiliang Zhang",
      "Ian McLoughlin",
      "Zhijie Yan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.08317"
  },
  {
    "id": "arXiv:2206.08355",
    "title": "FWD: Real-time Novel View Synthesis with Forward Warping and Depth",
    "abstract": "Comments: CVPR 2022. Project website this https URL",
    "descriptor": "\nComments: CVPR 2022. Project website this https URL\n",
    "authors": [
      "Ang Cao",
      "Chris Rockwell",
      "Justin Johnson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.08355"
  },
  {
    "id": "arXiv:2206.08362",
    "title": "Unified Fourier-based Kernel and Nonlinearity Design for Equivariant  Networks on Homogeneous Spaces",
    "abstract": "Comments: Accepted at ICML2022 Thirty-ninth International Conference on Machine Learning",
    "descriptor": "\nComments: Accepted at ICML2022 Thirty-ninth International Conference on Machine Learning\n",
    "authors": [
      "Yinshuang Xu",
      "Jiahui Lei",
      "Edgar Dobriban",
      "Kostas Daniilidis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.08362"
  },
  {
    "id": "arXiv:2206.08406",
    "title": "Predicting Hate Intensity of Twitter Conversation Threads",
    "abstract": "Comments: 22 pages, 10 figures, 3 tables",
    "descriptor": "\nComments: 22 pages, 10 figures, 3 tables\n",
    "authors": [
      "Qing Meng",
      "Tharun Suresh",
      "Roy Ka-Wei Lee",
      "Tanmoy Chakraborty"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.08406"
  },
  {
    "id": "arXiv:2206.08462",
    "title": "Recursive Neural Programs: Variational Learning of Image Grammars and  Part-Whole Hierarchies",
    "abstract": "Comments: 9 pages, 6 figures. fixed LaTeX typo for figure reference",
    "descriptor": "\nComments: 9 pages, 6 figures. fixed LaTeX typo for figure reference\n",
    "authors": [
      "Ares Fisher",
      "Rajesh P.N. Rao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.08462"
  },
  {
    "id": "arXiv:2206.08697",
    "title": "Reviewer Preferences and Gender Disparities in Aesthetic Judgments",
    "abstract": "Reviewer Preferences and Gender Disparities in Aesthetic Judgments",
    "descriptor": "",
    "authors": [
      "Ida Marie Schytt Lassen",
      "Yuri Bizzoni",
      "Telma Peura",
      "Mads Rosendahl Thomsen",
      "Kristoffer Laigaard Nielbo"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.08697"
  },
  {
    "id": "arXiv:2206.08742",
    "title": "Near-Optimal No-Regret Learning for General Convex Games",
    "abstract": "Near-Optimal No-Regret Learning for General Convex Games",
    "descriptor": "",
    "authors": [
      "Gabriele Farina",
      "Ioannis Anagnostides",
      "Haipeng Luo",
      "Chung-Wei Lee",
      "Christian Kroer",
      "Tuomas Sandholm"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.08742"
  },
  {
    "id": "arXiv:2206.08793",
    "title": "A general error analysis for randomized low-rank approximation methods",
    "abstract": "A general error analysis for randomized low-rank approximation methods",
    "descriptor": "",
    "authors": [
      "Youssef Diouane",
      "Selime G\u00fcrol",
      "Alexandre Scotto Di Perrotolo",
      "Xavier Vasseur"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.08793"
  },
  {
    "id": "arXiv:2206.08803",
    "title": "Local Characteristic Decomposition Based Central-Upwind Scheme",
    "abstract": "Local Characteristic Decomposition Based Central-Upwind Scheme",
    "descriptor": "",
    "authors": [
      "Alina Chertock",
      "Shaoshuai Chu",
      "Michael Herty",
      "Alexander Kurganov",
      "Maria Lukacova-Medvidova"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.08803"
  },
  {
    "id": "arXiv:2206.08929",
    "title": "TAVA: Template-free Animatable Volumetric Actors",
    "abstract": "Comments: Code: this https URL; Project Website: this https URL",
    "descriptor": "\nComments: Code: this https URL; Project Website: this https URL\n",
    "authors": [
      "Ruilong Li",
      "Julian Tanke",
      "Minh Vo",
      "Michael Zollhofer",
      "Jurgen Gall",
      "Angjoo Kanazawa",
      "Christoph Lassner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.08929"
  }
]
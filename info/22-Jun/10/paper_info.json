[
  {
    "id": "arXiv:2206.04049",
    "title": "Hypersyn: A Peer-to-Peer System for Mutual Credit",
    "abstract": "The Hypersyn protocol is a new type of permissionless and peer-to-peer\npayment network that is based on the concept of mutual credit and mutual\narbitrage. Unlike blockchain-based systems, Hypersyn does not rely on any\nconsensus algorithm. It does not require a distributed ledger to store the\nhistory of events nor a set of validators. Hypersyn does not have a\nsystem-imposed hard-cap on the number of transactions per second that it can\nperform, and can therefore easily scale up or down depending on network usage.\nUnlike in other payment systems, money in Hypersyn does not get transferred\nfrom person $A$ to person $B$ in the conventional sense. Instead of\ntransferring a token between each other, peers in Hypersyn change their\nexchange value of their credit (i.e. their purchasing power) within the\nnetwork. Just as in centrally-issued fiat systems, money in Hypersyn is treated\nas freely tradable debt, which inherently requires trust. But unlike\ncentrally-issued fiat systems, money issuance in Hypersyn is not controlled by\nan authority, but is instead created on the spot as mutual credit. In\nblockchain-based systems and even in centrally-issued fiat systems, money is\ntreated as a scarce commodity. In the Hypersyn protocol on the other hand,\nmoney supply within the system is elastic in nature. Because of these\nfundamental differences in assumptions, the Hypersyn protocol does not aim to\ncompete with, or substitute blockchain-based systems. Instead, Hypersyn should\nbe viewed as a tool that aims to offer a qualitative change in the way we\nexchange. It has the potential to increase the autonomy and self-organization\nthat people can have, by enabling people to become both the creditors and\ndebtors of their own \"money\" through mutual credit.",
    "descriptor": "",
    "authors": [
      "Lum Ramabaja"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.04049"
  },
  {
    "id": "arXiv:2206.04050",
    "title": "Balanced background and explanation data are needed in explaining deep  learning models with SHAP: An empirical study on clinical decision making",
    "abstract": "Objective: Shapley additive explanations (SHAP) is a popular post-hoc\ntechnique for explaining black box models. While the impact of data imbalance\non predictive models has been extensively studied, it remains largely unknown\nwith respect to SHAP-based model explanations. This study sought to investigate\nthe effects of data imbalance on SHAP explanations for deep learning models,\nand to propose a strategy to mitigate these effects. Materials and Methods: We\npropose to adjust class distributions in the background and explanation data in\nSHAP when explaining black box models. Our data balancing strategy is to\ncompose background data and explanation data with an equal distribution of\nclasses. To evaluate the effects of data adjustment on model explanation, we\npropose to use the beeswarm plot as a qualitative tool to identify \"abnormal\"\nexplanation artifacts, and quantitatively test the consistency between variable\nimportance and prediction power. We demonstrated our proposed approach in an\nempirical study that predicted inpatient mortality using the Medical\nInformation Mart for Intensive Care (MIMIC-III) data and a multilayer\nperceptron. Results: Using the data balancing strategy would allow us to reduce\nthe number of the artifacts in the beeswarm plot, thus mitigating the negative\neffects of data imbalance. Additionally, with the balancing strategy, the\ntop-ranked variables from the corresponding importance ranking demonstrated\nimproved discrimination power. Discussion and Conclusion: Our findings suggest\nthat balanced background and explanation data could help reduce the noise in\nexplanation results induced by skewed data distribution and improve the\nreliability of variable importance ranking. Furthermore, these balancing\nprocedures improve the potential of SHAP in identifying patients with abnormal\ncharacteristics in clinical applications.",
    "descriptor": "",
    "authors": [
      "Mingxuan Liu",
      "Yilin Ning",
      "Han Yuan",
      "Marcus Eng Hock Ong",
      "Nan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.04050"
  },
  {
    "id": "arXiv:2206.04053",
    "title": "Unsupervised Knowledge Adaptation for Passenger Demand Forecasting",
    "abstract": "Considering the multimodal nature of transport systems and potential\ncross-modal correlations, there is a growing trend of enhancing demand\nforecasting accuracy by learning from multimodal data. These multimodal\nforecasting models can improve accuracy but be less practical when different\nparts of multimodal datasets are owned by different institutions who cannot\ndirectly share data among them. While various institutions may can not share\ntheir data with each other directly, they may share forecasting models trained\nby their data, where such models cannot be used to identify the exact\ninformation from their datasets. This study proposes an Unsupervised Knowledge\nAdaptation Demand Forecasting framework to forecast the demand of the target\nmode by utilizing a pre-trained model based on data of another mode, which does\nnot require direct data sharing of the source mode. The proposed framework\nutilizes the potential shared patterns among multiple transport modes to\nimprove forecasting performance while avoiding the direct sharing of data among\ndifferent institutions. Specifically, a pre-trained forecasting model is first\nlearned based on the data of a source mode, which can capture and memorize the\nsource travel patterns. Then, the demand data of the target dataset is encoded\ninto an individual knowledge part and a sharing knowledge part which will\nextract travel patterns by individual extraction network and sharing extraction\nnetwork, respectively. The unsupervised knowledge adaptation strategy is\nutilized to form the sharing features for further forecasting by making the\npre-trained network and the sharing extraction network analogous. Our findings\nillustrate that unsupervised knowledge adaptation by sharing the pre-trained\nmodel to the target mode can improve the forecasting performance without the\ndependence on direct data sharing.",
    "descriptor": "",
    "authors": [
      "Can Li",
      "Lei Bai",
      "Wei Liu",
      "Lina Yao",
      "S Travis Waller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.04053"
  },
  {
    "id": "arXiv:2206.04055",
    "title": "Gradient Obfuscation Gives a False Sense of Security in Federated  Learning",
    "abstract": "Federated learning has been proposed as a privacy-preserving machine learning\nframework that enables multiple clients to collaborate without sharing raw\ndata. However, client privacy protection is not guaranteed by design in this\nframework. Prior work has shown that the gradient sharing strategies in\nfederated learning can be vulnerable to data reconstruction attacks. In\npractice, though, clients may not transmit raw gradients considering the high\ncommunication cost or due to privacy enhancement requirements. Empirical\nstudies have demonstrated that gradient obfuscation, including intentional\nobfuscation via gradient noise injection and unintentional obfuscation via\ngradient compression, can provide more privacy protection against\nreconstruction attacks. In this work, we present a new data reconstruction\nattack framework targeting the image classification task in federated learning.\nWe show that commonly adopted gradient postprocessing procedures, such as\ngradient quantization, gradient sparsification, and gradient perturbation, may\ngive a false sense of security in federated learning. Contrary to prior\nstudies, we argue that privacy enhancement should not be treated as a byproduct\nof gradient compression. Additionally, we design a new method under the\nproposed framework to reconstruct the image at the semantic level. We quantify\nthe semantic privacy leakage and compare with conventional based on image\nsimilarity scores. Our comparisons challenge the image data leakage evaluation\nschemes in the literature. The results emphasize the importance of revisiting\nand redesigning the privacy protection mechanisms for client data in existing\nfederated learning algorithms.",
    "descriptor": "",
    "authors": [
      "Kai Yue",
      "Richeng Jin",
      "Chau-Wai Wong",
      "Dror Baron",
      "Huaiyu Dai"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04055"
  },
  {
    "id": "arXiv:2206.04057",
    "title": "Hidden Markov Models with Momentum",
    "abstract": "Momentum is a popular technique for improving convergence rates during\ngradient descent. In this research, we experiment with adding momentum to the\nBaum-Welch expectation-maximization algorithm for training Hidden Markov\nModels. We compare discrete Hidden Markov Models trained with and without\nmomentum on English text and malware opcode data. The effectiveness of momentum\nis determined by measuring the changes in model score and classification\naccuracy due to momentum. Our extensive experiments indicate that adding\nmomentum to Baum-Welch can reduce the number of iterations required for initial\nconvergence during HMM training, particularly in cases where the model is slow\nto converge. However, momentum does not seem to improve the final model\nperformance at a high number of iterations.",
    "descriptor": "",
    "authors": [
      "Andrew Miller",
      "Fabio Di Troia",
      "Mark Stamp"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04057"
  },
  {
    "id": "arXiv:2206.04101",
    "title": "What-Is and How-To for Fairness in Machine Learning: A Survey,  Reflection, and Perspective",
    "abstract": "Algorithmic fairness has attracted increasing attention in the machine\nlearning community. Various definitions are proposed in the literature, but the\ndifferences and connections among them are not clearly addressed. In this\npaper, we review and reflect on various fairness notions previously proposed in\nmachine learning literature, and make an attempt to draw connections to\narguments in moral and political philosophy, especially theories of justice. We\nalso consider fairness inquiries from a dynamic perspective, and further\nconsider the long-term impact that is induced by current prediction and\ndecision. In light of the differences in the characterized fairness, we present\na flowchart that encompasses implicit assumptions and expected outcomes of\ndifferent types of fairness inquiries on the data generating process, on the\npredicted outcome, and on the induced impact, respectively. This paper\ndemonstrates the importance of matching the mission (which kind of fairness one\nwould like to enforce) and the means (which spectrum of fairness analysis is of\ninterest, what is the appropriate analyzing scheme) to fulfill the intended\npurpose.",
    "descriptor": "",
    "authors": [
      "Zeyu Tang",
      "Jiji Zhang",
      "Kun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.04101"
  },
  {
    "id": "arXiv:2206.04105",
    "title": "Words are all you need? Capturing human sensory similarity with textual  descriptors",
    "abstract": "Recent advances in multimodal training use textual descriptions to\nsignificantly enhance machine understanding of images and videos. Yet, it\nremains unclear to what extent language can fully capture sensory experiences\nacross different modalities. A well-established approach for characterizing\nsensory experiences relies on similarity judgments, namely, the degree to which\npeople perceive two distinct stimuli as similar. We explore the relation\nbetween human similarity judgments and language in a series of large-scale\nbehavioral studies ($N=1,823$ participants) across three modalities (images,\naudio, and video) and two types of text descriptors: simple word tags and\nfree-text captions. In doing so, we introduce a novel adaptive pipeline for tag\nmining that is both efficient and domain-general. We show that our prediction\npipeline based on text descriptors exhibits excellent performance, and we\ncompare it against a comprehensive array of 611 baseline models based on\nvision-, audio-, and video-processing architectures. We further show that the\ndegree to which textual descriptors and models predict human similarity varies\nacross and within modalities. Taken together, these studies illustrate the\nvalue of integrating machine learning and cognitive science approaches to\nbetter understand the similarities and differences between human and machine\nrepresentations. We present an interactive visualization at\nhttps://words-are-all-you-need.s3.amazonaws.com/index.html for exploring the\nsimilarity between stimuli as experienced by humans and different methods\nreported in the paper.",
    "descriptor": "\nComments: Preprint. Under review\n",
    "authors": [
      "Raja Marjieh",
      "Pol van Rijn",
      "Ilia Sucholutsky",
      "Theodore R. Sumers",
      "Harin Lee",
      "Thomas L. Griffiths",
      "Nori Jacoby"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.04105"
  },
  {
    "id": "arXiv:2206.04114",
    "title": "Deep Hierarchical Planning from Pixels",
    "abstract": "Intelligent agents need to select long sequences of actions to solve complex\ntasks. While humans easily break down tasks into subgoals and reach them\nthrough millions of muscle commands, current artificial intelligence is limited\nto tasks with horizons of a few hundred decisions, despite large compute\nbudgets. Research on hierarchical reinforcement learning aims to overcome this\nlimitation but has proven to be challenging, current methods rely on manually\nspecified goal spaces or subtasks, and no general solution exists. We introduce\nDirector, a practical method for learning hierarchical behaviors directly from\npixels by planning inside the latent space of a learned world model. The\nhigh-level policy maximizes task and exploration rewards by selecting latent\ngoals and the low-level policy learns to achieve the goals. Despite operating\nin latent space, the decisions are interpretable because the world model can\ndecode goals into images for visualization. Director outperforms exploration\nmethods on tasks with sparse rewards, including 3D maze traversal with a\nquadruped robot from an egocentric camera and proprioception, without access to\nthe global position or top-down view that was used by prior work. Director also\nlearns successful behaviors across a wide range of environments, including\nvisual control, Atari games, and DMLab levels.",
    "descriptor": "\nComments: Website: this https URL\n",
    "authors": [
      "Danijar Hafner",
      "Kuang-Huei Lee",
      "Ian Fischer",
      "Pieter Abbeel"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.04114"
  },
  {
    "id": "arXiv:2206.04115",
    "title": "Simplifying Polylogarithms with Machine Learning",
    "abstract": "Polylogrithmic functions, such as the logarithm or dilogarithm, satisfy a\nnumber of algebraic identities. For the logarithm, all the identities follow\nfrom the product rule. For the dilogarithm and higher-weight classical\npolylogarithms, the identities can involve five functions or more. In many\ncalculations relevant to particle physics, complicated combinations of\npolylogarithms often arise from Feynman integrals. Although the initial\nexpressions resulting from the integration usually simplify, it is often\ndifficult to know which identities to apply and in what order. To address this\nbottleneck, we explore to what extent machine learning methods can help. We\nconsider both a reinforcement learning approach, where the identities are\nanalogous to moves in a game, and a transformer network approach, where the\nproblem is viewed analogously to a language-translation task. While both\nmethods are effective, the transformer network appears more powerful and holds\npromise for practical use in symbolic manipulation tasks in mathematical\nphysics.",
    "descriptor": "\nComments: 41 pages, 10 figures\n",
    "authors": [
      "Aur\u00e9lien Dersy",
      "Matthew D. Schwartz",
      "Xiaoyuan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "High Energy Physics - Phenomenology (hep-ph)",
      "High Energy Physics - Theory (hep-th)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.04115"
  },
  {
    "id": "arXiv:2206.04122",
    "title": "ESCHER: Eschewing Importance Sampling in Games by Computing a History  Value Function to Estimate Regret",
    "abstract": "Recent techniques for approximating Nash equilibria in very large games\nleverage neural networks to learn approximately optimal policies (strategies).\nOne promising line of research uses neural networks to approximate\ncounterfactual regret minimization (CFR) or its modern variants. DREAM, the\nonly current CFR-based neural method that is model free and therefore scalable\nto very large games, trains a neural network on an estimated regret target that\ncan have extremely high variance due to an importance sampling term inherited\nfrom Monte Carlo CFR (MCCFR). In this paper we propose an unbiased model-free\nmethod that does not require any importance sampling. Our method, ESCHER, is\nprincipled and is guaranteed to converge to an approximate Nash equilibrium\nwith high probability in the tabular case. We show that the variance of the\nestimated regret of a tabular version of ESCHER with an oracle value function\nis significantly lower than that of outcome sampling MCCFR and tabular DREAM\nwith an oracle value function. We then show that a deep learning version of\nESCHER outperforms the prior state of the art -- DREAM and neural fictitious\nself play (NFSP) -- and the difference becomes dramatic as game size increases.",
    "descriptor": "",
    "authors": [
      "Stephen McAleer",
      "Gabriele Farina",
      "Marc Lanctot",
      "Tuomas Sandholm"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.04122"
  },
  {
    "id": "arXiv:2206.04123",
    "title": "A Framework for Building Secure, Scalable, Networked Enclaves",
    "abstract": "In 2020, Amazon introduced Nitro enclaves -- cloud-based secure enclaves that\ndo not share hardware with untrustworthy code, therefore promising resistance\nagainst side channel attacks, which have plagued Intel's SGX for years. While\ntheir security properties are attractive, Nitro enclaves are difficult to write\ncode for and are not meant to be used as a networked service, which greatly\nlimits their potential. In this paper, we built a framework that allows for\nconvenient and flexible use of Nitro enclaves by abstracting away complex\naspects like remote attestation and end-to-end encryption between an enclave\nand a remote client. We demonstrate the practicality of our framework by\ndesigning and implementing two production-grade systems that solve real-world\nproblems: remotely verifiable IP address pseudonymization and private\ntelemetry. Our practical experience suggests that our framework enables quick\nprototyping, is flexible enough to accommodate different use cases, and\ninherits strong security and performance properties from the underlying Nitro\nenclaves.",
    "descriptor": "",
    "authors": [
      "Philipp Winter",
      "Ralph Giles",
      "Alex Davidson",
      "Gon\u00e7alo Pestana"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.04123"
  },
  {
    "id": "arXiv:2206.04124",
    "title": "DRHDR: A Dual branch Residual Network for Multi-Bracket High Dynamic  Range Imaging",
    "abstract": "We introduce DRHDR, a Dual branch Residual Convolutional Neural Network for\nMulti-Bracket HDR Imaging. To address the challenges of fusing multiple\nbrackets from dynamic scenes, we propose an efficient dual branch network that\noperates on two different resolutions. The full resolution branch uses a\nDeformable Convolutional Block to align features and retain high-frequency\ndetails. A low resolution branch with a Spatial Attention Block aims to attend\nwanted areas from the non-reference brackets, and suppress displaced features\nthat could incur on ghosting artifacts. By using a dual branch approach we are\nable to achieve high quality results while constraining the computational\nresources required to estimate the HDR results.",
    "descriptor": "\nComments: Accepted by CVPRW 2022\n",
    "authors": [
      "Juan Mar\u00edn-Vega",
      "Michael Sloth",
      "Peter Schneider-Kamp",
      "Richard R\u00f6ttger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.04124"
  },
  {
    "id": "arXiv:2206.04125",
    "title": "Towards Self-supervised and Weight-preserving Neural Architecture Search",
    "abstract": "Neural architecture search (NAS) algorithms save tremendous labor from human\nexperts. Recent advancements further reduce the computational overhead to an\naffordable level. However, it is still cumbersome to deploy the NAS techniques\nin real-world applications due to the fussy procedures and the supervised\nlearning paradigm. In this work, we propose the self-supervised and\nweight-preserving neural architecture search (SSWP-NAS) as an extension of the\ncurrent NAS framework by allowing the self-supervision and retaining the\nconcomitant weights discovered during the search stage. As such, we simplify\nthe workflow of NAS to a one-stage and proxy-free procedure. Experiments show\nthat the architectures searched by the proposed framework achieve\nstate-of-the-art accuracy on CIFAR-10, CIFAR-100, and ImageNet datasets without\nusing manual labels. Moreover, we show that employing the concomitant weights\nas initialization consistently outperforms the random initialization and the\ntwo-stage weight pre-training method by a clear margin under semi-supervised\nlearning scenarios. Codes are publicly available at\nhttps://github.com/LzVv123456/SSWP-NAS.",
    "descriptor": "",
    "authors": [
      "Zhuowei Li",
      "Yibo Gao",
      "Zhenzhou Zha",
      "Zhiqiang HU",
      "Qing Xia",
      "Shaoting Zhang",
      "Dimitris N. Metaxas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.04125"
  },
  {
    "id": "arXiv:2206.04127",
    "title": "Open questions asked to analysis and numerics concerning the Hausdorff  moment problem",
    "abstract": "We address facts and open questions concerning the degree of ill-posedness of\nthe composite Hausdorff moment problem aimed at the recovery of a function $x\n\\in L^2(0,1)$ from elements of the infinite dimensional sequence space $\\ell^2$\nthat characterize moments applied to the antiderivative of $x$. This degree,\nunknown by now, results from the decay rate of the singular values of the\nassociated compact forward operator $A$, which is the composition of the\ncompact simple integration operator mapping in $L^2(0,1)$ and the non-compact\nHausdorff moment operator $B^{(H)}$ mapping from $L^2(0,1)$ to $\\ell^2$. There\nis a seeming contradiction between (a) numerical computations, which show (even\nfor large $n$) an exponential decay of the singular values for $n$-dimensional\nmatrices obtained by discretizing the operator $A$, and \\linebreak (b) a\nstrongly limited smoothness of the well-known kernel $k$ of the Hilbert-Schmidt\noperator $A^*A$. Fact (a) suggests severe ill-posedness of the infinite\ndimensional Hausdorff moment problem, whereas fact (b) lets us expect the\nopposite, because exponential ill-posedness occurs in common just for\n$C^\\infty$-kernels $k$. We recall arguments for the possible occurrence of a\npolynomial decay of the singular values of $A$, even if the numerics seems to\nbe against it, and discuss some issues in the numerical approximation of\nnon-compact operators.",
    "descriptor": "",
    "authors": [
      "Daniel Gerth",
      "Bernd Hofmann"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.04127"
  },
  {
    "id": "arXiv:2206.04129",
    "title": "Receding Moving Object Segmentation in 3D LiDAR Data Using Sparse 4D  Convolutions",
    "abstract": "A key challenge for autonomous vehicles is to navigate in unseen dynamic\nenvironments. Separating moving objects from static ones is essential for\nnavigation, pose estimation, and understanding how other traffic participants\nare likely to move in the near future. In this work, we tackle the problem of\ndistinguishing 3D LiDAR points that belong to currently moving objects, like\nwalking pedestrians or driving cars, from points that are obtained from\nnon-moving objects, like walls but also parked cars. Our approach takes a\nsequence of observed LiDAR scans and turns them into a voxelized sparse 4D\npoint cloud. We apply computationally efficient sparse 4D convolutions to\njointly extract spatial and temporal features and predict moving object\nconfidence scores for all points in the sequence. We develop a receding horizon\nstrategy that allows us to predict moving objects online and to refine\npredictions on the go based on new observations. We use a binary Bayes filter\nto recursively integrate new predictions of a scan resulting in more robust\nestimation. We evaluate our approach on the SemanticKITTI moving object\nsegmentation challenge and show more accurate predictions than existing\nmethods. Since our approach only operates on the geometric information of point\nclouds over time, it generalizes well to new, unseen environments, which we\nevaluate on the Apollo dataset.",
    "descriptor": "\nComments: Accepted for RA-L\n",
    "authors": [
      "Benedikt Mersch",
      "Xieyuanli Chen",
      "Ignacio Vizzo",
      "Lucas Nunes",
      "Jens Behley",
      "Cyrill Stachniss"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.04129"
  },
  {
    "id": "arXiv:2206.04132",
    "title": "Forecasting AI Progress: Evidence from a Survey of Machine Learning  Researchers",
    "abstract": "Advances in artificial intelligence (AI) are shaping modern life, from\ntransportation, health care, science, finance, to national defense. Forecasts\nof AI development could help improve policy- and decision-making. We report the\nresults from a large survey of AI and machine learning (ML) researchers on\ntheir beliefs about progress in AI. The survey, fielded in late 2019, elicited\nforecasts for near-term AI development milestones and high- or human-level\nmachine intelligence, defined as when machines are able to accomplish every or\nalmost every task humans are able to do currently. As part of this study, we\nre-contacted respondents from a highly-cited study by Grace et al. (2018), in\nwhich AI/ML researchers gave forecasts about high-level machine intelligence\nand near-term milestones in AI development. Results from our 2019 survey show\nthat, in aggregate, AI/ML researchers surveyed placed a 50% likelihood of\nhuman-level machine intelligence being achieved by 2060. The results show\nresearchers newly contacted in 2019 expressed similar beliefs about the\nprogress of advanced AI as respondents in the Grace et al. (2018) survey. For\nthe recontacted participants from the Grace et al. (2018) study, the aggregate\nforecast for a 50% likelihood of high-level machine intelligence shifted from\n2062 to 2076, although this change is not statistically significant, likely due\nto the small size of our panel sample. Forecasts of several near-term AI\nmilestones have reduced in time, suggesting more optimism about AI progress.\nFinally, AI/ML researchers also exhibited significant optimism about how\nhuman-level machine intelligence will impact society.",
    "descriptor": "",
    "authors": [
      "Baobao Zhang",
      "Noemi Dreksler",
      "Markus Anderljung",
      "Lauren Kahn",
      "Charlie Giattino",
      "Allan Dafoe",
      "Michael C. Horowitz"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.04132"
  },
  {
    "id": "arXiv:2206.04137",
    "title": "Adversarial Text Normalization",
    "abstract": "Text-based adversarial attacks are becoming more commonplace and accessible\nto general internet users. As these attacks proliferate, the need to address\nthe gap in model robustness becomes imminent. While retraining on adversarial\ndata may increase performance, there remains an additional class of\ncharacter-level attacks on which these models falter. Additionally, the process\nto retrain a model is time and resource intensive, creating a need for a\nlightweight, reusable defense. In this work, we propose the Adversarial Text\nNormalizer, a novel method that restores baseline performance on attacked\ncontent with low computational overhead. We evaluate the efficacy of the\nnormalizer on two problem areas prone to adversarial attacks, i.e. Hate Speech\nand Natural Language Inference. We find that text normalization provides a\ntask-agnostic defense against character-level attacks that can be implemented\nsupplementary to adversarial retraining solutions, which are more suited for\nsemantic alterations.",
    "descriptor": "",
    "authors": [
      "Joanna Bitton",
      "Maya Pavlova",
      "Ivan Evtimov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.04137"
  },
  {
    "id": "arXiv:2206.04140",
    "title": "TreeFlow: Going beyond Tree-based Gaussian Probabilistic Regression",
    "abstract": "The tree-based ensembles are known for their outstanding performance for\nclassification and regression problems characterized by feature vectors\nrepresented by mixed-type variables from various ranges and domains. However,\nconsidering regression problems, they are primarily designed to provide\ndeterministic responses or model the uncertainty of the output with a Gaussian\ndistribution. In this work, we introduce TreeFlow, the tree-based approach that\ncombines the benefits of using tree ensembles with capabilities of modeling\nflexible probability distributions using normalizing flows. The main idea of\nthe solution is to use a tree-based model as a feature extractor and combine it\nwith a conditional variant of normalizing flow. Consequently, our approach is\ncapable of modeling complex distributions for the regression outputs. We\nevaluate the proposed method on challenging regression benchmarks with varying\nvolume, feature characteristics, and target dimensionality. We obtain the SOTA\nresults on datasets with non-gaussian target distributions and competitive\nresults on gaussian ones compared to tree-based regression baselines.",
    "descriptor": "",
    "authors": [
      "Patryk Wielopolski",
      "Maciej Zi\u0119ba"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04140"
  },
  {
    "id": "arXiv:2206.04141",
    "title": "Role of Blockchain in Revolutionizing Online Transactional Security",
    "abstract": "This paper highlights the necessity to use modern blockchain technology in\ntraditional banking sector to reduce frauds and enable high-security\ntransactions on a permanent blockchain ledger. Reviewing different channels\nthrough which the traditional banking servers could integrate blockchain use,\nit is signified how a huge anti-fraud stand can be taken against bank servers\nallowing fraudulent transactions daily. Usage of a blockchain-based ledger is\nhighly impactful in terms of security of a banking organization.\nBlockchain-based currency tokens, also referred to as Cryptocurrencies are not\nregulated by the government, highly volatile, and anonymous to use.\nFurthermore, there is no security for any funds invested in a cryptocurrency\nmarket. However, the integration of a blockchain ledger in a traditional\nbanking organization would strengthen the security to provide more stability\nand confidence to its customers and at the same time, make blockchain a more\nreliable method to consider due to being trusted by large financial\norganizations.",
    "descriptor": "",
    "authors": [
      "Rishav Kumar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.04141"
  },
  {
    "id": "arXiv:2206.04149",
    "title": "A Comprehensive Survey of Graph-based Deep Learning Approaches for  Anomaly Detection in Complex Distributed Systems",
    "abstract": "Anomaly detection is an important problem for complex distributed systems\nconsisting of hardware and software components. A thorough understanding of the\nrequirements and challenges of anomaly detection for such systems is pivotal to\nthe security of a system, especially for real-world deployment. While there\nhave been many diverse research areas and application domains that deal with\nthe problem, few have attempted to provide an in-depth look at such systems.\nMost anomaly detection techniques have been specifically developed for certain\napplication domains, while others are more generic. In this survey, we explore\nthe significant potential of graph-based algorithms to identify and mitigate\ndifferent types of anomalies in complex distributed heterogeneous systems. Our\nmain focus is to provide an in-depth look at graphs when applied on\nheterogeneous computing devices spread across complex distributed systems. This\nstudy analyzes, compares, and contrasts the state-of-the-art research articles\nin the field. First, we describe the characteristics of the real-world\ndistributed systems and their specific challenges of anomaly detection in such\ncomplex networks, such as data and evaluation, nature of the anomalies, and\nreal-world requirements. Later, we discuss why graphs can be leveraged in such\nsystems and the benefits of utilizing graphs. Then we will aptly delve into the\nstate-of-the-art approaches and highlight their strength and weaknesses.\nFinally, we evaluate and compare these approaches and point out the areas for\npossible improvements.",
    "descriptor": "\nComments: The first two authors (A. Danesh Pazho and G. Alinezhad Noghre) have equal contribution. The article is submitted to IEEE Transactions on Knowledge and Data Engineering\n",
    "authors": [
      "Armin Danesh Pazho",
      "Ghazal Alinezhad Noghre",
      "Arnab A Purkayastha",
      "Jagannadh Vempati",
      "Otto Martin",
      "Hamed Tabkhi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04149"
  },
  {
    "id": "arXiv:2206.04153",
    "title": "Unsupervised Key Event Detection from Massive Text Corpora",
    "abstract": "Automated event detection from news corpora is a crucial task towards mining\nfast-evolving structured knowledge. As real-world events have different\ngranularities, from the top-level themes to key events and then to event\nmentions corresponding to concrete actions, there are generally two lines of\nresearch: (1) theme detection identifies from a news corpus major themes (e.g.,\n\"2019 Hong Kong Protests\" vs. \"2020 U.S. Presidential Election\") that have very\ndistinct semantics; and (2) action extraction extracts from one document\nmention-level actions (e.g., \"the police hit the left arm of the protester\")\nthat are too fine-grained for comprehending the event. In this paper, we\npropose a new task, key event detection at the intermediate level, aiming to\ndetect from a news corpus key events (e.g., \"HK Airport Protest on Aug.\n12-14\"), each happening at a particular time/location and focusing on the same\ntopic. This task can bridge event understanding and structuring and is\ninherently challenging because of the thematic and temporal closeness of key\nevents and the scarcity of labeled data due to the fast-evolving nature of news\narticles. To address these challenges, we develop an unsupervised key event\ndetection framework, EvMine, that (1) extracts temporally frequent peak phrases\nusing a novel ttf-itf score, (2) merges peak phrases into event-indicative\nfeature sets by detecting communities from our designed peak phrase graph that\ncaptures document co-occurrences, semantic similarities, and temporal closeness\nsignals, and (3) iteratively retrieves documents related to each key event by\ntraining a classifier with automatically generated pseudo labels from the\nevent-indicative feature sets and refining the detected key events using the\nretrieved documents. Extensive experiments and case studies show EvMine\noutperforms all the baseline methods and its ablations on two real-world news\ncorpora.",
    "descriptor": "\nComments: KDD 2022\n",
    "authors": [
      "Yunyi Zhang",
      "Fang Guo",
      "Jiaming Shen",
      "Jiawei Han"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.04153"
  },
  {
    "id": "arXiv:2206.04158",
    "title": "Ensembling Framework for Texture Extraction Techniques for  Classification",
    "abstract": "In the past few years, texture-based classification problems have proven\ntheir significance in many domains, from industrial inspection to\nhealth-related applications. New techniques and CNN-based architectures have\nbeen developed in recent years to solve texture-based classification problems.\nThe limitation of these approaches is that none of them claims to be the best\nsuited for all types of textures. Each technique has its advantage over a\nspecific texture type. To address this issue, we are proposing a framework that\ncombines existing techniques to extract texture features and displays better\nresults than the present ones. The proposed framework works well on the most of\nthe texture types, and in this framework, new techniques can also be added to\nachieve better results than existing ones. We are also presenting the SOTA\nresults on FMD and KTH datasets by combining three existing techniques, using\nthe proposed framework.",
    "descriptor": "",
    "authors": [
      "Vijay Pandey",
      "Mayank Gubba",
      "Mohammed Faisal",
      "Trapti Kalra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04158"
  },
  {
    "id": "arXiv:2206.04160",
    "title": "Alternating Mirror Descent for Constrained Min-Max Games",
    "abstract": "In this paper we study two-player bilinear zero-sum games with constrained\nstrategy spaces. An instance of natural occurrences of such constraints is when\nmixed strategies are used, which correspond to a probability simplex\nconstraint. We propose and analyze the alternating mirror descent algorithm, in\nwhich each player takes turns to take action following the mirror descent\nalgorithm for constrained optimization. We interpret alternating mirror descent\nas an alternating discretization of a skew-gradient flow in the dual space, and\nuse tools from convex optimization and modified energy function to establish an\n$O(K^{-2/3})$ bound on its average regret after $K$ iterations. This\nquantitatively verifies the algorithm's better behavior than the simultaneous\nversion of mirror descent algorithm, which is known to diverge and yields an\n$O(K^{-1/2})$ average regret bound. In the special case of an unconstrained\nsetting, our results recover the behavior of alternating gradient descent\nalgorithm for zero-sum games which was studied in (Bailey et al., COLT 2020).",
    "descriptor": "",
    "authors": [
      "Andre Wibisono",
      "Molei Tao",
      "Georgios Piliouras"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.04160"
  },
  {
    "id": "arXiv:2206.04162",
    "title": "Improved two-stage hate speech classification for twitter based on Deep  Neural Networks",
    "abstract": "Hate speech is a form of online harassment that involves the use of abusive\nlanguage, and it is commonly seen in social media posts. This sort of\nharassment mainly focuses on specific group characteristics such as religion,\ngender, ethnicity, etc and it has both societal and economic consequences\nnowadays. The automatic detection of abusive language in text postings has\nalways been a difficult task, but it is lately receiving much interest from the\nscientific community. This paper addresses the important problem of discerning\nhateful content in social media. The model we propose in this work is an\nextension of an existing approach based on LSTM neural network architectures,\nwhich we appropriately enhanced and fine-tuned to detect certain forms of\nhatred language, such as racism or sexism, in a short text. The most\nsignificant enhancement is the conversion to a two-stage scheme consisting of\nRecurrent Neural Network (RNN) classifiers. The output of all One-vs-Rest (OvR)\nclassifiers from the first stage are combined and used to train the second\nstage classifier, which finally determines the type of harassment. Our study\nincludes a performance comparison of several proposed alternative methods for\nthe second stage evaluated on a public corpus of 16k tweets, followed by a\ngeneralization study on another dataset. The reported results show the superior\nclassification quality of the proposed scheme in the task of hate speech\ndetection as compared to the current state-of-the-art.",
    "descriptor": "\nComments: 35 Pages, 4 Figures, 5 tables\n",
    "authors": [
      "Georgios K. Pitsilis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.04162"
  },
  {
    "id": "arXiv:2206.04166",
    "title": "Planning with Dynamically Estimated Action Costs",
    "abstract": "Information about action costs is critical for real-world AI planning\napplications. Rather than rely solely on declarative action models, recent\napproaches also use black-box external action cost estimators, often learned\nfrom data, that are applied during the planning phase. These, however, can be\ncomputationally expensive, and produce uncertain values. In this paper we\nsuggest a generalization of deterministic planning with action costs that\nallows selecting between multiple estimators for action cost, to balance\ncomputation time against bounded estimation uncertainty. This enables a much\nricher -- and correspondingly more realistic -- problem representation.\nImportantly, it allows planners to bound plan accuracy, thereby increasing\nreliability, while reducing unnecessary computational burden, which is critical\nfor scaling to large problems. We introduce a search algorithm, generalizing\n$A^*$, that solves such planning problems, and additional algorithmic\nextensions. In addition to theoretical guarantees, extensive experiments show\nconsiderable savings in runtime compared to alternatives.",
    "descriptor": "\nComments: 3 figures, 2 tables\n",
    "authors": [
      "Eyal Weiss",
      "Gal A. Kaminka"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2206.04166"
  },
  {
    "id": "arXiv:2206.04168",
    "title": "Incremental Recursive Ranking Grouping for Large Scale Global  Optimization",
    "abstract": "Real-world optimization problems may have a different underlying structure.\nIn black-box optimization, the dependencies between decision variables remain\nunknown. However, some techniques can discover such interactions accurately. In\nLarge Scale Global Optimization (LSGO), problems are high-dimensional. It was\nshown effective to decompose LSGO problems into subproblems and optimize them\nseparately. The effectiveness of such approaches may be highly dependent on the\naccuracy of problem decomposition. Many state-of-the-art decomposition\nstrategies are derived from Differential Grouping (DG). However, if a given\nproblem consists of non-additively separable subproblems, their ability to\ndetect only true interactions might decrease significantly. Therefore, we\npropose Incremental Recursive Ranking Grouping (IRRG) that does not suffer from\nthis flaw. IRRG consumes more fitness function evaluations than the recent\nDG-based propositions, e.g., Recursive DG 3 (RDG3). Nevertheless, the\neffectiveness of the considered Cooperative Co-evolution frameworks after\nembedding IRRG or RDG3 was similar for problems with additively separable\nsubproblems that are suitable for RDG3. However, after replacing the additive\nseparability with non-additive, embedding IRRG leads to results of\nsignificantly higher quality.",
    "descriptor": "",
    "authors": [
      "Marcin Michal Komarnicki",
      "Michal Witold Przewozniczek",
      "Halina Kwasnicka"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.04168"
  },
  {
    "id": "arXiv:2206.04170",
    "title": "CASS: Cross Architectural Self-Supervision for Medical Image Analysis",
    "abstract": "Recent advances in Deep Learning and Computer Vision have alleviated many of\nthe bottlenecks, allowing algorithms to be label-free with better performance.\nSpecifically, Transformers provide a global perspective of the image, which\nConvolutional Neural Networks (CNN) lack by design. Here we present\n\\textbf{C}ross \\textbf{A}rchitectural - \\textbf{S}elf \\textbf{S}upervision , a\nnovel self-supervised learning approach which leverages transformers and CNN\nsimultaneously, while also being computationally accessible to general\npractitioners via easily available cloud services. Compared to existing\nstate-of-the-art self-supervised learning approaches, we empirically show CASS\ntrained CNNs, and Transformers gained an average of 8.5\\% with 100\\% labelled\ndata, 7.3\\% with 10\\% labelled data, and 11.5\\% with 1\\% labelled data, across\nthree diverse datasets. Notably, one of the employed datasets included\nhistopathology slides of an autoimmune disease, a topic underrepresented in\nMedical Imaging and has minimal data. In addition, our findings reveal that\nCASS is twice as efficient as other state-of-the-art methods in terms of\ntraining time.",
    "descriptor": "\nComments: 15 pages, 4 figures\n",
    "authors": [
      "Pranav Singh",
      "Elena Sizikova",
      "Jacopo Cirrone"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.04170"
  },
  {
    "id": "arXiv:2206.04172",
    "title": "On Gradient Descent Convergence beyond the Edge of Stability",
    "abstract": "Gradient Descent (GD) is a powerful workhorse of modern machine learning\nthanks to its scalability and efficiency in high-dimensional spaces. Its\nability to find local minimisers is only guaranteed for losses with Lipschitz\ngradients, where it can be seen as a 'bona-fide' discretisation of an\nunderlying gradient flow. Yet, many ML setups involving overparametrised models\ndo not fall into this problem class, which has motivated research beyond the\nso-called \"Edge of Stability\", where the step-size crosses the admissibility\nthreshold inversely proportional to the Lipschitz constant above. Perhaps\nsurprisingly, GD has been empirically observed to still converge regardless of\nlocal instability. In this work, we study a local condition for such an\nunstable convergence around a local minima in a low dimensional setting. We\nthen leverage these insights to establish global convergence of a two-layer\nsingle-neuron ReLU student network aligning with the teacher neuron in a large\nlearning rate beyond the Edge of Stability under population loss. Meanwhile,\nwhile the difference of norms of the two layers is preserved by gradient flow,\nwe show that GD above the edge of stability induces a balancing effect, leading\nto the same norms across the layers.",
    "descriptor": "",
    "authors": [
      "Lei Chen",
      "Joan Bruna"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.04172"
  },
  {
    "id": "arXiv:2206.04176",
    "title": "VN-Transformer: Rotation-Equivariant Attention for Vector Neurons",
    "abstract": "Rotation equivariance is a desirable property in many practical applications\nsuch as motion forecasting and 3D perception, where it can offer benefits like\nsample efficiency, better generalization, and robustness to input\nperturbations. Vector Neurons (VN) is a recently developed framework offering a\nsimple yet effective approach for deriving rotation-equivariant analogs of\nstandard machine learning operations by extending one-dimensional scalar\nneurons to three-dimensional \"vector neurons.\" We introduce a novel\n\"VN-Transformer\" architecture to address several shortcomings of the current VN\nmodels. Our contributions are: $(i)$ we derive a rotation-equivariant attention\nmechanism which eliminates the need for the heavy feature preprocessing\nrequired by the original Vector Neurons models; $(ii)$ we extend the VN\nframework to support non-spatial attributes, expanding the applicability of\nthese models to real-world datasets; $(iii)$ we derive a rotation-equivariant\nmechanism for multi-scale reduction of point-cloud resolution, greatly speeding\nup inference and training; $(iv)$ we show that small tradeoffs in equivariance\n($\\epsilon$-approximate equivariance) can be used to obtain large improvements\nin numerical stability and training robustness on accelerated hardware, and we\nbound the propagation of equivariance violations in our models. Finally, we\napply our VN-Transformer to 3D shape classification and motion forecasting with\ncompelling results.",
    "descriptor": "",
    "authors": [
      "Serge Assaad",
      "Carlton Downey",
      "Rami Al-Rfou",
      "Nigamaa Nayakanti",
      "Ben Sapp"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.04176"
  },
  {
    "id": "arXiv:2206.04177",
    "title": "Towards Continuous Systematic Literature Review in Software Engineering",
    "abstract": "Context: New scientific evidence continuously arises with advances in\nSoftware Engineering (SE) research. Conventionally, Systematic Literature\nReviews (SLRs) are not updated or updated intermittently, leaving gaps between\nupdates, during which time the SLR may be missing crucial new evidence. Goal:\nWe propose and evaluate a concept and process called Continuous Systematic\nLiterature Review (CSLR) in SE. Method: To elaborate on the CSLR concept and\nprocess, we performed a synthesis of evidence by conducting a meta-ethnography,\naddressing knowledge from varied research areas. Furthermore, we conducted a\ncase study to evaluate the CSLR process. Results: We describe the resulting\nCSLR process in BPMN format. The case study results provide indications on the\nimportance and feasibility of applying CSLR in practice to continuously update\nSLR evidence in SE. Conclusion: The CSLR concept and process provide a feasible\nand systematic way to continuously incorporate new evidence into SLRs,\nsupporting trustworthy and up-to-date evidence for SLRs in SE.",
    "descriptor": "",
    "authors": [
      "Bianca Minetto Napole\u00e3o",
      "Fabio Petrillo",
      "Sylvain Hall\u00e9",
      "Marcos Kalinowski"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.04177"
  },
  {
    "id": "arXiv:2206.04179",
    "title": "Automating Ambiguity: Challenges and Pitfalls of Artificial Intelligence",
    "abstract": "Machine learning (ML) and artificial intelligence (AI) tools increasingly\npermeate every possible social, political, and economic sphere; sorting,\ntaxonomizing and predicting complex human behaviour and social phenomena.\nHowever, from fallacious and naive groundings regarding complex adaptive\nsystems to datasets underlying models, these systems are beset by problems,\nchallenges, and limitations. They remain opaque and unreliable, and fail to\nconsider societal and structural oppressive systems, disproportionately\nnegatively impacting those at the margins of society while benefiting the most\npowerful.\nThe various challenges, problems and pitfalls of these systems are a hot\ntopic of research in various areas, such as critical data/algorithm studies,\nscience and technology studies (STS), embodied and enactive cognitive science,\ncomplexity science, Afro-feminism, and the broadly construed emerging field of\nFairness, Accountability, and Transparency (FAccT). Yet, these fields of\nenquiry often proceed in silos. This thesis weaves together seemingly disparate\nfields of enquiry to examine core scientific and ethical challenges, pitfalls,\nand problems of AI.\nIn this thesis I, a) review the historical and cultural ecology from which AI\nresearch emerges, b) examine the shaky scientific grounds of machine prediction\nof complex behaviour illustrating how predicting complex behaviour with\nprecision is impossible in principle, c) audit large scale datasets behind\ncurrent AI demonstrating how they embed societal historical and structural\ninjustices, d) study the seemingly neutral values of ML research and put\nforward 67 prominent values underlying ML research, e) examine some of the\ninsidious and worrying applications of computer vision research, and f) put\nforward a framework for approaching challenges, failures and problems\nsurrounding ML systems as well as alternative ways forward.",
    "descriptor": "\nComments: PhD thesis\n",
    "authors": [
      "Abeba Birhane"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.04179"
  },
  {
    "id": "arXiv:2206.04180",
    "title": "Learning in Distributed Contextual Linear Bandits Without Sharing the  Context",
    "abstract": "Contextual linear bandits is a rich and theoretically important model that\nhas many practical applications. Recently, this setup gained a lot of interest\nin applications over wireless where communication constraints can be a\nperformance bottleneck, especially when the contexts come from a large\n$d$-dimensional space. In this paper, we consider a distributed memoryless\ncontextual linear bandit learning problem, where the agents who observe the\ncontexts and take actions are geographically separated from the learner who\nperforms the learning while not seeing the contexts. We assume that contexts\nare generated from a distribution and propose a method that uses $\\approx 5d$\nbits per context for the case of unknown context distribution and $0$ bits per\ncontext if the context distribution is known, while achieving nearly the same\nregret bound as if the contexts were directly observable. The former bound\nimproves upon existing bounds by a $\\log(T)$ factor, where $T$ is the length of\nthe horizon, while the latter achieves information theoretical tightness.",
    "descriptor": "",
    "authors": [
      "Osama A. Hanna",
      "Lin F. Yang",
      "Christina Fragouli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04180"
  },
  {
    "id": "arXiv:2206.04183",
    "title": "High-order implicit time integration scheme with controllable numerical  dissipation based on mixed-order Pad\u00e9 expansions",
    "abstract": "A single-step high-order implicit time integration scheme with controllable\nnumerical dissipation at high frequency is presented for the transient analysis\nof structural dynamic problems. The amount of numerical dissipation is\ncontrolled by a user-specified value of the spectral radius $\\rho_\\infty$ in\nthe high frequency limit. Using this user-specified parameter as a weight\nfactor, a Pad\\'e expansion of the matrix exponential solution of the equation\nof motion is constructed by mixing the diagonal and sub-diagonal expansions. An\nefficient time stepping scheme is designed where systems of equations similar\nin complexity to the standard Newmark method are solved recursively. It is\nshown that the proposed high-order scheme achieves high-frequency dissipation\nwhile minimizing low-frequency dissipation and period errors. The effectiveness\nof dissipation control and efficiency of the scheme are demonstrated with\nnumerical examples. A simple recommendation on the choice of the controlling\nparameter and time step size is provided. The source code written in MATLAB and\nFORTRAN is available for download at:\nhttps://github.com/ChongminSong/HighOrderTimeIntegration.",
    "descriptor": "\nComments: 32 pages, 28 figures, 86 equations\n",
    "authors": [
      "Chongmin Song",
      "Xiaoran Zhang",
      "Sascha Eisentr\u00e4ger"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.04183"
  },
  {
    "id": "arXiv:2206.04184",
    "title": "Abstraction not Memory: BERT and the English Article System",
    "abstract": "Article prediction is a task that has long defied accurate linguistic\ndescription. As such, this task is ideally suited to evaluate models on their\nability to emulate native-speaker intuition. To this end, we compare the\nperformance of native English speakers and pre-trained models on the task of\narticle prediction set up as a three way choice (a/an, the, zero). Our\nexperiments with BERT show that BERT outperforms humans on this task across all\narticles. In particular, BERT is far superior to humans at detecting the zero\narticle, possibly because we insert them using rules that the deep neural model\ncan easily pick up. More interestingly, we find that BERT tends to agree more\nwith annotators than with the corpus when inter-annotator agreement is high but\nswitches to agreeing more with the corpus as inter-annotator agreement drops.\nWe contend that this alignment with annotators, despite being trained on the\ncorpus, suggests that BERT is not memorising article use, but captures a high\nlevel generalisation of article use akin to human intuition.",
    "descriptor": "\nComments: Accepted for publication at 2022 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL 2022). Data and code available at this https URL\n",
    "authors": [
      "Harish Tayyar Madabushi",
      "Dagmar Divjak",
      "Petar Milin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.04184"
  },
  {
    "id": "arXiv:2206.04185",
    "title": "A Flash(bot) in the Pan: Measuring Maximal Extractable Value in Private  Pools",
    "abstract": "The rise of Ethereum has lead to a flourishing decentralized marketplace that\nhas, unfortunately, fallen victim to frontrunning and Maximal Extractable Value\n(MEV) activities, where savvy participants game transaction orderings within a\nblock for profit. One popular solution to address such behavior is Flashbots, a\nprivate pool with infrastructure and design goals aimed at eliminating the\nnegative externalities associated with MEV. While Flashbots has established\nlaudable goals to address MEV behavior, no evidence has been provided to show\nthat these goals are achieved in practice.\nIn this paper, we measure the popularity of Flashbots and evaluate if it is\nmeeting its chartered goals. We find that (1) Flashbots miners account for over\n99.9% of the hashing power in the Ethereum network, (2) powerful miners are\nmaking more than $2\\times$ what they were making prior to using Flashbots,\nwhile non-miners' slice of the pie has shrunk commensurately, (3) mining is\njust as centralized as it was prior to Flashbots with more than 90% of\nFlashbots blocks coming from just two miners, and (4) while more than 80% of\nMEV extraction in Ethereum is happening through Flashbots, 13.2% is coming from\nother private pools.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Ben Weintraub",
      "Christof Ferreira Torres",
      "Cristina Nita-Rotaru",
      "Radu State"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.04185"
  },
  {
    "id": "arXiv:2206.04186",
    "title": "Reinforced Inverse Scattering",
    "abstract": "Inverse wave scattering aims at determining the properties of an object using\ndata on how the object scatters incoming waves. In order to collect\ninformation, sensors are put in different locations to send and receive waves\nfrom each other. The choice of sensor positions and incident wave frequencies\ndetermines the reconstruction quality of scatterer properties. This paper\nintroduces reinforcement learning to develop precision imaging that decides\nsensor positions and wave frequencies adaptive to different scatterers in an\nintelligent way, thus obtaining a significant improvement in reconstruction\nquality with limited imaging resources. Extensive numerical results will be\nprovided to demonstrate the superiority of the proposed method over existing\nmethods.",
    "descriptor": "",
    "authors": [
      "Hanyang Jiang",
      "Yuehaw Khoo",
      "Haizhao Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.04186"
  },
  {
    "id": "arXiv:2206.04187",
    "title": "Few-shot Question Generation for Personalized Feedback in Intelligent  Tutoring Systems",
    "abstract": "Existing work on generating hints in Intelligent Tutoring Systems (ITS)\nfocuses mostly on manual and non-personalized feedback. In this work, we\nexplore automatically generated questions as personalized feedback in an ITS.\nOur personalized feedback can pinpoint correct and incorrect or missing phrases\nin student answers as well as guide them towards correct answer by asking a\nquestion in natural language. Our approach combines cause-effect analysis to\nbreak down student answers using text similarity-based NLP Transformer models\nto identify correct and incorrect or missing parts. We train a few-shot Neural\nQuestion Generation and Question Re-ranking models to show questions addressing\ncomponents missing in the student answers which steers students towards the\ncorrect answer. Our model vastly outperforms both simple and strong baselines\nin terms of student learning gains by 45% and 23% respectively when tested in a\nreal dialogue-based ITS. Finally, we show that our personalized corrective\nfeedback system has the potential to improve Generative Question Answering\nsystems.",
    "descriptor": "\nComments: PAIS 2022\n",
    "authors": [
      "Devang Kulshreshtha",
      "Muhammad Shayan",
      "Robert Belfer",
      "Siva Reddy",
      "Iulian Vlad Serban",
      "Ekaterina Kochmar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.04187"
  },
  {
    "id": "arXiv:2206.04192",
    "title": "ExpressivE: A Spatio-Functional Embedding For Knowledge Graph Completion",
    "abstract": "Knowledge graphs are inherently incomplete. Therefore substantial research\nhas been directed towards knowledge graph completion (KGC), i.e., predicting\nmissing triples from the information represented in the knowledge graph (KG).\nEmbedding models have yielded promising results for KGC, yet any current KGC\nembedding model is incapable of: (1) fully capturing vital inference patterns\n(e.g., composition), (2) capturing prominent logical rules jointly (e.g.,\nhierarchy and composition), and (3) providing an intuitive interpretation of\ncaptured patterns. In this work, we propose ExpressivE, a fully expressive\nspatio-functional embedding model that solves all these challenges\nsimultaneously. ExpressivE embeds pairs of entities as points and relations as\nhyper-parallelograms in the virtual triple space $\\mathbb{R}^{2d}$. This model\ndesign allows ExpressivE not only to capture a rich set of inference patterns\njointly but additionally to display any supported inference pattern through the\nspatial relation of hyper-parallelograms, offering an intuitive and consistent\ngeometric interpretation of ExpressivE embeddings and their captured patterns.\nExperimental results on standard KGC benchmarks reveal that ExpressivE is\ncompetitive with state-of-the-art models and even significantly outperforms\nthem on WN18RR.",
    "descriptor": "",
    "authors": [
      "Aleksandar Pavlovi\u0107",
      "Emanuel Sallinger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.04192"
  },
  {
    "id": "arXiv:2206.04197",
    "title": "SCAMPS: Synthetics for Camera Measurement of Physiological Signals",
    "abstract": "The use of cameras and computational algorithms for noninvasive, low-cost and\nscalable measurement of physiological (e.g., cardiac and pulmonary) vital signs\nis very attractive. However, diverse data representing a range of environments,\nbody motions, illumination conditions and physiological states is laborious,\ntime consuming and expensive to obtain. Synthetic data have proven a valuable\ntool in several areas of machine learning, yet are not widely available for\ncamera measurement of physiological states. Synthetic data offer \"perfect\"\nlabels (e.g., without noise and with precise synchronization), labels that may\nnot be possible to obtain otherwise (e.g., precise pixel level segmentation\nmaps) and provide a high degree of control over variation and diversity in the\ndataset. We present SCAMPS, a dataset of synthetics containing 2,800 videos\n(1.68M frames) with aligned cardiac and respiratory signals and facial action\nintensities. The RGB frames are provided alongside segmentation maps. We\nprovide precise descriptive statistics about the underlying waveforms,\nincluding inter-beat interval, heart rate variability, and pulse arrival time.\nFinally, we present baseline results training on these synthetic data and\ntesting on real-world datasets to illustrate generalizability.",
    "descriptor": "",
    "authors": [
      "Daniel McDuff",
      "Miah Wander",
      "Xin Liu",
      "Brian L. Hill",
      "Javier Hernandez",
      "Jonathan Lester",
      "Tadas Baltrusaitis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.04197"
  },
  {
    "id": "arXiv:2206.04199",
    "title": "Deep Surrogate Assisted Generation of Environments",
    "abstract": "Recent progress in reinforcement learning (RL) has started producing\ngenerally capable agents that can solve a distribution of complex environments.\nThese agents are typically tested on fixed, human-authored environments. On the\nother hand, quality diversity (QD) optimization has been proven to be an\neffective component of environment generation algorithms, which can generate\ncollections of high-quality environments that are diverse in the resulting\nagent behaviors. However, these algorithms require potentially expensive\nsimulations of agents on newly generated environments. We propose Deep\nSurrogate Assisted Generation of Environments (DSAGE), a sample-efficient QD\nenvironment generation algorithm that maintains a deep surrogate model for\npredicting agent behaviors in new environments. Results in two benchmark\ndomains show that DSAGE significantly outperforms existing QD environment\ngeneration algorithms in discovering collections of environments that elicit\ndiverse behaviors of a state-of-the-art RL agent and a planning agent.",
    "descriptor": "\nComments: 24 pages, 15 figures, supplemental website at this https URL\n",
    "authors": [
      "Varun Bhatt",
      "Bryon Tjanaka",
      "Matthew C. Fontaine",
      "Stefanos Nikolaidis"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.04199"
  },
  {
    "id": "arXiv:2206.04200",
    "title": "PartitionPIM: Practical Memristive Partitions for Fast  Processing-in-Memory",
    "abstract": "Digital memristive processing-in-memory overcomes the memory wall through a\nfundamental storage device capable of stateful logic within crossbar arrays.\nDynamically dividing the crossbar arrays by adding memristive partitions\nfurther increases parallelism, thereby overcoming an inherent trade-off in\nmemristive processing-in-memory. The algorithmic topology of partitions is\nhighly unique, and was recently exploited to accelerate multiplication (11x\nwith 32 partitions) and sorting (14x with 16 partitions). Yet, the physical\nimplementation of memristive partitions, such as the peripheral decoders and\nthe control message, has never been considered and may lead to vast\nimpracticality. This paper overcomes that challenge with several novel\ntechniques, presenting efficient practical designs of memristive partitions. We\nbegin by formalizing the algorithmic properties of memristive partitions into\nserial, parallel, and semi-parallel operations. Peripheral overhead is\naddressed via a novel technique of half-gates that enables efficient decoding\nwith negligible overhead. Control overhead is addressed by carefully reducing\nthe operation set of memristive partitions, while resulting in negligible\nperformance impact, by utilizing techniques such as shared indices and pattern\ngenerators. Ultimately, these efficient practical solutions, combined with the\nvast algorithmic potential, may revolutionize digital memristive\nprocessing-in-memory.",
    "descriptor": "",
    "authors": [
      "Orian Leitersdorf",
      "Ronny Ronen",
      "Shahar Kvatinsky"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2206.04200"
  },
  {
    "id": "arXiv:2206.04205",
    "title": "Min-Max Latency Optimization for IRS-aided Cell-Free Mobile Edge  Computing Systems",
    "abstract": "Mobile-edge computing (MEC) is expected to provide low-latency computation\nservice for wireless devices (WDs). However, when WDs are located at cell edge\nor communication links between base stations (BSs) and WDs are blocked, the\noffloading latency will be large. To address this issue, we propose an\nintelligent reflecting surface (IRS)-assisted cell-free MEC system consisting\nof multiple BSs and IRSs for improving the transmission environment.\nConsequently, we formulate a min-max latency optimization problem by jointly\ndesigning multi-user detection (MUD) matrices, IRSs' reflecting beamforming\nvectors, WDs' transmit power and edge computing resource, subject to\nconstraints on edge computing capability and IRSs phase shifts. To solve it, an\nalternating optimization algorithm based on the block coordinate descent (BCD)\ntechnique is proposed, in which the original non-convex problem is decoupled\ninto two subproblems for alternately optimizing computing and communication\nparameters. In particular, we optimize the MUD matrix based on the second-order\ncone programming (SOCP) technique, and then develop two efficient algorithms to\noptimize IRSs' reflecting vectors based on the semi-definite relaxation (SDR)\nand successive convex approximation (SCA) techniques, respectively. Numerical\nresults show that employing IRSs in cell-free MEC systems outperforms\nconventional MEC systems, resulting in up to about 60% latency reduction can be\nattained. Moreover, numerical results confirm that our proposed algorithms\nenjoy a fast convergence, which is beneficial for practical implementation.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Nana Li",
      "Wanming Hao",
      "Fuhui Zhou",
      "Shouyi Yang",
      "Naofal Al-Dhahir"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.04205"
  },
  {
    "id": "arXiv:2206.04215",
    "title": "It's a super deal -- train recurrent network on noisy data and get  smooth prediction free",
    "abstract": "Recent research demonstrate that prediction of time series by predictive\nrecurrent neural networks based on the noisy input generates a {\\it smooth}\nanticipated trajectory. We examine influence of the noise component in both the\ntraining data sets and the input sequences on network prediction quality. We\npropose and discuss an explanation of the observed noise compression in the\npredictive process. We also discuss importance of this property of recurrent\nnetworks in the neuroscience context for the evolution of living organisms.",
    "descriptor": "\nComments: 12 pages, 7 figures\n",
    "authors": [
      "Boris Rubinstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2206.04215"
  },
  {
    "id": "arXiv:2206.04216",
    "title": "Neo-GNNs: Neighborhood Overlap-aware Graph Neural Networks for Link  Prediction",
    "abstract": "Graph Neural Networks (GNNs) have been widely applied to various fields for\nlearning over graph-structured data. They have shown significant improvements\nover traditional heuristic methods in various tasks such as node classification\nand graph classification. However, since GNNs heavily rely on smoothed node\nfeatures rather than graph structure, they often show poor performance than\nsimple heuristic methods in link prediction where the structural information,\ne.g., overlapped neighborhoods, degrees, and shortest paths, is crucial. To\naddress this limitation, we propose Neighborhood Overlap-aware Graph Neural\nNetworks (Neo-GNNs) that learn useful structural features from an adjacency\nmatrix and estimate overlapped neighborhoods for link prediction. Our Neo-GNNs\ngeneralize neighborhood overlap-based heuristic methods and handle overlapped\nmulti-hop neighborhoods. Our extensive experiments on Open Graph Benchmark\ndatasets (OGB) demonstrate that Neo-GNNs consistently achieve state-of-the-art\nperformance in link prediction. Our code is publicly available at\nhttps://github.com/seongjunyun/Neo_GNNs.",
    "descriptor": "",
    "authors": [
      "Seongjun Yun",
      "Seoyoon Kim",
      "Junhyun Lee",
      "Jaewoo Kang",
      "Hyunwoo J. Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.04216"
  },
  {
    "id": "arXiv:2206.04218",
    "title": "AritPIM: High-Throughput In-Memory Arithmetic",
    "abstract": "Digital processing-in-memory (PIM) architectures are rapidly emerging to\novercome the memory-wall bottleneck by integrating logic within memory\nelements. Such architectures provide vast computational power within the memory\nitself in the form of parallel bitwise logic operations. We develop novel\nalgorithmic techniques for PIM that, combined with new perspectives on computer\narithmetic, extend this bitwise parallelism to the four fundamental arithmetic\noperations (addition, subtraction, multiplication, and division), for both\nfixed-point and floating-point numbers, and using both bit-serial and\nbit-parallel approaches. We propose a state-of-the-art suite of arithmetic\nalgorithms, demonstrating the first algorithm in the literature for a majority\nof cases - including cases previously considered impossible for digital PIM,\nsuch as floating-point addition. Through a case study on memristive PIM, we\ncompare the proposed algorithms to an NVIDIA RTX 3070 GPU and demonstrate\nmassive throughput and energy improvements. Overall, this paper provides a\nfundamental foundation for high-throughput arithmetic in PIM, thereby also\nexposing PIM algorithmic research to the wider computer-science community as\nall fundamental arithmetic operations can now be abstractly used, on both fixed\nand floating-point numbers.",
    "descriptor": "",
    "authors": [
      "Orian Leitersdorf",
      "Dean Leitersdorf",
      "Jonathan Gal",
      "Mor Dahan",
      "Ronny Ronen",
      "Shahar Kvatinsky"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2206.04218"
  },
  {
    "id": "arXiv:2206.04221",
    "title": "Analyzing Folktales of Different Regions Using Topic Modeling and  Clustering",
    "abstract": "This paper employs two major natural language processing techniques, topic\nmodeling and clustering, to find patterns in folktales and reveal cultural\nrelationships between regions. In particular, we used Latent Dirichlet\nAllocation and BERTopic to extract the recurring elements as well as K-means\nclustering to group folktales. Our paper tries to answer the question what are\nthe similarities and differences between folktales, and what do they say about\nculture. Here we show that the common trends between folktales are family,\nfood, traditional gender roles, mythological figures, and animals. Also,\nfolktales topics differ based on geographical location with folktales found in\ndifferent regions having different animals and environment. We were not\nsurprised to find that religious figures and animals are some of the common\ntopics in all cultures. However, we were surprised that European and Asian\nfolktales were often paired together. Our results demonstrate the prevalence of\ncertain elements in cultures across the world. We anticipate our work to be a\nresource to future research of folktales and an example of using natural\nlanguage processing to analyze documents in specific domains. Furthermore,\nsince we only analyzed the documents based on their topics, more work could be\ndone in analyzing the structure, sentiment, and the characters of these\nfolktales.",
    "descriptor": "\nComments: 5 pages, 2 figures\n",
    "authors": [
      "Jacob Werzinsky",
      "Zhiyan Zhong",
      "Xuedan Zou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.04221"
  },
  {
    "id": "arXiv:2206.04231",
    "title": "JNMR: Joint Non-linear Motion Regression for Video Frame Interpolation",
    "abstract": "Video frame interpolation (VFI) aims to generate predictive frames by warping\nlearnable motions from the bidirectional historical references. Most existing\nworks utilize spatio-temporal semantic information extractor to realize motion\nestimation and interpolation modeling, not enough considering with the real\nmechanistic rationality of generated middle motions. In this paper, we\nreformulate VFI as a multi-variable non-linear (MNL) regression problem, and a\nJoint Non-linear Motion Regression (JNMR) strategy is proposed to model\ncomplicated motions of inter-frame. To establish the MNL regression, ConvLSTM\nis adopted to construct the distribution of complete motions in temporal\ndimension. The motion correlations between the target frame and multiple\nreference frames can be regressed by the modeled distribution. Moreover, the\nfeature learning network is designed to optimize for the MNL regression\nmodeling. A coarse-to-fine synthesis enhancement module is further conducted to\nlearn visual dynamics at different resolutions through repetitive regression\nand interpolation. Highly competitive experimental results on frame\ninterpolation show that the effectiveness and significant improvement compared\nwith state-of-the-art performance, and the robustness of complicated motion\nestimation is improved by the MNL motion regression.",
    "descriptor": "",
    "authors": [
      "Meiqin Liu",
      "Chenming Xu",
      "Chao Yao",
      "Chunyu Lin",
      "Yao Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.04231"
  },
  {
    "id": "arXiv:2206.04236",
    "title": "Analytical Composition of Differential Privacy via the Edgeworth  Accountant",
    "abstract": "Many modern machine learning algorithms are composed of simple private\nalgorithms; thus, an increasingly important problem is to efficiently compute\nthe overall privacy loss under composition. In this study, we introduce the\nEdgeworth Accountant, an analytical approach to composing differential privacy\nguarantees of private algorithms. The Edgeworth Accountant starts by losslessly\ntracking the privacy loss under composition using the $f$-differential privacy\nframework, which allows us to express the privacy guarantees using privacy-loss\nlog-likelihood ratios (PLLRs). As the name suggests, this accountant next uses\nthe Edgeworth expansion to the upper and lower bounds the probability\ndistribution of the sum of the PLLRs. Moreover, by relying on a technique for\napproximating complex distributions using simple ones, we demonstrate that the\nEdgeworth Accountant can be applied to the composition of any noise-addition\nmechanism. Owing to certain appealing features of the Edgeworth expansion, the\n$(\\epsilon, \\delta)$-differential privacy bounds offered by this accountant are\nnon-asymptotic, with essentially no extra computational cost, as opposed to the\nprior approaches in, wherein the running times increase with the number of\ncompositions. Finally, we demonstrate that our upper and lower $(\\epsilon,\n\\delta)$-differential privacy bounds are tight in federated analytics and\ncertain regimes of training private deep learning models.",
    "descriptor": "",
    "authors": [
      "Hua Wang",
      "Sheng Gao",
      "Huanyu Zhang",
      "Milan Shen",
      "Weijie J. Su"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.04236"
  },
  {
    "id": "arXiv:2206.04239",
    "title": "Crosslinguistic word order variation reflects evolutionary pressures of  dependency and information locality",
    "abstract": "Languages vary considerably in syntactic structure. About 40% of the world's\nlanguages have subject-verb-object order, and about 40% have\nsubject-object-verb order. Extensive work has sought to explain this word order\nvariation across languages. However, the existing approaches are not able to\nexplain coherently the frequency distribution and evolution of word order in\nindividual languages. We propose that variation in word order reflects\ndifferent ways of balancing competing pressures of dependency locality and\ninformation locality, whereby languages favor placing elements together when\nthey are syntactically related or contextually informative about each other.\nUsing data from 80 languages in 17 language families and phylogenetic modeling,\nwe demonstrate that languages evolve to balance these pressures, such that word\norder change is accompanied by change in the frequency distribution of the\nsyntactic structures which speakers communicate to maintain overall efficiency.\nVariability in word order thus reflects different ways in which languages\nresolve these evolutionary pressures. We identify relevant characteristics that\nresult from this joint optimization, particularly the frequency with which\nsubjects and objects are expressed together for the same verb. Our findings\nsuggest that syntactic structure and usage across languages co-adapt to support\nefficient communication under limited cognitive resources.",
    "descriptor": "\nComments: Preprint of peer-reviewed paper published in PNAS. Final copyedited version is available at: this https URL\n",
    "authors": [
      "Michael Hahn",
      "Yang Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.04239"
  },
  {
    "id": "arXiv:2206.04240",
    "title": "Enhancement of Healthcare Data Transmission using the  Levenberg-Marquardt Algorithm",
    "abstract": "In the healthcare system, patients are required to use wearable devices for\nthe remote data collection and real-time monitoring of health data and the\nstatus of health conditions. This adoption of wearables results in a\nsignificant increase in the volume of data that is collected and transmitted.\nAs the devices are run by small battery power, they can be quickly diminished\ndue to the high processing requirements of the device for data collection and\ntransmission. Given the importance attached to medical data, it is imperative\nthat all transmitted data adhere to strict integrity and availability\nrequirements. Reducing the volume of healthcare data and the frequency of\ntransmission will improve the device battery life via using inference\nalgorithm. There is an issue of improving transmission metrics with accuracy\nand efficiency, which trade-off each other such as increasing accuracy reduces\nthe efficiency. This paper demonstrates that machine learning can be used to\nanalyze complex health data metrics such as the accuracy and efficiency of data\ntransmission to overcome the trade-off problem using the Levenberg-Marquardt\nalgorithm to enhance both metrics by taking fewer samples to transmit whilst\nmaintaining the accuracy. The algorithm is tested with a standard heart rate\ndataset to compare the metrics. The result shows that the LMA has best\nperformed with an efficiency of 3.33 times for reduced sample data size and\naccuracy of 79.17%, which has the similar accuracies in 7 different sampling\ncases adopted for testing but demonstrates improved efficiency. These proposed\nmethods significantly improved both metrics using machine learning without\nsacrificing a metric over the other compared to the existing methods with high\nefficiency.",
    "descriptor": "\nComments: 14 pages. arXiv admin note: text overlap with arXiv:2201.05962\n",
    "authors": [
      "Angela An",
      "James Jin Kang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.04240"
  },
  {
    "id": "arXiv:2206.04242",
    "title": "OOD Augmentation May Be at Odds with Open-Set Recognition",
    "abstract": "Despite advances in image classification methods, detecting the samples not\nbelonging to the training classes is still a challenging problem. There has\nbeen a burst of interest in this subject recently, which is called Open-Set\nRecognition (OSR). In OSR, the goal is to achieve both the classification and\ndetecting out-of-distribution (OOD) samples. Several ideas have been proposed\nto push the empirical result further through complicated techniques. We believe\nthat such complication is indeed not necessary. To this end, we have shown that\nMaximum Softmax Probability (MSP), as the simplest baseline for OSR, applied on\nVision Transformers (ViTs) as the base classifier that is trained with non-OOD\naugmentations can surprisingly outperform many recent methods. Non-OOD\naugmentations are the ones that do not alter the data distribution by much. Our\nresults outperform state-of-the-art in CIFAR-10 datasets, and is also better\nthan most of the current methods in SVHN and MNIST. We show that training\naugmentation has a significant effect on the performance of ViTs in the OSR\ntasks, and while they should produce significant diversity in the augmented\nsamples, the generated sample OOD-ness must remain limited.",
    "descriptor": "",
    "authors": [
      "Mohammad Azizmalayeri",
      "Mohammad Hossein Rohban"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.04242"
  },
  {
    "id": "arXiv:2206.04244",
    "title": "A Sparse Polynomial Chaos Expansion-Based Method for Probabilistic  Transient Stability Assessment and Enhancement",
    "abstract": "This paper proposes an adaptive sparse polynomial chaos expansion(PCE)-based\nmethod to quantify the impacts of uncertainties on critical clearing time (CCT)\nthat is an important index in transient stability analysis. The proposed method\ncan not only give fast and accurate estimations for the probabilistic\ncharacteristics (e.g., mean, variance, probability density function) of the\nprobabilistic CCT (PCCT), but also provides crucial information about the\nsensitivity of random inputs with respect to the variance of PCCT. Utilizing\nthe sensitivity information, mitigation measures can be developed for transient\nstability enhancement. Numerical studies on the WSCC 9-bus system demonstrate\nthe high accuracy and efficiency of the proposed method compared to the Monte\nCarlo simulation method. The provided sensitivity information and the\neffectiveness of mitigation measures in transient stability enhancement are\nalso verified.",
    "descriptor": "\nComments: 5 pages, 5 figures, to appear in IEEE PES General Meeting 2022\n",
    "authors": [
      "Jingyu Liu",
      "Xiaoting Wang",
      "Xiaozhe Wang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.04244"
  },
  {
    "id": "arXiv:2206.04246",
    "title": "SwinCheX: Multi-label classification on chest X-ray images with  transformers",
    "abstract": "According to the considerable growth in the avail of chest X-ray images in\ndiagnosing various diseases, as well as gathering extensive datasets, having an\nautomated diagnosis procedure using deep neural networks has occupied the minds\nof experts. Most of the available methods in computer vision use a CNN backbone\nto acquire high accuracy on the classification problems. Nevertheless, recent\nresearches show that transformers, established as the de facto method in NLP,\ncan also outperform many CNN-based models in vision. This paper proposes a\nmulti-label classification deep model based on the Swin Transformer as the\nbackbone to achieve state-of-the-art diagnosis classification. It leverages\nMulti-Layer Perceptron, also known as MLP, for the head architecture. We\nevaluate our model on one of the most widely-used and largest x-ray datasets\ncalled \"Chest X-ray14,\" which comprises more than 100,000 frontal/back-view\nimages from over 30,000 patients with 14 famous chest diseases. Our model has\nbeen tested with several number of MLP layers for the head setting, each\nachieves a competitive AUC score on all classes. Comprehensive experiments on\nChest X-ray14 have shown that a 3-layer head attains state-of-the-art\nperformance with an average AUC score of 0.810, compared to the former SOTA\naverage AUC of 0.799. We propose an experimental setup for the fair\nbenchmarking of existing methods, which could be used as a basis for the future\nstudies. Finally, we followed up our results by confirming that the proposed\nmethod attends to the pathologically relevant areas of the chest.",
    "descriptor": "",
    "authors": [
      "Sina Taslimi",
      "Soroush Taslimi",
      "Nima Fathi",
      "Mohammadreza Salehi",
      "Mohammad Hossein Rohban"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.04246"
  },
  {
    "id": "arXiv:2206.04249",
    "title": "An Optimization Method-Assisted Ensemble Deep Reinforcement Learning  Algorithm to Solve Unit Commitment Problems",
    "abstract": "Unit commitment (UC) is a fundamental problem in the day-ahead electricity\nmarket, and it is critical to solve UC problems efficiently. Mathematical\noptimization techniques like dynamic programming, Lagrangian relaxation, and\nmixed-integer quadratic programming (MIQP) are commonly adopted for UC\nproblems. However, the calculation time of these methods increases at an\nexponential rate with the amount of generators and energy resources, which is\nstill the main bottleneck in industry. Recent advances in artificial\nintelligence have demonstrated the capability of reinforcement learning (RL) to\nsolve UC problems. Unfortunately, the existing research on solving UC problems\nwith RL suffers from the curse of dimensionality when the size of UC problems\ngrows. To deal with these problems, we propose an optimization method-assisted\nensemble deep reinforcement learning algorithm, where UC problems are\nformulated as a Markov Decision Process (MDP) and solved by multi-step deep\nQ-learning in an ensemble framework. The proposed algorithm establishes a\ncandidate action set by solving tailored optimization problems to ensure a\nrelatively high performance and the satisfaction of operational constraints.\nNumerical studies on IEEE 118 and 300-bus systems show that our algorithm\noutperforms the baseline RL algorithm and MIQP. Furthermore, the proposed\nalgorithm shows strong generalization capacity under unforeseen operational\nconditions.",
    "descriptor": "",
    "authors": [
      "Jingtao Qin",
      "Yuanqi Gao",
      "Mikhail Bragin",
      "Nanpeng Yu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04249"
  },
  {
    "id": "arXiv:2206.04250",
    "title": "Massive MIMO Hybrid Precoding for LEO Satellite Communications With  Twin-Resolution Phase Shifters and Nonlinear Power Amplifiers",
    "abstract": "The massive multiple-input multiple-output (MIMO) transmission technology has\nrecently attracted much attention in the non-geostationary, e.g., low earth\norbit (LEO) satellite communication (SATCOM) systems since it can significantly\nimprove the energy efficiency (EE) and spectral efficiency. In this work, we\ndevelop a hybrid analog/digital precoding technique in the massive MIMO LEO\nSATCOM downlink, which reduces the onboard hardware complexity and power\nconsumption. In the proposed scheme, the analog precoder is implemented via a\nmore practical twin-resolution phase shifting (TRPS) network to make a\nmeticulous tradeoff between the power consumption and array gain. In addition,\nwe consider and study the impact of the distortion effect of the nonlinear\npower amplifiers (NPAs) in the system design. By jointly considering all the\nabove factors, we propose an efficient algorithmic approach for the TRPS-based\nhybrid precoding problem with NPAs. Numerical results show the EE gains\nconsidering the nonlinear distortion and the performance superiority of the\nproposed TRPS-based hybrid precoding scheme over the baselines.",
    "descriptor": "\nComments: 14 pages, 8 figures, to appear in IEEE Transactions on Communications\n",
    "authors": [
      "Li You",
      "Xiaoyu Qiang",
      "Ke-Xin Li",
      "Christos G. Tsinos",
      "Wenjin Wang",
      "Xiqi Gao",
      "Bj\u00f6rn Ottersten"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.04250"
  },
  {
    "id": "arXiv:2206.04253",
    "title": "CLTS+: A New Chinese Long Text Summarization Dataset with Abstractive  Summaries",
    "abstract": "The abstractive methods lack of creative ability is particularly a problem in\nautomatic text summarization. The summaries generated by models are mostly\nextracted from the source articles. One of the main causes for this problem is\nthe lack of dataset with abstractiveness, especially for Chinese. In order to\nsolve this problem, we paraphrase the reference summaries in CLTS, the Chinese\nLong Text Summarization dataset, correct errors of factual inconsistencies, and\npropose the first Chinese Long Text Summarization dataset with a high level of\nabstractiveness, CLTS+, which contains more than 180K article-summary pairs and\nis available online. Additionally, we introduce an intrinsic metric based on\nco-occurrence words to evaluate the dataset we constructed. We analyze the\nextraction strategies used in CLTS+ summaries against other datasets to\nquantify the abstractiveness and difficulty of our new data and train several\nbaselines on CLTS+ to verify the utility of it for improving the creative\nability of models.",
    "descriptor": "",
    "authors": [
      "Xiaojun Liu",
      "Shunan Zang",
      "Chuang Zhang",
      "Xiaojun Chen",
      "Yangyang Ding"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.04253"
  },
  {
    "id": "arXiv:2206.04255",
    "title": "ScatterSample: Diversified Label Sampling for Data Efficient Graph  Neural Network Learning",
    "abstract": "What target labels are most effective for graph neural network (GNN)\ntraining? In some applications where GNNs excel-like drug design or fraud\ndetection, labeling new instances is expensive. We develop a data-efficient\nactive sampling framework, ScatterSample, to train GNNs under an active\nlearning setting. ScatterSample employs a sampling module termed\nDiverseUncertainty to collect instances with large uncertainty from different\nregions of the sample space for labeling. To ensure diversification of the\nselected nodes, DiverseUncertainty clusters the high uncertainty nodes and\nselects the representative nodes from each cluster. Our ScatterSample algorithm\nis further supported by rigorous theoretical analysis demonstrating its\nadvantage compared to standard active sampling methods that aim to simply\nmaximize the uncertainty and not diversify the samples. In particular, we show\nthat ScatterSample is able to efficiently reduce the model uncertainty over the\nwhole sample space. Our experiments on five datasets show that ScatterSample\nsignificantly outperforms the other GNN active learning baselines, specifically\nit reduces the sampling cost by up to 50% while achieving the same test\naccuracy.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Zhenwei Dai",
      "Vasileios Ioannidis",
      "Soji Adeshina",
      "Zak Jost",
      "Christos Faloutsos",
      "George Karypis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04255"
  },
  {
    "id": "arXiv:2206.04263",
    "title": "Exploiting In-Slot Micro-Synchronism for S-ALOHA",
    "abstract": "Proliferation of the urban Internet-of-Things (IoTs) for smart cities has\nfuelled massive amounts of data over wireless cellular networks. Random access\n(RA) system of wireless cellular networks, e.g., 5G New Radio (NR), based on\nS-ALOHA system should cope with ever-growing IoT traffic. This work proposes\nS-ALOHA system with time offsets (TOs), where one slot consists of K TOs and\none packet transmission time. The length of the overall TOs is a fraction of a\npacket transmission time. In the system users (re)transmit to the boundary of a\nTO randomly selected. This enables the base station (BS) to inform the users of\nwho transmits the first and the last packets in the slot with collision so that\nthe two users can retransmit successfully in the following two slots\nrespectively. Our throughput analysis compared to simulations shows that\nadopting even with three and four TOs surpasses the throughput limit of S-ALOHA\nsystem without TOs. Additionally, we propose two Bayesian-optimized backoff\nalgorithms for S-ALOHA system with TOs, with which users can apply\nthroughput-optimal (re)transmission probability or uniform backoff window even\nin unsaturated traffic scenarios. Numerical results demonstrate that the\nproposed backoff algorithms can achieve the throughput close to an ideal system\nand drastically reduce the access delay compared to S-ALOHA system.",
    "descriptor": "\nComments: 17 pages, 26 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Yangqian Hu",
      "Jun-Bae Seo",
      "Hu Jin"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.04263"
  },
  {
    "id": "arXiv:2206.04264",
    "title": "Formation Tracking for a Multi-Auv System Based on an Adaptive Sliding  Mode Method in the Water Flow Environment",
    "abstract": "In this paper, formation tracking for a multi-AUV system (MAS) using an\nimproved adaptive sliding mode control method is studied in the Three\nDimensional (3-D) underwater environment. Firstly, the kinematics model and the\ndynamic model of the AUVs are given as the Six Dimensions of Freedom (6-DOF)\nconsidered. Then, control law based on the mathematical model of the AUVs is\nproposed based on the improved sliding mode method. A second order sliding mode\ncontrol method is adopted to eliminate the chatting phenomenon of the\ncontroller. Thirdly, considering the water flow in the underwater working\nenvironment of the AUVs, an adaptive module is added to the controller. With\nthe adaptive approach, the finite disturbances caused by water flow could be\nhandled with the controller. The proposed method achieves stability by\nsubstituting an adaptive continuous term for the switching term in the\ncontroller. At last, a robust sliding mode controller with continuous model\npredictive control strategy for the multi-AUV system is developed to achieve\nleader-follower formation tracking under the presence of bounded flow\ndisturbances, and simulations are implemented to confirm the effectiveness of\nthe proposed method.",
    "descriptor": "",
    "authors": [
      "Xin Li",
      "Daqi Zhu",
      "Qi Chen",
      "Wenyang Gan",
      "Zhigang Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.04264"
  },
  {
    "id": "arXiv:2206.04266",
    "title": "There is no Accuracy-Interpretability Tradeoff in Reinforcement Learning  for Mazes",
    "abstract": "Interpretability is an essential building block for trustworthiness in\nreinforcement learning systems. However, interpretability might come at the\ncost of deteriorated performance, leading many researchers to build complex\nmodels. Our goal is to analyze the cost of interpretability. We show that in\ncertain cases, one can achieve policy interpretability while maintaining its\noptimality. We focus on a classical problem from reinforcement learning: mazes\nwith $k$ obstacles in $\\mathbb{R}^d$. We prove the existence of a small\ndecision tree with a linear function at each inner node and depth $O(\\log k +\n2^d)$ that represents an optimal policy. Note that for the interesting case of\na constant $d$, we have $O(\\log k)$ depth. Thus, in this setting, there is no\naccuracy-interpretability tradeoff. To prove this result, we use a new\n\"compressing\" technique that might be useful in additional settings.",
    "descriptor": "",
    "authors": [
      "Yishay Mansour",
      "Michal Moshkovitz",
      "Cynthia Rudin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04266"
  },
  {
    "id": "arXiv:2206.04269",
    "title": "Smart System: Joint Utility and Frequency for Pattern Classification",
    "abstract": "Nowadays, the environments of smart systems for Industry 4.0 and Internet of\nThings (IoT) are experiencing fast industrial upgrading. Big data technologies\nsuch as design making, event detection, and classification are developed to\nhelp manufacturing organizations to achieve smart systems. By applying data\nanalysis, the potential values of rich data can be maximized and thus help\nmanufacturing organizations to finish another round of upgrading. In this\npaper, we propose two new algorithms with respect to big data analysis, namely\nUFC$_{gen}$ and UFC$_{fast}$. Both algorithms are designed to collect three\ntypes of patterns to help people determine the market positions for different\nproduct combinations. We compare these algorithms on various types of datasets,\nboth real and synthetic. The experimental results show that both algorithms can\nsuccessfully achieve pattern classification by utilizing three different types\nof interesting patterns from all candidate patterns based on user-specified\nthresholds of utility and frequency. Furthermore, the list-based UFC$_{fast}$\nalgorithm outperforms the level-wise-based UFC$_{gen}$ algorithm in terms of\nboth execution time and memory consumption.",
    "descriptor": "\nComments: ACM Transactions on Management Information Systems. 10 figures, 7 tables\n",
    "authors": [
      "Qi Lin",
      "Wensheng Gan",
      "Yongdong Wu",
      "Jiahui Chen",
      "Chien-Ming Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2206.04269"
  },
  {
    "id": "arXiv:2206.04270",
    "title": "A General Framework For Proving The Equivariant Strong Lottery Ticket  Hypothesis",
    "abstract": "The Strong Lottery Ticket Hypothesis (SLTH) stipulates the existence of a\nsubnetwork within a sufficiently overparameterized (dense) neural network that\n-- when initialized randomly and without any training -- achieves the accuracy\nof a fully trained target network. Recent work by \\citet{da2022proving}\ndemonstrates that the SLTH can also be extended to translation equivariant\nnetworks -- i.e. CNNs -- with the same level of overparametrization as needed\nfor SLTs in dense networks. However, modern neural networks are capable of\nincorporating more than just translation symmetry, and developing general\nequivariant architectures such as rotation and permutation has been a powerful\ndesign principle. In this paper, we generalize the SLTH to functions that\npreserve the action of the group $G$ -- i.e. $G$-equivariant network -- and\nprove, with high probability, that one can prune a randomly initialized\noverparametrized $G$-equivariant network to a $G$-equivariant subnetwork that\napproximates another fully trained $G$-equivariant network of fixed width and\ndepth. We further prove that our prescribed overparametrization scheme is also\noptimal as a function of the error tolerance. We develop our theory for a large\nrange of groups, including important ones such as subgroups of the Euclidean\ngroup $\\text{E}(n)$ and subgroups of the symmetric group $G \\leq \\mathcal{S}_n$\n-- allowing us to find SLTs for MLPs, CNNs, $\\text{E}(2)$-steerable CNNs, and\npermutation equivariant networks as specific instantiations of our unified\nframework which completely extends prior work. Empirically, we verify our\ntheory by pruning overparametrized $\\text{E}(2)$-steerable CNNs and message\npassing GNNs to match the performance of trained target networks within a given\nerror tolerance.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Damien Ferbach",
      "Christos Tsirigotis",
      "Gauthier Gidel",
      "Avishek",
      "Bose"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04270"
  },
  {
    "id": "arXiv:2206.04271",
    "title": "DeepVerge: Classification of Roadside Verge Biodiversity and  Conservation Potential",
    "abstract": "Open space grassland is being increasingly farmed or built upon, leading to a\nramping up of conservation efforts targeting roadside verges. Approximately\nhalf of all UK grassland species can be found along the country's 500,000 km of\nroads, with some 91 species either threatened or near threatened. Careful\nmanagement of these \"wildlife corridors\" is therefore essential to preventing\nspecies extinction and maintaining biodiversity in grassland habitats. Wildlife\ntrusts have often enlisted the support of volunteers to survey roadside verges\nand identify new \"Local Wildlife Sites\" as areas of high conservation\npotential. Using volunteer survey data from 3,900 km of roadside verges\nalongside publicly available street-view imagery, we present DeepVerge; a deep\nlearning-based method that can automatically survey sections of roadside verges\nby detecting the presence of positive indicator species. Using images and\nground truth survey data from the rural county of Lincolnshire, DeepVerge\nachieved a mean accuracy of 88%. Such a method may be used by local authorities\nto identify new local wildlife sites, and aid management and environmental\nplanning in line with legal and government policy obligations, saving thousands\nof hours of manual labour.",
    "descriptor": "",
    "authors": [
      "Andrew Perrett",
      "Charlie Barnes",
      "Mark Schofield",
      "Lan Qie",
      "Petra Bosilj",
      "James M. Brown"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.04271"
  },
  {
    "id": "arXiv:2206.04281",
    "title": "Local Spatiotemporal Representation Learning for  Longitudinally-consistent Neuroimage Analysis",
    "abstract": "Recent self-supervised advances in medical computer vision exploit global and\nlocal anatomical self-similarity for pretraining prior to downstream tasks such\nas segmentation. However, current methods assume i.i.d. image acquisition,\nwhich is invalid in clinical study designs where follow-up longitudinal scans\ntrack subject-specific temporal changes. Further, existing self-supervised\nmethods for medically-relevant image-to-image architectures exploit only\nspatial or temporal self-similarity and only do so via a loss applied at a\nsingle image-scale, with naive multi-scale spatiotemporal extensions collapsing\nto degenerate solutions. To these ends, this paper makes two contributions: (1)\nIt presents a local and multi-scale spatiotemporal representation learning\nmethod for image-to-image architectures trained on longitudinal images. It\nexploits the spatiotemporal self-similarity of learned multi-scale\nintra-subject features for pretraining and develops several feature-wise\nregularizations that avoid collapsed identity representations; (2) During\nfinetuning, it proposes a surprisingly simple self-supervised segmentation\nconsistency regularization to exploit intra-subject correlation. Benchmarked in\nthe one-shot segmentation setting, the proposed framework outperforms both\nwell-tuned randomly-initialized baselines and current self-supervised\ntechniques designed for both i.i.d. and longitudinal datasets. These\nimprovements are demonstrated across both longitudinal neurodegenerative adult\nMRI and developing infant brain MRI and yield both higher performance and\nlongitudinal consistency.",
    "descriptor": "\nComments: Code available at this https URL\n",
    "authors": [
      "Mengwei Ren",
      "Neel Dey",
      "Martin A. Styner",
      "Kelly Botteron",
      "Guido Gerig"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04281"
  },
  {
    "id": "arXiv:2206.04282",
    "title": "Sample-Efficient Reinforcement Learning in the Presence of Exogenous  Information",
    "abstract": "In real-world reinforcement learning applications the learner's observation\nspace is ubiquitously high-dimensional with both relevant and irrelevant\ninformation about the task at hand. Learning from high-dimensional observations\nhas been the subject of extensive investigation in supervised learning and\nstatistics (e.g., via sparsity), but analogous issues in reinforcement learning\nare not well understood, even in finite state/action (tabular) domains. We\nintroduce a new problem setting for reinforcement learning, the Exogenous\nMarkov Decision Process (ExoMDP), in which the state space admits an (unknown)\nfactorization into a small controllable (or, endogenous) component and a large\nirrelevant (or, exogenous) component; the exogenous component is independent of\nthe learner's actions, but evolves in an arbitrary, temporally correlated\nfashion. We provide a new algorithm, ExoRL, which learns a near-optimal policy\nwith sample complexity polynomial in the size of the endogenous component and\nnearly independent of the size of the exogenous component, thereby offering a\ndoubly-exponential improvement over off-the-shelf algorithms. Our results\nhighlight for the first time that sample-efficient reinforcement learning is\npossible in the presence of exogenous information, and provide a simple,\nuser-friendly benchmark for investigation going forward.",
    "descriptor": "\nComments: Accepted for presentation at the Conference on Learning Theory (COLT) 2022\n",
    "authors": [
      "Yonathan Efroni",
      "Dylan J. Foster",
      "Dipendra Misra",
      "Akshay Krishnamurthy",
      "John Langford"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04282"
  },
  {
    "id": "arXiv:2206.04285",
    "title": "Pseudo-Poincar\u00e9: A Unification Framework for Euclidean and Hyperbolic  Graph Neural Networks",
    "abstract": "Hyperbolic neural networks have recently gained significant attention due to\ntheir promising results on several graph problems including node classification\nand link prediction. The primary reason for this success is the effectiveness\nof the hyperbolic space in capturing the inherent hierarchy of graph datasets.\nHowever, they are limited in terms of generalization, scalability, and have\ninferior performance when it comes to non-hierarchical datasets. In this paper,\nwe take a completely orthogonal perspective for modeling hyperbolic networks.\nWe use Poincar\\'e disk to model the hyperbolic geometry and also treat it as if\nthe disk itself is a tangent space at origin. This enables us to replace\nnon-scalable M\\\"obius gyrovector operations with an Euclidean approximation,\nand thus simplifying the entire hyperbolic model to a Euclidean model cascaded\nwith a hyperbolic normalization function. Our approach does not adhere to\nM\\\"obius math, yet it still works in the Riemannian manifold, hence we call it\nPseudo-Poincar\\'e framework. We applied our non-linear hyperbolic normalization\nto the current state-of-the-art homogeneous and multi-relational graph networks\nand demonstrate significant improvements in performance compared to both\nEuclidean and hyperbolic counterparts. The primary impact of this work lies in\nits ability to capture hierarchical features in the Euclidean space, and thus,\ncan replace hyperbolic networks without loss in performance metrics while\nsimultaneously leveraging the power of Euclidean networks such as\ninterpretability and efficient execution of various model components.",
    "descriptor": "",
    "authors": [
      "Mehrdad Khatir",
      "Nurendra Choudhary",
      "Sutanay Choudhury",
      "Khushbu Agarwal",
      "Chandan K. Reddy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.04285"
  },
  {
    "id": "arXiv:2206.04287",
    "title": "Evaluating Aleatoric Uncertainty via Conditional Generative Models",
    "abstract": "Aleatoric uncertainty quantification seeks for distributional knowledge of\nrandom responses, which is important for reliability analysis and robustness\nimprovement in machine learning applications. Previous research on aleatoric\nuncertainty estimation mainly targets closed-formed conditional densities or\nvariances, which requires strong restrictions on the data distribution or\ndimensionality. To overcome these restrictions, we study conditional generative\nmodels for aleatoric uncertainty estimation. We introduce two metrics to\nmeasure the discrepancy between two conditional distributions that suit these\nmodels. Both metrics can be easily and unbiasedly computed via Monte Carlo\nsimulation of the conditional generative models, thus facilitating their\nevaluation and training. We demonstrate numerically how our metrics provide\ncorrect measurements of conditional distributional discrepancies and can be\nused to train conditional models competitive against existing benchmarks.",
    "descriptor": "",
    "authors": [
      "Ziyi Huang",
      "Henry Lam",
      "Haofeng Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.04287"
  },
  {
    "id": "arXiv:2206.04293",
    "title": "OptWedge: Cognitive Optimized Guidance toward Off-screen POIs",
    "abstract": "Guiding off-screen points of interest (POIs) is a practical way of providing\nadditional information to users of small-screen devices, such as smart devices\nand head-mounted displays. Popular previous methods involve displaying a\nprimitive figure referred to as Wedge on the screen for users to estimate\noff-screen POI on the invisible vertex. Because they utilize a cognitive\nprocess referred to as amodal completion, where users can imagine the entire\nfigure even when a part of it is occluded, localization accuracy is influenced\nby bias and individual differences. To improve the accuracy, we propose to\noptimize the figure using a cognitive cost that considers the influence. We\nalso design two types of optimizations with different parameters: unbiased\nOptWedge (UOW) and biased OptWedge (BOW). Experimental results indicate that\nOptWedge achieves more accurate guidance for a close distance compared to\nheuristics approach.",
    "descriptor": "\nComments: 14 pages,7 figures, accepted to PDPTA 2021\n",
    "authors": [
      "Shoki Miyagawa"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2206.04293"
  },
  {
    "id": "arXiv:2206.04294",
    "title": "FOAM: A Follower-aware Speaker Model For Vision-and-Language Navigation",
    "abstract": "The speaker-follower models have proven to be effective in\nvision-and-language navigation, where a speaker model is used to synthesize new\ninstructions to augment the training data for a follower navigation model.\nHowever, in many of the previous methods, the generated instructions are not\ndirectly trained to optimize the performance of the follower. In this paper, we\npresent \\textsc{foam}, a \\textsc{Fo}llower-\\textsc{a}ware speaker\n\\textsc{M}odel that is constantly updated given the follower feedback, so that\nthe generated instructions can be more suitable to the current learning state\nof the follower. Specifically, we optimize the speaker using a bi-level\noptimization framework and obtain its training signals by evaluating the\nfollower on labeled data. Experimental results on the Room-to-Room and\nRoom-across-Room datasets demonstrate that our methods can outperform strong\nbaseline models across settings. Analyses also reveal that our generated\ninstructions are of higher quality than the baselines.",
    "descriptor": "\nComments: NAACL 2022\n",
    "authors": [
      "Zi-Yi Dou",
      "Nanyun Peng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.04294"
  },
  {
    "id": "arXiv:2206.04295",
    "title": "Reconstruct Face from Features Using GAN Generator as a Distribution  Constraint",
    "abstract": "Face recognition based on the deep convolutional neural networks (CNN) shows\nsuperior accuracy performance attributed to the high discriminative features\nextracted. Yet, the security and privacy of the extracted features from deep\nlearning models (deep features) have been often overlooked. This paper proposes\nthe reconstruction of face images from deep features without accessing the CNN\nnetwork configurations as a constrained optimization problem. Such optimization\nminimizes the distance between the features extracted from the original face\nimage and the reconstructed face image. Instead of directly solving the\noptimization problem in the image space, we innovatively reformulate the\nproblem by looking for a latent vector of a GAN generator, then use it to\ngenerate the face image. The GAN generator serves as a dual role in this novel\nframework, i.e., face distribution constraint of the optimization goal and a\nface generator. On top of the novel optimization task, we also propose an\nattack pipeline to impersonate the target user based on the generated face\nimage. Our results show that the generated face images can achieve a\nstate-of-the-art successful attack rate of 98.0\\% on LFW under type-I attack @\nFAR of 0.1\\%. Our work sheds light on the biometric deployment to meet the\nprivacy-preserving and security policies.",
    "descriptor": "",
    "authors": [
      "Xingbo Dong",
      "Zhihui Miao",
      "Lan Ma",
      "Jiajun Shen",
      "Zhe Jin",
      "Zhenhua Guo",
      "Andrew Beng Jin Teoh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.04295"
  },
  {
    "id": "arXiv:2206.04301",
    "title": "Unveiling Transformers with LEGO: a synthetic reasoning task",
    "abstract": "We propose a synthetic task, LEGO (Learning Equality and Group Operations),\nthat encapsulates the problem of following a chain of reasoning, and we study\nhow the transformer architecture learns this task. We pay special attention to\ndata effects such as pretraining (on seemingly unrelated NLP tasks) and dataset\ncomposition (e.g., differing chain length at training and test time), as well\nas architectural variants such as weight-tied layers or adding convolutional\ncomponents. We study how the trained models eventually succeed at the task, and\nin particular, we are able to understand (to some extent) some of the attention\nheads as well as how the information flows in the network. Based on these\nobservations we propose a hypothesis that here pretraining helps merely due to\nbeing a smart initialization rather than some deep knowledge stored in the\nnetwork. We also observe that in some data regime the trained transformer finds\n\"shortcut\" solutions to follow the chain of reasoning, which impedes the\nmodel's ability to generalize to simple variants of the main task, and moreover\nwe find that one can prevent such shortcut with appropriate architecture\nmodification or careful data preparation. Motivated by our findings, we begin\nto explore the task of learning to execute C programs, where a convolutional\nmodification to transformers, namely adding convolutional structures in the\nkey/query/value maps, shows an encouraging edge.",
    "descriptor": "",
    "authors": [
      "Yi Zhang",
      "Arturs Backurs",
      "S\u00e9bastien Bubeck",
      "Ronen Eldan",
      "Suriya Gunasekar",
      "Tal Wagner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.04301"
  },
  {
    "id": "arXiv:2206.04303",
    "title": "Outage Analysis of Age-of-Information for Multi-Source Systems",
    "abstract": "Age of information (AoI) is an effective performance metric measuring the\nfreshness of information and is popular for applications involving status\nupdate. Most of the existing works have adopted average AoI as the metric,\nwhich cannot provide strict performance guarantees. In this work, the outage\nprobability of the peak AoI exceeding a given threshold is analyzed in a\nmulti-source system under round robin scheduling. Two queueing disciplines are\nconsidered, namely the first-come-first-serve (FCFS) queue and the single\npacket queue. For FCFS, upper and lower bounds on the outage probability are\nderived which coincides asymptotically, characterizing its true scaling. For\nthe single packet queue, an upper bound is derived whose effectiveness is\nvalidated by the simulation results. The analysis concretizes the common belief\nthat single packet queueing has a better AoI performance than FCFS. Moreover,\nit also reveals that the two disciplines would have similar asymptotic\nperformance when the inter-arrival time is much larger than the total\ntransmission time.",
    "descriptor": "",
    "authors": [
      "Guan-Yu Lin",
      "Yu-Chih Huang",
      "Yu-Pin Hsu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.04303"
  },
  {
    "id": "arXiv:2206.04310",
    "title": "GSmooth: Certified Robustness against Semantic Transformations via  Generalized Randomized Smoothing",
    "abstract": "Certified defenses such as randomized smoothing have shown promise towards\nbuilding reliable machine learning systems against $\\ell_p$-norm bounded\nattacks. However, existing methods are insufficient or unable to provably\ndefend against semantic transformations, especially those without closed-form\nexpressions (such as defocus blur and pixelate), which are more common in\npractice and often unrestricted. To fill up this gap, we propose generalized\nrandomized smoothing (GSmooth), a unified theoretical framework for certifying\nrobustness against general semantic transformations via a novel dimension\naugmentation strategy. Under the GSmooth framework, we present a scalable\nalgorithm that uses a surrogate image-to-image network to approximate the\ncomplex transformation. The surrogate model provides a powerful tool for\nstudying the properties of semantic transformations and certifying robustness.\nExperimental results on several datasets demonstrate the effectiveness of our\napproach for robustness certification against multiple kinds of semantic\ntransformations and corruptions, which is not achievable by the alternative\nbaselines.",
    "descriptor": "",
    "authors": [
      "Zhongkai Hao",
      "Chengyang Ying",
      "Yinpeng Dong",
      "Hang Su",
      "Jun Zhu",
      "Jian Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.04310"
  },
  {
    "id": "arXiv:2206.04311",
    "title": "Multi-class Classification with Fuzzy-feature Observations: Theory and  Algorithms",
    "abstract": "The theoretical analysis of multi-class classification has proved that the\nexisting multi-class classification methods can train a classifier with high\nclassification accuracy on the test set, when the instances are precise in the\ntraining and test sets with same distribution and enough instances can be\ncollected in the training set. However, one limitation with multi-class\nclassification has not been solved: how to improve the classification accuracy\nof multi-class classification problems when only imprecise observations are\navailable. Hence, in this paper, we propose a novel framework to address a new\nrealistic problem called multi-class classification with imprecise observations\n(MCIMO), where we need to train a classifier with fuzzy-feature observations.\nFirstly, we give the theoretical analysis of the MCIMO problem based on fuzzy\nRademacher complexity. Then, two practical algorithms based on support vector\nmachine and neural networks are constructed to solve the proposed new problem.\nExperiments on both synthetic and real-world datasets verify the rationality of\nour theoretical analysis and the efficacy of the proposed algorithms.",
    "descriptor": "\nComments: This article has been accepted by IEEE Transactions on Cybernetics on June 4, 2022\n",
    "authors": [
      "Guangzhi Ma",
      "Jie Lu",
      "Feng Liu",
      "Zhen Fang",
      "Guangquan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04311"
  },
  {
    "id": "arXiv:2206.04316",
    "title": "Adversarial Noises Are Linearly Separable for (Nearly) Random Neural  Networks",
    "abstract": "Adversarial examples, which are usually generated for specific inputs with a\nspecific model, are ubiquitous for neural networks. In this paper we unveil a\nsurprising property of adversarial noises when they are put together, i.e.,\nadversarial noises crafted by one-step gradient methods are linearly separable\nif equipped with the corresponding labels. We theoretically prove this property\nfor a two-layer network with randomly initialized entries and the neural\ntangent kernel setup where the parameters are not far from initialization. The\nproof idea is to show the label information can be efficiently backpropagated\nto the input while keeping the linear separability. Our theory and experimental\nevidence further show that the linear classifier trained with the adversarial\nnoises of the training data can well classify the adversarial noises of the\ntest data, indicating that adversarial noises actually inject a distributional\nperturbation to the original data distribution. Furthermore, we empirically\ndemonstrate that the adversarial noises may become less linearly separable when\nthe above conditions are compromised while they are still much easier to\nclassify than original features.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Huishuai Zhang",
      "Da Yu",
      "Yiping Lu",
      "Di He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.04316"
  },
  {
    "id": "arXiv:2206.04317",
    "title": "Topic-Aware Evaluation and Transformer Methods for Topic-Controllable  Summarization",
    "abstract": "Topic-controllable summarization is an emerging research area with a wide\nrange of potential applications. However, existing approaches suffer from\nsignificant limitations. First, there is currently no established evaluation\nmetric for this task. Furthermore, existing methods built upon recurrent\narchitectures, which can significantly limit their performance compared to more\nrecent Transformer-based architectures, while they also require modifications\nto the model's architecture for controlling the topic. In this work, we propose\na new topic-oriented evaluation measure to automatically evaluate the generated\nsummaries based on the topic affinity between the generated summary and the\ndesired topic. We also conducted a user study that validates the reliability of\nthis measure. Finally, we propose simple, yet powerful methods for\ntopic-controllable summarization either incorporating topic embeddings into the\nmodel's architecture or employing control tokens to guide the summary\ngeneration. Experimental results show that control tokens can achieve better\nperformance compared to more complicated embedding-based approaches while being\nat the same time significantly faster.",
    "descriptor": "",
    "authors": [
      "Tatiana Passali",
      "Grigorios Tsoumakas"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.04317"
  },
  {
    "id": "arXiv:2206.04318",
    "title": "Blind Surveillance Image Quality Assessment via Deep Neural Network  Combined with the Visual Saliency",
    "abstract": "The intelligent video surveillance system (IVSS) can automatically analyze\nthe content of the surveillance image (SI) and reduce the burden of the manual\nlabour. However, the SIs may suffer quality degradations in the procedure of\nacquisition, compression, and transmission, which makes IVSS hard to understand\nthe content of SIs. In this paper, we first conduct an example experiment (i.e.\nthe face detection task) to demonstrate that the quality of the SIs has a\ncrucial impact on the performance of the IVSS, and then propose a\nsaliency-based deep neural network for the blind quality assessment of the SIs,\nwhich helps IVSS to filter the low-quality SIs and improve the detection and\nrecognition performance. Specifically, we first compute the saliency map of the\nSI to select the most salient local region since the salient regions usually\ncontain rich semantic information for machine vision and thus have a great\nimpact on the overall quality of the SIs. Next, the convolutional neural\nnetwork (CNN) is adopted to extract quality-aware features for the whole image\nand local region, which are then mapped into the global and local quality\nscores through the fully connected (FC) network respectively. Finally, the\noverall quality score is computed as the weighted sum of the global and local\nquality scores. Experimental results on the SI quality database (SIQD) show\nthat the proposed method outperforms all compared state-of-the-art BIQA\nmethods.",
    "descriptor": "",
    "authors": [
      "Wei Lu",
      "Wei Sun",
      "Wenhan Zhu",
      "Xiongkuo Min",
      "Zicheng Zhang",
      "Tao Wang",
      "Guangtao Zhai"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.04318"
  },
  {
    "id": "arXiv:2206.04325",
    "title": "CFA: Coupled-hypersphere-based Feature Adaptation for Target-Oriented  Anomaly Localization",
    "abstract": "For a long time, anomaly localization has been widely used in industries.\nPrevious studies focused on approximating the distribution of normal features\nwithout adaptation to a target dataset. However, since anomaly localization\nshould precisely discriminate normal and abnormal features, the absence of\nadaptation may make the normality of abnormal features overestimated. Thus, we\npropose Coupled-hypersphere-based Feature Adaptation (CFA) which accomplishes\nsophisticated anomaly localization using features adapted to the target\ndataset. CFA consists of (1) a learnable patch descriptor that learns and\nembeds target-oriented features and (2) scalable memory bank independent of the\nsize of the target dataset. And, CFA adopts transfer learning to increase the\nnormal feature density so that abnormal features can be clearly distinguished\nby applying patch descriptor and memory bank to a pre-trained CNN. The proposed\nmethod outperforms the previous methods quantitatively and qualitatively. For\nexample, it provides an AUROC score of 99.5% in anomaly detection and 98.5% in\nanomaly localization of MVTec AD benchmark. In addition, this paper points out\nthe negative effects of biased features of pre-trained CNNs and emphasizes the\nimportance of the adaptation to the target dataset. The code is publicly\navailable at https://github.com/sungwool/CFA_for_anomaly_localization.",
    "descriptor": "",
    "authors": [
      "Sungwook Lee",
      "Seunghyun Lee",
      "Byung Cheol Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04325"
  },
  {
    "id": "arXiv:2206.04327",
    "title": "Language Identification for Austronesian Languages",
    "abstract": "This paper provides language identification models for low- and\nunder-resourced languages in the Pacific region with a focus on previously\nunavailable Austronesian languages. Accurate language identification is an\nimportant part of developing language resources. The approach taken in this\npaper combines 29 Austronesian languages with 171 non-Austronesian languages to\ncreate an evaluation set drawn from eight data sources. After evaluating six\napproaches to language identification, we find that a classifier based on\nskip-gram embeddings reaches a significantly higher performance than alternate\nmethods. We then systematically increase the number of non-Austronesian\nlanguages in the model up to a total of 800 languages to evaluate whether an\nincreased language inventory leads to less precise predictions for the\nAustronesian languages of interest. This evaluation finds that there is only a\nminimal impact on accuracy caused by increasing the inventory of\nnon-Austronesian languages. Further experiments adapt these language\nidentification models for code-switching detection, achieving high accuracy\nacross all 29 languages.",
    "descriptor": "",
    "authors": [
      "Jonathan Dunn",
      "Wikke Nijhof"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.04327"
  },
  {
    "id": "arXiv:2206.04330",
    "title": "Predicting Embedding Reliability in Low-Resource Settings Using Corpus  Similarity Measures",
    "abstract": "This paper simulates a low-resource setting across 17 languages in order to\nevaluate embedding similarity, stability, and reliability under different\nconditions. The goal is to use corpus similarity measures before training to\npredict properties of embeddings after training. The main contribution of the\npaper is to show that it is possible to predict downstream embedding similarity\nusing upstream corpus similarity measures. This finding is then applied to\nlow-resource settings by modelling the reliability of embeddings created from\nvery limited training data. Results show that it is possible to estimate the\nreliability of low-resource embeddings using corpus similarity measures that\nremain robust on small amounts of data. These findings have significant\nimplications for the evaluation of truly low-resource languages in which such\nsystematic downstream validation methods are not possible because of data\nlimitations.",
    "descriptor": "",
    "authors": [
      "Jonathan Dunn",
      "Haipeng Li",
      "Damian Sastre"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.04330"
  },
  {
    "id": "arXiv:2206.04332",
    "title": "Corpus Similarity Measures Remain Robust Across Diverse Languages",
    "abstract": "This paper experiments with frequency-based corpus similarity measures across\n39 languages using a register prediction task. The goal is to quantify (i) the\ndistance between different corpora from the same language and (ii) the\nhomogeneity of individual corpora. Both of these goals are essential for\nmeasuring how well corpus-based linguistic analysis generalizes from one\ndataset to another. The problem is that previous work has focused on\nIndo-European languages, raising the question of whether these measures are\nable to provide robust generalizations across diverse languages. This paper\nuses a register prediction task to evaluate competing measures across 39\nlanguages: how well are they able to distinguish between corpora representing\ndifferent contexts of production? Each experiment compares three corpora from a\nsingle language, with the same three digital registers shared across all\nlanguages: social media, web pages, and Wikipedia. Results show that measures\nof corpus similarity retain their validity across different language families,\nwriting systems, and types of morphology. Further, the measures remain robust\nwhen evaluated on out-of-domain corpora, when applied to low-resource\nlanguages, and when applied to different sets of registers. These findings are\nsignificant given our need to make generalizations across the rapidly\nincreasing number of corpora available for analysis.",
    "descriptor": "",
    "authors": [
      "Haipeng Li",
      "Jonathan Dunn"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.04332"
  },
  {
    "id": "arXiv:2206.04335",
    "title": "Learning to generate imaginary tasks for improving generalization in  meta-learning",
    "abstract": "The success of meta-learning on existing benchmarks is predicated on the\nassumption that the distribution of meta-training tasks covers meta-testing\ntasks. Frequent violation of the assumption in applications with either\ninsufficient tasks or a very narrow meta-training task distribution leads to\nmemorization or learner overfitting. Recent solutions have pursued augmentation\nof meta-training tasks, while it is still an open question to generate both\ncorrect and sufficiently imaginary tasks. In this paper, we seek an approach\nthat up-samples meta-training tasks from the task representation via a task\nup-sampling network. Besides, the resulting approach named Adversarial Task\nUp-sampling (ATU) suffices to generate tasks that can maximally contribute to\nthe latest meta-learner by maximizing an adversarial loss. On few-shot sine\nregression and image classification datasets, we empirically validate the\nmarked improvement of ATU over state-of-the-art task augmentation strategies in\nthe meta-testing performance and also the quality of up-sampled tasks.",
    "descriptor": "",
    "authors": [
      "Yichen Wu",
      "Long-Kai Huang",
      "Ying Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04335"
  },
  {
    "id": "arXiv:2206.04349",
    "title": "Deep radiomic signature with immune cell markers predicts the survival  of glioma patients",
    "abstract": "Imaging biomarkers offer a non-invasive way to predict the response of\nimmunotherapy prior to treatment. In this work, we propose a novel type of deep\nradiomic features (DRFs) computed from a convolutional neural network (CNN),\nwhich capture tumor characteristics related to immune cell markers and overall\nsurvival. Our study uses four MRI sequences (T1-weighted, T1-weighted\npost-contrast, T2-weighted and FLAIR) with corresponding immune cell markers of\n151 patients with brain tumor. The proposed method extracts a total of 180 DRFs\nby aggregating the activation maps of a pre-trained 3D-CNN within labeled tumor\nregions of MRI scans. These features offer a compact, yet powerful\nrepresentation of regional texture encoding tissue heterogeneity. A\ncomprehensive set of experiments is performed to assess the relationship\nbetween the proposed DRFs and immune cell markers, and measure their\nassociation with overall survival. Results show a high correlation between DRFs\nand various markers, as well as significant differences between patients\ngrouped based on these markers. Moreover, combining DRFs, clinical features and\nimmune cell markers as input to a random forest classifier helps discriminate\nbetween short and long survival outcomes, with AUC of 72\\% and\np=2.36$\\times$10$^{-5}$. These results demonstrate the usefulness of proposed\nDRFs as non-invasive biomarker for predicting treatment response in patients\nwith brain tumors.",
    "descriptor": "",
    "authors": [
      "Ahmad Chaddad",
      "Paul Daniel Mingli Zhang",
      "Saima Rathore",
      "Paul Sargos",
      "Christian Desrosiers",
      "Tamim Niazi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Genomics (q-bio.GN)",
      "Quantitative Methods (q-bio.QM)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2206.04349"
  },
  {
    "id": "arXiv:2206.04354",
    "title": "Long-Term or Temporary? Hybrid Worker Recruitment for Mobile Crowd  Sensing and Computing",
    "abstract": "Mobile crowd sensing and computing (MCSC) enables heterogeneous users\n(workers) to contribute real-time sensed, generated, and pre-processed data\nfrom their mobile devices to the MCSC platform, for intelligent service\nprovisioning. This paper investigates a novel hybrid worker recruitment problem\nwhere the MCSC platform employs workers to serve MCSC tasks with diverse\nquality requirements and budget constraints, while considering uncertainties in\nworkers' participation and their local workloads. We propose a hybrid worker\nrecruitment framework consisting of offline and online trading modes. The\nformer enables the platform to overbook long-term workers (services) to cope\nwith dynamic service supply via signing contracts in advance, which is\nformulated as 0-1 integer linear programming (ILP) with probabilistic\nconstraints related to service quality and budget. Besides, motivated by the\nexisting uncertainties which may render long-term workers fail to meet the\nservice quality requirement of each task, we augment our methodology with an\nonline temporary worker recruitment scheme as a backup Plan B to support\nseamless service provisioning for MCSC tasks, which also represents a 0-1 ILP\nproblem. To tackle these problems which are proved to be NP-hard, we develop\nthree algorithms, namely, i) exhaustive searching, ii) unique index-based\nstochastic searching with risk-aware filter constraint, and iii) geometric\nprogramming-based successive convex algorithm, which achieve the optimal (with\nhigh computational complexity) or sub-optimal (with low complexity) solutions.\nExperimental results demonstrate the effectiveness of our proposed hybrid\nworker recruitment mechanism in terms of service quality, time efficiency, etc.",
    "descriptor": "",
    "authors": [
      "Minghui Liwang",
      "Zhibin Gao",
      "Seyyedali Hosseinalipour",
      "Zhipeng Cheng",
      "Xianbin Wang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2206.04354"
  },
  {
    "id": "arXiv:2206.04355",
    "title": "Graph Attention Multi-Layer Perceptron",
    "abstract": "Graph neural networks (GNNs) have achieved great success in many graph-based\napplications. However, the enormous size and high sparsity level of graphs\nhinder their applications under industrial scenarios. Although some scalable\nGNNs are proposed for large-scale graphs, they adopt a fixed $K$-hop\nneighborhood for each node, thus facing the over-smoothing issue when adopting\nlarge propagation depths for nodes within sparse regions. To tackle the above\nissue, we propose a new GNN architecture -- Graph Attention Multi-Layer\nPerceptron (GAMLP), which can capture the underlying correlations between\ndifferent scales of graph knowledge. We have deployed GAMLP in Tencent with the\nAngel platform, and we further evaluate GAMLP on both real-world datasets and\nlarge-scale industrial datasets. Extensive experiments on these 14 graph\ndatasets demonstrate that GAMLP achieves state-of-the-art performance while\nenjoying high scalability and efficiency. Specifically, it outperforms GAT by\n1.3\\% regarding predictive accuracy on our large-scale Tencent Video dataset\nwhile achieving up to $50\\times$ training speedup. Besides, it ranks top-1 on\nboth the leaderboards of the largest homogeneous and heterogeneous graph (i.e.,\nogbn-papers100M and ogbn-mag) of Open Graph Benchmark.",
    "descriptor": "\nComments: 11 pages, 7 figures. arXiv admin note: text overlap with arXiv:2108.10097\n",
    "authors": [
      "Wentao Zhang",
      "Ziqi Yin",
      "Zeang Sheng",
      "Yang Li",
      "Wen Ouyang",
      "Xiaosen Li",
      "Yangyu Tao",
      "Zhi Yang",
      "Bin Cui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.04355"
  },
  {
    "id": "arXiv:2206.04359",
    "title": "Trajectory-dependent Generalization Bounds for Deep Neural Networks via  Fractional Brownian Motion",
    "abstract": "Despite being tremendously overparameterized, it is appreciated that deep\nneural networks trained by stochastic gradient descent (SGD) generalize\nsurprisingly well. Based on the Rademacher complexity of a pre-specified\nhypothesis set, different norm-based generalization bounds have been developed\nto explain this phenomenon. However, recent studies suggest these bounds might\nbe problematic as they increase with the training set size, which is contrary\nto empirical evidence. In this study, we argue that the hypothesis set SGD\nexplores is trajectory-dependent and thus may provide a tighter bound over its\nRademacher complexity. To this end, we characterize the SGD recursion via a\nstochastic differential equation by assuming the incurred stochastic gradient\nnoise follows the fractional Brownian motion. We then identify the Rademacher\ncomplexity in terms of the covering numbers and relate it to the Hausdorff\ndimension of the optimization trajectory. By invoking the hypothesis set\nstability, we derive a novel generalization bound for deep neural networks.\nExtensive experiments demonstrate that it predicts well the generalization gap\nover several common experimental interventions. We further show that the Hurst\nparameter of the fractional Brownian motion is more informative than existing\ngeneralization indicators such as the power-law index and the upper\nBlumenthal-Getoor index.",
    "descriptor": "\nComments: 35pages, 15figures\n",
    "authors": [
      "Chengli Tan",
      "Jiangshe Zhang",
      "Junmin Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.04359"
  },
  {
    "id": "arXiv:2206.04360",
    "title": "A general approximation lower bound in $L^p$ norm, with applications to  feed-forward neural networks",
    "abstract": "We study the fundamental limits to the expressive power of neural networks.\nGiven two sets $F$, $G$ of real-valued functions, we first prove a general\nlower bound on how well functions in $F$ can be approximated in $L^p(\\mu)$ norm\nby functions in $G$, for any $p \\geq 1$ and any probability measure $\\mu$. The\nlower bound depends on the packing number of $F$, the range of $F$, and the\nfat-shattering dimension of $G$. We then instantiate this bound to the case\nwhere $G$ corresponds to a piecewise-polynomial feed-forward neural network,\nand describe in details the application to two sets $F$: H{\\\"o}lder balls and\nmultivariate monotonic functions. Beside matching (known or new) upper bounds\nup to log factors, our lower bounds shed some light on the similarities or\ndifferences between approximation in $L^p$ norm or in sup norm, solving an open\nquestion by DeVore et al. (2021). Our proof strategy differs from the sup norm\ncase and uses a key probability result of Mendelson (2002).",
    "descriptor": "",
    "authors": [
      "El Mehdi Achour",
      "Armand Foucault",
      "S\u00e9bastien Gerchinovitz",
      "Fran\u00e7ois Malgouyres"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.04360"
  },
  {
    "id": "arXiv:2206.04361",
    "title": "Model Degradation Hinders Deep Graph Neural Networks",
    "abstract": "Graph Neural Networks (GNNs) have achieved great success in various graph\nmining tasks.However, drastic performance degradation is always observed when a\nGNN is stacked with many layers. As a result, most GNNs only have shallow\narchitectures, which limits their expressive power and exploitation of deep\nneighborhoods.Most recent studies attribute the performance degradation of deep\nGNNs to the \\textit{over-smoothing} issue. In this paper, we disentangle the\nconventional graph convolution operation into two independent operations:\n\\textit{Propagation} (\\textbf{P}) and \\textit{Transformation}\n(\\textbf{T}).Following this, the depth of a GNN can be split into the\npropagation depth ($D_p$) and the transformation depth ($D_t$). Through\nextensive experiments, we find that the major cause for the performance\ndegradation of deep GNNs is the \\textit{model degradation} issue caused by\nlarge $D_t$ rather than the \\textit{over-smoothing} issue mainly caused by\nlarge $D_p$. Further, we present \\textit{Adaptive Initial Residual} (AIR), a\nplug-and-play module compatible with all kinds of GNN architectures, to\nalleviate the \\textit{model degradation} issue and the \\textit{over-smoothing}\nissue simultaneously. Experimental results on six real-world datasets\ndemonstrate that GNNs equipped with AIR outperform most GNNs with shallow\narchitectures owing to the benefits of both large $D_p$ and $D_t$, while the\ntime costs associated with AIR can be ignored.",
    "descriptor": "\nComments: 11 pages, 10 figures\n",
    "authors": [
      "Wentao Zhang",
      "Zeang Sheng",
      "Ziqi Yin",
      "Yuezihan Jiang",
      "Yikuan Xia",
      "Jun Gao",
      "Zhi Yang",
      "Bin Cui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04361"
  },
  {
    "id": "arXiv:2206.04363",
    "title": "Deep Neural Network for Blind Visual Quality Assessment of 4K Content",
    "abstract": "The 4K content can deliver a more immersive visual experience to consumers\ndue to the huge improvement of spatial resolution. However, existing blind\nimage quality assessment (BIQA) methods are not suitable for the original and\nupscaled 4K contents due to the expanded resolution and specific distortions.\nIn this paper, we propose a deep learning-based BIQA model for 4K content,\nwhich on one hand can recognize true and pseudo 4K content and on the other\nhand can evaluate their perceptual visual quality. Considering the\ncharacteristic that high spatial resolution can represent more abundant\nhigh-frequency information, we first propose a Grey-level Co-occurrence Matrix\n(GLCM) based texture complexity measure to select three representative image\npatches from a 4K image, which can reduce the computational complexity and is\nproven to be very effective for the overall quality prediction through\nexperiments. Then we extract different kinds of visual features from the\nintermediate layers of the convolutional neural network (CNN) and integrate\nthem into the quality-aware feature representation. Finally, two multilayer\nperception (MLP) networks are utilized to map the quality-aware features into\nthe class probability and the quality score for each patch respectively. The\noverall quality index is obtained through the average pooling of patch results.\nThe proposed model is trained through the multi-task learning manner and we\nintroduce an uncertainty principle to balance the losses of the classification\nand regression tasks. The experimental results show that the proposed model\noutperforms all compared BIQA metrics on four 4K content quality assessment\ndatabases.",
    "descriptor": "",
    "authors": [
      "Wei Lu",
      "Wei Sun",
      "Xiongkuo Min",
      "Wenhan Zhu",
      "Quan Zhou",
      "Jun He",
      "Qiyuan Wang",
      "Zicheng Zhang",
      "Tao Wang",
      "Guangtao Zhai"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.04363"
  },
  {
    "id": "arXiv:2206.04364",
    "title": "Cross-Model Conjunctive Queries over Relation and Tree-structured Data  (Extended)",
    "abstract": "Conjunctive queries are the most basic and central class of database queries.\nWith the continued growth of demands to manage and process the massive volume\nof different types of data, there is little research to study the conjunctive\nqueries between relation and tree data. In this paper, we study of Cross-Model\nConjunctive Queries (CMCQs) over relation and tree-structured data (XML and\nJSON). To efficiently process CMCQs with bounded intermediate results, we first\nencode tree nodes with position information. With tree node original label\nvalues and encoded position values, it allows our proposed algorithm CMJoin to\njoin relations and tree data simultaneously, avoiding massive intermediate\nresults. CMJoin achieves worst-case optimality in terms of the total result of\nlabel values and encoded position values. Experimental results demonstrate the\nefficiency and scalability of the proposed techniques to answer a CMCQ in terms\nof running time and intermediate result size.",
    "descriptor": "",
    "authors": [
      "Yuxing Chen",
      "Jiaheng Lu"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2206.04364"
  },
  {
    "id": "arXiv:2206.04365",
    "title": "CARLA-GeAR: a Dataset Generator for a Systematic Evaluation of  Adversarial Robustness of Vision Models",
    "abstract": "Adversarial examples represent a serious threat for deep neural networks in\nseveral application domains and a huge amount of work has been produced to\ninvestigate them and mitigate their effects. Nevertheless, no much work has\nbeen devoted to the generation of datasets specifically designed to evaluate\nthe adversarial robustness of neural models. This paper presents CARLA-GeAR, a\ntool for the automatic generation of photo-realistic synthetic datasets that\ncan be used for a systematic evaluation of the adversarial robustness of neural\nmodels against physical adversarial patches, as well as for comparing the\nperformance of different adversarial defense/detection methods. The tool is\nbuilt on the CARLA simulator, using its Python API, and allows the generation\nof datasets for several vision tasks in the context of autonomous driving. The\nadversarial patches included in the generated datasets are attached to\nbillboards or the back of a truck and are crafted by using state-of-the-art\nwhite-box attack strategies to maximize the prediction error of the model under\ntest. Finally, the paper presents an experimental study to evaluate the\nperformance of some defense methods against such attacks, showing how the\ndatasets generated with CARLA-GeAR might be used in future work as a benchmark\nfor adversarial defense in the real world. All the code and datasets used in\nthis paper are available at this http URL",
    "descriptor": "",
    "authors": [
      "Federico Nesti",
      "Giulio Rossolini",
      "Gianluca D'Amico",
      "Alessandro Biondi",
      "Giorgio Buttazzo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.04365"
  },
  {
    "id": "arXiv:2206.04367",
    "title": "Distinct Angles in General Position",
    "abstract": "The Erd\\H{o}s distinct distance problem is a ubiquitous problem in discrete\ngeometry. Somewhat less well known is Erd\\H{o}s' distinct angle problem, the\nproblem of finding the minimum number of distinct angles between $n$\nnon-collinear points in the plane. Recent work has introduced bounds on a wide\narray of variants of this problem, inspired by similar variants in the distance\nsetting.\nIn this short note, we improve the best known upper bound for the minimum\nnumber of distinct angles formed by $n$ points in general position from\n$O(n^{\\log_2(7)})$ to $O(n^2)$. Before this work, similar bounds relied on\nprojections onto a generic plane from higher dimensional space. In this paper,\nwe employ the geometric properties of a logarithmic spiral, sidestepping the\nneed for a projection.",
    "descriptor": "",
    "authors": [
      "Henry L. Fleischmann",
      "Sergei V. Konyagin",
      "Steven J. Miller",
      "Eyvindur A. Palsson",
      "Ethan Pesikoff",
      "Charles Wolf"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Combinatorics (math.CO)",
      "Metric Geometry (math.MG)"
    ],
    "url": "https://arxiv.org/abs/2206.04367"
  },
  {
    "id": "arXiv:2206.04371",
    "title": "Ancestor-to-Creole Transfer is Not a Walk in the Park",
    "abstract": "We aim to learn language models for Creole languages for which large volumes\nof data are not readily available, and therefore explore the potential transfer\nfrom ancestor languages (the 'Ancestry Transfer Hypothesis'). We find that\nstandard transfer methods do not facilitate ancestry transfer. Surprisingly,\ndifferent from other non-Creole languages, a very distinct two-phase pattern\nemerges for Creoles: As our training losses plateau, and language models begin\nto overfit on their source languages, perplexity on the Creoles drop. We\nexplore if this compression phase can lead to practically useful language\nmodels (the 'Ancestry Bottleneck Hypothesis'), but also falsify this. Moreover,\nwe show that Creoles even exhibit this two-phase pattern even when training on\nrandom, unrelated languages. Thus Creoles seem to be typological outliers and\nwe speculate whether there is a link between the two observations.",
    "descriptor": "\nComments: Workshop on Insights from Negative Results in NLP 2022\n",
    "authors": [
      "Heather Lent",
      "Emanuele Bugliarello",
      "Anders S\u00f8gaard"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.04371"
  },
  {
    "id": "arXiv:2206.04372",
    "title": "Diagnosing Ensemble Few-Shot Classifiers",
    "abstract": "The base learners and labeled samples (shots) in an ensemble few-shot\nclassifier greatly affect the model performance. When the performance is not\nsatisfactory, it is usually difficult to understand the underlying causes and\nmake improvements. To tackle this issue, we propose a visual analysis method,\nFSLDiagnotor. Given a set of base learners and a collection of samples with a\nfew shots, we consider two problems: 1) finding a subset of base learners that\nwell predict the sample collections; and 2) replacing the low-quality shots\nwith more representative ones to adequately represent the sample collections.\nWe formulate both problems as sparse subset selection and develop two selection\nalgorithms to recommend appropriate learners and shots, respectively. A matrix\nvisualization and a scatterplot are combined to explain the recommended\nlearners and shots in context and facilitate users in adjusting them. Based on\nthe adjustment, the algorithm updates the recommendation results for another\nround of improvement. Two case studies are conducted to demonstrate that\nFSLDiagnotor helps build a few-shot classifier efficiently and increases the\naccuracy by 12% and 21%, respectively.",
    "descriptor": "\nComments: Accepted in IEEE TVCG\n",
    "authors": [
      "Weikai Yang",
      "Xi Ye",
      "Xingxing Zhang",
      "Lanxi Xiao",
      "Jiazhi Xia",
      "Zhongyuan Wang",
      "Jun Zhu",
      "Hanspeter Pfister",
      "Shixia Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04372"
  },
  {
    "id": "arXiv:2206.04374",
    "title": "Uncovering bias in the PlantVillage dataset",
    "abstract": "We report our investigation on the use of the popular PlantVillage dataset\nfor training deep learning based plant disease detection models. We trained a\nmachine learning model using only 8 pixels from the PlantVillage image\nbackgrounds. The model achieved 49.0% accuracy on the held-out test set, well\nabove the random guessing accuracy of 2.6%. This result indicates that the\nPlantVillage dataset contains noise correlated with the labels and deep\nlearning models can easily exploit this bias to make predictions. Possible\napproaches to alleviate this problem are discussed.",
    "descriptor": "",
    "authors": [
      "Mehmet Alican Noyan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04374"
  },
  {
    "id": "arXiv:2206.04380",
    "title": "Hinted Dictionaries: Efficient Functional Ordered Sets and Maps",
    "abstract": "This article introduces hinted dictionaries for expressing efficient ordered\nsets and maps functionally. As opposed to the traditional ordered dictionaries\nwith logarithmic operations, hinted dictionaries can achieve better performance\nby using cursor-like objects referred to as hints. Hinted dictionaries unify\nthe interfaces of imperative ordered dictionaries (e.g., C++ maps) and\nfunctional ones (e.g., Adams' sets). We show that such dictionaries can use\nsorted arrays, unbalanced trees, and balanced trees as their underlying\nrepresentations. Throughout the article, we use Scala to present the different\ncomponents of hinted dictionaries. We also provide a C++ implementation to\nevaluate the effectiveness of hinted dictionaries. Hinted dictionaries provide\nsuperior performance for set-set operations in comparison with the standard\nlibrary of C++. Also, they show a competitive performance in comparison with\nthe SciPy library for sparse vector operations.",
    "descriptor": "",
    "authors": [
      "Amir Shaikhha",
      "Mahdi Ghorbani",
      "Hesam Shahrokhi"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.04380"
  },
  {
    "id": "arXiv:2206.04381",
    "title": "STIP: A SpatioTemporal Information-Preserving and Perception-Augmented  Model for High-Resolution Video Prediction",
    "abstract": "Although significant achievements have been achieved by recurrent neural\nnetwork (RNN) based video prediction methods, their performance in datasets\nwith high resolutions is still far from satisfactory because of the information\nloss problem and the perception-insensitive mean square error (MSE) based loss\nfunctions. In this paper, we propose a Spatiotemporal Information-Preserving\nand Perception-Augmented Model (STIP) to solve the above two problems. To solve\nthe information loss problem, the proposed model aims to preserve the\nspatiotemporal information for videos during the feature extraction and the\nstate transitions, respectively. Firstly, a Multi-Grained Spatiotemporal\nAuto-Encoder (MGST-AE) is designed based on the X-Net structure. The proposed\nMGST-AE can help the decoders recall multi-grained information from the\nencoders in both the temporal and spatial domains. In this way, more\nspatiotemporal information can be preserved during the feature extraction for\nhigh-resolution videos. Secondly, a Spatiotemporal Gated Recurrent Unit (STGRU)\nis designed based on the standard Gated Recurrent Unit (GRU) structure, which\ncan efficiently preserve spatiotemporal information during the state\ntransitions. The proposed STGRU can achieve more satisfactory performance with\na much lower computation load compared with the popular Long Short-Term (LSTM)\nbased predictive memories. Furthermore, to improve the traditional MSE loss\nfunctions, a Learned Perceptual Loss (LP-loss) is further designed based on the\nGenerative Adversarial Networks (GANs), which can help obtain a satisfactory\ntrade-off between the objective quality and the perceptual quality.\nExperimental results show that the proposed STIP can predict videos with more\nsatisfactory visual quality compared with a variety of state-of-the-art\nmethods. Source code has been available at\n\\url{https://github.com/ZhengChang467/STIPHR}.",
    "descriptor": "\nComments: This journal paper is extended from our previous work accepted in CVPR2022 and has been submitted to IEEE Transactions on Multimedia\n",
    "authors": [
      "Zheng Chang",
      "Xinfeng Zhang",
      "Shanshe Wang",
      "Siwei Ma",
      "Wen Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.04381"
  },
  {
    "id": "arXiv:2206.04382",
    "title": "CLIP-Actor: Text-Driven Recommendation and Stylization for Animating  Human Meshes",
    "abstract": "We propose CLIP-Actor, a text-driven motion recommendation and neural mesh\nstylization system for human mesh animation. CLIP-Actor animates a 3D human\nmesh to conform to a text prompt by recommending a motion sequence and learning\nmesh style attributes. Prior work fails to generate plausible results when the\nartist-designed mesh content does not conform to the text from the beginning.\nInstead, we build a text-driven human motion recommendation system by\nleveraging a large-scale human motion dataset with language labels. Given a\nnatural language prompt, CLIP-Actor first suggests a human motion that conforms\nto the prompt in a coarse-to-fine manner. Then, we propose a\nsynthesize-through-optimization method that detailizes and texturizes a\nrecommended mesh sequence in a disentangled way from the pose of each frame. It\nallows the style attribute to conform to the prompt in a temporally-consistent\nand pose-agnostic manner. The decoupled neural optimization also enables\nspatio-temporal view augmentation from multi-frame human motion. We further\npropose the mask-weighted embedding attention, which stabilizes the\noptimization process by rejecting distracting renders containing scarce\nforeground pixels. We demonstrate that CLIP-Actor produces plausible and\nhuman-recognizable style 3D human mesh in motion with detailed geometry and\ntexture from a natural language prompt.",
    "descriptor": "\nComments: main paper: 18 pages, 9 figures, 1 table / supplementary: 5 pages, 3 figures\n",
    "authors": [
      "Kim Youwang",
      "Kim Ji-Yeon",
      "Tae-Hyun Oh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2206.04382"
  },
  {
    "id": "arXiv:2206.04384",
    "title": "Value Memory Graph: A Graph-Structured World Model for Offline  Reinforcement Learning",
    "abstract": "World models in model-based reinforcement learning usually face unrealistic\nlong-time-horizon prediction issues due to compounding errors as the prediction\nerrors accumulate over timesteps. Recent works in graph-structured world models\nimprove the long-horizon reasoning ability via building a graph to represent\nthe environment, but they are designed in a goal-conditioned setting and cannot\nguide the agent to maximize episode returns in a traditional reinforcement\nlearning setting without externally given target states. To overcome this\nlimitation, we design a graph-structured world model in offline reinforcement\nlearning by building a directed-graph-based Markov decision process (MDP) with\nrewards allocated to each directed edge as an abstraction of the original\ncontinuous environment. As our world model has small and finite state/action\nspaces compared to the original environment, value iteration can be easily\napplied here to estimate state values on the graph and figure out the best\nfuture. Unlike previous graph-structured world models that requires externally\nprovided targets, our world model, dubbed Value Memory Graph (VMG), can provide\nthe desired targets with high values by itself. VMG can be used to guide\nlow-level goal-conditioned policies that are trained via supervised learning to\nmaximize episode returns. Experiments on the D4RL benchmark show that VMG can\noutperform state-of-the-art methods in several tasks where long horizon\nreasoning ability is crucial. Code will be made publicly available.",
    "descriptor": "",
    "authors": [
      "Deyao Zhu",
      "Li Erran Li",
      "Mohamed Elhoseiny"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.04384"
  },
  {
    "id": "arXiv:2206.04385",
    "title": "HideNseek: Federated Lottery Ticket via Server-side Pruning and Sign  Supermask",
    "abstract": "Federated learning alleviates the privacy risk in distributed learning by\ntransmitting only the local model updates to the central server. However, it\nfaces challenges including statistical heterogeneity of clients' datasets and\nresource constraints of client devices, which severely impact the training\nperformance and user experience. Prior works have tackled these challenges by\ncombining personalization with model compression schemes including quantization\nand pruning. However, the pruning is data-dependent and thus must be done on\nthe client side which requires considerable computation cost. Moreover, the\npruning normally trains a binary supermask $\\in \\{0, 1\\}$ which significantly\nlimits the model capacity yet with no computation benefit. Consequently, the\ntraining requires high computation cost and a long time to converge while the\nmodel performance does not pay off. In this work, we propose HideNseek which\nemploys one-shot data-agnostic pruning at initialization to get a subnetwork\nbased on weights' synaptic saliency. Each client then optimizes a sign\nsupermask $\\in \\{-1, +1\\}$ multiplied by the unpruned weights to allow faster\nconvergence with the same compression rates as state-of-the-art. Empirical\nresults from three datasets demonstrate that compared to state-of-the-art,\nHideNseek improves inferences accuracies by up to 40.6\\% while reducing the\ncommunication cost and training time by up to 39.7\\% and 46.8\\% respectively.",
    "descriptor": "",
    "authors": [
      "Anish K. Vallapuram",
      "Pengyuan Zhou",
      "Young D. Kwon",
      "Lik Hang Lee",
      "Hengwei Xu",
      "Pan Hui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04385"
  },
  {
    "id": "arXiv:2206.04386",
    "title": "Interaction Design for VR Applications: Understanding Needs for  University Curricula",
    "abstract": "As virtual reality (VR) is emerging in the tech sector, developers and\ndesigners are under pressure to create immersive experiences for their\nproducts. However, the current curricula from top institutions focus primarily\non technical considerations for building VR applications, missing out on\nconcerns and usability problems specific to VR interaction design. To better\nunderstand current needs, we examined the status quo of existing university\npedagogies by carrying out a content analysis of undergraduate and graduate\ncourses about VR and related areas offered in the major citadels of learning\nand conducting interviews with 7 industry experts. Our analysis reveals that\nthe current teaching practices underemphasize design thinking, prototyping, and\nevaluation skills, while focusing on technical implementation. We recommend VR\ncurricula should emphasize design principles and guidelines, offer training in\nprototyping and ideation, prioritize practical design exercises while providing\nindustry insights, and encourage students to solve VR design problems beyond\nthe classroom.",
    "descriptor": "\nComments: 7 pages, 2 figures, published to CHI EA. For the associated presentation, see this https URL&file=3491101.3519859-talk-video.mp4\n",
    "authors": [
      "Oloff C. Biermann",
      "Daniel Ajisafe",
      "Dongwook Yoon"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2206.04386"
  },
  {
    "id": "arXiv:2206.04387",
    "title": "Kernelization for Feedback Vertex Set via Elimination Distance to a  Forest",
    "abstract": "We study efficient preprocessing for the undirected Feedback Vertex Set\nproblem, a fundamental problem in graph theory which asks for a minimum-sized\nvertex set whose removal yields an acyclic graph. More precisely, we aim to\ndetermine for which parameterizations this problem admits a polynomial kernel.\nWhile a characterization is known for the related Vertex Cover problem based on\nthe recently introduced notion of bridge-depth, it remained an open problem\nwhether this could be generalized to Feedback Vertex Set. The answer turns out\nto be negative; the existence of polynomial kernels for structural\nparameterizations for Feedback Vertex Set is governed by the elimination\ndistance to a forest. Under the standard assumption that NP is not a subset of\ncoNP/poly, we prove that for any minor-closed graph class $\\mathcal G$,\nFeedback Vertex Set parameterized by the size of a modulator to $\\mathcal G$\nhas a polynomial kernel if and only if $\\mathcal G$ has bounded elimination\ndistance to a forest. This captures and generalizes all existing kernels for\nstructural parameterizations of the Feedback Vertex Set problem.",
    "descriptor": "\nComments: 40 pages, 4 figures. To be published in the Proceedings of WG2022\n",
    "authors": [
      "David Dekker",
      "Bart M. P. Jansen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.04387"
  },
  {
    "id": "arXiv:2206.04394",
    "title": "Xplique: A Deep Learning Explainability Toolbox",
    "abstract": "Today's most advanced machine-learning models are hardly scrutable. The key\nchallenge for explainability methods is to help assisting researchers in\nopening up these black boxes, by revealing the strategy that led to a given\ndecision, by characterizing their internal states or by studying the underlying\ndata representation. To address this challenge, we have developed Xplique: a\nsoftware library for explainability which includes representative\nexplainability methods as well as associated evaluation metrics. It interfaces\nwith one of the most popular learning libraries: Tensorflow as well as other\nlibraries including PyTorch, scikit-learn and Theano. The code is licensed\nunder the MIT license and is freely available at github.com/deel-ai/xplique.",
    "descriptor": "",
    "authors": [
      "Thomas Fel",
      "Lucas Hervier",
      "David Vigouroux",
      "Antonin Poche",
      "Justin Plakoo",
      "Remi Cadene",
      "Mathieu Chalvidal",
      "Julien Colin",
      "Thibaut Boissin",
      "Louis Bethune",
      "Agustin Picard",
      "Claire Nicodeme",
      "Laurent Gardes",
      "Gregory Flandin",
      "Thomas Serre"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.04394"
  },
  {
    "id": "arXiv:2206.04397",
    "title": "ESBMC-Jimple: Verifying Kotlin Programs via Jimple Intermediate  Representation",
    "abstract": "In this work, we describe and evaluate the first model checker for verifying\nKotlin programs through the Jimple intermediate representation. The verifier,\nnamed ESBMC-Jimple, is built on top of the Efficient SMT-based Context-Bounded\nModel Checker (ESBMC). It uses the Soot framework to obtain the Jimple IR,\nrepresenting a simplified version of the Kotlin source code, containing a\nmaximum of three operands per instruction. ESBMC-Jimple processes Kotlin source\ncode together with a model of the standard Kotlin libraries and checks a set of\nsafety properties. Experimental results show that ESBMC-Jimple can correctly\nverify a set of Kotlin benchmarks from the literature and that it is\ncompetitive with state-of-the-art Java bytecode verifiers. A demonstration is\navailable at https://youtu.be/J6WhNfXvJNc.",
    "descriptor": "\nComments: ACM SIGSOFT International Symposium on Software Testing and Analysis 2022\n",
    "authors": [
      "Rafael Menezes",
      "Daniel Moura",
      "Helena Cavalcante",
      "Rosiane Freitas",
      "Lucas Cordeiro"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.04397"
  },
  {
    "id": "arXiv:2206.04399",
    "title": "Depression Recognition using Remote Photoplethysmography from Facial  Videos",
    "abstract": "Depression is a mental illness that may be harmful to an individual's health.\nThe detection of mental health disorders in the early stages and a precise\ndiagnosis are critical to avoid social, physiological, or psychological side\neffects. This work analyzes physiological signals to observe if different\ndepressive states have a noticeable impact on the blood volume pulse (BVP) and\nthe heart rate variability (HRV) response. Although typically, HRV features are\ncalculated from biosignals obtained with contact-based sensors such as\nwearables, we propose instead a novel scheme that directly extracts them from\nfacial videos, just based on visual information, removing the need for any\ncontact-based device. Our solution is based on a pipeline that is able to\nextract complete remote photoplethysmography signals (rPPG) in a fully\nunsupervised manner. We use these rPPG signals to calculate over 60\nstatistical, geometrical, and physiological features that are further used to\ntrain several machine learning regressors to recognize different levels of\ndepression. Experiments on two benchmark datasets indicate that this approach\noffers comparable results to other audiovisual modalities based on voice or\nfacial expression, potentially complementing them. In addition, the results\nachieved for the proposed method show promising and solid performance that\noutperforms hand-engineered methods and is comparable to deep learning-based\napproaches.",
    "descriptor": "\nComments: 10 pages, 5 figures, 8 tables\n",
    "authors": [
      "Constantino \u00c1lvarez Casado",
      "Manuel Lage Ca\u00f1ellas",
      "Miguel Bordallo L\u00f3pez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04399"
  },
  {
    "id": "arXiv:2206.04400",
    "title": "Information And Control: Insights from within the brain",
    "abstract": "The neural networks of the brain are capable of learning statistical input\nregularities on the basis of synaptic learning, functional integration into\nincreasingly larger, interconnected neural assemblies, and self organization.\nThis self organizing ability has implications for biologically inspired control\nstructures in robotics. On the basis of signal input from vision, sound, smell,\ntouch and proprioception, multisensory representations for action are generated\non the basis of physically specified input from the environment. The\nsomatosensory cortex is a brain hub that delivers a choice example of\nintegration for multifunctional representation and control. All sensory\ninformation is in a first instance topologically represented in the biological\nbrain, and thereafter integrated in somatosensory neural networks for\nmultimodal and multifunctional control of complex behaviors. Multisignal input\ntriggers interactions between visual, auditory, tactile, olfactive, and\nproprioceptive mechanisms, which cooperate or compete during learning, and\ncontribute to the formation of integrated representations for action,\nreflection, and communication between the agent and the outside world.\nInteraction fuels complex behavioral strategy deployment and further learning\nfor increasingly coherent representation of intrinsically ambiguous physical\nenvironments.",
    "descriptor": "\nComments: The Seventeenth International Multi Conference on Computing in Global Information Technology, ICCGI 2022. May 22-26 2022 ,Venice, Italy\n",
    "authors": [
      "Birgitta Dresp-Langley"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.04400"
  },
  {
    "id": "arXiv:2206.04401",
    "title": "Cross-modal Local Shortest Path and Global Enhancement for  Visible-Thermal Person Re-Identification",
    "abstract": "In addition to considering the recognition difficulty caused by human posture\nand occlusion, it is also necessary to solve the modal differences caused by\ndifferent imaging systems in the Visible-Thermal cross-modal person\nre-identification (VT-ReID) task. In this paper,we propose the Cross-modal\nLocal Shortest Path and Global Enhancement (CM-LSP-GE) modules,a two-stream\nnetwork based on joint learning of local and global features. The core idea of\nour paper is to use local feature alignment to solve occlusion problem, and to\nsolve modal difference by strengthening global feature. Firstly,\nAttention-based two-stream ResNet network is designed to extract dual-modality\nfeatures and map to a unified feature space. Then, to solve the cross-modal\nperson pose and occlusion problems, the image are cut horizontally into several\nequal parts to obtain local features and the shortest path in local features\nbetween two graphs is used to achieve the fine-grained local feature alignment.\nThirdly, a batch normalization enhancement module applies global features to\nenhance strategy, resulting in difference enhancement between different\nclasses. The multi granularity loss fusion strategy further improves the\nperformance of the algorithm. Finally, joint learning mechanism of local and\nglobal features is used to improve cross-modal person re-identification\naccuracy. The experimental results on two typical datasets show that our model\nis obviously superior to the most state-of-the-art methods. Especially, on\nSYSU-MM01 datasets, our model can achieve a gain of 2.89%and 7.96% in all\nsearch term of Rank-1 and mAP. The source code will be released soon.",
    "descriptor": "",
    "authors": [
      "Xiaohong Wang",
      "Chaoqi Li",
      "Xiangcai Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.04401"
  },
  {
    "id": "arXiv:2206.04403",
    "title": "VITA: Video Instance Segmentation via Object Token Association",
    "abstract": "We introduce a novel paradigm for offline Video Instance Segmentation (VIS),\nbased on the hypothesis that explicit object-oriented information can be a\nstrong clue for understanding the context of the entire sequence. To this end,\nwe propose VITA, a simple structure built on top of an off-the-shelf\nTransformer-based image instance segmentation model. Specifically, we use an\nimage object detector as a means of distilling object-specific contexts into\nobject tokens. VITA accomplishes video-level understanding by associating\nframe-level object tokens without using spatio-temporal backbone features. By\neffectively building relationships between objects using the condensed\ninformation, VITA achieves the state-of-the-art on VIS benchmarks with a\nResNet-50 backbone: 49.8 AP, 45.7 AP on YouTube-VIS 2019 & 2021 and 19.6 AP on\nOVIS. Moreover, thanks to its object token-based structure that is disjoint\nfrom the backbone features, VITA shows several practical advantages that\nprevious offline VIS methods have not explored - handling long and\nhigh-resolution videos with a common GPU and freezing a frame-level detector\ntrained on image domain. Code will be made available at\nhttps://github.com/sukjunhwang/VITA.",
    "descriptor": "",
    "authors": [
      "Miran Heo",
      "Sukjun Hwang",
      "Seoung Wug Oh",
      "Joon-Young Lee",
      "Seon Joo Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.04403"
  },
  {
    "id": "arXiv:2206.04406",
    "title": "Unsupervised Learning of the Total Variation Flow",
    "abstract": "The total variation (TV) flow generates a scale-space representation of an\nimage based on the TV functional. This gradient flow observes desirable\nfeatures for images such as sharp edges and enables spectral, scale, and\ntexture analysis. The standard numerical approach for TV flow requires solving\nmultiple non-smooth optimisation problems. Even with state-of-the-art convex\noptimisation techniques, this is often prohibitively expensive and strongly\nmotivates the use of alternative, faster approaches. Inspired by and extending\nthe framework of physics-informed neural networks (PINNs), we propose the\nTVflowNET, a neural network approach to compute the solution of the TV flow\ngiven an initial image and a time instance. We significantly speed up the\ncomputation time by more than one order of magnitude and show that the\nTVflowNET approximates the TV flow solution with high fidelity. This is a\npreliminary report, more details are to follow.",
    "descriptor": "",
    "authors": [
      "Tamara G. Grossmann",
      "S\u00f6ren Dittmer",
      "Yury Korolev",
      "Carola-Bibiane Sch\u00f6nlieb"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.04406"
  },
  {
    "id": "arXiv:2206.04409",
    "title": "Learning Vehicle Trajectory Uncertainty",
    "abstract": "The linear Kalman filter is commonly used for vehicle tracking. This filter\nrequires knowledge of the vehicle trajectory and the statistics of the system\nand measurement models. In real-life scenarios, prior assumptions made while\ndetermining those models do not hold. As a consequence, the overall filter\nperformance degrades and in some situations the estimated states diverge. To\novercome the uncertainty in the {vehicle kinematic} trajectory modeling,\nadditional artificial process noise may be added to the model or different\ntypes of adaptive filters may be employed. This paper proposes {a hybrid}\nadaptive Kalman filter based on {model and} machine learning algorithms. First,\nrecurrent neural networks are employed to learn the vehicle's geometrical and\nkinematic features. In turn, those features are plugged into a supervised\nlearning model, thereby providing the actual process noise covariance to be\nused in the Kalman framework. The proposed approach is evaluated and compared\nto six other adaptive filters using the Oxford RobotCar dataset. The proposed\nframework can be implemented in other estimation problems to accurately\ndetermine the process noise covariance in real-time scenarios.",
    "descriptor": "",
    "authors": [
      "Barak Or",
      "Itzik Klein"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.04409"
  },
  {
    "id": "arXiv:2206.04415",
    "title": "Deep Meta-learning in Recommendation Systems: A Survey",
    "abstract": "Deep neural network based recommendation systems have achieved great success\nas information filtering techniques in recent years. However, since model\ntraining from scratch requires sufficient data, deep learning-based\nrecommendation methods still face the bottlenecks of insufficient data and\ncomputational inefficiency. Meta-learning, as an emerging paradigm that learns\nto improve the learning efficiency and generalization ability of algorithms,\nhas shown its strength in tackling the data sparsity issue. Recently, a growing\nnumber of studies on deep meta-learning based recommenddation systems have\nemerged for improving the performance under recommendation scenarios where\navailable data is limited, e.g. user cold-start and item cold-start. Therefore,\nthis survey provides a timely and comprehensive overview of current deep\nmeta-learning based recommendation methods. Specifically, we propose a taxonomy\nto discuss existing methods according to recommendation scenarios,\nmeta-learning techniques, and meta-knowledge representations, which could\nprovide the design space for meta-learning based recommendation methods. For\neach recommendation scenario, we further discuss technical details about how\nexisting methods apply meta-learning to improve the generalization ability of\nrecommendation models. Finally, we also point out several limitations in\ncurrent research and highlight some promising directions for future research in\nthis area.",
    "descriptor": "",
    "authors": [
      "Chunyang Wang",
      "Yanmin Zhu",
      "Haobing Liu",
      "Tianzi Zang",
      "Jiadi Yu",
      "Feilong Tang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.04415"
  },
  {
    "id": "arXiv:2206.04416",
    "title": "Analysis of Learner Independent Variables for Estimating Assessment  Items Difficulty Level",
    "abstract": "The quality of assessment determines the quality of learning, and is\ncharacterized by validity, reliability and difficulty. Mastery of learning is\ngenerally represented by the difficulty levels of assessment items. A very\nlarge number of variables are identified in the literature to measure the\ndifficulty level. These variables, which are not completely independent of one\nanother, are categorized into learner dependent, learner independent, generic,\nnon-generic and score based. This research proposes a model for predicting the\ndifficulty level of assessment items in engineering courses using learner\nindependent and generic variables. An ordinal regression model is developed for\npredicting the difficulty level, and uses six variables including three stimuli\nvariables (item presentation, usage of technical notations and number of\nresources), two content related variables (number of concepts and procedures)\nand one task variable (number of conditions). Experimental results from three\nengineering courses provide around 80% accuracy in classification of items\nusing the proposed model.",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Shilpi Banerjee",
      "N.J.Rao"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.04416"
  },
  {
    "id": "arXiv:2206.04417",
    "title": "MIMICS-Duo: Offline & Online Evaluation of Search Clarification",
    "abstract": "Asking clarification questions is an active area of research; however,\nresources for training and evaluating search clarification methods are not\nsufficient. To address this issue, we describe MIMICS-Duo, a new freely\navailable dataset of 306 search queries with multiple clarifications (a total\nof 1,034 query-clarification pairs). MIMICS-Duo contains fine-grained\nannotations on clarification questions and their candidate answers and enhances\nthe existing MIMICS datasets by enabling multi-dimensional evaluation of search\nclarification methods, including online and offline evaluation. We conduct\nextensive analysis to demonstrate the relationship between offline and online\nsearch clarification datasets and outline several research directions enabled\nby MIMICS-Duo. We believe that this resource will help researchers better\nunderstand clarification in search.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Leila Tavakoli",
      "Johanne R. Trippas",
      "Hamed Zamani",
      "Falk Scholer",
      "Mark Sanderson"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.04417"
  },
  {
    "id": "arXiv:2206.04421",
    "title": "Solid NURBS Conforming Scaffolding for Isogeometric Analysis",
    "abstract": "This work introduces a scaffolding framework to compactly parametrise solid\nstructures with conforming NURBS elements for isogeometric analysis. A novel\nformulation introduces a topological, geometrical and parametric subdivision of\nthe space in a minimal plurality of conforming vectorial elements. These\ndetermine a multi-compartmental scaffolding for arbitrary branching patterns. A\nsolid smoothing paradigm is devised for the conforming scaffolding achieving\nhigher than positional geometrical and parametric continuity. Results are shown\nfor synthetic shapes of varying complexity, for modular CAD geometries, for\nbranching structures from tessellated meshes and for organic biological\nstructures from imaging data. Representative simulations demonstrate the\nvalidity of the introduced scaffolding framework with scalable performance and\ngroundbreaking applications for isogeometric analysis.",
    "descriptor": "",
    "authors": [
      "Stefano Moriconi",
      "Parashkev Nachev",
      "Sebastien Ourselin",
      "M. Jorge Cardoso"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2206.04421"
  },
  {
    "id": "arXiv:2206.04423",
    "title": "Learning to generalize Dispatching rules on the Job Shop Scheduling",
    "abstract": "This paper introduces a Reinforcement Learning approach to better generalize\nheuristic dispatching rules on the Job-shop Scheduling Problem (JSP). Current\nmodels on the JSP do not focus on generalization, although, as we show in this\nwork, this is key to learning better heuristics on the problem. A well-known\ntechnique to improve generalization is to learn on increasingly complex\ninstances using Curriculum Learning (CL). However, as many works in the\nliterature indicate, this technique might suffer from catastrophic forgetting\nwhen transferring the learned skills between different problem sizes. To\naddress this issue, we introduce a novel Adversarial Curriculum Learning (ACL)\nstrategy, which dynamically adjusts the difficulty level during the learning\nprocess to revisit the worst-performing instances. This work also presents a\ndeep learning model to solve the JSP, which is equivariant w.r.t. the job\ndefinition and size-agnostic. Conducted experiments on Taillard's and\nDemirkol's instances show that the presented approach significantly improves\nthe current state-of-the-art models on the JSP. It reduces the average\noptimality gap from 19.35\\% to 10.46\\% on Taillard's instances and from 38.43\\%\nto 18.85\\% on Demirkol's instances. Our implementation is available online.",
    "descriptor": "",
    "authors": [
      "Zangir Iklassov",
      "Dmitrii Medvedev",
      "Ruben Solozabal",
      "Martin Takac"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.04423"
  },
  {
    "id": "arXiv:2206.04425",
    "title": "Multiple Instance Learning for Digital Pathology: A Review on the  State-of-the-Art, Limitations & Future Potential",
    "abstract": "Digital whole slides images contain an enormous amount of information\nproviding a strong motivation for the development of automated image analysis\ntools. Particularly deep neural networks show high potential with respect to\nvarious tasks in the field of digital pathology. However, a limitation is given\nby the fact that typical deep learning algorithms require (manual) annotations\nin addition to the large amounts of image data, to enable effective training.\nMultiple instance learning exhibits a powerful tool for learning deep neural\nnetworks in a scenario without fully annotated data. These methods are\nparticularly effective in this domain, due to the fact that labels for a\ncomplete whole slide image are often captured routinely, whereas labels for\npatches, regions or pixels are not. This potential already resulted in a\nconsiderable number of publications, with the majority published in the last\nthree years. Besides the availability of data and a high motivation from the\nmedical perspective, the availability of powerful graphics processing units\nexhibits an accelerator in this field. In this paper, we provide an overview of\nwidely and effectively used concepts of used deep multiple instance learning\napproaches, recent advances and also critically discuss remaining challenges\nand future potential.",
    "descriptor": "",
    "authors": [
      "Michael Gadermayr",
      "Maximilian Tschuchnig"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.04425"
  },
  {
    "id": "arXiv:2206.04426",
    "title": "Biologically Inspired Dynamic Thresholds for Spiking Neural Networks",
    "abstract": "The dynamic membrane potential threshold, as one of the essential properties\nof a biological neuron, is a spontaneous regulation mechanism that maintains\nneuronal homeostasis, i.e., the constant overall spiking firing rate of a\nneuron. As such, the neuron firing rate is regulated by a dynamic spiking\nthreshold, which has been extensively studied in biology. Existing work in the\nmachine learning community does not employ bioplausible spiking threshold\nschemes. This work aims at bridging this gap by introducing a novel bioinspired\ndynamic energy-temporal threshold (BDETT) scheme for spiking neural networks\n(SNNs). The proposed BDETT scheme mirrors two bioplausible observations: a\ndynamic threshold has 1) a positive correlation with the average membrane\npotential and 2) a negative correlation with the preceding rate of\ndepolarization. We validate the effectiveness of the proposed BDETT on robot\nobstacle avoidance and continuous control tasks under both normal conditions\nand various degraded conditions, including noisy observations, weights, and\ndynamic environments. We find that the BDETT outperforms existing static and\nheuristic threshold approaches by significant margins in all tested conditions,\nand we confirm that the proposed bioinspired dynamic threshold scheme offers\nbioplausible homeostasis to SNNs in complex real-world tasks.",
    "descriptor": "",
    "authors": [
      "Jianchuan Ding",
      "Bo Dong",
      "Felix Heide",
      "Yufei Ding",
      "Yunduo Zhou",
      "Baocai Yin",
      "Xin Yang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.04426"
  },
  {
    "id": "arXiv:2206.04428",
    "title": "Security-Reliability Trade-Off Analysis for SWIPT- and AF-Based IoT  Networks with Friendly Jammers",
    "abstract": "Radio-frequency (RF) energy harvesting (EH) in wireless relaying networks has\nattracted considerable recent interest, especially for supplying energy to\nrelay nodes in Internet-of-Things (IoT) systems to assist the information\nexchange between a source and a destination. Moreover, limited hardware,\ncomputational resources, and energy availability of IoT devices have raised\nvarious security challenges. To this end, physical layer security (PLS) has\nbeen proposed as an effective alternative to cryptographic methods for\nproviding information security. In this study, we propose a PLS approach for\nsimultaneous wireless information and power transfer (SWIPT)-based half-duplex\n(HD) amplify-and-forward (AF) relaying systems in the presence of an\neavesdropper. Furthermore, we take into account both static power splitting\nrelaying (SPSR) and dynamic power splitting relaying (DPSR) to thoroughly\ninvestigate the benefits of each one. To further enhance secure communication,\nwe consider multiple friendly jammers to help prevent wiretapping attacks from\nthe eavesdropper. More specifically, we provide a reliability and security\nanalysis by deriving closed-form expressions of outage probability (OP) and\nintercept probability (IP), respectively, for both the SPSR and DPSR schemes.\nThen, simulations are also performed to validate our analysis and the\neffectiveness of the proposed schemes. Specifically, numerical results\nillustrate the non-trivial trade-off between reliability and security of the\nproposed system. In addition, we conclude from the simulation results that the\nproposed DPSR scheme outperforms the SPSR-based scheme in terms of OP and IP\nunder the influences of different parameters on system performance.",
    "descriptor": "\nComments: 15 pages, 12 figures, 1 table. Accepted by IEEE Internet of Things Journal\n",
    "authors": [
      "Tan N. Nguyen",
      "Dinh-Hieu Tran",
      "Trinh Van Chien",
      "Van-Duc Phan",
      "Miroslav Voznak",
      "Phu Tran Tin",
      "Symeon Chatzinotas",
      "Derrick Wing Kwan Ng",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.04428"
  },
  {
    "id": "arXiv:2206.04429",
    "title": "Cluster Builder -- A DSL to Deploy a Parallel Application Over a  Workstation Cluster",
    "abstract": "Many organisations have a large network of connected computers, which at\ntimes may be idle. These could be used to run larger data processing problems\nwere it not for the difficulty of organising and managing the deployment of\nsuch applications. ClusterBuilder is designed to make this task much simpler.\nClusterBuilder uses its own Domain Specific Language (DSL) to describe the\nprocessing required that removes the need for a deep understanding of parallel\nprogramming techniques. The application uses extant sequential data objects\nwhich are then invoked in a parallel manner. ClusterBuilder uses robust\nsoftware components and the created architecture is proved to be correct and\nfree from deadlock and livelock. The performance of the system is demonstrated\nusing the Mandelbrot set, which is executed on both a single multi-core\nprocessor and a cluster of workstations. It is shown that the cluster-based\nsystem has better performance characteristics than a multi-core processor\nsolution.",
    "descriptor": "\nComments: 12 pages 3 Figures\n",
    "authors": [
      "Jon Kerridge"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.04429"
  },
  {
    "id": "arXiv:2206.04434",
    "title": "Regret Analysis of Certainty Equivalence Policies in Continuous-Time  Linear-Quadratic Systems",
    "abstract": "This work studies theoretical performance guarantees of a ubiquitous\nreinforcement learning policy for controlling the canonical model of stochastic\nlinear-quadratic system. We show that randomized certainty equivalent policy\naddresses the exploration-exploitation dilemma for minimizing quadratic costs\nin linear dynamical systems that evolve according to stochastic differential\nequations. More precisely, we establish square-root of time regret bounds,\nindicating that randomized certainty equivalent policy learns optimal control\nactions fast from a single state trajectory. Further, linear scaling of the\nregret with the number of parameters is shown. The presented analysis\nintroduces novel and useful technical approaches, and sheds light on\nfundamental challenges of continuous-time reinforcement learning.",
    "descriptor": "",
    "authors": [
      "Mohamad Kazem Shirani Faradonbeh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.04434"
  },
  {
    "id": "arXiv:2206.04436",
    "title": "Towards Safe Reinforcement Learning via Constraining Conditional  Value-at-Risk",
    "abstract": "Though deep reinforcement learning (DRL) has obtained substantial success, it\nmay encounter catastrophic failures due to the intrinsic uncertainty of both\ntransition and observation. Most of the existing methods for safe reinforcement\nlearning can only handle transition disturbance or observation disturbance\nsince these two kinds of disturbance affect different parts of the agent;\nbesides, the popular worst-case return may lead to overly pessimistic policies.\nTo address these issues, we first theoretically prove that the performance\ndegradation under transition disturbance and observation disturbance depends on\na novel metric of Value Function Range (VFR), which corresponds to the gap in\nthe value function between the best state and the worst state. Based on the\nanalysis, we adopt conditional value-at-risk (CVaR) as an assessment of risk\nand propose a novel reinforcement learning algorithm of\nCVaR-Proximal-Policy-Optimization (CPPO) which formalizes the risk-sensitive\nconstrained optimization problem by keeping its CVaR under a given threshold.\nExperimental results show that CPPO achieves a higher cumulative reward and is\nmore robust against both observation and transition disturbances on a series of\ncontinuous control tasks in MuJoCo.",
    "descriptor": "",
    "authors": [
      "Chengyang Ying",
      "Xinning Zhou",
      "Hang Su",
      "Dong Yan",
      "Ning Chen",
      "Jun Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.04436"
  },
  {
    "id": "arXiv:2206.04438",
    "title": "A taxonomy of explanations to support Explainability-by-Design",
    "abstract": "As automated decision-making solutions are increasingly applied to all\naspects of everyday life, capabilities to generate meaningful explanations for\na variety of stakeholders (i.e., decision-makers, recipients of decisions,\nauditors, regulators...) become crucial. In this paper, we present a taxonomy\nof explanations that was developed as part of a holistic\n'Explainability-by-Design' approach for the purposes of the project PLEAD. The\ntaxonomy was built with a view to produce explanations for a wide range of\nrequirements stemming from a variety of regulatory frameworks or policies set\nat the organizational level either to translate high-level compliance\nrequirements or to meet business needs. The taxonomy comprises nine dimensions.\nIt is used as a stand-alone classifier of explanations conceived as detective\ncontrols, in order to aid supportive automated compliance strategies. A\nmachinereadable format of the taxonomy is provided in the form of a light\nontology and the benefits of starting the Explainability-by-Design journey with\nsuch a taxonomy are demonstrated through a series of examples.",
    "descriptor": "",
    "authors": [
      "Niko Tsakalakis",
      "Sophie Stalla-Bourdillon",
      "Trung Dong Huynh",
      "Luc Moreau"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.04438"
  },
  {
    "id": "arXiv:2206.04439",
    "title": "Dict-NMT: Bilingual Dictionary based NMT for Extremely Low Resource  Languages",
    "abstract": "Neural Machine Translation (NMT) models have been effective on large\nbilingual datasets. However, the existing methods and techniques show that the\nmodel's performance is highly dependent on the number of examples in training\ndata. For many languages, having such an amount of corpora is a far-fetched\ndream. Taking inspiration from monolingual speakers exploring new languages\nusing bilingual dictionaries, we investigate the applicability of bilingual\ndictionaries for languages with extremely low, or no bilingual corpus. In this\npaper, we explore methods using bilingual dictionaries with an NMT model to\nimprove translations for extremely low resource languages. We extend this work\nto multilingual systems, exhibiting zero-shot properties. We present a detailed\nanalysis of the effects of the quality of dictionaries, training dataset size,\nlanguage family, etc., on the translation quality. Results on multiple\nlow-resource test languages show a clear advantage of our bilingual\ndictionary-based method over the baselines.",
    "descriptor": "",
    "authors": [
      "Nalin Kumar",
      "Deepak Kumar",
      "Subhankar Mishra"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.04439"
  },
  {
    "id": "arXiv:2206.04449",
    "title": "Segmentation Enhanced Lameness Detection in Dairy Cows from RGB and  Depth Video",
    "abstract": "Cow lameness is a severe condition that affects the life cycle and life\nquality of dairy cows and results in considerable economic losses. Early\nlameness detection helps farmers address illnesses early and avoid negative\neffects caused by the degeneration of cows' condition. We collected a dataset\nof short clips of cows passing through a hallway exiting a milking station and\nannotated the degree of lameness of the cows. This paper explores the resulting\ndataset and provides a detailed description of the data collection process.\nAdditionally, we proposed a lameness detection method that leverages\npre-trained neural networks to extract discriminative features from videos and\nassign a binary score to each cow indicating its condition: \"healthy\" or\n\"lame.\" We improve this approach by forcing the model to focus on the structure\nof the cow, which we achieve by substituting the RGB videos with binary\nsegmentation masks predicted with a trained segmentation model. This work aims\nto encourage research and provide insights into the applicability of computer\nvision models for cow lameness detection on farms.",
    "descriptor": "\nComments: Accepted at the CV4Animals workshop in CVPR 2022\n",
    "authors": [
      "Eric Arazo",
      "Robin Aly",
      "Kevin McGuinness"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.04449"
  },
  {
    "id": "arXiv:2206.04451",
    "title": "Deep kernelization for the Tree Bisection and Reconnnect (TBR) distance  in phylogenetics",
    "abstract": "We describe a kernel of size 9k-8 for the NP-hard problem of computing the\nTree Bisection and Reconnect (TBR) distance k between two unrooted binary\nphylogenetic trees. We achieve this by extending the existing portfolio of\nreduction rules with three novel new reduction rules. Two of the rules are\nbased on the idea of topologically transforming the trees in a\ndistance-preserving way in order to guarantee execution of earlier reduction\nrules. The third rule extends the local neighbourhood approach introduced in\n(Kelk and Linz, Annals of Combinatorics 24(3), 2020) to more global structures,\nallowing new situations to be identified when deletion of a leaf definitely\nreduces the TBR distance by one. The bound on the kernel size is tight up to an\nadditive term. Our results also apply to the equivalent problem of computing a\nMaximum Agreement Forest (MAF) between two unrooted binary phylogenetic trees.\nWe anticipate that our results will be more widely applicable for computing\nagreement-forest based dissimilarity measures.",
    "descriptor": "\nComments: 37 pages\n",
    "authors": [
      "Steven Kelk",
      "Simone Linz",
      "Ruben Meuwese"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2206.04451"
  },
  {
    "id": "arXiv:2206.04452",
    "title": "Draft-and-Revise: Effective Image Generation with Contextual  RQ-Transformer",
    "abstract": "Although autoregressive models have achieved promising results on image\ngeneration, their unidirectional generation process prevents the resultant\nimages from fully reflecting global contexts. To address the issue, we propose\nan effective image generation framework of Draft-and-Revise with Contextual\nRQ-transformer to consider global contexts during the generation process. As a\ngeneralized VQ-VAE, RQ-VAE first represents a high-resolution image as a\nsequence of discrete code stacks. After code stacks in the sequence are\nrandomly masked, Contextual RQ-Transformer is trained to infill the masked code\nstacks based on the unmasked contexts of the image. Then, Contextual\nRQ-Transformer uses our two-phase decoding, Draft-and-Revise, and generates an\nimage, while exploiting the global contexts of the image during the generation\nprocess. Specifically. in the draft phase, our model first focuses on\ngenerating diverse images despite rather low quality. Then, in the revise\nphase, the model iteratively improves the quality of images, while preserving\nthe global contexts of generated images. In experiments, our method achieves\nstate-of-the-art results on conditional image generation. We also validate that\nthe Draft-and-Revise decoding can achieve high performance by effectively\ncontrolling the quality-diversity trade-off in image generation.",
    "descriptor": "\nComments: 20 pages, 11 figures\n",
    "authors": [
      "Doyup Lee",
      "Chiheon Kim",
      "Saehoon Kim",
      "Minsu Cho",
      "Wook-Shin Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04452"
  },
  {
    "id": "arXiv:2206.04453",
    "title": "The Missing Link: Finding label relations across datasets",
    "abstract": "Computer Vision is driven by the many datasets which can be used for training\nor evaluating novel methods. However, each dataset has different set of class\nlabels, visual definition of classes, images following a specific distribution,\nannotation protocols, etc. In this paper we explore the automatic discovery of\nvisual-semantic relations between labels across datasets. We want to understand\nhow the instances of a certain class in a dataset relate to the instances of\nanother class in another dataset. Are they in an identity, parent/child,\noverlap relation? Or is there no link between them at all? To find relations\nbetween labels across datasets, we propose methods based on language, on\nvision, and on a combination of both. Our methods can effectively discover\nlabel relations across datasets and the type of the relations. We use these\nresults for a deeper inspection on why instances relate, find missing aspects\nof a class, and use our relations to create finer-grained annotations. We\nconclude that label relations cannot be established by looking at the names of\nclasses alone, as they depend strongly on how each of the datasets was\nconstructed.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Jasper Uijlings",
      "Thomas Mensink",
      "Vittorio Ferrari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.04453"
  },
  {
    "id": "arXiv:2206.04457",
    "title": "Seamless Accurate Positioning in Deep Urban Area based on Mode Switching  Between DGNSS and Multipath Mitigation Positioning",
    "abstract": "Multipath and non-line-of-sight (NLOS) signals are the major causes of poor\naccuracy of a global navigation satellite system (GNSS) in urban areas. Despite\nthe wide usage of the GNSS in populated urban areas, it is difficult to suggest\na generalized method because multipath errors are user-specific errors that\ncannot be eliminated by the DGNSS or a real-time kinematic technique. This\npaper introduces a real-time multipath estimation and mitigation technique,\nwhich considers compensation for the time offset between constellations. It\nalso presents a mode-switching algorithm between the DGNSS and multipath\nmitigating mode and shows that this technique can be effectively utilized for\nautomobiles in a deep urban environment without any help from sensors other\nthan GNSS. The availability is improved from 64% to 100% and the error RMS is\nreduced from 11.1 m to 1.2 m on Teheran-ro, Seoul, Korea. Because this method\ndoes not require prior information or additional sensor implementation for\nhigh-positioning performance in deep urban areas, it is expected to gain wide\nusage in not only the automotive industry but also future intelligent\ntransportation systems.",
    "descriptor": "",
    "authors": [
      "Yongjun Lee",
      "Yoola Hwang",
      "Jae Young Ahn",
      "Jiwon Seo",
      "Byungwoon Park"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.04457"
  },
  {
    "id": "arXiv:2206.04459",
    "title": "SDQ: Stochastic Differentiable Quantization with Mixed Precision",
    "abstract": "In order to deploy deep models in a computationally efficient manner, model\nquantization approaches have been frequently used. In addition, as new hardware\nthat supports mixed bitwidth arithmetic operations, recent research on mixed\nprecision quantization (MPQ) begins to fully leverage the capacity of\nrepresentation by searching optimized bitwidths for different layers and\nmodules in a network. However, previous studies mainly search the MPQ strategy\nin a costly scheme using reinforcement learning, neural architecture search,\netc., or simply utilize partial prior knowledge for bitwidth assignment, which\nmight be biased and sub-optimal. In this work, we present a novel Stochastic\nDifferentiable Quantization (SDQ) method that can automatically learn the MPQ\nstrategy in a more flexible and globally-optimized space with smoother gradient\napproximation. Particularly, Differentiable Bitwidth Parameters (DBPs) are\nemployed as the probability factors in stochastic quantization between adjacent\nbitwidth choices. After the optimal MPQ strategy is acquired, we further train\nour network with entropy-aware bin regularization and knowledge distillation.\nWe extensively evaluate our method for several networks on different hardware\n(GPUs and FPGA) and datasets. SDQ outperforms all state-of-the-art mixed or\nsingle precision quantization with a lower bitwidth and is even better than the\nfull-precision counterparts across various ResNet and MobileNet families,\ndemonstrating the effectiveness and superiority of our method.",
    "descriptor": "\nComments: ICML 2022\n",
    "authors": [
      "Xijie Huang",
      "Zhiqiang Shen",
      "Shichao Li",
      "Zechun Liu",
      "Xianghong Hu",
      "Jeffry Wicaksana",
      "Eric Xing",
      "Kwang-Ting Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.04459"
  },
  {
    "id": "arXiv:2206.04460",
    "title": "Open ERP System Data For Occupational Fraud Detection",
    "abstract": "Recent estimates report that companies lose 5% of their revenue to\noccupational fraud. Since most medium-sized and large companies employ\nEnterprise Resource Planning (ERP) systems to track vast amounts of information\nregarding their business process, researchers have in the past shown interest\nin automatically detecting fraud through ERP system data. Current research in\nthis area, however, is hindered by the fact that ERP system data is not\npublicly available for the development and comparison of fraud detection\nmethods. We therefore endeavour to generate public ERP system data that\nincludes both normal business operation and fraud. We propose a strategy for\ngenerating ERP system data through a serious game, model a variety of fraud\nscenarios in cooperation with auditing experts, and generate data from a\nsimulated make-to-stock production company with multiple research participants.\nWe aggregate the generated data into ready to used datasets for fraud detection\nin ERP systems, and supply both the raw and aggregated data to the general\npublic to allow for open development and comparison of fraud detection\napproaches on ERP system data.",
    "descriptor": "",
    "authors": [
      "Julian Tritscher",
      "Fabian Gwinner",
      "Daniel Schl\u00f6r",
      "Anna Krause",
      "Andreas Hotho"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.04460"
  },
  {
    "id": "arXiv:2206.04461",
    "title": "From Dimension-Free Manifold to Dimension-varying (Control) System",
    "abstract": "Starting from the projection among Euclidean space of different\ndimensions(ESDD), the inner product, norm, and distance of two vectors of\ndifferent dimensions are proposed, which lead to an equivalence. As a quotient\nspace of ESDDs over equivalence, the dimension-free Euclidean space (DFES) and\ndimension-free Euclidean manifold (DFEM) are obtained, which have bundled\nvector spaces as the tangent space at each point. Main objects for classical\nmanifolds in differential geometry, such as functions, (co-)vector fields,\ntensor fields, etc., have been extended to DFEM. Using the natural projection\nfrom ESDDs to DFES, a fiber bundle structure is obtained, which has EFDDs as\nits total space and DFES as its base space. Then the dimension-varying dynamic\nsystem (DVDS) and dimension-varying control system (DVCS) are presented, which\nhave DFEM as their state spaces. The realization, which is a lifting of\ndimension-free dynamic system (DFDS) or dimension-free control system (DFCS)\nfrom DFEM into ESDD, and the projection of DVDS or DVCS from ESDD onto DFEM are\ninvestigated.",
    "descriptor": "",
    "authors": [
      "Daizhan Cheng"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.04461"
  },
  {
    "id": "arXiv:2206.04462",
    "title": "When Traceability Goes Awry: an Industrial Experience Report",
    "abstract": "The concept of traceability between artifacts is considered an enabler for\nsoftware project success. This concept has received plenty of attention from\nthe research community and is by many perceived to always be available in an\nindustrial setting. In this industry-academia collaborative project, a team of\nresearchers, supported by testing practitioners from a large telecommunication\ncompany, sought to investigate the partner company's issues related to software\nquality. However, it was soon identified that the fundamental traceability\nlinks between requirements and test cases were missing. This lack of\ntraceability impeded the implementation of a solution to help the company deal\nwith its quality issues. In this experience report, we discuss lessons learned\nabout the practical value of creating and maintaining traceability links in\ncomplex industrial settings and provide a cautionary tale for researchers.",
    "descriptor": "",
    "authors": [
      "Davide Fucci",
      "Emil Al\u00e9groth",
      "Thomas Axelsson"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.04462"
  },
  {
    "id": "arXiv:2206.04463",
    "title": "Meet You Halfway: Explaining Deep Learning Mysteries",
    "abstract": "Deep neural networks perform exceptionally well on various learning tasks\nwith state-of-the-art results. While these models are highly expressive and\nachieve impressively accurate solutions with excellent generalization\nabilities, they are susceptible to minor perturbations. Samples that suffer\nsuch perturbations are known as \"adversarial examples\". Even though deep\nlearning is an extensively researched field, many questions about the nature of\ndeep learning models remain unanswered. In this paper, we introduce a new\nconceptual framework attached with a formal description that aims to shed light\non the network's behavior and interpret the behind-the-scenes of the learning\nprocess. Our framework provides an explanation for inherent questions\nconcerning deep learning. Particularly, we clarify: (1) Why do neural networks\nacquire generalization abilities? (2) Why do adversarial examples transfer\nbetween different models?. We provide a comprehensive set of experiments that\nsupport this new framework, as well as its underlying theory.",
    "descriptor": "",
    "authors": [
      "Oriel BenShmuel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.04463"
  },
  {
    "id": "arXiv:2206.04465",
    "title": "Joint Encoder-Decoder Self-Supervised Pre-training for ASR",
    "abstract": "Self-supervised learning (SSL) has shown tremendous success in various\nspeech-related downstream tasks, including Automatic Speech Recognition (ASR).\nThe output embeddings of the SSL model are treated as powerful short-time\nrepresentations of the speech signal. However, in the ASR task, the main\nobjective is to get the correct sequence of acoustic units, characters, or\nbyte-pair encodings (BPEs). Usually, encoder-decoder architecture works\nexceptionally well for a sequence-to-sequence task like ASR. Therefore, in this\npaper, we propose a new paradigm that exploits the power of a decoder during\nself-supervised learning. We use Hidden Unit BERT (HuBERT) SSL framework to\ncompute the conventional masked prediction loss for the encoder. In addition,\nwe have introduced a decoder in the SSL framework and proposed a target\npreparation strategy for the decoder. Finally, we use a multitask SSL setup\nwherein we jointly optimize both the encoder and decoder losses. We hypothesize\nthat the presence of a decoder in the SSL model helps it learn an acoustic\nunit-based language model, which might improve the performance of an ASR\ndownstream task. We compare our proposed SSL model with HuBERT and show up to\n25% relative improvement in performance on ASR by finetuning on various\nLibriSpeech subsets.",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Arunkumar A",
      "Umesh S"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.04465"
  },
  {
    "id": "arXiv:2206.04471",
    "title": "Towards Understanding Graph Neural Networks: An Algorithm Unrolling  Perspective",
    "abstract": "The graph neural network (GNN) has demonstrated its superior performance in\nvarious applications. The working mechanism behind it, however, remains\nmysterious. GNN models are designed to learn effective representations for\ngraph-structured data, which intrinsically coincides with the principle of\ngraph signal denoising (GSD). Algorithm unrolling, a \"learning to optimize\"\ntechnique, has gained increasing attention due to its prospects in building\nefficient and interpretable neural network architectures. In this paper, we\nintroduce a class of unrolled networks built based on truncated optimization\nalgorithms (e.g., gradient descent and proximal gradient descent) for GSD\nproblems. They are shown to be tightly connected to many popular GNN models in\nthat the forward propagations in these GNNs are in fact unrolled networks\nserving specific GSDs. Besides, the training process of a GNN model can be seen\nas solving a bilevel optimization problem with a GSD problem at the lower\nlevel. Such a connection brings a fresh view of GNNs, as we could try to\nunderstand their practical capabilities from their GSD counterparts, and it can\nalso motivate designing new GNN models. Based on the algorithm unrolling\nperspective, an expressive model named UGDGNN, i.e., unrolled gradient descent\nGNN, is further proposed which inherits appealing theoretical properties.\nExtensive numerical simulations on seven benchmark datasets demonstrate that\nUGDGNN can achieve superior or competitive performance over the\nstate-of-the-art models.",
    "descriptor": "",
    "authors": [
      "Zepeng Zhang",
      "Ziping Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.04471"
  },
  {
    "id": "arXiv:2206.04472",
    "title": "Early Transferability of Adversarial Examples in Deep Neural Networks",
    "abstract": "This paper will describe and analyze a new phenomenon that was not known\nbefore, which we call \"Early Transferability\". Its essence is that the\nadversarial perturbations transfer among different networks even at extremely\nearly stages in their training. In fact, one can initialize two networks with\ntwo different independent choices of random weights and measure the angle\nbetween their adversarial perturbations after each step of the training. What\nwe discovered was that these two adversarial directions started to align with\neach other already after the first few training steps (which typically use only\na small fraction of the available training data), even though the accuracy of\nthe two networks hadn't started to improve from their initial bad values due to\nthe early stage of the training. The purpose of this paper is to present this\nphenomenon experimentally and propose plausible explanations for some of its\nproperties.",
    "descriptor": "",
    "authors": [
      "Oriel BenShmuel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.04472"
  },
  {
    "id": "arXiv:2206.04475",
    "title": "Individually Fair Learning with One-Sided Feedback",
    "abstract": "We consider an online learning problem with one-sided feedback, in which the\nlearner is able to observe the true label only for positively predicted\ninstances. On each round, $k$ instances arrive and receive classification\noutcomes according to a randomized policy deployed by the learner, whose goal\nis to maximize accuracy while deploying individually fair policies. We first\nextend the framework of Bechavod et al. (2020), which relies on the existence\nof a human fairness auditor for detecting fairness violations, to instead\nincorporate feedback from dynamically-selected panels of multiple, possibly\ninconsistent, auditors. We then construct an efficient reduction from our\nproblem of online learning with one-sided feedback and a panel reporting\nfairness violations to the contextual combinatorial semi-bandit problem\n(Cesa-Bianchi & Lugosi, 2009, Gy\\\"{o}rgy et al., 2007). Finally, we show how to\nleverage the guarantees of two algorithms in the contextual combinatorial\nsemi-bandit setting: Exp2 (Bubeck et al., 2012) and the oracle-efficient\nContext-Semi-Bandit-FTPL (Syrgkanis et al., 2016), to provide multi-criteria no\nregret guarantees simultaneously for accuracy and fairness. Our results\neliminate two potential sources of bias from prior work: the \"hidden outcomes\"\nthat are not available to an algorithm operating in the full information\nsetting, and human biases that might be present in any single human auditor,\nbut can be mitigated by selecting a well chosen panel.",
    "descriptor": "",
    "authors": [
      "Yahav Bechavod",
      "Aaron Roth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.04475"
  },
  {
    "id": "arXiv:2206.04477",
    "title": "Receding Horizon Inverse Reinforcement Learning",
    "abstract": "Inverse reinforcement learning (IRL) seeks to infer a cost function that\nexplains the underlying goals and preferences of expert demonstrations. This\npaper presents receding horizon inverse reinforcement learning (RHIRL), a new\nIRL algorithm for high-dimensional, noisy, continuous systems with black-box\ndynamic models. RHIRL addresses two key challenges of IRL: scalability and\nrobustness. To handle high-dimensional continuous systems, RHIRL matches the\ninduced optimal trajectories with expert demonstrations locally in a receding\nhorizon manner and 'stitches' together the local solutions to learn the cost;\nit thereby avoids the 'curse of dimensionality'. This contrasts sharply with\nearlier algorithms that match with expert demonstrations globally over the\nentire high-dimensional state space. To be robust against imperfect expert\ndemonstrations and system control noise, RHIRL learns a state-dependent cost\nfunction 'disentangled' from system dynamics under mild conditions. Experiments\non benchmark tasks show that RHIRL outperforms several leading IRL algorithms\nin most instances. We also prove that the cumulative error of RHIRL grows\nlinearly with the task duration.",
    "descriptor": "",
    "authors": [
      "Yiqing Xu",
      "Wei Gao",
      "David Hsu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.04477"
  },
  {
    "id": "arXiv:2206.04479",
    "title": "BSM loss: A superior way in modeling aleatory uncertainty of  fine_grained classification",
    "abstract": "Artificial intelligence(AI)-assisted method had received much attention in\nthe risk field such as disease diagnosis. Different from the classification of\ndisease types, it is a fine-grained task to classify the medical images as\nbenign or malignant. However, most research only focuses on improving the\ndiagnostic accuracy and ignores the evaluation of model reliability, which\nlimits its clinical application. For clinical practice, calibration presents\nmajor challenges in the low-data regime extremely for over-parametrized models\nand inherent noises. In particular, we discovered that modeling data-dependent\nuncertainty is more conducive to confidence calibrations. Compared with\ntest-time augmentation(TTA), we proposed a modified Bootstrapping loss(BS loss)\nfunction with Mixup data augmentation strategy that can better calibrate\npredictive uncertainty and capture data distribution transformation without\nadditional inference time. Our experiments indicated that BS loss with\nMixup(BSM) model can halve the Expected Calibration Error(ECE) compared to\nstandard data augmentation, deep ensemble and MC dropout. The correlation\nbetween uncertainty and similarity of in-domain data is up to -0.4428 under the\nBSM model. Additionally, the BSM model is able to perceive the semantic\ndistance of out-of-domain data, demonstrating high potential in real-world\nclinical practice.",
    "descriptor": "",
    "authors": [
      "Shuang Ge",
      "Kehong Yuan",
      "Maokun Han",
      "Desheng Sun",
      "Huabin Zhang",
      "Qiongyu Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.04479"
  },
  {
    "id": "arXiv:2206.04480",
    "title": "Comparison Study of Inertial Sensor Signal Combination for Human  Activity Recognition based on Convolutional Neural Networks",
    "abstract": "Human Activity Recognition (HAR) is one of the essential building blocks of\nso many applications like security, monitoring, the internet of things and\nhuman-robot interaction. The research community has developed various\nmethodologies to detect human activity based on various input types. However,\nmost of the research in the field has been focused on applications other than\nhuman-in-the-centre applications. This paper focused on optimising the input\nsignals to maximise the HAR performance from wearable sensors. A model based on\nConvolutional Neural Networks (CNN) has been proposed and trained on different\nsignal combinations of three Inertial Measurement Units (IMU) that exhibit the\nmovements of the dominant hand, leg and chest of the subject. The results\ndemonstrate k-fold cross-validation accuracy between 99.77 and 99.98% for\nsignals with the modality of 12 or higher. The performance of lower dimension\nsignals, except signals containing information from both chest and ankle, was\nfar inferior, showing between 73 and 85% accuracy.",
    "descriptor": "",
    "authors": [
      "Farhad Nazari",
      "Navid Mohajer",
      "Darius Nahavandi",
      "Abbas Khosravi",
      "Saeid Nahavandi"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.04480"
  },
  {
    "id": "arXiv:2206.04486",
    "title": "Data-Efficient Brain Connectome Analysis via Multi-Task Meta-Learning",
    "abstract": "Brain networks characterize complex connectivities among brain regions as\ngraph structures, which provide a powerful means to study brain connectomes. In\nrecent years, graph neural networks have emerged as a prevalent paradigm of\nlearning with structured data. However, most brain network datasets are limited\nin sample sizes due to the relatively high cost of data acquisition, which\nhinders the deep learning models from sufficient training. Inspired by\nmeta-learning that learns new concepts fast with limited training examples,\nthis paper studies data-efficient training strategies for analyzing brain\nconnectomes in a cross-dataset setting. Specifically, we propose to meta-train\nthe model on datasets of large sample sizes and transfer the knowledge to small\ndatasets. In addition, we also explore two brain-network-oriented designs,\nincluding atlas transformation and adaptive task reweighing. Compared to other\npre-training strategies, our meta-learning-based approach achieves higher and\nstabler performance, which demonstrates the effectiveness of our proposed\nsolutions. The framework is also able to derive new insights regarding the\nsimilarities among datasets and diseases in a data-driven fashion.",
    "descriptor": "\nComments: Accepted to KDD 2022 (Health Day), 9 pages\n",
    "authors": [
      "Yi Yang",
      "Yanqiao Zhu",
      "Hejie Cui",
      "Xuan Kan",
      "Lifang He",
      "Ying Guo",
      "Carl Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2206.04486"
  },
  {
    "id": "arXiv:2206.04487",
    "title": "Human Activity Recognition from Knee Angle Using Machine Learning  Techniques",
    "abstract": "Human Activity Recognition (HAR) is a crucial technology for many\napplications such as smart homes, surveillance, human assistance and health\ncare. This technology utilises pattern recognition and can contribute to the\ndevelopment of human-in-the-loop control of different systems such as orthoses\nand exoskeletons. The majority of reported studies use a small dataset\ncollected from an experiment for a specific purpose. The downsides of this\napproach include: 1) it is hard to generalise the outcome to different people\nwith different biomechanical characteristics and health conditions, and 2) it\ncannot be implemented in applications other than the original experiment. To\naddress these deficiencies, the current study investigates using a publicly\navailable dataset collected for pathology diagnosis purposes to train Machine\nLearning (ML) algorithms. A dataset containing knee motion of participants\nperforming different exercises has been used to classify human activity. The\nalgorithms used in this study are Gaussian Naive Bayes, Decision Tree, Random\nForest, K-Nearest Neighbors Vote, Support Vector Machine and Gradient Boosting.\nFurthermore, two training approaches are compared to raw data (de-noised) and\nmanually extracted features. The results show up to 0.94 performance of the\nArea Under the ROC Curve (AUC) metric for 11-fold cross-validation for Gradient\nBoosting algorithm using raw data. This outcome reflects the validity and\npotential use of the proposed approach for this type of dataset.",
    "descriptor": "\nComments: Published in 2021 IEEE International Conference on Systems, Man, and Cybernetics (SMC)\n",
    "authors": [
      "Farhad Nazari",
      "Darius Nahavandi",
      "Navid Mohajer",
      "Abbas Khosravi"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.04487"
  },
  {
    "id": "arXiv:2206.04489",
    "title": "Holistic Verification of Blockchain Consensus",
    "abstract": "Blockchain has recently attracted the attention of the industry due, in part,\nto its ability to automate asset transfers. It requires distributed\nparticipants to reach a consensus on a block despite the presence of malicious\n(a.k.a. Byzantine) participants. Malicious participants exploit regularly\nweaknesses of these blockchain consensus algorithms, with sometimes devastating\nconsequences. In fact, these weaknesses are quite common and are well\nillustrated by the flaws in the hand-written proofs of existing blockchain\nconsensus protocols [63]. Paradoxically, until now, no blockchain consensus has\nbeen holistically verified using model checking.\nIn this paper, we remedy this paradox by model checking for the first time a\nblockchain consensus used in industry. We propose a holistic approach to verify\nthe consensus algorithm of the Red Belly Blockchain [20], for any number $n$ of\nprocesses and any number $f<n/3$ of Byzantine processes. We decompose directly\nthe algorithm pseudocode in two parts -- an inner broadcast algorithm and an\nouter decision algorithm -- each modelled as a threshold automaton [36], and we\nformalize their expected properties in linear-time temporal logic. We then\nautomatically check the inner broadcasting algorithm, under a carefully\nidentified fairness assumption. For the verification of the outer algorithm, we\nsimplify the model of the inner algorithm by relying on its checked properties.\nDoing so, we formally verify not only the safety properties of the Red Belly\nBlockchain consensus but also its liveness in about 70 seconds.",
    "descriptor": "",
    "authors": [
      "Nathalie Bertrand",
      "Vincent Gramoli",
      "Igor Konnov",
      "Marijana Lazi\u0107",
      "Pierre Tholoniat",
      "Josef Widder"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2206.04489"
  },
  {
    "id": "arXiv:2206.04490",
    "title": "Redundancy in Deep Linear Neural Networks",
    "abstract": "Conventional wisdom states that deep linear neural networks benefit from\nexpressiveness and optimization advantages over a single linear layer. This\npaper suggests that, in practice, the training process of deep linear\nfully-connected networks using conventional optimizers is convex in the same\nmanner as a single linear fully-connected layer. This paper aims to explain\nthis claim and demonstrate it. Even though convolutional networks are not\naligned with this description, this work aims to attain a new conceptual\nunderstanding of fully-connected linear networks that might shed light on the\npossible constraints of convolutional settings and non-linear architectures.",
    "descriptor": "",
    "authors": [
      "Oriel BenShmuel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2206.04490"
  },
  {
    "id": "arXiv:2206.04496",
    "title": "Mitigating Modality Collapse in Multimodal VAEs via Impartial  Optimization",
    "abstract": "A number of variational autoencoders (VAEs) have recently emerged with the\naim of modeling multimodal data, e.g., to jointly model images and their\ncorresponding captions. Still, multimodal VAEs tend to focus solely on a subset\nof the modalities, e.g., by fitting the image while neglecting the caption. We\nrefer to this limitation as modality collapse. In this work, we argue that this\neffect is a consequence of conflicting gradients during multimodal VAE\ntraining. We show how to detect the sub-graphs in the computational graphs\nwhere gradients conflict (impartiality blocks), as well as how to leverage\nexisting gradient-conflict solutions from multitask learning to mitigate\nmodality collapse. That is, to ensure impartial optimization across modalities.\nWe apply our training framework to several multimodal VAE models, losses and\ndatasets from the literature, and empirically show that our framework\nsignificantly improves the reconstruction performance, conditional generation,\nand coherence of the latent space across modalities.",
    "descriptor": "\nComments: Accepted as a Spotlight paper at ICML 2022. 27 pages, 10 figures\n",
    "authors": [
      "Adri\u00e1n Javaloy",
      "Maryam Meghdadi",
      "Isabel Valera"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04496"
  },
  {
    "id": "arXiv:2206.04500",
    "title": "Unlearning Protected User Attributes in Recommendations with Adversarial  Training",
    "abstract": "Collaborative filtering algorithms capture underlying consumption patterns,\nincluding the ones specific to particular demographics or protected information\nof users, e.g. gender, race, and location. These encoded biases can influence\nthe decision of a recommendation system (RS) towards further separation of the\ncontents provided to various demographic subgroups, and raise privacy concerns\nregarding the disclosure of users' protected attributes. In this work, we\ninvestigate the possibility and challenges of removing specific protected\ninformation of users from the learned interaction representations of a RS\nalgorithm, while maintaining its effectiveness. Specifically, we incorporate\nadversarial training into the state-of-the-art MultVAE architecture, resulting\nin a novel model, Adversarial Variational Auto-Encoder with Multinomial\nLikelihood (Adv-MultVAE), which aims at removing the implicit information of\nprotected attributes while preserving recommendation performance. We conduct\nexperiments on the MovieLens-1M and LFM-2b-DemoBias datasets, and evaluate the\neffectiveness of the bias mitigation method based on the inability of external\nattackers in revealing the users' gender information from the model. Comparing\nwith baseline MultVAE, the results show that Adv-MultVAE, with marginal\ndeterioration in performance (w.r.t. NDCG and recall), largely mitigates\ninherent biases in the model on both datasets.",
    "descriptor": "\nComments: Accepted at SIGIR 2022\n",
    "authors": [
      "Christian Ganh\u00f6r",
      "David Penz",
      "Navid Rekabsaz",
      "Oleg Lesota",
      "Markus Schedl"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04500"
  },
  {
    "id": "arXiv:2206.04503",
    "title": "cycle text2face: cycle text-to-face gan via transformers",
    "abstract": "Text-to-face is a subset of text-to-image that require more complex\narchitecture due to their more detailed production. In this paper, we present\nan encoder-decoder model called Cycle Text2Face. Cycle Text2Face is a new\ninitiative in the encoder part, it uses a sentence transformer and GAN to\ngenerate the image described by the text. The Cycle is completed by reproducing\nthe text of the face in the decoder part of the model. Evaluating the model\nusing the CelebA dataset, leads to better results than previous GAN-based\nmodels. In measuring the quality of the generate face, in addition to\nsatisfying the human audience, we obtain an FID score of 3.458. This model,\nwith high-speed processing, provides quality face images in the short time.",
    "descriptor": "",
    "authors": [
      "Faezeh Gholamrezaie",
      "Mohammad Manthouri"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.04503"
  },
  {
    "id": "arXiv:2206.04507",
    "title": "Software Mitigation of RISC-V Spectre Attacks",
    "abstract": "Speculative attacks are still an active threat today that, even if initially\nfocused on the x86 platform, reach across all modern hardware architectures.\nRISC-V is a newly proposed open instruction set architecture that has seen\ntraction from both the industry and academia in recent years. In this paper we\nfocus on the RISC-V cores where speculation is enabled and, as we show, where\nSpectre attacks are as effective as on x86. Even though RISC-V hardware\nmitigations were proposed in the past, they have not yet passed the prototype\nphase. Instead, we propose low-overhead software mitigations for Spectre-BTI,\ninspired from those used on the x86 architecture, and for Spectre-RSB, to our\nknowledge the first such mitigation to be proposed. We show that these\nmitigations work in practice and that they can be integrated in the LLVM\ntoolchain. For transparency and reproducibility, all our programs and data are\nmade publicly available online.",
    "descriptor": "",
    "authors": [
      "Ruxandra B\u0103lucea",
      "Paul Irofti"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Operating Systems (cs.OS)"
    ],
    "url": "https://arxiv.org/abs/2206.04507"
  },
  {
    "id": "arXiv:2206.04510",
    "title": "SsciBERT: A Pre-trained Language Model for Social Science Texts",
    "abstract": "The academic literature of social sciences is the literature that records\nhuman civilization and studies human social problems. With the large-scale\ngrowth of this literature, ways to quickly find existing research on relevant\nissues have become an urgent demand for researchers. Previous studies, such as\nSciBERT, have shown that pre-training using domain-specific texts can improve\nthe performance of natural language processing tasks in those fields. However,\nthere is no pre-trained language model for social sciences, so this paper\nproposes a pre-trained model on many abstracts published in the Social Science\nCitation Index (SSCI) journals. The models, which are available on Github\n(https://github.com/S-T-Full-Text-Knowledge-Mining/SSCI-BERT), show excellent\nperformance on discipline classification and abstract structure-function\nrecognition tasks with the social sciences literature.",
    "descriptor": "\nComments: 20 pages,2 figures\n",
    "authors": [
      "Si Shen",
      "Jiangfeng Liu",
      "Litao Lin",
      "Ying Huang",
      "Lin Zhang",
      "Chang Liu",
      "Yutong Feng",
      "Dongbo Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.04510"
  },
  {
    "id": "arXiv:2206.04511",
    "title": "Efficient Human Pose Estimation via 3D Event Point Cloud",
    "abstract": "Human Pose Estimation (HPE) based on RGB images has experienced a rapid\ndevelopment benefiting from deep learning. However, event-based HPE has not\nbeen fully studied, which remains great potential for applications in extreme\nscenes and efficiency-critical conditions. In this paper, we are the first to\nestimate 2D human pose directly from 3D event point cloud. We propose a novel\nrepresentation of events, the rasterized event point cloud, aggregating events\non the same position of a small time slice. It maintains the 3D features from\nmultiple statistical cues and significantly reduces memory consumption and\ncomputation complexity, proved to be efficient in our work. We then leverage\nthe rasterized event point cloud as input to three different backbones,\nPointNet, DGCNN, and Point Transformer, with two linear layer decoders to\npredict the location of human keypoints. We find that based on our method,\nPointNet achieves promising results with much faster speed, whereas Point\nTransfomer reaches much higher accuracy, even close to previous\nevent-frame-based methods. A comprehensive set of results demonstrates that our\nproposed method is consistently effective for these 3D backbone models in\nevent-driven human pose estimation. Our method based on PointNet with 2048\npoints input achieves 82.46mm in MPJPE3D on the DHP19 dataset, while only has a\nlatency of 12.29ms on an NVIDIA Jetson Xavier NX edge computing platform, which\nis ideally suitable for real-time detection with event cameras. Code will be\nmade publicly at https://github.com/MasterHow/EventPointPose.",
    "descriptor": "\nComments: Code will be made publicly at this https URL\n",
    "authors": [
      "Jiaan Chen",
      "Hao Shi",
      "Yaozu Ye",
      "Kailun Yang",
      "Lei Sun",
      "Kaiwei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.04511"
  },
  {
    "id": "arXiv:2206.04513",
    "title": "AAM-Gym: Artificial Intelligence Testbed for Advanced Air Mobility",
    "abstract": "We introduce AAM-Gym, a research and development testbed for Advanced Air\nMobility (AAM). AAM has the potential to revolutionize travel by reducing\nground traffic and emissions by leveraging new types of aircraft such as\nelectric vertical take-off and landing (eVTOL) aircraft and new advanced\nartificial intelligence (AI) algorithms. Validation of AI algorithms require\nrepresentative AAM scenarios, as well as a fast time simulation testbed to\nevaluate their performance. Until now, there has been no such testbed available\nfor AAM to enable a common research platform for individuals in government,\nindustry, or academia. MIT Lincoln Laboratory has developed AAM-Gym to address\nthis gap by providing an ecosystem to develop, train, and validate new and\nestablished AI algorithms across a wide variety of AAM use-cases. In this\npaper, we use AAM-Gym to study the performance of two reinforcement learning\nalgorithms on an AAM use-case, separation assurance in AAM corridors. The\nperformance of the two algorithms is demonstrated based on a series of metrics\nprovided by AAM-Gym, showing the testbed's utility to AAM research.",
    "descriptor": "\nComments: 10 pages, accepted for publication in 2022 IEEE/AIAA Digital Avionics Systems Conference\n",
    "authors": [
      "Marc Brittain",
      "Luis E. Alvarez",
      "Kara Breeden",
      "Ian Jessen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.04513"
  },
  {
    "id": "arXiv:2206.04516",
    "title": "Accurate Node Feature Estimation with Structured Variational Graph  Autoencoder",
    "abstract": "Given a graph with partial observations of node features, how can we estimate\nthe missing features accurately? Feature estimation is a crucial problem for\nanalyzing real-world graphs whose features are commonly missing during the data\ncollection process. Accurate estimation not only provides diverse information\nof nodes but also supports the inference of graph neural networks that require\nthe full observation of node features. However, designing an effective approach\nfor estimating high-dimensional features is challenging, since it requires an\nestimator to have large representation power, increasing the risk of\noverfitting. In this work, we propose SVGA (Structured Variational Graph\nAutoencoder), an accurate method for feature estimation. SVGA applies strong\nregularization to the distribution of latent variables by structured\nvariational inference, which models the prior of variables as Gaussian Markov\nrandom field based on the graph structure. As a result, SVGA combines the\nadvantages of probabilistic inference and graph neural networks, achieving\nstate-of-the-art performance in real datasets.",
    "descriptor": "\nComments: Accepted to KDD 2022\n",
    "authors": [
      "Jaemin Yoo",
      "Hyunsik Jeon",
      "Jinhong Jung",
      "U Kang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04516"
  },
  {
    "id": "arXiv:2206.04520",
    "title": "An FPGA-based Solution for Convolution Operation Acceleration",
    "abstract": "Hardware-based acceleration is an extensive attempt to facilitate many\ncomputationally-intensive mathematics operations. This paper proposes an\nFPGA-based architecture to accelerate the convolution operation - a complex and\nexpensive computing step that appears in many Convolutional Neural Network\nmodels. We target the design to the standard convolution operation, intending\nto launch the product as an edge-AI solution. The project's purpose is to\nproduce an FPGA IP core that can process a convolutional layer at a time.\nSystem developers can deploy the IP core with various FPGA families by using\nVerilog HDL as the primary design language for the architecture. The\nexperimental results show that our single computing core synthesized on a\nsimple edge computing FPGA board can offer 0.224 GOPS. When the board is fully\nutilized, 4.48 GOPS can be achieved.",
    "descriptor": "\nComments: 11 pages, 6 figures, accepted to The First International Conference on Intelligence of Things (ICIT 2022)\n",
    "authors": [
      "Trung Dinh Pham",
      "Bao Gia Bach",
      "Lam Trinh Luu",
      "Minh Dinh Nguyen",
      "Hai Duc Pham",
      "Khoa Bui Anh",
      "Xuan Quang Nguyen",
      "Cuong Pham Quoc"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04520"
  },
  {
    "id": "arXiv:2206.04523",
    "title": "Face-Dubbing++: Lip-Synchronous, Voice Preserving Translation of Videos",
    "abstract": "In this paper, we propose a neural end-to-end system for voice preserving,\nlip-synchronous translation of videos. The system is designed to combine\nmultiple component models and produces a video of the original speaker speaking\nin the target language that is lip-synchronous with the target speech, yet\nmaintains emphases in speech, voice characteristics, face video of the original\nspeaker. The pipeline starts with automatic speech recognition including\nemphasis detection, followed by a translation model. The translated text is\nthen synthesized by a Text-to-Speech model that recreates the original emphases\nmapped from the original sentence. The resulting synthetic voice is then mapped\nback to the original speakers' voice using a voice conversion model. Finally,\nto synchronize the lips of the speaker with the translated audio, a conditional\ngenerative adversarial network-based model generates frames of adapted lip\nmovements with respect to the input face image as well as the output of the\nvoice conversion model. In the end, the system combines the generated video\nwith the converted audio to produce the final output. The result is a video of\na speaker speaking in another language without actually knowing it. To evaluate\nour design, we present a user study of the complete system as well as separate\nevaluations of the single components. Since there is no available dataset to\nevaluate our whole system, we collect a test set and evaluate our system on\nthis test set. The results indicate that our system is able to generate\nconvincing videos of the original speaker speaking the target language while\npreserving the original speaker's characteristics. The collected dataset will\nbe shared.",
    "descriptor": "",
    "authors": [
      "Alexander Waibel",
      "Moritz Behr",
      "Fevziye Irem Eyiokur",
      "Dogucan Yaman",
      "Tuan-Nam Nguyen",
      "Carlos Mullov",
      "Mehmet Arif Demirtas",
      "Alperen Kantarc\u0131",
      "Stefan Constantin",
      "Haz\u0131m Kemal Ekenel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.04523"
  },
  {
    "id": "arXiv:2206.04528",
    "title": "Joint radar and communications with multicarrier chirp-based waveform",
    "abstract": "We consider a multicarrier chirp-based waveform for joint radar and\ncommunication (JRC) systems and derive its time discrete periodic ambiguity\nfunction (AF). An advantage of the waveform is that it includes a set of\nwaveform parameters (e.g., chirp rate) which together with the transmit\nsequence, can be selected to flexibly shape the AF to be thumbtack-like, or to\nbe ridge-like, either along the delay axis or the Doppler axis. These shapes\nare applicable for different use cases, e.g., target detection or time- and\nfrequency synchronization. The results show that better signal detection\nperformance than OFDM and DFT-s-OFDM can be achieved on channels with large\nDoppler frequency. Furthermore, it is shown how transmit sequences can be\nselected in order to achieve 0 dB peak-to-average-power-ratio (PAPR) of the\nwaveform.",
    "descriptor": "\nComments: 16 pages, 11 figures, submitted to IEEE Open Journal of the Communications Society\n",
    "authors": [
      "Fredrik Berggren",
      "Branislav M. Popovic"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.04528"
  },
  {
    "id": "arXiv:2206.04530",
    "title": "DORA: Exploring outlier representations in Deep Neural Networks",
    "abstract": "Deep Neural Networks (DNNs) draw their power from the representations they\nlearn. In recent years, however, researchers have found that DNNs, while being\nincredibly effective in learning complex abstractions, also tend to be infected\nwith artifacts, such as biases, Clever Hanses (CH), or Backdoors, due to\nspurious correlations inherent in the training data. So far, existing methods\nfor uncovering such artifactual and malicious behavior in trained models focus\non finding artifacts in the input data, which requires both availabilities of a\ndata set and human intervention. In this paper, we introduce DORA\n(Data-agnOstic Representation Analysis): the first automatic data-agnostic\nmethod for the detection of potentially infected representations in Deep Neural\nNetworks. We further show that contaminated representations found by DORA can\nbe used to detect infected samples in any given dataset. We qualitatively and\nquantitatively evaluate the performance of our proposed method in both,\ncontrolled toy scenarios, and in real-world settings, where we demonstrate the\nbenefit of DORA in safety-critical applications.",
    "descriptor": "\nComments: 21 pages, 22 figures\n",
    "authors": [
      "Kirill Bykov",
      "Mayukh Deb",
      "Dennis Grinwald",
      "Klaus-Robert M\u00fcller",
      "Marina M.-C. H\u00f6hne"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.04530"
  },
  {
    "id": "arXiv:2206.04531",
    "title": "ECLAD: Extracting Concepts with Local Aggregated Descriptors",
    "abstract": "Convolutional neural networks are being increasingly used in critical\nsystems, where ensuring their robustness and alignment is crucial. In this\ncontext, the field of explainable artificial intelligence has proposed the\ngeneration of high-level explanations through concept extraction. These methods\ndetect whether a concept is present in an image, but are incapable of locating\nwhere. What is more, a fair comparison of approaches is difficult, as proper\nvalidation procedures are missing. To fill these gaps, we propose a novel\nmethod for automatic concept extraction and localization based on\nrepresentations obtained through the pixel-wise aggregations of activation maps\nof CNNs. Further, we introduce a process for the validation of\nconcept-extraction techniques based on synthetic datasets with pixel-wise\nannotations of their main components, reducing human intervention. Through\nextensive experimentation on both synthetic and real-world datasets, our method\nachieves better performance in comparison to state-of-the-art alternatives.",
    "descriptor": "\nComments: 32 pages, under review\n",
    "authors": [
      "Andres Felipe Posada-Moreno",
      "Nikita Surya",
      "Sebastian Trimpe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04531"
  },
  {
    "id": "arXiv:2206.04533",
    "title": "DogTouch: CNN-based Recognition of Surface Textures by Quadruped Robot  with High Density Tactile Sensors",
    "abstract": "The ability to perform locomotion in various terrains is critical for legged\nrobots. However, the robot has to have a better understanding of the surface it\nis walking on to perform robust locomotion on different terrains. Animals and\nhumans are able to recognize the surface with the help of the tactile sensation\non their feet. Although, the foot tactile sensation for legged robots has not\nbeen much explored. This paper presents research on a novel quadruped robot\nDogTouch with tactile sensing feet (TSF). TSF allows the recognition of\ndifferent surface textures utilizing a tactile sensor and a convolutional\nneural network (CNN). The experimental results show a sufficient validation\naccuracy of 74.37\\% for our trained CNN-based model, with the highest\nrecognition for line patterns of 90\\%. In the future, we plan to improve the\nprediction model by presenting surface samples with the various depths of\npatterns and applying advanced Deep Learning and Shallow learning models for\nsurface recognition.\nAdditionally, we propose a novel approach to navigation of quadruped and\nlegged robots. We can arrange the tactile paving textured surface (similar that\nused for blind or visually impaired people). Thus, DogTouch will be capable of\nlocomotion in unknown environment by just recognizing the specific tactile\npatterns which will indicate the straight path, left or right turn, pedestrian\ncrossing, road, and etc. That will allow robust navigation regardless of\nlighting condition. Future quadruped robots equipped with visual and tactile\nperception system will be able to safely and intelligently navigate and\ninteract in the unstructured indoor and outdoor environment.",
    "descriptor": "\nComments: Accepted paper at IEEE Vehicular Technology Conference 2022 (IEEE VTC 2022), IEEE copyright\n",
    "authors": [
      "Nipun Dhananjaya Weerakkodi Mudalige",
      "Elena Nazarova",
      "Ildar Babataev",
      "Pavel Kopanev",
      "Aleksey Fedoseev",
      "Miguel Altamirano Cabrera",
      "Dzmitry Tsetserukou"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.04533"
  },
  {
    "id": "arXiv:2206.04544",
    "title": "Service-Oriented Architecture for Drone-based Multi-Package Delivery",
    "abstract": "We propose a novel service-oriented architecture for drone-based\nmulti-package delivery in a skyway network. The proposed architecture provides\na high-level design for deploying a skyway network in a city for the effective\nprovisioning of drone services. We propose a graph-based heuristic to reduce\nthe search space for optimal service selection in the skyway network. We then\nfind an optimal solution using the selected drone services under a set of\nconstraints. We conduct experiments to demonstrate the efficiency of our\nproposed approach.",
    "descriptor": "\nComments: 6 pages, 4 figures. This is an accepted paper and it is going to appear in the Proceedings of the 2022 IEEE International Conference on Web Services (IEEE ICWS 2022)\n",
    "authors": [
      "Babar Shahzaad",
      "Athman Bouguettaya"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.04544"
  },
  {
    "id": "arXiv:2206.04545",
    "title": "Novel resolution analysis for the Radon transform in $\\mathbb R^2$ for  functions with rough edges",
    "abstract": "Let $f$ be a function in $\\mathbb R^2$, which has a jump across a smooth\ncurve $\\mathcal S$ with nonzero curvature. We consider a family of functions\n$f_\\epsilon$ with jumps across a family of curves $\\mathcal S_\\epsilon$. Each\n$\\mathcal S_\\epsilon$ is an $O(\\epsilon)$-size perturbation of $\\mathcal S$,\nwhich scales like $O(\\epsilon^{-1/2})$ along $\\mathcal S$. Let\n$f_\\epsilon^{\\text{rec}}$ be the reconstruction of $f_\\epsilon$ from its\ndiscrete Radon transform data, where $\\epsilon$ is the data sampling rate. A\nsimple asymptotic (as $\\epsilon\\to0$) formula to approximate\n$f_\\epsilon^{\\text{rec}}$ in any $O(\\epsilon)$-size neighborhood of $\\mathcal\nS$ was derived heuristically in an earlier paper of the author. Numerical\nexperiments revealed that the formula is highly accurate even for nonsmooth\n(i.e., only H{\\\"o}lder continuous) $\\mathcal S_\\epsilon$. In this paper we\nprovide a full proof of this result, which says that the magnitude of the error\nbetween $f_\\epsilon^{\\text{rec}}$ and its approximation is\n$O(\\epsilon^{1/2}\\ln(1/\\epsilon))$. The main assumption is that the level sets\nof the function $H_0(\\cdot,\\epsilon)$, which parametrizes the perturbation\n$\\mathcal S\\to\\mathcal S_\\epsilon$, are not too dense.",
    "descriptor": "",
    "authors": [
      "Alexander Katsevich"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.04545"
  },
  {
    "id": "arXiv:2206.04546",
    "title": "Pragmatically Learning from Pedagogical Demonstrations in Multi-Goal  Environments",
    "abstract": "Learning from demonstration methods usually leverage close to optimal\ndemonstrations to accelerate training. By contrast, when demonstrating a task,\nhuman teachers deviate from optimal demonstrations and pedagogically modify\ntheir behavior by giving demonstrations that best disambiguate the goal they\nwant to demonstrate. Analogously, human learners excel at pragmatically\ninferring the intent of the teacher, facilitating communication between the two\nagents. These mechanisms are critical in the few demonstrations regime, where\ninferring the goal is more difficult. In this paper, we implement pedagogy and\npragmatism mechanisms by leveraging a Bayesian model of goal inference from\ndemonstrations. We highlight the benefits of this model in multi-goal\nteacher-learner setups with two artificial agents that learn with\ngoal-conditioned Reinforcement Learning. We show that combining a pedagogical\nteacher and a pragmatic learner results in faster learning and reduced goal\nambiguity over standard learning from demonstrations, especially in the few\ndemonstrations regime.",
    "descriptor": "",
    "authors": [
      "Hugo Caselles-Dupr\u00e9",
      "Olivier Sigaud",
      "Mohamed Chetouani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04546"
  },
  {
    "id": "arXiv:2206.04549",
    "title": "Spencer's theorem in nearly input-sparsity time",
    "abstract": "A celebrated theorem of Spencer states that for every set system $S_1,\\dots,\nS_m \\subseteq [n]$, there is a coloring of the ground set with $\\{\\pm 1\\}$ with\ndiscrepancy $O(\\sqrt{n\\log(m/n+2)})$. We provide an algorithm to find such a\ncoloring in near input-sparsity time $\\tilde{O}(n+\\sum_{i=1}^{m}|S_i|)$. A key\ningredient in our work, which may be of independent interest, is a novel width\nreduction technique for solving linear programs, not of covering/packing type,\nin near input-sparsity time using the multiplicative weights update method.",
    "descriptor": "\nComments: 18 pages; comments welcome\n",
    "authors": [
      "Vishesh Jain",
      "Ashwin Sah",
      "Mehtaab Sawhney"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2206.04549"
  },
  {
    "id": "arXiv:2206.04551",
    "title": "A Relational Intervention Approach for Unsupervised Dynamics  Generalization in Model-Based Reinforcement Learning",
    "abstract": "The generalization of model-based reinforcement learning (MBRL) methods to\nenvironments with unseen transition dynamics is an important yet challenging\nproblem. Existing methods try to extract environment-specified information $Z$\nfrom past transition segments to make the dynamics prediction model\ngeneralizable to different dynamics. However, because environments are not\nlabelled, the extracted information inevitably contains redundant information\nunrelated to the dynamics in transition segments and thus fails to maintain a\ncrucial property of $Z$: $Z$ should be similar in the same environment and\ndissimilar in different ones. As a result, the learned dynamics prediction\nfunction will deviate from the true one, which undermines the generalization\nability. To tackle this problem, we introduce an interventional prediction\nmodule to estimate the probability of two estimated $\\hat{z}_i, \\hat{z}_j$\nbelonging to the same environment. Furthermore, by utilizing the $Z$'s\ninvariance within a single environment, a relational head is proposed to\nenforce the similarity between $\\hat{{Z}}$ from the same environment. As a\nresult, the redundant information will be reduced in $\\hat{Z}$. We empirically\nshow that $\\hat{{Z}}$ estimated by our method enjoy less redundant information\nthan previous methods, and such $\\hat{{Z}}$ can significantly reduce dynamics\nprediction errors and improve the performance of model-based RL methods on\nzero-shot new environments with unseen dynamics. The codes of this method are\navailable at \\url{https://github.com/CR-Gjx/RIA}.",
    "descriptor": "\nComments: ICLR2022 accepted paper\n",
    "authors": [
      "Jixian Guo",
      "Mingming Gong",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.04551"
  },
  {
    "id": "arXiv:2206.04557",
    "title": "SparseFormer: Attention-based Depth Completion Network",
    "abstract": "Most pipelines for Augmented and Virtual Reality estimate the ego-motion of\nthe camera by creating a map of sparse 3D landmarks. In this paper, we tackle\nthe problem of depth completion, that is, densifying this sparse 3D map using\nRGB images as guidance. This remains a challenging problem due to the low\ndensity, non-uniform and outlier-prone 3D landmarks produced by SfM and SLAM\npipelines. We introduce a transformer block, SparseFormer, that fuses 3D\nlandmarks with deep visual features to produce dense depth. The SparseFormer\nhas a global receptive field, making the module especially effective for depth\ncompletion with low-density and non-uniform landmarks. To address the issue of\ndepth outliers among the 3D landmarks, we introduce a trainable refinement\nmodule that filters outliers through attention between the sparse landmarks.",
    "descriptor": "\nComments: Accepted at CV4ARVR 2022\n",
    "authors": [
      "Frederik Warburg",
      "Michael Ramamonjisoa",
      "Manuel L\u00f3pez-Antequera"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.04557"
  },
  {
    "id": "arXiv:2206.04558",
    "title": "BFS-Net: Weakly Supervised Cell Instance Segmentation from Bright-Field  Microscopy Z-Stacks",
    "abstract": "Despite its broad availability, volumetric information acquisition from\nBright-Field Microscopy (BFM) is inherently difficult due to the projective\nnature of the acquisition process. We investigate the prediction of 3D cell\ninstances from a set of BFM Z-Stack images. We propose a novel two-stage weakly\nsupervised method for volumetric instance segmentation of cells which only\nrequires approximate cell centroids annotation. Created pseudo-labels are\nthereby refined with a novel refinement loss with Z-stack guidance. The\nevaluations show that our approach can generalize not only to BFM Z-Stack data,\nbut to other 3D cell imaging modalities. A comparison of our pipeline against\nfully supervised methods indicates that the significant gain in reduced data\ncollection and labelling results in minor performance difference.",
    "descriptor": "",
    "authors": [
      "Shervin Dehghani",
      "Benjamin Busam",
      "Nassir Navab",
      "Ali Nasseri"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.04558"
  },
  {
    "id": "arXiv:2206.04561",
    "title": "Functional Code Building Genetic Programming",
    "abstract": "General program synthesis has become an important application area for\ngenetic programming (GP), and for artificial intelligence more generally. Code\nBuilding Genetic Programming (CBGP) is a recently introduced GP method for\ngeneral program synthesis that leverages reflection and first class\nspecifications to support the evolution of programs that may use arbitrary data\ntypes, polymorphism, and functions drawn from existing codebases. However,\nneither a formal description nor a thorough benchmarking of CBGP have yet been\nreported. In this work, we formalize the method of CBGP using algorithms from\ntype theory. Specially, we show that a functional programming language and a\nHindley-Milner type system can be used to evolve type-safe programs using the\nprocess abstractly described in the original CBGP paper. Furthermore, we\nperform a comprehensive analysis of the search performance of this functional\nvariant of CBGP compared to other contemporary GP program synthesis methods.",
    "descriptor": "",
    "authors": [
      "Edward Pantridge",
      "Thomas Helmuth",
      "Lee Spector"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.04561"
  },
  {
    "id": "arXiv:2206.04564",
    "title": "TwiBot-22: Towards Graph-Based Twitter Bot Detection",
    "abstract": "Twitter bot detection has become an increasingly important task to combat\nmisinformation, facilitate social media moderation, and preserve the integrity\nof the online discourse. State-of-the-art bot detection methods generally\nleverage the graph structure of the Twitter network, and they exhibit promising\nperformance when confronting novel Twitter bots that traditional methods fail\nto detect. However, very few of the existing Twitter bot detection datasets are\ngraph-based, and even these few graph-based datasets suffer from limited\ndataset scale, incomplete graph structure, as well as low annotation quality.\nIn fact, the lack of a large-scale graph-based Twitter bot detection benchmark\nthat addresses these issues has seriously hindered the development and\nevaluation of novel graph-based bot detection approaches. In this paper, we\npropose TwiBot-22, a comprehensive graph-based Twitter bot detection benchmark\nthat presents the largest dataset to date, provides diversified entities and\nrelations on the Twitter network, and has considerably better annotation\nquality than existing datasets. In addition, we re-implement 35 representative\nTwitter bot detection baselines and evaluate them on 9 datasets, including\nTwiBot-22, to promote a fair comparison of model performance and a holistic\nunderstanding of research progress. To facilitate further research, we\nconsolidate all implemented codes and datasets into the TwiBot-22 evaluation\nframework, where researchers could consistently evaluate new models and\ndatasets. The TwiBot-22 Twitter bot detection benchmark and evaluation\nframework are publicly available at https://twibot22.github.io/",
    "descriptor": "",
    "authors": [
      "Shangbin Feng",
      "Zhaoxuan Tan",
      "Herun Wan",
      "Ningnan Wang",
      "Zilong Chen",
      "Binchi Zhang",
      "Qinghua Zheng",
      "Wenqian Zhang",
      "Zhenyu Lei",
      "Shujie Yang",
      "Xinshun Feng",
      "Qingyue Zhang",
      "Hongrui Wang",
      "Yuhan Liu",
      "Yuyang Bai",
      "Heng Wang",
      "Zijian Cai",
      "Yanbo Wang",
      "Lijing Zheng",
      "Zihan Ma",
      "Jundong Li",
      "Minnan Luo"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.04564"
  },
  {
    "id": "arXiv:2206.04568",
    "title": "Byzantine-Resilient Decentralized Stochastic Optimization with Robust  Aggregation Rules",
    "abstract": "This work focuses on decentralized stochastic optimization in the presence of\nByzantine attacks. During the optimization process, an unknown number of\nmalfunctioning or malicious nodes, which we term as Byzantine workers, disobey\nthe algorithmic protocol and send wrong messages to their neighbors. Even\nthough various Byzantine-resilient algorithms have been developed for\ndistributed stochastic optimization, we show that there are still two major\nchallenges during the designation of robust aggregation rules suitable for\ndecentralized stochastic optimization: disagreement and non-doubly stochastic\nmixing matrix. This paper provides a comprehensive analysis disclosing the\nnegative effects of these two issues, and gives guidelines of designing\nfavorable Byzantine-resilient decentralized stochastic optimization algorithms.\nFollowing the guidelines, we propose an iterative filtering-based robust\naggregation rule termed iterative outlier scissor (IOS), which has provable\nByzantine-resilience. Numerical experiments demonstrate the effectiveness of\nIOS.",
    "descriptor": "",
    "authors": [
      "Zhaoxian Wu",
      "Tianyi Chen",
      "Qing Ling"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.04568"
  },
  {
    "id": "arXiv:2206.04571",
    "title": "Revisiting End-to-End Speech-to-Text Translation From Scratch",
    "abstract": "End-to-end (E2E) speech-to-text translation (ST) often depends on pretraining\nits encoder and/or decoder using source transcripts via speech recognition or\ntext translation tasks, without which translation performance drops\nsubstantially. However, transcripts are not always available, and how\nsignificant such pretraining is for E2E ST has rarely been studied in the\nliterature. In this paper, we revisit this question and explore the extent to\nwhich the quality of E2E ST trained on speech-translation pairs alone can be\nimproved. We reexamine several techniques proven beneficial to ST previously,\nand offer a set of best practices that biases a Transformer-based E2E ST system\ntoward training from scratch. Besides, we propose parameterized distance\npenalty to facilitate the modeling of locality in the self-attention model for\nspeech. On four benchmarks covering 23 languages, our experiments show that,\nwithout using any transcripts or pretraining, the proposed system reaches and\neven outperforms previous studies adopting pretraining, although the gap\nremains in (extremely) low-resource settings. Finally, we discuss neural\nacoustic feature modeling, where a neural model is designed to extract acoustic\nfeatures from raw speech signals directly, with the goal to simplify inductive\nbiases and add freedom to the model in describing speech. For the first time,\nwe demonstrate its feasibility and show encouraging results on ST tasks.",
    "descriptor": "\nComments: ICML\n",
    "authors": [
      "Biao Zhang",
      "Barry Haddow",
      "Rico Sennrich"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.04571"
  },
  {
    "id": "arXiv:2206.04572",
    "title": "Log-Concave and Multivariate Canonical Noise Distributions for  Differential Privacy",
    "abstract": "A canonical noise distribution (CND) is an additive mechanism designed to\nsatisfy $f$-differential privacy ($f$-DP), without any wasted privacy budget.\n$f$-DP is a hypothesis testing-based formulation of privacy phrased in terms of\ntradeoff functions, which captures the difficulty of a hypothesis test. In this\npaper, we consider the existence and construction of log-concave CNDs as well\nas multivariate CNDs. Log-concave distributions are important to ensure that\nhigher outputs of the mechanism correspond to higher input values, whereas\nmultivariate noise distributions are important to ensure that a joint release\nof multiple outputs has a tight privacy characterization. We show that the\nexistence and construction of CNDs for both types of problems is related to\nwhether the tradeoff function can be decomposed by functional composition\n(related to group privacy) or mechanism composition. In particular, we show\nthat pure $\\epsilon$-DP cannot be decomposed in either way and that there is\nneither a log-concave CND nor any multivariate CND for $\\epsilon$-DP. On the\nother hand, we show that Gaussian-DP, $(0,\\delta)$-DP, and Laplace-DP each have\nboth log-concave and multivariate CNDs.",
    "descriptor": "\nComments: 9 pages before references, 1 Figure\n",
    "authors": [
      "Jordan Awan",
      "Jinshuo Dong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2206.04572"
  },
  {
    "id": "arXiv:2206.04575",
    "title": "Transformer based Urdu Handwritten Text Optical Character Reader",
    "abstract": "Extracting Handwritten text is one of the most important components of\ndigitizing information and making it available for large scale setting.\nHandwriting Optical Character Reader (OCR) is a research problem in computer\nvision and natural language processing computing, and a lot of work has been\ndone for English, but unfortunately, very little work has been done for low\nresourced languages such as Urdu. Urdu language script is very difficult\nbecause of its cursive nature and change of shape of characters based on it's\nrelative position, therefore, a need arises to propose a model which can\nunderstand complex features and generalize it for every kind of handwriting\nstyle. In this work, we propose a transformer based Urdu Handwritten text\nextraction model. As transformers have been very successful in Natural Language\nUnderstanding task, we explore them further to understand complex Urdu\nHandwriting.",
    "descriptor": "",
    "authors": [
      "Mohammad Daniyal Shaiq",
      "Musa Dildar Ahmed Cheema",
      "Ali Kamal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04575"
  },
  {
    "id": "arXiv:2206.04583",
    "title": "Clustering with Queries under Semi-Random Noise",
    "abstract": "The seminal paper by Mazumdar and Saha \\cite{MS17a} introduced an extensive\nline of work on clustering with noisy queries. Yet, despite significant\nprogress on the problem, the proposed methods depend crucially on knowing the\nexact probabilities of errors of the underlying fully-random oracle. In this\nwork, we develop robust learning methods that tolerate general semi-random\nnoise obtaining qualitatively the same guarantees as the best possible methods\nin the fully-random model.\nMore specifically, given a set of $n$ points with an unknown underlying\npartition, we are allowed to query pairs of points $u,v$ to check if they are\nin the same cluster, but with probability $p$, the answer may be adversarially\nchosen. We show that information theoretically $O\\left(\\frac{nk \\log n}\n{(1-2p)^2}\\right)$ queries suffice to learn any cluster of sufficiently large\nsize. Our main result is a computationally efficient algorithm that can\nidentify large clusters with $O\\left(\\frac{nk \\log n} {(1-2p)^2}\\right) +\n\\text{poly}\\left(\\log n, k, \\frac{1}{1-2p} \\right)$ queries, matching the\nguarantees of the best known algorithms in the fully-random model. As a\ncorollary of our approach, we develop the first parameter-free algorithm for\nthe fully-random model, answering an open question by \\cite{MS17a}.",
    "descriptor": "\nComments: Accepted for presentation at the Conference on Learning Theory (COLT) 2022\n",
    "authors": [
      "Alberto Del Pia",
      "Mingchen Ma",
      "Christos Tzamos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.04583"
  },
  {
    "id": "arXiv:2206.04584",
    "title": "Efficient and Robust 2D-to-BEV Representation Learning via  Geometry-guided Kernel Transformer",
    "abstract": "Learning Bird's Eye View (BEV) representation from surrounding-view cameras\nis of great importance for autonomous driving. In this work, we propose a\nGeometry-guided Kernel Transformer (GKT), a novel 2D-to-BEV representation\nlearning mechanism. GKT leverages the geometric priors to guide the transformer\nto focus on discriminative regions and unfolds kernel features to generate BEV\nrepresentation. For fast inference, we further introduce a look-up table (LUT)\nindexing method to get rid of the camera's calibrated parameters at runtime.\nGKT can run at $72.3$ FPS on 3090 GPU / $45.6$ FPS on 2080ti GPU and is robust\nto the camera deviation and the predefined BEV height. And GKT achieves the\nstate-of-the-art real-time segmentation results, i.e., 38.0 mIoU\n(100m$\\times$100m perception range at a 0.5m resolution) on the nuScenes val\nset. Given the efficiency, effectiveness, and robustness, GKT has great\npractical values in autopilot scenarios, especially for real-time running\nsystems. Code and models will be available at\n\\url{https://github.com/hustvl/GKT}.",
    "descriptor": "\nComments: Tech report. Work in progress\n",
    "authors": [
      "Shaoyu Chen",
      "Tianheng Cheng",
      "Xinggang Wang",
      "Wenming Meng",
      "Qian Zhang",
      "Wenyu Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.04584"
  },
  {
    "id": "arXiv:2206.04585",
    "title": "Extracting Zero-shot Common Sense from Large Language Models for Robot  3D Scene Understanding",
    "abstract": "Semantic 3D scene understanding is a problem of critical importance in\nrobotics. While significant advances have been made in simultaneous\nlocalization and mapping algorithms, robots are still far from having the\ncommon sense knowledge about household objects and their locations of an\naverage human. We introduce a novel method for leveraging common sense embedded\nwithin large language models for labelling rooms given the objects contained\nwithin. This algorithm has the added benefits of (i) requiring no task-specific\npre-training (operating entirely in the zero-shot regime) and (ii) generalizing\nto arbitrary room and object labels, including previously-unseen ones -- both\nof which are highly desirable traits in robotic scene understanding algorithms.\nThe proposed algorithm operates on 3D scene graphs produced by modern spatial\nperception systems, and we hope it will pave the way to more generalizable and\nscalable high-level 3D scene understanding for robotics.",
    "descriptor": "\nComments: 4 pages (excluding references and appendix), 2 figures, 2 tables. Submitted to Robotics: Science and Systems 2022 2nd Workshop on Scaling Robot Learning\n",
    "authors": [
      "William Chen",
      "Siyi Hu",
      "Rajat Talak",
      "Luca Carlone"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.04585"
  },
  {
    "id": "arXiv:2206.04589",
    "title": "Optimal SQ Lower Bounds for Robustly Learning Discrete Product  Distributions and Ising Models",
    "abstract": "We establish optimal Statistical Query (SQ) lower bounds for robustly\nlearning certain families of discrete high-dimensional distributions. In\nparticular, we show that no efficient SQ algorithm with access to an\n$\\epsilon$-corrupted binary product distribution can learn its mean within\n$\\ell_2$-error $o(\\epsilon \\sqrt{\\log(1/\\epsilon)})$. Similarly, we show that\nno efficient SQ algorithm with access to an $\\epsilon$-corrupted ferromagnetic\nhigh-temperature Ising model can learn the model to total variation distance\n$o(\\epsilon \\log(1/\\epsilon))$. Our SQ lower bounds match the error guarantees\nof known algorithms for these problems, providing evidence that current upper\nbounds for these tasks are best possible. At the technical level, we develop a\ngeneric SQ lower bound for discrete high-dimensional distributions starting\nfrom low dimensional moment matching constructions that we believe will find\nother applications. Additionally, we introduce new ideas to analyze these\nmoment-matching constructions for discrete univariate distributions.",
    "descriptor": "\nComments: To appear in COLT 2022\n",
    "authors": [
      "Ilias Diakonikolas",
      "Daniel M. Kane",
      "Yuxin Sun"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.04589"
  },
  {
    "id": "arXiv:2206.04590",
    "title": "GASP: Gated Attention For Saliency Prediction",
    "abstract": "Saliency prediction refers to the computational task of modeling overt\nattention. Social cues greatly influence our attention, consequently altering\nour eye movements and behavior. To emphasize the efficacy of such features, we\npresent a neural model for integrating social cues and weighting their\ninfluences. Our model consists of two stages. During the first stage, we detect\ntwo social cues by following gaze, estimating gaze direction, and recognizing\naffect. These features are then transformed into spatiotemporal maps through\nimage processing operations. The transformed representations are propagated to\nthe second stage (GASP) where we explore various techniques of late fusion for\nintegrating social cues and introduce two sub-networks for directing attention\nto relevant stimuli. Our experiments indicate that fusion approaches achieve\nbetter results for static integration methods, whereas non-fusion approaches\nfor which the influence of each modality is unknown, result in better outcomes\nwhen coupled with recurrent models for dynamic saliency prediction. We show\nthat gaze direction and affective representations contribute a prediction to\nground-truth correspondence improvement of at least 5% compared to dynamic\nsaliency models without social cues. Furthermore, affective representations\nimprove GASP, supporting the necessity of considering affect-biased attention\nin predicting saliency.",
    "descriptor": "\nComments: International Joint Conference on Artificial Intelligence (IJCAI-21)\n",
    "authors": [
      "Fares Abawi",
      "Tom Weber",
      "Stefan Wermter"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.04590"
  },
  {
    "id": "arXiv:2206.04591",
    "title": "Privacy Leakage in Text Classification: A Data Extraction Approach",
    "abstract": "Recent work has demonstrated the successful extraction of training data from\ngenerative language models. However, it is not evident whether such extraction\nis feasible in text classification models since the training objective is to\npredict the class label as opposed to next-word prediction. This poses an\ninteresting challenge and raises an important question regarding the privacy of\ntraining data in text classification settings. Therefore, we study the\npotential privacy leakage in the text classification domain by investigating\nthe problem of unintended memorization of training data that is not pertinent\nto the learning task. We propose an algorithm to extract missing tokens of a\npartial text by exploiting the likelihood of the class label provided by the\nmodel. We test the effectiveness of our algorithm by inserting canaries into\nthe training set and attempting to extract tokens in these canaries\npost-training. In our experiments, we demonstrate that successful extraction is\npossible to some extent. This can also be used as an auditing strategy to\nassess any potential unauthorized use of personal data without consent.",
    "descriptor": "\nComments: 8 pages, 4 tables. Accepted at NAACL 2022 Workshop on Privacy in NLP (PrivateNLP)\n",
    "authors": [
      "Adel Elmahdy",
      "Huseyin A. Inan",
      "Robert Sim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04591"
  },
  {
    "id": "arXiv:2206.04592",
    "title": "Representing Lanes as Arc-length-based Parametric Curves to Facilitate  Estimation in Vehicle Control",
    "abstract": "This paper revisits the fundamental mathematics of Taylor series to\napproximate curves with function representation and arc-length-based parametric\nrepresentation. Parametric representation is shown to preserve its form in\ncoordinate transformation and parameter shifting. These preservations can\nsignificantly facilitate lane estimation in vehicle control since lanes\nperceived by cameras are typically represented in vehicle body-fixed frames\nwhich are translating and rotating. Then we derived the transformation from\nfunction representation to arc-length-based parametric representation and its\ninverse. We applied the transformation to lane estimation in vehicle control\nproblem, and derived the evolution of coefficients for parametric\nrepresentation that can be used for prediction. We come up with a procedure to\nsimulate the whole process with perception, lane estimation and control for the\npath-following problem. Simulations are performed to demonstrate the efficacy\nof the proposed lane estimation algorithm using parametric representation. The\nresults indicate that the proposed technique ensures that vehicle control can\nachieve reasonably good performance at very low perception updating rate.",
    "descriptor": "\nComments: 14 pages, 8 figures, currently submitted and under review\n",
    "authors": [
      "Wubing B. Qin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.04592"
  },
  {
    "id": "arXiv:2206.04596",
    "title": "Linear Delta Arrays for Dexterous Distributed Manipulation",
    "abstract": "This paper presents a new type of distributed dexterous manipulators: delta\narrays. Each delta array consists of a grid of linearly-actuated delta robots\nwith compliant 3D-printed parallelogram links. These arrays can be used to\nperform planar transportation tasks, similar to smart conveyors. However, the\ndeltas' additional degrees of freedom also afford a wide range of out-of-plane\nmanipulations, as well as prehensile manipulations between sets of deltas. A\ndelta array thus affords a wide range of distributed manipulation strategies.\nIn this paper, we present the design of the delta arrays, including the\nindividual deltas, a modular array structure, and distributed communication and\ncontrol. We also construct and evaluate an 8x8 array using the proposed design.\nOur evaluations show that the resulting 192 DoF robot is capable of performing\nvarious coordinated distributed manipulations of a variety of objects,\nincluding translation, alignment, and prehensile squeezing.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Sarvesh Patil",
      "Tony Tao",
      "Tess Hellebrekers",
      "Oliver Kroemer",
      "F. Zeynep Temel"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.04596"
  },
  {
    "id": "arXiv:2206.04607",
    "title": "On Margins and Generalisation for Voting Classifiers",
    "abstract": "We study the generalisation properties of majority voting on finite ensembles\nof classifiers, proving margin-based generalisation bounds via the PAC-Bayes\ntheory. These provide state-of-the-art guarantees on a number of classification\ntasks. Our central results leverage the Dirichlet posteriors studied recently\nby Zantedeschi et al. [2021] for training voting classifiers; in contrast to\nthat work our bounds apply to non-randomised votes via the use of margins. Our\ncontributions add perspective to the debate on the \"margins theory\" proposed by\nSchapire et al. [1998] for the generalisation of ensemble classifiers.",
    "descriptor": "",
    "authors": [
      "Felix Biggs",
      "Valentina Zantedeschi",
      "Benjamin Guedj"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.04607"
  },
  {
    "id": "arXiv:2206.04613",
    "title": "Explicit Regularization in Overparametrized Models via Noise Injection",
    "abstract": "Injecting noise within gradient descent has several desirable features. In\nthis paper, we explore noise injection before computing a gradient step, which\nis known to have smoothing and regularizing properties. We show that small\nperturbations induce explicit regularization for simple finite-dimensional\nmodels based on the l1-norm, group l1-norms, or nuclear norms. When applied to\noverparametrized neural networks with large widths, we show that the same\nperturbations do not work due to variance explosion resulting from\noverparametrization. However, we also show that independent layer wise\nperturbations allow to avoid the exploding variance term, and explicit\nregularizers can then be obtained. We empirically show that the small\nperturbations lead to better generalization performance than vanilla\n(stochastic) gradient descent training, with minor adjustments to the training\nprocedure.",
    "descriptor": "\nComments: 32 pages\n",
    "authors": [
      "Antonio Orvieto",
      "Anant Raj",
      "Hans Kersting",
      "Francis Bach"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.04613"
  },
  {
    "id": "arXiv:2206.04615",
    "title": "Beyond the Imitation Game: Quantifying and extrapolating the  capabilities of language models",
    "abstract": "Language models demonstrate both quantitative improvement and new qualitative\ncapabilities with increasing scale. Despite their potentially transformative\nimpact, these new capabilities are as yet poorly characterized. In order to\ninform future research, prepare for disruptive new model capabilities, and\nameliorate socially harmful effects, it is vital that we understand the present\nand near-future capabilities and limitations of language models. To address\nthis challenge, we introduce the Beyond the Imitation Game benchmark\n(BIG-bench). BIG-bench currently consists of 204 tasks, contributed by 442\nauthors across 132 institutions. Task topics are diverse, drawing problems from\nlinguistics, childhood development, math, common-sense reasoning, biology,\nphysics, social bias, software development, and beyond. BIG-bench focuses on\ntasks that are believed to be beyond the capabilities of current language\nmodels. We evaluate the behavior of OpenAI's GPT models, Google-internal dense\ntransformer architectures, and Switch-style sparse transformers on BIG-bench,\nacross model sizes spanning millions to hundreds of billions of parameters. In\naddition, a team of human expert raters performed all tasks in order to provide\na strong baseline. Findings include: model performance and calibration both\nimprove with scale, but are poor in absolute terms (and when compared with\nrater performance); performance is remarkably similar across model classes,\nthough with benefits from sparsity; tasks that improve gradually and\npredictably commonly involve a large knowledge or memorization component,\nwhereas tasks that exhibit \"breakthrough\" behavior at a critical scale often\ninvolve multiple steps or components, or brittle metrics; social bias typically\nincreases with scale in settings with ambiguous context, but this can be\nimproved with prompting.",
    "descriptor": "\nComments: 27 pages, 17 figures + references and appendices, repo: this https URL\n",
    "authors": [
      "Aarohi Srivastava",
      "Abhinav Rastogi",
      "Abhishek Rao",
      "Abu Awal Md Shoeb",
      "Abubakar Abid",
      "Adam Fisch",
      "Adam R. Brown",
      "Adam Santoro",
      "Aditya Gupta",
      "Adri\u00e0 Garriga-Alonso",
      "Agnieszka Kluska",
      "Aitor Lewkowycz",
      "Akshat Agarwal",
      "Alethea Power",
      "Alex Ray",
      "Alex Warstadt",
      "Alexander W. Kocurek",
      "Ali Safaya",
      "Ali Tazarv",
      "Alice Xiang",
      "Alicia Parrish",
      "Allen Nie",
      "Aman Hussain",
      "Amanda Askell",
      "Amanda Dsouza",
      "Ameet Rahane",
      "Anantharaman S. Iyer",
      "Anders Andreassen",
      "Andrea Santilli",
      "Andreas Stuhlm\u00fcller",
      "Andrew Dai",
      "Andrew La",
      "Andrew Lampinen",
      "Andy Zou",
      "Angela Jiang",
      "Angelica Chen",
      "Anh Vuong",
      "Animesh Gupta",
      "Anna Gottardi",
      "Antonio Norelli",
      "Anu Venkatesh",
      "Arash Gholamidavoodi",
      "Arfa Tabassum",
      "Arul Menezes",
      "Arun Kirubarajan",
      "Asher Mullokandov",
      "Ashish Sabharwal",
      "Austin Herrick",
      "Avia Efrat",
      "Aykut Erdem",
      "Ayla Karaka\u015f"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.04615"
  },
  {
    "id": "arXiv:2206.04617",
    "title": "Autonomous Precision Drone Landing with Fiducial Markers and a  Gimbal-Mounted Camera for Active Tracking",
    "abstract": "Precision landing is a remaining challenge in autonomous drone flight, with\nno widespread solution. Fiducial markers provide a computationally cheap way\nfor a drone to locate a landing pad and autonomously execute precision\nlandings. However, most work in this field has depended on fixed,\ndownward-facing cameras which restrict the ability of the drone to detect the\nmarker. We present a method of autonomous landing that uses a gimbal-mounted\ncamera to quickly search for the landing pad by simply spinning in place while\ntilting the camera up and down, and to continually aim the camera at the\nlanding pad during approach and landing. This method demonstrates successful\nsearch, tracking, and landing with 4 of 5 tested fiducial systems on a physical\ndrone with no human intervention. Per fiducial system, we present the number of\nsuccessful and unsuccessful landings, and the distributions of the distances\nfrom the drone to the center of the landing pad after each successful landing,\nwith a statistical comparison among the systems. We also show representative\nexamples of flight trajectories, marker tracking performance, and control\noutputs for each channel during the landing. Finally, we discuss qualitative\nstrengths and weaknesses underlying the performance of each system.",
    "descriptor": "",
    "authors": [
      "Joshua Springer",
      "Marcel Kyas"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.04617"
  },
  {
    "id": "arXiv:2206.04620",
    "title": "On the Generalization and Adaption Performance of Causal Models",
    "abstract": "Learning models that offer robust out-of-distribution generalization and fast\nadaptation is a key challenge in modern machine learning. Modelling causal\nstructure into neural networks holds the promise to accomplish robust zero and\nfew-shot adaptation. Recent advances in differentiable causal discovery have\nproposed to factorize the data generating process into a set of modules, i.e.\none module for the conditional distribution of every variable where only causal\nparents are used as predictors. Such a modular decomposition of knowledge\nenables adaptation to distributions shifts by only updating a subset of\nparameters. In this work, we systematically study the generalization and\nadaption performance of such modular neural causal models by comparing it to\nmonolithic models and structured models where the set of predictors is not\nconstrained to causal parents. Our analysis shows that the modular neural\ncausal models outperform other models on both zero and few-shot adaptation in\nlow data regimes and offer robust generalization. We also found that the\neffects are more significant for sparser graphs as compared to denser graphs.",
    "descriptor": "",
    "authors": [
      "Nino Scherrer",
      "Anirudh Goyal",
      "Stefan Bauer",
      "Yoshua Bengio",
      "Nan Rosemary Ke"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.04620"
  },
  {
    "id": "arXiv:2206.04621",
    "title": "A Critical Review on the Use (and Misuse) of Differential Privacy in  Machine Learning",
    "abstract": "We review the use of differential privacy (DP) for privacy protection in\nmachine learning (ML). We show that, driven by the aim of preserving the\naccuracy of the learned models, DP-based ML implementations are so loose that\nthey do not offer the ex ante privacy guarantees of DP. Instead, what they\ndeliver is basically noise addition similar to the traditional (and often\ncriticized) statistical disclosure control approach. Due to the lack of formal\nprivacy guarantees, the actual level of privacy offered must be experimentally\nassessed ex post, which is done very seldom. In this respect, we present\nempirical results showing that standard anti-overfitting techniques in ML can\nachieve a better utility/privacy/efficiency trade-off than DP.",
    "descriptor": "",
    "authors": [
      "Alberto Blanco-Justicia",
      "David Sanchez",
      "Josep Domingo-Ferrer",
      "Krishnamurty Muralidhar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04621"
  },
  {
    "id": "arXiv:2206.04624",
    "title": "Factuality Enhanced Language Models for Open-Ended Text Generation",
    "abstract": "Pretrained language models (LMs) are susceptible to generate text with\nnonfactual information. In this work, we measure and improve the factual\naccuracy of large-scale LMs for open-ended text generation. We design the\nFactualityPrompts test set and metrics to measure the factuality of LM\ngenerations. Based on that, we study the factual accuracy of LMs with parameter\nsizes ranging from 126M to 530B. Interestingly, we find that larger LMs are\nmore factual than smaller ones, although a previous study suggests that larger\nLMs can be less truthful in terms of misconceptions. In addition, popular\nsampling algorithms (e.g., top-p) in open-ended text generation can harm the\nfactuality due to the \"uniform randomness\" introduced at every sampling step.\nWe propose the factual-nucleus sampling algorithm that dynamically adapts the\nrandomness to improve the factuality of generation while maintaining quality.\nFurthermore, we analyze the inefficiencies of the standard training method in\nlearning correct associations between entities from factual text corpus (e.g.,\nWikipedia). We propose a factuality-enhanced training method that uses\nTopicPrefix for better awareness of facts and sentence completion as the\ntraining objective, which can vastly reduce the factual errors.",
    "descriptor": "",
    "authors": [
      "Nayeon Lee",
      "Wei Ping",
      "Peng Xu",
      "Mostofa Patwary",
      "Mohammad Shoeybi",
      "Bryan Catanzaro"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04624"
  },
  {
    "id": "arXiv:2206.04625",
    "title": "AttX: Attentive Cross-Connections for Fusion of Wearable Signals in  Emotion Recognition",
    "abstract": "We propose cross-modal attentive connections, a new dynamic and effective\ntechnique for multimodal representation learning from wearable data. Our\nsolution can be integrated into any stage of the pipeline, i.e., after any\nconvolutional layer or block, to create intermediate connections between\nindividual streams responsible for processing each modality. Additionally, our\nmethod benefits from two properties. First, it can share information\nuni-directionally (from one modality to the other) or bi-directionally. Second,\nit can be integrated into multiple stages at the same time to further allow\nnetwork gradients to be exchanged in several touch-points. We perform extensive\nexperiments on three public multimodal wearable datasets, WESAD, SWELL-KW, and\nCASE, and demonstrate that our method can effectively regulate and share\ninformation between different modalities to learn better representations. Our\nexperiments further demonstrate that once integrated into simple CNN-based\nmultimodal solutions (2, 3, or 4 modalities), our method can result in superior\nor competitive performance to state-of-the-art and outperform a variety of\nbaseline uni-modal and classical multimodal methods.",
    "descriptor": "\nComments: 13 pages, 8 figures\n",
    "authors": [
      "Anubhav Bhatti",
      "Behnam Behinaein",
      "Paul Hungler",
      "Ali Etemad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.04625"
  },
  {
    "id": "arXiv:2206.04632",
    "title": "Temporal Logic Imitation: Learning Plan-Satisficing Motion Policies from  Demonstrations",
    "abstract": "Learning from demonstration (LfD) methods have shown promise for solving\nmulti-step tasks; however, these approaches do not guarantee successful\nreproduction of the task given disturbances. In this work, we identify the\nroots of such a challenge as the failure of the learned continuous policy to\nsatisfy the discrete plan implicit in the demonstration. By utilizing modes\n(rather than subgoals) as the discrete abstraction and motion policies with\nboth mode invariance and goal reachability properties, we prove our learned\ncontinuous policy can simulate any discrete plan specified by a Linear Temporal\nLogic (LTL) formula. Consequently, the imitator is robust to both task- and\nmotion-level disturbances and guaranteed to achieve task success. Project page:\nhttps://sites.google.com/view/ltl-ds",
    "descriptor": "",
    "authors": [
      "Yanwei Wang",
      "Nadia Figueroa",
      "Shen Li",
      "Ankit Shah",
      "Julie Shah"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.04632"
  },
  {
    "id": "arXiv:2206.04635",
    "title": "Optimal Design of Energy-Harvesting Hybrid VLC-RF Networks",
    "abstract": "In this extended abstract, we consider a dual-hop hybrid visible light\ncommunication (VLC)/radio frequency (RF) scenario where energy is harvested\nduring the VLC transmission and used to power the relay. We formulate the\noptimization problem in the sense of maximizing the data rate under the\nassumption of decode-and-forward (DF) relaying. As the design parameters, the\ndirect current (DC) bias and the assigned time duration for energy harvesting\nare taken into account. In particular, the joint optimization is split into two\nsubproblems, which are then cyclically solved. Additional details and numerical\nresults are left to be presented in the full paper.",
    "descriptor": "",
    "authors": [
      "Amir Hossein Fahim Raouf",
      "Chethan Kumar Anjinappa",
      "Ismail Guvenc"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.04635"
  },
  {
    "id": "arXiv:2206.04636",
    "title": "Spatial Entropy Regularization for Vision Transformers",
    "abstract": "Recent work has shown that the attention maps of Vision Transformers (VTs),\nwhen trained with self-supervision, can contain a semantic segmentation\nstructure which does not spontaneously emerge when training is supervised. In\nthis paper, we explicitly encourage the emergence of this spatial clustering as\na form of training regularization, this way including a self-supervised pretext\ntask into the standard supervised learning. In more detail, we propose a VT\nregularization method based on a spatial formulation of the information\nentropy. By minimizing the proposed spatial entropy, we explicitly ask the VT\nto produce spatially ordered attention maps, this way including an object-based\nprior during training. Using extensive experiments, we show that the proposed\nregularization approach is beneficial with different training scenarios,\ndatasets, downstream tasks and VT architectures. The code will be available\nupon acceptance.",
    "descriptor": "",
    "authors": [
      "Elia Peruzzo",
      "Enver Sangineto",
      "Yahui Liu",
      "Marco De Nadai",
      "Wei Bi",
      "Bruno Lepri",
      "Nicu Sebe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04636"
  },
  {
    "id": "arXiv:2206.04640",
    "title": "Regret Bounds for Information-Directed Reinforcement Learning",
    "abstract": "Information-directed sampling (IDS) has revealed its potential as a\ndata-efficient algorithm for reinforcement learning (RL). However, theoretical\nunderstanding of IDS for Markov Decision Processes (MDPs) is still limited. We\ndevelop novel information-theoretic tools to bound the information ratio and\ncumulative information gain about the learning target. Our theoretical results\nshed light on the importance of choosing the learning target such that the\npractitioners can balance the computation and regret bounds. As a consequence,\nwe derive prior-free Bayesian regret bounds for vanilla-IDS which learns the\nwhole environment under tabular finite-horizon MDPs. In addition, we propose a\ncomputationally-efficient regularized-IDS that maximizes an additive form\nrather than the ratio form and show that it enjoys the same regret bound as\nvanilla-IDS. With the aid of rate-distortion theory, we improve the regret\nbound by learning a surrogate, less informative environment. Furthermore, we\nextend our analysis to linear MDPs and prove similar regret bounds for Thompson\nsampling as a by-product.",
    "descriptor": "",
    "authors": [
      "Botao Hao",
      "Tor Lattimore"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.04640"
  },
  {
    "id": "arXiv:2206.04642",
    "title": "Probability flow solution of the Fokker-Planck equation",
    "abstract": "The method of choice for integrating the time-dependent Fokker-Planck\nequation in high-dimension is to generate samples from the solution via\nintegration of the associated stochastic differential equation. Here, we\nintroduce an alternative scheme based on integrating an ordinary differential\nequation that describes the flow of probability. Unlike the stochastic\ndynamics, this equation deterministically pushes samples from the initial\ndensity onto samples from the solution at any later time. The method has the\nadvantage of giving direct access to quantities that are challenging to\nestimate only given samples from the solution, such as the probability current,\nthe density itself, and its entropy. The probability flow equation depends on\nthe gradient of the logarithm of the solution (its \"score\"), and so is a-priori\nunknown. To resolve this dependence, we model the score with a deep neural\nnetwork that is learned on-the-fly by propagating a set of particles according\nto the instantaneous probability current. Our approach is based on recent\nadvances in score-based diffusion for generative modeling, with the important\ndifference that the training procedure is self-contained and does not require\nsamples from the target density to be available beforehand. To demonstrate the\nvalidity of the approach, we consider several examples from the physics of\ninteracting particle systems; we find that the method scales well to\nhigh-dimensional systems, and accurately matches available analytical solutions\nand moments computed via Monte-Carlo.",
    "descriptor": "",
    "authors": [
      "Nicholas M. Boffi",
      "Eric Vanden-Eijnden"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2206.04642"
  },
  {
    "id": "arXiv:2206.04655",
    "title": "Towards Layer-wise Image Vectorization",
    "abstract": "Image rasterization is a mature technique in computer graphics, while image\nvectorization, the reverse path of rasterization, remains a major challenge.\nRecent advanced deep learning-based models achieve vectorization and semantic\ninterpolation of vector graphs and demonstrate a better topology of generating\nnew figures. However, deep models cannot be easily generalized to out-of-domain\ntesting data. The generated SVGs also contain complex and redundant shapes that\nare not quite convenient for further editing. Specifically, the crucial\nlayer-wise topology and fundamental semantics in images are still not well\nunderstood and thus not fully explored. In this work, we propose Layer-wise\nImage Vectorization, namely LIVE, to convert raster images to SVGs and\nsimultaneously maintain its image topology. LIVE can generate compact SVG forms\nwith layer-wise structures that are semantically consistent with human\nperspective. We progressively add new bezier paths and optimize these paths\nwith the layer-wise framework, newly designed loss functions, and\ncomponent-wise path initialization technique. Our experiments demonstrate that\nLIVE presents more plausible vectorized forms than prior works and can be\ngeneralized to new images. With the help of this newly learned topology, LIVE\ninitiates human editable SVGs for both designers and other downstream\napplications. Codes are made available at\nhttps://github.com/Picsart-AI-Research/LIVE-Layerwise-Image-Vectorization.",
    "descriptor": "\nComments: Accepted as Oral Presentation at CVPR 2022\n",
    "authors": [
      "Xu Ma",
      "Yuqian Zhou",
      "Xingqian Xu",
      "Bin Sun",
      "Valerii Filev",
      "Nikita Orlov",
      "Yun Fu",
      "Humphrey Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.04655"
  },
  {
    "id": "arXiv:2206.04656",
    "title": "Simple Cues Lead to a Strong Multi-Object Tracker",
    "abstract": "For a long time, the most common paradigm in Multi-Object Tracking was\ntracking-by-detection (TbD), where objects are first detected and then\nassociated over video frames. For association, most models resource to motion\nand appearance cues. While still relying on these cues, recent approaches based\non, e.g., attention have shown an ever-increasing need for training data and\noverall complex frameworks. We claim that 1) strong cues can be obtained from\nlittle amounts of training data if some key design choices are applied, 2)\ngiven these strong cues, standard Hungarian matching-based association is\nenough to obtain impressive results. Our main insight is to identify key\ncomponents that allow a standard reidentification network to excel at\nappearance-based tracking. We extensively analyze its failure cases and show\nthat a combination of our appearance features with a simple motion model leads\nto strong tracking results. Our model achieves state-of-the-art performance on\nMOT17 and MOT20 datasets outperforming previous state-of-the-art trackers by up\nto 5.4pp in IDF1 and 4.4pp in HOTA. We will release the code and models after\nthe paper's acceptance.",
    "descriptor": "",
    "authors": [
      "Jenny Seidenschwarz",
      "Guillem Braso",
      "Ismail Elezi",
      "Laura Leal-Taixe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.04656"
  },
  {
    "id": "arXiv:2206.04658",
    "title": "BigVGAN: A Universal Neural Vocoder with Large-Scale Training",
    "abstract": "Despite recent progress in generative adversarial network(GAN)-based\nvocoders, where the model generates raw waveform conditioned on mel\nspectrogram, it is still challenging to synthesize high-fidelity audio for\nnumerous speakers across varied recording environments. In this work, we\npresent BigVGAN, a universal vocoder that generalizes well under various unseen\nconditions in zero-shot setting. We introduce periodic nonlinearities and\nanti-aliased representation into the generator, which brings the desired\ninductive bias for waveform synthesis and significantly improves audio quality.\nBased on our improved generator and the state-of-the-art discriminators, we\ntrain our GAN vocoder at the largest scale up to 112M parameters, which is\nunprecedented in the literature. In particular, we identify and address the\ntraining instabilities specific to such scale, while maintaining high-fidelity\noutput without over-regularization. Our BigVGAN achieves the state-of-the-art\nzero-shot performance for various out-of-distribution scenarios, including new\nspeakers, novel languages, singing voices, music and instrumental audio in\nunseen (even noisy) recording environments. We will release our code and model\nat: https://github.com/NVIDIA/BigVGAN",
    "descriptor": "\nComments: Listen to audio samples from BigVGAN at: this https URL\n",
    "authors": [
      "Sang-gil Lee",
      "Wei Ping",
      "Boris Ginsburg",
      "Bryan Catanzaro",
      "Sungroh Yoon"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.04658"
  },
  {
    "id": "arXiv:2206.04659",
    "title": "Jewelry Shop Conversational Chatbot",
    "abstract": "Since the advent of chatbots in the commercial sector, they have been widely\nemployed in the customer service department. Typically, these commercial\nchatbots are retrieval-based, so they are unable to respond to queries absent\nin the provided dataset. On the contrary, generative chatbots try to create the\nmost appropriate response, but are mostly unable to create a smooth flow in the\ncustomer-bot dialog. Since the client has few options left for continuing after\nreceiving a response, the dialog becomes short. Through our work, we try to\nmaximize the intelligence of a simple conversational agent so it can answer\nunseen queries, and generate follow-up questions or remarks. We have built a\nchatbot for a jewelry shop that finds the underlying objective of the\ncustomer's query by finding similarity of the input to patterns in the corpus.\nOur system features an audio input interface for clients, so they may speak to\nit in natural language. After converting the audio to text, we trained the\nmodel to extract the intent of the query, to find an appropriate response and\nto speak to the client in a natural human voice. To gauge the system's\nperformance, we used performance metrics such as Recall, Precision and F1\nscore.",
    "descriptor": "",
    "authors": [
      "Safa Zaid",
      "Aswah Malik",
      "Kisa Fatima"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.04659"
  },
  {
    "id": "arXiv:2206.04662",
    "title": "DiSparse: Disentangled Sparsification for Multitask Model Compression",
    "abstract": "Despite the popularity of Model Compression and Multitask Learning, how to\neffectively compress a multitask model has been less thoroughly analyzed due to\nthe challenging entanglement of tasks in the parameter space. In this paper, we\npropose DiSparse, a simple, effective, and first-of-its-kind multitask pruning\nand sparse training scheme. We consider each task independently by\ndisentangling the importance measurement and take the unanimous decisions among\nall tasks when performing parameter pruning and selection. Our experimental\nresults demonstrate superior performance on various configurations and settings\ncompared to popular sparse training and pruning methods. Besides the\neffectiveness in compression, DiSparse also provides a powerful tool to the\nmultitask learning community. Surprisingly, we even observed better performance\nthan some dedicated multitask learning methods in several cases despite the\nhigh model sparsity enforced by DiSparse. We analyzed the pruning masks\ngenerated with DiSparse and observed strikingly similar sparse network\narchitecture identified by each task even before the training starts. We also\nobserve the existence of a \"watershed\" layer where the task relatedness sharply\ndrops, implying no benefits in continued parameters sharing. Our code and\nmodels will be available at:\nhttps://github.com/SHI-Labs/DiSparse-Multitask-Model-Compression.",
    "descriptor": "\nComments: Accepted at CVPR 2022\n",
    "authors": [
      "Xinglong Sun",
      "Ali Hassani",
      "Zhangyang Wang",
      "Gao Huang",
      "Humphrey Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04662"
  },
  {
    "id": "arXiv:2206.04664",
    "title": "On Data Scaling in Masked Image Modeling",
    "abstract": "An important goal of self-supervised learning is to enable model pre-training\nto benefit from almost unlimited data. However, one method that has recently\nbecome popular, namely masked image modeling (MIM), is suspected to be unable\nto benefit from larger data. In this work, we break this misconception through\nextensive experiments, with data scales ranging from 10\\% of ImageNet-1K to\nfull ImageNet-22K, model sizes ranging from 49 million to 1 billion, and\ntraining lengths ranging from 125K iterations to 500K iterations. Our study\nreveals that: (i) Masked image modeling is also demanding on larger data. We\nobserved that very large models got over-fitted with relatively small data;\n(ii) The length of training matters. Large models trained with masked image\nmodeling can benefit from more data with longer training; (iii) The validation\nloss in pre-training is a good indicator to measure how well the model performs\nfor fine-tuning on multiple tasks. This observation allows us to pre-evaluate\npre-trained models in advance without having to make costly trial-and-error\nassessments of downstream tasks. We hope that our findings will advance the\nunderstanding of masked image modeling in terms of scaling ability.",
    "descriptor": "",
    "authors": [
      "Zhenda Xie",
      "Zheng Zhang",
      "Yue Cao",
      "Yutong Lin",
      "Yixuan Wei",
      "Qi Dai",
      "Han Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.04664"
  },
  {
    "id": "arXiv:2206.04665",
    "title": "AGConv: Adaptive Graph Convolution on 3D Point Clouds",
    "abstract": "Convolution on 3D point clouds is widely researched yet far from perfect in\ngeometric deep learning. The traditional wisdom of convolution characterises\nfeature correspondences indistinguishably among 3D points, arising an intrinsic\nlimitation of poor distinctive feature learning. In this paper, we propose\nAdaptive Graph Convolution (AGConv) for wide applications of point cloud\nanalysis. AGConv generates adaptive kernels for points according to their\ndynamically learned features. Compared with the solution of using\nfixed/isotropic kernels, AGConv improves the flexibility of point cloud\nconvolutions, effectively and precisely capturing the diverse relations between\npoints from different semantic parts. Unlike the popular attentional weight\nschemes, AGConv implements the adaptiveness inside the convolution operation\ninstead of simply assigning different weights to the neighboring points.\nExtensive evaluations clearly show that our method outperforms\nstate-of-the-arts of point cloud classification and segmentation on various\nbenchmark datasets.Meanwhile, AGConv can flexibly serve more point cloud\nanalysis approaches to boost their performance. To validate its flexibility and\neffectiveness, we explore AGConv-based paradigms of completion, denoising,\nupsampling, registration and circle extraction, which are comparable or even\nsuperior to their competitors. Our code is available at\nhttps://github.com/hrzhou2/AdaptConv-master.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2108.08035\n",
    "authors": [
      "Mingqiang Wei",
      "Zeyong Wei",
      "Haoran Zhou",
      "Fei Hu",
      "Huajian Si",
      "Zhilei Chen",
      "Zhe Zhu",
      "Jingbo Qiu",
      "Xuefeng Yan",
      "Yanwen Guo",
      "Jun Wang",
      "Jing Qin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.04665"
  },
  {
    "id": "arXiv:2206.04667",
    "title": "Extreme Masking for Learning Instance and Distributed Visual  Representations",
    "abstract": "The paper presents a scalable approach for learning distributed\nrepresentations over individual tokens and a holistic instance representation\nsimultaneously. We use self-attention blocks to represent distributed tokens,\nfollowed by cross-attention blocks to aggregate the holistic instance. The core\nof the approach is the use of extremely large token masking (75%-90%) as the\ndata augmentation for supervision. Our model, named ExtreMA, follows the plain\nBYOL approach where the instance representation from the unmasked subset is\ntrained to predict that from the intact input. Learning requires the model to\ncapture informative variations in an instance, instead of encouraging\ninvariances. The paper makes three contributions: 1) Random masking is a strong\nand computationally efficient data augmentation for learning generalizable\nattention representations. 2) With multiple sampling per instance, extreme\nmasking greatly speeds up learning and hungers for more data. 3) Distributed\nrepresentations can be learned from the instance supervision alone, unlike\nper-token supervisions in masked modeling.",
    "descriptor": "\nComments: Technical Report\n",
    "authors": [
      "Zhirong Wu",
      "Zihang Lai",
      "Xiao Sun",
      "Stephen Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.04667"
  },
  {
    "id": "arXiv:2206.04668",
    "title": "GateHUB: Gated History Unit with Background Suppression for Online  Action Detection",
    "abstract": "Online action detection is the task of predicting the action as soon as it\nhappens in a streaming video. A major challenge is that the model does not have\naccess to the future and has to solely rely on the history, i.e., the frames\nobserved so far, to make predictions. It is therefore important to accentuate\nparts of the history that are more informative to the prediction of the current\nframe. We present GateHUB, Gated History Unit with Background Suppression, that\ncomprises a novel position-guided gated cross-attention mechanism to enhance or\nsuppress parts of the history as per how informative they are for current frame\nprediction. GateHUB further proposes Future-augmented History (FaH) to make\nhistory features more informative by using subsequently observed frames when\navailable. In a single unified framework, GateHUB integrates the transformer's\nability of long-range temporal modeling and the recurrent model's capacity to\nselectively encode relevant information. GateHUB also introduces a background\nsuppression objective to further mitigate false positive background frames that\nclosely resemble the action frames. Extensive validation on three benchmark\ndatasets, THUMOS, TVSeries, and HDD, demonstrates that GateHUB significantly\noutperforms all existing methods and is also more efficient than the existing\nbest work. Furthermore, a flow-free version of GateHUB is able to achieve\nhigher or close accuracy at 2.8x higher frame rate compared to all existing\nmethods that require both RGB and optical flow information for prediction.",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Junwen Chen",
      "Gaurav Mittal",
      "Ye Yu",
      "Yu Kong",
      "Mei Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.04668"
  },
  {
    "id": "arXiv:2206.04669",
    "title": "Beyond RGB: Scene-Property Synthesis with Neural Radiance Fields",
    "abstract": "Comprehensive 3D scene understanding, both geometrically and semantically, is\nimportant for real-world applications such as robot perception. Most of the\nexisting work has focused on developing data-driven discriminative models for\nscene understanding. This paper provides a new approach to scene understanding,\nfrom a synthesis model perspective, by leveraging the recent progress on\nimplicit 3D representation and neural rendering. Building upon the great\nsuccess of Neural Radiance Fields (NeRFs), we introduce Scene-Property\nSynthesis with NeRF (SS-NeRF) that is able to not only render photo-realistic\nRGB images from novel viewpoints, but also render various accurate scene\nproperties (e.g., appearance, geometry, and semantics). By doing so, we\nfacilitate addressing a variety of scene understanding tasks under a unified\nframework, including semantic segmentation, surface normal estimation,\nreshading, keypoint detection, and edge detection. Our SS-NeRF framework can be\na powerful tool for bridging generative learning and discriminative learning,\nand thus be beneficial to the investigation of a wide range of interesting\nproblems, such as studying task relationships within a synthesis paradigm,\ntransferring knowledge to novel tasks, facilitating downstream discriminative\ntasks as ways of data augmentation, and serving as auto-labeller for data\ncreation.",
    "descriptor": "",
    "authors": [
      "Mingtong Zhang",
      "Shuhong Zheng",
      "Zhipeng Bao",
      "Martial Hebert",
      "Yu-Xiong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.04669"
  },
  {
    "id": "arXiv:2206.04670",
    "title": "PointNeXt: Revisiting PointNet++ with Improved Training and Scaling  Strategies",
    "abstract": "PointNet++ is one of the most influential neural architectures for point\ncloud understanding. Although the accuracy of PointNet++ has been largely\nsurpassed by recent networks such as PointMLP and Point Transformer, we find\nthat a large portion of the performance gain is due to improved training\nstrategies, i.e. data augmentation and optimization techniques, and increased\nmodel sizes rather than architectural innovations. Thus, the full potential of\nPointNet++ has yet to be explored. In this work, we revisit the classical\nPointNet++ through a systematic study of model training and scaling strategies,\nand offer two major contributions. First, we propose a set of improved training\nstrategies that significantly improve PointNet++ performance. For example, we\nshow that, without any change in architecture, the overall accuracy (OA) of\nPointNet++ on ScanObjectNN object classification can be raised from 77.9\\% to\n86.1\\%, even outperforming state-of-the-art PointMLP. Second, we introduce an\ninverted residual bottleneck design and separable MLPs into PointNet++ to\nenable efficient and effective model scaling and propose PointNeXt, the next\nversion of PointNets. PointNeXt can be flexibly scaled up and outperforms\nstate-of-the-art methods on both 3D classification and segmentation tasks. For\nclassification, PointNeXt reaches an overall accuracy of $87.7\\%$ on\nScanObjectNN, surpassing PointMLP by $2.3\\%$, while being $10 \\times$ faster in\ninference. For semantic segmentation, PointNeXt establishes a new\nstate-of-the-art performance with $74.9\\%$ mean IoU on S3DIS (6-fold\ncross-validation), being superior to the recent Point Transformer. The code and\nmodels are available at https://github.com/guochengqian/pointnext.",
    "descriptor": "\nComments: Code and models are available at this https URL\n",
    "authors": [
      "Guocheng Qian",
      "Yuchen Li",
      "Houwen Peng",
      "Jinjie Mai",
      "Hasan Abed Al Kader Hammoud",
      "Mohamed Elhoseiny",
      "Bernard Ghanem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.04670"
  },
  {
    "id": "arXiv:2206.04671",
    "title": "Open Challenges in Deep Stereo: the Booster Dataset",
    "abstract": "We present a novel high-resolution and challenging stereo dataset framing\nindoor scenes annotated with dense and accurate ground-truth disparities.\nPeculiar to our dataset is the presence of several specular and transparent\nsurfaces, i.e. the main causes of failures for state-of-the-art stereo\nnetworks. Our acquisition pipeline leverages a novel deep space-time stereo\nframework which allows for easy and accurate labeling with sub-pixel precision.\nWe release a total of 419 samples collected in 64 different scenes and\nannotated with dense ground-truth disparities. Each sample include a\nhigh-resolution pair (12 Mpx) as well as an unbalanced pair (Left: 12 Mpx,\nRight: 1.1 Mpx). Additionally, we provide manually annotated material\nsegmentation masks and 15K unlabeled samples. We evaluate state-of-the-art deep\nnetworks based on our dataset, highlighting their limitations in addressing the\nopen challenges in stereo and drawing hints for future research.",
    "descriptor": "\nComments: CVPR 2022, New Orleans. Project page: this https URL\n",
    "authors": [
      "Pierluigi Zama Ramirez",
      "Fabio Tosi",
      "Matteo Poggi",
      "Samuele Salti",
      "Stefano Mattoccia",
      "Luigi Di Stefano"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.04671"
  },
  {
    "id": "arXiv:2206.04672",
    "title": "Overcoming the Spectral Bias of Neural Value Approximation",
    "abstract": "Value approximation using deep neural networks is at the heart of off-policy\ndeep reinforcement learning, and is often the primary module that provides\nlearning signals to the rest of the algorithm. While multi-layer perceptron\nnetworks are universal function approximators, recent works in neural kernel\nregression suggest the presence of a spectral bias, where fitting\nhigh-frequency components of the value function requires exponentially more\ngradient update steps than the low-frequency ones. In this work, we re-examine\noff-policy reinforcement learning through the lens of kernel regression and\npropose to overcome such bias via a composite neural tangent kernel. With just\na single line-change, our approach, the Fourier feature networks (FFN) produce\nstate-of-the-art performance on challenging continuous control domains with\nonly a fraction of the compute. Faster convergence and better off-policy\nstability also make it possible to remove the target network without suffering\ncatastrophic divergences, which further reduces TD}(0)'s estimation bias on a\nfew tasks.",
    "descriptor": "\nComments: Code and analysis available at this https URL . First two authors contributed equally\n",
    "authors": [
      "Ge Yang",
      "Anurag Ajay",
      "Pulkit Agrawal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.04672"
  },
  {
    "id": "arXiv:2206.04673",
    "title": "Neural Prompt Search",
    "abstract": "The size of vision models has grown exponentially over the last few years,\nespecially after the emergence of Vision Transformer. This has motivated the\ndevelopment of parameter-efficient tuning methods, such as learning adapter\nlayers or visual prompt tokens, which allow a tiny portion of model parameters\nto be trained whereas the vast majority obtained from pre-training are frozen.\nHowever, designing a proper tuning method is non-trivial: one might need to try\nout a lengthy list of design choices, not to mention that each downstream\ndataset often requires custom designs. In this paper, we view the existing\nparameter-efficient tuning methods as \"prompt modules\" and propose Neural\nprOmpt seArcH (NOAH), a novel approach that learns, for large vision models,\nthe optimal design of prompt modules through a neural architecture search\nalgorithm, specifically for each downstream dataset. By conducting extensive\nexperiments on over 20 vision datasets, we demonstrate that NOAH (i) is\nsuperior to individual prompt modules, (ii) has a good few-shot learning\nability, and (iii) is domain-generalizable. The code and models are available\nat https://github.com/Davidzhangyuanhan/NOAH.",
    "descriptor": "\nComments: Code: this https URL\n",
    "authors": [
      "Yuanhan Zhang",
      "Kaiyang Zhou",
      "Ziwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04673"
  },
  {
    "id": "arXiv:2206.04674",
    "title": "Uni-Perceiver-MoE: Learning Sparse Generalist Models with Conditional  MoEs",
    "abstract": "To build an artificial neural network like the biological intelligence\nsystem, recent works have unified numerous tasks into a generalist model, which\ncan process various tasks with shared parameters and do not have any\ntask-specific modules. While generalist models achieve promising results on\nvarious benchmarks, they have performance degradation on some tasks compared\nwith task-specialized models. In this work, we find that interference among\ndifferent tasks and modalities is the main factor to this phenomenon. To\nmitigate such interference, we introduce the Conditional Mixture-of-Experts\n(Conditional MoEs) to generalist models. Routing strategies under different\nlevels of conditions are proposed to take both the training/inference cost and\ngeneralization ability into account. By incorporating the proposed Conditional\nMoEs, the recently proposed generalist model Uni-Perceiver can effectively\nmitigate the interference across tasks and modalities, and achieves\nstate-of-the-art results on a series of downstream tasks via prompt tuning on\n1% of downstream data. Moreover, the introduction of Conditional MoEs still\nholds the generalization ability of generalist models to conduct zero-shot\ninference on new tasks, e.g., video-text retrieval and video caption. Code and\npre-trained generalist models shall be released.",
    "descriptor": "",
    "authors": [
      "Jinguo Zhu",
      "Xizhou Zhu",
      "Wenhai Wang",
      "Xiaohua Wang",
      "Hongsheng Li",
      "Xiaogang Wang",
      "Jifeng Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.04674"
  },
  {
    "id": "arXiv:2206.04047",
    "title": "N-ACT: An Interpretable Deep Learning Model for Automatic Cell Type and  Salient Gene Identification",
    "abstract": "Single-cell RNA sequencing (scRNAseq) is rapidly advancing our understanding\nof cellular composition within complex tissues and organisms. A major\nlimitation in most scRNAseq analysis pipelines is the reliance on manual\nannotations to determine cell identities, which are time consuming, subjective,\nand require expertise. Given the surge in cell sequencing, supervised\nmethods-especially deep learning models-have been developed for automatic cell\ntype identification (ACTI), which achieve high accuracy and scalability.\nHowever, all existing deep learning frameworks for ACTI lack interpretability\nand are used as \"black-box\" models. We present N-ACT (Neural-Attention for Cell\nType identification): the first-of-its-kind interpretable deep neural network\nfor ACTI utilizing neural-attention to detect salient genes for use in\ncell-type identification. We compare N-ACT to conventional annotation methods\non two previously manually annotated data sets, demonstrating that N-ACT\naccurately identifies marker genes and cell types in an unsupervised manner,\nwhile performing comparably on multiple data sets to current state-of-the-art\nmodel in traditional supervised ACTI.",
    "descriptor": "",
    "authors": [
      "A. Ali Heydari",
      "Oscar A. Davalos",
      "Katrina K. Hoyer",
      "Suzanne S. Sindi"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04047"
  },
  {
    "id": "arXiv:2206.04056",
    "title": "An Improved Deep Convolutional Neural Network by Using Hybrid  Optimization Algorithms to Detect and Classify Brain Tumor Using Augmented  MRI Images",
    "abstract": "Automated brain tumor detection is becoming a highly considerable medical\ndiagnosis research. In recent medical diagnoses, detection and classification\nare highly considered to employ machine learning and deep learning techniques.\nNevertheless, the accuracy and performance of current models need to be\nimproved for suitable treatments. In this paper, an improvement in deep\nconvolutional learning is ensured by adopting enhanced optimization algorithms,\nThus, Deep Convolutional Neural Network (DCNN) based on improved Harris Hawks\nOptimization (HHO), called G-HHO has been considered. This hybridization\nfeatures Grey Wolf Optimization (GWO) and HHO to give better results, limiting\nthe convergence rate and enhancing performance. Moreover, Otsu thresholding is\nadopted to segment the tumor portion that emphasizes brain tumor detection.\nExperimental studies are conducted to validate the performance of the suggested\nmethod on a total number of 2073 augmented MRI images. The technique's\nperformance was ensured by comparing it with the nine existing algorithms on\nhuge augmented MRI images in terms of accuracy, precision, recall, f-measure,\nexecution time, and memory usage. The performance comparison shows that the\nDCNN-G-HHO is much more successful than existing methods, especially on a\nscoring accuracy of 97%. Additionally, the statistical performance analysis\nindicates that the suggested approach is faster and utilizes less memory at\nidentifying and categorizing brain tumor cancers on the MR images. The\nimplementation of this validation is conducted on the Python platform. The\nrelevant codes for the proposed approach are available at:\nhttps://github.com/bryarahassan/DCNN-G-HHO.",
    "descriptor": "\nComments: Multimed Tools Appl (2022)\n",
    "authors": [
      "Shko M. Qader",
      "Bryar A. Hassan",
      "Tarik A. Rashid"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.04056"
  },
  {
    "id": "arXiv:2206.04078",
    "title": "Quantum Advantage in Cryptography",
    "abstract": "Ever since its inception, cryptography has been caught in a vicious circle:\nCryptographers keep inventing methods to hide information, and cryptanalysts\nbreak them, prompting cryptographers to invent even more sophisticated\nencryption schemes, and so on. But could it be that quantum information\ntechnology breaks this circle? At first sight, it looks as if it just lifts the\ncompetition between cryptographers and cryptanalysts to the next level. Indeed,\nquantum computers will render most of today's public key cryptosystems\ninsecure. Nonetheless, there are good reasons to believe that cryptographers\nwill ultimately prevail over cryptanalysts. Quantum cryptography allows us to\nbuild communication schemes whose secrecy relies only on the laws of physics as\nwell as some minimum assumptions about the cryptographic hardware - leaving\nbasically no room for an attack. While we are not yet there, this article\nprovides an overview of the principles and state of the art of quantum\ncryptography.",
    "descriptor": "\nComments: 29 pages, 9 figures, 1 table\n",
    "authors": [
      "Renato Renner",
      "Ramona Wolf"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.04078"
  },
  {
    "id": "arXiv:2206.04079",
    "title": "Computational advantage of quantum random sampling",
    "abstract": "Quantum random sampling is the leading proposal for demonstrating a\ncomputational advantage of quantum computers over classical computers.\nRecently, first large-scale implementations of quantum random sampling have\narguably surpassed the boundary of what can be simulated on existing classical\nhardware. In this article, we comprehensively review the theoretical\nunderpinning of quantum random sampling in terms of computational complexity\nand verifiability, as well as the practical aspects of its experimental\nimplementation using superconducting and photonic devices and its classical\nsimulation. We discuss in detail open questions in the field and provide\nperspectives for the road ahead, including potential applications of quantum\nrandom sampling.",
    "descriptor": "\nComments: 81 pages, 13 figures, 2 tables. Sections II-V build on previously unpublished chapters of arXiv:2012.07905. We invite comments and suggestions\n",
    "authors": [
      "Dominik Hangleiter",
      "Jens Eisert"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Quantum Gases (cond-mat.quant-gas)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2206.04079"
  },
  {
    "id": "arXiv:2206.04089",
    "title": "On Minimally Non-Firm Binary Matrices",
    "abstract": "For a binary matrix X, the Boolean rank br(X) is the smallest integer k for\nwhich X equals the Boolean sum of k rank-1 binary matrices, and the isolation\nnumber i(X) is the maximum number of 1s no two of which are in a same row,\ncolumn and a 2x2 submatrix of all 1s. In this paper, we continue Lubiw's study\nof firm matrices. X is said to be firm if i(X)=br(X) and this equality holds\nfor all its submatrices. We show that the stronger concept of superfirmness of\nX is equivalent to having no odd holes in the rectangle cover graph of X, the\ngraph in which br(X) and i(X) translate to the clique cover and the\nindependence number, respectively. A binary matrix is minimally non-firm if it\nis not firm but all of its proper submatrices are. We introduce two matrix\noperations that lead to generalised binary matrices and use these operations to\nderive four infinite classes of minimally non-firm matrices. We hope that our\nwork may pave the way towards a complete characterisation of firm matrices via\nforbidden submatrices.",
    "descriptor": "\nComments: ISCO 2022\n",
    "authors": [
      "Reka Agnes Kovacs"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2206.04089"
  },
  {
    "id": "arXiv:2206.04091",
    "title": "Uplifting Bandits",
    "abstract": "We introduce a multi-armed bandit model where the reward is a sum of multiple\nrandom variables, and each action only alters the distributions of some of\nthem. After each action, the agent observes the realizations of all the\nvariables. This model is motivated by marketing campaigns and recommender\nsystems, where the variables represent outcomes on individual customers, such\nas clicks. We propose UCB-style algorithms that estimate the uplifts of the\nactions over a baseline. We study multiple variants of the problem, including\nwhen the baseline and affected variables are unknown, and prove sublinear\nregret bounds for all of these. We also provide lower bounds that justify the\nnecessity of our modeling assumptions. Experiments on synthetic and real-world\ndatasets show the benefit of methods that estimate the uplifts over policies\nthat do not use this structure.",
    "descriptor": "",
    "authors": [
      "Yu-Guan Hsieh",
      "Shiva Prasad Kasiviswanathan",
      "Branislav Kveton"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04091"
  },
  {
    "id": "arXiv:2206.04110",
    "title": "Likelihood-free Model Choice for Simulator-based Models with the  Jensen--Shannon Divergence",
    "abstract": "Choice of appropriate structure and parametric dimension of a model in the\nlight of data has a rich history in statistical research, where the first\nseminal approaches were developed in 1970s, such as the Akaike's and Schwarz's\nmodel scoring criteria that were inspired by information theory and embodied\nthe rationale called Occam's razor. After those pioneering works, model choice\nwas quickly established as its own field of research, gaining considerable\nattention in both computer science and statistics. However, to date, there have\nbeen limited attempts to derive scoring criteria for simulator-based models\nlacking a likelihood expression. Bayes factors have been considered for such\nmodels, but arguments have been put both for and against use of them and around\nissues related to their consistency. Here we use the asymptotic properties of\nJensen--Shannon divergence (JSD) to derive a consistent model scoring criterion\nfor the likelihood-free setting called JSD-Razor. Relationships of JSD-Razor\nwith established scoring criteria for the likelihood-based approach are\nanalyzed and we demonstrate the favorable properties of our criterion using\nboth synthetic and real modeling examples.",
    "descriptor": "\nComments: 40 pages, 4 figures, to be submittes\n",
    "authors": [
      "Jukka Corander",
      "Ulpu Remes",
      "Timo Koski"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04110"
  },
  {
    "id": "arXiv:2206.04113",
    "title": "Push--Pull with Device Sampling",
    "abstract": "We consider decentralized optimization problems in which a number of agents\ncollaborate to minimize the average of their local functions by exchanging over\nan underlying communication graph. Specifically, we place ourselves in an\nasynchronous model where only a random portion of nodes perform computation at\neach iteration, while the information exchange can be conducted between all the\nnodes and in an asymmetric fashion. For this setting, we propose an algorithm\nthat combines gradient tracking and variance reduction over the entire network.\nThis enables each node to track the average of the gradients of the objective\nfunctions. Our theoretical analysis shows that the algorithm converges\nlinearly, when the local objective functions are strongly convex, under mild\nconnectivity conditions on the expected mixing matrices. In particular, our\nresult does not require the mixing matrices to be doubly stochastic. In the\nexperiments, we investigate a broadcast mechanism that transmits information\nfrom computing nodes to their neighbors, and confirm the linear convergence of\nour method on both synthetic and real-world datasets.",
    "descriptor": "",
    "authors": [
      "Yu-Guan Hsieh",
      "Yassine Laguel",
      "Franck Iutzeler",
      "J\u00e9r\u00f4me Malick"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2206.04113"
  },
  {
    "id": "arXiv:2206.04118",
    "title": "Spatial Games of Fake News",
    "abstract": "To curb the spread of fake news on social media platforms, recent studies\nhave considered an online crowdsourcing fact-checking approach as one possible\nintervention method to reduce misinformation. However, it remains unclear under\nwhat conditions crowdsourcing fact-checking efforts deter the spread of\nmisinformation. To address this issue, we model such distributed fact-checking\nas `peer policing' that will reduce the perceived payoff to share or\ndisseminate false information (fake news) and also reward the spread of\ntrustworthy information (real news). By simulating our model on synthetic\nsquare lattices and small-world networks, we show that the presence of social\nnetwork structure enables fake news spreaders to be self-organized into echo\nchambers, thereby providing a boost to the efficacy of fake news and thus its\nresistance to fact-checking efforts. Additionally, to study our model in a more\nrealistic setting, we utilize a Twitter network dataset and study the\neffectiveness of deliberately choosing specific individuals to be\nfact-checkers. We find that targeted fact-checking efforts can be highly\neffective, seeing the same level of success with as little as a fifth of the\nnumber of fact-checkers, but it depends on the structure of the network in\nquestion. In the limit of weak selection, we obtain closed-form analytical\nconditions for critical threshold of crowdsourced fact-checking in terms of the\npayoff values in our fact-checker/fake news game. Our work has practical\nimplications for developing model-based mitigation strategies for controlling\nthe spread of misinformation that interferes with the political discourse.",
    "descriptor": "\nComments: 18 pages, 5 figures\n",
    "authors": [
      "Matthew I Jones",
      "Scott D. Pauls",
      "Feng Fu"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.04118"
  },
  {
    "id": "arXiv:2206.04119",
    "title": "Diffusion probabilistic modeling of protein backbones in 3D for the  motif-scaffolding problem",
    "abstract": "Construction of a scaffold structure that supports a desired motif,\nconferring protein function, shows promise for the design of vaccines and\nenzymes. But a general solution to this motif-scaffolding problem remains open.\nCurrent machine-learning techniques for scaffold design are either limited to\nunrealistically small scaffolds (up to length 20) or struggle to produce\nmultiple diverse scaffolds. We propose to learn a distribution over diverse and\nlonger protein backbone structures via an E(3)-equivariant graph neural\nnetwork. We develop SMCDiff to efficiently sample scaffolds from this\ndistribution conditioned on a given motif; our algorithm is the first to\ntheoretically guarantee conditional samples from a diffusion model in the\nlarge-compute limit. We evaluate our designed backbones by how well they align\nwith AlphaFold2-predicted structures. We show that our method can (1) sample\nscaffolds up to 80 residues and (2) achieve structurally diverse scaffolds for\na fixed motif.",
    "descriptor": "",
    "authors": [
      "Brian L. Trippe",
      "Jason Yim",
      "Doug Tischer",
      "Tamara Broderick",
      "David Baker",
      "Regina Barzilay",
      "Tommi Jaakkola"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.04119"
  },
  {
    "id": "arXiv:2206.04145",
    "title": "Deep Estimation of Speckle Statistics Parametric Images",
    "abstract": "Quantitative Ultrasound (QUS) provides important information about the tissue\nproperties. QUS parametric image can be formed by dividing the envelope data\ninto small overlapping patches and computing different speckle statistics such\nas parameters of the Nakagami and Homodyned K-distributions (HK-distribution).\nThe calculated QUS parametric images can be erroneous since only a few\nindependent samples are available inside the patches. Another challenge is that\nthe envelope samples inside the patch are assumed to come from the same\ndistribution, an assumption that is often violated given that the tissue is\nusually not homogenous. In this paper, we propose a method based on\nConvolutional Neural Networks (CNN) to estimate QUS parametric images without\npatching. We construct a large dataset sampled from the HK-distribution, having\nregions with random shapes and QUS parameter values. We then use a well-known\nnetwork to estimate QUS parameters in a multi-task learning fashion. Our\nresults confirm that the proposed method is able to reduce errors and improve\nborder definition in QUS parametric images.",
    "descriptor": "\nComments: Accepted in EMBC 2022\n",
    "authors": [
      "Ali K. Z. Tehrani",
      "Ivan M. Rosado-Mendez",
      "Hassan Rivaz"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.04145"
  },
  {
    "id": "arXiv:2206.04189",
    "title": "CCP: Correlated Clustering and Projection for Dimensionality Reduction",
    "abstract": "Most dimensionality reduction methods employ frequency domain representations\nobtained from matrix diagonalization and may not be efficient for large\ndatasets with relatively high intrinsic dimensions. To address this challenge,\nCorrelated Clustering and Projection (CCP) offers a novel data domain strategy\nthat does not need to solve any matrix. CCP partitions high-dimensional\nfeatures into correlated clusters and then projects correlated features in each\ncluster into a one-dimensional representation based on sample correlations.\nResidue-Similarity (R-S) scores and indexes, the shape of data in Riemannian\nmanifolds, and algebraic topology-based persistent Laplacian are introduced for\nvisualization and analysis. Proposed methods are validated with benchmark\ndatasets associated with various machine learning algorithms.",
    "descriptor": "",
    "authors": [
      "Yuta Hozumi",
      "Rui Wang",
      "Guo-Wei Wei"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computational Geometry (cs.CG)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04189"
  },
  {
    "id": "arXiv:2206.04198",
    "title": "Exploring Predictive States via Cantor Embeddings and Wasserstein  Distance",
    "abstract": "Predictive states for stochastic processes are a nonparametric and\ninterpretable construct with relevance across a multitude of modeling\nparadigms. Recent progress on the self-supervised reconstruction of predictive\nstates from time-series data focused on the use of reproducing kernel Hilbert\nspaces. Here, we examine how Wasserstein distances may be used to detect\npredictive equivalences in symbolic data. We compute Wasserstein distances\nbetween distributions over sequences (\"predictions\"), using a\nfinite-dimensional embedding of sequences based on the Cantor for the\nunderlying geometry. We show that exploratory data analysis using the resulting\ngeometry via hierarchical clustering and dimension reduction provides insight\ninto the temporal structure of processes ranging from the relatively simple\n(e.g., finite-state hidden Markov models) to the very complex (e.g.,\ninfinite-state indexed grammars).",
    "descriptor": "\nComments: 9 pages, 4 figures; this http URL\n",
    "authors": [
      "Samuel P. Loomis",
      "James P. Crutchfield"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.04198"
  },
  {
    "id": "arXiv:2206.04225",
    "title": "GCVAE: Generalized-Controllable Variational AutoEncoder",
    "abstract": "Variational autoencoders (VAEs) have recently been used for unsupervised\ndisentanglement learning of complex density distributions. Numerous variants\nexist to encourage disentanglement in latent space while improving\nreconstruction. However, none have simultaneously managed the trade-off between\nattaining extremely low reconstruction error and a high disentanglement score.\nWe present a generalized framework to handle this challenge under constrained\noptimization and demonstrate that it outperforms state-of-the-art existing\nmodels as regards disentanglement while balancing reconstruction. We introduce\nthree controllable Lagrangian hyperparameters to control reconstruction loss,\nKL divergence loss and correlation measure. We prove that maximizing\ninformation in the reconstruction network is equivalent to information\nmaximization during amortized inference under reasonable assumptions and\nconstraint relaxation.",
    "descriptor": "\nComments: 17 pages, 7 figures, 2 tables\n",
    "authors": [
      "Kenneth Ezukwoke",
      "Anis Hoayek",
      "Mireille Batton-Hubert",
      "Xavier Boucher"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04225"
  },
  {
    "id": "arXiv:2206.04238",
    "title": "Cardiac Adipose Tissue Segmentation via Image-Level Annotations",
    "abstract": "Automatically identifying the structural substrates underlying cardiac\nabnormalities can potentially provide real-time guidance for interventional\nprocedures. With the knowledge of cardiac tissue substrates, the treatment of\ncomplex arrhythmias such as atrial fibrillation and ventricular tachycardia can\nbe further optimized by detecting arrhythmia substrates to target for treatment\n(i.e., adipose) and identifying critical structures to avoid. Optical coherence\ntomography (OCT) is a real-time imaging modality that aids in addressing this\nneed. Existing approaches for cardiac image analysis mainly rely on fully\nsupervised learning techniques, which suffer from the drawback of workload on\nlabor-intensive annotation process of pixel-wise labeling. To lessen the need\nfor pixel-wise labeling, we develop a two-stage deep learning framework for\ncardiac adipose tissue segmentation using image-level annotations on OCT images\nof human cardiac substrates. In particular, we integrate class activation\nmapping with superpixel segmentation to solve the sparse tissue seed challenge\nraised in cardiac tissue segmentation. Our study bridges the gap between the\ndemand on automatic tissue analysis and the lack of high-quality pixel-wise\nannotations. To the best of our knowledge, this is the first study that\nattempts to address cardiac tissue segmentation on OCT images via weakly\nsupervised learning techniques. Within an in-vitro human cardiac OCT dataset,\nwe demonstrate that our weakly supervised approach on image-level annotations\nachieves comparable performance as fully supervised methods trained on\npixel-wise annotations.",
    "descriptor": "",
    "authors": [
      "Ziyi Huang",
      "Yu Gan",
      "Theresa Lye",
      "Yanchen Liu",
      "Haofeng Zhang",
      "Andrew Laine",
      "Elsa Angelini",
      "Christine Hendon"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.04238"
  },
  {
    "id": "arXiv:2206.04262",
    "title": "The Classical Capacity of Quantum Jackson Networks with Waiting  Time-Dependent Erasures",
    "abstract": "We study the fundamental limits of classical communication using quantum\nstates that decohere as they traverse through a network of queues. We consider\na network of Markovian queues, known as a Jackson network, with a single source\nor multiple sources and a single destination. Qubits are communicated through\nthis network with inevitable buffering at intermediate nodes. We model each\nnode as a `queue-channel,' wherein as the qubits wait in buffer, they continue\nto interact with the environment and suffer a waiting time-dependent noise.\nFocusing on erasures, we first obtain explicit classical capacity expressions\nfor simple topologies such as tandem queue-channel and parallel queue-channel.\nUsing these as building blocks, we characterize the classical capacity of a\ngeneral quantum Jackson network with waiting time-dependent erasures.\nThroughout, we study two types of quantum networks, namely, (i)\nRepeater-assisted and (ii) Repeater-less. We also obtain optimal pumping rates\nand routing probabilities to maximize capacity in simple topologies. More\nbroadly, our work quantifies the impact of delay-induced decoherence on the\nfundamental limits of classical communication over quantum networks.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Jaswanthi Mandalapu",
      "Krishna Jagannathan"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.04262"
  },
  {
    "id": "arXiv:2206.04272",
    "title": "STEM image analysis based on deep learning: identification of vacancy  defects and polymorphs of ${MoS_2}$",
    "abstract": "Scanning transmission electron microscopy (STEM) is an indispensable tool for\natomic-resolution structural analysis for a wide range of materials. The\nconventional analysis of STEM images is an extensive hands-on process, which\nlimits efficient handling of high-throughput data. Here we apply a fully\nconvolutional network (FCN) for identification of important structural features\nof two-dimensional crystals. ResUNet, a type of FCN, is utilized in identifying\nsulfur vacancies and polymorph types of ${MoS_2}$ from atomic resolution STEM\nimages. Efficient models are achieved based on training with simulated images\nin the presence of different levels of noise, aberrations, and carbon\ncontamination. The accuracy of the FCN models toward extensive experimental\nSTEM images is comparable to that of careful hands-on analysis. Our work\nprovides a guideline on best practices to train a deep learning model for STEM\nimage analysis and demonstrates FCN's application for efficient processing of a\nlarge volume of STEM data.",
    "descriptor": "\nComments: 24 pages, 5 figures\n",
    "authors": [
      "Kihyun Lee",
      "Jinsub Park",
      "Soyeon Choi",
      "Yangjin Lee",
      "Sol Lee",
      "Joowon Jung",
      "Jong-Young Lee",
      "Farman Ullah",
      "Zeeshan Tahir",
      "Yong Soo Kim",
      "Gwan-Hyoung Lee",
      "Kwanpyo Kim"
    ],
    "subjectives": [
      "Mesoscale and Nanoscale Physics (cond-mat.mes-hall)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.04272"
  },
  {
    "id": "arXiv:2206.04276",
    "title": "Robust Matrix Completion with Heavy-tailed Noise",
    "abstract": "This paper studies low-rank matrix completion in the presence of heavy-tailed\nand possibly asymmetric noise, where we aim to estimate an underlying low-rank\nmatrix given a set of highly incomplete noisy entries. Though the matrix\ncompletion problem has attracted much attention in the past decade, there is\nstill lack of theoretical understanding when the observations are contaminated\nby heavy-tailed noises. Prior theory falls short of explaining the empirical\nresults and is unable to capture the optimal dependence of the estimation error\non the noise level. In this paper, we adopt an adaptive Huber loss to\naccommodate heavy-tailed noise, which is robust against large and possibly\nasymmetric errors when the parameter in the loss function is carefully designed\nto balance the Huberization biases and robustness to outliers. Then, we propose\nan efficient nonconvex algorithm via a balanced low-rank Burer-Monteiro matrix\nfactorization and gradient decent with robust spectral initialization. We prove\nthat under merely bounded second moment condition on the error distributions,\nrather than the sub-Gaussian assumption, the Euclidean error of the iterates\ngenerated by the proposed algorithm decrease geometrically fast until achieving\na minimax-optimal statistical estimation error, which has the same order as\nthat in the sub-Gaussian case. The key technique behind this significant\nadvancement is a powerful leave-one-out analysis framework. The theoretical\nresults are corroborated by our simulation studies.",
    "descriptor": "",
    "authors": [
      "Bingyan Wang",
      "Jianqing Fan"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.04276"
  },
  {
    "id": "arXiv:2206.04277",
    "title": "On Transfer Learning in Functional Linear Regression",
    "abstract": "This work studies the problem of transfer learning under the functional\nlinear model framework, which aims to improve the fit of the target model by\nleveraging the knowledge from related source models. We measure the relatedness\nbetween target and source models using Reproducing Kernel Hilbert Spaces,\nallowing the type of knowledge being transferred to be interpreted by the\nstructure of the spaces. Two algorithms are proposed: one transfers knowledge\nwhen the index of transferable sources is known, while the other one utilizes\naggregation to achieve knowledge transfer without prior information about the\nsources. Furthermore, we establish the optimal convergence rates for excess\nrisk, making the statistical gain via transfer learning mathematically\nprovable. The effectiveness of the proposed algorithms is demonstrated on\nsynthetic data as well as real financial data.",
    "descriptor": "\nComments: 31 pages\n",
    "authors": [
      "Haotian Lin",
      "Matthew Reimherr"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04277"
  },
  {
    "id": "arXiv:2206.04289",
    "title": "A No-Reference Deep Learning Quality Assessment Method for  Super-resolution Images Based on Frequency Maps",
    "abstract": "To support the application scenarios where high-resolution (HR) images are\nurgently needed, various single image super-resolution (SISR) algorithms are\ndeveloped. However, SISR is an ill-posed inverse problem, which may bring\nartifacts like texture shift, blur, etc. to the reconstructed images, thus it\nis necessary to evaluate the quality of super-resolution images (SRIs). Note\nthat most existing image quality assessment (IQA) methods were developed for\nsynthetically distorted images, which may not work for SRIs since their\ndistortions are more diverse and complicated. Therefore, in this paper, we\npropose a no-reference deep-learning image quality assessment method based on\nfrequency maps because the artifacts caused by SISR algorithms are quite\nsensitive to frequency information. Specifically, we first obtain the\nhigh-frequency map (HM) and low-frequency map (LM) of SRI by using Sobel\noperator and piecewise smooth image approximation. Then, a two-stream network\nis employed to extract the quality-aware features of both frequency maps.\nFinally, the features are regressed into a single quality value using fully\nconnected layers. The experimental results show that our method outperforms all\ncompared IQA models on the selected three super-resolution quality assessment\n(SRQA) databases.",
    "descriptor": "",
    "authors": [
      "Zicheng Zhang",
      "Wei Sun",
      "Xiongkuo Min",
      "Wenhan Zhu",
      "Tao Wang",
      "Wei Lu",
      "Guangtao Zhai"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.04289"
  },
  {
    "id": "arXiv:2206.04300",
    "title": "Cone-Restricted Information Theory",
    "abstract": "The max-relative entropy and the conditional min-entropy it induces have\nbecome central to one-shot information theory. Both may be expressed in terms\nof a conic program over the positive semidefinite cone. Recently, it was shown\nthat the same conic program altered to be over the separable cone admits an\noperational interpretation in terms of communicating classical information over\na quantum channel. In this work, we generalize this framework of replacing the\ncone to determine which results in quantum information theory rely upon the\npositive semidefinite cone and which can be generalized. We show the fully\nquantum Stein's lemma and asymptotic equipartition property break down if the\ncone exponentially increases in resourcefulness but never approximates the\npositive semidefinite cone. However, we show for CQ states, the separable cone\nis sufficient to recover the asymptotic theory, thereby drawing a strong\ndistinction between the fully and partial quantum settings. We present parallel\nresults for the extended conditional min-entropy. In doing so, we extend the\nnotion of k-superpositive channels to superchannels. We also present\noperational uses of this framework. We first show the cone restricted\nmin-entropy of a Choi operator captures a measure of entanglement-assisted\nnoiseless classical communication using restricted measurements. We show that\nquantum majorization results naturally generalize to other cones. As a novel\nexample, we introduce a new min-entropy-like quantity that captures the quantum\nmajorization of quantum channels in terms of bistochastic pre-processing.\nLastly, we relate this framework to general conic norms and their\nnon-additivity. Throughout this work we emphasize the introduced measures'\nrelationship to general convex resource theories. In particular, we look at\nboth resource theories that capture locality and resource theories of\ncoherence/Abelian symmetries.",
    "descriptor": "\nComments: 32+6 pages, 7 Figures. Comments welcome!\n",
    "authors": [
      "Ian George",
      "Eric Chitambar"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.04300"
  },
  {
    "id": "arXiv:2206.04305",
    "title": "Context-based out-of-vocabulary word recovery for ASR systems in Indian  languages",
    "abstract": "Detecting and recovering out-of-vocabulary (OOV) words is always challenging\nfor Automatic Speech Recognition (ASR) systems. Many existing methods focus on\nmodeling OOV words by modifying acoustic and language models and integrating\ncontext words cleverly into models. To train such complex models, we need a\nlarge amount of data with context words, additional training time, and\nincreased model size. However, after getting the ASR transcription to recover\ncontext-based OOV words, the post-processing method has not been explored much.\nIn this work, we propose a post-processing technique to improve the performance\nof context-based OOV recovery. We created an acoustically boosted language\nmodel with a sub-graph made at phone level with an OOV words list. We proposed\ntwo methods to determine a suitable cost function to retrieve the OOV words\nbased on the context. The cost function is defined based on phonetic and\nacoustic knowledge for matching and recovering the correct context words in the\ndecode. The effectiveness of the proposed cost function is evaluated at both\nword-level and sentence-level. The evaluation results show that this approach\ncan recover an average of 50% context-based OOV words across multiple\ncategories.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Arun Baby",
      "Saranya Vinnaitherthan",
      "Akhil Kerhalkar",
      "Pranav Jawale",
      "Sharath Adavanne",
      "Nagaraj Adiga"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2206.04305"
  },
  {
    "id": "arXiv:2206.04307",
    "title": "An Autonomous Drone System with Jamming and Relative Positioning  Capabilities",
    "abstract": "As the number of unauthorized operations of Unmanned Aerial Vehicles (UAVs)\nis rising, the implementation of a versatile counter-drone system is becoming a\nnecessity. In this work, we develop a drone-based counter-drone system, that\nemploys algorithms for detecting and tracking a rogue drone, in conjunction\nwith wireless interception capabilities to jointly jam the rogue drone while\nachieving self positioning for the pursuer drone. In the proposed system a\nsoftware-defined-radio (SDR) is used for switching between jamming\ntransmissions and spectrum sweeping functionalities to achieve the desired GPS\ndisruption and self-localization, respectively. Extensive field experiments\ndemonstrate the effectiveness of the proposed solution in a realworld\nenvironment under various parameter settings.",
    "descriptor": "",
    "authors": [
      "Nicolas Souli",
      "Panayiotis Kolios",
      "Georgios Ellinas"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.04307"
  },
  {
    "id": "arXiv:2206.04320",
    "title": "Negative Shannon Information Hides Networks",
    "abstract": "Negative numbers are essential in mathematics. They are not needed to\ndescribe statistical experiments, as those are expressed in terms of positive\nprobabilities. Shannon information was firstly defined for characterizing\ninformational uncertainty of classical probabilistic distributions. However, it\nis unknown why there is negative information for more than two random variables\non finite sample spaces. We first show the negative Shannon mutual information\nof three random variables implies Bayesian network representations of its joint\ndistribution. We then show the intrinsic compatibility with negative Shannon\ninformation is generic for Bayesian networks with quantum realizations. This\nfurther suggests a new kind of space-dependent nonlocality. The present result\nprovides a device-independent witness of negative Shannon information.",
    "descriptor": "\nComments: 5+10 pages, 7 figures. Comments welcome!\n",
    "authors": [
      "Ming-Xing Luo"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.04320"
  },
  {
    "id": "arXiv:2206.04328",
    "title": "Novel projection schemes for graph-based Light Field coding",
    "abstract": "In Light Field compression, graph-based coding is powerful to exploit signal\nredundancy along irregular shapes and obtains good energy compaction. However,\napart from high time complexity to process high dimensional graphs, their graph\nconstruction method is highly sensitive to the accuracy of disparity\ninformation between viewpoints. In real world Light Field or synthetic Light\nField generated by computer software, the use of disparity information for\nsuper-rays projection might suffer from inaccuracy due to vignetting effect and\nlarge disparity between views in the two types of Light Fields respectively.\nThis paper introduces two novel projection schemes resulting in less error in\ndisparity information, in which one projection scheme can also significantly\nreduce time computation for both encoder and decoder. Experimental results show\nprojection quality of super-pixels across views can be considerably enhanced\nusing the proposals, along with rate-distortion performance when compared\nagainst original projection scheme and HEVC-based or JPEG Pleno-based coding\napproaches.",
    "descriptor": "",
    "authors": [
      "Bach Gia Nguyen",
      "Chanh Minh Tran",
      "Tho Nguyen Duc",
      "Tan Xuan Phan",
      "Kamioka Eiji"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2206.04328"
  },
  {
    "id": "arXiv:2206.04329",
    "title": "Damage Identification in Fiber Metal Laminates using Bayesian Analysis  with Model Order Reduction",
    "abstract": "Fiber metal laminates (FML) are composite structures consisting of metals and\nfiber reinforced plastics (FRP) which have experienced an increasing interest\nas the choice of materials in aerospace and automobile industries. Due to a\nsophisticated built up of the material, not only the design and production of\nsuch structures is challenging but also its damage detection. This research\nwork focuses on damage identification in FML with guided ultrasonic waves (GUW)\nthrough an inverse approach based on the Bayesian paradigm. As the Bayesian\ninference approach involves multiple queries of the underlying system, a\nparameterized reduced-order model (ROM) is used to closely approximate the\nsolution with considerably less computational cost. The signals measured by the\nembedded sensors and the ROM forecasts are employed for the localization and\ncharacterization of damage in FML. In this paper, a Markov Chain Monte-Carlo\n(MCMC) based Metropolis-Hastings (MH) algorithm and an Ensemble Kalman\nfiltering (EnKF) technique are deployed to identify the damage. Numerical tests\nillustrate the approaches and the results are compared in regard to accuracy\nand efficiency. It is found that both methods are successful in multivariate\ncharacterization of the damage with a high accuracy and were also able to\nquantify their associated uncertainties. The EnKF distinguishes itself with the\nMCMC-MH algorithm in the matter of computational efficiency. In this\napplication of identifying the damage, the EnKF is approximately thrice faster\nthan the MCMC-MH.",
    "descriptor": "",
    "authors": [
      "Nanda Kishore Bellam Muralidhar",
      "Carmen Gr\u00e4\u00dfle",
      "Natalie Rauter",
      "Andrey Mikhaylenko",
      "Rolf Lammering",
      "Dirk A. Lorenz"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.04329"
  },
  {
    "id": "arXiv:2206.04336",
    "title": "Joint Modeling of Image and Label Statistics for Enhancing Model  Generalizability of Medical Image Segmentation",
    "abstract": "Although supervised deep-learning has achieved promising performance in\nmedical image segmentation, many methods cannot generalize well on unseen data,\nlimiting their real-world applicability. To address this problem, we propose a\ndeep learning-based Bayesian framework, which jointly models image and label\nstatistics, utilizing the domain-irrelevant contour of a medical image for\nsegmentation. Specifically, we first decompose an image into components of\ncontour and basis. Then, we model the expected label as a variable only related\nto the contour. Finally, we develop a variational Bayesian framework to infer\nthe posterior distributions of these variables, including the contour, the\nbasis, and the label. The framework is implemented with neural networks, thus\nis referred to as deep Bayesian segmentation. Results on the task of\ncross-sequence cardiac MRI segmentation show that our method set a new state of\nthe art for model generalizability. Particularly, the BayeSeg model trained\nwith LGE MRI generalized well on T2 images and outperformed other models with\ngreat margins, i.e., over 0.47 in terms of average Dice. Our code is available\nat https://zmiclab.github.io/projects.html.",
    "descriptor": "\nComments: MICCAI 2022\n",
    "authors": [
      "Shangqi Gao",
      "Hangqi Zhou",
      "Yibo Gao",
      "Xiahai Zhuang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.04336"
  },
  {
    "id": "arXiv:2206.04341",
    "title": "How Asynchronous Events Encode Video",
    "abstract": "As event-based sensing gains in popularity, theoretical understanding is\nneeded to harness this technology's potential. Instead of recording video by\ncapturing frames, event-based cameras have sensors that emit events when their\ninputs change, thus encoding information in the timing of events. This creates\nnew challenges in establishing reconstruction guarantees and algorithms, but\nalso provides advantages over frame-based video. We use time encoding machines\nto model event-based sensors: TEMs also encode their inputs by emitting events\ncharacterized by their timing and reconstruction from time encodings is well\nunderstood. We consider the case of time encoding bandlimited video and\ndemonstrate a dependence between spatial sensor density and overall spatial and\ntemporal resolution. Such a dependence does not occur in frame-based video,\nwhere temporal resolution depends solely on the frame rate of the video and\nspatial resolution depends solely on the pixel grid. However, this dependence\narises naturally in event-based video and allows oversampling in space to\nprovide better time resolution. As such, event-based vision encourages using\nmore sensors that emit fewer events over time.",
    "descriptor": "\nComments: 6 pages, 4 figures\n",
    "authors": [
      "Karen Adam",
      "Adam Scholefield",
      "Martin Vetterli"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.04341"
  },
  {
    "id": "arXiv:2206.04356",
    "title": "A Simple Unified Approach to Testing High-Dimensional Conditional  Independences for Categorical and Ordinal Data",
    "abstract": "Conditional independence (CI) tests underlie many approaches to model testing\nand structure learning in causal inference. Most existing CI tests for\ncategorical and ordinal data stratify the sample by the conditioning variables,\nperform simple independence tests in each stratum, and combine the results.\nUnfortunately, the statistical power of this approach degrades rapidly as the\nnumber of conditioning variables increases. Here we propose a simple unified CI\ntest for ordinal and categorical data that maintains reasonable calibration and\npower in high dimensions. We show that our test outperforms existing baselines\nin model testing and structure learning for dense directed graphical models\nwhile being comparable for sparse models. Our approach could be attractive for\ncausal model testing because it is easy to implement, can be used with\nnon-parametric or parametric probability models, has the symmetry property, and\nhas reasonable computational requirements.",
    "descriptor": "\nComments: 10 pages, 5 figures, Submitted to NeurIPS 2022\n",
    "authors": [
      "Ankur Ankan",
      "Johannes Textor"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04356"
  },
  {
    "id": "arXiv:2206.04405",
    "title": "Conformal Off-Policy Prediction in Contextual Bandits",
    "abstract": "Most off-policy evaluation methods for contextual bandits have focused on the\nexpected outcome of a policy, which is estimated via methods that at best\nprovide only asymptotic guarantees. However, in many applications, the\nexpectation may not be the best measure of performance as it does not capture\nthe variability of the outcome. In addition, particularly in safety-critical\nsettings, stronger guarantees than asymptotic correctness may be required. To\naddress these limitations, we consider a novel application of conformal\nprediction to contextual bandits. Given data collected under a behavioral\npolicy, we propose \\emph{conformal off-policy prediction} (COPP), which can\noutput reliable predictive intervals for the outcome under a new target policy.\nWe provide theoretical finite-sample guarantees without making any additional\nassumptions beyond the standard contextual bandit setup, and empirically\ndemonstrate the utility of COPP compared with existing methods on synthetic and\nreal-world data.",
    "descriptor": "",
    "authors": [
      "Muhammad Faaiz Taufiq",
      "Jean-Francois Ton",
      "Rob Cornish",
      "Yee Whye Teh",
      "Arnaud Doucet"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04405"
  },
  {
    "id": "arXiv:2206.04420",
    "title": "Neonatal EEG graded for severity of background abnormalities in  hypoxic-ischaemic encephalopathy",
    "abstract": "This report describes a set of neonatal electroencephalogram (EEG) recordings\ngraded according to the severity of abnormalities in the background pattern.\nThe dataset consists of 169 hours of multichannel EEG from 53 neonates recorded\nin a neonatal intensive care unit. All neonates received a diagnosis of\nhypoxic-ischaemic encephalopathy (HIE), the most common cause of brain injury\nin full term infants. For each neonate, multiple 1-hour epochs of good quality\nEEG were selected and then graded for background abnormalities. The grading\nsystem assesses EEG attributes such as amplitude and frequency, continuity,\nsleep-wake cycling, symmetry and synchrony, and abnormal waveforms. Background\nseverity was then categorised into 4 grades: normal or mildly abnormal,\nmoderately abnormal, severely abnormal, and inactive EEG. The data can be used\nas a reference set of multi-channel EEG for neonates with HIE, for EEG training\npurposes, or for developing and evaluating automated grading algorithms.",
    "descriptor": "",
    "authors": [
      "John M O'Toole",
      "Sean R Mathieson",
      "Sumit A Raurale",
      "Fabio Magarelli",
      "William P Marnane",
      "Gordon Lightbody",
      "Geraldine B Boylan"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.04420"
  },
  {
    "id": "arXiv:2206.04431",
    "title": "Cross-boosting of WNNM Image Denoising method by Directional Wavelet  Packets",
    "abstract": "The paper presents an image denoising scheme by combining a method that is\nbased on directional quasi-analytic wavelet packets (qWPs) with the\nstate-of-the-art Weighted Nuclear Norm Minimization (WNNM) denoising algorithm.\nThe qWP-based denoising method (qWPdn) consists of multiscale qWP transform of\nthe degraded image, application of adaptive localized soft thresholding to the\ntransform coefficients using the Bivariate Shrinkage methodology, and\nrestoration of the image from the thresholded coefficients from several\ndecomposition levels. The combined method consists of several iterations of\nqWPdn and WNNM algorithms in a way that at each iteration the output from one\nalgorithm boosts the input to the other. The proposed methodology couples the\nqWPdn capabilities to capture edges and fine texture patterns even in the\nseverely corrupted images with utilizing the non-local self-similarity in real\nimages that is inherent in the WNNM algorithm.\nMultiple experiments, which compared the proposed methodology with six\nadvanced denoising algorithms, including WNNM, confirmed that the combined\ncross-boosting algorithm outperforms most of them in terms of both quantitative\nmeasure and visual perception quality.",
    "descriptor": "\nComments: 30 pages, 28 figures. arXiv admin note: substantial text overlap with arXiv:2008.11595\n",
    "authors": [
      "Amir Averbuch",
      "Pekka Neittaanm\u00e4ki",
      "Valery Zheludev",
      "Moshe Salhov",
      "Jonathan Hauser"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.04431"
  },
  {
    "id": "arXiv:2206.04432",
    "title": "Discriminative and Generative Learning for Linear Estimation of Random  Signals [Lecture Notes]",
    "abstract": "Inference tasks in signal processing are often characterized by the\navailability of reliable statistical modeling with some missing\ninstance-specific parameters. One conventional approach uses data to estimate\nthese missing parameters and then infers based on the estimated model.\nAlternatively, data can also be leveraged to directly learn the inference\nmapping end-to-end. These approaches for combining partially-known statistical\nmodels and data in inference are related to the notions of generative and\ndiscriminative models used in the machine learning literature, typically\nconsidered in the context of classifiers. The goal of this lecture note is to\nintroduce the concepts of generative and discriminative learning for inference\nwith a partially-known statistical model. While machine learning systems often\nlack the interpretability of traditional signal processing methods, we focus on\na simple setting where one can interpret and compare the approaches in a\ntractable manner that is accessible and relevant to signal processing readers.\nIn particular, we exemplify the approaches for the task of Bayesian signal\nestimation in a jointly Gaussian setting with the mean-squared error (MSE)\nobjective, i.e., a linear estimation setting.",
    "descriptor": "",
    "authors": [
      "Nir Shlezinger",
      "Tirza Routtenberg"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04432"
  },
  {
    "id": "arXiv:2206.04447",
    "title": "Convolutional Dictionary Learning by End-To-End Training of Iterative  Neural Networks",
    "abstract": "Sparsity-based methods have a long history in the field of signal processing\nand have been successfully applied to various image reconstruction problems.\nThe involved sparsifying transformations or dictionaries are typically either\npre-trained using a model which reflects the assumed properties of the signals\nor adaptively learned during the reconstruction - yielding so-called blind\nCompressed Sensing approaches. However, by doing so, the transforms are never\nexplicitly trained in conjunction with the physical model which generates the\nsignals. In addition, properly choosing the involved regularization parameters\nremains a challenging task. Another recently emerged training-paradigm for\nregularization methods is to use iterative neural networks (INNs) - also known\nas unrolled networks - which contain the physical model. In this work, we\nconstruct an INN which can be used as a supervised and physics-informed online\nconvolutional dictionary learning algorithm. We evaluated the proposed approach\nby applying it to a realistic large-scale dynamic MR reconstruction problem and\ncompared it to several other recently published works. We show that the\nproposed INN improves over two conventional model-agnostic training methods and\nyields competitive results also compared to a deep INN. Further, it does not\nrequire to choose the regularization parameters and - in contrast to deep INNs\n- each network component is entirely interpretable.",
    "descriptor": "\nComments: Accepted for publication at the European Signal Processing Conference (EUSIPCO) 2022\n",
    "authors": [
      "Andreas Kofler",
      "Christian Wald",
      "Tobias Schaeffter",
      "Markus Haltmeier",
      "Christoph Kolbitsch"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.04447"
  },
  {
    "id": "arXiv:2206.04456",
    "title": "Choosing Answers in $\\varepsilon$-Best-Answer Identification for Linear  Bandits",
    "abstract": "In pure-exploration problems, information is gathered sequentially to answer\na question on the stochastic environment. While best-arm identification for\nlinear bandits has been extensively studied in recent years, few works have\nbeen dedicated to identifying one arm that is $\\varepsilon$-close to the best\none (and not exactly the best one). In this problem with several correct\nanswers, an identification algorithm should focus on one candidate among those\nanswers and verify that it is correct. We demonstrate that picking the answer\nwith highest mean does not allow an algorithm to reach asymptotic optimality in\nterms of expected sample complexity. Instead, a \\textit{furthest answer} should\nbe identified. Using that insight to choose the candidate answer carefully, we\ndevelop a simple procedure to adapt best-arm identification algorithms to\ntackle $\\varepsilon$-best-answer identification in transductive linear\nstochastic bandits. Finally, we propose an asymptotically optimal algorithm for\nthis setting, which is shown to achieve competitive empirical performance\nagainst existing modified best-arm identification algorithms.",
    "descriptor": "\nComments: 47 pages, 10 figures, 8 tables. To be published in the 39th International Conference on Machine Learning, Baltimore, Maryland, USA, PMLR 162, 2022\n",
    "authors": [
      "Marc Jourdan",
      "R\u00e9my Degenne"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04456"
  },
  {
    "id": "arXiv:2206.04470",
    "title": "Efficient computational methods for rovibrational transition rates in  molecular collisions",
    "abstract": "Astrophysical modeling of processes in environments that are not in local\nthermal equilibrium requires the knowledge of state-to-state rate coefficients\nof rovibrational transitions in molecular collisions. These rate coefficients\ncan be obtained from coupled-channel (CC) quantum scattering calculations which\nare very demanding, however. Here we present various approximate, but more\nefficient methods based on the coupled-states approximation (CSA) which\nneglects the off-diagonal Coriolis coupling in the scattering Hamiltonian in\nbody-fixed coordinates. In particular, we investigated a method called NNCC\n(nearest-neighbor Coriolis coupling) [D. Yang, X. Hu, D. H. Zhang, and D. Xie,\nJ. Chem. Phys. 148, 084101 (2018)] that includes Coriolis coupling to first\norder. The NNCC method is more demanding than the common CSA method, but still\nmuch more efficient than full CC calculations, and it is substantially more\naccurate than CSA. All of this is illustrated by showing state-to-state cross\nsections and rate coefficients of rovibrational transitions induced in CO$_2$\nby collisions with He atoms. It is also shown that a further reduction of CPU\ntime, practically without loss of accuracy, can be obtained by combining the\nNNCC method with the multi-channel distorted-wave Born approximation (MC-DWBA)\nthat we applied in full CC calculations in a previous paper.",
    "descriptor": "\nComments: This article has been submitted to The Journal of Chemical Physics (JCP)\n",
    "authors": [
      "Taha Selim",
      "Ad van der Avoird",
      "Gerrit C. Groenenboom"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Numerical Analysis (math.NA)",
      "Atomic Physics (physics.atom-ph)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.04470"
  },
  {
    "id": "arXiv:2206.04498",
    "title": "Abstract message passing and distributed graph signal processing",
    "abstract": "Graph signal processing is a framework to handle graph structured data. The\nfundamental concept is graph shift operator, giving rise to the graph Fourier\ntransform. While the graph Fourier transform is a centralized procedure,\ndistributed graph signal processing algorithms are needed to address challenges\nsuch as scalability and privacy. In this paper, we develop a theory of\ndistributed graph signal processing based on the classical notion of message\npassing. However, we generalize the definition of a message to permit more\nabstract mathematical objects. The framework provides an alternative point of\nview that avoids the iterative nature of existing approaches to distributed\ngraph signal processing. Moreover, our framework facilitates investigating\ntheoretical questions such as solubility of distributed problems.",
    "descriptor": "",
    "authors": [
      "Feng Ji",
      "Yiqi Lu",
      "Wee Peng Tay",
      "Edwin Chong"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.04498"
  },
  {
    "id": "arXiv:2206.04502",
    "title": "What is a Good Metric to Study Generalization of Minimax Learners?",
    "abstract": "Minimax optimization has served as the backbone of many machine learning (ML)\nproblems. Although the convergence behavior of optimization algorithms has been\nextensively studied in minimax settings, their generalization guarantees in the\nstochastic setting, i.e., how the solution trained on empirical data performs\non the unseen testing data, have been relatively underexplored. A fundamental\nquestion remains elusive: What is a good metric to study generalization of\nminimax learners? In this paper, we aim to answer this question by first\nshowing that primal risk, a universal metric to study generalization in\nminimization, fails in simple examples of minimax problems. Furthermore,\nanother popular metric, the primal-dual risk, also fails to characterize the\ngeneralization behavior for minimax problems with nonconvexity, due to\nnon-existence of saddle points. We thus propose a new metric to study\ngeneralization of minimax learners: the primal gap, to circumvent these issues.\nNext, we derive generalization bounds for the primal gap in nonconvex-concave\nsettings. As byproducts of our analysis, we also solve two open questions:\nestablishing generalization bounds for primal risk and primal-dual risk in the\nstrong sense, i.e., without strong concavity or assuming that the maximization\nand expectation can be interchanged, while either of these assumptions was\nneeded in the literature. Finally, we leverage this new metric to compare the\ngeneralization behavior of two popular algorithms -- gradient descent-ascent\n(GDA) and gradient descent-max (GDMax) in stochastic minimax optimization.",
    "descriptor": "\nComments: 31 pages, 2 figures\n",
    "authors": [
      "Asuman Ozdaglar",
      "Sarath Pattathil",
      "Jiawei Zhang",
      "Kaiqing Zhang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04502"
  },
  {
    "id": "arXiv:2206.04514",
    "title": "SAR Despeckling using a Denoising Diffusion Probabilistic Model",
    "abstract": "Speckle is a multiplicative noise which affects all coherent imaging\nmodalities including Synthetic Aperture Radar (SAR) images. The presence of\nspeckle degrades the image quality and adversely affects the performance of SAR\nimage understanding applications such as automatic target recognition and\nchange detection. Thus, SAR despeckling is an important problem in remote\nsensing. In this paper, we introduce SAR-DDPM, a denoising diffusion\nprobabilistic model for SAR despeckling. The proposed method comprises of a\nMarkov chain that transforms clean images to white Gaussian noise by repeatedly\nadding random noise. The despeckled image is recovered by a reverse process\nwhich iteratively predicts the added noise using a noise predictor which is\nconditioned on the speckled image. In addition, we propose a new inference\nstrategy based on cycle spinning to improve the despeckling performance. Our\nexperiments on both synthetic and real SAR images demonstrate that the proposed\nmethod achieves significant improvements in both quantitative and qualitative\nresults over the state-of-the-art despeckling methods.",
    "descriptor": "\nComments: Our code is available at this https URL\n",
    "authors": [
      "Malsha V. Perera",
      "Nithin Gopalakrishnan Nair",
      "Wele Gedara Chaminda Bandara",
      "Vishal M. Patel"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.04514"
  },
  {
    "id": "arXiv:2206.04525",
    "title": "Large-Scale Crosstalk-Corrected Thermo-Optic Phase Shifter Arrays in  Silicon Photonics",
    "abstract": "We introduce a thermo-optic phase shifter (TOPS) array architecture with\nindependent phase control of each phase shifter for large-scale and\nhigh-density photonic integrated circuits with two different control schemes:\npulse amplitude modulation (PAM) and pulse width modulation (PWM). We realize a\ncompact spiral TOPS and a 288-element high-density row-column TOPS array with\nthis architecture and drive TOPS with waveforms of both control schemes and of\ndifferent array sizes. We present a thermal excitation model and a finite\ndifference method-based simulation to simulate large-scale TOPS arrays and\ncompare both schemes experimentally and theoretically. We also analyze the\neffects of thermal crosstalk in the realized TOPS array and implement a thermal\ncrosstalk correction algorithm with the developed model. The high-density TOPS\narray architecture and the thermal crosstalk correction algorithm pave the way\nfor high-density TOPS arrays with independent phase control in large-scale\nphotonic integrated circuits interfaced with electronics limited in voltage\nswing and bandwidth.",
    "descriptor": "\nComments: 12 pages and 19 figures accepted to IEEE JSTQE for publication\n",
    "authors": [
      "Volkan Gurses",
      "Reza Fatemi",
      "Aroutin Khachaturian",
      "Ali Hajimiri"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Systems and Control (eess.SY)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.04525"
  },
  {
    "id": "arXiv:2206.04529",
    "title": "Symmetrized semi-discrete optimal transport",
    "abstract": "Interpolating between measures supported by polygonal or polyhedral domains\nis a problem that has been recently addressed by the semi-discrete optimal\ntransport framework. Within this framework, one of the domains is discretized\nwith a set of samples, while the other one remains continuous. In this paper we\npresent a method to introduce some symmetry into the solution using coupled\npower diagrams. This symmetry is key to capturing the discontinuities of the\ntransport map reflected in the geometry of the power cells. We design our\nmethod as a fixed-point algorithm alternating between computations of\nsemi-discrete transport maps and recentering of the sites. The resulting\nobjects are coupled power diagrams with identical geometry, allowing us to\napproximate displacement interpolation through linear interpolation of the\nmeshes vertices. Through these coupled power diagrams, we have a natural way of\njointly sampling measures.",
    "descriptor": "",
    "authors": [
      "Agathe Herrou",
      "Bruno L\u00e9vy",
      "Vincent Nivoliers",
      "Nicolas Bonneel",
      "Julie Digne"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Geometry (cs.CG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.04529"
  },
  {
    "id": "arXiv:2206.04548",
    "title": "Classification of COVID-19 in Chest X-ray Images Using Fusion of Deep  Features and LightGBM",
    "abstract": "The COVID-19 disease was first discovered in Wuhan, China, and spread quickly\nworldwide. After the COVID-19 pandemic, many researchers have begun to identify\na way to diagnose the COVID-19 using chest X-ray images. The early diagnosis of\nthis disease can significantly impact the treatment process. In this article,\nwe propose a new technique that is faster and more accurate than the other\nmethods reported in the literature. The proposed method uses a combination of\nDenseNet169 and MobileNet Deep Neural Networks to extract the features of the\npatient's X-ray images. Using the univariate feature selection algorithm, we\nrefined the features for the most important ones. Then we applied the selected\nfeatures as input to the LightGBM (Light Gradient Boosting Machine) algorithm\nfor classification. To assess the effectiveness of the proposed method, the\nChestX-ray8 dataset, which includes 1125 X-ray images of the patient's chest,\nwas used. The proposed method achieved 98.54% and 91.11% accuracies in the\ntwo-class (COVID-19, Healthy) and multi-class (COVID-19, Healthy, Pneumonia)\nclassification problems, respectively. It is worth mentioning that we have used\nGradient-weighted Class Activation Mapping (Grad-CAM) for further analysis.",
    "descriptor": "",
    "authors": [
      "Hamid Nasiri",
      "Ghazal Kheyroddin",
      "Morteza Dorrigiv",
      "Mona Esmaeili",
      "Amir Raeisi Nafchi",
      "Mohsen Haji Ghorbani",
      "Payman Zarkesh-Ha"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.04548"
  },
  {
    "id": "arXiv:2206.04569",
    "title": "Benefits of Overparameterized Convolutional Residual Networks: Function  Approximation under Smoothness Constraint",
    "abstract": "Overparameterized neural networks enjoy great representation power on complex\ndata, and more importantly yield sufficiently smooth output, which is crucial\nto their generalization and robustness. Most existing function approximation\ntheories suggest that with sufficiently many parameters, neural networks can\nwell approximate certain classes of functions in terms of the function value.\nThe neural network themselves, however, can be highly nonsmooth. To bridge this\ngap, we take convolutional residual networks (ConvResNets) as an example, and\nprove that large ConvResNets can not only approximate a target function in\nterms of function value, but also exhibit sufficient first-order smoothness.\nMoreover, we extend our theory to approximating functions supported on a\nlow-dimensional manifold. Our theory partially justifies the benefits of using\ndeep and wide networks in practice. Numerical experiments on adversarial robust\nimage classification are provided to support our theory.",
    "descriptor": "",
    "authors": [
      "Hao Liu",
      "Minshuo Chen",
      "Siawpeng Er",
      "Wenjing Liao",
      "Tong Zhang",
      "Tuo Zhao"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04569"
  },
  {
    "id": "arXiv:2206.04573",
    "title": "Simple lessons from complex learning: what a neural network model learns  about cosmic structure formation",
    "abstract": "We train a neural network model to predict the full phase space evolution of\ncosmological N-body simulations. Its success implies that the neural network\nmodel is accurately approximating the Green's function expansion that relates\nthe initial conditions of the simulations to its outcome at later times in the\ndeeply nonlinear regime. We test the accuracy of this approximation by\nassessing its performance on well understood simple cases that have either\nknown exact solutions or well understood expansions. These scenarios include\nspherical configurations, isolated plane waves, and two interacting plane\nwaves: initial conditions that are very different from the Gaussian random\nfields used for training. We find our model generalizes well to these well\nunderstood scenarios, demonstrating that the networks have inferred general\nphysical principles and learned the nonlinear mode couplings from the complex,\nrandom Gaussian training data. These tests also provide a useful diagnostic for\nfinding the model's strengths and weaknesses, and identifying strategies for\nmodel improvement. We also test the model on initial conditions that contain\nonly transverse modes, a family of modes that differ not only in their phases\nbut also in their evolution from the longitudinal growing modes used in the\ntraining set. When the network encounters these initial conditions that are\northogonal to the training set, the model fails completely. In addition to\nthese simple configurations, we evaluate the model's predictions for the\ndensity, displacement, and momentum power spectra with standard initial\nconditions for N-body simulations. We compare these summary statistics against\nN-body results and an approximate, fast simulation method called COLA. Our\nmodel achieves percent level accuracy at nonlinear scales of $k\\sim 1\\\n\\mathrm{Mpc}^{-1}\\, h$, representing a significant improvement over COLA.",
    "descriptor": "\nComments: 13 pages, 8 figures\n",
    "authors": [
      "Drew Jamieson",
      "Yin Li",
      "Siyu He",
      "Francisco Villaescusa-Navarro",
      "Shirley Ho",
      "Renan Alves de Oliveira",
      "David N. Spergel"
    ],
    "subjectives": [
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04573"
  },
  {
    "id": "arXiv:2206.04594",
    "title": "Field Level Neural Network Emulator for Cosmological N-body Simulations",
    "abstract": "We build a field level emulator for cosmic structure formation that is\naccurate in the nonlinear regime. Our emulator consists of two convolutional\nneural networks trained to output the nonlinear displacements and velocities of\nN-body simulation particles based on their linear inputs. Cosmology dependence\nis encoded in the form of style parameters at each layer of the neural network,\nenabling the emulator to effectively interpolate the outcomes of structure\nformation between different flat $\\Lambda$CDM cosmologies over a wide range of\nbackground matter densities. The neural network architecture makes the model\ndifferentiable by construction, providing a powerful tool for fast field level\ninference. We test the accuracy of our method by considering several summary\nstatistics, including the density power spectrum with and without redshift\nspace distortions, the displacement power spectrum, the momentum power\nspectrum, the density bispectrum, halo abundances, and halo profiles with and\nwithout redshift space distortions. We compare these statistics from our\nemulator with the full N-body results, the COLA method, and a fiducial neural\nnetwork with no cosmological dependence. We find our emulator gives accurate\nresults down to scales of $k \\sim 1\\ \\mathrm{Mpc}^{-1}\\, h$, representing a\nconsiderable improvement over both COLA and the fiducial neural network. We\nalso demonstrate that our emulator generalizes well to initial conditions\ncontaining primordial non-Gaussianity, without the need for any additional\nstyle parameters or retraining.",
    "descriptor": "\nComments: 11 pages, 4 figures\n",
    "authors": [
      "Drew Jamieson",
      "Yin Li",
      "Renan Alves de Oliveira",
      "Francisco Villaescusa-Navarro",
      "Shirley Ho",
      "David N. Spergel"
    ],
    "subjectives": [
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04594"
  },
  {
    "id": "arXiv:2206.04612",
    "title": "A computational framework for weighted simplicial homology",
    "abstract": "We provide a bottom up construction of torsion generators for weighted\nhomology of a weighted complex over a discrete valuation ring\n$R=\\mathbb{F}[[\\pi]]$. This is achieved by starting from a basis for classical\nhomology of the $n$-th skeleton for the underlying complex with coefficients in\nthe residue field $\\mathbb{F}$ and then lifting it to a basis for the weighted\nhomology with coefficients in the ring $R$. Using the latter, a bijection is\nestablished between $n+1$ and $n$ dimensional simplices whose weight ratios\nprovide the exponents of the $\\pi$-monomials that generate each torsion summand\nin the structure theorem of the weighted homology modules over $R$. We present\nalgorithms that subsume the torsion computation by reducing it to normalization\nover the residue field of $R$, and describe a Python package we implemented\nthat takes advantage of this reduction and performs the computation\nefficiently.",
    "descriptor": "\nComments: 16 pages, 2 figures\n",
    "authors": [
      "Andrei C. Bura",
      "Neelav S. Dutta",
      "Thomas J. X. Li",
      "Christian M. Reidys"
    ],
    "subjectives": [
      "Algebraic Topology (math.AT)",
      "Symbolic Computation (cs.SC)",
      "Combinatorics (math.CO)",
      "General Topology (math.GN)",
      "K-Theory and Homology (math.KT)"
    ],
    "url": "https://arxiv.org/abs/2206.04612"
  },
  {
    "id": "arXiv:2206.04646",
    "title": "Globally Optimal Algorithms for Fixed-Budged Best Arm Identification",
    "abstract": "We consider the fixed-budget best arm identification problem where the goal\nis to find the arm of the largest mean with a fixed number of samples. It is\nknown that the probability of misidentifying the best arm is exponentially\nsmall to the number of rounds. However, limited characterizations have been\ndiscussed on the rate (exponent) of this value. In this paper, we characterize\nthe optimal rate as a result of global optimization over all possible\nparameters. We introduce two rates, $R^{\\mathrm{go}}$ and\n$R^{\\mathrm{go}}_{\\infty}$, corresponding to lower bounds on the\nmisidentification probability, each of which is associated with a proposed\nalgorithm. The rate $R^{\\mathrm{go}}$ is associated with\n$R^{\\mathrm{go}}$-tracking, which can be efficiently implemented by a neural\nnetwork and is shown to outperform existing algorithms. However, this rate\nrequires a nontrivial condition to be achievable. To deal with this issue, we\nintroduce the second rate $R^{\\mathrm{go}}_\\infty$. We show that this rate is\nindeed achievable by introducing a conceptual algorithm called delayed optimal\ntracking (DOT).",
    "descriptor": "",
    "authors": [
      "Junpei Komiyama",
      "Taira Tsuchiya",
      "Junya Honda"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04646"
  },
  {
    "id": "arXiv:2206.04647",
    "title": "VideoINR: Learning Video Implicit Neural Representation for Continuous  Space-Time Super-Resolution",
    "abstract": "Videos typically record the streaming and continuous visual data as discrete\nconsecutive frames. Since the storage cost is expensive for videos of high\nfidelity, most of them are stored in a relatively low resolution and frame\nrate. Recent works of Space-Time Video Super-Resolution (STVSR) are developed\nto incorporate temporal interpolation and spatial super-resolution in a unified\nframework. However, most of them only support a fixed up-sampling scale, which\nlimits their flexibility and applications. In this work, instead of following\nthe discrete representations, we propose Video Implicit Neural Representation\n(VideoINR), and we show its applications for STVSR. The learned implicit neural\nrepresentation can be decoded to videos of arbitrary spatial resolution and\nframe rate. We show that VideoINR achieves competitive performances with\nstate-of-the-art STVSR methods on common up-sampling scales and significantly\noutperforms prior works on continuous and out-of-training-distribution scales.\nOur project page is at this http URL .",
    "descriptor": "\nComments: Accepted to CVPR 2022. Project page: this http URL\n",
    "authors": [
      "Zeyuan Chen",
      "Yinbo Chen",
      "Jingwen Liu",
      "Xingqian Xu",
      "Vidit Goel",
      "Zhangyang Wang",
      "Humphrey Shi",
      "Xiaolong Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04647"
  },
  {
    "id": "arXiv:2206.04661",
    "title": "Distillation Decision Tree",
    "abstract": "Black-box machine learning models are criticized as lacking interpretability,\nalthough they tend to have good prediction accuracy. Knowledge Distillation\n(KD) is an emerging tool to interpret the black-box model by distilling its\nknowledge into a transparent model. With well-known advantages in\ninterpretation, decision tree is a competitive candidate of the transparent\nmodel. However, theoretical or empirical understanding for the decision tree\ngenerated from KD process is limited. In this paper, we name this kind of\ndecision tree the distillation decision tree (DDT) and lay the theoretical\nfoundations for tree structure stability which determines the validity of DDT's\ninterpretation. We prove that the structure of DDT can achieve stable\n(convergence) under some mild assumptions. Meanwhile, we develop algorithms for\nstabilizing the induction of DDT, propose parallel strategies for improving\nalgorithm's computational efficiency, and introduce a marginal principal\ncomponent analysis method for overcoming the curse of dimensionality in\nsampling. Simulated and real data studies justify our theoretical results,\nvalidate the efficacy of algorithms, and demonstrate that DDT can strike a good\nbalance between model's prediction accuracy and interpretability.",
    "descriptor": "",
    "authors": [
      "Xuetao Lu",
      "J. Jack Lee"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04661"
  },
  {
    "id": "arXiv:1802.09377",
    "title": "A Finite-Model-Theoretic View on Propositional Proof Complexity",
    "abstract": "A Finite-Model-Theoretic View on Propositional Proof Complexity",
    "descriptor": "",
    "authors": [
      "Erich Gr\u00e4del",
      "Martin Grohe",
      "Benedikt Pago",
      "Wied Pakusa"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/1802.09377"
  },
  {
    "id": "arXiv:1812.06840",
    "title": "An Immersed Interface Method for Discrete Surfaces",
    "abstract": "Comments: - Added a non-axisymmetric example (flow within eccentric rotating cylinder in Sec. 4.3) - Added a more in-depth analysis and comparison with a body-fitted approach for the application in Sec. 4.7",
    "descriptor": "\nComments: - Added a non-axisymmetric example (flow within eccentric rotating cylinder in Sec. 4.3) - Added a more in-depth analysis and comparison with a body-fitted approach for the application in Sec. 4.7\n",
    "authors": [
      "Ebrahim M. Kolahdouz",
      "Amneet Pal Singh Bhalla",
      "Brent A. Craven",
      "Boyce E. Griffith"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/1812.06840"
  },
  {
    "id": "arXiv:1908.08344",
    "title": "Indoor Depth Completion with Boundary Consistency and Self-Attention",
    "abstract": "Comments: Accepted by ICCVW (RLQ) 2019. The code is available at this https URL",
    "descriptor": "\nComments: Accepted by ICCVW (RLQ) 2019. The code is available at this https URL\n",
    "authors": [
      "Yu-Kai Huang",
      "Tsung-Han Wu",
      "Yueh-Cheng Liu",
      "Winston H. Hsu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1908.08344"
  },
  {
    "id": "arXiv:1912.08861",
    "title": "Establishing a Search String to Detect Secondary Studies in Software  Engineering",
    "abstract": "Establishing a Search String to Detect Secondary Studies in Software  Engineering",
    "descriptor": "",
    "authors": [
      "Bianca Minetto Napoleao",
      "Katia Romero Felizardo",
      "Erica Ferreira de Souza",
      "Fabio Petrillo",
      "Nandamudi L. Vijaykumar",
      "Elisa Yumi Nakagawa",
      "Sylvain Halle"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/1912.08861"
  },
  {
    "id": "arXiv:2002.04861",
    "title": "Training Two-Layer ReLU Networks with Gradient Descent is Inconsistent",
    "abstract": "Comments: To appear in Journal of Machine Learning Research (JMLR). Changes in v3: Added new Section 10 with extensive experimental evaluation. Code available at this https URL",
    "descriptor": "\nComments: To appear in Journal of Machine Learning Research (JMLR). Changes in v3: Added new Section 10 with extensive experimental evaluation. Code available at this https URL\n",
    "authors": [
      "David Holzm\u00fcller",
      "Ingo Steinwart"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2002.04861"
  },
  {
    "id": "arXiv:2005.11317",
    "title": "Privacy-Preserving Clustering of Unstructured Big Data for Cloud-Based  Enterprise Search Solutions",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:1908.04960",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1908.04960\n",
    "authors": [
      "SM Zobaed",
      "Mohsen Amini Salehi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Cryptography and Security (cs.CR)",
      "Databases (cs.DB)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2005.11317"
  },
  {
    "id": "arXiv:2006.14042",
    "title": "Blacklight: Scalable Defense for Neural Networks against Query-Based  Black-Box Attacks",
    "abstract": "Blacklight: Scalable Defense for Neural Networks against Query-Based  Black-Box Attacks",
    "descriptor": "",
    "authors": [
      "Huiying Li",
      "Shawn Shan",
      "Emily Wenger",
      "Jiayun Zhang",
      "Haitao Zheng",
      "Ben Y. Zhao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2006.14042"
  },
  {
    "id": "arXiv:2007.06728",
    "title": "On the Parallel Tower of Hanoi Puzzle: Acyclicity and a Conditional  Triangle Inequality",
    "abstract": "Comments: To be presented at the SIAM Conference on Discrete Mathematics 2022",
    "descriptor": "\nComments: To be presented at the SIAM Conference on Discrete Mathematics 2022\n",
    "authors": [
      "Andrey Rukhin"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2007.06728"
  },
  {
    "id": "arXiv:2007.12826",
    "title": "The Interpolation Phase Transition in Neural Networks: Memorization and  Generalization under Lazy Training",
    "abstract": "Comments: 83 pages, 5 figures",
    "descriptor": "\nComments: 83 pages, 5 figures\n",
    "authors": [
      "Andrea Montanari",
      "Yiqiao Zhong"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2007.12826"
  },
  {
    "id": "arXiv:2008.06029",
    "title": "Multi-Mask Self-Supervised Learning for Physics-Guided Neural Networks  in Highly Accelerated MRI",
    "abstract": "Multi-Mask Self-Supervised Learning for Physics-Guided Neural Networks  in Highly Accelerated MRI",
    "descriptor": "",
    "authors": [
      "Burhaneddin Yaman",
      "Hongyi Gu",
      "Seyed Amir Hossein Hosseini",
      "Omer Burak Demirel",
      "Steen Moeller",
      "Jutta Ellermann",
      "K\u00e2mil U\u011furbil",
      "Mehmet Ak\u00e7akaya"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2008.06029"
  },
  {
    "id": "arXiv:2008.10503",
    "title": "Universality of Linearized Message Passing for Phase Retrieval with  Structured Sensing Matrices",
    "abstract": "Universality of Linearized Message Passing for Phase Retrieval with  Structured Sensing Matrices",
    "descriptor": "",
    "authors": [
      "Rishabh Dudeja",
      "Milad Bakhshizadeh"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2008.10503"
  },
  {
    "id": "arXiv:2008.13492",
    "title": "Wireless for Machine Learning",
    "abstract": "Wireless for Machine Learning",
    "descriptor": "",
    "authors": [
      "Henrik Hellstr\u00f6m",
      "Jos\u00e9 Mairton B. da Silva Jr",
      "Mohammad Mohammadi Amiri",
      "Mingzhe Chen",
      "Viktoria Fodor",
      "H. Vincent Poor",
      "Carlo Fischione"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2008.13492"
  },
  {
    "id": "arXiv:2010.02502",
    "title": "Denoising Diffusion Implicit Models",
    "abstract": "Comments: ICLR 2021; updated connections with ODEs at page 6, fixed some typos",
    "descriptor": "\nComments: ICLR 2021; updated connections with ODEs at page 6, fixed some typos\n",
    "authors": [
      "Jiaming Song",
      "Chenlin Meng",
      "Stefano Ermon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2010.02502"
  },
  {
    "id": "arXiv:2010.05759",
    "title": "Explaining Clinical Decision Support Systems in Medical Imaging using  Cycle-Consistent Activation Maximization",
    "abstract": "Comments: 49 pages, 13 figures, 18 pages appendix, accepted manuscript",
    "descriptor": "\nComments: 49 pages, 13 figures, 18 pages appendix, accepted manuscript\n",
    "authors": [
      "Alexander Katzmann",
      "Oliver Taubmann",
      "Stephen Ahmad",
      "Alexander M\u00fchlberg",
      "Michael S\u00fchling",
      "Horst-Michael Gro\u00df"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.05759"
  },
  {
    "id": "arXiv:2010.15030",
    "title": "Actris 2.0: Asynchronous Session-Type Based Reasoning in Separation  Logic",
    "abstract": "Actris 2.0: Asynchronous Session-Type Based Reasoning in Separation  Logic",
    "descriptor": "",
    "authors": [
      "Jonas Kastberg Hinrichsen",
      "Jesper Bengtson",
      "Robbert Krebbers"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2010.15030"
  },
  {
    "id": "arXiv:2011.14574",
    "title": "DUT: Learning Video Stabilization by Simply Watching Unstable Videos",
    "abstract": "DUT: Learning Video Stabilization by Simply Watching Unstable Videos",
    "descriptor": "",
    "authors": [
      "Yufei Xu",
      "Jing Zhang",
      "Stephen J. Maybank",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.14574"
  },
  {
    "id": "arXiv:2011.14663",
    "title": "Revisiting Unsupervised Meta-Learning via the Characteristics of  Few-Shot Tasks",
    "abstract": "Comments: Accepted to IEEE TPAMI. Code is available at this https URL",
    "descriptor": "\nComments: Accepted to IEEE TPAMI. Code is available at this https URL\n",
    "authors": [
      "Han-Jia Ye",
      "Lu Han",
      "De-Chuan Zhan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.14663"
  },
  {
    "id": "arXiv:2012.02808",
    "title": "Persistent Laplacians: properties, algorithms and implications",
    "abstract": "Comments: We realized that the origin of the persistent Laplacian can be dated back to a talk given by Lieutier in 2014 (this https URL). We changed several places in the paper to give credit to Lieutier et al",
    "descriptor": "\nComments: We realized that the origin of the persistent Laplacian can be dated back to a talk given by Lieutier in 2014 (this https URL). We changed several places in the paper to give credit to Lieutier et al\n",
    "authors": [
      "Facundo M\u00e9moli",
      "Zhengchao Wan",
      "Yusu Wang"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2012.02808"
  },
  {
    "id": "arXiv:2012.08466",
    "title": "Objective-Based Hierarchical Clustering of Deep Embedding Vectors",
    "abstract": "Objective-Based Hierarchical Clustering of Deep Embedding Vectors",
    "descriptor": "",
    "authors": [
      "Stanislav Naumov",
      "Grigory Yaroslavtsev",
      "Dmitrii Avdiukhin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2012.08466"
  },
  {
    "id": "arXiv:2102.00872",
    "title": "A Weak Consensus Algorithm and Its Application to High-Performance  Blockchain",
    "abstract": "Comments: IEEE INFOCOM 2021, May 2021, Online, France",
    "descriptor": "\nComments: IEEE INFOCOM 2021, May 2021, Online, France\n",
    "authors": [
      "Qin Wang",
      "Rujia Li"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2102.00872"
  },
  {
    "id": "arXiv:2103.04053",
    "title": "NVUM: Non-Volatile Unbiased Memory for Robust Medical Image  Classification",
    "abstract": "Comments: MICCAI 2022 Early Accept",
    "descriptor": "\nComments: MICCAI 2022 Early Accept\n",
    "authors": [
      "Fengbei Liu",
      "Yuanhong Chen",
      "Yu Tian",
      "Yuyuan Liu",
      "Chong Wang",
      "Vasileios Belagiannis",
      "Gustavo Carneiro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.04053"
  },
  {
    "id": "arXiv:2103.06191",
    "title": "A Study of Face Obfuscation in ImageNet",
    "abstract": "Comments: Accepted to ICML 2022",
    "descriptor": "\nComments: Accepted to ICML 2022\n",
    "authors": [
      "Kaiyu Yang",
      "Jacqueline Yau",
      "Li Fei-Fei",
      "Jia Deng",
      "Olga Russakovsky"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.06191"
  },
  {
    "id": "arXiv:2104.06164",
    "title": "Fast Hierarchical Games for Image Explanations",
    "abstract": "Comments: 20 pages, 8 figures",
    "descriptor": "\nComments: 20 pages, 8 figures\n",
    "authors": [
      "Jacopo Teneggi",
      "Alexandre Luster",
      "Jeremias Sulam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.06164"
  },
  {
    "id": "arXiv:2104.10039",
    "title": "GraphGuess: Approximate Graph Processing System with Adaptive Correction",
    "abstract": "GraphGuess: Approximate Graph Processing System with Adaptive Correction",
    "descriptor": "",
    "authors": [
      "Morteza Ramezani",
      "Mahmut T. Kandemir",
      "Anand Sivasubramaniam"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2104.10039"
  },
  {
    "id": "arXiv:2105.03219",
    "title": "Subfield Algorithms for Ideal- and Module-SVP Based on the Decomposition  Group",
    "abstract": "Comments: 29 pages plus appendix, to appear in Banach Center Publications",
    "descriptor": "\nComments: 29 pages plus appendix, to appear in Banach Center Publications\n",
    "authors": [
      "Christian Porter",
      "Andrew Mendelsohn",
      "Cong Ling"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Number Theory (math.NT)",
      "Rings and Algebras (math.RA)"
    ],
    "url": "https://arxiv.org/abs/2105.03219"
  },
  {
    "id": "arXiv:2105.10123",
    "title": "Backdoor Attacks on Self-Supervised Learning",
    "abstract": "Comments: CVPR 2022 (Oral)",
    "descriptor": "\nComments: CVPR 2022 (Oral)\n",
    "authors": [
      "Aniruddha Saha",
      "Ajinkya Tejankar",
      "Soroush Abbasi Koohpayegani",
      "Hamed Pirsiavash"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.10123"
  },
  {
    "id": "arXiv:2106.04139",
    "title": "Image Deformation Estimation via Multi-Objective Optimization",
    "abstract": "Image Deformation Estimation via Multi-Objective Optimization",
    "descriptor": "",
    "authors": [
      "Takumi Nakane",
      "Haoran Xie",
      "Chao Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.04139"
  },
  {
    "id": "arXiv:2106.05009",
    "title": "Network insensitivity to parameter noise via adversarial regularization",
    "abstract": "Network insensitivity to parameter noise via adversarial regularization",
    "descriptor": "",
    "authors": [
      "Julian B\u00fcchel",
      "Fynn Faber",
      "Dylan R. Muir"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.05009"
  },
  {
    "id": "arXiv:2106.14556",
    "title": "Contrastive Counterfactual Visual Explanations With Overdetermination",
    "abstract": "Contrastive Counterfactual Visual Explanations With Overdetermination",
    "descriptor": "",
    "authors": [
      "Adam White",
      "Kwun Ho Ngan",
      "James Phelan",
      "Saman Sadeghi Afgeh",
      "Kevin Ryan",
      "Constantino Carlos Reyes-Aldasoro",
      "Artur d'Avila Garcez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.14556"
  },
  {
    "id": "arXiv:2107.00637",
    "title": "Generalization and Robustness Implications in Object-Centric Learning",
    "abstract": "Comments: Published at ICML 2022",
    "descriptor": "\nComments: Published at ICML 2022\n",
    "authors": [
      "Andrea Dittadi",
      "Samuele Papa",
      "Michele De Vita",
      "Bernhard Sch\u00f6lkopf",
      "Ole Winther",
      "Francesco Locatello"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.00637"
  },
  {
    "id": "arXiv:2107.05762",
    "title": "Strategic Instrumental Variable Regression: Recovering Causal  Relationships From Strategic Responses",
    "abstract": "Comments: In the 39th International Conference on Machine Learning (ICML 2022)",
    "descriptor": "\nComments: In the 39th International Conference on Machine Learning (ICML 2022)\n",
    "authors": [
      "Keegan Harris",
      "Daniel Ngo",
      "Logan Stapleton",
      "Hoda Heidari",
      "Zhiwei Steven Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.05762"
  },
  {
    "id": "arXiv:2107.08543",
    "title": "Zero-Shot Domain Adaptation in CT Segmentation by Filtered Back  Projection Augmentation",
    "abstract": "Comments: table fixed",
    "descriptor": "\nComments: table fixed\n",
    "authors": [
      "Talgat Saparov",
      "Anvar Kurmukov",
      "Boris Shirokikh",
      "Mikhail Belyaev"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.08543"
  },
  {
    "id": "arXiv:2107.09546",
    "title": "Responsible and Regulatory Conform Machine Learning for Medicine: A  Survey of Challenges and Solutions",
    "abstract": "Responsible and Regulatory Conform Machine Learning for Medicine: A  Survey of Challenges and Solutions",
    "descriptor": "",
    "authors": [
      "Eike Petersen",
      "Yannik Potdevin",
      "Esfandiar Mohammadi",
      "Stephan Zidowitz",
      "Sabrina Breyer",
      "Dirk Nowotka",
      "Sandra Henn",
      "Ludwig Pechmann",
      "Martin Leucker",
      "Philipp Rostalski",
      "Christian Herzog"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2107.09546"
  },
  {
    "id": "arXiv:2107.11769",
    "title": "ReDAL: Region-based and Diversity-aware Active Learning for Point Cloud  Semantic Segmentation",
    "abstract": "Comments: Accepted by ICCV 2021. The code is available at this https URL",
    "descriptor": "\nComments: Accepted by ICCV 2021. The code is available at this https URL\n",
    "authors": [
      "Tsung-Han Wu",
      "Yueh-Cheng Liu",
      "Yu-Kai Huang",
      "Hsin-Ying Lee",
      "Hung-Ting Su",
      "Ping-Chia Huang",
      "Winston H. Hsu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.11769"
  },
  {
    "id": "arXiv:2107.13137",
    "title": "Unsupervised Monocular Depth Estimation in Highly Complex Environments",
    "abstract": "Comments: Accepted by IEEE Transactions on Emerging Topics in Computational Intelligence",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Emerging Topics in Computational Intelligence\n",
    "authors": [
      "Chaoqiang Zhao",
      "Yang Tang",
      "Qiyu Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.13137"
  },
  {
    "id": "arXiv:2108.00980",
    "title": "Neuromechanical model-based adaptive control of bi-lateral ankle  exoskeletons: biological joint torque and electromyogram reduction across  walking conditions",
    "abstract": "Comments: 16 pages, 12 figures, 1 table",
    "descriptor": "\nComments: 16 pages, 12 figures, 1 table\n",
    "authors": [
      "Guillaume Durandau",
      "Wolfgang Rampeltshammer",
      "Herman van der Kooij",
      "Massimo Sartori"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2108.00980"
  },
  {
    "id": "arXiv:2108.04303",
    "title": "Canonical Noise Distributions and Private Hypothesis Tests",
    "abstract": "Comments: 25 pages + references and appendix. 4 figues",
    "descriptor": "\nComments: 25 pages + references and appendix. 4 figues\n",
    "authors": [
      "Jordan Awan",
      "Salil Vadhan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2108.04303"
  },
  {
    "id": "arXiv:2108.06717",
    "title": "Time Delay Estimation of Traffic Congestion Propagation based on  Transfer Entropy",
    "abstract": "Time Delay Estimation of Traffic Congestion Propagation based on  Transfer Entropy",
    "descriptor": "",
    "authors": [
      "YongKyung Oh",
      "JiIn Kwak",
      "JuYeong Lee",
      "Sungil Kim"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2108.06717"
  },
  {
    "id": "arXiv:2108.06771",
    "title": "NPBDREG: Uncertainty Assessment in Diffeomorphic Brain MRI Registration  using a Non-parametric Bayesian Deep-Learning Based Approach",
    "abstract": "Comments: To appear in Computerized Medical Imaging and Graphics, DOI: this https URL This is an extension representing a more comprehensive work extending preliminary work presented at arXiv:2008.03949",
    "descriptor": "\nComments: To appear in Computerized Medical Imaging and Graphics, DOI: this https URL This is an extension representing a more comprehensive work extending preliminary work presented at arXiv:2008.03949\n",
    "authors": [
      "Samah Khawaled",
      "Moti Freiman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.06771"
  },
  {
    "id": "arXiv:2108.08798",
    "title": "Field Trace Polynomial Codes for Secure Distributed Matrix  Multiplication",
    "abstract": "Field Trace Polynomial Codes for Secure Distributed Matrix  Multiplication",
    "descriptor": "",
    "authors": [
      "Roberto Assis Machado",
      "Rafael G. L. D'Oliveira",
      "Salim El Rouayheb",
      "Daniel Heinlein"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2108.08798"
  },
  {
    "id": "arXiv:2108.10097",
    "title": "Graph Attention MLP with Reliable Label Utilization",
    "abstract": "Comments: 12 pages, 4 figures",
    "descriptor": "\nComments: 12 pages, 4 figures\n",
    "authors": [
      "Wentao Zhang",
      "Ziqi Yin",
      "Zeang Sheng",
      "Wen Ouyang",
      "Xiaosen Li",
      "Yangyu Tao",
      "Zhi Yang",
      "Bin Cui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.10097"
  },
  {
    "id": "arXiv:2108.12828",
    "title": "MEDIC: A Multi-Task Learning Dataset for Disaster Image Classification",
    "abstract": "Comments: Multi-task Learning, Social media images, Image Classification, Natural disasters, Crisis Informatics, Deep learning, Dataset",
    "descriptor": "\nComments: Multi-task Learning, Social media images, Image Classification, Natural disasters, Crisis Informatics, Deep learning, Dataset\n",
    "authors": [
      "Firoj Alam",
      "Tanvirul Alam",
      "Md. Arid Hasan",
      "Abul Hasnat",
      "Muhammad Imran",
      "Ferda Ofli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2108.12828"
  },
  {
    "id": "arXiv:2109.02035",
    "title": "Variational Physics Informed Neural Networks: the role of quadratures  and test functions",
    "abstract": "Comments: 20 pages, 22 figures",
    "descriptor": "\nComments: 20 pages, 22 figures\n",
    "authors": [
      "Stefano Berrone",
      "Claudio Canuto",
      "Moreno Pintore"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.02035"
  },
  {
    "id": "arXiv:2109.05233",
    "title": "AdaK-NER: An Adaptive Top-K Approach for Named Entity Recognition with  Incomplete Annotations",
    "abstract": "AdaK-NER: An Adaptive Top-K Approach for Named Entity Recognition with  Incomplete Annotations",
    "descriptor": "",
    "authors": [
      "Hongtao Ruan",
      "Liying Zheng",
      "Peixian Hu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.05233"
  },
  {
    "id": "arXiv:2109.05742",
    "title": "Domain Generalization for Medical Image Segmentation via Hierarchical  Consistency Regularization",
    "abstract": "Domain Generalization for Medical Image Segmentation via Hierarchical  Consistency Regularization",
    "descriptor": "",
    "authors": [
      "Yijun Yang",
      "Shujun Wang",
      "Lei Zhu",
      "Pheng-Ann Heng",
      "Lequan Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.05742"
  },
  {
    "id": "arXiv:2109.06429",
    "title": "Robust Inverse Framework using Knowledge-guided Self-Supervised  Learning: An application to Hydrology",
    "abstract": "Comments: Accepted at KDD 2022",
    "descriptor": "\nComments: Accepted at KDD 2022\n",
    "authors": [
      "Rahul Ghosh",
      "Arvind Renganathan",
      "Kshitij Tayal",
      "Xiang Li",
      "Ankush Khandelwal",
      "Xiaowei Jia",
      "Chris Duffy",
      "John Neiber",
      "Vipin Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06429"
  },
  {
    "id": "arXiv:2109.08026",
    "title": "EVAGAN: Evasion Generative Adversarial Network for Low Data Regimes",
    "abstract": "Comments: 12 pages, 10 figures",
    "descriptor": "\nComments: 12 pages, 10 figures\n",
    "authors": [
      "Rizwan Hamid Randhawa",
      "Nauman Aslam",
      "Mohammad Alauthman",
      "Husnain Rafiq"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.08026"
  },
  {
    "id": "arXiv:2109.09461",
    "title": "Machine-Learning Side-Channel Attacks on the GALACTICS Constant-Time  Implementation of BLISS",
    "abstract": "Comments: 23 pages, 4 Figures, 7 algorithms",
    "descriptor": "\nComments: 23 pages, 4 Figures, 7 algorithms\n",
    "authors": [
      "Soundes Marzougui",
      "Nils Wisiol",
      "Patrick Gersch",
      "Juliane Kr\u00e4mer",
      "Jean-Pierre Seifert"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.09461"
  },
  {
    "id": "arXiv:2110.04157",
    "title": "Velocity Level Approximation of Pressure Field Contact Patches",
    "abstract": "Comments: 8 pages, 10 figures. Supplementary video can be found at this https URL",
    "descriptor": "\nComments: 8 pages, 10 figures. Supplementary video can be found at this https URL\n",
    "authors": [
      "Joseph Masterjohn",
      "Damrong Guoy",
      "John Shepherd",
      "Alejandro Castro"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2110.04157"
  },
  {
    "id": "arXiv:2110.05007",
    "title": "Boosting Fast Adversarial Training with Learnable Adversarial  Initialization",
    "abstract": "Comments: Accepted TIP",
    "descriptor": "\nComments: Accepted TIP\n",
    "authors": [
      "Xiaojun Jia",
      "Yong Zhang",
      "Baoyuan Wu",
      "Jue Wang",
      "Xiaochun Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05007"
  },
  {
    "id": "arXiv:2110.06717",
    "title": "On the Parameter Combinations That Matter and on Those That do Not",
    "abstract": "Comments: 47 pages, 23 figures, 4 tables, submitted to PNAS Nexus, revised and expanded in response to reviewers' comments",
    "descriptor": "\nComments: 47 pages, 23 figures, 4 tables, submitted to PNAS Nexus, revised and expanded in response to reviewers' comments\n",
    "authors": [
      "Nikolaos Evangelou",
      "Noah J. Wichrowski",
      "George A. Kevrekidis",
      "Felix Dietrich",
      "Mahdi Kooshkbaghi",
      "Sarah McFann",
      "Ioannis G. Kevrekidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.06717"
  },
  {
    "id": "arXiv:2110.06892",
    "title": "TAG: Toward Accurate Social Media Content Tagging with a Concept Graph",
    "abstract": "Comments: Accepted by ACM SIGKDD 2022",
    "descriptor": "\nComments: Accepted by ACM SIGKDD 2022\n",
    "authors": [
      "Jiuding Yang",
      "Weidong Guo",
      "Bang Liu",
      "Yakun Yu",
      "Chaoyue Wang",
      "Jinwen Luo",
      "Linglong Kong",
      "Di Niu",
      "Zhen Wen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.06892"
  },
  {
    "id": "arXiv:2110.11088",
    "title": "RoMA: a Method for Neural Network Robustness Measurement and Assessment",
    "abstract": "RoMA: a Method for Neural Network Robustness Measurement and Assessment",
    "descriptor": "",
    "authors": [
      "Natan Levy",
      "Guy Katz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.11088"
  },
  {
    "id": "arXiv:2110.12311",
    "title": "Vector Optimization with Stochastic Bandit Feedback",
    "abstract": "Comments: 28 pages, 3 tables, 1 figure",
    "descriptor": "\nComments: 28 pages, 3 tables, 1 figure\n",
    "authors": [
      "\u00c7a\u011f\u0131n Ararat",
      "Cem Tekin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.12311"
  },
  {
    "id": "arXiv:2111.02357",
    "title": "Multivariate feature ranking of gene expression data",
    "abstract": "Multivariate feature ranking of gene expression data",
    "descriptor": "",
    "authors": [
      "Fernando Jim\u00e9nez",
      "Gracia S\u00e1nchez",
      "Jos\u00e9 Palma",
      "Luis Miralles-Pechu\u00e1n",
      "Juan Bot\u00eda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.02357"
  },
  {
    "id": "arXiv:2111.04522",
    "title": "Terahertz Wireless Channels: A Holistic Survey on Measurement, Modeling,  and Analysis",
    "abstract": "Comments: to appear in IEEE Communications Surveys and Tutorials",
    "descriptor": "\nComments: to appear in IEEE Communications Surveys and Tutorials\n",
    "authors": [
      "Chong Han",
      "Yiqin Wang",
      "Yuanbo Li",
      "Yi Chen",
      "Naveed A. Abbasi",
      "Thomas K\u00fcrner",
      "Andreas F. Molisch"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.04522"
  },
  {
    "id": "arXiv:2111.05944",
    "title": "Multi-Objective Optimization for Value-Sensitive and Sustainable Basket  Recommendations",
    "abstract": "Comments: Second Draft, merged appendix to main text, stressed the importance of straight-through estimators for fractional decoupling, updated nomenclature and references",
    "descriptor": "\nComments: Second Draft, merged appendix to main text, stressed the importance of straight-through estimators for fractional decoupling, updated nomenclature and references\n",
    "authors": [
      "Thomas Asikis"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.05944"
  },
  {
    "id": "arXiv:2111.06628",
    "title": "Learning to Break Deep Perceptual Hashing: The Use Case NeuralHash",
    "abstract": "Comments: Accepted by ACM FAccT 2022 as Oral",
    "descriptor": "\nComments: Accepted by ACM FAccT 2022 as Oral\n",
    "authors": [
      "Lukas Struppek",
      "Dominik Hintersdorf",
      "Daniel Neider",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.06628"
  },
  {
    "id": "arXiv:2111.11926",
    "title": "An Educated Warm Start For Deep Image Prior-Based Micro CT  Reconstruction",
    "abstract": "An Educated Warm Start For Deep Image Prior-Based Micro CT  Reconstruction",
    "descriptor": "",
    "authors": [
      "Riccardo Barbano",
      "Johannes Leuschner",
      "Maximilian Schmidt",
      "Alexander Denker",
      "Andreas Hauptmann",
      "Peter Maa\u00df",
      "Bangti Jin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.11926"
  },
  {
    "id": "arXiv:2111.12284",
    "title": "A Self-Supervised Automatic Post-Editing Data Generation Tool",
    "abstract": "Comments: Accepted for DataPerf workshop at ICML 2022",
    "descriptor": "\nComments: Accepted for DataPerf workshop at ICML 2022\n",
    "authors": [
      "Hyeonseok Moon",
      "Chanjun Park",
      "Sugyeong Eo",
      "Jaehyung Seo",
      "SeungJun Lee",
      "Heuiseok Lim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.12284"
  },
  {
    "id": "arXiv:2111.13384",
    "title": "EOLANG and $\\varphi$-calculus",
    "abstract": "EOLANG and $\\varphi$-calculus",
    "descriptor": "",
    "authors": [
      "Yegor Bugayenko"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2111.13384"
  },
  {
    "id": "arXiv:2111.14737",
    "title": "Beyond Time-Average Convergence: Near-Optimal Uncoupled Online Learning  via Clairvoyant Multiplicative Weights Update",
    "abstract": "Comments: Expanded on the uncoupled online nature of the dynamics",
    "descriptor": "\nComments: Expanded on the uncoupled online nature of the dynamics\n",
    "authors": [
      "Georgios Piliouras",
      "Ryann Sim",
      "Stratis Skoulakis"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2111.14737"
  },
  {
    "id": "arXiv:2112.00881",
    "title": "Learning Invariant Representations with Missing Data",
    "abstract": "Comments: CLeaR (Causal Learning and Reasoning) 2022",
    "descriptor": "\nComments: CLeaR (Causal Learning and Reasoning) 2022\n",
    "authors": [
      "Mark Goldstein",
      "J\u00f6rn-Henrik Jacobsen",
      "Olina Chau",
      "Adriel Saporta",
      "Aahlad Puli",
      "Rajesh Ranganath",
      "Andrew C. Miller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.00881"
  },
  {
    "id": "arXiv:2112.01174",
    "title": "Multi-task Self-distillation for Graph-based Semi-Supervised Learning",
    "abstract": "Multi-task Self-distillation for Graph-based Semi-Supervised Learning",
    "descriptor": "",
    "authors": [
      "Yating Ren",
      "Junzhong Ji",
      "Lingfeng Niu",
      "Minglong Lei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01174"
  },
  {
    "id": "arXiv:2112.04330",
    "title": "Estimation in Rotationally Invariant Generalized Linear Models via  Approximate Message Passing",
    "abstract": "Comments: 35 pages, 8 figures, to appear in International Conference on Machine Learning (ICML), 2022",
    "descriptor": "\nComments: 35 pages, 8 figures, to appear in International Conference on Machine Learning (ICML), 2022\n",
    "authors": [
      "Ramji Venkataramanan",
      "Kevin K\u00f6gler",
      "Marco Mondelli"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2112.04330"
  },
  {
    "id": "arXiv:2112.11181",
    "title": "Achievable Rate Maximization for Underlay Spectrum Sharing MIMO System  with Intelligent Reflecting Surface",
    "abstract": "Comments: 5 pages, 5 figures. IEEE Wireless Communications Letters, 2022",
    "descriptor": "\nComments: 5 pages, 5 figures. IEEE Wireless Communications Letters, 2022\n",
    "authors": [
      "Vaibhav Kumar",
      "Mark Flanagan",
      "Rui Zhang",
      "Le-Nam Tran"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.11181"
  },
  {
    "id": "arXiv:2112.13593",
    "title": "Multi-modal Attention Network for Stock Movements Prediction",
    "abstract": "Multi-modal Attention Network for Stock Movements Prediction",
    "descriptor": "",
    "authors": [
      "Shwai He",
      "Shi Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Trading and Market Microstructure (q-fin.TR)"
    ],
    "url": "https://arxiv.org/abs/2112.13593"
  },
  {
    "id": "arXiv:2201.02588",
    "title": "FogAdapt: Self-Supervised Domain Adaptation for Semantic Segmentation of  Foggy Images",
    "abstract": "Comments: Accepted at Elsevier Journal of Neurocomputing",
    "descriptor": "\nComments: Accepted at Elsevier Journal of Neurocomputing\n",
    "authors": [
      "Javed Iqbal",
      "Rehan Hafiz",
      "Mohsen Ali"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.02588"
  },
  {
    "id": "arXiv:2201.03809",
    "title": "Music2Video: Automatic Generation of Music Video with fusion of audio  and text",
    "abstract": "Music2Video: Automatic Generation of Music Video with fusion of audio  and text",
    "descriptor": "",
    "authors": [
      "Yoonjeon Kim",
      "Joel Jang",
      "Sumin Shin"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Graphics (cs.GR)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2201.03809"
  },
  {
    "id": "arXiv:2201.05461",
    "title": "RecoMed: A Knowledge-Aware Recommender System for Hypertension  Medications",
    "abstract": "RecoMed: A Knowledge-Aware Recommender System for Hypertension  Medications",
    "descriptor": "",
    "authors": [
      "Maryam Sajde",
      "Hamed Malek",
      "Mehran Mohsenzadeh"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.05461"
  },
  {
    "id": "arXiv:2201.05609",
    "title": "Multilingual Open Text Release 1: Public Domain News in 44 Languages",
    "abstract": "Comments: Submitted to LREC 2022",
    "descriptor": "\nComments: Submitted to LREC 2022\n",
    "authors": [
      "Chester Palen-Michel",
      "June Kim",
      "Constantine Lignos"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.05609"
  },
  {
    "id": "arXiv:2201.06247",
    "title": "Contrastive Regularization for Semi-Supervised Learning",
    "abstract": "Comments: CVPR'22 Workshop on Learning with Limited Labelled Data for Image and Video Understanding",
    "descriptor": "\nComments: CVPR'22 Workshop on Learning with Limited Labelled Data for Image and Video Understanding\n",
    "authors": [
      "Doyup Lee",
      "Sungwoong Kim",
      "Ildoo Kim",
      "Yeongjae Cheon",
      "Minsu Cho",
      "Wook-Shin Han"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.06247"
  },
  {
    "id": "arXiv:2201.06289",
    "title": "The CLEAR Benchmark: Continual LEArning on Real-World Imagery",
    "abstract": "Comments: Project site: this https URL",
    "descriptor": "\nComments: Project site: this https URL\n",
    "authors": [
      "Zhiqiu Lin",
      "Jia Shi",
      "Deepak Pathak",
      "Deva Ramanan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.06289"
  },
  {
    "id": "arXiv:2201.08443",
    "title": "Diversifying the Genomic Data Science Research Community",
    "abstract": "Comments: 42 pages, 3 figures",
    "descriptor": "\nComments: 42 pages, 3 figures\n",
    "authors": [
      "Genomic Data Science Community Network",
      "Rosa Alcazar",
      "Maria Alvarez",
      "Rachel Arnold",
      "Mentewab Ayalew",
      "Lyle G. Best",
      "Michael C. Campbell",
      "Kamal Chowdhury",
      "Katherine E. L. Cox",
      "Christina Daulton",
      "Youping Deng",
      "Carla Easter",
      "Karla Fuller",
      "Shazia Tabassum Hakim",
      "Ava M. Hoffman",
      "Natalie Kucher",
      "Andrew Lee",
      "Joslynn Lee",
      "Jeffrey T. Leek",
      "Robert Meller",
      "Loyda B. M\u00e9ndez",
      "Miguel P. M\u00e9ndez-Gonz\u00e1lez",
      "Stephen Mosher",
      "Michele Nishiguchi",
      "Siddharth Pratap",
      "Tiffany Rolle",
      "Sourav Roy",
      "Rachel Saidi",
      "Michael C. Schatz",
      "Shurjo Sen",
      "James Sniezek",
      "Edu Suarez Martinez",
      "Frederick Tan",
      "Jennifer Vessio",
      "Karriem Watson",
      "Wendy Westbroek"
    ],
    "subjectives": [
      "Other Quantitative Biology (q-bio.OT)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2201.08443"
  },
  {
    "id": "arXiv:2201.09180",
    "title": "Prescribed Performance Adaptive Fixed-Time Attitude Tracking Control of  a 3-DOF Helicopter with Small Overshoot",
    "abstract": "Comments: 6 pages, 4 figures",
    "descriptor": "\nComments: 6 pages, 4 figures\n",
    "authors": [
      "Xidong Wang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.09180"
  },
  {
    "id": "arXiv:2201.11578",
    "title": "KRCORE: a microsecond-scale RDMA control plane for elastic computing",
    "abstract": "Comments: To appear in USENIX ATC'2022 (this https URL)",
    "descriptor": "\nComments: To appear in USENIX ATC'2022 (this https URL)\n",
    "authors": [
      "Xingda Wei",
      "Fangming Lu",
      "Rong Chen",
      "Haibo Chen"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2201.11578"
  },
  {
    "id": "arXiv:2201.12179",
    "title": "Plug & Play Attacks: Towards Robust and Flexible Model Inversion Attacks",
    "abstract": "Comments: Accepted by ICML 2022",
    "descriptor": "\nComments: Accepted by ICML 2022\n",
    "authors": [
      "Lukas Struppek",
      "Dominik Hintersdorf",
      "Antonio De Almeida Correia",
      "Antonia Adler",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.12179"
  },
  {
    "id": "arXiv:2201.12383",
    "title": "Bounding Training Data Reconstruction in Private (Deep) Learning",
    "abstract": "Bounding Training Data Reconstruction in Private (Deep) Learning",
    "descriptor": "",
    "authors": [
      "Chuan Guo",
      "Brian Karrer",
      "Kamalika Chaudhuri",
      "Laurens van der Maaten"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2201.12383"
  },
  {
    "id": "arXiv:2201.12431",
    "title": "Neuro-Symbolic Language Modeling with Automaton-augmented Retrieval",
    "abstract": "Comments: Accepted to ICML'2022. Code and models are available at this https URL",
    "descriptor": "\nComments: Accepted to ICML'2022. Code and models are available at this https URL\n",
    "authors": [
      "Uri Alon",
      "Frank F. Xu",
      "Junxian He",
      "Sudipta Sengupta",
      "Dan Roth",
      "Graham Neubig"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12431"
  },
  {
    "id": "arXiv:2201.12460",
    "title": "On the Global Convergence of Particle Swarm Optimization Methods",
    "abstract": "Comments: 28 pages, 4 figures",
    "descriptor": "\nComments: 28 pages, 4 figures\n",
    "authors": [
      "Hui Huang",
      "Jinniao Qiu",
      "Konstantin Riedl"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2201.12460"
  },
  {
    "id": "arXiv:2202.00753",
    "title": "ADG-Pose: Automated Dataset Generation for Real-World Human Pose  Estimation",
    "abstract": "Comments: The first two authors (G. Alinezhad Noghre and A. Danesh Pazho) have equal contribution. Conference: International Conference on Pattern Recognition and Artificial Intelligence",
    "descriptor": "\nComments: The first two authors (G. Alinezhad Noghre and A. Danesh Pazho) have equal contribution. Conference: International Conference on Pattern Recognition and Artificial Intelligence\n",
    "authors": [
      "Ghazal Alinezhad Noghre",
      "Armin Danesh Pazho",
      "Justin Sanchez",
      "Nathan Hewitt",
      "Christopher Neff",
      "Hamed Tabkhi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.00753"
  },
  {
    "id": "arXiv:2202.01361",
    "title": "Generative Flow Networks for Discrete Probabilistic Modeling",
    "abstract": "Comments: Accepted by ICML 2022",
    "descriptor": "\nComments: Accepted by ICML 2022\n",
    "authors": [
      "Dinghuai Zhang",
      "Nikolay Malkin",
      "Zhen Liu",
      "Alexandra Volokhova",
      "Aaron Courville",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.01361"
  },
  {
    "id": "arXiv:2202.08312",
    "title": "Improved Differential Privacy for SGD via Optimal Private Linear  Operators on Adaptive Streams",
    "abstract": "Comments: 32 pages, 6 figures. Associated code at this https URL",
    "descriptor": "\nComments: 32 pages, 6 figures. Associated code at this https URL\n",
    "authors": [
      "Sergey Denisov",
      "Brendan McMahan",
      "Keith Rush",
      "Adam Smith",
      "Abhradeep Guha Thakurta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.08312"
  },
  {
    "id": "arXiv:2202.11009",
    "title": "Computing Multiple Image Reconstructions with a Single Hypernetwork",
    "abstract": "Comments: Accepted for publication at the Journal of Machine Learning for Biomedical Imaging (MELBA) this https URL",
    "descriptor": "\nComments: Accepted for publication at the Journal of Machine Learning for Biomedical Imaging (MELBA) this https URL\n",
    "authors": [
      "Alan Q. Wang",
      "Adrian V. Dalca",
      "Mert R. Sabuncu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.11009"
  },
  {
    "id": "arXiv:2202.11204",
    "title": "Study of Feature Importance for Quantum Machine Learning Models",
    "abstract": "Comments: 21 pages, 15 figures, 1 Table",
    "descriptor": "\nComments: 21 pages, 15 figures, 1 Table\n",
    "authors": [
      "Aaron Baughman",
      "Kavitha Yogaraj",
      "Raja Hebbar",
      "Sudeep Ghosh",
      "Rukhsan Ul Haq",
      "Yoshika Chhabra"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.11204"
  },
  {
    "id": "arXiv:2202.11425",
    "title": "Multi-view Intent Disentangle Graph Networks for Bundle Recommendation",
    "abstract": "Multi-view Intent Disentangle Graph Networks for Bundle Recommendation",
    "descriptor": "",
    "authors": [
      "Sen Zhao",
      "Wei Wei",
      "Ding Zou",
      "Xianling Mao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.11425"
  },
  {
    "id": "arXiv:2202.13291",
    "title": "A Simple Discretization Scheme for Gain Matrix Conditioning",
    "abstract": "Comments: Revised manuscript accepted in AdCONIP 2022",
    "descriptor": "\nComments: Revised manuscript accepted in AdCONIP 2022\n",
    "authors": [
      "Daniel L. O'Connor",
      "Lim C. Siang",
      "Shams Elnawawi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.13291"
  },
  {
    "id": "arXiv:2203.00418",
    "title": "Recovery of Missing Sensor Data by Reconstructing Time-varying Graph  Signals",
    "abstract": "Comments: Five pages, two figures, Accepted at EUSIPCO 2022",
    "descriptor": "\nComments: Five pages, two figures, Accepted at EUSIPCO 2022\n",
    "authors": [
      "Anindya Mondal",
      "Mayukhmali Das",
      "Aditi Chatterjee",
      "Palaniandavar Venkateswaran"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.00418"
  },
  {
    "id": "arXiv:2203.01825",
    "title": "What Makes Transfer Learning Work For Medical Images: Feature Reuse &  Other Factors",
    "abstract": "Comments: Originally published at CVPR 2022",
    "descriptor": "\nComments: Originally published at CVPR 2022\n",
    "authors": [
      "Christos Matsoukas",
      "Johan Fredin Haslum",
      "Moein Sorkhei",
      "Magnus S\u00f6derberg",
      "Kevin Smith"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.01825"
  },
  {
    "id": "arXiv:2203.01827",
    "title": "Democratic Governance and International Research Collaboration: A  Longitudinal Analysis of the Global Science Network",
    "abstract": "Democratic Governance and International Research Collaboration: A  Longitudinal Analysis of the Global Science Network",
    "descriptor": "",
    "authors": [
      "Travis A. Whetsell"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Digital Libraries (cs.DL)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2203.01827"
  },
  {
    "id": "arXiv:2203.01928",
    "title": "Label-Free Explainability for Unsupervised Models",
    "abstract": "Comments: Presented at ICML 2022",
    "descriptor": "\nComments: Presented at ICML 2022\n",
    "authors": [
      "Jonathan Crabb\u00e9",
      "Mihaela van der Schaar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.01928"
  },
  {
    "id": "arXiv:2203.03279",
    "title": "Evaluating State of the Art, Forecasting Ensembles- and Meta-learning  Strategies for Model Fusion",
    "abstract": "Evaluating State of the Art, Forecasting Ensembles- and Meta-learning  Strategies for Model Fusion",
    "descriptor": "",
    "authors": [
      "Pieter Cawood",
      "Terence van Zyl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.03279"
  },
  {
    "id": "arXiv:2203.03816",
    "title": "Quantum Volume in Practice: What Users Can Expect from NISQ Devices",
    "abstract": "Comments: 27 pages; v4 includes additional results and revisions",
    "descriptor": "\nComments: 27 pages; v4 includes additional results and revisions\n",
    "authors": [
      "Elijah Pelofske",
      "Andreas B\u00e4rtschi",
      "Stephan Eidenbenz"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2203.03816"
  },
  {
    "id": "arXiv:2203.07057",
    "title": "Self-Promoted Supervision for Few-Shot Transformer",
    "abstract": "Comments: Code is available at this https URL",
    "descriptor": "\nComments: Code is available at this https URL\n",
    "authors": [
      "Bowen Dong",
      "Pan Zhou",
      "Shuicheng Yan",
      "Wangmeng Zuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07057"
  },
  {
    "id": "arXiv:2203.08134",
    "title": "Privacy-Aware Compression for Federated Data Analysis",
    "abstract": "Privacy-Aware Compression for Federated Data Analysis",
    "descriptor": "",
    "authors": [
      "Kamalika Chaudhuri",
      "Chuan Guo",
      "Mike Rabbat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.08134"
  },
  {
    "id": "arXiv:2203.12616",
    "title": "Unsupervised Pre-Training on Patient Population Graphs for Patient-Level  Predictions",
    "abstract": "Comments: 10 pages, 1 figure, 3 tables",
    "descriptor": "\nComments: 10 pages, 1 figure, 3 tables\n",
    "authors": [
      "Chantal Pellegrini",
      "Anees Kazi",
      "Nassir Navab"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.12616"
  },
  {
    "id": "arXiv:2203.13887",
    "title": "Automatic Debiased Machine Learning for Dynamic Treatment Effects and  General Nested Functionals",
    "abstract": "Automatic Debiased Machine Learning for Dynamic Treatment Effects and  General Nested Functionals",
    "descriptor": "",
    "authors": [
      "Victor Chernozhukov",
      "Whitney Newey",
      "Rahul Singh",
      "Vasilis Syrgkanis"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.13887"
  },
  {
    "id": "arXiv:2203.15041",
    "title": "Socially Compliant Navigation Dataset (SCAND): A Large-Scale Dataset of  Demonstrations for Social Navigation",
    "abstract": "Socially Compliant Navigation Dataset (SCAND): A Large-Scale Dataset of  Demonstrations for Social Navigation",
    "descriptor": "",
    "authors": [
      "Haresh Karnan",
      "Anirudh Nair",
      "Xuesu Xiao",
      "Garrett Warnell",
      "Soeren Pirk",
      "Alexander Toshev",
      "Justin Hart",
      "Joydeep Biswas",
      "Peter Stone"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.15041"
  },
  {
    "id": "arXiv:2203.16093",
    "title": "Beamforming Optimization for Active Intelligent Reflecting Surface-Aided  SWIPT",
    "abstract": "Comments: 32 pages, 10 figures, submitted to IEEE journal for possible publication",
    "descriptor": "\nComments: 32 pages, 10 figures, submitted to IEEE journal for possible publication\n",
    "authors": [
      "Ying Gao",
      "Qingqing Wu",
      "Guangchi Zhang",
      "Wen Chen",
      "Derrick Wing Kwan Ng",
      "Marco Di Renzo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.16093"
  },
  {
    "id": "arXiv:2203.16434",
    "title": "TubeDETR: Spatio-Temporal Video Grounding with Transformers",
    "abstract": "Comments: Updated vIoU results compared to the CVPR'22 camera-ready version; 17 pages; 8 figures",
    "descriptor": "\nComments: Updated vIoU results compared to the CVPR'22 camera-ready version; 17 pages; 8 figures\n",
    "authors": [
      "Antoine Yang",
      "Antoine Miech",
      "Josef Sivic",
      "Ivan Laptev",
      "Cordelia Schmid"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.16434"
  },
  {
    "id": "arXiv:2203.16616",
    "title": "Knowledge-based Entity Prediction for Improved Machine Perception in  Autonomous Systems",
    "abstract": "Comments: 6 pages, 4 figures, in IEEE Intelligent Systems, 2022",
    "descriptor": "\nComments: 6 pages, 4 figures, in IEEE Intelligent Systems, 2022\n",
    "authors": [
      "Ruwan Wickramarachchi",
      "Cory Henson",
      "Amit Sheth"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.16616"
  },
  {
    "id": "arXiv:2204.01050",
    "title": "Understanding the unstable convergence of gradient descent",
    "abstract": "Comments: Accepted to the 39th International Conference on Machine Learning (ICML 2022), Baltimore, Maryland, USA. Version 2 improves writing and presentation, adds discussion regarding concurrent works",
    "descriptor": "\nComments: Accepted to the 39th International Conference on Machine Learning (ICML 2022), Baltimore, Maryland, USA. Version 2 improves writing and presentation, adds discussion regarding concurrent works\n",
    "authors": [
      "Kwangjun Ahn",
      "Jingzhao Zhang",
      "Suvrit Sra"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.01050"
  },
  {
    "id": "arXiv:2204.02134",
    "title": "Scalable tube model predictive control of uncertain linear systems using  ellipsoidal sets",
    "abstract": "Comments: Submitted to International Journal of Robust and Nonlinear Control",
    "descriptor": "\nComments: Submitted to International Journal of Robust and Nonlinear Control\n",
    "authors": [
      "Anilkumar Parsi",
      "Andrea Iannelli",
      "Roy S. Smith"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2204.02134"
  },
  {
    "id": "arXiv:2204.02189",
    "title": "Automating Staged Rollout with Reinforcement Learning",
    "abstract": "Automating Staged Rollout with Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Shadow Pritchard",
      "Vidhyashree Nagaraju",
      "Lance Fiondella"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.02189"
  },
  {
    "id": "arXiv:2204.04962",
    "title": "IC-GVINS: A Robust, Real-time, INS-Centric GNSS-Visual-Inertial  Navigation System for Wheeled Robot",
    "abstract": "IC-GVINS: A Robust, Real-time, INS-Centric GNSS-Visual-Inertial  Navigation System for Wheeled Robot",
    "descriptor": "",
    "authors": [
      "Hailiang Tang",
      "Tisheng Zhang",
      "Xiaoji Niu",
      "Jing Fan",
      "Jingnan Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.04962"
  },
  {
    "id": "arXiv:2204.05731",
    "title": "PyDTS: A Python Package for Discrete-Time Survival (Regularized)  Regression with Competing Risks",
    "abstract": "PyDTS: A Python Package for Discrete-Time Survival (Regularized)  Regression with Competing Risks",
    "descriptor": "",
    "authors": [
      "Tomer Meir",
      "Rom Gutman",
      "Malka Gorfine"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.05731"
  },
  {
    "id": "arXiv:2204.08323",
    "title": "Experimental twin-field quantum key distribution with flawed and  correlated sources",
    "abstract": "Comments: 16 pages, 7 figures, 8 tables. Comments are welcome!",
    "descriptor": "\nComments: 16 pages, 7 figures, 8 tables. Comments are welcome!\n",
    "authors": [
      "Jie Gu",
      "Xiao-Yu Cao",
      "Yao Fu",
      "Zong-Wu He",
      "Ze-Jie Yin",
      "Hua-Lei Yin",
      "Zeng-Bing Chen"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2204.08323"
  },
  {
    "id": "arXiv:2204.08663",
    "title": "Pre-training of Equivariant Graph Matching Networks with Conformation  Flexibility for Drug Binding",
    "abstract": "Pre-training of Equivariant Graph Matching Networks with Conformation  Flexibility for Drug Binding",
    "descriptor": "",
    "authors": [
      "Fang Wu",
      "Yinghui Jiang",
      "Shuting Jin",
      "Xurui Jin",
      "Xiangrong Liu",
      "Zhangming Niu",
      "Qiang Zhang",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2204.08663"
  },
  {
    "id": "arXiv:2204.12698",
    "title": "Multi-task Learning-based CSI Feedback Design in Multiple Scenarios",
    "abstract": "Comments: 30 pages, 12 figures, 9 Tables",
    "descriptor": "\nComments: 30 pages, 12 figures, 9 Tables\n",
    "authors": [
      "Xiangyi Li",
      "Jiajia Guo",
      "Chao-Kai Wen",
      "Shi Jin",
      "Shuangfeng Han"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.12698"
  },
  {
    "id": "arXiv:2204.12710",
    "title": "CREER: A Large-Scale Corpus for Relation Extraction and Entity  Recognition",
    "abstract": "CREER: A Large-Scale Corpus for Relation Extraction and Entity  Recognition",
    "descriptor": "",
    "authors": [
      "Yu-Siou Tang",
      "Chung-Hsien Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.12710"
  },
  {
    "id": "arXiv:2204.13638",
    "title": "Russian Texts Detoxification with Levenshtein Editing",
    "abstract": "Comments: Accepted to Dialogue 2022",
    "descriptor": "\nComments: Accepted to Dialogue 2022\n",
    "authors": [
      "Ilya Gusev"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.13638"
  },
  {
    "id": "arXiv:2205.00608",
    "title": "Physics-aware Reduced-order Modeling of Transonic Flow via  $\u03b2$-Variational Autoencoder",
    "abstract": "Physics-aware Reduced-order Modeling of Transonic Flow via  $\u03b2$-Variational Autoencoder",
    "descriptor": "",
    "authors": [
      "Yu-Eop Kang",
      "Sunwoong Yang",
      "Kwanjung Yee"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.00608"
  },
  {
    "id": "arXiv:2205.02293",
    "title": "Original or Translated? A Causal Analysis of the Impact of  Translationese on Machine Translation Performance",
    "abstract": "Comments: NAACL 2022 (Oral)",
    "descriptor": "\nComments: NAACL 2022 (Oral)\n",
    "authors": [
      "Jingwei Ni",
      "Zhijing Jin",
      "Markus Freitag",
      "Mrinmaya Sachan",
      "Bernhard Sch\u00f6lkopf"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.02293"
  },
  {
    "id": "arXiv:2205.05343",
    "title": "Learning Multitask Gaussian Bayesian Networks",
    "abstract": "Learning Multitask Gaussian Bayesian Networks",
    "descriptor": "",
    "authors": [
      "Shuai Liu",
      "Yixuan Qiu",
      "Baojuan Li",
      "Huaning Wang",
      "Xiangyu Chang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05343"
  },
  {
    "id": "arXiv:2205.06506",
    "title": "Collaborative Drug Discovery: Inference-level Data Protection  Perspective",
    "abstract": "Collaborative Drug Discovery: Inference-level Data Protection  Perspective",
    "descriptor": "",
    "authors": [
      "Balazs Pejo",
      "Mina Remeli",
      "Adam Arany",
      "Mathieu Galtier",
      "Gergely Acs"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.06506"
  },
  {
    "id": "arXiv:2205.07547",
    "title": "SQ-VAE: Variational Bayes on Discrete Representation with Self-annealed  Stochastic Quantization",
    "abstract": "Comments: 25 pages with 10 figures, accepted for publication in ICML 2022 (Our code is available at this https URL)",
    "descriptor": "\nComments: 25 pages with 10 figures, accepted for publication in ICML 2022 (Our code is available at this https URL)\n",
    "authors": [
      "Yuhta Takida",
      "Takashi Shibuya",
      "WeiHsiang Liao",
      "Chieh-Hsin Lai",
      "Junki Ohmura",
      "Toshimitsu Uesaka",
      "Naoki Murata",
      "Shusuke Takahashi",
      "Toshiyuki Kumakura",
      "Yuki Mitsufuji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.07547"
  },
  {
    "id": "arXiv:2205.08452",
    "title": "A Psychological Theory of Explainability",
    "abstract": "Comments: 15 pages, 3 figures, ICML 2022",
    "descriptor": "\nComments: 15 pages, 3 figures, ICML 2022\n",
    "authors": [
      "Scott Cheng-Hsin Yang",
      "Tomas Folke",
      "Patrick Shafto"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.08452"
  },
  {
    "id": "arXiv:2205.09351",
    "title": "Mip-NeRF RGB-D: Depth Assisted Fast Neural Radiance Fields",
    "abstract": "Mip-NeRF RGB-D: Depth Assisted Fast Neural Radiance Fields",
    "descriptor": "",
    "authors": [
      "Arnab Dey",
      "Yassine Ahmine",
      "Andrew I. Comport"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.09351"
  },
  {
    "id": "arXiv:2205.10047",
    "title": "The Sufficiency of Off-policyness: PPO is insufficient according to an  Off-policy Measure",
    "abstract": "The Sufficiency of Off-policyness: PPO is insufficient according to an  Off-policy Measure",
    "descriptor": "",
    "authors": [
      "Xing Chen",
      "Dongcui Diao",
      "Hechang Chen",
      "Hengshuai Yao",
      "Jielong Yang",
      "Haiyin Piao",
      "Zhixiao Sun",
      "Bei Jiang",
      "Yi Chang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.10047"
  },
  {
    "id": "arXiv:2205.10218",
    "title": "Learning Task-relevant Representations for Generalization via  Characteristic Functions of Reward Sequence Distributions",
    "abstract": "Comments: Accepted to KDD 2022",
    "descriptor": "\nComments: Accepted to KDD 2022\n",
    "authors": [
      "Rui Yang",
      "Jie Wang",
      "Zijie Geng",
      "Mingxuan Ye",
      "Shuiwang Ji",
      "Bin Li",
      "Feng Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.10218"
  },
  {
    "id": "arXiv:2205.10895",
    "title": "Contextual Information-Directed Sampling",
    "abstract": "Comments: Accepted at ICML 2022",
    "descriptor": "\nComments: Accepted at ICML 2022\n",
    "authors": [
      "Botao Hao",
      "Tor Lattimore",
      "Chao Qin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.10895"
  },
  {
    "id": "arXiv:2205.11648",
    "title": "Deep Representations for Time-varying Brain Datasets",
    "abstract": "Comments: ACM SIGKDD Conference on Knowledge Discovery and Data Mining, 2022",
    "descriptor": "\nComments: ACM SIGKDD Conference on Knowledge Discovery and Data Mining, 2022\n",
    "authors": [
      "Sikun Lin",
      "Shuyun Tang",
      "Scott Grafton",
      "Ambuj Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2205.11648"
  },
  {
    "id": "arXiv:2205.11916",
    "title": "Large Language Models are Zero-Shot Reasoners",
    "abstract": "Comments: Main update : PaLM(540B) experiment results added. Our code is available at this https URL",
    "descriptor": "\nComments: Main update : PaLM(540B) experiment results added. Our code is available at this https URL\n",
    "authors": [
      "Takeshi Kojima",
      "Shixiang Shane Gu",
      "Machel Reid",
      "Yutaka Matsuo",
      "Yusuke Iwasawa"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11916"
  },
  {
    "id": "arXiv:2205.13216",
    "title": "Aggregating Gradients in Encoded Domain for Federated Learning",
    "abstract": "Aggregating Gradients in Encoded Domain for Federated Learning",
    "descriptor": "",
    "authors": [
      "Dun Zeng",
      "Shiyu Liu",
      "Siqi Liang",
      "Zonghang Li",
      "Zenglin Xu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.13216"
  },
  {
    "id": "arXiv:2205.14014",
    "title": "What Dense Graph Do You Need for Self-Attention?",
    "abstract": "Comments: Accepted by ICML 2022. Code is available at this https URL",
    "descriptor": "\nComments: Accepted by ICML 2022. Code is available at this https URL\n",
    "authors": [
      "Yuxing Wang",
      "Chu-Tak Lee",
      "Qipeng Guo",
      "Zhangyue Yin",
      "Yunhua Zhou",
      "Xuanjing Huang",
      "Xipeng Qiu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.14014"
  },
  {
    "id": "arXiv:2205.14822",
    "title": "Exploring students' backtracking behaviors in digital textbooks and its  relationship to learning styles",
    "abstract": "Comments: I'm very sorry that there is a statistical error in the data shown in Fig.6 in the Result section",
    "descriptor": "\nComments: I'm very sorry that there is a statistical error in the data shown in Fig.6 in the Result section\n",
    "authors": [
      "Bo Jiang",
      "Meijun Gu",
      "Chengjiu Yin"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2205.14822"
  },
  {
    "id": "arXiv:2205.14970",
    "title": "Towards Personalized Bundle Creative Generation with Contrastive  Non-Autoregressive Decoding",
    "abstract": "Comments: SIGIR 2022 (short)",
    "descriptor": "\nComments: SIGIR 2022 (short)\n",
    "authors": [
      "Penghui Wei",
      "Shaoguo Liu",
      "Xuanhua Yang",
      "Liang Wang",
      "Bo Zheng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2205.14970"
  },
  {
    "id": "arXiv:2205.15059",
    "title": "Hilbert Curve Projection Distance for Distribution Comparison",
    "abstract": "Comments: 28 pages, 19 figures, add some references",
    "descriptor": "\nComments: 28 pages, 19 figures, add some references\n",
    "authors": [
      "Tao Li",
      "Cheng Meng",
      "Jun Yu",
      "Hongteng Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.15059"
  },
  {
    "id": "arXiv:2205.15060",
    "title": "Duplex Conversation: Towards Human-like Interaction in Spoken Dialogue  Systems",
    "abstract": "Comments: Accepted by KDD 2022, ADS track",
    "descriptor": "\nComments: Accepted by KDD 2022, ADS track\n",
    "authors": [
      "Ting-En Lin",
      "Yuchuan Wu",
      "Fei Huang",
      "Luo Si",
      "Jian Sun",
      "Yongbin Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.15060"
  },
  {
    "id": "arXiv:2205.15168",
    "title": "Subrank and Optimal Reduction of Scalar Multiplications to Generic  Tensors",
    "abstract": "Comments: Citation fix",
    "descriptor": "\nComments: Citation fix\n",
    "authors": [
      "Harm Derksen",
      "Visu Makam",
      "Jeroen Zuiddam"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Algebraic Geometry (math.AG)"
    ],
    "url": "https://arxiv.org/abs/2205.15168"
  },
  {
    "id": "arXiv:2205.15443",
    "title": "Dynamic Walking with Footstep Adaptation on the MIT Humanoid via Linear  Model Predictive Control",
    "abstract": "Dynamic Walking with Footstep Adaptation on the MIT Humanoid via Linear  Model Predictive Control",
    "descriptor": "",
    "authors": [
      "Yanran Ding",
      "Charles Khazoom",
      "Matthew Chignoli",
      "Sangbae Kim"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.15443"
  },
  {
    "id": "arXiv:2206.00065",
    "title": "FELARE: Fair Scheduling of Machine Learning Applications on  Heterogeneous Edge Systems",
    "abstract": "FELARE: Fair Scheduling of Machine Learning Applications on  Heterogeneous Edge Systems",
    "descriptor": "",
    "authors": [
      "Ali Mokhtari",
      "Pooyan Jamshidi",
      "Mohsen Amini Salehi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2206.00065"
  },
  {
    "id": "arXiv:2206.00730",
    "title": "The Phenomenon of Policy Churn",
    "abstract": "The Phenomenon of Policy Churn",
    "descriptor": "",
    "authors": [
      "Tom Schaul",
      "Andr\u00e9 Barreto",
      "John Quan",
      "Georg Ostrovski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.00730"
  },
  {
    "id": "arXiv:2206.01121",
    "title": "The Loop of the Rings: A Distributed Cooperative System",
    "abstract": "The Loop of the Rings: A Distributed Cooperative System",
    "descriptor": "",
    "authors": [
      "Arash Vaezi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.01121"
  },
  {
    "id": "arXiv:2206.01368",
    "title": "Density-Based Pruning of Drone Swarm Services",
    "abstract": "Comments: 10 pages, 9 figures. This is an accepted paper and it is going to appear in the Proceedings of the 2022 IEEE International Conference on Web Services (ICWS 2022)",
    "descriptor": "\nComments: 10 pages, 9 figures. This is an accepted paper and it is going to appear in the Proceedings of the 2022 IEEE International Conference on Web Services (ICWS 2022)\n",
    "authors": [
      "Balsam Alkouz",
      "Athman Bouguettaya",
      "Abdallah Lakhdari"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.01368"
  },
  {
    "id": "arXiv:2206.01612",
    "title": "OmniXAI: A Library for Explainable AI",
    "abstract": "Comments: Wait for the Github release. The name of the library may need to be changed due to legal concerns",
    "descriptor": "\nComments: Wait for the Github release. The name of the library may need to be changed due to legal concerns\n",
    "authors": [
      "Wenzhuo Yang",
      "Hung Le",
      "Silvio Savarese",
      "Steven C.H. Hoi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01612"
  },
  {
    "id": "arXiv:2206.01714",
    "title": "Compositional Visual Generation with Composable Diffusion Models",
    "abstract": "Comments: Project website: this https URL First three authors contributed equally",
    "descriptor": "\nComments: Project website: this https URL First three authors contributed equally\n",
    "authors": [
      "Nan Liu",
      "Shuang Li",
      "Yilun Du",
      "Antonio Torralba",
      "Joshua B. Tenenbaum"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01714"
  },
  {
    "id": "arXiv:2206.01775",
    "title": "Seamless Interaction Design with Coexistence and Cooperation Modes for  Robust Human-Robot Collaboration",
    "abstract": "Comments: Accepted by CASE 2022 Special Session on Adaptive and Resilient Cyber-Physical Manufacturing Networks",
    "descriptor": "\nComments: Accepted by CASE 2022 Special Session on Adaptive and Resilient Cyber-Physical Manufacturing Networks\n",
    "authors": [
      "Zhe Huang",
      "Ye-Ji Mun",
      "Xiang Li",
      "Yiqing Xie",
      "Ninghan Zhong",
      "Weihang Liang",
      "Junyi Geng",
      "Tan Chen",
      "Katherine Driggs-Campbell"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.01775"
  },
  {
    "id": "arXiv:2206.02284",
    "title": "Tagged-MRI Sequence to Audio Synthesis via Self Residual Attention  Guided Heterogeneous Translator",
    "abstract": "Comments: MICCAI 2022 (early accept)",
    "descriptor": "\nComments: MICCAI 2022 (early accept)\n",
    "authors": [
      "Xiaofeng Liu",
      "Fangxu Xing",
      "Jerry L. Prince",
      "Jiachen Zhuo",
      "Maureen Stone",
      "Georges El Fakhri",
      "Jonghye Woo"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.02284"
  },
  {
    "id": "arXiv:2206.02288",
    "title": "ACT: Semi-supervised Domain-adaptive Medical Image Segmentation with  Asymmetric Co-training",
    "abstract": "Comments: MICCAI 2022 (early accept)",
    "descriptor": "\nComments: MICCAI 2022 (early accept)\n",
    "authors": [
      "Xiaofeng Liu",
      "Fangxu Xing",
      "Nadya Shusharina",
      "Ruth Lim",
      "C-C Jay Kuo",
      "Georges El Fakhri",
      "Jonghye Woo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02288"
  },
  {
    "id": "arXiv:2206.02330",
    "title": "Linear MSRD codes with Different Matrix Sizes",
    "abstract": "Comments: 18 pages. arXiv admin note: text overlap with arXiv:2205.13087",
    "descriptor": "\nComments: 18 pages. arXiv admin note: text overlap with arXiv:2205.13087\n",
    "authors": [
      "Hao Chen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.02330"
  },
  {
    "id": "arXiv:2206.02371",
    "title": "Markovian Interference in Experiments",
    "abstract": "Markovian Interference in Experiments",
    "descriptor": "",
    "authors": [
      "Vivek F. Farias",
      "Andrew A. Li",
      "Tianyi Peng",
      "Andrew Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.02371"
  },
  {
    "id": "arXiv:2206.02837",
    "title": "EVC-Net: Multi-scale V-Net with Conditional Random Fields for Brain  Extraction",
    "abstract": "EVC-Net: Multi-scale V-Net with Conditional Random Fields for Brain  Extraction",
    "descriptor": "",
    "authors": [
      "Jong Sung Park",
      "Shreyas Fadnavis",
      "Eleftherios Garyfallidis"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02837"
  },
  {
    "id": "arXiv:2206.02976",
    "title": "Recall Distortion in Neural Network Pruning and the Undecayed Pruning  Algorithm",
    "abstract": "Comments: (Under review.)",
    "descriptor": "\nComments: (Under review.)\n",
    "authors": [
      "Aidan Good",
      "Jiaqi Lin",
      "Hannah Sieg",
      "Mikey Ferguson",
      "Xin Yu",
      "Shandian Zhe",
      "Jerzy Wieczorek",
      "Thiago Serra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02976"
  },
  {
    "id": "arXiv:2206.03354",
    "title": "cViL: Cross-Lingual Training of Vision-Language Models using Knowledge  Distillation",
    "abstract": "Comments: Accepted at ICPR 2022; 9 pages",
    "descriptor": "\nComments: Accepted at ICPR 2022; 9 pages\n",
    "authors": [
      "Kshitij Gupta",
      "Devansh Gautam",
      "Radhika Mamidi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.03354"
  },
  {
    "id": "arXiv:2206.03429",
    "title": "Generating Long Videos of Dynamic Scenes",
    "abstract": "Generating Long Videos of Dynamic Scenes",
    "descriptor": "",
    "authors": [
      "Tim Brooks",
      "Janne Hellsten",
      "Miika Aittala",
      "Ting-Chun Wang",
      "Timo Aila",
      "Jaakko Lehtinen",
      "Ming-Yu Liu",
      "Alexei A. Efros",
      "Tero Karras"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.03429"
  },
  {
    "id": "arXiv:2206.03538",
    "title": "WIDESim: A toolkit for simulating resource management techniques of  scientific Workflows In Distributed Environments with graph topology",
    "abstract": "WIDESim: A toolkit for simulating resource management techniques of  scientific Workflows In Distributed Environments with graph topology",
    "descriptor": "",
    "authors": [
      "Mohammad Amin Rayej",
      "Hajar Siar",
      "Mohammad Izadi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.03538"
  },
  {
    "id": "arXiv:2206.03544",
    "title": "A Penny for Your (visual) Thoughts: Self-Supervised Reconstruction of  Natural Movies from Brain Activity",
    "abstract": "A Penny for Your (visual) Thoughts: Self-Supervised Reconstruction of  Natural Movies from Brain Activity",
    "descriptor": "",
    "authors": [
      "Ganit Kupershmidt",
      "Roman Beliy",
      "Guy Gaziv",
      "Michal Irani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03544"
  },
  {
    "id": "arXiv:2206.03581",
    "title": "Compromised account detection using authorship verification: a novel  approach",
    "abstract": "Compromised account detection using authorship verification: a novel  approach",
    "descriptor": "",
    "authors": [
      "Forough Farazmanesh",
      "Fateme Foroutan",
      "Amir Jalaly Bidgoly"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.03581"
  },
  {
    "id": "arXiv:2206.03669",
    "title": "Toward Certified Robustness Against Real-World Distribution Shifts",
    "abstract": "Comments: Under submission",
    "descriptor": "\nComments: Under submission\n",
    "authors": [
      "Haoze Wu",
      "Teruhiro Tagomori",
      "Alexander Robey",
      "Fengjun Yang",
      "Nikolai Matni",
      "George Pappas",
      "Hamed Hassani",
      "Corina Pasareanu",
      "Clark Barrett"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.03669"
  },
  {
    "id": "arXiv:2206.03709",
    "title": "Hypernetwork-based Personalized Federated Learning for  Multi-Institutional CT Imaging",
    "abstract": "Hypernetwork-based Personalized Federated Learning for  Multi-Institutional CT Imaging",
    "descriptor": "",
    "authors": [
      "Ziyuan Yang",
      "Wenjun Xia",
      "Zexin Lu",
      "Yingyu Chen",
      "Xiaoxiao Li",
      "Yi Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.03709"
  },
  {
    "id": "arXiv:2206.03826",
    "title": "Towards Understanding Why Mask-Reconstruction Pretraining Helps in  Downstream Tasks",
    "abstract": "Comments: wrong information and contents",
    "descriptor": "\nComments: wrong information and contents\n",
    "authors": [
      "Jiachun Pan",
      "Pan Zhou",
      "Shuicheng Yan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.03826"
  },
  {
    "id": "arXiv:2206.03931",
    "title": "Few-shot Prompting Towards Controllable Response Generation",
    "abstract": "Few-shot Prompting Towards Controllable Response Generation",
    "descriptor": "",
    "authors": [
      "Hsuan Su",
      "Pohan Chi",
      "Shih-Cheng Huang",
      "Chung Ho Lam",
      "Saurav Sahay",
      "Shang-Tse Chen",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03931"
  },
  {
    "id": "arXiv:2206.03935",
    "title": "Dual-Distribution Discrepancy for Anomaly Detection in Chest X-Rays",
    "abstract": "Comments: Early Accepted to MICCAI 2022",
    "descriptor": "\nComments: Early Accepted to MICCAI 2022\n",
    "authors": [
      "Yu Cai",
      "Hao Chen",
      "Xin Yang",
      "Yu Zhou",
      "Kwang-Ting Cheng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.03935"
  },
  {
    "id": "arXiv:2206.04029",
    "title": "Accelerating Score-based Generative Models for High-Resolution Image  Synthesis",
    "abstract": "Accelerating Score-based Generative Models for High-Resolution Image  Synthesis",
    "descriptor": "",
    "authors": [
      "Hengyuan Ma",
      "Li Zhang",
      "Xiatian Zhu",
      "Jingfeng Zhang",
      "Jianfeng Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04029"
  }
]
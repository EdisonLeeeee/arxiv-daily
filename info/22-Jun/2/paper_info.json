[
  {
    "id": "arXiv:2206.00001",
    "title": "Weight Set Decomposition for Weighted Rank Aggregation: An interpretable  and visual decision support tool",
    "abstract": "The problem of interpreting or aggregating multiple rankings is common to\nmany real-world applications. Perhaps the simplest and most common approach is\na weighted rank aggregation, wherein a (convex) weight is applied to each input\nranking and then ordered. This paper describes a new tool for visualizing and\ndisplaying ranking information for the weighted rank aggregation method.\nTraditionally, the aim of rank aggregation is to summarize the information from\nthe input rankings and provide one final ranking that hopefully represents a\nmore accurate or truthful result than any one input ranking. While such an\naggregated ranking is, and clearly has been, useful to many applications, it\nalso obscures information. In this paper, we show the wealth of information\nthat is available for the weighted rank aggregation problem due to its\nstructure. We apply weight set decomposition to the set of convex multipliers,\nstudy the properties useful for understanding this decomposition, and visualize\nthe indifference regions. This methodology reveals information--that is\notherwise collapsed by the aggregated ranking--into a useful, interpretable,\nand intuitive decision support tool. Included are multiple illustrative\nexamples, along with heuristic and exact algorithms for computing the weight\nset decomposition.",
    "descriptor": "",
    "authors": [
      "Tyler Perini",
      "Amy Langville",
      "Glenn Kramer",
      "Jeff Shrager",
      "Mark Shapiro"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.00001"
  },
  {
    "id": "arXiv:2206.00003",
    "title": "Predictive Modeling of Physical and Mechanical Properties of Pervious  Concrete using XGBoost",
    "abstract": "High permeability of pervious concrete (PC) makes it a special type of\nconcrete utilised for certain applications. However, the complexity of the\nbehaviour and properties of PC leads to costly, time consuming and energy\ndemanding experimental works to accurately determine the mechanical and\nphysical properties of PC. This study presents a predictive model to predict\nthe mechanical and physical properties of PC using Extreme Gradient Boost\n(XGBoost). The compressive strength, tensile strength, density and porosity of\nPC was predicted using four models evaluated using different statistical\nparameters. These statistical measures are the root mean squared error (RMSE),\nsquare of correlation coefficient (R2), mean absolute error (MAE) and mean\nabsolute percentage error (MAPE). The estimation of these properties by the\nXGBoost models were in agreement with the experimental measurements. The\nperformance of XGBoost is further validated by comparing its estimations to\nthose obtained from four corresponding support vector regression (SVR) models.\nThe comparison showed that XGBoost generally outperformed SVR with lower RMSE\nof 0.58, 0.17, 0.98 and 34.97 compared to 0.74, 0.21, 1.28 and 44.06 in SVR for\ncompressive strength, tensile strength, porosity, and density estimation\nrespectively. Due to high correlation between the predicted and experimentally\nobtained properties, the XGBoost models are able to provide quick and reliable\ninformation on the properties of PC which are experimentally costly and time\nconsuming. A feature importance and contribution analysis of the\ninput/predictor variables showed that the cement proportion is the most\nimportant and contributory factor in the PC properties estimated.",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Ismail B. Mustapha",
      "Zainab Abdulkareem",
      "Muyideen Abdulkareem",
      "Abideen Ganiyu"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2206.00003"
  },
  {
    "id": "arXiv:2206.00005",
    "title": "Are classical neural networks quantum?",
    "abstract": "Neural networks are being used to improve the probing of the state spaces of\nmany particle systems as approximations to wavefunctions and in order to avoid\nthe recurring sign problem of quantum monte-carlo. One may ask whether the\nusual classical neural networks have some actual hidden quantum properties that\nmake them such suitable tools for a highly coupled quantum problem. I discuss\nhere what makes a system quantum and to what extent we can interpret a neural\nnetwork as having quantum remnants.",
    "descriptor": "",
    "authors": [
      "Andrei T. Patrascu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "High Energy Physics - Theory (hep-th)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.00005"
  },
  {
    "id": "arXiv:2206.00006",
    "title": "COIN: Co-Cluster Infomax for Bipartite Graphs",
    "abstract": "Bipartite graphs are powerful data structures to model interactions between\ntwo types of nodes, which have been used in a variety of applications, such as\nrecommender systems, information retrieval, and drug discovery. A fundamental\nchallenge for bipartite graphs is how to learn informative node embeddings.\nDespite the success of recent self-supervised learning methods on bipartite\ngraphs, their objectives are discriminating instance-wise positive and negative\nnode pairs, which could contain cluster-level errors. In this paper, we\nintroduce a novel co-cluster infomax (COIN) framework, which captures the\ncluster-level information by maximizing the mutual information of co-clusters.\nDifferent from previous infomax methods which estimate mutual information by\nneural networks, COIN could easily calculate mutual information. Besides, COIN\nis an end-to-end co-clustering method which can be trained jointly with other\nobjective functions and optimized via back-propagation. Furthermore, we also\nprovide theoretical analysis for COIN. We theoretically prove that COIN is able\nto effectively maximize the mutual information of node embeddings and COIN is\nupper-bounded by the prior distributions of nodes. We extensively evaluate the\nproposed COIN framework on various benchmark datasets and tasks to demonstrate\nthe effectiveness of COIN.",
    "descriptor": "\nComments: Preprint. In Submission\n",
    "authors": [
      "Baoyu Jing",
      "Yuchen Yan",
      "Yada Zhu",
      "Hanghang Tong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.00006"
  },
  {
    "id": "arXiv:2206.00007",
    "title": "A Cross-City Federated Transfer Learning Framework: A Case Study on  Urban Region Profiling",
    "abstract": "Data insufficiency problem (i.e., data missing and label scarcity issues)\ncaused by inadequate services and infrastructures or unbalanced development\nlevels of cities has seriously affected the urban computing tasks in real\nscenarios. Prior transfer learning methods inspire an elegant solution to the\ndata insufficiency, but are only concerned with one kind of insufficiency issue\nand fail to fully explore these two issues existing in the real world. In\naddition, cross-city transfer in existing methods overlooks the inter-city data\nprivacy which is a public concern in practical application. To address the\nabove challenging problems, we propose a novel Cross-city Federated Transfer\nLearning framework (CcFTL) to cope with the data insufficiency and privacy\nproblems. Concretely, CcFTL transfers the relational knowledge from multiple\nrich-data source cities to the target city. Besides, the model parameters\nspecific to the target task are firstly trained on the source data and then\nfine-tuned to the target city by parameter transfer. With our adaptation of\nfederated training and homomorphic encryption settings, CcFTL can effectively\ndeal with the data privacy problem among cities. We take the urban region\nprofiling as an application of smart cities and evaluate the proposed method\nwith a real-world study. The experiments demonstrate the notable superiority of\nour framework over several competitive state-of-the-art models.",
    "descriptor": "",
    "authors": [
      "Gaode Chen",
      "Yijun Su",
      "Xinghua Zhang",
      "Anmin Hu",
      "Guochun Chen",
      "Siyuan Feng",
      "Ji Xiang",
      "Junbo Zhang",
      "Yu Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.00007"
  },
  {
    "id": "arXiv:2206.00024",
    "title": "Online PAC-Bayes Learning",
    "abstract": "Most PAC-Bayesian bounds hold in the batch learning setting where data is\ncollected at once, prior to inference or prediction. This somewhat departs from\nmany contemporary learning problems where data streams are collected and the\nalgorithms must dynamically adjust. We prove new PAC-Bayesian bounds in this\nonline learning framework, leveraging an updated definition of regret, and we\nrevisit classical PAC-Bayesian results with a batch-to-online conversion,\nextending their remit to the case of dependent data. Our results hold for\nbounded losses, potentially \\emph{non-convex}, paving the way to promising\ndevelopments in online learning.",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Maxime Haddouche",
      "Benjamin Guedj"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.00024"
  },
  {
    "id": "arXiv:2206.00026",
    "title": "Network Cards: concise, readable summaries of network data",
    "abstract": "The deluge of network datasets demands a standard way to effectively and\nsuccinctly summarize network datasets. Building on similar efforts to\nstandardize the documentation of models and datasets in machine learning, here\nwe propose *network cards*, short summaries of network datasets that can\ncapture not only the basic statistics of the network but also information about\nthe data construction process, provenance, ethical considerations, and other\nmetadata. In this paper, we lay out (i) the rationales and objectives for\nnetwork cards, (ii) key elements that should be included in network cards, and\n(iii) example network cards to underscore their benefits across a variety of\nresearch domains. We also provide a schema, templates, and a software package\nfor generating network cards.",
    "descriptor": "\nComments: 17 pages, 5 tables\n",
    "authors": [
      "James Bagrow",
      "Yong-Yeol Ahn"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.00026"
  },
  {
    "id": "arXiv:2206.00035",
    "title": "Weaving Privacy and Power: On the Privacy Practices of Labor Organizers  in the U.S. Technology Industry",
    "abstract": "We investigate the privacy practices of labor organizers in the computing\ntechnology industry and explore the changes in these practices as a response to\nremote work. Our study is situated at the intersection of two pivotal shifts in\nworkplace dynamics: (a) the increase in online workplace communications due to\nremote work, and (b) the resurgence of the labor movement and an increase in\ncollective action in workplaces -- especially in the tech industry, where this\nphenomenon has been dubbed the tech worker movement. Through a series of\nqualitative interviews with 29 tech workers involved in collective action, we\ninvestigate how labor organizers assess and mitigate risks to privacy while\nengaging in these actions. Among the most common risks that organizers\nexperienced are retaliation from their employer, lateral worker conflict,\nemotional burnout, and the possibility of information about the collective\neffort leaking to management. Depending on the nature and source of the risk,\norganizers use a blend of digital security practices and community-based\nmechanisms. We find that digital security practices are more relevant when the\nthreat comes from management, while community management and moderation are\ncentral to protecting organizers from lateral worker conflict. Since labor\norganizing is a collective rather than individual project, individual privacy\nand collective privacy are intertwined, sometimes in conflict and often\nmutually constitutive. Notions of privacy that solely center individuals are\noften incompatible with the needs of organizers, who noted that safety in\nnumbers could only be achieved when workers presented a united front to\nmanagement. We conclude with design recommendations that can help create safer,\nmore secure and more private tools to better address the risks that organizers\nface.",
    "descriptor": "\nComments: Accepted to CSCW 2022\n",
    "authors": [
      "Sayash Kapoor",
      "Matthew Sun",
      "Mona Wang",
      "Klaudia Ja\u017awi\u0144ska",
      "Elizabeth Anne Watkins"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.00035"
  },
  {
    "id": "arXiv:2206.00047",
    "title": "Evolving Domain Generalization",
    "abstract": "Domain generalization aims to learn a predictive model from multiple\ndifferent but related source tasks that can generalize well to a target task\nwithout the need of accessing any target data. Existing domain generalization\nmethods ignore the relationship between tasks, implicitly assuming that all the\ntasks are sampled from a stationary environment. Therefore, they can fail when\ndeployed in an evolving environment. To this end, we formulate and study the\n\\emph{evolving domain generalization} (EDG) scenario, which exploits not only\nthe source data but also their evolving pattern to generate a model for the\nunseen task. Our theoretical result reveals the benefits of modeling the\nrelation between two consecutive tasks by learning a globally consistent\ndirectional mapping function. In practice, our analysis also suggests solving\nthe DDG problem in a meta-learning manner, which leads to \\emph{directional\nprototypical network}, the first method for the DDG problem. Empirical\nevaluation of both synthetic and real-world data sets validates the\neffectiveness of our approach.",
    "descriptor": "",
    "authors": [
      "Wei Wang",
      "Gezheng Xu",
      "Ruizhi Pu",
      "Jiaqi Li",
      "Fan Zhou",
      "Changjian Shui",
      "Charles Ling",
      "Christian Gagn\u00e9",
      "Boyu Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00047"
  },
  {
    "id": "arXiv:2206.00048",
    "title": "PandA: Unsupervised Learning of Parts and Appearances in the Feature  Maps of GANs",
    "abstract": "Recent advances in the understanding of Generative Adversarial Networks\n(GANs) have led to remarkable progress in visual editing and synthesis tasks,\ncapitalizing on the rich semantics that are embedded in the latent spaces of\npre-trained GANs. However, existing methods are often tailored to specific GAN\narchitectures and are limited to either discovering global semantic directions\nthat do not facilitate localized control, or require some form of supervision\nthrough manually provided regions or segmentation masks. In this light, we\npresent an architecture-agnostic approach that jointly discovers factors\nrepresenting spatial parts and their appearances in an entirely unsupervised\nfashion. These factors are obtained by applying a semi-nonnegative tensor\nfactorization on the feature maps, which in turn enables context-aware local\nimage editing with pixel-level control. In addition, we show that the\ndiscovered appearance factors correspond to saliency maps that localize\nconcepts of interest, without using any labels. Experiments on a wide range of\nGAN architectures and datasets show that, in comparison to the state of the\nart, our method is far more efficient in terms of training time and, most\nimportantly, provides much more accurate localized control. Our code is\navailable at: https://github.com/james-oldfield/PandA.",
    "descriptor": "\nComments: Code available at: this https URL\n",
    "authors": [
      "James Oldfield",
      "Christos Tzelepis",
      "Yannis Panagakis",
      "Mihalis A. Nicolaou",
      "Ioannis Patras"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00048"
  },
  {
    "id": "arXiv:2206.00050",
    "title": "FiLM-Ensemble: Probabilistic Deep Learning via Feature-wise Linear  Modulation",
    "abstract": "The ability to estimate epistemic uncertainty is often crucial when deploying\nmachine learning in the real world, but modern methods often produce\noverconfident, uncalibrated uncertainty predictions. A common approach to\nquantify epistemic uncertainty, usable across a wide class of prediction\nmodels, is to train a model ensemble. In a naive implementation, the ensemble\napproach has high computational cost and high memory demand. This challenges in\nparticular modern deep learning, where even a single deep network is already\ndemanding in terms of compute and memory, and has given rise to a number of\nattempts to emulate the model ensemble without actually instantiating separate\nensemble members. We introduce FiLM-Ensemble, a deep, implicit ensemble method\nbased on the concept of Feature-wise Linear Modulation (FiLM). That technique\nwas originally developed for multi-task learning, with the aim of decoupling\ndifferent tasks. We show that the idea can be extended to uncertainty\nquantification: by modulating the network activations of a single deep network\nwith FiLM, one obtains a model ensemble with high diversity, and consequently\nwell-calibrated estimates of epistemic uncertainty, with low computational\noverhead in comparison. Empirically, FiLM-Ensemble outperforms other implicit\nensemble methods, and it and comes very close to the upper bound of an explicit\nensemble of networks (sometimes even beating it), at a fraction of the memory\ncost.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Mehmet Ozgur Turkoglu",
      "Alexander Becker",
      "H\u00fcseyin Anil G\u00fcnd\u00fcz",
      "Mina Rezaei",
      "Bernd Bischl",
      "Rodrigo Caye Daudt",
      "Stefano D'Aronco",
      "Jan Dirk Wegner",
      "Konrad Schindler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00050"
  },
  {
    "id": "arXiv:2206.00051",
    "title": "Learning Instance-Specific Data Augmentations",
    "abstract": "Existing data augmentation methods typically assume independence between\ntransformations and inputs: they use the same transformation distribution for\nall input instances. We explain why this can be problematic and propose\nInstaAug, a method for automatically learning input-specific augmentations from\ndata. This is achieved by introducing an augmentation module that maps an input\nto a distribution over transformations. This is simultaneously trained\nalongside the base model in a fully end-to-end manner using only the training\ndata. We empirically demonstrate that InstaAug learns meaningful augmentations\nfor a wide range of transformation classes, which in turn provides better\nperformance on supervised and self-supervised tasks compared with augmentations\nthat assume input--transformation independence.",
    "descriptor": "",
    "authors": [
      "Ning Miao",
      "Emile Mathieu",
      "Yann Dubois",
      "Tom Rainforth",
      "Yee Whye Teh",
      "Adam Foster",
      "Hyunjik Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00051"
  },
  {
    "id": "arXiv:2206.00052",
    "title": "CodeAttack: Code-based Adversarial Attacks for Pre-Trained Programming  Language Models",
    "abstract": "Pre-trained programming language (PL) models (such as CodeT5, CodeBERT,\nGraphCodeBERT, etc.,) have the potential to automate software engineering tasks\ninvolving code understanding and code generation. However, these models are not\nrobust to changes in the input and thus, are potentially susceptible to\nadversarial attacks. We propose, CodeAttack, a simple yet effective black-box\nattack model that uses code structure to generate imperceptible, effective, and\nminimally perturbed adversarial code samples. We demonstrate the\nvulnerabilities of the state-of-the-art PL models to code-specific adversarial\nattacks. We evaluate the transferability of CodeAttack on several code-code\n(translation and repair) and code-NL (summarization) tasks across different\nprogramming languages. CodeAttack outperforms state-of-the-art adversarial NLP\nattack models to achieve the best overall performance while being more\nefficient and imperceptible.",
    "descriptor": "",
    "authors": [
      "Akshita Jha",
      "Chandan K. Reddy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.00052"
  },
  {
    "id": "arXiv:2206.00054",
    "title": "Asynchronous Hierarchical Federated Learning",
    "abstract": "Federated Learning is a rapidly growing area of research and with various\nbenefits and industry applications. Typical federated patterns have some\nintrinsic issues such as heavy server traffic, long periods of convergence, and\nunreliable accuracy. In this paper, we address these issues by proposing\nasynchronous hierarchical federated learning, in which the central server uses\neither the network topology or some clustering algorithm to assign clusters for\nworkers (i.e., client devices). In each cluster, a special aggregator device is\nselected to enable hierarchical learning, leads to efficient communication\nbetween server and workers, so that the burden of the server can be\nsignificantly reduced. In addition, asynchronous federated learning schema is\nused to tolerate heterogeneity of the system and achieve fast convergence,\ni.e., the server aggregates the gradients from the workers weighted by a\nstaleness parameter to update the global model, and regularized stochastic\ngradient descent is performed in workers, so that the instability of\nasynchronous learning can be alleviated. We evaluate the proposed algorithm on\nCIFAR-10 image classification task, the experimental results demonstrate the\neffectiveness of asynchronous hierarchical federated learning.",
    "descriptor": "",
    "authors": [
      "Xing Wang",
      "Yijun Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00054"
  },
  {
    "id": "arXiv:2206.00057",
    "title": "Distributed Graph Neural Network Training with Periodic Historical  Embedding Synchronization",
    "abstract": "Despite the recent success of Graph Neural Networks (GNNs), it remains\nchallenging to train a GNN on large graphs, which are prevalent in various\napplications such as social network, recommender systems, and knowledge graphs.\nTraditional sampling-based methods accelerate GNN by dropping edges and nodes,\nwhich impairs the graph integrity and model performance. Differently,\ndistributed GNN algorithms, which accelerate GNN training by utilizing multiple\ncomputing devices, can be classified into two types: \"partition-based\" methods\nenjoy low communication costs but suffer from information loss due to dropped\nedges, while \"propagation-based\" methods avoid information loss but suffer\nprohibitive communication overhead. To jointly address these problems, this\npaper proposes DIstributed Graph Embedding SynchronizaTion (DIGEST), a novel\ndistributed GNN training framework that synergizes the complementary strength\nof both categories of existing methods. During subgraph parallel training, we\npropose to let each device store the historical embedding of its neighbors in\nother subgraphs. Therefore, our method does not discard any neighbors in other\nsubgraphs, nor does it updates them intensively. This effectively avoids (1)\nthe intensive computation on explosively-increasing neighbors and (2) excessive\ncommunications across different devices. We proved that the approximation error\ninduced by the staleness of historical embedding can be upper bounded and it\ndoes NOT affect the GNN model's expressiveness. More importantly, our\nconvergence analysis demonstrates that DIGEST enjoys a state-of-the-art\nconvergence rate. Extensive experimental evaluation on large, real-world graph\ndatasets shows that DIGEST achieves up to $21.82\\times$ speedup without\ncompromising the performance compared to state-of-the-art distributed GNN\ntraining frameworks.",
    "descriptor": "\nComments: Preprint: 18 pages, 7 figures\n",
    "authors": [
      "Zheng Chai",
      "Guangji Bai",
      "Liang Zhao",
      "Yue Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.00057"
  },
  {
    "id": "arXiv:2206.00059",
    "title": "A Mixture-of-Expert Approach to RL-based Dialogue Management",
    "abstract": "Despite recent advancements in language models (LMs), their application to\ndialogue management (DM) problems and ability to carry on rich conversations\nremain a challenge. We use reinforcement learning (RL) to develop a dialogue\nagent that avoids being short-sighted (outputting generic utterances) and\nmaximizes overall user satisfaction. Most existing RL approaches to DM train\nthe agent at the word-level, and thus, have to deal with a combinatorially\ncomplex action space even for a medium-size vocabulary. As a result, they\nstruggle to produce a successful and engaging dialogue even if they are\nwarm-started with a pre-trained LM. To address this issue, we develop a\nRL-based DM using a novel mixture of expert language model (MoE-LM) that\nconsists of (i) a LM capable of learning diverse semantics for conversation\nhistories, (ii) a number of {\\em specialized} LMs (or experts) capable of\ngenerating utterances corresponding to a particular attribute or personality,\nand (iii) a RL-based DM that performs dialogue planning with the utterances\ngenerated by the experts. Our MoE approach provides greater flexibility to\ngenerate sensible utterances with different intents and allows RL to focus on\nconversational-level DM. We compare it with SOTA baselines on open-domain\ndialogues and demonstrate its effectiveness both in terms of the diversity and\nsensibility of the generated utterances and the overall DM performance.",
    "descriptor": "",
    "authors": [
      "Yinlam Chow",
      "Aza Tulepbergenov",
      "Ofir Nachum",
      "MoonKyung Ryu",
      "Mohammad Ghavamzadeh",
      "Craig Boutilier"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.00059"
  },
  {
    "id": "arXiv:2206.00065",
    "title": "FELARE: Fair Scheduling of Machine Learning Applications on  Heterogeneous Edge Systems",
    "abstract": "Edge computing enables smart IoT-based systems via concurrent and continuous\nexecution of latency-sensitive machine learning (ML) applications. These\nedge-based machine learning systems are often battery-powered (i.e.,\nenergy-limited). They use heterogeneous resources with diverse computing\nperformance (e.g., CPU, GPU, and/or FPGAs) to fulfill the latency constraints\nof ML applications. The challenge is to allocate user requests for different ML\napplications on the Heterogeneous Edge Computing Systems (HEC) with respect to\nboth the energy and latency constraints of these systems. To this end, we study\nand analyze resource allocation solutions that can increase the on-time task\ncompletion rate while considering the energy constraint. Importantly, we\ninvestigate edge-friendly (lightweight) multi-objective mapping heuristics that\ndo not become biased toward a particular application type to achieve the\nobjectives; instead, the heuristics consider \"fairness\" across the concurrent\nML applications in their mapping decisions. Performance evaluations demonstrate\nthat the proposed heuristic outperforms widely-used heuristics in heterogeneous\nsystems in terms of the latency and energy objectives, particularly, at low to\nmoderate request arrival rates. We observed 8.9% improvement in on-time task\ncompletion rate and 12.6% in energy-saving without imposing any significant\noverhead on the edge system.",
    "descriptor": "",
    "authors": [
      "Ali Mokhtari",
      "Pooyan Jamshidi",
      "Mohsen Amini Salehi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2206.00065"
  },
  {
    "id": "arXiv:2206.00069",
    "title": "Comparing feature fusion strategies for Deep Learning-based kidney stone  identification",
    "abstract": "This contribution presents a deep-learning method for extracting and fusing\nimage information acquired from different viewpoints with the aim to produce\nmore discriminant object features. Our approach was specifically designed to\nmimic the morpho-constitutional analysis used by urologists to visually\nclassify kidney stones by inspecting the sections and surfaces of their\nfragments. Deep feature fusion strategies improved the results of single view\nextraction backbone models by more than 10\\% in terms of precision of the\nkidney stones classification.",
    "descriptor": "\nComments: 4 pages, 3 figures, XXVIII\\`eme Colloque Francophone de Traitement du Signal et des Images\n",
    "authors": [
      "Elias Villalvazo-Avila",
      "Francisco Lopez-Tiro",
      "Daniel Flores-Araiza",
      "Gilberto Ochoa-Ruiz",
      "Jonathan El-Beze",
      "Jacques Hubert",
      "Christian Daul"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.00069"
  },
  {
    "id": "arXiv:2206.00070",
    "title": "On Analyzing Generative and Denoising Capabilities of Diffusion-based  Deep Generative Models",
    "abstract": "Diffusion-based Deep Generative Models (DDGMs) offer state-of-the-art\nperformance in generative modeling. Their main strength comes from their unique\nsetup in which a model (the backward diffusion process) is trained to reverse\nthe forward diffusion process, which gradually adds noise to the input signal.\nAlthough DDGMs are well studied, it is still unclear how the small amount of\nnoise is transformed during the backward diffusion process. Here, we focus on\nanalyzing this problem to gain more insight into the behavior of DDGMs and\ntheir denoising and generative capabilities. We observe a fluid transition\npoint that changes the functionality of the backward diffusion process from\ngenerating a (corrupted) image from noise to denoising the corrupted image to\nthe final sample. Based on this observation, we postulate to divide a DDGM into\ntwo parts: a denoiser and a generator. The denoiser could be parameterized by a\ndenoising auto-encoder, while the generator is a diffusion-based model with its\nown set of parameters. We experimentally validate our proposition, showing its\npros and cons.",
    "descriptor": "",
    "authors": [
      "Kamil Deja",
      "Anna Kuzina",
      "Tomasz Trzci\u0144ski",
      "Jakub M. Tomczak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00070"
  },
  {
    "id": "arXiv:2206.00071",
    "title": "Generative Models with Information-Theoretic Protection Against  Membership Inference Attacks",
    "abstract": "Deep generative models, such as Generative Adversarial Networks (GANs),\nsynthesize diverse high-fidelity data samples by estimating the underlying\ndistribution of high dimensional data. Despite their success, GANs may disclose\nprivate information from the data they are trained on, making them susceptible\nto adversarial attacks such as membership inference attacks, in which an\nadversary aims to determine if a record was part of the training set. We\npropose an information theoretically motivated regularization term that\nprevents the generative model from overfitting to training data and encourages\ngeneralizability. We show that this penalty minimizes the JensenShannon\ndivergence between components of the generator trained on data with different\nmembership, and that it can be implemented at low cost using an additional\nclassifier. Our experiments on image datasets demonstrate that with the\nproposed regularization, which comes at only a small added computational cost,\nGANs are able to preserve privacy and generate high-quality samples that\nachieve better downstream classification performance compared to non-private\nand differentially private generative models.",
    "descriptor": "",
    "authors": [
      "Parisa Hassanzadeh",
      "Robert E. Tillman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.00071"
  },
  {
    "id": "arXiv:2206.00085",
    "title": "Semantically-enhanced Topic Recommendation System for Software Projects",
    "abstract": "Software-related platforms have enabled their users to collaboratively label\nsoftware entities with topics. Tagging software repositories with relevant\ntopics can be exploited for facilitating various downstream tasks. For\ninstance, a correct and complete set of topics assigned to a repository can\nincrease its visibility. Consequently, this improves the outcome of tasks such\nas browsing, searching, navigation, and organization of repositories.\nUnfortunately, assigned topics are usually highly noisy, and some repositories\ndo not have well-assigned topics. Thus, there have been efforts on recommending\ntopics for software projects, however, the semantic relationships among these\ntopics have not been exploited so far. We propose two recommender models for\ntagging software projects that incorporate the semantic relationship among\ntopics. Our approach has two main phases; (1) we first take a collaborative\napproach to curate a dataset of quality topics specifically for the domain of\nsoftware engineering and development. We also enrich this data with the\nsemantic relationships among these topics and encapsulate them in a knowledge\ngraph we call SED-KGraph. Then, (2) we build two recommender systems; The first\none operates only based on the list of original topics assigned to a repository\nand the relationships specified in our knowledge graph. The second predictive\nmodel, however, assumes there are no topics available for a repository, hence\nit proceeds to predict the relevant topics based on both textual information of\na software project and SED-KGraph. We built SED-KGraph in a crowd-sourced\nproject with 170 contributors from both academia and industry. The experiment\nresults indicate that our solutions outperform baselines that neglect the\nsemantic relationships among topics by at least 25% and 23% in terms of ASR and\nMAP metrics.",
    "descriptor": "",
    "authors": [
      "Maliheh Izadi",
      "Mahtab Nejati",
      "Abbas Heydarnoori"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00085"
  },
  {
    "id": "arXiv:2206.00092",
    "title": "FHIST: A Benchmark for Few-shot Classification of Histological Images",
    "abstract": "Few-shot learning has recently attracted wide interest in image\nclassification, but almost all the current public benchmarks are focused on\nnatural images. The few-shot paradigm is highly relevant in medical-imaging\napplications due to the scarcity of labeled data, as annotations are expensive\nand require specialized expertise. However, in medical imaging, few-shot\nlearning research is sparse, limited to private data sets and is at its early\nstage. In particular, the few-shot setting is of high interest in histology due\nto the diversity and fine granularity of cancer related tissue classification\ntasks, and the variety of data-preparation techniques. This paper introduces a\nhighly diversified public benchmark, gathered from various public datasets, for\nfew-shot histology data classification. We build few-shot tasks and\nbase-training data with various tissue types, different levels of domain shifts\nstemming from various cancer sites, and different class-granularity levels,\nthereby reflecting realistic scenarios. We evaluate the performances of\nstate-of-the-art few-shot learning methods on our benchmark, and observe that\nsimple fine-tuning and regularization methods achieve better results than the\npopular meta-learning and episodic-training paradigm. Furthermore, we introduce\nthree scenarios based on the domain shifts between the source and target\nhistology data: near-domain, middle-domain and out-domain. Our experiments\ndisplay the potential of few-shot learning in histology classification, with\nstate-of-art few shot learning methods approaching the supervised-learning\nbaselines in the near-domain setting. In our out-domain setting, for 5-way\n5-shot, the best performing method reaches 60% accuracy. We believe that our\nwork could help in building realistic evaluations and fair comparisons of\nfew-shot learning methods and will further encourage research in the few-shot\nparadigm.",
    "descriptor": "\nComments: Code available at: this https URL\n",
    "authors": [
      "Fereshteh Shakeri",
      "Malik Boudiaf",
      "Sina Mohammadi",
      "Ivaxi Sheth",
      "Mohammad Havaei",
      "Ismail Ben Ayed",
      "Samira Ebrahimi Kahou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.00092"
  },
  {
    "id": "arXiv:2206.00097",
    "title": "Real-time motion planning and decision-making for a group of  differential drive robots under connectivity constraints using robust MPC and  mixed-integer programming",
    "abstract": "This work is concerned with the problem of planning trajectories and\nassigning tasks for a Multi-Agent System (MAS) comprised of differential drive\nrobots. We propose a multirate hierarchical control structure that employs a\nplanner based on robust Model Predictive Control (MPC) with mixed-integer\nprogramming (MIP) encoding. The planner computes trajectories and assigns tasks\nfor each element of the group in real-time, while also guaranteeing the\ncommunication network of the MAS to be robustly connected at all times.\nAdditionally, we provide a data-based methodology to estimate the disturbances\nsets required by the robust MPC formulation. The results are demonstrated with\nexperiments in two obstacle-filled scenarios",
    "descriptor": "\nComments: Submitted to Advanced Robotics special issue on Online Motion Planning and Model Predictive Control\n",
    "authors": [
      "Angelo Caregnato-Neto",
      "Marcos Ricardo Omena de Albuquerque Maximo",
      "Rubens Junqueira Magalh\u00e3es Afonso"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.00097"
  },
  {
    "id": "arXiv:2206.00100",
    "title": "VALHALLA: Visual Hallucination for Machine Translation",
    "abstract": "Designing better machine translation systems by considering auxiliary inputs\nsuch as images has attracted much attention in recent years. While existing\nmethods show promising performance over the conventional text-only translation\nsystems, they typically require paired text and image as input during\ninference, which limits their applicability to real-world scenarios. In this\npaper, we introduce a visual hallucination framework, called VALHALLA, which\nrequires only source sentences at inference time and instead uses hallucinated\nvisual representations for multimodal machine translation. In particular, given\na source sentence an autoregressive hallucination transformer is used to\npredict a discrete visual representation from the input text, and the combined\ntext and hallucinated representations are utilized to obtain the target\ntranslation. We train the hallucination transformer jointly with the\ntranslation transformer using standard backpropagation with cross-entropy\nlosses while being guided by an additional loss that encourages consistency\nbetween predictions using either ground-truth or hallucinated visual\nrepresentations. Extensive experiments on three standard translation datasets\nwith a diverse set of language pairs demonstrate the effectiveness of our\napproach over both text-only baselines and state-of-the-art methods. Project\npage: this http URL",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Yi Li",
      "Rameswar Panda",
      "Yoon Kim",
      "Chun-Fu Chen",
      "Rogerio Feris",
      "David Cox",
      "Nuno Vasconcelos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.00100"
  },
  {
    "id": "arXiv:2206.00101",
    "title": "MAD-EN: Microarchitectural Attack Detection through System-wide Energy  Consumption",
    "abstract": "Microarchitectural attacks have become more threatening the hardware security\nthan before with the increasing diversity of attacks such as Spectre and\nMeltdown. Vendor patches cannot keep up with the pace of the new threats, which\nmakes the dynamic anomaly detection tools more evident than before.\nUnfortunately, previous studies utilize hardware performance counters that lead\nto high performance overhead and profile limited number of microarchitectural\nattacks due to the small number of counters that can be profiled concurrently.\nThis yields those detection tools inefficient in real-world scenarios.\nIn this study, we introduce MAD-EN dynamic detection tool that leverages\nsystem-wide energy consumption traces collected from a generic Intel RAPL tool\nto detect ongoing anomalies in a system. In our experiments, we show that\nCNN-based MAD-EN can detect 10 different microarchitectural attacks with a\ntotal of 15 variants with the highest F1 score of 0.999, which makes our tool\nthe most generic attack detection tool so far. Moreover, individual attacks can\nbe distinguished with a 98% accuracy after an anomaly is detected in a system.\nWe demonstrate that MAD-EN introduces 69.3% less performance overhead compared\nto performance counter-based detection mechanisms.",
    "descriptor": "",
    "authors": [
      "Debopriya Roy Dipta",
      "Berk Gulmezoglu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00101"
  },
  {
    "id": "arXiv:2206.00103",
    "title": "An Empirical Study on How Well Do COVID-19 Information Dashboards  Service Users' Information Needs",
    "abstract": "The ongoing COVID-19 pandemic highlights the importance of dashboards for\nproviding critical real-time information. In order to enable people to obtain\ninformation in time and to understand complex statistical data, many developers\nhave designed and implemented public-oriented COVID-19 \"information dashboards\"\nduring the pandemic. However, development often takes a long time and\ndevelopers are not clear about many people's information needs, resulting in\ngaps between information needs and supplies. According to our empirical study\nand observations with popular developed COVID-19 dashboards, this seriously\nimpedes information acquirement. Our study compares people's needs on Twitter\nwith existing information suppliers. We determine that despite the COVID-19\ninformation that is currently on existing dashboards, people are also\ninterested in the relationship between COVID-19 and other viruses, the origin\nof COVID-19, vaccine development, fake new about COVID-19, impact on women,\nimpact on school/university, and impact on business. Most of these have not yet\nbeen well addressed. We also summarise the visualization and interaction\npatterns commonly applied in dashboards, finding key patterns between data and\nvisualization as well as visualization and interaction. Our findings can help\ndevelopers to better optimize their dashboard to meet people's needs and make\nimprovements to future crisis management dashboard development.",
    "descriptor": "",
    "authors": [
      "Xinyan Li",
      "Han Wang",
      "Chunyang Chen",
      "John Grundy"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.00103"
  },
  {
    "id": "arXiv:2206.00104",
    "title": "Smart operators in industry 4.0: A human-centered approach to enhance  operators' capabilities and competencies within the new smart factory context",
    "abstract": "As the Industry 4.0 takes shape, human operators experience an increased\ncomplexity of their daily tasks: they are required to be highly flexible and to\ndemonstrate adaptive capabilities in a very dynamic working environment. It\ncalls for tools and approaches that could be easily embedded into everyday\npractices and able to combine complex methodologies with high usability\nrequirements. In this perspective, the proposed research work is focused on the\ndesign and development of a practical solution, called Sophos-MS, able to\nintegrate augmented reality contents and intelligent tutoring systems with\ncutting-edge fruition technologies for operators' support in complex\nman-machine interactions. After establishing a reference methodological\nframework for the smart operator concept within the Industry 4.0 paradigm, the\nproposed solution is presented, along with its functional and non-function\nrequirements. Such requirements are fulfilled through a structured design\nstrategy whose main outcomes include a multi-layered modular solution,\nSophos-MS, that relies on Augmented Reality contents and on an intelligent\npersonal digital assistant with vocal interaction capabilities. The proposed\napproach has been deployed and its training potentials have been investigated\nwith field experiments. The experimental campaign results have been firstly\nchecked to ensure their statistical relevance and then analytically assessed in\norder to show that the proposed solution has a real impact on operators'\nlearning curves and can make the difference between who uses it and who does\nnot.",
    "descriptor": "\nComments: 16 pages, 25 figures, 9 tables\n",
    "authors": [
      "Francesco Longo",
      "Letizia Nicoletti",
      "Antonio Padovano"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.00104"
  },
  {
    "id": "arXiv:2206.00106",
    "title": "Mario Plays on a Manifold: Generating Functional Content in Latent Space  through Differential Geometry",
    "abstract": "Deep generative models can automatically create content of diverse types.\nHowever, there are no guarantees that such content will satisfy the criteria\nnecessary to present it to end-users and be functional, e.g. the generated\nlevels could be unsolvable or incoherent. In this paper we study this problem\nfrom a geometric perspective, and provide a method for reliable interpolation\nand random walks in the latent spaces of Categorical VAEs based on Riemannian\ngeometry. We test our method with \"Super Mario Bros\" and \"The Legend of Zelda\"\nlevels, and against simpler baselines inspired by current practice. Results\nshow that the geometry we propose is better able to interpolate and sample,\nreliably staying closer to parts of the latent space that decode to playable\ncontent.",
    "descriptor": "\nComments: Accepted at CoG 2022\n",
    "authors": [
      "Miguel Gonz\u00e1lez-Duque",
      "Rasmus Berg Palm",
      "S\u00f8ren Hauberg",
      "Sebastian Risi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00106"
  },
  {
    "id": "arXiv:2206.00108",
    "title": "Modeling pre-Exascale AMR Parallel I/O Workloads via Proxy Applications",
    "abstract": "The present work investigates the modeling of pre-exascale input/output (I/O)\nworkloads of Adaptive Mesh Refinement (AMR) simulations through a simple proxy\napplication. We collect data from the AMReX Castro framework running on the\nSummit supercomputer for a wide range of scales and mesh partitions for the\nhydrodynamic Sedov case as a baseline to provide sufficient coverage to the\nformulated proxy model. The non-linear analysis data production rates are\nquantified as a function of a set of input parameters such as output frequency,\ngrid size, number of levels, and the Courant-Friedrichs-Lewy (CFL) condition\nnumber for each rank, mesh level and simulation time step. Linear regression is\nthen applied to formulate a simple analytical model which allows to translate\nAMReX inputs into MACSio proxy I/O application parameters, resulting in a\nsimple \"kernel\" approximation for data production at each time step. Results\nshow that MACSio can simulate actual AMReX non-linear \"static\" I/O workloads to\na certain degree of confidence on the Summit supercomputer using the present\nmethodology. The goal is to provide an initial level of understanding of AMR\nI/O workloads via lightweight proxy applications models to facilitate autotune\ndata management strategies in anticipation of exascale systems.",
    "descriptor": "\nComments: 10 pages, 11 figures, accepted at Seventeenth International Workshop on Automatic Performance Tuning, iWAPT2022, held in conjunction with IEEE IPDPS 2022\n",
    "authors": [
      "William F Godoy",
      "Jenna Delozier",
      "Gregory R Watson"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2206.00108"
  },
  {
    "id": "arXiv:2206.00111",
    "title": "To Collaborate or Not in Distributed Statistical Estimation with  Resource Constraints?",
    "abstract": "We study how the amount of correlation between observations collected by\ndistinct sensors/learners affects data collection and collaboration strategies\nby analyzing Fisher information and the Cramer-Rao bound. In particular, we\nconsider a simple setting wherein two sensors sample from a bivariate Gaussian\ndistribution, which already motivates the adoption of various strategies,\ndepending on the correlation between the two variables and resource\nconstraints. We identify two particular scenarios: (1) where the knowledge of\nthe correlation between samples cannot be leveraged for collaborative\nestimation purposes and (2) where the optimal data collection strategy involves\ninvesting scarce resources to collaboratively sample and transfer information\nthat is not of immediate interest and whose statistics are already known, with\nthe sole goal of increasing the confidence on an estimate of the parameter of\ninterest. We discuss two applications, IoT DDoS attack detection and\ndistributed estimation in wireless sensor networks, that may benefit from our\nresults.",
    "descriptor": "\nComments: 2021 55th Annual Conference on Information Sciences and Systems (CISS)\n",
    "authors": [
      "Yu-Zhen Janice Chen",
      "Daniel S. Menasche",
      "Don Towsley"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.00111"
  },
  {
    "id": "arXiv:2206.00113",
    "title": "BRExIt: On Opponent Modelling in Expert Iteration",
    "abstract": "Finding a best response policy is a central objective in game theory and\nmulti-agent learning, with modern population-based training approaches\nemploying reinforcement learning algorithms as best-response oracles to improve\nplay against candidate opponents (typically previously learnt policies). We\npropose Best Response Expert Iteration (BRExIt), which accelerates learning in\ngames by incorporating opponent models into the state-of-the-art learning\nalgorithm Expert Iteration (ExIt). BRExIt aims to (1) improve feature shaping\nin the apprentice, with a policy head predicting opponent policies as an\nauxiliary task, and (2) bias opponent moves in planning towards the given or\nlearnt opponent model, to generate apprentice targets that better approximate a\nbest response. In an empirical ablation on BRExIt's algorithmic variants in the\ngame Connect4 against a set of fixed test agents, we provide statistical\nevidence that BRExIt learns well-performing policies with greater sample\nefficiency than ExIt.",
    "descriptor": "",
    "authors": [
      "Daniel Hernandez",
      "Hendrik Baier",
      "Michael Kaisers"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2206.00113"
  },
  {
    "id": "arXiv:2206.00118",
    "title": "Principle of Relevant Information for Graph Sparsification",
    "abstract": "Graph sparsification aims to reduce the number of edges of a graph while\nmaintaining its structural properties. In this paper, we propose the first\ngeneral and effective information-theoretic formulation of graph\nsparsification, by taking inspiration from the Principle of Relevant\nInformation (PRI). To this end, we extend the PRI from a standard scalar random\nvariable setting to structured data (i.e., graphs). Our Graph-PRI objective is\nachieved by operating on the graph Laplacian, made possible by expressing the\ngraph Laplacian of a subgraph in terms of a sparse edge selection vector\n$\\mathbf{w}$. We provide both theoretical and empirical justifications on the\nvalidity of our Graph-PRI approach. We also analyze its analytical solutions in\na few special cases. We finally present three representative real-world\napplications, namely graph sparsification, graph regularized multi-task\nlearning, and medical imaging-derived brain network classification, to\ndemonstrate the effectiveness, the versatility and the enhanced\ninterpretability of our approach over prevalent sparsification techniques. Code\nof Graph-PRI is available at https://github.com/SJYuCNEL/PRI-Graphs",
    "descriptor": "\nComments: accepted by UAI-22\n",
    "authors": [
      "Shujian Yu",
      "Francesco Alesiani",
      "Wenzhe Yin",
      "Robert Jenssen",
      "Jose C. Principe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.00118"
  },
  {
    "id": "arXiv:2206.00121",
    "title": "Near-Optimal Collaborative Learning in Bandits",
    "abstract": "This paper introduces a general multi-agent bandit model in which each agent\nis facing a finite set of arms and may communicate with other agents through a\ncentral controller in order to identify, in pure exploration, or play, in\nregret minimization, its optimal arm. The twist is that the optimal arm for\neach agent is the arm with largest expected mixed reward, where the mixed\nreward of an arm is a weighted sum of the rewards of this arm for all agents.\nThis makes communication between agents often necessary. This general setting\nallows to recover and extend several recent models for collaborative bandit\nlearning, including the recently proposed federated learning with\npersonalization (Shi et al., 2021). In this paper, we provide new lower bounds\non the sample complexity of pure exploration and on the regret. We then propose\na near-optimal algorithm for pure exploration. This algorithm is based on\nphased elimination with two novel ingredients: a data-dependent sampling scheme\nwithin each phase, aimed at matching a relaxation of the lower bound.",
    "descriptor": "",
    "authors": [
      "Cl\u00e9mence R\u00e9da",
      "Sattar Vakili",
      "Emilie Kaufmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.00121"
  },
  {
    "id": "arXiv:2206.00123",
    "title": "Glo-In-One: Holistic Glomerular Detection, Segmentation, and Lesion  Characterization with Large-scale Web Image Mining",
    "abstract": "The quantitative detection, segmentation, and characterization of glomeruli\nfrom high-resolution whole slide imaging (WSI) play essential roles in the\ncomputer-assisted diagnosis and scientific research in digital renal pathology.\nHistorically, such comprehensive quantification requires extensive programming\nskills in order to be able to handle heterogeneous and customized computational\ntools. To bridge the gap of performing glomerular quantification for\nnon-technical users, we develop the Glo-In-One toolkit to achieve holistic\nglomerular detection, segmentation, and characterization via a single line of\ncommand. Additionally, we release a large-scale collection of 30,000 unlabeled\nglomerular images to further facilitate the algorithmic development of\nself-supervised deep learning. The inputs of the Glo-In-One toolkit are WSIs,\nwhile the outputs are (1) WSI-level multi-class circle glomerular detection\nresults (which can be directly manipulated with ImageScope), (2) glomerular\nimage patches with segmentation masks, and (3) different lesion types. To\nleverage the performance of the Glo-In-One toolkit, we introduce\nself-supervised deep learning to glomerular quantification via large-scale web\nimage mining. The GGS fine-grained classification model achieved a decent\nperformance compared with baseline supervised methods while only using 10% of\nthe annotated data. The glomerular detection achieved an average precision of\n0.627 with circle representations, while the glomerular segmentation achieved a\n0.955 patch-wise Dice Similarity Coefficient (DSC).",
    "descriptor": "",
    "authors": [
      "Tianyuan Yao",
      "Yuzhe Lu",
      "Jun Long",
      "Aadarsh Jha",
      "Zheyu Zhu",
      "Zuhayr Asad",
      "Haichun Yang",
      "Agnes B. Fogo",
      "Yuankai Huo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.00123"
  },
  {
    "id": "arXiv:2206.00129",
    "title": "Fairness Transferability Subject to Bounded Distribution Shift",
    "abstract": "Given an algorithmic predictor that is \"fair\" on some source distribution,\nwill it still be fair on an unknown target distribution that differs from the\nsource within some bound? In this paper, we study the transferability of\nstatistical group fairness for machine learning predictors (i.e., classifiers\nor regressors) subject to bounded distribution shift, a phenomenon frequently\ncaused by user adaptation to a deployed model or a dynamic environment. Herein,\nwe develop a bound characterizing such transferability, flagging potentially\ninappropriate deployments of machine learning for socially consequential tasks.\nWe first develop a framework for bounding violations of statistical fairness\nsubject to distribution shift, formulating a generic upper bound for\ntransferred fairness violation as our primary result. We then develop bounds\nfor specific worked examples, adopting two commonly used fairness definitions\n(i.e., demographic parity and equalized odds) for two classes of distribution\nshift (i.e., covariate shift and label shift). Finally, we compare our\ntheoretical bounds to deterministic models of distribution shift as well as\nreal-world data.",
    "descriptor": "",
    "authors": [
      "Yatong Chen",
      "Reilly Raab",
      "Jialu Wang",
      "Yang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.00129"
  },
  {
    "id": "arXiv:2206.00130",
    "title": "CBS-Budget (CBSB): A Complete and Bounded Suboptimal Search for  Multi-Agent Path Finding",
    "abstract": "Multi-Agent Path Finding (MAPF) is the problem of finding a collection of\ncollision-free paths for a team of multiple agents while minimizing some global\ncost, such as the sum of the time travelled by all agents, or the time\ntravelled by the last agent. Conflict Based Search (CBS) is a leading complete\nand optimal MAPF solver which lazily explores the joint agent state space,\nusing an admissible heuristic joint plan. Such an admissible heuristic joint\nplan is computed by combining individual shortest paths found without\nconsidering inter-agent conflicts, and which becomes gradually more informed as\nconstraints are added to individual agents' path planning problems to avoid\ndiscovered conflicts. In this paper, we seek to speedup CBS by finding a more\ninformed heuristic joint plan which is bounded from above. We first propose the\nbudgeted Class-Ordered A* (bCOA*), a novel algorithm that finds the shortest\npath with minimal number of conflicts that is upper bounded in terms of length.\nThen, we propose a novel bounded-cost variant of CBS, called CBS-Budget (CBSB)\nby using a bCOA* search at the low-level search of the CBS and by using a\nmodified focal search at the high-level search of the CBS. We prove that CBSB\nis complete and bounded-suboptimal. In our numerical experiments, CBSB finds a\nnear optimal solution for hundreds of agents within a fraction of a second.\nCBSB shows state-of-the-art performance, comparable to Explicit Estimation CBS\n(EECBS), an enhanced recent version of CBS. On the other hand, CBSB is easier\nto implement than EECBS, since only two priority queues at the high-level\nsearch are needed as in Enhanced CBS (ECBS).",
    "descriptor": "",
    "authors": [
      "Jaein Lim",
      "Panagiotis Tsiotras"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.00130"
  },
  {
    "id": "arXiv:2206.00133",
    "title": "Pre-training via Denoising for Molecular Property Prediction",
    "abstract": "Many important problems involving molecular property prediction from 3D\nstructures have limited data, posing a generalization challenge for neural\nnetworks. In this paper, we describe a pre-training technique that utilizes\nlarge datasets of 3D molecular structures at equilibrium to learn meaningful\nrepresentations for downstream tasks. Inspired by recent advances in noise\nregularization, our pre-training objective is based on denoising. Relying on\nthe well-known link between denoising autoencoders and score-matching, we also\nshow that the objective corresponds to learning a molecular force field --\narising from approximating the physical state distribution with a mixture of\nGaussians -- directly from equilibrium structures. Our experiments demonstrate\nthat using this pre-training objective significantly improves performance on\nmultiple benchmarks, achieving a new state-of-the-art on the majority of\ntargets in the widely used QM9 dataset. Our analysis then provides practical\ninsights into the effects of different factors -- dataset sizes, model size and\narchitecture, and the choice of upstream and downstream datasets -- on\npre-training.",
    "descriptor": "",
    "authors": [
      "Sheheryar Zaidi",
      "Michael Schaarschmidt",
      "James Martens",
      "Hyunjik Kim",
      "Yee Whye Teh",
      "Alvaro Sanchez-Gonzalez",
      "Peter Battaglia",
      "Razvan Pascanu",
      "Jonathan Godwin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.00133"
  },
  {
    "id": "arXiv:2206.00134",
    "title": "A Formula for the Determinant",
    "abstract": "We give a formula for the determinant of an $n\\times n$ matrix with entries\nfrom a commutative ring with unit. The formula can be evaluated by a\n\"straight-line program\" performing only additions, subtractions and\nmultiplications of ring elements; in particular it requires no divisions or\nconditional branching (as are required, for example, by Gaussian elimination).\nThe number of operations performed is bounded by a fixed power of $n$,\nspecifically $O(n^4\\log n)$. Furthermore, the operations can be partitioned\ninto \"stages\" in such a way that the operands of the operations in a given\nstage are either matrix entries or the results of operations in earlier stages,\nand the number of stages is bounded by a fixed power of the logarithm of $n$,\nspecifically $O\\big((\\log n)^2\\big)$.",
    "descriptor": "\nComments: i+13 pages\n",
    "authors": [
      "Nicholas Pippenger"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Commutative Algebra (math.AC)"
    ],
    "url": "https://arxiv.org/abs/2206.00134"
  },
  {
    "id": "arXiv:2206.00136",
    "title": "End-to-end Optimization of Machine Learning Prediction Queries",
    "abstract": "Prediction queries are widely used across industries to perform advanced\nanalytics and draw insights from data. They include a data processing part\n(e.g., for joining, filtering, cleaning, featurizing the datasets) and a\nmachine learning (ML) part invoking one or more trained models to perform\npredictions. These parts have so far been optimized in isolation, leaving\nsignificant opportunities for optimization unexplored. We present Raven, a\nproduction-ready system for optimizing prediction queries. Raven follows the\nenterprise architectural trend of collocating data and ML runtimes. It relies\non a unified intermediate representation that captures both data and ML\noperators in a single graph structure to unlock two families of optimizations.\nFirst, it employs logical optimizations that pass information between the data\npart (and the properties of the underlying data) and the ML part to optimize\neach other. Second, it introduces logical-to-physical transformations that\nallow operators to be executed on different runtimes (relational, ML, and DNN)\nand hardware (CPU, GPU). Novel data-driven optimizations determine the runtime\nto be used for each part of the query to achieve optimal performance. Our\nevaluation shows that Raven improves performance of prediction queries on\nApache Spark and SQL Server by up to 13.1x and 330x, respectively. For complex\nmodels where GPU acceleration is beneficial, Raven provides up to 8x speedup\ncompared to state-of-the-art systems.",
    "descriptor": "",
    "authors": [
      "Kwanghyun Park",
      "Karla Saur",
      "Dalitso Banda",
      "Rathijit Sen",
      "Matteo Interlandi",
      "Konstantinos Karanasos"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00136"
  },
  {
    "id": "arXiv:2206.00137",
    "title": "Social Bias Meets Data Bias: The Impacts of Labeling and Measurement  Errors on Fairness Criteria",
    "abstract": "Although many fairness criteria have been proposed to ensure that machine\nlearning algorithms do not exhibit or amplify our existing social biases, these\nalgorithms are trained on datasets that can themselves be statistically biased.\nIn this paper, we investigate the robustness of a number of existing\n(demographic) fairness criteria when the algorithm is trained on biased data.\nWe consider two forms of dataset bias: errors by prior decision makers in the\nlabeling process, and errors in measurement of the features of disadvantaged\nindividuals. We analytically show that some constraints (such as Demographic\nParity) can remain robust when facing certain statistical biases, while others\n(such as Equalized Odds) are significantly violated if trained on biased data.\nWe also analyze the sensitivity of these criteria and the decision maker's\nutility to biases. We provide numerical experiments based on three real-world\ndatasets (the FICO, Adult, and German credit score datasets) supporting our\nanalytical findings. Our findings present an additional guideline for choosing\namong existing fairness criteria, or for proposing new criteria, when available\ndatasets may be biased.",
    "descriptor": "",
    "authors": [
      "Yiqiao Liao",
      "Parinaz Naghizadeh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.00137"
  },
  {
    "id": "arXiv:2206.00140",
    "title": "What Can Database Query Processing Do for Instance-Spanning Constraints?",
    "abstract": "In the last decade, the term instance-spanning constraint has been introduced\nin the process mining field to refer to constraints that span multiple process\ninstances of one or several processes. Of particular relevance, in this\nsetting, is checking whether process executions comply with constraints of\ninterest, which at runtime calls for suitable monitoring techniques. Even\nthough event data are often stored in some sort of database, there is a lack of\ndatabase-oriented approaches to tackle compliance checking and monitoring of\n(instance-spanning) constraints. In this paper, we fill this gap by showing how\nwell-established technology from database query processing can be effectively\nused for this purpose. We propose to define an instance-spanning constraint\nthrough an ensemble of four database queries that retrieve the satisfying,\nviolating, pending-satisfying, and pending-violating cases of the constraint.\nIn this context, the problem of compliance monitoring then becomes an\napplication of techniques for incremental view maintenance, which is\nwell-developed in database query processing. In this paper, we argue for our\napproach in detail, and, as a proof of concept, present an experimental\nvalidation using the DBToaster incremental database query engine.",
    "descriptor": "",
    "authors": [
      "Heba Aamer",
      "Marco Montali",
      "Jan Van den Bussche"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2206.00140"
  },
  {
    "id": "arXiv:2206.00142",
    "title": "IGLU Gridworld: Simple and Fast Environment for Embodied Dialog Agents",
    "abstract": "We present the IGLU Gridworld: a reinforcement learning environment for\nbuilding and evaluating language conditioned embodied agents in a scalable way.\nThe environment features visual agent embodiment, interactive learning through\ncollaboration, language conditioned RL, and combinatorically hard task (3d\nblocks building) space.",
    "descriptor": "",
    "authors": [
      "Artem Zholus",
      "Alexey Skrynnik",
      "Shrestha Mohanty",
      "Zoya Volovikova",
      "Julia Kiseleva",
      "Artur Szlam",
      "Marc-Alexandre Cot\u00e9",
      "Aleksandr I. Panov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.00142"
  },
  {
    "id": "arXiv:2206.00145",
    "title": "CASSOCK: Viable Backdoor Attacks against DNN in The Wall of  Source-Specific Backdoor Defences",
    "abstract": "Backdoor attacks have been a critical threat to deep neural network (DNN).\nHowever, most existing countermeasures focus on source-agnostic backdoor\nattacks (SABAs) and fail to defeat source-specific backdoor attacks (SSBAs).\nCompared to an SABA, an SSBA activates a backdoor when an input from\nattacker-chosen class(es) is stamped with an attacker-specified trigger, making\nitself stealthier and thus evade most existing backdoor mitigation.\nNonetheless, existing SSBAs have trade-offs on attack success rate (ASR, a\nbackdoor is activated by a trigger input from a source class as expected) and\nfalse positive rate (FPR, a backdoor is activated unexpectedly by a trigger\ninput from a non-source class). Significantly, they can still be effectively\ndetected by the state-of-the-art (SOTA) countermeasures targeting SSBAs. This\nwork overcomes efficiency and effectiveness deficiencies of existing SSBAs,\nthus bypassing the SOTA defences. The key insight is to construct desired\npoisoned and cover data during backdoor training by characterising SSBAs\nin-depth. Both data are samples with triggers: the cover/poisoned data from\nnon-source/source class(es) holds ground-truth/target labels. Therefore, two\ncover/poisoned data enhancements are developed from trigger style and content,\nrespectively, coined CASSOCK. First, we leverage trigger patterns with\ndiscrepant transparency to craft cover/poisoned data, enforcing triggers with\nheterogeneous sensitivity on different classes. The second enhancement chooses\nthe target class features as triggers to craft these samples, entangling\ntrigger features with the target class heavily. Compared with existing SSBAs,\nCASSOCK-based attacks have higher ASR and low FPR on four popular tasks: MNIST,\nCIFAR10, GTSRB, and LFW. More importantly, CASSOCK has effectively evaded three\ndefences (SCAn, Februus and extended Neural Cleanse) already defeat existing\nSSBAs effectively.",
    "descriptor": "\nComments: 11pages,7 figures\n",
    "authors": [
      "Shang Wang",
      "Yansong Gao",
      "Anmin Fu",
      "Zhi Zhang",
      "Yuqing Zhang",
      "Willy Susilo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00145"
  },
  {
    "id": "arXiv:2206.00147",
    "title": "Unbiased Implicit Feedback via Bi-level Optimization",
    "abstract": "Implicit feedback is widely leveraged in recommender systems since it is easy\nto collect and provides weak supervision signals. Recent works reveal a huge\ngap between the implicit feedback and user-item relevance due to the fact that\nimplicit feedback is also closely related to the item exposure. To bridge this\ngap, existing approaches explicitly model the exposure and propose unbiased\nestimators to improve the relevance. Unfortunately, these unbiased estimators\nsuffer from the high gradient variance, especially for long-tail items, leading\nto inaccurate gradient updates and degraded model performance. To tackle this\nchallenge, we propose a low-variance unbiased estimator from a probabilistic\nperspective, which effectively bounds the variance of the gradient. Unlike\nprevious works which either estimate the exposure via heuristic-based\nstrategies or use a large biased training set, we propose to estimate the\nexposure via an unbiased small-scale validation set. Specifically, we first\nparameterize the user-item exposure by incorporating both user and item\ninformation, and then construct an unbiased validation set from the biased\ntraining set. By leveraging the unbiased validation set, we adopt bi-level\noptimization to automatically update exposure-related parameters along with\nrecommendation model parameters during the learning. Experiments on two\nreal-world datasets and two semi-synthetic datasets verify the effectiveness of\nour method.",
    "descriptor": "",
    "authors": [
      "Can Chen",
      "Chen Ma",
      "Xi Chen",
      "Sirui Song",
      "Hao Liu",
      "Xue Liu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.00147"
  },
  {
    "id": "arXiv:2206.00148",
    "title": "Hands-Up: Leveraging Synthetic Data for Hands-On-Wheel Detection",
    "abstract": "Over the past few years there has been major progress in the field of\nsynthetic data generation using simulation based techniques. These methods use\nhigh-end graphics engines and physics-based ray-tracing rendering in order to\nrepresent the world in 3D and create highly realistic images. Datagen has\nspecialized in the generation of high-quality 3D humans, realistic 3D\nenvironments and generation of realistic human motion. This technology has been\ndeveloped into a data generation platform which we used for these experiments.\nThis work demonstrates the use of synthetic photo-realistic in-cabin data to\ntrain a Driver Monitoring System that uses a lightweight neural network to\ndetect whether the driver's hands are on the wheel. We demonstrate that when\nonly a small amount of real data is available, synthetic data can be a simple\nway to boost performance. Moreover, we adopt the data-centric approach and show\nhow performing error analysis and generating the missing edge-cases in our\nplatform boosts performance. This showcases the ability of human-centric\nsynthetic data to generalize well to the real world, and help train algorithms\nin computer vision settings where data from the target domain is scarce or hard\nto collect.",
    "descriptor": "",
    "authors": [
      "Paul Yudkin",
      "Eli Friedman",
      "Orly Zvitia",
      "Gil Elbaz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00148"
  },
  {
    "id": "arXiv:2206.00151",
    "title": "DotMat: Solving Cold-start Problem and Alleviating Sparsity Problem for  Recommender Systems",
    "abstract": "Cold-start and sparsity problem are two key intrinsic problems to recommender\nsystems. During the past two decades, researchers and industrial practitioners\nhave spent considerable amount of efforts trying to solve the problems.\nHowever, for cold-start problem, most research relies on importing side\ninformation to transfer knowledge. A notable exception is ZeroMat, which uses\nno extra input data. Sparsity is a lesser noticed problem. In this paper, we\npropose a new algorithm named DotMat that relies on no extra input data, but is\ncapable of solving cold-start and sparsity problems. In experiments, we prove\nthat like ZeroMat, DotMat can achieve competitive results with recommender\nsystems with full data, such as the classic matrix factorization algorithm.",
    "descriptor": "",
    "authors": [
      "Hao Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.00151"
  },
  {
    "id": "arXiv:2206.00152",
    "title": "Human-AI Shared Control via Frequency-based Policy Dissection",
    "abstract": "Human-AI shared control allows human to interact and collaborate with AI to\naccomplish control tasks in complex environments. Previous Reinforcement\nLearning (RL) methods attempt the goal-conditioned design to achieve\nhuman-controllable policies at the cost of redesigning the reward function and\ntraining paradigm. Inspired by the neuroscience approach to investigate the\nmotor cortex in primates, we develop a simple yet effective frequency-based\napproach called \\textit{Policy Dissection} to align the intermediate\nrepresentation of the learned neural controller with the kinematic attributes\nof the agent behavior. Without modifying the neural controller or retraining\nthe model, the proposed approach can convert a given RL-trained policy into a\nhuman-interactive policy. We evaluate the proposed approach on the RL tasks of\nautonomous driving and locomotion. The experiments show that human-AI shared\ncontrol achieved by Policy Dissection in driving task can substantially improve\nthe performance and safety in unseen traffic scenes. With human in the loop,\nthe locomotion robots also exhibit versatile controllable motion skills even\nthough they are only trained to move forward. Our results suggest the promising\ndirection of implementing human-AI shared autonomy through interpreting the\nlearned representation of the autonomous agents. Demo video and code will be\nmade available at https://metadriverse.github.io/policydissect.",
    "descriptor": "",
    "authors": [
      "Quanyi Li",
      "Zhenghao Peng",
      "Haibin Wu",
      "Lan Feng",
      "Bolei Zhou"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.00152"
  },
  {
    "id": "arXiv:2206.00159",
    "title": "Provably Efficient Offline Multi-agent Reinforcement Learning via  Strategy-wise Bonus",
    "abstract": "This paper considers offline multi-agent reinforcement learning. We propose\nthe strategy-wise concentration principle which directly builds a confidence\ninterval for the joint strategy, in contrast to the point-wise concentration\nprinciple that builds a confidence interval for each point in the joint action\nspace. For two-player zero-sum Markov games, by exploiting the convexity of the\nstrategy-wise bonus, we propose a computationally efficient algorithm whose\nsample complexity enjoys a better dependency on the number of actions than the\nprior methods based on the point-wise bonus. Furthermore, for offline\nmulti-agent general-sum Markov games, based on the strategy-wise bonus and a\nnovel surrogate function, we give the first algorithm whose sample complexity\nonly scales $\\sum_{i=1}^mA_i$ where $A_i$ is the action size of the $i$-th\nplayer and $m$ is the number of players. In sharp contrast, the sample\ncomplexity of methods based on the point-wise bonus would scale with the size\nof the joint action space $\\Pi_{i=1}^m A_i$ due to the curse of multiagents.\nLastly, all of our algorithms can naturally take a pre-specified strategy class\n$\\Pi$ as input and output a strategy that is close to the best strategy in\n$\\Pi$. In this setting, the sample complexity only scales with $\\log |\\Pi|$\ninstead of $\\sum_{i=1}^mA_i$.",
    "descriptor": "\nComments: 34 pages\n",
    "authors": [
      "Qiwen Cui",
      "Simon S. Du"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2206.00159"
  },
  {
    "id": "arXiv:2206.00160",
    "title": "On a Control Architecture for Future Electric Energy Systems",
    "abstract": "This paper presents considerations towards a control architecture for future\nelectric energy systems driven by massive changes resulting from the societal\ngoals of decarbonization and electrification. A historical perspective is\nprovided on the role that architecture and abstractions have played in other\ntechnological systems such as the Internet, serial computation, and\ncommunication systems. For power systems, we present a viewpoint of\narchitecture as the organization of multiple control loops aligned with the\nentities involved, as well as taking advantage of time-scale and spatial scale\nseparations. New requirements and challenges in designing the set of control\nloops required for future electric energy systems are substantiated from a\ntemporal and spatial scale perspective. Finally, we articulate key desirable\ncontrol loops that can enable decarbonization of the electricity sector. We\nthereby argue that the present architecture of electric power grids designed in\na different era is indeed extensible to allow the incorporation of increased\nrenewables.",
    "descriptor": "\nComments: Submitted to Proceedings of the IEEE\n",
    "authors": [
      "Le Xie",
      "Tong Huang",
      "P. R. Kumar",
      "Anupam A. Thatte",
      "Sanjoy K. Mitter"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.00160"
  },
  {
    "id": "arXiv:2206.00162",
    "title": "PAGER: Progressive Attribute-Guided Extendable Robust Image Generation",
    "abstract": "This work presents a generative modeling approach based on successive\nsubspace learning (SSL). Unlike most generative models in the literature, our\nmethod does not utilize neural networks to analyze the underlying source\ndistribution and synthesize images. The resulting method, called the\nprogressive attribute-guided extendable robust image generative (PAGER) model,\nhas advantages in mathematical transparency, progressive content generation,\nlower training time, robust performance with fewer training samples, and\nextendibility to conditional image generation. PAGER consists of three modules:\ncore generator, resolution enhancer, and quality booster. The core generator\nlearns the distribution of low-resolution images and performs unconditional\nimage generation. The resolution enhancer increases image resolution via\nconditional generation. Finally, the quality booster adds finer details to\ngenerated images. Extensive experiments on MNIST, Fashion-MNIST, and CelebA\ndatasets are conducted to demonstrate generative performance of PAGER.",
    "descriptor": "\nComments: 16 pages, 10 figures, 2 tables\n",
    "authors": [
      "Zohreh Azizi",
      "C.-C. Jay Kuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.00162"
  },
  {
    "id": "arXiv:2206.00164",
    "title": "A Theoretical Framework for Inference Learning",
    "abstract": "Backpropagation (BP) is the most successful and widely used algorithm in deep\nlearning. However, the computations required by BP are challenging to reconcile\nwith known neurobiology. This difficulty has stimulated interest in more\nbiologically plausible alternatives to BP. One such algorithm is the inference\nlearning algorithm (IL). IL has close connections to neurobiological models of\ncortical function and has achieved equal performance to BP on supervised\nlearning and auto-associative tasks. In contrast to BP, however, the\nmathematical foundations of IL are not well-understood. Here, we develop a\nnovel theoretical framework for IL. Our main result is that IL closely\napproximates an optimization method known as implicit stochastic gradient\ndescent (implicit SGD), which is distinct from the explicit SGD implemented by\nBP. Our results further show how the standard implementation of IL can be\naltered to better approximate implicit SGD. Our novel implementation\nconsiderably improves the stability of IL across learning rates, which is\nconsistent with our theory, as a key property of implicit SGD is its stability.\nWe provide extensive simulation results that further support our theoretical\ninterpretations and also demonstrate IL achieves quicker convergence when\ntrained with small mini-batches while matching the performance of BP for large\nmini-batches.",
    "descriptor": "",
    "authors": [
      "Nick Alonso",
      "Beren Millidge",
      "Jeff Krichmar",
      "Emre Neftci"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00164"
  },
  {
    "id": "arXiv:2206.00165",
    "title": "Byzantine-Robust Online and Offline Distributed Reinforcement Learning",
    "abstract": "We consider a distributed reinforcement learning setting where multiple\nagents separately explore the environment and communicate their experiences\nthrough a central server. However, $\\alpha$-fraction of agents are adversarial\nand can report arbitrary fake information. Critically, these adversarial agents\ncan collude and their fake data can be of any sizes. We desire to robustly\nidentify a near-optimal policy for the underlying Markov decision process in\nthe presence of these adversarial agents. Our main technical contribution is\nWeighted-Clique, a novel algorithm for the robust mean estimation from batches\nproblem, that can handle arbitrary batch sizes. Building upon this new\nestimator, in the offline setting, we design a Byzantine-robust distributed\npessimistic value iteration algorithm; in the online setting, we design a\nByzantine-robust distributed optimistic value iteration algorithm. Both\nalgorithms obtain near-optimal sample complexities and achieve superior\nrobustness guarantee than prior works.",
    "descriptor": "",
    "authors": [
      "Yiding Chen",
      "Xuezhou Zhang",
      "Kaiqing Zhang",
      "Mengdi Wang",
      "Xiaojin Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.00165"
  },
  {
    "id": "arXiv:2206.00167",
    "title": "Understanding How People Rate Their Conversations",
    "abstract": "User ratings play a significant role in spoken dialogue systems. Typically,\nsuch ratings tend to be averaged across all users and then utilized as feedback\nto improve the system or personalize its behavior. While this method can be\nuseful to understand broad, general issues with the system and its behavior, it\ndoes not take into account differences between users that affect their ratings.\nIn this work, we conduct a study to better understand how people rate their\ninteractions with conversational agents. One macro-level characteristic that\nhas been shown to correlate with how people perceive their inter-personal\ncommunication is personality. We specifically focus on agreeableness and\nextraversion as variables that may explain variation in ratings and therefore\nprovide a more meaningful signal for training or personalization. In order to\nelicit those personality traits during an interaction with a conversational\nagent, we designed and validated a fictional story, grounded in prior work in\npsychology. We then implemented the story into an experimental conversational\nagent that allowed users to opt-in to hearing the story. Our results suggest\nthat for human-conversational agent interactions, extraversion may play a role\nin user ratings, but more data is needed to determine if the relationship is\nsignificant. Agreeableness, on the other hand, plays a statistically\nsignificant role in conversation ratings: users who are more agreeable are more\nlikely to provide a higher rating for their interaction. In addition, we found\nthat users who opted to hear the story were, in general, more likely to rate\ntheir conversational experience higher than those who did not.",
    "descriptor": "\nComments: Published at IWSDS 2021\n",
    "authors": [
      "Alexandros Papangelis",
      "Nicole Chartier",
      "Pankaj Rajan",
      "Julia Hirschberg",
      "Dilek Hakkani-Tur"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.00167"
  },
  {
    "id": "arXiv:2206.00169",
    "title": "Discovering the Hidden Vocabulary of DALLE-2",
    "abstract": "We discover that DALLE-2 seems to have a hidden vocabulary that can be used\nto generate images with absurd prompts. For example, it seems that\n\\texttt{Apoploe vesrreaitais} means birds and \\texttt{Contarra ccetnxniams\nluryca tanniounons} (sometimes) means bugs or pests. We find that these prompts\nare often consistent in isolation but also sometimes in combinations. We\npresent our black-box method to discover words that seem random but have some\ncorrespondence to visual concepts. This creates important security and\ninterpretability challenges.",
    "descriptor": "\nComments: 6 pages, 4 figures\n",
    "authors": [
      "Giannis Daras",
      "Alexandros G. Dimakis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.00169"
  },
  {
    "id": "arXiv:2206.00171",
    "title": "Learning Sequential Contexts using Transformer for 3D Hand Pose  Estimation",
    "abstract": "3D hand pose estimation (HPE) is the process of locating the joints of the\nhand in 3D from any visual input. HPE has recently received an increased amount\nof attention due to its key role in a variety of human-computer interaction\napplications. Recent HPE methods have demonstrated the advantages of employing\nvideos or multi-view images, allowing for more robust HPE systems. Accordingly,\nin this study, we propose a new method to perform Sequential learning with\nTransformer for Hand Pose (SeTHPose) estimation. Our SeTHPose pipeline begins\nby extracting visual embeddings from individual hand images. We then use a\ntransformer encoder to learn the sequential context along time or viewing\nangles and generate accurate 2D hand joint locations. Then, a graph\nconvolutional neural network with a U-Net configuration is used to convert the\n2D hand joint locations to 3D poses. Our experiments show that SeTHPose\nperforms well on both hand sequence varieties, temporal and angular. Also,\nSeTHPose outperforms other methods in the field to achieve new state-of-the-art\nresults on two public available sequential datasets, STB and MuViHand.",
    "descriptor": "",
    "authors": [
      "Leyla Khaleghi",
      "Joshua Marshall",
      "Ali Etemad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.00171"
  },
  {
    "id": "arXiv:2206.00172",
    "title": "Towards an AAK Theory Approach to Approximate Minimization in the  Multi-Letter Case",
    "abstract": "We study the approximate minimization problem of weighted finite automata\n(WFAs): given a WFA, we want to compute its optimal approximation when\nrestricted to a given size. We reformulate the problem as a rank-minimization\ntask in the spectral norm, and propose a framework to apply Adamyan-Arov-Krein\n(AAK) theory to the approximation problem. This approach has already been\nsuccessfully applied to the case of WFAs and language modelling black boxes\nover one-letter alphabets \\citep{AAK-WFA,AAK-RNN}. Extending the result to\nmulti-letter alphabets requires solving the following two steps. First, we need\nto reformulate the approximation problem in terms of noncommutative Hankel\noperators and noncommutative functions, in order to apply results from\nmultivariable operator theory. Secondly, to obtain the optimal approximation we\nneed a version of noncommutative AAK theory that is constructive. In this\npaper, we successfully tackle the first step, while the second challenge\nremains open.",
    "descriptor": "\nComments: LearnAut 2022\n",
    "authors": [
      "Clara Lacroce",
      "Prakash Panangaden",
      "Guillaume Rabusseau"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2206.00172"
  },
  {
    "id": "arXiv:2206.00176",
    "title": "Learning Sparse Nonlinear Dynamics via Mixed-Integer Optimization",
    "abstract": "Discovering governing equations of complex dynamical systems directly from\ndata is a central problem in scientific machine learning. In recent years, the\nsparse identification of nonlinear dynamics (SINDy) framework, powered by\nheuristic sparse regression methods, has become a dominant tool for learning\nparsimonious models. We propose an exact formulation of the SINDy problem using\nmixed-integer optimization (MIO) to solve the sparsity constrained regression\nproblem to provable optimality in seconds. On a large number of canonical\nordinary and partial differential equations, we illustrate the dramatic\nimprovement of our approach in accurate model discovery while being more sample\nefficient, robust to noise, and flexible in accommodating physical constraints.",
    "descriptor": "",
    "authors": [
      "Dimitris Bertsimas",
      "Wes Gurnee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.00176"
  },
  {
    "id": "arXiv:2206.00177",
    "title": "On Gap-dependent Bounds for Offline Reinforcement Learning",
    "abstract": "This paper presents a systematic study on gap-dependent sample complexity in\noffline reinforcement learning. Prior work showed when the density ratio\nbetween an optimal policy and the behavior policy is upper bounded (the optimal\npolicy coverage assumption), then the agent can achieve an\n$O\\left(\\frac{1}{\\epsilon^2}\\right)$ rate, which is also minimax optimal. We\nshow under the optimal policy coverage assumption, the rate can be improved to\n$O\\left(\\frac{1}{\\epsilon}\\right)$ when there is a positive sub-optimality gap\nin the optimal $Q$-function. Furthermore, we show when the visitation\nprobabilities of the behavior policy are uniformly lower bounded for states\nwhere an optimal policy's visitation probabilities are positive (the uniform\noptimal policy coverage assumption), the sample complexity of identifying an\noptimal policy is independent of $\\frac{1}{\\epsilon}$. Lastly, we present\nnearly-matching lower bounds to complement our gap-dependent upper bounds.",
    "descriptor": "\nComments: 33 pages, 1 figure, submitted to NeurIPS 2022\n",
    "authors": [
      "Xinqi Wang",
      "Qiwen Cui",
      "Simon S. Du"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.00177"
  },
  {
    "id": "arXiv:2206.00181",
    "title": "Labeling Where Adapting Fails: Cross-Domain Semantic Segmentation with  Point Supervision via Active Selection",
    "abstract": "Training models dedicated to semantic segmentation requires a large amount of\npixel-wise annotated data. Due to their costly nature, these annotations might\nnot be available for the task at hand. To alleviate this problem, unsupervised\ndomain adaptation approaches aim at aligning the feature distributions between\nthe labeled source and the unlabeled target data. While these strategies lead\nto noticeable improvements, their effectiveness remains limited. To guide the\ndomain adaptation task more efficiently, previous works attempted to include\nhuman interactions in this process under the form of sparse single-pixel\nannotations in the target data. In this work, we propose a new domain\nadaptation framework for semantic segmentation with annotated points via active\nselection. First, we conduct an unsupervised domain adaptation of the model;\nfrom this adaptation, we use an entropy-based uncertainty measurement for\ntarget points selection. Finally, to minimize the domain gap, we propose a\ndomain adaptation framework utilizing these target points annotated by human\nannotators. Experimental results on benchmark datasets show the effectiveness\nof our methods against existing unsupervised domain adaptation approaches. The\npropose pipeline is generic and can be included as an extra module to existing\ndomain adaptation strategies.",
    "descriptor": "",
    "authors": [
      "Fei Pan",
      "Francois Rameau",
      "In So Kweon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.00181"
  },
  {
    "id": "arXiv:2206.00182",
    "title": "Differentiable Soft-Masked Attention",
    "abstract": "Transformers have become prevalent in computer vision due to their\nperformance and flexibility in modelling complex operations. Of particular\nsignificance is the 'cross-attention' operation, which allows a vector\nrepresentation (e.g. of an object in an image) to be learned by attending to an\narbitrarily sized set of input features. Recently, \"Masked Attention\" was\nproposed in which a given object representation only attends to those image\npixel features for which the segmentation mask of that object is active. This\nspecialization of attention proved beneficial for various image and video\nsegmentation tasks. In this paper, we propose another specialization of\nattention which enables attending over `soft-masks' (those with continuous mask\nprobabilities instead of binary values), and is also differentiable through\nthese mask probabilities, thus allowing the mask used for attention to be\nlearned within the network without requiring direct loss supervision. This can\nbe useful for several applications. Specifically, we employ our \"Differentiable\nSoft-Masked Attention\" for the task of Weakly-Supervised Video Object\nSegmentation (VOS), where we develop a transformer-based network for VOS which\nonly requires a single annotated image frame for training, but can also benefit\nfrom cycle consistency training on a video with just one annotated frame.\nAlthough there is no loss for masks in unlabeled frames, the network is still\nable to segment objects in those frames due to our novel attention formulation.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2112.09131\n",
    "authors": [
      "Ali Athar",
      "Jonathon Luiten",
      "Alexander Hermans",
      "Deva Ramanan",
      "Bastian Leibe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.00182"
  },
  {
    "id": "arXiv:2206.00184",
    "title": "How Much Demand Flexibility Could Have Spared Texas from the 2021  Outage?",
    "abstract": "The February 2021 Texas winter power outage has led to hundreds of deaths and\nbillions of dollars in economic losses, largely due to the generation failure\nand record-breaking electric demand. In this paper, we study the scaling-up of\ndemand flexibility as a means to avoid load shedding during such an extreme\nweather event. The three mechanisms considered are interruptible load,\nresidential load rationing, and incentive-based demand response. By simulating\non a synthetic but realistic large-scale Texas grid model along with demand\nflexibility modeling and electricity outage data, we identify portfolios of\nmixing mechanisms that exactly avoid outages, which a single mechanism may fail\ndue to decaying marginal effects. We also reveal a complementary relationship\nbetween interruptible load and residential load rationing and find nonlinear\nimpacts of incentive-based demand response on the efficacy of other mechanisms.",
    "descriptor": "\nComments: This paper has been submitted to a journal for review\n",
    "authors": [
      "Dongqi Wu",
      "Xiangtian Zheng",
      "Ali Menati",
      "Lane Smith",
      "Bainan Xia",
      "Yixing Xu",
      "Chanan Singh",
      "Le Xie"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.00184"
  },
  {
    "id": "arXiv:2206.00187",
    "title": "DisPFL: Towards Communication-Efficient Personalized Federated Learning  via Decentralized Sparse Training",
    "abstract": "Personalized federated learning is proposed to handle the data heterogeneity\nproblem amongst clients by learning dedicated tailored local models for each\nuser. However, existing works are often built in a centralized way, leading to\nhigh communication pressure and high vulnerability when a failure or an attack\non the central server occurs. In this work, we propose a novel personalized\nfederated learning framework in a decentralized (peer-to-peer) communication\nprotocol named Dis-PFL, which employs personalized sparse masks to customize\nsparse local models on the edge. To further save the communication and\ncomputation cost, we propose a decentralized sparse training technique, which\nmeans that each local model in Dis-PFL only maintains a fixed number of active\nparameters throughout the whole local training and peer-to-peer communication\nprocess. Comprehensive experiments demonstrate that Dis-PFL significantly saves\nthe communication bottleneck for the busiest node among all clients and, at the\nsame time, achieves higher model accuracy with less computation cost and\ncommunication rounds. Furthermore, we demonstrate that our method can easily\nadapt to heterogeneous local clients with varying computation complexities and\nachieves better personalized performances.",
    "descriptor": "\nComments: To be published in ICML2022\n",
    "authors": [
      "Rong Dai",
      "Li Shen",
      "Fengxiang He",
      "Xinmei Tian",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00187"
  },
  {
    "id": "arXiv:2206.00188",
    "title": "Benchmark of DNN Model Search at Deployment Time",
    "abstract": "Deep learning has become the most popular direction in machine learning and\nartificial intelligence. However, the preparation of training data, as well as\nmodel training, are often time-consuming and become the bottleneck of the\nend-to-end machine learning lifecycle. Reusing models for inferring a dataset\ncan avoid the costs of retraining. However, when there are multiple candidate\nmodels, it is challenging to discover the right model for reuse. Although there\nexist a number of model sharing platforms such as ModelDB, TensorFlow Hub,\nPyTorch Hub, and DLHub, most of these systems require model uploaders to\nmanually specify the details of each model and model downloaders to screen\nkeyword search results for selecting a model. We are lacking a highly\nproductive model search tool that selects models for deployment without the\nneed for any manual inspection and/or labeled data from the target domain. This\npaper proposes multiple model search strategies including various\nsimilarity-based approaches and non-similarity-based approaches. We design,\nimplement, and evaluate these approaches on multiple model inference scenarios,\nincluding activity recognition, image recognition, text classification, natural\nlanguage processing, and entity matching. The experimental evaluation showed\nthat our proposed asymmetric similarity-based measurement, adaptivity,\noutperformed symmetric similarity-based measurements and non-similarity-based\nmeasurements in most of the workloads.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2010.09474\n",
    "authors": [
      "Lixi Zhou",
      "Arindam Jain",
      "Zijie Wang",
      "Amitabh Das",
      "Yingzhen Yang",
      "Jia Zou"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.00188"
  },
  {
    "id": "arXiv:2206.00192",
    "title": "Order-sensitive Shapley Values for Evaluating Conceptual Soundness of  NLP Models",
    "abstract": "Previous works show that deep NLP models are not always conceptually sound:\nthey do not always learn the correct linguistic concepts. Specifically, they\ncan be insensitive to word order. In order to systematically evaluate models\nfor their conceptual soundness with respect to word order, we introduce a new\nexplanation method for sequential data: Order-sensitive Shapley Values (OSV).\nWe conduct an extensive empirical evaluation to validate the method and surface\nhow well various deep NLP models learn word order. Using synthetic data, we\nfirst show that OSV is more faithful in explaining model behavior than\ngradient-based methods. Second, applying to the HANS dataset, we discover that\nthe BERT-based NLI model uses only the word occurrences without word orders.\nAlthough simple data augmentation improves accuracy on HANS, OSV shows that the\naugmented model does not fundamentally improve the model's learning of order.\nThird, we discover that not all sentiment analysis models learn negation\nproperly: some fail to capture the correct syntax of the negation construct.\nFinally, we show that pretrained language models such as BERT may rely on the\nabsolute positions of subject words to learn long-range Subject-Verb Agreement.\nWith each NLP task, we also demonstrate how OSV can be leveraged to generate\nadversarial examples.",
    "descriptor": "",
    "authors": [
      "Kaiji Lu",
      "Anupam Datta"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.00192"
  },
  {
    "id": "arXiv:2206.00204",
    "title": "Intelligent Omni-Surfaces: Reflection-Refraction Circuit Model,  Full-Dimensional Beamforming, and System Implementation",
    "abstract": "The intelligent omni-surface (IOS) is a dynamic metasurface that has recently\nbeen proposed to achieve full-dimensional communications by realizing the dual\nfunction of anomalous reflection and anomalous refraction. Existing research\nworks provide only simplified models for the reflection and refraction\nresponses of the IOS, which do not explicitly depend on the physical structure\nof the IOS and the angle of incidence of the electromagnetic (EM) wave.\nTherefore, the available reflection-refraction models are insufficient to\ncharacterize the performance of full-dimensional communications. In this paper,\nwe propose a complete and detailed circuit-based reflection-refraction model\nfor the IOS, which is formulated in terms of the physical structure and\nequivalent circuits of the IOS elements, as well as we validate it against\nfull-wave EM simulations. Based on the proposed circuit-based model for the\nIOS, we analyze the asymmetry between the reflection and transmission\ncoefficients. Moreover, the proposed circuit-based model is utilized for\noptimizing the hybrid beamforming of IOS-assisted networks and hence improving\nthe system performance. To verify the circuit-based model, the theoretical\nfindings, and to evaluate the performance of full-dimensional beamforming, we\nimplement a prototype of IOS and deploy an IOS-assisted wireless communication\ntestbed to experimentally measure the beam patterns and to quantify the\nachievable rate. The obtained experimental results validate the theoretical\nfindings and the accuracy of the proposed circuit-based reflection-refraction\nmodel for IOSs.",
    "descriptor": "\nComments: 31 pages, 19 figures\n",
    "authors": [
      "Shuhao Zeng",
      "Hongliang Zhang",
      "Boya Di",
      "Yuanwei Liu",
      "Marco Di Renzo",
      "Zhu Han",
      "H. Vincent Poor",
      "Lingyang Song"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.00204"
  },
  {
    "id": "arXiv:2206.00205",
    "title": "CAFA: Class-Aware Feature Alignment for Test-Time Adaptation",
    "abstract": "Despite recent advancements in deep learning, deep networks still suffer from\nperformance degradation when they face new and different data from their\ntraining distributions. Addressing such a problem, test-time adaptation (TTA)\naims to adapt a model to unlabeled test data on test time while making\npredictions simultaneously. TTA applies to pretrained networks without\nmodifying their training procedures, which enables to utilize the already\nwell-formed source distribution for adaptation. One possible approach is to\nalign the representation space of test samples to the source distribution\n(\\textit{i.e.,} feature alignment). However, performing feature alignments in\nTTA is especially challenging in that the access to labeled source data is\nrestricted during adaptation. That is, a model does not have a chance to learn\ntest data in a class-discriminative manner, which was feasible in other\nadaptation tasks (\\textit{e.g.,} unsupervised domain adaptation) via supervised\nloss on the source data. Based on such an observation, this paper proposes\n\\emph{a simple yet effective} feature alignment loss, termed as Class-Aware\nFeature Alignment (CAFA), which 1) encourages a model to learn target\nrepresentations in a class-discriminative manner and 2) effectively mitigates\nthe distribution shifts in test time, simultaneously. Our method does not\nrequire any hyper-parameters or additional losses, which are required in the\nprevious approaches. We conduct extensive experiments and show our proposed\nmethod consistently outperforms existing baselines.",
    "descriptor": "",
    "authors": [
      "Sanghun Jung",
      "Jungsoo Lee",
      "Nanhee Kim",
      "Jaegul Choo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.00205"
  },
  {
    "id": "arXiv:2206.00206",
    "title": "Transformer with Fourier Integral Attentions",
    "abstract": "Multi-head attention empowers the recent success of transformers, the\nstate-of-the-art models that have achieved remarkable success in sequence\nmodeling and beyond. These attention mechanisms compute the pairwise dot\nproducts between the queries and keys, which results from the use of\nunnormalized Gaussian kernels with the assumption that the queries follow a\nmixture of Gaussian distribution. There is no guarantee that this assumption is\nvalid in practice. In response, we first interpret attention in transformers as\na nonparametric kernel regression. We then propose the FourierFormer, a new\nclass of transformers in which the dot-product kernels are replaced by the\nnovel generalized Fourier integral kernels. Different from the dot-product\nkernels, where we need to choose a good covariance matrix to capture the\ndependency of the features of data, the generalized Fourier integral kernels\ncan automatically capture such dependency and remove the need to tune the\ncovariance matrix. We theoretically prove that our proposed Fourier integral\nkernels can efficiently approximate any key and query distributions. Compared\nto the conventional transformers with dot-product attention, FourierFormers\nattain better accuracy and reduce the redundancy between attention heads. We\nempirically corroborate the advantages of FourierFormers over the baseline\ntransformers in a variety of practical applications including language modeling\nand image classification.",
    "descriptor": "\nComments: 35 pages, 5 tables. Tan Nguyen and Minh Pham contributed equally to this work\n",
    "authors": [
      "Tan Nguyen",
      "Minh Pham",
      "Tam Nguyen",
      "Khai Nguyen",
      "Stanley J. Osher",
      "Nhat Ho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.00206"
  },
  {
    "id": "arXiv:2206.00208",
    "title": "AdaVITS: Tiny VITS for Low Computing Resource Speaker Adaptation",
    "abstract": "Speaker adaptation in text-to-speech synthesis (TTS) is to finetune a\npre-trained TTS model to adapt to new target speakers with limited data. While\nmuch effort has been conducted towards this task, seldom work has been\nperformed for low computational resource scenarios due to the challenges raised\nby the requirement of the lightweight model and less computational complexity.\nIn this paper, a tiny VITS-based TTS model, named AdaVITS, for low computing\nresource speaker adaptation is proposed. To effectively reduce parameters and\ncomputational complexity of VITS, an iSTFT-based wave construction decoder is\nproposed to replace the upsampling-based decoder which is resource-consuming in\nthe original VITS. Besides, NanoFlow is introduced to share the density\nestimate across flow blocks to reduce the parameters of the prior encoder.\nFurthermore, to reduce the computational complexity of the textual encoder,\nscaled-dot attention is replaced with linear attention. To deal with the\ninstability caused by the simplified model, instead of using the original text\nencoder, phonetic posteriorgram (PPG) is utilized as linguistic feature via a\ntext-to-PPG module, which is then used as input for the encoder. Experiment\nshows that AdaVITS can generate stable and natural speech in speaker adaptation\nwith 8.97M model parameters and 0.72GFlops computational complexity.",
    "descriptor": "",
    "authors": [
      "Kun Song",
      "Heyang Xue",
      "Xinsheng Wang",
      "Jian Cong",
      "Yongmao Zhang",
      "Lei Xie",
      "Bing Yang",
      "Xiong Zhang",
      "Dan Su"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.00208"
  },
  {
    "id": "arXiv:2206.00212",
    "title": "Negative Sampling for Contrastive Representation Learning: A Review",
    "abstract": "The learn-to-compare paradigm of contrastive representation learning (CRL),\nwhich compares positive samples with negative ones for representation learning,\nhas achieved great success in a wide range of domains, including natural\nlanguage processing, computer vision, information retrieval and graph learning.\nWhile many research works focus on data augmentations, nonlinear\ntransformations or other certain parts of CRL, the importance of negative\nsample selection is usually overlooked in literature. In this paper, we provide\na systematic review of negative sampling (NS) techniques and discuss how they\ncontribute to the success of CRL. As the core part of this paper, we summarize\nthe existing NS methods into four categories with pros and cons in each genre,\nand further conclude with several open research questions as future directions.\nBy generalizing and aligning the fundamental NS ideas across multiple domains,\nwe hope this survey can accelerate cross-domain knowledge sharing and motivate\nfuture researches for better CRL.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Lanling Xu",
      "Jianxun Lian",
      "Wayne Xin Zhao",
      "Ming Gong",
      "Linjun Shou",
      "Daxin Jiang",
      "Xing Xie",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.00212"
  },
  {
    "id": "arXiv:2206.00214",
    "title": "LiDAR-MIMO: Efficient Uncertainty Estimation for LiDAR-based 3D Object  Detection",
    "abstract": "The estimation of uncertainty in robotic vision, such as 3D object detection,\nis an essential component in developing safe autonomous systems aware of their\nown performance. However, the deployment of current uncertainty estimation\nmethods in 3D object detection remains challenging due to timing and\ncomputational constraints. To tackle this issue, we propose LiDAR-MIMO, an\nadaptation of the multi-input multi-output (MIMO) uncertainty estimation method\nto the LiDAR-based 3D object detection task. Our method modifies the original\nMIMO by performing multi-input at the feature level to ensure the detection,\nuncertainty estimation, and runtime performance benefits are retained despite\nthe limited capacity of the underlying detector and the large computational\ncosts of point cloud processing. We compare LiDAR-MIMO with MC dropout and\nensembles as baselines and show comparable uncertainty estimation results with\nonly a small number of output heads. Further, LiDAR-MIMO can be configured to\nbe twice as fast as MC dropout and ensembles, while achieving higher mAP than\nMC dropout and approaching that of ensembles.",
    "descriptor": "\nComments: 8 pages, 4 figures and 5 tables. Accepted in IEEE IV 2022\n",
    "authors": [
      "Matthew Pitropov",
      "Chengjie Huang",
      "Vahdat Abdelzad",
      "Krzysztof Czarnecki",
      "Steven Waslander"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.00214"
  },
  {
    "id": "arXiv:2206.00216",
    "title": "THE-X: Privacy-Preserving Transformer Inference with Homomorphic  Encryption",
    "abstract": "As more and more pre-trained language models adopt on-cloud deployment, the\nprivacy issues grow quickly, mainly for the exposure of plain-text user data\n(e.g., search history, medical record, bank account). Privacy-preserving\ninference of transformer models is on the demand of cloud service users. To\nprotect privacy, it is an attractive choice to compute only with ciphertext in\nhomomorphic encryption (HE). However, enabling pre-trained models inference on\nciphertext data is difficult due to the complex computations in transformer\nblocks, which are not supported by current HE tools yet. In this work, we\nintroduce $\\textit{THE-X}$, an approximation approach for transformers, which\nenables privacy-preserving inference of pre-trained models developed by popular\nframeworks. $\\textit{THE-X}$ proposes a workflow to deal with complex\ncomputation in transformer networks, including all the non-polynomial functions\nlike GELU, softmax, and LayerNorm. Experiments reveal our proposed\n$\\textit{THE-X}$ can enable transformer inference on encrypted data for\ndifferent downstream tasks, all with negligible performance drop but enjoying\nthe theory-guaranteed privacy-preserving advantage.",
    "descriptor": "\nComments: Findings of ACL 2022\n",
    "authors": [
      "Tianyu Chen",
      "Hangbo Bao",
      "Shaohan Huang",
      "Li Dong",
      "Binxing Jiao",
      "Daxin Jiang",
      "Haoyi Zhou",
      "Jianxin Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.00216"
  },
  {
    "id": "arXiv:2206.00217",
    "title": "Resilience in Industrial Internet of Things Systems: A Communication  Perspective",
    "abstract": "Industrial Internet of Things is an ultra-large-scale system that is much\nmore sophisticated and fragile than conventional industrial platforms. The\neffective management of such a system relies heavily on the resilience of the\nnetwork, especially the communication part. Imperative as resilient\ncommunication is, there is not enough attention from literature and a\nstandardized framework is still missing. In awareness of these, this paper\nintends to provide a systematic overview of resilience in IIoT with a\ncommunication perspective, aiming to answer the questions of why we need it,\nwhat it is, how to enhance it, and where it can be applied. Specifically, we\nemphasize the urgency of resilience studies via examining existing literature\nand analyzing malfunction data from a real satellite communication system.\nResilience-related concepts and metrics, together with standardization efforts\nare then summarized and discussed, presenting a basic framework for analyzing\nthe resilience of the system before, during, and after disruptive events. On\nthe basis of the framework, key resilience concerns associated with the design,\ndeployment, and operation of IIoT are briefly described to shed light on the\nmethods for resilience enhancement. Promising resilient applications in\ndifferent IIoT sectors are also introduced to highlight the opportunities and\nchallenges in practical implementations.",
    "descriptor": "",
    "authors": [
      "Hao Wu",
      "Yifan Miao",
      "Peng Zhang",
      "Yang Tian",
      "Hui Tian"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.00217"
  },
  {
    "id": "arXiv:2206.00219",
    "title": "Inter-BIN: Interaction-based Cross-architecture IoT Binary Similarity  Comparison",
    "abstract": "The big wave of Internet of Things (IoT) malware reflects the fragility of\nthe current IoT ecosystem. Research has found that IoT malware can spread\nquickly on devices of different processer architectures, which leads our\nattention to cross-architecture binary similarity comparison technology. The\ngoal of binary similarity comparison is to determine whether the semantics of\ntwo binary snippets is similar. Existing learning-based approaches usually\nlearn the representations of binary code snippets individually and perform\nsimilarity matching based on the distance metric, without considering\ninter-binary semantic interactions. Moreover, they often rely on the\nlarge-scale external code corpus for instruction embeddings pre-training, which\nis heavyweight and easy to suffer the out-of-vocabulary (OOV) problem. In this\npaper, we propose an interaction-based cross-architecture IoT binary similarity\ncomparison system, Inter-BIN. Our key insight is to introduce interaction\nbetween instruction sequences by co-attention mechanism, which can flexibly\nperform soft alignment of semantically related instructions from different\narchitectures. And we design a lightweight multi-feature fusion-based\ninstruction embedding method, which can avoid the heavy workload and the OOV\nproblem of previous approaches. Extensive experiments show that Inter-BIN can\nsignificantly outperform state-of-the-art approaches on cross-architecture\nbinary similarity comparison tasks of different input granularities.\nFurthermore, we present an IoT malware function matching dataset from real\nnetwork environments, CrossMal, containing 1,878,437 cross-architecture reuse\nfunction pairs. Experimental results on CrossMal prove that Inter-BIN is\npractical and scalable on real-world binary similarity comparison collections.",
    "descriptor": "\nComments: Accepted by IEEE Internet of Things Journal,15 pages, 11 figures and 8 tables\n",
    "authors": [
      "Qige Song",
      "Yongzheng Zhang",
      "Binglai Wang",
      "Yige Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.00219"
  },
  {
    "id": "arXiv:2206.00220",
    "title": "Adaptive Online Learning of Quantum States",
    "abstract": "In the fundamental problem of shadow tomography, the goal is to efficiently\nlearn an unknown $d$-dimensional quantum state using projective measurements.\nHowever, it is rarely the case that the underlying state remains stationary:\nchanges may occur due to measurements, environmental noise, or an underlying\nHamiltonian state evolution. In this paper we adopt tools from adaptive online\nlearning to learn a changing state, giving adaptive and dynamic regret bounds\nfor online shadow tomography that are polynomial in the number of qubits and\nsublinear in the number of measurements. Our analysis utilizes tools from\ncomplex matrix analysis to cope with complex numbers, which may be of\nindependent interest in online learning. In addition, we provide numerical\nexperiments that corroborate our theoretical results.",
    "descriptor": "",
    "authors": [
      "Xinyi Chen",
      "Elad Hazan",
      "Tongyang Li",
      "Zhou Lu",
      "Xinzhao Wang",
      "Rui Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.00220"
  },
  {
    "id": "arXiv:2206.00221",
    "title": "Distributed Estimation for Interconnected Systems with Arbitrary  Coupling Structures",
    "abstract": "This paper is concerned with the problem of distributed estimation for\ntime-varying interconnected dynamic systems with arbitrary coupling structures.\nTo guarantee the robustness of the designed estimators, novel distributed\nstability conditions are proposed with only local information and the\ninformation from neighbors. Then, simplified stability conditions which do not\nrequire timely exchange of neighbors' estimator gain information is further\ndeveloped for systems with delayed communication. By merging these\nsubsystem-level stability conditions and the optimization-based estimator gain\ndesign, the distributed, stable and optimal estimators are proposed. Quite\nnotably, these optimization solutions can be easily obtained by standard\nsoftware packages, and it is also shown that the designed estimators are\nscalable in the sense of adding or subtracting subsystems. Finally, an\nillustrative example is employed to show the effectiveness of the proposed\nmethods.",
    "descriptor": "\nComments: 11 pages,5 figures (The first version of this manuscript was completed on June 2021)\n",
    "authors": [
      "Yuchen Zhang",
      "Bo Chen",
      "Li Yu",
      "Daniel W.C. Ho"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.00221"
  },
  {
    "id": "arXiv:2206.00222",
    "title": "Cross-domain Detection Transformer based on Spatial-aware and  Semantic-aware Token Alignment",
    "abstract": "Detection transformers like DETR have recently shown promising performance on\nmany object detection tasks, but the generalization ability of those methods is\nstill quite challenging for cross-domain adaptation scenarios. To address the\ncross-domain issue, a straightforward way is to perform token alignment with\nadversarial training in transformers. However, its performance is often\nunsatisfactory as the tokens in detection transformers are quite diverse and\nrepresent different spatial and semantic information. In this paper, we propose\na new method called Spatial-aware and Semantic-aware Token Alignment (SSTA) for\ncross-domain detection transformers. In particular, we take advantage of the\ncharacteristics of cross-attention as used in detection transformer and propose\nthe spatial-aware token alignment (SpaTA) and the semantic-aware token\nalignment (SemTA) strategies to guide the token alignment across domains. For\nspatial-aware token alignment, we can extract the information from the\ncross-attention map (CAM) to align the distribution of tokens according to\ntheir attention to object queries. For semantic-aware token alignment, we\ninject the category information into the cross-attention map and construct\ndomain embedding to guide the learning of a multi-class discriminator so as to\nmodel the category relationship and achieve category-level token alignment\nduring the entire adaptation process. We conduct extensive experiments on\nseveral widely-used benchmarks, and the results clearly show the effectiveness\nof our proposed method over existing state-of-the-art baselines.",
    "descriptor": "\nComments: Technical report\n",
    "authors": [
      "Jinhong Deng",
      "Xiaoyue Zhang",
      "Wen Li",
      "Lixin Duan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.00222"
  },
  {
    "id": "arXiv:2206.00225",
    "title": "Can Artificial Intelligence Transform DevOps?",
    "abstract": "DevOps and Artificial Intelligence (AI) are interconnected with each other.\nDevOps is a business-driven approach to providing quickly delivered quality\nsoftware, and AI is the technology that can be used in the system to enhance\nits functionality. So, DevOps teams can use AI to test, code, release, monitor,\nand improve the system. Through AI, the automation process delivered by DevOps\ncould be improved efficiently. This study aims to explore how AI can transform\nDevOps. The research is useful in terms of facilitating software developers and\nbusinesses to assess the importance of AI in DevOps. The study has practical\nimplications as it elaborates on how AI transforms DevOps and in what way it\ncan support businesses in their business.",
    "descriptor": "",
    "authors": [
      "Mamdouh Alenezi",
      "Mohammad Zarour",
      "Mohammad Akour"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.00225"
  },
  {
    "id": "arXiv:2206.00227",
    "title": "Rethinking the Augmentation Module in Contrastive Learning: Learning  Hierarchical Augmentation Invariance with Expanded Views",
    "abstract": "A data augmentation module is utilized in contrastive learning to transform\nthe given data example into two views, which is considered essential and\nirreplaceable. However, the predetermined composition of multiple data\naugmentations brings two drawbacks. First, the artificial choice of\naugmentation types brings specific representational invariances to the model,\nwhich have different degrees of positive and negative effects on different\ndownstream tasks. Treating each type of augmentation equally during training\nmakes the model learn non-optimal representations for various downstream tasks\nand limits the flexibility to choose augmentation types beforehand. Second, the\nstrong data augmentations used in classic contrastive learning methods may\nbring too much invariance in some cases, and fine-grained information that is\nessential to some downstream tasks may be lost. This paper proposes a general\nmethod to alleviate these two problems by considering where and what to\ncontrast in a general contrastive learning framework. We first propose to learn\ndifferent augmentation invariances at different depths of the model according\nto the importance of each data augmentation instead of learning\nrepresentational invariances evenly in the backbone. We then propose to expand\nthe contrast content with augmentation embeddings to reduce the misleading\neffects of strong data augmentations. Experiments based on several baseline\nmethods demonstrate that we learn better representations for various benchmarks\non classification, detection, and segmentation downstream tasks.",
    "descriptor": "",
    "authors": [
      "Junbo Zhang",
      "Kaisheng Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.00227"
  },
  {
    "id": "arXiv:2206.00228",
    "title": "Lower and Upper Bounds for Numbers of Linear Regions of Graph  Convolutional Networks",
    "abstract": "The research for characterizing GNN expressiveness attracts much attention as\ngraph neural networks achieve a champion in the last five years. The number of\nlinear regions has been considered a good measure for the expressivity of\nneural networks with piecewise linear activation. In this paper, we present\nsome estimates for the number of linear regions of the classic graph\nconvolutional networks (GCNs) with one layer and multiple-layer scenarios. In\nparticular, we obtain an optimal upper bound for the maximum number of linear\nregions for one-layer GCNs, and the upper and lower bounds for multi-layer\nGCNs. The simulated estimate shows that the true maximum number of linear\nregions is possibly closer to our estimated lower bound. These results imply\nthat the number of linear regions of multi-layer GCNs is exponentially greater\nthan one-layer GCNs per parameter in general. This suggests that deeper GCNs\nhave more expressivity than shallow GCNs.",
    "descriptor": "",
    "authors": [
      "Hao Chen",
      "Yu Guang Wang",
      "Huan Xiong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.00228"
  },
  {
    "id": "arXiv:2206.00229",
    "title": "Multi-Object Grasping in the Plane",
    "abstract": "We consider the problem where multiple rigid convex polygonal objects rest in\nrandomly placed positions and orientations on a planar surface visible from an\noverhead camera. The objective is to efficiently grasp and transport all\nobjects into a bin. Specifically, we explore multi-object push-grasps where\nmultiple objects are pushed together before the grasp can occur. We provide\nnecessary conditions for multi-object push-grasps and apply these to filter\ninadmissible grasps in a novel multi-object grasp planner. We find that our\nplanner is 19 times faster than a Mujoco simulator baseline. We also propose a\npicking algorithm that uses both single- and multi-object grasps to pick\nobjects. In physical grasping experiments, compared to a single-object picking\nbaseline, we find that the multi-object grasping system achieves 13.6% higher\ngrasp success and is 59.9% faster. See\nhttps://sites.google.com/view/multi-object-grasping for videos, code, and data.",
    "descriptor": "",
    "authors": [
      "Wisdom C. Agboh",
      "Jeffrey Ichnowski",
      "Ken Goldberg",
      "Mehmet R. Dogar"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.00229"
  },
  {
    "id": "arXiv:2206.00233",
    "title": "DM$^2$: Distributed Multi-Agent Reinforcement Learning for Distribution  Matching",
    "abstract": "Current approaches to multi-agent cooperation rely heavily on centralized\nmechanisms or explicit communication protocols to ensure convergence. This\npaper studies the problem of distributed multi-agent learning without resorting\nto explicit coordination schemes. The proposed algorithm (DM$^2$) leverages\ndistribution matching to facilitate independent agents' coordination. Each\nindividual agent matches a target distribution of concurrently sampled\ntrajectories from a joint expert policy. The theoretical analysis shows that\nunder some conditions, if each agent optimizes their individual distribution\nmatching objective, the agents increase a lower bound on the objective of\nmatching the joint expert policy, allowing convergence to the joint expert\npolicy. Further, if the distribution matching objective is aligned with a joint\ntask, a combination of environment reward and distribution matching reward\nleads to the same equilibrium. Experimental validation on the StarCraft domain\nshows that combining the reward for distribution matching with the environment\nreward allows agents to outperform a fully distributed baseline. Additional\nexperiments probe the conditions under which expert demonstrations need to be\nsampled in order to outperform the fully distributed baseline.",
    "descriptor": "",
    "authors": [
      "Caroline Wang",
      "Ishan Durugkar",
      "Elad Liebman",
      "Peter Stone"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.00233"
  },
  {
    "id": "arXiv:2206.00234",
    "title": "Assessing Group-level Gender Bias in Professional Evaluations: The Case  of Medical Student End-of-Shift Feedback",
    "abstract": "Although approximately 50% of medical school graduates today are women,\nfemale physicians tend to be underrepresented in senior positions, make less\nmoney than their male counterparts and receive fewer promotions. There is a\ngrowing body of literature demonstrating gender bias in various forms of\nevaluation in medicine, but this work was mainly conducted by looking for\nspecific words using fixed dictionaries such as LIWC and focused on\nrecommendation letters. We use a dataset of written and quantitative\nassessments of medical student performance on individual shifts of work,\ncollected across multiple institutions, to investigate the extent to which\ngender bias exists in a day-to-day context for medical students. We investigate\ndifferences in the narrative comments given to male and female students by both\nmale or female faculty assessors, using a fine-tuned BERT model. This allows us\nto examine whether groups are written about in systematically different ways,\nwithout relying on hand-crafted wordlists or topic models. We compare these\nresults to results from the traditional LIWC method and find that, although we\nfind no evidence of group-level gender bias in this dataset, terms related to\nfamily and children are used more in feedback given to women.",
    "descriptor": "\nComments: GeBNLP @ NAACL 2022\n",
    "authors": [
      "Emmy Liu",
      "Michael Henry Tessler",
      "Nicole Dubosh",
      "Katherine Mosher Hiller",
      "Roger Levy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.00234"
  },
  {
    "id": "arXiv:2206.00235",
    "title": "Fairing of planar curves to log-aesthetic curves",
    "abstract": "We present an algorithm to fair a given planar curve by a log-aesthetic curve\n(LAC). We show how a general LAC segment can be uniquely characterized by seven\nparameters and present a method of parametric approximation based on this fact.\nThis work aims to provide tools to be used in reverse engineering for computer\naided geometric design. Finally, we show an example of usage by applying this\nalgorithm to the point data obtained from 3D scanning a car's roof.",
    "descriptor": "",
    "authors": [
      "Sebasti\u00e1n El\u00edas Graiff Zurita",
      "Kenji Kajiwara",
      "Kenjiro T. Miura"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Geometry (cs.CG)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2206.00235"
  },
  {
    "id": "arXiv:2206.00236",
    "title": "Continuous Prediction with Experts' Advice",
    "abstract": "Prediction with experts' advice is one of the most fundamental problems in\nonline learning and captures many of its technical challenges. A recent line of\nwork has looked at online learning through the lens of differential equations\nand continuous-time analysis. This viewpoint has yielded optimal results for\nseveral problems in online learning.\nIn this paper, we employ continuous-time stochastic calculus in order to\nstudy the discrete-time experts' problem. We use these tools to design a\ncontinuous-time, parameter-free algorithm with improved guarantees for the\nquantile regret. We then develop an analogous discrete-time algorithm with a\nvery similar analysis and identical quantile regret bounds. Finally, we design\nan anytime continuous-time algorithm with regret matching the optimal\nfixed-time rate when the gains are independent Brownian Motions; in many\nsettings, this is the most difficult case. This gives some evidence that, even\nwith adversarial gains, the optimal anytime and fixed-time regrets may\ncoincide.",
    "descriptor": "\nComments: 28 pages, 1 figure\n",
    "authors": [
      "Victor Sanches Portella",
      "Christopher Liaw",
      "Nicholas J. A. Harvey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.00236"
  },
  {
    "id": "arXiv:2206.00238",
    "title": "Transferable Reward Learning by Dynamics-Agnostic Discriminator Ensemble",
    "abstract": "Inverse reinforcement learning (IRL) recovers the underlying reward function\nfrom expert demonstrations. A generalizable reward function is even desired as\nit captures the fundamental motivation of the expert. However, classical IRL\nmethods can only recover reward functions coupled with the training dynamics,\nthus are hard to generalize to a changed environment. Previous\ndynamics-agnostic reward learning methods have strict assumptions, such as that\nthe reward function has to be state-only. This work proposes a general approach\nto learn transferable reward functions, Dynamics-Agnostic\nDiscriminator-Ensemble Reward Learning (DARL). Following the adversarial\nimitation learning (AIL) framework, DARL learns a dynamics-agnostic\ndiscriminator on a latent space mapped from the original state-action space.\nThe latent space is learned to contain the least information of the dynamics.\nMoreover, to reduce the reliance of the discriminator on policies, the reward\nfunction is represented as an ensemble of the discriminators during training.\nWe assess DARL in four MuJoCo tasks with dynamics transfer. Empirical results\ncompared with the state-of-the-art AIL methods show that DARL can learn a\nreward that is more consistent with the true reward, thus obtaining higher\nenvironment returns.",
    "descriptor": "",
    "authors": [
      "Fan-Ming Luo",
      "Xingchen Cao",
      "Yang Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00238"
  },
  {
    "id": "arXiv:2206.00240",
    "title": "Privacy for Free: How does Dataset Condensation Help Privacy?",
    "abstract": "To prevent unintentional data leakage, research community has resorted to\ndata generators that can produce differentially private data for model\ntraining. However, for the sake of the data privacy, existing solutions suffer\nfrom either expensive training cost or poor generalization performance.\nTherefore, we raise the question whether training efficiency and privacy can be\nachieved simultaneously. In this work, we for the first time identify that\ndataset condensation (DC) which is originally designed for improving training\nefficiency is also a better solution to replace the traditional data generators\nfor private data generation, thus providing privacy for free. To demonstrate\nthe privacy benefit of DC, we build a connection between DC and differential\nprivacy, and theoretically prove on linear feature extractors (and then\nextended to non-linear feature extractors) that the existence of one sample has\nlimited impact ($O(m/n)$) on the parameter distribution of networks trained on\n$m$ samples synthesized from $n (n \\gg m)$ raw samples by DC. We also\nempirically validate the visual privacy and membership privacy of\nDC-synthesized data by launching both the loss-based and the state-of-the-art\nlikelihood-based membership inference attacks. We envision this work as a\nmilestone for data-efficient and privacy-preserving machine learning.",
    "descriptor": "\nComments: Accepted by ICML 2022 as Oral\n",
    "authors": [
      "Tian Dong",
      "Bo Zhao",
      "Lingjuan Lyu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00240"
  },
  {
    "id": "arXiv:2206.00242",
    "title": "CrossCBR: Cross-view Contrastive Learning for Bundle Recommendation",
    "abstract": "Bundle recommendation aims to recommend a bundle of related items to users,\nwhich can satisfy the users' various needs with one-stop convenience. Recent\nmethods usually take advantage of both user-bundle and user-item interactions\ninformation to obtain informative representations for users and bundles,\ncorresponding to bundle view and item view, respectively. However, they either\nuse a unified view without differentiation or loosely combine the predictions\nof two separate views, while the crucial cooperative association between the\ntwo views' representations is overlooked. In this work, we propose to model the\ncooperative association between the two different views through cross-view\ncontrastive learning. By encouraging the alignment of the two separately\nlearned views, each view can distill complementary information from the other\nview, achieving mutual enhancement. Moreover, by enlarging the dispersion of\ndifferent users/bundles, the self-discrimination of representations is\nenhanced. Extensive experiments on three public datasets demonstrate that our\nmethod outperforms SOTA baselines by a large margin. Meanwhile, our method\nrequires minimal parameters of three set of embeddings (user, bundle, and item)\nand the computational costs are largely reduced due to more concise graph\nstructure and graph learning module. In addition, various ablation and model\nstudies demystify the working mechanism and justify our hypothesis. Codes and\ndatasets are available at https://github.com/mysbupt/CrossCBR.",
    "descriptor": "\nComments: 9 pages, 5 figures, 5 tables\n",
    "authors": [
      "Yunshan Ma",
      "Yingzhi He",
      "An Zhang",
      "Xiang Wang",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.00242"
  },
  {
    "id": "arXiv:2206.00244",
    "title": "Fair Comparison between Efficient Attentions",
    "abstract": "Transformers have been successfully used in various fields and are becoming\nthe standard tools in computer vision. However, self-attention, a core\ncomponent of transformers, has a quadratic complexity problem, which limits the\nuse of transformers in various vision tasks that require dense prediction. Many\nstudies aiming at solving this problem have been reported proposed. However, no\ncomparative study of these methods using the same scale has been reported due\nto different model configurations, training schemes, and new methods. In our\npaper, we validate these efficient attention models on the ImageNet1K\nclassification task by changing only the attention operation and examining\nwhich efficient attention is better.",
    "descriptor": "\nComments: 4 pages abstract\n",
    "authors": [
      "Jiuk Hong",
      "Chaehyeon Lee",
      "Soyoun Bang",
      "Heechul Jung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00244"
  },
  {
    "id": "arXiv:2206.00250",
    "title": "Time-multiplexed In-memory computation scheme for mapping Quantized  Neural Networks on hybrid CMOS-OxRAM building blocks",
    "abstract": "In this work, we experimentally demonstrate two key building blocks for\nrealizing Binary/Ternary Neural Networks (BNNs/TNNs): (i) 130 nm CMOS based\nsigmoidal neurons and (ii) HfOx based multi-level (MLC) OxRAM-synaptic blocks.\nAn optimized vector matrix multiplication programming scheme that utilizes the\ntwo building blocks is also presented. Compared to prior approaches that\nutilize differential synaptic structures, a single device per synapse with two\nsets of READ operations is used. Proposed hardware mapping strategy shows\nperformance change of <5% (decrease of 2-5% for TNN, increase of 0.2% for BNN)\ncompared to ideal quantized neural networks (QNN) with significant memory\nsavings in the order of 16-32x for classification problem on Fashion MNIST\n(FMNIST) dataset. Impact of OxRAM device variability on the performance of\nHardware QNN (BNN/TNN) is also analyzed.",
    "descriptor": "",
    "authors": [
      "Sandeep Kaur Kingra",
      "Vivek Parmar",
      "Manoj Sharma",
      "Manan Suri"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2206.00250"
  },
  {
    "id": "arXiv:2206.00251",
    "title": "The Reactive Synthesis Competition (SYNTCOMP): 2018-2021",
    "abstract": "We report on the last four editions of the reactive synthesis competition\n(SYNTCOMP 2018-2021). We briefly describe the evaluation scheme and the\nexperimental setup of SYNTCOMP. Then, we introduce new benchmark classes that\nhave been added to the SYNTCOMP library and give an overview of the\nparticipants of SYNTCOMP. Finally, we present and analyze the results of our\nexperimental evaluations, including a ranking of tools with respect to quantity\nand quality of solutions.",
    "descriptor": "",
    "authors": [
      "Swen Jacobs",
      "Guillermo A. Perez",
      "Remco Abraham",
      "Veronique Bruyere",
      "Michael Cadilhac",
      "Maximilien Colange",
      "Charly Delfosse",
      "Tom van Dijk",
      "Alexandre Duret-Lutz",
      "Peter Faymonville",
      "Bernd Finkbeiner",
      "Ayrat Khalimov",
      "Felix Klein",
      "Michael Luttenberger",
      "Klara Meyer",
      "Thibaud Michaud",
      "Adrien Pommellet",
      "Florian Renkin",
      "Philipp Schlehuber-Caissier",
      "Mouhammad Sakr",
      "Salomon Sickert",
      "Gaetan Staquet",
      "Clement Tamines",
      "Leander Tentrup",
      "Adam Walker"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.00251"
  },
  {
    "id": "arXiv:2206.00252",
    "title": "Interpretable Deep Learning Classifier by Detection of Prototypical  Parts on Kidney Stones Images",
    "abstract": "Identifying the type of kidney stones can allow urologists to determine their\nformation cause, improving the early prescription of appropriate treatments to\ndiminish future relapses. However, currently, the associated ex-vivo diagnosis\n(known as morpho-constitutional analysis, MCA) is time-consuming, expensive,\nand requires a great deal of experience, as it requires a visual analysis\ncomponent that is highly operator dependant. Recently, machine learning methods\nhave been developed for in-vivo endoscopic stone recognition. Shallow methods\nhave been demonstrated to be reliable and interpretable but exhibit low\naccuracy, while deep learning-based methods yield high accuracy but are not\nexplainable. However, high stake decisions require understandable\ncomputer-aided diagnosis (CAD) to suggest a course of action based on\nreasonable evidence, rather than merely prescribe one. Herein, we investigate\nmeans for learning part-prototypes (PPs) that enable interpretable models. Our\nproposal suggests a classification for a kidney stone patch image and provides\nexplanations in a similar way as those used on the MCA method.",
    "descriptor": "\nComments: Extended abstract accepted at LatinX in Computer Vision Research Workshop, at CVPR 2022\n",
    "authors": [
      "Daniel Flores-Araiza",
      "Francisco Lopez-Tiro",
      "Elias Villalvazo-Avila",
      "Jonathan El-Beze",
      "Jacques Hubert",
      "Gilberto Ochoa-Ruiz",
      "Cristian Daul"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00252"
  },
  {
    "id": "arXiv:2206.00253",
    "title": "Intelligent UNIT LEVEL TEST Generator for Enhanced Software Quality",
    "abstract": "Unit level test has been widely recognized as an important approach to\nimprove the software quality, as it can expose bugs earlier during the\ndevelopment phase. However, manual unit level test development is often tedious\nand insufficient. Also, it is hard for developers to precisely identify the\nmost error prone code block deserving the best test coverage by themselves. In\nthis paper, we present the automatic Unit level test framework we used for\nintel media driver development. It can help us identify the most critical code\nblock, provide the test coverage recommendation, and automatically generate\n>80% ULT code (~400K Lines of test code) as well as ~35% test cases (~7K test\ncases) for intel media driver. It helps us to greatly shrink the average ULT\ndevelopment effort from ~24 Man hours to ~3 Man hours per 1000 Lines of driver\nsource code.",
    "descriptor": "\nComments: 10 pages, 6 figures\n",
    "authors": [
      "Ning Luo",
      "Linlin Zhang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.00253"
  },
  {
    "id": "arXiv:2206.00255",
    "title": "Star algorithm for NN ensembling",
    "abstract": "Neural network ensembling is a common and robust way to increase model\nefficiency. In this paper, we propose a new neural network ensemble algorithm\nbased on Audibert's empirical star algorithm. We provide optimal theoretical\nminimax bound on the excess squared risk. Additionally, we empirically study\nthis algorithm on regression and classification tasks and compare it to most\npopular ensembling methods.",
    "descriptor": "",
    "authors": [
      "Sergey Zinchenko",
      "Dmitry Lishudi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2206.00255"
  },
  {
    "id": "arXiv:2206.00257",
    "title": "CoNSoLe: Convex Neural Symbolic Learning",
    "abstract": "Learning the underlying equation from data is a fundamental problem in many\ndisciplines. Recent advances rely on Neural Networks (NNs) but do not provide\ntheoretical guarantees in obtaining the exact equations owing to the\nnon-convexity of NNs. In this paper, we propose Convex Neural Symbolic Learning\n(CoNSoLe) to seek convexity under mild conditions. The main idea is to\ndecompose the recovering process into two steps and convexify each step. In the\nfirst step of searching for right symbols, we convexify the deep Q-learning.\nThe key is to maintain double convexity for both the negative Q-function and\nthe negative reward function in each iteration, leading to provable convexity\nof the negative optimal Q function to learn the true symbol connections.\nConditioned on the exact searching result, we construct a Locally Convex\nequation Learner (LoCaL) neural network to convexify the estimation of symbol\ncoefficients. With such a design, we quantify a large region with strict\nconvexity in the loss surface of LoCaL for commonly used physical functions.\nFinally, we demonstrate the superior performance of the CoNSoLe framework over\nthe state-of-the-art on a diverse set of datasets.",
    "descriptor": "\nComments: 17 pages, 5 figures, conference for NeurIPS 2022\n",
    "authors": [
      "Haoran Li",
      "Yang Weng",
      "Hanghang Tong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.00257"
  },
  {
    "id": "arXiv:2206.00258",
    "title": "On the Simulation of Hypervisor Instructions for Accurate Timing  Simulation of Virtualized Systems",
    "abstract": "Architectural simulators help in better understanding the behaviour of\nexisting architectures and the design of new architectures. Virtualization has\nregained importance and this has put a pressing demand for the simulation of\nvirtualized systems. Existing full-system simulators for virtualized systems\nsimulate the application program instructions and the operating system\ninstructions but abstract the hypercalls or traps to the hypervisor. This leads\nto inaccuracy in the simulation. This paper proposes an approach to simulate\nhypervisor instructions in addition to operating system instructions for\naccurate timing simulation of virtualized systems. The proposed approach is\ndemonstrated by simulating RISC-V binary instructions. The simulator is an\nexecution-driven, functional-first, hardware-based simulator coded in Verilog.\nThe paper concludes that the proposed approach leads to accurate timing\nsimulation of virtualized systems.",
    "descriptor": "",
    "authors": [
      "Swapneel C. Mhatre",
      "Priya Chandran"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2206.00258"
  },
  {
    "id": "arXiv:2206.00259",
    "title": "IDANI: Inference-time Domain Adaptation via Neuron-level Interventions",
    "abstract": "Large pre-trained models are usually fine-tuned on downstream task data, and\ntested on unseen data. When the train and test data come from different\ndomains, the model is likely to struggle, as it is not adapted to the test\ndomain. We propose a new approach for domain adaptation (DA), using\nneuron-level interventions: We modify the representation of each test example\nin specific neurons, resulting in a counterfactual example from the source\ndomain, which the model is more familiar with. The modified example is then fed\nback into the model. While most other DA methods are applied during training\ntime, ours is applied during inference only, making it more efficient and\napplicable. Our experiments show that our method improves performance on unseen\ndomains.",
    "descriptor": "\nComments: Our code is available at this https URL\n",
    "authors": [
      "Omer Antverg",
      "Eyal Ben-David",
      "Yonatan Belinkov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00259"
  },
  {
    "id": "arXiv:2206.00261",
    "title": "Structured Neural-PI Control for Networked Systems: Stability and  Steady-State Optimality Guarantees",
    "abstract": "We study the control of networked systems with the goal of optimizing both\ntransient and steady-state performances while providing stability guarantees.\nLinear Proportional-Integral (PI) controllers are almost always used in\npractice, but the linear parameterization of the controller fundamentally\nlimits its performance. Learning-based approaches are becoming popular in\ndesigning nonlinear controllers, but the lack of stability guarantees makes the\nlearned controllers difficult to apply in practical applications. This paper\nbridges the gap between neural network-based controller design and the need for\nstability guarantees. Using equilibrium-independent passivity, a property\npresent in a wide range of physical systems, we propose structured neural-PI\ncontrollers that have provable guarantees on stability and zero steady-state\noutput tracking error. If communication between neighbours is available, we\nfurther extend the controller to distributedly achieve optimal resource\nallocation at the steady state. We explicitly characterize the stability\nconditions and engineer neural networks that satisfy them by design.\nExperiments on traffic and power networks demonstrate that the proposed\napproach can improve both transient and steady-state performances compared to\nexisting state-of-the-art, while unstructured neural networks lead to unstable\nbehaviors.",
    "descriptor": "",
    "authors": [
      "Wenqi Cui",
      "Yan Jiang",
      "Baosen Zhang",
      "Yuanyuan Shi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.00261"
  },
  {
    "id": "arXiv:2206.00262",
    "title": "Self-supervised Learning for Label Sparsity in Computational Drug  Repositioning",
    "abstract": "The computational drug repositioning aims to discover new uses for marketed\ndrugs, which can accelerate the drug development process and play an important\nrole in the existing drug discovery system. However, the number of validated\ndrug-disease associations is scarce compared to the number of drugs and\ndiseases in the real world. Too few labeled samples will make the\nclassification model unable to learn effective latent factors of drugs,\nresulting in poor generalization performance. In this work, we propose a\nmulti-task self-supervised learning framework for computational drug\nrepositioning. The framework tackles label sparsity by learning a better drug\nrepresentation. Specifically, we take the drug-disease association prediction\nproblem as the main task, and the auxiliary task is to use data augmentation\nstrategies and contrast learning to mine the internal relationships of the\noriginal drug features, so as to automatically learn a better drug\nrepresentation without supervised labels. And through joint training, it is\nensured that the auxiliary task can improve the prediction accuracy of the main\ntask. More precisely, the auxiliary task improves drug representation and\nserving as additional regularization to improve generalization. Furthermore, we\ndesign a multi-input decoding network to improve the reconstruction ability of\nthe autoencoder model. We evaluate our model using three real-world datasets.\nThe experimental results demonstrate the effectiveness of the multi-task\nself-supervised learning framework, and its predictive ability is superior to\nthe state-of-the-art model.",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Xinxing Yang",
      "Genke Yang",
      "Jian Chu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2206.00262"
  },
  {
    "id": "arXiv:2206.00263",
    "title": "PiDRAM: An FPGA-based Framework for End-to-end Evaluation of  Processing-in-DRAM Techniques",
    "abstract": "DRAM-based main memory is used in nearly all computing systems as a major\ncomponent. One way of overcoming the main memory bottleneck is to move\ncomputation near memory, a paradigm known as processing-in-memory (PiM). Recent\nPiM techniques provide a promising way to improve the performance and energy\nefficiency of existing and future systems at no additional DRAM hardware cost.\nWe develop the Processing-in-DRAM (PiDRAM) framework, the first flexible,\nend-to-end, and open source framework that enables system integration studies\nand evaluation of real PiM techniques using real DRAM chips. We demonstrate a\nprototype of PiDRAM on an FPGA-based platform (Xilinx ZC706) that implements an\nopen-source RISC-V system (Rocket Chip). To demonstrate the flexibility and\nease of use of PiDRAM, we implement two PiM techniques: (1) RowClone, an\nin-DRAM copy and initialization mechanism (using command sequences proposed by\nComputeDRAM), and (2) D-RaNGe, an in-DRAM true random number generator based on\nDRAM activation-latency failures.\nOur end-to-end evaluation of RowClone shows up to 14.6X speedup for copy and\n12.6X initialization operations over CPU copy (i.e., conventional memcpy) and\ninitialization (i.e., conventional calloc) operations. Our implementation of\nD-RaNGe provides high throughput true random numbers, reaching 8.30 Mb/s\nthroughput. Over the Verilog and C++ basis provided by PiDRAM, implementing the\nrequired hardware and software components, implementing RowClone end-to-end\ntakes 198 (565) and implementing D-RaNGe end-to-end takes 190 (78) lines of\nVerilog (C++) code. PiDRAM is open sourced on Github:\nhttps://github.com/CMU-SAFARI/PiDRAM.",
    "descriptor": "\nComments: To appear in ISVLSI 2022 Special Session on Processing in Memory. arXiv admin note: text overlap with arXiv:2111.00082\n",
    "authors": [
      "Ataberk Olgun",
      "Juan Gomez Luna",
      "Konstantinos Kanellopoulos",
      "Behzad Salami",
      "Hasan Hassan",
      "Oguz Ergin",
      "Onur Mutlu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2206.00263"
  },
  {
    "id": "arXiv:2206.00265",
    "title": "InducT-GCN: Inductive Graph Convolutional Networks for Text  Classification",
    "abstract": "Text classification aims to assign labels to textual units by making use of\nglobal information. Recent studies have applied graph neural network (GNN) to\ncapture the global word co-occurrence in a corpus. Existing approaches require\nthat all the nodes (training and test) in a graph are present during training,\nwhich are transductive and do not naturally generalise to unseen nodes. To make\nthose models inductive, they use extra resources, like pretrained word\nembedding. However, high-quality resource is not always available and hard to\ntrain. Under the extreme settings with no extra resource and limited amount of\ntraining set, can we still learn an inductive graph-based text classification\nmodel? In this paper, we introduce a novel inductive graph-based text\nclassification framework, InducT-GCN (InducTive Graph Convolutional Networks\nfor Text classification). Compared to transductive models that require test\ndocuments in training, we construct a graph based on the statistics of training\ndocuments only and represent document vectors with a weighted sum of word\nvectors. We then conduct one-directional GCN propagation during testing. Across\nfive text classification benchmarks, our InducT-GCN outperformed\nstate-of-the-art methods that are either transductive in nature or pre-trained\nadditional resources. We also conducted scalability testing by gradually\nincreasing the data size and revealed that our InducT-GCN can reduce the time\nand space complexity. The code is available on:\nhttps://github.com/usydnlp/InductTGCN.",
    "descriptor": "\nComments: ICPR 2022\n",
    "authors": [
      "Kunze Wang",
      "Soyeon Caren Han",
      "Josiah Poon"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.00265"
  },
  {
    "id": "arXiv:2206.00266",
    "title": "PaGO-LOAM: Robust Ground-Optimized LiDAR Odometry",
    "abstract": "Numerous researchers have conducted studies to achieve fast and robust\nground-optimized LiDAR odometry methods for terrestrial mobile platforms. In\nparticular, ground-optimized LiDAR odometry usually employs ground segmentation\nas a preprocessing method. This is because most of the points in a 3D point\ncloud captured by a 3D LiDAR sensor on a terrestrial platform are from the\nground. However, the effect of the performance of ground segmentation on LiDAR\nodometry is still not closely examined. In this paper, a robust\nground-optimized LiDAR odometry framework is proposed to facilitate the study\nto check the effect of ground segmentation on LiDAR SLAM based on the\nstate-of-the-art (SOTA) method. By using our proposed odometry framework, it is\neasy and straightforward to test whether ground segmentation algorithms help\nextract well-described features and thus improve SLAM performance. In addition,\nby leveraging the SOTA ground segmentation method called Patchwork, which shows\nrobust ground segmentation even in complex and uneven urban environments with\nlittle performance perturbation, a novel ground-optimized LiDAR odometry is\nproposed, called PaGO-LOAM. The methods were tested using the KITTI odometry\ndataset. \\textit{PaGO-LOAM} shows robust and accurate performance compared with\nthe baseline method. Our code is available at\nhttps://github.com/url-kaist/AlterGround-LeGO-LOAM.",
    "descriptor": "\nComments: 7 pages, 5 figures, conference\n",
    "authors": [
      "Dong-Uk Seo",
      "Hyungtae Lim",
      "Seungjae Lee",
      "Hyun Myung"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.00266"
  },
  {
    "id": "arXiv:2206.00267",
    "title": "LPFS: Learnable Polarizing Feature Selection for Click-Through Rate  Prediction",
    "abstract": "In industry, feature selection is a standard but necessary step to search for\nan optimal set of informative feature fields for efficient and effective\ntraining of deep Click-Through Rate (CTR) models. Most previous works measure\nthe importance of feature fields by using their corresponding continuous\nweights from the model, then remove the feature fields with small weight\nvalues. However, removing many features that correspond to small but not exact\nzero weights will inevitably hurt model performance and not be friendly to\nhot-start model training. There is also no theoretical guarantee that the\nmagnitude of weights can represent the importance, thus possibly leading to\nsub-optimal results if using these methods.\nTo tackle this problem, we propose a novel Learnable Polarizing Feature\nSelection (LPFS) method using a smoothed-$\\ell^0$ function in literature.\nFurthermore, we extend LPFS to LPFS++ by our newly designed\nsmoothed-$\\ell^0$-liked function to select a more informative subset of\nfeatures. LPFS and LPFS++ can be used as gates inserted at the input of the\ndeep network to control the active and inactive state of each feature. When\ntraining is finished, some gates are exact zero, while others are around one,\nwhich is particularly favored by the practical hot-start training in the\nindustry, due to no damage to the model performance before and after removing\nthe features corresponding to exact-zero gates. Experiments show that our\nmethods outperform others by a clear margin, and have achieved great A/B test\nresults in KuaiShou Technology.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Yi Guo",
      "Zhaocheng Liu",
      "Jianchao Tan",
      "Chao Liao",
      "Daqing Chang",
      "Qiang Liu",
      "Sen Yang",
      "Ji Liu",
      "Dongying Kong",
      "Zhi Chen",
      "Chengru Song"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.00267"
  },
  {
    "id": "arXiv:2206.00268",
    "title": "The Hipster Paradox in Electronic Dance Music: How Musicians Trade  Mainstream Success off against Alternative Status",
    "abstract": "The hipster paradox in Electronic Dance Music is the phenomenon that\ncommercial success is collectively considered illegitimate while serious and\naspiring professional musicians strive for it. We study this behavioral dilemma\nusing digital traces of performing live and releasing music as they are stored\nin the \\textit{Resident Advisor}, \\textit{Juno Download}, and \\textit{Discogs}\ndatabases from 2001-2018. We construct network snapshots following a formal\nsociological approach based on bipartite networks, and we use network positions\nto explain success in regression models of artistic careers. We find evidence\nfor a structural trade-off among success and autonomy. Musicians in EDM embed\ninto exclusive performance-based communities for autonomy but, in earlier\ncareer stages, seek the mainstream for commercial success. Our approach\nhighlights how Computational Social Science can benefit from a close connection\nof data analysis and theory.",
    "descriptor": "\nComments: 16th International Conference on Web and Social Media\n",
    "authors": [
      "Mohsen Jadidi",
      "Haiko Lietz",
      "Mattia Samory",
      "Claudia Wagner"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.00268"
  },
  {
    "id": "arXiv:2206.00270",
    "title": "Provably Efficient Lifelong Reinforcement Learning with Linear Function  Approximation",
    "abstract": "We study lifelong reinforcement learning (RL) in a regret minimization\nsetting of linear contextual Markov decision process (MDP), where the agent\nneeds to learn a multi-task policy while solving a streaming sequence of tasks.\nWe propose an algorithm, called UCB Lifelong Value Distillation (UCBlvd), that\nprovably achieves sublinear regret for any sequence of tasks, which may be\nadaptively chosen based on the agent's past behaviors. Remarkably, our\nalgorithm uses only sublinear number of planning calls, which means that the\nagent eventually learns a policy that is near optimal for multiple tasks (seen\nor unseen) without the need of deliberate planning. A key to this property is a\nnew structural assumption that enables computation sharing across tasks during\nexploration. Specifically, for $K$ task episodes of horizon $H$, our algorithm\nhas a regret bound $\\tilde{\\mathcal{O}}(\\sqrt{(d^3+d^\\prime d)H^4K})$ based on\n$\\mathcal{O}(dH\\log(K))$ number of planning calls, where $d$ and $d^\\prime$ are\nthe feature dimensions of the dynamics and rewards, respectively. This\ntheoretical guarantee implies that our algorithm can enable a lifelong learning\nagent to accumulate experiences and learn to rapidly solve new tasks.",
    "descriptor": "",
    "authors": [
      "Sanae Amani",
      "Lin F. Yang",
      "Ching-An Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.00270"
  },
  {
    "id": "arXiv:2206.00272",
    "title": "Vision GNN: An Image is Worth Graph of Nodes",
    "abstract": "Network architecture plays a key role in the deep learning-based computer\nvision system. The widely-used convolutional neural network and transformer\ntreat the image as a grid or sequence structure, which is not flexible to\ncapture irregular and complex objects. In this paper, we propose to represent\nthe image as a graph structure and introduce a new Vision GNN (ViG)\narchitecture to extract graph-level feature for visual tasks. We first split\nthe image to a number of patches which are viewed as nodes, and construct a\ngraph by connecting the nearest neighbors. Based on the graph representation of\nimages, we build our ViG model to transform and exchange information among all\nthe nodes. ViG consists of two basic modules: Grapher module with graph\nconvolution for aggregating and updating graph information, and FFN module with\ntwo linear layers for node feature transformation. Both isotropic and pyramid\narchitectures of ViG are built with different model sizes. Extensive\nexperiments on image recognition and object detection tasks demonstrate the\nsuperiority of our ViG architecture. We hope this pioneering study of GNN on\ngeneral visual tasks will provide useful inspiration and experience for future\nresearch. The PyTroch code will be available at\nhttps://github.com/huawei-noah/CV-Backbones and the MindSpore code will be\navaiable at https://gitee.com/mindspore/models.",
    "descriptor": "\nComments: tech report\n",
    "authors": [
      "Kai Han",
      "Yunhe Wang",
      "Jianyuan Guo",
      "Yehui Tang",
      "Enhua Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.00272"
  },
  {
    "id": "arXiv:2206.00273",
    "title": "A reinforcement learning-based link quality estimation strategy for RPL  and its impact on topology management",
    "abstract": "Over the last few years, standardisation efforts are consolidating the role\nof the Routing Protocol for LowPower and Lossy Networks (RPL) as the standard\nrouting protocol for IPv6 based Wireless Sensor Networks (WSNs). Although many\ncore functionalities are well defined, others are left implementation\ndependent. Among them, the definition of an efficient link quality estimation\n(LQE) strategy is of paramount importance, as it influences significantly both\nthe quality of the selected network routes and nodes' energy consumption. In\nthis paper, we present RLProbe, a novel strategy for link quality monitoring in\nRPL, which accurately measures link quality with minimal overhead and energy\nwaste. To achieve this goal, RLProbe leverages both synchronous and\nasynchronous monitoring schemes to maintain up-to-date information on link\nquality and to promptly react to sudden topology changes, e.g. due to mobility.\nOur solution relies on a reinforcement learning model to drive the monitoring\nprocedures in order to minimise the overhead caused by active probing\noperations. The performance of the proposed solution is assessed by means of\nsimulations and real experiments. Results demonstrated that RLProbe helps in\neffectively improving packet loss rates, allowing nodes to promptly react to\nlink quality variations as well as to link failures due to node mobility.",
    "descriptor": "",
    "authors": [
      "Emilio Ancillotti",
      "Carlo Vallati",
      "Raffaele Bruno",
      "Enzo Mingozzi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.00273"
  },
  {
    "id": "arXiv:2206.00274",
    "title": "Point-Teaching: Weakly Semi-Supervised Object Detection with Point  Annotations",
    "abstract": "Point annotations are considerably more time-efficient than bounding box\nannotations. However, how to use cheap point annotations to boost the\nperformance of semi-supervised object detection remains largely unsolved. In\nthis work, we present Point-Teaching, a weakly semi-supervised object detection\nframework to fully exploit the point annotations. Specifically, we propose a\nHungarian-based point matching method to generate pseudo labels for point\nannotated images. We further propose multiple instance learning (MIL)\napproaches at the level of images and points to supervise the object detector\nwith point annotations. Finally, we propose a simple-yet-effective data\naugmentation, termed point-guided copy-paste, to reduce the impact of the\nunmatched points. Experiments demonstrate the effectiveness of our method on a\nfew datasets and various data regimes.",
    "descriptor": "",
    "authors": [
      "Yongtao Ge",
      "Qiang Zhou",
      "Xinlong Wang",
      "Chunhua Shen",
      "Zhibin Wang",
      "Hao Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.00274"
  },
  {
    "id": "arXiv:2206.00276",
    "title": "An adaptive fuzzy dead-zone compensation scheme for nonlinear systems",
    "abstract": "The dead-zone nonlinearity is frequently encountered in many industrial\nautomation equipment and its presence can severely compromise control system\nperformance. Due to the possibility to express human experience in an\nalgorithmic manner, fuzzy logic has been largely employed in the last decades\nto both control and identification of uncertain dynamical systems. In spite of\nthe simplicity of this heuristic approach, in some situations a more rigorous\nmathematical treatment of the problem is required. In this work, an adaptive\nfuzzy controller is proposed for nonlinear systems subject to dead-zone input.\nThe convergence properties of the tracking error will be proven using Lyapunov\nstability theory and Barbalat's lemma. An application of this adaptive fuzzy\nscheme to a Van der Pol oscillator is introduced to illustrate the controller\ndesign method. Numerical results are also presented in order to demonstrate the\ncontrol system performance.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2205.13669; text overlap with arXiv:2205.15639, arXiv:2205.13344, arXiv:2205.13343\n",
    "authors": [
      "Wallace Moreira Bessa",
      "Max Suell Dutra",
      "Edwin Kreuzer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.00276"
  },
  {
    "id": "arXiv:2206.00277",
    "title": "Task-Specific Expert Pruning for Sparse Mixture-of-Experts",
    "abstract": "The sparse Mixture-of-Experts (MoE) model is powerful for large-scale\npre-training and has achieved promising results due to its model capacity.\nHowever, with trillions of parameters, MoE is hard to be deployed on cloud or\nmobile environment. The inference of MoE requires expert parallelism, which is\nnot hardware-friendly and communication expensive. Especially for\nresource-limited downstream tasks, such sparse structure has to sacrifice a lot\nof computing efficiency for limited performance gains. In this work, we observe\nmost experts contribute scarcely little to the MoE fine-tuning and inference.\nWe further propose a general method to progressively drop the non-professional\nexperts for the target downstream task, which preserves the benefits of MoE\nwhile reducing the MoE model into one single-expert dense model. Our\nexperiments reveal that the fine-tuned single-expert model could preserve 99.3%\nbenefits from MoE across six different types of tasks while enjoying 2x\ninference speed with free communication cost.",
    "descriptor": "\nComments: under review\n",
    "authors": [
      "Tianyu Chen",
      "Shaohan Huang",
      "Yuan Xie",
      "Binxing Jiao",
      "Daxin Jiang",
      "Haoyi Zhou",
      "Jianxin Li",
      "Furu Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.00277"
  },
  {
    "id": "arXiv:2206.00278",
    "title": "On the Perils of Cascading Robust Classifiers",
    "abstract": "Ensembling certifiably robust neural networks has been shown to be a\npromising approach for improving the \\emph{certified robust accuracy} of neural\nmodels. Black-box ensembles that assume only query-access to the constituent\nmodels (and their robustness certifiers) during prediction are particularly\nattractive due to their modular structure. Cascading ensembles are a popular\ninstance of black-box ensembles that appear to improve certified robust\naccuracies in practice. However, we find that the robustness certifier used by\na cascading ensemble is unsound. That is, when a cascading ensemble is\ncertified as locally robust at an input $x$, there can, in fact, be inputs $x'$\nin the $\\epsilon$-ball centered at $x$, such that the cascade's prediction at\n$x'$ is different from $x$. We present an alternate black-box ensembling\nmechanism based on weighted voting which we prove to be sound for robustness\ncertification. Via a thought experiment, we demonstrate that if the constituent\nclassifiers are suitably diverse, voting ensembles can improve certified\nperformance. Our code is available at\n\\url{https://github.com/TristaChi/ensembleKW}.",
    "descriptor": "",
    "authors": [
      "Ravi Mangal",
      "Zifan Wang",
      "Chi Zhang",
      "Klas Leino",
      "Corina Pasareanu",
      "Matt Fredrikson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00278"
  },
  {
    "id": "arXiv:2206.00279",
    "title": "Defensive Design of Saturating Counters Based on Differential Privacy",
    "abstract": "The saturating counter is the basic module of the dynamic branch predictor,\nwhich involves the core technique to improve instruction level parallelism\nperformance in modern processors. However, most studies focus on the\nperformance improvement and hardware consumption of saturating counters, while\nignoring the security problems they may cause. In this paper, we creatively\npropose to study and design saturating counters from the defense perspective of\ndifferential privacy, so that attackers cannot distinguish the states that\nsaturating counters are in and further infer sensitive information. To obtain\ntheoretical guarantees, we use Markov chain to formalize the attack algorithm\napplied to the saturating counter, investigate into the optimal attack strategy\nand calculate the probability of successful attack. Furthermore, we find that\nthe attacker is able to accurately guess the branch execution of the victim's\nprocess in the existing saturating counters. To avoid this, we design a new\nprobabilistic saturating counter, which generalizes the existing conventional\nand probabilistic saturating counters. The guarantee of differential privacy is\napplied to deduce parameters of the new saturating counters so that the\nsecurity requirement can be satisfied. We also theoretically calculate the\nmisprediction rate when the saturating counter reaches the steady state. The\nexperimental results on testing programs show that the calculated theoretical\nresults agree with the experimental performances. Compared with the existing\nconventional and probabilistic saturating counters, when the parameters of our\ndesigned models are selected appropriately, the new saturating counters can not\nonly ensure similar operational performance, but also establish strict security\nguarantee.",
    "descriptor": "",
    "authors": [
      "Depeng Liu",
      "Lutan Zhao",
      "Pengfei Yang",
      "Bow-Yaw Wang",
      "Rui Hou",
      "Lijun Zhang",
      "Naijun Zhan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2206.00279"
  },
  {
    "id": "arXiv:2206.00280",
    "title": "Automatic Bounding Box Annotation with Small Training Data Sets for  Industrial Manufacturing",
    "abstract": "In the past few years, object detection has attracted a lot of attention in\nthe context of human-robot collaboration and Industry 5.0 due to enormous\nquality improvements in deep learning technologies. In many applications,\nobject detection models have to be able to quickly adapt to a changing\nenvironment, i.e., to learn new objects. A crucial but challenging prerequisite\nfor this is the automatic generation of new training data which currently still\nlimits the broad application of object detection methods in industrial\nmanufacturing. In this work, we discuss how to adapt state-of-the-art object\ndetection methods for the task of automatic bounding box annotation for the use\ncase where the background is homogeneous and the object's label is provided by\na human. We compare an adapted version of Faster R-CNN and the Scaled Yolov4-p5\narchitecture and show that both can be trained to distinguish unknown objects\nfrom a complex but homogeneous background using only a small amount of training\ndata.",
    "descriptor": "",
    "authors": [
      "Manuela Gei\u00df",
      "Raphael Wagner",
      "Martin Baresch",
      "Josef Steiner",
      "Michael Zwick"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.00280"
  },
  {
    "id": "arXiv:2206.00282",
    "title": "Needle In A Haystack, Fast: Benchmarking Image Perceptual Similarity  Metrics At Scale",
    "abstract": "The advent of the internet, followed shortly by the social media made it\nubiquitous in consuming and sharing information between anyone with access to\nit. The evolution in the consumption of media driven by this change, led to the\nemergence of images as means to express oneself, convey information and\nconvince others efficiently. With computer vision algorithms progressing\nradically over the last decade, it is become easier and easier to study at\nscale the role of images in the flow of information online. While the research\nquestions and overall pipelines differ radically, almost all start with a\ncrucial first step - evaluation of global perceptual similarity between\ndifferent images. That initial step is crucial for overall pipeline performance\nand processes most images. A number of algorithms are available and currently\nused to perform it, but so far no comprehensive review was available to guide\nthe choice of researchers as to the choice of an algorithm best suited to their\nquestion, assumptions and computational resources. With this paper we aim to\nfill this gap, showing that classical computer vision methods are not\nnecessarily the best approach, whereas a pair of relatively little used methods\n- Dhash perceptual hash and SimCLR v2 ResNets achieve excellent performance,\nscale well and are computationally efficient.",
    "descriptor": "\nComments: 26 pages, 10 figures\n",
    "authors": [
      "Cyril Vallez",
      "Andrei Kucharavy",
      "Ljiljana Dolamic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2206.00282"
  },
  {
    "id": "arXiv:2206.00287",
    "title": "Strict Half-Singleton Bound, Strict Direct Upper Bound for Linear  Insertion-Deletion Codes and Optimal Codes",
    "abstract": "Insertion-deletion codes (insdel codes for short) are used for correcting\nsynchronization errors in communications, and in other many interesting fields\nsuch as DNA storage, date analysis, race-track memory error correction and\nlanguage processing, and have recently gained a lot of attention. To determine\nthe insdel distances of linear codes is a very challenging problem. The\nhalf-Singleton bound on the insdel distances of linear codes due to\nCheng-Guruswami-Haeupler-Li is a basic upper bound on the insertion-deletion\nerror-correcting capabilities of linear codes. On the other hand the natural\ndirect upper bound $d_I(\\mathcal C) \\leq 2d_H(\\mathcal C)$ is valid for any\ninsdel code. In this paper, for a linear insdel code $\\mathcal C$ we propose a\nstrict half-Singleton upper bound $d_I(\\mathcal C) \\leq 2(n-2k+1)$ if $\\mathcal\nC$ does not contain the codeword with all 1s, and a stronger direct upper bound\n$d_I(\\mathcal C) \\leq 2(d_H(\\mathcal C)-t)$ under a weak condition, where\n$t\\geq 1$ is a positive integer determined by the generator matrix. We also\ngive optimal linear insdel codes attaining our strict half-Singleton bound and\ndirect upper bound, and show that the code length of optimal binary linear\ninsdel codes with respect to the (strict) half-Singleton bound is about twice\nthe dimension. Interestingly explicit optimal linear insdel codes attaining the\n(strict) half-Singleton bound, with the code length being independent of the\nfinite field size, are given.",
    "descriptor": "",
    "authors": [
      "Qinqin Ji",
      "Dabin Zheng",
      "Hao Chen",
      "Xiaoqiang Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.00287"
  },
  {
    "id": "arXiv:2206.00288",
    "title": "Sustaining Security and Safety in ICT: A Quest for Terminology,  Objectives, and Limits",
    "abstract": "Security and safety are intertwined concepts in the world of computing. In\nrecent years, the terms \"sustainable security\" and \"sustainable safety\" came\ninto fashion and are being used referring to a variety of systems properties\nranging from efficiency to profitability, and sometimes meaning that a product\nor service is good for people and planet. This leads to confusing perceptions\nof products where customers might expect a sustainable product to be developed\nwithout child labour, while the producer uses the term to signify that their\nnew product uses marginally less power than the previous generation of that\nproducts. Even in research on sustainably safe and secure ICT, these different\nnotions of terminology are prevalent. As researchers we often work towards\noptimising our subject of study towards one specific sustainability metric -\nlet's say energy consumption - while being blissfully unaware of, e.g., social\nimpacts, life-cycle impacts, or rebound effects of such optimisations.\nIn this paper I dissect the idea of sustainable safety and security, starting\nfrom the questions of what we want to sustain, and for whom we want to sustain\nit. I believe that a general \"people and planet\" answer is inadequate here\nbecause this form of sustainability cannot be the property of a single industry\nsector but must be addressed by society as a whole. However, with sufficient\nunderstanding of life-cycle impacts we may very well be able to devise research\nand development efforts, and inform decision making processes towards the use\nof integrated safety and security solutions that help us to address societal\nchallenges in the context of the climate and ecological crises, and that are\naligned with concepts such as intersectionality and climate justice. Of course,\nthese solutions can only be effective if they are embedded in societal and\neconomic change towards more frugal uses of data and ICT.",
    "descriptor": "",
    "authors": [
      "Jan Tobias Muehlberg"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.00288"
  },
  {
    "id": "arXiv:2206.00289",
    "title": "MORE: A Metric Learning Based Framework for Open-domain Relation  Extraction",
    "abstract": "Open relation extraction (OpenRE) is the task of extracting relation schemes\nfrom open-domain corpora. Most existing OpenRE methods either do not fully\nbenefit from high-quality labeled corpora or can not learn semantic\nrepresentation directly, affecting downstream clustering efficiency. To address\nthese problems, in this work, we propose a novel learning framework named MORE\n(Metric learning-based Open Relation Extraction). The framework utilizes deep\nmetric learning to obtain rich supervision signals from labeled data and drive\nthe neural model to learn semantic relational representation directly.\nExperiments result in two real-world datasets show that our method outperforms\nother state-of-the-art baselines. Our source code is available on Github.",
    "descriptor": "\nComments: 5 pages, 3 figures, accepted by ICASSP 2021\n",
    "authors": [
      "Yutong Wang",
      "Renze Lou",
      "Kai Zhang",
      "MaoYan Chen",
      "Yujiu Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.00289"
  },
  {
    "id": "arXiv:2206.00290",
    "title": "Discrete Gradient Flow Approximations of High Dimensional Evolution  Partial Differential Equations via Deep Neural Networks",
    "abstract": "We consider the approximation of initial/boundary value problems involving,\npossibly high-dimensional, dissipative evolution partial differential equations\n(PDEs) using a deep neural network framework. More specifically, we first\npropose discrete gradient flow approximations based on non-standard Dirichlet\nenergies for problems involving essential boundary conditions posed on bounded\nspatial domains. The imposition of the boundary conditions is realized weakly\nvia non-standard functionals; the latter classically arise in the construction\nof Galerkin-type numerical methods and are often referred to as \"Nitsche-type\"\nmethods. Moreover, inspired by the seminal work of Jordan, Kinderleher, and\nOtto (JKO) \\cite{jko}, we consider the second class of discrete gradient flows\nfor special classes of dissipative evolution PDE problems with non-essential\nboundary conditions. These JKO-type gradient flows are solved via deep neural\nnetwork approximations. A key, distinct aspect of the proposed methods is that\nthe discretization is constructed via a sequence of residual-type deep neural\nnetworks (DNN) corresponding to implicit time-stepping. As a result, a DNN\nrepresents the PDE problem solution at each time node. This approach offers\nseveral advantages in the training of each DNN. We present a series of\nnumerical experiments which showcase the good performance of Dirichlet-type\nenergy approximations for lower space dimensions and the excellent performance\nof the JKO-type energies for higher spatial dimensions.",
    "descriptor": "",
    "authors": [
      "Emmanuil H. Georgoulis",
      "Michail Loulakis",
      "Asterios Tsiourvas"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.00290"
  },
  {
    "id": "arXiv:2206.00291",
    "title": "Efficient Multi-Purpose Cross-Attention Based Image Alignment Block for  Edge Devices",
    "abstract": "Image alignment, also known as image registration, is a critical block used\nin many computer vision problems. One of the key factors in alignment is\nefficiency, as inefficient aligners can cause significant overhead to the\noverall problem. In the literature, there are some blocks that appear to do the\nalignment operation, although most do not focus on efficiency. Therefore, an\nimage alignment block which can both work in time and/or space and can work on\nedge devices would be beneficial for almost all networks dealing with multiple\nimages. Given its wide usage and importance, we propose an efficient,\ncross-attention-based, multi-purpose image alignment block (XABA) suitable to\nwork within edge devices. Using cross-attention, we exploit the relationships\nbetween features extracted from images. To make cross-attention feasible for\nreal-time image alignment problems and handle large motions, we provide a\npyramidal block based cross-attention scheme. This also captures local\nrelationships besides reducing memory requirements and number of operations.\nEfficient XABA models achieve real-time requirements of running above 20 FPS\nperformance on NVIDIA Jetson Xavier with 30W power consumption compared to\nother powerful computers. Used as a sub-block in a larger network, XABA also\nimproves multi-image super-resolution network performance in comparison to\nother alignment methods.",
    "descriptor": "\nComments: Accepted into Embedded Vision Workshop 2022 of CVPR 2022\n",
    "authors": [
      "Bahri Batuhan Bilecen",
      "Alparslan Fisne",
      "Mustafa Ayazoglu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.00291"
  },
  {
    "id": "arXiv:2206.00298",
    "title": "Exploration of Knitted Spacer Fabrics using Grasshopper",
    "abstract": "We describe a novel approach for exploring, visualizing and modelling of\ncomplex textile structures. We show this approach in action for the exploration\nof weft-knitted spacer fabrics. The modelling tools are readily available and\nrepresent a fast-growing approach in communities of generative design. The\napproach helps solving the problem that spacer fabrics are complex structures\nwhich are hard to imagine and to visualize. The explorations turn out\ninsight-full and flexible and are complementary to what can be done with\nexisting tools.",
    "descriptor": "\nComments: 11 pages, 7 figures\n",
    "authors": [
      "Suzanne Oude Hengel",
      "Loe Feijs"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.00298"
  },
  {
    "id": "arXiv:2206.00302",
    "title": "Multi-Complexity-Loss DNAS for Energy-Efficient and Memory-Constrained  Deep Neural Networks",
    "abstract": "Neural Architecture Search (NAS) is increasingly popular to automatically\nexplore the accuracy versus computational complexity trade-off of Deep Learning\n(DL) architectures. When targeting tiny edge devices, the main challenge for DL\ndeployment is matching the tight memory constraints, hence most NAS algorithms\nconsider model size as the complexity metric. Other methods reduce the energy\nor latency of DL models by trading off accuracy and number of inference\noperations. Energy and memory are rarely considered simultaneously, in\nparticular by low-search-cost Differentiable NAS (DNAS) solutions. We overcome\nthis limitation proposing the first DNAS that directly addresses the most\nrealistic scenario from a designer's perspective: the co-optimization of\naccuracy and energy (or latency) under a memory constraint, determined by the\ntarget HW. We do so by combining two complexity-dependent loss functions during\ntraining, with independent strength. Testing on three edge-relevant tasks from\nthe MLPerf Tiny benchmark suite, we obtain rich Pareto sets of architectures in\nthe energy vs. accuracy space, with memory footprints constraints spanning from\n75% to 6.25% of the baseline networks. When deployed on a commercial edge\ndevice, the STM NUCLEO-H743ZI2, our networks span a range of 2.18x in energy\nconsumption and 4.04% in accuracy for the same memory constraint, and reduce\nenergy by up to 2.2x with negligible accuracy drop with respect to the\nbaseline.",
    "descriptor": "\nComments: Accepted for publication at the ISLPED 2022 ACM/IEEE International Symposium on Low Power Electronics and Design\n",
    "authors": [
      "Matteo Risso",
      "Alessio Burrello",
      "Luca Benini",
      "Enrico Macii",
      "Massimo Poncino",
      "Daniele Jahier Pagliari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00302"
  },
  {
    "id": "arXiv:2206.00303",
    "title": "Predecessor Features",
    "abstract": "Any reinforcement learning system must be able to identify which past events\ncontributed to observed outcomes, a problem known as credit assignment. A\ncommon solution to this problem is to use an eligibility trace to assign credit\nto recency-weighted set of experienced events. However, in many realistic\ntasks, the set of recently experienced events are only one of the many possible\naction events that could have preceded the current outcome. This suggests that\nreinforcement learning can be made more efficient by allowing credit assignment\nto any viable preceding state, rather than only those most recently\nexperienced. Accordingly, we propose \"Predecessor Features\", an algorithm that\nachieves this richer form of credit assignment. By maintaining a representation\nthat approximates the expected sum of past occupancies, our algorithm allows\ntemporal difference (TD) errors to be propagated accurately to a larger number\nof predecessor states than conventional methods, greatly improving learning\nspeed. Our algorithm can also be naturally extended from tabular state\nrepresentation to feature representations allowing for increased performance on\na wide range of environments. We demonstrate several use cases for Predecessor\nFeatures and contrast its performance with other similar approaches.",
    "descriptor": "\nComments: Accepted to RLDM 2022. Refer to Book of Abstracts RLDM 22\n",
    "authors": [
      "Duncan Bailey",
      "Marcelo Mattar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.00303"
  },
  {
    "id": "arXiv:2206.00304",
    "title": "Perception-Intention-Action Cycle in Human-Robot Collaborative Tasks",
    "abstract": "In this work we argue that in Human-Robot Collaboration (HRC) tasks, the\nPerception-Action cycle in HRC tasks can not fully explain the collaborative\nbehaviour of the human and robot and it has to be extended to\nPerception-Intention-Action cycle, where Intention is a key topic. In some\ncases, agent Intention can be perceived or inferred by the other agent, but in\nothers, it has to be explicitly informed to the other agent to succeed the goal\nof the HRC task. The Perception-Intention-Action cycle includes three basic\nfunctional procedures: Perception-Intention, Situation Awareness and Action.\nThe Perception and the Intention are the input of the Situation Awareness,\nwhich evaluates the current situation and projects it, into the future\nsituation. The agents receive this information, plans and agree with the\nactions to be executed and modify their action roles while perform the HRC\ntask. In this work, we validate the Perception-Intention-Action cycle in a\njoint object transportation task, modeling the Perception-Intention-Action\ncycle through a force model which uses real life and social forces. The\nperceived world is projected into a force world and the human intention\n(perceived or informed) is also modelled as a force that acts in the HRC task.\nFinally, we show that the action roles (master-slave, collaborative, neutral or\nadversary) are intrinsic to any HRC task and they appear in the different steps\nof a collaborative sequence of actions performed during the task.",
    "descriptor": "",
    "authors": [
      "J. E. Dominguez-Vidal",
      "Nicolas Rodriguez",
      "Rene Alquezar",
      "Alberto Sanfeliu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.00304"
  },
  {
    "id": "arXiv:2206.00307",
    "title": "Federated Learning in Satellite Constellations",
    "abstract": "Distributed machine learning (DML) results from the synergy between machine\nlearning and connectivity. Federated learning (FL) is a prominent instance of\nDML in which intermittently connected mobile clients contribute to the training\nof a common learning model. This paper presents the new context brought to FL\nby satellite constellations where the connectivity patterns are significantly\ndifferent from the ones assumed in terrestrial FL. We provide a taxonomy of\ndifferent types of satellite connectivity relevant for FL and show how the\ndistributed training process can overcome the slow convergence due to long\noffline times of clients by taking advantage of the predictable intermittency\nof the satellite communication links.",
    "descriptor": "",
    "authors": [
      "Bho Matthiesen",
      "Nasrin Razmi",
      "Israel Leyva-Mayorga",
      "Armin Dekorsy",
      "Petar Popovski"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.00307"
  },
  {
    "id": "arXiv:2206.00308",
    "title": "Content Distribution based on Joint V2I and V2V Scheduling in mmWave  Vehicular Networks",
    "abstract": "With the explosive growth of vehicle applications, vehicular networks based\non millimeter wave (mmWave) bands have attracted interests from both academia\nand industry. mmWave communications are able to utilize the huge available\nbandwidth to provide multiple Gbps transmission rates among vehicles. In this\npaper, we address the content distribution scheduling problem in mmWave\nvehicular networks. It has been challenging for all vehicles in the same\nnetwork to complete content downloading due to the limited communication\nresources of roadside units (RSUs) and the high mobility of vehicles. We\npropose a joint vehicle-to-infrastructure (V2I) and vehicle-tovehicle (V2V)\nscheduling scheme to minimize the total number of content distribution time\nslots from a global optimization perspective. In the V2I phase, the RSU\nserially transmits integrity content to vehicles, which are selected according\nto the vehicular network topology and transmission scheduling scheme. In the\nV2V phase, full-duplex communications and concurrent transmissions are\nexploited to achieve content sharing between vehicles and improve transmission\nefficiency. Performance evaluations demonstrate that our proposed scheme\nreduces the number of time slots and significantly improves system throughput\nwhen compared with other schemes, especially under large-size file transfers\nand a large number of vehicles.",
    "descriptor": "\nComments: 12 pages, 11 figures, IEEE Transactions on Vehicular Technology\n",
    "authors": [
      "Lan Su",
      "Yong Niu",
      "Zhu Han",
      "Bo Ai",
      "Ruisi He",
      "Yibing Wang",
      "Ning Wang",
      "Xiang Su"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.00308"
  },
  {
    "id": "arXiv:2206.00309",
    "title": "Label-Efficient Online Continual Object Detection in Streaming Video",
    "abstract": "To thrive in evolving environments, humans are capable of continual\nacquisition and transfer of new knowledge, from a continuous video stream, with\nminimal supervisions, while retaining previously learnt experiences. In\ncontrast to human learning, most standard continual learning benchmarks focus\non learning from static iid images in fully supervised settings. Here, we\nexamine a more realistic and challenging\nproblem$\\unicode{x2014}$Label-Efficient Online Continual Object Detection\n(LEOCOD) in video streams. By addressing this problem, it would greatly benefit\nmany real-world applications with reduced annotation costs and retraining time.\nTo tackle this problem, we seek inspirations from complementary learning\nsystems (CLS) in human brains and propose a computational model, dubbed as\nEfficient-CLS. Functionally correlated with the hippocampus and the neocortex\nin CLS, Efficient-CLS posits a memory encoding mechanism involving\nbidirectional interaction between fast and slow learners via synaptic weight\ntransfers and pattern replays. We test Efficient-CLS and competitive baselines\nin two challenging real-world video stream datasets. Like humans, Efficient-CLS\nlearns to detect new object classes incrementally from a continuous temporal\nstream of non-repeating video with minimal forgetting. Remarkably, with only\n25% annotated video frames, our Efficient-CLS still leads among all comparative\nmodels, which are trained with 100% annotations on all video frames. The data\nand source code will be publicly available at\nhttps://github.com/showlab/Efficient-CLS.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Jay Zhangjie Wu",
      "David Junhao Zhang",
      "Wynne Hsu",
      "Mengmi Zhang",
      "Mike Zheng Shou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.00309"
  },
  {
    "id": "arXiv:2206.00310",
    "title": "Digital Twin for Networking: A Data-driven Performance Modeling  Perspective",
    "abstract": "Emerging technologies and applications make the network unprecedentedly\ncomplex and heterogeneous, leading physical network practices to be costly and\nrisky. The digital twin network (DTN) can ease these burdens by virtually\nenabling users to understand how performance changes accordingly with\nmodifications. For this \"What-if\" performance evaluation, conventional\nsimulation and analytical approaches are inefficient, inaccurate, and\ninflexible, and we argue that data-driven methods are most promising. In this\narticle, we identify three requirements (fidelity, efficiency, and flexibility)\nfor performance evaluation. Then we present a comparison of selected\ndata-driven methods and investigate their potential trends in data, models, and\napplications. Although extensive applications have been enabled, there are\nstill significant conflicts between models' capacities to handle diversified\ninputs and limited data collected from the production network. We further\nillustrate the opportunities for data collection, model construction, and\napplication prospects. This survey aims to provide a reference for performance\nevaluation while also facilitating future DTN research.",
    "descriptor": "",
    "authors": [
      "Linbo Hui",
      "Mowei Wang",
      "Liang Zhang",
      "Lu Lu",
      "Yong Cui"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.00310"
  },
  {
    "id": "arXiv:2206.00311",
    "title": "MaskOCR: Text Recognition with Masked Encoder-Decoder Pretraining",
    "abstract": "In this paper, we present a model pretraining technique, named MaskOCR, for\ntext recognition. Our text recognition architecture is an encoder-decoder\ntransformer: the encoder extracts the patch-level representations, and the\ndecoder recognizes the text from the representations. Our approach pretrains\nboth the encoder and the decoder in a sequential manner. (i) We pretrain the\nencoder in a self-supervised manner over a large set of unlabeled real text\nimages. We adopt the masked image modeling approach, which shows the\neffectiveness for general images, expecting that the representations take on\nsemantics. (ii) We pretrain the decoder over a large set of synthesized text\nimages in a supervised manner and enhance the language modeling capability of\nthe decoder by randomly masking some text image patches occupied by characters\ninput to the encoder and accordingly the representations input to the decoder.\nExperiments show that the proposed MaskOCR approach achieves superior results\non the benchmark datasets, including Chinese and English text images.",
    "descriptor": "",
    "authors": [
      "Pengyuan Lyu",
      "Chengquan Zhang",
      "Shanshan Liu",
      "Meina Qiao",
      "Yangliu Xu",
      "Liang Wu",
      "Kun Yao",
      "Junyu Han",
      "Errui Ding",
      "Jingdong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.00311"
  },
  {
    "id": "arXiv:2206.00312",
    "title": "A Wavenumber Integration Model of Underwater Acoustic Propagation in  Arbitrary Horizontally Stratified Media Based on a Spectral Method",
    "abstract": "The wavenumber integration method is considered to be the most accurate\nalgorithm of arbitrary horizontally stratified media in computational ocean\nacoustics. Compared with normal modes, it contains not only the discrete\nspectrum of the wavenumber but also the components of the continuous spectrum,\neliminating errors in the model approximation for horizontally stratified\nmedia. Traditionally, analytical and semianalytical methods have been used to\nsolve the depth-separated wave equation of the wavenumber integration method,\nand numerical solutions have generally focused on the finite difference method\nand the finite element method. In this paper, an algorithm for solving the\ndepth equation with the Chebyshev--Tau spectral method combined with the domain\ndecomposition strategy is proposed, and a numerical program named WISpec is\ndeveloped accordingly. The algorithm can simulate both the sound field excited\nby a point source and the sound field excited by a line source. The key idea of\nthe algorithm is first to discretize the depth equations of each layer by using\nthe Chebyshev--Tau spectral method and then to solve the equations of each\nlayer simultaneously by combining boundary and interface conditions. Several\nrepresentative numerical experiments are devised to test the accuracy of\n`WISpec'. The high consistency of the results of different models running under\nthe same configuration proves that the numerical algorithm proposed in this\npaper is accurate, reliable, and numerically stable.",
    "descriptor": "\nComments: 26 pages, 10 figures and 2 tables\n",
    "authors": [
      "Houwang Tu",
      "Yongxian Wang",
      "Wei Liu",
      "Shuqing Ma",
      "Xiaodong Wang",
      "Wenbin Xiao"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.00312"
  },
  {
    "id": "arXiv:2206.00314",
    "title": "Contextual Bandits with Knapsacks for a Conversion Model",
    "abstract": "We consider contextual bandits with knapsacks, with an underlying structure\nbetween rewards generated and cost vectors suffered. We do so motivated by\nsales with commercial discounts. At each round, given the stochastic i.i.d.\\\ncontext $\\mathbf{x}_t$ and the arm picked $a_t$ (corresponding, e.g., to a\ndiscount level), a customer conversion may be obtained, in which case a reward\n$r(a,\\mathbf{x}_t)$ is gained and vector costs $c(a_t,\\mathbf{x}_t)$ are\nsuffered (corresponding, e.g., to losses of earnings). Otherwise, in the\nabsence of a conversion, the reward and costs are null. The reward and costs\nachieved are thus coupled through the binary variable measuring conversion or\nthe absence thereof. This underlying structure between rewards and costs is\ndifferent from the linear structures considered by Agrawal and Devanur [2016]\nbut we show that the techniques introduced in this article may also be applied\nto the latter case. Namely, the adaptive policies exhibited solve at each round\na linear program based on upper-confidence estimates of the probabilities of\nconversion given $a$ and $\\mathbf{x}$. This kind of policy is most natural and\nachieves a regret bound of the typical order (OPT/$B$) $\\sqrt{T}$, where $B$ is\nthe total budget allowed, OPT is the optimal expected reward achievable by a\nstatic policy, and $T$ is the number of rounds.",
    "descriptor": "",
    "authors": [
      "Zhen Li",
      "Gilles Stoltz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.00314"
  },
  {
    "id": "arXiv:2206.00316",
    "title": "Model Generation with Provable Coverability for Offline Reinforcement  Learning",
    "abstract": "Model-based offline optimization with dynamics-aware policy provides a new\nperspective for policy learning and out-of-distribution generalization, where\nthe learned policy could adapt to different dynamics enumerated at the training\nstage. But due to the limitation under the offline setting, the learned model\ncould not mimic real dynamics well enough to support reliable\nout-of-distribution exploration, which still hinders policy to generalize well.\nTo narrow the gap, previous works roughly ensemble randomly initialized models\nto better approximate the real dynamics. However, such practice is costly and\ninefficient, and provides no guarantee on how well the real dynamics could be\napproximated by the learned models, which we name coverability in this paper.\nWe actively address this issue by generating models with provable ability to\ncover real dynamics in an efficient and controllable way. To that end, we\ndesign a distance metric for dynamic models based on the occupancy of policies\nunder the dynamics, and propose an algorithm to generate models optimizing\ntheir coverage for the real dynamics. We give a theoretical analysis on the\nmodel generation process and proves that our algorithm could provide enhanced\ncoverability. As a downstream task, we train a dynamics-aware policy with minor\nor no conservative penalty, and experiments demonstrate that our algorithm\noutperforms prior offline methods on existing offline RL benchmarks. We also\ndiscover that policies learned by our method have better zero-shot transfer\nperformance, implying their better generalization.",
    "descriptor": "\nComments: 10 pages, 8 figures\n",
    "authors": [
      "Chengxing Jia",
      "Hao Yin",
      "Chenxiao Gao",
      "Tian Xu",
      "Lei Yuan",
      "Zongzhang Zhang",
      "Yang Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00316"
  },
  {
    "id": "arXiv:2206.00317",
    "title": "Temporal Characterization of VR Traffic for Network Slicing Requirement  Definition",
    "abstract": "Over the past few years, the concept of VR has attracted increasing interest\nthanks to its extensive industrial and commercial applications. Currently, the\n3D models of the virtual scenes are generally stored in the VR visor itself,\nwhich operates as a standalone device. However, applications that entail\nmulti-party interactions will likely require the scene to be processed by an\nexternal server and then streamed to the visors. However, the stringent Quality\nof Service (QoS) constraints imposed by VR's interactive nature require Network\nSlicing (NS) solutions, for which profiling the traffic generated by the VR\napplication is crucial. To this end, we collected more than 4 hours of traces\nin a real setup and analyzed their temporal correlation. More specifically, we\nfocused on the CBR encoding mode, which should generate more predictable\ntraffic streams. From the collected data, we then distilled two prediction\nmodels for future frame size, which can be instrumental in the design of\ndynamic resource allocation algorithms. Our results show that even the\nstate-of-the-art H.264 CBR mode can have significant fluctuations, which can\nimpact the NS optimization. We then exploited the proposed models to\ndynamically determine the Service Level Agreement (SLA) parameters in an NS\nscenario, providing service with the required QoS while minimizing resource\nusage.",
    "descriptor": "\nComments: 17 pages. 18 figures. This paper has been submitted to IEEE Transactions on Mobile Computing. Copyright may change without notice. arXiv admin note: substantial text overlap with arXiv:2201.07043\n",
    "authors": [
      "Federico Chiariotti",
      "Matteo Drago",
      "Paolo Testolina",
      "Mattia Lecci",
      "Andrea Zanella",
      "Michele Zorzi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.00317"
  },
  {
    "id": "arXiv:2206.00320",
    "title": "Well-posedness and Mittag--Leffler Euler integrator for space-time  fractional SPDEs with fractionally integrated additive noise",
    "abstract": "This paper considers the space-time fractional stochastic partial\ndifferential equation (SPDE, for short) with fractionally integrated additive\nnoise, which is general and includes many (fractional) SPDEs with additive\nnoise. Firstly, the existence, uniqueness and temporal regularity of the mild\nsolution are presented. Then the Mittag--Leffler Euler integrator is proposed\nas a time-stepping method to numerically solve the underlying model. Two key\ningredients are developed to overcome the difficulty caused by the interaction\nbetween the time-fractional derivative and the fractionally integrated noise.\nOne is a novel decomposition way for the drift part of the mild solution, named\nhere the integral decomposition technique, and the other is to derive some fine\nestimates associated with the solution operator by making use of the properties\nof the Mittag--Leffler function. Consequently, the proposed Mittag--Leffler\nEuler integrator is proved to be convergent with order $\\min\\{ \\frac{1}{2} +\n\\frac{\\alpha}{2\\beta}(r+\\lambda-\\kappa), 1 \\}$ if $\\alpha + \\gamma = 1$,\notherwise order $\\min\\{ \\frac{\\alpha}{2\\beta}\\min\\{\\kappa,r+\\lambda\\} +\n(\\gamma-\\frac{1}{2})^{+}, 1-\\varepsilon\\}$ in the sense of $L^2(\\Omega,H)$-norm\nfor the nonlinear case. In particular, the corresponding convergence order can\nattain $\\min\\{ \\alpha + \\frac{\\alpha r}{2\\beta} +\n(\\gamma-\\frac{1}{2})^{+}-\\varepsilon, \\alpha+\\gamma -\\varepsilon, 1 \\}$ for the\nlinear case.",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Xinjie Dai",
      "Jialin Hong",
      "Derui Sheng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.00320"
  },
  {
    "id": "arXiv:2206.00322",
    "title": "Missed Opportunities: Measuring the Untapped TLS Support in the  Industrial Internet of Things",
    "abstract": "The ongoing trend to move industrial appliances from previously isolated\nnetworks to the Internet requires fundamental changes in security to uphold\nsecure and safe operation. Consequently, to ensure end-to-end secure\ncommunication and authentication, (i) traditional industrial protocols, e.g.,\nModbus, are retrofitted with TLS support, and (ii) modern protocols, e.g.,\nMQTT, are directly designed to use TLS. To understand whether these changes\nindeed lead to secure Industrial Internet of Things deployments, i.e., using\nTLS-based protocols, which are configured according to security best practices,\nwe perform an Internet-wide security assessment of ten industrial protocols\ncovering the complete IPv4 address space.\nOur results show that both, retrofitted existing protocols and newly\ndeveloped secure alternatives, are barely noticeable in the wild. While we find\nthat new protocols have a higher TLS adoption rate than traditional protocols\n(7.2% vs. 0.4%), the overall adoption of TLS is comparably low (6.5% of hosts).\nThus, most industrial deployments (934,736 hosts) are insecurely connected to\nthe Internet. Furthermore, we identify that 42% of hosts with TLS support\n(26,665 hosts) show security deficits, e.g., missing access control. Finally,\nwe show that support in configuring systems securely, e.g., via configuration\ntemplates, is promising to strengthen security.",
    "descriptor": "\nComments: 15 pages, 6 figures\n",
    "authors": [
      "Markus Dahlmanns",
      "Johannes Lohm\u00f6ller",
      "Jan Pennekamp",
      "J\u00f6rn Bodenhausen",
      "Klaus Wehrle",
      "Martin Henze"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.00322"
  },
  {
    "id": "arXiv:2206.00325",
    "title": "LDoS attack detection method based on traffic time-frequency  characteristics",
    "abstract": "For the traditional denial-of-service attack detection methods have complex\nalgorithms and high computational overhead, which are difficult to meet the\ndemand of online detection; and the experimental environment is mostly a\nsimulation platform, which is difficult to deploy in real network environment,\nwe propose a real network environment-oriented LDoS attack detection method\nbased on the time-frequency characteristics of traffic data. All the traffic\ndata flowing through the Web server is obtained through the acquisition storage\nsystem, and the detection data set is constructed using pre-processing; the\nsimple features of the flow fragments are used as input, and the deep neural\nnetwork is used to learn the time-frequency domain features of normal traffic\nfeatures and generate reconstructed sequences, and the LDoS attack is\ndiscriminated based on the differences between the reconstructed sequences and\nthe input data in the time-frequency domain. The experimental results show that\nthe proposed method can accurately detect the attack features in the flow\nfragments in a very short time and achieve high detection accuracy for complex\nand diverse LDoS attacks; since only the statistical features of the packets\nare used, there is no need to parse the packet data, which can be adapted to\ndifferent network environments.",
    "descriptor": "",
    "authors": [
      "Yu Fu",
      "Xueyuan Duan",
      "Kun Wang",
      "Bin Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.00325"
  },
  {
    "id": "arXiv:2206.00330",
    "title": "On Layer Normalizations and Residual Connections in Transformers",
    "abstract": "In the perspective of a layer normalization (LN) position, the architecture\nof Transformers can be categorized into two types: Post-LN and Pre-LN. Recent\nTransformers prefer to select Pre-LN because the training in Post-LN with deep\nTransformers, e.g., ten or more layers, often becomes unstable, resulting in\nuseless models. However, in contrast, Post-LN has also consistently achieved\nbetter performance than Pre-LN in relatively shallow Transformers, e.g., six or\nfewer layers. This study first investigates the reason for these discrepant\nobservations empirically and theoretically and discovers 1, the LN in Post-LN\nis the source of the vanishing gradient problem that mainly leads the unstable\ntraining whereas Pre-LN prevents it, and 2, Post-LN tends to preserve larger\ngradient norms in higher layers during the back-propagation that may lead an\neffective training. Exploiting the new findings, we propose a method that can\nequip both higher stability and effective training by a simple modification\nfrom Post-LN. We conduct experiments on a wide range of text generation tasks\nand demonstrate that our method outperforms Pre-LN, and stable training\nregardless of the shallow or deep layer settings.",
    "descriptor": "",
    "authors": [
      "Sho Takase",
      "Shun Kiyono",
      "Sosuke Kobayashi",
      "Jun Suzuki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.00330"
  },
  {
    "id": "arXiv:2206.00334",
    "title": "On the Hardness of Dominant Strategy Mechanism Design",
    "abstract": "We study the communication complexity of dominant strategy implementations of\ncombinatorial auctions. We start with two domains that are generally considered\n\"easy\": multi-unit auctions with decreasing marginal values and combinatorial\nauctions with gross substitutes valuations. For both domains we have fast\nalgorithms that find the welfare-maximizing allocation with communication\ncomplexity that is poly-logarithmic in the input size. This immediately implies\nthat welfare maximization can be achieved in ex-post equilibrium with no\nsignificant communication cost, by using VCG payments. In contrast, we show\nthat in both domains the communication complexity of any dominant strategy\nimplementation that achieves the optimal welfare is polynomial in the input\nsize.\nWe then move on to studying the approximation ratios achievable by dominant\nstrategy mechanisms. For multi-unit auctions with decreasing marginal values,\nwe provide a dominant-strategy communication FPTAS. For combinatorial auctions\nwith general valuations, we show that there is no dominant strategy mechanism\nthat achieves an approximation ratio better than $m^{1-\\epsilon}$ that uses\n$poly(m,n)$ bits of communication, where $m$ is the number of items and $n$ is\nthe number of bidders. In contrast, a \\emph{randomized} dominant strategy\nmechanism that achieves an $O(\\sqrt m)$ approximation with $poly(m,n)$\ncommunication is known. This proves the first gap between computationally\nefficient deterministic dominant strategy mechanisms and randomized ones.\nEn route, we answer an open question on the communication cost of\nimplementing dominant strategy mechanisms for more than two players, and also\nsolve some open problems in the area of simultaneous combinatorial auctions.",
    "descriptor": "",
    "authors": [
      "Shahar Dobzinski",
      "Shiri Ron",
      "Jan Vondr\u00e1k"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2206.00334"
  },
  {
    "id": "arXiv:2206.00335",
    "title": "Putting AI Ethics into Practice: The Hourglass Model of Organizational  AI Governance",
    "abstract": "The organizational use of artificial intelligence (AI) has rapidly spread\nacross various sectors. Alongside the awareness of the benefits brought by AI,\nthere is a growing consensus on the necessity of tackling the risks and\npotential harms, such as bias and discrimination, brought about by advanced AI\ntechnologies. A multitude of AI ethics principles have been proposed to tackle\nthese risks, but the outlines of organizational processes and practices for\nensuring socially responsible AI development are in a nascent state. To address\nthe paucity of comprehensive governance models, we present an AI governance\nframework, the hourglass model of organizational AI governance, which targets\norganizations that develop and use AI systems. The framework is designed to\nhelp organizations deploying AI systems translate ethical AI principles into\npractice and align their AI systems and processes with the forthcoming European\nAI Act. The hourglass framework includes governance requirements at the\nenvironmental, organizational, and AI system levels. At the AI system level, we\nconnect governance requirements to AI system life cycles to ensure governance\nthroughout the system's life span. The governance model highlights the systemic\nnature of AI governance and opens new research avenues into its practical\nimplementation, the mechanisms that connect different AI governance layers, and\nthe dynamics between the AI governance actors. The model also offers a starting\npoint for organizational decision-makers to consider the governance components\nneeded to ensure social acceptability, mitigate risks, and realize the\npotential of AI.",
    "descriptor": "\nComments: 20 pages, 4 figures\n",
    "authors": [
      "Matti M\u00e4ntym\u00e4ki",
      "Matti Minkkinen",
      "Teemu Birkstedt",
      "Mika Viljanen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.00335"
  },
  {
    "id": "arXiv:2206.00337",
    "title": "Insertion of real agents behaviors in CARLA autonomous driving simulator",
    "abstract": "The role of simulation in autonomous driving is becoming increasingly\nimportant due to the need for rapid prototyping and extensive testing. The use\nof physics-based simulation involves multiple benefits and advantages at a\nreasonable cost while eliminating risks to prototypes, drivers and vulnerable\nroad users. However, there are two main limitations. First, the well-known\nreality gap which refers to the discrepancy between reality and simulation that\nprevents simulated autonomous driving experience from enabling effective\nreal-world performance. Second, the lack of empirical knowledge about the\nbehavior of real agents, including backup drivers or passengers and other road\nusers such as vehicles, pedestrians or cyclists. Agent simulation is usually\npre-programmed deterministically, randomized probabilistically or generated\nbased on real data, but it does not represent behaviors from real agents\ninteracting with the specific simulated scenario. In this paper we present a\npreliminary framework to enable real-time interaction between real agents and\nthe simulated environment (including autonomous vehicles) and generate\nsynthetic sequences from simulated sensor data from multiple views that can be\nused for training predictive systems that rely on behavioral models. Our\napproach integrates immersive virtual reality and human motion capture systems\nwith the CARLA simulator for autonomous driving. We describe the proposed\nhardware and software architecture, and discuss about the so-called behavioural\ngap or presence. We present preliminary, but promising, results that support\nthe potential of this methodology and discuss about future steps.",
    "descriptor": "\nComments: Submitted to the International Conference on Computer-Human Interaction Research and Applications (CHIRA) 2022\n",
    "authors": [
      "Sergio Mart\u00edn Serrano",
      "David Fern\u00e1ndez Llorca",
      "Iv\u00e1n Garc\u00eda Daza",
      "Miguel \u00c1ngel Sotelo"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.00337"
  },
  {
    "id": "arXiv:2206.00339",
    "title": "Adaptive time integration of mechanical forces in center-based models  for biological cell populationas",
    "abstract": "Center-based models are used to simulate the mechanical behavior of\nbiological cells during embryonic development or cancer growth. To allow for\nthe simulation of biological populations potentially growing from a few\nindividual cells to many thousands or more, these models have to be numerically\nefficient, while being reasonably accurate on the level of individual cell\ntrajectories. In this work, we increase the robustness, accuracy, and\nefficiency of the simulation of center-based models by choosing the time steps\nadaptively in the numerical method. We investigate the gain in using single\nrate time stepping for the forward and backward Euler methods, based on local\nestimates of the numerical errors and the stability of the method in the case\nof the explicit forward Euler method. Furthermore, we propose a multirate time\nstepping scheme that simulates regions with high local force gradients (e.g. as\nthey happen after cell division) with multiple smaller time steps within a\nlarger single time step for regions with smoother forces. These methods are\ncompared for different model systems in numerical experiments. We conclude that\nthe adaptive single rate forward Euler method results in significant gains in\nterms of reduced wall clock times for the simulation of a linearly growing\ntissue, while at the same time eliminating the need for manual determination of\na suitable time step size.",
    "descriptor": "",
    "authors": [
      "Per L\u00f6tstedt",
      "Sonja Mathias"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Tissues and Organs (q-bio.TO)"
    ],
    "url": "https://arxiv.org/abs/2206.00339"
  },
  {
    "id": "arXiv:2206.00340",
    "title": "On the latency of multi-level polar coded modulations",
    "abstract": "A commonly assumed drawback of multi-level coding, compared to a\nbit-interleaved coded modulation, is its high latency: Indeed, the levels must\nbe decoded sequentially. In this paper, we consider polar codes to code each\nlevel. We show that the decoding time complexity of the multi-level scheme,\nusing successive-cancellation list decoding for each polar code, is only 1.5\ntimes the one of a single polar code, regardless of the signal-to-noise ratio\nand the number of levels.",
    "descriptor": "\nComments: Accepted to the GRETSI\n",
    "authors": [
      "Vincent Corlay"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.00340"
  },
  {
    "id": "arXiv:2206.00342",
    "title": "Control of Two-way Coupled Fluid Systems with Differentiable Solvers",
    "abstract": "We investigate the use of deep neural networks to control complex nonlinear\ndynamical systems, specifically the movement of a rigid body immersed in a\nfluid. We solve the Navier Stokes equations with two way coupling, which gives\nrise to nonlinear perturbations that make the control task very challenging.\nNeural networks are trained in an unsupervised way to act as controllers with\ndesired characteristics through a process of learning from a differentiable\nsimulator. Here we introduce a set of physically interpretable loss terms to\nlet the networks learn robust and stable interactions. We demonstrate that\ncontrollers trained in a canonical setting with quiescent initial conditions\nreliably generalize to varied and challenging environments such as previously\nunseen inflow conditions and forcing, although they do not have any fluid\ninformation as input. Further, we show that controllers trained with our\napproach outperform a variety of classical and learned alternatives in terms of\nevaluation metrics and generalization capabilities.",
    "descriptor": "\nComments: 24 pages, 18 figures\n",
    "authors": [
      "Brener Ramos",
      "Felix Trost",
      "Nils Thuerey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00342"
  },
  {
    "id": "arXiv:2206.00343",
    "title": "Towards view-invariant vehicle speed detection from driving simulator  images",
    "abstract": "The use of cameras for vehicle speed measurement is much more cost effective\ncompared to other technologies such as inductive loops, radar or laser.\nHowever, accurate speed measurement remains a challenge due to the inherent\nlimitations of cameras to provide accurate range estimates. In addition,\nclassical vision-based methods are very sensitive to extrinsic calibration\nbetween the camera and the road. In this context, the use of data-driven\napproaches appears as an interesting alternative. However, data collection\nrequires a complex and costly setup to record videos under real traffic\nconditions from the camera synchronized with a high-precision speed sensor to\ngenerate the ground truth speed values. It has recently been demonstrated that\nthe use of driving simulators (e.g., CARLA) can serve as a robust alternative\nfor generating large synthetic datasets to enable the application of deep\nlearning techniques for vehicle speed estimation for a single camera. In this\npaper, we study the same problem using multiple cameras in different virtual\nlocations and with different extrinsic parameters. We address the question of\nwhether complex 3D-CNN architectures are capable of implicitly learning\nview-invariant speeds using a single model, or whether view-specific models are\nmore appropriate. The results are very promising as they show that a single\nmodel with data from multiple views reports even better accuracy than\ncamera-specific models, paving the way towards a view-invariant vehicle speed\nmeasurement system.",
    "descriptor": "\nComments: Submitted to the 14th International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management (IC3K 2022)\n",
    "authors": [
      "Antonio Hern\u00e1ndez Mart\u00ednez",
      "David Fernandez Llorca",
      "Iv\u00e1n Garc\u00eda Daza"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.00343"
  },
  {
    "id": "arXiv:2206.00344",
    "title": "Self-Supervised Learning as a Means To Reduce the Need for Labeled Data  in Medical Image Analysis",
    "abstract": "One of the largest problems in medical image processing is the lack of\nannotated data. Labeling medical images often requires highly trained experts\nand can be a time-consuming process. In this paper, we evaluate a method of\nreducing the need for labeled data in medical image object detection by using\nself-supervised neural network pretraining. We use a dataset of chest X-ray\nimages with bounding box labels for 13 different classes of anomalies. The\nnetworks are pretrained on a percentage of the dataset without labels and then\nfine-tuned on the rest of the dataset. We show that it is possible to achieve\nsimilar performance to a fully supervised model in terms of mean average\nprecision and accuracy with only 60\\% of the labeled data. We also show that it\nis possible to increase the maximum performance of a fully-supervised model by\nadding a self-supervised pretraining step, and this effect can be observed with\neven a small amount of unlabeled data for pretraining.",
    "descriptor": "\nComments: Accepted by 30th European Signal Processing Conference, EUSIPCO 2022\n",
    "authors": [
      "Marin Ben\u010devi\u0107",
      "Marija Habijan",
      "Irena Gali\u0107",
      "Aleksandra Pizurica"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.00344"
  },
  {
    "id": "arXiv:2206.00349",
    "title": "Games for Hybrid Logic -- From Semantic Games to Analytic Calculi",
    "abstract": "Game semantics and winning strategies offer a potential conceptual bridge\nbetween semantics and proof systems of logics. We illustrate this link for\nhybrid logic -- an extension of modal logic that allows for explicit reference\nto worlds within the language. The main result is that the systematic search of\nwinning strategies over all models can be finitized and thus reformulated as a\nproof system.",
    "descriptor": "\nComments: 17 pages, 2 figures, WoLLIC\n",
    "authors": [
      "Robert Freiman"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.00349"
  },
  {
    "id": "arXiv:2206.00352",
    "title": "Support Vector Machines under Adversarial Label Contamination",
    "abstract": "Machine learning algorithms are increasingly being applied in\nsecurity-related tasks such as spam and malware detection, although their\nsecurity properties against deliberate attacks have not yet been widely\nunderstood. Intelligent and adaptive attackers may indeed exploit specific\nvulnerabilities exposed by machine learning techniques to violate system\nsecurity. Being robust to adversarial data manipulation is thus an important,\nadditional requirement for machine learning algorithms to successfully operate\nin adversarial settings. In this work, we evaluate the security of Support\nVector Machines (SVMs) to well-crafted, adversarial label noise attacks. In\nparticular, we consider an attacker that aims to maximize the SVM's\nclassification error by flipping a number of labels in the training data. We\nformalize a corresponding optimal attack strategy, and solve it by means of\nheuristic approaches to keep the computational complexity tractable. We report\nan extensive experimental analysis on the effectiveness of the considered\nattacks against linear and non-linear SVMs, both on synthetic and real-world\ndatasets. We finally argue that our approach can also provide useful insights\nfor developing more secure SVM learning algorithms, and also novel techniques\nin a number of related research areas, such as semi-supervised and active\nlearning.",
    "descriptor": "",
    "authors": [
      "Huang Xiao",
      "Battista Biggio",
      "Blaine Nelson",
      "Han Xiao",
      "Claudia Eckert",
      "Fabio Roli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00352"
  },
  {
    "id": "arXiv:2206.00354",
    "title": "Synthesizing Safety Controllers for Uncertain Linear Systems: A Direct  Data-driven Approach",
    "abstract": "In this paper, we provide a direct data-driven approach to synthesize safety\ncontrollers for unknown linear systems affected by unknown-but-bounded\ndisturbances, in which identifying the unknown model is not required. First, we\npropose a notion of $\\gamma$-robust safety invariant ($\\gamma$-RSI) sets and\ntheir associated state-feedback controllers, which can be applied to enforce\ninvariance properties. Then, we formulate a data-driven computation of these\nsets in terms of convex optimization problems with linear matrix inequalities\n(LMI) as constraints, which can be solved based on a finite number of data\ncollected from a single input-state trajectory of the system. To show the\neffectiveness of the proposed approach, we apply our results to a 4-dimensional\ninverted pendulum.",
    "descriptor": "\nComments: 6th IEEE Conference on Control Technology and Applications\n",
    "authors": [
      "Bingzhuo Zhong",
      "Majid Zamani",
      "Marco Caccamo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.00354"
  },
  {
    "id": "arXiv:2206.00359",
    "title": "DeepCluE: Enhanced Image Clustering via Multi-layer Ensembles in Deep  Neural Networks",
    "abstract": "Deep clustering has recently emerged as a promising technique for complex\nimage clustering. Despite the significant progress, previous deep clustering\nworks mostly tend to construct the final clustering by utilizing a single layer\nof representation, e.g., by performing $K$-means on the last fully-connected\nlayer or by associating some clustering loss to a specific layer. However, few\nof them have considered the possibilities and potential benefits of jointly\nleveraging multi-layer representations for enhancing the deep clustering\nperformance. In light of this, this paper presents a Deep Clustering via\nEnsembles (DeepCluE) approach, which bridges the gap between deep clustering\nand ensemble clustering by harnessing the power of multiple layers in deep\nneural networks. Particularly, we utilize a weight-sharing convolutional neural\nnetwork as the backbone, which is trained with both the instance-level\ncontrastive learning (via an instance projector) and the cluster-level\ncontrastive learning (via a cluster projector) in an unsupervised manner.\nThereafter, multiple layers of feature representations are extracted from the\ntrained network, upon which a set of diversified base clusterings can be\ngenerated via a highly efficient clusterer. Then, the reliability of the\nclusters in multiple base clusterings is automatically estimated by exploiting\nan entropy-based criterion, based on which the multiple base clusterings are\nfurther formulated into a weighted-cluster bipartite graph. By partitioning\nthis bipartite graph via transfer cut, the final image clustering result can\ntherefore be obtained. Experimental results on six image datasets confirm the\nadvantages of our DeepCluE approach over the state-of-the-art deep clustering\napproaches.",
    "descriptor": "",
    "authors": [
      "Dong Huang",
      "Ding-Hua Chen",
      "Xiangji Chen",
      "Chang-Dong Wang",
      "Jian-Huang Lai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00359"
  },
  {
    "id": "arXiv:2206.00362",
    "title": "Augmenting Message Passing by Retrieving Similar Graphs",
    "abstract": "Graph Neural Networks (GNNs) are effective tools for graph representation\nlearning. Most GNNs rely on a recursive neighborhood aggregation scheme, named\nmessage passing. In this paper, motivated by the success of retrieval-based\nmodels, we propose a non-parametric scheme called GraphRetrieval, in which\nsimilar training graphs associated with their ground-truth labels are retrieved\nto be jointly utilized with the input graph representation to complete various\ngraph-based predictive tasks. In particular, we take a well-trained model with\nits parameters fixed and then we add an adapter based on self-attention with\nonly a few trainable parameters per task to explicitly learn the interaction\nbetween an input graph and its retrieved similar graphs. Our experiments on 12\ndifferent datasets involving different tasks (classification and regression)\nshow that GraphRetrieval is able to achieve substantial improvements on all\ntwelve datasets compared to three strong GNN baseline models. Our work\ndemonstrates that GraphRetrieval is a promising augmentation for message\npassing.",
    "descriptor": "",
    "authors": [
      "Dingmin Wang",
      "Shengchao Liu",
      "Hanchen Wang",
      "Linfeng Song",
      "Jian Tang",
      "Song Le",
      "Bernardo Cuenca Grau",
      "Qi Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.00362"
  },
  {
    "id": "arXiv:2206.00363",
    "title": "Bring Your Own Algorithm for Optimal Differentially Private Stochastic  Minimax Optimization",
    "abstract": "We study differentially private (DP) algorithms for smooth stochastic minimax\noptimization, with stochastic minimization as a byproduct. The holy grail of\nthese settings is to guarantee the optimal trade-off between the privacy and\nthe excess population loss, using an algorithm with a linear time-complexity in\nthe number of training samples. We provide a general framework for solving\ndifferentially private stochastic minimax optimization (DP-SMO) problems, which\nenables the practitioners to bring their own base optimization algorithm and\nuse it as a black-box to obtain the near-optimal privacy-loss trade-off. Our\nframework is inspired from the recently proposed Phased-ERM method [20] for\nnonsmooth differentially private stochastic convex optimization (DP-SCO), which\nexploits the stability of the empirical risk minimization (ERM) for the privacy\nguarantee. The flexibility of our approach enables us to sidestep the\nrequirement that the base algorithm needs to have bounded sensitivity, and\nallows the use of sophisticated variance-reduced accelerated methods to achieve\nnear-linear time-complexity. To the best of our knowledge, these are the first\nlinear-time optimal algorithms, up to logarithmic factors, for smooth DP-SMO\nwhen the objective is (strongly-)convex-(strongly-)concave. Additionally, based\non our flexible framework, we derive a new family of near-linear time\nalgorithms for smooth DP-SCO with optimal privacy-loss trade-offs for a wider\nrange of smoothness parameters compared to previous algorithms.",
    "descriptor": "",
    "authors": [
      "Liang Zhang",
      "Kiran Koshy Thekumparampil",
      "Sewoong Oh",
      "Niao He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.00363"
  },
  {
    "id": "arXiv:2206.00364",
    "title": "Elucidating the Design Space of Diffusion-Based Generative Models",
    "abstract": "We argue that the theory and practice of diffusion-based generative models\nare currently unnecessarily convoluted and seek to remedy the situation by\npresenting a design space that clearly separates the concrete design choices.\nThis lets us identify several changes to both the sampling and training\nprocesses, as well as preconditioning of the score networks. Together, our\nimprovements yield new state-of-the-art FID of 1.79 for CIFAR-10 in a\nclass-conditional setting and 1.97 in an unconditional setting, with much\nfaster sampling (35 network evaluations per image) than prior designs. To\nfurther demonstrate their modular nature, we show that our design changes\ndramatically improve both the efficiency and quality obtainable with\npre-trained score networks from previous work, including improving the FID of\nan existing ImageNet-64 model from 2.07 to near-SOTA 1.55.",
    "descriptor": "",
    "authors": [
      "Tero Karras",
      "Miika Aittala",
      "Timo Aila",
      "Samuli Laine"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.00364"
  },
  {
    "id": "arXiv:2206.00365",
    "title": "ORKA: Object reconstruction using a K-approximation graph",
    "abstract": "Data processing has to deal with many practical difficulties. Data is often\ncorrupted by artifacts or noise and acquiring data can be expensive and\ndifficult. Thus, the given data is often incomplete and inaccurate. To overcome\nthese problems, it is often assumed that the data is sparse or low-dimensional\nin some domain. When multiple measurements are taken, this sparsity often\nappears in a structured manner. We propose a new model that assumes the data\nonly contains a few relevant objects, i.e., it is sparse in some object domain.\nWe model an object as a structure that can only change slightly in form and\ncontinuously in position over different measurements. This can be modeled by a\nmatrix with highly correlated columns and a column shift operator that we\nintroduce in this work. We present an efficient algorithm to solve the object\nreconstruction problem based on a K-approximation graph. We prove optimal\napproximation bounds and perform a numerical evaluation of the method. Examples\nfrom applications including Geophysics, video processing, and others will be\ngiven.",
    "descriptor": "",
    "authors": [
      "Florian Bossmann",
      "Jianwei Ma"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.00365"
  },
  {
    "id": "arXiv:2206.00369",
    "title": "Optical character recognition quality affects perceived usefulness of  historical newspaper clippings",
    "abstract": "Introduction. We study effect of different quality optical character\nrecognition in interactive information retrieval with a collection of one\ndigitized historical Finnish newspaper. Method. This study is based on the\nsimulated interactive information retrieval work task model. Thirty-two users\nmade searches to an article collection of Finnish newspaper Uusi Suometar\n1869-1918 with ca. 1.45 million auto segmented articles. Our article search\ndatabase had two versions of each article with different quality optical\ncharacter recognition. Each user performed six pre-formulated and six\nself-formulated short queries and evaluated subjectively the top-10 results\nusing graded relevance scale of 0-3 without knowing about the optical character\nrecognition quality differences of the otherwise identical articles. Analysis.\nAnalysis of the user evaluations was performed by comparing mean averages of\nevaluations scores in user sessions. Differences of query results were detected\nby analysing lengths of returned articles in pre-formulated and self-formulated\nqueries and number of different documents retrieved overall in these two\nsessions. Results. The main result of the study is that improved optical\ncharacter recognition quality affects perceived usefulness of historical\nnewspaper articles positively. Conclusions. We were able to show that\nimprovement in optical character recognition quality of documents leads to\nhigher mean relevance evaluation scores of query results in our historical\nnewspaper collection. To the best of our knowledge this simulated interactive\nuser-task is the first one showing empirically that users' subjective relevance\nassessments are affected by a change in the quality of optically read text.",
    "descriptor": "\nComments: 21 pages, 6 figures, 2 tables, 1 appendix. arXiv admin note: substantial text overlap with arXiv:2203.03557\n",
    "authors": [
      "Kimmo Kettunen",
      "Heikki Keskustalo",
      "Sanna Kumpulainen",
      "Tuula P\u00e4\u00e4kk\u00f6nen",
      "Juha Rautiainen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.00369"
  },
  {
    "id": "arXiv:2206.00371",
    "title": "Dynamic Complexity of Group Problems",
    "abstract": "Dynamic Complexity was introduced by Immerman and Patnaik PI97 in the\nnineties and has seen a resurgence of interest with the positive resolution of\ntheir conjecture on directed reachability in DynFO DKMSZ18. Since then many\nnatural problems related to reachability and matching have been placed in DynFO\nand related classes DMVZ18,DKMTVZ20,DTV21. In this work, we place some dynamic\nproblems from group theory in DynFO.\nIn particular, suppose we are given an arbitrary multiplication table over n\nelements representing an unstructured binary operation (representing a\nstructure called a magma). Suppose the table evolves through a change in one of\nits n^2 entries in one step. For a set S of magma elements which also changes\none element at a time, we can maintain enough auxiliary information so that\nwhen the magma is a group, we are able to answer the Cayley Group Membership\n(CGM) problem for S and a target t (i.e. \"Is t a product of elements from S? \")\nusing an FO query at every step. This places the dynamic CGM problem (for\ngroups) when the ambient magma is specified via a table in DynFO. In contrast,\nfor the table setting, statically CGM was known to be in the class Logspace\nBarringtonM06. Building on the dynamic CGM result, we can maintain the\nisomorphism of of two magmas, whenever both are Abelian groups, in DynFO.\nOur techniques include a way to maintain the powers of the elements of a\nmagma in DynFO using left associative parenthesisation, the notion of cube\nindependence to cube generate a subgroup generated by a set, a way to maintain\nmaximal cube independent sequences in a magma along with some group theoretic\nmachinery available from McKenzieCook. The notion of cube independent sequences\nis new as far as we know and may be of independent interest. These techniques\nare very different from the ones employed in Dynamic Complexity so far.",
    "descriptor": "\nComments: Submitted\n",
    "authors": [
      "Samir Datta",
      "Asif Khan",
      "Shivdutt Sharma",
      "Yadu Vasudev",
      "Shankar Ram Vasudevan"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2206.00371"
  },
  {
    "id": "arXiv:2206.00372",
    "title": "BD-SHS: A Benchmark Dataset for Learning to Detect Online Bangla Hate  Speech in Different Social Contexts",
    "abstract": "Social media platforms and online streaming services have spawned a new breed\nof Hate Speech (HS). Due to the massive amount of user-generated content on\nthese sites, modern machine learning techniques are found to be feasible and\ncost-effective to tackle this problem. However, linguistically diverse datasets\ncovering different social contexts in which offensive language is typically\nused are required to train generalizable models. In this paper, we identify the\nshortcomings of existing Bangla HS datasets and introduce a large manually\nlabeled dataset BD-SHS that includes HS in different social contexts. The\nlabeling criteria were prepared following a hierarchical annotation process,\nwhich is the first of its kind in Bangla HS to the best of our knowledge. The\ndataset includes more than 50,200 offensive comments crawled from online social\nnetworking sites and is at least 60% larger than any existing Bangla HS\ndatasets. We present the benchmark result of our dataset by training different\nNLP models resulting in the best one achieving an F1-score of 91.0%. In our\nexperiments, we found that a word embedding trained exclusively using 1.47\nmillion comments from social media and streaming sites consistently resulted in\nbetter modeling of HS detection in comparison to other pre-trained embeddings.\nOur dataset and all accompanying codes is publicly available at\ngithub.com/naurosromim/hate-speech-dataset-for-Bengali-social-media",
    "descriptor": "",
    "authors": [
      "Nauros Romim",
      "Mosahed Ahmed",
      "Md. Saiful Islam",
      "Arnab Sen Sharma",
      "Hriteshwar Talukder",
      "Mohammad Ruhul Amin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.00372"
  },
  {
    "id": "arXiv:2206.00373",
    "title": "A Flexible and Robust Vision Trap for Automated Part Feeder Design",
    "abstract": "Fast, robust, and flexible part feeding is essential for enabling automation\nof low volume, high variance assembly tasks. An actuated vision-based solution\non a traditional vibratory feeder, referred to here as a vision trap, should in\nprinciple be able to meet these demands for a wide range of parts. However, in\npractice, the flexibility of such a trap is limited as an expert is needed to\nboth identify manageable tasks and to configure the vision system. We propose a\nnovel approach to vision trap design in which the identification of manageable\ntasks is automatic and the configuration of these tasks can be delegated to an\nautomated feeder design system. We show that the trap's capabilities can be\nformalized in such a way that it integrates seamlessly into the ecosystem of\nautomated feeder design. Our results on six canonical parts show great promise\nfor autonomous configuration of feeder systems.",
    "descriptor": "",
    "authors": [
      "Rasmus Laurvig Haugaard",
      "Thorbj\u00f8rn Mosekj\u00e6r Iversen",
      "Anders Glent Buch",
      "Aljaz Kramberger",
      "Simon Faarvang Mathiesen"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.00373"
  },
  {
    "id": "arXiv:2206.00375",
    "title": "Detecting Cybercriminal Bitcoin Relationships through Backwards  Exploration",
    "abstract": "Cybercriminals often leverage Bitcoin for their illicit activities. In this\nwork, we propose back-and-forth exploration, a novel automated Bitcoin\ntransaction tracing technique to identify cybercrime financial relationships.\nGiven seed addresses belonging to a cybercrime campaign, it outputs a\ntransaction graph, and identifies paths corresponding to relationships between\nthe campaign under study and external services and other cybercrime campaigns.\nBack-and-forth exploration provides two key contributions. First, it explores\nboth forward and backwards, instead of only forward as done by prior work,\nenabling the discovery of relationships that cannot be found by only exploring\nforward (e.g., deposits from clients of a mixer). Second, it prevents graph\nexplosion by combining a tagging database with a machine learning classifier\nfor identifying addresses belonging to exchanges. We evaluate back-and-forth\nexploration on 30 malware families. We build oracles for 4 families using\nBitcoin for C&C and use them to demonstrate that back-and-forth exploration\nidentifies 13 C&C signaling addresses missed by prior work, 8 of which are\nfundamentally missed by forward-only explorations. Our approach uncovers a\nwealth of services used by the malware including 44 exchanges, 11 gambling\nsites, 5 payment service providers, 4 underground markets, 4 mining pools, and\n2 mixers. In 4 families, the relations include new attribution points missed by\nforward-only explorations. It also identifies relationships between the malware\nfamilies and other cybercrime campaigns, highlighting how some malware\noperators participate in a variety of cybercriminal activities.",
    "descriptor": "",
    "authors": [
      "Gibran Gomez",
      "Pedro Moreno-Sanchez",
      "Juan Caballero"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.00375"
  },
  {
    "id": "arXiv:2206.00376",
    "title": "String Attractors and Infinite Words",
    "abstract": "The notion of string attractor has been introduced in [Kempa and Prezza,\n2018] in the context of Data Compression and it represents a set of positions\nof a finite word in which all of its factors can be \"attracted\". The smallest\nsize $\\gamma^*$ of a string attractor for a finite word is a lower bound for\nseveral repetitiveness measures associated with the most common compression\nschemes, including BWT-based and LZ-based compressors. The combinatorial\nproperties of the measure $\\gamma^*$ have been studied in [Mantaci et al.,\n2021]. Very recently, a complexity measure, called string attractor profile\nfunction, has been introduced for infinite words, by evaluating $\\gamma^*$ on\neach prefix. Such a measure has been studied for automatic sequences and\nlinearly recurrent infinite words [Schaeffer and Shallit, 2021]. In this paper,\nwe study the relationship between such a complexity measure and other\nwell-known combinatorial notions related to repetitiveness in the context of\ninfinite words, such as the factor complexity and the recurrence. Furthermore,\nwe introduce new string attractor-based complexity measures, in which the\nstructure and the distribution of positions in a string attractor of the\nprefixes of infinite words are considered. We show that such measures provide a\nfiner classification of some infinite families of words.",
    "descriptor": "",
    "authors": [
      "Antonio Restivo",
      "Giuseppe Romana",
      "Marinella Sciortino"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.00376"
  },
  {
    "id": "arXiv:2206.00377",
    "title": "NOMA for Integrating Sensing and Communications towards 6G: A Multiple  Access Perspective",
    "abstract": "This article focuses on the development of integrated sensing and\ncommunications (ISAC) from a multiple access (MA) perspective, where the idea\nof non-orthogonal multiple access (NOMA) is exploited for harmoniously\naccommodating the sensing and communication functionalities. We first reveal\nthat the developing trend of ISAC is from \\emph{orthogonality} to\n\\emph{non-orthogonality}, and introduce the fundamental models of the downlink\nand uplink ISAC while identifying the design challenges from the MA\nperspective. (1) For the downlink ISAC, we propose two novel designs, namely\n\\emph{NOMA-empowered} downlink ISAC and \\emph{NOMA-inspired} downlink ISAC to\neffectively coordinate the inter-user interference and the\nsensing-to-communication interference, respectively. (2) For the uplink ISAC,\nwe first propose a \\emph{pure-NOMA-based} uplink ISAC design, where a fixed\ncommunication-to-sensing successive interference cancellation order is employed\nfor distinguishing the mixed sensing-communication signal received over the\nfully shared radio resources. Then, we propose a general \\emph{semi-NOMA-based}\nuplink ISAC design, which includes the conventional orthogonal multiple\naccess-based and pure-NOMA-based uplink ISAC as special cases, thus being\ncapable of providing flexible resource allocation strategies between sensing\nand communication. Along each proposed NOMA-ISAC design, numerical results are\nprovided for showing the superiority over conventional ISAC designs.",
    "descriptor": "\nComments: 7 pages, 5 figures\n",
    "authors": [
      "Xidong Mu",
      "Zhaolin Wang",
      "Yuanwei Liu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.00377"
  },
  {
    "id": "arXiv:2206.00378",
    "title": "Smartphone-based crowdsourcing for estimating the bottleneck capacity in  wireless networks",
    "abstract": "Crowdsourcing enables the fine-grained characterization and performance\nevaluation of today's large-scale networks using the power of the masses and\ndistributed intelligence. This paper presents SmartProbe, a system that\nassesses the bottleneck capacity of Internet paths using smartphones, from a\nmobile crowdsourcing perspective. With SmartProbe measurement activities are\nmore bandwidth efficient compared to similar systems, and a larger number of\nusers can be supported. An application based on SmartProbe is also presented:\ngeoreferenced measurements are mapped and used to compare the performance of\nmobile broadband operators in wide areas. Results from one year of operation\nare included.",
    "descriptor": "",
    "authors": [
      "Enrico Gregori",
      "Alessandro Improta",
      "Luciano Lenzini",
      "Valerio Luconi",
      "Nilo Redini",
      "Alessio Vecchio"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.00378"
  },
  {
    "id": "arXiv:2206.00379",
    "title": "YOLoC: DeploY Large-Scale Neural Network by ROM-based  Computing-in-Memory using ResiduaL Branch on a Chip",
    "abstract": "Computing-in-memory (CiM) is a promising technique to achieve high energy\nefficiency in data-intensive matrix-vector multiplication (MVM) by relieving\nthe memory bottleneck. Unfortunately, due to the limited SRAM capacity,\nexisting SRAM-based CiM needs to reload the weights from DRAM in large-scale\nnetworks. This undesired fact weakens the energy efficiency significantly. This\nwork, for the first time, proposes the concept, design, and optimization of\ncomputing-in-ROM to achieve much higher on-chip memory capacity, and thus less\nDRAM access and lower energy consumption. Furthermore, to support different\ncomputing scenarios with varying weights, a weight fine-tune technique, namely\nResidual Branch (ReBranch), is also proposed. ReBranch combines ROM-CiM and\nassisting SRAM-CiM to ahieve high versatility. YOLoC, a ReBranch-assisted\nROM-CiM framework for object detection is presented and evaluated. With the\nsame area in 28nm CMOS, YOLoC for several datasets has shown significant energy\nefficiency improvement by 14.8x for YOLO (Darknet-19) and 4.8x for ResNet-18,\nwith <8% latency overhead and almost no mean average precision (mAP) loss\n(-0.5% ~ +0.2%), compared with the fully SRAM-based CiM.",
    "descriptor": "\nComments: 6 pages, 14 figures. to be published in DAC 2022\n",
    "authors": [
      "Yiming Chen",
      "Guodong Yin",
      "Zhanhong Tan",
      "Mingyen Lee",
      "Zekun Yang",
      "Yongpan Liu",
      "Huazhong Yang",
      "Kaisheng Ma",
      "Xueqing Li"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2206.00379"
  },
  {
    "id": "arXiv:2206.00380",
    "title": "Strongly Augmented Contrastive Clustering",
    "abstract": "Deep clustering has attracted increasing attention in recent years due to its\ncapability of joint representation learning and clustering via deep neural\nnetworks. In its latest developments, the contrastive learning has emerged as\nan effective technique to substantially enhance the deep clustering\nperformance. However, the existing contrastive learning based deep clustering\nalgorithms mostly focus on some carefully-designed augmentations (often with\nlimited transformations to preserve the structure), referred to as weak\naugmentations, but cannot go beyond the weak augmentations to explore the more\nopportunities in stronger augmentations (with more aggressive transformations\nor even severe distortions). In this paper, we present an end-to-end deep\nclustering approach termed strongly augmented contrastive clustering (SACC),\nwhich extends the conventional two-augmentation-view paradigm to multiple views\nand jointly leverages strong and weak augmentations for strengthened deep\nclustering. Particularly, we utilize a backbone network with triply-shared\nweights, where a strongly augmented view and two weakly augmented views are\nincorporated. Based on the representations produced by the backbone, the\nweak-weak view pair and the strong-weak view pairs are simultaneously exploited\nfor the instance-level contrastive learning (via an instance projector) and the\ncluster-level contrastive learning (via a cluster projector), which, together\nwith the backbone, can be jointly optimized in a purely unsupervised manner.\nExperimental results on five challenging image datasets have shown the superior\nperformance of the proposed SACC approach over the state-of-the-art.",
    "descriptor": "",
    "authors": [
      "Xiaozhi Deng",
      "Dong Huang",
      "Ding-Hua Chen",
      "Chang-Dong Wang",
      "Jian-Huang Lai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.00380"
  },
  {
    "id": "arXiv:2206.00383",
    "title": "Neural Improvement Heuristics for Preference Ranking",
    "abstract": "In recent years, Deep Learning based methods have been a revolution in the\nfield of combinatorial optimization. They learn to approximate solutions and\nconstitute an interesting choice when dealing with repetitive problems drawn\nfrom similar distributions. Most effort has been devoted to investigating\nneural constructive methods, while the works that propose neural models to\niteratively improve a candidate solution are less frequent. In this paper, we\npresent a Neural Improvement (NI) model for graph-based combinatorial problems\nthat, given an instance and a candidate solution, encodes the problem\ninformation by means of edge features. Our model proposes a modification on the\npairwise precedence of items to increase the quality of the solution. We\ndemonstrate the practicality of the model by applying it as the building block\nof a Neural Hill Climber and other trajectory-based methods. The algorithms are\nused to solve the Preference Ranking Problem and results show that they\noutperform conventional alternatives in simulated and real-world data.\nConducted experiments also reveal that the proposed model can be a milestone in\nthe development of efficiently guided trajectory-based optimization algorithms.",
    "descriptor": "",
    "authors": [
      "Andoni I. Garmendia",
      "Josu Ceberio",
      "Alexander Mendiburu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00383"
  },
  {
    "id": "arXiv:2206.00384",
    "title": "A Generalized Supervised Contrastive Learning Framework",
    "abstract": "Based on recent remarkable achievements of contrastive learning in\nself-supervised representation learning, supervised contrastive learning\n(SupCon) has successfully extended the batch contrastive approaches to the\nsupervised context and outperformed cross-entropy on various datasets on\nResNet. In this work, we present GenSCL: a generalized supervised contrastive\nlearning framework that seamlessly adapts modern image-based regularizations\n(such as Mixup-Cutmix) and knowledge distillation (KD) to SupCon by our\ngeneralized supervised contrastive loss. Generalized supervised contrastive\nloss is a further extension of supervised contrastive loss measuring\ncross-entropy between the similarity of labels and that of latent features.\nThen a model can learn to what extent contrastives should be pulled closer to\nan anchor in the latent space. By explicitly and fully leveraging label\ninformation, GenSCL breaks the boundary between conventional positives and\nnegatives, and any kind of pre-trained teacher classifier can be utilized.\nResNet-50 trained in GenSCL with Mixup-Cutmix and KD achieves state-of-the-art\naccuracies of 97.6% and 84.7% on CIFAR10 and CIFAR100 without external data,\nwhich significantly improves the results reported in the original SupCon (1.6%\nand 8.2%, respectively). Pytorch implementation is available at\nhttps://t.ly/yuUO.",
    "descriptor": "",
    "authors": [
      "Jaewon Kim",
      "Jooyoung Chang",
      "Sang Min Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00384"
  },
  {
    "id": "arXiv:2206.00385",
    "title": "Mining Function Homology of Bot Loaders from Honeypot Logs",
    "abstract": "Self-contained loaders are widely adopted in botnets for injecting loading\ncommands and spawning new bots. While researchers can dissect bot clients to\nget various information of botnets, the cloud-based and self-contained design\nof loaders effectively hinders researchers from understanding the loaders'\nevolution and variation using classic methods. The decoupled nature of bot\nloaders also dramatically reduces the feasibility of investigating\nrelationships among clients and infrastructures. In this paper, we propose a\ntext-based method to investigate and analyze details of bot loaders using\nhoneypots. We leverage high interaction honeypots to collect request logs and\ndefine eight families of bot loaders based on the result of agglomerative\nclustering. At the function level, we push our study further to explore their\nhomological relationship based on similarity analysis of request logs using\nsequence aligning techniques. This further exploration discloses that the\nreleased code of Mirai keeps spawning new generations of botnets both on the\nclient and the server side. This paper uncovers the homology of active botnet\ninfrastructures, providing a new prospect on finding covert relationships among\ncybercrimes. Bot loaders are precisely investigated at the function level to\nyield a new insight for researchers to identify the botnet's infrastructures\nand track their evolution over time.",
    "descriptor": "",
    "authors": [
      "Yuhui Zhu",
      "Zhenxiang Chen",
      "Qiben Yan",
      "Shanshan Wang",
      "Enlong Li",
      "Lizhi Peng",
      "Chuan Zhao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.00385"
  },
  {
    "id": "arXiv:2206.00386",
    "title": "DiVAE: Photorealistic Images Synthesis with Denoising Diffusion Decoder",
    "abstract": "Recently most successful image synthesis models are multi stage process to\ncombine the advantages of different methods, which always includes a VAE-like\nmodel for faithfully reconstructing embedding to image and a prior model to\ngenerate image embedding. At the same time, diffusion models have shown be\ncapacity to generate high-quality synthetic images. Our work proposes a VQ-VAE\narchitecture model with a diffusion decoder (DiVAE) to work as the\nreconstructing component in image synthesis. We explore how to input image\nembedding into diffusion model for excellent performance and find that simple\nmodification on diffusion's UNet can achieve it. Training on ImageNet, Our\nmodel achieves state-of-the-art results and generates more photorealistic\nimages specifically. In addition, we apply the DiVAE with an Auto-regressive\ngenerator on conditional synthesis tasks to perform more human-feeling and\ndetailed samples.",
    "descriptor": "",
    "authors": [
      "Jie Shi",
      "Chenfei Wu",
      "Jian Liang",
      "Xiang Liu",
      "Nan Duan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.00386"
  },
  {
    "id": "arXiv:2206.00388",
    "title": "Transfer without Forgetting",
    "abstract": "This work investigates the entanglement between Continual Learning (CL) and\nTransfer Learning (TL). In particular, we shed light on the widespread\napplication of network pretraining, highlighting that it is itself subject to\ncatastrophic forgetting. Unfortunately, this issue leads to the\nunder-exploitation of knowledge transfer during later tasks. On this ground, we\npropose Transfer without Forgetting (TwF), a hybrid Continual Transfer Learning\napproach building upon a fixed pretrained sibling network, which continuously\npropagates the knowledge inherent in the source domain through a layer-wise\nloss term. Our experiments indicate that TwF steadily outperforms other CL\nmethods across a variety of settings, averaging a 4.81% gain in\nClass-Incremental accuracy over a variety of datasets and different buffer\nsizes.",
    "descriptor": "\nComments: 23 pages, 3 Figures\n",
    "authors": [
      "Matteo Boschini",
      "Lorenzo Bonicelli",
      "Angelo Porrello",
      "Giovanni Bellitto",
      "Matteo Pennisi",
      "Simone Palazzo",
      "Concetto Spampinato",
      "Simone Calderara"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.00388"
  },
  {
    "id": "arXiv:2206.00390",
    "title": "Attention-embedded Quadratic Network (Qttention) for Effective and  Interpretable Bearing Fault Diagnosis",
    "abstract": "Bearing fault diagnosis is of great importance to decrease the damage risk of\nrotating machines and further improve economic profits. Recently, machine\nlearning, represented by deep learning, has made great progress in bearing\nfault diagnosis. However, applying deep learning to such a task still faces two\nmajor problems. On the one hand, deep learning loses its effectiveness when\nbearing data are noisy or big data are unavailable, making deep learning hard\nto implement in industrial fields. On the other hand, a deep network is\nnotoriously a black box. It is difficult to know how a model classifies faulty\nsignals from the normal and the physics principle behind the classification. To\nsolve the effectiveness and interpretability issues, we prototype a\nconvolutional network with recently-invented quadratic neurons. This quadratic\nneuron empowered network can qualify the noisy and small bearing data due to\nthe strong feature representation ability of quadratic neurons. Moreover, we\nindependently derive the attention mechanism from a quadratic neuron, referred\nto as qttention, by factorizing the learned quadratic function in analogue to\nthe attention, making the model with quadratic neurons inherently\ninterpretable. Experiments on the public and our datasets demonstrate that the\nproposed network can facilitate effective and interpretable bearing fault\ndiagnosis.",
    "descriptor": "\nComments: Bearing fault diagnosis, quadratic convolutional network (QCNN), quadratic attention (qttention)\n",
    "authors": [
      "Jing-Xiao Liao",
      "Hang-Cheng Dong",
      "Zhi-Qi Sun",
      "Jinwei Sun",
      "Shiping Zhang",
      "Feng-Lei Fan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.00390"
  },
  {
    "id": "arXiv:2206.00393",
    "title": "Towards Generalisable Audio Representations for Audio-Visual Navigation",
    "abstract": "In audio-visual navigation (AVN), an intelligent agent needs to navigate to a\nconstantly sound-making object in complex 3D environments based on its audio\nand visual perceptions. While existing methods attempt to improve the\nnavigation performance with preciously designed path planning or intricate task\nsettings, none has improved the model generalisation on unheard sounds with\ntask settings unchanged. We thus propose a contrastive learning-based method to\ntackle this challenge by regularising the audio encoder, where the\nsound-agnostic goal-driven latent representations can be learnt from various\naudio signals of different classes. In addition, we consider two data\naugmentation strategies to enrich the training sounds. We demonstrate that our\ndesigns can be easily equipped to existing AVN frameworks to obtain an\nimmediate performance gain (13.4%$\\uparrow$ in SPL on Replica and\n12.2%$\\uparrow$ in SPL on MP3D). Our project is available at\nhttps://AV-GeN.github.io/.",
    "descriptor": "\nComments: CVPR 2022 Embodied AI Workshop\n",
    "authors": [
      "Shunqi Mao",
      "Chaoyi Zhang",
      "Heng Wang",
      "Weidong Cai"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.00393"
  },
  {
    "id": "arXiv:2206.00395",
    "title": "Optimization with access to auxiliary information",
    "abstract": "We investigate the fundamental optimization question of minimizing a target\nfunction $f(x)$ whose gradients are expensive to compute or have limited\navailability, given access to some auxiliary side function $h(x)$ whose\ngradients are cheap or more available. This formulation captures many settings\nof practical relevance such as i) re-using batches in SGD, ii) transfer\nlearning, iii) federated learning, iv) training with compressed models/dropout,\netc. We propose two generic new algorithms which are applicable in all these\nsettings and prove using only an assumption on the Hessian similarity between\nthe target and side information that we can benefit from this framework.",
    "descriptor": "",
    "authors": [
      "El Mahdi Chayti",
      "Sai Praneeth Karimireddy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.00395"
  },
  {
    "id": "arXiv:2206.00402",
    "title": "NeuroUnlock: Unlocking the Architecture of Obfuscated Deep Neural  Networks",
    "abstract": "The advancements of deep neural networks (DNNs) have led to their deployment\nin diverse settings, including safety and security-critical applications. As a\nresult, the characteristics of these models have become sensitive intellectual\nproperties that require protection from malicious users. Extracting the\narchitecture of a DNN through leaky side-channels (e.g., memory access) allows\nadversaries to (i) clone the model, and (ii) craft adversarial attacks. DNN\nobfuscation thwarts side-channel-based architecture stealing (SCAS) attacks by\naltering the run-time traces of a given DNN while preserving its functionality.\nIn this work, we expose the vulnerability of state-of-the-art DNN obfuscation\nmethods to these attacks. We present NeuroUnlock, a novel SCAS attack against\nobfuscated DNNs. Our NeuroUnlock employs a sequence-to-sequence model that\nlearns the obfuscation procedure and automatically reverts it, thereby\nrecovering the original DNN architecture. We demonstrate the effectiveness of\nNeuroUnlock by recovering the architecture of 200 randomly generated and\nobfuscated DNNs running on the Nvidia RTX 2080 TI graphics processing unit\n(GPU). Moreover, NeuroUnlock recovers the architecture of various other\nobfuscated DNNs, such as the VGG-11, VGG-13, ResNet-20, and ResNet-32 networks.\nAfter recovering the architecture, NeuroUnlock automatically builds a\nnear-equivalent DNN with only a 1.4% drop in the testing accuracy. We further\nshow that launching a subsequent adversarial attack on the recovered DNNs\nboosts the success rate of the adversarial attack by 51.7% in average compared\nto launching it on the obfuscated versions. Additionally, we propose a novel\nmethodology for DNN obfuscation, ReDLock, which eradicates the deterministic\nnature of the obfuscation and achieves 2.16X more resilience to the NeuroUnlock\nattack. We release the NeuroUnlock and the ReDLock as open-source frameworks.",
    "descriptor": "\nComments: The definitive Version of Record will be Published in the 2022 International Joint Conference on Neural Networks (IJCNN)\n",
    "authors": [
      "Mahya Morid Ahmadi",
      "Lilas Alrahis",
      "Alessio Colucci",
      "Ozgur Sinanoglu",
      "Muhammad Shafique"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00402"
  },
  {
    "id": "arXiv:2206.00407",
    "title": "Generalized Delayed Feedback Model with Post-Click Information in  Recommender Systems",
    "abstract": "Predicting conversion rate (e.g., the probability that a user will purchase\nan item) is a fundamental problem in machine learning based recommender\nsystems. However, accurate conversion labels are revealed after a long delay,\nwhich harms the timeliness of recommender systems. Previous literature\nconcentrates on utilizing early conversions to mitigate such a delayed feedback\nproblem. In this paper, we show that post-click user behaviors are also\ninformative to conversion rate prediction and can be used to improve\ntimeliness. We propose a generalized delayed feedback model (GDFM) that unifies\nboth post-click behaviors and early conversions as stochastic post-click\ninformation, which could be utilized to train GDFM in a streaming manner\nefficiently. Based on GDFM, we further establish a novel perspective that the\nperformance gap introduced by delayed feedback can be attributed to a temporal\ngap and a sampling gap. Inspired by our analysis, we propose to measure the\nquality of post-click information with a combination of temporal distance and\nsample complexity. The training objective is re-weighted accordingly to\nhighlight informative and timely signals. We validate our analysis on public\ndatasets, and experimental performance confirms the effectiveness of our\nmethod.",
    "descriptor": "",
    "authors": [
      "Jia-Qi Yang",
      "De-Chuan Zhan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.00407"
  },
  {
    "id": "arXiv:2206.00415",
    "title": "Learning Invariant Visual Representations for Compositional Zero-Shot  Learning",
    "abstract": "Compositional Zero-Shot Learning (CZSL) aims to recognize novel compositions\nusing knowledge learned from seen attribute-object compositions in the training\nset. Previous works mainly project an image and a composition into a common\nembedding space to measure their compatibility score. However, both attributes\nand objects share the visual representations learned above, leading the model\nto exploit spurious correlations and bias towards seen pairs. Instead, we\nreconsider CZSL as an out-of-distribution generalization problem. If an object\nis treated as a domain, we can learn object-invariant features to recognize the\nattributes attached to any object reliably. Similarly, attribute-invariant\nfeatures can also be learned when recognizing the objects with attributes as\ndomains. Specifically, we propose an invariant feature learning framework to\nalign different domains at the representation and gradient levels to capture\nthe intrinsic characteristics associated with the tasks. Experiments on two\nCZSL benchmarks demonstrate that the proposed method significantly outperforms\nthe previous state-of-the-art.",
    "descriptor": "",
    "authors": [
      "Tian Zhang",
      "Kongming Liang",
      "Ruoyi Du",
      "Xian Sun",
      "Zhanyu Ma",
      "Jun Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.00415"
  },
  {
    "id": "arXiv:2206.00416",
    "title": "In the Eye of the Beholder: Robust Prediction with Causal User Modeling",
    "abstract": "Accurately predicting the relevance of items to users is crucial to the\nsuccess of many social platforms. Conventional approaches train models on\nlogged historical data; but recommendation systems, media services, and online\nmarketplaces all exhibit a constant influx of new content -- making relevancy a\nmoving target, to which standard predictive models are not robust. In this\npaper, we propose a learning framework for relevance prediction that is robust\nto changes in the data distribution. Our key observation is that robustness can\nbe obtained by accounting for how users causally perceive the environment. We\nmodel users as boundedly-rational decision makers whose causal beliefs are\nencoded by a causal graph, and show how minimal information regarding the graph\ncan be used to contend with distributional changes. Experiments in multiple\nsettings demonstrate the effectiveness of our approach.",
    "descriptor": "",
    "authors": [
      "Amir Feder",
      "Guy Horowitz",
      "Yoav Wald",
      "Roi Reichart",
      "Nir Rosenfeld"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.00416"
  },
  {
    "id": "arXiv:2206.00421",
    "title": "The Use of NLP-Based Text Representation Techniques to Support  Requirement Engineering Tasks: A Systematic Mapping Review",
    "abstract": "Natural Language Processing (NLP) is widely used to support the automation of\ndifferent Requirements Engineering (RE) tasks. Most of the proposed approaches\nstart with various NLP steps that analyze requirements statements, extract\ntheir linguistic information, and convert them to easy-to-process\nrepresentations, such as lists of features or embedding-based vector\nrepresentations. These NLP-based representations are usually used at a later\nstage as inputs for machine learning techniques or rule-based methods. Thus,\nrequirements representations play a major role in determining the accuracy of\ndifferent approaches. In this paper, we conducted a survey in the form of a\nsystematic literature mapping (classification) to find out (1) what are the\nrepresentations used in RE tasks literature, (2) what is the main focus of\nthese works, (3) what are the main research directions in this domain, and (4)\nwhat are the gaps and potential future directions. After compiling an initial\npool of 2,227 papers, and applying a set of inclusion/exclusion criteria, we\nobtained a final pool containing 104 relevant papers. Our survey shows that the\nresearch direction has changed from the use of lexical and syntactic features\nto the use of advanced embedding techniques, especially in the last two years.\nUsing advanced embedding representations has proved its effectiveness in most\nRE tasks (such as requirement analysis, extracting requirements from reviews\nand forums, and semantic-level quality tasks). However, representations that\nare based on lexical and syntactic features are still more appropriate for\nother RE tasks (such as modeling and syntax-level quality tasks) since they\nprovide the required information for the rules and regular expressions used\nwhen handling these tasks. In addition, we identify four gaps in the existing\nliterature, why they matter, and how future research can begin to address them.",
    "descriptor": "",
    "authors": [
      "Riad Sonbol",
      "Ghaida Rebdawi",
      "Nada Ghneim"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.00421"
  },
  {
    "id": "arXiv:2206.00422",
    "title": "Edge Learning for B5G Networks with Distributed Signal Processing:  Semantic Communication, Edge Computing, and Wireless Sensing",
    "abstract": "To process and transfer large amounts of data in emerging wireless services,\nit has become increasingly appealing to exploit distributed data communication\nand learning. Specifically, edge learning (EL) enables local model training on\ngeographically disperse edge nodes and minimizes the need for frequent data\nexchange. However, the current design of separating EL deployment and\ncommunication optimization does not yet reap the promised benefits of\ndistributed signal processing, and sometimes suffers from excessive signalling\noverhead, long processing delay, and unstable learning convergence. In this\npaper, we provide an overview on practical distributed EL techniques and their\ninterplay with advanced communication optimization designs. In particular,\ntypical performance metrics for dual-functional learning and communication\nnetworks are discussed. Also, recent achievements of enabling techniques for\nthe dual-functional design are surveyed with exemplifications from the mutual\nperspectives of \"communications for learning\" and \"learning for\ncommunications.\" The application of EL techniques within a variety of future\ncommunication systems are also envisioned for beyond 5G (B5G) wireless\nnetworks. For the application in goal-oriented semantic communication, we\npresent a first mathematical model of the goal-oriented source entropy as an\noptimization problem. In addition, from the viewpoint of information theory, we\nidentify fundamental open problems of characterizing rate regions for\ncommunication networks supporting distributed learning-and-computing tasks. We\nalso present technical challenges as well as emerging application opportunities\nin this field, with the aim of inspiring future research and promoting\nwidespread developments of EL in B5G.",
    "descriptor": "",
    "authors": [
      "Wei Xu",
      "Zhaohui Yang",
      "Derrick Wing Kwan Ng",
      "Marco Levorato",
      "Yonina C. Eldar",
      "M'erouane Debbah"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.00422"
  },
  {
    "id": "arXiv:2206.00423",
    "title": "Open Environment Machine Learning",
    "abstract": "Conventional machine learning studies generally assume close world scenarios\nwhere important factors of the learning process hold invariant. With the great\nsuccess of machine learning, nowadays, more and more practical tasks,\nparticularly those involving open world scenarios where important factors are\nsubject to change, called open environment machine learning (Open ML) in this\narticle, are present to the community. Evidently it is a grand challenge for\nmachine learning turning from close world to open world. It becomes even more\nchallenging since, in various big data tasks, data are usually accumulated with\ntime, like streams, while it is hard to train the machine learning model after\ncollecting all data as in conventional studies. This article briefly introduces\nsome advances in this line of research, focusing on techniques concerning\nemerging new classes, decremental/incremental features, changing data\ndistributions, varied learning objectives, and discusses some theoretical\nissues.",
    "descriptor": "",
    "authors": [
      "Zhi-Hua Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00423"
  },
  {
    "id": "arXiv:2206.00426",
    "title": "Semantic Probabilistic Layers for Neuro-Symbolic Learning",
    "abstract": "We design a predictive layer for structured-output prediction (SOP) that can\nbe plugged into any neural network guaranteeing its predictions are consistent\nwith a set of predefined symbolic constraints. Our Semantic Probabilistic Layer\n(SPL) can model intricate correlations, and hard constraints, over a structured\noutput space all while being amenable to end-to-end learning via maximum\nlikelihood. SPLs combine exact probabilistic inference with logical reasoning\nin a clean and modular way, learning complex distributions and restricting\ntheir support to solutions of the constraint. As such, they can faithfully, and\nefficiently, model complex SOP tasks beyond the reach of alternative\nneuro-symbolic approaches. We empirically demonstrate that SPLs outperform\nthese competitors in terms of accuracy on challenging SOP tasks including\nhierarchical multi-label classification, pathfinding and preference learning,\nwhile retaining perfect constraint satisfaction.",
    "descriptor": "",
    "authors": [
      "Kareem Ahmed",
      "Stefano Teso",
      "Kai-Wei Chang",
      "Guy Van den Broeck",
      "Antonio Vergari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.00426"
  },
  {
    "id": "arXiv:2206.00429",
    "title": "Collaborative Cluster Configuration for Distributed Data-Parallel  Processing: A Research Overview",
    "abstract": "Many organizations routinely analyze large datasets using systems for\ndistributed data-parallel processing and clusters of commodity resources. Yet,\nusers need to configure adequate resources for their data processing jobs. This\nrequires significant insights into expected job runtimes and scaling behavior,\nresource characteristics, input data distributions, and other factors. Unable\nto estimate performance accurately, users frequently overprovision resources\nfor their jobs, leading to low resource utilization and high costs. In this\npaper, we present major building blocks towards a collaborative approach for\noptimization of data processing cluster configurations based on runtime data\nand performance models. We believe that runtime data can be shared and used for\nperformance models across different execution contexts, significantly reducing\nthe reliance on the recurrence of individual processing jobs or, else,\ndedicated job profiling. For this, we describe how the similarity of processing\njobs and cluster infrastructures can be employed to combine suitable data\npoints from local and global job executions into accurate performance models.\nFurthermore, we outline approaches to performance prediction via more\ncontext-aware and reusable models. Finally, we lay out how metrics from\nprevious executions can be combined with runtime monitoring to effectively\nre-configure models and clusters dynamically.",
    "descriptor": "",
    "authors": [
      "Lauritz Thamsen",
      "Dominik Scheinert",
      "Jonathan Will",
      "Jonathan Bader",
      "Odej Kao"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.00429"
  },
  {
    "id": "arXiv:2206.00432",
    "title": "Evaluating Gaussian Grasp Maps for Generative Grasping Models",
    "abstract": "Generalising robotic grasping to previously unseen objects is a key task in\ngeneral robotic manipulation. The current method for training many antipodal\ngenerative grasping models rely on a binary ground truth grasp map generated\nfrom the centre thirds of correctly labelled grasp rectangles. However, these\nbinary maps do not accurately reflect the positions in which a robotic arm can\ncorrectly grasp a given object. We propose a continuous Gaussian representation\nof annotated grasps to generate ground truth training data which achieves a\nhigher success rate on a simulated robotic grasping benchmark. Three modern\ngenerative grasping networks are trained with either binary or Gaussian grasp\nmaps, along with recent advancements from the robotic grasping literature, such\nas discretisation of grasp angles into bins and an attentional loss function.\nDespite negligible difference according to the standard rectangle metric,\nGaussian maps better reproduce the training data and therefore improve success\nrates when tested on the same simulated robot arm by avoiding collisions with\nthe object: achieving 87.94\\% accuracy. Furthermore, the best performing model\nis shown to operate with a high success rate when transferred to a real robotic\narm, at high inference speeds, without the need for transfer learning. The\nsystem is then shown to be capable of performing grasps on an antagonistic\nphysical object dataset benchmark.",
    "descriptor": "\nComments: 9 pages, 6 figures, to be published in IJCNN 2022\n",
    "authors": [
      "William Prew",
      "Toby P. Breckon",
      "Magnus Bordewich",
      "Ulrik Beierholm"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00432"
  },
  {
    "id": "arXiv:2206.00437",
    "title": "What a Creole Wants, What a Creole Needs",
    "abstract": "In recent years, the natural language processing (NLP) community has given\nincreased attention to the disparity of efforts directed towards high-resource\nlanguages over low-resource ones. Efforts to remedy this delta often begin with\ntranslations of existing English datasets into other languages. However, this\napproach ignores that different language communities have different needs. We\nconsider a group of low-resource languages, Creole languages. Creoles are both\nlargely absent from the NLP literature, and also often ignored by society at\nlarge due to stigma, despite these languages having sizable and vibrant\ncommunities. We demonstrate, through conversations with Creole experts and\nsurveys of Creole-speaking communities, how the things needed from language\ntechnology can change dramatically from one language to another, even when the\nlanguages are considered to be very similar to each other, as with Creoles. We\ndiscuss the prominent themes arising from these conversations, and ultimately\ndemonstrate that useful language technology cannot be built without involving\nthe relevant community.",
    "descriptor": "\nComments: LREC 2022\n",
    "authors": [
      "Heather Lent",
      "Kelechi Ogueji",
      "Miryam de Lhoneux",
      "Orevaoghene Ahia",
      "Anders S\u00f8gaard"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.00437"
  },
  {
    "id": "arXiv:2206.00439",
    "title": "Algorithmic Foundation of Deep X-Risk Optimization",
    "abstract": "X-risk is a term introduced to represent a family of compositional measures\nor objectives, in which each data point is compared with a set of data points\nexplicitly or implicitly for defining a risk function. It includes many widely\nused measures or objectives, e.g., AUROC, AUPRC, partial AUROC, NDCG, MAP,\ntop-$K$ NDCG, top-$K$ MAP, listwise losses, p-norm push, top push,\nprecision/recall at top $K$ positions, precision at a certain recall level,\ncontrastive objectives, etc. While these measures/objectives and their\noptimization algorithms have been studied in the literature of machine\nlearning, computer vision, information retrieval, and etc, optimizing these\nmeasures/objectives has encountered some unique challenges for deep learning.\nIn this technical report, we survey our recent rigorous efforts for deep X-risk\noptimization (DXO) by focusing on its algorithmic foundation. We introduce a\nclass of techniques for optimizing X-risk for deep learning. We formulate DXO\ninto three special families of non-convex optimization problems belonging to\nnon-convex min-max optimization, non-convex compositional optimization, and\nnon-convex bilevel optimization, respectively. For each family of problems, we\npresent some strong baseline algorithms and their complexities, which will\nmotivate further research for improving the existing results. Discussions about\nthe presented results and future studies are given at the end.",
    "descriptor": "",
    "authors": [
      "Tianbao Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.00439"
  },
  {
    "id": "arXiv:2206.00447",
    "title": "CD$^2$: Fine-grained 3D Mesh Reconstruction with Twice Chamfer Distance",
    "abstract": "Monocular 3D reconstruction is to reconstruct the shape of object and its\nother detailed information from a single RGB image. In 3D reconstruction,\npolygon mesh is the most prevalent expression form obtained from deep learning\nmodels, with detailed surface information and low computational cost. However,\nsome state-of-the-art works fail to generate well-structured meshes, these\nmeshes have two severe problems which we call Vertices Clustering and Illegal\nTwist. By delving into the mesh deformation procedure, we pinpoint the\ninadequate usage of Chamfer Distance(CD) metric in deep learning model. In this\npaper, we initially demonstrate the problems resulting from CD with visual\nexamples and quantitative analyses. To solve these problems, we propose a\nfine-grained reconstruction method CD$^2$ with Chamfer distance adopted twice\nto perform a plausible and adaptive deformation. Extensive experiments on two\n3D datasets and the comparison of our newly proposed mesh quality metrics\ndemonstrate that our CD$^2$ outperforms others by generating better-structured\nmeshes.",
    "descriptor": "\nComments: under review in TOMM\n",
    "authors": [
      "Rongfei Zeng",
      "Mai Su",
      "Xingwei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.00447"
  },
  {
    "id": "arXiv:2206.00448",
    "title": "A fast algorithm for the inversion of Abel's transform",
    "abstract": "We present a new algorithm for the computation of the inverse Abel transform,\na problem which emerges in many areas of physics and engineering. We prove that\nthe Legendre coefficients of a given function coincide with the Fourier\ncoefficients of a suitable periodic function associated with its Abel\ntransform. This allows us to compute the Legendre coefficients of the inverse\nAbel transform in an easy, fast and accurate way by means of a single Fast\nFourier Transform. The algorithm is thus appropriate also for the inversion of\nAbel integrals given in terms of samples representing noisy measurements.\nRigorous stability estimates are proved and the accuracy of the algorithm is\nillustrated also by some numerical experiments.",
    "descriptor": "\nComments: 19 pages, 4 figures\n",
    "authors": [
      "Enrico De Micheli"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Classical Analysis and ODEs (math.CA)"
    ],
    "url": "https://arxiv.org/abs/2206.00448"
  },
  {
    "id": "arXiv:2206.00449",
    "title": "Ultrahyperbolic Knowledge Graph Embeddings",
    "abstract": "Recent knowledge graph (KG) embeddings have been advanced by hyperbolic\ngeometry due to its superior capability for representing hierarchies. The\ntopological structures of real-world KGs, however, are rather heterogeneous,\ni.e., a KG is composed of multiple distinct hierarchies and non-hierarchical\ngraph structures. Therefore, a homogeneous (either Euclidean or hyperbolic)\ngeometry is not sufficient for fairly representing such heterogeneous\nstructures. To capture the topological heterogeneity of KGs, we present an\nultrahyperbolic KG embedding (UltraE) in an ultrahyperbolic (or\npseudo-Riemannian) manifold that seamlessly interleaves hyperbolic and\nspherical manifolds. In particular, we model each relation as a\npseudo-orthogonal transformation that preserves the pseudo-Riemannian bilinear\nform. The pseudo-orthogonal transformation is decomposed into various operators\n(i.e., circular rotations, reflections and hyperbolic rotations), allowing for\nsimultaneously modeling heterogeneous structures as well as complex relational\npatterns. Experimental results on three standard KGs show that UltraE\noutperforms previous Euclidean- and hyperbolic-based approaches.",
    "descriptor": "\nComments: Accepted to SIGKDD'22\n",
    "authors": [
      "Bo Xiong",
      "Shichao Zhu",
      "Mojtaba Nayyeri",
      "Chengjin Xu",
      "Shirui Pan",
      "Chuan Zhou",
      "Steffen Staab"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.00449"
  },
  {
    "id": "arXiv:2206.00452",
    "title": "The effect of time discretization on the solution of parabolic PDEs with  ANNs",
    "abstract": "We investigate the resolution of parabolic PDEs via Extreme Learning Machine\n(ELMs) Neural Networks, which have a single hidden layer and can be trained at\na modest computational cost as compared with Deep Learning Neural Networks. Our\napproach addresses the time evolution by applying classical ODEs techniques and\nuses ELM-based collocation for solving the resulting stationary elliptic\nproblems. In this framework, the $\\theta$-method and Backward Difference\nFormulae (BDF) techniques are investigated on some linear parabolic PDEs that\nare challeging problems for the stability and accuracy properties of the\nmethods. The results of numerical experiments confirm that ELM-based solution\ntechniques combined with BDF methods can provide high-accuracy solutions of\nparabolic PDEs.",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Francesco Calabr\u00f2",
      "Salvatore Cuomo",
      "Daniela di Serafino",
      "Giuseppe Izzo",
      "Eleonora Messina"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.00452"
  },
  {
    "id": "arXiv:2206.00454",
    "title": "Towards Context-Aware Neural Performance-Score Synchronisation",
    "abstract": "Music can be represented in multiple forms, such as in the audio form as a\nrecording of a performance, in the symbolic form as a computer readable score,\nor in the image form as a scan of the sheet music. Music synchronisation\nprovides a way to navigate among multiple representations of music in a unified\nmanner by generating an accurate mapping between them, lending itself\napplicable to a myriad of domains like music education, performance analysis,\nautomatic accompaniment and music editing. Traditional synchronisation methods\ncompute alignment using knowledge-driven and stochastic approaches, typically\nemploying handcrafted features. These methods are often unable to generalise\nwell to different instruments, acoustic environments and recording conditions,\nand normally assume complete structural agreement between the performances and\nthe scores. This PhD furthers the development of performance-score\nsynchronisation research by proposing data-driven, context-aware alignment\napproaches, on three fronts: Firstly, I replace the handcrafted features by\nemploying a metric learning based approach that is adaptable to different\nacoustic settings and performs well in data-scarce conditions. Secondly, I\naddress the handling of structural differences between the performances and\nscores, which is a common limitation of standard alignment methods. Finally, I\neschew the reliance on both feature engineering and dynamic programming, and\npropose a completely data-driven synchronisation method that computes\nalignments using a neural framework, whilst also being robust to structural\ndifferences between the performances and scores.",
    "descriptor": "\nComments: PhD Thesis, Queen Mary University of London (190 pages)\n",
    "authors": [
      "Ruchit Agrawal"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00454"
  },
  {
    "id": "arXiv:2206.00460",
    "title": "A hybrid-model approach for reducing the performance gap in building  energy forecasting",
    "abstract": "The performance gap between predicted and actual energy consumption in the\nbuilding domain remains an unsolved problem in practice. The gap exists\ndifferently in both current mainstream methods: the first-principles model and\nthe machine learning (ML) model. Inspired by the concept of time-series\ndecomposition to identify different uncertainties, we proposed a hybrid-model\napproach by combining both methods to minimize this gap: 1. Use the\nfirst-principles method as an encoding tool to convert the building static\nfeatures and predictable patterns in time-series simulation results; 2. The ML\nmethod combines the results as extra inputs with historical records\nsimultaneously, trains the model to capture the implicit performance\ndifference, and aligns to calibrate the output. To extend this approach in\npractice, a new concept in the modeling process: Level-of-Information (LOI), is\nintroduced to leverage the balance between the investment of simulation\nmodeling detail and the accuracy boost. The approach is tested over a\nthree-year period, with hourly measured energy load from an operating\ncommercial building in Shanghai. The result presents a dominant accuracy\nenhancement: The hybrid-model shows higher accuracy in prediction with better\ninterpretability; More important, it releases the practitioners from modeling\nworkload and computational resources in refining simulation. In summary, the\napproach provides a nexus for integrating domain knowledge via building\nsimulation with data-driven methods. This mindset applies to solving general\nengineering problems and leads to improved prediction accuracy. The result and\nsource data are available at\nhttps://github.com/ResearchGroup-G/PerformanceGap-Hybrid-Approach.",
    "descriptor": "\nComments: 18 pages, 11 figures; The result and source data are available at this https URL\n",
    "authors": [
      "Xia Chen",
      "Tong Guo",
      "Martin Kriegel",
      "Philipp Geyer"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2206.00460"
  },
  {
    "id": "arXiv:2206.00462",
    "title": "MDS and AMDS symbol-pair codes constructed from repeated-root codes",
    "abstract": "Symbol-pair codes introduced by Cassuto and Blaum in 2010 are designed to\nprotect against the pair errors in symbol-pair read channels. One of the\ncentral themes in symbol-error correction is the construction of maximal\ndistance separable (MDS) symbol-pair codes that possess the largest possible\npair-error correcting performance. Based on repeated-root cyclic codes, we\nconstruct two classes of MDS symbol-pair codes for more general generator\npolynomials and also give a new class of almost MDS (AMDS) symbol-pair codes\nwith the length $lp$. In addition, we derive all MDS and AMDS symbol-pair codes\nwith length $3p$, when the degree of the generator polynomials is no more than\n10. The main results are obtained by determining the solutions of certain\nequations over finite fields.",
    "descriptor": "\nComments: 22 pages. arXiv admin note: substantial text overlap with arXiv:2204.02670\n",
    "authors": [
      "Xiuxin Tang",
      "Rong Luo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.00462"
  },
  {
    "id": "arXiv:2206.00466",
    "title": "An $\u03b1$-No-Regret Algorithm For Graphical Bilinear Bandits",
    "abstract": "We propose the first regret-based approach to the Graphical Bilinear Bandits\nproblem, where $n$ agents in a graph play a stochastic bilinear bandit game\nwith each of their neighbors. This setting reveals a combinatorial NP-hard\nproblem that prevents the use of any existing regret-based algorithm in the\n(bi-)linear bandit literature. In this paper, we fill this gap and present the\nfirst regret-based algorithm for graphical bilinear bandits using the principle\nof optimism in the face of uncertainty. Theoretical analysis of this new method\nyields an upper bound of $\\tilde{O}(\\sqrt{T})$ on the $\\alpha$-regret and\nevidences the impact of the graph structure on the rate of convergence.\nFinally, we show through various experiments the validity of our approach.",
    "descriptor": "",
    "authors": [
      "Geovani Rizk",
      "Igor Colin",
      "Albert Thomas",
      "Rida Laraki",
      "Yann Chevaleyre"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.00466"
  },
  {
    "id": "arXiv:2206.00468",
    "title": "PanopticDepth: A Unified Framework for Depth-aware Panoptic Segmentation",
    "abstract": "This paper presents a unified framework for depth-aware panoptic segmentation\n(DPS), which aims to reconstruct 3D scene with instance-level semantics from\none single image. Prior works address this problem by simply adding a dense\ndepth regression head to panoptic segmentation (PS) networks, resulting in two\nindependent task branches. This neglects the mutually-beneficial relations\nbetween these two tasks, thus failing to exploit handy instance-level semantic\ncues to boost depth accuracy while also producing sub-optimal depth maps. To\novercome these limitations, we propose a unified framework for the DPS task by\napplying a dynamic convolution technique to both the PS and depth prediction\ntasks. Specifically, instead of predicting depth for all pixels at a time, we\ngenerate instance-specific kernels to predict depth and segmentation masks for\neach instance. Moreover, leveraging the instance-wise depth estimation scheme,\nwe add additional instance-level depth cues to assist with supervising the\ndepth learning via a new depth loss. Extensive experiments on Cityscapes-DPS\nand SemKITTI-DPS show the effectiveness and promise of our method. We hope our\nunified solution to DPS can lead a new paradigm in this area. Code is available\nat https://github.com/NaiyuGao/PanopticDepth.",
    "descriptor": "\nComments: CVPR2022\n",
    "authors": [
      "Naiyu Gao",
      "Fei He",
      "Jian Jia",
      "Yanhu Shan",
      "Haoyang Zhang",
      "Xin Zhao",
      "Kaiqi Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.00468"
  },
  {
    "id": "arXiv:2206.00469",
    "title": "A barycentric trigonometric Hermite interpolant via an iterative  approach",
    "abstract": "In this paper an interative approach for constructing the Hermite interpolant\nintroduced by Cirillo and Hormann (2018) for the Floater-Hormann family of\ninterpolants is extended and generalised. In particular, we apply that scheme\nto produce an effective barycentric rational trigonometric Hermite interpolant\nusing the basis function of the interpolant introduced by Berrut (1988). In\norder to give an easy construction of such an interpolant we compute the\ndifferentation matrix analytically and we conclude with various examples and a\nnumerical study of the rate of convergence at equidistant nodes.",
    "descriptor": "",
    "authors": [
      "Giacomo Elefante"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.00469"
  },
  {
    "id": "arXiv:2206.00470",
    "title": "Good Intentions: Adaptive Parameter Servers via Intent Signaling",
    "abstract": "Parameter servers (PSs) ease the implementation of distributed training for\nlarge machine learning (ML) tasks by providing primitives for shared parameter\naccess. Especially for ML tasks that access parameters sparsely, PSs can\nachieve high efficiency and scalability. To do so, they employ a number of\ntechniques -- such as replication or relocation -- to reduce communication cost\nand/or latency of parameter accesses. A suitable choice and parameterization of\nthese techniques is crucial to realize these gains, however. Unfortunately,\nsuch choices depend on the task, the workload, and even individual parameters,\nthey often require expensive upfront experimentation, and they are susceptible\nto workload changes. In this paper, we explore whether PSs can automatically\nadapt to the workload without any prior tuning. Our goals are to improve\nusability and to maintain (or even improve) efficiency. We propose (i) a novel\nintent signaling mechanism that acts as an enabler for adaptivity and naturally\nintegrates into ML tasks, and (ii) a fully adaptive, zero-tuning PS called\nAdaPS based on this mechanism. Our experimental evaluation suggests that\nautomatic adaptation to the workload is indeed possible: AdaPS matched or\noutperformed state-of-the-art PSs out of the box.",
    "descriptor": "",
    "authors": [
      "Alexander Renz-Wieland",
      "Andreas Kieslinger",
      "Robert Gericke",
      "Rainer Gemulla",
      "Zoi Kaoudi",
      "Volker Markl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Databases (cs.DB)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.00470"
  },
  {
    "id": "arXiv:2206.00471",
    "title": "Contrastive Principal Component Learning: Modeling Similarity by  Augmentation Overlap",
    "abstract": "Traditional self-supervised contrastive learning methods learn embeddings by\npulling views of the same sample together and pushing views of different\nsamples away. Since views of a sample are usually generated via data\naugmentations, the semantic relationship between samples is ignored. Based on\nthe observation that semantically similar samples are more likely to have\nsimilar augmentations, we propose to measure similarity via the distribution of\naugmentations, i.e., how much the augmentations of two samples overlap. To\nhandle the dimensional and computational complexity, we propose a novel\nContrastive Principal Component Learning (CPCL) method composed of a\ncontrastive-like loss and an on-the-fly projection loss to efficiently perform\nPCA on the augmentation feature, which encodes the augmentation distribution.\nBy CPCL, the learned low-dimensional embeddings theoretically preserve the\nsimilarity of augmentation distribution between samples. Empirical results show\nour method can achieve competitive results against various traditional\ncontrastive learning methods on different benchmarks.",
    "descriptor": "",
    "authors": [
      "Lu Han",
      "Han-Jia Ye",
      "De-Chuan Zhan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.00471"
  },
  {
    "id": "arXiv:2206.00473",
    "title": "ILMART: Interpretable Ranking with Constrained LambdaMART",
    "abstract": "Interpretable Learning to Rank (LtR) is an emerging field within the research\narea of explainable AI, aiming at developing intelligible and accurate\npredictive models. While most of the previous research efforts focus on\ncreating post-hoc explanations, in this paper we investigate how to train\neffective and intrinsically-interpretable ranking models. Developing these\nmodels is particularly challenging and it also requires finding a trade-off\nbetween ranking quality and model complexity. State-of-the-art rankers, made of\neither large ensembles of trees or several neural layers, exploit in fact an\nunlimited number of feature interactions making them black boxes. Previous\napproaches on intrinsically-interpretable ranking models address this issue by\navoiding interactions between features thus paying a significant performance\ndrop with respect to full-complexity models. Conversely, ILMART, our novel and\ninterpretable LtR solution based on LambdaMART, is able to train effective and\nintelligible models by exploiting a limited and controlled number of pairwise\nfeature interactions. Exhaustive and reproducible experiments conducted on\nthree publicly-available LtR datasets show that ILMART outperforms the current\nstate-of-the-art solution for interpretable ranking of a large margin with a\ngain of nDCG of up to 8%.",
    "descriptor": "\nComments: 5 pages, 3 figures, to be published in SIGIR 2022 proceedings\n",
    "authors": [
      "Claudio Lucchese",
      "Franco Maria Nardini",
      "Salvatore Orlando",
      "Raffaele Perego",
      "Alberto Veneri"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.00473"
  },
  {
    "id": "arXiv:2206.00474",
    "title": "Towards Responsible AI: A Design Space Exploration of Human-Centered  Artificial Intelligence User Interfaces to Investigate Fairness",
    "abstract": "With Artificial intelligence (AI) to aid or automate decision-making\nadvancing rapidly, a particular concern is its fairness. In order to create\nreliable, safe and trustworthy systems through human-centred artificial\nintelligence (HCAI) design, recent efforts have produced user interfaces (UIs)\nfor AI experts to investigate the fairness of AI models. In this work, we\nprovide a design space exploration that supports not only data scientists but\nalso domain experts to investigate AI fairness. Using loan applications as an\nexample, we held a series of workshops with loan officers and data scientists\nto elicit their requirements. We instantiated these requirements into FairHIL,\na UI to support human-in-the-loop fairness investigations, and describe how\nthis UI could be generalized to other use cases. We evaluated FairHIL through a\nthink-aloud user study. Our work contributes better designs to investigate an\nAI model's fairness-and move closer towards responsible AI.",
    "descriptor": "\nComments: 44 pages, 17 figures, the draft of a paper on International Journal of Human-Computer Interaction\n",
    "authors": [
      "Yuri Nakao",
      "Lorenzo Strappelli",
      "Simone Stumpf",
      "Aisha Naseer",
      "Daniele Regoli",
      "Giulia Del Gamba"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.00474"
  },
  {
    "id": "arXiv:2206.00477",
    "title": "Anti-Forgery: Towards a Stealthy and Robust DeepFake Disruption Attack  via Adversarial Perceptual-aware Perturbations",
    "abstract": "DeepFake is becoming a real risk to society and brings potential threats to\nboth individual privacy and political security due to the DeepFaked multimedia\nare realistic and convincing. However, the popular DeepFake passive detection\nis an ex-post forensics countermeasure and failed in blocking the\ndisinformation spreading in advance. To address this limitation, researchers\nstudy the proactive defense techniques by adding adversarial noises into the\nsource data to disrupt the DeepFake manipulation. However, the existing studies\non proactive DeepFake defense via injecting adversarial noises are not robust,\nwhich could be easily bypassed by employing simple image reconstruction\nrevealed in a recent study MagDR.\nIn this paper, we investigate the vulnerability of the existing forgery\ntechniques and propose a novel \\emph{anti-forgery} technique that helps users\nprotect the shared facial images from attackers who are capable of applying the\npopular forgery techniques. Our proposed method generates perceptual-aware\nperturbations in an incessant manner which is vastly different from the prior\nstudies by adding adversarial noises that is sparse. Experimental results\nreveal that our perceptual-aware perturbations are robust to diverse image\ntransformations, especially the competitive evasion technique, MagDR via image\nreconstruction. Our findings potentially open up a new research direction\ntowards thorough understanding and investigation of perceptual-aware\nadversarial attack for protecting facial images against DeepFakes in a\nproactive and robust manner. We open-source our tool to foster future research.\nCode is available at https://github.com/AbstractTeen/AntiForgery/.",
    "descriptor": "\nComments: Accepted by IJCAI 2022\n",
    "authors": [
      "Run Wang",
      "Ziheng Huang",
      "Zhikai Chen",
      "Li Liu",
      "Jing Chen",
      "Lina Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.00477"
  },
  {
    "id": "arXiv:2206.00478",
    "title": "Weak consistency of P-time event graphs",
    "abstract": "P-time event graphs (P-TEGs) are event graphs where the residence time of\ntokens in places is bounded by specified time windows. In this paper, we define\na new property of PTEGs, called weak consistency. In weakly consistent P-TEGs,\nthe amount of times a transition can fire before the first violation of a time\nconstraint can be made as large as desired. We show the practical implications\nof this property and, based on previous results in graph theory, we formulate\nan algorithm of strongly polynomial time complexity that verifies it. From this\nalgorithm, it is possible to determine, in pseudo-polynomial time, the maximum\nnumber of firings before the first constraint violation in a P-TEG.",
    "descriptor": "\nComments: 7 pages, 3 figures, conference\n",
    "authors": [
      "Davide Zorzenon",
      "Ji\u0159\u00ed Balun",
      "J\u00f6rg Raisch"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2206.00478"
  },
  {
    "id": "arXiv:2206.00480",
    "title": "Sex and Gender in the Computer Graphics Research Literature",
    "abstract": "We survey the treatment of sex and gender in the Computer Graphics research\nliterature from an algorithmic fairness perspective. The established practices\non the use of gender and sex in our community are scientifically incorrect and\nconstitute a form of algorithmic bias with potential harmful effects. We\npropose ways of addressing these as technical limitations.",
    "descriptor": "",
    "authors": [
      "Ana Dodik",
      "Silvia Sell\u00e1n",
      "Theodore Kim",
      "Amanda Phillips"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.00480"
  },
  {
    "id": "arXiv:2206.00481",
    "title": "Where are my Neighbors? Exploiting Patches Relations in Self-Supervised  Vision Transformer",
    "abstract": "Vision Transformers (ViTs) enabled the use of transformer architecture on\nvision tasks showing impressive performances when trained on big datasets.\nHowever, on relatively small datasets, ViTs are less accurate given their lack\nof inductive bias. To this end, we propose a simple but still effective\nself-supervised learning (SSL) strategy to train ViTs, that without any\nexternal annotation, can significantly improve the results. Specifically, we\ndefine a set of SSL tasks based on relations of image patches that the model\nhas to solve before or jointly during the downstream training. Differently from\nViT, our RelViT model optimizes all the output tokens of the transformer\nencoder that are related to the image patches, thus exploiting more training\nsignal at each training step. We investigated our proposed methods on several\nimage benchmarks finding that RelViT improves the SSL state-of-the-art methods\nby a large margin, especially on small datasets.",
    "descriptor": "\nComments: Extended Abstract / Spotlight presentation at CVPR 2022 Transformers for Vision (T4V) Workshop\n",
    "authors": [
      "Guglielmo Camporese",
      "Elena Izzo",
      "Lamberto Ballan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00481"
  },
  {
    "id": "arXiv:2206.00484",
    "title": "DEP-RL: Embodied Exploration for Reinforcement Learning in Overactuated  and Musculoskeletal Systems",
    "abstract": "Muscle-actuated organisms are capable of learning an unparalleled diversity\nof dexterous movements despite their vast amount of muscles. Reinforcement\nlearning (RL) on large musculoskeletal models, however, has not been able to\nshow similar performance. We conjecture that ineffective exploration in large\noveractuated action spaces is a key problem. This is supported by the finding\nthat common exploration noise strategies are inadequate in synthetic examples\nof overactuated systems. We identify differential extrinsic plasticity (DEP), a\nmethod from the domain of self-organization, as being able to induce\nstate-space covering exploration within seconds of interaction. By integrating\nDEP into RL, we achieve fast learning of reaching and locomotion in\nmusculoskeletal systems, outperforming current approaches in all considered\ntasks in sample efficiency and robustness.",
    "descriptor": "",
    "authors": [
      "Pierre Schumacher",
      "Daniel H\u00e4ufle",
      "Dieter B\u00fcchler",
      "Syn Schmitt",
      "Georg Martius"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00484"
  },
  {
    "id": "arXiv:2206.00485",
    "title": "Co-creation and ownership for AI radio",
    "abstract": "Recent breakthroughs in AI-generated music open the door for new forms for\nco-creation and co-creativity. We present Artificial$.\\!$fm, a proof-of-concept\ncasual creator that blends AI-music generation, subjective ratings, and\npersonalized recommendation for the creation and curation of AI-generated\nmusic. Listeners can rate emergent songs to steer the evolution of future\nmusic. They can also personalize their preferences to better navigate the\npossibility space. As a \"slow creator\" with many human stakeholders,\nArtificial$.\\!$fm is an example of how casual creators can leverage human\ncuration at scale to collectively navigate a possibility space. It also\nprovides a case study to reflect on how ownership should be considered in these\ncontexts. We report on the design and development of Artificial$.\\!$fm, and\nprovide a legal analysis on the ownership of artifacts generated on the\nplatform.",
    "descriptor": "",
    "authors": [
      "Skylar Gordon",
      "Robert Mahari",
      "Manaswi Mishra",
      "Ziv Epstein"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.00485"
  },
  {
    "id": "arXiv:2206.00488",
    "title": "Rotate the ReLU to implicitly sparsify deep networks",
    "abstract": "In the era of Deep Neural Network based solutions for a variety of real-life\ntasks, having a compact and energy-efficient deployable model has become fairly\nimportant. Most of the existing deep architectures use Rectifier Linear Unit\n(ReLU) activation. In this paper, we propose a novel idea of rotating the ReLU\nactivation to give one more degree of freedom to the architecture. We show that\nthis activation wherein the rotation is learned via training results in the\nelimination of those parameters/filters in the network which are not important\nfor the task. In other words, rotated ReLU seems to be doing implicit\nsparsification. The slopes of the rotated ReLU activations act as coarse\nfeature extractors and unnecessary features can be eliminated before\nretraining. Our studies indicate that features always choose to pass through a\nlesser number of filters in architectures such as ResNet and its variants.\nHence, by rotating the ReLU, the weights or the filters that are not necessary\nare automatically identified and can be dropped thus giving rise to significant\nsavings in memory and computation. Furthermore, in some cases, we also notice\nthat along with saving in memory and computation we also obtain improvement\nover the reported performance of the corresponding baseline work in the popular\ndatasets such as MNIST, CIFAR-10, CIFAR-100, and SVHN.",
    "descriptor": "",
    "authors": [
      "Nancy Nayak",
      "Sheetal Kalyani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00488"
  },
  {
    "id": "arXiv:2206.00489",
    "title": "Attack-Agnostic Adversarial Detection",
    "abstract": "The growing number of adversarial attacks in recent years gives attackers an\nadvantage over defenders, as defenders must train detectors after knowing the\ntypes of attacks, and many models need to be maintained to ensure good\nperformance in detecting any upcoming attacks. We propose a way to end the\ntug-of-war between attackers and defenders by treating adversarial attack\ndetection as an anomaly detection problem so that the detector is agnostic to\nthe attack. We quantify the statistical deviation caused by adversarial\nperturbations in two aspects. The Least Significant Component Feature (LSCF)\nquantifies the deviation of adversarial examples from the statistics of benign\nsamples and Hessian Feature (HF) reflects how adversarial examples distort the\nlandscape of the model's optima by measuring the local loss curvature.\nEmpirical results show that our method can achieve an overall ROC AUC of 94.9%,\n89.7%, and 94.6% on CIFAR10, CIFAR100, and SVHN, respectively, and has\ncomparable performance to adversarial detectors trained with adversarial\nexamples on most of the attacks.",
    "descriptor": "",
    "authors": [
      "Jiaxin Cheng",
      "Mohamed Hussein",
      "Jay Billa",
      "Wael AbdAlmageed"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.00489"
  },
  {
    "id": "arXiv:2206.00491",
    "title": "Semantic Room Wireframe Detection from a Single View",
    "abstract": "Reconstruction of indoor surfaces with limited texture information or with\nrepeated textures, a situation common in walls and ceilings, may be difficult\nwith a monocular Structure from Motion system. We propose a Semantic Room\nWireframe Detection task to predict a Semantic Wireframe from a single\nperspective image. Such predictions may be used with shape priors to estimate\nthe Room Layout and aid reconstruction. To train and test the proposed\nalgorithm we create a new set of annotations from the simulated Structured3D\ndataset. We show qualitatively that the SRW-Net handles complex room geometries\nbetter than previous Room Layout Estimation algorithms while quantitatively\nout-performing the baseline in non-semantic Wireframe Detection.",
    "descriptor": "\nComments: Accepted for ICPR2022\n",
    "authors": [
      "David Gillsj\u00f6",
      "Gabrielle Flood",
      "Kalle \u00c5str\u00f6m"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.00491"
  },
  {
    "id": "arXiv:2206.00494",
    "title": "Incentivizing Combinatorial Bandit Exploration",
    "abstract": "Consider a bandit algorithm that recommends actions to self-interested users\nin a recommendation system. The users are free to choose other actions and need\nto be incentivized to follow the algorithm's recommendations. While the users\nprefer to exploit, the algorithm can incentivize them to explore by leveraging\nthe information collected from the previous users. All published work on this\nproblem, known as incentivized exploration, focuses on small, unstructured\naction sets and mainly targets the case when the users' beliefs are independent\nacross actions. However, realistic exploration problems often feature large,\nstructured action sets and highly correlated beliefs. We focus on a\nparadigmatic exploration problem with structure: combinatorial semi-bandits. We\nprove that Thompson Sampling, when applied to combinatorial semi-bandits, is\nincentive-compatible when initialized with a sufficient number of samples of\neach arm (where this number is determined in advance by the Bayesian prior).\nMoreover, we design incentive-compatible algorithms for collecting the initial\nsamples.",
    "descriptor": "\nComments: 9 pages of main text, 21 pages in total\n",
    "authors": [
      "Xinyan Hu",
      "Dung Daniel Ngo",
      "Aleksandrs Slivkins",
      "Zhiwei Steven Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00494"
  },
  {
    "id": "arXiv:2206.00501",
    "title": "Realistic Deep Learning May Not Fit Benignly",
    "abstract": "Studies on benign overfitting provide insights for the success of\noverparameterized deep learning models. In this work, we examine the benign\noverfitting phenomena in real-world settings. We found that for tasks such as\ntraining a ResNet model on ImageNet dataset, the model does not fit benignly.\nTo understand why benign overfitting fails in the ImageNet experiment, we\nanalyze previous benign overfitting models under a more restrictive setup where\nthe number of parameters is not significantly larger than the number of data\npoints. Under this mild overparameterization setup, our analysis identifies a\nphase change: unlike in the heavy overparameterization setting, benign\noverfitting can now fail in the presence of label noise. Our study explains our\nempirical observations, and naturally leads to a simple technique known as\nself-training that can boost the model's generalization performances.\nFurthermore, our work highlights the importance of understanding implicit bias\nin underfitting regimes as a future direction.",
    "descriptor": "",
    "authors": [
      "Kaiyue Wen",
      "Jiaye Teng",
      "Jingzhao Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.00501"
  },
  {
    "id": "arXiv:2206.00502",
    "title": "Fast generation of simple directed social network graphs with reciprocal  edges and high clustering",
    "abstract": "Online social networks have emerged as useful tools to communicate or share\ninformation and news on a daily basis. One of the most popular networks is\nTwitter, where users connect to each other via directed follower relationships.\nResearchers have studied Twitter follower graphs and described them with\nvarious topological features. Collecting Twitter data, especially crawling the\nfollowers of users, is a tedious and time-consuming process and the data needs\nto be treated carefully due to its sensitive nature, containing personal user\ninformation. We therefore aim at the fast generation of synthetic directed\nsocial network graphs with reciprocal edges and high clustering. Our proposed\nmethod is based on a previously developed model, but relies on less\nhyperparameters and has a significantly lower runtime. Results show that the\nmethod does not only replicate the crawled directed Twitter graphs well w.r.t.\nseveral topological features and the application of an epidemics spreading\nprocess, but that it is also highly scalable which allows the fast creation of\nbigger graphs that exhibit similar properties as real-world networks.",
    "descriptor": "\nComments: 6 pages, 1 figure\n",
    "authors": [
      "Christoph Schweimer"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.00502"
  },
  {
    "id": "arXiv:2206.00504",
    "title": "helyOS: A customized off-the-shelf solution for autonomous driving  applications in delimited areas",
    "abstract": "Microservice Architectures (MSA), known to successfully handle complex\nsoftware systems, are emerging as the new paradigm for automotive software. The\ndesign of an MSA requires correct subdivision of the software system and\nimplementation of the communication between components. These tasks demand both\nsoftware expertise and domain knowledge. In this context, we developed an MSA\nframework pre-tailored to meet the requirements of autonomous driving\napplications in delimited areas - the helyOS framework. The framework\ndecomposes complex applications in predefined microservice domains and provides\na communication backbone for event messages and data. This paper demonstrates\nhow such a tailored MSA framework can accelerate the development by prompting a\nquick start for the integration of motion planning algorithms, device\ncontrollers, vehicles simulators and web-browser interfaces.",
    "descriptor": "",
    "authors": [
      "Carlos Viol Barbosa",
      "Nikolay Belov",
      "Felix Keppler",
      "Julius Kolb",
      "Gunter Nitzsche",
      "Sebastian Wagner"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.00504"
  },
  {
    "id": "arXiv:2206.00506",
    "title": "Proximally Sensitive Error for Anomaly Detection and Feature Learning",
    "abstract": "Mean squared error (MSE) is one of the most widely used metrics to expression\ndifferences between multi-dimensional entities, including images. However, MSE\nis not locally sensitive as it does not take into account the spatial\narrangement of the (pixel) differences, which matters for structured data types\nlike images. Such spatial arrangements carry information about the source of\nthe differences; therefore, an error function that also incorporates the\nlocation of errors can lead to a more meaningful distance measure. We introduce\nProximally Sensitive Error (PSE), through which we suggest that a regional\nemphasis in the error measure can 'highlight' semantic differences between\nimages over syntactic/random deviations. We demonstrate that this emphasis can\nbe leveraged upon for the task of anomaly/occlusion detection. We further\nexplore its utility as a loss function to help a model focus on learning\nrepresentations of semantic objects instead of minimizing syntactic\nreconstruction noise.",
    "descriptor": "",
    "authors": [
      "Amogh Gudi",
      "Fritjof B\u00fcttner",
      "Jan van Gemert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00506"
  },
  {
    "id": "arXiv:2206.00510",
    "title": "HIEN: Hierarchical Intention Embedding Network for Click-Through Rate  Prediction",
    "abstract": "Click-through rate (CTR) prediction plays an important role in online\nadvertising and recommendation systems, which aims at estimating the\nprobability of a user clicking on a specific item. Feature interaction modeling\nand user interest modeling methods are two popular domains in CTR prediction,\nand they have been studied extensively in recent years. However, these methods\nstill suffer from two limitations. First, traditional methods regard item\nattributes as ID features, while neglecting structure information and relation\ndependencies among attributes. Second, when mining user interests from\nuser-item interactions, current models ignore user intents and item intents for\ndifferent attributes, which lacks interpretability. Based on this observation,\nin this paper, we propose a novel approach Hierarchical Intention Embedding\nNetwork (HIEN), which considers dependencies of attributes based on bottom-up\ntree aggregation in the constructed attribute graph. HIEN also captures user\nintents for different item attributes as well as item intents based on our\nproposed hierarchical attention mechanism. Extensive experiments on both public\nand production datasets show that the proposed model significantly outperforms\nthe state-of-the-art methods. In addition, HIEN can be applied as an input\nmodule to state-of-the-art CTR prediction methods, bringing further performance\nlift for these existing models that might already be intensively used in real\nsystems.",
    "descriptor": "\nComments: Accepted by SIGIR 2022\n",
    "authors": [
      "Zuowu Zheng",
      "Changwang Zhang",
      "Xiaofeng Gao",
      "Guihai Chen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.00510"
  },
  {
    "id": "arXiv:2206.00511",
    "title": "Differentially Private Shapley Values for Data Evaluation",
    "abstract": "The Shapley value has been proposed as a solution to many applications in\nmachine learning, including for equitable valuation of data. Shapley values are\ncomputationally expensive and involve the entire dataset. The query for a\npoint's Shapley value can also compromise the statistical privacy of other data\npoints. We observe that in machine learning problems such as empirical risk\nminimization, and in many learning algorithms (such as those with uniform\nstability), a diminishing returns property holds, where marginal benefit per\ndata point decreases rapidly with data sample size. Based on this property, we\npropose a new stratified approximation method called the Layered Shapley\nAlgorithm. We prove that this method operates on small (O(\\polylog(n))) random\nsamples of data and small sized ($O(\\log n)$) coalitions to achieve the results\nwith guaranteed probabilistic accuracy, and can be modified to incorporate\ndifferential privacy. Experimental results show that the algorithm correctly\nidentifies high-value data points that improve validation accuracy, and that\nthe differentially private evaluations preserve approximate ranking of data.",
    "descriptor": "",
    "authors": [
      "Lauren Watson",
      "Rayna Andreeva",
      "Hao-Tsung Yang",
      "Rik Sarkar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.00511"
  },
  {
    "id": "arXiv:2206.00512",
    "title": "Neural Network Verification with Proof Production",
    "abstract": "Deep neural networks (DNNs) are increasingly being employed in\nsafety-critical systems, and there is an urgent need to guarantee their\ncorrectness. Consequently, the verification community has devised multiple\ntechniques and tools for verifying DNNs. When DNN verifiers discover an input\nthat triggers an error, that is easy to confirm; but when they report that no\nerror exists, there is no way to ensure that the verification tool itself is\nnot flawed. As multiple errors have already been observed in DNN verification\ntools, this calls the applicability of DNN verification into question. In this\nwork, we present a novel mechanism for enhancing Simplex-based DNN verifiers\nwith proof production capabilities: the generation of an easy-to-check witness\nof unsatisfiability, which attests to the absence of errors. Our proof\nproduction is based on an efficient adaptation of the well-known Farkas' lemma,\ncombined with mechanisms for handling piecewise-linear functions and numerical\nprecision errors. As a proof of concept, we implemented our technique on top of\nthe Marabou DNN verifier. Our evaluation on a safety-critical system for\nairborne collision avoidance shows that proof production succeeds in almost all\ncases and requires only minimal overhead.",
    "descriptor": "",
    "authors": [
      "Omri Isac",
      "Clark Barrett",
      "Min Zhang",
      "Guy Katz"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00512"
  },
  {
    "id": "arXiv:2206.00513",
    "title": "The robust way to stack and bag: the local Lipschitz way",
    "abstract": "Recent research has established that the local Lipschitz constant of a neural\nnetwork directly influences its adversarial robustness. We exploit this\nrelationship to construct an ensemble of neural networks which not only\nimproves the accuracy, but also provides increased adversarial robustness. The\nlocal Lipschitz constants for two different ensemble methods - bagging and\nstacking - are derived and the architectures best suited for ensuring\nadversarial robustness are deduced. The proposed ensemble architectures are\ntested on MNIST and CIFAR-10 datasets in the presence of white-box attacks,\nFGSM and PGD. The proposed architecture is found to be more robust than a) a\nsingle network and b) traditional ensemble methods.",
    "descriptor": "",
    "authors": [
      "Thulasi Tholeti",
      "Sheetal Kalyani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.00513"
  },
  {
    "id": "arXiv:2206.00515",
    "title": "Landslide4Sense: Reference Benchmark Data and Deep Learning Models for  Landslide Detection",
    "abstract": "This study introduces \\textit{Landslide4Sense}, a reference benchmark for\nlandslide detection from remote sensing. The repository features 3,799 image\npatches fusing optical layers from Sentinel-2 sensors with the digital\nelevation model and slope layer derived from ALOS PALSAR. The added\ntopographical information facilitates an accurate detection of landslide\nborders, which recent researches have shown to be challenging using optical\ndata alone. The extensive data set supports deep learning (DL) studies in\nlandslide detection and the development and validation of methods for the\nsystematic update of landslide inventories. The benchmark data set has been\ncollected at four different times and geographical locations: Iburi (September\n2018), Kodagu (August 2018), Gorkha (April 2015), and Taiwan (August 2009).\nEach image pixel is labelled as belonging to a landslide or not, incorporating\nvarious sources and thorough manual annotation. We then evaluate the landslide\ndetection performance of 11 state-of-the-art DL segmentation models: U-Net,\nResU-Net, PSPNet, ContextNet, DeepLab-v2, DeepLab-v3+, FCN-8s, LinkNet, FRRN-A,\nFRRN-B, and SQNet. All models were trained from scratch on patches from one\nquarter of each study area and tested on independent patches from the other\nthree quarters. Our experiments demonstrate that ResU-Net outperformed the\nother models for the landslide detection task. We make the multi-source\nlandslide benchmark data (Landslide4Sense) and the tested DL models publicly\navailable at \\url{www.landslide4sense.org}, establishing an important resource\nfor remote sensing, computer vision, and machine learning communities in\nstudies of image classification in general and applications to landslide\ndetection in particular.",
    "descriptor": "",
    "authors": [
      "Omid Ghorbanzadeh",
      "Yonghao Xu",
      "Pedram Ghamis",
      "Michael Kopp",
      "David Kreil"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.00515"
  },
  {
    "id": "arXiv:2206.00516",
    "title": "Feature Selection for Discovering Distributional Treatment Effect  Modifiers",
    "abstract": "Finding the features relevant to the difference in treatment effects is\nessential to unveil the underlying causal mechanisms. Existing methods seek\nsuch features by measuring how greatly the feature attributes affect the degree\nof the {\\it conditional average treatment effect} (CATE). However, these\nmethods may overlook important features because CATE, a measure of the average\ntreatment effect, cannot detect differences in distribution parameters other\nthan the mean (e.g., variance). To resolve this weakness of existing methods,\nwe propose a feature selection framework for discovering {\\it distributional\ntreatment effect modifiers}. We first formulate a feature importance measure\nthat quantifies how strongly the feature attributes influence the discrepancy\nbetween potential outcome distributions. Then we derive its computationally\nefficient estimator and develop a feature selection algorithm that can control\nthe type I error rate to the desired level. Experimental results show that our\nframework successfully discovers important features and outperforms the\nexisting mean-based method.",
    "descriptor": "\nComments: 18 pages, Accepted to UAI2022\n",
    "authors": [
      "Yoichi Chikahara",
      "Makoto Yamada",
      "Hisashi Kashima"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.00516"
  },
  {
    "id": "arXiv:2206.00517",
    "title": "One Positive Label is Sufficient: Single-Positive Multi-Label Learning  with Label Enhancement",
    "abstract": "Multi-label learning (MLL) learns from the examples each associated with\nmultiple labels simultaneously, where the high cost of annotating all relevant\nlabels for each training example is challenging for real-world applications. To\ncope with the challenge, we investigate single-positive multi-label learning\n(SPMLL) where each example is annotated with only one relevant label and show\nthat one can successfully learn a theoretically grounded multi-label classifier\nfor the problem. In this paper, a novel SPMLL method named {\\proposed}, i.e.,\nSingle-positive MultI-label learning with Label Enhancement, is proposed.\nSpecifically, an unbiased risk estimator is derived, which could be guaranteed\nto approximately converge to the optimal risk minimizer of fully supervised\nlearning and shows that one positive label of each instance is sufficient to\ntrain the predictive model. Then, the corresponding empirical risk estimator is\nestablished via recovering the latent soft label as a label enhancement\nprocess, where the posterior density of the latent soft labels is approximate\nto the variational Beta density parameterized by an inference model.\nExperiments on benchmark datasets validate the effectiveness of the proposed\nmethod.",
    "descriptor": "",
    "authors": [
      "Ning Xu",
      "Congyu Qiao",
      "Jiaqi Lv",
      "Xin Geng",
      "Min-Ling Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00517"
  },
  {
    "id": "arXiv:2206.00518",
    "title": "Efficient Scheduling of Data Augmentation for Deep Reinforcement  Learning",
    "abstract": "In deep reinforcement learning (RL), data augmentation is widely considered\nas a tool to induce a set of useful priors about semantic consistency and\nimprove sample efficiency and generalization performance. However, even when\nthe prior is useful for generalization, distilling it to RL agent often\ninterferes with RL training and degenerates sample efficiency. Meanwhile, the\nagent is forgetful of the prior due to the non-stationary nature of RL. These\nobservations suggest two extreme schedules of distillation: (i) over the entire\ntraining; or (ii) only at the end. Hence, we devise a stand-alone network\ndistillation method to inject the consistency prior at any time (even after\nRL), and a simple yet efficient framework to automatically schedule the\ndistillation. Specifically, the proposed framework first focuses on mastering\ntrain environments regardless of generalization by adaptively deciding which\n{\\it or no} augmentation to be used for the training. After this, we add the\ndistillation to extract the remaining benefits for generalization from all the\naugmentations, which requires no additional new samples. In our experiments, we\ndemonstrate the utility of the proposed framework, in particular, that\nconsiders postponing the augmentation to the end of RL training.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2102.08581\n",
    "authors": [
      "Byungchan Ko",
      "Jungseul Ok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.00518"
  },
  {
    "id": "arXiv:2206.00520",
    "title": "Deep Learning Opacity in Scientific Discovery",
    "abstract": "Philosophers have recently focused on critical, epistemological challenges\nthat arise from the opacity of deep neural networks. One might conclude from\nthis literature that doing good science with opaque models is exceptionally\nchallenging, if not impossible. Yet, this is hard to square with the recent\nboom in optimism for AI in science alongside a flood of recent scientific\nbreakthroughs driven by AI methods. In this paper, I argue that the disconnect\nbetween philosophical pessimism and scientific optimism is driven by a failure\nto examine how AI is actually used in science. I show that, in order to\nunderstand the epistemic justification for AI-powered breakthroughs,\nphilosophers must examine the role played by deep learning as part of a wider\nprocess of discovery. The philosophical distinction between the 'context of\ndiscovery' and the 'context of justification' is helpful in this regard. I\ndemonstrate the importance of attending to this distinction with two cases\ndrawn from the scientific literature, and show that epistemic opacity need not\ndiminish AI's capacity to lead scientists to significant and justifiable\nbreakthroughs.",
    "descriptor": "\nComments: 12 pages, 1 figure\n",
    "authors": [
      "Eamon Duede"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.00520"
  },
  {
    "id": "arXiv:2206.00523",
    "title": "Frequency-domain analysis for reset systems using pulse-based model",
    "abstract": "In the precision motion industry, the demand for machines with higher speed,\naccuracy, and stability is rapidly increasing. Traditional linear controllers\nstruggle to meet these requirements due to fundamental limitations such as\nBode's gain-phase relationship and waterbed effects. Hence, non-linear\ncontrollers that can address these constraints are needed. Reset controllers\nare potential alternatives with the advantage of phase lead in comparison to\ntheir linear counterparts. However, reset controllers are incompatible with the\nloop-shaping analysis technique, since loop-shaping relies on the simple\nfirst-order element, whereas reset controllers include complex higher-order\nharmonics. Thus, the analysis and design of reset controllers remain\nbottlenecks in their way of widespread application. In this paper, a new\nanalytical technique for reset controllers is proposed to break the\nlimitations. A novel pulse-based model for analyzing general reset control\nsystems both in open-loop and closed-loop is developed, for the first time\nenabling loop-shaping implemented into the analysis of reset control systems\naccurately. Corresponding sensitivity functions are subsequently illustrated.\nFinally, through intuitive examples, the accuracy of the proposed model is\nevaluated.",
    "descriptor": "\nComments: 29 pages; 13 figures\n",
    "authors": [
      "Xinxin Zhang",
      "Marcin B Kaczmarek",
      "S. Hassan HosseinNia"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.00523"
  },
  {
    "id": "arXiv:2206.00524",
    "title": "Vietnamese Hate and Offensive Detection using PhoBERT-CNN and Social  Media Streaming Data",
    "abstract": "Society needs to develop a system to detect hate and offense to build a\nhealthy and safe environment. However, current research in this field still\nfaces four major shortcomings, including deficient pre-processing techniques,\nindifference to data imbalance issues, modest performance models, and lacking\npractical applications. This paper focused on developing an intelligent system\ncapable of addressing these shortcomings. Firstly, we proposed an efficient\npre-processing technique to clean comments collected from Vietnamese social\nmedia. Secondly, a novel hate speech detection (HSD) model, which is the\ncombination of a pre-trained PhoBERT model and a Text-CNN model, was proposed\nfor solving tasks in Vietnamese. Thirdly, EDA techniques are applied to deal\nwith imbalanced data to improve the performance of classification models.\nBesides, various experiments were conducted as baselines to compare and\ninvestigate the proposed model's performance against state-of-the-art methods.\nThe experiment results show that the proposed PhoBERT-CNN model outperforms\nSOTA methods and achieves an F1-score of 67,46% and 98,45% on two benchmark\ndatasets, ViHSD and HSD-VLSP, respectively. Finally, we also built a streaming\nHSD application to demonstrate the practicality of our proposed system.",
    "descriptor": "",
    "authors": [
      "Khanh Q. Tran",
      "An T. Nguyen",
      "Phu Gia Hoang",
      "Canh Duc Luu",
      "Trong-Hop Do",
      "Kiet Van Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00524"
  },
  {
    "id": "arXiv:2206.00525",
    "title": "Passive Beamforming Design for Reconfigurable Intelligent Surface  Enabled Integrated Sensing and Communication",
    "abstract": "To exploit the potential of the reconfigurable intelligent surface (RIS) in\nsupporting the future integrated sensing and communication (ISAC), this paper\nproposes a novel passive beamforming strategy for the RIS-enabled ISAC\n(RIS-ISAC) system in consideration of the target size. To this end, the\ndetection probability for target sensing is derived in closed-form based on the\nillumination power on an approximated scattering surface area (SSA) of the\ntarget, and a new concept of ultimate detection resolution (UDR) is defined for\nthe first time to measure the capability of the target detection. Subsequently,\nan optimization problem is formulated to maximize the signal-to-noise ratio\n(SNR) at the user-equipment (UE) under a minimum detection probability\nconstraint. To solve this problem, a novel convexification process is performed\nto convexify the detection probability constraint with matrix operations and a\nreal-valued first-order Taylor approximation. The semidefinite relaxation (SDR)\nis then adopted to relax the problem. A successive convex approximation (SCA)\nbased algorithm is finally designed to yield a phase-shift solution, followed\nby a detailed analysis on the problem feasibility condition as well as the\nalgorithm convergence. Our results reveal the inherent trade-offs between the\nsensing and the communication performances, and between the UDR and the\nduration of a sensing time slot. In comparison with two existing approaches,\nthe proposed strategy is validated to be superior when detecting targets with\npractical sizes.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Zhe Xing",
      "Rui Wang",
      "Xiaojun Yuan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.00525"
  },
  {
    "id": "arXiv:2206.00527",
    "title": "Amodal Cityscapes: A New Dataset, its Generation, and an Amodal Semantic  Segmentation Challenge Baseline",
    "abstract": "Amodal perception terms the ability of humans to imagine the entire shapes of\noccluded objects. This gives humans an advantage to keep track of everything\nthat is going on, especially in crowded situations. Typical perception\nfunctions, however, lack amodal perception abilities and are therefore at a\ndisadvantage in situations with occlusions. Complex urban driving scenarios\noften experience many different types of occlusions and, therefore, amodal\nperception for automated vehicles is an important task to investigate. In this\npaper, we consider the task of amodal semantic segmentation and propose a\ngeneric way to generate datasets to train amodal semantic segmentation methods.\nWe use this approach to generate an amodal Cityscapes dataset. Moreover, we\npropose and evaluate a method as baseline on Amodal Cityscapes, showing its\napplicability for amodal semantic segmentation in automotive environment\nperception. We provide the means to re-generate this dataset on github.",
    "descriptor": "\nComments: This paper is accepted at IEEE Intelligent Vehicles Symposium 2022\n",
    "authors": [
      "Jasmin Breitenstein",
      "Tim Fingscheidt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.00527"
  },
  {
    "id": "arXiv:2206.00528",
    "title": "Collaborative Bimanual Manipulation Using Optimal Motion Adaptation and  Interaction Control",
    "abstract": "This work developed collaborative bimanual manipulation for reliable and safe\nhuman-robot collaboration, which allows remote and local human operators to\nwork interactively for bimanual tasks. We proposed an optimal motion adaptation\nto retarget arbitrary commands from multiple human operators into feasible\ncontrol references. The collaborative manipulation framework has three main\nmodules: (1) contact force modulation for compliant physical interactions with\nobjects via admittance control; (2) task-space sequential equilibrium and\ninverse kinematics optimization, which adapts interactive commands from\nmultiple operators to feasible motions by satisfying the task constraints and\nphysical limits of the robots; and (3) an interaction controller adopted from\nthe fractal impedance control, which is robust to time delay and stable to\nsuperimpose multiple control efforts for generating desired joint torques and\ncontrolling the dual-arm robots. Extensive experiments demonstrated the\ncapability of the collaborative bimanual framework, including (1) dual-arm\nteleoperation that adapts arbitrary infeasible commands that violate joint\ntorque limits into continuous operations within safe boundaries, compared to\nfailures without the proposed optimization; (2) robust maneuver of a stack of\nobjects via physical interactions in presence of model inaccuracy; (3)\ncollaborative multi-operator part assembly, and teleoperated industrial\nconnector insertion, which validate the guaranteed stability of reliable\nhuman-robot co-manipulation.",
    "descriptor": "",
    "authors": [
      "Ruoshi Wen",
      "Quentin Rouxel",
      "Michael Mistry",
      "Zhibin Li",
      "Carlo Tiseo"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.00528"
  },
  {
    "id": "arXiv:2206.00529",
    "title": "Variance Reduction is an Antidote to Byzantines: Better Rates, Weaker  Assumptions and Communication Compression as a Cherry on the Top",
    "abstract": "Byzantine-robustness has been gaining a lot of attention due to the growth of\nthe interest in collaborative and federated learning. However, many fruitful\ndirections, such as the usage of variance reduction for achieving robustness\nand communication compression for reducing communication costs, remain weakly\nexplored in the field. This work addresses this gap and proposes Byz-VR-MARINA\n- a new Byzantine-tolerant method with variance reduction and compression. A\nkey message of our paper is that variance reduction is key to fighting\nByzantine workers more effectively. At the same time, communication compression\nis a bonus that makes the process more communication efficient. We derive\ntheoretical convergence guarantees for Byz-VR-MARINA outperforming previous\nstate-of-the-art for general non-convex and Polyak-Lojasiewicz loss functions.\nUnlike the concurrent Byzantine-robust methods with variance reduction and/or\ncompression, our complexity results are tight and do not rely on restrictive\nassumptions such as boundedness of the gradients or limited compression.\nMoreover, we provide the first analysis of a Byzantine-tolerant method\nsupporting non-uniform sampling of stochastic gradients. Numerical experiments\ncorroborate our theoretical findings.",
    "descriptor": "\nComments: 33 pages, 6 figures\n",
    "authors": [
      "Eduard Gorbunov",
      "Samuel Horv\u00e1th",
      "Peter Richt\u00e1rik",
      "Gauthier Gidel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.00529"
  },
  {
    "id": "arXiv:2206.00533",
    "title": "When happy accidents spark creativity: Bringing collaborative  speculation to life with generative AI",
    "abstract": "Generative AI techniques like those that synthesize images from text\n(text-to-image models) offer new possibilities for creatively imagining new\nideas. We investigate the capabilities of these models to help communities\nengage in conversations about their collective future. In particular, we design\nand deploy a facilitated experience where participants collaboratively\nspeculate on utopias they want to see, and then produce AI-generated imagery\nfrom those speculations. In a series of in-depth user interviews, we invite\nparticipants to reflect on the generated images and refine their visions for\nthe future. We synthesize findings with a bespoke community zine on the\nexperience. We observe that participants often generated ideas for implementing\ntheir vision and drew new lateral considerations as a result of viewing the\ngenerated images. Critically, we find that the unexpected difference between\nthe participant's imagined output and the generated image is what facilitated\nnew insight for the participant. We hope our experimental model for\nco-creation, computational creativity, and community reflection inspires the\nuse of generative models to help communities and organizations envision better\nfutures.",
    "descriptor": "",
    "authors": [
      "Ziv Epstein",
      "Hope Schroeder",
      "Dava Newman"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.00533"
  },
  {
    "id": "arXiv:2206.00535",
    "title": "Deepfake Caricatures: Amplifying attention to artifacts increases  deepfake detection by humans and machines",
    "abstract": "Deepfakes pose a serious threat to our digital society by fueling the spread\nof misinformation. It is essential to develop techniques that both detect them,\nand effectively alert the human user to their presence. Here, we introduce a\nnovel deepfake detection framework that meets both of these needs. Our approach\nlearns to generate attention maps of video artifacts, semi-supervised on human\nannotations. These maps make two contributions. First, they improve the\naccuracy and generalizability of a deepfake classifier, demonstrated across\nseveral deepfake detection datasets. Second, they allow us to generate an\nintuitive signal for the human user, in the form of \"Deepfake Caricatures\":\ntransformations of the original deepfake video where attended artifacts are\nexacerbated to improve human recognition. Our approach, based on a mixture of\nhuman and artificial supervision, aims to further the development of\ncountermeasures against fake visual content, and grants humans the ability to\nmake their own judgment when presented with dubious visual media.",
    "descriptor": "\nComments: 9 pages, 5 figures, 4 tables\n",
    "authors": [
      "Camilo Fosco",
      "Emilie Josephs",
      "Alex Andonian",
      "Allen Lee",
      "Xi Wang",
      "Aude Oliva"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.00535"
  },
  {
    "id": "arXiv:2206.00539",
    "title": "Privacy-Preserving Epidemiological Modeling on Mobile Graphs",
    "abstract": "Over the last two years, governments all over the world have used a variety\nof containment measures to control the spread of COVID-19, such as contact\ntracing, social distance regulations, and curfews. Epidemiological simulations\nare commonly used to assess the impact of those policies before they are\nimplemented in actuality. Unfortunately, their predictive accuracy is hampered\nby the scarcity of relevant empirical data, concretely detailed social contact\ngraphs. As this data is inherently privacy-critical, there is an urgent need\nfor a method to perform powerful epidemiological simulations on real-world\ncontact graphs without disclosing sensitive information. In this work, we\npresent RIPPLE, a privacy-preserving epidemiological modeling framework that\nenables the execution of a wide range of standard epidemiological models for\nany infectious disease on a population's most recent real contact graph while\nkeeping all contact information private locally on the participants' devices.\nIn this regard, we also present PIR-SUM, a novel extension to private\ninformation retrieval that allows users to securely download the sum of a set\nof elements from a database rather than individual elements. Our theoretical\nconstructs are supported by a proof-of-concept implementation in which we show\nthat a 2-week simulation over a population of half a million can be finished in\n7 minutes with each participant consuming less than 50 KB of data.",
    "descriptor": "",
    "authors": [
      "Daniel G\u00fcnther",
      "Marco Holz",
      "Benjamin Judkewitz",
      "Helen M\u00f6llering",
      "Benny Pinkas",
      "Thomas Schneider",
      "Ajith Suresh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.00539"
  },
  {
    "id": "arXiv:2206.00542",
    "title": "Multi-Contact Motion Retargeting using Whole-body Optimization of Full  Kinematics and Sequential Force Equilibrium",
    "abstract": "This paper presents a multi-contact motion adaptation framework that enables\nteleoperation of high degree-of-freedom (DoF) robots, such as quadrupeds and\nhumanoids, for loco-manipulation tasks in multi-contact settings. Our proposed\nalgorithms optimize whole-body configurations and formulate the retargeting of\nmulti-contact motions as sequential quadratic programming, which is robust and\nstable near the edges of feasibility constraints. Our framework allows\nreal-time operation of the robot and reduces cognitive load for the operator\nbecause infeasible commands are automatically adapted into physically stable\nand viable motions on the robot. The results in simulations with full dynamics\ndemonstrated the effectiveness of teleoperating different legged robots\ninteractively and generating rich multi-contact movements. We evaluated the\ncomputational efficiency of the proposed algorithms, and further validated and\nanalyzed multi-contact loco-manipulation tasks on humanoid and quadruped robots\nby reaching, active pushing and various traversal on uneven terrains.",
    "descriptor": "",
    "authors": [
      "Quentin Rouxel",
      "Kai Yuan",
      "Ruoshi Wen",
      "Zhibin Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.00542"
  },
  {
    "id": "arXiv:2206.00550",
    "title": "A Normal Form for Matrix Multiplication Schemes",
    "abstract": "Schemes for exact multiplication of small matrices have a large symmetry\ngroup. This group defines an equivalence relation on the set of multiplication\nschemes. There are algorithms to decide whether two schemes are equivalent.\nHowever, for a large number of schemes a pairwise equivalence check becomes\ncumbersome. In this paper we propose an algorithm to compute a normal form of\nmatrix multiplication schemes. This allows us to decide pairwise equivalence of\na larger number of schemes efficiently.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Manuel Kauers",
      "Jakob Moosbauer"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2206.00550"
  },
  {
    "id": "arXiv:2206.00553",
    "title": "FETA: Fairness Enforced Verifying, Training, and Predicting Algorithms  for Neural Networks",
    "abstract": "Algorithmic decision making driven by neural networks has become very\nprominent in applications that directly affect people's quality of life. In\nthis paper, we study the problem of verifying, training, and guaranteeing\nindividual fairness of neural network models. A popular approach for enforcing\nfairness is to translate a fairness notion into constraints over the parameters\nof the model. However, such a translation does not always guarantee fair\npredictions of the trained neural network model. To address this challenge, we\ndevelop a counterexample-guided post-processing technique to provably enforce\nfairness constraints at prediction time. Contrary to prior work that enforces\nfairness only on points around test or train data, we are able to enforce and\nguarantee fairness on all points in the input domain. Additionally, we propose\nan in-processing technique to use fairness as an inductive bias by iteratively\nincorporating fairness counterexamples in the learning process. We have\nimplemented these techniques in a tool called FETA. Empirical evaluation on\nreal-world datasets indicates that FETA is not only able to guarantee fairness\non-the-fly at prediction time but also is able to train accurate models\nexhibiting a much higher degree of individual fairness.",
    "descriptor": "",
    "authors": [
      "Kiarash Mohammadi",
      "Aishwarya Sivaraman",
      "Golnoosh Farnadi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.00553"
  },
  {
    "id": "arXiv:2206.00557",
    "title": "A Near-Optimal Best-of-Both-Worlds Algorithm for Online Learning with  Feedback Graphs",
    "abstract": "We consider online learning with feedback graphs, a sequential\ndecision-making framework where the learner's feedback is determined by a\ndirected graph over the action set. We present a computationally efficient\nalgorithm for learning in this framework that simultaneously achieves\nnear-optimal regret bounds in both stochastic and adversarial environments. The\nbound against oblivious adversaries is $\\tilde{O} (\\sqrt{\\alpha T})$, where $T$\nis the time horizon and $\\alpha$ is the independence number of the feedback\ngraph. The bound against stochastic environments is $O\\big( (\\ln T)^2\n\\max_{S\\in \\mathcal I(G)} \\sum_{i \\in S} \\Delta_i^{-1}\\big)$ where $\\mathcal\nI(G)$ is the family of all independent sets in a suitably defined undirected\nversion of the graph and $\\Delta_i$ are the suboptimality gaps. The algorithm\ncombines ideas from the EXP3++ algorithm for stochastic and adversarial bandits\nand the EXP3.G algorithm for feedback graphs with a novel exploration scheme.\nThe scheme, which exploits the structure of the graph to reduce exploration, is\nkey to obtain best-of-both-worlds guarantees with feedback graphs. We also\nextend our algorithm and results to a setting where the feedback graphs are\nallowed to change over time.",
    "descriptor": "",
    "authors": [
      "Chlo\u00e9 Rouyer",
      "Dirk van der Hoeven",
      "Nicol\u00f2 Cesa-Bianchi",
      "Yevgeny Seldin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00557"
  },
  {
    "id": "arXiv:2206.00559",
    "title": "Learning to Sequence and Blend Robot Skills via Differentiable  Optimization",
    "abstract": "In contrast to humans and animals who naturally execute seamless motions,\nlearning and smoothly executing sequences of actions remains a challenge in\nrobotics. This paper introduces a novel skill-agnostic framework that learns to\nsequence and blend skills based on differentiable optimization. Our approach\nencodes sequences of previously-defined skills as quadratic programs (QP),\nwhose parameters determine the relative importance of skills along the task.\nSeamless skill sequences are then learned from demonstrations by exploiting\ndifferentiable optimization layers and a tailored loss formulated from the QP\noptimality conditions. Via the use of differentiable optimization, our work\noffers novel perspectives on multitask control. We validate our approach in a\npick-and-place scenario with planar robots, a pouring experiment with a real\nhumanoid robot, and a bimanual sweeping task with a human model.",
    "descriptor": "\nComments: Accepted for publication in IEEE Robotics and Automation Letters. Video: this https URL, code: this https URL\n",
    "authors": [
      "No\u00e9mie Jaquier",
      "You Zhou",
      "Julia Starke",
      "Tamim Asfour"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.00559"
  },
  {
    "id": "arXiv:2206.00564",
    "title": "Exploring Diversity in Back Translation for Low-Resource Machine  Translation",
    "abstract": "Back translation is one of the most widely used methods for improving the\nperformance of neural machine translation systems. Recent research has sought\nto enhance the effectiveness of this method by increasing the 'diversity' of\nthe generated translations. We argue that the definitions and metrics used to\nquantify 'diversity' in previous work have been insufficient. This work puts\nforward a more nuanced framework for understanding diversity in training data,\nsplitting it into lexical diversity and syntactic diversity. We present novel\nmetrics for measuring these different aspects of diversity and carry out\nempirical analysis into the effect of these types of diversity on final neural\nmachine translation model performance for low-resource\nEnglish$\\leftrightarrow$Turkish and mid-resource\nEnglish$\\leftrightarrow$Icelandic. Our findings show that generating back\ntranslation using nucleus sampling results in higher final model performance,\nand that this method of generation has high levels of both lexical and\nsyntactic diversity. We also find evidence that lexical diversity is more\nimportant than syntactic for back translation performance.",
    "descriptor": "",
    "authors": [
      "Laurie Burchell",
      "Alexandra Birch",
      "Kenneth Heafield"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.00564"
  },
  {
    "id": "arXiv:2206.00568",
    "title": "RMT-Net: Reject-aware Multi-Task Network for Modeling  Missing-not-at-random Data in Financial Credit Scoring",
    "abstract": "In financial credit scoring, loan applications may be approved or rejected.\nWe can only observe default/non-default labels for approved samples but have no\nobservations for rejected samples, which leads to missing-not-at-random\nselection bias. Machine learning models trained on such biased data are\ninevitably unreliable. In this work, we find that the default/non-default\nclassification task and the rejection/approval classification task are highly\ncorrelated, according to both real-world data study and theoretical analysis.\nConsequently, the learning of default/non-default can benefit from\nrejection/approval. Accordingly, we for the first time propose to model the\nbiased credit scoring data with Multi-Task Learning (MTL). Specifically, we\npropose a novel Reject-aware Multi-Task Network (RMT-Net), which learns the\ntask weights that control the information sharing from the rejection/approval\ntask to the default/non-default task by a gating network based on rejection\nprobabilities. RMT-Net leverages the relation between the two tasks that the\nlarger the rejection probability, the more the default/non-default task needs\nto learn from the rejection/approval task. Furthermore, we extend RMT-Net to\nRMT-Net++ for modeling scenarios with multiple rejection/approval strategies.\nExtensive experiments are conducted on several datasets, and strongly verifies\nthe effectiveness of RMT-Net on both approved and rejected samples. In\naddition, RMT-Net++ further improves RMT-Net's performances.",
    "descriptor": "\nComments: Accepted by IEEE TKDE\n",
    "authors": [
      "Qiang Liu",
      "Yingtao Luo",
      "Shu Wu",
      "Zhen Zhang",
      "Xiangnan Yue",
      "Hong Jin",
      "Liang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistical Finance (q-fin.ST)"
    ],
    "url": "https://arxiv.org/abs/2206.00568"
  },
  {
    "id": "arXiv:2206.00580",
    "title": "Dog nose print matching with dual global descriptor based on Contrastive  Learning",
    "abstract": "Recent studies in biometric-based identification tasks have shown that deep\nlearning methods can achieve better performance. These methods generally\nextract the global features as descriptor to represent the original image.\nNonetheless, it does not perform well for biometric identification under\nfine-grained tasks. The main reason is that the single image descriptor\ncontains insufficient information to represent image. In this paper, we present\na dual global descriptor model, which combines multiple global descriptors to\nexploit multi level image features. Moreover, we utilize a contrastive loss to\nenlarge the distance between image representations of confusing classes. The\nproposed framework achieves the top2 on the CVPR2022 Biometrics Workshop Pet\nBiometric Challenge. The source code and trained models are publicly available\nat: https://github.com/flyingsheepbin/pet-biometrics",
    "descriptor": "",
    "authors": [
      "Bin Li",
      "Zhongan Wang",
      "Nan Wu",
      "Shuai Shi",
      "Qijun Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.00580"
  },
  {
    "id": "arXiv:2206.00582",
    "title": "The elements of flexibility for task-performing systems",
    "abstract": "What makes living systems flexible so that they can react quickly and adapt\neasily to changingenvironments? In this paper, we consider how the design of\nliving systems promotes flexibility andpresent a research perspective how these\ninsights can contribute to the realization of a \"batch size one\" production\nregime based on cyber-physical production systems. To this end, we introduce\nthe concept of task-performing systems and a unifying formalism to formulate\nand study flexibilityproblems for task-performing systems appearing in\nproduction engineering, machine learning or the life sciences. Moreover, we\ngive an overview of the elements of flexibility which are six design features\nthat promote flexibility on many levels of biological organization in living\nsystems.",
    "descriptor": "",
    "authors": [
      "Sebastian Mayer",
      "Leo Francoso Dal Piccol Sotto",
      "Jochen Garcke"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.00582"
  },
  {
    "id": "arXiv:2206.00583",
    "title": "Calibrate and Debias Layer-wise Sampling for Graph Convolutional  Networks",
    "abstract": "To accelerate the training of graph convolutional networks (GCNs), many\nsampling-based methods have been developed for approximating the embedding\naggregation. Among them, a layer-wise approach recursively performs importance\nsampling to select neighbors jointly for existing nodes in each layer. This\npaper revisits the approach from a matrix approximation perspective. We\nidentify two issues in the existing layer-wise sampling methods: sub-optimal\nsampling probabilities and the approximation bias induced by sampling without\nreplacement. We propose two remedies: new sampling probabilities and a\ndebiasing algorithm, to address these issues, and provide the statistical\nanalysis of the estimation variance. The improvements are demonstrated by\nextensive analyses and experiments on common benchmarks.",
    "descriptor": "",
    "authors": [
      "Yifan Chen",
      "Tianning Xu",
      "Dilek Hakkani-Tur",
      "Di Jin",
      "Yun Yang",
      "Ruoqing Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00583"
  },
  {
    "id": "arXiv:2206.00585",
    "title": "Convergence rates of individual Ritz values in block preconditioned  gradient-type eigensolvers",
    "abstract": "Many popular eigensolvers for large and sparse Hermitian matrices or matrix\npairs can be interpreted as accelerated block preconditioned gradient (BPG)\niterations in order to analyze their convergence behavior by composing known\nestimates. An important feature of BPG is the cluster robustness, i.e.,\nreasonable performance for computing clustered eigenvalues is ensured by a\nsufficiently large block size. This feature can easily be explained for\nexact-inverse (exact shift-inverse) preconditioning by adapting classical\nestimates on nonpreconditioned eigensolvers, whereas the existing results for\nmore general preconditioning are still improvable. We expect to extend certain\nsharp estimates for the corresponding vector iterations to BPG where proper\nbounds of convergence rates of individual Ritz values are to be derived. Such\nan extension has been achieved for BPG with fixed step sizes in [Math. Comp. 88\n(2019), 2737--2765]. The present paper deals with the more practical case that\nthe step sizes are implicitly optimized by the Rayleigh-Ritz method. Our new\nestimates improve some previous ones in view of concise and more flexible\nbounds.",
    "descriptor": "\nComments: 21 pages, 4 figures\n",
    "authors": [
      "Ming Zhou",
      "Klaus Neymeyr"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.00585"
  },
  {
    "id": "arXiv:2206.00586",
    "title": "Multi-Armed Bandit Problem with Temporally-Partitioned Rewards: When  Partial Feedback Counts",
    "abstract": "There is a rising interest in industrial online applications where data\nbecomes available sequentially. Inspired by the recommendation of playlists to\nusers where their preferences can be collected during the listening of the\nentire playlist, we study a novel bandit setting, namely Multi-Armed Bandit\nwith Temporally-Partitioned Rewards (TP-MAB), in which the stochastic reward\nassociated with the pull of an arm is partitioned over a finite number of\nconsecutive rounds following the pull. This setting, unexplored so far to the\nbest of our knowledge, is a natural extension of delayed-feedback bandits to\nthe case in which rewards may be dilated over a finite-time span after the pull\ninstead of being fully disclosed in a single, potentially delayed round. We\nprovide two algorithms to address TP-MAB problems, namely, TP-UCB-FR and\nTP-UCB-EW, which exploit the partial information disclosed by the reward\ncollected over time. We show that our algorithms provide better asymptotical\nregret upper bounds than delayed-feedback bandit algorithms when a property\ncharacterizing a broad set of reward structures of practical interest, namely\nalpha-smoothness, holds. We also empirically evaluate their performance across\na wide range of settings, both synthetically generated and from a real-world\nmedia recommendation problem.",
    "descriptor": "",
    "authors": [
      "Giulia Romano",
      "Andrea Agostini",
      "Francesco Trov\u00f2",
      "Nicola Gatti",
      "Marcello Restelli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.00586"
  },
  {
    "id": "arXiv:2206.00587",
    "title": "A Geometry-Sensitive Quorum Sensing Algorithm for the Best-of-N Site  Selection Problem",
    "abstract": "The house hunting behavior of the Temnothorax albipennis ant allows the\ncolony to explore several nest choices and agree on the best one. Their\nbehavior serves as the basis for many bio-inspired swarm models to solve the\nsame problem. However, many of the existing site selection models in both\ninsect colony and swarm literature test the model's accuracy and decision time\nonly on setups where all potential site choices are equidistant from the\nswarm's starting location. These models do not account for the geographic\nchallenges that result from site choices with different geometry. For example,\nalthough actual ant colonies are capable of consistently choosing a higher\nquality, further site instead of a lower quality, closer site, existing models\nare much less accurate in this scenario. Existing models are also more prone to\ncommitting to a low quality site if it is on the path between the agents'\nstarting site and a higher quality site. We present a new model for the site\nselection problem and verify via simulation that is able to better handle these\ngeographic challenges. Our results provide insight into the types of challenges\nsite selection models face when distance is taken into account. Our work will\nallow swarms to be robust to more realistic situations where sites could be\ndistributed in the environment in many different ways.",
    "descriptor": "\nComments: 17 pages, 4 figures, submitted to ANTS 2022\n",
    "authors": [
      "Grace Cai",
      "Nancy Lynch"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2206.00587"
  },
  {
    "id": "arXiv:2206.00588",
    "title": "VTOL Failure Detection and Recovery by Utilizing Redundancy",
    "abstract": "Offering vertical take-off and landing (VTOL) capabilities and the ability to\ntravel great distances are crucial for Urban Air Mobility (UAM) vehicles. These\ncapabilities make hybrid VTOLs the clear front-runners among UAM platforms. On\nthe other hand, concerns regarding the safety and reliability of autonomous\naircraft have grown in response to the recent growth in aerial vehicle usage.\nAs a result, monitoring the aircraft status to report any failures and\nrecovering to prevent the loss of control when a failure happens are becoming\nincreasingly important. Hybrid VTOLs can withstand some degree of actuator\nfailure due to their intrinsic redundancy. Their aerodynamic performance,\ndesign, modeling, and control have all been addressed in the previous studies.\nHowever, research on their potential fault tolerance is still a less\ninvestigated field. In this workshop, we will present a summary of our work on\naircraft fault detection and the recovery of our hybrid VTOL. First, we will go\nover our real-time aircraft-independent system for detecting actuator failures\nand abnormal behaviors. Then, in the context of our custom tiltrotor VTOL\naircraft design, we talk about our optimization-based control allocation\nsystem, which utilizes the vehicle's configuration redundancy to recover from\ndifferent actuation failures. Finally, we explore the ideas of how these parts\ncan work together to provide a fail-safe system. We present our simulation and\nreal-life experiments.",
    "descriptor": "",
    "authors": [
      "Mohammadreza Mousaei",
      "Azarakhsh Keipour",
      "Junyi Geng",
      "Sebastian Scherer"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.00588"
  },
  {
    "id": "arXiv:2206.00592",
    "title": "Stopping Silent Sneaks: Defending against Malicious Mixes with  Topological Engineering",
    "abstract": "Mixnets are a fundamental type of anonymous communication system and recent\nacademic research has made progress in designing Mixnets that are scalable,\nhave sustainable communication/computation overhead, and/or provable security.\nWe focus our work on stratified Mixnets, a popular design with real-world\nadoption. The security of many designs rely on the anytrust assumption where at\nleast one server in the user's path must be honest. We identify the critical\nrole Mixnet topological configuration algorithms play for user anonymity, and\npropose Bow-Tie, a performant topological engineering design for Mixnets that\nfurther ensures the anytrust assumption holds realized by introducing guard\nmixes. To draw actionable conclusions, we perform an analysis of the best\nrealistic and resource-bounded adversarial strategies against each of the\nstudied algorithms, and evaluate security metrics against each best adversarial\nstrategy. Moreover, we highlight the need for a temporal security analysis and\ndevelop routesim, a simulator to evaluate the effect of temporal dynamics and\nuser behaviors over the Mixnet. The resulting security notions are\ncomplementary to the state-of-the-art entropic definitions. The simulator is\ndesigned to help Mixnets developers in assessing the devil in the details\nresulting from design decisions. Ultimately, our results suggest strong\npotential improvements to current designs and guidance for shaping Mix\nnetworks.",
    "descriptor": "",
    "authors": [
      "Xinshu Ma",
      "Florentin Rochet",
      "Tariq Elahi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.00592"
  },
  {
    "id": "arXiv:2206.00595",
    "title": "Logic-Based Ethical Planning",
    "abstract": "In this paper we propose a framework for ethical decision making in the\ncontext of planning, with intended application to robotics. We put forward a\ncompact but highly expressive language for ethical planning that combines\nlinear temporal logic with lexicographic preference modelling. This original\ncombination allows us to assess plans both with respect to an agent's values\nand their desires, introducing the novel concept of the morality level of an\nagent and moving towards multigoal, multivalue planning. We initiate the study\nof computational complexity of planning tasks in our setting, and we discuss\npotential applications to robotics.",
    "descriptor": "",
    "authors": [
      "Umberto Grandi",
      "Emiliano Lorini",
      "Timothy Parker",
      "Rachid Alami"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.00595"
  },
  {
    "id": "arXiv:2206.00597",
    "title": "Post-Disaster Repair Crew Assignment Optimization Using Minimum Latency",
    "abstract": "Across infrastructure domains, physical damage caused by storms and other\nweather events often requires costly and time-sensitive repairs to restore\nservices as quickly as possible. While previous studies have used agent-based\nmodels to estimate the cost of the repairs, the implemented strategies for\nassignment of repair crews to different locations are generally human-driven or\nbased on simple rules. In order to find performant strategies, we model this\nproblem as a combinational optimization problem known as the Minimum Weighted\nLatency Problem (MWLP) for $m$ repair crews. We apply a partitioning algorithm\nthat balances assigning targets amongst all the crews using two different\nheuristics that optimize either the importance of repair locations or the\ntravel time between them. We benchmark our algorithm on both randomly generated\ngraphs as well as data derived from a real-world urban environment, and show\nthat our algorithm delivers significantly better assignments than existing\nmethods.",
    "descriptor": "\nComments: 7 pages, 5 figures\n",
    "authors": [
      "Anakin Dey",
      "Melkior Ornik"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2206.00597"
  },
  {
    "id": "arXiv:2206.00599",
    "title": "Cooling Down FaaS: Towards Getting Rid of Warm Starts",
    "abstract": "Serverless execution and most notably the Function as a Service (FaaS) model\ngot quite some attention during the recent years. As of today, all commercial\nand open source implementations follow the common practice of keeping the\nexecution environments running to achieve low function execution latency. In\nthis paper we compare the startup latency of different available virtualization\ntechnologies, then we implement and benchmark an FaaS prototype system using\nIncludeOS unikernels for function execution. We show that our system can start\nand execute functions with essentially the same latency as AWS Lambda with its\ncontinuously running executor units. Due to the low overhead, this approach\nopens the possibility for simplified FaaS platforms without the resource waste\nand extensive monitoring requirements of existing solutions.",
    "descriptor": "",
    "authors": [
      "D\u00e1niel G\u00e9hberger",
      "D\u00e1vid Kov\u00e1cs"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2206.00599"
  },
  {
    "id": "arXiv:2206.00606",
    "title": "Higher-Order Attention Networks",
    "abstract": "This paper introduces higher-order attention networks (HOANs), a novel class\nof attention-based neural networks defined on a generalized higher-order domain\ncalled a combinatorial complex (CC). Similar to hypergraphs, CCs admit\narbitrary set-like relations between a collection of abstract entities.\nSimultaneously, CCs permit the construction of hierarchical higher-order\nrelations analogous to those supported by cell complexes. Thus, CCs effectively\ngeneralize both hypergraphs and cell complexes and combine their desirable\ncharacteristics. By exploiting the rich combinatorial nature of CCs, HOANs\ndefine a new class of message-passing attention-based networks that unifies\nhigher-order neural networks. Our evaluation on tasks related to mesh shape\nanalysis and graph learning demonstrates that HOANs attain competitive, and in\nsome examples superior, predictive performance in comparison to\nstate-of-the-art neural networks.",
    "descriptor": "",
    "authors": [
      "Mustafa Hajij",
      "Ghada Zamzmi",
      "Theodore Papamarkou",
      "Nina Miolane",
      "Aldo Guzm\u00e1n-S\u00e1enz",
      "Karthikeyan Natesan Ramamurthy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Social and Information Networks (cs.SI)",
      "Algebraic Topology (math.AT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.00606"
  },
  {
    "id": "arXiv:2206.00607",
    "title": "Performance Study of Low Inertia Magnetorheological Actuators for  Kinesthetic Haptic Devices",
    "abstract": "A challenge to high quality virtual reality (VR) simulations is the\ndevelopment of high-fidelity haptic devices that can render a wide range of\nimpedances at both low and high frequencies. To this end, a thorough analytical\nand experimental assessment of the performance of magnetorheological (MR)\nactuators is performed and compared to electric motor (EM) actuation. A 2\ndegrees-of-freedom dynamic model of a kinesthetic haptic device is used to\nconduct the analytical study comparing the rendering area, rendering bandwidth,\ngearing and scaling of both technologies. Simulation predictions are\ncorroborated by experimental validation over a wide range of operating\nconditions. Results show that, for a same output force, MR actuators can render\na bandwidth over 52.9% higher than electric motors due to their low inertia.\nUnlike electric motors, the performance of MR actuators for use in haptic\ndevices are not limited by their output inertia but by their viscous damping,\nwhich must be carefully addressed at the design stage.",
    "descriptor": "",
    "authors": [
      "Louis-Philippe Lebel",
      "Jean-Alexis Verreault",
      "Jean-Philippe Lucking Bigu\u00e9",
      "Jean-S\u00e9bastien Plante",
      "Alexandre Girard"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.00607"
  },
  {
    "id": "arXiv:2206.00608",
    "title": "On the Choice of Data for Efficient Training and Validation of  End-to-End Driving Models",
    "abstract": "The emergence of data-driven machine learning (ML) has facilitated\nsignificant progress in many complicated tasks such as highly-automated\ndriving. While much effort is put into improving the ML models and learning\nalgorithms in such applications, little focus is put into how the training data\nand/or validation setting should be designed. In this paper we investigate the\ninfluence of several data design choices regarding training and validation of\ndeep driving models trainable in an end-to-end fashion. Specifically, (i) we\ninvestigate how the amount of training data influences the final driving\nperformance, and which performance limitations are induced through currently\nused mechanisms to generate training data. (ii) Further, we show by correlation\nanalysis, which validation design enables the driving performance measured\nduring validation to generalize well to unknown test environments. (iii)\nFinally, we investigate the effect of random seeding and non-determinism,\ngiving insights which reported improvements can be deemed significant. Our\nevaluations using the popular CARLA simulator provide recommendations regarding\ndata generation and driving route selection for an efficient future development\nof end-to-end driving models.",
    "descriptor": "\nComments: Accepted at CVPR VDU Workshop 2022\n",
    "authors": [
      "Marvin Klingner",
      "Konstantin M\u00fcller",
      "Mona Mirzaie",
      "Jasmin Breitenstein",
      "Jan-Aike Term\u00f6hlen",
      "Tim Fingscheidt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.00608"
  },
  {
    "id": "arXiv:2206.00614",
    "title": "Dual-stream spatiotemporal networks with feature sharing for monitoring  animals in the home cage",
    "abstract": "This paper presents a spatiotemporal deep learning approach for mouse\nbehavioural classification in the home cage. Using a series of dual-stream\narchitectures with assorted modifications to increase performance, we introduce\na novel feature-sharing approach that jointly processes the streams at regular\nintervals throughout the network. Using a publicly available labelled dataset\nof singly-housed mice, we achieve a prediction accuracy of 86.47% using an\nensemble of Inception-based networks that utilize feature sharing. We also\ndemonstrate through ablation studies that for all models, the feature-sharing\narchitectures consistently perform better than conventional ones having\nseparate streams. The best performing models were further evaluated on other\nactivity datasets, both mouse and human, and achieved state-of-the-art results.\nFuture work will investigate the effectiveness of feature sharing in\nbehavioural classification in the unsupervised anomaly detection domain.",
    "descriptor": "",
    "authors": [
      "Ezechukwu I. Nwokedi",
      "Rasneer S. Bains",
      "Luc Bidaut",
      "Xujiong Ye",
      "Sara Wells",
      "James M. Brown"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.00614"
  },
  {
    "id": "arXiv:2206.00619",
    "title": "Graph Machine Learning for Design of High-Octane Fuels",
    "abstract": "Fuels with high-knock resistance enable modern spark-ignition engines to\nachieve high efficiency and thus low CO2 emissions. Identification of molecules\nwith desired autoignition properties indicated by a high research octane number\nand a high octane sensitivity is therefore of great practical relevance and can\nbe supported by computer-aided molecular design (CAMD). Recent developments in\nthe field of graph machine learning (graph-ML) provide novel, promising tools\nfor CAMD. We propose a modular graph-ML CAMD framework that integrates\ngenerative graph-ML models with graph neural networks and optimization,\nenabling the design of molecules with desired ignition properties in a\ncontinuous molecular space. In particular, we explore the potential of Bayesian\noptimization and genetic algorithms in combination with generative graph-ML\nmodels. The graph-ML CAMD framework successfully identifies well-established\nhigh-octane components. It also suggests new candidates, one of which we\nexperimentally investigate and use to illustrate the need for further\nauto-ignition training data.",
    "descriptor": "\nComments: manuscript (24 pages, 9 figures, 2 tables), supporting information (12 pages, 8 figures, 1 table)\n",
    "authors": [
      "Jan G. Rittig",
      "Martin Ritzert",
      "Artur M. Schweidtmann",
      "Stefanie Winkler",
      "Jana M. Weber",
      "Philipp Morsch",
      "K. Alexander Heufer",
      "Martin Grohe",
      "Alexander Mitsos",
      "Manuel Dahmen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00619"
  },
  {
    "id": "arXiv:2206.00621",
    "title": "Cross-View Language Modeling: Towards Unified Cross-Lingual Cross-Modal  Pre-training",
    "abstract": "In this paper, we introduce Cross-View Language Modeling, a simple and\neffective language model pre-training framework that unifies cross-lingual\ncross-modal pre-training with shared architectures and objectives. Our approach\nis motivated by a key observation that cross-lingual and cross-modal\npre-training share the same goal of aligning two different views of the same\nobject into a common semantic space. To this end, the cross-view language\nmodeling framework considers both multi-modal data (i.e., image-caption pairs)\nand multi-lingual data (i.e., parallel sentence pairs) as two different views\nof the same object, and trains the model to align the two views by maximizing\nthe mutual information between them with conditional masked language modeling\nand contrastive learning. We pre-train CCLM, a Cross-lingual Cross-modal\nLanguage Model, with the cross-view language modeling framework. Empirical\nresults on IGLUE, a multi-lingual multi-modal benchmark, and two multi-lingual\nimage-text retrieval datasets show that while conceptually simpler, CCLM\nsignificantly outperforms the prior state-of-the-art with an average absolute\nimprovement of over 10%. Notably, CCLM is the first multi-lingual multi-modal\nmodel that surpasses the translate-test performance of representative English\nvision-language models by zero-shot cross-lingual transfer.",
    "descriptor": "\nComments: 19 pages, 3 figures\n",
    "authors": [
      "Yan Zeng",
      "Wangchunshu Zhou",
      "Ao Luo",
      "Xinsong Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00621"
  },
  {
    "id": "arXiv:2206.00623",
    "title": "P4DB -- The Case for In-Network OLTP (Extended Technical Report)",
    "abstract": "In this paper we present a new approach for distributed DBMSs called P4DB,\nthat uses a programmable switch to accelerate OLTP workloads. The main idea of\nP4DB is that it implements a transaction processing engine on top of a\nP4-programmable switch. The switch can thus act as an accelerator in the\nnetwork, especially when it is used to store and process hot (contended) tuples\non the switch. In our experiments, we show that P4DB hence provides significant\nbenefits compared to traditional DBMS architectures and can achieve a speedup\nof up to 8x.",
    "descriptor": "\nComments: Extended Technical Report for: P4DB - The Case for In-Network OLTP\n",
    "authors": [
      "Matthias Jasny",
      "Lasse Thostrup",
      "Tobias Ziegler",
      "Carsten Binnig"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2206.00623"
  },
  {
    "id": "arXiv:2206.00626",
    "title": "Regular Convergence and Finite Element Methods for Eigenvalue Problems",
    "abstract": "Regular convergence, together with various other types of convergence, has\nbeen studied since the 1970s for the discrete approximations of linear\noperators. In this paper, we consider the eigenvalue approximation of compact\noperators whose spectral problem is equivalent to the eigenvalue problem of\nsome holomophic Fredholm operator function. Focusing on the finite element\nmethods (conforming, non-conforming, discontinuous Galerkin, etc.), we show\nthat the regular convergence of discrete holomorphic operator functions follows\nfrom the approximation property of the finite element spaces and the point\nconvergence of the discrete operators in a suitable Sobolev space. The\nconvergence for eigenvalues is then obtained using the discrete approximation\ntheory for the eigenvalue problems of holomorphic Fredholm operator functions.\nThe result can be used to show the convergence of many finite element methods\nfor eigenvalue problems such as the Dirhcilet eigenvalue problem and the\nbiharmonic eigenvalue problem.",
    "descriptor": "",
    "authors": [
      "Jiguang Sun"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.00626"
  },
  {
    "id": "arXiv:2206.00629",
    "title": "CLIP4IDC: CLIP for Image Difference Captioning",
    "abstract": "Image Difference Captioning (IDC) aims at generating sentences to describe\nthe differences between two similar-looking images. The conventional approaches\nlearn captioning models on the offline-extracted visual features and the\nlearning can not be propagated back to the fixed feature extractors pre-trained\non image classification datasets. Accordingly, potential improvements can be\nmade by fine-tuning the visual features for: 1) narrowing the gap when\ngeneralizing the visual extractor trained on image classification to IDC, and\n2) relating the extracted visual features to the descriptions of the\ncorresponding changes. We thus propose CLIP4IDC to transfer a CLIP model for\nthe IDC task to attain these improvements. Different from directly fine-tuning\nCLIP to generate sentences, a task-specific domain adaptation is used to\nimprove the extracted features. Specifically, the target is to train CLIP on\nraw pixels to relate the image pairs to the described changes. Afterwards, a\nvanilla Transformer is trained for IDC on the features extracted by the vision\nencoder of CLIP. Experiments on three IDC benchmark datasets, CLEVR-Change,\nSpot-the-Diff and Image-Editing-Request, demonstrate the effectiveness of\nCLIP4IDC. Our code and models will be released at\nhttps://github.com/sushizixin/CLIP4IDC.",
    "descriptor": "\nComments: Accepted at the Transformers for Vision (T4V) workshop at CVPR 2022\n",
    "authors": [
      "Zixin Guo",
      "Tzu-Jui Julius Wang",
      "Jorma Laaksonen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.00629"
  },
  {
    "id": "arXiv:2206.00630",
    "title": "Unifying Voxel-based Representation with Transformer for 3D Object  Detection",
    "abstract": "In this work, we present a unified framework for multi-modality 3D object\ndetection, named UVTR. The proposed method aims to unify multi-modality\nrepresentations in the voxel space for accurate and robust single- or\ncross-modality 3D detection. To this end, the modality-specific space is first\ndesigned to represent different inputs in the voxel feature space. Different\nfrom previous work, our approach preserves the voxel space without height\ncompression to alleviate semantic ambiguity and enable spatial interactions.\nBenefit from the unified manner, cross-modality interaction is then proposed to\nmake full use of inherent properties from different sensors, including\nknowledge transfer and modality fusion. In this way, geometry-aware expressions\nin point clouds and context-rich features in images are well utilized for\nbetter performance and robustness. The transformer decoder is applied to\nefficiently sample features from the unified space with learnable positions,\nwhich facilitates object-level interactions. In general, UVTR presents an early\nattempt to represent different modalities in a unified framework. It surpasses\nprevious work in single- and multi-modality entries and achieves leading\nperformance in the nuScenes test set with 69.7%, 55.1%, and 71.1% NDS for\nLiDAR, camera, and multi-modality inputs, respectively. Code is made available\nat https://github.com/dvlab-research/UVTR.",
    "descriptor": "\nComments: Code is available at this https URL\n",
    "authors": [
      "Yanwei Li",
      "Yilun Chen",
      "Xiaojuan Qi",
      "Zeming Li",
      "Jian Sun",
      "Jiaya Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.00630"
  },
  {
    "id": "arXiv:2206.00635",
    "title": "Speech Artifact Removal from EEG Recordings of Spoken Word Production  with Tensor Decomposition",
    "abstract": "Research about brain activities involving spoken word production is\nconsiderably underdeveloped because of the undiscovered characteristics of\nspeech artifacts, which contaminate electroencephalogram (EEG) signals and\nprevent the inspection of the underlying cognitive processes. To fuel further\nEEG research with speech production, a method using three-mode tensor\ndecomposition (time x space x frequency) is proposed to perform speech artifact\nremoval. Tensor decomposition enables simultaneous inspection of multiple\nmodes, which suits the multi-way nature of EEG data. In a picture-naming task,\nwe collected raw data with speech artifacts by placing two electrodes near the\nmouth to record lip EMG. Based on our evaluation, which calculated the\ncorrelation values between grand-averaged speech artifacts and the lip EMG,\ntensor decomposition outperformed the former methods that were based on\nindependent component analysis (ICA) and blind source separation (BSS), both in\ndetecting speech artifact (0.985) and producing clean data (0.101). Our\nproposed method correctly preserved the components unrelated to speech, which\nwas validated by computing the correlation value between the grand-averaged raw\ndata without EOG and cleaned data before the speech onset (0.92-0.94).",
    "descriptor": "",
    "authors": [
      "Holy Lovenia",
      "Hiroki Tanaka",
      "Sakriani Sakti",
      "Ayu Purwarianti",
      "Satoshi Nakamura"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.00635"
  },
  {
    "id": "arXiv:2206.00636",
    "title": "A modular architecture for creating multimodal agents",
    "abstract": "The paper describes a flexible and modular platform to create multimodal\ninteractive agents. The platform operates through an event-bus on which signals\nand interpretations are posted in a sequence in time. Different sensors and\ninterpretation components can be integrated by defining their input and output\nas topics, which results in a logical workflow for further interpretations. We\nexplain a broad range of components that have been developed so far and\nintegrated into a range of interactive agents. We also explain how the actual\ninteraction is recorded as multimodal data as well as in a so-called episodic\nKnowledge Graph. By analysing the recorded interaction, we can analyse and\ncompare different agents and agent components.",
    "descriptor": "",
    "authors": [
      "Thomas Baier",
      "Selene Baez Santamaria",
      "Piek Vossen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.00636"
  },
  {
    "id": "arXiv:2206.00637",
    "title": "Graph Neural Networks with Precomputed Node Features",
    "abstract": "Most Graph Neural Networks (GNNs) cannot distinguish some graphs or indeed\nsome pairs of nodes within a graph. This makes it impossible to solve certain\nclassification tasks. However, adding additional node features to these models\ncan resolve this problem. We introduce several such augmentations, including\n(i) positional node embeddings, (ii) canonical node IDs, and (iii) random\nfeatures. These extensions are motivated by theoretical results and\ncorroborated by extensive testing on synthetic subgraph detection tasks. We\nfind that positional embeddings significantly outperform other extensions in\nthese tasks. Moreover, positional embeddings have better sample efficiency,\nperform well on different graph distributions and even outperform learning with\nground truth node positions. Finally, we show that the different augmentations\nperform competitively on established GNN benchmarks, and advise on when to use\nthem.",
    "descriptor": "",
    "authors": [
      "Beni Egressy",
      "Roger Wattenhofer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00637"
  },
  {
    "id": "arXiv:2206.00638",
    "title": "Towards the Development of A Three-Dimensional SBP-SAT FDTD Method:  Theory and Validation",
    "abstract": "To enhance the scalability and performance of the traditional\nfinite-difference time-domain (FDTD) methods, a three-dimensional\nsummation-by-parts simultaneous approximation term (SBP-SAT) FDTD method is\ndeveloped to solve complex electromagnetic problems. It is theoretically stable\nand can be further used for multiple mesh blocks with different mesh sizes.\nThis paper mainly focuses on the fundamental theoretical aspects upon its\nthree-dimensional implementation, the SAT for various boundary conditions, and\nthe numerical dispersion properties and the comparison with the FDTD method.\nThe proposed SBP-SAT FDTD method inherits all the merits of the FDTD method,\nwhich is matrix-free, easy to implement, and has the same level of accuracy\nwith a negligible overhead of runtime (0.13\\%) and memory usage (1.2\\%). Four\nnumerical examples are carried out to validate the effectiveness of the\nproposed method.",
    "descriptor": "",
    "authors": [
      "Yu Cheng",
      "Hanhong Liu",
      "Xinsong Wang",
      "Guangzhi Chen",
      "Xiang-Hua Wang",
      "Xingqi Zhang",
      "Shunchuan Yang",
      "Zhizhang Chen"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2206.00638"
  },
  {
    "id": "arXiv:2206.00645",
    "title": "Extreme Floorplan Reconstruction by Structure-Hallucinating Transformer  Cascades",
    "abstract": "This paper presents an extreme floorplan reconstruction task, a new benchmark\nfor the task, and a neural architecture as a solution. Given a partial\nfloorplan reconstruction inferred or curated from panorama images, the task is\nto reconstruct a complete floorplan including invisible architectural\nstructures. The proposed neural network 1) encodes an input partial floorplan\ninto a set of latent vectors by convolutional neural networks and a\nTransformer; and 2) reconstructs an entire floorplan while hallucinating\ninvisible rooms and doors by cascading Transformer decoders. Qualitative and\nquantitative evaluations demonstrate effectiveness of our approach over the\nbenchmark of 701 houses, outperforming the state-of-the-art reconstruction\ntechniques. We will share our code, models, and data.",
    "descriptor": "",
    "authors": [
      "Sepidehsadat Hosseini",
      "Yasutaka Furukawa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.00645"
  },
  {
    "id": "arXiv:2206.00655",
    "title": "Learning-Augmented Algorithms for Online TSP on the Line",
    "abstract": "We study the online Traveling Salesman Problem (TSP) on the line augmented\nwith machine-learned predictions. In the classical problem, there is a stream\nof requests released over time along the real line. The goal is to minimize the\nmakespan of the algorithm. We distinguish between the open variant and the\nclosed one, in which we additionally require the algorithm to return to the\norigin after serving all requests. The state of the art is a $1.64$-competitive\nalgorithm and a $2.04$-competitive algorithm for the closed and open variants,\nrespectively \\cite{Bjelde:1.64}. In both cases, a tight lower bound is known\n\\cite{Ausiello:1.75, Bjelde:1.64}.\nIn both variants, our primary prediction model involves predicted positions\nof the requests. We introduce algorithms that (i) obtain a tight 1.5\ncompetitive ratio for the closed variant and a 1.66 competitive ratio for the\nopen variant in the case of perfect predictions, (ii) are robust against\nunbounded prediction error, and (iii) are smooth, i.e., their performance\ndegrades gracefully as the prediction error increases.\nMoreover, we further investigate the learning-augmented setting in the open\nvariant by additionally considering a prediction for the last request served by\nthe optimal offline algorithm. Our algorithm for this enhanced setting obtains\na 1.33 competitive ratio with perfect predictions while also being smooth and\nrobust, beating the lower bound of 1.44 we show for our original prediction\nsetting for the open variant. Also, we provide a lower bound of 1.25 for this\nenhanced setting.",
    "descriptor": "",
    "authors": [
      "Themis Gouleakis",
      "Konstantinos Lakis",
      "Golnoosh Shahkarami"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00655"
  },
  {
    "id": "arXiv:2206.00663",
    "title": "Error-Bounded Approximation of Pareto Fronts in Robot Planning Problems",
    "abstract": "Many problems in robotics seek to simultaneously optimize several competing\nobjectives under constraints. A conventional approach to solving such\nmulti-objective optimization problems is to create a single cost function\ncomprised of the weighted sum of the individual objectives. Solutions to this\nscalarized optimization problem are Pareto optimal solutions to the original\nmulti-objective problem. However, finding an accurate representation of a\nPareto front remains an important challenge. Using uniformly spaced weight\nvectors is often inefficient and does not provide error bounds. Thus, we\naddress the problem of computing a finite set of weight vectors such that for\nany other weight vector, there exists an element in the set whose error\ncompared to optimal is minimized. To this end, we prove fundamental properties\nof the optimal cost as a function of the weight vector, including its\ncontinuity and concavity. Using these, we propose an algorithm that greedily\nadds the weight vector least-represented by the current set, and provide bounds\non the error. Finally, we illustrate that the proposed approach significantly\noutperforms uniformly distributed weights for different robot planning problems\nwith varying numbers of objective functions.",
    "descriptor": "",
    "authors": [
      "Alexander Botros",
      "Armin Sadeghi",
      "Nils Wilde",
      "Javier Alonso-Mora",
      "Stephen L. Smith"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.00663"
  },
  {
    "id": "arXiv:2206.00664",
    "title": "Hopular: Modern Hopfield Networks for Tabular Data",
    "abstract": "While Deep Learning excels in structured data as encountered in vision and\nnatural language processing, it failed to meet its expectations on tabular\ndata. For tabular data, Support Vector Machines (SVMs), Random Forests, and\nGradient Boosting are the best performing techniques with Gradient Boosting in\nthe lead. Recently, we saw a surge of Deep Learning methods that were tailored\nto tabular data but still underperform compared to Gradient Boosting on\nsmall-sized datasets. We suggest \"Hopular\", a novel Deep Learning architecture\nfor medium- and small-sized datasets, where each layer is equipped with\ncontinuous modern Hopfield networks. The modern Hopfield networks use stored\ndata to identify feature-feature, feature-target, and sample-sample\ndependencies. Hopular's novelty is that every layer can directly access the\noriginal input as well as the whole training set via stored data in the\nHopfield networks. Therefore, Hopular can step-wise update its current model\nand the resulting prediction at every layer like standard iterative learning\nalgorithms. In experiments on small-sized tabular datasets with less than 1,000\nsamples, Hopular surpasses Gradient Boosting, Random Forests, SVMs, and in\nparticular several Deep Learning methods. In experiments on medium-sized\ntabular data with about 10,000 samples, Hopular outperforms XGBoost, CatBoost,\nLightGBM and a state-of-the art Deep Learning method designed for tabular data.\nThus, Hopular is a strong alternative to these methods on tabular data.",
    "descriptor": "\nComments: 9 pages (+ appendix); 5 figures; source code available at: this https URL ; blog post available at: this https URL\n",
    "authors": [
      "Bernhard Sch\u00e4fl",
      "Lukas Gruber",
      "Angela Bitto-Nemling",
      "Sepp Hochreiter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00664"
  },
  {
    "id": "arXiv:2206.00665",
    "title": "MonoSDF: Exploring Monocular Geometric Cues for Neural Implicit Surface  Reconstruction",
    "abstract": "In recent years, neural implicit surface reconstruction methods have become\npopular for multi-view 3D reconstruction. In contrast to traditional multi-view\nstereo methods, these approaches tend to produce smoother and more complete\nreconstructions due to the inductive smoothness bias of neural networks.\nState-of-the-art neural implicit methods allow for high-quality reconstructions\nof simple scenes from many input views. Yet, their performance drops\nsignificantly for larger and more complex scenes and scenes captured from\nsparse viewpoints. This is caused primarily by the inherent ambiguity in the\nRGB reconstruction loss that does not provide enough constraints, in particular\nin less-observed and textureless areas. Motivated by recent advances in the\narea of monocular geometry prediction, we systematically explore the utility\nthese cues provide for improving neural implicit surface reconstruction. We\ndemonstrate that depth and normal cues, predicted by general-purpose monocular\nestimators, significantly improve reconstruction quality and optimization time.\nFurther, we analyse and investigate multiple design choices for representing\nneural implicit surfaces, ranging from monolithic MLP models over single-grid\nto multi-resolution grid representations. We observe that geometric monocular\npriors improve performance both for small-scale single-object as well as\nlarge-scale multi-object scenes, independent of the choice of representation.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Zehao Yu",
      "Songyou Peng",
      "Michael Niemeyer",
      "Torsten Sattler",
      "Andreas Geiger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.00665"
  },
  {
    "id": "arXiv:2206.00666",
    "title": "Technical Debts and Faults in Open-source Quantum Software Systems: An  Empirical Study",
    "abstract": "Quantum computing is a rapidly growing field attracting the interest of both\nresearchers and software developers. Supported by its numerous open-source\ntools, developers can now build, test, or run their quantum algorithms.\nAlthough the maintenance practices for traditional software systems have been\nextensively studied, the maintenance of quantum software is still a new field\nof study but a critical part to ensure the quality of a whole quantum computing\nsystem. In this work, we set out to investigate the distribution and evolution\nof technical debts in quantum software and their relationship with fault\noccurrences. Understanding these problems could guide future quantum\ndevelopment and provide maintenance recommendations for the key areas where\nquantum software developers and researchers should pay more attention. In this\npaper, we empirically studied 118 open-source quantum projects, which were\nselected from GitHub. The projects are categorized into 10 categories. We found\nthat the studied quantum software suffers from the issues of code convention\nviolation, error-handling, and code design. We also observed a statistically\nsignificant correlation between code design, redundant code or code convention,\nand the occurrences of faults in quantum software.",
    "descriptor": "",
    "authors": [
      "Moses Openja",
      "Mohammad Mehdi Morovati",
      "Le An",
      "Foutse Khomh",
      "Mouna Abidi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.00666"
  },
  {
    "id": "arXiv:2206.00002",
    "title": "Calibrated Bagging Deep Learning for Image Semantic Segmentation: A Case  Study on COVID-19 Chest X-ray Image",
    "abstract": "Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) causes\ncoronavirus disease 2019 (COVID-19). Imaging tests such as chest X-ray (CXR)\nand computed tomography (CT) can provide useful information to clinical staff\nfor facilitating a diagnosis of COVID-19 in a more efficient and comprehensive\nmanner. As a breakthrough of artificial intelligence (AI), deep learning has\nbeen applied to perform COVID-19 infection region segmentation and disease\nclassification by analyzing CXR and CT data. However, prediction uncertainty of\ndeep learning models for these tasks, which is very important to\nsafety-critical applications like medical image processing, has not been\ncomprehensively investigated. In this work, we propose a novel ensemble deep\nlearning model through integrating bagging deep learning and model calibration\nto not only enhance segmentation performance, but also reduce prediction\nuncertainty. The proposed method has been validated on a large dataset that is\nassociated with CXR image segmentation. Experimental results demonstrate that\nthe proposed method can improve the segmentation performance, as well as\ndecrease prediction uncertainties.",
    "descriptor": "",
    "authors": [
      "Lucy Nwosu",
      "Xiangfang Li",
      "Lijun Qian",
      "Seungchan Kim",
      "Xishuang Dong"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00002"
  },
  {
    "id": "arXiv:2206.00031",
    "title": "On the coset graph construction of distance-regular graphs",
    "abstract": "We show that no more new distance-regular graphs in the tables of the book of\n(Brouwer, Cohen, Neumaier, 1989) can be produced by using the coset graph of\nadditive completely regular codes over finite fields.",
    "descriptor": "",
    "authors": [
      "Minjia Shi",
      "Denis S. Krotov",
      "Patrick Sol\u00e9"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2206.00031"
  },
  {
    "id": "arXiv:2206.00041",
    "title": "Characterization of 3D Printers and X-Ray Computerized Tomography",
    "abstract": "The 3D printing process flow requires several inputs for the best printing\nquality. These settings may vary from sample to sample, printer to printer, and\ndepend upon users' previous experience. The involved operational parameters for\n3D Printing are varied to test the optimality. Thirty-eight samples are printed\nusing four commercially available 3D printers, namely: (a) Ultimaker 2\nExtended+, (b) Delta Wasp, (c) Raise E2, and (d) ProJet MJP. The sample\nprofiles contain uniform and non-uniform distribution of the assorted size of\ncubes and spheres with a known amount of porosity. These samples are scanned\nusing X-Ray Computed Tomography system. Functional Imaging analysis is\nperformed using AI-based segmentation codes to (a) characterize these 3D\nprinters and (b) find Three-dimensional surface roughness of three teeth and\none sandstone pebble (from riverbed) with naturally deposited layers is also\ncompared with printed sample values. Teeth has best quality. It is found that\nProJet MJP gives the best quality of printed samples with the least amount of\nsurface roughness and almost near to the actual porosity value. As expected,\n100% infill density value, best spatial resolution for printing or Layer\nheight, and minimum nozzle speed give the best quality of 3D printing.",
    "descriptor": "\nComments: Total 13 Pages, 11 Figures, 5 Tables, 10 References\n",
    "authors": [
      "Sunita Khod",
      "Akshay Dvivedi",
      "Mayank Goswami"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.00041"
  },
  {
    "id": "arXiv:2206.00060",
    "title": "Universal Early Warning Signals of Phase Transitions in Climate Systems",
    "abstract": "The potential for complex systems to exhibit tipping points in which an\nequilibrium state undergoes a sudden and potentially irreversible shift is well\nestablished, but prediction of these events using standard forecast modeling\ntechniques is quite difficult. This has led to the development of an\nalternative suite of methods that seek to identify signatures of critical\nphenomena in data, which are expected to occur in advance of many classes of\ndynamical bifurcation. Crucially, the manifestations of these critical\nphenomena are generic across a variety of systems, meaning that data-intensive\ndeep learning methods can be trained on (abundant) synthetic data and plausibly\nprove effective when transferred to (more limited) empirical data sets. This\npaper provides a proof of concept for this approach as applied to lattice phase\ntransitions: a deep neural network trained exclusively on 2D Ising model phase\ntransitions is tested on a number of real and simulated climate systems with\nconsiderable success. Its accuracy frequently surpasses that of conventional\nstatistical indicators, with performance shown to be consistently improved by\nthe inclusion of spatial indicators. Tools such as this may offer valuable\ninsight into climate tipping events, as remote sensing measurements provide\nincreasingly abundant data on complex geospatially-resolved Earth systems.",
    "descriptor": "",
    "authors": [
      "Daniel Dylewsky",
      "Timothy M. Lenton",
      "Marten Scheffer",
      "Thomas M. Bury",
      "Christopher G. Fletcher",
      "Madhur Anand",
      "Chris T. Bauch"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.00060"
  },
  {
    "id": "arXiv:2206.00074",
    "title": "To the Fairness Frontier and Beyond: Identifying, Quantifying, and  Optimizing the Fairness-Accuracy Pareto Frontier",
    "abstract": "Algorithmic fairness has emerged as an important consideration when using\nmachine learning to make high-stakes societal decisions. Yet, improved fairness\noften comes at the expense of model accuracy. While aspects of the\nfairness-accuracy tradeoff have been studied, most work reports the fairness\nand accuracy of various models separately; this makes model comparisons nearly\nimpossible without a model-agnostic metric that reflects the balance of the two\ndesiderata. We seek to identify, quantify, and optimize the empirical Pareto\nfrontier of the fairness-accuracy tradeoff. Specifically, we identify and\noutline the empirical Pareto frontier through\nTradeoff-between-Fairness-and-Accuracy (TAF) Curves; we then develop a metric\nto quantify this Pareto frontier through the weighted area under the TAF Curve\nwhich we term the Fairness-Area-Under-the-Curve (FAUC). TAF Curves provide the\nfirst empirical, model-agnostic characterization of the Pareto frontier, while\nFAUC provides the first metric to impartially compare model families on both\nfairness and accuracy. Both TAF Curves and FAUC can be employed with all group\nfairness definitions and accuracy measures. Next, we ask: Is it possible to\nexpand the empirical Pareto frontier and thus improve the FAUC for a given\ncollection of fitted models? We answer affirmately by developing a novel fair\nmodel stacking framework, FairStacks, that solves a convex program to maximize\nthe accuracy of model ensemble subject to a score-bias constraint. We show that\noptimizing with FairStacks always expands the empirical Pareto frontier and\nimproves the FAUC; we additionally study other theoretical properties of our\nproposed approach. Finally, we empirically validate TAF, FAUC, and FairStacks\nthrough studies on several real benchmark data sets, showing that FairStacks\nleads to major improvements in FAUC that outperform existing algorithmic\nfairness approaches.",
    "descriptor": "",
    "authors": [
      "Camille Olivia Little",
      "Michael Weylandt",
      "Genevera I Allen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2206.00074"
  },
  {
    "id": "arXiv:2206.00086",
    "title": "Extensive Study of Multiple Deep Neural Networks for Complex Random  Telegraph Signals",
    "abstract": "Time-fluctuating signals are ubiquitous and diverse in many physical,\nchemical, and biological systems, among which random telegraph signals (RTSs)\nrefer to a series of instantaneous switching events between two discrete levels\nfrom single-particle movements. Reliable RTS analyses are crucial prerequisite\nto identify underlying mechanisms related to performance sensitivity. When\nnumerous levels partake, complex patterns of multilevel RTSs occur, making\ntheir quantitative analysis exponentially difficult, hereby systematic\napproaches are found elusive. Here, we present a three-step analysis protocol\nvia progressive knowledge-transfer, where the outputs of early step are passed\nonto a subsequent step. Especially, to quantify complex RTSs, we build three\ndeep neural network architectures that can process temporal data well and\ndemonstrate the model accuracy extensively with a large dataset of different\nRTS types affected by controlling background noise size. Our protocol offers\nstructured schemes to quantify complex RTSs from which meaningful\ninterpretation and inference can ensue.",
    "descriptor": "\nComments: 10 pages, 6 figures\n",
    "authors": [
      "Marcel Robitaille",
      "HeeBong Yang",
      "Lu Wang",
      "Na Young Kim"
    ],
    "subjectives": [
      "Applied Physics (physics.app-ph)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.00086"
  },
  {
    "id": "arXiv:2206.00088",
    "title": "Strong convergence of the tamed Euler scheme for scalar SDEs with  superlinearly growing and discontinuous drift coefficient",
    "abstract": "In this paper, we consider scalar stochastic differential equations (SDEs)\nwith a superlinearly growing and piecewise continuous drift coefficient.\nExistence and uniqueness of strong solutions of such SDEs are obtained.\nFurthermore, the classical $L_p$-error rate 1/2 for all $p\\in [1, +\\infty)$ is\nrecovered for the tamed Euler scheme. A numerical example is provided to\nsupport our conclusion.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:1809.08423, arXiv:2204.02343 by other authors\n",
    "authors": [
      "Huimin Hu",
      "Siqing Gan"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.00088"
  },
  {
    "id": "arXiv:2206.00089",
    "title": "Defining Quantum Games",
    "abstract": "In this article, we explore the concept of quantum games and define quantum\ngames as any type of playable games that are related to or reference quantum\nphysics through any of three proposed aspects. The rise of the quantum\ncomputers has made it possible to think about a new wave of computer games,\nnamely quantum computer games, games on quantum computers. But at the same\ntime, there are also various games that are exploring quantum mechanics and\nrelated topics through digital, analogue and hybrid means. In this article we\ngo through the emerging body of quantum games, the history of quantum games and\nthe different ways a game may be considered a quantum game. For this we propose\nthree dimensions for analysing and defining the phenomenon of quantum games:\nthe perceivable dimension of quantum games, the dimension of quantum\ntechnologies and the dimension of scientific purposes.",
    "descriptor": "",
    "authors": [
      "Laura Piispanen",
      "Marcel Pfaffhauser",
      "Annakaisa Kultima",
      "James R. Wootton"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2206.00089"
  },
  {
    "id": "arXiv:2206.00093",
    "title": "Easy Variational Inference for Categorical Models via an Independent  Binary Approximation",
    "abstract": "We pursue tractable Bayesian analysis of generalized linear models (GLMs) for\ncategorical data. Thus far, GLMs are difficult to scale to more than a few\ndozen categories due to non-conjugacy or strong posterior dependencies when\nusing conjugate auxiliary variable methods. We define a new class of GLMs for\ncategorical data called categorical-from-binary (CB) models. Each CB model has\na likelihood that is bounded by the product of binary likelihoods, suggesting a\nnatural posterior approximation. This approximation makes inference\nstraightforward and fast; using well-known auxiliary variables for probit or\nlogistic regression, the product of binary models admits conjugate closed-form\nvariational inference that is embarrassingly parallel across categories and\ninvariant to category ordering. Moreover, an independent binary model\nsimultaneously approximates multiple CB models. Bayesian model averaging over\nthese can improve the quality of the approximation for any given dataset. We\nshow that our approach scales to thousands of categories, outperforming\nposterior estimation competitors like Automatic Differentiation Variational\nInference (ADVI) and No U-Turn Sampling (NUTS) in the time required to achieve\nfixed prediction quality.",
    "descriptor": "\nComments: to appear at ICML 2022\n",
    "authors": [
      "Michael T. Wojnowicz",
      "Shuchin Aeron",
      "Eric L. Miller",
      "Michael C. Hughes"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2206.00093"
  },
  {
    "id": "arXiv:2206.00099",
    "title": "Provably and Practically Efficient Neural Contextual Bandits",
    "abstract": "We consider the neural contextual bandit problem. In contrast to the existing\nwork which primarily focuses on ReLU neural nets, we consider a general set of\nsmooth activation functions. Under this more general setting, (i) we derive\nnon-asymptotic error bounds on the difference between an overparameterized\nneural net and its corresponding neural tangent kernel, (ii) we propose an\nalgorithm with a provably sublinear regret bound that is also efficient in the\nfinite regime as demonstrated by empirical studies. The non-asymptotic error\nbounds may be of broader interest as a tool to establish the relation between\nthe smoothness of the activation functions in neural contextual bandits and the\nsmoothness of the kernels in kernel bandits.",
    "descriptor": "",
    "authors": [
      "Sudeep Salgia",
      "Sattar Vakili",
      "Qing Zhao"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00099"
  },
  {
    "id": "arXiv:2206.00105",
    "title": "Deep learning pipeline for image classification on mobile phones",
    "abstract": "This article proposes and documents a machine-learning framework and tutorial\nfor classifying images using mobile phones. Compared to computers, the\nperformance of deep learning model performance degrades when deployed on a\nmobile phone and requires a systematic approach to find a model that performs\noptimally on both computers and mobile phones. By following the proposed\npipeline, which consists of various computational tools, simple procedural\nrecipes, and technical considerations, one can bring the power of deep learning\nmedical image classification to mobile devices, potentially unlocking new\ndomains of applications. The pipeline is demonstrated on four different\npublicly available datasets: COVID X-rays, COVID CT scans, leaves, and\ncolorectal cancer. We used two application development frameworks: TensorFlow\nLite (real-time testing) and Flutter (digital image testing) to test the\nproposed pipeline. We found that transferring deep learning models to a mobile\nphone is limited by hardware and classification accuracy drops. To address this\nissue, we proposed this pipeline to find an optimized model for mobile phones.\nFinally, we discuss additional applications and computational concerns related\nto deploying deep-learning models on phones, including real-time analysis and\nimage preprocessing. We believe the associated documentation and code can help\nphysicians and medical experts develop medical image classification\napplications for distribution.",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Muhammad Muneeb",
      "Samuel F. Feng",
      "Andreas Henschel"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00105"
  },
  {
    "id": "arXiv:2206.00120",
    "title": "Decentralized Competing Bandits in Non-Stationary Matching Markets",
    "abstract": "Understanding complex dynamics of two-sided online matching markets, where\nthe demand-side agents compete to match with the supply-side (arms), has\nrecently received substantial interest. To that end, in this paper, we\nintroduce the framework of decentralized two-sided matching market under non\nstationary (dynamic) environments. We adhere to the serial dictatorship\nsetting, where the demand-side agents have unknown and different preferences\nover the supply-side (arms), but the arms have fixed and known preference over\nthe agents. We propose and analyze a decentralized and asynchronous learning\nalgorithm, namely Decentralized Non-stationary Competing Bandits\n(\\texttt{DNCB}), where the agents play (restrictive) successive elimination\ntype learning algorithms to learn their preference over the arms. The\ncomplexity in understanding such a system stems from the fact that the\ncompeting bandits choose their actions in an asynchronous fashion, and the\nlower ranked agents only get to learn from a set of arms, not \\emph{dominated}\nby the higher ranked agents, which leads to \\emph{forced exploration}. With\ncarefully defined complexity parameters, we characterize this \\emph{forced\nexploration} and obtain sub-linear (logarithmic) regret of \\texttt{DNCB}.\nFurthermore, we validate our theoretical findings via experiments.",
    "descriptor": "",
    "authors": [
      "Avishek Ghosh",
      "Abishek Sankararaman",
      "Kannan Ramchandran",
      "Tara Javidi",
      "Arya Mazumdar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00120"
  },
  {
    "id": "arXiv:2206.00122",
    "title": "A Class of Low-complexity DCT-like Transforms for Image and Video Coding",
    "abstract": "The discrete cosine transform (DCT) is a relevant tool in signal processing\napplications, mainly known for its good decorrelation properties. Current image\nand video coding standards -- such as JPEG and HEVC -- adopt the DCT as a\nfundamental building block for compression. Recent works have introduced\nlow-complexity approximations for the DCT, which become paramount in\napplications demanding real-time computation and low-power consumption. The\ndesign of DCT approximations involves a trade-off between computational\ncomplexity and performance. This paper introduces a new multiparametric\ntransform class encompassing the round-off DCT (RDCT) and the modified RDCT\n(MRDCT), two relevant multiplierless 8-point approximate DCTs. The associated\nfast algorithm is provided. Four novel orthogonal low-complexity 8-point DCT\napproximations are obtained by solving a multicriteria optimization problem.\nThe optimal 8-point transforms are scaled to lengths 16 and 32 while keeping\nthe arithmetic complexity low. The proposed methods are assessed by proximity\nand coding measures with respect to the exact DCT. Image and video coding\nexperiments hardware realization are performed. The novel transforms perform\nclose to or outperform the current state-of-the-art DCT approximations.",
    "descriptor": "\nComments: 13 pages, 8 figures, 9 tables\n",
    "authors": [
      "T. L. T. da Silveira",
      "D. R. Canterle",
      "D. F. G. Coelho",
      "V. A. Coutinho",
      "F. M. Bayer",
      "R. J. Cintra"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Multimedia (cs.MM)",
      "Signal Processing (eess.SP)",
      "Numerical Analysis (math.NA)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2206.00122"
  },
  {
    "id": "arXiv:2206.00124",
    "title": "Low-complexity Three-dimensional Discrete Hartley Transform  Approximations for Medical Image Compression",
    "abstract": "The discrete Hartley transform (DHT) is a useful tool for medical image\ncoding. The three-dimensional DHT (3D DHT) can be employed to compress medical\nimage data, such as magnetic resonance and X-ray angiography. However, the\ncomputation of the 3D DHT involves several multiplications by irrational\nquantities, which require floating-point arithmetic and inherent truncation\nerrors. In recent years, a significant progress in wireless and implantable\nbiomedical devices has been achieved. Such devices present critical power and\nhardware limitations. The multiplication operation demands higher hardware,\npower, and time consumption than other arithmetic operations, such as addition\nand bit-shifts. In this work, we present a set of multiplierless DHT\napproximations, which can be implemented with fixed-point arithmetic. We derive\n3D DHT approximations by employing tensor formalism. Such proposed methods\npresent prominent computational savings compared to the usual 3D DHT approach,\nbeing appropriate for devices with limited resources. The proposed transforms\nare applied in a lossy 3D DHT-based medical image compression algorithm,\npresenting practically the same level of visual quality ($>98\\%$ in terms of\nSSIM) at a considerable reduction in computational effort ($100 \\%$\nmultiplicative complexity reduction). Furthermore, we implemented the proposed\n3D transforms in an ARM Cortex-M0+ processor employing the low-cost Raspberry\nPi Pico board. The execution time was reduced by $\\sim$70% compared to the\nusual 3D DHT and $\\sim$90% compared to 3D DCT.",
    "descriptor": "\nComments: 22 pages, 7 tables, 6 figures\n",
    "authors": [
      "V. A. Coutinho",
      "F. M. Bayer",
      "R. J. Cintra"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Multimedia (cs.MM)",
      "Image and Video Processing (eess.IV)",
      "Numerical Analysis (math.NA)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2206.00124"
  },
  {
    "id": "arXiv:2206.00127",
    "title": "Communication-efficient distributed eigenspace estimation with arbitrary  node failures",
    "abstract": "We develop an eigenspace estimation algorithm for distributed environments\nwith arbitrary node failures, where a subset of computing nodes can return\nstructurally valid but otherwise arbitrarily chosen responses. Notably, this\nsetting encompasses several important scenarios that arise in distributed\ncomputing and data-collection environments such as silent/soft errors, outliers\nor corrupted data at certain nodes, and adversarial responses. Our estimator\nbuilds upon and matches the performance of a recently proposed non-robust\nestimator up to an additive $\\tilde{O}(\\sigma \\sqrt{\\alpha})$ error, where\n$\\sigma^2$ is the variance of the existing estimator and $\\alpha$ is the\nfraction of corrupted nodes.",
    "descriptor": "\nComments: 23 pages, 1 figure\n",
    "authors": [
      "Vasileios Charisopoulos",
      "Anil Damle"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.00127"
  },
  {
    "id": "arXiv:2206.00128",
    "title": "ForestPrune: Compact Depth-Controlled Tree Ensembles",
    "abstract": "Tree ensembles are versatile supervised learning algorithms that achieve\nstate-of-the-art performance. These models are extremely powerful but can grow\nto enormous sizes. As a result, tree ensembles are often post-processed to\nreduce memory footprint and improve interpretability. In this paper, we present\nForestPrune, a novel optimization framework that can post-process tree\nensembles by pruning depth layers from individual trees. We also develop a new\nblock coordinate descent method to efficiently obtain high-quality solutions to\noptimization problems under this framework. The number of nodes in a decision\ntree increases exponentially with tree depth, so pruning deep trees can\ndrastically improve model parsimony. ForestPrune can substantially reduce the\nspace complexity of an ensemble for a minimal cost to performance. The\nframework supports various weighting schemes and contains just a single\nhyperparameter to tune. In our experiments, we observe that ForestPrune can\nreduce model size 20-fold with negligible performance loss.",
    "descriptor": "",
    "authors": [
      "Brian Liu",
      "Rahul Mazumder"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00128"
  },
  {
    "id": "arXiv:2206.00135",
    "title": "AVIDA: Alternating method for Visualizing and Integrating Data",
    "abstract": "High-dimensional multimodal data arises in many scientific fields. The\nintegration of multimodal data becomes challenging when there is no known\ncorrespondence between the samples and the features of different datasets. To\ntackle this challenge, we introduce AVIDA, a framework for simultaneously\nperforming data alignment and dimension reduction. In the numerical\nexperiments, Gromov-Wasserstein optimal transport and t-distributed stochastic\nneighbor embedding are used as the alignment and dimension reduction modules\nrespectively. We show that AVIDA correctly aligns high-dimensional datasets\nwithout common features with four synthesized datasets and two real multimodal\nsingle-cell datasets. Compared to several existing methods, we demonstrate that\nAVIDA better preserves structures of individual datasets, especially distinct\nlocal structures in the joint low-dimensional visualization, while achieving\ncomparable alignment performance. Such a property is important in multimodal\nsingle-cell data analysis as some biological processes are uniquely captured by\none of the datasets. In general applications, other methods can be used for the\nalignment and dimension reduction modules.",
    "descriptor": "",
    "authors": [
      "Kathryn Dover",
      "Zixuan Cang",
      "Anna Ma",
      "Qing Nie",
      "Roman Vershynin"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00135"
  },
  {
    "id": "arXiv:2206.00149",
    "title": "A Kernelised Stein Statistic for Assessing Implicit Generative Models",
    "abstract": "Synthetic data generation has become a key ingredient for training machine\nlearning procedures, addressing tasks such as data augmentation, analysing\nprivacy-sensitive data, or visualising representative samples. Assessing the\nquality of such synthetic data generators hence has to be addressed. As (deep)\ngenerative models for synthetic data often do not admit explicit probability\ndistributions, classical statistical procedures for assessing model\ngoodness-of-fit may not be applicable. In this paper, we propose a principled\nprocedure to assess the quality of a synthetic data generator. The procedure is\na kernelised Stein discrepancy (KSD)-type test which is based on a\nnon-parametric Stein operator for the synthetic data generator of interest.\nThis operator is estimated from samples which are obtained from the synthetic\ndata generator and hence can be applied even when the model is only implicit.\nIn contrast to classical testing, the sample size from the synthetic data\ngenerator can be as large as desired, while the size of the observed data,\nwhich the generator aims to emulate is fixed. Experimental results on synthetic\ndistributions and trained generative models on synthetic and real datasets\nillustrate that the method shows improved power performance compared to\nexisting approaches.",
    "descriptor": "",
    "authors": [
      "Wenkai Xu",
      "Gesine Reinert"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00149"
  },
  {
    "id": "arXiv:2206.00157",
    "title": "Design and Simulation of an Autonomous Quantum Flying Robot Vehicle: An  IBM Quantum Experience",
    "abstract": "The application of quantum computation and information in robotics has caught\nthe attention of researchers off late. The field of robotics has always put its\neffort on the minimization of the space occupied by the robot, and on making\nthe robot `smarter. `The smartness of a robot is its sensitivity to its\nsurroundings and the user input and its ability to react upon them desirably.\nQuantum phenomena in robotics make sure that the robots occupy less space and\nthe ability of quantum computation to process the huge amount of information\neffectively, consequently making the robot smarter. Braitenberg vehicle is a\nsimple circuited robot that moves according to the input that its sensors\nreceive. Building upon that, we propose a quantum robot vehicle that is `smart'\nenough to understand the complex situations more than that of a simple\nBraitenberg vehicle and navigate itself as per the obstacles present. It can\ndetect an obstacle-free path and can navigate itself accordingly. It also takes\ninput from the user when there is more than one free path available. When left\nwith no option on the ground, it can airlift itself off the ground. As these\nvehicles sort of `react to the surrounding conditions, this idea can be used to\nbuild artificial life and genetic algorithms, space exploration and deep-earth\nexploration probes, and a handy tool in defense and intelligence services.",
    "descriptor": "\nComments: 7 pages, 5 figures\n",
    "authors": [
      "Sudev Pradhan",
      "Anshuman Padhi",
      "Bikash Kumar Behera"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.00157"
  },
  {
    "id": "arXiv:2206.00213",
    "title": "The Quantum and Classical Streaming Complexity of Quantum and Classical  Max-Cut",
    "abstract": "We investigate the space complexity of two graph streaming problems: Max-Cut\nand its quantum analogue, Quantum Max-Cut. Previous work by Kapralov and\nKrachun [STOC `19] resolved the classical complexity of the \\emph{classical}\nproblem, showing that any $(2 - \\varepsilon)$-approximation requires\n$\\Omega(n)$ space (a $2$-approximation is trivial with $\\textrm{O}(\\log n)$\nspace). We generalize both of these qualifiers, demonstrating $\\Omega(n)$ space\nlower bounds for $(2 - \\varepsilon)$-approximating Max-Cut and Quantum Max-Cut,\neven if the algorithm is allowed to maintain a quantum state. As the trivial\napproximation algorithm for Quantum Max-Cut only gives a $4$-approximation, we\nshow tightness with an algorithm that returns a $(2 +\n\\varepsilon)$-approximation to the Quantum Max-Cut value of a graph in\n$\\textrm{O}(\\log n)$ space. Our work resolves the quantum and classical\napproximability of quantum and classical Max-Cut using $\\textrm{o}(n)$ space.\nWe prove our lower bounds through the techniques of Boolean Fourier analysis.\nWe give the first application of these methods to sequential one-way quantum\ncommunication, in which each player receives a quantum message from the\nprevious player, and can then perform arbitrary quantum operations on it before\nsending it to the next. To this end, we show how Fourier-analytic techniques\nmay be used to understand the application of a quantum channel.",
    "descriptor": "",
    "authors": [
      "John Kallaugher",
      "Ojas Parekh"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.00213"
  },
  {
    "id": "arXiv:2206.00215",
    "title": "Quantum Error Mitigation by Pauli Check Sandwiching",
    "abstract": "We introduce an error mitigation technique that uses multiple pairs of parity\nchecks to mitigate errors. Each pair of checks uses one ancilla qubit to detect\na component of the error operator and represents one layer of the technique. We\nprove that our technique can recover the noiseless state under the assumption\nof noise not affecting the checks. Our method is inspired by the parity checks\npresent in stabilizer codes. Our error mitigation scheme does not incur any\nencoding overhead. Instead, we choose the checks based on the input circuit. We\ndevelop an algorithm for obtaining such checks for an arbitrary target circuit.\nSince our method applies to any circuit and input state, it can be easily\ncombined with other error mitigation techniques. We evaluate the performance of\nthe proposed methods using extensive numerical simulations on 1,850 random\ninput circuits composed of Clifford gates and non-Clifford single-qubit\nrotations, a class of circuits encompassing most commonly considered\nvariational algorithm circuits. We observe average improvements in fidelity of\n34 percentage points with six layers of checks.",
    "descriptor": "\nComments: Preprint. Comments are welcome\n",
    "authors": [
      "Alvin Gonzales",
      "Ruslan Shaydulin",
      "Zain Saleem",
      "Martin Suchara"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2206.00215"
  },
  {
    "id": "arXiv:2206.00224",
    "title": "Accelerated first-order methods for a class of semidefinite programs",
    "abstract": "This paper introduces a new storage-optimal first-order method (FOM),\nCertSDP, for solving a special class of semidefinite programs (SDPs) to high\naccuracy. The class of SDPs that we consider, the exact QMP-like SDPs, is\ncharacterized by low-rank solutions, a priori knowledge of the restriction of\nthe SDP solution to a small subspace, and standard regularity assumptions such\nas strict complementarity. Crucially, we show how to use a certificate of\nstrict complementarity to construct a low-dimensional strongly convex minimax\nproblem whose optimizer coincides with a factorization of the SDP optimizer.\nFrom an algorithmic standpoint, we show how to construct the necessary\ncertificate and how to solve the minimax problem efficiently. We accompany our\ntheoretical results with preliminary numerical experiments suggesting that\nCertSDP significantly outperforms current state-of-the-art methods on large\nsparse exact QMP-like SDPs.",
    "descriptor": "",
    "authors": [
      "Alex L. Wang",
      "Fatma Kilinc-Karzan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.00224"
  },
  {
    "id": "arXiv:2206.00241",
    "title": "Asymptotic Properties for Bayesian Neural Network in Besov Space",
    "abstract": "Neural networks have shown great predictive power when dealing with various\nunstructured data such as images and natural languages. The Bayesian neural\nnetwork captures the uncertainty of prediction by putting a prior distribution\nfor the parameter of the model and computing the posterior distribution. In\nthis paper, we show that the Bayesian neural network using spike-and-slab prior\nhas consistency with nearly minimax convergence rate when the true regression\nfunction is in the Besov space. Even when the smoothness of the regression\nfunction is unknown the same posterior convergence rate holds and thus the\nspike and slab prior is adaptive to the smoothness of the regression function.\nWe also consider the shrinkage prior and show that it has the same convergence\nrate. In other words, we propose a practical Bayesian neural network with\nguaranteed asymptotic properties.",
    "descriptor": "",
    "authors": [
      "Kyeongwon Lee",
      "Jaeyong Lee"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2206.00241"
  },
  {
    "id": "arXiv:2206.00260",
    "title": "Multi-block Min-max Bilevel Optimization with Applications in Multi-task  Deep AUC Maximization",
    "abstract": "In this paper, we study multi-block min-max bilevel optimization problems,\nwhere the upper level is non-convex strongly-concave minimax objective and the\nlower level is a strongly convex objective, and there are multiple blocks of\ndual variables and lower level problems. Due to the intertwined multi-block\nmin-max bilevel structure, the computational cost at each iteration could be\nprohibitively high, especially with a large number of blocks. To tackle this\nchallenge, we present a single-loop randomized stochastic algorithm, which\nrequires updates for only a constant number of blocks at each iteration. Under\nsome mild assumptions on the problem, we establish its sample complexity of\n$\\mathcal{O}(1/\\epsilon^4)$ for finding an $\\epsilon$-stationary point. This\nmatches the optimal complexity for solving stochastic nonconvex optimization\nunder a general unbiased stochastic oracle model. Moreover, we provide two\napplications of the proposed method in multi-task deep AUC (area under ROC\ncurve) maximization and multi-task deep partial AUC maximization. Experimental\nresults validate our theory and demonstrate the effectiveness of our method on\nproblems with hundreds of tasks.",
    "descriptor": "",
    "authors": [
      "Quanqi Hu",
      "Yongjian Zhong",
      "Tianbao Yang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.00260"
  },
  {
    "id": "arXiv:2206.00285",
    "title": "Stochastic Gradient Methods with Preconditioned Updates",
    "abstract": "This work considers non-convex finite sum minimization. There are a number of\nalgorithms for such problems, but existing methods often work poorly when the\nproblem is badly scaled and/or ill-conditioned, and a primary goal of this work\nis to introduce methods that alleviate this issue. Thus, here we include a\npreconditioner that is based upon Hutchinson's approach to approximating the\ndiagonal of the Hessian, and couple it with several gradient based methods to\ngive new `scaled' algorithms: {\\tt Scaled SARAH} and {\\tt Scaled L-SVRG}.\nTheoretical complexity guarantees under smoothness assumptions are presented,\nand we prove linear convergence when both smoothness and the PL-condition is\nassumed. Because our adaptively scaled methods use approximate partial second\norder curvature information, they are better able to mitigate the impact of\nbadly scaled problems, and this improved practical performance is demonstrated\nin the numerical experiments that are also presented in this work.",
    "descriptor": "\nComments: 31 pages, 2 new algorithms, 19 figures, 2 tables\n",
    "authors": [
      "Abdurakhmon Sadiev",
      "Aleksandr Beznosikov",
      "Abdulla Jasem Almansoori",
      "Dmitry Kamzolov",
      "Rachael Tappenden",
      "Martin Tak\u00e1\u010d"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00285"
  },
  {
    "id": "arXiv:2206.00305",
    "title": "Supervised Denoising of Diffusion-Weighted Magnetic Resonance Images  Using a Convolutional Neural Network and Transfer Learning",
    "abstract": "In this paper, we propose a method for denoising diffusion-weighted images\n(DWI) of the brain using a convolutional neural network trained on realistic,\nsynthetic MR data. We compare our results to averaging of repeated scans, a\nwidespread method used in clinics to improve signal-to-noise ratio of MR\nimages. To obtain training data for transfer learning, we model, in a\ndata-driven fashion, the effects of echo-planar imaging (EPI): Nyquist ghosting\nand ramp sampling. We introduce these effects to the digital phantom of brain\nanatomy (BrainWeb). Instead of simulating pseudo-random noise with a defined\nprobability distribution, we perform noise scans with a brain-DWI-designed\nprotocol to obtain realistic noise maps. We combine them with the simulated,\nnoise-free EPI images. We also measure the Point Spread Function in a DW image\nof an AJR-approved geometrical phantom and inter-scan movement in a brain scan\nof a healthy volunteer. Their influence on image denoising and averaging of\nrepeated images is investigated at different signal-to-noise ratio levels.\nDenoising performance is evaluated quantitatively using the simulated EPI\nimages and qualitatively in real EPI DWI of the brain. We show that the\napplication of our method allows for a significant reduction in scan time by\nlowering the number of repeated scans. Visual comparisons made in the acquired\nbrain images indicate that the denoised single-repetition images are less noisy\nthan multi-repetition averaged images. We also analyse the convolutional neural\nnetwork denoiser and point out the challenges accompanying this denoising\nmethod.",
    "descriptor": "\nComments: Preprint submitted to NeuroImage\n",
    "authors": [
      "Jakub Jurek",
      "Andrzej Materka",
      "Kamil Ludwisiak",
      "Agata Majos",
      "Kamil Gorczewski",
      "Kamil Cepuch",
      "Agata Zawadzka"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.00305"
  },
  {
    "id": "arXiv:2206.00332",
    "title": "Smart Channel State Information Pre-processing for Joint Authentication  and Secret Key Distillation",
    "abstract": "While the literature on RF fingerprinting-based authentication and key\ndistillation is vast, the two topics have customarily been studied separately.\nIn this paper, starting from the observation that the wireless channel is a\ncomposite, deterministic / stochastic process, we propose a power domain\ndecomposition that allows performing the two tasks simultaneously. We devise\nintelligent pre-processing schemes to decompose channel state information (CSI)\nobservation vectors into \"predictable\" and \"unpredictable\" components. The\nformer, primarily due to large-scale fading, can be used for node\nauthentication through RF fingerprinting. The latter, primarily due to\nsmall-scale fading, could be used for semantically secure secret key generation\n(SKG). To perform the decomposition, we propose: (i) a fingerprint\n\"separability\" criterion, expressed through the maximisation of the total\nvariation distance between the empirical fingerprint measures; (ii) a\nstatistical independence metric for observations collected at different users,\nexpressed through a normalised version of the $d$-dimensional Hilbert Schmidt\nindependence criterion (dHSIC) test statistic. We propose both explicit\nimplementations, using principal component analysis (PCA) and kernel PCA and\nblack-box, unsupervised learning, using autoencoders. Our experiments on\nsynthetic and real CSI datasets showcase that the incorporation of RF\nfingerprinting and SKG, with explicit security guarantees, is tangible in\nfuture generations of wireless.",
    "descriptor": "",
    "authors": [
      "Muralikrishnan Srinivasan",
      "Sotiris Skaperas",
      "Arsenia Chorti",
      "Mahdi Shakiba Herfeh",
      "Muhammad K. Shehzad",
      "Philippe Sehier"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.00332"
  },
  {
    "id": "arXiv:2206.00333",
    "title": "$\\mathcal{S}$-adic characterization of minimal dendric shifts",
    "abstract": "Dendric shifts are defined by combinatorial restrictions of the extensions of\nthe words in their languages. This family generalizes well-known families of\nshifts such as Sturmian shifts, Arnoux-Rauzy shifts and codings of interval\nexchange transformations. It is known that any minimal dendric shift has a\nprimitive $\\mathcal{S}$-adic representation where the morphisms in\n$\\mathcal{S}$ are positive tame automorphisms of the free group generated by\nthe alphabet. In this paper we give an $\\mathcal{S}$-adic characterization of\nthis family by means of two finite graphs.",
    "descriptor": "\nComments: 31 pages\n",
    "authors": [
      "France Gheeraert",
      "Julien Leroy"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2206.00333"
  },
  {
    "id": "arXiv:2206.00338",
    "title": "CellCentroidFormer: Combining Self-attention and Convolution for Cell  Detection",
    "abstract": "Cell detection in microscopy images is important to study how cells move and\ninteract with their environment. Most recent deep learning-based methods for\ncell detection use convolutional neural networks (CNNs). However, inspired by\nthe success in other computer vision applications, vision transformers (ViTs)\nare also used for this purpose. We propose a novel hybrid CNN-ViT model for\ncell detection in microscopy images to exploit the advantages of both types of\ndeep learning models. We employ an efficient CNN, that was pre-trained on the\nImageNet dataset, to extract image features and utilize transfer learning to\nreduce the amount of required training data. Extracted image features are\nfurther processed by a combination of convolutional and transformer layers, so\nthat the convolutional layers can focus on local information and the\ntransformer layers on global information. Our centroid-based cell detection\nmethod represents cells as ellipses and is end-to-end trainable. Furthermore,\nwe show that our proposed model can outperform a fully convolutional baseline\nmodel on four different 2D microscopy datasets. Code is available at:\nhttps://github.com/roydenwa/cell-centroid-former",
    "descriptor": "\nComments: Accepted at MIUA 2022\n",
    "authors": [
      "Royden Wagner",
      "Karl Rohr"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.00338"
  },
  {
    "id": "arXiv:2206.00356",
    "title": "A Survey on Deep Learning for Skin Lesion Segmentation",
    "abstract": "Skin cancer is a major public health problem that could benefit from\ncomputer-aided diagnosis to reduce the burden of this common disease. Skin\nlesion segmentation from images is an important step toward achieving this\ngoal. However, the presence of natural and artificial artifacts (e.g., hair and\nair bubbles), intrinsic factors (e.g., lesion shape and contrast), and\nvariations in image acquisition conditions make skin lesion segmentation a\nchallenging task. Recently, various researchers have explored the applicability\nof deep learning models to skin lesion segmentation. In this survey, we\ncross-examine 134 research papers that deal with deep learning based\nsegmentation of skin lesions. We analyze these works along several dimensions,\nincluding input data (datasets, preprocessing, and synthetic data generation),\nmodel design (architecture, modules, and losses), and evaluation aspects (data\nannotation requirements and segmentation performance). We discuss these\ndimensions both from the viewpoint of select seminal works, and from a\nsystematic viewpoint, examining how those choices have influenced current\ntrends, and how their limitations should be addressed. We summarize all\nexamined works in a comprehensive table to facilitate comparisons.",
    "descriptor": "\nComments: 43 pages, 8 figures\n",
    "authors": [
      "Zahra Mirikharaji",
      "Catarina Barata",
      "Kumar Abhishek",
      "Alceu Bissoto",
      "Sandra Avila",
      "Eduardo Valle",
      "M. Emre Celebi",
      "Ghassan Hamarneh"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00356"
  },
  {
    "id": "arXiv:2206.00357",
    "title": "Propagation of epidemics in a polarized society: impact of clustering  among unvaccinated individuals",
    "abstract": "Polarization of opinions about vaccination can have a negative impact on\npandemic control. In this work we quantify this negative impact for the\ntransmission of COVID-19, using an agent based simulation in an heterogeneous\npopulation with multi-type networks, representing different types of social\ninteractions. We show that the clustering of unvaccinated individuals,\nassociated with polarization of opinion, can lead to significant differences in\nthe evolution of the pandemic compared to deterministic model predictions.\nUnder our realistic baseline scenario these differences are a 33pc increase of\nthe effective reproduction number, a 157pc increase of infections at the peak\nand a 30pc increase in the final cumulative attack rate.",
    "descriptor": "\nComments: 5pages, 3 figures\n",
    "authors": [
      "Ixandra Achitouv"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Multiagent Systems (cs.MA)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.00357"
  },
  {
    "id": "arXiv:2206.00381",
    "title": "The statistical nature of h-index of a network node",
    "abstract": "Evaluating the importance of a network node is a crucial task in network\nscience and graph data mining. H-index is a popular centrality measure for this\ntask, however, there is still a lack of its interpretation from a rigorous\nstatistical aspect. Here we show the statistical nature of h-index from the\nperspective of order statistics, and we obtain a new family of centrality\nindices by generalizing the h-index along this direction. The theoretical and\nempirical evidences show that such a statistical interpretation enables us to\nobtain a general and versatile framework for quantifying the importance of a\nnetwork node. Under this framework, many new centrality indices can be derived\nand some of which can be more accurate and robust than h-index. We believe that\nthis research opens up new avenues for developing more effective indices for\nnode importance quantification from a viewpoint that still remains unexplored.",
    "descriptor": "",
    "authors": [
      "Yan Liua",
      "Mudi Jianga",
      "Lianyu Hua",
      "Zengyou He"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2206.00381"
  },
  {
    "id": "arXiv:2206.00389",
    "title": "A comparative study between vision transformers and CNNs in digital  pathology",
    "abstract": "Recently, vision transformers were shown to be capable of outperforming\nconvolutional neural networks when pretrained on sufficient amounts of data. In\ncomparison to convolutional neural networks, vision transformers have a weaker\ninductive bias and therefore allow a more flexible feature detection. Due to\ntheir promising feature detection, this work explores vision transformers for\ntumor detection in digital pathology whole slide images in four tissue types,\nand for tissue type identification. We compared the patch-wise classification\nperformance of the vision transformer DeiT-Tiny to the state-of-the-art\nconvolutional neural network ResNet18. Due to the sparse availability of\nannotated whole slide images, we further compared both models pretrained on\nlarge amounts of unlabeled whole-slide images using state-of-the-art\nself-supervised approaches. The results show that the vision transformer\nperformed slightly better than the ResNet18 for three of four tissue types for\ntumor detection while the ResNet18 performed slightly better for the remaining\ntasks. The aggregated predictions of both models on slide level were\ncorrelated, indicating that the models captured similar imaging features. All\ntogether, the vision transformer models performed on par with the ResNet18\nwhile requiring more effort to train. In order to surpass the performance of\nconvolutional neural networks, vision transformers might require more\nchallenging tasks to benefit from their weak inductive bias.",
    "descriptor": "\nComments: 8 pages, 2 figures, accepted for workshop T4Vision (CVPR 2022)\n",
    "authors": [
      "Luca Deininger",
      "Bernhard Stimpel",
      "Anil Yuce",
      "Samaneh Abbasi-Sureshjani",
      "Simon Sch\u00f6nenberger",
      "Paolo Ocampo",
      "Konstanty Korski",
      "Fabien Gaire"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00389"
  },
  {
    "id": "arXiv:2206.00397",
    "title": "Predicting Political Ideology from Digital Footprints",
    "abstract": "This paper proposes a new method to predict individual political ideology\nfrom digital footprints on one of the world's largest online discussion forum.\nWe compiled a unique data set from the online discussion forum reddit that\ncontains information on the political ideology of around 91,000 users as well\nas records of their comment frequency and the comments' text corpus in over\n190,000 different subforums of interest. Applying a set of statistical learning\napproaches, we show that information about activity in non-political discussion\nforums alone, can very accurately predict a user's political ideology.\nDepending on the model, we are able to predict the economic dimension of\nideology with an accuracy of up to 90.63% and the social dimension with and\naccuracy of up to 82.02%. In comparison, using the textual features from actual\ncomments does not improve predictive accuracy. Our paper highlights the\nimportance of revealed digital behaviour to complement stated preferences from\ndigital communication when analysing human preferences and behaviour using\nonline data.",
    "descriptor": "",
    "authors": [
      "Michael Kitchener",
      "Nandini Anantharama",
      "Simon D. Angus",
      "Paul A. Raschky"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.00397"
  },
  {
    "id": "arXiv:2206.00436",
    "title": "Top-down inference in an early visual cortex inspired hierarchical  Variational Autoencoder",
    "abstract": "Interpreting computations in the visual cortex as learning and inference in a\ngenerative model of the environment has received wide support both in\nneuroscience and cognitive science. However, hierarchical computations, a\nhallmark of visual cortical processing, has remained impervious for generative\nmodels because of a lack of adequate tools to address it. Here we capitalize on\nadvances in Variational Autoencoders (VAEs) to investigate the early visual\ncortex with sparse coding hierarchical VAEs trained on natural images. We\ndesign alternative architectures that vary both in terms of the generative and\nthe recognition components of the two latent-layer VAE. We show that\nrepresentations similar to the one found in the primary and secondary visual\ncortices naturally emerge under mild inductive biases. Importantly, a nonlinear\nrepresentation for texture-like patterns is a stable property of the high-level\nlatent space resistant to the specific architecture of the VAE, reminiscent of\nthe secondary visual cortex. We show that a neuroscience-inspired choice of the\nrecognition model, which features a top-down processing component is critical\nfor two signatures of computations with generative models: learning higher\norder moments of the posterior beyond the mean and image inpainting. Patterns\nin higher order response statistics provide inspirations for neuroscience to\ninterpret response correlations and for machine learning to evaluate the\nlearned representations through more detailed characterization of the\nposterior.",
    "descriptor": "\nComments: 15 pages, 5 figures\n",
    "authors": [
      "Ferenc Csikor",
      "Bal\u00e1zs Mesz\u00e9na",
      "Bence Szab\u00f3",
      "Gerg\u0151 Orb\u00e1n"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.00436"
  },
  {
    "id": "arXiv:2206.00453",
    "title": "A New Approach to Solve the Fuzzy Nonlinear Unconstraint Optimization  Problem",
    "abstract": "This paper investigates fuzzy nonlinear system equations using an\noptimization approach. Here, the inner-outer direct search technique is used\nwith fuzzy coefficients and vectors to quantify the uncertain solution. The\nfuzzy nonlinear system of equations is converted into an unconstrained fuzzy\nmultivariable optimization problem with preserving the operating constraints.\nThen developed fuzzy inner-outer direct search is applied. The developed\nalgorithm is demonstrated through an example problem. The obtained uncertain\nsolutions are depicted and compared with the special case. The results are\nfound to be in good agreement when the membership values are unity.",
    "descriptor": "",
    "authors": [
      "Paresh Kumar Panigrahi",
      "Sukanta Nayak",
      "Sudipta Priyadarshini"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.00453"
  },
  {
    "id": "arXiv:2206.00455",
    "title": "A robust and lightweight deep attention multiple instance learning  algorithm for predicting genetic alterations",
    "abstract": "Deep-learning models based on whole-slide digital pathology images (WSIs)\nbecome increasingly popular for predicting molecular biomarkers. Instance-based\nmodels has been the mainstream strategy for predicting genetic alterations\nusing WSIs although bag-based models along with self-attention mechanism-based\nalgorithms have been proposed for other digital pathology applications. In this\npaper, we proposed a novel Attention-based Multiple Instance Mutation Learning\n(AMIML) model for predicting gene mutations. AMIML was comprised of successive\n1-D convolutional layers, a decoder, and a residual weight connection to\nfacilitate further integration of a lightweight attention mechanism to detect\nthe most predictive image patches. Using data for 24 clinically relevant genes\nfrom four cancer cohorts in The Cancer Genome Atlas (TCGA) studies (UCEC, BRCA,\nGBM and KIRC), we compared AMIML with one popular instance-based model and four\nrecently published bag-based models (e.g., CHOWDER, HE2RNA, etc.). AMIML\ndemonstrated excellent robustness, not only outperforming all the five baseline\nalgorithms in the vast majority of the tested genes (17 out of 24), but also\nproviding near-best-performance for the other seven genes. Conversely, the\nperformance of the baseline published algorithms varied across different\ncancers/genes. In addition, compared to the published models for genetic\nalterations, AMIML provided a significant improvement for predicting a wide\nrange of genes (e.g., KMT2C, TP53, and SETD2 for KIRC; ERBB2, BRCA1, and BRCA2\nfor BRCA; JAK1, POLE, and MTOR for UCEC) as well as produced outstanding\npredictive models for other clinically relevant gene mutations, which have not\nbeen reported in the current literature. Furthermore, with the flexible and\ninterpretable attention-based MIL pooling mechanism, AMIML could further\nzero-in and detect predictive image patches.",
    "descriptor": "",
    "authors": [
      "Bangwei Guo",
      "Xingyu Li",
      "Miaomiao Yang",
      "Hong Zhang",
      "Xu Steven Xu"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Genomics (q-bio.GN)"
    ],
    "url": "https://arxiv.org/abs/2206.00455"
  },
  {
    "id": "arXiv:2206.00457",
    "title": "Automatic differentiation of nonsmooth iterative algorithms",
    "abstract": "Differentiation along algorithms, i.e., piggyback propagation of derivatives,\nis now routinely used to differentiate iterative solvers in differentiable\nprogramming. Asymptotics is well understood for many smooth problems but the\nnondifferentiable case is hardly considered. Is there a limiting object for\nnonsmooth piggyback automatic differentiation (AD)? Does it have any\nvariational meaning and can it be used effectively in machine learning? Is\nthere a connection with classical derivative? All these questions are addressed\nunder appropriate nonexpansivity conditions in the framework of conservative\nderivatives which has proved useful in understanding nonsmooth AD. For\nnonsmooth piggyback iterations, we characterize the attractor set of nonsmooth\npiggyback iterations as a set-valued fixed point which remains in the\nconservative framework. This has various consequences and in particular almost\neverywhere convergence of classical derivatives. Our results are illustrated on\nparametric convex optimization problems with forward-backward, Douglas-Rachford\nand Alternating Direction of Multiplier algorithms as well as the Heavy-Ball\nmethod.",
    "descriptor": "",
    "authors": [
      "J\u00e9r\u00f4me Bolte",
      "Edouard Pauwels",
      "Samuel Vaiter"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00457"
  },
  {
    "id": "arXiv:2206.00493",
    "title": "Networked Sensing in 6G Cellular Networks: Opportunities and Challenges",
    "abstract": "Radar and wireless communication are widely acknowledged as the two most\nsuccessful applications of the radio technology over the past decades.\nRecently, there is a trend in both academia and industry to achieve integrated\nsensing and communication (ISAC) in one system via utilizing a common radio\nspectrum and the same hardware platform. This article will discuss about the\npossibility of exploiting the future sixth-generation (6G) cellular network to\nrealize ISAC. Our vision is that the cellular base stations (BSs) deployed all\nover the world can be transformed into a powerful sensor to provide\nhighresolution localization services. Specifically, motivated by the joint\nencoding/decoding gain in multi-cell coordinated communication, we advocate the\nadoption of the networked sensing technique in 6G network to achieve the above\ngoal, where the BSs can share the sensing information with each other for\njointly estimating the locations and velocities of the targets. Several\nopportunities and challenges to realize networked sensing in the 6G era will be\nrevealed in this article. Moreover, the future research directions for this\npromising trend will be outlined as well.",
    "descriptor": "",
    "authors": [
      "Liang Liu",
      "Shuowen Zhang",
      "Rui Du",
      "Tong Xiao Han",
      "Shuguang Cui"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.00493"
  },
  {
    "id": "arXiv:2206.00495",
    "title": "A kinetic description of the body size distributions of species",
    "abstract": "In this paper, by resorting to classical methods of statistical mechanics, we\nbuild a kinetic model able to reproduce the observed statistical weight\ndistribution of many diverse species. The kinetic description of the time\nvariations of the weight distribution is based on elementary interactions that\ndescribe in a qualitative and quantitative way successive evolutionary updates,\nand determine explicit equilibrium distributions. Numerical fittings on\nmammalian eutherians of the order Chiroptera population illustrates the\neffectiveness of the approach.",
    "descriptor": "",
    "authors": [
      "Stefano Gualandi",
      "Giuseppe Toscani",
      "Eleonora Vercesi"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2206.00495"
  },
  {
    "id": "arXiv:2206.00508",
    "title": "Convergence of Stein Variational Gradient Descent under a Weaker  Smoothness Condition",
    "abstract": "Stein Variational Gradient Descent (SVGD) is an important alternative to the\nLangevin-type algorithms for sampling from probability distributions of the\nform $\\pi(x) \\propto \\exp(-V(x))$. In the existing theory of Langevin-type\nalgorithms and SVGD, the potential function $V$ is often assumed to be\n$L$-smooth. However, this restrictive condition excludes a large class of\npotential functions such as polynomials of degree greater than $2$. Our paper\nstudies the convergence of the SVGD algorithm for distributions with\n$(L_0,L_1)$-smooth potentials. This relaxed smoothness assumption was\nintroduced by Zhang et al. [2019a] for the analysis of gradient clipping\nalgorithms. With the help of trajectory-independent auxiliary conditions, we\nprovide a descent lemma establishing that the algorithm decreases the\n$\\mathrm{KL}$ divergence at each iteration and prove a complexity bound for\nSVGD in the population limit in terms of the Stein Fisher information.",
    "descriptor": "",
    "authors": [
      "Lukang Sun",
      "Avetik Karagulyan",
      "Peter Richtarik"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2206.00508"
  },
  {
    "id": "arXiv:2206.00526",
    "title": "Minimum-Cost Flows Over Time",
    "abstract": "In this paper we show that every maximum minimum-cost flow over time problem\nhas an optimal solution with a repeated structure if the given time horizon is\nlarge enough.",
    "descriptor": "",
    "authors": [
      "Miriam Schl\u00f6ter",
      "Robert Weismantel"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.00526"
  },
  {
    "id": "arXiv:2206.00536",
    "title": "Impact of loss function in Deep Learning methods for accurate retinal  vessel segmentation",
    "abstract": "The retinal vessel network studied through fundus images contributes to the\ndiagnosis of multiple diseases not only found in the eye. The segmentation of\nthis system may help the specialized task of analyzing these images by\nassisting in the quantification of morphological characteristics. Due to its\nrelevance, several Deep Learning-based architectures have been tested for\ntackling this problem automatically. However, the impact of loss function\nselection on the segmentation of the intricate retinal blood vessel system\nhasn't been systematically evaluated. In this work, we present the comparison\nof the loss functions Binary Cross Entropy, Dice, Tversky, and Combo loss using\nthe deep learning architectures (i.e. U-Net, Attention U-Net, and Nested UNet)\nwith the DRIVE dataset. Their performance is assessed using four metrics: the\nAUC, the mean squared error, the dice score, and the Hausdorff distance. The\nmodels were trained with the same number of parameters and epochs. Using dice\nscore and AUC, the best combination was SA-UNet with Combo loss, which had an\naverage of 0.9442 and 0.809 respectively. The best average of Hausdorff\ndistance and mean square error were obtained using the Nested U-Net with the\nDice loss function, which had an average of 6.32 and 0.0241 respectively. The\nresults showed that there is a significant difference in the selection of loss\nfunction",
    "descriptor": "\nComments: Paper submitted to MICAI 2022\n",
    "authors": [
      "Daniela Herrera",
      "Gilberto Ochoa-Ruiz",
      "Miguel Gonzalez-Mendoza",
      "Christian Mata"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.00536"
  },
  {
    "id": "arXiv:2206.00566",
    "title": "The Fully Convolutional Transformer for Medical Image Segmentation",
    "abstract": "We propose a novel transformer model, capable of segmenting medical images of\nvarying modalities. Challenges posed by the fine grained nature of medical\nimage analysis mean that the adaptation of the transformer for their analysis\nis still at nascent stages. The overwhelming success of the UNet lay in its\nability to appreciate the fine-grained nature of the segmentation task, an\nability which existing transformer based models do not currently posses. To\naddress this shortcoming, we propose The Fully Convolutional Transformer (FCT),\nwhich builds on the proven ability of Convolutional Neural Networks to learn\neffective image representations, and combines them with the ability of\nTransformers to effectively capture long-term dependencies in its inputs. The\nFCT is the first fully convolutional Transformer model in medical imaging\nliterature. It processes its input in two stages, where first, it learns to\nextract long range semantic dependencies from the input image, and then learns\nto capture hierarchical global attributes from the features. FCT is compact,\naccurate and robust. Our results show that it outperforms all existing\ntransformer architectures by large margins across multiple medical image\nsegmentation datasets of varying data modalities without the need for any\npre-training. FCT outperforms its immediate competitor on the ACDC dataset by\n1.3%, on the Synapse dataset by 4.4%, on the Spleen dataset by 1.2% and on ISIC\n2017 dataset by 1.1% on the dice metric, with up to five times fewer\nparameters. Our code, environments and models will be available via GitHub.",
    "descriptor": "",
    "authors": [
      "Athanasios Tragakis",
      "Chaitanya Kaul",
      "Roderick Murray-Smith",
      "Dirk Husmeier"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.00566"
  },
  {
    "id": "arXiv:2206.00572",
    "title": "Discrete-velocity-direction models of BGK-type with minimum entropy: I.  Basic idea",
    "abstract": "In this series of works, we develop a discrete-velocity-direction model\n(DVDM) with collisions of BGK-type for simulating rarefied flows. Unlike the\nconventional kinetic models (both BGK and discrete-velocity models), the new\nmodel restricts the transport to finite fixed directions but leaves the\ntransport speed to be a 1-D continuous variable. Analogous to the BGK equation,\nthe discrete equilibriums of the model are determined by minimizing a discrete\nentropy. In this first paper, we introduce the DVDM and investigate its basic\nproperties, including the existence of the discrete equilibriums and the\n$H$-theorem. We also show that the discrete equilibriums can be efficiently\nobtained by solving a convex optimization problem. The proposed model provides\na new way in choosing discrete velocities for the computational practice of the\nconventional discrete-velocity methodology. It also facilitates a convenient\nmultidimensional extension of the extended quadrature method of moments. We\nvalidate the model with numerical experiments for two benchmark problems at\nmoderate computational costs.",
    "descriptor": "\nComments: 22 pages, 9 figures\n",
    "authors": [
      "Huang Qian",
      "Chen Yihong",
      "Yong Wen-An"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.00572"
  },
  {
    "id": "arXiv:2206.00579",
    "title": "Subexponential mixing for partition chains on grid-like graphs",
    "abstract": "We consider the problem of generating uniformly random partitions of the\nvertex set of a graph such that every piece induces a connected subgraph. For\nthe case where we want to have partitions with linearly many pieces of bounded\nsize, we obtain approximate sampling algorithms based on Glauber dynamics which\nare fixed-parameter tractable with respect to the bandwidth of $G$, with\nsimple-exponential dependence on the bandwidth. For example, for rectangles of\nconstant or logarithmic width this gives polynomial-time sampling algorithms.\nMore generally, this gives sub-exponential algorithms for bounded-degree graphs\nwithout large expander subgraphs (for example, we obtain $O(2^{\\sqrt n})$ time\nalgorithms for square grids).\nIn the case where we instead want partitions with a small number of pieces of\nlinear size, we show that Glauber dynamics can have exponential mixing time,\neven just for the case of 2 pieces, and even for 2-connected subgraphs of the\ngrid with bounded bandwidth.",
    "descriptor": "\nComments: 24 pages, 4 figures\n",
    "authors": [
      "Alan Frieze",
      "Wesley Pegden"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2206.00579"
  },
  {
    "id": "arXiv:2206.00594",
    "title": "Sparse graphs with bounded induced cycle packing number have logarithmic  treewidth",
    "abstract": "A graph is $O_k$-free if it does not contain $k$ pairwise vertex-disjoint and\nnon-adjacent cycles. We prove that \"sparse\" (here, not containing large\ncomplete bipartite graphs as subgraphs) $O_k$-free graphs have treewidth (even,\nfeedback vertex set number) at most logarithmic in the number of vertices,\nwhich is sharp already for $k=2$. As a consequence, most of the central\nNP-complete problems (such as Maximum Independent Set, Minimum Vertex Cover,\nMinimum Dominating Set, Minimum Coloring) can be solved in polynomial time in\nthese graphs, and in particular deciding the $O_k$-freeness of sparse graphs is\npolytime.",
    "descriptor": "\nComments: 27 pages, 6 figures\n",
    "authors": [
      "Marthe Bonamy",
      "\u00c9douard Bonnet",
      "Hugues D\u00e9pr\u00e9s",
      "Louis Esperet",
      "Colin Geniet",
      "Claire Hilaire",
      "St\u00e9phan Thomass\u00e9",
      "Alexandra Wesolek"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.00594"
  },
  {
    "id": "arXiv:2206.00632",
    "title": "Computing the Variance of Shuffling Stochastic Gradient Algorithms via  Power Spectral Density Analysis",
    "abstract": "When solving finite-sum minimization problems, two common alternatives to\nstochastic gradient descent (SGD) with theoretical benefits are random\nreshuffling (SGD-RR) and shuffle-once (SGD-SO), in which functions are sampled\nin cycles without replacement. Under a convenient stochastic noise\napproximation which holds experimentally, we study the stationary variances of\nthe iterates of SGD, SGD-RR and SGD-SO, whose leading terms decrease in this\norder, and obtain simple approximations. To obtain our results, we study the\npower spectral density of the stochastic gradient noise sequences. Our analysis\nextends beyond SGD to SGD with momentum and to the stochastic Nesterov's\naccelerated gradient method. We perform experiments on quadratic objective\nfunctions to test the validity of our approximation and the correctness of our\nfindings.",
    "descriptor": "\nComments: The code can be found at \\url{this https URL}\n",
    "authors": [
      "Carles Domingo-Enrich"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.00632"
  },
  {
    "id": "arXiv:2206.00648",
    "title": "A multimodal model with Twitter FinBERT embeddings for extreme price  movement prediction of Bitcoin",
    "abstract": "Bitcoin, with its ever-growing popularity, has demonstrated extreme price\nvolatility since its origin. This volatility, together with its decentralised\nnature, make Bitcoin highly subjective to speculative trading as compared to\nmore traditional assets. In this paper, we propose a multimodal model for\npredicting extreme price fluctuations. This model takes as input a variety of\ncorrelated assets, technical indicators, as well as Twitter content. In an\nin-depth study, we explore whether social media discussions from the general\npublic on Bitcoin have predictive power for extreme price movements. A dataset\nof 5,000 tweets per day containing the keyword `Bitcoin' was collected from\n2015 to 2021. This dataset, called PreBit, is made available online. In our\nhybrid model, we use sentence-level FinBERT embeddings, pretrained on financial\nlexicons, so as to capture the full contents of the tweets and feed it to the\nmodel in an understandable way. By combining these embeddings with a\nConvolutional Neural Network, we built a predictive model for significant\nmarket movements. The final multimodal ensemble model includes this NLP model\ntogether with a model based on candlestick data, technical indicators and\ncorrelated asset prices. In an ablation study, we explore the contribution of\nthe individual modalities. Finally, we propose and backtest a trading strategy\nbased on the predictions of our models with varying prediction threshold and\nshow that it can used to build a profitable trading strategy with a reduced\nrisk over a `hold' or moving average strategy.",
    "descriptor": "\nComments: 18 pages, submitted preprint to Elsevier Expert Systems with Applications\n",
    "authors": [
      "Yanzhao Zou",
      "Dorien Herremans"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00648"
  },
  {
    "id": "arXiv:2206.00649",
    "title": "Differentiable programming for functional connectomics",
    "abstract": "Mapping the functional connectome has the potential to uncover key insights\ninto brain organisation. However, existing workflows for functional\nconnectomics are limited in their adaptability to new data, and principled\nworkflow design is a challenging combinatorial problem. We introduce a new\nanalytic paradigm and software toolbox that implements common operations used\nin functional connectomics as fully differentiable processing blocks. Under\nthis paradigm, workflow configurations exist as reparameterisations of a\ndifferentiable functional that interpolates them. The differentiable program\nthat we envision occupies a niche midway between traditional pipelines and\nend-to-end neural networks, combining the glass-box tractability and domain\nknowledge of the former with the amenability to optimisation of the latter. In\nthis preliminary work, we provide a proof of concept for differentiable\nconnectomics, demonstrating the capacity of our processing blocks both to\nrecapitulate canonical knowledge in neuroscience and to make new discoveries in\nan unsupervised setting. Our differentiable modules are competitive with\nstate-of-the-art methods in problem domains including functional parcellation,\ndenoising, and covariance modelling. Taken together, our results and software\ndemonstrate the promise of differentiable programming for functional\nconnectomics.",
    "descriptor": "\nComments: 12 pages, 6 figures (Supplement: 10 pages, 3 figures). For associated code, see this https URL\n",
    "authors": [
      "Rastko Ciric",
      "Armin W. Thomas",
      "Oscar Esteban",
      "Russell A. Poldrack"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00649"
  },
  {
    "id": "arXiv:1810.07822",
    "title": "When Can We Answer Queries Using Result-Bounded Data Interfaces?",
    "abstract": "Comments: journal version of the PODS'18 paper arXiv:1706.07936",
    "descriptor": "\nComments: journal version of the PODS'18 paper arXiv:1706.07936\n",
    "authors": [
      "Antoine Amarilli",
      "Michael Benedikt"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/1810.07822"
  },
  {
    "id": "arXiv:1910.06708",
    "title": "Efficiently Embedding Dynamic Knowledge Graphs",
    "abstract": "Comments: 46 pages",
    "descriptor": "\nComments: 46 pages\n",
    "authors": [
      "Tianxing Wu",
      "Arijit Khan",
      "Melvin Yong",
      "Guilin Qi",
      "Meng Wang"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/1910.06708"
  },
  {
    "id": "arXiv:1911.03629",
    "title": "Tit-for-Tat Dynamics and Market Volatility",
    "abstract": "Comments: 19 pages, 5 figures",
    "descriptor": "\nComments: 19 pages, 5 figures\n",
    "authors": [
      "Simina Br\u00e2nzei"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/1911.03629"
  },
  {
    "id": "arXiv:1912.06252",
    "title": "A scaling-invariant algorithm for linear programming whose running time  depends only on the constraint matrix",
    "abstract": "A scaling-invariant algorithm for linear programming whose running time  depends only on the constraint matrix",
    "descriptor": "",
    "authors": [
      "Daniel Dadush",
      "Sophie Huiberts",
      "Bento Natura",
      "L\u00e1szl\u00f3 A. V\u00e9gh"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/1912.06252"
  },
  {
    "id": "arXiv:1912.11225",
    "title": "A note on the elementary construction of High-Dimensional Expanders of  Kaufman and Oppenheim",
    "abstract": "A note on the elementary construction of High-Dimensional Expanders of  Kaufman and Oppenheim",
    "descriptor": "",
    "authors": [
      "Prahladh Harsha",
      "Ramprasad Saptharishi"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/1912.11225"
  },
  {
    "id": "arXiv:2007.09248",
    "title": "Fine Timing and Frequency Synchronization for MIMO-OFDM: An Extreme  Learning Approach",
    "abstract": "Comments: 13 pages, 12 figures, has been accepted for publication in IEEE Transactions on Cognitive Communications and Networking",
    "descriptor": "\nComments: 13 pages, 12 figures, has been accepted for publication in IEEE Transactions on Cognitive Communications and Networking\n",
    "authors": [
      "Jun Liu",
      "Kai Mei",
      "Xiaochen Zhang",
      "Des McLernon",
      "Dongtang Ma",
      "Jibo Wei",
      "Syed Ali Raza Zaidi"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2007.09248"
  },
  {
    "id": "arXiv:2009.13243",
    "title": "Generating End-to-End Adversarial Examples for Malware Classifiers Using  Explainability",
    "abstract": "Comments: Accepted as a conference paper at IJCNN 2020",
    "descriptor": "\nComments: Accepted as a conference paper at IJCNN 2020\n",
    "authors": [
      "Ishai Rosenberg",
      "Shai Meir",
      "Jonathan Berrebi",
      "Ilay Gordon",
      "Guillaume Sicard",
      "Eli David"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2009.13243"
  },
  {
    "id": "arXiv:2011.09497",
    "title": "High-Throughput Approach to Modeling Healthcare Costs Using Electronic  Healthcare Records",
    "abstract": "Comments: 4 pages, 3 figures",
    "descriptor": "\nComments: 4 pages, 3 figures\n",
    "authors": [
      "Alex Taylor",
      "Ross Kleiman",
      "Scott Hebbring",
      "Peggy Peissig",
      "David Page"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.09497"
  },
  {
    "id": "arXiv:2011.10221",
    "title": "Goldblatt-Thomason Theorems for Modal Intuitionistic Logics",
    "abstract": "Goldblatt-Thomason Theorems for Modal Intuitionistic Logics",
    "descriptor": "",
    "authors": [
      "Jim de Groot"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2011.10221"
  },
  {
    "id": "arXiv:2011.10487",
    "title": "Normalization effects on shallow neural networks and related asymptotic  expansions",
    "abstract": "Comments: Added link to code on GitHub: this https URL",
    "descriptor": "\nComments: Added link to code on GitHub: this https URL\n",
    "authors": [
      "Jiahui Yu",
      "Konstantinos Spiliopoulos"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2011.10487"
  },
  {
    "id": "arXiv:2012.05776",
    "title": "Multi-Sense Language Modelling",
    "abstract": "Multi-Sense Language Modelling",
    "descriptor": "",
    "authors": [
      "Andrea Lekkas",
      "Peter Schneider-Kamp",
      "Isabelle Augenstein"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2012.05776"
  },
  {
    "id": "arXiv:2012.06268",
    "title": "Motion Mappings for Continuous Bilateral Teleoperation",
    "abstract": "Comments: Accepted for publication at the IEEE Robotics and Automation Letters (RA-L)",
    "descriptor": "\nComments: Accepted for publication at the IEEE Robotics and Automation Letters (RA-L)\n",
    "authors": [
      "Xiao Gao",
      "Jo\u00e3o Silv\u00e9rio",
      "Emmanuel Pignat",
      "Sylvain Calinon",
      "Miao Li",
      "Xiaohui Xiao"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2012.06268"
  },
  {
    "id": "arXiv:2012.10559",
    "title": "Identifying the latent space geometry of network models through analysis  of curvature",
    "abstract": "Identifying the latent space geometry of network models through analysis  of curvature",
    "descriptor": "",
    "authors": [
      "Shane Lubold",
      "Arun G. Chandrasekhar",
      "Tyler H. McCormick"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Social and Information Networks (cs.SI)",
      "Geometric Topology (math.GT)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2012.10559"
  },
  {
    "id": "arXiv:2102.10828",
    "title": "Automatic sequences: from rational bases to trees",
    "abstract": "Comments: 26 pages, 16 figures; final version accepted for publication in Discrete Mathematics & Theoretical Computer Science",
    "descriptor": "\nComments: 26 pages, 16 figures; final version accepted for publication in Discrete Mathematics & Theoretical Computer Science\n",
    "authors": [
      "Michel Rigo",
      "Manon Stipulanti"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2102.10828"
  },
  {
    "id": "arXiv:2103.08241",
    "title": "Reinforcement Learning with Algorithms from Probabilistic Structure  Estimation",
    "abstract": "Reinforcement Learning with Algorithms from Probabilistic Structure  Estimation",
    "descriptor": "",
    "authors": [
      "Jonathan P. Epperlein",
      "Roman Overko",
      "Sergiy Zhuk",
      "Christopher King",
      "Djallel Bouneffouf",
      "Andrew Cullen",
      "Robert Shorten"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.08241"
  },
  {
    "id": "arXiv:2103.15022",
    "title": "'Just because you are right, doesn't mean I am wrong': Overcoming a  Bottleneck in the Development and Evaluation of Open-Ended Visual Question  Answering (VQA) Tasks",
    "abstract": "Comments: accepted to EACL 2021",
    "descriptor": "\nComments: accepted to EACL 2021\n",
    "authors": [
      "Man Luo",
      "Shailaja Keyur Sampat",
      "Riley Tallman",
      "Yankai Zeng",
      "Manuha Vancha",
      "Akarshan Sajja",
      "Chitta Baral"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2103.15022"
  },
  {
    "id": "arXiv:2104.00432",
    "title": "Anchor Pruning for Object Detection",
    "abstract": "Anchor Pruning for Object Detection",
    "descriptor": "",
    "authors": [
      "Maxim Bonnaerens",
      "Matthias Freiberger",
      "Joni Dambre"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.00432"
  },
  {
    "id": "arXiv:2104.02556",
    "title": "Physics-Informed Neural Nets for Control of Dynamical Systems",
    "abstract": "Physics-Informed Neural Nets for Control of Dynamical Systems",
    "descriptor": "",
    "authors": [
      "Eric Aislan Antonelo",
      "Eduardo Camponogara",
      "Laio Oriel Seman",
      "Eduardo Rehbein de Souza",
      "Jean P. Jordanou",
      "Jomi F. Hubner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.02556"
  },
  {
    "id": "arXiv:2104.07182",
    "title": "Convolutions for Spatial Interaction Modeling",
    "abstract": "Comments: Supplementary material included",
    "descriptor": "\nComments: Supplementary material included\n",
    "authors": [
      "Zhaoen Su",
      "Chao Wang",
      "David Bradley",
      "Carlos Vallespi-Gonzalez",
      "Carl Wellington",
      "Nemanja Djuric"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.07182"
  },
  {
    "id": "arXiv:2105.03288",
    "title": "A Hybrid Architecture for Federated and Centralized Learning",
    "abstract": "Comments: Accepted paper in IEEE Transactions on Cognitive Communications and Networking",
    "descriptor": "\nComments: Accepted paper in IEEE Transactions on Cognitive Communications and Networking\n",
    "authors": [
      "Ahmet M. Elbir",
      "Sinem Coleri",
      "Anastasios K. Papazafeiropoulos",
      "Pandelis Kourtessis",
      "Symeon Chatzinotas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.03288"
  },
  {
    "id": "arXiv:2105.14173",
    "title": "FoveaTer: Foveated Transformer for Image Classification",
    "abstract": "Comments: 17 pages, 7 figures",
    "descriptor": "\nComments: 17 pages, 7 figures\n",
    "authors": [
      "Aditya Jonnalagadda",
      "William Yang Wang",
      "B. S. Manjunath",
      "Miguel P. Eckstein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14173"
  },
  {
    "id": "arXiv:2106.01628",
    "title": "A Coalgebraic Approach to Dualities for Neighborhood Frames",
    "abstract": "A Coalgebraic Approach to Dualities for Neighborhood Frames",
    "descriptor": "",
    "authors": [
      "Guram Bezhanishvili",
      "Nick Bezhanishvili",
      "Jim de Groot"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.01628"
  },
  {
    "id": "arXiv:2106.03462",
    "title": "SILVAN: Estimating Betweenness Centralities with Progressive Sampling  and Non-uniform Rademacher Bounds",
    "abstract": "SILVAN: Estimating Betweenness Centralities with Progressive Sampling  and Non-uniform Rademacher Bounds",
    "descriptor": "",
    "authors": [
      "Leonardo Pellegrina",
      "Fabio Vandin"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.03462"
  },
  {
    "id": "arXiv:2106.03676",
    "title": "Learning a performance metric of Buchberger's algorithm",
    "abstract": "Learning a performance metric of Buchberger's algorithm",
    "descriptor": "",
    "authors": [
      "Jelena Mojsilovi\u0107",
      "Dylan Peifer",
      "Sonja Petrovi\u0107"
    ],
    "subjectives": [
      "Commutative Algebra (math.AC)",
      "Machine Learning (cs.LG)",
      "Symbolic Computation (cs.SC)",
      "Algebraic Geometry (math.AG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.03676"
  },
  {
    "id": "arXiv:2106.08567",
    "title": "Optimal Accounting of Differential Privacy via Characteristic Function",
    "abstract": "Optimal Accounting of Differential Privacy via Characteristic Function",
    "descriptor": "",
    "authors": [
      "Yuqing Zhu",
      "Jinshuo Dong",
      "Yu-Xiang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.08567"
  },
  {
    "id": "arXiv:2106.10151",
    "title": "The Dimpled Manifold Model of Adversarial Examples in Machine Learning",
    "abstract": "The Dimpled Manifold Model of Adversarial Examples in Machine Learning",
    "descriptor": "",
    "authors": [
      "Adi Shamir",
      "Odelia Melamed",
      "Oriel BenShmuel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10151"
  },
  {
    "id": "arXiv:2107.02363",
    "title": "Asymptotics of Network Embeddings Learned via Subsampling",
    "abstract": "Comments: 117 pages, 3 figures, 1 table",
    "descriptor": "\nComments: 117 pages, 3 figures, 1 table\n",
    "authors": [
      "Andrew Davison",
      "Morgane Austern"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2107.02363"
  },
  {
    "id": "arXiv:2107.07999",
    "title": "From block-Toeplitz matrices to differential equations on graphs:  towards a general theory for scalable masked Transformers",
    "abstract": "Comments: 20 pages, 12 figures",
    "descriptor": "\nComments: 20 pages, 12 figures\n",
    "authors": [
      "Krzysztof Choromanski",
      "Han Lin",
      "Haoxian Chen",
      "Tianyi Zhang",
      "Arijit Sehanobish",
      "Valerii Likhosherstov",
      "Jack Parker-Holder",
      "Tamas Sarlos",
      "Adrian Weller",
      "Thomas Weingarten"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.07999"
  },
  {
    "id": "arXiv:2107.08036",
    "title": "The strong converse exponent of discriminating infinite-dimensional  quantum states",
    "abstract": "Comments: 39 pages. v4: Some proofs simplified, some statements improved, some typos corrected. Submitted version. v5: Remark IV.7 on the strong converse of Stein's lemma corrected",
    "descriptor": "\nComments: 39 pages. v4: Some proofs simplified, some statements improved, some typos corrected. Submitted version. v5: Remark IV.7 on the strong converse of Stein's lemma corrected\n",
    "authors": [
      "Mil\u00e1n Mosonyi"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2107.08036"
  },
  {
    "id": "arXiv:2107.12910",
    "title": "Sparse Bayesian Deep Learning for Dynamic System Identification",
    "abstract": "Sparse Bayesian Deep Learning for Dynamic System Identification",
    "descriptor": "",
    "authors": [
      "Hongpeng Zhou",
      "Chahine Ibrahim",
      "Wei Xing Zheng",
      "Wei Pan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.12910"
  },
  {
    "id": "arXiv:2108.00190",
    "title": "Sequence-to-Sequence Voice Reconstruction for Silent Speech in a Tonal  Language",
    "abstract": "Sequence-to-Sequence Voice Reconstruction for Silent Speech in a Tonal  Language",
    "descriptor": "",
    "authors": [
      "Huiyan Li",
      "Haohong Lin",
      "You Wang",
      "Hengyang Wang",
      "Ming Zhang",
      "Han Gao",
      "Qing Ai",
      "Zhiyuan Luo",
      "Guang Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Human-Computer Interaction (cs.HC)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2108.00190"
  },
  {
    "id": "arXiv:2108.00356",
    "title": "Improving Social Meaning Detection with Pragmatic Masking and Surrogate  Fine-Tuning",
    "abstract": "Comments: 12th Workshop on Computational Approaches to Subjectivity, Sentiment & Social Media Analysis at ACL 2022 (corrected typos)",
    "descriptor": "\nComments: 12th Workshop on Computational Approaches to Subjectivity, Sentiment & Social Media Analysis at ACL 2022 (corrected typos)\n",
    "authors": [
      "Chiyu Zhang",
      "Muhammad Abdul-Mageed"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.00356"
  },
  {
    "id": "arXiv:2108.01558",
    "title": "Intra-Basis Multiplication of Polynomials Given in Various Polynomial  Bases",
    "abstract": "Intra-Basis Multiplication of Polynomials Given in Various Polynomial  Bases",
    "descriptor": "",
    "authors": [
      "S. Karami",
      "M. Ahmadnasab",
      "M. Hadizadeh",
      "A. Amiraslani"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2108.01558"
  },
  {
    "id": "arXiv:2108.03874",
    "title": "Zero-Error Feedback Capacity for Bounded Stabilization and Finite-State  Additive Noise Channels",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2006.00892",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2006.00892\n",
    "authors": [
      "Amir Saberi",
      "Farhad Farokhi",
      "Girish Nair"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2108.03874"
  },
  {
    "id": "arXiv:2108.05345",
    "title": "The Lawson-Hanson Algorithm with Deviation Maximization: Finite  Convergence and Sparse Recovery",
    "abstract": "Comments: 30 pages",
    "descriptor": "\nComments: 30 pages\n",
    "authors": [
      "Monica Dessole",
      "Marco Dell'Orto",
      "Fabio Marcuzzi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2108.05345"
  },
  {
    "id": "arXiv:2108.07467",
    "title": "Neonatal Bowel Sound Detection Using Convolutional Neural Network and  Laplace Hidden Semi-Markov Model",
    "abstract": "Comments: Published in IEEE/ACM Transactions on Audio Speech and Language Processing journal",
    "descriptor": "\nComments: Published in IEEE/ACM Transactions on Audio Speech and Language Processing journal\n",
    "authors": [
      "Chiranjibi Sitaula",
      "Jinyuan He",
      "Archana Priyadarshi",
      "Mark Tracy",
      "Omid Kavehei",
      "Murray Hinder",
      "Anusha Withana",
      "Alistair McEwan",
      "Faezeh Marzbanrad"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2108.07467"
  },
  {
    "id": "arXiv:2108.07689",
    "title": "A multimodal sensor dataset for continuous stress detection of nurses in  a hospital",
    "abstract": "Comments: 14 pages, 9 images",
    "descriptor": "\nComments: 14 pages, 9 images\n",
    "authors": [
      "Seyedmajid Hosseini",
      "Satya Katragadda",
      "Ravi Teja Bhupatiraju",
      "Ziad Ashkar",
      "Christoph W. Borst",
      "Kenneth Cochran",
      "Raju Gottumukkala"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2108.07689"
  },
  {
    "id": "arXiv:2108.08963",
    "title": "Impact of Aviation Electrification on Airports: Flight Scheduling and  Charging",
    "abstract": "Comments: 19 pages, 8 figures",
    "descriptor": "\nComments: 19 pages, 8 figures\n",
    "authors": [
      "Boya Hou",
      "Subhonmesh Bose",
      "Lavanya Marla",
      "Kiruba Haran"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2108.08963"
  },
  {
    "id": "arXiv:2109.02555",
    "title": "GPT-3 Models are Poor Few-Shot Learners in the Biomedical Domain",
    "abstract": "GPT-3 Models are Poor Few-Shot Learners in the Biomedical Domain",
    "descriptor": "",
    "authors": [
      "Milad Moradi",
      "Kathrin Blagec",
      "Florian Haberl",
      "Matthias Samwald"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.02555"
  },
  {
    "id": "arXiv:2109.02934",
    "title": "Fishr: Invariant Gradient Variances for Out-of-Distribution  Generalization",
    "abstract": "Comments: 31 pages, 14 tables, 7 figures",
    "descriptor": "\nComments: 31 pages, 14 tables, 7 figures\n",
    "authors": [
      "Alexandre Rame",
      "Corentin Dancette",
      "Matthieu Cord"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.02934"
  },
  {
    "id": "arXiv:2109.03878",
    "title": "Unsupervised Detection and Clustering of Malicious TLS Flows",
    "abstract": "Unsupervised Detection and Clustering of Malicious TLS Flows",
    "descriptor": "",
    "authors": [
      "Gibran Gomez",
      "Platon Kotzias",
      "Matteo Dell'Amico",
      "Leyla Bilge",
      "Juan Caballero"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.03878"
  },
  {
    "id": "arXiv:2109.08475",
    "title": "GoG: Relation-aware Graph-over-Graph Network for Visual Dialog",
    "abstract": "Comments: ACL Findings 2021. arXiv admin note: text overlap with arXiv:2109.06013",
    "descriptor": "\nComments: ACL Findings 2021. arXiv admin note: text overlap with arXiv:2109.06013\n",
    "authors": [
      "Feilong Chen",
      "Xiuyi Chen",
      "Fandong Meng",
      "Peng Li",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.08475"
  },
  {
    "id": "arXiv:2109.09136",
    "title": "An adaptive stochastic Galerkin method based on multilevel expansions of  random fields: Convergence and optimality",
    "abstract": "Comments: 35 pages, 2 figures",
    "descriptor": "\nComments: 35 pages, 2 figures\n",
    "authors": [
      "Markus Bachmayr",
      "Igor Voulis"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.09136"
  },
  {
    "id": "arXiv:2109.09447",
    "title": "Algorithmic Fairness Verification with Graphical Models",
    "abstract": "Algorithmic Fairness Verification with Graphical Models",
    "descriptor": "",
    "authors": [
      "Bishwamittra Ghosh",
      "Debabrota Basu",
      "Kuldeep S. Meel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2109.09447"
  },
  {
    "id": "arXiv:2109.12784",
    "title": "Learning from Small Samples: Transformation-Invariant SVMs with  Composition and Locality at Multiple Scales",
    "abstract": "Learning from Small Samples: Transformation-Invariant SVMs with  Composition and Locality at Multiple Scales",
    "descriptor": "",
    "authors": [
      "Tao Liu",
      "P. R. Kumar",
      "Ruida Zhou",
      "Xi Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.12784"
  },
  {
    "id": "arXiv:2109.13665",
    "title": "A deep dive into the accuracy of IP Geolocation Databases and its impact  on online advertising",
    "abstract": "A deep dive into the accuracy of IP Geolocation Databases and its impact  on online advertising",
    "descriptor": "",
    "authors": [
      "Patricia Callejo",
      "Marco Gramaglia",
      "Rub\u00e9n Cuevas",
      "\u00c1ngel Cuevas"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2109.13665"
  },
  {
    "id": "arXiv:2110.08449",
    "title": "Adversarial Attacks on Gaussian Process Bandits",
    "abstract": "Comments: Accepted to ICML 2022",
    "descriptor": "\nComments: Accepted to ICML 2022\n",
    "authors": [
      "Eric Han",
      "Jonathan Scarlett"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08449"
  },
  {
    "id": "arXiv:2110.15609",
    "title": "BiC-Net: Learning Efficient Spatio-Temporal Relation for Text-Video  Retrieval",
    "abstract": "Comments: 12 pages",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Ning Han",
      "Jingjing Chen",
      "Chuhao Shi",
      "Yawen Zeng",
      "Guangyi Xiao",
      "Hao Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.15609"
  },
  {
    "id": "arXiv:2111.00282",
    "title": "Twin-width VI: the lens of contraction sequences",
    "abstract": "Comments: 27 pages, 3 figures",
    "descriptor": "\nComments: 27 pages, 3 figures\n",
    "authors": [
      "\u00c9douard Bonnet",
      "Eun Jung Kim",
      "Amadeus Reinald",
      "St\u00e9phan Thomass\u00e9"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Logic in Computer Science (cs.LO)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2111.00282"
  },
  {
    "id": "arXiv:2111.01526",
    "title": "A modified gravity model based on network efficiency for vital nodes  identification in complex networks",
    "abstract": "A modified gravity model based on network efficiency for vital nodes  identification in complex networks",
    "descriptor": "",
    "authors": [
      "Hanwen Li",
      "Qiuyan Shang",
      "Yong Deng"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.01526"
  },
  {
    "id": "arXiv:2111.03333",
    "title": "Effective Cross-Utterance Language Modeling for Conversational Speech  Recognition",
    "abstract": "Comments: 6 pages, 6 figures, and 4 tables. Accepted by 2022 International Joint Conference on Neural Networks (IJCNN 2022)",
    "descriptor": "\nComments: 6 pages, 6 figures, and 4 tables. Accepted by 2022 International Joint Conference on Neural Networks (IJCNN 2022)\n",
    "authors": [
      "Bi-Cheng Yan",
      "Hsin-Wei Wang",
      "Shih-Hsuan Chiu",
      "Hsuan-Sheng Chiu",
      "Berlin Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.03333"
  },
  {
    "id": "arXiv:2111.04089",
    "title": "Sampling from Log-Concave Distributions with Infinity-Distance  Guarantees",
    "abstract": "Sampling from Log-Concave Distributions with Infinity-Distance  Guarantees",
    "descriptor": "",
    "authors": [
      "Oren Mangoubi",
      "Nisheeth K. Vishnoi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.04089"
  },
  {
    "id": "arXiv:2111.05463",
    "title": "An Open-Source RRAM Compiler",
    "abstract": "Comments: Final Version of NEWCAS 2022. 5 pages",
    "descriptor": "\nComments: Final Version of NEWCAS 2022. 5 pages\n",
    "authors": [
      "Dimitris Antoniadis",
      "Andrea Mifsud",
      "Peilong Feng",
      "Timothy G. Constandinou"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2111.05463"
  },
  {
    "id": "arXiv:2111.06682",
    "title": "A Bayesian Nash equilibrium-based moving target defense against stealthy  sensor attacks",
    "abstract": "Comments: 16 pages, 4 figures, 4 tables",
    "descriptor": "\nComments: 16 pages, 4 figures, 4 tables\n",
    "authors": [
      "David Umsonst",
      "Serkan Sar\u0131ta\u015f",
      "Gy\u00f6rgy D\u00e1n",
      "Henrik Sandberg"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.06682"
  },
  {
    "id": "arXiv:2111.07283",
    "title": "Intensity Mapping Functions For HDR Panorama Imaging: Weighted Histogram  Averaging",
    "abstract": "Comments: 11 pages, 5 figures",
    "descriptor": "\nComments: 11 pages, 5 figures\n",
    "authors": [
      "Yilun Xu",
      "Zhengguo Li",
      "Weihai Chen",
      "Changyun Wen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.07283"
  },
  {
    "id": "arXiv:2111.08276",
    "title": "Multi-Grained Vision Language Pre-Training: Aligning Texts with Visual  Concepts",
    "abstract": "Comments: ICML 2022",
    "descriptor": "\nComments: ICML 2022\n",
    "authors": [
      "Yan Zeng",
      "Xinsong Zhang",
      "Hang Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.08276"
  },
  {
    "id": "arXiv:2111.12677",
    "title": "Topological and Algebraic Structures of Atanassov's Intuitionistic  Fuzzy-Values Space",
    "abstract": "Topological and Algebraic Structures of Atanassov's Intuitionistic  Fuzzy-Values Space",
    "descriptor": "",
    "authors": [
      "Xinxing Wu",
      "Tao Wang",
      "Qian Liu",
      "Peide Liu",
      "Guanrong Chen",
      "Xu Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.12677"
  },
  {
    "id": "arXiv:2111.13143",
    "title": "Casimir preserving stochastic Lie-Poisson integrators",
    "abstract": "Comments: 22 pages, 9 figures, fourth version, all comments are welcome!",
    "descriptor": "\nComments: 22 pages, 9 figures, fourth version, all comments are welcome!\n",
    "authors": [
      "Erwin Luesink",
      "Sagy Ephrati",
      "Paolo Cifani",
      "Bernard Geurts"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.13143"
  },
  {
    "id": "arXiv:2111.13149",
    "title": "A Comparative Analysis of Machine Learning Techniques for IoT Intrusion  Detection",
    "abstract": "Comments: 16 pages, 12 tables, 4 figures, FPS 2021 conference",
    "descriptor": "\nComments: 16 pages, 12 tables, 4 figures, FPS 2021 conference\n",
    "authors": [
      "Jo\u00e3o Vitorino",
      "Rui Andrade",
      "Isabel Pra\u00e7a",
      "Orlando Sousa",
      "Eva Maia"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.13149"
  },
  {
    "id": "arXiv:2111.14621",
    "title": "Improving Customer Service Chatbots with Attention-based Transfer  Learning",
    "abstract": "Improving Customer Service Chatbots with Attention-based Transfer  Learning",
    "descriptor": "",
    "authors": [
      "Jordan J. Bird"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.14621"
  },
  {
    "id": "arXiv:2112.00980",
    "title": "Trap of Feature Diversity in the Learning of MLPs",
    "abstract": "Trap of Feature Diversity in the Learning of MLPs",
    "descriptor": "",
    "authors": [
      "Dongrui Liu",
      "Shaobo Wang",
      "Jie Ren",
      "Kangrui Wang",
      "Sheng Yin",
      "Huiqi Deng",
      "Quanshi Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.00980"
  },
  {
    "id": "arXiv:2112.01583",
    "title": "The Representation Jensen-R\u00e9nyi Divergence",
    "abstract": "Comments: We added acknowledgments",
    "descriptor": "\nComments: We added acknowledgments\n",
    "authors": [
      "Jhoan Keider Hoyos Osorio",
      "Oscar Skean",
      "Austin J. Brockmeier",
      "Luis Gonzalo Sanchez Giraldo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.01583"
  },
  {
    "id": "arXiv:2112.04150",
    "title": "BA-Net: Bridge Attention for Deep Convolutional Neural Networks",
    "abstract": "BA-Net: Bridge Attention for Deep Convolutional Neural Networks",
    "descriptor": "",
    "authors": [
      "Yue Zhao",
      "Junzhou Chen",
      "Zirui Zhang",
      "Ronghui Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.04150"
  },
  {
    "id": "arXiv:2112.05579",
    "title": "Solving degree, last fall degree, and related invariants",
    "abstract": "Comments: Final version. To appear in Journal of Symbolic Computation",
    "descriptor": "\nComments: Final version. To appear in Journal of Symbolic Computation\n",
    "authors": [
      "Alessio Caminata",
      "Elisa Gorla"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Symbolic Computation (cs.SC)",
      "Commutative Algebra (math.AC)"
    ],
    "url": "https://arxiv.org/abs/2112.05579"
  },
  {
    "id": "arXiv:2112.08739",
    "title": "Forensic Analysis of Synthetically Generated Western Blot Images",
    "abstract": "Forensic Analysis of Synthetically Generated Western Blot Images",
    "descriptor": "",
    "authors": [
      "Sara Mandelli",
      "Davide Cozzolino",
      "Edoardo D. Cannas",
      "Joao P. Cardenuto",
      "Daniel Moreira",
      "Paolo Bestagini",
      "Walter J. Scheirer",
      "Anderson Rocha",
      "Luisa Verdoliva",
      "Stefano Tubaro",
      "Edward J. Delp"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08739"
  },
  {
    "id": "arXiv:2112.10325",
    "title": "Incremental Cross-view Mutual Distillation for Self-supervised Medical  CT Synthesis",
    "abstract": "Comments: Accepted by CVPR2022",
    "descriptor": "\nComments: Accepted by CVPR2022\n",
    "authors": [
      "Chaowei Fang",
      "Liang Wang",
      "Dingwen Zhang",
      "Jun Xu",
      "Yixuan Yuan",
      "Junwei Han"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.10325"
  },
  {
    "id": "arXiv:2112.11020",
    "title": "Efficient reductions and algorithms for variants of Subset Sum",
    "abstract": "Comments: A part of this work has been published in the proceedings of CALDAM 2022. We have improved running-time of some algorithms from the previous version of the draft",
    "descriptor": "\nComments: A part of this work has been published in the proceedings of CALDAM 2022. We have improved running-time of some algorithms from the previous version of the draft\n",
    "authors": [
      "Pranjal Dutta",
      "Mahesh Sreekumar Rajasree"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.11020"
  },
  {
    "id": "arXiv:2112.14683",
    "title": "StyleGAN-V: A Continuous Video Generator with the Price, Image Quality  and Perks of StyleGAN2",
    "abstract": "Comments: CVPR 2022",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Ivan Skorokhodov",
      "Sergey Tulyakov",
      "Mohamed Elhoseiny"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.14683"
  },
  {
    "id": "arXiv:2112.15011",
    "title": "Radiology Report Generation with a Learned Knowledge Base and  Multi-modal Alignment",
    "abstract": "Radiology Report Generation with a Learned Knowledge Base and  Multi-modal Alignment",
    "descriptor": "",
    "authors": [
      "Shuxin Yang",
      "Xian Wu",
      "Shen Ge",
      "S.Kevin Zhou",
      "Li Xiao"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.15011"
  },
  {
    "id": "arXiv:2201.01105",
    "title": "New RED-type TCP-AQM algorithms based on beta distribution drop  functions",
    "abstract": "New RED-type TCP-AQM algorithms based on beta distribution drop  functions",
    "descriptor": "",
    "authors": [
      "Angel Gim\u00e9nez",
      "Miguel A. Murcia",
      "Jos\u00e9 M. Amig\u00f3",
      "Oscar Mart\u00ednez-Bonastre",
      "Jos\u00e9 Valero"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2201.01105"
  },
  {
    "id": "arXiv:2201.01689",
    "title": "Asymptotics of $\\ell_2$ Regularized Network Embeddings",
    "abstract": "Comments: 40 pages, 2 figures, 2 tables",
    "descriptor": "\nComments: 40 pages, 2 figures, 2 tables\n",
    "authors": [
      "Andrew Davison"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2201.01689"
  },
  {
    "id": "arXiv:2201.03698",
    "title": "Verified Probabilistic Policies for Deep Reinforcement Learning",
    "abstract": "Comments: NFM 2022",
    "descriptor": "\nComments: NFM 2022\n",
    "authors": [
      "Edoardo Bacci",
      "David Parker"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2201.03698"
  },
  {
    "id": "arXiv:2201.06262",
    "title": "Optimisation of Structured Neural Controller Based on Continuous-Time  Policy Gradient",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Namhoon Cho",
      "Hyo-Sang Shin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.06262"
  },
  {
    "id": "arXiv:2201.07459",
    "title": "Using Self-Supervised Pretext Tasks for Active Learning",
    "abstract": "Using Self-Supervised Pretext Tasks for Active Learning",
    "descriptor": "",
    "authors": [
      "John Seon Keun Yi",
      "Minseok Seo",
      "Jongchan Park",
      "Dong-Geol Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.07459"
  },
  {
    "id": "arXiv:2201.09555",
    "title": "A Knowledge Graph Embeddings based Approach for Author Name  Disambiguation using Literals",
    "abstract": "A Knowledge Graph Embeddings based Approach for Author Name  Disambiguation using Literals",
    "descriptor": "",
    "authors": [
      "Cristian Santini",
      "Genet Asefa Gesese",
      "Silvio Peroni",
      "Aldo Gangemi",
      "Harald Sack",
      "Mehwish Alam"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2201.09555"
  },
  {
    "id": "arXiv:2201.11579",
    "title": "Total variation-based reconstruction and phase retrieval for diffraction  tomography",
    "abstract": "Comments: 30 pages, 13 figures",
    "descriptor": "\nComments: 30 pages, 13 figures\n",
    "authors": [
      "Robert Beinert",
      "Michael Quellmalz"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Image and Video Processing (eess.IV)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2201.11579"
  },
  {
    "id": "arXiv:2201.11611",
    "title": "Asymmetric Coded Caching for Multi-Antenna Location-Dependent Content  Delivery",
    "abstract": "Comments: 31 pages, 15 figures, journal paper. arXiv admin note: text overlap with arXiv:2102.02518",
    "descriptor": "\nComments: 31 pages, 15 figures, journal paper. arXiv admin note: text overlap with arXiv:2102.02518\n",
    "authors": [
      "Hamidreza Bakhshzad Mahmoodi",
      "MohammadJavad Salehi",
      "Antti T\u00f6lli"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2201.11611"
  },
  {
    "id": "arXiv:2201.11903",
    "title": "Chain of Thought Prompting Elicits Reasoning in Large Language Models",
    "abstract": "Chain of Thought Prompting Elicits Reasoning in Large Language Models",
    "descriptor": "",
    "authors": [
      "Jason Wei",
      "Xuezhi Wang",
      "Dale Schuurmans",
      "Maarten Bosma",
      "Brian Ichter",
      "Fei Xia",
      "Ed Chi",
      "Quoc Le",
      "Denny Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11903"
  },
  {
    "id": "arXiv:2201.11936",
    "title": "Consistent Collaborative Filtering via Tensor Decomposition",
    "abstract": "Consistent Collaborative Filtering via Tensor Decomposition",
    "descriptor": "",
    "authors": [
      "Shiwen Zhao",
      "Charles Crissman",
      "Guillermo R Sapiro"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.11936"
  },
  {
    "id": "arXiv:2201.12278",
    "title": "Quantitative Resilience of Linear Systems",
    "abstract": "Quantitative Resilience of Linear Systems",
    "descriptor": "",
    "authors": [
      "Jean-Baptiste Bouvier",
      "Melkior Ornik"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.12278"
  },
  {
    "id": "arXiv:2201.12477",
    "title": "An Indirect Rate-Distortion Characterization for Semantic Sources:  General Model and the Case of Gaussian Observation",
    "abstract": "Comments: Part of the preliminary results appears in arXiv:2105.04278",
    "descriptor": "\nComments: Part of the preliminary results appears in arXiv:2105.04278\n",
    "authors": [
      "Jiakun Liu",
      "Shuo Shao",
      "Wenyi Zhang",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12477"
  },
  {
    "id": "arXiv:2202.00099",
    "title": "A Comparison of Different Approaches to Dynamic Origin-Destination  Matrix Estimation in Urban Traffic",
    "abstract": "A Comparison of Different Approaches to Dynamic Origin-Destination  Matrix Estimation in Urban Traffic",
    "descriptor": "",
    "authors": [
      "Nicklas Sindlev Andersen",
      "Marco Chiarandini",
      "Kristian Debrabant"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00099"
  },
  {
    "id": "arXiv:2202.00633",
    "title": "Efficient Policy Space Response Oracles",
    "abstract": "Comments: improved theoretical results; fixed some typos; 22 pages, 8 figures",
    "descriptor": "\nComments: improved theoretical results; fixed some typos; 22 pages, 8 figures\n",
    "authors": [
      "Ming Zhou",
      "Jingxiao Chen",
      "Ying Wen",
      "Weinan Zhang",
      "Yaodong Yang",
      "Yong Yu",
      "Jun Wang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2202.00633"
  },
  {
    "id": "arXiv:2202.01999",
    "title": "Neural Dual Contouring",
    "abstract": "Comments: Accepted to SIGGRAPH (journal) 2022. Code: this https URL",
    "descriptor": "\nComments: Accepted to SIGGRAPH (journal) 2022. Code: this https URL\n",
    "authors": [
      "Zhiqin Chen",
      "Andrea Tagliasacchi",
      "Thomas Funkhouser",
      "Hao Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01999"
  },
  {
    "id": "arXiv:2202.02989",
    "title": "Graph Self-supervised Learning with Accurate Discrepancy Learning",
    "abstract": "Comments: 9 pages",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Dongki Kim",
      "Jinheon Baek",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02989"
  },
  {
    "id": "arXiv:2202.03052",
    "title": "OFA: Unifying Architectures, Tasks, and Modalities Through a Simple  Sequence-to-Sequence Learning Framework",
    "abstract": "Comments: Accepted at ICML2022",
    "descriptor": "\nComments: Accepted at ICML2022\n",
    "authors": [
      "Peng Wang",
      "An Yang",
      "Rui Men",
      "Junyang Lin",
      "Shuai Bai",
      "Zhikang Li",
      "Jianxin Ma",
      "Chang Zhou",
      "Jingren Zhou",
      "Hongxia Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.03052"
  },
  {
    "id": "arXiv:2202.03613",
    "title": "Conformal prediction for the design problem",
    "abstract": "Comments: for associated code, see this https URL",
    "descriptor": "\nComments: for associated code, see this https URL\n",
    "authors": [
      "Clara Fannjiang",
      "Stephen Bates",
      "Anastasios N. Angelopoulos",
      "Jennifer Listgarten",
      "Michael I. Jordan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2202.03613"
  },
  {
    "id": "arXiv:2202.03841",
    "title": "Width is Less Important than Depth in ReLU Neural Networks",
    "abstract": "Comments: Camera ready version in COLT 2022",
    "descriptor": "\nComments: Camera ready version in COLT 2022\n",
    "authors": [
      "Gal Vardi",
      "Gilad Yehudai",
      "Ohad Shamir"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.03841"
  },
  {
    "id": "arXiv:2202.04136",
    "title": "Generative multitask learning mitigates target-causing confounding",
    "abstract": "Generative multitask learning mitigates target-causing confounding",
    "descriptor": "",
    "authors": [
      "Taro Makino",
      "Krzysztof J. Geras",
      "Kyunghyun Cho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.04136"
  },
  {
    "id": "arXiv:2202.04870",
    "title": "Online Learning for Min Sum Set Cover and Pandora's Box",
    "abstract": "Online Learning for Min Sum Set Cover and Pandora's Box",
    "descriptor": "",
    "authors": [
      "Evangelia Gergatsouli",
      "Christos Tzamos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04870"
  },
  {
    "id": "arXiv:2202.05907",
    "title": "Fast and perfect sampling of subgraphs and polymer systems",
    "abstract": "Fast and perfect sampling of subgraphs and polymer systems",
    "descriptor": "",
    "authors": [
      "Antonio Blanca",
      "Sarah Cannon",
      "Will Perkins"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.05907"
  },
  {
    "id": "arXiv:2202.07961",
    "title": "Identity Testing for Radical Expressions",
    "abstract": "Comments: 32 pages",
    "descriptor": "\nComments: 32 pages\n",
    "authors": [
      "Nikhil Balaji",
      "Klara Nosan",
      "Mahsa Shirmohammadi",
      "James Worrell"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Logic in Computer Science (cs.LO)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2202.07961"
  },
  {
    "id": "arXiv:2202.08821",
    "title": "Human-Algorithm Collaboration: Achieving Complementarity and Avoiding  Unfairness",
    "abstract": "Comments: Accepted to ACM FAccT 2022. Preliminary version accepted (panel presentation) at Neurips workshop on Human-Centered AI",
    "descriptor": "\nComments: Accepted to ACM FAccT 2022. Preliminary version accepted (panel presentation) at Neurips workshop on Human-Centered AI\n",
    "authors": [
      "Kate Donahue",
      "Alexandra Chouldechova",
      "Krishnaram Kenthapadi"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08821"
  },
  {
    "id": "arXiv:2202.09698",
    "title": "Analyzing Adaptive Scaffolds that Help Students Develop Self-Regulated  Learning Behaviors",
    "abstract": "Analyzing Adaptive Scaffolds that Help Students Develop Self-Regulated  Learning Behaviors",
    "descriptor": "",
    "authors": [
      "Anabil Munshi",
      "Gautam Biswas",
      "Ryan Baker",
      "Jaclyn Ocumpaugh",
      "Stephen Hutt",
      "Luc Paquette"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.09698"
  },
  {
    "id": "arXiv:2202.11361",
    "title": "Exploratory Methods for Relation Discovery in Archival Data",
    "abstract": "Comments: 25 pages, 4 figures, 7 tables, journal article. Author's Original Version of a further manuscript accepted by Digital Scholarship in the Humanities (DSH)",
    "descriptor": "\nComments: 25 pages, 4 figures, 7 tables, journal article. Author's Original Version of a further manuscript accepted by Digital Scholarship in the Humanities (DSH)\n",
    "authors": [
      "Lucia Giagnolini",
      "Marilena Daquino",
      "Francesca Mambelli",
      "Francesca Tomasi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Digital Libraries (cs.DL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2202.11361"
  },
  {
    "id": "arXiv:2202.11655",
    "title": "TEE-based decentralized recommender systems: The raw data sharing  redemption",
    "abstract": "TEE-based decentralized recommender systems: The raw data sharing  redemption",
    "descriptor": "",
    "authors": [
      "Akash Dhasade",
      "Nevena Dresevic",
      "Anne-Marie Kermarrec",
      "Rafael Pires"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Cryptography and Security (cs.CR)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.11655"
  },
  {
    "id": "arXiv:2202.12104",
    "title": "A Transformer-based Network for Deformable Medical Image Registration",
    "abstract": "Comments: 5 pages, 4 figures, 18 conferences",
    "descriptor": "\nComments: 5 pages, 4 figures, 18 conferences\n",
    "authors": [
      "Yibo Wang",
      "Wen Qian",
      "Xuming Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12104"
  },
  {
    "id": "arXiv:2202.12232",
    "title": "Bounding Membership Inference",
    "abstract": "Bounding Membership Inference",
    "descriptor": "",
    "authors": [
      "Anvith Thudi",
      "Ilia Shumailov",
      "Franziska Boenisch",
      "Nicolas Papernot"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12232"
  },
  {
    "id": "arXiv:2203.00035",
    "title": "Can Mean Field Control (MFC) Approximate Cooperative Multi Agent  Reinforcement Learning (MARL) with Non-Uniform Interaction?",
    "abstract": "Can Mean Field Control (MFC) Approximate Cooperative Multi Agent  Reinforcement Learning (MARL) with Non-Uniform Interaction?",
    "descriptor": "",
    "authors": [
      "Washim Uddin Mondal",
      "Vaneet Aggarwal",
      "Satish V. Ukkusuri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2203.00035"
  },
  {
    "id": "arXiv:2203.00551",
    "title": "Bayesian Optimisation for Robust Model Predictive Control under Model  Parameter Uncertainty",
    "abstract": "Comments: To appear in the 2022 IEEE International Conference on Robotics and Automation (ICRA), Philadelphia (PA), USA",
    "descriptor": "\nComments: To appear in the 2022 IEEE International Conference on Robotics and Automation (ICRA), Philadelphia (PA), USA\n",
    "authors": [
      "Rel Guzman",
      "Rafael Oliveira",
      "Fabio Ramos"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.00551"
  },
  {
    "id": "arXiv:2203.01203",
    "title": "Manipulation of unknown objects via contact configuration regulation",
    "abstract": "Comments: Authors contributed equally, names listed in alphabetical order. ICRA 2022",
    "descriptor": "\nComments: Authors contributed equally, names listed in alphabetical order. ICRA 2022\n",
    "authors": [
      "Neel Doshi",
      "Orion Taylor",
      "Alberto Rodriguez"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.01203"
  },
  {
    "id": "arXiv:2203.01297",
    "title": "Sparse Matrix Multiplication in the Low-Bandwidth Model",
    "abstract": "Sparse Matrix Multiplication in the Low-Bandwidth Model",
    "descriptor": "",
    "authors": [
      "Chetan Gupta",
      "Juho Hirvonen",
      "Janne H. Korhonen",
      "Jan Studen\u00fd",
      "Jukka Suomela"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2203.01297"
  },
  {
    "id": "arXiv:2203.01845",
    "title": "MooAFEM: An object oriented Matlab code for higher-order adaptive FEM  for (nonlinear) elliptic PDEs",
    "abstract": "MooAFEM: An object oriented Matlab code for higher-order adaptive FEM  for (nonlinear) elliptic PDEs",
    "descriptor": "",
    "authors": [
      "Michael Innerberger",
      "Dirk Praetorius"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2203.01845"
  },
  {
    "id": "arXiv:2203.02214",
    "title": "Plan Your Target and Learn Your Skills: Transferable State-Only  Imitation Learning via Decoupled Policy Optimization",
    "abstract": "Comments: 22 pages, 3 tabels, 17 figures. Published at ICML 2022",
    "descriptor": "\nComments: 22 pages, 3 tabels, 17 figures. Published at ICML 2022\n",
    "authors": [
      "Minghuan Liu",
      "Zhengbang Zhu",
      "Yuzheng Zhuang",
      "Weinan Zhang",
      "Jianye Hao",
      "Yong Yu",
      "Jun Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.02214"
  },
  {
    "id": "arXiv:2203.03341",
    "title": "Recovering single precision accuracy from Tensor Cores while surpassing  the FP32 theoretical peak performance",
    "abstract": "Recovering single precision accuracy from Tensor Cores while surpassing  the FP32 theoretical peak performance",
    "descriptor": "",
    "authors": [
      "Hiroyuki Ootomo",
      "Rio Yokota"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2203.03341"
  },
  {
    "id": "arXiv:2203.03673",
    "title": "AgraSSt: Approximate Graph Stein Statistics for Interpretable Assessment  of Implicit Graph Generators",
    "abstract": "AgraSSt: Approximate Graph Stein Statistics for Interpretable Assessment  of Implicit Graph Generators",
    "descriptor": "",
    "authors": [
      "Wenkai Xu",
      "Gesine Reinert"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.03673"
  },
  {
    "id": "arXiv:2203.06850",
    "title": "Efficient Language Modeling with Sparse all-MLP",
    "abstract": "Efficient Language Modeling with Sparse all-MLP",
    "descriptor": "",
    "authors": [
      "Ping Yu",
      "Mikel Artetxe",
      "Myle Ott",
      "Sam Shleifer",
      "Hongyu Gong",
      "Ves Stoyanov",
      "Xian Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.06850"
  },
  {
    "id": "arXiv:2203.06925",
    "title": "WCL-BBCD: A Contrastive Learning and Knowledge Graph Approach to Named  Entity Recognition",
    "abstract": "WCL-BBCD: A Contrastive Learning and Knowledge Graph Approach to Named  Entity Recognition",
    "descriptor": "",
    "authors": [
      "Renjie Zhou",
      "Qiang Hu",
      "Jian Wan",
      "Jilin Zhang",
      "Qiang Liu",
      "Tianxiang Hu",
      "Jianjun Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.06925"
  },
  {
    "id": "arXiv:2203.07524",
    "title": "Convolutional-Recurrent Neural Network Proxy for Robust Optimization and  Closed-Loop Reservoir Management",
    "abstract": "Comments: Corrected a typo (page 9, from '400 bar' to '320 bar')",
    "descriptor": "\nComments: Corrected a typo (page 9, from '400 bar' to '320 bar')\n",
    "authors": [
      "Yong Do Kim",
      "Louis J. Durlofsky"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07524"
  },
  {
    "id": "arXiv:2203.08110",
    "title": "Topology optimization including a model of the layer-by-layer additive  manufacturing process",
    "abstract": "Topology optimization including a model of the layer-by-layer additive  manufacturing process",
    "descriptor": "",
    "authors": [
      "G.A. Haveroth",
      "C-J. Thore",
      "M.R. Correa",
      "R.F. Ausas",
      "S. Jakobsson",
      "J.A. Cuminato",
      "A. Klarbring"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.08110"
  },
  {
    "id": "arXiv:2203.10912",
    "title": "Depth Completion using Geometry-Aware Embedding",
    "abstract": "Comments: Accepted by ICRA22",
    "descriptor": "\nComments: Accepted by ICRA22\n",
    "authors": [
      "Wenchao Du",
      "Hu Chen",
      "Hongyu Yang",
      "Yi Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.10912"
  },
  {
    "id": "arXiv:2203.11055",
    "title": "backbone: An R package to extract network backbones",
    "abstract": "backbone: An R package to extract network backbones",
    "descriptor": "",
    "authors": [
      "Zachary P. Neal"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2203.11055"
  },
  {
    "id": "arXiv:2203.11579",
    "title": "Local Stochastic Factored Gradient Descent for Distributed Quantum State  Tomography",
    "abstract": "Local Stochastic Factored Gradient Descent for Distributed Quantum State  Tomography",
    "descriptor": "",
    "authors": [
      "Junhyung Lyle Kim",
      "Mohammad Taha Toghani",
      "C\u00e9sar A. Uribe",
      "Anastasios Kyrillidis"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.11579"
  },
  {
    "id": "arXiv:2203.12023",
    "title": "Generative Modeling Helps Weak Supervision (and Vice Versa)",
    "abstract": "Generative Modeling Helps Weak Supervision (and Vice Versa)",
    "descriptor": "",
    "authors": [
      "Benedikt Boecking",
      "Nicholas Roberts",
      "Willie Neiswanger",
      "Stefano Ermon",
      "Frederic Sala",
      "Artur Dubrawski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.12023"
  },
  {
    "id": "arXiv:2203.13544",
    "title": "Performance evaluation of switching between WiFi and LiFi under a common  virtual network interface",
    "abstract": "Comments: 6 pages, 12 figures (including subfigures), 2 tables, conference paper",
    "descriptor": "\nComments: 6 pages, 12 figures (including subfigures), 2 tables, conference paper\n",
    "authors": [
      "Loreto Pescosolido",
      "Emilio Ancillotti",
      "Andrea Passarella"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.13544"
  },
  {
    "id": "arXiv:2203.14260",
    "title": "Unsupervised Vision-Language Parsing: Seamlessly Bridging Visual Scene  Graphs with Language Structures via Dependency Relationships",
    "abstract": "Comments: Updated",
    "descriptor": "\nComments: Updated\n",
    "authors": [
      "Chao Lou",
      "Wenjuan Han",
      "Yuhuan Lin",
      "Zilong Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.14260"
  },
  {
    "id": "arXiv:2203.15177",
    "title": "Min-Max Similarity: A Contrastive Semi-Supervised Deep Learning Network  for Surgical Tools Segmentation",
    "abstract": "Min-Max Similarity: A Contrastive Semi-Supervised Deep Learning Network  for Surgical Tools Segmentation",
    "descriptor": "",
    "authors": [
      "Ange Lou",
      "Kareem Tawfik",
      "Xing Yao",
      "Ziteng Liu",
      "Jack Noble"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.15177"
  },
  {
    "id": "arXiv:2203.15544",
    "title": "Graph Neural Networks are Dynamic Programmers",
    "abstract": "Comments: 15 pages, 2 figures. A significant extension of our contribution at ICLR'22 GroundedML and GTRL Workshops. Work in progress -- comments welcome!",
    "descriptor": "\nComments: 15 pages, 2 figures. A significant extension of our contribution at ICLR'22 GroundedML and GTRL Workshops. Work in progress -- comments welcome!\n",
    "authors": [
      "Andrew Dudzik",
      "Petar Veli\u010dkovi\u0107"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Category Theory (math.CT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.15544"
  },
  {
    "id": "arXiv:2203.16027",
    "title": "Clozer: Adaptable Data Augmentation for Cloze-style Reading  Comprehension",
    "abstract": "Clozer: Adaptable Data Augmentation for Cloze-style Reading  Comprehension",
    "descriptor": "",
    "authors": [
      "Holy Lovenia",
      "Bryan Wilie",
      "Willy Chung",
      "Min Zeng",
      "Samuel Cahyawijaya",
      "Su Dan",
      "Pascale Fung"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.16027"
  },
  {
    "id": "arXiv:2204.01392",
    "title": "JShelter: Give Me My Browser Back",
    "abstract": "Comments: Paper update after internal review",
    "descriptor": "\nComments: Paper update after internal review\n",
    "authors": [
      "Libor Pol\u010d\u00e1k",
      "Marek Salo\u0148",
      "Giorgio Maone",
      "Radek Hranick\u00fd",
      "Michael McMahon"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2204.01392"
  },
  {
    "id": "arXiv:2204.02078",
    "title": "Semi-supervised Semantic Segmentation with Error Localization Network",
    "abstract": "Semi-supervised Semantic Segmentation with Error Localization Network",
    "descriptor": "",
    "authors": [
      "Donghyeon Kwon",
      "Suha Kwak"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02078"
  },
  {
    "id": "arXiv:2204.03845",
    "title": "Decompositional Generation Process for Instance-Dependent Partial Label  Learning",
    "abstract": "Decompositional Generation Process for Instance-Dependent Partial Label  Learning",
    "descriptor": "",
    "authors": [
      "Congyu Qiao",
      "Ning Xu",
      "Xin Geng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.03845"
  },
  {
    "id": "arXiv:2204.05381",
    "title": "Self-supervised Vision Transformers for Joint SAR-optical Representation  Learning",
    "abstract": "Comments: 4 pages, 1 figure; IGARSS 2022",
    "descriptor": "\nComments: 4 pages, 1 figure; IGARSS 2022\n",
    "authors": [
      "Yi Wang",
      "Conrad M Albrecht",
      "Xiao Xiang Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.05381"
  },
  {
    "id": "arXiv:2204.08612",
    "title": "Metamorphic Testing-based Adversarial Attack to Fool Deepfake Detectors",
    "abstract": "Comments: paper accepted at 26TH International Conference on Pattern Recognition (ICPR2022)",
    "descriptor": "\nComments: paper accepted at 26TH International Conference on Pattern Recognition (ICPR2022)\n",
    "authors": [
      "Nyee Thoang Lim",
      "Meng Yi Kuan",
      "Muxin Pu",
      "Mei Kuan Lim",
      "Chun Yong Chong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.08612"
  },
  {
    "id": "arXiv:2204.08663",
    "title": "Pre-training of Equivariant Graph Matching Networks with Conformation  Flexibility for Drug Binding",
    "abstract": "Pre-training of Equivariant Graph Matching Networks with Conformation  Flexibility for Drug Binding",
    "descriptor": "",
    "authors": [
      "Fang Wu",
      "Shuting Jin",
      "Xurui Jin",
      "Xiangrong Liu",
      "Yinghui Jiang",
      "Zhangming Niu",
      "Qiang Zhang",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2204.08663"
  },
  {
    "id": "arXiv:2204.08775",
    "title": "Plots.jl -- a user extendable plotting API for the julia programming  language",
    "abstract": "Comments: 22 pages, 6 figures, 6 code listings",
    "descriptor": "\nComments: 22 pages, 6 figures, 6 code listings\n",
    "authors": [
      "Simon Christ",
      "Daniel Schwabeneder",
      "Christopher Rackauckas"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2204.08775"
  },
  {
    "id": "arXiv:2204.09960",
    "title": "Planning for Temporally Extended Goals in Pure-Past Linear Temporal  Logic: A Polynomial Reduction to Standard Planning",
    "abstract": "Comments: 26 pages, 8 figures, 2 tables",
    "descriptor": "\nComments: 26 pages, 8 figures, 2 tables\n",
    "authors": [
      "Giuseppe De Giacomo",
      "Marco Favorito",
      "Francesco Fuggitti"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.09960"
  },
  {
    "id": "arXiv:2204.10125",
    "title": "Physical Modeling using Recurrent Neural Networks with Fast  Convolutional Layers",
    "abstract": "Comments: Accepted to DAFx2022",
    "descriptor": "\nComments: Accepted to DAFx2022\n",
    "authors": [
      "Julian D. Parker",
      "Sebastian J. Schlecht",
      "Rudolf Rabenstein",
      "Maximilian Sch\u00e4fer"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2204.10125"
  },
  {
    "id": "arXiv:2204.11596",
    "title": "A Simple Structure For Building A Robust Model",
    "abstract": "Comments: Accepted by Fifth International Conference on Intelligence Science (ICIS2022); 10 pages, 3 figures, 4 tables",
    "descriptor": "\nComments: Accepted by Fifth International Conference on Intelligence Science (ICIS2022); 10 pages, 3 figures, 4 tables\n",
    "authors": [
      "Xiao Tan",
      "Jingbo Gao",
      "Ruolin Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.11596"
  },
  {
    "id": "arXiv:2205.00147",
    "title": "Operational Adaptation of DNN Classifiers using Elastic Weight  Consolidation",
    "abstract": "Operational Adaptation of DNN Classifiers using Elastic Weight  Consolidation",
    "descriptor": "",
    "authors": [
      "Abanoub Ghobrial",
      "Xuan Zheng",
      "Darryl Hond",
      "Hamid Asgari",
      "Kerstin Eder"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.00147"
  },
  {
    "id": "arXiv:2205.01240",
    "title": "Using Constraint Programming and Graph Representation Learning for  Generating Interpretable Cloud Security Policies",
    "abstract": "Comments: to be published in IJCAI/ECAI'22",
    "descriptor": "\nComments: to be published in IJCAI/ECAI'22\n",
    "authors": [
      "Mikhail Kazdagli",
      "Mohit Tiwari",
      "Akshat Kumar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.01240"
  },
  {
    "id": "arXiv:2205.01681",
    "title": "Growing Isotropic Neural Cellular Automata",
    "abstract": "Growing Isotropic Neural Cellular Automata",
    "descriptor": "",
    "authors": [
      "Alexander Mordvintsev",
      "Ettore Randazzo",
      "Craig Fouts"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Cell Behavior (q-bio.CB)"
    ],
    "url": "https://arxiv.org/abs/2205.01681"
  },
  {
    "id": "arXiv:2205.04263",
    "title": "Spiking Neural Network Equalization for IM/DD Optical Communication",
    "abstract": "Spiking Neural Network Equalization for IM/DD Optical Communication",
    "descriptor": "",
    "authors": [
      "Elias Arnold",
      "Georg B\u00f6cherer",
      "Eric M\u00fcller",
      "Philipp Spilger",
      "Johannes Schemmel",
      "Stefano Calabr\u00f2",
      "Maxim Kuschnerov"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2205.04263"
  },
  {
    "id": "arXiv:2205.05126",
    "title": "A Meta-Analysis of the Utility of Explainable Artificial Intelligence in  Human-AI Decision-Making",
    "abstract": "Comments: AAAI/ACM Conference on AI, Ethics, and Society (AIES'22)",
    "descriptor": "\nComments: AAAI/ACM Conference on AI, Ethics, and Society (AIES'22)\n",
    "authors": [
      "Max Schemmer",
      "Patrick Hemmer",
      "Maximilian Nitsche",
      "Niklas K\u00fchl",
      "Michael V\u00f6ssing"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.05126"
  },
  {
    "id": "arXiv:2205.05883",
    "title": "SeGraM: A Universal Hardware Accelerator for Genomic Sequence-to-Graph  and Sequence-to-Sequence Mapping",
    "abstract": "Comments: To appear in ISCA'22",
    "descriptor": "\nComments: To appear in ISCA'22\n",
    "authors": [
      "Damla Senol Cali",
      "Konstantinos Kanellopoulos",
      "Joel Lindegger",
      "Z\u00fclal Bing\u00f6l",
      "Gurpreet S. Kalsi",
      "Ziyi Zuo",
      "Can Firtina",
      "Meryem Banu Cavlak",
      "Jeremie Kim",
      "Nika Mansouri Ghiasi",
      "Gagandeep Singh",
      "Juan G\u00f3mez-Luna",
      "Nour Almadhoun Alserr",
      "Mohammed Alser",
      "Sreenivas Subramoney",
      "Can Alkan",
      "Saugata Ghose",
      "Onur Mutlu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Genomics (q-bio.GN)"
    ],
    "url": "https://arxiv.org/abs/2205.05883"
  },
  {
    "id": "arXiv:2205.06131",
    "title": "Framework for inferring empirical causal graphs from binary data to  support multidimensional poverty analysis",
    "abstract": "Comments: Revised some typos. The latest version of R package can be found at this https URL",
    "descriptor": "\nComments: Revised some typos. The latest version of R package can be found at this https URL\n",
    "authors": [
      "Chainarong Amornbunchornvej",
      "Navaporn Surasvadi",
      "Anon Plangprasopchok",
      "Suttipong Thajchayapong"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2205.06131"
  },
  {
    "id": "arXiv:2205.06911",
    "title": "Blockaid: Data Access Policy Enforcement for Web Applications",
    "abstract": "Comments: Extended technical report for OSDI 2022 paper",
    "descriptor": "\nComments: Extended technical report for OSDI 2022 paper\n",
    "authors": [
      "Wen Zhang",
      "Eric Sheng",
      "Michael Chang",
      "Aurojit Panda",
      "Mooly Sagiv",
      "Scott Shenker"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2205.06911"
  },
  {
    "id": "arXiv:2205.07217",
    "title": "Online Nonsubmodular Minimization with Delayed Costs: From Full  Information to Bandit Feedback",
    "abstract": "Comments: Accepted by ICML 2022; The first three authors contributed equally to this work; 36 pages, 9 figures",
    "descriptor": "\nComments: Accepted by ICML 2022; The first three authors contributed equally to this work; 36 pages, 9 figures\n",
    "authors": [
      "Tianyi Lin",
      "Aldo Pacchiano",
      "Yaodong Yu",
      "Michael I. Jordan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.07217"
  },
  {
    "id": "arXiv:2205.07525",
    "title": "A model aggregation approach for high-dimensional large-scale  optimization",
    "abstract": "A model aggregation approach for high-dimensional large-scale  optimization",
    "descriptor": "",
    "authors": [
      "Haowei Wang",
      "Ercong Zhang",
      "Szu Hui Ng",
      "Giulia Pedrielli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.07525"
  },
  {
    "id": "arXiv:2205.07633",
    "title": "Taming Continuous Posteriors for Latent Variational Dialogue Policies",
    "abstract": "Taming Continuous Posteriors for Latent Variational Dialogue Policies",
    "descriptor": "",
    "authors": [
      "Marin Vlastelica",
      "Patrick Ernst",
      "Gy\u00f6rgy Szarvas"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.07633"
  },
  {
    "id": "arXiv:2205.08991",
    "title": "Symbolic-Numeric Factorization of Differential Operators",
    "abstract": "Symbolic-Numeric Factorization of Differential Operators",
    "descriptor": "",
    "authors": [
      "Fr\u00e9d\u00e9ric Chyzak",
      "Alexandre Goyer",
      "Marc Mezzarobba"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2205.08991"
  },
  {
    "id": "arXiv:2205.09073",
    "title": "Dialog Inpainting: Turning Documents into Dialogs",
    "abstract": "Dialog Inpainting: Turning Documents into Dialogs",
    "descriptor": "",
    "authors": [
      "Zhuyun Dai",
      "Arun Tejasvi Chaganty",
      "Vincent Zhao",
      "Aida Amini",
      "Qazi Mamunur Rashid",
      "Mike Green",
      "Kelvin Guu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.09073"
  },
  {
    "id": "arXiv:2205.09607",
    "title": "LAGr: Label Aligned Graphs for Better Systematic Generalization in  Semantic Parsing",
    "abstract": "Comments: published latest version of a paper that's already on arxiv instead of adding it as a new version. Please see arXiv:2110.07572",
    "descriptor": "\nComments: published latest version of a paper that's already on arxiv instead of adding it as a new version. Please see arXiv:2110.07572\n",
    "authors": [
      "Dora Jambor",
      "Dzmitry Bahdanau"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.09607"
  },
  {
    "id": "arXiv:2205.09626",
    "title": "BARS: Towards Open Benchmarking for Recommender Systems",
    "abstract": "Comments: Author's draft version. BARS benchmark available at this https URL",
    "descriptor": "\nComments: Author's draft version. BARS benchmark available at this https URL\n",
    "authors": [
      "Jieming Zhu",
      "Quanyu Dai",
      "Liangcai Su",
      "Rong Ma",
      "Jinyang Liu",
      "Guohao Cai",
      "Xi Xiao",
      "Rui Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2205.09626"
  },
  {
    "id": "arXiv:2205.10471",
    "title": "Retrieval-Augmented Multilingual Keyphrase Generation with  Retriever-Generator Iterative Training",
    "abstract": "Comments: NAACL 2022 (Findings)",
    "descriptor": "\nComments: NAACL 2022 (Findings)\n",
    "authors": [
      "Yifan Gao",
      "Qingyu Yin",
      "Zheng Li",
      "Rui Meng",
      "Tong Zhao",
      "Bing Yin",
      "Irwin King",
      "Michael R. Lyu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.10471"
  },
  {
    "id": "arXiv:2205.10760",
    "title": "CNNs are Myopic",
    "abstract": "Comments: Added reference and comparison to BagNets in related work section",
    "descriptor": "\nComments: Added reference and comparison to BagNets in related work section\n",
    "authors": [
      "Vamshi C. Madala",
      "Shivkumar Chandrasekaran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.10760"
  },
  {
    "id": "arXiv:2205.11913",
    "title": "Deep Learning Workload Scheduling in GPU Datacenters: Taxonomy,  Challenges and Vision",
    "abstract": "Comments: Submitted to ACM Computing Surveys",
    "descriptor": "\nComments: Submitted to ACM Computing Surveys\n",
    "authors": [
      "Wei Gao",
      "Qinghao Hu",
      "Zhisheng Ye",
      "Peng Sun",
      "Xiaolin Wang",
      "Yingwei Luo",
      "Tianwei Zhang",
      "Yonggang Wen"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11913"
  },
  {
    "id": "arXiv:2205.12493",
    "title": "Federated Self-supervised Learning for Heterogeneous Clients",
    "abstract": "Federated Self-supervised Learning for Heterogeneous Clients",
    "descriptor": "",
    "authors": [
      "Disha Makhija",
      "Nhat Ho",
      "Joydeep Ghosh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2205.12493"
  },
  {
    "id": "arXiv:2205.12693",
    "title": "Contrastive Learning with Boosted Memorization",
    "abstract": "Contrastive Learning with Boosted Memorization",
    "descriptor": "",
    "authors": [
      "Zhihan Zhou",
      "Jiangchao Yao",
      "Yanfeng Wang",
      "Bo Han",
      "Ya Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.12693"
  },
  {
    "id": "arXiv:2205.13087",
    "title": "New Explicit Good Linear Sum-Rank-Metric Codes",
    "abstract": "Comments: 23 pages, submitted",
    "descriptor": "\nComments: 23 pages, submitted\n",
    "authors": [
      "Hao Chen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.13087"
  },
  {
    "id": "arXiv:2205.13147",
    "title": "Matryoshka Representations for Adaptive Deployment",
    "abstract": "Comments: 32 pages, 11 figures Edits: Fixed details about adaptive classification",
    "descriptor": "\nComments: 32 pages, 11 figures Edits: Fixed details about adaptive classification\n",
    "authors": [
      "Aditya Kusupati",
      "Gantavya Bhatt",
      "Aniket Rege",
      "Matthew Wallingford",
      "Aditya Sinha",
      "Vivek Ramanujan",
      "William Howard-Snyder",
      "Kaifeng Chen",
      "Sham Kakade",
      "Prateek Jain",
      "Ali Farhadi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.13147"
  },
  {
    "id": "arXiv:2205.13504",
    "title": "Are Transformers Effective for Time Series Forecasting?",
    "abstract": "Comments: Code is available at this https URL",
    "descriptor": "\nComments: Code is available at this https URL\n",
    "authors": [
      "Ailing Zeng",
      "Muxi Chen",
      "Lei Zhang",
      "Qiang Xu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.13504"
  },
  {
    "id": "arXiv:2205.13523",
    "title": "PerDoor: Persistent Non-Uniform Backdoors in Federated Learning using  Adversarial Perturbations",
    "abstract": "PerDoor: Persistent Non-Uniform Backdoors in Federated Learning using  Adversarial Perturbations",
    "descriptor": "",
    "authors": [
      "Manaar Alam",
      "Esha Sarkar",
      "Michail Maniatakos"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.13523"
  },
  {
    "id": "arXiv:2205.13619",
    "title": "Fairness in Recommendation: A Survey",
    "abstract": "Comments: 38 pages, 2 figures, 1 table",
    "descriptor": "\nComments: 38 pages, 2 figures, 1 table\n",
    "authors": [
      "Yunqi Li",
      "Hanxiong Chen",
      "Shuyuan Xu",
      "Yingqiang Ge",
      "Juntao Tan",
      "Shuchang Liu",
      "Yongfeng Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.13619"
  },
  {
    "id": "arXiv:2205.13648",
    "title": "A Unified Analysis of Federated Learning with Arbitrary Client  Participation",
    "abstract": "A Unified Analysis of Federated Learning with Arbitrary Client  Participation",
    "descriptor": "",
    "authors": [
      "Shiqiang Wang",
      "Mingyue Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.13648"
  },
  {
    "id": "arXiv:2205.13799",
    "title": "Generalization Bounds for Gradient Methods via Discrete and Continuous  Prior",
    "abstract": "Generalization Bounds for Gradient Methods via Discrete and Continuous  Prior",
    "descriptor": "",
    "authors": [
      "Jian Li",
      "Xuanyuan Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.13799"
  },
  {
    "id": "arXiv:2205.13943",
    "title": "Architecture-Agnostic Masked Image Modeling -- From ViT back to CNN",
    "abstract": "Comments: A preprint reversion (fix typos and update appendix). The source code will be released in this https URL",
    "descriptor": "\nComments: A preprint reversion (fix typos and update appendix). The source code will be released in this https URL\n",
    "authors": [
      "Siyuan Li",
      "Di Wu",
      "Fang Wu",
      "Zelin Zang",
      "Kai Wang",
      "Lei Shang",
      "Baigui Sun",
      "Hao Li",
      "Stan.Z.Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.13943"
  },
  {
    "id": "arXiv:2205.14071",
    "title": "A Mechanically Assisted Examination of Vacuity and Question Begging in  Anselm's Ontological Argument",
    "abstract": "A Mechanically Assisted Examination of Vacuity and Question Begging in  Anselm's Ontological Argument",
    "descriptor": "",
    "authors": [
      "John Rushby"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2205.14071"
  },
  {
    "id": "arXiv:2205.14100",
    "title": "GIT: A Generative Image-to-text Transformer for Vision and Language",
    "abstract": "GIT: A Generative Image-to-text Transformer for Vision and Language",
    "descriptor": "",
    "authors": [
      "Jianfeng Wang",
      "Zhengyuan Yang",
      "Xiaowei Hu",
      "Linjie Li",
      "Kevin Lin",
      "Zhe Gan",
      "Zicheng Liu",
      "Ce Liu",
      "Lijuan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.14100"
  },
  {
    "id": "arXiv:2205.14109",
    "title": "Bayesian Robust Graph Contrastive Learning",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2106.04714 by other authors",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2106.04714 by other authors\n",
    "authors": [
      "Yancheng Wang",
      "Yingzhen Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.14109"
  },
  {
    "id": "arXiv:2205.14204",
    "title": "Multimodal Masked Autoencoders Learn Transferable Representations",
    "abstract": "Multimodal Masked Autoencoders Learn Transferable Representations",
    "descriptor": "",
    "authors": [
      "Xinyang Geng",
      "Hao Liu",
      "Lisa Lee",
      "Dale Schuurmans",
      "Sergey Levine",
      "Pieter Abbeel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.14204"
  },
  {
    "id": "arXiv:2205.14224",
    "title": "Will Bilevel Optimizers Benefit from Loops",
    "abstract": "Comments: 32 pages, 2 figures, 3 tables",
    "descriptor": "\nComments: 32 pages, 2 figures, 3 tables\n",
    "authors": [
      "Kaiyi Ji",
      "Mingrui Liu",
      "Yingbin Liang",
      "Lei Ying"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.14224"
  },
  {
    "id": "arXiv:2205.14226",
    "title": "Fast and Light-Weight Answer Text Retrieval in Dialogue Systems",
    "abstract": "Comments: Accepted in NAACL-HLT 2022 Industry Track",
    "descriptor": "\nComments: Accepted in NAACL-HLT 2022 Industry Track\n",
    "authors": [
      "Hui Wan",
      "Siva Sankalp Patel",
      "J. William Murdock",
      "Saloni Potdar",
      "Sachindra Joshi"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.14226"
  },
  {
    "id": "arXiv:2205.14375",
    "title": "WaveMix-Lite: A Resource-efficient Neural Network for Image Analysis",
    "abstract": "Comments: 17 pages, 5 figures. arXiv admin note: text overlap with arXiv:2203.03689",
    "descriptor": "\nComments: 17 pages, 5 figures. arXiv admin note: text overlap with arXiv:2203.03689\n",
    "authors": [
      "Pranav Jeevan",
      "Kavitha Viswanathan",
      "Amit Sethi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.14375"
  },
  {
    "id": "arXiv:2205.14450",
    "title": "Zero-Hopf Bifurcation of Limit Cycles in Certain Differential Systems",
    "abstract": "Zero-Hopf Bifurcation of Limit Cycles in Certain Differential Systems",
    "descriptor": "",
    "authors": [
      "Bo Huang",
      "Dongming Wang"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2205.14450"
  },
  {
    "id": "arXiv:2205.14625",
    "title": "Cervical Glandular Cell Detection from Whole Slide Image with  Out-Of-Distribution Data",
    "abstract": "Comments: 11 pages, 9 figures",
    "descriptor": "\nComments: 11 pages, 9 figures\n",
    "authors": [
      "Ziquan Wei",
      "Shenghua Cheng",
      "Jing Cai",
      "Shaoqun Zeng",
      "Xiuli Liu",
      "Zehua Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.14625"
  },
  {
    "id": "arXiv:2205.14631",
    "title": "Anchor Prediction: A Topic Modeling Approach",
    "abstract": "Comments: 14 pages, correct typo and \\citep",
    "descriptor": "\nComments: 14 pages, correct typo and \\citep\n",
    "authors": [
      "Jean Dupuy",
      "Adrien Guille",
      "Julien Jacques"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.14631"
  },
  {
    "id": "arXiv:2205.14831",
    "title": "Temporal Multiresolution Graph Neural Networks For Epidemic Prediction",
    "abstract": "Temporal Multiresolution Graph Neural Networks For Epidemic Prediction",
    "descriptor": "",
    "authors": [
      "Truong Son Hy",
      "Viet Bach Nguyen",
      "Long Tran-Thanh",
      "Risi Kondor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2205.14831"
  },
  {
    "id": "arXiv:2205.15117",
    "title": "OOD Link Prediction Generalization Capabilities of Message-Passing GNNs  in Larger Test Graphs",
    "abstract": "Comments: Under submission",
    "descriptor": "\nComments: Under submission\n",
    "authors": [
      "Yangze Zhou",
      "Gitta Kutyniok",
      "Bruno Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.15117"
  },
  {
    "id": "arXiv:2205.15360",
    "title": "Revisiting Audio Pattern Recognition for Asthma Medication Adherence:  Evaluation with the RDA Benchmark Suite",
    "abstract": "Revisiting Audio Pattern Recognition for Asthma Medication Adherence:  Evaluation with the RDA Benchmark Suite",
    "descriptor": "",
    "authors": [
      "Nikos D. Fakotakis",
      "Stavros Nousias",
      "Gerasimos Arvanitis",
      "Evangelia I. Zacharaki",
      "Konstantinos Moustakas"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)",
      "General Literature (cs.GL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2205.15360"
  },
  {
    "id": "arXiv:2205.15364",
    "title": "Associative Learning Mechanism for Drug-Target Interaction Prediction",
    "abstract": "Comments: Revised and supplemented author information",
    "descriptor": "\nComments: Revised and supplemented author information\n",
    "authors": [
      "Zhiqin Zhu",
      "Zheng Yao",
      "Guanqiu Qi",
      "Neal Mazur",
      "Baisen Cong"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15364"
  },
  {
    "id": "arXiv:2205.15404",
    "title": "Gator: Customizable Channel Pruning of Neural Networks with Gating",
    "abstract": "Comments: 14 pages, 3 figures. The version that appeared in ICANN is an earlier version",
    "descriptor": "\nComments: 14 pages, 3 figures. The version that appeared in ICANN is an earlier version\n",
    "authors": [
      "Eli Passov",
      "Eli David",
      "Nathan S. Netanyahu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15404"
  },
  {
    "id": "arXiv:2205.15469",
    "title": "GCoNet+: A Stronger Group Collaborative Co-Salient Object Detector",
    "abstract": "GCoNet+: A Stronger Group Collaborative Co-Salient Object Detector",
    "descriptor": "",
    "authors": [
      "Peng Zheng",
      "Huazhu Fu",
      "Deng-Ping Fan",
      "Qi Fan",
      "Jie Qin",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15469"
  },
  {
    "id": "arXiv:2205.15503",
    "title": "Leveraging Pre-Trained Language Models to Streamline Natural Language  Interaction for Self-Tracking",
    "abstract": "Comments: Accepted to NAACL '22 2nd Workshop on Bridging Human-Computer Interaction and Natural Language Processing. 10 pages including appendix, 2 figures, and 1 table",
    "descriptor": "\nComments: Accepted to NAACL '22 2nd Workshop on Bridging Human-Computer Interaction and Natural Language Processing. 10 pages including appendix, 2 figures, and 1 table\n",
    "authors": [
      "Young-Ho Kim",
      "Sungdong Kim",
      "Minsuk Chang",
      "Sang-Woo Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2205.15503"
  },
  {
    "id": "arXiv:2205.15638",
    "title": "Differentiable Invariant Causal Discovery",
    "abstract": "Comments: 22 pages, 11 figures",
    "descriptor": "\nComments: 22 pages, 11 figures\n",
    "authors": [
      "Yu Wang",
      "An Zhang",
      "Xiang Wang",
      "Xiangnan He",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2205.15638"
  },
  {
    "id": "arXiv:2205.15688",
    "title": "Self-Supervised Learning for Building Damage Assessment from Large-scale  xBD Satellite Imagery Benchmark Datasets",
    "abstract": "Comments: 14 pages, 7 figures, DEXA 2022",
    "descriptor": "\nComments: 14 pages, 7 figures, DEXA 2022\n",
    "authors": [
      "Zaishuo Xia",
      "Zelin Li",
      "Yanbing Bai",
      "Jinze Yu",
      "Bruno Adriano"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.15688"
  },
  {
    "id": "arXiv:2205.15702",
    "title": "New theoretical insights in the decomposition and time-frequency  representation of nonstationary signals: the IMFogram algorithm",
    "abstract": "New theoretical insights in the decomposition and time-frequency  representation of nonstationary signals: the IMFogram algorithm",
    "descriptor": "",
    "authors": [
      "Antonio Cicone",
      "Wing Suet Li",
      "Haomin Zhou"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.15702"
  },
  {
    "id": "arXiv:2205.15712",
    "title": "Multilingual Transformers for Product Matching -- Experiments and a New  Benchmark in Polish",
    "abstract": "Comments: 11 pages, 5 figures",
    "descriptor": "\nComments: 11 pages, 5 figures\n",
    "authors": [
      "Micha\u0142 Mo\u017cd\u017conek",
      "Anna Wr\u00f3blewska",
      "Sergiy Tkachuk",
      "Szymon \u0141ukasik"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15712"
  },
  {
    "id": "arXiv:2205.15749",
    "title": "Non-Iterative Recovery from Nonlinear Observations using Generative  Models",
    "abstract": "Comments: CVPR 2022",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Jiulong Liu",
      "Zhaoqiang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15749"
  },
  {
    "id": "arXiv:2205.15764",
    "title": "SymFormer: End-to-end symbolic regression using transformer-based  architecture",
    "abstract": "SymFormer: End-to-end symbolic regression using transformer-based  architecture",
    "descriptor": "",
    "authors": [
      "Martin Vastl",
      "Jon\u00e1\u0161 Kulh\u00e1nek",
      "Ji\u0159\u00ed Kubal\u00edk",
      "Erik Derner",
      "Robert Babu\u0161ka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2205.15764"
  },
  {
    "id": "arXiv:2205.15838",
    "title": "D$^2$NeRF: Self-Supervised Decoupling of Dynamic and Static Objects from  a Monocular Video",
    "abstract": "D$^2$NeRF: Self-Supervised Decoupling of Dynamic and Static Objects from  a Monocular Video",
    "descriptor": "",
    "authors": [
      "Tianhao Wu",
      "Fangcheng Zhong",
      "Andrea Tagliasacchi",
      "Forrester Cole",
      "Cengiz Oztireli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15838"
  },
  {
    "id": "arXiv:2205.15853",
    "title": "Predicting Day-Ahead Stock Returns using Search Engine Query Volumes: An  Application of Gradient Boosted Decision Trees to the S&P 100",
    "abstract": "Predicting Day-Ahead Stock Returns using Search Engine Query Volumes: An  Application of Gradient Boosted Decision Trees to the S&P 100",
    "descriptor": "",
    "authors": [
      "Christopher Bockel-Rickermann"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15853"
  },
  {
    "id": "arXiv:2205.15896",
    "title": "FedWalk: Communication Efficient Federated Unsupervised Node Embedding  with Differential Privacy",
    "abstract": "Comments: 10 pages, 8 figures, to be published in the Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining",
    "descriptor": "\nComments: 10 pages, 8 figures, to be published in the Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining\n",
    "authors": [
      "Qiying Pan",
      "Yifei Zhu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15896"
  },
  {
    "id": "arXiv:2205.15934",
    "title": "A Competitive Method for Dog Nose-print Re-identification",
    "abstract": "Comments: 3rd place solution to 2022 Pet Biometric Challenge (CVPRW). The source code and trained models can be obtained at this this https URL",
    "descriptor": "\nComments: 3rd place solution to 2022 Pet Biometric Challenge (CVPRW). The source code and trained models can be obtained at this this https URL\n",
    "authors": [
      "Fei Shen",
      "Zhe Wang",
      "Zijun Wang",
      "Xiaode Fu",
      "Jiayi Chen",
      "Xiaoyu Du",
      "Jinhui Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.15934"
  },
  {
    "id": "arXiv:2205.15951",
    "title": "Hollywood Identity Bias Dataset: A Context Oriented Bias Analysis of  Movie Dialogues",
    "abstract": "Hollywood Identity Bias Dataset: A Context Oriented Bias Analysis of  Movie Dialogues",
    "descriptor": "",
    "authors": [
      "Sandhya Singh",
      "Prapti Roy",
      "Nihar Sahoo",
      "Niteesh Mallela",
      "Himanshu Gupta",
      "Pushpak Bhattacharyya",
      "Milind Savagaonkar",
      "Nidhi",
      "Roshni Ramnani",
      "Anutosh Maitra",
      "Shubhashis Sengupta"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15951"
  },
  {
    "id": "arXiv:2205.15958",
    "title": "The dynamics of online polarization",
    "abstract": "The dynamics of online polarization",
    "descriptor": "",
    "authors": [
      "Carlo Michele Valensise",
      "Matteo Cinelli",
      "Walter Quattrociocchi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2205.15958"
  },
  {
    "id": "arXiv:2205.15972",
    "title": "K-Detector: Identifying Duplicate Crash Failures in Large-Scale Software  Delivery",
    "abstract": "Comments: 6 pages, 7 figures, ISSRE 2020",
    "descriptor": "\nComments: 6 pages, 7 figures, ISSRE 2020\n",
    "authors": [
      "Hao Yang",
      "Yang Xu",
      "Yong Li",
      "Hyun-Deok Choi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2205.15972"
  },
  {
    "id": "arXiv:2205.16001",
    "title": "Cluster-based Evaluation of Automatically Generated Text",
    "abstract": "Comments: Tiago Pimentel and Clara Meister contributed equally to this work",
    "descriptor": "\nComments: Tiago Pimentel and Clara Meister contributed equally to this work\n",
    "authors": [
      "Tiago Pimentel",
      "Clara Meister",
      "Ryan Cotterell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.16001"
  }
]
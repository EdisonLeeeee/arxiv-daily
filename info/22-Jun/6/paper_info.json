[
  {
    "id": "arXiv:2206.01206",
    "title": "Positive Unlabeled Contrastive Learning",
    "abstract": "Self-supervised pretraining on unlabeled data followed by supervised\nfinetuning on labeled data is a popular paradigm for learning from limited\nlabeled examples. In this paper, we investigate and extend this paradigm to the\nclassical positive unlabeled (PU) setting - the weakly supervised task of\nlearning a binary classifier only using a few labeled positive examples and a\nset of unlabeled samples. We propose a novel PU learning objective positive\nunlabeled Noise Contrastive Estimation (puNCE) that leverages the available\nexplicit (from labeled samples) and implicit (from unlabeled samples)\nsupervision to learn useful representations from positive unlabeled input data.\nThe underlying idea is to assign each training sample an individual weight;\nlabeled positives are given unit weight; unlabeled samples are duplicated, one\ncopy is labeled positive and the other as negative with weights $\\pi$ and\n$(1-\\pi)$ where $\\pi$ denotes the class prior. Extensive experiments across\nvision and natural language tasks reveal that puNCE consistently improves over\nexisting unsupervised and supervised contrastive baselines under limited\nsupervision.",
    "descriptor": "",
    "authors": [
      "Anish Acharya",
      "Sujay Sanghavi",
      "Li Jing",
      "Bhargav Bhushanam",
      "Dhruv Choudhary",
      "Michael Rabbat",
      "Inderjit Dhillon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.01206"
  },
  {
    "id": "arXiv:2206.01207",
    "title": "RACA: Relation-Aware Credit Assignment for Ad-Hoc Cooperation in  Multi-Agent Deep Reinforcement Learning",
    "abstract": "In recent years, reinforcement learning has faced several challenges in the\nmulti-agent domain, such as the credit assignment issue. Value function\nfactorization emerges as a promising way to handle the credit assignment issue\nunder the centralized training with decentralized execution (CTDE) paradigm.\nHowever, existing value function factorization methods cannot deal with ad-hoc\ncooperation, that is, adapting to new configurations of teammates at test time.\nSpecifically, these methods do not explicitly utilize the relationship between\nagents and cannot adapt to different sizes of inputs. To address these\nlimitations, we propose a novel method, called Relation-Aware Credit Assignment\n(RACA), which achieves zero-shot generalization in ad-hoc cooperation\nscenarios. RACA takes advantage of a graph-based relation encoder to encode the\ntopological structure between agents. Furthermore, RACA utilizes an\nattention-based observation abstraction mechanism that can generalize to an\narbitrary number of teammates with a fixed number of parameters. Experiments\ndemonstrate that our method outperforms baseline methods on the StarCraftII\nmicromanagement benchmark and ad-hoc cooperation scenarios.",
    "descriptor": "\nComments: Accepted at IJCNN 2022 (Oral)\n",
    "authors": [
      "Hao Chen",
      "Guangkai Yang",
      "Junge Zhang",
      "Qiyue Yin",
      "Kaiqi Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.01207"
  },
  {
    "id": "arXiv:2206.01228",
    "title": "Constellation Shared Multiple Access -- A NOMA scheme for increased user  capacity in 5G MMTC",
    "abstract": "While the legacy cyclic prefix orthogonal frequency division multiple access\nis retained as the preferred multiple access scheme for 5G enhanced mobile\nbroadband the research is now focussed on the multiple access schemes for\nmassive machine type communication (mMTC) and ultra-reliable low latency\ncommunication .Though orthogonal multiple access schemes provide simple\nreception, they limit number of simultaneous user equipment as against the\nprimary requirement of mMTC. On the other hand, the various non-orthogonal\nmultiple access schemes which have been proposed so far as the likely solution,\nneed complex successive interference cancellation receivers. So a simplified\nscheme named constellation shared multiple access is proposed here which\nsubstantially increases the number of simultaneous users to be served within a\nsingle resource block (RB) in LTE or 5G New Radio, thus aiding the massive\nconnectivity requirement of mMTC. This is achieved by differentiating among the\nusers in constellation domain. Moreover, the simple architecture compatible\nwith 5G eMBB makes it a strong contender multiple access contender for 5G mMTC.",
    "descriptor": "",
    "authors": [
      "Kiran V. Shanbhag",
      "Savitha H. M"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.01228"
  },
  {
    "id": "arXiv:2206.01230",
    "title": "Formalizing Human Ingenuity: A Quantitative Framework for Coyright Law's  Substantial Similarity",
    "abstract": "A central notion in U.S. copyright law is judging the substantial similarity\nbetween an original and an (allegedly) derived work. Capturing this notion has\nproven elusive, and the many approaches offered by case law and legal\nscholarship are often ill-defined, contradictory, or internally-inconsistent.\nThis work suggests that key parts of the substantial-similarity puzzle are\namendable to modeling inspired by theoretical computer science. Our proposed\nframework quantitatively evaluates how much \"novelty\" is needed to produce the\nderived work with access to the original work, versus reproducing it without\naccess to the copyrighted elements of the original work. \"Novelty\" is captured\nby a computational notion of description length, in the spirit of\nKolmogorov-Levin complexity, which is robust to mechanical transformations and\navailability of contextual information.\nThis results in an actionable framework that could be used by courts as an\naid for deciding substantial similarity. We evaluate it on several pivotal\ncases in copyright law and observe that the results are consistent with the\nrulings, and are philosophically aligned with the\nabstraction-filtration-comparison test of Altai.",
    "descriptor": "",
    "authors": [
      "Sarah Scheffler",
      "Eran Tromer",
      "Mayank Varia"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.01230"
  },
  {
    "id": "arXiv:2206.01232",
    "title": "What Are Expected Queries in End-to-End Object Detection?",
    "abstract": "End-to-end object detection is rapidly progressed after the emergence of\nDETR. DETRs use a set of sparse queries that replace the dense candidate boxes\nin most traditional detectors. In comparison, the sparse queries cannot\nguarantee a high recall as dense priors. However, making queries dense is not\ntrivial in current frameworks. It not only suffers from heavy computational\ncost but also difficult optimization. As both sparse and dense queries are\nimperfect, then \\emph{what are expected queries in end-to-end object\ndetection}? This paper shows that the expected queries should be Dense Distinct\nQueries (DDQ). Concretely, we introduce dense priors back to the framework to\ngenerate dense queries. A duplicate query removal pre-process is applied to\nthese queries so that they are distinguishable from each other. The dense\ndistinct queries are then iteratively processed to obtain final sparse outputs.\nWe show that DDQ is stronger, more robust, and converges faster. It obtains\n44.5 AP on the MS COCO detection dataset with only 12 epochs. DDQ is also\nrobust as it outperforms previous methods on both object detection and instance\nsegmentation tasks on various datasets. DDQ blends advantages from traditional\ndense priors and recent end-to-end detectors. We hope it can serve as a new\nbaseline and inspires researchers to revisit the complementarity between\ntraditional methods and end-to-end detectors. The source code is publicly\navailable at \\url{https://github.com/jshilong/DDQ}.",
    "descriptor": "\nComments: The source code is publicly available at this https URL\n",
    "authors": [
      "Shilong Zhang",
      "Xinjiang Wang",
      "Jiaqi Wang",
      "Jiangmiao Pang",
      "Kai Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01232"
  },
  {
    "id": "arXiv:2206.01233",
    "title": "Equivariant Reinforcement Learning for Quadrotor UAV",
    "abstract": "This paper presents an equivariant reinforcement learning framework for\nquadrotor unmanned aerial vehicles. Successful training of reinforcement\nlearning often requires numerous interactions with the environments, which\nhinders its applicability especially when the available computational resources\nare limited, or when there is no reliable simulation model. We identified an\nequivariance property of the quadrotor dynamics such that the dimension of the\nstate required in the training is reduced by one, thereby improving the\nsampling efficiency of reinforcement learning substantially. This is\nillustrated by numerical examples with popular reinforcement learning\ntechniques of TD3 and SAC.",
    "descriptor": "\nComments: 7 pages, 7 figures\n",
    "authors": [
      "Beomyeol Yu",
      "Taeyoung Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.01233"
  },
  {
    "id": "arXiv:2206.01237",
    "title": "Impact of Frequency Support by Wind Turbines on Small-Signal Stability  of Power Systems",
    "abstract": "Rising wind energy integration, accompanied by a decreasing level of system\ninertia, requires additional sources of ancillary services. Wind turbines based\non doubly fed induction generators (DFIG) can provide inertial and primary\nfrequency support, when equipped with specific controls. This paper\ninvestigates the effect of frequency support provision by DFIGs on the\nsmall-signal stability of power systems. To this end, a modified version of the\nKundur two-area test system is employed to analyze different scenarios. Wind\nenergy generation is either added to the existing system or displaces part of\nthe synchronous generation. Simulations show that primary frequency support\ntends to improve the damping of electromechanical oscillations and deteriorate\nit for converter control-based ones. On the other hand, inertial response may\nbe either beneficial, detrimental or negligible to damping, depending on the\ntuning of control parameters.",
    "descriptor": "",
    "authors": [
      "Antonio Pepiciello",
      "Jos\u00e9 Luis Dom\u00ednguez-Garc\u00eda",
      "Alfredo Vaccaro"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.01237"
  },
  {
    "id": "arXiv:2206.01239",
    "title": "Design and evaluation of a cognitive approach for disseminating semantic  knowledge and content in opportunistic networks",
    "abstract": "In cyber-physical convergence scenarios information flows seamlessly between\nthe physical and the cyber worlds. Here, users' mobile devices represent a\nnatural bridge through which users process acquired information and perform\nactions. The sheer amount of data available in this context calls for novel,\nautonomous and lightweight data-filtering solutions, where only relevant\ninformation is finally presented to users. Moreover, in many real-world\nscenarios data is not categorised in predefined topics, but it is generally\naccompanied by semantic descriptions possibly describing users' interests. In\nthese complex conditions, user devices should autonomously become aware not\nonly of the existence of data in the network, but also of their semantic\ndescriptions and correlations between them. To tackle these issues, we present\na set of algorithms for knowledge and data dissemination in opportunistic\nnetworks, based on simple and very effective models (called cognitive\nheuristics) coming from cognitive sciences. We show how to exploit them to\ndisseminate both semantic data and the corresponding data items. We provide a\nthorough performance analysis, under various different conditions comparing our\nresults against non-cognitive solutions. Simulation results demonstrate the\nsuperior performance of our solution towards a more effective semantic\nknowledge acquisition and representation, and a more tailored content\nacquisition.",
    "descriptor": "",
    "authors": [
      "Matteo Mordacchini",
      "Lorenzo Valerio",
      "Marco Conti",
      "Andrea Passarella"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.01239"
  },
  {
    "id": "arXiv:2206.01240",
    "title": "Fuzzy granular approximation classifier",
    "abstract": "In this article, a new Fuzzy Granular Approximation Classifier (FGAC) is\nintroduced. The classifier is based on the previously introduced concept of the\ngranular approximation and its multi-class classification case. The classifier\nis instance-based and its biggest advantage is its local transparency i.e., the\nability to explain every individual prediction it makes. We first develop the\nFGAC for the binary classification case and the multi-class classification case\nand we discuss its variation that includes the Ordered Weighted Average (OWA)\noperators. Those variations of the FGAC are then empirically compared with\nother locally transparent ML methods. At the end, we discuss the transparency\nof the FGAC and its advantage over other locally transparent methods. We\nconclude that while the FGAC has similar predictive performance to other\nlocally transparent ML models, its transparency can be superior in certain\ncases.",
    "descriptor": "",
    "authors": [
      "Marko Palangeti\u0107",
      "Chris Cornelis",
      "Salvatore Greco",
      "Roman S\u0142owi\u0144ski"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.01240"
  },
  {
    "id": "arXiv:2206.01242",
    "title": "Inf-sup stabilized Scott--Vogelius pairs on general simplicial grids by  Raviart--Thomas enrichment",
    "abstract": "This paper considers the discretization of the Stokes equations with\nScott--Vogelius pairs of finite element spaces on arbitrary shape-regular\nsimplicial grids. A novel way of stabilizing these pairs with respect to the\ndiscrete inf-sup condition is proposed and analyzed. The key idea consists in\nenriching the continuous polynomials of order $k$ of the Scott--Vogelius\nvelocity space with appropriately chosen and explicitly given Raviart--Thomas\nbubbles. This approach is inspired by [Li/Rui, IMA J. Numer. Anal, 2021], where\nthe case $k=1$ was studied. The proposed method is pressure-robust, with\noptimally converging $\\boldsymbol{H}^1$-conforming velocity and a small\n$\\boldsymbol{H}(\\mathrm{div})$-conforming correction rendering the full\nvelocity divergence-free. For $k\\ge d$, with $d$ being the dimension, the\nmethod is parameter-free. Furthermore, it is shown that the additional degrees\nof freedom for the Raviart--Thomas enrichment and also all non-constant\npressure degrees of freedom can be condensated, effectively leading to a\npressure-robust, inf-sup stable, optimally convergent $\\boldsymbol{P}_k \\times\nP_0$ scheme. Aspects of the implementation are discussed and numerical studies\nconfirm the analytic results.",
    "descriptor": "\nComments: 23 pages\n",
    "authors": [
      "Volker John",
      "Xu Li",
      "Christian Merdon",
      "Hongxing Rui"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.01242"
  },
  {
    "id": "arXiv:2206.01243",
    "title": "A multi-fidelity approach coupling parameter space reduction and  non-intrusive POD with application to structural optimization of passenger  ship hulls",
    "abstract": "Nowadays, the shipbuilding industry is facing a radical change towards\nsolutions with a smaller environmental impact. This can be achieved with low\nemissions engines, optimized shape designs with lower wave resistance and noise\ngeneration, and by reducing the metal raw materials used during the\nmanufacturing. This work focuses on the last aspect by presenting a complete\nstructural optimization pipeline for modern passenger ship hulls which exploits\nadvanced model order reduction techniques to reduce the dimensionality of both\ninput parameters and outputs of interest. We introduce a novel approach which\nincorporates parameter space reduction through active subspaces into the proper\northogonal decomposition with interpolation method. This is done in a\nmulti-fidelity setting. We test the whole framework on a simplified model of a\nmidship section and on the full model of a passenger ship, controlled by 20 and\n16 parameters, respectively. We present a comprehensive error analysis and show\nthe capabilities and usefulness of the methods especially during the\npreliminary design phase, finding new unconsidered designs while handling high\ndimensional parameterizations.",
    "descriptor": "",
    "authors": [
      "Marco Tezzele",
      "Lorenzo Fabris",
      "Matteo Sidari",
      "Mauro Sicchiero",
      "Gianluigi Rozza"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.01243"
  },
  {
    "id": "arXiv:2206.01244",
    "title": "Real-Time Portrait Stylization on the Edge",
    "abstract": "In this work we demonstrate real-time portrait stylization, specifically,\ntranslating self-portrait into cartoon or anime style on mobile devices. We\npropose a latency-driven differentiable architecture search method, maintaining\nrealistic generative quality. With our framework, we obtain $10\\times$\ncomputation reduction on the generative model and achieve real-time video\nstylization on off-the-shelf smartphone using mobile GPUs.",
    "descriptor": "",
    "authors": [
      "Yanyu Li",
      "Xuan Shen",
      "Geng Yuan",
      "Jiexiong Guan",
      "Wei Niu",
      "Hao Tang",
      "Bin Ren",
      "Yanzhi Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.01244"
  },
  {
    "id": "arXiv:2206.01245",
    "title": "Simultaneous Contact Location and Object Pose Estimation Using  Proprioceptive Tactile Feedback",
    "abstract": "Joint estimation of grasped object pose and externally made contact on the\nobject is central to robust and dexterous manipulation. In this paper, we\npropose a novel state-estimation algorithm that jointly estimates contact\nlocation and object pose in 3D using exclusively proprioceptive tactile\nfeedback. Our approach leverages two complementary particle filters: one to\nestimate contact location (CPFGrasp) and another to estimate object poses\n(SCOPE). We implement and evaluate our approach on real-world single-arm and\ndual-arm robotic systems. We demonstrate how by bringing two objects into\ncontact, the robots can infer contact location and object poses simultaneously.\nOur proposed method can be applied to a number of downstream tasks that require\naccurate pose estimates, such as assembly and insertion.",
    "descriptor": "",
    "authors": [
      "Andrea Sipos",
      "Nima Fazeli"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.01245"
  },
  {
    "id": "arXiv:2206.01250",
    "title": "Proceedings of the 2022 Workshop on Resource AWareness of Systems and  Society (RAW)",
    "abstract": "Proceedings of the 2022 Workshop on Resource AWareness of Systems and Society\n(RAW), colocated with ICT4S 2022 in Plovdiv, Bulgaria on 13th of June 2022.",
    "descriptor": "",
    "authors": [
      "Rafal Graczyk",
      "Padma Iyenghar"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.01250"
  },
  {
    "id": "arXiv:2206.01251",
    "title": "Expressiveness and Learnability: A Unifying View for Evaluating  Self-Supervised Learning",
    "abstract": "We propose a unifying view to analyze the representation quality of\nself-supervised learning (SSL) models without access to supervised labels,\nwhile being agnostic to the architecture, learning algorithm or data\nmanipulation used during training. We argue that representations can be\nevaluated through the lens of expressiveness and learnability. We propose to\nuse the Intrinsic Dimension (ID) to assess expressiveness and introduce Cluster\nLearnability (CL) to assess learnability. CL is measured as the learning speed\nof a KNN classifier trained to predict labels obtained by clustering the\nrepresentations with K-means. We thus combine CL and ID into a single\npredictor: CLID. Through a large-scale empirical study with a diverse family of\nSSL algorithms, we find that CLID better correlates with in-distribution model\nperformance than other competing recent evaluation schemes. We also benchmark\nCLID on out-of-domain generalization, where CLID serves as a predictor of the\ntransfer performance of SSL models on several classification tasks, yielding\nimprovements with respect to the competing baselines.",
    "descriptor": "",
    "authors": [
      "Yuchen Lu",
      "Zhen Liu",
      "Aristide Baratin",
      "Romain Laroche",
      "Aaron Courville",
      "Alessandro Sordoni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01251"
  },
  {
    "id": "arXiv:2206.01254",
    "title": "Which Explanation Should I Choose? A Function Approximation Perspective  to Characterizing Post hoc Explanations",
    "abstract": "Despite the plethora of post hoc model explanation methods, the basic\nproperties and behavior of these methods and the conditions under which each\none is effective are not well understood. In this work, we bridge these gaps\nand address a fundamental question: Which explanation method should one use in\na given situation? To this end, we adopt a function approximation perspective\nand formalize the local function approximation (LFA) framework. We show that\npopular explanation methods are instances of this framework, performing\nfunction approximations of the underlying model in different neighborhoods\nusing different loss functions. We introduce a no free lunch theorem for\nexplanation methods which demonstrates that no single method can perform\noptimally across all neighbourhoods and calls for choosing among methods. To\nchoose among methods, we set forth a guiding principle based on the function\napproximation perspective, considering a method to be effective if it recovers\nthe underlying model when the model is a member of the explanation function\nclass. Then, we analyze the conditions under which popular explanation methods\nare effective and provide recommendations for choosing among explanation\nmethods and creating new ones. Lastly, we empirically validate our theoretical\nresults using various real world datasets, model classes, and prediction tasks.\nBy providing a principled mathematical framework which unifies diverse\nexplanation methods, our work characterizes the behaviour of these methods and\ntheir relation to one another, guides the choice of explanation methods, and\npaves the way for the creation of new ones.",
    "descriptor": "",
    "authors": [
      "Tessa Han",
      "Suraj Srinivas",
      "Himabindu Lakkaraju"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.01254"
  },
  {
    "id": "arXiv:2206.01255",
    "title": "Compressive Fourier collocation methods for high-dimensional diffusion  equations with periodic boundary conditions",
    "abstract": "High-dimensional Partial Differential Equations (PDEs) are a popular\nmathematical modelling tool, with applications ranging from finance to\ncomputational chemistry. However, standard numerical techniques for solving\nthese PDEs are typically affected by the curse of dimensionality. In this work,\nwe tackle this challenge while focusing on stationary diffusion equations\ndefined over a high-dimensional domain with periodic boundary conditions.\nInspired by recent progress in sparse function approximation in high\ndimensions, we propose a new method called compressive Fourier collocation.\nCombining ideas from compressive sensing and spectral collocation, our method\nreplaces the use of structured collocation grids with Monte Carlo sampling and\nemploys sparse recovery techniques, such as orthogonal matching pursuit and\n$\\ell^1$ minimization, to approximate the Fourier coefficients of the PDE\nsolution. We conduct a rigorous theoretical analysis showing that the\napproximation error of the proposed method is comparable with the best $s$-term\napproximation (with respect to the Fourier basis) to the solution. Using the\nrecently introduced framework of random sampling in bounded Riesz systems, our\nanalysis shows that the compressive Fourier collocation method mitigates the\ncurse of dimensionality with respect to the number of collocation points under\nsufficient conditions on the regularity of the diffusion coefficient. We also\npresent numerical experiments that illustrate the accuracy and stability of the\nmethod for the approximation of sparse and compressible solutions.",
    "descriptor": "\nComments: 34 pages, 9 figures\n",
    "authors": [
      "Weiqi Wang",
      "Simone Brugiapaglia"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01255"
  },
  {
    "id": "arXiv:2206.01256",
    "title": "PETRv2: A Unified Framework for 3D Perception from Multi-Camera Images",
    "abstract": "In this paper, we propose PETRv2, a unified framework for 3D perception from\nmulti-view images. Based on PETR, PETRv2 explores the effectiveness of temporal\nmodeling, which utilizes the temporal information of previous frames to boost\n3D object detection. More specifically, we extend the 3D position embedding (3D\nPE) in PETR for temporal modeling. The 3D PE achieves the temporal alignment on\nobject position of different frames. A feature-guided position encoder is\nfurther introduced to improve the data adaptability of 3D PE. To support for\nhigh-quality BEV segmentation, PETRv2 provides a simply yet effective solution\nby adding a set of segmentation queries. Each segmentation query is responsible\nfor segmenting one specific patch of BEV map. PETRv2 achieves state-of-the-art\nperformance on 3D object detection and BEV segmentation. Detailed robustness\nanalysis is also conducted on PETR framework. We hope PETRv2 can serve as a\nunified framework for 3D perception.",
    "descriptor": "\nComments: Tech Report\n",
    "authors": [
      "Yingfei Liu",
      "Junjie Yan",
      "Fan Jia",
      "Shuailin Li",
      "Qi Gao",
      "Tiancai Wang",
      "Xiangyu Zhang",
      "Jian Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01256"
  },
  {
    "id": "arXiv:2206.01261",
    "title": "Entangled Residual Mappings",
    "abstract": "Residual mappings have been shown to perform representation learning in the\nfirst layers and iterative feature refinement in higher layers. This interplay,\ncombined with their stabilizing effect on the gradient norms, enables them to\ntrain very deep networks. In this paper, we take a step further and introduce\nentangled residual mappings to generalize the structure of the residual\nconnections and evaluate their role in iterative learning representations. An\nentangled residual mapping replaces the identity skip connections with\nspecialized entangled mappings such as orthogonal, sparse, and structural\ncorrelation matrices that share key attributes (eigenvalues, structure, and\nJacobian norm) with identity mappings. We show that while entangled mappings\ncan preserve the iterative refinement of features across various deep models,\nthey influence the representation learning process in convolutional networks\ndifferently than attention-based models and recurrent neural networks. In\ngeneral, we find that for CNNs and Vision Transformers entangled sparse mapping\ncan help generalization while orthogonal mappings hurt performance. For\nrecurrent networks, orthogonal residual mappings form an inductive bias for\ntime-variant sequences, which degrades accuracy on time-invariant tasks.",
    "descriptor": "\nComments: 21 Pages\n",
    "authors": [
      "Mathias Lechner",
      "Ramin Hasani",
      "Zahra Babaiee",
      "Radu Grosu",
      "Daniela Rus",
      "Thomas A. Henzinger",
      "Sepp Hochreiter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.01261"
  },
  {
    "id": "arXiv:2206.01266",
    "title": "Exponential Separations in Symmetric Neural Networks",
    "abstract": "In this work we demonstrate a novel separation between symmetric neural\nnetwork architectures. Specifically, we consider the Relational\nNetwork~\\parencite{santoro2017simple} architecture as a natural generalization\nof the DeepSets~\\parencite{zaheer2017deep} architecture, and study their\nrepresentational gap. Under the restriction to analytic activation functions,\nwe construct a symmetric function acting on sets of size $N$ with elements in\ndimension $D$, which can be efficiently approximated by the former\narchitecture, but provably requires width exponential in $N$ and $D$ for the\nlatter.",
    "descriptor": "",
    "authors": [
      "Aaron Zweig",
      "Joan Bruna"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01266"
  },
  {
    "id": "arXiv:2206.01268",
    "title": "MMTM: Multi-Tasking Multi-Decoder Transformer for Math Word Problems",
    "abstract": "Recently, quite a few novel neural architectures were derived to solve math\nword problems by predicting expression trees. These architectures varied from\nseq2seq models, including encoders leveraging graph relationships combined with\ntree decoders. These models achieve good performance on various MWPs datasets\nbut perform poorly when applied to an adversarial challenge dataset, SVAMP. We\npresent a novel model MMTM that leverages multi-tasking and multi-decoder\nduring pre-training. It creates variant tasks by deriving labels using\npre-order, in-order and post-order traversal of expression trees, and uses\ntask-specific decoders in a multi-tasking framework. We leverage transformer\narchitectures with lower dimensionality and initialize weights from RoBERTa\nmodel. MMTM model achieves better mathematical reasoning ability and\ngeneralisability, which we demonstrate by outperforming the best state of the\nart baseline models from Seq2Seq, GTS, and Graph2Tree with a relative\nimprovement of 19.4% on an adversarial challenge dataset SVAMP.",
    "descriptor": "\nComments: 10 pages, 3 figures, 3 tables\n",
    "authors": [
      "Keyur Faldu",
      "Amit Sheth",
      "Prashant Kikani",
      "Darshan Patel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.01268"
  },
  {
    "id": "arXiv:2206.01270",
    "title": "Max-Weight Online Stochastic Matching: Improved Approximations Against  the Online Benchmark",
    "abstract": "In this paper, we study max-weight stochastic matchings on online bipartite\ngraphs under both vertex and edge arrivals. We focus on designing polynomial\ntime approximation algorithms with respect to the online benchmark, which was\nfirst considered by Papadimitriou, Pollner, Saberi, and Wajc [EC'21].\nIn the vertex arrival version of the problem, the goal is to find an\napproximate max-weight matching of a given bipartite graph when the vertices in\none part of the graph arrive online in a fixed order with independent chances\nof failure. Whenever a vertex arrives we should decide, irrevocably, whether to\nmatch it with one of its unmatched neighbors or leave it unmatched forever.\nThere has been a long line of work designing approximation algorithms for\ndifferent variants of this problem with respect to the offline benchmark\n(prophet). Papadimitriou et al., however, propose the alternative online\nbenchmark and show that considering this new benchmark allows them to improve\nthe 0.5 approximation ratio, which is the best ratio achievable with respect to\nthe offline benchmark. They provide a 0.51-approximation algorithm which was\nlater improved to 0.526 by Saberi and Wajc [ICALP'21]. The main contribution of\nthis paper is designing a simple algorithm with a significantly improved\napproximation ratio of (1-1/e) for this problem.\nWe also consider the edge arrival version in which, instead of vertices,\nedges of the graph arrive in an online fashion with independent chances of\nfailure. Designing approximation algorithms for this problem has also been\nstudied extensively with the best approximation ratio being 0.337 with respect\nto the offline benchmark. This paper, however, is the first to consider the\nonline benchmark for the edge arrival version of the problem. For this problem,\nwe provide a simple algorithm with an approximation ratio of 0.5 with respect\nto the online benchmark.",
    "descriptor": "",
    "authors": [
      "Mark Braverman",
      "Mahsa Derakhshan",
      "Antonio Molina Lovett"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.01270"
  },
  {
    "id": "arXiv:2206.01272",
    "title": "Data-Driven Linear Koopman Embedding for Model-Predictive Power System  Control",
    "abstract": "This paper presents a linear Koopman embedding for model predictive emergency\nvoltage regulation in power systems, by way of a data-driven lifting of the\nsystem dynamics into a higher dimensional linear space over which the MPC\n(model predictive control) is exercised, thereby scaling as well as expediting\nthe MPC computation for its real-time implementation for practical systems. We\ndevelop a {\\em Koopman-inspired deep neural network} (KDNN) architecture for\nthe linear embedding of the voltage dynamics subjected to reactive controls.\nThe training of the KDNN for the purposes of linear embedding is done using the\nsimulated voltage trajectories under a variety of applied control inputs and\nload conditions. The proposed framework learns the underlying system dynamics\nfrom the input/output data in the form of a triple of transforms: A Neural\nNetwork (NN)-based lifting to a higher dimension, a linear dynamics within that\nhigher dynamics, and an NN-based projection to original space. This approach\nalleviates the burden of an ad-hoc selection of the basis functions for the\npurposes of lifting to higher dimensional linear space. The MPC is computed\nover the linear dynamics, making the control computation scalable and also\nreal-time.",
    "descriptor": "",
    "authors": [
      "Ramij R. Hossain",
      "Rahmat Adesunkanmi",
      "Ratnesh Kumar"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.01272"
  },
  {
    "id": "arXiv:2206.01278",
    "title": "Lottery Tickets on a Data Diet: Finding Initializations with Sparse  Trainable Networks",
    "abstract": "A striking observation about iterative magnitude pruning (IMP; Frankle et al.\n2020) is that $\\unicode{x2014}$ after just a few hundred steps of dense\ntraining $\\unicode{x2014}$ the method can find a sparse sub-network that can be\ntrained to the same accuracy as the dense network. However, the same does not\nhold at step 0, i.e. random initialization. In this work, we seek to understand\nhow this early phase of pre-training leads to a good initialization for IMP\nboth through the lens of the data distribution and the loss landscape geometry.\nEmpirically we observe that, holding the number of pre-training iterations\nconstant, training on a small fraction of (randomly chosen) data suffices to\nobtain an equally good initialization for IMP. We additionally observe that by\npre-training only on \"easy\" training data, we can decrease the number of steps\nnecessary to find a good initialization for IMP compared to training on the\nfull dataset or a randomly chosen subset. Finally, we identify novel properties\nof the loss landscape of dense networks that are predictive of IMP performance,\nshowing in particular that more examples being linearly mode connected in the\ndense network correlates well with good initializations for IMP. Combined,\nthese results provide new insight into the role played by the early phase\ntraining in IMP.",
    "descriptor": "\nComments: The first two authors contributed equally\n",
    "authors": [
      "Mansheej Paul",
      "Brett W. Larsen",
      "Surya Ganguli",
      "Jonathan Frankle",
      "Gintare Karolina Dziugaite"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.01278"
  },
  {
    "id": "arXiv:2206.01280",
    "title": "On the Parallel Parameterized Complexity of MaxSAT Variants",
    "abstract": "In the maximum satisfiability problem (MAX-SAT) we are given a propositional\nformula in conjunctive normal form and have to find an assignment that\nsatisfies as many clauses as possible. We study the parallel parameterized\ncomplexity of various versions of MAX-SAT and provide the first constant-time\nalgorithms parameterized either by the solution size or by the allowed excess\nrelative to some guarantee (\"above guarantee\" versions). For the dual\nparameterized version where the parameter is the number of clauses we are\nallowed to leave unsatisfied, we present the first parallel algorithm for\nMAX-2SAT (known as ALMOST-2SAT). The difficulty in solving ALMOST-2SAT in\nparallel comes from the fact that the iterative compression method, originally\ndeveloped to prove that the problem is fixed-parameter tractable at all, is\ninherently sequential. We observe that a graph flow whose value is a parameter\ncan be computed in parallel and use this fact to develop a parallel algorithm\nfor the vertex cover problem parameterized above the size of a given matching.\nFinally, we study the parallel complexity of MAX-SAT parameterized by the\nvertex cover number, the treedepth, the feedback vertex set number, and the\ntreewidth of the input's incidence graph. While MAX-SAT is fixed-parameter\ntractable for all of these parameters, we show that they allow different\ndegrees of possible parallelization. For all four we develop dedicated parallel\nalgorithms that are constructive, meaning that they output an optimal\nassignment - in contrast to results that can be obtained by parallel\nmeta-theorems, which often only solve the decision version.",
    "descriptor": "\nComments: SAT 2022\n",
    "authors": [
      "Max Bannach",
      "Malte Skambath",
      "Till Tantau"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.01280"
  },
  {
    "id": "arXiv:2206.01281",
    "title": "Sparx: Distributed Outlier Detection at Scale",
    "abstract": "There is no shortage of outlier detection (OD) algorithms in the literature,\nyet a vast body of them are designed for a single machine. With the increasing\nreality of already cloud-resident datasets comes the need for distributed OD\ntechniques. This area, however, is not only understudied but also short of\npublic-domain implementations for practical use. This paper aims to fill this\ngap: We design Sparx, a data-parallel OD algorithm suitable for shared-nothing\ninfrastructures, which we specifically implement in Apache Spark. Through\nextensive experiments on three real-world datasets, with several billions of\npoints and millions of features, we show that existing open-source solutions\nfail to scale up; either by large number of points or high dimensionality,\nwhereas Sparx yields scalable and effective performance. To facilitate\npractical use of OD on modern-scale datasets, we open-source Sparx under the\nApache license at https://tinyurl.com/sparx2022.",
    "descriptor": "\nComments: 11 pages, 7 figures, 14 tables\n",
    "authors": [
      "Sean Zhang",
      "Varun Ursekar",
      "Leman Akoglu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2206.01281"
  },
  {
    "id": "arXiv:2206.01288",
    "title": "Decentralized Training of Foundation Models in Heterogeneous  Environments",
    "abstract": "Training foundation models, such as GPT-3 and PaLM, can be extremely\nexpensive, often involving tens of thousands of GPUs running continuously for\nmonths. These models are typically trained in specialized clusters featuring\nfast, homogeneous interconnects and using carefully designed software systems\nthat support both data parallelism and model/pipeline parallelism. Such\ndedicated clusters can be costly and difficult to obtain. Can we instead\nleverage the much greater amount of decentralized, heterogeneous, and\nlower-bandwidth interconnected compute? Previous works examining the\nheterogeneous, decentralized setting focus on relatively small models that can\nbe trained in a purely data parallel manner. State-of-the-art schemes for model\nparallel foundation model training, such as Megatron, only consider the\nhomogeneous data center setting. In this paper, we present the first study of\ntraining large foundation models with model parallelism in a decentralized\nregime over a heterogeneous network. Our key technical contribution is a\nscheduling algorithm that allocates different computational \"tasklets\" in the\ntraining of foundation models to a group of decentralized GPU devices connected\nby a slow heterogeneous network. We provide a formal cost model and further\npropose an efficient evolutionary algorithm to find the optimal allocation\nstrategy. We conduct extensive experiments that represent different scenarios\nfor learning over geo-distributed devices simulated using real-world network\nmeasurements. In the most extreme case, across 8 different cities spanning 3\ncontinents, our approach is 4.8X faster than prior state-of-the-art training\nsystems (Megatron).",
    "descriptor": "",
    "authors": [
      "Binhang Yuan",
      "Yongjun He",
      "Jared Quincy Davis",
      "Tianyi Zhang",
      "Tri Dao",
      "Beidi Chen",
      "Percy Liang",
      "Christopher Re",
      "Ce Zhang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01288"
  },
  {
    "id": "arXiv:2206.01290",
    "title": "Points2NeRF: Generating Neural Radiance Fields from 3D point cloud",
    "abstract": "Contemporary registration devices for 3D visual information, such as LIDARs\nand various depth cameras, capture data as 3D point clouds. In turn, such\nclouds are challenging to be processed due to their size and complexity.\nExisting methods address this problem by fitting a mesh to the point cloud and\nrendering it instead. This approach, however, leads to the reduced fidelity of\nthe resulting visualization and misses color information of the objects crucial\nin computer graphics applications. In this work, we propose to mitigate this\nchallenge by representing 3D objects as Neural Radiance Fields (NeRFs). We\nleverage a hypernetwork paradigm and train the model to take a 3D point cloud\nwith the associated color values and return a NeRF network's weights that\nreconstruct 3D objects from input 2D images. Our method provides efficient 3D\nobject representation and offers several advantages over the existing\napproaches, including the ability to condition NeRFs and improved\ngeneralization beyond objects seen in training. The latter we also confirmed in\nthe results of our empirical evaluation.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2003.08934 by other authors\n",
    "authors": [
      "D. Zimny",
      "T. Trzci\u0144ski",
      "P. Spurek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01290"
  },
  {
    "id": "arXiv:2206.01293",
    "title": "Incrementality Bidding via Reinforcement Learning under Mixed and  Delayed Rewards",
    "abstract": "Incrementality, which is used to measure the causal effect of showing an ad\nto a potential customer (e.g. a user in an internet platform) versus not, is a\ncentral object for advertisers in online advertising platforms. This paper\ninvestigates the problem of how an advertiser can learn to optimize the bidding\nsequence in an online manner \\emph{without} knowing the incrementality\nparameters in advance. We formulate the offline version of this problem as a\nspecially structured episodic Markov Decision Process (MDP) and then, for its\nonline learning counterpart, propose a novel reinforcement learning (RL)\nalgorithm with regret at most $\\widetilde{O}(H^2\\sqrt{T})$, which depends on\nthe number of rounds $H$ and number of episodes $T$, but does not depend on the\nnumber of actions (i.e., possible bids). A fundamental difference between our\nlearning problem from standard RL problems is that the realized reward feedback\nfrom conversion incrementality is \\emph{mixed} and \\emph{delayed}. To handle\nthis difficulty we propose and analyze a novel pairwise moment-matching\nalgorithm to learn the conversion incrementality, which we believe is of\nindependent of interest.",
    "descriptor": "",
    "authors": [
      "Ashwinkumar Badanidiyuru",
      "Zhe Feng",
      "Tianxi Li",
      "Haifeng Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2206.01293"
  },
  {
    "id": "arXiv:2206.01295",
    "title": "Rashomon Capacity: A Metric for Predictive Multiplicity in Probabilistic  Classification",
    "abstract": "Predictive multiplicity occurs when classification models with nearly\nindistinguishable average performances assign conflicting predictions to\nindividual samples. When used for decision-making in applications of\nconsequence (e.g., lending, education, criminal justice), models developed\nwithout regard for predictive multiplicity may result in unjustified and\narbitrary decisions for specific individuals. We introduce a new measure of\npredictive multiplicity in probabilistic classification called Rashomon\nCapacity. Prior metrics for predictive multiplicity focus on classifiers that\noutput thresholded (i.e., 0-1) predicted classes. In contrast, Rashomon\nCapacity applies to probabilistic classifiers, capturing more nuanced score\nvariations for individual samples. We provide a rigorous derivation for\nRashomon Capacity, argue its intuitive appeal, and demonstrate how to estimate\nit in practice. We show that Rashomon Capacity yields principled strategies for\ndisclosing conflicting models to stakeholders. Our numerical experiments\nillustrate how Rashomon Capacity captures predictive multiplicity in various\ndatasets and learning models, including neural networks. The tools introduced\nin this paper can help data scientists measure, report, and ultimately resolve\npredictive multiplicity prior to model deployment.",
    "descriptor": "\nComments: 28 pages, 22 figures\n",
    "authors": [
      "Hsiang Hsu",
      "Flavio du Pin Calmon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.01295"
  },
  {
    "id": "arXiv:2206.01297",
    "title": "Lossless Compression of Point Cloud Sequences Using Sequence Optimized  CNN Models",
    "abstract": "We propose a new paradigm for encoding the geometry of point cloud sequences,\nwhere the convolutional neural network (CNN) which estimates the encoding\ndistributions is optimized on several frames of the sequence to be compressed.\nWe adopt lightweight CNN structures, we perform training as part of the\nencoding process, and the CNN parameters are transmitted as part of the\nbitstream. The newly proposed encoding scheme operates on the octree\nrepresentation for each point cloud, encoding consecutively each octree\nresolution layer. At every octree resolution layer, the voxel grid is traversed\nsection-by-section (each section being perpendicular to a selected coordinate\naxis) and in each section the occupancies of groups of two-by-two voxels are\nencoded at once, in a single arithmetic coding operation. A context for the\nconditional encoding distribution is defined for each two-by-two group of\nvoxels, based on the information available about the occupancy of neighbor\nvoxels in the current and lower resolution layers of the octree. The CNN\nestimates the probability distributions of occupancy patterns of all voxel\ngroups from one section in four phases. In each new phase the contexts are\nupdated with the occupancies encoded in the previous phase, and each phase\nestimates the probabilities in parallel, providing a reasonable trade-off\nbetween the parallelism of processing and the informativeness of the contexts.\nThe CNN training time is comparable to the time spent in the remaining encoding\nsteps, leading to competitive overall encoding times. Bitrates and\nencoding-decoding times compare favorably with those of recently published\ncompression schemes.",
    "descriptor": "\nComments: 9 pages, 5 figures\n",
    "authors": [
      "Emre Can Kaya",
      "Ioan Tabus"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.01297"
  },
  {
    "id": "arXiv:2206.01298",
    "title": "PNODE: A memory-efficient neural ODE framework based on high-level  adjoint differentiation",
    "abstract": "Neural ordinary differential equations (neural ODEs) have emerged as a novel\nnetwork architecture that bridges dynamical systems and deep learning. However,\nthe gradient obtained with the continuous adjoint method in the vanilla neural\nODE is not reverse-accurate. Other approaches suffer either from excessive\nmemory requirement due to deep computational graphs or from limited choices for\nthe time integration scheme, hampering their application to large-scale complex\ndynamical systems. To achieve accurate gradients without compromising memory\nefficiency and flexibility, we present a new neural ODE framework, PNODE, based\non high-level discrete adjoint algorithmic differentiation. By leveraging\ndiscrete adjoint time integrators and advanced checkpointing strategies\ntailored for these integrators, PNODE can provide a balance between memory and\ncomputational costs, while computing the gradients consistently and accurately.\nWe provide an open-source implementation based on PyTorch and PETSc, one of the\nmost commonly used portable, scalable scientific computing libraries. We\ndemonstrate the performance through extensive numerical experiments on image\nclassification and continuous normalizing flow problems. We show that PNODE\nachieves the highest memory efficiency when compared with other\nreverse-accurate methods. On the image classification problems, PNODE is up to\ntwo times faster than the vanilla neural ODE and up to 2.3 times faster than\nthe best existing reverse-accurate method. We also show that PNODE enables the\nuse of the implicit time integration methods that are needed for stiff\ndynamical systems.",
    "descriptor": "",
    "authors": [
      "Hong Zhang",
      "Wenjun Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01298"
  },
  {
    "id": "arXiv:2206.01299",
    "title": "Fine-tuning Language Models over Slow Networks using Activation  Compression with Guarantees",
    "abstract": "Communication compression is a crucial technique for modern distributed\nlearning systems to alleviate their communication bottlenecks over slower\nnetworks. Despite recent intensive studies of gradient compression for data\nparallel-style training, compressing the activations for models trained with\npipeline parallelism is still an open problem. In this paper, we propose\nAC-SGD, a novel activation compression algorithm for communication-efficient\npipeline parallelism training over slow networks. Different from previous\nefforts in activation compression, instead of compressing activation values\ndirectly, AC-SGD compresses the changes of the activations. This allows us to\nshow, to the best of our knowledge for the first time, that one can still\nachieve $O(1/\\sqrt{T})$ convergence rate for non-convex objectives under\nactivation compression, without making assumptions on gradient unbiasedness\nthat do not hold for deep learning models with non-linear activation\nfunctions.We then show that AC-SGD can be optimized and implemented\nefficiently, without additional end-to-end runtime overhead.We evaluated AC-SGD\nto fine-tune language models with up to 1.5 billion parameters, compressing\nactivations to 2-4 bits.AC-SGD provides up to 4.3X end-to-end speed-up in\nslower networks, without sacrificing model quality. Moreover, we also show that\nAC-SGD can be combined with state-of-the-art gradient compression algorithms to\nenable \"end-to-end communication compression: All communications between\nmachines, including model gradients, forward activations, and backward\ngradients are compressed into lower precision.This provides up to 4.9X\nend-to-end speed-up, without sacrificing model quality.",
    "descriptor": "",
    "authors": [
      "Jue Wang",
      "Binhang Yuan",
      "Luka Rimanic",
      "Yongjun He",
      "Tri Dao",
      "Beidi Chen",
      "Christopher Re",
      "Ce Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.01299"
  },
  {
    "id": "arXiv:2206.01305",
    "title": "The Musical Arrow of Time -- The Role of Temporal Asymmetry in Music and  Its Organicist Implications",
    "abstract": "Adopting a performer-centric perspective, we frequently encounter two\nstatements: \"music flows\", and \"music is life-like\". This dissertation builds\non top of the two statements above, resulting in an exploration of the role of\ntemporal asymmetry in music (generalizing \"music flows\") and its relation to\nthe idea of organicism (generalizing \"music is life-like\"). We focus on two\naspects of temporal asymmetry. The first aspect concerns the vastly different\nepistemic mechanisms with which we obtain knowledge of the past and the future.\nA particular musical consequence follows: recurrence. The epistemic difference\nbetween the past and the future shapes our experience and interpretation of\nrecurring events in music. The second aspect concerns the arrow of time: the\nunambiguous ordering imposed on temporal events gives rise to the a priori\npointedness of time, rendering time asymmetrical and irreversible. A discussion\non thermodynamics informs us musically: the arrow of time effectuates itself in\nmusical forms by delaying the placement of the climax.\nOrganicism serves as a mediating topic, engaging with the concept of life as\nin organisms. On the one hand, organicism is related to temporal asymmetry in\nscience via a thermodynamical interpretation of life as entropy-reducing\nentities. On the other hand, organicism is a topic native to music via the\nuniversally acknowledged artistic idea that music should be interpreted as a\nvital force possessing volitional power. With organicism as a mediator, we\nbetter understand the role of temporal asymmetry in music. In particular, we\nview musical form as a process of expansion and elaboration analogous to\norganic growth. Finally, we present an organicist interpretation of delaying\nthe climax: viewing musical form as the result of organic growth, the arrow of\ntime translates to a preference for prepending structure over appending\nstructure.",
    "descriptor": "",
    "authors": [
      "Qi Xu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.01305"
  },
  {
    "id": "arXiv:2206.01309",
    "title": "H-EMD: A Hierarchical Earth Mover's Distance Method for Instance  Segmentation",
    "abstract": "Deep learning (DL) based semantic segmentation methods have achieved\nexcellent performance in biomedical image segmentation, producing high quality\nprobability maps to allow extraction of rich instance information to facilitate\ngood instance segmentation. While numerous efforts were put into developing new\nDL semantic segmentation models, less attention was paid to a key issue of how\nto effectively explore their probability maps to attain the best possible\ninstance segmentation. We observe that probability maps by DL semantic\nsegmentation models can be used to generate many possible instance candidates,\nand accurate instance segmentation can be achieved by selecting from them a set\nof \"optimized\" candidates as output instances. Further, the generated instance\ncandidates form a well-behaved hierarchical structure (a forest), which allows\nselecting instances in an optimized manner. Hence, we propose a novel\nframework, called hierarchical earth mover's distance (H-EMD), for instance\nsegmentation in biomedical 2D+time videos and 3D images, which judiciously\nincorporates consistent instance selection with semantic-segmentation-generated\nprobability maps. H-EMD contains two main stages. (1) Instance candidate\ngeneration: capturing instance-structured information in probability maps by\ngenerating many instance candidates in a forest structure. (2) Instance\ncandidate selection: selecting instances from the candidate set for final\ninstance segmentation. We formulate a key instance selection problem on the\ninstance candidate forest as an optimization problem based on the earth mover's\ndistance (EMD), and solve it by integer linear programming. Extensive\nexperiments on eight biomedical video or 3D datasets demonstrate that H-EMD\nconsistently boosts DL semantic segmentation models and is highly competitive\nwith state-of-the-art methods.",
    "descriptor": "\nComments: Accepted at IEEE Transactions On Medical Imaging (TMI)\n",
    "authors": [
      "Peixian Liang",
      "Yizhe Zhang",
      "Yifan Ding",
      "Jianxu Chen",
      "Chinedu S. Madukoma",
      "Tim Weninger",
      "Joshua D. Shrout",
      "Danny Z. Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01309"
  },
  {
    "id": "arXiv:2206.01310",
    "title": "Learning a Restricted Boltzmann Machine using biased Monte Carlo  sampling",
    "abstract": "Restricted Boltzmann Machines are simple and powerful generative models\ncapable of encoding any complex dataset. Despite all their advantages, in\npractice, trainings are often unstable, and it is hard to assess their quality\nbecause dynamics are hampered by extremely slow time-dependencies. This\nsituation becomes critical when dealing with low-dimensional clustered\ndatasets, where the time needed to sample ergodically the trained models\nbecomes computationally prohibitive. In this work, we show that this divergence\nof Monte Carlo mixing times is related to a phase coexistence phenomenon,\nsimilar to that encountered in Physics in the vicinity of a first order phase\ntransition. We show that sampling the equilibrium distribution via Markov Chain\nMonte Carlo can be dramatically accelerated using biased sampling techniques,\nin particular, the Tethered Monte Carlo method (TMC). This sampling technique\nsolves efficiently the problem of evaluating the quality of a given trained\nmodel and the generation of new samples in reasonable times. In addition, we\nshow that this sampling technique can be exploited to improve the computation\nof the log-likelihood gradient during the training too, which produces dramatic\nimprovements when training RBMs with artificial clustered datasets. When\ndealing with real low-dimensional datasets, this new training procedure fits\nRBM models with significantly faster relaxational dynamics than those obtained\nwith standard PCD recipes. We also show that TMC sampling can be used to\nrecover free-energy profile of the RBM, which turns out to be extremely useful\nto compute the probability distribution of a given model and to improve the\ngeneration of new decorrelated samples on slow PCD trained models.",
    "descriptor": "\nComments: 22 pages, 11 figures\n",
    "authors": [
      "Nicolas B\u00e9reux",
      "Aur\u00e9lien Decelle",
      "Cyril Furtlehner",
      "Beatriz Seoane"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.01310"
  },
  {
    "id": "arXiv:2206.01311",
    "title": "Learning Soft Constraints From Constrained Expert Demonstrations",
    "abstract": "Inverse reinforcement learning (IRL) methods assume that the expert data is\ngenerated by an agent optimizing some reward function. However, in many\nsettings, the agent may optimize a reward function subject to some constraints,\nwhere the constraints induce behaviors that may be otherwise difficult to\nexpress with just a reward function. We consider the setting where the reward\nfunction is given, and the constraints are unknown, and propose a method that\nis able to recover these constraints satisfactorily from the expert data. While\nprevious work has focused on recovering hard constraints, our method can\nrecover cumulative soft constraints that the agent satisfies on average per\nepisode. In IRL fashion, our method solves this problem by adjusting the\nconstraint function iteratively through a constrained optimization procedure,\nuntil the agent behavior matches the expert behavior. Despite the simplicity of\nthe formulation, our method is able to obtain good results. We demonstrate our\napproach on synthetic environments and real world highway driving data.",
    "descriptor": "\nComments: Supplementary material included\n",
    "authors": [
      "Ashish Gaurav",
      "Kasra Rezaee",
      "Guiliang Liu",
      "Pascal Poupart"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01311"
  },
  {
    "id": "arXiv:2206.01312",
    "title": "Optimization of Energy-Constrained IRS-NOMA Using a Complex Circle  Manifold Approach",
    "abstract": "This work investigates the performance of intelligent reflective surfaces\n(IRSs) assisted uplink non-orthogonal multiple access (NOMA) in\nenergy-constrained networks. Specifically, we formulate and solve two\noptimization problems, one for minimizing the users' sum transmit power and\nanother for maximizing the energy efficiency (EE) of the system. The two\nproblems are solved by jointly optimizing the users' transmit powers and the\npassive beamforming coefficients at the IRS reflectors subject to the users'\nindividual uplink rate constraints. A novel algorithm is developed to optimize\nthe IRS passive beamforming coefficients by optimizing the objective function\nover the \\textit{complex circle manifold} (CCM), exploiting the manifold\noptimization technique. The proposed manifold optimization-based solution is\nbench-marked against the rather \\textit{standard} semi-definite relaxation\nmethod (SDR). The results show that the manifold optimization-based algorithm\nachieves significantly better performance for both transmit power minimization\nand EE maximization problems at a computational complexity lower than the SDR\napproach. The results also reveal that IRS-NOMA is superior to the orthogonal\nmultiple access (OMA) counterpart only when the users' target achievable rate\nrequirements are relatively high.",
    "descriptor": "",
    "authors": [
      "Mahmoud AlaaEldin",
      "Emad Alsusa",
      "Karim G. Seddik",
      "Constantinos B. Papadias",
      "Mohammad Al-Jarrah"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.01312"
  },
  {
    "id": "arXiv:2206.01314",
    "title": "A New Security Boundary of Component Differentially Challenged XOR PUFs  Against Machine Learning Modeling Attacks",
    "abstract": "Physical Unclonable Functions (PUFs) are promising security primitives for\nresource-constrained network nodes. The XOR Arbiter PUF (XOR PUF or XPUF) is an\nintensively studied PUF invented to improve the security of the Arbiter PUF,\nprobably the most lightweight delay-based PUF. Recently, highly powerful\nmachine learning attack methods were discovered and were able to easily break\nlarge-sized XPUFs, which were highly secure against earlier machine learning\nattack methods. Component-differentially-challenged XPUFs (CDC-XPUFs) are XPUFs\nwith different component PUFs receiving different challenges. Studies showed\nthey were much more secure against machine learning attacks than the\nconventional XPUFs, whose component PUFs receive the same challenge. But these\nstudies were all based on earlier machine learning attack methods, and hence it\nis not clear if CDC-XPUFs can remain secure under the recently discovered\npowerful attack methods. In this paper, the two current most powerful two\nmachine learning methods for attacking XPUFs are adapted by fine-tuning the\nparameters of the two methods for CDC-XPUFs. Attack experiments using both\nsimulated PUF data and silicon data generated from PUFs implemented on\nfield-programmable gate array (FPGA) were carried out, and the experimental\nresults showed that some previously secure CDC-XPUFs of certain circuit\nparameter values are no longer secure under the adapted new attack methods,\nwhile many more CDC-XPUFs of other circuit parameter values remain secure.\nThus, our experimental attack study has re-defined the boundary between the\nsecure region and the insecure region of the PUF circuit parameter space,\nproviding PUF manufacturers and IoT security application developers with\nvaluable information in choosing PUFs with secure parameter values.",
    "descriptor": "",
    "authors": [
      "Gaoxiang Li",
      "Khalid T. Mursi",
      "Ahmad O. Aseeri",
      "Mohammed S. Alkatheiri",
      "Yu Zhuang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01314"
  },
  {
    "id": "arXiv:2206.01315",
    "title": "Sample-Efficient Reinforcement Learning of Partially Observable Markov  Games",
    "abstract": "This paper considers the challenging tasks of Multi-Agent Reinforcement\nLearning (MARL) under partial observability, where each agent only sees her own\nindividual observations and actions that reveal incomplete information about\nthe underlying state of system. This paper studies these tasks under the\ngeneral model of multiplayer general-sum Partially Observable Markov Games\n(POMGs), which is significantly larger than the standard model of Imperfect\nInformation Extensive-Form Games (IIEFGs). We identify a rich subclass of POMGs\n-- weakly revealing POMGs -- in which sample-efficient learning is tractable.\nIn the self-play setting, we prove that a simple algorithm combining optimism\nand Maximum Likelihood Estimation (MLE) is sufficient to find approximate Nash\nequilibria, correlated equilibria, as well as coarse correlated equilibria of\nweakly revealing POMGs, in a polynomial number of samples when the number of\nagents is small. In the setting of playing against adversarial opponents, we\nshow that a variant of our optimistic MLE algorithm is capable of achieving\nsublinear regret when being compared against the optimal maximin policies. To\nour best knowledge, this work provides the first line of sample-efficient\nresults for learning POMGs.",
    "descriptor": "",
    "authors": [
      "Qinghua Liu",
      "Csaba Szepesv\u00e1ri",
      "Chi Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.01315"
  },
  {
    "id": "arXiv:2206.01317",
    "title": "Realization of the inverse scattering transform method for the  Korteweg-de Vries equation",
    "abstract": "A method for practical realization of the inverse scattering transform method\nfor the Korteweg-de Vries equation is proposed. It is based on analytical\nrepresentations for Jost solutions and for integral kernels of transformation\noperators obtained recently by the authors. The representations have the form\nof functional series in which the first coefficient plays a crucial role both\nin solving the direct scattering and the inverse scattering problems. The\ndirect scattering problem reduces to computation of a number of the\ncoefficients following a simple recurrent integration procedure with a\nposterior calculation of scattering data by well known formulas. The inverse\nscattering problem reduces to a system of linear algebraic equations from which\nthe first component of the solution vector leads to the recovery of the\npotential. We prove the applicability of the finite section method to the\nsystem of linear algebraic equations and discuss numerical aspects of the\nproposed method. Numerical examples are given, which reveal the accuracy and\nspeed of the method.",
    "descriptor": "\nComments: 37 pages, 4 figures\n",
    "authors": [
      "Sergei M. Grudsky",
      "Vladislav V. Kravchenko",
      "Sergii M. Torba"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Physics (math-ph)",
      "Analysis of PDEs (math.AP)",
      "Classical Analysis and ODEs (math.CA)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/2206.01317"
  },
  {
    "id": "arXiv:2206.01319",
    "title": "Learning Unbiased Transferability for Domain Adaptation by Uncertainty  Modeling",
    "abstract": "Domain adaptation (DA) aims to transfer knowledge learned from a labeled\nsource domain to an unlabeled or a less labeled but related target domain.\nIdeally, the source and target distributions should be aligned to each other\nequally to achieve unbiased knowledge transfer. However, due to the significant\nimbalance between the amount of annotated data in the source and target\ndomains, usually only the target distribution is aligned to the source domain,\nleading to adapting unnecessary source specific knowledge to the target domain,\ni.e., biased domain adaptation. To resolve this problem, in this work, we delve\ninto the transferability estimation problem in domain adaptation and propose a\nnon-intrusive Unbiased Transferability Estimation Plug-in (UTEP) by modeling\nthe uncertainty of a discriminator in adversarial-based DA methods to optimize\nunbiased transfer. We theoretically analyze the effectiveness of the proposed\napproach to unbiased transferability learning in DA. Furthermore, to alleviate\nthe impact of imbalanced annotated data, we utilize the estimated uncertainty\nfor pseudo label selection of unlabeled samples in the target domain, which\nhelps achieve better marginal and conditional distribution alignments between\ndomains. Extensive experimental results on a high variety of DA benchmark\ndatasets show that the proposed approach can be readily incorporated into\nvarious adversarial-based DA methods, achieving state-of-the-art performance.",
    "descriptor": "\nComments: version 1\n",
    "authors": [
      "Jian Hu",
      "Haowen Zhong",
      "Junchi Yan",
      "Shaogang Gong",
      "Guile Wu",
      "Fei Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01319"
  },
  {
    "id": "arXiv:2206.01323",
    "title": "SPD domain-specific batch normalization to crack interpretable  unsupervised domain adaptation in EEG",
    "abstract": "Electroencephalography (EEG) provides access to neuronal dynamics\nnon-invasively with millisecond resolution, rendering it a viable method in\nneuroscience and healthcare. However, its utility is limited as current EEG\ntechnology does not generalize well across domains (i.e., sessions and\nsubjects) without expensive supervised re-calibration. Contemporary methods\ncast this transfer learning (TL) problem as a multi-source/-target unsupervised\ndomain adaptation (UDA) problem and address it with deep learning or shallow,\nRiemannian geometry aware alignment methods. Both directions have, so far,\nfailed to consistently close the performance gap to state-of-the-art\ndomain-specific methods based on tangent space mapping (TSM) on the symmetric\npositive definite (SPD) manifold. Here, we propose a theory-based machine\nlearning framework that enables, for the first time, learning domain-invariant\nTSM models in an end-to-end fashion. To achieve this, we propose a new building\nblock for geometric deep learning, which we denote SPD domain-specific momentum\nbatch normalization (SPDDSMBN). A SPDDSMBN layer can transform domain-specific\nSPD inputs into domain-invariant SPD outputs, and can be readily applied to\nmulti-source/-target and online UDA scenarios. In extensive experiments with 6\ndiverse EEG brain-computer interface (BCI) datasets, we obtain state-of-the-art\nperformance in inter-session and -subject TL with a simple, intrinsically\ninterpretable network architecture, which we denote TSMNet.",
    "descriptor": "\nComments: 9 pages, submitted to NeurIPS 2022\n",
    "authors": [
      "Reinmar J Kobler",
      "Jun-ichiro Hirayama",
      "Qibin Zhao",
      "Motoaki Kawanabe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.01323"
  },
  {
    "id": "arXiv:2206.01326",
    "title": "Improving Fairness in Large-Scale Object Recognition by CrowdSourced  Demographic Information",
    "abstract": "There has been increasing awareness of ethical issues in machine learning,\nand fairness has become an important research topic. Most fairness efforts in\ncomputer vision have been focused on human sensing applications and preventing\ndiscrimination by people's physical attributes such as race, skin color or age\nby increasing visual representation for particular demographic groups. We argue\nthat ML fairness efforts should extend to object recognition as well.\nBuildings, artwork, food and clothing are examples of the objects that define\nhuman culture. Representing these objects fairly in machine learning datasets\nwill lead to models that are less biased towards a particular culture and more\ninclusive of different traditions and values. There exist many research\ndatasets for object recognition, but they have not carefully considered which\nclasses should be included, or how much training data should be collected per\nclass. To address this, we propose a simple and general approach, based on\ncrowdsourcing the demographic composition of the contributors: we define fair\nrelevance scores, estimate them, and assign them to each class. We showcase its\napplication to the landmark recognition domain, presenting a detailed analysis\nand the final fairer landmark rankings. We present analysis which leads to a\nmuch fairer coverage of the world compared to existing datasets. The evaluation\ndataset was used for the 2021 Google Landmark Challenges, which was the first\nof a kind with an emphasis on fairness in generic object recognition.",
    "descriptor": "",
    "authors": [
      "Zu Kim",
      "Andr\u00e9 Araujo",
      "Bingyi Cao",
      "Cam Askew",
      "Jack Sim",
      "Mike Green",
      "N'Mah Fodiatu Yilla",
      "Tobias Weyand"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01326"
  },
  {
    "id": "arXiv:2206.01327",
    "title": "RELAY: Robotic EyeLink AnalYsis of the EyeLink 1000 using an Artificial  Eye",
    "abstract": "There is a widespread assumption that the peak velocities of visually guided\nsaccades in the dark are up to 10~\\% slower than those made in the light.\nStudies that questioned the impact of the surrounding brightness conditions,\ncome to differing conclusions, whether they have an influence or not and if so,\nin which manner. The problem is of a complex nature as the illumination\ncondition itself may not contribute to different measured peak velocities\nsolely but in combination with the estimation of the pupil size due to its\ndeformation during saccades or different gaze positions. Even the measurement\ntechnique of video-based eye tracking itself could play a significant role. To\ninvestigate this issue, we constructed a stepper motor driven artificial eye\nwith fixed pupil size to mimic human saccades with predetermined peak velocity\n\\& amplitudes under three different brightness conditions with the EyeLink\n1000, one of the most common used eye trackers. The aim was to control the\npupil and brightness. With our device, an overall good accuracy and precision\nof the EyeLink 1000 could be confirmed. Furthermore, we could find that there\nis no artifact for pupil based eye tracking in relation to changing brightness\nconditions, neither for the pupil size nor for the peak velocities. What we\nfound, was a systematic, small, yet significant change of the measured pupil\nsizes as a function of different gaze directions.",
    "descriptor": "\nComments: 12 Pages, 17 Figures, 2 Tables. Git Repository: this https URL Appendix Repository: this https URL\n",
    "authors": [
      "Anna-Maria Fel\u00dfberg",
      "Dominykas Strazdas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.01327"
  },
  {
    "id": "arXiv:2206.01328",
    "title": "Augmenting Scientific Creativity with Retrieval across Knowledge Domains",
    "abstract": "Exposure to ideas in domains outside a scientist's own may benefit her in\nreformulating existing research problems in novel ways and discovering new\napplication domains for existing solution ideas. While improved performance in\nscholarly search engines can help scientists efficiently identify relevant\nadvances in domains they may already be familiar with, it may fall short of\nhelping them explore diverse ideas \\textit{outside} such domains. In this paper\nwe explore the design of systems aimed at augmenting the end-user ability in\ncross-domain exploration with flexible query specification. To this end, we\ndevelop an exploratory search system in which end-users can select a portion of\ntext core to their interest from a paper abstract and retrieve papers that have\na high similarity to the user-selected core aspect but differ in terms of\ndomains. Furthermore, end-users can `zoom in' to specific domain clusters to\nretrieve more papers from them and understand nuanced differences within the\nclusters. Our case studies with scientists uncover opportunities and design\nimplications for systems aimed at facilitating cross-domain exploration and\ninspiration.",
    "descriptor": "\nComments: NLP+HCI Workshop at NAACL 2022\n",
    "authors": [
      "Hyeonsu B. Kang",
      "Sheshera Mysore",
      "Kevin Huang",
      "Haw-Shiuan Chang",
      "Thorben Prein",
      "Andrew McCallum",
      "Aniket Kittur",
      "Elsa Olivetti"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.01328"
  },
  {
    "id": "arXiv:2206.01330",
    "title": "Understanding the Effect of the COVID-19 Pandemic on the Usage of School  Buildings in Greece Using an IoT Data-Driven Analysis",
    "abstract": "The COVID-19 pandemic has brought profound change in the daily lives of a\nlarge part of the global population during 2020 and 2021. Such changes were\nmirrored in aspects such as changes to the overall energy consumption, or long\nperiods of sustained inactivity inside public buildings. At the same time, due\nto the large proliferation of IoT, sensors and smartphones in the past few\nyears, we are able to monitor such changes to a certain degree over time. In\nthis paper, we focus on the effect of the pandemic on school buildings and\ncertain aspects in the operation of schools. Our study is based on data from a\nnumber of school buildings equipped with an IoT infrastructure. The buildings\nwere situated in Greece, a country that faced an extended lockdown during both\n2020 and 2021. Our results show that as regards power consumption there is room\nfor energy efficiency improvements since there was significant power\nconsumption during lockdown, and that using other sensor data we can also infer\ninteresting points regarding the buildings and activity during the lockdown.",
    "descriptor": "\nComments: Preprint submitted to 2021 IEEE International Conference on Smart Internet of Things (SmartIoT 2021)\n",
    "authors": [
      "Georgios Mylonas",
      "Dimitrios Amaxilatis",
      "Ioannis Chatzigiannakis"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.01330"
  },
  {
    "id": "arXiv:2206.01331",
    "title": "Characterizing Within-Driver Variability in Driving Dynamics During  Obstacle Avoidance Maneuvers",
    "abstract": "Variability in human response creates non-trivial challenges for modeling and\ncontrol of human-automation systems. As autonomy becomes pervasive, methods\nthat can accommodate human variability will become paramount, to ensure\nefficiency, safety, and high levels of performance. We propose an easily\ncomputable modeling framework which takes advantage of a metric to assess\nvariability in individual human response in a dynamic task that subjects repeat\nover several trials. Our approach is based in a transformation of observed\ntrajectories to a reproducing kernel Hilbert space, which captures variability\nin human response as a distribution embedded within the Hilbert space. We\nevaluate the similarity across responses via the maximum mean discrepancy,\nwhich measures the distance between distributions within the Hilbert space. We\napply this metric to a difficult driving task designed to elucidate differences\nacross subjects. We conducted a pilot study with 6 subjects in an advanced\ndriving simulator, in which subjects were tasked with collision avoidance of an\nobstacle in the middle of the road, around a blind corner, in a nighttime\nscenario, while steering only with the non-dominant hand.",
    "descriptor": "\nComments: 7 pages, 2 titles due to IFAC submission requirements, 7 figures\n",
    "authors": [
      "Kendric R. Ortiz",
      "Adam J. Thorpe",
      "AnaMaria Perez",
      "Maya Luster",
      "Brandon J. Pitts",
      "Meeko Oishi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.01331"
  },
  {
    "id": "arXiv:2206.01333",
    "title": "Formal Analysis of Lending Pools in Decentralized Finance",
    "abstract": "Decentralised Finance (DeFi) applications constitute an entire financial\necosystem deployed on blockchains. Such applications are based on complex\nprotocols and incentive mechanisms whose financial safety is hard to determine.\nBesides, their adoption is rapidly growing, hence imperilling an increasingly\nhigher amount of assets. Therefore, accurate formalisation and verification of\nDeFi applications is essential to assess their safety. We present a tool for\nthe formal analysis of one of the most widespread DeFi applications: Lending\nPools (LP). This was achieved by leveraging an existing formal model for LPs,\nthe Maude verification environment and the MultiVeStA statistical analyser. The\ntool supports several analyses including reachability analysis, LTL model\nchecking and statistical model checking. We show how the tool can be used to\nstatistically analyse several parameters of LPs that are fundamental to assess\nand predict their behaviour.",
    "descriptor": "",
    "authors": [
      "Massimo Bartoletti",
      "James Chiang",
      "Tommi Junttila",
      "Alberto Lluch Lafuente",
      "Massimiliano Mirelli",
      "Andrea Vandin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.01333"
  },
  {
    "id": "arXiv:2206.01334",
    "title": "Long Scale Error Control in Low Light Image and Video Enhancement Using  Equivariance",
    "abstract": "Image frames obtained in darkness are special. Just multiplying by a constant\ndoesn't restore the image. Shot noise, quantization effects and camera\nnon-linearities mean that colors and relative light levels are estimated\npoorly. Current methods learn a mapping using real dark-bright image pairs.\nThese are very hard to capture. A recent paper has shown that simulated data\npairs produce real improvements in restoration, likely because huge volumes of\nsimulated data are easy to obtain. In this paper, we show that respecting\nequivariance -- the color of a restored pixel should be the same, however the\nimage is cropped -- produces real improvements over the state of the art for\nrestoration. We show that a scale selection mechanism can be used to improve\nreconstructions. Finally, we show that our approach produces improvements on\nvideo restoration as well. Our methods are evaluated both quantitatively and\nqualitatively.",
    "descriptor": "",
    "authors": [
      "Sara Aghajanzadeh",
      "David Forsyth"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01334"
  },
  {
    "id": "arXiv:2206.01335",
    "title": "Code Generation Tools (Almost) for Free? A Study of Few-Shot,  Pre-Trained Language Models on Code",
    "abstract": "Few-shot learning with large-scale, pre-trained language models is a powerful\nway to answer questions about code, e.g., how to complete a given code example,\nor even generate code snippets from scratch. The success of these models raises\nthe question whether they could serve as a basis for building a wide range code\ngeneration tools. Traditionally, such tools are built manually and separately\nfor each task. Instead, few-shot learning may allow to obtain different tools\nfrom a single pre-trained language model by simply providing a few examples or\na natural language description of the expected tool behavior. This paper\nstudies to what extent a state-of-the-art, pre-trained language model of code,\nCodex, may serve this purpose. We consider three code manipulation and code\ngeneration tasks targeted by a range of traditional tools: (i) code mutation;\n(ii) test oracle generation from natural language documentation; and (iii) test\ncase generation. For each task, we compare few-shot learning to a manually\nbuilt tool. Our results show that the model-based tools complement (code\nmutation), are on par (test oracle generation), or even outperform their\nrespective traditionally built tool (test case generation), while imposing far\nless effort to develop them. By comparing the effectiveness of different\nvariants of the model-based tools, we provide insights on how to design an\nappropriate input (\"prompt\") to the model and what influence the size of the\nmodel has. For example, we find that providing a small natural language\ndescription of the code generation task is an easy way to improve predictions.\nOverall, we conclude that few-shot language models are surprisingly effective,\nyet there is still more work to be done, such as exploring more diverse ways of\nprompting and tackling even more involved tasks.",
    "descriptor": "\nComments: 12 pages, 5 figures, submitted to ASE 2022\n",
    "authors": [
      "Patrick Barei\u00df",
      "Beatriz Souza",
      "Marcelo d'Amorim",
      "Michael Pradel"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01335"
  },
  {
    "id": "arXiv:2206.01339",
    "title": "A peristaltic soft, wearable robot for compression and massage therapy",
    "abstract": "Soft robotics is attractive for wearable applications that require conformal\ninteractions with the human body. Soft wearable robotic garments hold promise\nfor supplying dynamic compression or massage therapies, such as are applied for\ndisorders affecting lymphatic and blood circulation. In this paper, we present\na wearable robot capable of supplying dynamic compression and massage therapy\nvia peristaltic motion of finger-sized soft, fluidic actuators. We show that\nthis peristaltic wearable robot can supply dynamic compression pressures\nexceeding 22 kPa at frequencies of 14 Hz or more, meeting requirements for\ncompression and massage therapy. A large variety of software-programmable\ncompression wave patterns can be generated by varying frequency, amplitude,\nphase delay, and duration parameters. We first demonstrate the utility of this\nperistaltic wearable robot for compression therapy, showing fluid transport in\na laboratory model of the upper limb. We theoretically and empirically identify\ndriving regimes that optimize fluid transport. We second demonstrate the\nutility of this garment for dynamic massage therapy. These findings show the\npotential of such a wearable robot for the treatment of several health\ndisorders associated with lymphatic and blood circulation, such as lymphedema\nand blood clots.",
    "descriptor": "\nComments: 10 pages, 10 figures\n",
    "authors": [
      "Mengjia Zhu",
      "Adrian Ferstera",
      "Stejara Dinulescu",
      "Nikolas Kastor",
      "Max Linnander",
      "Elliot W. Hawkes",
      "Yon Visell"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.01339"
  },
  {
    "id": "arXiv:2206.01341",
    "title": "Equipping Black-Box Policies with Model-Based Advice for Stable  Nonlinear Control",
    "abstract": "Machine-learned black-box policies are ubiquitous for nonlinear control\nproblems. Meanwhile, crude model information is often available for these\nproblems from, e.g., linear approximations of nonlinear dynamics. We study the\nproblem of equipping a black-box control policy with model-based advice for\nnonlinear control on a single trajectory. We first show a general negative\nresult that a naive convex combination of a black-box policy and a linear\nmodel-based policy can lead to instability, even if the two policies are both\nstabilizing. We then propose an adaptive $\\lambda$-confident policy, with a\ncoefficient $\\lambda$ indicating the confidence in a black-box policy, and\nprove its stability. With bounded nonlinearity, in addition, we show that the\nadaptive $\\lambda$-confident policy achieves a bounded competitive ratio when a\nblack-box policy is near-optimal. Finally, we propose an online learning\napproach to implement the adaptive $\\lambda$-confident policy and verify its\nefficacy in case studies about the CartPole problem and a real-world electric\nvehicle (EV) charging problem with data bias due to COVID-19.",
    "descriptor": "\nComments: 33 pages, 7 figures\n",
    "authors": [
      "Tongxin Li",
      "Ruixiao Yang",
      "Guannan Qu",
      "Yiheng Lin",
      "Steven Low",
      "Adam Wierman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.01341"
  },
  {
    "id": "arXiv:2206.01342",
    "title": "Understanding the Role of Nonlinearity in Training Dynamics of  Contrastive Learning",
    "abstract": "While the empirical success of self-supervised learning (SSL) heavily relies\non the usage of deep nonlinear models, many theoretical works proposed to\nunderstand SSL still focus on linear ones. In this paper, we study the role of\nnonlinearity in the training dynamics of contrastive learning (CL) on one and\ntwo-layer nonlinear networks with homogeneous activation $h(x) = h'(x)x$. We\ntheoretically demonstrate that (1) the presence of nonlinearity leads to many\nlocal optima even in 1-layer setting, each corresponding to certain patterns\nfrom the data distribution, while with linear activation, only one major\npattern can be learned; and (2) nonlinearity leads to specialized weights into\ndiverse patterns, a behavior that linear activation is proven not capable of.\nThese findings suggest that models with lots of parameters can be regarded as a\n\\emph{brute-force} way to find these local optima induced by nonlinearity, a\npossible underlying reason why empirical observations such as the lottery\nticket hypothesis hold. In addition, for 2-layer setting, we also discover\n\\emph{global modulation}: those local patterns discriminative from the\nperspective of global-level patterns are prioritized to learn, further\ncharacterizing the learning process. Simulation verifies our theoretical\nfindings.",
    "descriptor": "",
    "authors": [
      "Yuandong Tian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.01342"
  },
  {
    "id": "arXiv:2206.01343",
    "title": "HEX: Human-in-the-loop Explainability via Deep Reinforcement Learning",
    "abstract": "The use of machine learning (ML) models in decision-making contexts,\nparticularly those used in high-stakes decision-making, are fraught with issue\nand peril since a person - not a machine - must ultimately be held accountable\nfor the consequences of the decisions made using such systems. Machine learning\nexplainability (MLX) promises to provide decision-makers with\nprediction-specific rationale, assuring them that the model-elicited\npredictions are made for the right reasons and are thus reliable. Few works\nexplicitly consider this key human-in-the-loop (HITL) component, however. In\nthis work we propose HEX, a human-in-the-loop deep reinforcement learning\napproach to MLX. HEX incorporates 0-distrust projection to synthesize decider\nspecific explanation-providing policies from any arbitrary classification\nmodel. HEX is also constructed to operate in limited or reduced training data\nscenarios, such as those employing federated learning. Our formulation\nexplicitly considers the decision boundary of the ML model in question, rather\nthan the underlying training data, which is a shortcoming of many\nmodel-agnostic MLX methods. Our proposed methods thus synthesize HITL MLX\npolicies that explicitly capture the decision boundary of the model in question\nfor use in limited data scenarios.",
    "descriptor": "",
    "authors": [
      "Michael T. Lash"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.01343"
  },
  {
    "id": "arXiv:2206.01345",
    "title": "QMLP: An Error-Tolerant Nonlinear Quantum MLP Architecture using  Parameterized Two-Qubit Gates",
    "abstract": "Despite potential quantum supremacy, state-of-the-art quantum neural networks\n(QNNs) suffer from low inference accuracy. First, the current Noisy\nIntermediate-Scale Quantum (NISQ) devices with high error rates of 0.001 to\n0.01 significantly degrade the accuracy of a QNN. Second, although recently\nproposed Re-Uploading Units (RUUs) introduce some non-linearity into the QNN\ncircuits, the theory behind it is not fully understood. Furthermore, previous\nRUUs that repeatedly upload original data can only provide marginal accuracy\nimprovements. Third, current QNN circuit ansatz uses fixed two-qubit gates to\nenforce maximum entanglement capability, making task-specific entanglement\ntuning impossible, resulting in poor overall performance. In this paper, we\npropose a Quantum Multilayer Perceptron (QMLP) architecture featured by\nerror-tolerant input embedding, rich nonlinearity, and enhanced variational\ncircuit ansatz with parameterized two-qubit entangling gates. Compared to prior\narts, QMLP increases the inference accuracy on the 10-class MNIST dataset by\n10% with 2 times fewer quantum gates and 3 times reduced parameters. Our source\ncode is available and can be found in [1]",
    "descriptor": "",
    "authors": [
      "Cheng Chu",
      "Nai-Hui Chia",
      "Lei Jiang",
      "Fan Chen"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.01345"
  },
  {
    "id": "arXiv:2206.01347",
    "title": "MultiHiertt: Numerical Reasoning over Multi Hierarchical Tabular and  Textual Data",
    "abstract": "Numerical reasoning over hybrid data containing both textual and tabular\ncontent (e.g., financial reports) has recently attracted much attention in the\nNLP community. However, existing question answering (QA) benchmarks over hybrid\ndata only include a single flat table in each document and thus lack examples\nof multi-step numerical reasoning across multiple hierarchical tables. To\nfacilitate data analytical progress, we construct a new large-scale benchmark,\nMultiHiertt, with QA pairs over Multi Hierarchical Tabular and Textual data.\nMultiHiertt is built from a wealth of financial reports and has the following\nunique characteristics: 1) each document contain multiple tables and longer\nunstructured texts; 2) most of tables contained are hierarchical; 3) the\nreasoning process required for each question is more complex and challenging\nthan existing benchmarks; and 4) fine-grained annotations of reasoning\nprocesses and supporting facts are provided to reveal complex numerical\nreasoning. We further introduce a novel QA model termed MT2Net, which first\napplies facts retrieving to extract relevant supporting facts from both tables\nand text and then uses a reasoning module to perform symbolic reasoning over\nretrieved facts. We conduct comprehensive experiments on various baselines. The\nexperimental results show that MultiHiertt presents a strong challenge for\nexisting baselines whose results lag far behind the performance of human\nexperts. The dataset and code are publicly available at\nhttps://github.com/psunlpgroup/MultiHiertt.",
    "descriptor": "",
    "authors": [
      "Yilun Zhao",
      "Yunxiang Li",
      "Chenying Li",
      "Rui Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01347"
  },
  {
    "id": "arXiv:2206.01349",
    "title": "On the Privacy Properties of GAN-generated Samples",
    "abstract": "The privacy implications of generative adversarial networks (GANs) are a\ntopic of great interest, leading to several recent algorithms for training GANs\nwith privacy guarantees. By drawing connections to the generalization\nproperties of GANs, we prove that under some assumptions, GAN-generated samples\ninherently satisfy some (weak) privacy guarantees. First, we show that if a GAN\nis trained on m samples and used to generate n samples, the generated samples\nare (epsilon, delta)-differentially-private for (epsilon, delta) pairs where\ndelta scales as O(n/m). We show that under some special conditions, this upper\nbound is tight. Next, we study the robustness of GAN-generated samples to\nmembership inference attacks. We model membership inference as a hypothesis\ntest in which the adversary must determine whether a given sample was drawn\nfrom the training dataset or from the underlying data distribution. We show\nthat this adversary can achieve an area under the ROC curve that scales no\nbetter than O(m^{-1/4}).",
    "descriptor": "\nComments: AISTATS 2021\n",
    "authors": [
      "Zinan Lin",
      "Vyas Sekar",
      "Giulia Fanti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.01349"
  },
  {
    "id": "arXiv:2206.01359",
    "title": "Thread and Data Mapping in Software Transactional Memory: An Overview",
    "abstract": "In current microarchitectures, due to the complex memory hierarchies and\ndifferent latencies on memory accesses, thread and data mapping are important\nissues to improve application performance. Software transactional memory (STM)\nis an abstraction used for thread synchronization, replacing the use of locks\nin parallel programming. Regarding thread and data mapping, STM presents new\nchallenges and mapping opportunities, since (1) STM can use different conflict\ndetection and resolution strategies, making the behavior of the application\nless predictable and; (2) the STM runtime has precise information about shared\ndata and the intensity with each thread accesses them. These unique\ncharacteristics provide many opportunities for low-overhead, but precise\nstatistics to guide mapping strategies for STM applications. The main objective\nof this paper is to survey the existing work about thread and data mapping that\nuses solely information gathered from the STM runtime to guide thread and data\nmapping decisions. We also discuss future research directions within this\nresearch area.",
    "descriptor": "\nComments: 14 pages, 2 figures, 1 table, 52 references\n",
    "authors": [
      "Douglas Pereira Pasqualin",
      "Matthias Diener",
      "Andr\u00e9 Rauber Du Bois",
      "Maur\u00edcio Lima Pilla"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.01359"
  },
  {
    "id": "arXiv:2206.01360",
    "title": "Balancing Flow Time and Energy Consumption",
    "abstract": "In this paper, we study the following batch scheduling model: find a schedule\nthat minimizes total flow time for $n$ uniform length jobs, with release times\nand deadlines, where the machine is only actively processing jobs in at most\n$k$ synchronized batches of size at most $B$. Prior work on such batch\nscheduling models has considered only feasibility with no regard to the flow\ntime of the schedule. However, algorithms that minimize the cost from the\nscheduler's perspective -- such as ones that minimize the active time of the\nprocessor -- can result in schedules where the total flow time is arbitrarily\nhigh \\cite{ChangGabowKhuller}. Such schedules are not valuable from the\nperspective of the client. In response, our work provides dynamic programs\nwhich minimize flow time subject to active time constraints. Our main\ncontribution focuses on jobs with agreeable deadlines; for such job instances,\nwe introduce dynamic programs that achieve runtimes of O$(B \\cdot k \\cdot n)$\nfor unit jobs and O$(B \\cdot k \\cdot n^5)$ for uniform length jobs. These\nresults improve upon our modification of a different, classical dynamic\nprogramming approach by Baptiste. While the modified DP works when deadlines\nare non-agreeable, this solution is more expensive, with runtime $O(B \\cdot k^2\n\\cdot n^7)$ \\cite{Baptiste00}.",
    "descriptor": "",
    "authors": [
      "Sami Davies",
      "Samir Khuller",
      "Shirley Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.01360"
  },
  {
    "id": "arXiv:2206.01364",
    "title": "Robotic Planning under Uncertainty in Spatiotemporal Environments in  Expeditionary Science",
    "abstract": "In the expeditionary sciences, spatiotemporally varying environments --\nhydrothermal plumes, algal blooms, lava flows, or animal migrations -- are\nubiquitous. Mobile robots are uniquely well-suited to study these dynamic,\nmesoscale natural environments. We formalize expeditionary science as a\nsequential decision-making problem, modeled using the language of\npartially-observable Markov decision processes (POMDPs). Solving the\nexpeditionary science POMDP under real-world constraints requires efficient\nprobabilistic modeling and decision-making in problems with complex dynamics\nand observational models. Previous work in informative path planning, adaptive\nsampling, and experimental design have shown compelling results, largely in\nstatic environments, using data-driven models and information-based rewards.\nHowever, these methodologies do not trivially extend to expeditionary science\nin spatiotemporal environments: they generally do not make use of scientific\nknowledge such as equations of state dynamics, they focus on information\ngathering as opposed to scientific task execution, and they make use of\ndecision-making approaches that scale poorly to large, continuous problems with\nlong planning horizons and real-time operational constraints. In this work, we\ndiscuss these and other challenges related to probabilistic modeling and\ndecision-making in expeditionary science, and present some of our preliminary\nwork that addresses these gaps. We ground our results in a real expeditionary\nscience deployment of an autonomous underwater vehicle (AUV) in the deep ocean\nfor hydrothermal vent discovery and characterization. Our concluding thoughts\nhighlight remaining work to be done, and the challenges that merit\nconsideration by the reinforcement learning and decision-making community.",
    "descriptor": "\nComments: 5 pages, 1 figure, as submitted to The Multi-disciplinary Conference on Reinforcement Learning and Decision Making\n",
    "authors": [
      "Victoria Preston",
      "Genevieve Flaspohler",
      "Anna P. M. Michel",
      "John W. Fisher III",
      "Nicholas Roy"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.01364"
  },
  {
    "id": "arXiv:2206.01365",
    "title": "Adversarial Attacks on Human Vision",
    "abstract": "This article presents an introduction to visual attention retargeting, its\nconnection to visual saliency, the challenges associated with it, and ideas for\nhow it can be approached. The difficulty of attention retargeting as a saliency\ninversion problem lies in the lack of one-to-one mapping between saliency and\nthe image domain, in addition to the possible negative impact of saliency\nalterations on image aesthetics. A few approaches from recent literature to\nsolve this challenging problem are reviewed, and several suggestions for future\ndevelopment are presented.",
    "descriptor": "\nComments: 21 pages, 8 figures, 1 table\n",
    "authors": [
      "Victor A. Mateescu",
      "Ivan V. Baji\u0107"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.01365"
  },
  {
    "id": "arXiv:2206.01366",
    "title": "Supernet Training for Federated Image Classification under System  Heterogeneity",
    "abstract": "Efficient deployment of deep neural networks across many devices and resource\nconstraints, especially on edge devices, is one of the most challenging\nproblems in the presence of data-privacy preservation issues. Conventional\napproaches have evolved to either improve a single global model while keeping\neach local training data decentralized (i.e., data-heterogeneity) or to train a\nonce-for-all network that supports diverse architectural settings to address\nheterogeneous systems equipped with different computational capabilities (i.e.,\nmodel-heterogeneity). However, little research has considered both directions\nsimultaneously. In this work, we propose a novel framework to consider both\nscenarios, namely Federation of Supernet Training (FedSup), where clients send\nand receive a supernet whereby it contains all possible architectures sampled\nfrom itself. It is inspired by how averaging parameters in the model\naggregation stage of Federated Learning (FL) is similar to weight-sharing in\nsupernet training. Specifically, in the FedSup framework, a weight-sharing\napproach widely used in the training single shot model is combined with the\naveraging of Federated Learning (FedAvg). Under our framework, we present an\nefficient algorithm (E-FedSup) by sending the sub-model to clients in the\nbroadcast stage for reducing communication costs and training overhead. We\ndemonstrate several strategies to enhance supernet training in the FL\nenvironment and conduct extensive empirical evaluations. The resulting\nframework is shown to pave the way for the robustness of both data- and\nmodel-heterogeneity on several standard benchmarks.",
    "descriptor": "\nComments: Under review for NeurIPS 22 Proceedings\n",
    "authors": [
      "Taehyeon Kim",
      "Se-Young Yun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01366"
  },
  {
    "id": "arXiv:2206.01367",
    "title": "Adversarial Unlearning: Reducing Confidence Along Adversarial Directions",
    "abstract": "Supervised learning methods trained with maximum likelihood objectives often\noverfit on training data. Most regularizers that prevent overfitting look to\nincrease confidence on additional examples (e.g., data augmentation,\nadversarial training), or reduce it on training data (e.g., label smoothing).\nIn this work we propose a complementary regularization strategy that reduces\nconfidence on self-generated examples. The method, which we call RCAD (Reducing\nConfidence along Adversarial Directions), aims to reduce confidence on\nout-of-distribution examples lying along directions adversarially chosen to\nincrease training loss. In contrast to adversarial training, RCAD does not try\nto robustify the model to output the original label, but rather regularizes it\nto have reduced confidence on points generated using much larger perturbations\nthan in conventional adversarial training. RCAD can be easily integrated into\ntraining pipelines with a few lines of code. Despite its simplicity, we find on\nmany classification benchmarks that RCAD can be added to existing techniques\n(e.g., label smoothing, MixUp training) to increase test accuracy by 1-3% in\nabsolute value, with more significant gains in the low data regime. We also\nprovide a theoretical analysis that helps to explain these benefits in\nsimplified settings, showing that RCAD can provably help the model unlearn\nspurious features in the training data.",
    "descriptor": "",
    "authors": [
      "Amrith Setlur",
      "Benjamin Eysenbach",
      "Virginia Smith",
      "Sergey Levine"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.01367"
  },
  {
    "id": "arXiv:2206.01368",
    "title": "Density-Based Pruning of Drone Swarm Services",
    "abstract": "We propose a novel framework for the recommendation of swarm-based drone\ndelivery services based on the consumers preferences. We propose a\ndensity-based pruning approach that uses the concept of partnerships with\ncharging station providers to reduce the search space of swarm-based drone\nservice delivery providers. A weighted service composition algorithm is\nproposed that considers the providers capabilities and consumers' preferences\nin selecting the best next service. We propose a voting-based recommendation\nalgorithm to select the best providers. We conduct a set of experiments to\nevaluate the efficiency of the framework in terms of consumer satisfaction,\nrun-time, and search space reduction cost.",
    "descriptor": "\nComments: 10 pages, 9 figures. This is an accepted paper and it is going to appear in the Proceedings of the 2022 IEEE International Conference on Web Services (ICWS 2022)\n",
    "authors": [
      "Balsam Alkouz",
      "Athman Bouguettaya",
      "Abdallah Lakhdari"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.01368"
  },
  {
    "id": "arXiv:2206.01369",
    "title": "Incremental Learning Meets Transfer Learning: Application to Multi-site  Prostate MRI Segmentation",
    "abstract": "Many medical datasets have recently been created for medical image\nsegmentation tasks, and it is natural to question whether we can use them to\nsequentially train a single model that (1) performs better on all these\ndatasets, and (2) generalizes well and transfers better to the unknown target\nsite domain. Prior works have achieved this goal by jointly training one model\non multi-site datasets, which achieve competitive performance on average but\nsuch methods rely on the assumption about the availability of all training\ndata, thus limiting its effectiveness in practical deployment. In this paper,\nwe propose a novel multi-site segmentation framework called\nincremental-transfer learning (ITL), which learns a model from multi-site\ndatasets in an end-to-end sequential fashion. Specifically, \"incremental\"\nrefers to training sequentially constructed datasets, and \"transfer\" is\nachieved by leveraging useful information from the linear combination of\nembedding features on each dataset. In addition, we introduce our ITL\nframework, where we train the network including a site-agnostic encoder with\npre-trained weights and at most two segmentation decoder heads. We also design\na novel site-level incremental loss in order to generalize well on the target\ndomain. Second, we show for the first time that leveraging our ITL training\nscheme is able to alleviate challenging catastrophic forgetting problems in\nincremental learning. We conduct experiments using five challenging benchmark\ndatasets to validate the effectiveness of our incremental-transfer learning\napproach. Our approach makes minimal assumptions on computation resources and\ndomain-specific expertise, and hence constitutes a strong starting point in\nmulti-site medical image segmentation.",
    "descriptor": "",
    "authors": [
      "Chenyu You",
      "Jinlin Xiang",
      "Kun Su",
      "Xiaoran Zhang",
      "Siyuan Dong",
      "John Onofrey",
      "Lawrence Staib",
      "James S. Duncan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.01369"
  },
  {
    "id": "arXiv:2206.01370",
    "title": "Slot Order Matters for Compositional Scene Understanding",
    "abstract": "Empowering agents with a compositional understanding of their environment is\na promising next step toward solving long-horizon planning problems. On the one\nhand, we have seen encouraging progress on variational inference algorithms for\nobtaining sets of object-centric latent representations (\"slots\") from\nunstructured scene observations. On the other hand, generating scenes from\nslots has received less attention, in part because it is complicated by the\nlack of a canonical object order. A canonical object order is useful for\nlearning the object correlations necessary to generate physically plausible\nscenes similar to how raster scan order facilitates learning pixel correlations\nfor pixel-level autoregressive image generation. In this work, we address this\nlack by learning a fixed object order for a hierarchical variational\nautoencoder with a single level of autoregressive slots and a global scene\nprior. We cast autoregressive slot inference as a set-to-sequence modeling\nproblem. We introduce an auxiliary loss to train the slot prior to generate\nobjects in a fixed order. During inference, we align a set of inferred slots to\nthe object order obtained from a slot prior rollout. To ensure the rolled out\nobjects are meaningful for the given scene, we condition the prior on an\ninferred global summary of the input. Experiments on compositional environments\nand ablations demonstrate that our model with global prior, inference with\naligned slot order, and auxiliary loss achieves state-of-the-art sample\nquality.",
    "descriptor": "\nComments: 30 pages, 17 figures. Code and videos available at this https URL\n",
    "authors": [
      "Patrick Emami",
      "Pan He",
      "Sanjay Ranka",
      "Anand Rangarajan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01370"
  },
  {
    "id": "arXiv:2206.01378",
    "title": "Regularization-wise double descent: Why it occurs and how to eliminate  it",
    "abstract": "The risk of overparameterized models, in particular deep neural networks, is\noften double-descent shaped as a function of the model size. Recently, it was\nshown that the risk as a function of the early-stopping time can also be\ndouble-descent shaped, and this behavior can be explained as a super-position\nof bias-variance tradeoffs. In this paper, we show that the risk of explicit\nL2-regularized models can exhibit double descent behavior as a function of the\nregularization strength, both in theory and practice. We find that for linear\nregression, a double descent shaped risk is caused by a superposition of\nbias-variance tradeoffs corresponding to different parts of the model and can\nbe mitigated by scaling the regularization strength of each part appropriately.\nMotivated by this result, we study a two-layer neural network and show that\ndouble descent can be eliminated by adjusting the regularization strengths for\nthe first and second layer. Lastly, we study a 5-layer CNN and ResNet-18\ntrained on CIFAR-10 with label noise, and CIFAR-100 without label noise, and\ndemonstrate that all exhibit double descent behavior as a function of the\nregularization strength.",
    "descriptor": "\nComments: To be published in the 2022 IEEE International Symposium on Information Theory (ISIT) Proceedings\n",
    "authors": [
      "Fatih Furkan Yilmaz",
      "Reinhard Heckel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.01378"
  },
  {
    "id": "arXiv:2206.01379",
    "title": "Instant Graph Neural Networks for Dynamic Graphs",
    "abstract": "Graph Neural Networks (GNNs) have been widely used for modeling\ngraph-structured data. With the development of numerous GNN variants, recent\nyears have witnessed groundbreaking results in improving the scalability of\nGNNs to work on static graphs with millions of nodes. However, how to instantly\nrepresent continuous changes of large-scale dynamic graphs with GNNs is still\nan open problem. Existing dynamic GNNs focus on modeling the periodic evolution\nof graphs, often on a snapshot basis. Such methods suffer from two drawbacks:\nfirst, there is a substantial delay for the changes in the graph to be\nreflected in the graph representations, resulting in losses on the model's\naccuracy; second, repeatedly calculating the representation matrix on the\nentire graph in each snapshot is predominantly time-consuming and severely\nlimits the scalability. In this paper, we propose Instant Graph Neural Network\n(InstantGNN), an incremental computation approach for the graph representation\nmatrix of dynamic graphs. Set to work with dynamic graphs with the edge-arrival\nmodel, our method avoids time-consuming, repetitive computations and allows\ninstant updates on the representation and instant predictions. Graphs with\ndynamic structures and dynamic attributes are both supported. The upper bounds\nof time complexity of those updates are also provided. Furthermore, our method\nprovides an adaptive training strategy, which guides the model to retrain at\nmoments when it can make the greatest performance gains. We conduct extensive\nexperiments on several real-world and synthetic datasets. Empirical results\ndemonstrate that our model achieves state-of-the-art accuracy while having\norders-of-magnitude higher efficiency than existing methods.",
    "descriptor": "",
    "authors": [
      "Yanping Zheng",
      "Hanzhi Wang",
      "Zhewei Wei",
      "Jiajun Liu",
      "Sibo Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01379"
  },
  {
    "id": "arXiv:2206.01381",
    "title": "CF-YOLO: Cross Fusion YOLO for Object Detection in Adverse Weather with  a High-quality Real Snow Dataset",
    "abstract": "Snow is one of the toughest adverse weather conditions for object detection\n(OD). Currently, not only there is a lack of snowy OD datasets to train\ncutting-edge detectors, but also these detectors have difficulties learning\nlatent information beneficial for detection in snow. To alleviate the two above\nproblems, we first establish a real-world snowy OD dataset, named RSOD.\nBesides, we develop an unsupervised training strategy with a distinctive\nactivation function, called $Peak \\ Act$, to quantitatively evaluate the effect\nof snow on each object. Peak Act helps grading the images in RSOD into\nfour-difficulty levels. To our knowledge, RSOD is the first quantitatively\nevaluated and graded snowy OD dataset. Then, we propose a novel Cross Fusion\n(CF) block to construct a lightweight OD network based on YOLOv5s (call\nCF-YOLO). CF is a plug-and-play feature aggregation module, which integrates\nthe advantages of Feature Pyramid Network and Path Aggregation Network in a\nsimpler yet more flexible form. Both RSOD and CF lead our CF-YOLO to possess an\noptimization ability for OD in real-world snow. That is, CF-YOLO can handle\nunfavorable detection problems of vagueness, distortion and covering of snow.\nExperiments show that our CF-YOLO achieves better detection results on RSOD,\ncompared to SOTAs. The code and dataset are available at\nhttps://github.com/qqding77/CF-YOLO-and-RSOD.",
    "descriptor": "\nComments: 10pages\n",
    "authors": [
      "Qiqi Ding",
      "Peng Li",
      "Xuefeng Yan",
      "Ding Shi",
      "Luming Liang",
      "Weiming Wang",
      "Haoran Xie",
      "Jonathan Li",
      "Mingqiang Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01381"
  },
  {
    "id": "arXiv:2206.01382",
    "title": "Falconn++: A Locality-sensitive Filtering Approach for Approximate  Nearest Neighbor Search",
    "abstract": "We present Falconn++, a novel locality-sensitive filtering (LSF) approach for\napproximate nearest neighbor search on angular distance. Falconn++ can filter\nout potential far away points in any hash bucket before querying, which results\nin higher quality candidates compared to other hashing-based solutions.\nTheoretically, Falconn++ asymptotically achieves lower query time complexity\nthan Falconn, an optimal locality-sensitive hashing scheme on angular distance.\nEmpirically, Falconn++ achieves a higher recall-speed tradeoff than Falconn on\nmany real-world data sets. Falconn++ is also competitive against HNSW, an\nefficient representative of graph-based solutions on high search recall\nregimes.",
    "descriptor": "",
    "authors": [
      "Ninh Pham",
      "Tao Liu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01382"
  },
  {
    "id": "arXiv:2206.01384",
    "title": "End-to-End 3D Hand Pose Estimation from Stereo Cameras",
    "abstract": "This work proposes an end-to-end approach to estimate full 3D hand pose from\nstereo cameras. Most existing methods of estimating hand pose from stereo\ncameras apply stereo matching to obtain depth map and use depth-based solution\nto estimate hand pose. In contrast, we propose to bypass the stereo matching\nand directly estimate the 3D hand pose from the stereo image pairs. The\nproposed neural network architecture extends from any keypoint predictor to\nestimate the sparse disparity of the hand joints. In order to effectively train\nthe model, we propose a large scale synthetic dataset that is composed of\nstereo image pairs and ground truth 3D hand pose annotations. Experiments show\nthat the proposed approach outperforms the existing methods based on the stereo\ndepth.",
    "descriptor": "",
    "authors": [
      "Yuncheng Li",
      "Zehao Xue",
      "Yingying Wang",
      "Liuhao Ge",
      "Zhou Ren",
      "Jonathan Rodriguez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01384"
  },
  {
    "id": "arXiv:2206.01386",
    "title": "Eilmer: an Open-Source Multi-Physics Hypersonic Flow Solver",
    "abstract": "This paper introduces Eilmer, a general-purpose open-source compressible flow\nsolver developed at the University of Queensland, designed to support research\ncalculations in hypersonics and high-speed aerothermodynamics. Eilmer has a\nbroad userbase in several university research groups and a wide range of\ncapabilities, which are documented on the project's website, in the\naccompanying reference manuals, and in an extensive catalogue of example\nsimulations. The first part of this paper describes the formulation of the\ncode: the equations, physical models, and numerical methods that are used in a\nbasic fluid dynamics simulation, as well as a handful of optional multi-physics\nmodels that are commonly added on to do calculations of hypersonic flow. The\nsecond section describes the processes used to develop and maintain the code,\ndocumenting our adherence to good programming practice and endorsing certain\ntechniques that seem to be particularly helpful for scientific codes. The final\nsection describes a half-dozen example simulations that span the range of\nEilmer's capabilities, each consisting of some sample results and a short\nexplanation of the problem being solved, which together will hopefully assist\nnew users in beginning to use Eilmer in their own research projects.",
    "descriptor": "",
    "authors": [
      "Nicholas N. Gibbons",
      "Kyle A. Damm",
      "Peter A. Jacobs",
      "Rowan J. Gollan"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2206.01386"
  },
  {
    "id": "arXiv:2206.01394",
    "title": "Influence Maximization in Hypergraphs",
    "abstract": "Influence maximization in complex networks, i.e., maximizing the size of\ninfluenced nodes via selecting K seed nodes for a given spreading process, has\nattracted great attention in recent years. However, the influence maximization\nproblem in hypergraphs, in which the hyperedges are leveraged to represent the\ninteractions among more than two nodes, is still an open question. In this\npaper, we propose an adaptive degree-based heuristic algorithm, i.e., Heuristic\nDegree Discount (HDD), which iteratively selects nodes with low influence\noverlap as seeds, to solve the influence maximization problem in hypergraphs.\nWe further extend algorithms from ordinary networks as baselines and compare\nthe performance of the proposed algorithm and baselines on both real data and\nsynthetic hypergraphs. Results show that HDD outperforms the baselines in terms\nof both effectiveness and efficiency. Moreover, the experiments on synthetic\nhypergraphs indicate that HDD shows high performance, especially in hypergraphs\nwith heterogeneous degree distribution.",
    "descriptor": "",
    "authors": [
      "Ming Xie",
      "Xiu-Xiu Zhan",
      "Chuang Liu",
      "Zi-Ke Zhang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.01394"
  },
  {
    "id": "arXiv:2206.01398",
    "title": "A closer look at TDFA",
    "abstract": "We present an algorithm for regular expression parsing and submatch\nextraction based on tagged deterministic finite automata. The algorithm works\nwith different disambiguation policies. We give detailed pseudocode for the\nalgorithm, covering important practical optimizations. All transformations from\na regular expression to an optimized automaton are explained on a step-by-step\nexample. We consider both ahead-of-time and just-in-time determinization and\ndescribe variants of the algorithm suited to each setting. We provide\nbenchmarks showing that the algorithm is very fast in practice. Our research is\nbased on two independent implementations: an open-source lexer generator RE2C\nand an experimental Java library.",
    "descriptor": "\nComments: 26 pages, 11 figures\n",
    "authors": [
      "Angelo Borsotti",
      "Ulya Trafimovich"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.01398"
  },
  {
    "id": "arXiv:2206.01399",
    "title": "Generalization for multiclass classification with overparameterized  linear models",
    "abstract": "Via an overparameterized linear model with Gaussian features, we provide\nconditions for good generalization for multiclass classification of\nminimum-norm interpolating solutions in an asymptotic setting where both the\nnumber of underlying features and the number of classes scale with the number\nof training points. The survival/contamination analysis framework for\nunderstanding the behavior of overparameterized learning problems is adapted to\nthis setting, revealing that multiclass classification qualitatively behaves\nlike binary classification in that, as long as there are not too many classes\n(made precise in the paper), it is possible to generalize well even in some\nsettings where the corresponding regression tasks would not generalize. Besides\nvarious technical challenges, it turns out that the key difference from the\nbinary classification setting is that there are relatively fewer positive\ntraining examples of each class in the multiclass setting as the number of\nclasses increases, making the multiclass problem \"harder\" than the binary one.",
    "descriptor": "\nComments: 44 pages, 4 figures\n",
    "authors": [
      "Vignesh Subramanian",
      "Rahul Arya",
      "Anant Sahai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.01399"
  },
  {
    "id": "arXiv:2206.01402",
    "title": "Data Encryption based on 9D Complex Chaotic System with Quaternion for  Smart Grid",
    "abstract": "With the development of smart grid, the operation and control of power system\nis realized through power communication network, especially the power\nproduction and enterprise management business involve a large amount of\nsensitive information, and the requirements for data security and real-time\ntransmission are gradually improved. In this paper, a new 9D complex chaotic\nsystem with quaternion is proposed for the encryption of smart grid data.\nFirstly, a new 9D complex chaotic system with quaternion is proposed, and its\nattractors, bifurcation diagram, complexity, and 0-1 test are analyzed.\nSecondly, the pseudo-random sequences are generated by the new chaotic system\nto encrypt power data. Finally, the proposed encryption algorithm is verifed\nwith power data and images in the smart grid, which can ensure the encryption\nsecurity and real-time. The verifcation results show that the proposed\nencryption scheme is technically feasible and available for power data and\nimage encryption in smart grid.",
    "descriptor": "\nComments: Accepted by Chinese Physics B\n",
    "authors": [
      "Fangfang Zhang",
      "Zhe Huang",
      "Lei Kou",
      "Yang Li",
      "Maoyong Cao",
      "Fengying Ma"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.01402"
  },
  {
    "id": "arXiv:2206.01408",
    "title": "MetaLR: Layer-wise Learning Rate based on Meta-Learning for Adaptively  Fine-tuning Medical Pre-trained Models",
    "abstract": "When applying transfer learning for medical image analysis, downstream tasks\noften have significant gaps with the pre-training tasks. Previous methods\nmainly focus on improving the transferabilities of the pre-trained models to\nbridge the gaps. In fact, model fine-tuning can also play a very important role\nin tackling this problem. A conventional fine-tuning method is updating all\ndeep neural networks (DNNs) layers by a single learning rate (LR), which\nignores the unique transferabilities of different layers. In this work, we\nexplore the behaviors of different layers in the fine-tuning stage. More\nprecisely, we first hypothesize that lower-level layers are more\ndomain-specific while higher-level layers are more task-specific, which is\nverified by a simple bi-directional fine-tuning scheme. It is harder for the\npre-trained specific layers to transfer to new tasks than general layers. On\nthis basis, to make different layers better co-adapt to the downstream tasks\naccording to their transferabilities, a meta-learning-based LR learner, namely\nMetaLR, is proposed to assign LRs for each layer automatically. Extensive\nexperiments on various medical applications (i.e., POCUS, BUSI, Chest X-ray,\nand LiTS) well confirm our hypothesis and show the superior performance of the\nproposed methods to previous state-of-the-art fine-tuning methods.",
    "descriptor": "",
    "authors": [
      "Yixiong Chen",
      "Jingxian Li",
      "Hua Jiang",
      "Li Liu",
      "Chris Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.01408"
  },
  {
    "id": "arXiv:2206.01409",
    "title": "Hybrid Models for Mixed Variables in Bayesian Optimization",
    "abstract": "We systematically describe the problem of simultaneous surrogate modeling of\nmixed variables (i.e., continuous, integer and categorical variables) in the\nBayesian optimization (BO) context. We provide a unified hybrid model using\nboth Monte-Carlo tree search (MCTS) and Gaussian processes (GP) that\nencompasses and generalizes multiple state-of-the-art mixed BO surrogates.\nBased on the architecture, we propose applying a new dynamic model selection\ncriterion among novel candidate families of covariance kernels, including\nnon-stationary kernels and associated families. Different benchmark problems\nare studied and presented to support the superiority of our model, along with\nresults highlighting the effectiveness of our method compared to most\nstate-of-the-art mixed-variable methods in BO.",
    "descriptor": "\nComments: 56 pages, 22 Figures\n",
    "authors": [
      "Hengrui Luo",
      "Younghyun Cho",
      "James W. Demmel",
      "Xiaoye S. Li",
      "Yang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.01409"
  },
  {
    "id": "arXiv:2206.01410",
    "title": "Fair Classification via Transformer Neural Networks: Case Study of an  Educational Domain",
    "abstract": "Educational technologies nowadays increasingly use data and Machine Learning\n(ML) models. This gives the students, instructors, and administrators support\nand insights for the optimum policy. However, it is well acknowledged that ML\nmodels are subject to bias, which raises concern about the fairness, bias, and\ndiscrimination of using these automated ML algorithms in education and its\nunintended and unforeseen negative consequences. The contribution of bias\nduring the decision-making comes from datasets used for training ML models and\nthe model architecture. This paper presents a preliminary investigation of\nfairness constraint in transformer neural networks on Law School and\nStudent-Mathematics datasets. The used transformer models transform these raw\ndatasets into a richer representation space of natural language processing\n(NLP) while solving fairness classification. We have employed fairness metrics\nfor evaluation and check the trade-off between fairness and accuracy. We have\nreported the various metrics of F1, SPD, EOD, and accuracy for different\narchitectures from the transformer model class.",
    "descriptor": "",
    "authors": [
      "Modar Sulaiman",
      "Kallol Roy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.01410"
  },
  {
    "id": "arXiv:2206.01411",
    "title": "One-shot Learning for Autonomous Aerial Manipulation",
    "abstract": "This paper is concerned with learning transferable contact models for aerial\nmanipulation tasks. We investigate a contact-based approach for enabling\nunmanned aerial vehicles with cable-suspended passive grippers to compute the\nattach points on novel payloads for aerial transportation. This is the first\ntime that the problem of autonomously generating contact points for such tasks\nhas been investigated. Our approach builds on the underpinning idea that we can\nlearn a probability density of contacts over objects' surfaces from a single\ndemonstration. We enhance this formulation for encoding aerial transportation\ntasks while maintaining the one-shot learning paradigm without handcrafting\ntask-dependent features or employing ad-hoc heuristics; the only prior is\nextrapolated directly from a single demonstration. Our models only rely on the\ngeometrical properties of the payloads computed from a point cloud, and they\nare robust to partial views. The effectiveness of our approach is evaluated in\nsimulation, in which one or three quadropters are requested to transport\npreviously unseen payloads along a desired trajectory. The contact points and\nthe quadroptors configurations are computed on-the-fly for each test by our\napporach and compared with a baseline method, a modified grasp learning\nalgorithm from the literature. Empirical experiments show that the contacts\ngenerated by our approach yield a better controllability of the payload for a\ntransportation task. We conclude this paper with a discussion on the strengths\nand limitations of the presented idea, and our suggested future research\ndirections.",
    "descriptor": "\nComments: aerial manipulation, aerial grasping, one-shot learning, collaborative transportation\n",
    "authors": [
      "Claudio Zito",
      "Eliseo Ferrante"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.01411"
  },
  {
    "id": "arXiv:2206.01413",
    "title": "Impact of the composition of feature extraction and class sampling in  medicare fraud detection",
    "abstract": "With healthcare being critical aspect, health insurance has become an\nimportant scheme in minimizing medical expenses. Following this, the healthcare\nindustry has seen a significant increase in fraudulent activities owing to\nincreased insurance, and fraud has become a significant contributor to rising\nmedical care expenses, although its impact can be mitigated using fraud\ndetection techniques. To detect fraud, machine learning techniques are used.\nThe Centers for Medicaid and Medicare Services (CMS) of the United States\nfederal government released \"Medicare Part D\" insurance claims is utilized in\nthis study to develop fraud detection system. Employing machine learning\nalgorithms on a class-imbalanced and high dimensional medicare dataset is a\nchallenging task. To compact such challenges, the present work aims to perform\nfeature extraction following data sampling, afterward applying various\nclassification algorithms, to get better performance. Feature extraction is a\ndimensionality reduction approach that converts attributes into linear or\nnon-linear combinations of the actual attributes, generating a smaller and more\ndiversified set of attributes and thus reducing the dimensions. Data sampling\nis commonlya used to address the class imbalance either by expanding the\nfrequency of minority class or reducing the frequency of majority class to\nobtain approximately equal numbers of occurrences for both classes. The\nproposed approach is evaluated through standard performance metrics. Thus, to\ndetect fraud efficiently, this study applies autoencoder as a feature\nextraction technique, synthetic minority oversampling technique (SMOTE) as a\ndata sampling technique, and various gradient boosted decision tree-based\nclassifiers as a classification algorithm. The experimental results show the\ncombination of autoencoders followed by SMOTE on the LightGBM classifier\nachieved best results.",
    "descriptor": "",
    "authors": [
      "Akrity Kumari",
      "Narinder Singh Punn",
      "Sanjay Kumar Sonbhadra",
      "Sonali Agarwal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01413"
  },
  {
    "id": "arXiv:2206.01417",
    "title": "Learning an Adaptation Function to Assess Image Visual Similarities",
    "abstract": "Human perception is routinely assessing the similarity between images, both\nfor decision making and creative thinking. But the underlying cognitive process\nis not really well understood yet, hence difficult to be mimicked by computer\nvision systems. State-of-the-art approaches using deep architectures are often\nbased on the comparison of images described as feature vectors learned for\nimage categorization task. As a consequence, such features are powerful to\ncompare semantically related images but not really efficient to compare images\nvisually similar but semantically unrelated. Inspired by previous works on\nneural features adaptation to psycho-cognitive representations, we focus here\non the specific task of learning visual image similarities when analogy\nmatters. We propose to compare different supervised, semi-supervised and\nself-supervised networks, pre-trained on distinct scales and contents datasets\n(such as ImageNet-21k, ImageNet-1K or VGGFace2) to conclude which model may be\nthe best to approximate the visual cortex and learn only an adaptation function\ncorresponding to the approximation of the the primate IT cortex through the\nmetric learning framework. Our experiments conducted on the Totally Looks Like\nimage dataset highlight the interest of our method, by increasing the retrieval\nscores of the best model @1 by 2.25x. This research work was recently accepted\nfor publication at the ICIP 2021 international conference [1]. In this new\narticle, we expand on this previous work by using and comparing new pre-trained\nfeature extractors on other datasets.",
    "descriptor": "",
    "authors": [
      "Olivier Risser-Maroix",
      "Amine Marzouki",
      "Hala Djeghim",
      "Camille Kurtz",
      "Nicolas Lomenie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01417"
  },
  {
    "id": "arXiv:2206.01421",
    "title": "12 Years of Self-tracking for Promoting Physical Activity from a User  Diversity Perspective: Taking Stock and Thinking Ahead",
    "abstract": "Despite the indisputable personal and societal benefits of regular physical\nactivity, a large portion of the population does not follow the recommended\nguidelines, harming their health and wellness. The World Health Organization\nhas called upon governments, practitioners, and researchers to accelerate\naction to address the global prevalence of physical inactivity. To this end, an\nemerging wave of research in ubiquitous computing has been exploring the\npotential of interactive self-tracking technology in encouraging positive\nhealth behavior change. Numerous findings indicate the benefits of\npersonalization and inclusive design regarding increasing the motivational\nappeal and overall effectiveness of behavior change systems, with the ultimate\ngoal of empowering and facilitating people to achieve their goals. However,\nmost interventions still adopt a \"one-size-fits-all\" approach to their design,\nassuming equal effectiveness for all system features in spite of individual and\ncollective user differences. To this end, we analyze a corpus of 12 years of\nresearch in self-tracking technology for health behavior change, focusing on\nphysical activity, to identify those design elements that have proven most\neffective in inciting desirable behavior across diverse population segments. We\nthen provide actionable recommendations for designing and evaluating behavior\nchange self-tracking technology based on age, gender, occupation, fitness, and\nhealth condition. Finally, we engage in a critical commentary on the diversity\nof the domain and discuss ethical concerns surrounding tailored interventions\nand directions for moving forward.",
    "descriptor": "",
    "authors": [
      "Sofia Yfantidou",
      "Pavlos Sermpezis",
      "Athena Vakali"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.01421"
  },
  {
    "id": "arXiv:2206.01423",
    "title": "Time-Continuous and Time-Discontinuous Space-Time Finite Elements for  Advection-Diffusion Problems",
    "abstract": "We construct four variants of space-time finite element discretizations based\non linear tensor-product and simplex-type finite elements. The resulting\ndiscretizations are continuous in space, and continuous or discontinuous in\ntime. In a first test run, all four methods are applied to a linear scalar\nadvection-diffusion model problem. Then, the convergence properties of the\ntime-discontinuous space-time finite element discretizations are studied in\nnumerical experiments. Advection velocity and diffusion coefficient are varied,\nsuch that the parabolic case of pure diffusion (heat equation), as well as, the\nhyperbolic case of pure advection (transport equation) are included in the\nstudy. For each model parameter set, the L2 error at the final time is computed\nfor spatial and temporal element lengths ranging over several orders of\nmagnitude to allow for an individual evaluation of the methods' spatial,\ntemporal, and spacetime accuracy. In the parabolic case, particular attention\nis paid to the influence of time-dependent boundary conditions. Key findings\ninclude a spatial accuracy of second order and a temporal accuracy between\nsecond and third order. The temporal accuracy tends towards third order\ndepending on how advection-dominated the test case is, on the choice of the\nspecific discretization method, and on the time-(in)dependence and treatment of\nthe boundary conditions. Additionally, the potential of time-continuous simplex\nspace-time finite elements for heat flux computations is demonstrated with a\npiston ring pack test case.",
    "descriptor": "\nComments: 29 pages, 22 figures\n",
    "authors": [
      "Max von Danwitz",
      "Igor Voulis",
      "Norbert Hosters",
      "Marek Behr"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.01423"
  },
  {
    "id": "arXiv:2206.01424",
    "title": "Comprehensive Survey of Ternary Full Adders: Statistics, Corrections,  and Assessments",
    "abstract": "The history of ternary adders goes back to more than six decades ago. Since\nthen, a multitude of ternary full adders (TFAs) have been presented in the\nliterature. This paper aims to conduct a survey to be familiar with the\nutilized design methodologies and logic families and their prevalence. Although\nthe number of papers about this topic is high, almost none of the previously\npresented TFAs are in their simplest form. A large number of transistors could\nhave been eliminated by considering a partial TFA instead of a complete one.\nMoreover, they could have been simplified even further by assuming a partial\nTFA where the voltage of the output carry is either 0V or VDD. This way, less\nstatic power would be dissipated. Therefore, a strong motivation is to correct\nand enhance the previous designs. Furthermore, different simulation setups,\nwhich are not realistic enough, have been taken into account. Therefore, the\nsimulation results reported in the previous papers are neither comparable nor\nentirely valid. Among the 75 papers in which a new design of TFA has been\ngiven, 11 papers are selected, simplified, and simulated in this paper.\nSimulations are carried out by HSPICE and 32nm CNFET technology while\nconsidering a standard test-bed and a complete input pattern to reveal the\nmaximum cell delay. The simplified partial TFAs outperform their original\nversions in delay, power, and transistor count.",
    "descriptor": "\nComments: 26 Pages, 20 Figures, 16 Tables\n",
    "authors": [
      "Sarina Nemati",
      "Mostafa Haghi Kashani",
      "Reza Faghih Mirzaee"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2206.01424"
  },
  {
    "id": "arXiv:2206.01426",
    "title": "Rate-Optimal Online Convex Optimization in Adaptive Linear Control",
    "abstract": "We consider the problem of controlling an unknown linear dynamical system\nunder adversarially changing convex costs and full feedback of both the state\nand cost function. We present the first computationally-efficient algorithm\nthat attains an optimal $\\smash{\\sqrt{T}}$-regret rate compared to the best\nstabilizing linear controller in hindsight, while avoiding stringent\nassumptions on the costs such as strong convexity. Our approach is based on a\ncareful design of non-convex lower confidence bounds for the online costs, and\nuses a novel technique for computationally-efficient regret minimization of\nthese bounds that leverages their particular non-convex structure.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2203.01170\n",
    "authors": [
      "Asaf Cassel",
      "Alon Cohen",
      "Tomer Koren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.01426"
  },
  {
    "id": "arXiv:2206.01428",
    "title": "Age- and Deviation-of-Information of Time-Triggered and Event-Triggered  Systems",
    "abstract": "Age-of-information is a metric that quantifies the freshness of information\nobtained by sampling a remote sensor. In signal-agnostic sampling, sensor\nupdates are triggered at certain times without being conditioned on the actual\nsensor signal. Optimal update policies have been researched and it is accepted\nthat periodic updates achieve smaller age-of-information than random updates.\nWe contribute a study of a signal-aware policy, where updates are triggered by\na random sensor event. By definition, this implies random updates and as a\nconsequence inferior age-of-information. Considering a notion of\ndeviation-of-information as a signal-aware metric, our results show, however,\nthat event-triggered systems can perform equally well as time-triggered systems\nwhile causing smaller mean network utilization.",
    "descriptor": "",
    "authors": [
      "Mahsa Noroozi",
      "Markus Fidler"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2206.01428"
  },
  {
    "id": "arXiv:2206.01429",
    "title": "Learning rich optical embeddings for privacy-preserving lensless image  classification",
    "abstract": "By replacing the lens with a thin optical element, lensless imaging enables\nnew applications and solutions beyond those supported by traditional camera\ndesign and post-processing, e.g. compact and lightweight form factors and\nvisual privacy. The latter arises from the highly multiplexed measurements of\nlensless cameras, which require knowledge of the imaging system to recover a\nrecognizable image. In this work, we exploit this unique multiplexing property:\ncasting the optics as an encoder that produces learned embeddings directly at\nthe camera sensor. We do so in the context of image classification, where we\njointly optimize the encoder's parameters and those of an image classifier in\nan end-to-end fashion. Our experiments show that jointly learning the lensless\noptical encoder and the digital processing allows for lower resolution\nembeddings at the sensor, and hence better privacy as it is much harder to\nrecover meaningful images from these measurements. Additional experiments show\nthat such an optimization allows for lensless measurements that are more robust\nto typical real-world image transformations. While this work focuses on\nclassification, the proposed programmable lensless camera and end-to-end\noptimization can be applied to other computational imaging tasks.",
    "descriptor": "\nComments: 29 pages, 23 figures, under review\n",
    "authors": [
      "Eric Bezzam",
      "Martin Vetterli",
      "Matthieu Simeoni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.01429"
  },
  {
    "id": "arXiv:2206.01431",
    "title": "Receding Horizon Games with Coupling Constraints for Demand-Side  Management",
    "abstract": "Distributed energy storage and flexible loads are essential tools for\nensuring stable and robust operation of the power grid in spite of the\nchallenges arising from the integration of volatile renewable energy generation\nand increasing peak loads due to widespread electrification. This paper\nproposes a novel demand-side management policy to coordinate self-interested\nenergy prosumers based on receding horizon games, i.e., a closed-loop\nreceding-horizon implementation of game-theoretic day-ahead planning. Practical\nstability and recursive constraint satisfaction of the proposed feedback\ncontrol policy is proven under symmetric pricing assumptions using tools from\ngame theory and economic model predictive control. Our numerical studies show\nthat the proposed approach is superior to standard open-loop day-head\nimplementations in terms of peak-shaving, disturbance rejection, and control\nperformance.",
    "descriptor": "",
    "authors": [
      "Sophie Hall",
      "Giuseppe Belgioioso",
      "Dominic Liao-McPherson",
      "Florian D\u00f6rfler"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.01431"
  },
  {
    "id": "arXiv:2206.01432",
    "title": "On the Generalization of Wasserstein Robust Federated Learning",
    "abstract": "In federated learning, participating clients typically possess non-i.i.d.\ndata, posing a significant challenge to generalization to unseen distributions.\nTo address this, we propose a Wasserstein distributionally robust optimization\nscheme called WAFL. Leveraging its duality, we frame WAFL as an empirical\nsurrogate risk minimization problem, and solve it using a local SGD-based\nalgorithm with convergence guarantees. We show that the robustness of WAFL is\nmore general than related approaches, and the generalization bound is robust to\nall adversarial distributions inside the Wasserstein ball (ambiguity set).\nSince the center location and radius of the Wasserstein ball can be suitably\nmodified, WAFL shows its applicability not only in robustness but also in\ndomain adaptation. Through empirical evaluation, we demonstrate that WAFL\ngeneralizes better than the vanilla FedAvg in non-i.i.d. settings, and is more\nrobust than other related methods in distribution shift settings. Further,\nusing benchmark datasets we show that WAFL is capable of generalizing to unseen\ntarget domains.",
    "descriptor": "",
    "authors": [
      "Tung-Anh Nguyen",
      "Tuan Dung Nguyen",
      "Long Tan Le",
      "Canh T. Dinh",
      "Nguyen H. Tran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.01432"
  },
  {
    "id": "arXiv:2206.01433",
    "title": "Stability analysis of tensegrity mechanism coupled with a bio-inspired  piping inspection robot",
    "abstract": "Piping inspection robots play an essential role for industries as they can\nreduce human effort and pose a lesser risk to their lives. Generally, the\nlocomotion techniques of these robots can be classified into mechanical and\nbioinspired. By using slot-follower leg mechanisms, DC-motors, and control\nunits, a rigid caterpillar type inspection robot was designed and developed at\nLS2N, France . This rigid prototype helped in identifying the static forces\nrequired to accomplish good contact forces with the pipeline walls. In order to\nwork inside curvatures, a tensegrity mechanism that uses three tension springs\nand a passive universal joint was introduced between each module of this robot.\nThe optimal parameters of the robot assembly were identified by considering a\npreload of the cables, which ensured the stability of the entire robot.\nHowever, under static conditions, there exist some forces on the robot,\nespecially on the tensegrity mechanism when one end of the leg mechanism is\nclamped with the pipeline walls. These forces are dominant when the orientation\nof the pipeline is horizontal. The objective of this article is to understand\nthe effect of the stiffness of the spring on the static stability of the\ntensegrity mechanism under the self-weight of the robot assembly.",
    "descriptor": "",
    "authors": [
      "Swaminath Venkateswaran",
      "Damien Chablat"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.01433"
  },
  {
    "id": "arXiv:2206.01435",
    "title": "Dual-Port Dynamically Reconfigurable Battery with Semi-Controlled and  Fully-Controlled Outputs",
    "abstract": "Modular multilevel converters (MMC) and cascaded H-bridge (CHB) converters\nare an established concept in ultra-high voltage systems. In combination with\nbatteries, these circuits allow dynamically changing the series or parallel\nconfiguration of subportions of the battery as so-called modular battery\nintegrated converters or reconfigurable batteries, and are being discussed for\ngrid-storage and electromobility applications. A large body of research focuses\non such circuits for supplying a single load, such as a motor for electric\ndrives. Modularity, failure tolerance, less dependence on the weakest element\nof a battery pack, higher controllability, and better efficiency are the main\nincentives behind this pursuit. However, most studies neglect the auxiliary\nloads which require isolation from the high-voltage battery. This paper\nproposes a simple topology and controller that can fork off a second\n(galvanically isolated) output of a reconfigurable dc battery. The proposed\nsystem provides a nonisolated semicontrolled port for the dc link to maintain\nthe operating point of the main inverter(s) close to optimal, while fully\ncontrolling an isolated output for the auxiliaries per the safety regulations.\nThe proposed system does not require additional active switches for the\nauxiliary port and can operate with a wide range of voltages. Simulation and\nexperiments verify the developed analysis.",
    "descriptor": "\nComments: All Rights reserved. This work has been submitted for publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "N. Tashakor",
      "J. Kacetl",
      "J. Fang",
      "Z. Li",
      "S. Goetz"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.01435"
  },
  {
    "id": "arXiv:2206.01436",
    "title": "Modeling electronic health record data using a knowledge-graph-embedded  topic model",
    "abstract": "The rapid growth of electronic health record (EHR) datasets opens up\npromising opportunities to understand human diseases in a systematic way.\nHowever, effective extraction of clinical knowledge from the EHR data has been\nhindered by its sparsity and noisy information. We present KG-ETM, an\nend-to-end knowledge graph-based multimodal embedded topic model. KG-ETM\ndistills latent disease topics from EHR data by learning the embedding from the\nmedical knowledge graphs. We applied KG-ETM to a large-scale EHR dataset\nconsisting of over 1 million patients. We evaluated its performance based on\nEHR reconstruction and drug imputation. KG-ETM demonstrated superior\nperformance over the alternative methods on both tasks. Moreover, our model\nlearned clinically meaningful graph-informed embedding of the EHR codes. In\nadditional, our model is also able to discover interpretable and accurate\npatient representations for patient stratification and drug recommendations.",
    "descriptor": "",
    "authors": [
      "Yuesong Zou",
      "Ahmad Pesaranghader",
      "Aman Verma",
      "David Buckeridge",
      "Yue Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2206.01436"
  },
  {
    "id": "arXiv:2206.01439",
    "title": "Open Research Knowledge Graph:A System Walkthrough",
    "abstract": "Despite improved digital access to scholarly literature in the last decades,\nthe fundamental principles of scholarly communication remain unchanged and\ncontinue to be largely document-based. Scholarly knowledge remains locked in\nrepresentations that are inadequate for machine processing. The Open Research\nKnowledge Graph (ORKG) is an infrastructure for representing, curating and\nexploring scholarly knowledge in a machine actionable manner. We demonstrate\nthe core functionality of ORKG for representing research contributions\npublished in scholarly articles. A video of the demonstration and the system\nare available online.",
    "descriptor": "\nComments: Pre-print for TPDL 2019 demo\n",
    "authors": [
      "Mohamad Yaser Jaradeh",
      "Allard Oelen",
      "Manuel Prinz",
      "Markus Stocker",
      "S\u00f6ren Auer"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2206.01439"
  },
  {
    "id": "arXiv:2206.01441",
    "title": "Exploring Transformers for Behavioural Biometrics: A Case Study in Gait  Recognition",
    "abstract": "Biometrics on mobile devices has attracted a lot of attention in recent years\nas it is considered a user-friendly authentication method. This interest has\nalso been motivated by the success of Deep Learning (DL). Architectures based\non Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs)\nhave been established to be convenient for the task, improving the performance\nand robustness in comparison to traditional machine learning techniques.\nHowever, some aspects must still be revisited and improved. To the best of our\nknowledge, this is the first article that intends to explore and propose novel\ngait biometric recognition systems based on Transformers, which currently\nobtain state-of-the-art performance in many applications. Several\nstate-of-the-art architectures (Vanilla, Informer, Autoformer, Block-Recurrent\nTransformer, and THAT) are considered in the experimental framework. In\naddition, new configurations of the Transformers are proposed to further\nincrease the performance. Experiments are carried out using the two popular\npublic databases whuGAIT and OU-ISIR. The results achieved prove the high\nability of the proposed Transformer, outperforming state-of-the-art CNN and RNN\narchitectures.",
    "descriptor": "",
    "authors": [
      "Paula Delgado-Santos",
      "Ruben Tolosana",
      "Richard Guest",
      "Farzin Deravi",
      "Ruben Vera-Rodriguez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.01441"
  },
  {
    "id": "arXiv:2206.01442",
    "title": "Plumber: A Modular Framework to Create Information Extraction Pipelines",
    "abstract": "Information Extraction (IE) tasks are commonly studied topics in various\ndomains of research. Hence, the community continuously produces multiple\ntechniques, solutions, and tools to perform such tasks. However, running those\ntools and integrating them within existing infrastructure requires time,\nexpertise, and resources. One pertinent task here is triples extraction and\nlinking, where structured triples are extracted from a text and aligned to an\nexisting Knowledge Graph (KG). In this paper, we present PLUMBER, the first\nframework that allows users to manually and automatically create suitable IE\npipelines from a community-created pool of tools to perform triple extraction\nand alignment on unstructured text. Our approach provides an interactive medium\nto alter the pipelines and perform IE tasks. A short video to show the working\nof the framework for different use-cases is available online under:\nhttps://www.youtube.com/watch?v=XC9rJNIUv8g",
    "descriptor": "\nComments: pre-print for WWW'21 demo of ICWE PLUMBER publication\n",
    "authors": [
      "Mohamad Yaser Jaradeh",
      "Kuldeep Singh",
      "Markus Stocker",
      "S\u00f6ren Auer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2206.01442"
  },
  {
    "id": "arXiv:2206.01444",
    "title": "XPASC: Measuring Generalization in Weak Supervision",
    "abstract": "Weak supervision is leveraged in a wide range of domains and tasks due to its\nability to create massive amounts of labeled data, requiring only little manual\neffort. Standard approaches use labeling functions to specify signals that are\nrelevant for the labeling. It has been conjectured that weakly supervised\nmodels over-rely on those signals and as a result suffer from overfitting. To\nverify this assumption, we introduce a novel method, XPASC\n(eXPlainability-Association SCore), for measuring the generalization of a model\ntrained with a weakly supervised dataset. Considering the occurrences of\nfeatures, classes and labeling functions in a dataset, XPASC takes into account\nthe relevance of each feature for the predictions of the model as well as the\nassociations of the feature with the class and the labeling function,\nrespectively. The association in XPASC can be measured in two variants:\nXPASC-CHI SQAURE measures associations relative to their statistical\nsignificance, while XPASC-PPMI measures association strength more generally.\nWe use XPASC to analyze KnowMAN, an adversarial architecture intended to\ncontrol the degree of generalization from the labeling functions and thus to\nmitigate the problem of overfitting. On one hand, we show that KnowMAN is able\nto control the degree of generalization through a hyperparameter. On the other\nhand, results and qualitative analysis show that generalization and performance\ndo not relate one-to-one, and that the highest degree of generalization does\nnot necessarily imply the best performance. Therefore methods that allow for\ncontrolling the amount of generalization can achieve the right degree of benign\noverfitting. Our contributions in this study are i) the XPASC score to measure\ngeneralization in weakly-supervised models, ii) evaluation of XPASC across\ndatasets and models and iii) the release of the XPASC implementation.",
    "descriptor": "\nComments: 21 pages, 16 Figures, 5 Tables\n",
    "authors": [
      "Luisa M\u00e4rz",
      "Ehsaneddin Asgari",
      "Fabienne Braune",
      "Franziska Zimmermann",
      "Benjamin Roth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2206.01444"
  },
  {
    "id": "arXiv:2206.01448",
    "title": "Optimal Control for Unmanned Systems with One-way Broadcast  Communication",
    "abstract": "Unmanned systems (USs) including unmanned aerial vehicles, unmanned\nunderwater vehicles, and unmanned ground vehicles have great application\nprospects in military and civil fields, among which the process of finding\nfeasible and optimal paths for the agents in USs is a kernel problem.\nTraditional path finding algorithms are hard to adequately obtain optimal paths\nin real-time under fast time-varying and poor communication environments. We\npropose an online optimal control algorithm for USs based on a one-way\nbroadcast communication mode under the assumption of a poor communication\nenvironment, mobile targets, radars (or sonar), and missiles (or torpedoes).\nWith the principle of receding horizon control, optimal (or suboptimal) paths\nare then generated by the approximation theory of neural networks and gradient\noptimization techniques, with low computation requirements. Also, we give a\nconvergence analysis for our algorithm, and show that each agent can reach its\ntarget in finite time under some conditions on agents, targets and\nradar-missiles. Moreover, simulations demonstrate that the agents in USs can\ngenerate optimal (or suboptimal) paths in real time using our algorithm while\neffectively avoiding collision with other agents or detection by enemy radars.",
    "descriptor": "",
    "authors": [
      "Chao Ge",
      "Ge Chen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.01448"
  },
  {
    "id": "arXiv:2206.01451",
    "title": "Learning Distributed and Fair Policies for Network Load Balancing as  Markov Potentia Game",
    "abstract": "This paper investigates the network load balancing problem in data centers\n(DCs) where multiple load balancers (LBs) are deployed, using the multi-agent\nreinforcement learning (MARL) framework. The challenges of this problem consist\nof the heterogeneous processing architecture and dynamic environments, as well\nas limited and partial observability of each LB agent in distributed networking\nsystems, which can largely degrade the performance of in-production load\nbalancing algorithms in real-world setups.\nCentralised-training-decentralised-execution (CTDE) RL scheme has been proposed\nto improve MARL performance, yet it incurs -- especially in distributed\nnetworking systems, which prefer distributed and plug-and-play design scheme --\nadditional communication and management overhead among agents. We formulate the\nmulti-agent load balancing problem as a Markov potential game, with a carefully\nand properly designed workload distribution fairness as the potential function.\nA fully distributed MARL algorithm is proposed to approximate the Nash\nequilibrium of the game. Experimental evaluations involve both an event-driven\nsimulator and real-world system, where the proposed MARL load balancing\nalgorithm shows close-to-optimal performance in simulations, and superior\nresults over in-production LBs in the real-world system.",
    "descriptor": "",
    "authors": [
      "Zhiyuan Yao",
      "Zihan Ding"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.01451"
  },
  {
    "id": "arXiv:2206.01463",
    "title": "Safety Certification for Stochastic Systems via Neural Barrier Functions",
    "abstract": "Providing non-trivial certificates of safety for non-linear stochastic\nsystems is an important open problem that limits the wider adoption of\nautonomous systems in safety-critical applications. One promising solution to\naddress this problem is barrier functions. The composition of a barrier\nfunction with a stochastic system forms a supermartingale, thus enabling the\ncomputation of the probability that the system stays in a safe set over a\nfinite time horizon via martingale inequalities. However, existing approaches\nto find barrier functions for stochastic systems generally rely on convex\noptimization programs that restrict the search of a barrier to a small class of\nfunctions such as low degree SoS polynomials and can be computationally\nexpensive. In this paper, we parameterize a barrier function as a neural\nnetwork and show that techniques for robust training of neural networks can be\nsuccessfully employed to find neural barrier functions. Specifically, we\nleverage bound propagation techniques to certify that a neural network\nsatisfies the conditions to be a barrier function via linear programming and\nthen employ the resulting bounds at training time to enforce the satisfaction\nof these conditions. We also present a branch-and-bound scheme that makes the\ncertification framework scalable. We show that our approach outperforms\nexisting methods in several case studies and often returns certificates of\nsafety that are orders of magnitude larger.",
    "descriptor": "",
    "authors": [
      "Frederik Baymler Mathiesen",
      "Simeon Calvert",
      "Luca Laurenti"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01463"
  },
  {
    "id": "arXiv:2206.01465",
    "title": "PAC Statistical Model Checking of Mean Payoff in Discrete- and  Continuous-Time MDP",
    "abstract": "Markov decision processes (MDP) and continuous-time MDP (CTMDP) are the\nfundamental models for non-deterministic systems with probabilistic\nuncertainty. Mean payoff (a.k.a. long-run average reward) is one of the most\nclassic objectives considered in their context. We provide the first algorithm\nto compute mean payoff probably approximately correctly in unknown MDP;\nfurther, we extend it to unknown CTMDP. We do not require any knowledge of the\nstate space, only a lower bound on the minimum transition probability, which\nhas been advocated in literature. In addition to providing probably\napproximately correct (PAC) bounds for our algorithm, we also demonstrate its\npractical nature by running experiments on standard benchmarks.",
    "descriptor": "\nComments: Full version of CAV 2022 paper, 57 pages\n",
    "authors": [
      "Chaitanya Agarwal",
      "Shibashis Guha",
      "Jan K\u0159et\u00ednsk\u00fd",
      "M. Pazhamalai"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01465"
  },
  {
    "id": "arXiv:2206.01466",
    "title": "Zero-Shot Bird Species Recognition by Learning from Field Guides",
    "abstract": "We exploit field guides to learn bird species recognition, in particular\nzero-shot recognition of unseen species. The illustrations contained in field\nguides deliberately focus on discriminative properties of a species, and can\nserve as side information to transfer knowledge from seen to unseen classes. We\nstudy two approaches: (1) a contrastive encoding of illustrations that can be\nfed into zero-shot learning schemes; and (2) a novel method that leverages the\nfact that illustrations are also images and as such structurally more similar\nto photographs than other kinds of side information. Our results show that\nillustrations from field guides, which are readily available for a wide range\nof species, are indeed a competitive source of side information. On the\niNaturalist2021 subset, we obtain a harmonic mean from 749 seen and 739 unseen\nclasses greater than $45\\%$ (@top-10) and $15\\%$ (@top-1). Which shows that\nfield guides are a valuable option for challenging real-world scenarios with\nmany species.",
    "descriptor": "",
    "authors": [
      "Andr\u00e9s C. Rodr\u00edguez",
      "Stefano D'Aronco",
      "Rodrigo Caye Daudt",
      "Jan D. Wegner",
      "Konrad Schindler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01466"
  },
  {
    "id": "arXiv:2206.01467",
    "title": "Evaluating Transfer-based Targeted Adversarial Perturbations against  Real-World Computer Vision Systems based on Human Judgments",
    "abstract": "Computer vision systems are remarkably vulnerable to adversarial\nperturbations. Transfer-based adversarial images are generated on one (source)\nsystem and used to attack another (target) system. In this paper, we take the\nfirst step to investigate transfer-based targeted adversarial images in a\nrealistic scenario where the target system is trained on some private data with\nits inventory of semantic labels not publicly available. Our main contributions\ninclude an extensive human-judgment-based evaluation of attack success on the\nGoogle Cloud Vision API and additional analysis of the different behaviors of\nGoogle Cloud Vision in face of original images vs. adversarial images.\nResources are publicly available at\n\\url{https://github.com/ZhengyuZhao/Targeted-Tansfer/blob/main/google_results.zip}.",
    "descriptor": "\nComments: technical report\n",
    "authors": [
      "Zhengyu Zhao",
      "Nga Dang",
      "Martha Larson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01467"
  },
  {
    "id": "arXiv:2206.01471",
    "title": "Controlled Signaling and Transmitter Replenishment for MC with  Functionalized Nanoparticles",
    "abstract": "In this paper, we propose novel Transmitter (Tx) models for Molecular\nCommunication (MC) systems based on functionalized Nanoparticles (NPs). Current\nTx models often rely on simplifying assumptions for the molecule release and\nreplenishment mechanisms. In contrast, we propose a Tx model where the\nsignaling molecule release is controlled by a switchable membrane driven by an\nexternal trigger. Moreover, we propose a reloading mechanism, where signaling\nmolecules are harvested based on an enzymatic reaction. Hence, no repeated\ninjection of signaling molecules is required. For the proposed Tx model, we\ndevelop a general mathematical description in terms of a discrete-time transfer\nfunction model. Furthermore, we investigate two realizations of the proposed Tx\nmodel, i.e., an idealized Tx relying on simplifying assumptions, and a\nrealistic Tx employing practical components for the reloading and release\nmechanisms. Finally, we numerically evaluate the proposed model and compare our\nresults to stochastic Particle Based Simulations (PBSs).",
    "descriptor": "\nComments: 7 pages, 7 figures. submitted to 9th ACM International Conference on Nanoscale Computing and Communication, Barcelona, Catalunya, Spain\n",
    "authors": [
      "Maximilian Sch\u00e4fer",
      "Lukas Brand",
      "Sebastian Lotter",
      "Atakan B\u00fcy\u00fckoglu",
      "Franz Enzenhofer",
      "Werner Haselmayr",
      "Kathrin Castiglione",
      "Dietmar Appelhans",
      "Robert Schober"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2206.01471"
  },
  {
    "id": "arXiv:2206.01473",
    "title": "Distributional loss for convolutional neural network regression and  application to GNSS multi-path estimation",
    "abstract": "Convolutional Neural Network (CNN) have been widely used in image\nclassification. Over the years, they have also benefited from various\nenhancements and they are now considered as state of the art techniques for\nimage like data. However, when they are used for regression to estimate some\nfunction value from images, fewer recommendations are available. In this study,\na novel CNN regression model is proposed. It combines convolutional neural\nlayers to extract high level features representations from images with a soft\nlabelling technique. More specifically, as the deep regression task is\nchallenging, the idea is to account for some uncertainty in the targets that\nare seen as distributions around their mean. The estimations are carried out by\nthe model in the form of distributions. Building from earlier work, a specific\nhistogram loss function based on the Kullback-Leibler (KL) divergence is\napplied during training. The model takes advantage of the CNN feature\nrepresentation and is able to carry out estimation from multi-channel input\nimages. To assess and illustrate the technique, the model is applied to Global\nNavigation Satellite System (GNSS) multi-path estimation where multi-path\nsignal parameters have to be estimated from correlator output images from the I\nand Q channels. The multi-path signal delay, magnitude, Doppler shift frequency\nand phase parameters are estimated from synthetically generated datasets of\nsatellite signals. Experiments are conducted under various receiving conditions\nand various input images resolutions to test the estimation performances\nquality and robustness. The results show that the proposed soft labelling CNN\ntechnique using distributional loss outperforms classical CNN regression under\nall conditions. Furthermore, the extra learning performance achieved by the\nmodel allows the reduction of input image resolution from 80x80 down to 40x40\nor sometimes 20x20.",
    "descriptor": "",
    "authors": [
      "Thomas Gonzalez",
      "Antoine Blais",
      "Nicolas Cou\u00ebllan",
      "Christian Ruiz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.01473"
  },
  {
    "id": "arXiv:2206.01474",
    "title": "Offline Reinforcement Learning with Causal Structured World Models",
    "abstract": "Model-based methods have recently shown promising for offline reinforcement\nlearning (RL), aiming to learn good policies from historical data without\ninteracting with the environment. Previous model-based offline RL methods learn\nfully connected nets as world-models that map the states and actions to the\nnext-step states. However, it is sensible that a world-model should adhere to\nthe underlying causal effect such that it will support learning an effective\npolicy generalizing well in unseen states. In this paper, We first provide\ntheoretical results that causal world-models can outperform plain world-models\nfor offline RL by incorporating the causal structure into the generalization\nerror bound. We then propose a practical algorithm, oFfline mOdel-based\nreinforcement learning with CaUsal Structure (FOCUS), to illustrate the\nfeasibility of learning and leveraging causal structure in offline RL.\nExperimental results on two benchmarks show that FOCUS reconstructs the\nunderlying causal structure accurately and robustly. Consequently, it performs\nbetter than the plain model-based offline RL algorithms and other causal\nmodel-based RL algorithms.",
    "descriptor": "",
    "authors": [
      "Zheng-Mao Zhu",
      "Xiong-Hui Chen",
      "Hong-Long Tian",
      "Kun Zhang",
      "Yang Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.01474"
  },
  {
    "id": "arXiv:2206.01476",
    "title": "Task-Adaptive Pre-Training for Boosting Learning With Noisy Labels: A  Study on Text Classification for African Languages",
    "abstract": "For high-resource languages like English, text classification is a\nwell-studied task. The performance of modern NLP models easily achieves an\naccuracy of more than 90% in many standard datasets for text classification in\nEnglish (Xie et al., 2019; Yang et al., 2019; Zaheer et al., 2020). However,\ntext classification in low-resource languages is still challenging due to the\nlack of annotated data. Although methods like weak supervision and\ncrowdsourcing can help ease the annotation bottleneck, the annotations obtained\nby these methods contain label noise. Models trained with label noise may not\ngeneralize well. To this end, a variety of noise-handling techniques have been\nproposed to alleviate the negative impact caused by the errors in the\nannotations (for extensive surveys see (Hedderich et al., 2021; Algan & Ulusoy,\n2021)). In this work, we experiment with a group of standard noisy-handling\nmethods on text classification tasks with noisy labels. We study both simulated\nnoise and realistic noise induced by weak supervision. Moreover, we find\ntask-adaptive pre-training techniques (Gururangan et al., 2020) are beneficial\nfor learning with noisy labels.",
    "descriptor": "\nComments: AfricaNLP Workshop @ ICLR2022\n",
    "authors": [
      "Dawei Zhu",
      "Michael A. Hedderich",
      "Fangzhou Zhai",
      "David Ifeoluwa Adelani",
      "Dietrich Klakow"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.01476"
  },
  {
    "id": "arXiv:2206.01480",
    "title": "Arbitrary pattern formation by opaque fat robots on infinite grid",
    "abstract": "Arbitrary Pattern formation ($\\mathcal{APF}$) by a swarm of mobile robots is\na widely studied problem in the literature. Many works regarding\n$\\mathcal{APF}$ have been proposed on plane and infinite grid by point robots.\nBut in practical application, it is impossible to design point robots. In\n\\cite{BoseAKS20}, the robots are assumed opaque fat robots but the environment\nis plane. To the best of our knowledge, no work till now ever considered the\n$\\mathcal{APF}$ problem assuming opaque fat robots on infinite grid where\nmovements are restricted. In this paper, we have provided a collisionless\ndistributed algorithm and solved $\\mathcal{APF}$ using 9 colors.",
    "descriptor": "",
    "authors": [
      "Manash Kumar Kundu",
      "Pritam Goswami",
      "Satakshi Ghosh",
      "Buddhadeb Sau"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.01480"
  },
  {
    "id": "arXiv:2206.01483",
    "title": "Finding Rule-Interpretable Non-Negative Data Representation",
    "abstract": "Non-negative Matrix Factorization (NMF) is an intensively used technique for\nobtaining parts-based, lower dimensional and non-negative representation of\nnon-negative data. It is a popular method in different research fields.\nScientists performing research in the fields of biology, medicine and pharmacy\noften prefer NMF over other dimensionality reduction approaches (such as PCA)\nbecause the non-negativity of the approach naturally fits the characteristics\nof the domain problem and its result is easier to analyze and understand.\nDespite these advantages, it still can be hard to get exact characterization\nand interpretation of the NMF's resulting latent factors due to their numerical\nnature. On the other hand, rule-based approaches are often considered more\ninterpretable but lack the parts-based interpretation. In this work, we present\na version of the NMF approach that merges rule-based descriptions with\nadvantages of part-based representation offered by the NMF approach. Given the\nnumerical input data with non-negative entries and a set of rules with high\nentity coverage, the approach creates the lower-dimensional non-negative\nrepresentation of the input data in such a way that its factors are described\nby the appropriate subset of the input rules. In addition to revealing\nimportant attributes for latent factors, it allows analyzing relations between\nthese attributes and provides the exact numerical intervals or categorical\nvalues they take. The proposed approach provides numerous advantages in tasks\nsuch as focused embedding or performing supervised multi-label NMF.",
    "descriptor": "\nComments: 13 pages, 3 figures. Journal manuscript\n",
    "authors": [
      "Matej Mihel\u010di\u0107",
      "Pauli Miettinen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01483"
  },
  {
    "id": "arXiv:2206.01488",
    "title": "GINK: Graph-based Interaction-aware Kinodynamic Planning via  Reinforcement Learning for Autonomous Driving",
    "abstract": "There are many challenges in applying deep reinforcement learning (DRL) to\nautonomous driving in a structured environment such as an urban area. This is\nbecause the massive traffic flows moving along the road network change\ndynamically. It is a key factor to detect changes in the intentions of\nsurrounding vehicles and quickly find a response strategy. In this paper, we\nsuggest a new framework that effectively combines graph-based intention\nrepresentation learning and reinforcement learning for kinodynamic planning.\nSpecifically, the movement of dynamic agents is expressed as a graph. The\nspatio-temporal locality of node features is conserved and the features are\naggregated by considering the interaction between adjacent nodes. We\nsimultaneously learn motion planner and controller that share the aggregated\ninformation via a safe RL framework. We intuitively interpret a given situation\nwith predicted trajectories to generate additional cost signals. The dense cost\nsignals encourage the policy to be safe for dynamic risk. Moreover, by\nutilizing the data obtained through the direct rollout of learned policy,\nrobust intention inference is achieved for various situations encountered in\ntraining. We set up a navigation scenario in which various situations exist by\nusing CARLA, an urban driving simulator. The experiments show the\nstate-of-the-art performance of our approach compared to the existing\nbaselines.",
    "descriptor": "\nComments: 9 pages, 7 figures\n",
    "authors": [
      "Se-Wook Yoo",
      "Seung-Woo Seo"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.01488"
  },
  {
    "id": "arXiv:2206.01492",
    "title": "A Tableau Method for the Realizability and Synthesis of Reactive Safety  Specifications",
    "abstract": "We introduce a tableau decision method for deciding realizability of\nspecifications expressed in a safety fragment of LTL that includes bounded\nfuture temporal operators. Tableau decision procedures for temporal and modal\nlogics have been thoroughly studied for satisfiability and for translating\ntemporal formulae into equivalent B\\\"uchi automata, and also for model\nchecking, where a specification and system are provided. However, to the best\nof our knowledge no tableau method has been studied for the reactive synthesis\nproblem.\nReactive synthesis starts from a specification where propositional variables\nare split into those controlled by the environment and those controlled by the\nsystem, and consists on automatically producing a system that guarantees the\nspecification for all environments. Realizability is the decision problem of\nwhether there is one such system.\nIn this paper we present a method to decide realizability of safety\nspecifications, from which we can also extract (i.e. synthesize) a correct\nsystem (in case the specification is realizable). Our method can easily be\nextended to handle richer domains (integers, etc) and bounds in the temporal\noperators in ways that automata approaches for synthesis cannot.",
    "descriptor": "\nComments: 35 pages\n",
    "authors": [
      "Montserrat Hermo",
      "Paqui Lucio",
      "C\u00e9sar S\u00e1nchez"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.01492"
  },
  {
    "id": "arXiv:2206.01493",
    "title": "Transferring Studies Across Embodiments: A Case Study in Confusion  Detection",
    "abstract": "Human-robot studies are expensive to conduct and difficult to control, and as\nsuch researchers sometimes turn to human-avatar interaction in the hope of\nfaster and cheaper data collection that can be transferred to the robot domain.\nIn terms of our work, we are particularly interested in the challenge of\ndetecting and modelling user confusion in interaction, and as part of this\nresearch programme, we conducted situated dialogue studies to investigate\nusers' reactions in confusing scenarios that we give in both physical and\nvirtual environments. In this paper, we present a combined review of these\nstudies and the results that we observed across these two embodiments. For the\nphysical embodiment, we used a Pepper Robot, while for the virtual modality, we\nused a 3D avatar. Our study shows that despite attitudinal differences and\ntechnical control limitations, there were a number of similarities detected in\nuser behaviour and self-reporting results across embodiment options. This work\nsuggests that, while avatar interaction is no true substitute for robot\ninteraction studies, sufficient care in study design may allow well executed\nhuman-avatar studies to supplement more challenging human-robot studies.",
    "descriptor": "\nComments: 6 pages paper for the 1st Workshop on the representation, sharing and evaluation of multimodal agent interaction, link: this https URL\n",
    "authors": [
      "Na Li",
      "Robert Ross"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.01493"
  },
  {
    "id": "arXiv:2206.01495",
    "title": "Constraining Gaussian processes for physics-informed acoustic emission  mapping",
    "abstract": "The automated localisation of damage in structures is a challenging but\ncritical ingredient in the path towards predictive or condition-based\nmaintenance of high value structures. The use of acoustic emission time of\narrival mapping is a promising approach to this challenge, but is severely\nhindered by the need to collect a dense set of artificial acoustic emission\nmeasurements across the structure, resulting in a lengthy and often impractical\ndata acquisition process. In this paper, we consider the use of\nphysics-informed Gaussian processes for learning these maps to alleviate this\nproblem. In the approach, the Gaussian process is constrained to the physical\ndomain such that information relating to the geometry and boundary conditions\nof the structure are embedded directly into the learning process, returning a\nmodel that guarantees that any predictions made satisfy physically-consistent\nbehaviour at the boundary. A number of scenarios that arise when training\nmeasurement acquisition is limited, including where training data are sparse,\nand also of limited coverage over the structure of interest. Using a complex\nplate-like structure as an experimental case study, we show that our approach\nsignificantly reduces the burden of data collection, where it is seen that\nincorporation of boundary condition knowledge significantly improves predictive\naccuracy as training observations are reduced, particularly when training\nmeasurements are not available across all parts of the structure.",
    "descriptor": "",
    "authors": [
      "Matthew R Jones",
      "Timothy J Rogers",
      "Elizabeth J Cross"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.01495"
  },
  {
    "id": "arXiv:2206.01496",
    "title": "Causality Learning With Wasserstein Generative Adversarial Networks",
    "abstract": "Conventional methods for causal structure learning from data face significant\nchallenges due to combinatorial search space. Recently, the problem has been\nformulated into a continuous optimization framework with an acyclicity\nconstraint to learn Directed Acyclic Graphs (DAGs). Such a framework allows the\nutilization of deep generative models for causal structure learning to better\ncapture the relations between data sample distributions and DAGs. However, so\nfar no study has experimented with the use of Wasserstein distance in the\ncontext of causal structure learning. Our model named DAG-WGAN combines the\nWasserstein-based adversarial loss with an acyclicity constraint in an\nauto-encoder architecture. It simultaneously learns causal structures while\nimproving its data generation capability. We compare the performance of\nDAG-WGAN with other models that do not involve the Wasserstein metric in order\nto identify its contribution to causal structure learning. Our model performs\nbetter with high cardinality data according to our experiments.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2204.00387\n",
    "authors": [
      "Hristo Petkov",
      "Colin Hanley",
      "Feng Dong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2206.01496"
  },
  {
    "id": "arXiv:2206.01498",
    "title": "YOLOv5s-GTB: light-weighted and improved YOLOv5s for bridge crack  detection",
    "abstract": "In response to the situation that the conventional bridge crack manual\ndetection method has a large amount of human and material resources wasted,\nthis study is aimed to propose a light-weighted, high-precision, deep\nlearning-based bridge apparent crack recognition model that can be deployed in\nmobile devices' scenarios. In order to enhance the performance of YOLOv5,\nfirstly, the data augmentation methods are supplemented, and then the YOLOv5\nseries algorithm is trained to select a suitable basic framework. The YOLOv5s\nis identified as the basic framework for the light-weighted crack detection\nmodel through experiments for comparison and validation.By replacing the\ntraditional DarkNet backbone network of YOLOv5s with GhostNet backbone network,\nintroducing Transformer multi-headed self-attention mechanism and\nbi-directional feature pyramid network (BiFPN) to replace the commonly used\nfeature pyramid network, the improved model not only has 42% fewer parameters\nand faster inference response, but also significantly outperforms the original\nmodel in terms of accuracy and mAP (8.5% and 1.1% improvement, respectively).\nLuckily each improved part has a positive impact on the result. This paper\nprovides a feasible idea to establish a digital operation management system in\nthe field of highway and bridge in the future and to implement the whole life\ncycle structure health monitoring of civil infrastructure in China.",
    "descriptor": "",
    "authors": [
      "Xiao Ruiqiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01498"
  },
  {
    "id": "arXiv:2206.01506",
    "title": "Can Hybrid Geometric Scattering Networks Help Solve the Maximal Clique  Problem?",
    "abstract": "We propose a geometric scattering-based graph neural network (GNN) for\napproximating solutions of the NP-hard maximal clique (MC) problem. We\nconstruct a loss function with two terms, one which encourages the network to\nfind a large set of nodes and the other which acts as a surrogate for the\nconstraint that the nodes form a clique. We then use this loss to train a novel\nGNN architecture that outputs a vector representing the probability for each\nnode to be part of the MC and apply a rule-based decoder to make our final\nprediction. The incorporation of the scattering transform alleviates the\nso-called oversmoothing problem that is often encountered in GNNs and would\ndegrade the performance of our proposed setup. Our empirical results\ndemonstrate that our method outperforms representative GNN baselines in terms\nof solution accuracy and inference speed as well as conventional solvers like\nGUROBI with limited time budgets.",
    "descriptor": "\nComments: 13 pages, 4 tables, 7 figures\n",
    "authors": [
      "Yimeng Min",
      "Frederik Wenkel",
      "Michael Perlmutter",
      "Guy Wolf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01506"
  },
  {
    "id": "arXiv:2206.01507",
    "title": "Can Requirements Engineering Support Explainable Artificial  Intelligence? Towards a User-Centric Approach for Explainability Requirements",
    "abstract": "With the recent proliferation of artificial intelligence systems, there has\nbeen a surge in the demand for explainability of these systems. Explanations\nhelp to reduce system opacity, support transparency, and increase stakeholder\ntrust. In this position paper, we discuss synergies between requirements\nengineering (RE) and Explainable AI (XAI). We highlight challenges in the field\nof XAI, and propose a framework and research directions on how RE practices can\nhelp to mitigate these challenges.",
    "descriptor": "",
    "authors": [
      "Umm-e-Habiba",
      "Justus Bogner",
      "Stefan Wagner"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01507"
  },
  {
    "id": "arXiv:2206.01509",
    "title": "Canonical convolutional neural networks",
    "abstract": "We introduce canonical weight normalization for convolutional neural\nnetworks. Inspired by the canonical tensor decomposition, we express the weight\ntensors in so-called canonical networks as scaled sums of outer vector\nproducts. In particular, we train network weights in the decomposed form, where\nscale weights are optimized separately for each mode. Additionally, similarly\nto weight normalization, we include a global scaling parameter. We study the\ninitialization of the canonical form by running the power method and by drawing\nrandomly from Gaussian or uniform distributions. Our results indicate that we\ncan replace the power method with cheaper initializations drawn from standard\ndistributions. The canonical re-parametrization leads to competitive\nnormalization performance on the MNIST, CIFAR10, and SVHN data sets. Moreover,\nthe formulation simplifies network compression. Once training has converged,\nthe canonical form allows convenient model-compression by truncating the\nparameter sums.",
    "descriptor": "\nComments: Source code available at this https URL\n",
    "authors": [
      "Lokesh Veeramacheneni",
      "Moritz Wolter",
      "Reinhard Klein",
      "Jochen Garcke"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01509"
  },
  {
    "id": "arXiv:2206.01512",
    "title": "Latent Topology Induction for Understanding Contextualized  Representations",
    "abstract": "In this work, we study the representation space of contextualized embeddings\nand gain insight into the hidden topology of large language models. We show\nthere exists a network of latent states that summarize linguistic properties of\ncontextualized representations. Instead of seeking alignments to existing\nwell-defined annotations, we infer this latent network in a fully unsupervised\nway using a structured variational autoencoder. The induced states not only\nserve as anchors that mark the topology (neighbors and connectivity) of the\nrepresentation manifold but also reveal the internal mechanism of encoding\nsentences. With the induced network, we: (1). decompose the representation\nspace into a spectrum of latent states which encode fine-grained word meanings\nwith lexical, morphological, syntactic and semantic information; (2). show\nstate-state transitions encode rich phrase constructions and serve as the\nbackbones of the latent space. Putting the two together, we show that sentences\nare represented as a traversal over the latent network where state-state\ntransition chains encode syntactic templates and state-word emissions fill in\nthe content. We demonstrate these insights with extensive experiments and\nvisualizations.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Yao Fu",
      "Mirella Lapata"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.01512"
  },
  {
    "id": "arXiv:2206.01515",
    "title": "Understanding deep learning via decision boundary",
    "abstract": "This paper discovers that the neural network with lower decision boundary\n(DB) variability has better generalizability. Two new notions, algorithm DB\nvariability and $(\\epsilon, \\eta)$-data DB variability, are proposed to measure\nthe decision boundary variability from the algorithm and data perspectives.\nExtensive experiments show significant negative correlations between the\ndecision boundary variability and the generalizability. From the theoretical\nview, two lower bounds based on algorithm DB variability are proposed and do\nnot explicitly depend on the sample size. We also prove an upper bound of order\n$\\mathcal{O}\\left(\\frac{1}{\\sqrt{m}}+\\epsilon+\\eta\\log\\frac{1}{\\eta}\\right)$\nbased on data DB variability. The bound is convenient to estimate without the\nrequirement of labels, and does not explicitly depend on the network size which\nis usually prohibitively large in deep learning.",
    "descriptor": "\nComments: 23 pages, 7 figures\n",
    "authors": [
      "Shiye Lei",
      "Fengxiang He",
      "Yancheng Yuan",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.01515"
  },
  {
    "id": "arXiv:2206.01517",
    "title": "GraphDistNet: A Graph-based Collision-distance Estimator for  Gradient-based Trajectory",
    "abstract": "Trajectory optimization (TO) aims to find a sequence of valid states while\nminimizing costs. However, its fine validation process is often costly due to\ncomputationally expensive collision searches, otherwise coarse searches lower\nthe safety of the system losing a precise solution. To resolve the issues, we\nintroduce a new collision-distance estimator, GraphDistNet, that can precisely\nencode the structural information between two geometries by leveraging edge\nfeature-based convolutional operations, and also efficiently predict a batch of\ncollision distances and gradients through 25,000 random environments with a\nmaximum of 20 unforeseen objects. Further, we show the adoption of attention\nmechanism enables our method to be easily generalized in unforeseen complex\ngeometries toward TO. Our evaluation show GraphDistNet outperforms\nstate-of-the-art baseline methods in both simulated and real world tasks.",
    "descriptor": "\nComments: 8 pages, 7 figures, submitted to RA-L with IROS 2022 Option\n",
    "authors": [
      "Yeseung Kim",
      "Jinwoo Kim",
      "Daehyung Park"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.01517"
  },
  {
    "id": "arXiv:2206.01520",
    "title": "A Survey on Surrogate-assisted Efficient Neural Architecture Search",
    "abstract": "Neural architecture search (NAS) has become increasingly popular in the deep\nlearning community recently, mainly because it can provide an opportunity to\nallow interested users without rich expertise to benefit from the success of\ndeep neural networks (DNNs). However, NAS is still laborious and time-consuming\nbecause a large number of performance estimations are required during the\nsearch process of NAS, and training DNNs is computationally intensive. To solve\nthe major limitation of NAS, improving the efficiency of NAS is essential in\nthe design of NAS. This paper begins with a brief introduction to the general\nframework of NAS. Then, the methods for evaluating network candidates under the\nproxy metrics are systematically discussed. This is followed by a description\nof surrogate-assisted NAS, which is divided into three different categories,\nnamely Bayesian optimization for NAS, surrogate-assisted evolutionary\nalgorithms for NAS, and MOP for NAS. Finally, remaining challenges and open\nresearch questions are discussed, and promising research topics are suggested\nin this emerging field.",
    "descriptor": "\nComments: 17 pages, 7 figures\n",
    "authors": [
      "Shiqing Liu",
      "Haoyu Zhang",
      "Yaochu Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.01520"
  },
  {
    "id": "arXiv:2206.01523",
    "title": "A High-Performance Customer Churn Prediction System based on  Self-Attention",
    "abstract": "Customer churn prediction is a challenging domain of research that\ncontributes to customer retention strategy. The predictive performance of\nexisting machine learning models, which are often adopted by churn communities,\nappear to be at a bottleneck, partly due to models' poor feature extraction\ncapability. Therefore, a novel algorithm, a hybrid neural network with\nself-attention enhancement (HNNSAE), is proposed in this paper to improve the\nefficiency of feature screening and feature extraction, consequently improving\nthe model's predictive performance. This model consists of three main blocks.\nThe first block is the entity embedding layer, which is employed to process the\ncategorical variables transformed into 0-1 code. The second block is the\nfeature extractor, which extracts the significant features through the\nmulti-head self-attention mechanism. In addition, to improve the feature\nextraction effect, we stack the residual connection neural network on\nmulti-head self-attention modules. The third block is a classifier, which is a\nthree-layer multilayer perceptron. This work conducts experiments on publicly\navailable dataset related to commercial bank customers. The result demonstrates\nthat HNNSAE significantly outperforms the other Individual Machine Learning\n(IML), Ensemble Machine Learning (EML), and Deep Learning (DL) methods tested\nin this paper. Furthermore, we compare the performance of the feature extractor\nproposed in this paper with that of other three feature extractors and find\nthat the method proposed in this paper significantly outperforms other methods.\nIn addition, four hypotheses about model prediction performance and overfitting\nrisk are tested on the publicly available dataset.",
    "descriptor": "\nComments: 34 pages, 12 figures\n",
    "authors": [
      "Haotian Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01523"
  },
  {
    "id": "arXiv:2206.01524",
    "title": "Anomaly detection in surveillance videos using transformer based  attention model",
    "abstract": "Surveillance footage can catch a wide range of realistic anomalies. This\nresearch suggests using a weakly supervised strategy to avoid annotating\nanomalous segments in training videos, which is time consuming. In this\napproach only video level labels are used to obtain frame level anomaly scores.\nWeakly supervised video anomaly detection (WSVAD) suffers from the wrong\nidentification of abnormal and normal instances during the training process.\nTherefore it is important to extract better quality features from the available\nvideos. WIth this motivation, the present paper uses better quality\ntransformer-based features named Videoswin Features followed by the attention\nlayer based on dilated convolution and self attention to capture long and short\nrange dependencies in temporal domain. This gives us a better understanding of\navailable videos. The proposed framework is validated on real-world dataset\ni.e. ShanghaiTech Campus dataset which results in competitive performance than\ncurrent state-of-the-art methods. The model and the code are available at\nhttps://github.com/kapildeshpande/Anomaly-Detection-in-Surveillance-Videos",
    "descriptor": "",
    "authors": [
      "Kapil Deshpande",
      "Narinder Singh Punn",
      "Sanjay Kumar Sonbhadra",
      "Sonali Agarwal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01524"
  },
  {
    "id": "arXiv:2206.01532",
    "title": "Acquiring and Modelling Abstract Commonsense Knowledge via  Conceptualization",
    "abstract": "Conceptualization, or viewing entities and situations as instances of\nabstract concepts in mind and making inferences based on that, is a vital\ncomponent in human intelligence for commonsense reasoning. Although recent\nartificial intelligence has made progress in acquiring and modelling\ncommonsense, attributed to large neural language models and commonsense\nknowledge graphs (CKGs), conceptualization is yet to thoroughly be introduced,\nmaking current approaches ineffective to cover knowledge about countless\ndiverse entities and situations in the real world. To address the problem, we\nthoroughly study the possible role of conceptualization in commonsense\nreasoning, and formulate a framework to replicate human conceptual induction\nfrom acquiring abstract knowledge about abstract concepts. Aided by the\ntaxonomy Probase, we develop tools for contextualized conceptualization on\nATOMIC, a large-scale human annotated CKG. We annotate a dataset for the\nvalidity of conceptualizations for ATOMIC on both event and triple level,\ndevelop a series of heuristic rules based on linguistic features, and train a\nset of neural models, so as to generate and verify abstract knowledge. Based on\nthese components, a pipeline to acquire abstract knowledge is built. A large\nabstract CKG upon ATOMIC is then induced, ready to be instantiated to infer\nabout unseen entities or situations. Furthermore, experiments find directly\naugmenting data with abstract triples to be helpful in commonsense modelling.",
    "descriptor": "\nComments: 36 pages, 11 figures\n",
    "authors": [
      "Mutian He",
      "Tianqing Fang",
      "Weiqi Wang",
      "Yangqiu Song"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.01532"
  },
  {
    "id": "arXiv:2206.01535",
    "title": "Rethinking and Scaling Up Graph Contrastive Learning: An Extremely  Efficient Approach with Group Discrimination",
    "abstract": "Graph contrastive learning (GCL) alleviates the heavy reliance on label\ninformation for graph representation learning (GRL) via self-supervised\nlearning schemes. The core idea is to learn by maximising mutual information\nfor similar instances, which requires similarity computation between two node\ninstances. However, this operation can be computationally expensive. For\nexample, the time complexity of two commonly adopted contrastive loss functions\n(i.e., InfoNCE and JSD estimator) for a node is $O(ND)$ and $O(D)$,\nrespectively, where $N$ is the number of nodes, and $D$ is the embedding\ndimension. Additionally, GCL normally requires a large number of training\nepochs to be well-trained on large-scale datasets. Inspired by an observation\nof a technical defect (i.e., inappropriate usage of Sigmoid function) commonly\nused in two representative GCL works, DGI and MVGRL, we revisit GCL and\nintroduce a new learning paradigm for self-supervised GRL, namely, Group\nDiscrimination (GD), and propose a novel GD-based method called Graph Group\nDiscrimination (GGD). Instead of similarity computation, GGD directly\ndiscriminates two groups of summarised node instances with a simple binary\ncross-entropy loss. As such, GGD only requires $O(1)$ for loss computation of a\nnode. In addition, GGD requires much fewer training epochs to obtain\ncompetitive performance compared with GCL methods on large-scale datasets.\nThese two advantages endow GGD with the very efficient property. Extensive\nexperiments show that GGD outperforms state-of-the-art self-supervised methods\non 8 datasets. In particular, GGD can be trained in 0.18 seconds (6.44 seconds\nincluding data preprocessing) on ogbn-arxiv, which is orders of magnitude\n(10,000+ faster than GCL baselines} while consuming much less memory. Trained\nwith 9 hours on ogbn-papers100M with billion edges, GGD outperforms its GCL\ncounterparts in both accuracy and efficiency.",
    "descriptor": "",
    "authors": [
      "Yizhen Zheng",
      "Shirui Pan",
      "Vincent Cs Lee",
      "Yu Zheng",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.01535"
  },
  {
    "id": "arXiv:2206.01538",
    "title": "Accelerating hydrodynamic simulations of urban drainage systems with  physics-guided machine learning",
    "abstract": "We propose and demonstrate a new approach for fast and accurate surrogate\nmodelling of urban drainage system hydraulics based on physics-guided machine\nlearning. The surrogates are trained against a limited set of simulation\nresults from a hydrodynamic (HiFi) model. Our approach reduces simulation times\nby one to two orders of magnitude compared to a HiFi model. It is thus slower\nthan e.g. conceptual hydrological models, but it enables simulations of water\nlevels, flows and surcharges in all nodes and links of a drainage network and\nthus largely preserves the level of detail provided by HiFi models. Comparing\ntime series simulated by the surrogate and the HiFi model, R2 values in the\norder of 0.9 are achieved. Surrogate training times are currently in the order\nof one hour. However, they can likely be reduced through the application of\ntransfer learning and graph neural networks. Our surrogate approach will be\nuseful for interactive workshops in initial design phases of urban drainage\nsystems, as well as for real time applications. In addition, our model\nformulation is generic and future research should investigate its application\nfor simulating other water systems.",
    "descriptor": "",
    "authors": [
      "Rocco Palmitessa",
      "Morten Grum",
      "Allan Peter Engsig-Karup",
      "Roland L\u00f6we"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2206.01538"
  },
  {
    "id": "arXiv:2206.01541",
    "title": "A robust solution strategy for the Cahn-Larch\u00e9 equations",
    "abstract": "In this paper we propose a solution strategy for the Cahn-Larch\\'e equations,\nwhich is a model for linearized elasticity in a medium with two elastic phases\nthat evolve subject to a Ginzburg-Landau type energy functional. The system can\nbe seen as a combination of the Cahn-Hilliard regularized interface equation\nand linearized elasticity, and is non-linearly coupled, has a fourth order term\nthat comes from the Cahn-Hilliard subsystem, and is non-convex and nonlinear in\nboth the phase-field and displacement variables. We propose a novel\nsemi-implicit discretization in time that uses a standard convex-concave\nsplitting method of the nonlinear double-well potential, as well as special\ntreatment to the elastic energy. We show that the resulting discrete system is\nequivalent to a convex minimization problem, and propose and prove the\nconvergence of alternating minimization applied to it. Finally, we present\nnumerical experiments that show the robustness and effectiveness of both\nalternating minimization and the monolithic Newton method applied to the newly\nproposed discrete system of equations. We compare it to a system of equations\nthat has been discretized with a standard convex-concave splitting of the\ndouble-well potential, and implicit evaluations of the elasticity contributions\nand show that the newly proposed discrete system is better conditioned for\nlinearization techniques.",
    "descriptor": "",
    "authors": [
      "Erlend Storvik",
      "Jakub Wiktor Both",
      "Jan Martin Nordbotten",
      "Florin Adrian Radu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.01541"
  },
  {
    "id": "arXiv:2206.01542",
    "title": "Detecting the Severity of Major Depressive Disorder from Speech: A Novel  HARD-Training Methodology",
    "abstract": "Major Depressive Disorder (MDD) is a common worldwide mental health issue\nwith high associated socioeconomic costs. The prediction and automatic\ndetection of MDD can, therefore, make a huge impact on society. Speech, as a\nnon-invasive, easy to collect signal, is a promising marker to aid the\ndiagnosis and assessment of MDD. In this regard, speech samples were collected\nas part of the Remote Assessment of Disease and Relapse in Major Depressive\nDisorder (RADAR-MDD) research programme. RADAR-MDD was an observational cohort\nstudy in which speech and other digital biomarkers were collected from a cohort\nof individuals with a history of MDD in Spain, United Kingdom and the\nNetherlands. In this paper, the RADAR-MDD speech corpus was taken as an\nexperimental framework to test the efficacy of a Sequence-to-Sequence model\nwith a local attention mechanism in a two-class depression severity\nclassification paradigm. Additionally, a novel training method, HARD-Training,\nis proposed. It is a methodology based on the selection of more ambiguous\nsamples for the model training, and inspired by the curriculum learning\nparadigm. HARD-Training was found to consistently improve - with an average\nincrement of 8.6% - the performance of our classifiers for both of two speech\nelicitation tasks used and each collection site of the RADAR-MDD speech corpus.\nWith this novel methodology, our Sequence-to-Sequence model was able to\neffectively detect MDD severity regardless of language. Finally, recognising\nthe need for greater awareness of potential algorithmic bias, we conduct an\nadditional analysis of our results separately for each gender.",
    "descriptor": "",
    "authors": [
      "Edward L. Campbell",
      "Judith Dineley",
      "Pauline Conde",
      "Faith Matcham",
      "Femke Lamers",
      "Sara Siddi",
      "Laura Docio-Fernandez",
      "Carmen Garcia-Mateo",
      "Nicholas Cummins",
      "RADAR-CNS Consortium"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2206.01542"
  },
  {
    "id": "arXiv:2206.01543",
    "title": "Beyond Opinion Mining: Summarizing Opinions of Customer Reviews",
    "abstract": "Customer reviews are vital for making purchasing decisions in the Information\nAge. Such reviews can be automatically summarized to provide the user with an\noverview of opinions. In this tutorial, we present various aspects of opinion\nsummarization that are useful for researchers and practitioners. First, we will\nintroduce the task and major challenges. Then, we will present existing opinion\nsummarization solutions, both pre-neural and neural. We will discuss how\nsummarizers can be trained in the unsupervised, few-shot, and supervised\nregimes. Each regime has roots in different machine learning methods, such as\nauto-encoding, controllable text generation, and variational inference.\nFinally, we will discuss resources and evaluation methods and conclude with the\nfuture directions. This three-hour tutorial will provide a comprehensive\noverview over major advances in opinion summarization. The listeners will be\nwell-equipped with the knowledge that is both useful for research and practical\napplications.",
    "descriptor": "\nComments: SIGIR Tutorial 2022\n",
    "authors": [
      "Reinald Kim Amplayo",
      "Arthur Bra\u017einskas",
      "Yoshi Suhara",
      "Xiaolan Wang",
      "Bing Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01543"
  },
  {
    "id": "arXiv:2206.01545",
    "title": "Truly Mesh-free Physics-Informed Neural Networks",
    "abstract": "Physics-informed Neural Networks (PINNs) have recently emerged as a\nprincipled way to include prior physical knowledge in form of partial\ndifferential equations (PDEs) into neural networks. Although generally viewed\nas being mesh-free, current approaches still rely on collocation points\nobtained within a bounded region, even in settings with spatially sparse\nsignals. Furthermore, if the boundaries are not known, the selection of such a\nregion may be arbitrary, resulting in a large proportion of collocation points\nbeing selected in areas of low relevance. To resolve this, we present a\nmesh-free and adaptive approach termed particle-density PINN (pdPINN), which is\ninspired by the microscopic viewpoint of fluid dynamics. Instead of sampling\nfrom a bounded region, we propose to sample directly from the distribution over\nthe (fluids) particle positions, eliminating the need to introduce boundaries\nwhile adaptively focusing on the most relevant regions. This is achieved by\nreformulating the modeled fluid density as an unnormalized probability\ndistribution from which we sample with dynamic Monte Carlo methods. We further\ngeneralize pdPINNs to different settings that allow interpreting a positive\nscalar quantity as a particle density, such as the evolution of the temperature\nin the heat equation. The utility of our approach is demonstrated on\nexperiments for modeling (non-steady) compressible fluids in up to three\ndimensions and a two-dimensional diffusion problem, illustrating the high\nflexibility and sample efficiency compared to existing refinement methods for\nPINNs.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Fabricio Arend Torres",
      "Marcello Massimo Negri",
      "Monika Nagy-Huber",
      "Maxim Samarin",
      "Volker Roth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.01545"
  },
  {
    "id": "arXiv:2206.01547",
    "title": "Understanding NVMe Zoned Namespace (ZNS) Flash SSD Storage Devices",
    "abstract": "The standardization of NVMe Zoned Namespaces (ZNS) in the NVMe 2.0\nspecification presents a unique new addition to storage devices. Unlike\ntraditional SSDs, where the flash media management idiosyncrasies are hidden\nbehind a flash translation layer (FTL) inside the device, ZNS devices push\ncertain operations regarding data placement and garbage collection out from the\ndevice to the host. This allows the host to achieve more optimal data placement\nand predictable garbage collection overheads, along with lower device write\namplification. Thus, additionally increasing flash media lifetime. As a result,\nZNS devices are gaining significant attention in the research community.\nHowever, with the current software stack there are numerous ways of\nintegrating ZNS devices into a host system. In this work, we begin to\nsystematically analyze the integration options, report on the current software\nsupport for ZNS devices in the Linux Kernel, and provide an initial set of\nperformance measurements. Our main findings show that larger I/O sizes are\nrequired to saturate the ZNS device bandwidth, and configuration of the I/O\nscheduler can provide workload dependent performance gains, requiring careful\nconsideration of ZNS integration and configuration depending on the application\nworkload and its access patterns. Our dataset and code are available at https:\n//github.com/nicktehrany/ZNS-Study.",
    "descriptor": "",
    "authors": [
      "Nick Tehrany",
      "Animesh Trivedi"
    ],
    "subjectives": [
      "Operating Systems (cs.OS)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2206.01547"
  },
  {
    "id": "arXiv:2206.01550",
    "title": "TCE at Qur'an QA 2022: Arabic Language Question Answering Over Holy  Qur'an Using a Post-Processed Ensemble of BERT-based Models",
    "abstract": "In recent years, we witnessed great progress in different tasks of natural\nlanguage understanding using machine learning. Question answering is one of\nthese tasks which is used by search engines and social media platforms for\nimproved user experience. Arabic is the language of the Holy Qur'an; the sacred\ntext for 1.8 billion people across the world. Arabic is a challenging language\nfor Natural Language Processing (NLP) due to its complex structures. In this\narticle, we describe our attempts at OSACT5 Qur'an QA 2022 Shared Task, which\nis a question answering challenge on the Holy Qur'an in Arabic. We propose an\nensemble learning model based on Arabic variants of BERT models. In addition,\nwe perform post-processing to enhance the model predictions. Our system\nachieves a Partial Reciprocal Rank (pRR) score of 56.6% on the official test\nset.",
    "descriptor": "\nComments: OSACT5 workshop, Qur'an QA 2022 Shared Task participation by TCE\n",
    "authors": [
      "Mohammed ElKomy",
      "Amany M. Sarhan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.01550"
  },
  {
    "id": "arXiv:2206.01552",
    "title": "Is an encoder within reach?",
    "abstract": "The encoder network of an autoencoder is an approximation of the nearest\npoint projection onto the manifold spanned by the decoder. A concern with this\napproximation is that, while the output of the encoder is always unique, the\nprojection can possibly have infinitely many values. This implies that the\nlatent representations learned by the autoencoder can be misleading. Borrowing\nfrom geometric measure theory, we introduce the idea of using the reach of the\nmanifold spanned by the decoder to determine if an optimal encoder exists for a\ngiven dataset and decoder. We develop a local generalization of this reach and\npropose a numerical estimator thereof. We demonstrate that this allows us to\ndetermine which observations can be expected to have a unique, and thereby\ntrustworthy, latent representation. As our local reach estimator is\ndifferentiable, we investigate its usage as a regularizer and show that this\nleads to learned manifolds for which projections are more often unique than\nwithout regularization.",
    "descriptor": "\nComments: 11 pages, 6 figures\n",
    "authors": [
      "Helene Hauschultz",
      "Rasmus Berg Palm. Pablo Moreno-Mu\u00f1os",
      "Nicki Skafte Detlefsen",
      "Andrew Allan du Plessis",
      "S\u00f8ren Hauberg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01552"
  },
  {
    "id": "arXiv:2206.01558",
    "title": "Disentangling Epistemic and Aleatoric Uncertainty in Reinforcement  Learning",
    "abstract": "Characterizing aleatoric and epistemic uncertainty on the predicted rewards\ncan help in building reliable reinforcement learning (RL) systems. Aleatoric\nuncertainty results from the irreducible environment stochasticity leading to\ninherently risky states and actions. Epistemic uncertainty results from the\nlimited information accumulated during learning to make informed decisions.\nCharacterizing aleatoric and epistemic uncertainty can be used to speed up\nlearning in a training environment, improve generalization to similar testing\nenvironments, and flag unfamiliar behavior in anomalous testing environments.\nIn this work, we introduce a framework for disentangling aleatoric and\nepistemic uncertainty in RL. (1) We first define four desiderata that capture\nthe desired behavior for aleatoric and epistemic uncertainty estimation in RL\nat both training and testing time. (2) We then present four RL models inspired\nby supervised learning (i.e. Monte Carlo dropout, ensemble, deep kernel\nlearning models, and evidential networks) to instantiate aleatoric and\nepistemic uncertainty. Finally, (3) we propose a practical evaluation method to\nevaluate uncertainty estimation in model-free RL based on detection of\nout-of-distribution environments and generalization to perturbed environments.\nWe present theoretical and experimental evidence to validate that carefully\nequipping model-free RL agents with supervised learning uncertainty methods can\nfulfill our desiderata.",
    "descriptor": "",
    "authors": [
      "Bertrand Charpentier",
      "Ransalu Senanayake",
      "Mykel Kochenderfer",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01558"
  },
  {
    "id": "arXiv:2206.01559",
    "title": "Root of Unity for Secure Distributed Matrix Multiplication: Grid  Partition Case",
    "abstract": "We consider the problem of secure distributed matrix multiplication (SDMM),\nwhere a user has two matrices and wishes to compute their product with the help\nof $N$ honest but curious servers under the security constraint that any\ninformation about either $A$ or $B$ is not leaked to any server. This paper\npresents a \\emph{new scheme} that considers a grid product partition for\nmatrices $A$ and $B$, which achieves an upload cost significantly lower than\nthe existing results in the literature. Since the grid partition is a general\npartition that incorporates the inner and outer ones, it turns out that the\ncommunication load of the proposed scheme matches the best-known protocols for\nthose extreme cases.",
    "descriptor": "",
    "authors": [
      "Roberto Assis Machado",
      "Felice Manganiello"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.01559"
  },
  {
    "id": "arXiv:2206.01563",
    "title": "Optimal Weak to Strong Learning",
    "abstract": "The classic algorithm AdaBoost allows to convert a weak learner, that is an\nalgorithm that produces a hypothesis which is slightly better than chance, into\na strong learner, achieving arbitrarily high accuracy when given enough\ntraining data. We present a new algorithm that constructs a strong learner from\na weak learner but uses less training data than AdaBoost and all other weak to\nstrong learners to achieve the same generalization bounds. A sample complexity\nlower bound shows that our new algorithm uses the minimum possible amount of\ntraining data and is thus optimal. Hence, this work settles the sample\ncomplexity of the classic problem of constructing a strong learner from a weak\nlearner.",
    "descriptor": "",
    "authors": [
      "Kasper Green Larsen",
      "Martin Ritzert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.01563"
  },
  {
    "id": "arXiv:2206.01566",
    "title": "Hyperownership: Beyond the Current State of Interaction with Digital  Property",
    "abstract": "The introduction of novel technology has oftentimes changed the concept of\nownership. Non-fungible tokens are a recent example, as they allow a\ndecentralized way to generate and verify proof of ownership via distributed\nledger technology. Despite crucial uncertainties, these tokens have generated\ngreat enthusiasm for the future of digital property and its surrounding\neconomy. In this regard, I think there is an untapped opportunity in applying a\nhypertext approach to augment such highly structured ownership-based\nassociations. To this end, in this work I propose hyperownership, based on the\npremises that property is the law of lists and ledgers, and that hypertext is\nan apt method to inquiry such a ledger system. In spite of the significant\nrisks and challenges to realize such a vision, I believe that it has great\npotential to transform the way with which we interact with digital property.",
    "descriptor": "\nComments: Accepted Blue Sky Idea in the 33rd ACM Conference on Hypertext and Social Media (HT '22)\n",
    "authors": [
      "Amaury Trujillo"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.01566"
  },
  {
    "id": "arXiv:2206.01567",
    "title": "Energy-Efficient Resource Allocation for Aggregated RF/VLC Systems",
    "abstract": "Visible light communication (VLC) is envisioned as a core component of future\nwireless communication networks due to, among others, the huge unlicensed\nbandwidth it offers and the fact that it does not cause any interference to\nexisting radio frequency (RF) communication systems. Most research on RF and\nVLC coexistence has focused on hybrid designs where data transmission to any\nuser could originate from either an RF or a VLC access point (AP). However,\nhybrid RF/VLC systems fail to exploit the distinct transmission characteristics\nof RF and VLC systems to fully reap the benefits they can offer. Aggregated\nRF/VLC systems, in which any user can be served simultaneously by both RF and\nVLC APs, have recently emerged as a more promising and robust design for the\ncoexistence of RF and VLC systems. To this end, this paper, for the first time,\ninvestigates AP assignment, subchannel allocation (SA), and transmit power\nallocation (PA) to optimize the energy efficiency (EE) of aggregated RF/VLC\nsystems while considering the effects of interference and VLC line-of-sight\nlink blockages. A novel and challenging EE optimization problem is formulated\nfor which an efficient joint solution based on alternating optimization is\ndeveloped. More particularly, an energy-efficient AP assignment algorithm based\non matching theory is proposed. Then, a low-complexity SA scheme that allocates\nsubchannels to users based on their channel conditions is developed. Finally,\nan effective PA algorithm is presented by utilizing the quadratic transform\napproach and a multi-objective optimization framework. Extensive simulation\nresults reveal that: 1) the proposed joint AP assignment, SA, and PA solution\nobtains significant EE, sum-rate, and outage performance gains with low\ncomplexity, and 2) the aggregated RF/VLC system provides considerable\nperformance improvement compared to hybrid RF/VLC systems.",
    "descriptor": "\nComments: 30 pages, 11 figures, 1 table\n",
    "authors": [
      "Sylvester Aboagye",
      "Telex M. N. Ngatched",
      "Octavia A. Dobre",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.01567"
  },
  {
    "id": "arXiv:2206.01568",
    "title": "Improved Deterministic Connectivity in Massively Parallel Computation",
    "abstract": "A long line of research about connectivity in the Massively Parallel\nComputation model has culminated in the seminal works of Andoni et al.\n[FOCS'18] and Behnezhad et al. [FOCS'19]. They provide a randomized algorithm\nfor low-space MPC with conjectured to be optimal round complexity $O(\\log D +\n\\log \\log_{\\frac m n} n)$ and $O(m)$ space, for graphs on $n$ vertices with $m$\nedges and diameter $D$. Surprisingly, a recent result of Coy and Czumaj\n[STOC'22] shows how to achieve the same deterministically. Unfortunately,\nhowever, their algorithm suffers from large local computation time. We present\na deterministic connectivity algorithm that matches all the parameters of the\nrandomized algorithm and, in addition, significantly reduces the local\ncomputation time to nearly linear. Our derandomization method is based on\nreducing the amount of randomness needed to allow for a simpler efficient\nsearch. While similar randomness reduction approaches have been used before,\nour result is not only strikingly simpler, but it is the first to have\nefficient local computation. This is why we believe it to serve as a starting\npoint for the systematic development of computation-efficient derandomization\napproaches in low-memory MPC.",
    "descriptor": "",
    "authors": [
      "Manuela Fischer",
      "Jeff Giliberti",
      "Christoph Grunau"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.01568"
  },
  {
    "id": "arXiv:2206.01570",
    "title": "On Calibration of Graph Neural Networks for Node Classification",
    "abstract": "Graphs can model real-world, complex systems by representing entities and\ntheir interactions in terms of nodes and edges. To better exploit the graph\nstructure, graph neural networks have been developed, which learn entity and\nedge embeddings for tasks such as node classification and link prediction.\nThese models achieve good performance with respect to accuracy, but the\nconfidence scores associated with the predictions might not be calibrated. That\nmeans that the scores might not reflect the ground-truth probabilities of the\npredicted events, which would be especially important for safety-critical\napplications. Even though graph neural networks are used for a wide range of\ntasks, the calibration thereof has not been sufficiently explored yet. We\ninvestigate the calibration of graph neural networks for node classification,\nstudy the effect of existing post-processing calibration methods, and analyze\nthe influence of model capacity, graph density, and a new loss function on\ncalibration. Further, we propose a topology-aware calibration method that takes\nthe neighboring nodes into account and yields improved calibration compared to\nbaseline methods.",
    "descriptor": "\nComments: Accepted by IJCNN 2022 (IEEE WCCI 2022)\n",
    "authors": [
      "Tong Liu",
      "Yushan Liu",
      "Marcel Hildebrandt",
      "Mitchell Joblin",
      "Hang Li",
      "Volker Tresp"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01570"
  },
  {
    "id": "arXiv:2206.01583",
    "title": "Findings of the The RuATD Shared Task 2022 on Artificial Text Detection  in Russian",
    "abstract": "We present the shared task on artificial text detection in Russian, which is\norganized as a part of the Dialogue Evaluation initiative, held in 2022. The\nshared task dataset includes texts from 14 text generators, i.e., one human\nwriter and 13 text generative models fine-tuned for one or more of the\nfollowing generation tasks: machine translation, paraphrase generation, text\nsummarization, text simplification. We also consider back-translation and\nzero-shot generation approaches. The human-written texts are collected from\npublicly available resources across multiple domains. The shared task consists\nof two sub-tasks: (i) to determine if a given text is automatically generated\nor written by a human; (ii) to identify the author of a given text. The first\ntask is framed as a binary classification problem. The second task is a\nmulti-class classification problem. We provide count-based and BERT-based\nbaselines, along with the human evaluation on the first sub-task. A total of 30\nand 8 systems have been submitted to the binary and multi-class sub-tasks,\ncorrespondingly. Most teams outperform the baselines by a wide margin. We\npublicly release our codebase, human evaluation results, and other materials in\nour GitHub repository (https://github.com/dialogue-evaluation/RuATD).",
    "descriptor": "\nComments: Accepted to Dialogue-22\n",
    "authors": [
      "Tatiana Shamardina",
      "Vladislav Mikhailov",
      "Daniil Chernianskii",
      "Alena Fenogenova",
      "Marat Saidov",
      "Anastasiya Valeeva",
      "Tatiana Shavrina",
      "Ivan Smurov",
      "Elena Tutubalina",
      "Ekaterina Artemova"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.01583"
  },
  {
    "id": "arXiv:2206.01585",
    "title": "Extracting Similar Questions From Naturally-occurring Business  Conversations",
    "abstract": "Pre-trained contextualized embedding models such as BERT are a standard\nbuilding block in many natural language processing systems. We demonstrate that\nthe sentence-level representations produced by some off-the-shelf\ncontextualized embedding models have a narrow distribution in the embedding\nspace, and thus perform poorly for the task of identifying semantically similar\nquestions in real-world English business conversations. We describe a method\nthat uses appropriately tuned representations and a small set of exemplars to\ngroup questions of interest to business users in a visualization that can be\nused for data exploration or employee coaching.",
    "descriptor": "",
    "authors": [
      "Xiliang Zhu",
      "David Rossouw",
      "Shayna Gardiner",
      "Simon Corston-Oliver"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.01585"
  },
  {
    "id": "arXiv:2206.01587",
    "title": "Employing Socially Interactive Agents for Robotic Neurorehabilitation  Training",
    "abstract": "In today's world, many patients with cognitive impairments and motor\ndysfunction seek the attention of experts to perform specific conventional\ntherapies to improve their situation. However, due to a lack of\nneurorehabilitation professionals, patients suffer from severe effects that\nworsen their condition. In this paper, we present a technological approach for\na novel robotic neurorehabilitation training system. It relies on a combination\nof a rehabilitation device, signal classification methods, supervised machine\nlearning models for training adaptation, training exercises, and socially\ninteractive agents as a user interface. Together with a professional, the\nsystem can be trained towards the patient's specific needs. Furthermore, after\na training phase, patients are enabled to train independently at home without\nthe assistance of a physical therapist with a socially interactive agent in the\nrole of a coaching assistant.",
    "descriptor": "\nComments: The 5th Workshop on Behavior Adaptation Interaction and Learning for Assistive Robotics (BAILAR)\n",
    "authors": [
      "Rhythm Arora",
      "Matteo Lavit Nicora",
      "Pooja Prajod",
      "Daniele Panzeri",
      "Elisabeth Andr\u00e9",
      "Patrick Gebhard",
      "Matteo Malosio"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.01587"
  },
  {
    "id": "arXiv:2206.01588",
    "title": "Decentralized Optimistic Hyperpolicy Mirror Descent: Provably No-Regret  Learning in Markov Games",
    "abstract": "We study decentralized policy learning in Markov games where we control a\nsingle agent to play with nonstationary and possibly adversarial opponents. Our\ngoal is to develop a no-regret online learning algorithm that (i) takes actions\nbased on the local information observed by the agent and (ii) is able to find\nthe best policy in hindsight. For such a problem, the nonstationary state\ntransitions due to the varying opponent pose a significant challenge. In light\nof a recent hardness result \\citep{liu2022learning}, we focus on the setting\nwhere the opponent's previous policies are revealed to the agent for decision\nmaking. With such an information structure, we propose a new algorithm,\n\\underline{D}ecentralized \\underline{O}ptimistic hype\\underline{R}policy\nm\\underline{I}rror de\\underline{S}cent (DORIS), which achieves\n$\\sqrt{K}$-regret in the context of general function approximation, where $K$\nis the number of episodes. Moreover, when all the agents adopt DORIS, we prove\nthat their mixture policy constitutes an approximate coarse correlated\nequilibrium. In particular, DORIS maintains a \\textit{hyperpolicy} which is a\ndistribution over the policy space. The hyperpolicy is updated via mirror\ndescent, where the update direction is obtained by an optimistic variant of\nleast-squares policy evaluation. Furthermore, to illustrate the power of our\nmethod, we apply DORIS to constrained and vector-valued MDPs, which can be\nformulated as zero-sum Markov games with a fictitious opponent.",
    "descriptor": "",
    "authors": [
      "Wenhao Zhan",
      "Jason D. Lee",
      "Zhuoran Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.01588"
  },
  {
    "id": "arXiv:2206.01589",
    "title": "OdomBeyondVision: An Indoor Multi-modal Multi-platform Odometry Dataset  Beyond the Visible Spectrum",
    "abstract": "This paper presents a multimodal indoor odometry dataset, OdomBeyondVision,\nfeaturing multiple sensors across the different spectrum and collected with\ndifferent mobile platforms. Not only does OdomBeyondVision contain the\ntraditional navigation sensors, sensors such as IMUs, mechanical LiDAR, RGBD\ncamera, it also includes several emerging sensors such as the single-chip\nmmWave radar, LWIR thermal camera and solid-state LiDAR. With the above sensors\non UAV, UGV and handheld platforms, we respectively recorded the multimodal\nodometry data and their movement trajectories in various indoor scenes and\ndifferent illumination conditions. We release the exemplar radar,\nradar-inertial and thermal-inertial odometry implementations to demonstrate\ntheir results for future works to compare against and improve upon. The full\ndataset including toolkit and documentation is publicly available at:\nhttps://github.com/MAPS-Lab/OdomBeyondVision.",
    "descriptor": "",
    "authors": [
      "Peize Li",
      "Kaiwen Cai",
      "Muhamad Risqi U. Saputra",
      "Zhuangzhuang Dai",
      "Chris Xiaoxuan Lu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.01589"
  },
  {
    "id": "arXiv:2206.01594",
    "title": "Federating and querying heterogeneous and distributed Web APIs and  triple stores",
    "abstract": "Today's international corporations such as BASF, a leading company in the\ncrop protection industry, produce and consume more and more data that are often\nfragmented and accessible through Web APIs. In addition, part of the\nproprietary and public data of BASF's interest are stored in triple stores and\naccessible with the SPARQL query language. Homogenizing the data access modes\nand the underlying semantics of the data without modifying or replicating the\noriginal data sources become important requirements to achieve data integration\nand interoperability. In this work, we propose a federated data integration\narchitecture within an industrial setup, that relies on an ontology-based data\naccess method. Our performance evaluation in terms of query response time\nshowed that most queries can be answered in under 1 second.",
    "descriptor": "",
    "authors": [
      "Tarcisio Mendes de Farias",
      "Christophe Dessimoz",
      "Aaron Ayllon Benitez",
      "Chen Yang",
      "Jiao Long",
      "Ana-Claudia Sima"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2206.01594"
  },
  {
    "id": "arXiv:2206.01597",
    "title": "Convergence Analysis of the Deep Splitting Scheme: the Case of Partial  Integro-Differential Equations and the associated FBSDEs with Jumps",
    "abstract": "High-dimensional parabolic partial integro-differential equations (PIDEs)\nappear in many applications in insurance and finance. Existing numerical\nmethods suffer from the curse of dimensionality or provide solutions only for a\ngiven space-time point. This gave rise to a growing literature on deep learning\nbased methods for solving partial differential equations; results for\nintegro-differential equations on the other hand are scarce. In this paper we\nconsider an extension of the deep splitting scheme due to arXiv:1907.03452 and\narXiv:2006.01496v3 to PIDEs. Our main contribution is an analysis of the\napproximation error which yields convergence rates in terms of the number of\nneurons for shallow neural networks. Moreover we discuss several test case\nstudies to show the viability of our approach.",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "R\u00fcdiger Frey",
      "Verena K\u00f6ck"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2206.01597"
  },
  {
    "id": "arXiv:2206.01598",
    "title": "Moral Narratives Around the Vaccination Discourse on the Facebook  Platform",
    "abstract": "Vaccination hesitancy has been a threat to public health since a long time,\nand it is currently being fueled by the large spreading of misinformation in\nmany social media. Attitudes against vaccination usually rise around fake news\nor conspiracy theories, but according to moral psychology they are shaped by\nindividual moral preferences. The Moral Foundations Theory (MFT) explains\nindividual variations in moral preferences using five dimensions (foundations):\nharm, fairness, loyalty, authority and purity, and it has been shown that these\nfoundations underlie human judgements on politics, religion and social\ncooperation. In this work we assess the moral preferences expressed in the pro-\nand anti-vax discourses in a large dataset of Facebook comments. We show that\nsignificant differences exist in some moral dimensions between these two\ngroups, and we suggest that these differences should be taken into account when\ndesigning vaccination campaigns",
    "descriptor": "",
    "authors": [
      "Maria Florencia Prado",
      "Victoria Perez Bustos",
      "Kyriaki Kalimeri",
      "Mariano G. Beiro"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.01598"
  },
  {
    "id": "arXiv:2206.01601",
    "title": "A Hierarchical Pedestrian Behavior Model to Generate Realistic Human  Behavior in Traffic Simulation",
    "abstract": "Modelling pedestrian behavior is crucial in the development and testing of\nautonomous vehicles. In this work, we present a hierarchical pedestrian\nbehavior model that generates high-level decisions through the use of behavior\ntrees, in order to produce maneuvers executed by a low-level motion planner\nusing an adapted Social Force model. A full implementation of our work is\nintegrated into GeoScenario Server, a scenario definition and execution engine,\nextending its vehicle simulation capabilities with pedestrian simulation. The\nextended environment allows simulating test scenarios involving both vehicles\nand pedestrians to assist in the scenario-based testing process of autonomous\nvehicles. The presented hierarchical model is evaluated on two real-world data\nsets collected at separate locations with different road structures. Our model\nis shown to replicate the real-world pedestrians' trajectories with a high\ndegree of fidelity and a decision-making accuracy of 98% or better, given only\nhigh-level routing information for each pedestrian.",
    "descriptor": "\nComments: 9 pages, 4 figures, 3 tables. Accepted to the 2022 IEEE Intelligent Vehicles Symposium\n",
    "authors": [
      "Scott Larter",
      "Rodrigo Queiroz",
      "Sean Sedwards",
      "Atrisha Sarkar",
      "Krzysztof Czarnecki"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.01601"
  },
  {
    "id": "arXiv:2206.01604",
    "title": "Non-Intrusive Reduced Models based on Operator Inference for Chaotic  Systems",
    "abstract": "This work explores the physics-driven machine learning technique Operator\nInference (OpInf) for predicting the state of chaotic dynamical systems. OpInf\nprovides a non-intrusive approach to infer approximations of polynomial\noperators in reduced space without having access to the full order operators\nappearing in discretized models. Datasets for the physics systems are generated\nusing conventional numerical solvers and then projected to a low-dimensional\nspace via Principal Component Analysis (PCA). In latent space, a least-squares\nproblem is set to fit a quadratic polynomial operator which is subsequently\nemployed in a time-integration scheme in order to produce extrapolations in the\nsame space. Once solved, the inverse PCA operation is applied for\nreconstructing the extrapolations in the original space. The quality of the\nOpInf predictions is assessed via the Normalized Root Mean Squared Error\n(NRMSE) metric from which the Valid Prediction Time (VPT) is computed.\nNumerical experiments considering the chaotic systems Lorenz 96 and the\nKuramoto-Sivashinsky equation show promising forecasting capabilities of the\nOpInf reduced order models with VPT ranges that outperform state-of-the-art\nmachine learning methods such as backpropagation and reservoir computing\nrecurrent neural networks [1]. The best results based on randomized initial\nconditions show that Lorenz 96 system can be forecasted up to 6.66 or 3.19\nLyapunov time units corresponding to the forcing terms F=8 and F=10,\nrespectively, while the KS system achieved remarkable 794 Lyapunov time units.",
    "descriptor": "\nComments: 12 pages, 37 figures, submitted to IEEE-TAI-PIML\n",
    "authors": [
      "Jo\u00e3o Lucas de Sousa Almeida",
      "Arthur Cancellieri Pires",
      "Klaus Feine Vaz Cid",
      "Alberto Costa Nogueira Junior"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2206.01604"
  },
  {
    "id": "arXiv:2206.01609",
    "title": "A Comparative Study on Energy Consumption Models for Drones",
    "abstract": "Creating an appropriate energy consumption prediction model is becoming an\nimportant topic for drone-related research in the literature. However, a\ngeneral consensus on the energy consumption model is yet to be reached at\npresent. As a result, there are many variations that attempt to create models\nthat range in complexity with a focus on different aspects. In this paper, we\nbenchmark the five most popular energy consumption models for drones derived\nfrom their physical behaviours and point to the difficulties in matching with a\nrealistic energy dataset collected from a delivery drone in flight under\ndifferent testing conditions. Moreover, we propose a novel data-driven energy\nmodel using the Long Short-Term Memory (LSTM) based deep learning architecture\nand the accuracy is compared based on the dataset. Our experimental results\nhave shown that the LSTM based approach can easily outperform other\nmathematical models for the dataset under study. Finally, sensitivity analysis\nhas been carried out in order to interpret the model.",
    "descriptor": "\nComments: Accepted at Global IoT Summit 2022 Conference\n",
    "authors": [
      "Carlos Muli",
      "Sangyoung Park",
      "Mingming Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01609"
  },
  {
    "id": "arXiv:2206.01612",
    "title": "OmniXAI: A Library for Explainable AI",
    "abstract": "We introduce OmniXAI, an open-source Python library of eXplainable AI (XAI),\nwhich offers omni-way explainable AI capabilities and various interpretable\nmachine learning techniques to address the pain points of understanding and\ninterpreting the decisions made by machine learning (ML) in practice. OmniXAI\naims to be a one-stop comprehensive library that makes explainable AI easy for\ndata scientists, ML researchers and practitioners who need explanation for\nvarious types of data, models and explanation methods at different stages of ML\nprocess (data exploration, feature engineering, model development, evaluation,\nand decision-making, etc). In particular, our library includes a rich family of\nexplanation methods integrated in a unified interface, which supports multiple\ndata types (tabular data, images, texts, time-series), multiple types of ML\nmodels (traditional ML in Scikit-learn and deep learning models in\nPyTorch/TensorFlow), and a range of diverse explanation methods including\n\"model-specific\" and \"model-agnostic\" ones (such as feature-attribution\nexplanation, counterfactual explanation, gradient-based explanation, etc). For\npractitioners, the library provides an easy-to-use unified interface to\ngenerate the explanations for their applications by only writing a few lines of\ncodes, and also a GUI dashboard for visualization of different explanations for\nmore insights about decisions. In this technical report, we present OmniXAI's\ndesign principles, system architectures, and major functionalities, and also\ndemonstrate several example use cases across different types of data, tasks,\nand models.",
    "descriptor": "\nComments: 18 pages, 7 figures\n",
    "authors": [
      "Wenzhuo Yang",
      "Hung Le",
      "Silvio Savarese",
      "Steven C.H. Hoi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01612"
  },
  {
    "id": "arXiv:2206.01614",
    "title": "Learning programs by combining programs",
    "abstract": "The goal of inductive logic programming is to induce a set of rules (a logic\nprogram) that generalises examples. Inducing programs with many rules and\nliterals is a major challenge. To tackle this challenge, we decompose programs\ninto \\emph{non-separable} fragments, learn fragments separately, and then\ncombine them. We implement our approach in a generate, test, combine, and\nconstrain loop. Our anytime approach can learn optimal, recursive, and large\nprograms and supports predicate invention. Our experiments on multiple domains\n(including program synthesis and inductive general game playing) show that our\napproach can increase predictive accuracies and reduce learning times compared\nto existing approaches.",
    "descriptor": "\nComments: early draft of manuscript (more of a technical report) to accompany code release. arXiv admin note: text overlap with arXiv:2109.07818\n",
    "authors": [
      "Andrew Cropper"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.01614"
  },
  {
    "id": "arXiv:2206.01617",
    "title": "An adaptive fuzzy sliding mode controller applied to a chaotic pendulum",
    "abstract": "In this work, an intelligent controller is employed to the chaos control\nproblem in a nonlinear pendulum. The adopted approach is based on the sliding\nmode control strategy and enhanced by an adaptive fuzzy algorithm to cope with\nmodeling inaccuracies. The convergence properties of the closed-loop system are\nanalytically proven using Lyapunov's direct method and Barbalat's lemma.\nNumerical results are also presented in order to demonstrate the control system\nperformance.",
    "descriptor": "",
    "authors": [
      "Wallace Moreira Bessa",
      "Aline Souza de Paula",
      "Marcelo Amorim Savi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.01617"
  },
  {
    "id": "arXiv:2206.01626",
    "title": "Beyond Tabula Rasa: Reincarnating Reinforcement Learning",
    "abstract": "Learning tabula rasa, that is without any prior knowledge, is the prevalent\nworkflow in reinforcement learning (RL) research. However, RL systems, when\napplied to large-scale settings, rarely operate tabula rasa. Such large-scale\nsystems undergo multiple design or algorithmic changes during their development\ncycle and use ad hoc approaches for incorporating these changes without\nre-training from scratch, which would have been prohibitively expensive.\nAdditionally, the inefficiency of deep RL typically excludes researchers\nwithout access to industrial-scale resources from tackling\ncomputationally-demanding problems. To address these issues, we present\nreincarnating RL as an alternative workflow, where prior computational work\n(e.g., learned policies) is reused or transferred between design iterations of\nan RL agent, or from one RL agent to another. As a step towards enabling\nreincarnating RL from any agent to any other agent, we focus on the specific\nsetting of efficiently transferring an existing sub-optimal policy to a\nstandalone value-based RL agent. We find that existing approaches fail in this\nsetting and propose a simple algorithm to address their limitations. Equipped\nwith this algorithm, we demonstrate reincarnating RL's gains over tabula rasa\nRL on Atari 2600 games, a challenging locomotion task, and the real-world\nproblem of navigating stratospheric balloons. Overall, this work argues for an\nalternative approach to RL research, which we believe could significantly\nimprove real-world RL adoption and help democratize it further.",
    "descriptor": "",
    "authors": [
      "Rishabh Agarwal",
      "Max Schwarzer",
      "Pablo Samuel Castro",
      "Aaron Courville",
      "Marc G. Bellemare"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.01626"
  },
  {
    "id": "arXiv:2206.01627",
    "title": "Pruning for Interpretable, Feature-Preserving Circuits in CNNs",
    "abstract": "Deep convolutional neural networks are a powerful model class for a range of\ncomputer vision problems, but it is difficult to interpret the image filtering\nprocess they implement, given their sheer size. In this work, we introduce a\nmethod for extracting 'feature-preserving circuits' from deep CNNs, leveraging\nmethods from saliency-based neural network pruning. These circuits are modular\nsub-functions, embedded within the network, containing only a subset of\nconvolutional kernels relevant to a target feature. We compare the efficacy of\n3 saliency-criteria for extracting these sparse circuits. Further, we show how\n'sub-feature' circuits can be extracted, that preserve a feature's responses to\nparticular images, dividing the feature into even sparser filtering processes.\nWe also develop a tool for visualizing 'circuit diagrams', which render the\nentire image filtering process implemented by circuits in a parsable format.",
    "descriptor": "\nComments: Under Review\n",
    "authors": [
      "Chris Hamblin",
      "Talia Konkle",
      "George Alvarez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01627"
  },
  {
    "id": "arXiv:2206.01634",
    "title": "Reinforcement Learning with Neural Radiance Fields",
    "abstract": "It is a long-standing problem to find effective representations for training\nreinforcement learning (RL) agents. This paper demonstrates that learning state\nrepresentations with supervision from Neural Radiance Fields (NeRFs) can\nimprove the performance of RL compared to other learned representations or even\nlow-dimensional, hand-engineered state information. Specifically, we propose to\ntrain an encoder that maps multiple image observations to a latent space\ndescribing the objects in the scene. The decoder built from a\nlatent-conditioned NeRF serves as the supervision signal to learn the latent\nspace. An RL algorithm then operates on the learned latent space as its state\nrepresentation. We call this NeRF-RL. Our experiments indicate that NeRF as\nsupervision leads to a latent space better suited for the downstream RL tasks\ninvolving robotic object manipulations like hanging mugs on hooks, pushing\nobjects, or opening doors. Video: https://dannydriess.github.io/nerf-rl",
    "descriptor": "",
    "authors": [
      "Danny Driess",
      "Ingmar Schubert",
      "Pete Florence",
      "Yunzhu Li",
      "Marc Toussaint"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.01634"
  },
  {
    "id": "arXiv:2206.01640",
    "title": "PROMISSING: Pruning Missing Values in Neural Networks",
    "abstract": "While data are the primary fuel for machine learning models, they often\nsuffer from missing values, especially when collected in real-world scenarios.\nHowever, many off-the-shelf machine learning models, including artificial\nneural network models, are unable to handle these missing values directly.\nTherefore, extra data preprocessing and curation steps, such as data\nimputation, are inevitable before learning and prediction processes. In this\nstudy, we propose a simple and intuitive yet effective method for pruning\nmissing values (PROMISSING) during learning and inference steps in neural\nnetworks. In this method, there is no need to remove or impute the missing\nvalues; instead, the missing values are treated as a new source of information\n(representing what we do not know). Our experiments on simulated data, several\nclassification and regression benchmarks, and a multi-modal clinical dataset\nshow that PROMISSING results in similar prediction performance compared to\nvarious imputation techniques. In addition, our experiments show models trained\nusing PROMISSING techniques are becoming less decisive in their predictions\nwhen facing incomplete samples with many unknowns. This finding hopefully\nadvances machine learning models from being pure predicting machines to more\nrealistic thinkers that can also say \"I do not know\" when facing incomplete\nsources of information.",
    "descriptor": "",
    "authors": [
      "Seyed Mostafa Kia",
      "Nastaran Mohammadian Rad",
      "Daniel van Opstal",
      "Bart van Schie",
      "Andre F. Marquand",
      "Josien Pluim",
      "Wiepke Cahn",
      "Hugo G. Schnack"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2206.01640"
  },
  {
    "id": "arXiv:2206.01643",
    "title": "ChaTEAU: A Universal Toolkit for Applying the Chase",
    "abstract": "What do applications like semantic optimization, data exchange and\nintegration, answering queries under dependencies, query reformulation with\nconstraints, and data cleaning have in common? All these applications can be\nprocessed by the Chase, a family of algorithms for reasoning with constraints.\nWhile the theory of the Chase is well understood, existing implementations are\nconfined to specific use cases and application scenarios, making it difficult\nto reuse them in other settings. ChaTEAU overcomes this limitation: It takes\nthe logical core of the Chase, generalizes it, and provides a software library\nfor different Chase applications in a single toolkit.",
    "descriptor": "",
    "authors": [
      "Tanja Auge",
      "Nic Scharlau",
      "Andreas G\u00f6rres",
      "Jakob Zimmer",
      "Andreas Heuer"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.01643"
  },
  {
    "id": "arXiv:2206.01645",
    "title": "Clustering Trust Dynamics in a Human-Robot Sequential Decision-Making  Task",
    "abstract": "In this paper, we present a framework for trust-aware sequential\ndecision-making in a human-robot team. We model the problem as a finite-horizon\nMarkov Decision Process with a reward-based performance metric, allowing the\nrobotic agent to make trust-aware recommendations. Results of a human-subject\nexperiment show that the proposed trust update model is able to accurately\ncapture the human agent's moment-to-moment trust changes. Moreover, we cluster\nthe participants' trust dynamics into three categories, namely, Bayesian\ndecision makers, oscillators, and disbelievers, and identify personal\ncharacteristics that could be used to predict which type of trust dynamics a\nperson will belong to. We find that the disbelievers are less extroverted, less\nagreeable, and have lower expectations toward the robotic agent, compared to\nthe Bayesian decision makers and oscillators. The oscillators are significantly\nmore frustrated than the Bayesian decision makers.",
    "descriptor": "\nComments: 4 pages, 4 figures\n",
    "authors": [
      "Shreyas Bhat",
      "Joseph B. Lyons",
      "Cong Shi",
      "X. Jessie Yang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.01645"
  },
  {
    "id": "arXiv:2206.01646",
    "title": "Rethinking Positive Sampling for Contrastive Learning with Kernel",
    "abstract": "Data augmentation is a crucial component in unsupervised contrastive learning\n(CL). It determines how positive samples are defined and, ultimately, the\nquality of the representation. While efficient augmentations have been found\nfor standard vision datasets, such as ImageNet, it is still an open problem in\nother applications, such as medical imaging, or in datasets with easy-to-learn\nbut irrelevant imaging features. In this work, we propose a new way to define\npositive samples using kernel theory along with a novel loss called decoupled\nuniformity. We propose to integrate prior information, learnt from generative\nmodels or given as auxiliary attributes, into contrastive learning, to make it\nless dependent on data augmentation. We draw a connection between contrastive\nlearning and the conditional mean embedding theory to derive tight bounds on\nthe downstream classification loss. In an unsupervised setting, we empirically\ndemonstrate that CL benefits from generative models, such as VAE and GAN, to\nless rely on data augmentations. We validate our framework on vision datasets\nincluding CIFAR10, CIFAR100, STL10 and ImageNet100 and a brain MRI dataset. In\nthe weakly supervised setting, we demonstrate that our formulation provides\nstate-of-the-art results.",
    "descriptor": "",
    "authors": [
      "Benoit Dufumier",
      "Carlo Alberto Barbano",
      "Robin Louiset",
      "Edouard Duchesnay",
      "Pietro Gori"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01646"
  },
  {
    "id": "arXiv:2206.01649",
    "title": "Neural Differential Equations for Learning to Program Neural Nets  Through Continuous Learning Rules",
    "abstract": "Neural ordinary differential equations (ODEs) have attracted much attention\nas continuous-time counterparts of deep residual neural networks (NNs), and\nnumerous extensions for recurrent NNs have been proposed. Since the 1980s, ODEs\nhave also been used to derive theoretical results for NN learning rules, e.g.,\nthe famous connection between Oja's rule and principal component analysis. Such\nrules are typically expressed as additive iterative update processes which have\nstraightforward ODE counterparts. Here we introduce a novel combination of\nlearning rules and Neural ODEs to build continuous-time sequence processing\nnets that learn to manipulate short-term memory in rapidly changing synaptic\nconnections of other nets. This yields continuous-time counterparts of Fast\nWeight Programmers and linear Transformers. Our novel models outperform the\nbest existing Neural Controlled Differential Equation based models on various\ntime series classification tasks, while also addressing their scalability\nlimitations. Our code is public.",
    "descriptor": "",
    "authors": [
      "Kazuki Irie",
      "Francesco Faccio",
      "J\u00fcrgen Schmidhuber"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01649"
  },
  {
    "id": "arXiv:2206.01651",
    "title": "D'ARTAGNAN: Counterfactual Video Generation",
    "abstract": "Causally-enabled machine learning frameworks could help clinicians to\nidentify the best course of treatments by answering counterfactual questions.\nWe explore this path for the case of echocardiograms by looking into the\nvariation of the Left Ventricle Ejection Fraction, the most essential clinical\nmetric gained from these examinations. We combine deep neural networks, twin\ncausal networks and generative adversarial methods for the first time to build\nD'ARTAGNAN (Deep ARtificial Twin-Architecture GeNerAtive Networks), a novel\ncausal generative model. We demonstrate the soundness of our approach on a\nsynthetic dataset before applying it to cardiac ultrasound videos by answering\nthe question: \"What would this echocardiogram look like if the patient had a\ndifferent ejection fraction?\". To do so, we generate new ultrasound videos,\nretaining the video style and anatomy of the original patient, with variations\nof the Ejection Fraction conditioned on a given input. We achieve an SSIM score\nof 0.79 and an R2 score of 0.51 on the counterfactual videos. Code and models\nare available at https://github.com/HReynaud/dartagnan.",
    "descriptor": "\nComments: Accepted for MICCAI 2022\n",
    "authors": [
      "Hadrien Reynaud",
      "Athanasios Vlontzos",
      "Mischa Dombrowski",
      "Ciar\u00e1n Lee",
      "Arian Beqiri",
      "Paul Leeson",
      "Bernhard Kainz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01651"
  },
  {
    "id": "arXiv:2206.01653",
    "title": "Metrics reloaded: Pitfalls and recommendations for image analysis  validation",
    "abstract": "The field of automatic biomedical image analysis crucially depends on robust\nand meaningful performance metrics for algorithm validation. Current metric\nusage, however, is often ill-informed and does not reflect the underlying\ndomain interest. Here, we present a comprehensive framework that guides\nresearchers towards choosing performance metrics in a problem-aware manner.\nSpecifically, we focus on biomedical image analysis problems that can be\ninterpreted as a classification task at image, object or pixel level. The\nframework first compiles domain interest-, target structure-, data set- and\nalgorithm output-related properties of a given problem into a problem\nfingerprint, while also mapping it to the appropriate problem category, namely\nimage-level classification, semantic segmentation, instance segmentation, or\nobject detection. It then guides users through the process of selecting and\napplying a set of appropriate validation metrics while making them aware of\npotential pitfalls related to individual choices. In this paper, we describe\nthe current status of the Metrics Reloaded recommendation framework, with the\ngoal of obtaining constructive feedback from the image analysis community. The\ncurrent version has been developed within an international consortium of more\nthan 60 image analysis experts and will be made openly available as a\nuser-friendly toolkit after community-driven optimization.",
    "descriptor": "\nComments: Shared first authors: Lena Maier-Hein, Annika Reinke\n",
    "authors": [
      "Lena Maier-Hein",
      "Annika Reinke",
      "Evangelia Christodoulou",
      "Ben Glocker",
      "Patrick Godau",
      "Fabian Isensee",
      "Jens Kleesiek",
      "Michal Kozubek",
      "Mauricio Reyes",
      "Michael A. Riegler",
      "Manuel Wiesenfarth",
      "Michael Baumgartner",
      "Matthias Eisenmann",
      "Doreen Heckmann-N\u00f6tzel",
      "A. Emre Kavur",
      "Tim R\u00e4dsch",
      "Minu D. Tizabi",
      "Laura Acion",
      "Michela Antonelli",
      "Tal Arbel",
      "Spyridon Bakas",
      "Peter Bankhead",
      "Arriel Benis",
      "M. Jorge Cardoso",
      "Veronika Cheplygina",
      "Beth Cimini",
      "Gary S. Collins",
      "Keyvan Farahani",
      "Bram van Ginneken",
      "Daniel A. Hashimoto",
      "Michael M. Hoffman",
      "Merel Huisman",
      "Pierre Jannin",
      "Charles E. Kahn",
      "Alexandros Karargyris",
      "Alan Karthikesalingam",
      "Hannes Kenngott",
      "Annette Kopp-Schneider",
      "Anna Kreshuk",
      "Tahsin Kurc",
      "Bennett A. Landman",
      "Geert Litjens",
      "Amin Madani",
      "Klaus Maier-Hein",
      "Anne L. Martel",
      "Peter Mattson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01653"
  },
  {
    "id": "arXiv:2206.01657",
    "title": "A unifying framework for tangential interpolation of structured bilinear  control systems",
    "abstract": "In this paper, we consider the structure-preserving model order reduction\nproblem for multi-input/multi-output bilinear control systems by tangential\ninterpolation. We propose a new type of tangential interpolation problem for\nstructured bilinear systems, for which we develop a new structure-preserving\ninterpolation framework. This new framework extends and generalizes different\nformulations of tangential interpolation for bilinear systems from the\nliterature and also provides a unifying framework. We then derive explicit\nconditions on the projection spaces to enforce tangential interpolation in\ndifferent settings, including conditions for tangential Hermite interpolation.\nThe analysis is illustrated by means of three numerical examples.",
    "descriptor": "\nComments: 33 pages, 9 figures\n",
    "authors": [
      "Peter Benner",
      "Serkan Gugercin",
      "Steffen W. R. Werner"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.01657"
  },
  {
    "id": "arXiv:2206.01658",
    "title": "Identification via Retinal Vessels Combining LBP and HOG",
    "abstract": "With development of information technology and necessity for high security,\nusing different identification methods has become very important. Each\nbiometric feature has its own advantages and disadvantages and choosing each of\nthem depends on our usage. Retinal scanning is a bio scale method for\nidentification. The retina is composed of vessels and optical disk. The vessels\ndistribution pattern is one the remarkable retinal identification methods. In\nthis paper, a new approach is presented for identification via retinal images\nusing LBP and hog methods. In the proposed method, it will be tried to separate\nthe retinal vessels accurately via machine vision techniques which will have\ngood sustainability in rotation and size change. HOG-based or LBP-based methods\nor their combination can be used for separation and also HSV color space can be\nused too. Having extracted the features, the similarity criteria can be used\nfor identification. The implementation of proposed method and its comparison\nwith one of the newly-presented methods in this area shows better performance\nof the proposed method.",
    "descriptor": "",
    "authors": [
      "Ali Noori"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01658"
  },
  {
    "id": "arXiv:2206.01661",
    "title": "Style-Content Disentanglement in Language-Image Pretraining  Representations for Zero-Shot Sketch-to-Image Synthesis",
    "abstract": "In this work, we propose and validate a framework to leverage language-image\npretraining representations for training-free zero-shot sketch-to-image\nsynthesis. We show that disentangled content and style representations can be\nutilized to guide image generators to employ them as sketch-to-image generators\nwithout (re-)training any parameters. Our approach for disentangling style and\ncontent entails a simple method consisting of elementary arithmetic assuming\ncompositionality of information in representations of input sketches. Our\nresults demonstrate that this approach is competitive with state-of-the-art\ninstance-level open-domain sketch-to-image models, while only depending on\npretrained off-the-shelf models and a fraction of the data.",
    "descriptor": "",
    "authors": [
      "Jan Zuiderveld"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01661"
  },
  {
    "id": "arXiv:2206.01663",
    "title": "Joint Energy Dispatch and Unit Commitment in Microgrids Based on Deep  Reinforcement Learning",
    "abstract": "Nowadays, the application of microgrids (MG) with renewable energy is\nbecoming more and more extensive, which creates a strong need for dynamic\nenergy management. In this paper, deep reinforcement learning (DRL) is applied\nto learn an optimal policy for making joint energy dispatch (ED) and unit\ncommitment (UC) decisions in an isolated MG, with the aim for reducing the\ntotal power generation cost on the premise of ensuring the supply-demand\nbalance. In order to overcome the challenge of discrete-continuous hybrid\naction space due to joint ED and UC, we propose a DRL algorithm, i.e., the\nhybrid action finite-horizon DDPG (HAFH-DDPG), that seamlessly integrates two\nclassical DRL algorithms, i.e., deep Q-network (DQN) and deep deterministic\npolicy gradient (DDPG), based on a finite-horizon dynamic programming (DP)\nframework. Moreover, a diesel generator (DG) selection strategy is presented to\nsupport a simplified action space for reducing the computation complexity of\nthis algorithm. Finally, the effectiveness of our proposed algorithm is\nverified through comparison with several baseline algorithms by experiments\nwith real-world data set.",
    "descriptor": "",
    "authors": [
      "Jiaju Qi",
      "Lei Lei",
      "Kan Zheng",
      "Simon X. Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2206.01663"
  },
  {
    "id": "arXiv:2206.01665",
    "title": "BaCaDI: Bayesian Causal Discovery with Unknown Interventions",
    "abstract": "Learning causal structures from observation and experimentation is a central\ntask in many domains. For example, in biology, recent advances allow us to\nobtain single-cell expression data under multiple interventions such as drugs\nor gene knockouts. However, a key challenge is that often the targets of the\ninterventions are uncertain or unknown. Thus, standard causal discovery methods\ncan no longer be used. To fill this gap, we propose a Bayesian framework\n(BaCaDI) for discovering the causal structure that underlies data generated\nunder various unknown experimental/interventional conditions. BaCaDI is fully\ndifferentiable and operates in the continuous space of latent probabilistic\nrepresentations of both causal structures and interventions. This enables us to\napproximate complex posteriors via gradient-based variational inference and to\nreason about the epistemic uncertainty in the predicted structure. In\nexperiments on synthetic causal discovery tasks and simulated gene-expression\ndata, BaCaDI outperforms related methods in identifying causal structures and\nintervention targets. Finally, we demonstrate that, thanks to its rigorous\nBayesian approach, our method provides well-calibrated uncertainty estimates.",
    "descriptor": "",
    "authors": [
      "Alexander H\u00e4gele",
      "Jonas Rothfuss",
      "Lars Lorch",
      "Vignesh Ram Somnath",
      "Bernhard Sch\u00f6lkopf",
      "Andreas Krause"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.01665"
  },
  {
    "id": "arXiv:2206.01670",
    "title": "Egocentric Video-Language Pretraining",
    "abstract": "Video-Language Pretraining (VLP), aiming to learn transferable representation\nto advance a wide range of video-text downstream tasks, has recently received\nincreasing attention. Dominant works that achieve strong performance rely on\nlarge-scale, 3rd-person video-text datasets, such as HowTo100M. In this work,\nwe exploit the recently released Ego4D dataset to pioneer Egocentric VLP along\nthree directions. (i) We create EgoClip, a 1st-person video-text pretraining\ndataset comprising 3.8M clip-text pairs well-chosen from Ego4D, covering a\nlarge variety of human daily activities. (ii) We propose a novel pretraining\nobjective, dubbed as EgoNCE, which adapts video-text contrastive learning to\negocentric domain by mining egocentric-aware positive and negative samples.\n(iii) We introduce EgoMCQ, a development benchmark that is close to EgoClip and\nhence can support effective validation and fast exploration of our design\ndecisions regarding EgoClip and EgoNCE. Furthermore, we demonstrate strong\nperformance on five egocentric downstream tasks across three datasets:\nvideo-text retrieval on EPIC-KITCHENS-100; action recognition on Charades-Ego;\nand natural language query, moment query, and object state change\nclassification on Ego4D challenge benchmarks. The dataset and code will be\navailable at https://github.com/showlab/EgoVLP.",
    "descriptor": "\nComments: Preprint. 22 pages, 13 figures, 11 tables. Code: this https URL\n",
    "authors": [
      "Kevin Qinghong Lin",
      "Alex Jinpeng Wang",
      "Mattia Soldan",
      "Michael Wray",
      "Rui Yan",
      "Eric Zhongcong Xu",
      "Difei Gao",
      "Rongcheng Tu",
      "Wenzhe Zhao",
      "Weijie Kong",
      "Chengfei Cai",
      "Hongfa Wang",
      "Dima Damen",
      "Bernard Ghanem",
      "Wei Liu",
      "Mike Zheng Shou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.01670"
  },
  {
    "id": "arXiv:2206.01677",
    "title": "ArgRewrite V.2: an Annotated Argumentative Revisions Corpus",
    "abstract": "Analyzing how humans revise their writings is an interesting research\nquestion, not only from an educational perspective but also in terms of\nartificial intelligence. Better understanding of this process could facilitate\nmany NLP applications, from intelligent tutoring systems to supportive and\ncollaborative writing environments. Developing these applications, however,\nrequires revision corpora, which are not widely available. In this work, we\npresent ArgRewrite V.2, a corpus of annotated argumentative revisions,\ncollected from two cycles of revisions to argumentative essays about\nself-driving cars. Annotations are provided at different levels of purpose\ngranularity (coarse and fine) and scope (sentential and subsentential). In\naddition, the corpus includes the revision goal given to each writer, essay\nscores, annotation verification, pre- and post-study surveys collected from\nparticipants as meta-data. The variety of revision unit scope and purpose\ngranularity levels in ArgRewrite, along with the inclusion of new types of\nmeta-data, can make it a useful resource for research and applications that\ninvolve revision analysis. We demonstrate some potential applications of\nArgRewrite V.2 in the development of automatic revision purpose predictors, as\na training source and benchmark.",
    "descriptor": "\nComments: Lang Resources & Evaluation (2022)\n",
    "authors": [
      "Omid Kashefi",
      "Tazin Afrin",
      "Meghan Dale",
      "Christopher Olshefski",
      "Amanda Godley",
      "Diane Litman",
      "Rebecca Hwa"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.01677"
  },
  {
    "id": "arXiv:2206.01678",
    "title": "Toward a Sensitivity-based Implicit Measure of Patients' Important Goal  Pursuits",
    "abstract": "When individuals arrive to receive help from mental health providers, they do\nnot always have well specified and well established goals. It is the mental\nhealth providers responsibility to work collaboratively with patients to\nclarify their goals in the therapy sessions as well as life in general through\nclinical interviews, diagnostic assessments, and thorough observations.\nHowever, recognizing individuals important life goals is not always\nstraightforward. Here we introduce a novel method that gauges a patient\nimportant goal pursuits from their relative sensitivity to goal related words.\nPast research has shown that a person active goal pursuits cause them to be\nmore sensitive to the presence of goal related stimuli in the environment being\nable to consciously report those stimuli when others cannot see them. By\npresenting words related to a variety of different life goal pursuits very\nquickly for 50 msec or less, the patient would be expected to notice and be\naware of words related to their strongest motivations but not the other goal\nrelated words. These may or may not be among the goals they have identified in\ntherapy sessions, and the ones not previously identified can be fertile grounds\nfor further discussion and exploration in subsequent therapy sessions. Results\nfrom eight patient volunteers are described and discussed in terms of the\npotential utility of this supplemental personal therapy aid.",
    "descriptor": "\nComments: 35 pages, 1 figure, was accepted for presentation at the Connecticut Psychological Association convention, November 2022. No acknowledgement has been added yet\n",
    "authors": [
      "Shiva Rezvan",
      "John A. Bargh"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.01678"
  },
  {
    "id": "arXiv:2206.01683",
    "title": "FishGym: A High-Performance Physics-based Simulation Framework for  Underwater Robot Learning",
    "abstract": "Bionic underwater robots have demonstrated their superiority in many\napplications. Yet, training their intelligence for a variety of tasks that\nmimic the behavior of underwater creatures poses a number of challenges in\npractice, mainly due to lack of a large amount of available training data as\nwell as the high cost in real physical environment. Alternatively, simulation\nhas been considered as a viable and important tool for acquiring datasets in\ndifferent environments, but it mostly targeted rigid and soft body systems.\nThere is currently dearth of work for more complex fluid systems interacting\nwith immersed solids that can be efficiently and accurately simulated for robot\ntraining purposes. In this paper, we propose a new platform called \"FishGym\",\nwhich can be used to train fish-like underwater robots. The framework consists\nof a robotic fish modeling module using articulated body with skinning, a\nGPU-based high-performance localized two-way coupled fluid-structure\ninteraction simulation module that handles both finite and infinitely large\ndomains, as well as a reinforcement learning module. We leveraged existing\ntraining methods with adaptations to underwater fish-like robots and obtained\nlearned control policies for multiple benchmark tasks. The training results are\ndemonstrated with reasonable motion trajectories, with comparisons and analyses\nto empirical models as well as known real fish swimming behaviors to highlight\nthe advantages of the proposed platform.",
    "descriptor": "\nComments: 8 pages,8 figures\n",
    "authors": [
      "Wenji Liu",
      "Kai Bai",
      "Xuming He",
      "Shuran Song",
      "Changxi Zheng",
      "Xiaopei Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.01683"
  },
  {
    "id": "arXiv:2206.01684",
    "title": "HashBeam: Enabling Feedback Through Downlink Beamforming in Unsourced  Random Access",
    "abstract": "Unsourced random access (URA) has emerged as a candidate paradigm for massive\nmachine-type communication (MTC) in next-generation wireless networks. While\nmany excellent uplink schemes have been developed for URA, these schemes do not\nspecify a mechanism for providing feedback regarding whether a user's message\nwas successfully decoded. While this may be acceptable in some MTC scenarios,\nthe lack of feedback is inadequate for applications that demand a high level of\nreliability. However, the problem of providing feedback to active users is\ncomplicated by the fact that the base station does not know the identities of\nthe active users. In this paper, a novel downlink beamforming scheme called\nHashBeam is presented that enables the base station to provide feedback to the\nactive users within URA, despite not knowing their identities. The key idea of\nthis scheme is that the users' channels and hashes of their messages may be\nused as proxies for their true identities. The proposed scheme may be adapted\nto any number of antennas at the base station and it is shown that the required\nnumber of channel uses is linear in the number of users to acknowledge. The\nidea of using channel gains in conjunction with user hashes as discriminating\nattributes of active users is novel and expands the design space of URA\nschemes.",
    "descriptor": "",
    "authors": [
      "Jamison R. Ebert",
      "Krishna R. Narayanan",
      "Jean-Francois Chamberland"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.01684"
  },
  {
    "id": "arXiv:2206.01688",
    "title": "L-systems for Measuring Repetitiveness*",
    "abstract": "An L-system (for lossless compression) is a CPD0L-system extended with two\nparameters $d$ and $n$, which determines unambiguously a string $w =\n\\tau(\\varphi^d(s))[1:n]$, where $\\varphi$ is the morphism of the system, $s$ is\nits axiom, and $\\tau$ is its coding. The length of the shortest description of\nan L-system generating $w$ is known as $\\ell$, and is arguably a relevant\nmeasure of repetitiveness that builds on the self-similarities that arise in\nthe sequence.\nIn this paper we deepen the study of the measure $\\ell$ and its relation with\n$\\delta$, a better established lower bound that builds on substring complexity.\nOur results show that $\\ell$ and $\\delta$ are largely orthogonal, in the sense\nthat one can be much larger than the other depending on the case. This suggests\nthat both sources of repetitiveness are mostly unrelated. We also show that the\nrecently introduced NU-systems, which combine the capabilities of L-systems\nwith bidirectional macro-schemes, can be asymptotically strictly smaller than\nboth mechanisms, which makes the size $\\nu$ of the smallest NU-system the\nunique smallest reachable repetitiveness measure to date.",
    "descriptor": "\nComments: Funded in part by Basal Funds FB0001, Fondecyt Grant 1-200038, and a Conicyt Doctoral Scholarship, ANID, Chile\n",
    "authors": [
      "Gonzalo Navarro",
      "Cristian Urbina"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2206.01688"
  },
  {
    "id": "arXiv:2206.01690",
    "title": "Dynamic Kernel Selection for Improved Generalization and Memory  Efficiency in Meta-learning",
    "abstract": "Gradient based meta-learning methods are prone to overfit on the\nmeta-training set, and this behaviour is more prominent with large and complex\nnetworks. Moreover, large networks restrict the application of meta-learning\nmodels on low-power edge devices. While choosing smaller networks avoid these\nissues to a certain extent, it affects the overall generalization leading to\nreduced performance. Clearly, there is an approximately optimal choice of\nnetwork architecture that is best suited for every meta-learning problem,\nhowever, identifying it beforehand is not straightforward. In this paper, we\npresent MetaDOCK, a task-specific dynamic kernel selection strategy for\ndesigning compressed CNN models that generalize well on unseen tasks in\nmeta-learning. Our method is based on the hypothesis that for a given set of\nsimilar tasks, not all kernels of the network are needed by each individual\ntask. Rather, each task uses only a fraction of the kernels, and the selection\nof the kernels per task can be learnt dynamically as a part of the inner update\nsteps. MetaDOCK compresses the meta-model as well as the task-specific inner\nmodels, thus providing significant reduction in model size for each task, and\nthrough constraining the number of active kernels for every task, it implicitly\nmitigates the issue of meta-overfitting. We show that for the same inference\nbudget, pruned versions of large CNN models obtained using our approach\nconsistently outperform the conventional choices of CNN models. MetaDOCK\ncouples well with popular meta-learning approaches such as iMAML. The efficacy\nof our method is validated on CIFAR-fs and mini-ImageNet datasets, and we have\nobserved that our approach can provide improvements in model accuracy of up to\n2% on standard meta-learning benchmark, while reducing the model size by more\nthan 75%.",
    "descriptor": "\nComments: Published at CVPR 2022\n",
    "authors": [
      "Arnav Chavan",
      "Rishabh Tiwari",
      "Udbhav Bamba",
      "Deepak K. Gupta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01690"
  },
  {
    "id": "arXiv:2206.01691",
    "title": "Measuring Gender Bias in Word Embeddings of Gendered Languages Requires  Disentangling Grammatical Gender Signals",
    "abstract": "Does the grammatical gender of a language interfere when measuring the\nsemantic gender information captured by its word embeddings? A number of\nanomalous gender bias measurements in the embeddings of gendered languages\nsuggest this possibility. We demonstrate that word embeddings learn the\nassociation between a noun and its grammatical gender in grammatically gendered\nlanguages, which can skew social gender bias measurements. Consequently, word\nembedding post-processing methods are introduced to quantify, disentangle, and\nevaluate grammatical gender signals. The evaluation is performed on five\ngendered languages from the Germanic, Romance, and Slavic branches of the\nIndo-European language family. Our method reduces the strength of grammatical\ngender signals, which is measured in terms of effect size (Cohen's d), by a\nsignificant average of d = 1.3 for French, German, and Italian, and d = 0.56\nfor Polish and Spanish. Once grammatical gender is disentangled, the\nassociation between over 90% of 10,000 inanimate nouns and their assigned\ngrammatical gender weakens, and cross-lingual bias results from the Word\nEmbedding Association Test (WEAT) become more congruent with country-level\nimplicit bias measurements. The results further suggest that disentangling\ngrammatical gender signals from word embeddings may lead to improvement in\nsemantic machine learning tasks.",
    "descriptor": "",
    "authors": [
      "Shiva Omrani Sabbaghi",
      "Aylin Caliskan"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01691"
  },
  {
    "id": "arXiv:2206.01692",
    "title": "LTL with Local and Remote Data Constraints",
    "abstract": "We consider an extension of linear-time temporal logic (LTL) with both local\nand remote data constraints interpreted over a concrete domain. This extension\nis a natural extension of constraint LTL and the Temporal Logic of Repeating\nValues, which have been studied before. We shall use previous results to prove\nthat the satisfiability problem for this logic is decidable. Further, we shall\nsee that trying to extend this logic by making it more expressive can lead to\nundecidability.",
    "descriptor": "\nComments: 31 pages; Masters' Thesis, Chennai Mathematical Institute\n",
    "authors": [
      "Ashwin Bhaskar"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2206.01692"
  },
  {
    "id": "arXiv:2206.01694",
    "title": "Towards an Algebra of Computon Spaces",
    "abstract": "Compositionality is a key property for dealing with complexity, which has\nbeen studied from many points of view in diverse fields. Particularly, the\ncomposition of individual computations (or programs) has been widely studied\nalmost since the inception of computer science. Unlike existing composition\ntheories, this paper presents an algebraic model not for composing individual\nprograms but for inductively composing spaces of sequential and/or parallel\nconstructs. We particularly describe the semantics of the proposed model and\npresent an abstract example to demonstrate its application.",
    "descriptor": "",
    "authors": [
      "Damian Arellanes"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2206.01694"
  },
  {
    "id": "arXiv:2206.01695",
    "title": "Optimal Design of Electric Machine with Efficient Handling of  Constraints and Surrogate Assistance",
    "abstract": "Electric machine design optimization is a computationally expensive\nmulti-objective optimization problem. While the objectives require\ntime-consuming finite element analysis, optimization constraints can often be\nbased on mathematical expressions, such as geometric constraints. This article\ninvestigates this optimization problem of mixed computationally expensive\nnature by proposing an optimization method incorporated into a popularly-used\nevolutionary multi-objective optimization algorithm - NSGA-II. The proposed\nmethod exploits the inexpensiveness of geometric constraints to generate\nfeasible designs by using a custom repair operator. The proposed method also\naddresses the time-consuming objective functions by incorporating surrogate\nmodels for predicting machine performance. The article successfully establishes\nthe superiority of the proposed method over the conventional optimization\napproach. This study clearly demonstrates how a complex engineering design can\nbe optimized for multiple objectives and constraints requiring heterogeneous\nevaluation times and optimal solutions can be analyzed to select a single\npreferred solution and importantly harnessed to reveal vital design features\ncommon to optimal solutions as design principles.",
    "descriptor": "",
    "authors": [
      "Bhuvan Khoshoo",
      "Julian Blank",
      "Thang Q. Pham",
      "Kalyanmoy Deb",
      "Shanelle N. Foster"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.01695"
  },
  {
    "id": "arXiv:2206.01696",
    "title": "Deep Learning Prediction of Severe Health Risks for Pediatric COVID-19  Patients with a Large Feature Set in 2021 BARDA Data Challenge",
    "abstract": "Most children infected with COVID-19 have no or mild symptoms and can recover\nautomatically by themselves, but some pediatric COVID-19 patients need to be\nhospitalized or even to receive intensive medical care (e.g., invasive\nmechanical ventilation or cardiovascular support) to recover from the\nillnesses. Therefore, it is critical to predict the severe health risk that\nCOVID-19 infection poses to children to provide precise and timely medical care\nfor vulnerable pediatric COVID-19 patients. However, predicting the severe\nhealth risk for COVID-19 patients including children remains a significant\nchallenge because many underlying medical factors affecting the risk are still\nlargely unknown. In this work, instead of searching for a small number of most\nuseful features to make prediction, we design a novel large-scale bag-of-words\nlike method to represent various medical conditions and measurements of\nCOVID-19 patients. After some simple feature filtering based on logistical\nregression, the large set of features is used with a deep learning method to\npredict both the hospitalization risk for COVID-19 infected children and the\nsevere complication risk for the hospitalized pediatric COVID-19 patients. The\nmethod was trained and tested on the datasets of the Biomedical Advanced\nResearch and Development Authority (BARDA) Pediatric COVID-19 Data Challenge\nheld from Sept. 15 to Dec. 17, 2021. The results show that the approach can\nrather accurately predict the risk of hospitalization and severe complication\nfor pediatric COVID-19 patients and deep learning is more accurate than other\nmachine learning methods.",
    "descriptor": "",
    "authors": [
      "Sajid Mahmud",
      "Elham Soltanikazemi",
      "Frimpong Boadu",
      "Ashwin Dhakal",
      "Jianlin Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01696"
  },
  {
    "id": "arXiv:2206.01700",
    "title": "Composite Adaptive Control for Time-varying Systems with Dual Adaptation",
    "abstract": "This paper proposes a composite adaptive control architecture using dual\nadaptation scheme for dynamical systems comprising time-varying uncertain\nparameters. While majority of the adaptive control schemes in literature\naddress the case of constant parameters, recent research has conceptualized\nimproved adaptive control techniques for time-varying systems with rigorous\nstability proofs. The proposed work is an effort towards a similar direction,\nwhere a novel dual adaptation mechanism is introduced to efficiently tackle the\ntime-varying nature of the parameters. Projection and $\\sigma$-modification\nalgorithms are strategically combined using congelation of variables to claim a\nglobal result for the tracking error space. While the classical adaptive\nsystems demand a restrictive condition of persistence of excitation (PE) for\naccurate parameter estimation, the proposed work relies on a milder condition,\ncalled initial excitation (IE) for the same. A rigorous Lyapunov stability\nanalysis is carried out to establish uniformly ultimately bounded (UUB)\nstability of the closed-loop system. Further it is analytically shown that the\nproposed work can recover the performance of previously designed IE-based\nadaptive controller in case of time invariant systems.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Raghavv Goel",
      "Sayan Basu Roy"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.01700"
  },
  {
    "id": "arXiv:2206.01702",
    "title": "Scalar is Not Enough: Vectorization-based Unbiased Learning to Rank",
    "abstract": "Unbiased learning to rank (ULTR) aims to train an unbiased ranking model from\nbiased user click logs. Most of the current ULTR methods are based on the\nexamination hypothesis (EH), which assumes that the click probability can be\nfactorized into two scalar functions, one related to ranking features and the\nother related to bias factors. Unfortunately, the interactions among features,\nbias factors and clicks are complicated in practice, and usually cannot be\nfactorized in this independent way. Fitting click data with EH could lead to\nmodel misspecification and bring the approximation error.\nIn this paper, we propose a vector-based EH and formulate the click\nprobability as a dot product of two vector functions. This solution is complete\ndue to its universality in fitting arbitrary click functions. Based on it, we\npropose a novel model named Vectorization to adaptively learn the relevance\nembeddings and sort documents by projecting embeddings onto a base vector.\nExtensive experiments show that our method significantly outperforms the\nstate-of-the-art ULTR methods on complex real clicks as well as simple\nsimulated clicks.",
    "descriptor": "\nComments: Accepted by KDD 2022\n",
    "authors": [
      "Mouxiang Chen",
      "Chenghao Liu",
      "Zemin Liu",
      "Jianling Sun"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01702"
  },
  {
    "id": "arXiv:2206.01704",
    "title": "KCRL: Krasovskii-Constrained Reinforcement Learning with Guaranteed  Stability in Nonlinear Dynamical Systems",
    "abstract": "Learning a dynamical system requires stabilizing the unknown dynamics to\navoid state blow-ups. However, current reinforcement learning (RL) methods lack\nstabilization guarantees, which limits their applicability for the control of\nsafety-critical systems. We propose a model-based RL framework with formal\nstability guarantees, Krasovskii Constrained RL (KCRL), that adopts\nKrasovskii's family of Lyapunov functions as a stability constraint. The\nproposed method learns the system dynamics up to a confidence interval using\nfeature representation, e.g. Random Fourier Features. It then solves a\nconstrained policy optimization problem with a stability constraint based on\nKrasovskii's method using a primal-dual approach to recover a stabilizing\npolicy. We show that KCRL is guaranteed to learn a stabilizing policy in a\nfinite number of interactions with the underlying unknown system. We also\nderive the sample complexity upper bound for stabilization of unknown nonlinear\ndynamical systems via the KCRL framework.",
    "descriptor": "",
    "authors": [
      "Sahin Lale",
      "Yuanyuan Shi",
      "Guannan Qu",
      "Kamyar Azizzadenesheli",
      "Adam Wierman",
      "Anima Anandkumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.01704"
  },
  {
    "id": "arXiv:2206.01705",
    "title": "Gradient Obfuscation Checklist Test Gives a False Sense of Security",
    "abstract": "One popular group of defense techniques against adversarial attacks is based\non injecting stochastic noise into the network. The main source of robustness\nof such stochastic defenses however is often due to the obfuscation of the\ngradients, offering a false sense of security. Since most of the popular\nadversarial attacks are optimization-based, obfuscated gradients reduce their\nattacking ability, while the model is still susceptible to stronger or\nspecifically tailored adversarial attacks. Recently, five characteristics have\nbeen identified, which are commonly observed when the improvement in robustness\nis mainly caused by gradient obfuscation. It has since become a trend to use\nthese five characteristics as a sufficient test, to determine whether or not\ngradient obfuscation is the main source of robustness. However, these\ncharacteristics do not perfectly characterize all existing cases of gradient\nobfuscation, and therefore can not serve as a basis for a conclusive test. In\nthis work, we present a counterexample, showing this test is not sufficient for\nconcluding that gradient obfuscation is not the main cause of improvements in\nrobustness.",
    "descriptor": "",
    "authors": [
      "Nikola Popovic",
      "Danda Pani Paudel",
      "Thomas Probst",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01705"
  },
  {
    "id": "arXiv:2206.01706",
    "title": "Weighted Model Counting with Twin-Width",
    "abstract": "Bonnet et al. (FOCS 2020) introduced the graph invariant twin-width and\nshowed that many NP-hard problems are tractable for graphs of bounded\ntwin-width, generalizing similar results for other width measures, including\ntreewidth and clique-width. In this paper, we investigate the use of twin-width\nfor solving the propositional satisfiability problem (SAT) and propositional\nmodel counting. We particularly focus on Bounded-ones Weighted Model Counting\n(BWMC), which takes as input a CNF formula $F$ along with a bound $k$ and asks\nfor the weighted sum of all models with at most $k$ positive literals. BWMC\ngeneralizes not only SAT but also (weighted) model counting.\nWe develop the notion of \"signed\" twin-width of CNF formulas and establish\nthat BWMC is fixed-parameter tractable when parameterized by the certified\nsigned twin-width of $F$ plus $k$. We show that this result is tight: it is\nneither possible to drop the bound $k$ nor use the vanilla twin-width instead\nif one wishes to retain fixed-parameter tractability, even for the easier\nproblem SAT. Our theoretical results are complemented with an empirical\nevaluation and comparison of signed twin-width on various classes of CNF\nformulas.",
    "descriptor": "",
    "authors": [
      "Robert Ganian",
      "Filip Pokr\u00fdvka",
      "Andr\u00e9 Schidler",
      "Kirill Simonov",
      "Stefan Szeider"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.01706"
  },
  {
    "id": "arXiv:2206.01710",
    "title": "Existence and Computation of Epistemic EFX",
    "abstract": "We consider the problem of allocating indivisible goods among $n$ agents in a\nfair manner. For this problem, one of the best notions of fairness is\nenvy-freeness up to any good (EFX). However, it is not known if EFX allocations\nalways exist. Hence, several relaxations of EFX allocations have been studied.\nWe propose another relaxation of EFX, called epistemic EFX (EEFX). An\nallocation is EEFX iff for every agent $i$, it is possible to shuffle the goods\nof the other agents such that agent $i$ does not envy any other agent up to any\ngood. We show that EEFX allocations always exist for additive valuations, and\ngive a polynomial-time algorithm for computing them. We also show how EEFX is\nrelated to some previously-known notions of fairness.",
    "descriptor": "",
    "authors": [
      "Jugal Garg",
      "Eklavya Sharma"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2206.01710"
  },
  {
    "id": "arXiv:2206.01714",
    "title": "Compositional Visual Generation with Composable Diffusion Models",
    "abstract": "Large text-guided diffusion models, such as DALLE-2, are able to generate\nstunning photorealistic images given natural language descriptions. While such\nmodels are highly flexible, they struggle to understand the composition of\ncertain concepts, such as confusing the attributes of different objects or\nrelations between objects. In this paper, we propose an alternative structured\napproach for compositional generation using diffusion models. An image is\ngenerated by composing a set of diffusion models, with each of them modeling a\ncertain component of the image. To do this, we interpret diffusion models as\nenergy-based models in which the data distributions defined by the energy\nfunctions may be explicitly combined. The proposed method can generate scenes\nat test time that are substantially more complex than those seen in training,\ncomposing sentence descriptions, object relations, human facial attributes, and\neven generalizing to new combinations that are rarely seen in the real world.\nWe further illustrate how our approach may be used to compose pre-trained\ntext-guided diffusion models and generate photorealistic images containing all\nthe details described in the input descriptions, including the binding of\ncertain object attributes that have been shown difficult for DALLE-2. These\nresults point to the effectiveness of the proposed method in promoting\nstructured generalization for visual generation.",
    "descriptor": "",
    "authors": [
      "Nan Liu",
      "Shuang Li",
      "Yilun Du",
      "Antonio Torralba",
      "Joshua B. Tenenbaum"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01714"
  },
  {
    "id": "arXiv:2206.01715",
    "title": "Towards Evading the Limits of Randomized Smoothing: A Theoretical  Analysis",
    "abstract": "Randomized smoothing is the dominant standard for provable defenses against\nadversarial examples. Nevertheless, this method has recently been proven to\nsuffer from important information theoretic limitations. In this paper, we\nargue that these limitations are not intrinsic, but merely a byproduct of\ncurrent certification methods. We first show that these certificates use too\nlittle information about the classifier, and are in particular blind to the\nlocal curvature of the decision boundary. This leads to severely sub-optimal\nrobustness guarantees as the dimension of the problem increases. We then show\nthat it is theoretically possible to bypass this issue by collecting more\ninformation about the classifier. More precisely, we show that it is possible\nto approximate the optimal certificate with arbitrary precision, by probing the\ndecision boundary with several noise distributions. Since this process is\nexecuted at certification time rather than at test time, it entails no loss in\nnatural accuracy while enhancing the quality of the certificates. This result\nfosters further research on classifier-specific certification and demonstrates\nthat randomized smoothing is still worth investigating. Although\nclassifier-specific certification may induce more computational cost, we also\nprovide some theoretical insight on how to mitigate it.",
    "descriptor": "",
    "authors": [
      "Raphael Ettedgui",
      "Alexandre Araujo",
      "Rafael Pinot",
      "Yann Chevaleyre",
      "Jamal Atif"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01715"
  },
  {
    "id": "arXiv:2206.01717",
    "title": "A Theoretical Analysis on Feature Learning in Neural Networks: Emergence  from Inputs and Advantage over Fixed Features",
    "abstract": "An important characteristic of neural networks is their ability to learn\nrepresentations of the input data with effective features for prediction, which\nis believed to be a key factor to their superior empirical performance. To\nbetter understand the source and benefit of feature learning in neural\nnetworks, we consider learning problems motivated by practical data, where the\nlabels are determined by a set of class relevant patterns and the inputs are\ngenerated from these along with some background patterns. We prove that neural\nnetworks trained by gradient descent can succeed on these problems. The success\nrelies on the emergence and improvement of effective features, which are\nlearned among exponentially many candidates efficiently by exploiting the data\n(in particular, the structure of the input distribution). In contrast, no\nlinear models on data-independent features of polynomial sizes can learn to as\ngood errors. Furthermore, if the specific input structure is removed, then no\npolynomial algorithm in the Statistical Query model can learn even weakly.\nThese results provide theoretical evidence showing that feature learning in\nneural networks depends strongly on the input structure and leads to the\nsuperior performance. Our preliminary experimental results on synthetic and\nreal data also provide positive support.",
    "descriptor": "\nComments: 81 pages. ICLR2022 Poster\n",
    "authors": [
      "Zhenmei Shi",
      "Junyi Wei",
      "Yingyu Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01717"
  },
  {
    "id": "arXiv:2206.01718",
    "title": "A-OKVQA: A Benchmark for Visual Question Answering using World Knowledge",
    "abstract": "The Visual Question Answering (VQA) task aspires to provide a meaningful\ntestbed for the development of AI models that can jointly reason over visual\nand natural language inputs. Despite a proliferation of VQA datasets, this goal\nis hindered by a set of common limitations. These include a reliance on\nrelatively simplistic questions that are repetitive in both concepts and\nlinguistic structure, little world knowledge needed outside of the paired\nimage, and limited reasoning required to arrive at the correct answer. We\nintroduce A-OKVQA, a crowdsourced dataset composed of a diverse set of about\n25K questions requiring a broad base of commonsense and world knowledge to\nanswer. In contrast to the existing knowledge-based VQA datasets, the questions\ngenerally cannot be answered by simply querying a knowledge base, and instead\nrequire some form of commonsense reasoning about the scene depicted in the\nimage. We demonstrate the potential of this new dataset through a detailed\nanalysis of its contents and baseline performance measurements over a variety\nof state-of-the-art vision-language models. Project page:\nthis http URL",
    "descriptor": "",
    "authors": [
      "Dustin Schwenk",
      "Apoorv Khandelwal",
      "Christopher Clark",
      "Kenneth Marino",
      "Roozbeh Mottaghi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.01718"
  },
  {
    "id": "arXiv:2206.01720",
    "title": "Revisiting the \"Video\" in Video-Language Understanding",
    "abstract": "What makes a video task uniquely suited for videos, beyond what can be\nunderstood from a single image? Building on recent progress in self-supervised\nimage-language models, we revisit this question in the context of video and\nlanguage tasks. We propose the atemporal probe (ATP), a new model for\nvideo-language analysis which provides a stronger bound on the baseline\naccuracy of multimodal models constrained by image-level understanding. By\napplying this model to standard discriminative video and language tasks, such\nas video question answering and text-to-video retrieval, we characterize the\nlimitations and potential of current video-language benchmarks. We find that\nunderstanding of event temporality is often not necessary to achieve strong or\nstate-of-the-art performance, even compared with recent large-scale\nvideo-language models and in contexts intended to benchmark deeper video-level\nunderstanding. We also demonstrate how ATP can improve both video-language\ndataset and model design. We describe a technique for leveraging ATP to better\ndisentangle dataset subsets with a higher concentration of temporally\nchallenging data, improving benchmarking efficacy for causal and temporal\nunderstanding. Further, we show that effectively integrating ATP into full\nvideo-level temporal models can improve efficiency and state-of-the-art\naccuracy.",
    "descriptor": "\nComments: CVPR 2022 (Oral)\n",
    "authors": [
      "Shyamal Buch",
      "Crist\u00f3bal Eyzaguirre",
      "Adrien Gaidon",
      "Jiajun Wu",
      "Li Fei-Fei",
      "Juan Carlos Niebles"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01720"
  },
  {
    "id": "arXiv:2206.01722",
    "title": "A Learning-Based Method for Automatic Operator Selection in the Fanoos  XAI System",
    "abstract": "We describe an extension of the Fanoos XAI system [Bayani et al 2022] which\nenables the system to learn the appropriate action to take in order to satisfy\na user's request for description to be made more or less abstract.\nSpecifically, descriptions of systems under analysis are stored in states, and\nin order to make a description more or less abstract, Fanoos selects an\noperator from a large library to apply to the state and generate a new\ndescription. Prior work on Fanoos predominately used hand-written methods for\noperator-selection; this current work allows Fanoos to leverage experience to\nlearn the best operator to apply in a particular situation, balancing\nexploration and exploitation, leveraging expert insights when available, and\nutilizing similarity between the current state and past states. Additionally,\nin order to bootstrap the learning process (i.e., like in curriculum learning),\nwe describe a simulated user which we implemented; this simulation allows\nFanoos to gain general insights that enable reasonable courses of action,\ninsights which later can be refined by experience with real users, as opposed\nto interacting with humans completely from scratch. Code implementing the\nmethods described in the paper can be found at\nhttps://github/DBay-ani/Operator_Selection_Learning_Extensions_For_Fanoos.",
    "descriptor": "\nComments: 23 pages\n",
    "authors": [
      "David Bayani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.01722"
  },
  {
    "id": "arXiv:2206.01724",
    "title": "SNAKE: Shape-aware Neural 3D Keypoint Field",
    "abstract": "Detecting 3D keypoints from point clouds is important for shape\nreconstruction, while this work investigates the dual question: can shape\nreconstruction benefit 3D keypoint detection? Existing methods either seek\nsalient features according to statistics of different orders or learn to\npredict keypoints that are invariant to transformation. Nevertheless, the idea\nof incorporating shape reconstruction into 3D keypoint detection is\nunder-explored. We argue that this is restricted by former problem\nformulations. To this end, a novel unsupervised paradigm named SNAKE is\nproposed, which is short for shape-aware neural 3D keypoint field. Similar to\nrecent coordinate-based radiance or distance field, our network takes 3D\ncoordinates as inputs and predicts implicit shape indicators and keypoint\nsaliency simultaneously, thus naturally entangling 3D keypoint detection and\nshape reconstruction. We achieve superior performance on various public\nbenchmarks, including standalone object datasets ModelNet40, KeypointNet, SMPL\nmeshes and scene-level datasets 3DMatch and Redwood. Intrinsic shape awareness\nbrings several advantages as follows. (1) SNAKE generates 3D keypoints\nconsistent with human semantic annotation, even without such supervision. (2)\nSNAKE outperforms counterparts in terms of repeatability, especially when the\ninput point clouds are down-sampled. (3) the generated keypoints allow accurate\ngeometric registration, notably in a zero-shot setting. Codes are available at\nhttps://github.com/zhongcl-thu/SNAKE",
    "descriptor": "\nComments: Codes are available at this https URL\n",
    "authors": [
      "Chengliang Zhong",
      "Peixing You",
      "Xiaoxue Chen",
      "Hao Zhao",
      "Fuchun Sun",
      "Guyue Zhou",
      "Xiaodong Mu",
      "Chuang Gan",
      "Wenbing Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.01724"
  },
  {
    "id": "arXiv:2204.05103",
    "title": "Transformer-Based Self-Supervised Learning for Emotion Recognition",
    "abstract": "In order to exploit representations of time-series signals, such as\nphysiological signals, it is essential that these representations capture\nrelevant information from the whole signal. In this work, we propose to use a\nTransformer-based model to process electrocardiograms (ECG) for emotion\nrecognition. Attention mechanisms of the Transformer can be used to build\ncontextualized representations for a signal, giving more importance to relevant\nparts. These representations may then be processed with a fully-connected\nnetwork to predict emotions. To overcome the relatively small size of datasets\nwith emotional labels, we employ self-supervised learning. We gathered several\nECG datasets with no labels of emotion to pre-train our model, which we then\nfine-tuned for emotion recognition on the AMIGOS dataset. We show that our\napproach reaches state-of-the-art performances for emotion recognition using\nECG signals on AMIGOS. More generally, our experiments show that transformers\nand pre-training are promising strategies for emotion recognition with\nphysiological signals.",
    "descriptor": "",
    "authors": [
      "Juan Vazquez-Rodriguez",
      "Gr\u00e9goire Lefebvre",
      "Julien Cumin",
      "James L. Crowley"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2204.05103"
  },
  {
    "id": "arXiv:2206.01205",
    "title": "Snow Mountain: Dataset of Audio Recordings of The Bible in Low Resource  Languages",
    "abstract": "Automatic Speech Recognition (ASR) has increasing utility in the modern\nworld. There are a many ASR models available for languages with large amounts\nof training data like English. However, low-resource languages are poorly\nrepresented. In response we create and release an open-licensed and formatted\ndataset of audio recordings of the Bible in low-resource northern Indian\nlanguages. We setup multiple experimental splits and train and analyze two\ncompetitive ASR models to serve as the baseline for future research using this\ndata.",
    "descriptor": "\nComments: See dataset at this https URL\n",
    "authors": [
      "Kavitha Raju",
      "Anjaly V",
      "Ryan Lish",
      "Joel Mathew"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2206.01205"
  },
  {
    "id": "arXiv:2206.01209",
    "title": "Accelerated first-order methods for convex optimization with locally  Lipschitz continuous gradient",
    "abstract": "In this paper we develop accelerated first-order methods for convex\noptimization with locally Lipschitz continuous gradient (LLCG), which is beyond\nthe well-studied class of convex optimization with Lipschitz continuous\ngradient. In particular, we first consider unconstrained convex optimization\nwith LLCG and propose accelerated proximal gradient (APG) methods for solving\nit. The proposed APG methods are equipped with a verifiable termination\ncriterion and enjoy an operation complexity of ${\\cal O}(\\varepsilon^{-1/2}\\log\n\\varepsilon^{-1})$ and ${\\cal O}(\\log \\varepsilon^{-1})$ for finding an\n$\\varepsilon$-residual solution of an unconstrained convex and strongly convex\noptimization problem, respectively. We then consider constrained convex\noptimization with LLCG and propose an first-order proximal augmented Lagrangian\nmethod for solving it by applying one of our proposed APG methods to\napproximately solve a sequence of proximal augmented Lagrangian subproblems.\nThe resulting method is equipped with a verifiable termination criterion and\nenjoys an operation complexity of ${\\cal O}(\\varepsilon^{-1}\\log\n\\varepsilon^{-1})$ and ${\\cal O}(\\varepsilon^{-1/2}\\log \\varepsilon^{-1})$ for\nfinding an $\\varepsilon$-KKT solution of a constrained convex and strongly\nconvex optimization problem, respectively. All the proposed methods in this\npaper are parameter-free or almost parameter-free except that the knowledge on\nconvexity parameter is required. To the best of our knowledge, no prior studies\nwere conducted to investigate accelerated first-order methods with complexity\nguarantees for convex optimization with LLCG. All the complexity results\nobtained in this paper are entirely new.",
    "descriptor": "\nComments: 27 pages\n",
    "authors": [
      "Zhaosong Lu",
      "Sanyou Mei"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.01209"
  },
  {
    "id": "arXiv:2206.01211",
    "title": "Electrically pumped quantum-dot lasers grown on 300 mm patterned Si  photonic wafers",
    "abstract": "Monolithic integration of quantum dot (QD) gain materials onto Si photonic\nplatforms via direct epitaxial growth is a promising solution for on-chip light\nsources. Recent developments have demonstrated superior device reliability in\nblanket hetero-epitaxy of III-V devices on Si at elevated temperatures. Yet,\nthick, defect management epi designs prevent vertical light coupling from the\ngain region to the Si-on-Insulator (SOI) waveguides. Here, we demonstrate the\nfirst electrically pumped QD lasers grown on a 300 mm patterned (001) Si wafer\nwith a butt-coupled configuration by molecular beam epitaxy (MBE). Unique\ngrowth and fabrication challenges imposed by the template architecture have\nbeen resolved, contributing to continuous wave lasing to 60 {\\deg}C and a\nmaximum double-side output power of 126.6 mW at 20 {\\deg}C with a double-side\nwall plug efficiency of 8.6%. The potential for robust on-chip laser operation\nand efficient low-loss light coupling to Si photonic circuits makes this\nheteroepitaxial integration platform on Si promising for scalable and low-cost\nmass production.",
    "descriptor": "\nComments: 11 pages including references, 6 figures\n",
    "authors": [
      "Chen Shang",
      "Kaiyin Feng",
      "Eamonn T. Hughes",
      "Andrew Clark",
      "Mukul Debnath",
      "Rosalyn Koscica",
      "Gerald Leake",
      "Joshua Herman",
      "David Harame",
      "Peter Ludewig",
      "Yating Wan",
      "John E. Bowers"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2206.01211"
  },
  {
    "id": "arXiv:2206.01246",
    "title": "Stochastic gradient descent introduces an effective landscape-dependent  regularization favoring flat solutions",
    "abstract": "Generalization is one of the most important problems in deep learning (DL).\nIn the overparameterized regime in neural networks, there exist many low-loss\nsolutions that fit the training data equally well. The key question is which\nsolution is more generalizable. Empirical studies showed a strong correlation\nbetween flatness of the loss landscape at a solution and its generalizability,\nand stochastic gradient descent (SGD) is crucial in finding the flat solutions.\nTo understand how SGD drives the learning system to flat solutions, we\nconstruct a simple model whose loss landscape has a continuous set of\ndegenerate (or near degenerate) minima. By solving the Fokker-Planck equation\nof the underlying stochastic learning dynamics, we show that due to its strong\nanisotropy the SGD noise introduces an additional effective loss term that\ndecreases with flatness and has an overall strength that increases with the\nlearning rate and batch-to-batch variation. We find that the additional\nlandscape-dependent SGD-loss breaks the degeneracy and serves as an effective\nregularization for finding flat solutions. Furthermore, a stronger SGD noise\nshortens the convergence time to the flat solutions. However, we identify an\nupper bound for the SGD noise beyond which the system fails to converge. Our\nresults not only elucidate the role of SGD for generalization they may also\nhave important implications for hyperparameter selection for learning\nefficiently without divergence.",
    "descriptor": "\nComments: Main text: 11 pages, 3 figures; supplementary materials: 19 pages, 5 figures\n",
    "authors": [
      "Ning Yang",
      "Chao Tang",
      "Yuhai Tu"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01246"
  },
  {
    "id": "arXiv:2206.01263",
    "title": "Deep Learning Architecture Based Approach For 2D-Simulation of Microwave  Plasma Interaction",
    "abstract": "This paper presents a convolutional neural network (CNN)-based deep learning\nmodel, inspired from UNet with series of encoder and decoder units with skip\nconnections, for the simulation of microwave-plasma interaction. The microwave\npropagation characteristics in complex plasma medium pertaining to\ntransmission, absorption and reflection primarily depends on the ratio of\nelectromagnetic (EM) wave frequency and electron plasma frequency, and the\nplasma density profile. The scattering of a plane EM wave with fixed frequency\n(1 GHz) and amplitude incident on a plasma medium with different gaussian\ndensity profiles (in the range of $1\\times 10^{17}-1\\times 10^{22}{m^{-3}}$)\nhave been considered. The training data associated with microwave-plasma\ninteraction has been generated using 2D-FDTD (Finite Difference Time Domain)\nbased simulations. The trained deep learning model is then used to reproduce\nthe scattered electric field values for the 1GHz incident microwave on\ndifferent plasma profiles with error margin of less than 2\\%. We propose a\ncomplete deep learning (DL) based pipeline to train, validate and evaluate the\nmodel. We compare the results of the network, using various metrics like SSIM\nindex, average percent error and mean square error, with the physical data\nobtained from well-established FDTD based EM solvers. To the best of our\nknowledge, this is the first effort towards exploring a DL based approach for\nthe simulation of complex microwave plasma interaction. The deep learning\ntechnique proposed in this work is significantly fast as compared to the\nexisting computational techniques, and can be used as a new, prospective and\nalternative computational approach for investigating microwave-plasma\ninteraction in a real time scenario.",
    "descriptor": "",
    "authors": [
      "Mihir Desai",
      "Pratik Ghosh",
      "Ahlad Kumar",
      "Bhaskar Chaudhury"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01263"
  },
  {
    "id": "arXiv:2206.01274",
    "title": "Algorithmic Stability of Heavy-Tailed Stochastic Gradient Descent on  Least Squares",
    "abstract": "Recent studies have shown that heavy tails can emerge in stochastic\noptimization and that the heaviness of the tails has links to the\ngeneralization error. While these studies have shed light on interesting\naspects of the generalization behavior in modern settings, they relied on\nstrong topological and statistical regularity assumptions, which are hard to\nverify in practice. Furthermore, it has been empirically illustrated that the\nrelation between heavy tails and generalization might not always be monotonic\nin practice, contrary to the conclusions of existing theory. In this study, we\nestablish novel links between the tail behavior and generalization properties\nof stochastic gradient descent (SGD), through the lens of algorithmic\nstability. We consider a quadratic optimization problem and use a heavy-tailed\nstochastic differential equation as a proxy for modeling the heavy-tailed\nbehavior emerging in SGD. We then prove uniform stability bounds, which reveal\nthe following outcomes: (i) Without making any exotic assumptions, we show that\nSGD will not be stable if the stability is measured with the squared-loss\n$x\\mapsto x^2$, whereas it in turn becomes stable if the stability is instead\nmeasured with a surrogate loss $x\\mapsto |x|^p$ with some $p<2$. (ii) Depending\non the variance of the data, there exists a \\emph{`threshold of\nheavy-tailedness'} such that the generalization error decreases as the tails\nbecome heavier, as long as the tails are lighter than this threshold. This\nsuggests that the relation between heavy tails and generalization is not\nglobally monotonic. (iii) We prove matching lower-bounds on uniform stability,\nimplying that our bounds are tight in terms of the heaviness of the tails. We\nsupport our theory with synthetic and real neural network experiments.",
    "descriptor": "\nComments: 40 pages\n",
    "authors": [
      "Anant Raj",
      "Melih Barsbey",
      "Mert G\u00fcrb\u00fczbalaban",
      "Lingjiong Zhu",
      "Umut \u015eim\u015fekli"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01274"
  },
  {
    "id": "arXiv:2206.01284",
    "title": "Sequential Permutation Testing of Random Forest Variable Importance  Measures",
    "abstract": "Hypothesis testing of random forest (RF) variable importance measures (VIMP)\nremains the subject of ongoing research. Among recent developments, heuristic\napproaches to parametric testing have been proposed whose distributional\nassumptions are based on empirical evidence. Other formal tests under\nregularity conditions were derived analytically. However, these approaches can\nbe computationally expensive or even practically infeasible. This problem also\noccurs with non-parametric permutation tests, which are, however,\ndistribution-free and can generically be applied to any type of RF and VIMP.\nEmbracing this advantage, it is proposed here to use sequential permutation\ntests and sequential p-value estimation to reduce the high computational costs\nassociated with conventional permutation tests. The popular and widely used\npermutation VIMP serves as a practical and relevant application example. The\nresults of simulation studies confirm that the theoretical properties of the\nsequential tests apply, that is, the type-I error probability is controlled at\na nominal level and a high power is maintained with considerably fewer\npermutations needed in comparison to conventional permutation testing. The\nnumerical stability of the methods is investigated in two additional\napplication studies. In summary, theoretically sound sequential permutation\ntesting of VIMP is possible at greatly reduced computational costs.\nRecommendations for application are given. A respective implementation is\nprovided through the accompanying R package $rfvimptest$. The approach can also\nbe easily applied to any kind of prediction model.",
    "descriptor": "",
    "authors": [
      "Alexander Hapfelmeier",
      "Roman Hornung",
      "Bernhard Haller"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.01284"
  },
  {
    "id": "arXiv:2206.01291",
    "title": "A Multiset Version of Even-Odd Permutations Identity",
    "abstract": "In this paper, we give a new bijective proof of a multiset analogue of\neven-odd permutations identity. This multiset version is equivalent to the\noriginal coin arrangements lemma which is a key combinatorial lemma in the\nSherman's Proof of a conjecture of Feynman about an identity on paths in planar\ngraphs related to combinatorial solution of two dimensional Ising model in\nstatistical physics.",
    "descriptor": "",
    "authors": [
      "Hossein Teimoori Faal"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.01291"
  },
  {
    "id": "arXiv:2206.01306",
    "title": "Deceptive Planning for Resource Allocation",
    "abstract": "We consider a team of autonomous agents that navigate in an adversarial\nenvironment and aim to achieve a task by allocating their resources over a set\nof target locations. The adversaries in the environment observe the autonomous\nteam's behavior to infer their objective and counter-allocate their own\nresources to the target locations. In this setting, we develop strategies for\ncontrolling the density of the autonomous team so that they can deceive the\nadversaries regarding their objective while achieving the desired final\nresource allocation. We first develop a prediction algorithm, based on the\nprinciple of maximum entropy, to express the team's behavior expected by the\nadversaries. Then, by measuring the deceptiveness via Kullback-Leibler\ndivergence, we develop convex optimization-based planning algorithms that\ndeceives adversaries by either exaggerating the behavior towards a decoy\nallocation strategy or creating ambiguity regarding the final allocation\nstrategy. Finally, we illustrate the performance of the proposed algorithms\nthrough numerical simulations.",
    "descriptor": "",
    "authors": [
      "Yagiz Savas",
      "Mustafa O. Karabag",
      "Brian M. Sadler",
      "Ufuk Topcu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.01306"
  },
  {
    "id": "arXiv:2206.01332",
    "title": "Optimal Activation Functions for the Random Features Regression Model",
    "abstract": "The asymptotic mean squared test error and sensitivity of the Random Features\nRegression model (RFR) have been recently studied. We build on this work and\nidentify in closed-form the family of Activation Functions (AFs) that minimize\na combination of the test error and sensitivity of the RFR under different\nnotions of functional parsimony. We find scenarios under which the optimal AFs\nare linear, saturated linear functions, or expressible in terms of Hermite\npolynomials. Finally, we show how using optimal AFs impacts well-established\nproperties of the RFR model, such as its double descent curve, and the\ndependency of its optimal regularization parameter on the observation noise\nlevel.",
    "descriptor": "",
    "authors": [
      "Jianxin Wang",
      "Jos\u00e9 Bento"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01332"
  },
  {
    "id": "arXiv:2206.01338",
    "title": "Biologically-plausible backpropagation through arbitrary timespans via  local neuromodulators",
    "abstract": "The spectacular successes of recurrent neural network models where key\nparameters are adjusted via backpropagation-based gradient descent have\ninspired much thought as to how biological neuronal networks might solve the\ncorresponding synaptic credit assignment problem. There is so far little\nagreement, however, as to how biological networks could implement the necessary\nbackpropagation through time, given widely recognized constraints of biological\nsynaptic network signaling architectures. Here, we propose that extra-synaptic\ndiffusion of local neuromodulators such as neuropeptides may afford an\neffective mode of backpropagation lying within the bounds of biological\nplausibility. Going beyond existing temporal truncation-based gradient\napproximations, our approximate gradient-based update rule, ModProp, propagates\ncredit information through arbitrary time steps. ModProp suggests that\nmodulatory signals can act on receiving cells by convolving their eligibility\ntraces via causal, time-invariant and synapse-type-specific filter taps. Our\nmathematical analysis of ModProp learning, together with simulation results on\nbenchmark temporal tasks, demonstrate the advantage of ModProp over existing\nbiologically-plausible temporal credit assignment rules. These results suggest\na potential neuronal mechanism for signaling credit information related to\nrecurrent interactions over a longer time horizon. Finally, we derive an\nin-silico implementation of ModProp that could serve as a low-complexity and\ncausal alternative to backpropagation through time.",
    "descriptor": "",
    "authors": [
      "Yuhan Helena Liu",
      "Stephen Smith",
      "Stefan Mihalas",
      "Eric Shea-Brown",
      "Uygar S\u00fcmb\u00fcl"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.01338"
  },
  {
    "id": "arXiv:2206.01344",
    "title": "Detecting Pulmonary Embolism from Computed Tomography Using  Convolutional Neural Network",
    "abstract": "The clinical symptoms of pulmonary embolism (PE) are very diverse and\nnon-specific, which makes it difficult to diagnose. In addition, pulmonary\nembolism has multiple triggers and is one of the major causes of vascular\ndeath. Therefore, if it can be detected and treated quickly, it can\nsignificantly reduce the risk of death in hospitalized patients. In the\ndetection process, the cost of computed tomography pulmonary angiography (CTPA)\nis high, and angiography requires the injection of contrast agents, which\nincrease the risk of damage to the patient. Therefore, this study will use a\ndeep learning approach to detect pulmonary embolism in all patients who take a\nCT image of the chest using a convolutional neural network. With the proposed\npulmonary embolism detection system, we can detect the possibility of pulmonary\nembolism at the same time as the patient's first CT image, and schedule the\nCTPA test immediately, saving more than a week of CT image screening time and\nproviding timely diagnosis and treatment to the patient.",
    "descriptor": "",
    "authors": [
      "Chia-Hung Yang",
      "Yun-Chien Cheng",
      "Chin Kuo"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01344"
  },
  {
    "id": "arXiv:2206.01373",
    "title": "Completion Time Minimization of Fog-RAN-Assisted Federated Learning With  Rate-Splitting Transmission",
    "abstract": "This work studies federated learning (FL) over a fog radio access network, in\nwhich multiple internet-of-things (IoT) devices cooperatively learn a shared\nmachine learning model by communicating with a cloud server (CS) through\ndistributed access points (APs). Under the assumption that the fronthaul links\nconnecting APs to CS have finite capacity, a rate-splitting transmission at IoT\ndevices (IDs) is proposed which enables hybrid edge and cloud decoding of split\nuplink messages. The problem of completion time minimization for FL is tackled\nby optimizing the rate-splitting transmission and fronthaul quantization\nstrategies along with training hyperparameters such as precision and iteration\nnumbers. Numerical results show that the proposed rate-splitting transmission\nachieves notable gains over benchmark schemes which rely solely on edge or\ncloud decoding.",
    "descriptor": "\nComments: accepted for publication on IEEE Transactions on Vehicular Technology\n",
    "authors": [
      "Seok-Hwan Park",
      "Hoon Lee"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01373"
  },
  {
    "id": "arXiv:2206.01385",
    "title": "Feedback Stabilization of Tank-Liquid System with Robustness to Wall  Friction",
    "abstract": "We solve the feedback stabilization problem for a tank, with friction,\ncontaining a liquid modeled by the viscous Saint-Venant system of Partial\nDifferential Equations. A spill-free exponential stabilization is achieved,\nwith robustness to the wall friction forces. A Control Lyapunov Functional\n(CLF) methodology with two different Lyapunov functionals is employed. These\nfunctionals determine specific parameterized sets which approximate the state\nspace. The feedback law is designed based only on one of the two functionals\n(which is the CLF) while the other functional is used for the derivation of\nestimates of the sup-norm of the velocity. The feedback law does not require\nthe knowledge of the exact relation of the friction coefficient. Two main\nresults are provided: the first deals with the special case of a\nvelocity-independent friction coefficient, while the second deals with the\ngeneral case. The obtained results are new even in the frictionless case.",
    "descriptor": "\nComments: 39 pages, 2 figures, submitted to ESAIM-COCV for possible publication. arXiv admin note: text overlap with arXiv:2108.11052\n",
    "authors": [
      "Iasson Karafyllis",
      "Filippos Vokos",
      "Miroslav Krstic"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)",
      "Analysis of PDEs (math.AP)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2206.01385"
  },
  {
    "id": "arXiv:2206.01393",
    "title": "Simulation of Crowd Egress with Environmental Stressors",
    "abstract": "This brief report presents a model to characterize evacuees' response to\nenvironmental stimuli during emergency egress, especially in smoke and fire\ncondition. The model is developed in consistency with stress theory, which\nexplains how an organism reacts to environmental stressors. We integrate the\ntheory in the well-known social-force model and apply the model to simulate\ncrowd evacuation in fire emergency. Part of the algorithm has been tested in\nFDS+EVAC.",
    "descriptor": "\nComments: 8 pages, 10 figures\n",
    "authors": [
      "Peng Wang",
      "Xiaoda Wang",
      "Timo Korhonen",
      "Peter Luh"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2206.01393"
  },
  {
    "id": "arXiv:2206.01397",
    "title": "Dynamic Structured Illumination Microscopy with a Neural Space-time  Model",
    "abstract": "Structured illumination microscopy (SIM) reconstructs a super-resolved image\nfrom multiple raw images; hence, acquisition speed is limited, making it\nunsuitable for dynamic scenes. We propose a new method, Speckle Flow SIM, that\nmodels sample motion during the data capture in order to reconstruct dynamic\nscenes with super-resolution. Speckle Flow SIM uses fixed speckle illumination\nand relies on sample motion to capture a sequence of raw images. Then, the\nspatio-temporal relationship of the dynamic scene is modeled using a neural\nspace-time model with coordinate-based multi-layer perceptrons (MLPs), and the\nmotion dynamics and the super-resolved scene are jointly recovered. We\nvalidated Speckle Flow SIM in simulation and built a simple, inexpensive\nexperimental setup with off-the-shelf components. We demonstrated that Speckle\nFlow SIM can reconstruct a dynamic scene with deformable motion and 1.88x the\ndiffraction-limited resolution in experiment.",
    "descriptor": "",
    "authors": [
      "Ruiming Cao",
      "Fanglin Linda Liu",
      "Li-Hao Yeh",
      "Laura Waller"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Image and Video Processing (eess.IV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.01397"
  },
  {
    "id": "arXiv:2206.01403",
    "title": "Wigner-Smith Time Delay Matrix for Electromagnetics: Systems with  Material Dispersion and Losses",
    "abstract": "The Wigner-Smith (WS) time delay matrix relates a system's scattering matrix\nto its frequency derivative and gives rise to so-called WS modes that\nexperience well-defined group delays when interacting with the system. For\nsystems composed of nondispersive and lossless materials, the WS time delay\nmatrix previously was shown to consist of volume integrals of energy-like\ndensities plus correction terms that account for the guiding, scattering, or\nradiating characteristics of the system. This study extends the use of the WS\ntime delay matrix to systems composed of dispersive and lossy materials.\nSpecifically, it shows that such systems' WS time delay matrix can be expressed\nby augmenting the previously derived expressions with terms that account for\nthe dispersive and lossy nature of the system, followed by a transformation\nthat disentangles effects of losses from time delays. Analytical and numerical\nexamples demonstrate the new formulation once again allows for the construction\nof frequency stable WS modes that experience well-defined group delays upon\ninteracting with a system.",
    "descriptor": "",
    "authors": [
      "Yiqian Mao",
      "Utkarsh R. Patel",
      "Eric Michielssen"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2206.01403"
  },
  {
    "id": "arXiv:2206.01430",
    "title": "LenslessPiCam: A Hardware and Software Platform for Lensless  Computational Imaging with a Raspberry Pi",
    "abstract": "Lensless imaging seeks to replace/remove the lens in a conventional imaging\nsystem. The earliest cameras were in fact lensless, relying on long exposure\ntimes to form images on the other end of a small aperture in a darkened\nroom/container (camera obscura). The introduction of a lens allowed for more\nlight throughput and therefore shorter exposure times, while retaining sharp\nfocus. The incorporation of digital sensors readily enabled the use of\ncomputational imaging techniques to post-process and enhance raw images (e.g.\nvia deblurring, inpainting, denoising, sharpening). Recently, imaging\nscientists have started leveraging computational imaging as an integral part of\nlensless imaging systems, allowing them to form viewable images from the highly\nmultiplexed raw measurements of lensless cameras (see [5] and references\ntherein for a comprehensive treatment of lensless imaging). This represents a\nreal paradigm shift in camera system design as there is more flexibility to\ncater the hardware to the application at hand (e.g. lightweight or flat\ndesigns). This increased flexibility comes however at the price of a more\ndemanding post-processing of the raw digital recordings and a tighter\nintegration of sensing and computation, often difficult to achieve in practice\ndue to inefficient interactions between the various communities of scientists\ninvolved. With LenslessPiCam, we provide an easily accessible hardware and\nsoftware framework to enable researchers, hobbyists, and students to implement\nand explore practical and computational aspects of lensless imaging. We also\nprovide detailed guides and exercises so that LenslessPiCam can be used as an\neducational resource, and point to results from our graduate-level signal\nprocessing course.",
    "descriptor": "",
    "authors": [
      "Eric Bezzam",
      "Sepand Kashani",
      "Martin Vetterli",
      "Matthieu Simeoni"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01430"
  },
  {
    "id": "arXiv:2206.01445",
    "title": "Quantum coherent feedback control with photons",
    "abstract": "The purpose of this paper is to study two-photon dynamics induced by the\ncoherent feedback control of a cavity quantum electrodynamics (cavity QED)\nsystem coupled to a waveguide with a terminal mirror. In this set-up, the\ntwo-level system in the cavity can work as a photon source, and the photon\nemitted into the waveguide can re-interact with the cavity-QED system many\ntimes after perfectly reflected by the terminal mirror of the waveguide, during\nwhich the feedback can tune the number of the photons in the waveguide and\ncavity. We analyze the dynamics of two-photon processes in this coherent\nfeedback network in two scenarios: the continuous mode coupling scheme and the\ndiscrete periodic mode coupling scheme between the waveguide and cavity. The\ndifference of these coupling schemes is due to the transmission of fields\nbetween the waveguide and cavity, and the their relative scales. Specifically,\nin the continuous mode coupling scheme, the generation of two-photon states is\ninfluenced by the length of the feedback loop of the waveguide and the coupling\nstrength between the waveguide and the cavity QED system. By tuning the length\nof the waveguide and the coupling strength, we are able to generate two-photon\nstates efficiently. In the discrete periodic mode coupling scheme, the Rabi\noscillation in the cavity can be stabilized and there are no notable two-photon\nstates in the waveguide.",
    "descriptor": "\nComments: 37 pages, 5 figure, comments are welcome\n",
    "authors": [
      "Haijin Ding",
      "Guofeng Zhang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.01445"
  },
  {
    "id": "arXiv:2206.01454",
    "title": "Indirect Active Learning",
    "abstract": "Traditional models of active learning assume a learner can directly\nmanipulate or query a covariate $X$ in order to study its relationship with a\nresponse $Y$. However, if $X$ is a feature of a complex system, it may be\npossible only to indirectly influence $X$ by manipulating a control variable\n$Z$, a scenario we refer to as Indirect Active Learning. Under a nonparametric\nmodel of Indirect Active Learning with a fixed budget, we study minimax\nconvergence rates for estimating the relationship between $X$ and $Y$ locally\nat a point, obtaining different rates depending on the complexities and noise\nlevels of the relationships between $Z$ and $X$ and between $X$ and $Y$. We\nalso identify minimax rates for passive learning under comparable assumptions.\nIn many cases, our results show that, while there is an asymptotic benefit to\nactive learning, this benefit is fully realized by a simple two-stage learner\nthat runs two passive experiments in sequence.",
    "descriptor": "",
    "authors": [
      "Shashank Singh"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.01454"
  },
  {
    "id": "arXiv:2206.01475",
    "title": "Functional Connectivity Methods for EEG-based Biometrics on a Large,  Heterogeneous Dataset",
    "abstract": "This study examines the utility of functional connectivity (FC) and\ngraph-based (GB) measures with a support vector machine classifier for use in\nelectroencephalogram (EEG) based biometrics. Although FC-based features have\nbeen used in biometric applications, studies assessing the identification\nalgorithms on heterogeneous and large datasets are scarce. This work\ninvestigates the performance of FC and GB metrics on a dataset of 184 subjects\nformed by pooling three datasets recorded under different protocols and\nacquisition systems. The results demonstrate the higher discriminatory power of\nFC than GB metrics. The identification accuracy increases with higher frequency\nEEG bands, indicating the enhanced uniqueness of the neural signatures in beta\nand gamma bands. Using all the 56 EEG channels common to the three databases,\nthe best identification accuracy of 97.4% is obtained using phase-locking value\n(PLV) based measures extracted from the gamma frequency band. Further, we\ninvestigate the effect of the length of the analysis epoch to determine the\ndata acquisition time required to obtain satisfactory identification accuracy.\nWhen the number of channels is reduced to 21 from 56, there is a marginal\nreduction of 2.4% only in the identification accuracy using PLV features in the\ngamma band. Additional experiments have been conducted to study the effect of\nthe cognitive state of the subject and mismatched train/test conditions on the\nperformance of the system.",
    "descriptor": "\nComments: 11 pages, 5 figures and 7 Tables\n",
    "authors": [
      "Pradeep Kumar G",
      "Utsav Dutta",
      "Kanishka Sharma",
      "Ramakrishnan Angarai Ganesan"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01475"
  },
  {
    "id": "arXiv:2206.01501",
    "title": "Key Agreement and Oblivious Transfer from Free-Energy Limitations",
    "abstract": "We propose one of the very few constructive consequences of the second law of\nthermodynamics. More specifically, we present protocols for secret-key\nestablishment and multiparty computation the security of which is based\nfundamentally on Landauer's principle. The latter states that the erasure cost\nof each bit of information is at least kTln2 (where k is Boltzmann's constant\nand T is the absolute temperature of the environment). Albeit impractical, our\nprotocols explore the limits of reversible computation, and the only assumption\nabout the adversary is her inability to access a quantity of free energy that\nis exponential in the one of the honest participants. Our results generalize to\nthe quantum realm.",
    "descriptor": "\nComments: 31 pages, 3 figures\n",
    "authors": [
      "Xavier Coiteux-Roy",
      "Stefan Wolf"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.01501"
  },
  {
    "id": "arXiv:2206.01526",
    "title": "Erd\u0151s Matching Conjecture for almost perfect matchings",
    "abstract": "In 1965 Erd\\H{o}s asked, what is the largest size of a family of $k$-elements\nsubsets of an $n$-element set that does not have a matching of size $s+1$? In\nthis note, we improve upon a recent result of Frankl and resolve this problem\nfor $s>101k^{3}$ and $(s+1)k\\le n<(s+1)(k+\\frac{1}{100k})$.",
    "descriptor": "",
    "authors": [
      "Dmitriy Kolupaev",
      "Andrey Kupavskii"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2206.01526"
  },
  {
    "id": "arXiv:2206.01544",
    "title": "Polynomial approximation on $C^2$-domains",
    "abstract": "We introduce appropriate computable moduli of smoothness to characterize the\nrate of best approximation by multivariate polynomials on a connected and\ncompact $C^2$-domain $\\Omega\\subset \\mathbb{R}^d$. This new modulus of\nsmoothness is defined via finite differences along the directions of coordinate\naxes, and along a number of tangential directions from the boundary. With this\nmodulus, we prove both the direct Jackson inequality and the corresponding\ninverse for the best polynomial approximation in $L_p(\\Omega)$. The Jackson\ninequality is established for the full range of $0<p\\leq \\infty$, while its\nproof relies on a recently established Whitney type estimates with constants\ndepending only on certain parameters; and on a highly localized polynomial\npartitions of unity on a $C^2$-domain which is of independent interest. The\ninverse inequality is established for $1\\leq p\\leq \\infty$, and its proof\nrelies on a recently proved Bernstein type inequality associated with the\ntangential derivatives on the boundary of $\\Omega$. Such an inequality also\nallows us to establish the inverse theorem for Ivanov's average moduli of\nsmoothness on general compact $C^2$-domains.",
    "descriptor": "\nComments: the material in this article is based heavily on a part of arXiv:1910.11719\n",
    "authors": [
      "Feng Dai",
      "Andriy Prymak"
    ],
    "subjectives": [
      "Classical Analysis and ODEs (math.CA)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.01544"
  },
  {
    "id": "arXiv:2206.01553",
    "title": "Detecting hyperbolic geometry in networks: why triangles are not enough",
    "abstract": "In the past decade, geometric network models have received vast attention in\nthe literature. These models formalize the natural idea that similar vertices\nare likely to connect. Because of that, these models are able to adequately\ncapture many common structural properties of real-world networks, such as\nself-invariance and high clustering. Indeed, many real-world networks can be\naccurately modeled by positioning vertices of a network graph in hyperbolic\nspaces. Nevertheless, if one observes only the network connections, the\npresence of geometry is not always evident. Currently, triangle counts and\nclustering coefficients are the standard statistics to signal the presence of\ngeometry. In this paper we show that triangle counts or clustering coefficients\nare insufficient because they fail to detect geometry induced by hyperbolic\nspaces. We therefore introduce a novel triangle-based statistic, which weighs\ntriangles based on their strength of evidence for geometry. We show\nanalytically, as well as on synthetic and real-world data, that this is a\npowerful statistic to detect hyperbolic geometry in networks.",
    "descriptor": "\nComments: 11 pages, 2 figures, 1 table\n",
    "authors": [
      "Nelly Litvak",
      "Riccardo Michielan",
      "Clara Stegehuis"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2206.01553"
  },
  {
    "id": "arXiv:2206.01562",
    "title": "Prescriptive maintenance with causal machine learning",
    "abstract": "Machine maintenance is a challenging operational problem, where the goal is\nto plan sufficient preventive maintenance to avoid machine failures and\noverhauls. Maintenance is often imperfect in reality and does not make the\nasset as good as new. Although a variety of imperfect maintenance policies have\nbeen proposed in the literature, these rely on strong assumptions regarding the\neffect of maintenance on the machine's condition, assuming the effect is (1)\ndeterministic or governed by a known probability distribution, and (2)\nmachine-independent. This work proposes to relax both assumptions by learning\nthe effect of maintenance conditional on a machine's characteristics from\nobservational data on similar machines using existing methodologies for causal\ninference. By predicting the maintenance effect, we can estimate the number of\noverhauls and failures for different levels of maintenance and, consequently,\noptimize the preventive maintenance frequency to minimize the total estimated\ncost. We validate our proposed approach using real-life data on more than 4,000\nmaintenance contracts from an industrial partner. Empirical results show that\nour novel, causal approach accurately predicts the maintenance effect and\nresults in individualized maintenance schedules that are more accurate and\ncost-effective than supervised or non-individualized approaches.",
    "descriptor": "",
    "authors": [
      "Toon Vanderschueren",
      "Robert Boute",
      "Tim Verdonck",
      "Bart Baesens",
      "Wouter Verbeke"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.01562"
  },
  {
    "id": "arXiv:2206.01592",
    "title": "MCD: Marginal Contrastive Discrimination for conditional density  estimation",
    "abstract": "We consider the problem of conditional density estimation, which is a major\ntopic of interest in the fields of statistical and machine learning. Our\nmethod, called Marginal Contrastive Discrimination, MCD, reformulates the\nconditional density function into two factors, the marginal density function of\nthe target variable and a ratio of density functions which can be estimated\nthrough binary classification. Like noise-contrastive methods, MCD can leverage\nstate-of-the-art supervised learning techniques to perform conditional density\nestimation, including neural networks. Our benchmark reveals that our method\nsignificantly outperforms in practice existing methods on most density models\nand regression datasets.",
    "descriptor": "",
    "authors": [
      "Benjamin Riu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2206.01592"
  },
  {
    "id": "arXiv:2206.01606",
    "title": "Excess risk analysis for epistemic uncertainty with application to  variational inference",
    "abstract": "We analyze the epistemic uncertainty (EU) of supervised learning in Bayesian\ninference by focusing on the excess risk. Existing analysis is limited to the\nBayesian setting, which assumes a correct model and exact Bayesian posterior\ndistribution. Thus we cannot apply the existing theory to modern Bayesian\nalgorithms, such as variational inference. To address this, we present a novel\nEU analysis in the frequentist setting, where data is generated from an unknown\ndistribution. We show a relation between the generalization ability and the\nwidely used EU measurements, such as the variance and entropy of the predictive\ndistribution. Then we show their convergence behaviors theoretically. Finally,\nwe propose new variational inference that directly controls the prediction and\nEU evaluation performances based on the PAC-Bayesian theory. Numerical\nexperiments show that our algorithm significantly improves the EU evaluation\nover the existing methods.",
    "descriptor": "",
    "authors": [
      "Futoshi Futami",
      "Tomoharu Iwata",
      "Naonori Ueda",
      "Issei Sato",
      "Masashi Sugiyama"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01606"
  },
  {
    "id": "arXiv:2206.01608",
    "title": "Structure-Preserving Model Order Reduction for Index One  Port-Hamiltonian Descriptor Systems",
    "abstract": "We develop optimization-based structure-preserving model order reduction\n(MOR) methods for port-Hamiltonian (pH) descriptor systems of differentiation\nindex one. Descriptor systems in pH form permit energy-based modeling and\nintuitive coupling of physical systems across different physical domains,\nscales, and accuracies. This makes pH models well-suited building-blocks for\ncomponent-wise modeling of large system networks. In this context, it is often\nnecessary to preserve the pH structure during MOR. We discuss current\nprojection-based and structure-preserving MOR algorithms for pH systems and\npresent a new optimization-based framework for that task. The benefits of our\nmethod include a simplified treatment of algebraic constraints and often a\nhigher accuracy of the resulting reduced-order model, which is demonstrated by\nseveral numerical examples.",
    "descriptor": "\nComments: 11 pages, 4 figures\n",
    "authors": [
      "Paul Schwerdtner",
      "Tim Moser",
      "Volker Mehrmann",
      "Matthias Voigt"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.01608"
  },
  {
    "id": "arXiv:2206.01638",
    "title": "Rapid rhythmic entrainment in bio-inspired central pattern generators",
    "abstract": "Entrainment of movement to a periodic stimulus is a characteristic\nintelligent behaviour in humans and an important goal for adaptive robotics. We\ndemonstrate a quadruped central pattern generator (CPG), consisting of modified\nMatsuoka neurons, that spontaneously adjusts its period of oscillation to that\nof a periodic input signal. This is done by simple forcing, with the aid of a\nfiltering network as well as a neural model with tonic input-dependent\noscillation period. We first use the NSGA3 algorithm to evolve the CPG\nparameters, using separate fitness functions for period tunability, limb\nhomogeneity and gait stability. Four CPGs, maximizing different weighted\naverages of the fitness functions, are then selected from the Pareto front and\neach is used as a basis for optimizing a filter network. Different numbers of\nneurons are tested for each filter network. We find that period tunability in\nparticular facilitates robust entrainment, that bounding gaits entrain more\neasily than walking gaits, and that more neurons in the filter network are\nbeneficial for pre-processing input signals. The system that we present can be\nused in conjunction with sensory feedback to allow low-level adaptive and\nrobust behaviour in walking robots.",
    "descriptor": "\nComments: 7 pages, 6 figures. To appear in Proceedings of the IEEE International Joint Conference on Neural Networks 2022\n",
    "authors": [
      "Alex Szorkovszky",
      "Frank Veenstra",
      "Kyrre Glette"
    ],
    "subjectives": [
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.01638"
  },
  {
    "id": "arXiv:2206.01644",
    "title": "Mirror modular cloning and fast quantum associative retrieval",
    "abstract": "We show that a quantum state can be perfectly cloned up to global mirroring\nwith a unitary transformation that depends on one single parameter. We then\nshow that this is equivalent to \"perfect\" cloning for quantum associative\nmemories which, as a consequence efficiently hold exponentially more\ninformation than their classical counterparts. Finally, we present a quantum\nassociative retrieval algorithm which can correct corrupted inputs and is\nexponentially faster than the Grover algorithm.",
    "descriptor": "",
    "authors": [
      "M. C. Diamantini",
      "C. A. Trugenberger"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01644"
  },
  {
    "id": "arXiv:2206.01660",
    "title": "L1-norm vs. L2-norm fitting in optimizing focal multi-channel tES  stimulation: linear and semidefinite programming vs. weighted least squares",
    "abstract": "This study focuses on Multi-Channel Transcranial Electrical Stimulation, a\nnon-invasive brain method for stimulating neuronal activity under the influence\nof low-intensity currents. We introduce mathematical formulation for finding a\ncurrent pattern which optimizes a L1-norm fit between a given focal target\ndistribution and volume current density inside the brain. L1-norm is well-known\nto favor well-localized or sparse distributions compared to L2-norm\n(least-squares) fitted estimates. We present a linear programming approach\nwhich performs L1-norm fitting and penalization of the current pattern (L1L1)\nto control the number of non-zero currents. The optimizer filters a large set\nof candidate solutions using a two-stage metaheuristic search in from a\npre-filtered set of candidates. The numerical simulation results, obtained with\nboth a 8- and 20-channel electrode montages, suggest that our hypothesis on the\nbenefits of L1-norm data fitting is valid. As compared to L1-norm regularized\nL2-norm fitting (L1L2) via semidefinite programming and weighted Tikhonov\nleast-squares method, the L1L1 results were overall preferable with respect to\nmaximizing the focused current density at the target position and the ratio\nbetween focused and nuisance current magnitudes. We propose the metaheuristic\nL1L1 optimization approach as a potential technique to obtain a well-localized\nstimulus with a controllable magnitude at a given target position. L1L1 finds a\ncurrent pattern with a steep contrast between the anodal and cathodal\nelectrodes meanwhile suppressing the nuisance currents in the brain, hence,\nproviding a potential alternative to modulate the effects of the stimulation,\ne.g., the sensation experienced by the subject.",
    "descriptor": "",
    "authors": [
      "Fernando Galaz Prieto",
      "Atena Rezaei",
      "Maryam Samavaki",
      "Sampsa Pursiainen"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.01660"
  },
  {
    "id": "arXiv:2206.01666",
    "title": "Algorithm for Constrained Markov Decision Process with Linear  Convergence",
    "abstract": "The problem of constrained Markov decision process is considered. An agent\naims to maximize the expected accumulated discounted reward subject to multiple\nconstraints on its costs (the number of constraints is relatively small). A new\ndual approach is proposed with the integration of two ingredients: entropy\nregularized policy optimizer and Vaidya's dual optimizer, both of which are\ncritical to achieve faster convergence. The finite-time error bound of the\nproposed approach is provided. Despite the challenge of the nonconcave\nobjective subject to nonconcave constraints, the proposed approach is shown to\nconverge (with linear rate) to the global optimum. The complexity expressed in\nterms of the optimality gap and the constraint violation significantly improves\nupon the existing primal-dual approaches.",
    "descriptor": "\nComments: 26 pages, 2 figures, 2 tables\n",
    "authors": [
      "Egor Gladin",
      "Maksim Lavrik-Karmazin",
      "Karina Zainullina",
      "Varvara Rudenko",
      "Alexander Gasnikov",
      "Martin Tak\u00e1\u010d"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01666"
  },
  {
    "id": "arXiv:2206.01685",
    "title": "Toward a realistic model of speech processing in the brain with  self-supervised learning",
    "abstract": "Several deep neural networks have recently been shown to generate activations\nsimilar to those of the brain in response to the same input. These algorithms,\nhowever, remain largely implausible: they require (1) extraordinarily large\namounts of data, (2) unobtainable supervised labels, (3) textual rather than\nraw sensory input, and / or (4) implausibly large memory (e.g. thousands of\ncontextual words). These elements highlight the need to identify algorithms\nthat, under these limitations, would suffice to account for both behavioral and\nbrain responses. Focusing on the issue of speech processing, we here\nhypothesize that self-supervised algorithms trained on the raw waveform\nconstitute a promising candidate. Specifically, we compare a recent\nself-supervised architecture, Wav2Vec 2.0, to the brain activity of 412\nEnglish, French, and Mandarin individuals recorded with functional Magnetic\nResonance Imaging (fMRI), while they listened to ~1h of audio books. Our\nresults are four-fold. First, we show that this algorithm learns brain-like\nrepresentations with as little as 600 hours of unlabelled speech -- a quantity\ncomparable to what infants can be exposed to during language acquisition.\nSecond, its functional hierarchy aligns with the cortical hierarchy of speech\nprocessing. Third, different training regimes reveal a functional\nspecialization akin to the cortex: Wav2Vec 2.0 learns sound-generic,\nspeech-specific and language-specific representations similar to those of the\nprefrontal and temporal cortices. Fourth, we confirm the similarity of this\nspecialization with the behavior of 386 additional participants. These\nelements, resulting from the largest neuroimaging benchmark to date, show how\nself-supervised learning can account for a rich organization of speech\nprocessing in the brain, and thus delineate a path to identify the laws of\nlanguage acquisition which shape the human brain.",
    "descriptor": "",
    "authors": [
      "Juliette Millet",
      "Charlotte Caucheteux",
      "Pierre Orhan",
      "Yves Boubenec",
      "Alexandre Gramfort",
      "Ewan Dunbar",
      "Christophe Pallier",
      "Jean-Remi King"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.01685"
  },
  {
    "id": "arXiv:2206.01693",
    "title": "Three-dimensional microstructure generation using generative adversarial  neural networks in the context of continuum micromechanics",
    "abstract": "Multiscale simulations are demanding in terms of computational resources. In\nthe context of continuum micromechanics, the multiscale problem arises from the\nneed of inferring macroscopic material parameters from the microscale. If the\nunderlying microstructure is explicitly given by means of microCT-scans,\nconvolutional neural networks can be used to learn the microstructure-property\nmapping, which is usually obtained from computational homogenization. The CNN\napproach provides a significant speedup, especially in the context of\nheterogeneous or functionally graded materials. Another application is\nuncertainty quantification, where many expansive evaluations are required.\nHowever, one bottleneck of this approach is the large number of training\nmicrostructures needed. This work closes this gap by proposing a generative\nadversarial network tailored towards three-dimensional microstructure\ngeneration. The lightweight algorithm is able to learn the underlying\nproperties of the material from a single microCT-scan without the need of\nexplicit descriptors. During prediction time, the network can produce unique\nthree-dimensional microstructures with the same properties of the original data\nin a fraction of seconds and at consistently high quality.",
    "descriptor": "",
    "authors": [
      "Alexander Henkes",
      "Henning Wessels"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01693"
  },
  {
    "id": "arXiv:1805.05121",
    "title": "The EPFL Logic Synthesis Libraries",
    "abstract": "Comments: 13 pages, originally accepted at Int'l Workshop on Logic & Synthesis 2018, extended for Workshop on Open-Source EDA Technology 2019",
    "descriptor": "\nComments: 13 pages, originally accepted at Int'l Workshop on Logic & Synthesis 2018, extended for Workshop on Open-Source EDA Technology 2019\n",
    "authors": [
      "Mathias Soeken",
      "Heinz Riener",
      "Winston Haaswijk",
      "Eleonora Testa",
      "Bruno Schmitt",
      "Giulia Meuli",
      "Fereshte Mozafari",
      "Siang-Yun Lee",
      "Alessandro Tempia Calvino",
      "Dewmini Sudara Marakkalage",
      "Giovanni De Micheli"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/1805.05121"
  },
  {
    "id": "arXiv:1902.04522",
    "title": "ELF OpenGo: An Analysis and Open Reimplementation of AlphaZero",
    "abstract": "Comments: Published as a conference paper at ICML 2019. This version contains supplementary appendices",
    "descriptor": "\nComments: Published as a conference paper at ICML 2019. This version contains supplementary appendices\n",
    "authors": [
      "Yuandong Tian",
      "Jerry Ma",
      "Qucheng Gong",
      "Shubho Sengupta",
      "Zhuoyuan Chen",
      "James Pinkerton",
      "C. Lawrence Zitnick"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1902.04522"
  },
  {
    "id": "arXiv:1902.10630",
    "title": "Alternating Synthetic and Real Gradients for Neural Language Modeling",
    "abstract": "Comments: renew the ideas",
    "descriptor": "\nComments: renew the ideas\n",
    "authors": [
      "Fangxin Shang",
      "Hao Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/1902.10630"
  },
  {
    "id": "arXiv:1904.01267",
    "title": "Decidability and Periodicity of Low Complexity Tilings",
    "abstract": "Comments: Extended version: new higher bounds on pattern complexity",
    "descriptor": "\nComments: Extended version: new higher bounds on pattern complexity\n",
    "authors": [
      "Jarkko Kari",
      "Etienne Moutot"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/1904.01267"
  },
  {
    "id": "arXiv:1906.11713",
    "title": "GASP, a generalized framework for agglomerative clustering of signed  graphs and its application to Instance Segmentation",
    "abstract": "Comments: Published in CVPR 2022",
    "descriptor": "\nComments: Published in CVPR 2022\n",
    "authors": [
      "Alberto Bailoni",
      "Constantin Pape",
      "Nathan H\u00fctsch",
      "Steffen Wolf",
      "Thorsten Beier",
      "Anna Kreshuk",
      "Fred A. Hamprecht"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1906.11713"
  },
  {
    "id": "arXiv:2002.03673",
    "title": "Rethinking Class-Prior Estimation for Positive-Unlabeled Learning",
    "abstract": "Rethinking Class-Prior Estimation for Positive-Unlabeled Learning",
    "descriptor": "",
    "authors": [
      "Yu Yao",
      "Tongliang Liu",
      "Bo Han",
      "Mingming Gong",
      "Gang Niu",
      "Masashi Sugiyama",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.03673"
  },
  {
    "id": "arXiv:2003.00354",
    "title": "A Stochastic Covariance Shrinkage Approach in Ensemble Transform Kalman  Filtering",
    "abstract": "A Stochastic Covariance Shrinkage Approach in Ensemble Transform Kalman  Filtering",
    "descriptor": "",
    "authors": [
      "Andrey A Popov",
      "Adrian Sandu",
      "Elias D. Nino-Ruiz",
      "Geir Evensen"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2003.00354"
  },
  {
    "id": "arXiv:2007.12291",
    "title": "Reinforcement Learning with Fast Stabilization in Linear Dynamical  Systems",
    "abstract": "Comments: 25th International Conference on Artificial Intelligence and Statistics (AISTATS) 2022",
    "descriptor": "\nComments: 25th International Conference on Artificial Intelligence and Statistics (AISTATS) 2022\n",
    "authors": [
      "Sahin Lale",
      "Kamyar Azizzadenesheli",
      "Babak Hassibi",
      "Anima Anandkumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.12291"
  },
  {
    "id": "arXiv:2010.01033",
    "title": "Numerical Methods to Compute the Coriolis Matrix and Christoffel Symbols  for Rigid-Body Systems",
    "abstract": "Comments: Author version of paper in the ASME Journal of Computational and Nonlinear Dynamics. Includes two footnotes added post-publication",
    "descriptor": "\nComments: Author version of paper in the ASME Journal of Computational and Nonlinear Dynamics. Includes two footnotes added post-publication\n",
    "authors": [
      "Sebastian Echeandia",
      "Patrick M. Wensing"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2010.01033"
  },
  {
    "id": "arXiv:2010.14692",
    "title": "Bidirectional Sampling Based Search Without Two Point Boundary Value  Solution",
    "abstract": "Comments: Journal version (Video: this https URL). Accepted to IEEE Transactions on Robotics (T-RO)",
    "descriptor": "\nComments: Journal version (Video: this https URL). Accepted to IEEE Transactions on Robotics (T-RO)\n",
    "authors": [
      "Sharan Nayak",
      "Michael W. Otte"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2010.14692"
  },
  {
    "id": "arXiv:2010.15114",
    "title": "The geometry of integration in text classification RNNs",
    "abstract": "Comments: 9+19 pages, 30 figures; v2: smaller file size",
    "descriptor": "\nComments: 9+19 pages, 30 figures; v2: smaller file size\n",
    "authors": [
      "Kyle Aitken",
      "Vinay V. Ramasesh",
      "Ankush Garg",
      "Yuan Cao",
      "David Sussillo",
      "Niru Maheswaranathan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.15114"
  },
  {
    "id": "arXiv:2011.03633",
    "title": "Augmented Equivariant Attention Networks for Microscopy Image  Reconstruction",
    "abstract": "Comments: 13 pages, 8 figures, accepted by TMI",
    "descriptor": "\nComments: 13 pages, 8 figures, accepted by TMI\n",
    "authors": [
      "Yaochen Xie",
      "Yu Ding",
      "Shuiwang Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.03633"
  },
  {
    "id": "arXiv:2101.02916",
    "title": "Towards Accelerating Training of Batch Normalization: A Manifold  Perspective",
    "abstract": "Towards Accelerating Training of Batch Normalization: A Manifold  Perspective",
    "descriptor": "",
    "authors": [
      "Mingyang Yi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.02916"
  },
  {
    "id": "arXiv:2102.01969",
    "title": "Greatest HITs: Higher inductive types in coinductive definitions via  induction under clocks",
    "abstract": "Comments: 29 pages",
    "descriptor": "\nComments: 29 pages\n",
    "authors": [
      "Magnus Baunsgaard Kristensen",
      "Rasmus Ejlers M\u00f8gelberg",
      "Andrea Vezzosi"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2102.01969"
  },
  {
    "id": "arXiv:2102.07433",
    "title": "Measuring the Internet during Covid-19 to Evaluate Work-from-Home",
    "abstract": "Measuring the Internet during Covid-19 to Evaluate Work-from-Home",
    "descriptor": "",
    "authors": [
      "Xiao Song",
      "John Heidemann"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2102.07433"
  },
  {
    "id": "arXiv:2102.07960",
    "title": "A Combination of Multi-Objective Genetic Algorithm and Deep Learning for  Music Harmony Generation",
    "abstract": "Comments: 14 pages, 8 figures, 1 table",
    "descriptor": "\nComments: 14 pages, 8 figures, 1 table\n",
    "authors": [
      "Maryam Majidi",
      "Rahil Mahdian Toroghi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.07960"
  },
  {
    "id": "arXiv:2102.09905",
    "title": "Self-Confidence of Undergraduate Students in Designing Software  Architecture",
    "abstract": "Self-Confidence of Undergraduate Students in Designing Software  Architecture",
    "descriptor": "",
    "authors": [
      "Lotfi ben Othmane",
      "Ameerah-Muhsina Jamil"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2102.09905"
  },
  {
    "id": "arXiv:2103.11878",
    "title": "BlonDe: An Automatic Evaluation Metric for Document-level Machine  Translation",
    "abstract": "Comments: 9 pages, accepted to NAACL 2022",
    "descriptor": "\nComments: 9 pages, accepted to NAACL 2022\n",
    "authors": [
      "Yuchen Eleanor Jiang",
      "Tianyu Liu",
      "Shuming Ma",
      "Dongdong Zhang",
      "Jian Yang",
      "Haoyang Huang",
      "Rico Sennrich",
      "Ryan Cotterell",
      "Mrinmaya Sachan",
      "Ming Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.11878"
  },
  {
    "id": "arXiv:2103.15163",
    "title": "Countering Racial Bias in Computer Graphics Research",
    "abstract": "Comments: 2 pages",
    "descriptor": "\nComments: 2 pages\n",
    "authors": [
      "Theodore Kim",
      "Holly Rushmeier",
      "Julie Dorsey",
      "Derek Nowrouzezahrai",
      "Raqi Syed",
      "Wojciech Jarosz",
      "A.M. Darke"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2103.15163"
  },
  {
    "id": "arXiv:2104.05097",
    "title": "Pay attention to your loss: understanding misconceptions about  1-Lipschitz neural networks",
    "abstract": "Comments: 28 pages, 10 figures",
    "descriptor": "\nComments: 28 pages, 10 figures\n",
    "authors": [
      "Louis B\u00e9thune",
      "Thibaut Boissin",
      "Mathieu Serrurier",
      "Franck Mamalet",
      "Corentin Friedrich",
      "Alberto Gonz\u00e1lez-Sanz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2104.05097"
  },
  {
    "id": "arXiv:2104.05877",
    "title": "Simpler is better: A comparative study of randomized algorithms for  computing the CUR decomposition",
    "abstract": "Comments: 21 pages, 7 figures",
    "descriptor": "\nComments: 21 pages, 7 figures\n",
    "authors": [
      "Yijun Dong",
      "Per-Gunnar Martinsson"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2104.05877"
  },
  {
    "id": "arXiv:2105.07132",
    "title": "Offline Time-Independent Multi-Agent Path Planning",
    "abstract": "Comments: to be presented at IJCAI-22",
    "descriptor": "\nComments: to be presented at IJCAI-22\n",
    "authors": [
      "Keisuke Okumura",
      "Fran\u00e7ois Bonnet",
      "Yasumasa Tamura",
      "Xavier D\u00e9fago"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.07132"
  },
  {
    "id": "arXiv:2105.07877",
    "title": "Quantum Uncertainty in Decision Theory",
    "abstract": "Comments: 17 pages",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "V.I. Yukalov"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2105.07877"
  },
  {
    "id": "arXiv:2105.10018",
    "title": "Scalable Multirobot Planning for Informed Spatial Sampling",
    "abstract": "Comments: Accepted for publication on Autonomous Robots (Journal), Spl. Issue on Robot Swarms in the Real World: from Design to Deployment",
    "descriptor": "\nComments: Accepted for publication on Autonomous Robots (Journal), Spl. Issue on Robot Swarms in the Real World: from Design to Deployment\n",
    "authors": [
      "Sandeep Manjanna",
      "M. Ani Hsieh",
      "Gregory Dudek"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.10018"
  },
  {
    "id": "arXiv:2105.14431",
    "title": "Contact Mode Guided Motion Planning for Quasidynamic Dexterous  Manipulation in 3D",
    "abstract": "Contact Mode Guided Motion Planning for Quasidynamic Dexterous  Manipulation in 3D",
    "descriptor": "",
    "authors": [
      "Xianyi Cheng",
      "Eric Huang",
      "Yifan Hou",
      "Matthew T. Mason"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.14431"
  },
  {
    "id": "arXiv:2106.00011",
    "title": "Constrained Deep Reinforcement Based Functional Split Optimization in  Virtualized RANs",
    "abstract": "Comments: This article has been accepted for publication in IEEE Transactions on Wireless Communications",
    "descriptor": "\nComments: This article has been accepted for publication in IEEE Transactions on Wireless Communications\n",
    "authors": [
      "Fahri Wisnu Murti",
      "Samad Ali",
      "Matti Latva-aho"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.00011"
  },
  {
    "id": "arXiv:2106.03228",
    "title": "Distributional Reinforcement Learning with Unconstrained Monotonic  Neural Networks",
    "abstract": "Distributional Reinforcement Learning with Unconstrained Monotonic  Neural Networks",
    "descriptor": "",
    "authors": [
      "Thibaut Th\u00e9ate",
      "Antoine Wehenkel",
      "Adrien Bolland",
      "Gilles Louppe",
      "Damien Ernst"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.03228"
  },
  {
    "id": "arXiv:2106.03987",
    "title": "Weakly Supervised Volumetric Image Segmentation with Deformed Templates",
    "abstract": "Comments: 12 Pages",
    "descriptor": "\nComments: 12 Pages\n",
    "authors": [
      "Udaranga Wickramasinghe",
      "Patrick M. Jensen",
      "Mian Shah",
      "Jiancheng Yang",
      "Pascal Fua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.03987"
  },
  {
    "id": "arXiv:2106.11653",
    "title": "Source Data-Free Cross-Domain Semantic Segmentation: Align, Teach and  Propagate",
    "abstract": "Comments: 15 pages, 6 figures",
    "descriptor": "\nComments: 15 pages, 6 figures\n",
    "authors": [
      "Yuxi Wang",
      "Jian Liang",
      "Zhaoxiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11653"
  },
  {
    "id": "arXiv:2106.12196",
    "title": "Multiband VAE: Latent Space Alignment for Knowledge Consolidation in  Continual Learning",
    "abstract": "Multiband VAE: Latent Space Alignment for Knowledge Consolidation in  Continual Learning",
    "descriptor": "",
    "authors": [
      "Kamil Deja",
      "Pawe\u0142 Wawrzy\u0144ski",
      "Wojciech Masarczyk",
      "Daniel Marczak",
      "Tomasz Trzci\u0144ski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.12196"
  },
  {
    "id": "arXiv:2106.12413",
    "title": "Transformer Meets Convolution: A Bilateral Awareness Network for  Semantic Segmentation of Very Fine Resolution Urban Scene Images",
    "abstract": "Comments: Accepted by Remote Sensing, see this https URL",
    "descriptor": "\nComments: Accepted by Remote Sensing, see this https URL\n",
    "authors": [
      "Libo Wang",
      "Rui Li",
      "Dongzhi Wang",
      "Chenxi Duan",
      "Teng Wang",
      "Xiaoliang Meng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.12413"
  },
  {
    "id": "arXiv:2106.15113",
    "title": "An Efficient Cervical Whole Slide Image Analysis Framework Based on  Multi-scale Semantic and Location Deep Features",
    "abstract": "Comments: 15 pages, 8 figures, under review to Medical Image Analysis (2nd round)",
    "descriptor": "\nComments: 15 pages, 8 figures, under review to Medical Image Analysis (2nd round)\n",
    "authors": [
      "Ziquan Wei",
      "Shenghua Cheng",
      "Junbo Hu",
      "Li Chen",
      "Shaoqun Zeng",
      "Xiuli Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.15113"
  },
  {
    "id": "arXiv:2107.00910",
    "title": "Learned Token Pruning for Transformers",
    "abstract": "Comments: KDD 2022 (Research Track)",
    "descriptor": "\nComments: KDD 2022 (Research Track)\n",
    "authors": [
      "Sehoon Kim",
      "Sheng Shen",
      "David Thorsley",
      "Amir Gholami",
      "Woosuk Kwon",
      "Joseph Hassoun",
      "Kurt Keutzer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.00910"
  },
  {
    "id": "arXiv:2108.03348",
    "title": "Global Self-Attention as a Replacement for Graph Convolution",
    "abstract": "Comments: The accepted version in KDD '22",
    "descriptor": "\nComments: The accepted version in KDD '22\n",
    "authors": [
      "Md Shamim Hussain",
      "Mohammed J. Zaki",
      "Dharmashankar Subramanian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.03348"
  },
  {
    "id": "arXiv:2108.12285",
    "title": "OpenFish: Biomimetic Design of a Soft Robotic Fish for High Speed  Locomotion",
    "abstract": "OpenFish: Biomimetic Design of a Soft Robotic Fish for High Speed  Locomotion",
    "descriptor": "",
    "authors": [
      "Sander C. van den Berg",
      "Rob B.N. Scharff",
      "Zolt\u00e1n Rus\u00e1k",
      "Jun Wu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2108.12285"
  },
  {
    "id": "arXiv:2109.00389",
    "title": "Optimization problems in graphs with locational uncertainty",
    "abstract": "Optimization problems in graphs with locational uncertainty",
    "descriptor": "",
    "authors": [
      "Marin Bougeret",
      "J\u00e9r\u00e9my Omer",
      "Michael Poss"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2109.00389"
  },
  {
    "id": "arXiv:2109.01365",
    "title": "A Comparative Study of Nonlinear MPC and Differential-Flatness-Based  Control for Quadrotor Agile Flight",
    "abstract": "Comments: The paper has been accepted for publication in the IEEE Transactions on Robotics (T-RO), 2022",
    "descriptor": "\nComments: The paper has been accepted for publication in the IEEE Transactions on Robotics (T-RO), 2022\n",
    "authors": [
      "Sihao Sun",
      "Angel Romero",
      "Philipp Foehn",
      "Elia Kaufmann",
      "Davide Scaramuzza"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.01365"
  },
  {
    "id": "arXiv:2109.02986",
    "title": "Instance-dependent Label-noise Learning under a Structural Causal Model",
    "abstract": "Instance-dependent Label-noise Learning under a Structural Causal Model",
    "descriptor": "",
    "authors": [
      "Yu Yao",
      "Tongliang Liu",
      "Mingming Gong",
      "Bo Han",
      "Gang Niu",
      "Kun Zhang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.02986"
  },
  {
    "id": "arXiv:2109.12147",
    "title": "Trajectory Distribution Control for Model Predictive Path Integral  Control using Covariance Steering",
    "abstract": "Comments: \"Previously titled \"Improving Model Predictive Path Integral Using Covariance Steering\", this paper is one of the Outstanding Planning Paper Award finalists in ICRA 2022. For associated video, see this https URL .\"",
    "descriptor": "\nComments: \"Previously titled \"Improving Model Predictive Path Integral Using Covariance Steering\", this paper is one of the Outstanding Planning Paper Award finalists in ICRA 2022. For associated video, see this https URL .\"\n",
    "authors": [
      "Ji Yin",
      "Zhiyuan Zhang",
      "Evangelos Theodorou",
      "Panagiotis Tsiotras"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.12147"
  },
  {
    "id": "arXiv:2109.12191",
    "title": "NanoBatch Privacy: Enabling fast Differentially Private learning on the  IPU",
    "abstract": "NanoBatch Privacy: Enabling fast Differentially Private learning on the  IPU",
    "descriptor": "",
    "authors": [
      "Edward H. Lee",
      "Mario Michael Krell",
      "Alexander Tsyplikhin",
      "Victoria Rege",
      "Errol Colak",
      "Kristen W. Yeom"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2109.12191"
  },
  {
    "id": "arXiv:2109.13410",
    "title": "KITTI-360: A Novel Dataset and Benchmarks for Urban Scene Understanding  in 2D and 3D",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:1511.03240",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1511.03240\n",
    "authors": [
      "Yiyi Liao",
      "Jun Xie",
      "Andreas Geiger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.13410"
  },
  {
    "id": "arXiv:2110.00719",
    "title": "One-Bit Matrix Completion with Differential Privacy",
    "abstract": "Comments: In this updated version, we have added a new privacy-preserving perturbation method and the related experiments. In addition, we have added theoretical analysis on the recovery error bounds",
    "descriptor": "\nComments: In this updated version, we have added a new privacy-preserving perturbation method and the related experiments. In addition, we have added theoretical analysis on the recovery error bounds\n",
    "authors": [
      "Zhengpin Li",
      "Zheng Wei",
      "Zengfeng Huang",
      "Xiaojun Mao",
      "Jian Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.00719"
  },
  {
    "id": "arXiv:2110.01351",
    "title": "Towards Time-Optimal Tunnel-Following for Quadrotors",
    "abstract": "Comments: This paper has been accepted for publication at the IEEE International Conference on Robotics and Automation (ICRA), Philadelphia, USA, May 2022. Copyright @ IEEE",
    "descriptor": "\nComments: This paper has been accepted for publication at the IEEE International Conference on Robotics and Automation (ICRA), Philadelphia, USA, May 2022. Copyright @ IEEE\n",
    "authors": [
      "Jon Arrizabalaga",
      "Markus Ryll"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.01351"
  },
  {
    "id": "arXiv:2110.01439",
    "title": "SecurePtrs: Proving Secure Compilation with Data-Flow Back-Translation  and Turn-Taking Simulation",
    "abstract": "Comments: CSF 2022 pre-print with extra appendices",
    "descriptor": "\nComments: CSF 2022 pre-print with extra appendices\n",
    "authors": [
      "Akram El-Korashy",
      "Roberto Blanco",
      "J\u00e9r\u00e9my Thibault",
      "Adrien Durier",
      "Deepak Garg",
      "Catalin Hritcu"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.01439"
  },
  {
    "id": "arXiv:2110.07572",
    "title": "LAGr: Labeling Aligned Graphs for Improving Systematic Generalization in  Semantic Parsing",
    "abstract": "LAGr: Labeling Aligned Graphs for Improving Systematic Generalization in  Semantic Parsing",
    "descriptor": "",
    "authors": [
      "Dora Jambor",
      "Dzmitry Bahdanau"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.07572"
  },
  {
    "id": "arXiv:2110.10149",
    "title": "Continuous Control with Action Quantization from Demonstrations",
    "abstract": "Comments: Accepted to ICML 2022",
    "descriptor": "\nComments: Accepted to ICML 2022\n",
    "authors": [
      "Robert Dadashi",
      "L\u00e9onard Hussenot",
      "Damien Vincent",
      "Sertan Girgin",
      "Anton Raichuk",
      "Matthieu Geist",
      "Olivier Pietquin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.10149"
  },
  {
    "id": "arXiv:2111.01983",
    "title": "Obvious Manipulability of Voting Rules",
    "abstract": "Obvious Manipulability of Voting Rules",
    "descriptor": "",
    "authors": [
      "Haris Aziz",
      "Alexander Lam"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2111.01983"
  },
  {
    "id": "arXiv:2111.08308",
    "title": "Learning with convolution and pooling operations in kernel methods",
    "abstract": "Comments: 52 pages, 6 figures",
    "descriptor": "\nComments: 52 pages, 6 figures\n",
    "authors": [
      "Theodor Misiakiewicz",
      "Song Mei"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08308"
  },
  {
    "id": "arXiv:2111.08823",
    "title": "Meta-Auto-Decoder for Solving Parametric Partial Differential Equations",
    "abstract": "Meta-Auto-Decoder for Solving Parametric Partial Differential Equations",
    "descriptor": "",
    "authors": [
      "Xiang Huang",
      "Zhanhong Ye",
      "Hongsheng Liu",
      "Beiji Shi",
      "Zidong Wang",
      "Kang Yang",
      "Yang Li",
      "Bingya Weng",
      "Min Wang",
      "Haotian Chu",
      "Jing Zhou",
      "Fan Yu",
      "Bei Hua",
      "Lei Chen",
      "Bin Dong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.08823"
  },
  {
    "id": "arXiv:2111.11215",
    "title": "Direct Voxel Grid Optimization: Super-fast Convergence for Radiance  Fields Reconstruction",
    "abstract": "Comments: Project page at this https URL ; Code at this https URL",
    "descriptor": "\nComments: Project page at this https URL ; Code at this https URL\n",
    "authors": [
      "Cheng Sun",
      "Min Sun",
      "Hwann-Tzong Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.11215"
  },
  {
    "id": "arXiv:2111.12981",
    "title": "Efficient Mean Estimation with Pure Differential Privacy via a  Sum-of-Squares Exponential Mechanism",
    "abstract": "Comments: 66 pages, STOC 2022",
    "descriptor": "\nComments: 66 pages, STOC 2022\n",
    "authors": [
      "Samuel B. Hopkins",
      "Gautam Kamath",
      "Mahbod Majid"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.12981"
  },
  {
    "id": "arXiv:2111.13040",
    "title": "Sketch-Guided Equality Saturation: Scaling Equality Saturation to  Complex Optimizations of Functional Programs",
    "abstract": "Comments: 23 pages excluding references, submitted to OOPLSA 2022",
    "descriptor": "\nComments: 23 pages excluding references, submitted to OOPLSA 2022\n",
    "authors": [
      "Thomas Koehler",
      "Phil Trinder",
      "Michel Steuwer"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2111.13040"
  },
  {
    "id": "arXiv:2111.13336",
    "title": "MAE-DET: Revisiting Maximum Entropy Principle in Zero-Shot NAS for  Efficient Object Detection",
    "abstract": "MAE-DET: Revisiting Maximum Entropy Principle in Zero-Shot NAS for  Efficient Object Detection",
    "descriptor": "",
    "authors": [
      "Zhenhong Sun",
      "Ming Lin",
      "Xiuyu Sun",
      "Zhiyu Tan",
      "Hao Li",
      "Rong Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.13336"
  },
  {
    "id": "arXiv:2112.00720",
    "title": "Quasi-universality of Reeb graph distances",
    "abstract": "Comments: 17 pages + 6 pages appendix, 5 figures; this version includes the appendix to the conference paper for SoCG 2022 with the same content otherwise",
    "descriptor": "\nComments: 17 pages + 6 pages appendix, 5 figures; this version includes the appendix to the conference paper for SoCG 2022 with the same content otherwise\n",
    "authors": [
      "Ulrich Bauer",
      "H\u00e5vard Bakke Bjerkevik",
      "Benedikt Fluhr"
    ],
    "subjectives": [
      "Geometric Topology (math.GT)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2112.00720"
  },
  {
    "id": "arXiv:2112.01085",
    "title": "PTCT: Patches with 3D-Temporal Convolutional Transformer Network for  Precipitation Nowcasting",
    "abstract": "Comments: 9 pages, 3 figures",
    "descriptor": "\nComments: 9 pages, 3 figures\n",
    "authors": [
      "Ziao Yang",
      "Xiangrui Yang",
      "Qifeng Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2112.01085"
  },
  {
    "id": "arXiv:2112.04417",
    "title": "What I Cannot Predict, I Do Not Understand: A Human-Centered Evaluation  Framework for Explainability Methods",
    "abstract": "What I Cannot Predict, I Do Not Understand: A Human-Centered Evaluation  Framework for Explainability Methods",
    "descriptor": "",
    "authors": [
      "Julien Colin",
      "Thomas Fel",
      "Remi Cadene",
      "Thomas Serre"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.04417"
  },
  {
    "id": "arXiv:2112.07837",
    "title": "Central-Smoothing Hypergraph Neural Networks for Predicting Drug-Drug  Interactions",
    "abstract": "Central-Smoothing Hypergraph Neural Networks for Predicting Drug-Drug  Interactions",
    "descriptor": "",
    "authors": [
      "Duc Anh Nguyen",
      "Canh Hao Nguyen",
      "Hiroshi Mamitsuka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2112.07837"
  },
  {
    "id": "arXiv:2112.08765",
    "title": "On Up-to Context Techniques in the $\u03c0$-calculus",
    "abstract": "On Up-to Context Techniques in the $\u03c0$-calculus",
    "descriptor": "",
    "authors": [
      "Enguerrand Prebet"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2112.08765"
  },
  {
    "id": "arXiv:2112.08909",
    "title": "CodedPaddedFL and CodedSecAgg: Straggler Mitigation and Secure  Aggregation in Federated Learning",
    "abstract": "Comments: 14 pages, 7 figures, this work has been submitted to the IEEE for possible publication",
    "descriptor": "\nComments: 14 pages, 7 figures, this work has been submitted to the IEEE for possible publication\n",
    "authors": [
      "Reent Schlegel",
      "Siddhartha Kumar",
      "Eirik Rosnes",
      "Alexandre Graell i Amat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.08909"
  },
  {
    "id": "arXiv:2112.08935",
    "title": "MVSS-Net: Multi-View Multi-Scale Supervised Networks for Image  Manipulation Detection",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2104.06832 Accepted by T-PAMI",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2104.06832 Accepted by T-PAMI\n",
    "authors": [
      "Chengbo Dong",
      "Xinru Chen",
      "Ruohan Hu",
      "Juan Cao",
      "Xirong Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08935"
  },
  {
    "id": "arXiv:2112.09963",
    "title": "The Kolmogorov Superposition Theorem can Break the Curse of  Dimensionality When Approximating High Dimensional Functions",
    "abstract": "The Kolmogorov Superposition Theorem can Break the Curse of  Dimensionality When Approximating High Dimensional Functions",
    "descriptor": "",
    "authors": [
      "Ming-Jun Lai",
      "Zhaiming Shen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.09963"
  },
  {
    "id": "arXiv:2112.14988",
    "title": "Deniable Encryption in a Quantum World",
    "abstract": "Deniable Encryption in a Quantum World",
    "descriptor": "",
    "authors": [
      "Andrea Coladangelo",
      "Shafi Goldwasser",
      "Umesh Vazirani"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.14988"
  },
  {
    "id": "arXiv:2201.06459",
    "title": "A Novel Framework to Jointly Compress and Index Remote Sensing Images  for Efficient Content-Based Retrieval",
    "abstract": "Comments: Accepted at IEEE International Geoscience and Remote Sensing Symposium (IGARSS) 2022. Our code is available at this https URL",
    "descriptor": "\nComments: Accepted at IEEE International Geoscience and Remote Sensing Symposium (IGARSS) 2022. Our code is available at this https URL\n",
    "authors": [
      "Gencer Sumbul",
      "Jun Xiang",
      "Nimisha Thekke Madam",
      "Beg\u00fcm Demir"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.06459"
  },
  {
    "id": "arXiv:2201.07784",
    "title": "On Distributed Lossy Coding of Symmetrically Correlated Gaussian Sources",
    "abstract": "On Distributed Lossy Coding of Symmetrically Correlated Gaussian Sources",
    "descriptor": "",
    "authors": [
      "Siyao Zhou",
      "Sadaf Salehkalaibar",
      "Jingjing Qian",
      "Jun Chen",
      "Wuxian Shi",
      "Yiqun Ge",
      "Wen Tong"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.07784"
  },
  {
    "id": "arXiv:2201.08814",
    "title": "Separating polynomial $\u03c7$-boundedness from $\u03c7$-boundedness",
    "abstract": "Comments: v2: new proof with improved results",
    "descriptor": "\nComments: v2: new proof with improved results\n",
    "authors": [
      "Marcin Bria\u0144ski",
      "James Davies",
      "Bartosz Walczak"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2201.08814"
  },
  {
    "id": "arXiv:2201.12023",
    "title": "Alpa: Automating Inter- and Intra-Operator Parallelism for Distributed  Deep Learning",
    "abstract": "Comments: OSDI 2022",
    "descriptor": "\nComments: OSDI 2022\n",
    "authors": [
      "Lianmin Zheng",
      "Zhuohan Li",
      "Hao Zhang",
      "Yonghao Zhuang",
      "Zhifeng Chen",
      "Yanping Huang",
      "Yida Wang",
      "Eric P. Xing",
      "Yuanzhong Xu",
      "Danyang Zhuo",
      "Joseph E. Gonzalez",
      "Ion Stoica"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2201.12023"
  },
  {
    "id": "arXiv:2201.12680",
    "title": "Understanding Deep Contrastive Learning via Coordinate-wise Optimization",
    "abstract": "Understanding Deep Contrastive Learning via Coordinate-wise Optimization",
    "descriptor": "",
    "authors": [
      "Yuandong Tian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2201.12680"
  },
  {
    "id": "arXiv:2202.01824",
    "title": "Waveform inversion via reduced order modeling",
    "abstract": "Waveform inversion via reduced order modeling",
    "descriptor": "",
    "authors": [
      "Liliana Borcea",
      "Josselin Garnier",
      "Alexander V. Mamonov",
      "J\u00f6rn Zimmerling"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.01824"
  },
  {
    "id": "arXiv:2202.02394",
    "title": "JARVix at SemEval-2022 Task 2: It Takes One to Know One? Idiomaticity  Detection using Zero and One Shot Learning",
    "abstract": "Comments: Accepted at the 16th International Workshop on Semantic Evaluation (SemEval-2022), NAACL. Best Project Award for Georgia Tech CS 7650. Code available at this https URL",
    "descriptor": "\nComments: Accepted at the 16th International Workshop on Semantic Evaluation (SemEval-2022), NAACL. Best Project Award for Georgia Tech CS 7650. Code available at this https URL\n",
    "authors": [
      "Yash Jakhotiya",
      "Vaibhav Kumar",
      "Ashwin Pathak",
      "Raj Shah"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02394"
  },
  {
    "id": "arXiv:2202.02812",
    "title": "Lossy Gradient Compression: How Much Accuracy Can One Bit Buy?",
    "abstract": "Lossy Gradient Compression: How Much Accuracy Can One Bit Buy?",
    "descriptor": "",
    "authors": [
      "Sadaf Salehkalaibar",
      "Stefano Rini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.02812"
  },
  {
    "id": "arXiv:2202.03302",
    "title": "Numerical analysis for the interaction of mean curvature flow and  diffusion on closed surfaces",
    "abstract": "Numerical analysis for the interaction of mean curvature flow and  diffusion on closed surfaces",
    "descriptor": "",
    "authors": [
      "Charles M. Elliott",
      "Harald Garcke",
      "Bal\u00e1zs Kov\u00e1cs"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.03302"
  },
  {
    "id": "arXiv:2202.05139",
    "title": "Game of Privacy: Towards Better Federated Platform Collaboration under  Privacy Restriction",
    "abstract": "Comments: Submitted to KDD 2022",
    "descriptor": "\nComments: Submitted to KDD 2022\n",
    "authors": [
      "Chuhan Wu",
      "Fangzhao Wu",
      "Tao Qi",
      "Yanlin Wang",
      "Yuqing Yang",
      "Yongfeng Huang",
      "Xing Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05139"
  },
  {
    "id": "arXiv:2202.07135",
    "title": "Compositional Scene Representation Learning via Reconstruction: A Survey",
    "abstract": "Compositional Scene Representation Learning via Reconstruction: A Survey",
    "descriptor": "",
    "authors": [
      "Jinyang Yuan",
      "Tonglin Chen",
      "Bin Li",
      "Xiangyang Xue"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07135"
  },
  {
    "id": "arXiv:2202.07549",
    "title": "Robust Multi-Objective Bayesian Optimization Under Input Noise",
    "abstract": "Comments: To appear at ICML 2022. 36 pages. Code is available at this https URL",
    "descriptor": "\nComments: To appear at ICML 2022. 36 pages. Code is available at this https URL\n",
    "authors": [
      "Samuel Daulton",
      "Sait Cakmak",
      "Maximilian Balandat",
      "Michael A. Osborne",
      "Enlu Zhou",
      "Eytan Bakshy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.07549"
  },
  {
    "id": "arXiv:2202.08876",
    "title": "An alternative approach to train neural networks using monotone  variational inequality",
    "abstract": "An alternative approach to train neural networks using monotone  variational inequality",
    "descriptor": "",
    "authors": [
      "Chen Xu",
      "Xiuyuan Cheng",
      "Yao Xie"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08876"
  },
  {
    "id": "arXiv:2202.09557",
    "title": "Safe Control Synthesis with Uncertain Dynamics and Constraints",
    "abstract": "Safe Control Synthesis with Uncertain Dynamics and Constraints",
    "descriptor": "",
    "authors": [
      "Kehan Long",
      "Vikas Dhiman",
      "Melvin Leok",
      "Jorge Cort\u00e9s",
      "Nikolay Atanasov"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.09557"
  },
  {
    "id": "arXiv:2202.10847",
    "title": "UncertaINR: Uncertainty Quantification of End-to-End Implicit Neural  Representations for Computed Tomography",
    "abstract": "UncertaINR: Uncertainty Quantification of End-to-End Implicit Neural  Representations for Computed Tomography",
    "descriptor": "",
    "authors": [
      "Francisca Vasconcelos",
      "Bobby He",
      "Nalini Singh",
      "Yee Whye Teh"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.10847"
  },
  {
    "id": "arXiv:2202.11966",
    "title": "A Fair Empirical Risk Minimization with Generalized Entropy",
    "abstract": "Comments: 34 pages and 12 figures Revised for adding experimental results",
    "descriptor": "\nComments: 34 pages and 12 figures Revised for adding experimental results\n",
    "authors": [
      "Youngmi Jin",
      "Tae-Jin Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.11966"
  },
  {
    "id": "arXiv:2202.12448",
    "title": "Deep neural networks for fine-grained surveillance of overdose mortality",
    "abstract": "Comments: Minor revision under review at the American Journal of Epidemiology",
    "descriptor": "\nComments: Minor revision under review at the American Journal of Epidemiology\n",
    "authors": [
      "Patrick J. Ward",
      "April M. Young",
      "Svetla Slavova",
      "Madison Liford",
      "Lara Daniels",
      "Ripley Lucas",
      "Ramakanth Kavuluru"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.12448"
  },
  {
    "id": "arXiv:2202.13164",
    "title": "Edge Augmentation for Large-Scale Sketch Recognition without Sketches",
    "abstract": "Edge Augmentation for Large-Scale Sketch Recognition without Sketches",
    "descriptor": "",
    "authors": [
      "Nikos Efthymiadis",
      "Giorgos Tolias",
      "Ondrej Chum"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.13164"
  },
  {
    "id": "arXiv:2202.13174",
    "title": "BioADAPT-MRC: Adversarial Learning-based Domain Adaptation Improves  Biomedical Machine Reading Comprehension Task",
    "abstract": "BioADAPT-MRC: Adversarial Learning-based Domain Adaptation Improves  Biomedical Machine Reading Comprehension Task",
    "descriptor": "",
    "authors": [
      "Maria Mahbub",
      "Sudarshan Srinivasan",
      "Edmon Begoli",
      "Gregory D Peterson"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.13174"
  },
  {
    "id": "arXiv:2202.13733",
    "title": "On the Benefits of Large Learning Rates for Kernel Methods",
    "abstract": "Comments: Accepted paper at Conference COLT 2022. To be published to Proceedings of Machine Learning Research (PMLR)",
    "descriptor": "\nComments: Accepted paper at Conference COLT 2022. To be published to Proceedings of Machine Learning Research (PMLR)\n",
    "authors": [
      "Gaspard Beugnot",
      "Julien Mairal",
      "Alessandro Rudi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.13733"
  },
  {
    "id": "arXiv:2203.03405",
    "title": "Depth-SIMS: Semi-Parametric Image and Depth Synthesis",
    "abstract": "Depth-SIMS: Semi-Parametric Image and Depth Synthesis",
    "descriptor": "",
    "authors": [
      "Valentina Musat",
      "Daniele De Martini",
      "Matthew Gadd",
      "Paul Newman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.03405"
  },
  {
    "id": "arXiv:2203.10850",
    "title": "Automatic Creation of High-Bandwidth Memory Architectures from  Domain-Specific Languages: The Case of Computational Fluid Dynamics",
    "abstract": "Comments: Submitted to ACM Transactions on Reconfigurable Technology and Systems (TRETS)",
    "descriptor": "\nComments: Submitted to ACM Transactions on Reconfigurable Technology and Systems (TRETS)\n",
    "authors": [
      "Stephanie Soldavini",
      "Karl F. A. Friebel",
      "Mattia Tibaldi",
      "Gerald Hempel",
      "Jeronimo Castrillon",
      "Christian Pilato"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2203.10850"
  },
  {
    "id": "arXiv:2203.12253",
    "title": "Inquisitive Logic as an Epistemic Logic of Knowing How",
    "abstract": "Comments: draft, 28 pages, to appear in Annals of Pure and Applied Logic",
    "descriptor": "\nComments: draft, 28 pages, to appear in Annals of Pure and Applied Logic\n",
    "authors": [
      "Haoyu Wang",
      "Yanjing Wang",
      "Yunsong Wang"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2203.12253"
  },
  {
    "id": "arXiv:2203.12385",
    "title": "A Blueprint for Four-states Quantum Formal System",
    "abstract": "A Blueprint for Four-states Quantum Formal System",
    "descriptor": "",
    "authors": [
      "Kazuki Otsuka"
    ],
    "subjectives": [
      "Other Computer Science (cs.OH)"
    ],
    "url": "https://arxiv.org/abs/2203.12385"
  },
  {
    "id": "arXiv:2203.12467",
    "title": "A Lower-bound for Variable-length Source Coding in  Linear-Quadratic-Gaussian Control with Shared Randomness",
    "abstract": "Comments: To appear in the IEEE Control Systems Letters. Version as finally accepted. Copyright 2022 IEEE",
    "descriptor": "\nComments: To appear in the IEEE Control Systems Letters. Version as finally accepted. Copyright 2022 IEEE\n",
    "authors": [
      "Travis C. Cuvelier",
      "Takashi Tanaka",
      "Robert W. Heath Jr"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.12467"
  },
  {
    "id": "arXiv:2203.15143",
    "title": "Towards End-to-End Unified Scene Text Detection and Layout Analysis",
    "abstract": "Comments: To appear at CVPR 2022. Code Available: this https URL",
    "descriptor": "\nComments: To appear at CVPR 2022. Code Available: this https URL\n",
    "authors": [
      "Shangbang Long",
      "Siyang Qin",
      "Dmitry Panteleev",
      "Alessandro Bissacco",
      "Yasuhisa Fujii",
      "Michalis Raptis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15143"
  },
  {
    "id": "arXiv:2203.16615",
    "title": "A Fast and Convergent Proximal Algorithm for Regularized Nonconvex and  Nonsmooth Bi-level Optimization",
    "abstract": "Comments: 20 pages, 1 figure, 1 table",
    "descriptor": "\nComments: 20 pages, 1 figure, 1 table\n",
    "authors": [
      "Ziyi Chen",
      "Bhavya Kailkhura",
      "Yi Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.16615"
  },
  {
    "id": "arXiv:2203.16618",
    "title": "End-to-end Document Recognition and Understanding with Dessurt",
    "abstract": "End-to-end Document Recognition and Understanding with Dessurt",
    "descriptor": "",
    "authors": [
      "Brian Davis",
      "Bryan Morse",
      "Bryan Price",
      "Chris Tensmeyer",
      "Curtis Wigington",
      "Vlad Morariu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.16618"
  },
  {
    "id": "arXiv:2203.17274",
    "title": "Exploring Visual Prompts for Adapting Large-Scale Models",
    "abstract": "Comments: 16 pages, 10 figures",
    "descriptor": "\nComments: 16 pages, 10 figures\n",
    "authors": [
      "Hyojin Bahng",
      "Ali Jahanian",
      "Swami Sankaranarayanan",
      "Phillip Isola"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.17274"
  },
  {
    "id": "arXiv:2204.03749",
    "title": "Powering Finetuning in Few-Shot Learning: Domain-Agnostic Bias Reduction  with Selected Sampling",
    "abstract": "Comments: published in AAAI-22",
    "descriptor": "\nComments: published in AAAI-22\n",
    "authors": [
      "Ran Tao",
      "Han Zhang",
      "Yutong Zheng",
      "Marios Savvides"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03749"
  },
  {
    "id": "arXiv:2204.05103",
    "title": "Transformer-Based Self-Supervised Learning for Emotion Recognition",
    "abstract": "Transformer-Based Self-Supervised Learning for Emotion Recognition",
    "descriptor": "",
    "authors": [
      "Juan Vazquez-Rodriguez",
      "Gr\u00e9goire Lefebvre",
      "Julien Cumin",
      "James L. Crowley"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2204.05103"
  },
  {
    "id": "arXiv:2204.06882",
    "title": "On Random Number Generation for Kernel Applications",
    "abstract": "Comments: Accepted in Fundamenta Informaticae",
    "descriptor": "\nComments: Accepted in Fundamenta Informaticae\n",
    "authors": [
      "Kunal Abhishek",
      "George Dharma Prakash Raj E"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2204.06882"
  },
  {
    "id": "arXiv:2204.07258",
    "title": "Causal Transformer for Estimating Counterfactual Outcomes",
    "abstract": "Causal Transformer for Estimating Counterfactual Outcomes",
    "descriptor": "",
    "authors": [
      "Valentyn Melnychuk",
      "Dennis Frauen",
      "Stefan Feuerriegel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.07258"
  },
  {
    "id": "arXiv:2204.08129",
    "title": "Animal Kingdom: A Large and Diverse Dataset for Animal Behavior  Understanding",
    "abstract": "Comments: Accepted by CVPR2022 (Oral). Dataset: this https URL",
    "descriptor": "\nComments: Accepted by CVPR2022 (Oral). Dataset: this https URL\n",
    "authors": [
      "Xun Long Ng",
      "Kian Eng Ong",
      "Qichen Zheng",
      "Yun Ni",
      "Si Yong Yeo",
      "Jun Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.08129"
  },
  {
    "id": "arXiv:2204.09984",
    "title": "Convergence analysis of a Local Discontinuous Galerkin approximation for  nonlinear systems with Orlicz-structure",
    "abstract": "Comments: 27 pages, 4 figures, 5 tables",
    "descriptor": "\nComments: 27 pages, 4 figures, 5 tables\n",
    "authors": [
      "Alex Kaltenbach",
      "Michael R\u016f\u017ei\u010dka"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.09984"
  },
  {
    "id": "arXiv:2204.12103",
    "title": "Centimeter-level Positioning by Instantaneous Lidar-aided GNSS Ambiguity  Resolution",
    "abstract": "Comments: 14 pages, 12 figures. Submitted to Measurement Science and Technology",
    "descriptor": "\nComments: 14 pages, 12 figures. Submitted to Measurement Science and Technology\n",
    "authors": [
      "Junjie Zhang",
      "Amir Khodabandeh",
      "Kourosh Khoshelham"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2204.12103"
  },
  {
    "id": "arXiv:2204.13361",
    "title": "It's DONE: Direct ONE-shot learning with Hebbian weight imprinting",
    "abstract": "Comments: 12 pages, 4 figures, 1 table",
    "descriptor": "\nComments: 12 pages, 4 figures, 1 table\n",
    "authors": [
      "Kazufumi Hosoda",
      "Keigo Nishida",
      "Shigeto Seno",
      "Tomohiro Mashita",
      "Hideki Kashioka",
      "Izumi Ohzawa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.13361"
  },
  {
    "id": "arXiv:2204.14026",
    "title": "Semi-Assisted Signal Authentication based on Galileo ACAS",
    "abstract": "Semi-Assisted Signal Authentication based on Galileo ACAS",
    "descriptor": "",
    "authors": [
      "Ignacio Fernandez-Hernandez",
      "Simon Cancela",
      "Rafael Terris-Gallego",
      "Gonzalo Seco-Granados",
      "Jos\u00e9 A. L\u00f3pez-Salcedo",
      "C. O'Driscoll",
      "J. Winkel",
      "A. dalla Chiara",
      "C. Sarto",
      "Vincent Rijmen",
      "Daniel Blonski",
      "Javier de Blas"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2204.14026"
  },
  {
    "id": "arXiv:2205.00180",
    "title": "Katana: Dual Slicing-Based Context for Learning Bug Fixes",
    "abstract": "Katana: Dual Slicing-Based Context for Learning Bug Fixes",
    "descriptor": "",
    "authors": [
      "Mifta Sintaha",
      "Noor Nashid",
      "Ali Mesbah"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2205.00180"
  },
  {
    "id": "arXiv:2205.00436",
    "title": "Differentially Private Multivariate Time Series Forecasting of  Aggregated Human Mobility With Deep Learning: Input or Gradient Perturbation?",
    "abstract": "Comments: Final version accepted in the journal Neural Computing and Applications",
    "descriptor": "\nComments: Final version accepted in the journal Neural Computing and Applications\n",
    "authors": [
      "H\u00e9ber H. Arcolezi",
      "Jean-Fran\u00e7ois Couchot",
      "Denis Renaud",
      "Bechara Al Bouna",
      "Xiaokui Xiao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.00436"
  },
  {
    "id": "arXiv:2205.01970",
    "title": "Nonstationary Bandit Learning via Predictive Sampling",
    "abstract": "Nonstationary Bandit Learning via Predictive Sampling",
    "descriptor": "",
    "authors": [
      "Yueyang Liu",
      "Benjamin Van Roy",
      "Kuang Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.01970"
  },
  {
    "id": "arXiv:2205.02156",
    "title": "Approximations of dispersive PDEs in the presence of low-regularity  randomness",
    "abstract": "Comments: 44 pages",
    "descriptor": "\nComments: 44 pages\n",
    "authors": [
      "Yvonne Alama Bronsard",
      "Yvain Bruned",
      "Katharina Schratz"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)",
      "Rings and Algebras (math.RA)"
    ],
    "url": "https://arxiv.org/abs/2205.02156"
  },
  {
    "id": "arXiv:2205.04326",
    "title": "HierAttn: Effectively Learn Representations from Stage Attention and  Branch Attention for Skin Lesions Diagnosis",
    "abstract": "Comments: 12 pages, 10 figures. Submitted to Medical Image Analysis",
    "descriptor": "\nComments: 12 pages, 10 figures. Submitted to Medical Image Analysis\n",
    "authors": [
      "Wei Dai",
      "Rui Liu",
      "Tianyi Wu",
      "Min Wang",
      "Jianqin Yin",
      "Jun Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.04326"
  },
  {
    "id": "arXiv:2205.04401",
    "title": "Accelerating potential evaluation over unstructured meshes in two  dimensions",
    "abstract": "Comments: 47 pages, 9 tables, 13 figures",
    "descriptor": "\nComments: 47 pages, 9 tables, 13 figures\n",
    "authors": [
      "Zewen Shen",
      "Kirill Serkh"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.04401"
  },
  {
    "id": "arXiv:2205.08148",
    "title": "Gender and Racial Bias in Visual Question Answering Datasets",
    "abstract": "Comments: ACM Conference on Fairness, Accountability, and Transparency (FAccT 2022)",
    "descriptor": "\nComments: ACM Conference on Fairness, Accountability, and Transparency (FAccT 2022)\n",
    "authors": [
      "Yusuke Hirota",
      "Yuta Nakashima",
      "Noa Garcia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2205.08148"
  },
  {
    "id": "arXiv:2205.08451",
    "title": "MAS2HP: A Multi Agent System to Predict Protein Structure in 2D HP model",
    "abstract": "MAS2HP: A Multi Agent System to Predict Protein Structure in 2D HP model",
    "descriptor": "",
    "authors": [
      "Hossein Parineh",
      "Nasser Mozayani"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.08451"
  },
  {
    "id": "arXiv:2205.08964",
    "title": "Skew constacyclic codes over a class of finite commutative semisimple  rings",
    "abstract": "Skew constacyclic codes over a class of finite commutative semisimple  rings",
    "descriptor": "",
    "authors": [
      "Ying Zhao"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Rings and Algebras (math.RA)"
    ],
    "url": "https://arxiv.org/abs/2205.08964"
  },
  {
    "id": "arXiv:2205.08972",
    "title": "The Structure of Configurations in One-Dimensional Majority Cellular  Automata: From Cell Stability to Configuration Periodicity",
    "abstract": "The Structure of Configurations in One-Dimensional Majority Cellular  Automata: From Cell Stability to Configuration Periodicity",
    "descriptor": "",
    "authors": [
      "Yonatan Nakar",
      "Dana Ron"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2205.08972"
  },
  {
    "id": "arXiv:2205.08991",
    "title": "Symbolic-Numeric Factorization of Differential Operators",
    "abstract": "Symbolic-Numeric Factorization of Differential Operators",
    "descriptor": "",
    "authors": [
      "Fr\u00e9d\u00e9ric Chyzak",
      "Alexandre Goyer",
      "Marc Mezzarobba"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2205.08991"
  },
  {
    "id": "arXiv:2205.09510",
    "title": "An Introduction to Quantum Machine Learning for Engineers",
    "abstract": "Comments: This is a first draft, and is currently under review. Comments are very welcome, including corrections",
    "descriptor": "\nComments: This is a first draft, and is currently under review. Comments are very welcome, including corrections\n",
    "authors": [
      "Osvaldo Simeone"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09510"
  },
  {
    "id": "arXiv:2205.10233",
    "title": "RigoBERTa: A State-of-the-Art Language Model For Spanish",
    "abstract": "RigoBERTa: A State-of-the-Art Language Model For Spanish",
    "descriptor": "",
    "authors": [
      "Alejandro Vaca Serrano",
      "Guillem Garcia Subies",
      "Helena Montoro Zamorano",
      "Nuria Aldama Garcia",
      "Doaa Samy",
      "David Betancur Sanchez",
      "Antonio Moreno Sandoval",
      "Marta Guerrero Nieto",
      "Alvaro Barbero Jimenez"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.10233"
  },
  {
    "id": "arXiv:2205.11805",
    "title": "Hybrid Manufacturing Process Planning for Arbitrary Part and Tool Shapes",
    "abstract": "Comments: Special Issue on symposium on Solid and Physical Modeling (SPM'2022)",
    "descriptor": "\nComments: Special Issue on symposium on Solid and Physical Modeling (SPM'2022)\n",
    "authors": [
      "George P. Harabin",
      "Morad Behandish"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.11805"
  },
  {
    "id": "arXiv:2205.12411",
    "title": "Linear Connectivity Reveals Generalization Strategies",
    "abstract": "Linear Connectivity Reveals Generalization Strategies",
    "descriptor": "",
    "authors": [
      "Jeevesh Juneja",
      "Rachit Bansal",
      "Kyunghyun Cho",
      "Jo\u00e3o Sedoc",
      "Naomi Saphra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.12411"
  },
  {
    "id": "arXiv:2205.12460",
    "title": "Linear Algorithms for Nonparametric Multiclass Probability Estimation",
    "abstract": "Linear Algorithms for Nonparametric Multiclass Probability Estimation",
    "descriptor": "",
    "authors": [
      "Liyun Zeng",
      "Hao Helen Zhang"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.12460"
  },
  {
    "id": "arXiv:2205.12693",
    "title": "Contrastive Learning with Boosted Memorization",
    "abstract": "Contrastive Learning with Boosted Memorization",
    "descriptor": "",
    "authors": [
      "Zhihan Zhou",
      "Jiangchao Yao",
      "Yanfeng Wang",
      "Bo Han",
      "Ya Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.12693"
  },
  {
    "id": "arXiv:2205.13146",
    "title": "Grasping as Inference: Reactive Grasping in Heavily Cluttered  Environment",
    "abstract": "Grasping as Inference: Reactive Grasping in Heavily Cluttered  Environment",
    "descriptor": "",
    "authors": [
      "Dongwon Son"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.13146"
  },
  {
    "id": "arXiv:2205.13586",
    "title": "Comparing the Digital Annealer with Classical Evolutionary Algorithm",
    "abstract": "Comments: 16 pages, New Architectures for Search and Optimization workshop, INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE",
    "descriptor": "\nComments: 16 pages, New Architectures for Search and Optimization workshop, INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE\n",
    "authors": [
      "Mayowa Ayodele"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.13586"
  },
  {
    "id": "arXiv:2205.13607",
    "title": "Self-supervised Pretraining and Transfer Learning Enable Flu and  COVID-19 Predictions in Small Mobile Sensing Datasets",
    "abstract": "Self-supervised Pretraining and Transfer Learning Enable Flu and  COVID-19 Predictions in Small Mobile Sensing Datasets",
    "descriptor": "",
    "authors": [
      "Mike A. Merrill",
      "Tim Althoff"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2205.13607"
  },
  {
    "id": "arXiv:2205.13947",
    "title": "Spatio-Temporal Graph Few-Shot Learning with Cross-City Knowledge  Transfer",
    "abstract": "Comments: Accepted to KDD2022",
    "descriptor": "\nComments: Accepted to KDD2022\n",
    "authors": [
      "Bin Lu",
      "Xiaoying Gan",
      "Weinan Zhang",
      "Huaxiu Yao",
      "Luoyi Fu",
      "Xinbing Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.13947"
  },
  {
    "id": "arXiv:2205.13954",
    "title": "Geometer: Graph Few-Shot Class-Incremental Learning via Prototype  Representation",
    "abstract": "Comments: Accepted to KDD2022",
    "descriptor": "\nComments: Accepted to KDD2022\n",
    "authors": [
      "Bin Lu",
      "Xiaoying Gan",
      "Lina Yang",
      "Weinan Zhang",
      "Luoyi Fu",
      "Xinbing Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.13954"
  },
  {
    "id": "arXiv:2205.14109",
    "title": "Bayesian Robust Graph Contrastive Learning",
    "abstract": "Bayesian Robust Graph Contrastive Learning",
    "descriptor": "",
    "authors": [
      "Yancheng Wang",
      "Yingzhen Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.14109"
  },
  {
    "id": "arXiv:2205.14829",
    "title": "Adaptive Learning for Discovery",
    "abstract": "Adaptive Learning for Discovery",
    "descriptor": "",
    "authors": [
      "Ziping Xu",
      "Eunjae Shim",
      "Ambuj Tewari",
      "Paul Zimmerman"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.14829"
  },
  {
    "id": "arXiv:2205.14925",
    "title": "The u-index: a simple metric to objectively measure academic impact of  individual researchers",
    "abstract": "Comments: 3 pages, 1 table, no figures",
    "descriptor": "\nComments: 3 pages, 1 table, no figures\n",
    "authors": [
      "Roberto Dillon"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2205.14925"
  },
  {
    "id": "arXiv:2205.15904",
    "title": "Synthesizing Configuration Tactics for Exercising Hidden Options in  Serverless Systems",
    "abstract": "Comments: updated typo in abstract",
    "descriptor": "\nComments: updated typo in abstract\n",
    "authors": [
      "J\u00f6rn Kuhlenkamp",
      "Sebastian Werner",
      "Chin Hong Tran",
      "Stefan Tai"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2205.15904"
  },
  {
    "id": "arXiv:2206.00518",
    "title": "Efficient Scheduling of Data Augmentation for Deep Reinforcement  Learning",
    "abstract": "Comments: I want to update my previous submitted paper arXiv:2102.08581,rather than new submission. Thus, I want to withdraw this submission, and i already replace 2102.08581 by updated paper",
    "descriptor": "\nComments: I want to update my previous submitted paper arXiv:2102.08581,rather than new submission. Thus, I want to withdraw this submission, and i already replace 2102.08581 by updated paper\n",
    "authors": [
      "Byungchan Ko",
      "Jungseul Ok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.00518"
  },
  {
    "id": "arXiv:2206.00803",
    "title": "Robust recovery of low-rank matrices and low-tubal-rank tensors from  noisy sketches",
    "abstract": "Comments: 16 pages, 2 figures",
    "descriptor": "\nComments: 16 pages, 2 figures\n",
    "authors": [
      "Anna Ma",
      "Dominik St\u00f6ger",
      "Yizhe Zhu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2206.00803"
  },
  {
    "id": "arXiv:2206.01041",
    "title": "End-to-End Security for Distributed Event-Driven Enclave Applications on  Heterogeneous TEEs",
    "abstract": "Comments: 35 pages, submitted to ACM Transactions on Privacy and Security, first co-authorship between Gianluca Scopelliti and Sepideh Pouyanrad, source code available at this https URL",
    "descriptor": "\nComments: 35 pages, submitted to ACM Transactions on Privacy and Security, first co-authorship between Gianluca Scopelliti and Sepideh Pouyanrad, source code available at this https URL\n",
    "authors": [
      "Gianluca Scopelliti",
      "Sepideh Pouyanrad",
      "Job Noorman",
      "Fritz Alder",
      "Christoph Baumann",
      "Frank Piessens",
      "Jan Tobias M\u00fchlberg"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.01041"
  },
  {
    "id": "arXiv:2206.01088",
    "title": "Machine Learning-based Lung and Colon Cancer Detection using Deep  Feature Extraction and Ensemble Learning",
    "abstract": "Comments: Accepted for publication in the Special Issue of Expert Systems with Applications (IF:6.954, Cite:12.70) How to Cite: Md. Alamin Talukder, Md. Manowarul Islam, Md Ashraf Uddin, Arnisha Akhter, Khondokar Fida Hasan, Mohammad Ali Moni. \"Machine Learning-based Lung and Colon Cancer Detection using Deep Feature Extraction and Ensemble Learning\", Expert Systems with Applications. 2022 Jun 1",
    "descriptor": "\nComments: Accepted for publication in the Special Issue of Expert Systems with Applications (IF:6.954, Cite:12.70) How to Cite: Md. Alamin Talukder, Md. Manowarul Islam, Md Ashraf Uddin, Arnisha Akhter, Khondokar Fida Hasan, Mohammad Ali Moni. \"Machine Learning-based Lung and Colon Cancer Detection using Deep Feature Extraction and Ensemble Learning\", Expert Systems with Applications. 2022 Jun 1\n",
    "authors": [
      "Md. Alamin Talukder",
      "Md. Manowarul Islam",
      "Md Ashraf Uddin",
      "Arnisha Akhter",
      "Khondokar Fida Hasan",
      "Mohammad Ali Moni"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01088"
  },
  {
    "id": "arXiv:2206.01136",
    "title": "Transforming medical imaging with Transformers? A comparative review of  key properties, current progresses, and future perspectives",
    "abstract": "Transforming medical imaging with Transformers? A comparative review of  key properties, current progresses, and future perspectives",
    "descriptor": "",
    "authors": [
      "Jun Li",
      "Junyu Chen",
      "Yucheng Tang",
      "Ce Wang",
      "Bennett A. Landman",
      "S. Kevin Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01136"
  }
]
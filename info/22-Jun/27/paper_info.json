[
  {
    "id": "arXiv:2206.11899",
    "title": "Navigating Incommensurability Between Ethnomethodology, Conversation  Analysis, and Artificial Intelligence",
    "abstract": "Like many research communities, ethnomethodologists and conversation analysts\nhave begun to get caught up -- yet again -- in the pervasive spectacle of\nsurging interests in Artificial Intelligence (AI). Inspired by discussions\namongst a growing network of researchers in ethnomethodology (EM) and\nconversation analysis (CA) traditions who nurse such interests, I started\nthinking about what things EM and the more EM end of conversation analysis\nmight be doing about, for, or even with, fields of AI research. So, this piece\nis about the disciplinary and conceptual questions that might be encountered,\nand -- in my view -- may need addressing for engagements with AI research and\nits affiliates. Although I'm mostly concerned with things to be aware of as\nwell as outright dangers, later on we can think about some opportunities. And\nthroughout I will keep using 'we' to talk about EM&CA researchers; but this\nreally is for convenience only -- I don't wish to ventriloquise for our complex\nresearch communities. All of the following should be read as emanating from my\nparticular research history, standpoint etc., and treated (hopefully) as an\ninvitation for further discussion amongst EM and CA researchers turning to\ntechnology and AI specifically.",
    "descriptor": "",
    "authors": [
      "Stuart Reeves"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.11899"
  },
  {
    "id": "arXiv:2206.11900",
    "title": "ASTERYX : A model-Agnostic SaT-basEd appRoach for sYmbolic and  score-based eXplanations",
    "abstract": "The ever increasing complexity of machine learning techniques used more and\nmore in practice, gives rise to the need to explain the predictions and\ndecisions of these models, often used as black-boxes. Explainable AI approaches\nare either numerical feature-based aiming to quantify the contribution of each\nfeature in a prediction or symbolic providing certain forms of symbolic\nexplanations such as counterfactuals. This paper proposes a generic agnostic\napproach named ASTERYX allowing to generate both symbolic explanations and\nscore-based ones. Our approach is declarative and it is based on the encoding\nof the model to be explained in an equivalent symbolic representation, this\nlatter serves to generate in particular two types of symbolic explanations\nwhich are sufficient reasons and counterfactuals. We then associate scores\nreflecting the relevance of the explanations and the features w.r.t to some\nproperties. Our experimental results show the feasibility of the proposed\napproach and its effectiveness in providing symbolic and score-based\nexplanations.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2206.11539\n",
    "authors": [
      "Ryma Boumazouza",
      "Fahima Cheikh-Alili",
      "Bertrand Mazure",
      "Karim Tabia"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.11900"
  },
  {
    "id": "arXiv:2206.11920",
    "title": "Agriculture-Vision Challenge 2022 -- The Runner-Up Solution for  Agricultural Pattern Recognition via Transformer-based Models",
    "abstract": "The Agriculture-Vision Challenge in CVPR is one of the most famous and\ncompetitive challenges for global researchers to break the boundary between\ncomputer vision and agriculture sectors, aiming at agricultural pattern\nrecognition from aerial images. In this paper, we propose our solution to the\nthird Agriculture-Vision Challenge in CVPR 2022. We leverage a data\npre-processing scheme and several Transformer-based models as well as data\naugmentation techniques to achieve a mIoU of 0.582, accomplishing the 2nd place\nin this challenge.",
    "descriptor": "\nComments: CVPR 2022, Agriculture-Vision Challenge, Remote Sensing\n",
    "authors": [
      "Zhicheng Yang",
      "Jui-Hsin Lai",
      "Jun Zhou",
      "Hang Zhou",
      "Chen Du",
      "Zhongcheng Lai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.11920"
  },
  {
    "id": "arXiv:2206.11922",
    "title": "Worldwide AI Ethics: a review of 200 guidelines and recommendations for  AI governance",
    "abstract": "In the last decade, a great number of organizations have produced documents\nintended to standardize, in the normative sense, and promote guidance to our\nrecent and rapid AI development. However, the full content and divergence of\nideas presented in these documents have not yet been analyzed, except for a few\nmeta-analyses and critical reviews of the field. In this work, we seek to\nexpand on the work done by past researchers and create a tool for better data\nvisualization of the contents and nature of these documents. We also provide\nour critical analysis of the results acquired by the application of our tool\ninto a sample size of 200 documents.",
    "descriptor": "",
    "authors": [
      "Nicholas Kluge Corr\u00eaa",
      "Camila Galv\u00e3o",
      "James William Santos",
      "Carolina Del Pino",
      "Edson Pontes Pinto",
      "Camila Barbosa",
      "Diogo Massmann",
      "Rodrigo Mambrini",
      "Luiza Galv\u00e3o",
      "Edmund Terem"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.11922"
  },
  {
    "id": "arXiv:2206.11925",
    "title": "Set Norm and Equivariant Skip Connections: Putting the Deep in Deep Sets",
    "abstract": "Permutation invariant neural networks are a promising tool for making\npredictions from sets. However, we show that existing permutation invariant\narchitectures, Deep Sets and Set Transformer, can suffer from vanishing or\nexploding gradients when they are deep. Additionally, layer norm, the\nnormalization of choice in Set Transformer, can hurt performance by removing\ninformation useful for prediction. To address these issues, we introduce the\nclean path principle for equivariant residual connections and develop set norm,\na normalization tailored for sets. With these, we build Deep Sets++ and Set\nTransformer++, models that reach high depths with comparable or better\nperformance than their original counterparts on a diverse suite of tasks. We\nadditionally introduce Flow-RBC, a new single-cell dataset and real-world\napplication of permutation invariant prediction. We open-source our data and\ncode here: https://github.com/rajesh-lab/deep_permutation_invariant.",
    "descriptor": "\nComments: Accepted at ICML 2022\n",
    "authors": [
      "Lily H. Zhang",
      "Veronica Tozzo",
      "John M. Higgins",
      "Rajesh Ranganath"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.11925"
  },
  {
    "id": "arXiv:2206.11927",
    "title": "Towards Galaxy Foundation Models with Hybrid Contrastive Learning",
    "abstract": "New astronomical tasks are often related to earlier tasks for which labels\nhave already been collected. We adapt the contrastive framework BYOL to\nleverage those labels as a pretraining task while also enforcing augmentation\ninvariance. For large-scale pretraining, we introduce GZ-Evo v0.1, a set of\n96.5M volunteer responses for 552k galaxy images plus a further 1.34M\ncomparable unlabelled galaxies. Most of the 206 GZ-Evo answers are unknown for\nany given galaxy, and so our pretraining task uses a Dirichlet loss that\nnaturally handles unknown answers. GZ-Evo pretraining, with or without hybrid\nlearning, improves on direct training even with plentiful downstream labels\n(+4% accuracy with 44k labels). Our hybrid pretraining/contrastive method\nfurther improves downstream accuracy vs. pretraining or contrastive learning,\nespecially in the low-label transfer regime (+6% accuracy with 750 labels).",
    "descriptor": "\nComments: Accepted at the ICML 2022 Workshop on Machine Learning for Astrophysics. Data: www.github.com/mwalmsley/pytorch-galaxy-datasets. Please reach out to share your labelled data - all contributions will be credited in future work\n",
    "authors": [
      "Mike Walmsley",
      "Inigo Val Slijepcevic",
      "Micah Bowles",
      "Anna M. M. Scaife"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Astrophysics of Galaxies (astro-ph.GA)"
    ],
    "url": "https://arxiv.org/abs/2206.11927"
  },
  {
    "id": "arXiv:2206.11936",
    "title": "Towards a Maturity Model for Systematic Literature Review Process",
    "abstract": "Background: Systematic literature review (SLR) has been widely adopted to\nsynthesize evidence in a reliable and unbiased manner. The process of\nconducting SLR is rigorous and well-known; however, most SLR have not followed\nthis process systematically, leading to various problems, including poor\ndocumentation, lack of quality, and difficulty to be reproduced. These problems\nare added to the inherent difficulties in conducting SLR, especially regarding\neffort and time consumption. Several practices (including methods, techniques,\nand tools) have already been experimented with to mitigate such problems.\nStill, it is unclear which practices should be prioritized to reduce such\nproblems and difficulties. Aims: The main goal of this paper is to contribute\nto improving the SLR process being adopted by the community. For that, we\nintroduce the idea of the Maturity Model for SLR process (MM4SLR). Method: We\nsystematically examined the literature searching for practices destined to\nsupport or improve the SLR process. After collecting 84 practices, we analyzed,\ngrouped, and synthesized them into 46 key practices further distributed into 15\nspecific goals. Inspired by the maturity model for software development\nprocess, we also propose five process areas and an initial version of MM4SLR\ncontaining four maturity levels. Results: MM4SLR provides a new view on those\npractices that could be progressively adopted to improve the SLR process.\nMM4SLR could define a pragmatic pathway that guides the adoption of those\npractices, which better fit the reality of who conducts SLR. Conclusion: The\nSLR process is very complex and should be more investigated. We argue that ways\nto better select and adopt the various existing practices are necessary. We\nconclude that a long research agenda to be fulfilled addressing the SLR process\nstill exists.",
    "descriptor": "",
    "authors": [
      "Vinicius dos Santos",
      "Elisa Yumi Nakagawa"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.11936"
  },
  {
    "id": "arXiv:2206.11939",
    "title": "Measuring Representational Robustness of Neural Networks Through Shared  Invariances",
    "abstract": "A major challenge in studying robustness in deep learning is defining the set\nof ``meaningless'' perturbations to which a given Neural Network (NN) should be\ninvariant. Most work on robustness implicitly uses a human as the reference\nmodel to define such perturbations. Our work offers a new view on robustness by\nusing another reference NN to define the set of perturbations a given NN should\nbe invariant to, thus generalizing the reliance on a reference ``human NN'' to\nany NN. This makes measuring robustness equivalent to measuring the extent to\nwhich two NNs share invariances, for which we propose a measure called STIR.\nSTIR re-purposes existing representation similarity measures to make them\nsuitable for measuring shared invariances. Using our measure, we are able to\ngain insights into how shared invariances vary with changes in weight\ninitialization, architecture, loss functions, and training dataset. Our\nimplementation is available at: \\url{https://github.com/nvedant07/STIR}.",
    "descriptor": "\nComments: Accepted for oral presentation at ICML 2022\n",
    "authors": [
      "Vedant Nanda",
      "Till Speicher",
      "Camila Kolling",
      "John P. Dickerson",
      "Krishna P. Gummadi",
      "Adrian Weller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.11939"
  },
  {
    "id": "arXiv:2206.11940",
    "title": "World Value Functions: Knowledge Representation for Learning and  Planning",
    "abstract": "We propose world value functions (WVFs), a type of goal-oriented general\nvalue function that represents how to solve not just a given task, but any\nother goal-reaching task in an agent's environment. This is achieved by\nequipping an agent with an internal goal space defined as all the world states\nwhere it experiences a terminal transition. The agent can then modify the\nstandard task rewards to define its own reward function, which provably drives\nit to learn how to achieve all reachable internal goals, and the value of doing\nso in the current task. We demonstrate two key benefits of WVFs in the context\nof learning and planning. In particular, given a learned WVF, an agent can\ncompute the optimal policy in a new task by simply estimating the task's reward\nfunction. Furthermore, we show that WVFs also implicitly encode the transition\ndynamics of the environment, and so can be used to perform planning.\nExperimental results show that WVFs can be learned faster than regular value\nfunctions, while their ability to infer the environment's dynamics can be used\nto integrate learning and planning methods to further improve sample\nefficiency.",
    "descriptor": "\nComments: Accepted at the Planning and Reinforcement Learning Workshop at ICAPS 2022. arXiv admin note: text overlap with arXiv:2205.08827\n",
    "authors": [
      "Geraud Nangue Tasse",
      "Benjamin Rosman",
      "Steven James"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.11940"
  },
  {
    "id": "arXiv:2206.11941",
    "title": "Affinity-Aware Graph Networks",
    "abstract": "Graph Neural Networks (GNNs) have emerged as a powerful technique for\nlearning on relational data. Owing to the relatively limited number of message\npassing steps they perform -- and hence a smaller receptive field -- there has\nbeen significant interest in improving their expressivity by incorporating\nstructural aspects of the underlying graph. In this paper, we explore the use\nof affinity measures as features in graph neural networks, in particular\nmeasures arising from random walks, including effective resistance, hitting and\ncommute times. We propose message passing networks based on these features and\nevaluate their performance on a variety of node and graph property prediction\ntasks. Our architecture has lower computational complexity, while our features\nare invariant to the permutations of the underlying graph. The measures we\ncompute allow the network to exploit the connectivity properties of the graph,\nthereby allowing us to outperform relevant benchmarks for a wide variety of\ntasks, often with significantly fewer message passing steps. On one of the\nlargest publicly available graph regression datasets, OGB-LSC-PCQM4Mv1, we\nobtain the best known single-model validation MAE at the time of writing.",
    "descriptor": "",
    "authors": [
      "Ameya Velingker",
      "Ali Kemal Sinop",
      "Ira Ktena",
      "Petar Veli\u010dkovi\u0107",
      "Sreenivas Gollapudi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.11941"
  },
  {
    "id": "arXiv:2206.11952",
    "title": "UNeRF: Time and Memory Conscious U-Shaped Network for Training Neural  Radiance Fields",
    "abstract": "Neural Radiance Fields (NeRFs) increase reconstruction detail for novel view\nsynthesis and scene reconstruction, with applications ranging from large static\nscenes to dynamic human motion. However, the increased resolution and\nmodel-free nature of such neural fields come at the cost of high training times\nand excessive memory requirements. Recent advances improve the inference time\nby using complementary data structures yet these methods are ill-suited for\ndynamic scenes and often increase memory consumption. Little has been done to\nreduce the resources required at training time. We propose a method to exploit\nthe redundancy of NeRF's sample-based computations by partially sharing\nevaluations across neighboring sample points. Our UNeRF architecture is\ninspired by the UNet, where spatial resolution is reduced in the middle of the\nnetwork and information is shared between adjacent samples. Although this\nchange violates the strict and conscious separation of view-dependent\nappearance and view-independent density estimation in the NeRF method, we show\nthat it improves novel view synthesis. We also introduce an alternative\nsubsampling strategy which shares computation while minimizing any violation of\nview invariance. UNeRF is a plug-in module for the original NeRF network. Our\nmajor contributions include reduction of the memory footprint, improved\naccuracy, and reduced amortized processing time both during training and\ninference. With only weak assumptions on locality, we achieve improved resource\nutilization on a variety of neural radiance fields tasks. We demonstrate\napplications to the novel view synthesis of static scenes as well as dynamic\nhuman shape and motion.",
    "descriptor": "",
    "authors": [
      "Abiramy Kuganesan",
      "Shih-yang Su",
      "James J. Little",
      "Helge Rhodin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2206.11952"
  },
  {
    "id": "arXiv:2206.11953",
    "title": "Do Trajectories Encode Verb Meaning?",
    "abstract": "Distributional models learn representations of words from text, but are\ncriticized for their lack of grounding, or the linking of text to the\nnon-linguistic world. Grounded language models have had success in learning to\nconnect concrete categories like nouns and adjectives to the world via images\nand videos, but can struggle to isolate the meaning of the verbs themselves\nfrom the context in which they typically occur. In this paper, we investigate\nthe extent to which trajectories (i.e. the position and rotation of objects\nover time) naturally encode verb semantics. We build a procedurally generated\nagent-object-interaction dataset, obtain human annotations for the verbs that\noccur in this data, and compare several methods for representation learning\ngiven the trajectories. We find that trajectories correlate as-is with some\nverbs (e.g., fall), and that additional abstraction via self-supervised\npretraining can further capture nuanced differences in verb meaning (e.g., roll\nvs. slide).",
    "descriptor": "\nComments: NAACL 2022\n",
    "authors": [
      "Dylan Ebert",
      "Chen Sun",
      "Ellie Pavlick"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.11953"
  },
  {
    "id": "arXiv:2206.11959",
    "title": "Similarity-aware Positive Instance Sampling for Graph Contrastive  Pre-training",
    "abstract": "Graph instance contrastive learning has been proved as an effective task for\nGraph Neural Network (GNN) pre-training. However, one key issue may seriously\nimpede the representative power in existing works: Positive instances created\nby current methods often miss crucial information of graphs or even yield\nillegal instances (such as non-chemically-aware graphs in molecular\ngeneration). To remedy this issue, we propose to select positive graph\ninstances directly from existing graphs in the training set, which ultimately\nmaintains the legality and similarity to the target graphs. Our selection is\nbased on certain domain-specific pair-wise similarity measurements as well as\nsampling from a hierarchical graph encoding similarity relations among graphs.\nBesides, we develop an adaptive node-level pre-training method to dynamically\nmask nodes to distribute them evenly in the graph. We conduct extensive\nexperiments on $13$ graph classification and node classification benchmark\ndatasets from various domains. The results demonstrate that the GNN models\npre-trained by our strategies can outperform those trained-from-scratch models\nas well as the variants obtained by existing methods.",
    "descriptor": "\nComments: 31 pages, 2 figures\n",
    "authors": [
      "Xueyi Liu",
      "Yu Rong",
      "Tingyang Xu",
      "Fuchun Sun",
      "Wenbing Huang",
      "Junzhou Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.11959"
  },
  {
    "id": "arXiv:2206.11960",
    "title": "A physics-guided data-driven feedforward tracking controller for systems  with unmodeled dynamics -- applied to 3D printing",
    "abstract": "A hybrid (i.e., physics-guided data-driven) feedforward tracking controller\nis proposed for systems with unmodeled linear or nonlinear dynamics. The\ncontroller is based on the filtered basis function (FBF) approach, hence it is\ncalled a hybrid FBF controller. It formulates the feedforward control input to\na system as a linear combination of a set of basis functions whose coefficients\nare selected to minimize tracking errors. The basis functions are filtered\nusing a combination of two linear models to predict and minimize the tracking\nerrors. The first model is physics-based and remains unaltered during the\nexecution of the controller, while the second is data-driven and is\ncontinuously updated during the execution of the controller. To ensure its\npracticality and safe learning, the proposed hybrid FBF controller is equipped\nwith the ability to handle delays in data acquisition and to detect impending\ninstability due to its inherent data-driven feedback loop. Its effectiveness is\ndemonstrated via application to vibration compensation of a 3D printer with\nunmodeled linear and nonlinear dynamics. Thanks to the proposed hybrid FBF\ncontroller, the tracking accuracy of the 3D printer is significantly improved\nin experiments involving high-speed printing, compared to a standard FBF\ncontroller that does not incorporate a data-driven model. Furthermore, the\nability of the hybrid FBF controller to detect and, hence, potentially avoid\nimpending instability is demonstrated offline using data collected online from\nexperiments.",
    "descriptor": "\nComments: 10 pages, 11 figures, submitted to the IEEE for possible journal publication\n",
    "authors": [
      "Cheng-Hao Chou",
      "Molong Duan",
      "Chinedum E. Okwudire"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.11960"
  },
  {
    "id": "arXiv:2206.11961",
    "title": "LRPC codes with multiple syndromes: near ideal-size KEMs without ideals",
    "abstract": "We introduce a new rank-based key encapsulation mechanism (KEM) with public\nkey and ciphertext sizes around 3.5 Kbytes each, for 128 bits of security,\nwithout using ideal structures. Such structures allow to compress objects, but\ngive reductions to specific problems whose security is potentially weaker than\nfor unstructured problems. To the best of our knowledge, our scheme improves in\nsize all the existing unstructured post-quantum lattice or code-based\nalgorithms such as FrodoKEM or Classic McEliece. Our technique, whose\nefficiency relies on properties of rank metric, is to build upon existing Low\nRank Parity Check (LRPC) code-based KEMs and to send multiple syndromes in one\nciphertext, allowing to reduce the parameters and still obtain an acceptable\ndecoding failure rate. Our system relies on the hardness of the Rank Support\nLearning problem, a well-known variant of the Rank Syndrome Decoding problem.\nThe gain on parameters is enough to significantly close the gap between ideal\nand non-ideal constructions. It enables to choose an error weight close to the\nrank Gilbert-Varshamov bound, which is a relatively harder zone for algebraic\nattacks. We also give a version of our KEM that keeps an ideal structure and\npermits to roughly divide the bandwidth by two compared to previous versions of\nLRPC KEMs submitted to the NIST with a Decoding Failure Rate (DFR) of\n$2^{-128}$.",
    "descriptor": "\nComments: 31 pages\n",
    "authors": [
      "Carlos Aguilar-Melchor",
      "Nicolas Aragon",
      "Victor Dyseryn",
      "Philippe Gaborit",
      "Gilles Z\u00e9mor"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.11961"
  },
  {
    "id": "arXiv:2206.11965",
    "title": "Nystrom discretizations of boundary integral equations for the solution  of 2D elastic scattering problems",
    "abstract": "We present three high-order Nystrom discretization strategies of various\nboundary integral equation formulations of the impenetrable time-harmonic\nNavier equations in two dimensions. One class of such formulations is based on\nthe four classical Boundary Integral Operators (BIOs) associated with the\nGreen's function of the Navier operator. We consider two types of Nystrom\ndiscretizations of these operators, one that relies on Kussmaul-Martensen\nlogarithmic splittings and the other on Alpert quadratures. In addition, we\nconsider an alternative formulation of Navier scattering problems based on\nHelmholtz decompositions of the elastic fields, which can be solved via a\nsystem of boundary integral equations that feature integral operators\nassociated with the Helmholtz equation. Owing to the fact that some of the BIOs\nthat are featured in those formulations are non-standard, we use Quadrature by\nExpansion (QBX) methods for their high order Nystrom discretization.\nAlternatively, we use Maue integration by parts techniques to recast those\nnon-standard operators in terms of single and double layer Helmholtz BIOs whose\nNystrom discretizations is amenable to the Kussmaul-Martensen methodology. We\npresent a variety of numerical results concerning the high order accuracy that\nour Nystrom discretization elastic scattering solvers achieve for both smooth\nand Lipschitz boundaries. We also present extensive comparisons regarding the\niterative behavior of solvers based on different integral equations in the high\nfrequency regime. Finally, we illustrate how some of the Nystrom\ndiscretizations we considered can be incorporated seamlessly into the\nConvolution Quadrature (CQ) methodology to deliver high-order solutions of the\ntime domain elastic scattering problems.",
    "descriptor": "\nComments: 35 pages\n",
    "authors": [
      "Victor Dominguez",
      "Catalin Turc"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.11965"
  },
  {
    "id": "arXiv:2206.11968",
    "title": "Comparing supervised and self-supervised embedding for ExVo Multi-Task  learning track",
    "abstract": "The ICML Expressive Vocalizations (ExVo) Multi-task challenge 2022, focuses\non understanding the emotional facets of the non-linguistic vocalizations\n(vocal bursts (VB)). The objective of this challenge is to predict emotional\nintensities for VB, being a multi-task challenge it also requires to predict\nspeakers' age and native-country. For this challenge we study and compare two\ndistinct embedding spaces namely, self-supervised learning (SSL) based\nembeddings and task-specific supervised learning based embeddings. Towards\nthat, we investigate feature representations obtained from several pre-trained\nSSL neural networks and task-specific supervised classification neural\nnetworks. Our studies show that the best performance is obtained with a hybrid\napproach, where predictions derived via both SSL and task-specific supervised\nlearning are used. Our best system on test-set surpasses the ComPARE baseline\n(harmonic mean of all sub-task scores i.e., $S_{MTL}$) by a relative $13\\%$\nmargin.",
    "descriptor": "",
    "authors": [
      "Tilak Purohit",
      "Imen Ben Mahmoud",
      "Bogdan Vlasenko",
      "Mathew Magimai.-Doss"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.11968"
  },
  {
    "id": "arXiv:2206.11971",
    "title": "Looking for related discussions on GitHub Discussions",
    "abstract": "Software teams are increasingly adopting different tools and communication\nchannels to aid the software collaborative development model and coordinate\ntasks. Among such resources, Programming Community-based Question Answering\n(PCQA) forums have become widely used by developers. Such environments enable\ndevelopers to get and share technical information. Interested in supporting the\ndevelopment and management of Open Source Software (OSS) projects, GitHub\nannounced GitHub Discussions - a native forum to facilitate collaborative\ndiscussions between users and members of communities hosted on the platform. As\nGitHub Discussions resembles PCQA forums, it faces challenges similar to those\nfaced by such environments, which include the occurrence of related discussions\n(duplicates or near-duplicated posts). While duplicate posts have the same\ncontent - and may be exact copies - near-duplicates share similar topics and\ninformation. Both can introduce noise to the platform and compromise project\nknowledge sharing. In this paper, we address the problem of detecting related\nposts in GitHub Discussions. To do so, we propose an approach based on a\nSentence-BERT pre-trained model: the RD-Detector. We evaluated RD-Detector\nusing data from different OSS communities. OSS maintainers and Software\nEngineering (SE) researchers manually evaluated the RD-Detector results, which\nachieved 75% to 100% in terms of precision. In addition, maintainers pointed\nout practical applications of the approach, such as merging the discussions'\nthreads and making discussions as comments on one another. OSS maintainers can\nbenefit from RD-Detector to address the labor-intensive task of manually\ndetecting related discussions and answering the same question multiple times.",
    "descriptor": "\nComments: 36 pages, 3 figures, submitted to Computer Supported Cooperative Work (CSCW) - The Journal of Collaborative Computing and Work Practices\n",
    "authors": [
      "Marcia Lima",
      "Igor Steinmacher",
      "Denae Ford",
      "Evangeline Liu",
      "Grace Vorreuter",
      "Tayana Conte",
      "Bruno Gadelha"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.11971"
  },
  {
    "id": "arXiv:2206.11972",
    "title": "Task-Adaptive Few-shot Node Classification",
    "abstract": "Node classification is of great importance among various graph mining tasks.\nIn practice, real-world graphs generally follow the long-tail distribution,\nwhere a large number of classes only consist of limited labeled nodes. Although\nGraph Neural Networks (GNNs) have achieved significant improvements in node\nclassification, their performance decreases substantially in such a few-shot\nscenario. The main reason can be attributed to the vast generalization gap\nbetween meta-training and meta-test due to the task variance caused by\ndifferent node/class distributions in meta-tasks (i.e., node-level and\nclass-level variance). Therefore, to effectively alleviate the impact of task\nvariance, we propose a task-adaptive node classification framework under the\nfew-shot learning setting. Specifically, we first accumulate meta-knowledge\nacross classes with abundant labeled nodes. Then we transfer such knowledge to\nthe classes with limited labeled nodes via our proposed task-adaptive modules.\nIn particular, to accommodate the different node/class distributions among\nmeta-tasks, we propose three essential modules to perform \\emph{node-level},\n\\emph{class-level}, and \\emph{task-level} adaptations in each meta-task,\nrespectively. In this way, our framework can conduct adaptations to different\nmeta-tasks and thus advance the model generalization performance on meta-test\ntasks. Extensive experiments on four prevalent node classification datasets\ndemonstrate the superiority of our framework over the state-of-the-art\nbaselines. Our code is provided at https://github.com/SongW-SW/TENT.",
    "descriptor": "",
    "authors": [
      "Song Wang",
      "Kaize Ding",
      "Chuxu Zhang",
      "Chen Chen",
      "Jundong Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.11972"
  },
  {
    "id": "arXiv:2206.11974",
    "title": "Keep Your Transactions On Short Leashes",
    "abstract": "The adversary's goal in mounting Long Range Attacks (LRAs) is to fool\npotential victims into using and relying on a side chain, i.e., a false,\nalternate history of transactions, and into proposing transactions that end up\nharming themselves or others. Previous research work on LRAs on blockchain\nsystems have used, at a high level, one of two approaches. They either try to\n(1) prevent the creation of a bogus side chain or (2) make it possible to\ndistinguish such a side chain from the main consensus chain.\nIn this paper, we take a different approach. We start with the\nindistinguishability of side chains from the consensus chain -- for the\neclipsed victim -- as a given and assume the potential victim will be fooled.\nInstead, we protect the victim via harm reduction applying \"short leashes\" to\ntransactions. The leashes prevent transactions from being used in the wrong\ncontext.\nThe primary contribution of this paper is the design and analysis of leashes.\nA secondary contribution is the careful explication of the LRA threat model in\nthe context of BAR fault tolerance, and using it to analyze related work to\nidentify their limitations.",
    "descriptor": "",
    "authors": [
      "Bennet Yee"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.11974"
  },
  {
    "id": "arXiv:2206.11977",
    "title": "Hierarchical Planning with Annotated Skeleton Guidance",
    "abstract": "We present a hierarchical skeleton-guided motion planning algorithm to guide\nmobile robots. A good skeleton maps the connectivity of the subspace of c-space\ncontaining significant degrees of freedom and is able to guide the planner to\nfind the desired solutions fast. However, sometimes the skeleton does not\nclosely represent the free c-space, which often misleads current\nskeleton-guided planners. The hierarchical skeleton-guided planning strategy\ngradually relaxes its reliance on the workspace skeleton as C space is sampled,\nthereby incrementally returning a sub-optimal path, a feature that is not\nguaranteed in the standard skeleton-guided algorithm. Experimental comparisons\nto the standard skeleton-guided planners and other lazy planning strategies\nshow significant improvement in roadmap construction run time while maintaining\npath quality for multi-query problems in cluttered environments.",
    "descriptor": "",
    "authors": [
      "Diane Uwacu",
      "Ananya Yammanuru",
      "Marco Morales",
      "Nancy M. Amato"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.11977"
  },
  {
    "id": "arXiv:2206.11981",
    "title": "Never trust, always verify : a roadmap for Trustworthy AI?",
    "abstract": "Artificial Intelligence (AI) is becoming the corner stone of many systems\nused in our daily lives such as autonomous vehicles, healthcare systems, and\nunmanned aircraft systems. Machine Learning is a field of AI that enables\nsystems to learn from data and make decisions on new data based on models to\nachieve a given goal. The stochastic nature of AI models makes verification and\nvalidation tasks challenging. Moreover, there are intrinsic biaises in AI\nmodels such as reproductibility bias, selection bias (e.g., races, genders,\ncolor), and reporting bias (i.e., results that do not reflect the reality).\nIncreasingly, there is also a particular attention to the ethical, legal, and\nsocietal impacts of AI. AI systems are difficult to audit and certify because\nof their black-box nature. They also appear to be vulnerable to threats; AI\nsystems can misbehave when untrusted data are given, making them insecure and\nunsafe. Governments, national and international organizations have proposed\nseveral principles to overcome these challenges but their applications in\npractice are limited and there are different interpretations in the principles\nthat can bias implementations. In this paper, we examine trust in the context\nof AI-based systems to understand what it means for an AI system to be\ntrustworthy and identify actions that need to be undertaken to ensure that AI\nsystems are trustworthy. To achieve this goal, we first review existing\napproaches proposed for ensuring the trustworthiness of AI systems, in order to\nidentify potential conceptual gaps in understanding what trustworthy AI is.\nThen, we suggest a trust (resp. zero-trust) model for AI and suggest a set of\nproperties that should be satisfied to ensure the trustworthiness of AI\nsystems.",
    "descriptor": "",
    "authors": [
      "Lionel Nganyewou Tidjon",
      "Foutse Khomh"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.11981"
  },
  {
    "id": "arXiv:2206.11985",
    "title": "Path Integral Methods with Stochastic Control Barrier Functions",
    "abstract": "Safe control designs for robotic systems remain challenging because of the\ndifficulties of explicitly solving optimal control with nonlinear dynamics\nperturbed by stochastic noise. However, recent technological advances in\ncomputing devices enable online optimization or sampling-based methods to solve\ncontrol problems. For example, Control Barrier Functions (CBFs), a\nLyapunov-like control algorithm, have been proposed to numerically solve convex\noptimizations that determine control input to stay in the safe set. Model\nPredictive Path Integral (MPPI) uses forward sampling of stochastic\ndifferential equations to solve optimal control problems online. Both control\nalgorithms are widely used for nonlinear systems because they avoid calculating\nthe derivatives of the nonlinear dynamic function. In this paper, we utilize\nStochastic Control Barrier Functions (SCBFs) constraints to limit sample\nregions in the sample-based algorithm, ensuring safety in a probabilistic sense\nand improving sample efficiency with a stochastic differential equation. We\nprovide a sampling complexity analysis for the required sample size of our\nalgorithm and show that our algorithm needs fewer samples than the original\nMPPI algorithm does. Finally, we apply our algorithm to a path planning problem\nin a cluttered environment and compare the performance of the algorithms.",
    "descriptor": "",
    "authors": [
      "Chuyuan Tao",
      "Hyung-Jin Yoon",
      "Hunmin Kim",
      "Naira Hovakimyan",
      "Petros Voulgaris"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.11985"
  },
  {
    "id": "arXiv:2206.11987",
    "title": "Businesses in high-income zip codes saw sharper foot-traffic reductions  during the COVID-19 pandemic",
    "abstract": "As the COVID-19 pandemic unfolded, the mobility patterns of people worldwide\nchanged drastically. While travel time, the cost of the service, and trip\nconvenience had always influenced mobility, the risk of infection and policy\naction such as lockdowns and stay-at-home orders emerged as new factors to\nconsider in the mobility calculus. Using SafeGraph mobility data from\nMinnesota, USA, we demonstrate that businesses and point-of-interest locations\nin the more affluent zip codes witnessed much sharper reductions in foot\ntraffic than their poorer counterparts. We contend post-pandemic recovery\nefforts should prioritize relief funding accordingly.",
    "descriptor": "\nComments: 15 pages, 6 figures, 3 tables\n",
    "authors": [
      "Aditya Kulkarni",
      "Min Kim",
      "Joydeep Bhattacharya",
      "Jayanta Bhattacharya"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Databases (cs.DB)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.11987"
  },
  {
    "id": "arXiv:2206.11990",
    "title": "Equiformer: Equivariant Graph Attention Transformer for 3D Atomistic  Graphs",
    "abstract": "3D-related inductive biases like translational invariance and rotational\nequivariance are indispensable to graph neural networks operating on 3D\natomistic graphs such as molecules. Inspired by the success of Transformers in\nvarious domains, we study how to incorporate these inductive biases into\nTransformers. In this paper, we present Equiformer, a graph neural network\nleveraging the strength of Transformer architectures and incorporating\n$SE(3)/E(3)$-equivariant features based on irreducible representations\n(irreps). Irreps features encode equivariant information in channel dimensions\nwithout complicating graph structures. The simplicity enables us to directly\nincorporate them by replacing original operations with equivariant\ncounterparts. Moreover, to better adapt Transformers to 3D graphs, we propose a\nnovel equivariant graph attention, which considers both content and geometric\ninformation such as relative position contained in irreps features. To improve\nexpressivity of the attention, we replace dot product attention with\nmulti-layer perceptron attention and include non-linear message passing. We\nbenchmark Equiformer on two quantum properties prediction datasets, QM9 and\nOC20. For QM9, among models trained with the same data partition, Equiformer\nachieves best results on 11 out of 12 regression tasks. For OC20, under the\nsetting of training with IS2RE data and optionally IS2RS data, Equiformer\nimproves upon state-of-the-art models. Code reproducing all main results will\nbe available soon.",
    "descriptor": "",
    "authors": [
      "Yi-Lun Liao",
      "Tess Smidt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.11990"
  },
  {
    "id": "arXiv:2206.11992",
    "title": "The LBNL Superfacility Project Report",
    "abstract": "The Superfacility model is designed to leverage HPC for experimental science.\nIt is more than simply a model of connected experiment, network, and HPC\nfacilities; it encompasses the full ecosystem of infrastructure, software,\ntools, and expertise needed to make connected facilities easy to use. The\nthree-year Lawrence Berkeley National Laboratory (LBNL) Superfacility project\nwas initiated in 2019 to coordinate work being performed at LBNL to support\nthis model, and to provide a coherent and comprehensive set of science\nrequirements to drive existing and new work.\nA key component of the project was the in-depth engagements with eight\nscience teams that represent challenging use cases across the DOE Office of\nScience. By the close of the project, we met our project goal by enabling our\nscience application engagements to demonstrate automated pipelines that analyze\ndata from remote facilities at large scale, without routine human intervention.\nIn several cases, we have gone beyond demonstrations and now provide\nproduction-level services. To achieve this goal, the Superfacility team\ndeveloped tools, infrastructure, and policies for near-real-time computing\nsupport, dynamic high-performance networking, data management and movement\ntools, API-driven automation, HPC-scale notebooks via Jupyter, authentication\nusing Federated Identity and container-based edge services supported.\nThe lessons we learned during this project provide a valuable model for\nfuture large, complex, cross-disciplinary collaborations. There is a pressing\nneed for a coherent computing infrastructure across national facilities, and\nLBNL's Superfacility project is a unique model for success in tackling the\nchallenges that will be faced in hardware, software, policies, and services\nacross multiple science domains.",
    "descriptor": "\nComments: 85 pages, 23 figures\n",
    "authors": [
      "Deborah Bard",
      "Cory Snavely",
      "Lisa Gerhardt",
      "Jason Lee",
      "Becci Totzke",
      "Katie Antypas",
      "William Arndt",
      "Johannes Blaschke",
      "Suren Byna",
      "Ravi Cheema",
      "Shreyas Cholia",
      "Mark Day",
      "Bjoern Enders",
      "Aditi Gaur",
      "Annette Greiner",
      "Taylor Groves",
      "Mariam Kiran",
      "Quincey Koziol",
      "Tom Lehman",
      "Kelly Rowland",
      "Chris Samuel",
      "Ashwin Selvarajan",
      "Alex Sim",
      "David Skinner",
      "Laurie Stephie",
      "Rollin Thomas",
      "Gabor Torok"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.11992"
  },
  {
    "id": "arXiv:2206.11993",
    "title": "A Disability Lens towards Biases in GPT-3 Generated Open-Ended Languages",
    "abstract": "Language models (LM) are becoming prevalent in many language-based\napplication spaces globally. Although these LMs are improving our day-to-day\ninteractions with digital products, concerns remain whether open-ended\nlanguages or text generated from these models reveal any biases toward a\nspecific group of people, thereby risking the usability of a certain product.\nThere is a need to identify whether these models possess bias to improve the\nfairness in these models. This gap motivates our ongoing work, where we\nmeasured the two aspects of bias in GPT-3 generated text through a disability\nlens.",
    "descriptor": "\nComments: 5 pages, 1 figure, 1 table, IJCAI 2022 Workshop on Diversity in Artificial Intelligence\n",
    "authors": [
      "Akhter Al Amin",
      "Kazi Sinthia Kabir"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.11993"
  },
  {
    "id": "arXiv:2206.11995",
    "title": "Efficient and Accurate Top-$K$ Recovery from Choice Data",
    "abstract": "The intersection of learning to rank and choice modeling is an active area of\nresearch with applications in e-commerce, information retrieval and the social\nsciences. In some applications such as recommendation systems, the statistician\nis primarily interested in recovering the set of the top ranked items from a\nlarge pool of items as efficiently as possible using passively collected\ndiscrete choice data, i.e., the user picks one item from a set of multiple\nitems. Motivated by this practical consideration, we propose the choice-based\nBorda count algorithm as a fast and accurate ranking algorithm for top\n$K$-recovery i.e., correctly identifying all of the top $K$ items. We show that\nthe choice-based Borda count algorithm has optimal sample complexity for\ntop-$K$ recovery under a broad class of random utility models. We prove that in\nthe limit, the choice-based Borda count algorithm produces the same top-$K$\nestimate as the commonly used Maximum Likelihood Estimate method but the\nformer's speed and simplicity brings considerable advantages in practice.\nExperiments on both synthetic and real datasets show that the counting\nalgorithm is competitive with commonly used ranking algorithms in terms of\naccuracy while being several orders of magnitude faster.",
    "descriptor": "",
    "authors": [
      "Duc Nguyen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.11995"
  },
  {
    "id": "arXiv:2206.11996",
    "title": "The Real Deal: A Review of Challenges and Opportunities in Moving  Reinforcement Learning-Based Traffic Signal Control Systems Towards Reality",
    "abstract": "Traffic signal control (TSC) is a high-stakes domain that is growing in\nimportance as traffic volume grows globally. An increasing number of works are\napplying reinforcement learning (RL) to TSC; RL can draw on an abundance of\ntraffic data to improve signalling efficiency. However, RL-based signal\ncontrollers have never been deployed. In this work, we provide the first review\nof challenges that must be addressed before RL can be deployed for TSC. We\nfocus on four challenges involving (1) uncertainty in detection, (2)\nreliability of communications, (3) compliance and interpretability, and (4)\nheterogeneous road users. We show that the literature on RL-based TSC has made\nsome progress towards addressing each challenge. However, more work should take\na systems thinking approach that considers the impacts of other pipeline\ncomponents on RL.",
    "descriptor": "\nComments: 26 pages; accepted version, with shortened version to be published at the 12th International Workshop on Agents in Traffic and Transportation (ATT '22) at IJCAI 2022\n",
    "authors": [
      "Rex Chen",
      "Fei Fang",
      "Norman Sadeh"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.11996"
  },
  {
    "id": "arXiv:2206.12002",
    "title": "STREAMLINE: A Simple, Transparent, End-To-End Automated Machine Learning  Pipeline Facilitating Data Analysis and Algorithm Comparison",
    "abstract": "Machine learning (ML) offers powerful methods for detecting and modeling\nassociations often in data with large feature spaces and complex associations.\nMany useful tools/packages (e.g. scikit-learn) have been developed to make the\nvarious elements of data handling, processing, modeling, and interpretation\naccessible. However, it is not trivial for most investigators to assemble these\nelements into a rigorous, replicatable, unbiased, and effective data analysis\npipeline. Automated machine learning (AutoML) seeks to address these issues by\nsimplifying the process of ML analysis for all. Here, we introduce STREAMLINE,\na simple, transparent, end-to-end AutoML pipeline designed as a framework to\neasily conduct rigorous ML modeling and analysis (limited initially to binary\nclassification). STREAMLINE is specifically designed to compare performance\nbetween datasets, ML algorithms, and other AutoML tools. It is unique among\nother autoML tools by offering a fully transparent and consistent baseline of\ncomparison using a carefully designed series of pipeline elements including:\n(1) exploratory analysis, (2) basic data cleaning, (3) cross validation\npartitioning, (4) data scaling and imputation, (5) filter-based feature\nimportance estimation, (6) collective feature selection, (7) ML modeling with\n`Optuna' hyperparameter optimization across 15 established algorithms\n(including less well-known Genetic Programming and rule-based ML), (8)\nevaluation across 16 classification metrics, (9) model feature importance\nestimation, (10) statistical significance comparisons, and (11) automatically\nexporting all results, plots, a PDF summary report, and models that can be\neasily applied to replication data.",
    "descriptor": "\nComments: 24 pages, 15 figures, submitted for publication in Genetic Programming Theory and Practice Proceedings\n",
    "authors": [
      "Ryan J. Urbanowicz",
      "Robert Zhang",
      "Yuhan Cui",
      "Pranshu Suri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)",
      "Genomics (q-bio.GN)"
    ],
    "url": "https://arxiv.org/abs/2206.12002"
  },
  {
    "id": "arXiv:2206.12004",
    "title": "Sampling Enclosing Subgraphs for Link Prediction",
    "abstract": "Link prediction is a fundamental problem for graph-structured data (e.g.,\nsocial networks, drug side-effect networks, etc.). Graph neural networks have\noffered robust solutions for this problem, specifically by learning the\nrepresentation of the subgraph enclosing the target link (i.e., pair of nodes).\nHowever, these solutions do not scale well to large graphs as extraction and\noperation on enclosing subgraphs are computationally expensive, especially for\nlarge graphs. This paper presents a scalable link prediction solution, that we\ncall ScaLed, which utilizes sparse enclosing subgraphs to make predictions. To\nextract sparse enclosing subgraphs, ScaLed takes multiple random walks from a\ntarget pair of nodes, then operates on the sampled enclosing subgraph induced\nby all visited nodes. By leveraging the smaller sampled enclosing subgraph,\nScaLed can scale to larger graphs with much less overhead while maintaining\nhigh accuracy. ScaLed further provides the flexibility to control the trade-off\nbetween computation overhead and accuracy. Through comprehensive experiments,\nwe have shown that ScaLed can produce comparable accuracy to those reported by\nthe existing subgraph representation learning frameworks while being less\ncomputationally demanding.",
    "descriptor": "",
    "authors": [
      "Paul Louis",
      "Shweta Ann Jacob",
      "Amirali Salehi-Abari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.12004"
  },
  {
    "id": "arXiv:2206.12005",
    "title": "Knowledge Distillation via Weighted Ensemble of Teaching Assistants",
    "abstract": "Knowledge distillation in machine learning is the process of transferring\nknowledge from a large model called the teacher to a smaller model called the\nstudent. Knowledge distillation is one of the techniques to compress the large\nnetwork (teacher) to a smaller network (student) that can be deployed in small\ndevices such as mobile phones. When the network size gap between the teacher\nand student increases, the performance of the student network decreases. To\nsolve this problem, an intermediate model is employed between the teacher model\nand the student model known as the teaching assistant model, which in turn\nbridges the gap between the teacher and the student. In this research, we have\nshown that using multiple teaching assistant models, the student model (the\nsmaller model) can be further improved. We combined these multiple teaching\nassistant models using weighted ensemble learning where we have used a\ndifferential evaluation optimization algorithm to generate the weight values.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1902.03393 by other authors\n",
    "authors": [
      "Durga Prasad Ganta",
      "Himel Das Gupta",
      "Victor S. Sheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.12005"
  },
  {
    "id": "arXiv:2206.12006",
    "title": "When Satellites Work as Eavesdroppers",
    "abstract": "This paper considers satellite eavesdroppers in uplink satellite\ncommunication systems where the eavesdroppers are randomly distributed at\narbitrary altitudes according to homogeneous binomial point processes and\nattempt to overhear signals that a ground terminal transmits to a serving\nsatellite. Non-colluding eavesdropping satellites are assumed, i.e., they do\nnot cooperate with each other, so that their received signals are not combined\nbut are decoded individually. Directional beamforming with two types of\nantennas: fixed- and steerable-beam antennas, is adopted at the eavesdropping\nsatellites. The possible distribution cases for the eavesdropping satellites\nand the distributions of the distances between the terminal and the satellites\nare analyzed. The distributions of the signal-to-noise ratios (SNRs) at both\nthe serving satellite and the most detrimental eavesdropping satellite are\nderived as closed-form expressions. The ergodic and outage secrecy capacities\nof the systems are derived with the secrecy outage probability using the SNR\ndistributions. Simpler approximate expressions for the secrecy performance are\nobtained based on the Poisson limit theorem, and asymptotic analyses are also\ncarried out in the high-SNR regime. Monte-Carlo simulations verify the\nanalytical results for the secrecy performance. The analytical results are\nexpected to be used to evaluate the secrecy performance and design secure\nsatellite constellations by considering the impact of potential threats from\nmalicious satellite eavesdroppers.",
    "descriptor": "\nComments: 16 pages, 11 figures, 1 table, accepted by IEEE Transactions on Information Forensics and Security\n",
    "authors": [
      "Dong-Hyun Jung",
      "Joon-Gyu Ryu",
      "Junil Choi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.12006"
  },
  {
    "id": "arXiv:2206.12011",
    "title": "Detecting Correlated Gaussian Databases",
    "abstract": "This paper considers the problem of detecting whether two databases, each\nconsisting of $n$ users with $d$ Gaussian features, are correlated. Under the\nnull hypothesis, the databases are independent. Under the alternate hypothesis,\nthe features are correlated across databases, under an unknown row permutation.\nA simple test is developed to show that detection is achievable above $\\rho^2\n\\approx \\frac{1}{d}$. For the converse, the truncated second moment method is\nused to establish that detection is impossible below roughly $\\rho^2 \\approx\n\\frac{1}{d\\sqrt{n}}$. These results are compared to the corresponding recovery\nproblem, where the goal is to decode the row permutation, and a converse bound\nof roughly $\\rho^2 \\approx 1 - n^{-4/d}$ has been previously shown. For certain\nchoices of parameters, the detection achievability bound outperforms this\nrecovery converse bound, demonstrating that detection can be easier than\nrecovery in this scenario.",
    "descriptor": "\nComments: 26 pages, 4 figures\n",
    "authors": [
      "Zeynep K",
      "Bobak Nazer"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2206.12011"
  },
  {
    "id": "arXiv:2206.12016",
    "title": "Unsupervised Learning Algorithms for Keyword Extraction in an  Undergraduate Thesis",
    "abstract": "The amount of data managed in many academic institutions has increased in\nrecent years, particularly in all the research work done by undergraduate\nstudents, who simply use empirical techniques for keyword selection, forgetting\nexisting technical methods to assist their students in this process.\nInformation and communication technologies, such as the platform for integrated\nresearch and academic work with responsibility (PILAR), which records\ninformation about research projects, such as titles, summaries, and keywords in\ntheir various modalities, have gained relevance and importance in the\nmanagement of these. We proved algorithms with these records of research\nprojects that have been analysed in this study, and predictions were made for\neach of the nine (09) models of unsupervised machine learning algorithms that\nwere implemented for each of the 7430 records from the dataset. The most\nefficient way of extracting keywords for this dataset was the TF-IDF method,\nobtaining 72% accuracy and [0.4786, SD 0.0501] in average extraction time for\neach thesis file processed by this model.",
    "descriptor": "",
    "authors": [
      "Fred Torres-Cruz",
      "Edelfre Flores",
      "William E. Arcaya",
      "Irenio L. Chagua",
      "Marga I. Ingaluque"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.12016"
  },
  {
    "id": "arXiv:2206.12020",
    "title": "Provably Efficient Reinforcement Learning in Partially Observable  Dynamical Systems",
    "abstract": "We study Reinforcement Learning for partially observable dynamical systems\nusing function approximation. We propose a new \\textit{Partially Observable\nBilinear Actor-Critic framework}, that is general enough to include models such\nas observable tabular Partially Observable Markov Decision Processes (POMDPs),\nobservable Linear-Quadratic-Gaussian (LQG), Predictive State Representations\n(PSRs), as well as a newly introduced model Hilbert Space Embeddings of POMDPs\nand observable POMDPs with latent low-rank transition. Under this framework, we\npropose an actor-critic style algorithm that is capable of performing agnostic\npolicy learning. Given a policy class that consists of memory based policies\n(that look at a fixed-length window of recent observations), and a value\nfunction class that consists of functions taking both memory and future\nobservations as inputs, our algorithm learns to compete against the best\nmemory-based policy in the given policy class. For certain examples such as\nundercomplete observable tabular POMDPs, observable LQGs and observable POMDPs\nwith latent low-rank transition, by implicitly leveraging their special\nproperties, our algorithm is even capable of competing against the globally\noptimal policy without paying an exponential dependence on the horizon in its\nsample complexity.",
    "descriptor": "",
    "authors": [
      "Masatoshi Uehara",
      "Ayush Sekhari",
      "Jason D. Lee",
      "Nathan Kallus",
      "Wen Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.12020"
  },
  {
    "id": "arXiv:2206.12023",
    "title": "Error estimates for fractional semilinear optimal control on Lipschitz  polytopes",
    "abstract": "We adopt the integral definition of the fractional Laplace operator and\nanalyze discretization techniques for a fractional, semilinear, and elliptic\noptimal control problem posed on a Lipschitz polytope. We consider two\nstrategies of discretization: a semidiscrete scheme where control variables are\nnot discretized -- the so-called variational discretization approach -- and a\nfully discrete scheme where control variables are discretized with piecewise\nconstant functions. We discretize the corresponding state and adjoint equations\nwith a finite element scheme based on continuous piecewise linear functions and\nderive error estimates. With these estimates at hand, we derive error bounds\nfor the semidiscrete scheme on quasi-uniform and suitable graded meshes, and\nimprove the ones that are available in the literature for the fully discrete\nscheme.",
    "descriptor": "",
    "authors": [
      "Enrique Otarola"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.12023"
  },
  {
    "id": "arXiv:2206.12027",
    "title": "A multi-model-based deep learning framework for short text multiclass  classification with the imbalanced and extremely small data set",
    "abstract": "Text classification plays an important role in many practical applications.\nIn the real world, there are extremely small datasets. Most existing methods\nadopt pre-trained neural network models to handle this kind of dataset.\nHowever, these methods are either difficult to deploy on mobile devices because\nof their large output size or cannot fully extract the deep semantic\ninformation between phrases and clauses. This paper proposes a multimodel-based\ndeep learning framework for short-text multiclass classification with an\nimbalanced and extremely small data set. Our framework mainly includes five\nlayers: The encoder layer uses DISTILBERT to obtain context-sensitive dynamic\nword vectors that are difficult to represent in traditional feature engineering\nmethods. Since the transformer part of this layer is distilled, our framework\nis compressed. Then, we use the next two layers to extract deep semantic\ninformation. The output of the encoder layer is sent to a bidirectional LSTM\nnetwork, and the feature matrix is extracted hierarchically through the LSTM at\nthe word and sentence level to obtain the fine-grained semantic representation.\nAfter that, the max-pooling layer converts the feature matrix into a\nlower-dimensional matrix, preserving only the obvious features. Finally, the\nfeature matrix is taken as the input of a fully connected softmax layer, which\ncontains a function that can convert the predicted linear vector into the\noutput value as the probability of the text in each classification. Extensive\nexperiments on two public benchmarks demonstrate the effectiveness of our\nproposed approach on an extremely small data set. It retains the\nstate-of-the-art baseline performance in terms of precision, recall, accuracy,\nand F1 score, and through the model size, training time, and convergence epoch,\nwe can conclude that our method can be deployed faster and lighter on mobile\ndevices.",
    "descriptor": "",
    "authors": [
      "Jiajun Tong",
      "Zhixiao Wang",
      "Xiaobin Rui"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.12027"
  },
  {
    "id": "arXiv:2206.12030",
    "title": "Phasic Self-Imitative Reduction for Sparse-Reward Goal-Conditioned  Reinforcement Learning",
    "abstract": "It has been a recent trend to leverage the power of supervised learning (SL)\ntowards more effective reinforcement learning (RL) methods. We propose a novel\nphasic approach by alternating online RL and offline SL for tackling\nsparse-reward goal-conditioned problems. In the online phase, we perform RL\ntraining and collect rollout data while in the offline phase, we perform SL on\nthose successful trajectories from the dataset. To further improve sample\nefficiency, we adopt additional techniques in the online phase including task\nreduction to generate more feasible trajectories and a value-difference-based\nintrinsic reward to alleviate the sparse-reward issue. We call this overall\nalgorithm, PhAsic self-Imitative Reduction (PAIR). PAIR substantially\noutperforms both non-phasic RL and phasic SL baselines on sparse-reward\ngoal-conditioned robotic control problems, including a challenging stacking\ntask. PAIR is the first RL method that learns to stack 6 cubes with only 0/1\nsuccess rewards from scratch.",
    "descriptor": "\nComments: Accepted at ICML 2022\n",
    "authors": [
      "Yunfei Li",
      "Tian Gao",
      "Jiaqi Yang",
      "Huazhe Xu",
      "Yi Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.12030"
  },
  {
    "id": "arXiv:2206.12034",
    "title": "DialogID: A Dialogic Instruction Dataset for Improving Teaching  Effectiveness in Online Environments",
    "abstract": "Online dialogic instructions are a set of pedagogical instructions used in\nreal-world online educational contexts to motivate students, help understand\nlearning materials, and build effective study habits. In spite of the\npopularity and advantages of online learning, the education technology and\neducational data mining communities still suffer from the lack of large-scale,\nhigh-quality, and well-annotated teaching instruction datasets to study\ncomputational approaches to automatically detect online dialogic instructions\nand further improve the online teaching effectiveness. Therefore, in this\npaper, we present a dataset of online dialogic instruction detection,\n\\textsc{DialogID}, which contains 30,431 effective dialogic instructions. These\nteaching instructions are well annotated into 8 categories. Furthermore, we\nutilize the prevalent pre-trained language models (PLMs) and propose a simple\nyet effective adversarial training learning paradigm to improve the quality and\ngeneralization of dialogic instruction detection. Extensive experiments\ndemonstrate that our approach outperforms a wide range of baseline methods. The\ndata and our code are available for research purposes from:\n\\url{https://github.com/ai4ed/DialogID}.",
    "descriptor": "",
    "authors": [
      "Jiahao Chen",
      "Shuyan Huang",
      "Zitao Liu",
      "Weiqi Luo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.12034"
  },
  {
    "id": "arXiv:2206.12035",
    "title": "The Second Place Solution for The 4th Large-scale Video Object  Segmentation Challenge--Track 3: Referring Video Object Segmentation",
    "abstract": "The referring video object segmentation task (RVOS) aims to segment object\ninstances in a given video referred by a language expression in all video\nframes. Due to the requirement of understanding cross-modal semantics within\nindividual instances, this task is more challenging than the traditional\nsemi-supervised video object segmentation where the ground truth object masks\nin the first frame are given. With the great achievement of Transformer in\nobject detection and object segmentation, RVOS has been made remarkable\nprogress where ReferFormer achieved the state-of-the-art performance. In this\nwork, based on the strong baseline framework--ReferFormer, we propose several\ntricks to boost further, including cyclical learning rates, semi-supervised\napproach, and test-time augmentation inference. The improved ReferFormer ranks\n2nd place on CVPR2022 Referring Youtube-VOS Challenge.",
    "descriptor": "\nComments: 4 pages, 2 figures\n",
    "authors": [
      "Leilei Cao",
      "Zhuang Li",
      "Bo Yan",
      "Feng Zhang",
      "Fengliang Qi",
      "Yuchen Hu",
      "Hongbin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2206.12035"
  },
  {
    "id": "arXiv:2206.12036",
    "title": "SC-Ques: A Sentence Completion Question Dataset for English as a Second  Language Learners",
    "abstract": "Sentence completion (SC) questions present a sentence with one or more blanks\nthat need to be filled in, three to five possible words or phrases as options.\nSC questions are widely used for students learning English as a Second Language\n(ESL). In this paper, we present a large-scale SC dataset, \\textsc{SC-Ques},\nwhich is made up of 292,517 ESL SC questions from real-world standardized\nEnglish examinations. Furthermore, we build a comprehensive benchmark of\nautomatically solving the SC questions by training the large-scale pre-trained\nlanguage models on the proposed \\textsc{SC-Ques} dataset. We conduct detailed\nanalysis of the baseline models performance, limitations and trade-offs. The\ndata and our code are available for research purposes from:\n\\url{https://github.com/ai4ed/SC-Ques}.",
    "descriptor": "",
    "authors": [
      "Qiongqiong Liu",
      "Shuyan Huang",
      "Zitao Liu",
      "Weiqi Luo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.12036"
  },
  {
    "id": "arXiv:2206.12037",
    "title": "How to Train Your HiPPO: State Space Models with Generalized Orthogonal  Basis Projections",
    "abstract": "Linear time-invariant state space models (SSM) are a classical model from\nengineering and statistics, that have recently been shown to be very promising\nin machine learning through the Structured State Space sequence model (S4). A\ncore component of S4 involves initializing the SSM state matrix to a particular\nmatrix called a HiPPO matrix, which was empirically important for S4's ability\nto handle long sequences. However, the specific matrix that S4 uses was\nactually derived in previous work for a particular time-varying dynamical\nsystem, and the use of this matrix as a time-invariant SSM had no known\nmathematical interpretation. Consequently, the theoretical mechanism by which\nS4 models long-range dependencies actually remains unexplained. We derive a\nmore general and intuitive formulation of the HiPPO framework, which provides a\nsimple mathematical interpretation of S4 as a decomposition onto\nexponentially-warped Legendre polynomials, explaining its ability to capture\nlong dependencies. Our generalization introduces a theoretically rich class of\nSSMs that also lets us derive more intuitive S4 variants for other bases such\nas the Fourier basis, and explains other aspects of training S4, such as how to\ninitialize the important timescale parameter. These insights improve S4's\nperformance to 86% on the Long Range Arena benchmark, with 96% on the most\ndifficult Path-X task.",
    "descriptor": "",
    "authors": [
      "Albert Gu",
      "Isys Johnson",
      "Aman Timalsina",
      "Atri Rudra",
      "Christopher R\u00e9"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.12037"
  },
  {
    "id": "arXiv:2206.12038",
    "title": "BYOL-S: Learning Self-supervised Speech Representations by Bootstrapping",
    "abstract": "Methods for extracting audio and speech features have been studied since\npioneering work on spectrum analysis decades ago. Recent efforts are guided by\nthe ambition to develop general-purpose audio representations. For example,\ndeep neural networks can extract optimal embeddings if they are trained on\nlarge audio datasets. This work extends existing methods based on\nself-supervised learning by bootstrapping, proposes various encoder\narchitectures, and explores the effects of using different pre-training\ndatasets. Lastly, we present a novel training framework to come up with a\nhybrid audio representation, which combines handcrafted and data-driven learned\naudio features. All the proposed representations were evaluated within the HEAR\nNeurIPS 2021 challenge for auditory scene classification and timestamp\ndetection tasks. Our results indicate that the hybrid model with a\nconvolutional transformer as the encoder yields superior performance in most\nHEAR challenge tasks.",
    "descriptor": "",
    "authors": [
      "Gasser Elbanna",
      "Neil Scheidwasser-Clow",
      "Mikolaj Kegler",
      "Pierre Beckmann",
      "Karl El Hajal",
      "Milos Cernak"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.12038"
  },
  {
    "id": "arXiv:2206.12043",
    "title": "Protecting President Zelenskyy against Deep Fakes",
    "abstract": "The 2022 Russian invasion of Ukraine is being fought on two fronts: a brutal\nground war and a duplicitous disinformation campaign designed to conceal and\njustify Russia's actions. This campaign includes at least one example of a\ndeep-fake video purportedly showing Ukrainian President Zelenskyy admitting\ndefeat and surrendering. In anticipation of future attacks of this form, we\ndescribe a facial and gestural behavioral model that captures distinctive\ncharacteristics of Zelenskyy's speaking style. Trained on over eight hours of\nauthentic video from four different settings, we show that this behavioral\nmodel can distinguish Zelenskyy from deep-fake imposters.This model can play an\nimportant role -- particularly during the fog of war -- in distinguishing the\nreal from the fake.",
    "descriptor": "",
    "authors": [
      "Maty\u00e1\u0161 Boh\u00e1\u010dek",
      "Hany Farid"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.12043"
  },
  {
    "id": "arXiv:2206.12046",
    "title": "Bilateral Network with Channel Splitting Network and Transformer for  Thermal Image Super-Resolution",
    "abstract": "In recent years, the Thermal Image Super-Resolution (TISR) problem has become\nan attractive research topic. TISR would been used in a wide range of fields,\nincluding military, medical, agricultural and animal ecology. Due to the\nsuccess of PBVS-2020 and PBVS-2021 workshop challenge, the result of TISR keeps\nimproving and attracts more researchers to sign up for PBVS-2022 challenge. In\nthis paper, we will introduce the technical details of our submission to\nPBVS-2022 challenge designing a Bilateral Network with Channel Splitting\nNetwork and Transformer(BN-CSNT) to tackle the TISR problem. Firstly, we\ndesigned a context branch based on channel splitting network with transformer\nto obtain sufficient context information. Secondly, we designed a spatial\nbranch with shallow transformer to extract low level features which can\npreserve the spatial information. Finally, for the context branch in order to\nfuse the features from channel splitting network and transformer, we proposed\nan attention refinement module, and then features from context branch and\nspatial branch are fused by proposed feature fusion module. The proposed method\ncan achieve PSNR=33.64, SSIM=0.9263 for x4 and PSNR=21.08, SSIM=0.7803 for x2\nin the PBVS-2022 challenge test dataset.",
    "descriptor": "\nComments: The second place solution for CVPR2022 PBVS-TISR challenge\n",
    "authors": [
      "Bo Yan",
      "Leilei Cao",
      "Fengliang Qi",
      "Hongbin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.12046"
  },
  {
    "id": "arXiv:2206.12051",
    "title": "Exploring Tenets of Data Democratization",
    "abstract": "Data democratization is an ongoing process that broadens access to data and\nfacilitates employees to find, access, self-analyze, and share data without\nadditional support. This data access management process enables organizations\nto make informed decisions, which in return enhances organizational\nperformance. Technological advancements and extensive market pressure have\nmandated organizations to transform their traditional businesses into\ndata-driven organizations, focusing on data democratization as a part of their\ndata governance strategy. This paper explores the tenets of data\ndemocratization through an in-depth review of the literature. The analysis\nidentified twelve attributes that enable data democratization based on the\nliterature review. Future work will focus on testing and further empirically\ninvestigating these to develop a framework for the data democratization process\nto overcome the challenges.",
    "descriptor": "",
    "authors": [
      "Sasari Samarasinghe",
      "Sachithra Lokuge",
      "Lan Snell"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.12051"
  },
  {
    "id": "arXiv:2206.12052",
    "title": "Learning the policy for mixed electric platoon control of automated and  human-driven vehicles at signalized intersection: a random search approach",
    "abstract": "The upgrading and updating of vehicles have accelerated in the past decades.\nOut of the need for environmental friendliness and intelligence, electric\nvehicles (EVs) and connected and automated vehicles (CAVs) have become new\ncomponents of transportation systems. This paper develops a reinforcement\nlearning framework to implement adaptive control for an electric platoon\ncomposed of CAVs and human-driven vehicles (HDVs) at a signalized intersection.\nFirstly, a Markov Decision Process (MDP) model is proposed to describe the\ndecision process of the mixed platoon. Novel state representation and reward\nfunction are designed for the model to consider the behavior of the whole\nplatoon. Secondly, in order to deal with the delayed reward, an Augmented\nRandom Search (ARS) algorithm is proposed. The control policy learned by the\nagent can guide the longitudinal motion of the CAV, which serves as the leader\nof the platoon. Finally, a series of simulations are carried out in simulation\nsuite SUMO. Compared with several state-of-the-art (SOTA) reinforcement\nlearning approaches, the proposed method can obtain a higher reward. Meanwhile,\nthe simulation results demonstrate the effectiveness of the delay reward, which\nis designed to outperform distributed reward mechanism} Compared with normal\ncar-following behavior, the sensitivity analysis reveals that the energy can be\nsaved to different extends (39.27%-82.51%) by adjusting the relative importance\nof the optimization goal. On the premise that travel delay is not sacrificed,\nthe proposed control method can save up to 53.64% electric energy.",
    "descriptor": "",
    "authors": [
      "Xia Jiang",
      "Jian Zhang",
      "Xiaoyu Shi",
      "Jian Cheng"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.12052"
  },
  {
    "id": "arXiv:2206.12055",
    "title": "SDF-StyleGAN: Implicit SDF-Based StyleGAN for 3D Shape Generation",
    "abstract": "We present a StyleGAN2-based deep learning approach for 3D shape generation,\ncalled SDF-StyleGAN, with the aim of reducing visual and geometric\ndissimilarity between generated shapes and a shape collection. We extend\nStyleGAN2 to 3D generation and utilize the implicit signed distance function\n(SDF) as the 3D shape representation, and introduce two novel global and local\nshape discriminators that distinguish real and fake SDF values and gradients to\nsignificantly improve shape geometry and visual quality. We further complement\nthe evaluation metrics of 3D generative models with the shading-image-based\nFr\\'echet inception distance (FID) scores to better assess visual quality and\nshape distribution of the generated shapes. Experiments on shape generation\ndemonstrate the superior performance of SDF-StyleGAN over the state-of-the-art.\nWe further demonstrate the efficacy of SDF-StyleGAN in various tasks based on\nGAN inversion, including shape reconstruction, shape completion from partial\npoint clouds, single-view image-based shape generation, and shape style\nediting. Extensive ablation studies justify the efficacy of our framework\ndesign. Our code and trained models are available at\nhttps://github.com/Zhengxinyang/SDF-StyleGAN.",
    "descriptor": "\nComments: Accepted to Computer Graphics Forum (SGP), 2022\n",
    "authors": [
      "Xin-Yang Zheng",
      "Yang Liu",
      "Peng-Shuai Wang",
      "Xin Tong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.12055"
  },
  {
    "id": "arXiv:2206.12056",
    "title": "A new family of nonconforming elements with  $\\pmb{H}(\\mathrm{curl})$-continuity for the three-dimensional quad-curl  problem",
    "abstract": "We propose and analyze a new family of nonconforming finite elements for the\nthree-dimensional quad-curl problem. The proposed finite element spaces are\nsubspaces of $\\pmb{H}(\\mathrm{curl})$, but not of\n$\\pmb{H}(\\mathrm{grad}~\\mathrm{curl})$, which are different from the existing\nnonconforming ones. The well-posedness of the discrete problem is proved and\noptimal error estimates in discrete $\\pmb{H}(\\mathrm{grad}~\\mathrm{curl})$\nnorm, $\\pmb{H}(\\mathrm{curl})$ norm and $\\pmb{L}^2$ norm are derived. Numerical\nexperiments are provided to illustrate the good performance of the method and\nconfirm our theoretical predictions.",
    "descriptor": "",
    "authors": [
      "Baiju Zhang",
      "Zhimin Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.12056"
  },
  {
    "id": "arXiv:2206.12063",
    "title": "Mutual Information-guided Knowledge Transfer for Novel Class Discovery",
    "abstract": "We tackle the novel class discovery problem, aiming to discover novel classes\nin unlabeled data based on labeled data from seen classes. The main challenge\nis to transfer knowledge contained in the seen classes to unseen ones. Previous\nmethods mostly transfer knowledge through sharing representation space or joint\nlabel space. However, they tend to neglect the class relation between seen and\nunseen categories, and thus the learned representations are less effective for\nclustering unseen classes. In this paper, we propose a principle and general\nmethod to transfer semantic knowledge between seen and unseen classes. Our\ninsight is to utilize mutual information to measure the relation between seen\nclasses and unseen classes in a restricted label space and maximizing mutual\ninformation promotes transferring semantic knowledge. To validate the\neffectiveness and generalization of our method, we conduct extensive\nexperiments both on novel class discovery and general novel class discovery\nsettings. Our results show that the proposed method outperforms previous SOTA\nby a significant margin on several benchmarks.",
    "descriptor": "\nComments: in submission\n",
    "authors": [
      "Chuyu Zhang",
      "Chuanyang Hu",
      "Ruijie Xu",
      "Zhitong Gao",
      "Qian He",
      "Xuming He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.12063"
  },
  {
    "id": "arXiv:2206.12065",
    "title": "Eco-driving for Electric Connected Vehicles at Signalized Intersections:  A Parameterized Reinforcement Learning approach",
    "abstract": "This paper proposes an eco-driving framework for electric connected vehicles\n(CVs) based on reinforcement learning (RL) to improve vehicle energy efficiency\nat signalized intersections. The vehicle agent is specified by integrating the\nmodel-based car-following policy, lane-changing policy, and the RL policy, to\nensure safe operation of a CV. Subsequently, a Markov Decision Process (MDP) is\nformulated, which enables the vehicle to perform longitudinal control and\nlateral decisions, jointly optimizing the car-following and lane-changing\nbehaviors of the CVs in the vicinity of intersections. Then, the hybrid action\nspace is parameterized as a hierarchical structure and thereby trains the\nagents with two-dimensional motion patterns in a dynamic traffic environment.\nFinally, our proposed methods are evaluated in SUMO software from both a\nsingle-vehicle-based perspective and a flow-based perspective. The results show\nthat our strategy can significantly reduce energy consumption by learning\nproper action schemes without any interruption of other human-driven vehicles\n(HDVs).",
    "descriptor": "",
    "authors": [
      "Xia Jiang",
      "Jian Zhang",
      "Dan Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.12065"
  },
  {
    "id": "arXiv:2206.12070",
    "title": "New Classes of Binary Sequences with High Merit Factor",
    "abstract": "The Merit Factor (MF) measure was first introduced by Golay in 1972.\nSequences possessing large values of MF are of great interest to a rich list of\ndisciplines - from physics and chemistry to digital communications, signal\nprocessing, and cryptography. Throughout the last half-century, manifold\napproaches and strategies were proposed for finding such sequences. Referenced\nas one of the most difficult optimization problems, Golay wrote that it is a\n\"challenging and charming problem\". His publications on this problem spanned\nmore than 20 years. Golay himself introduced one beneficial class of sequences,\ncalled skew-symmetric sequences, or finite binary sequences with odd lengths\nwith alternate autocorrelation values equal to 0. Their sieving construction\ngreatly reduces the computational efforts of finding binary sequences with odd\nlengths and high MF. Having this in mind, the majority of papers to be found in\nthe literature are focused solely on this class, preferring them over binary\nsequences with even lengths. In this work, a new class of finite binary\nsequences with even lengths with alternate autocorrelation absolute values\nequal to 1 is presented. We show that the MF values of the new class are\nclosely related to the MF values of adjacent classes of skew-symmetric\nsequences. We further introduce new sub-classes of sequences using the\npartition number problem and the notion of potentials, measured by helper\nternary sequences. Throughout our experiments, MF records for binary sequences\nwith many lengths less than 225, and all lengths greater than 225, are\ndiscovered. Binary sequences of all lengths, odd or even, less than $2^8$ and\nwith MF $>8$, and all lengths, odd or even, less than $2^9$ and with MF $>7$,\nare now revealed.",
    "descriptor": "",
    "authors": [
      "Miroslav Dimitrov"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.12070"
  },
  {
    "id": "arXiv:2206.12071",
    "title": "Contrastive Learning of Features between Images and LiDAR",
    "abstract": "Image and Point Clouds provide different information for robots. Finding the\ncorrespondences between data from different sensors is crucial for various\ntasks such as localization, mapping, and navigation. Learning-based descriptors\nhave been developed for single sensors; there is little work on cross-modal\nfeatures. This work treats learning cross-modal features as a dense contrastive\nlearning problem. We propose a Tuple-Circle loss function for cross-modality\nfeature learning. Furthermore, to learn good features and not lose generality,\nwe developed a variant of widely used PointNet++ architecture for point cloud\nand U-Net CNN architecture for images. Moreover, we conduct experiments on a\nreal-world dataset to show the effectiveness of our loss function and network\nstructure. We show that our models indeed learn information from both images as\nwell as LiDAR by visualizing the features.",
    "descriptor": "\nComments: accepted in CASE2022\n",
    "authors": [
      "Peng Jiang",
      "Srikanth Saripalli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.12071"
  },
  {
    "id": "arXiv:2206.12073",
    "title": "MaskRange: A Mask-classification Model for Range-view based LiDAR  Segmentation",
    "abstract": "Range-view based LiDAR segmentation methods are attractive for practical\napplications due to their direct inheritance from efficient 2D CNN\narchitectures. In literature, most range-view based methods follow the\nper-pixel classification paradigm. Recently, in the image segmentation domain,\nanother paradigm formulates segmentation as a mask-classification problem and\nhas achieved remarkable performance. This raises an interesting question: can\nthe mask-classification paradigm benefit the range-view based LiDAR\nsegmentation and achieve better performance than the counterpart per-pixel\nparadigm? To answer this question, we propose a unified mask-classification\nmodel, MaskRange, for the range-view based LiDAR semantic and panoptic\nsegmentation. Along with the new paradigm, we also propose a novel data\naugmentation method to deal with overfitting, context-reliance, and\nclass-imbalance problems. Extensive experiments are conducted on the\nSemanticKITTI benchmark. Among all published range-view based methods, our\nMaskRange achieves state-of-the-art performance with $66.10$ mIoU on semantic\nsegmentation and promising results with $53.10$ PQ on panoptic segmentation\nwith high efficiency. Our code will be released.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Yi Gu",
      "Yuming Huang",
      "Chengzhong Xu",
      "Hui Kong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.12073"
  },
  {
    "id": "arXiv:2206.12076",
    "title": "Synthesizing Rolling Bearing Fault Samples in New Conditions: A  framework based on a modified CGAN",
    "abstract": "Bearings are one of the vital components of rotating machines that are prone\nto unexpected faults. Therefore, bearing fault diagnosis and condition\nmonitoring is essential for reducing operational costs and downtime in numerous\nindustries. In various production conditions, bearings can be operated under a\nrange of loads and speeds, which causes different vibration patterns associated\nwith each fault type. Normal data is ample as systems usually work in desired\nconditions. On the other hand, fault data is rare, and in many conditions,\nthere is no data recorded for the fault classes. Accessing fault data is\ncrucial for developing data-driven fault diagnosis tools that can improve both\nthe performance and safety of operations. To this end, a novel algorithm based\non Conditional Generative Adversarial Networks (CGANs) is introduced. Trained\non the normal and fault data on any actual fault conditions, this algorithm\ngenerates fault data from normal data of target conditions. The proposed method\nis validated on a real-world bearing dataset, and fault data are generated for\ndifferent conditions. Several state-of-the-art classifiers and visualization\nmodels are implemented to evaluate the quality of the synthesized data. The\nresults demonstrate the efficacy of the proposed algorithm.",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Maryam Ahang",
      "Masoud Jalayer",
      "Ardeshir Shojaeinasab",
      "Oluwaseyi Ogunfowora",
      "Todd Charter",
      "Homayoun Najjaran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.12076"
  },
  {
    "id": "arXiv:2206.12078",
    "title": "Multi-modal Sensor Data Fusion for In-situ Classification of Animal  Behavior Using Accelerometry and GNSS Data",
    "abstract": "We examine using data from multiple sensing modes, i.e., accelerometry and\nglobal navigation satellite system (GNSS), for classifying animal behavior. We\nextract three new features from the GNSS data, namely, the distance from the\nwater point, median speed, and median estimated horizontal position error. We\nconsider two approaches for combining the information available from the\naccelerometry and GNSS data. The first approach is based on concatenating the\nfeatures extracted from both sensor data and feeding the concatenated feature\nvector into a multi-layer perceptron (MLP) classifier. The second approach is\nbased on fusing the posterior probabilities predicted by two MLP classifiers\neach taking the features extracted from the data of one sensor as input. We\nevaluate the performance of the developed multi-modal animal behavior\nclassification algorithms using two real-world datasets collected via smart\ncattle collar and ear tags. The leave-one-animal-out cross-validation results\nshow that both approaches improve the classification performance appreciably\ncompared with using the data from only one sensing mode, in particular, for the\ninfrequent but important behaviors of walking and drinking. The algorithms\ndeveloped based on both approaches require rather small computational and\nmemory resources hence are suitable for implementation on embedded systems of\nour collar and ear tags. However, the multi-modal animal behavior\nclassification algorithm based on posterior probability fusion is preferable to\nthe one based on feature concatenation as it delivers better classification\naccuracy, has less computational and memory complexity, is more robust to\nsensor data failure, and enjoys better modularity.",
    "descriptor": "",
    "authors": [
      "Reza Arablouei",
      "Ziwei Wang",
      "Greg J. Bishop-Hurley",
      "Jiajun Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.12078"
  },
  {
    "id": "arXiv:2206.12081",
    "title": "Computationally Efficient PAC RL in POMDPs with Latent Determinism and  Conditional Embeddings",
    "abstract": "We study reinforcement learning with function approximation for large-scale\nPartially Observable Markov Decision Processes (POMDPs) where the state space\nand observation space are large or even continuous. Particularly, we consider\nHilbert space embeddings of POMDP where the feature of latent states and the\nfeature of observations admit a conditional Hilbert space embedding of the\nobservation emission process, and the latent state transition is deterministic.\nUnder the function approximation setup where the optimal latent state-action\n$Q$-function is linear in the state feature, and the optimal $Q$-function has a\ngap in actions, we provide a \\emph{computationally and statistically efficient}\nalgorithm for finding the \\emph{exact optimal} policy. We show our algorithm's\ncomputational and statistical complexities scale polynomially with respect to\nthe horizon and the intrinsic dimension of the feature on the observation\nspace. Furthermore, we show both the deterministic latent transitions and gap\nassumptions are necessary to avoid statistical complexity exponential in\nhorizon or dimension. Since our guarantee does not have an explicit dependence\non the size of the state and observation spaces, our algorithm provably scales\nto large-scale POMDPs.",
    "descriptor": "",
    "authors": [
      "Masatoshi Uehara",
      "Ayush Sekhari",
      "Jason D. Lee",
      "Nathan Kallus",
      "Wen Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.12081"
  },
  {
    "id": "arXiv:2206.12082",
    "title": "Symbolic-Regression Boosting",
    "abstract": "Modifying standard gradient boosting by replacing the embedded weak learner\nin favor of a strong(er) one, we present SyRBo: Symbolic-Regression Boosting.\nExperiments over 98 regression datasets show that by adding a small number of\nboosting stages -- between 2--5 -- to a symbolic regressor, statistically\nsignificant improvements can often be attained. We note that coding SyRBo on\ntop of any symbolic regressor is straightforward, and the added cost is simply\na few more evolutionary rounds. SyRBo is essentially a simple add-on that can\nbe readily added to an extant symbolic regressor, often with beneficial\nresults.",
    "descriptor": "",
    "authors": [
      "Moshe Sipper",
      "Jason H Moore"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.12082"
  },
  {
    "id": "arXiv:2206.12088",
    "title": "Classifying Unstructured Clinical Notes via Automatic Weak Supervision",
    "abstract": "Healthcare providers usually record detailed notes of the clinical care\ndelivered to each patient for clinical, research, and billing purposes. Due to\nthe unstructured nature of these narratives, providers employ dedicated staff\nto assign diagnostic codes to patients' diagnoses using the International\nClassification of Diseases (ICD) coding system. This manual process is not only\ntime-consuming but also costly and error-prone. Prior work demonstrated\npotential utility of Machine Learning (ML) methodology in automating this\nprocess, but it has relied on large quantities of manually labeled data to\ntrain the models. Additionally, diagnostic coding systems evolve with time,\nwhich makes traditional supervised learning strategies unable to generalize\nbeyond local applications. In this work, we introduce a general\nweakly-supervised text classification framework that learns from class-label\ndescriptions only, without the need to use any human-labeled documents. It\nleverages the linguistic domain knowledge stored within pre-trained language\nmodels and the data programming framework to assign code labels to individual\ntexts. We demonstrate the efficacy and flexibility of our method by comparing\nit to state-of-the-art weak text classifiers across four real-world text\nclassification datasets, in addition to assigning ICD codes to medical notes in\nthe publicly available MIMIC-III database.",
    "descriptor": "\nComments: 18 pages, 3 figures and 6 tables. Accepted at the Machine Learning for Healthcare Conference (MLHC) 2022\n",
    "authors": [
      "Chufan Gao",
      "Mononito Goswami",
      "Jieshi Chen",
      "Artur Dubrawski"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.12088"
  },
  {
    "id": "arXiv:2206.12089",
    "title": "Evolution of Activation Functions for Deep Learning-Based Image  Classification",
    "abstract": "Activation functions (AFs) play a pivotal role in the performance of neural\nnetworks. The Rectified Linear Unit (ReLU) is currently the most commonly used\nAF. Several replacements to ReLU have been suggested but improvements have\nproven inconsistent. Some AFs exhibit better performance for specific tasks,\nbut it is hard to know a priori how to select the appropriate one(s). Studying\nboth standard fully connected neural networks (FCNs) and convolutional neural\nnetworks (CNNs), we propose a novel, three-population, coevolutionary algorithm\nto evolve AFs, and compare it to four other methods, both evolutionary and\nnon-evolutionary. Tested on four datasets -- MNIST, FashionMNIST, KMNIST, and\nUSPS -- coevolution proves to be a performant algorithm for finding good AFs\nand AF architectures.",
    "descriptor": "",
    "authors": [
      "Raz Lapid",
      "Moshe Sipper"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.12089"
  },
  {
    "id": "arXiv:2206.12093",
    "title": "An Improved Lattice-Based Ring Signature with Unclaimable Anonymity in  the Standard Model",
    "abstract": "Ring signatures enable a user to sign messages on behalf of an arbitrary set\nof users, called the ring, without revealing exactly which member of that ring\nactually generated the signature. The signer-anonymity property makes ring\nsignatures have been an active research topic. Recently, Park and Sealfon\n(CRYPTO 19) presented an important anonymity notion named signer-unclaimability\nand constructed a lattice-based ring signature scheme with unclaimable\nanonymity in the standard model, however, it did not consider the unforgeable\nw.r.t. adversarially-chosen-key attack (the public key ring of a signature may\ncontain keys created by an adversary) and the signature size grows\nquadratically in the size of ring and message. In this work, we propose a new\nlattice-based ring signature scheme with unclaimable anonymity in the standard\nmodel. In particular, our work improves the security and efficiency of Park and\nSealfons work, which is unforgeable w.r.t. adversarially-chosen-key attack, and\nthe ring signature size grows linearly in the ring size.",
    "descriptor": "",
    "authors": [
      "Mingxing Hu",
      "Weijiong Zhang",
      "Zhen Liu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.12093"
  },
  {
    "id": "arXiv:2206.12094",
    "title": "Unified BERT for Few-shot Natural Language Understanding",
    "abstract": "Even as pre-trained language models share a semantic encoder, natural\nlanguage understanding suffers from a diversity of output schemas. In this\npaper, we propose UBERT, a unified bidirectional language understanding model\nbased on BERT framework, which can universally model the training objects of\ndifferent NLU tasks through a biaffine network. Specifically, UBERT encodes\nprior knowledge from various aspects, uniformly constructing learning\nrepresentations across multiple NLU tasks, which is conducive to enhancing the\nability to capture common semantic understanding. Using the biaffine to model\nscores pair of the start and end position of the original text, various\nclassification and extraction structures can be converted into a universal,\nspan-decoding approach. Experiments show that UBERT achieves the\nstate-of-the-art performance on 7 NLU tasks, 14 datasets on few-shot and\nzero-shot setting, and realizes the unification of extensive information\nextraction and linguistic reasoning tasks.",
    "descriptor": "",
    "authors": [
      "JunYu Lu",
      "Ping Yang",
      "JiaXing Zhang",
      "RuYi Gan",
      "Jing Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.12094"
  },
  {
    "id": "arXiv:2206.12099",
    "title": "A novel approach for glaucoma classification by wavelet neural networks  using graph-based, statisitcal features of qualitatively improved images",
    "abstract": "In this paper, we have proposed a new glaucoma classification approach that\nemploys a wavelet neural network (WNN) on optimally enhanced retinal images\nfeatures. To avoid tedious and error prone manual analysis of retinal images by\nophthalmologists, computer aided diagnosis (CAD) substantially aids in robust\ndiagnosis. Our objective is to introduce a CAD system with a fresh approach.\nRetinal image quality improvement is attempted in two phases. The retinal image\npreprocessing phase improves the brightness and contrast of the image through\nquantile based histogram modification. It is followed by the image enhancement\nphase, which involves multi scale morphological operations using image specific\ndynamic structuring elements for the retinal structure enrichment. Graph based\nretinal image features in terms of Local Graph Structures (LGS) and Graph\nShortest Path (GSP) statistics are extracted from various directions along with\nthe statistical features from the enhanced retinal dataset. WNN is employed to\nclassify glaucoma retinal images with a suitable wavelet activation function.\nThe performance of the WNN classifier is compared with multilayer perceptron\nneural networks with various datasets. The results show our approach is\nsuperior to the existing approaches.",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "N. Krishna Santosh",
      "Dr. Soubhagya Sankar Barpanda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.12099"
  },
  {
    "id": "arXiv:2206.12100",
    "title": "zPROBE: Zero Peek Robustness Checks for Federated Learning",
    "abstract": "Privacy-preserving federated learning allows multiple users to jointly train\na model with coordination of a central server. The server only learns the final\naggregation result, thereby preventing leakage of the users' (private) training\ndata from the individual model updates. However, keeping the individual updates\nprivate allows malicious users to perform Byzantine attacks and degrade the\nmodel accuracy without being detected. Best existing defenses against Byzantine\nworkers rely on robust rank-based statistics, e.g., the median, to find\nmalicious updates. However, implementing privacy-preserving rank-based\nstatistics is nontrivial and unscalable in the secure domain, as it requires\nsorting of all individual updates. We establish the first private robustness\ncheck that uses high break point rank-based statistics on aggregated model\nupdates. By exploiting randomized clustering, we significantly improve the\nscalability of our defense without compromising privacy. We leverage the\nderived statistical bounds in zero-knowledge proofs to detect and remove\nmalicious updates without revealing the private user updates. Our novel\nframework, zPROBE, enables Byzantine resilient and secure federated learning.\nEmpirical evaluations demonstrate that zPROBE provides a low overhead solution\nto defend against state-of-the-art Byzantine attacks while preserving privacy.",
    "descriptor": "",
    "authors": [
      "Zahra Ghodsi",
      "Mojan Javaheripi",
      "Nojan Sheybani",
      "Xinqiao Zhang",
      "Ke Huang",
      "Farinaz Koushanfar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.12100"
  },
  {
    "id": "arXiv:2206.12101",
    "title": "Do You Know My Emotion? Emotion-Aware Strategy Recognition towards a  Persuasive Dialogue System",
    "abstract": "Persuasive strategy recognition task requires the system to recognize the\nadopted strategy of the persuader according to the conversation. However,\nprevious methods mainly focus on the contextual information, little is known\nabout incorporating the psychological feedback, i.e. emotion of the persuadee,\nto predict the strategy. In this paper, we propose a Cross-channel Feedback\nmemOry Network (CFO-Net) to leverage the emotional feedback to iteratively\nmeasure the potential benefits of strategies and incorporate them into the\ncontextual-aware dialogue information. Specifically, CFO-Net designs a feedback\nmemory module, including strategy pool and feedback pool, to obtain\nemotion-aware strategy representation. The strategy pool aims to store\nhistorical strategies and the feedback pool is to obtain updated strategy\nweight based on feedback emotional information. Furthermore, a cross-channel\nfusion predictor is developed to make a mutual interaction between the\nemotion-aware strategy representation and the contextual-aware dialogue\ninformation for strategy recognition. Experimental results on\n\\textsc{PersuasionForGood} confirm that the proposed model CFO-Net is effective\nto improve the performance on M-F1 from 61.74 to 65.41.",
    "descriptor": "\nComments: Accepted by ECML-PKDD 2022\n",
    "authors": [
      "Wei Peng",
      "Yue Hu",
      "Luxi Xing",
      "Yuqiang Xie",
      "Yajing Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.12101"
  },
  {
    "id": "arXiv:2206.12104",
    "title": "On Structural Explanation of Bias in Graph Neural Networks",
    "abstract": "Graph Neural Networks (GNNs) have shown satisfying performance in various\ngraph analytical problems. Hence, they have become the \\emph{de facto} solution\nin a variety of decision-making scenarios. However, GNNs could yield biased\nresults against certain demographic subgroups. Some recent works have\nempirically shown that the biased structure of the input network is a\nsignificant source of bias for GNNs. Nevertheless, no studies have\nsystematically scrutinized which part of the input network structure leads to\nbiased predictions for any given node. The low transparency on how the\nstructure of the input network influences the bias in GNN outcome largely\nlimits the safe adoption of GNNs in various decision-critical scenarios. In\nthis paper, we study a novel research problem of structural explanation of bias\nin GNNs. Specifically, we propose a novel post-hoc explanation framework to\nidentify two edge sets that can maximally account for the exhibited bias and\nmaximally contribute to the fairness level of the GNN prediction for any given\nnode, respectively. Such explanations not only provide a comprehensive\nunderstanding of bias/fairness of GNN predictions but also have practical\nsignificance in building an effective yet fair GNN model. Extensive experiments\non real-world datasets validate the effectiveness of the proposed framework\ntowards delivering effective structural explanations for the bias of GNNs.\nOpen-source code can be found at https://github.com/yushundong/REFEREE.",
    "descriptor": "\nComments: Published as a conference paper at SIGKDD 2022\n",
    "authors": [
      "Yushun Dong",
      "Song Wang",
      "Yu Wang",
      "Tyler Derr",
      "Jundong Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.12104"
  },
  {
    "id": "arXiv:2206.12106",
    "title": "TreeDRNet:A Robust Deep Model for Long Term Time Series Forecasting",
    "abstract": "Various deep learning models, especially some latest Transformer-based\napproaches, have greatly improved the state-of-art performance for long-term\ntime series forecasting.However, those transformer-based models suffer a severe\ndeterioration performance with prolonged input length, which prohibits them\nfrom using extended historical info.Moreover, these methods tend to handle\ncomplex examples in long-term forecasting with increased model complexity,\nwhich often leads to a significant increase in computation and less robustness\nin performance(e.g., overfitting). We propose a novel neural network\narchitecture, called TreeDRNet, for more effective long-term forecasting.\nInspired by robust regression, we introduce doubly residual link structure to\nmake prediction more robust.Built upon Kolmogorov-Arnold representation\ntheorem, we explicitly introduce feature selection, model ensemble, and a tree\nstructure to further utilize the extended input sequence, which improves the\nrobustness and representation power of TreeDRNet. Unlike previous deep models\nfor sequential forecasting work, TreeDRNet is built entirely on multilayer\nperceptron and thus enjoys high computational efficiency. Our extensive\nempirical studies show that TreeDRNet is significantly more effective than\nstate-of-the-art methods, reducing prediction errors by 20% to 40% for\nmultivariate time series. In particular, TreeDRNet is over 10 times more\nefficient than transformer-based methods. The code will be released soon.",
    "descriptor": "",
    "authors": [
      "Tian Zhou",
      "Jianqing Zhu",
      "Xue Wang",
      "Ziqing Ma",
      "Qingsong Wen",
      "Liang Sun",
      "Rong Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.12106"
  },
  {
    "id": "arXiv:2206.12107",
    "title": "Nonconforming finite element approximations and the analysis of  Nitsche's method for a singularly perturbed quad-curl problem in three  dimensions",
    "abstract": "We introduce and analyze a robust nonconforming finite element method for a\nthree dimensional singularly perturbed quad-curl model problem. For the\nsolution of the model problem, we derive proper a priori bounds, based on\nwhich, we prove that the proposed finite element method is robust with respect\nto the singular perturbation parameter $\\varepsilon$ and the numerical solution\nis uniformly convergent with order $h^{1/2}$. In addition, we investigate the\neffect of treating the second boundary condition weakly by Nitsche's method. We\nshow that such a treatment leads to sharper error estimates than imposing the\nboundary condition strongly when the parameter $\\varepsilon< h$. Finally,\nnumerical experiments are provided to illustrate the good performance of the\nmethod and confirm our theoretical predictions.",
    "descriptor": "",
    "authors": [
      "Baiju Zhang",
      "Zhimin Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.12107"
  },
  {
    "id": "arXiv:2206.12110",
    "title": "Learning Augmented Binary Search Trees",
    "abstract": "A treap is a classic randomized binary search tree data structure that is\neasy to implement and supports O(\\log n) expected time access. However, classic\ntreaps do not take advantage of the input distribution or patterns in the\ninput. Given recent advances in algorithms with predictions, we propose pairing\ntreaps with machine advice to form a learning-augmented treap. We are the first\nto propose a learning-augmented data structure that supports binary search tree\noperations such as range-query and successor functionalities. With the\nassumption that we have access to advice from a frequency estimation oracle, we\nassign learned priorities to the nodes to better improve the treap's structure.\nWe theoretically analyze the learning-augmented treap's performance under\nvarious input distributions and show that under those circumstances, our\nlearning-augmented treap has stronger guarantees than classic treaps and other\nclassic tree-based data structures. Further, we experimentally evaluate our\nlearned treap on synthetic datasets and demonstrate a performance advantage\nover other search tree data structures. We also present experiments on real\nworld datasets with known frequency estimation oracles and show improvements as\nwell.",
    "descriptor": "",
    "authors": [
      "Honghao Lin",
      "Tian Luo",
      "David P. Woodruff"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.12110"
  },
  {
    "id": "arXiv:2206.12111",
    "title": "Signal Knowledge Graph",
    "abstract": "This paper presents an knowledge graph to assist in reasoning over signals\nfor intelligence purposes. We highlight limitations of existing knowledge\ngraphs and reasoning systems for this purpose, using inference of an attack\nusing combined data from microphones, cameras and social media as an example.\nRather than acting directly on the received signal, our approach considers\nattacker behaviour, signal emission, receiver characteristics, and how signals\nare summarised to support inferring the underlying cause of the signal.",
    "descriptor": "\nComments: 8 pages, 10 figures\n",
    "authors": [
      "Anj Simmons",
      "Rajesh Vasa"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.12111"
  },
  {
    "id": "arXiv:2206.12114",
    "title": "Partially adjoint discretizations of adjoint operators",
    "abstract": "This paper concerns the discretizations in pair of adjoint operators between\nHilbert spaces so that the adjoint properties can be preserved. Due to the\nfinite-dimensional essence of discretized operators, a new framework, theory of\npartially adjoint operators, is motivated and presented in this paper, so that\nadjoint properties can be figured out for finite-dimensional operators which\ncan not be non-trivially densely defined in other background spaces. A formal\nmethodology is presented under the framework to construct partially adjoint\ndiscretizations by a conforming discretization (CD) and an\naccompanied-by-conforming discretization (ABCD) for each of the operators.\nMoreover, the methodology leads to an asymptotic uniformity of an infinite\nfamily of finite-dimensional operators. The validities of the theoretical\nframework and the formal construction of discretizations are illustrated by a\nsystematic family of in-pair discretizations of the adjoint exterior\ndifferential operators.\nThe adjoint properties concerned in the paper are the closed range theorem\nand the strong dualities, whose preservations have not been well studied yet.\nQuantified versions of the closed range theorem are established for both\nadjoint operators and partially adjoint discretizations. The notion\nPoincare-Alexander-Lefschetz (P-A-L for short) type duality is borrowed for\noperator theory, and horizontal and vertical P-A-L dualities are figured out\nfor adjoint operators and their analogues are established for partially adjoint\ndiscretizations. Particularly by partially adjoint discretizations of exterior\ndifferential operators, the Poincare-Lefschetz duality is preserved as an\nidentity, which was not yet obtained before.",
    "descriptor": "",
    "authors": [
      "Shuo Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/2206.12114"
  },
  {
    "id": "arXiv:2206.12117",
    "title": "Self Supervised Learning for Few Shot Hyperspectral Image Classification",
    "abstract": "Deep learning has proven to be a very effective approach for Hyperspectral\nImage (HSI) classification. However, deep neural networks require large\nannotated datasets to generalize well. This limits the applicability of deep\nlearning for HSI classification, where manually labelling thousands of pixels\nfor every scene is impractical. In this paper, we propose to leverage Self\nSupervised Learning (SSL) for HSI classification. We show that by pre-training\nan encoder on unlabeled pixels using Barlow-Twins, a state-of-the-art SSL\nalgorithm, we can obtain accurate models with a handful of labels. Experimental\nresults demonstrate that this approach significantly outperforms vanilla\nsupervised learning.",
    "descriptor": "\nComments: Accepted in IGARSS 2022\n",
    "authors": [
      "Nassim Ait Ali Braham",
      "Lichao Mou",
      "Jocelyn Chanussot",
      "Julien Mairal",
      "Xiao Xiang Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.12117"
  },
  {
    "id": "arXiv:2206.12118",
    "title": "How Does Automation Shape the Process of Narrative Visualization: A  Survey on Tools",
    "abstract": "In recent years, narrative visualization has gained a lot of attention.\nResearchers have proposed different design spaces for various narrative\nvisualization types and scenarios to facilitate the creation process. As users'\nneeds grow and automation technologies advance, more and more tools have been\ndesigned and developed. In this paper, we surveyed 122 papers and tools to\nstudy how automation can progressively engage in the visualization design and\nnarrative process. By investigating the narrative strengths and the drawing\nefforts of various visualizations, we created a two-dimensional coordinate to\nmap different visualization types. Our resulting taxonomy is organized by the\nseven types of narrative visualization on the +x-axis of the coordinate and the\nfour automation levels (i.e., design space, authoring tool, AI-supported tool,\nand AI-generator tool) we identified from the collected work. The taxonomy aims\nto provide an overview of current research and development in the automation\ninvolvement of narrative visualization tools. We discuss key research problems\nin each category and suggest new opportunities to encourage further research in\nthe related domain.",
    "descriptor": "",
    "authors": [
      "Qing Chen",
      "Shixiong Cao",
      "Jiazhe Wang",
      "Nan Cao"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.12118"
  },
  {
    "id": "arXiv:2206.12123",
    "title": "Some theoretical results on discrete contour trees",
    "abstract": "Contour trees have been developed to visualize or encode scalar data in\nimaging technologies and scientific simulations. Contours are defined on a\ncontinuous scalar field. For discrete data, a continuous function is first\ninterpolated, where contours are then defined. In this paper we define a\ndiscrete contour tree, called the iso-tree, on a scalar graph, and discuss its\nproperties. We show that the iso-tree model works for data of all dimensions,\nand develop an axiomatic system formalizing the discrete contour structures. We\nalso report an isomorphism between iso-trees and augmented contour trees,\nshowing that contour tree algorithms can be used to compute discrete contour\ntrees, and vice versa.",
    "descriptor": "\nComments: 5 pages, 5 figures\n",
    "authors": [
      "Yuqing Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2206.12123"
  },
  {
    "id": "arXiv:2206.12124",
    "title": "Towards Effective Depthwise Convolutions on ARMv8 Architecture",
    "abstract": "Depthwise convolutions are widely used in lightweight convolutional neural\nnetworks (CNNs). The performance of depthwise convolutions is mainly bounded by\nthe memory access rather than the arithmetic operations for classic\nconvolutions so that direct algorithms are often more efficient than indirect\nones (matrix multiplication-, Winograd-, and FFT-based convolutions) with\nadditional memory accesses. However, the existing direct implementations of\ndepthwise convolutions on ARMv8 architectures feature a bad trade-off between\nregister-level reuse of different tensors, which usually leads to sub-optimal\nperformance. In this paper, we propose new direct implementations of depthwise\nconvolutions by means of implicit padding, register tiling, etc., which contain\nforward propagation, backward propagation and weight gradient update\nprocedures. Compared to the existing ones, our new implementations can incur\nmuch less communication overhead between registers and cache. Experimental\nresults on two ARMv8 CPUs show that our implementations can averagely deliver\n4.88x and 16.4x performance improvement over the existing direct ones in open\nsource libraries and matrix multiplications-based ones in Pytorch,\nrespectively.",
    "descriptor": "",
    "authors": [
      "Ruochen Hao",
      "Qinglin Wang",
      "Shangfei Yin",
      "Tianyang Zhou",
      "Siqi Shen",
      "Songzhu Mei",
      "Jie Liu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.12124"
  },
  {
    "id": "arXiv:2206.12126",
    "title": "Temporal Attention Unit: Towards Efficient Spatiotemporal Predictive  Learning",
    "abstract": "Spatiotemporal predictive learning aims to generate future frames by learning\nfrom historical frames. In this paper, we investigate existing methods and\npresent a general framework of spatiotemporal predictive learning, in which the\nspatial encoder and decoder capture intra-frame features and the middle\ntemporal module catches inter-frame correlations. While the mainstream methods\nemploy recurrent units to capture long-term temporal dependencies, they suffer\nfrom low computational efficiency due to their unparallelizable architectures.\nTo parallelize the temporal module, we propose the Temporal Attention Unit\n(TAU), which decomposes the temporal attention into intra-frame statical\nattention and inter-frame dynamical attention. Moreover, while the mean squared\nerror loss focuses on intra-frame errors, we introduce a novel differential\ndivergence regularization to take inter-frame variations into account.\nExtensive experiments demonstrate that the proposed method enables the derived\nmodel to achieve competitive performance on various spatiotemporal prediction\nbenchmarks.",
    "descriptor": "",
    "authors": [
      "Cheng Tan",
      "Zhangyang Gao",
      "Siyuan Li",
      "Yongjie Xu",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.12126"
  },
  {
    "id": "arXiv:2206.12128",
    "title": "Excavating RoI Attention for Underwater Object Detection",
    "abstract": "Self-attention is one of the most successful designs in deep learning, which\ncalculates the similarity of different tokens and reconstructs the feature\nbased on the attention matrix. Originally designed for NLP, self-attention is\nalso popular in computer vision, and can be categorized into pixel-level\nattention and patch-level attention. In object detection, RoI features can be\nseen as patches from base feature maps. This paper aims to apply the attention\nmodule to RoI features to improve performance. Instead of employing an original\nself-attention module, we choose the external attention module, a modified\nself-attention with reduced parameters. With the proposed double head structure\nand the Positional Encoding module, our method can achieve promising\nperformance in object detection. The comprehensive experiments show that it\nachieves promising performance, especially in the underwater object detection\ndataset. The code will be avaiable in:\nhttps://github.com/zsyasd/Excavating-RoI-Attention-for-Underwater-Object-Detection",
    "descriptor": "",
    "authors": [
      "Xutao Liang",
      "Pinhao Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.12128"
  },
  {
    "id": "arXiv:2206.12131",
    "title": "MVP: Multi-task Supervised Pre-training for Natural Language Generation",
    "abstract": "Pre-trained language models (PLMs) have achieved notable success in natural\nlanguage generation (NLG) tasks. Up to now, most of the PLMs are pre-trained in\nan unsupervised manner using large-scale general corpus. In the meanwhile, an\nincreasing number of models pre-trained with less labeled data showcase\nsuperior performance compared to unsupervised models. Motivated by the success\nof supervised pre-training, we propose Multi-task superVised Pre-training (MVP)\nfor natural language generation. For pre-training the text generation model\nMVP, we collect a labeled pre-training corpus from 45 datasets over seven\ngeneration tasks. For each task, we further pre-train specific soft prompts to\nstimulate the model capacity in performing a specific task. Extensive\nexperiments have demonstrated the effectiveness of our supervised pre-training\nin a number of NLG tasks, and our general methods achieve state-of-the-art\nperformance on 12 of 17 datasets.",
    "descriptor": "",
    "authors": [
      "Tianyi Tang",
      "Junyi Li",
      "Wayne Xin Zhao",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.12131"
  },
  {
    "id": "arXiv:2206.12134",
    "title": "Capacity Optimal Coded Generalized MU-MIMO",
    "abstract": "With the complication of future communication scenarios, most conventional\nsignal processing technologies of multi-user multiple-input multiple-output\n(MU-MIMO) become unreliable, which are designed based on ideal assumptions,\nsuch as Gaussian signaling and independent identically distributed (IID)\nchannel matrices. As a result, this paper considers a generalized MU-MIMO\n(GMU-MIMO) system with more general assumptions, i.e., arbitrarily fixed input\ndistributions, and general unitarily-invariant channel matrices. However, there\nis still no accurate capacity analysis and capacity optimal transceiver with\npractical complexity for GMU-MIMO under the constraint of coding. To address\nthese issues, inspired by the replica method, the constrained sum capacity of\ncoded GMU-MIMO with fixed input distribution is calculated by using the\ncelebrated mutual information and minimum mean-square error (MMSE) lemma and\nthe MMSE optimality of orthogonal/vector approximate message passing\n(OAMP/VAMP). Then, a capacity optimal multiuser OAMP/VAMP receiver is proposed,\nwhose achievable rate is proved to be equal to the constrained sum capacity.\nMoreover, a design principle of multi-user codes is presented for the multiuser\nOAMP/VAMP, based on which a kind of practical multi-user low-density\nparity-check (MU-LDPC) code is designed. Numerical results show that\nfinite-length performances of the proposed MU-LDPC codes with multi-user\nOAMP/VAMP are about 2 dB away from the constrained sum capacity and outperform\nthose of the existing state-of-art methods.",
    "descriptor": "\nComments: Accepted by the 2022 IEEE International Symposium on Information Theory (ISIT).arXiv admin note:substantial text overlap with arXiv:2111.11061\n",
    "authors": [
      "Yuhao Chi",
      "Lei Liu",
      "Guanghui Song",
      "Ying Li",
      "Yong Liang Guan",
      "Chau Yuen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.12134"
  },
  {
    "id": "arXiv:2206.12139",
    "title": "Augmented Reality-Empowered Network Planning Services for Private  Networks",
    "abstract": "To support Industry 4.0 applications with haptics and human-machine\ninteraction, the sixth generation (6G) requires a new framework that is fully\nautonomous, visual, and interactive. In this paper, we propose a novel\nframework for private network planning services, providing an end-to-end\nsolution that receives visual and sensory data from the user device,\nreconstructs the 3D network environment and performs network planning on the\nserver, and visualizes the network performance with augmented reality (AR) on\nthe display of the user devices. The solution is empowered by three key\ntechnical components: 1) vision- and sensor fusion-based 3D environment\nreconstruction, 2) ray tracing-based radio map generation and network planning,\nand 3) AR-empowered network visualization enabled by real-time camera\nrelocalization. We conducted the proof-of-concept in a Bosch plant in Germany\nand showed good network coverage of the optimized antenna location, as well as\nhigh accuracy in both environment reconstruction and camera relocalization. We\nalso achieved real-time AR-supported network monitoring with an end-to-end\nlatency of about 32 ms per frame.",
    "descriptor": "",
    "authors": [
      "Qi Liao",
      "Tianlun Hu",
      "Nikolaj Marchenko"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.12139"
  },
  {
    "id": "arXiv:2206.12142",
    "title": "ER: Equivariance Regularizer for Knowledge Graph Completion",
    "abstract": "Tensor factorization and distanced based models play important roles in\nknowledge graph completion (KGC). However, the relational matrices in KGC\nmethods often induce a high model complexity, bearing a high risk of\noverfitting. As a remedy, researchers propose a variety of different\nregularizers such as the tensor nuclear norm regularizer. Our motivation is\nbased on the observation that the previous work only focuses on the \"size\" of\nthe parametric space, while leaving the implicit semantic information widely\nuntouched. To address this issue, we propose a new regularizer, namely,\nEquivariance Regularizer (ER), which can suppress overfitting by leveraging the\nimplicit semantic information. Specifically, ER can enhance the generalization\nability of the model by employing the semantic equivariance between the head\nand tail entities. Moreover, it is a generic solution for both distance based\nmodels and tensor factorization based models. The experimental results indicate\na clear and substantial improvement over the state-of-the-art relation\nprediction methods.",
    "descriptor": "",
    "authors": [
      "Zongsheng Cao",
      "Qianqian Xu",
      "Zhiyong Yang",
      "Qingming Huang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.12142"
  },
  {
    "id": "arXiv:2206.12143",
    "title": "Subdomain solution decomposition method for nonstationary problems",
    "abstract": "The reduction of computational costs in the numerical solution of\nnonstationary problems is achieved through splitting schemes. In this case,\nsolving a set of less computationally complex problems provides the transition\nto a new level in time. The traditional construction approach of splitting\nschemes is based on an additive representation of the problem operator(s) and\nuses explicit-implicit approximations for individual terms. Recently (Y.\nEfendiev, P.N. Vabishchevich. Splitting methods for solution decomposition in\nnonstationary problems. \\textit{Applied Mathematics and Computation}.\n\\textbf{397}, 125785, 2021), a new class of methods of approximate solution of\nnonstationary problems has been introduced based on decomposition not of\noperators but of the solution itself. This new approach with subdomain solution\nselection is used in this paper to construct domain decomposition schemes. The\nboundary value problem for a second-order parabolic equation in a rectangle\nwith a difference approximation in space is typical. Two and three-level\nschemes for decomposition of the domain with and without overlapping subdomains\nare investigated. Our numerical experiments complement the theoretical results.",
    "descriptor": "\nComments: 22 pages, 10 figures\n",
    "authors": [
      "Petr N. Vabishchevich"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.12143"
  },
  {
    "id": "arXiv:2206.12145",
    "title": "Efficient and Robust Training of Dense Object Nets for Multi-Object  Robot Manipulation",
    "abstract": "We propose a framework for robust and efficient training of Dense Object Nets\n(DON) with a focus on multi-object robot manipulation scenarios. DON is a\npopular approach to obtain dense, view-invariant object descriptors, which can\nbe used for a multitude of downstream tasks in robot manipulation, such as,\npose estimation, state representation for control, etc.. However, the original\nwork focused training on singulated objects, with limited results on\ninstance-specific, multi-object applications. Additionally, a complex data\ncollection pipeline, including 3D reconstruction and mask annotation of each\nobject, is required for training. In this paper, we further improve the\nefficacy of DON with a simplified data collection and training regime, that\nconsistently yields higher precision and enables robust tracking of keypoints\nwith less data requirements. In particular, we focus on training with\nmulti-object data instead of singulated objects, combined with a well-chosen\naugmentation scheme. We additionally propose an alternative loss formulation to\nthe original pixelwise formulation that offers better results and is less\nsensitive to hyperparameters. Finally, we demonstrate the robustness and\naccuracy of our proposed framework on a real-world robotic grasping task.",
    "descriptor": "",
    "authors": [
      "David B. Adrian",
      "Andras Gabor Kupcsik",
      "Markus Spies",
      "Heiko Neumann"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.12145"
  },
  {
    "id": "arXiv:2206.12146",
    "title": "Multi-Agent Deep Reinforcement Learning for Cost- and Delay-Sensitive  Virtual Network Function Placement and Routing",
    "abstract": "This paper proposes an effective and novel multiagent deep reinforcement\nlearning (MADRL)-based method for solving the joint virtual network function\n(VNF) placement and routing (P&R), where multiple service requests with\ndifferentiated demands are delivered at the same time. The differentiated\ndemands of the service requests are reflected by their delay- and\ncost-sensitive factors. We first construct a VNF P&R problem to jointly\nminimize a weighted sum of service delay and resource consumption cost, which\nis NP-complete. Then, the joint VNF P&R problem is decoupled into two iterative\nsubtasks: placement subtask and routing subtask. Each subtask consists of\nmultiple concurrent parallel sequential decision processes. By invoking the\ndeep deterministic policy gradient method and multi-agent technique, an\nMADRL-P&R framework is designed to perform the two subtasks. The new joint\nreward and internal rewards mechanism is proposed to match the goals and\nconstraints of the placement and routing subtasks. We also propose the\nparameter migration-based model-retraining method to deal with changing network\ntopologies. Corroborated by experiments, the proposed MADRL-P&R framework is\nsuperior to its alternatives in terms of service cost and delay, and offers\nhigher flexibility for personalized service demands. The parameter\nmigration-based model-retraining method can efficiently accelerate convergence\nunder moderate network topology changes.",
    "descriptor": "\nComments: 17 pages, 15 figures, Accepted by IEEE Transactions on Communications\n",
    "authors": [
      "Shaoyang Wang",
      "Chau Yuen",
      "Wei Ni",
      "Guan Yong Liang",
      "Tiejun Lv"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.12146"
  },
  {
    "id": "arXiv:2206.12147",
    "title": "MCMF: Multi-Constraints With Merging Features Bid Optimization in Online  Display Advertising",
    "abstract": "In the Real-Time Bidding (RTB), advertisers are increasingly relying on bid\noptimization to gain more conversions (i.e trade or arrival). Currently, the\nefficiency of bid optimization is still challenged by the (1) sparse feedback,\n(2) the budget management separated from the optimization, and (3) absence of\nbidding environment modeling. The conversion feedback is delayed and sparse,\nyet most methods rely on dense input (impression or click). Furthermore, most\napproaches are implemented in two stages: optimum formulation and budget\nmanagement, but the separation always degrades performance. Meanwhile, absence\nof bidding environment modeling, model-free controllers are commonly utilized,\nwhich perform poorly on sparse feedback and lead to control instability. We\naddress these challenges and provide the Multi-Constraints with Merging\nFeatures (MCMF) framework. It collects various bidding statuses as merging\nfeatures to promise performance on the sparse and delayed feedback. A cost\nfunction is formulated as dynamic optimum solution with budget management, the\noptimization and budget management are not separated. According to the cost\nfunction, the approximated gradients based on the Hebbian Learning Rule are\ncapable of updating the MCMF, even without modeling of the bidding environment.\nOur technique performs the best in the open dataset and provides stable budget\nmanagement even in extreme sparsity. The MCMF is applied in our real RTB\nproduction and we get 2.69% more conversions with 2.46% fewer expenditures.",
    "descriptor": "\nComments: 5 pages, 5 figures\n",
    "authors": [
      "Xiao Wang",
      "Shaoguo Liu",
      "Yidong Jia",
      "Yuxin Fu",
      "Yufang Yu",
      "Liang Wang",
      "Bo Zheng"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2206.12147"
  },
  {
    "id": "arXiv:2206.12150",
    "title": "Decoding Short LDPC Codes via BP-RNN Diversity and Reliability-Based  Post-Processing",
    "abstract": "This paper investigates decoder diversity architectures for short low-density\nparity-check (LDPC) codes, based on recurrent neural network (RNN) models of\nthe belief-propagation (BP) algorithm. We propose a new approach to achieve\ndecoder diversity, by specializing BP-RNN decoders to specific classes of\nerrors, with absorbing set support. We further combine our approach with an\nordered statistics decoding (OSD) post-processing step. We show that the OSD\npost-processing step effectively takes advantage of the bit-error rate\noptimization, deriving from the use of binary cross-entropy loss function, and\nthe diversity brought by the use of multiple BP-RNN decoders, thus providing an\nefficient way to bridge the gap to maximum likelihood decoding.",
    "descriptor": "",
    "authors": [
      "Joachim Rosseel",
      "Val\u00e9rian Mannoni",
      "Inbar Fijalkow",
      "Valentin Savin"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.12150"
  },
  {
    "id": "arXiv:2206.12156",
    "title": "Notes on presheaf representations of strategies and cohomological  refinements of $k$-consistency and $k$-equivalence",
    "abstract": "In this note, we show how positional strategies for $k$-pebble games have a\nnatural representation as certain presheaves. These representations correspond\nexactly to the sheaf-theoretic models of contextuality introduced by\nAbramsky-Brandenburger. We study the notion of cohomological $k$-consistency\nrecently introduced by Adam O' Conghaile from this perspective.",
    "descriptor": "\nComments: Working notes\n",
    "authors": [
      "Samson Abramsky"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.12156"
  },
  {
    "id": "arXiv:2206.12164",
    "title": "Elementary analytic functions in $VTC^0$",
    "abstract": "It is known that rational approximations of elementary analytic functions\n(exp, log, trigonometric, and hyperbolic functions, and their inverse\nfunctions) are computable in the weak complexity class $\\mathrm{TC}^0$. We show\nhow to formalize the construction and basic properties of these functions in\nthe corresponding theory of bounded arithmetic, $\\mathit{VTC}^0$.",
    "descriptor": "\nComments: 55 pages\n",
    "authors": [
      "Emil Je\u0159\u00e1bek"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.12164"
  },
  {
    "id": "arXiv:2206.12166",
    "title": "Neural Networks with A La Carte Selection of Activation Functions",
    "abstract": "Activation functions (AFs), which are pivotal to the success (or failure) of\na neural network, have received increased attention in recent years, with\nresearchers seeking to design novel AFs that improve some aspect of network\nperformance. In this paper we take another direction, wherein we combine a slew\nof known AFs into successful architectures, proposing three methods to do so\nbeneficially: 1) generate AF architectures at random, 2) use Optuna, an\nautomatic hyper-parameter optimization software framework, with a\nTree-structured Parzen Estimator (TPE) sampler, and 3) use Optuna with a\nCovariance Matrix Adaptation Evolution Strategy (CMA-ES) sampler. We show that\nall methods often produce significantly better results for 25 classification\nproblems when compared with a standard network composed of ReLU hidden units\nand a softmax output unit. Optuna with the TPE sampler emerged as the best AF\narchitecture-producing method.",
    "descriptor": "",
    "authors": [
      "Moshe Sipper"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.12166"
  },
  {
    "id": "arXiv:2206.12169",
    "title": "AdAUC: End-to-end Adversarial AUC Optimization Against Long-tail  Problems",
    "abstract": "It is well-known that deep learning models are vulnerable to adversarial\nexamples. Existing studies of adversarial training have made great progress\nagainst this challenge. As a typical trait, they often assume that the class\ndistribution is overall balanced. However, long-tail datasets are ubiquitous in\na wide spectrum of applications, where the amount of head class instances is\nlarger than the tail classes. Under such a scenario, AUC is a much more\nreasonable metric than accuracy since it is insensitive toward class\ndistribution. Motivated by this, we present an early trial to explore\nadversarial training methods to optimize AUC. The main challenge lies in that\nthe positive and negative examples are tightly coupled in the objective\nfunction. As a direct result, one cannot generate adversarial examples without\na full scan of the dataset. To address this issue, based on a concavity\nregularization scheme, we reformulate the AUC optimization problem as a saddle\npoint problem, where the objective becomes an instance-wise function. This\nleads to an end-to-end training protocol. Furthermore, we provide a convergence\nguarantee of the proposed algorithm. Our analysis differs from the existing\nstudies since the algorithm is asked to generate adversarial examples by\ncalculating the gradient of a min-max problem. Finally, the extensive\nexperimental results show the performance and robustness of our algorithm in\nthree long-tail datasets.",
    "descriptor": "",
    "authors": [
      "Wenzheng Hou",
      "Qianqian Xu",
      "Zhiyong Yang",
      "Shilong Bao",
      "Yuan He",
      "Qingming Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.12169"
  },
  {
    "id": "arXiv:2206.12178",
    "title": "MULTI-FLGANs: Multi-Distributed Adversarial Networks for Non-IID  distribution",
    "abstract": "Federated learning is an emerging concept in the domain of distributed\nmachine learning. This concept has enabled GANs to benefit from the rich\ndistributed training data while preserving privacy. However, in a non-iid\nsetting, current federated GAN architectures are unstable, struggling to learn\nthe distinct features and vulnerable to mode collapse. In this paper, we\npropose a novel architecture MULTI-FLGAN to solve the problem of low-quality\nimages, mode collapse and instability for non-iid datasets. Our results show\nthat MULTI-FLGAN is four times as stable and performant (i.e. high inception\nscore) on average over 20 clients compared to baseline FLGAN.",
    "descriptor": "",
    "authors": [
      "Akash Amalan",
      "Rui Wang",
      "Yanqi Qiao",
      "Emmanouil Panaousis",
      "Kaitai Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.12178"
  },
  {
    "id": "arXiv:2206.12183",
    "title": "\"You Can't Fix What You Can't Measure\": Privately Measuring Demographic  Performance Disparities in Federated Learning",
    "abstract": "Federated learning allows many devices to collaborate in the training of\nmachine learning models. As in traditional machine learning, there is a growing\nconcern that models trained with federated learning may exhibit disparate\nperformance for different demographic groups. Existing solutions to measure and\nensure equal model performance across groups require access to information\nabout group membership, but this access is not always available or desirable,\nespecially under the privacy aspirations of federated learning. We study the\nfeasibility of measuring such performance disparities while protecting the\nprivacy of the user's group membership and the federated model's performance on\nthe user's data. Protecting both is essential for privacy, because they may be\ncorrelated, and thus learning one may reveal the other. On the other hand, from\nthe utility perspective, the privacy-preserved data should maintain the\ncorrelation to ensure the ability to perform accurate measurements of the\nperformance disparity. We achieve both of these goals by developing locally\ndifferentially private mechanisms that preserve the correlations between group\nmembership and model performance. To analyze the effectiveness of the\nmechanisms, we bound their error in estimating the disparity when optimized for\na given privacy budget, and validate these bounds on synthetic data. Our\nresults show that the error rapidly decreases for realistic numbers of\nparticipating clients, demonstrating that, contrary to what prior work\nsuggested, protecting the privacy of protected attributes is not necessarily in\nconflict with identifying disparities in the performance of federated models.",
    "descriptor": "\nComments: 14 pages, 6 figures\n",
    "authors": [
      "Marc Juarez",
      "Aleksandra Korolova"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.12183"
  },
  {
    "id": "arXiv:2206.12188",
    "title": "Dynamic network congestion pricing based on deep reinforcement learning",
    "abstract": "Traffic congestion is a serious problem in urban areas. Dynamic congestion\npricing is one of the useful schemes to eliminate traffic congestion in\nstrategic scale. However, in the reality, an optimal dynamic congestion pricing\nis very difficult or impossible to determine theoretically, because road\nnetworks are usually large and complicated, and behavior of road users is\nuncertain. To account for this challenge, this work proposes a dynamic\ncongestion pricing method using deep reinforcement learning (DRL). It is\ndesigned to eliminate traffic congestion based on observable data in general\nlarge-scale road networks, by leveraging the data-driven nature of deep\nreinforcement learning. One of the novel elements of the proposed method is the\ndistributed and cooperative learning scheme. Specifically, the DRL is\nimplemented by a spatial-temporally distributed manner, and cooperation among\nDRL agents is established by novel techniques we call spatially shared reward\nand temporally switching learning. It enables fast and computationally\nefficient learning in large-scale networks. The numerical experiments using\nSioux Falls Network showed that the proposed method works well thanks to the\nnovel learning scheme.",
    "descriptor": "",
    "authors": [
      "Kimihiro Sato",
      "Toru Seo",
      "Takashi Fuse"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.12188"
  },
  {
    "id": "arXiv:2206.12190",
    "title": "SECLEDS: Sequence Clustering in Evolving Data Streams via Multiple  Medoids and Medoid Voting",
    "abstract": "Sequence clustering in a streaming environment is challenging because it is\ncomputationally expensive, and the sequences may evolve over time. K-medoids or\nPartitioning Around Medoids (PAM) is commonly used to cluster sequences since\nit supports alignment-based distances, and the k-centers being actual data\nitems helps with cluster interpretability. However, offline k-medoids has no\nsupport for concept drift, while also being prohibitively expensive for\nclustering data streams. We therefore propose SECLEDS, a streaming variant of\nthe k-medoids algorithm with constant memory footprint. SECLEDS has two unique\nproperties: i) it uses multiple medoids per cluster, producing stable\nhigh-quality clusters, and ii) it handles concept drift using an intuitive\nMedoid Voting scheme for approximating cluster distances. Unlike existing\nadaptive algorithms that create new clusters for new concepts, SECLEDS follows\na fundamentally different approach, where the clusters themselves evolve with\nan evolving stream. Using real and synthetic datasets, we empirically\ndemonstrate that SECLEDS produces high-quality clusters regardless of drift,\nstream size, data dimensionality, and number of clusters. We compare against\nthree popular stream and batch clustering algorithms. The state-of-the-art\nBanditPAM is used as an offline benchmark. SECLEDS achieves comparable F1 score\nto BanditPAM while reducing the number of required distance computations by\n83.7%. Importantly, SECLEDS outperforms all baselines by 138.7% when the stream\ncontains drift. We also cluster real network traffic, and provide evidence that\nSECLEDS can support network bandwidths of up to 1.08 Gbps while using the\n(expensive) dynamic time warping distance.",
    "descriptor": "\nComments: Accepted to appear in ECML/PKDD 2022\n",
    "authors": [
      "Azqa Nadeem",
      "Sicco Verwer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.12190"
  },
  {
    "id": "arXiv:2206.12195",
    "title": "Bioinspired composite learning control under discontinuous friction for  industrial robots",
    "abstract": "Adaptive control can be applied to robotic systems with parameter\nuncertainties, but improving its performance is usually difficult, especially\nunder discontinuous friction. Inspired by the human motor learning control\nmechanism, an adaptive learning control approach is proposed for a broad class\nof robotic systems with discontinuous friction, where a composite error\nlearning technique that exploits data memory is employed to enhance parameter\nestimation. Compared with the classical feedback error learning control, the\nproposed approach can achieve superior transient and steady-state tracking\nwithout high-gain feedback and persistent excitation at the cost of extra\ncomputational burden and memory usage. The performance improvement of the\nproposed approach has been verified by experiments based on a DENSO industrial\nrobot.",
    "descriptor": "\nComments: Submitted to 2022 IFAC International Workshop on Adaptive and Learning Control Systems\n",
    "authors": [
      "Yongping Pan",
      "Kai Guo",
      "Tairen Sun",
      "Mohamed Darouach"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.12195"
  },
  {
    "id": "arXiv:2206.12198",
    "title": "Space-time reduced basis methods for parametrized unsteady Stokes  equations",
    "abstract": "In this work, we analyse space-time reduced basis methods for the efficient\nnumerical simulation of haemodynamics in arteries. The classical formulation of\nthe reduced basis (RB) method features dimensionality reduction in space, while\nfinite differences schemes are employed for the time integration of the\nresulting ordinary differential equation (ODE). Space-time reduced basis\n(ST-RB) methods extend the dimensionality reduction paradigm to the temporal\ndimension, projecting the full-order problem onto a low-dimensional\nspatio-temporal subspace. Our goal is to investigate the application of ST-RB\nmethods to the unsteady incompressible Stokes equations, with a particular\nfocus on stability. High-fidelity simulations are performed using the Finite\nElement (FE) method and BDF2 as time marching scheme. We consider two different\nST-RB methods. In the first one - called ST--GRB - space-time model order\nreduction is achieved by means of a Galerkin projection; a spatio-temporal\nsupremizers enrichment procedure is introduced to guarantee stability. The\nsecond method - called ST-PGRB - is characterized by a Petrov-Galerkin\nprojection, stemming from a suitable minimization of the FOM residual, that\nallows to automatically attain stability. The classical RB method - denoted as\nSRB-TFO - serves as a baseline for theoretical development. Numerical tests\nhave been conducted on an idealized symmetric bifurcation geometry and on the\npatient-specific one of a femoropopliteal bypass. The results show that both\nST-RB methods provide accurate approximations of the high-fidelity solutions,\nwhile considerably reducing the computational cost. In particular, the ST-PGRB\nmethod exhibits the best performance, as it features a better computational\nefficiency while retaining accuracies in accordance with theoretical\nexpectations.",
    "descriptor": "\nComments: 27 pages (25 + 2 in appendix), 3 figures, 7 tables, to be submitted to SIAM Journal on Scientific Computing (SISC)\n",
    "authors": [
      "Riccardo Tenderini",
      "Nicholas Mueller",
      "Simone Deparis"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.12198"
  },
  {
    "id": "arXiv:2206.12204",
    "title": "Reaching the End of Unbiasedness: Uncovering Implicit Limitations of  Click-Based Learning to Rank",
    "abstract": "Click-based learning to rank (LTR) tackles the mismatch between click\nfrequencies on items and their actual relevance. The approach of previous work\nhas been to assume a model of click behavior and to subsequently introduce a\nmethod for unbiasedly estimating preferences under that assumed model. The\nsuccess of this approach is evident in that unbiased methods have been found\nfor an increasing number of behavior models and types of bias. This work aims\nto uncover the implicit limitations of the high-level prevalent approach in the\ncounterfactual LTR field. Thus, in contrast with limitations that follow from\nexplicit assumptions, our aim is to recognize limitations that the field is\ncurrently unaware of. We do this by inverting the existing approach: we start\nby capturing existing methods in generic terms, and subsequently, from these\ngeneric descriptions we derive the click behavior for which these methods can\nbe unbiased. Our inverted approach reveals that there are indeed implicit\nlimitations to the counterfactual LTR approach: we find counterfactual\nestimation can only produce unbiased methods for click behavior based on affine\ntransformations. In addition, we also recognize previously undiscussed\nlimitations of click-modelling and pairwise approaches to click-based LTR. Our\nfindings reveal that it is impossible for existing approaches to provide\nunbiasedness guarantees for all plausible click behavior models.",
    "descriptor": "\nComments: In Proceedings of the 2022 ACM SIGIR International Conference on the Theory of Information Retrieval (ICTIR '22), July 11-12, 2022, Madrid, Spain. ACM, New York, NY, USA, 11 pages. this https URL ISBN 978-1-4503-9412-3/22/07\n",
    "authors": [
      "Harrie Oosterhuis"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.12204"
  },
  {
    "id": "arXiv:2206.12209",
    "title": "Capture Salient Historical Information: A Fast and Accurate  Non-Autoregressive Model for Multi-turn Spoken Language Understanding",
    "abstract": "Spoken Language Understanding (SLU), a core component of the task-oriented\ndialogue system, expects a shorter inference facing the impatience of human\nusers. Existing work increases inference speed by designing non-autoregressive\nmodels for single-turn SLU tasks but fails to apply to multi-turn SLU in\nconfronting the dialogue history. The intuitive idea is to concatenate all\nhistorical utterances and utilize the non-autoregressive models directly.\nHowever, this approach seriously misses the salient historical information and\nsuffers from the uncoordinated-slot problems. To overcome those shortcomings,\nwe propose a novel model for multi-turn SLU named Salient History Attention\nwith Layer-Refined Transformer (SHA-LRT), which composes of an SHA module, a\nLayer-Refined Mechanism (LRM), and a Slot Label Generation (SLG) task. SHA\ncaptures salient historical information for the current dialogue from both\nhistorical utterances and results via a well-designed history-attention\nmechanism. LRM predicts preliminary SLU results from Transformer's middle\nstates and utilizes them to guide the final prediction, and SLG obtains the\nsequential dependency information for the non-autoregressive encoder.\nExperiments on public datasets indicate that our model significantly improves\nmulti-turn SLU performance (17.5% on Overall) with accelerating (nearly 15\ntimes) the inference process over the state-of-the-art baseline as well as\neffective on the single-turn SLU tasks.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2108.07005\n",
    "authors": [
      "Lizhi Cheng",
      "Weijia jia",
      "Wenmian Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.12209"
  },
  {
    "id": "arXiv:2206.12214",
    "title": "Optimization-Based Exploration of the Feasible Power Flow Space for  Rapid Data Collection",
    "abstract": "This paper provides a systematic investigation into the various nonlinear\nobjective functions which can be used to explore the feasible space associated\nwith the optimal power flow problem. A total of 40 nonlinear objective\nfunctions are tested, and their results are compared to the data generated by a\nnovel exhaustive rejection sampling routine. The Hausdorff distance, which is a\nmin-max set dissimilarity metric, is then used to assess how well each\nnonlinear objective function performed (i.e., how well the tested objective\nfunctions were able to explore the non-convex power flow space). Exhaustive\ntest results were collected from five PGLib test-cases and systematically\nanalyzed.",
    "descriptor": "",
    "authors": [
      "Ignasi Ventura Nadal",
      "Samuel Chevalier"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.12214"
  },
  {
    "id": "arXiv:2206.12216",
    "title": "Optimized Views Photogrammetry: Precision Analysis and A Large-scale  Case Study in Qingdao",
    "abstract": "UAVs have become one of the widely used remote sensing platforms and played a\ncritical role in the construction of smart cities. However, due to the complex\nenvironment in urban scenes, secure and accurate data acquisition brings great\nchallenges to 3D modeling and scene updating. Optimal trajectory planning of\nUAVs and accurate data collection of onboard cameras are non-trivial issues in\nurban modeling. This study presents the principle of optimized views\nphotogrammetry and verifies its precision and potential in large-scale 3D\nmodeling. Different from oblique photogrammetry, optimized views photogrammetry\nuses rough models to generate and optimize UAV trajectories, which is achieved\nthrough the consideration of model point reconstructability and view point\nredundancy. Based on the principle of optimized views photogrammetry, this\nstudy first conducts a precision analysis of 3D models by using UAV images of\noptimized views photogrammetry and then executes a large-scale case study in\nthe urban region of Qingdao city, China, to verify its engineering potential.\nBy using GCPs for image orientation precision analysis and TLS (terrestrial\nlaser scanning) point clouds for model quality analysis, experimental results\nshow that optimized views photogrammetry could construct stable image\nconnection networks and could achieve comparable image orientation accuracy.\nBenefiting from the accurate image acquisition strategy, the quality of mesh\nmodels significantly improves, especially for urban areas with serious\nocclusions, in which 3 to 5 times of higher accuracy has been achieved.\nBesides, the case study in Qingdao city verifies that optimized views\nphotogrammetry can be a reliable and powerful solution for the large-scale 3D\nmodeling in complex urban scenes.",
    "descriptor": "\nComments: 16 pages, 24 figures\n",
    "authors": [
      "Qingquan Li",
      "Wenshuai Yu",
      "San Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.12216"
  },
  {
    "id": "arXiv:2206.12222",
    "title": "On the Optimisation of the GSACA Suffix Array Construction Algorithm",
    "abstract": "The suffix array is arguably one of the most important data structures in\nsequence analysis and consequently there is a multitude of suffix sorting\nalgorithms. However, to this date the \\texttt{GSACA} algorithm introduced in\n2015 is the only known non-recursive linear-time suffix array construction\nalgorithm (SACA). Despite its interesting theoretical properties, there has\nbeen little effort in improving the algorithm's subpar real-world performance.\nThere is a super-linear algorithm \\texttt{DSH} which relies on the same sorting\nprinciple and is faster than \\texttt{DivSufSort}, the fastest SACA for over a\ndecade. This paper is concerned with analysing the sorting principle used in\n\\texttt{GSACA} and \\texttt{DSH} and exploiting its properties in order to give\nan optimised linear-time algorithm. Our resulting algorithm is not only\nsignificantly faster than \\texttt{GSACA} but also\noutperforms\\texttt{DivSufSort} and \\texttt{DSH}.",
    "descriptor": "",
    "authors": [
      "Jannik Olbrich",
      "Enno Ohlebusch",
      "Thomas B\u00fcchler"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.12222"
  },
  {
    "id": "arXiv:2206.12224",
    "title": "MPClan: Protocol Suite for Privacy-Conscious Computations",
    "abstract": "The growing volumes of data being collected and its analysis to provide\nbetter services are creating worries about digital privacy. To address privacy\nconcerns and give practical solutions, the literature has relied on secure\nmultiparty computation. However, recent research has mostly focused on the\nsmall-party honest-majority setting of up to four parties, noting efficiency\nconcerns. In this work, we extend the strategies to support a larger number of\nparticipants in an honest-majority setting with efficiency at the center stage.\nCast in the preprocessing paradigm, our semi-honest protocol improves the\nonline complexity of the decade-old state-of-the-art protocol of Damg\\aa rd and\nNielson (CRYPTO'07). In addition to having an improved online communication\ncost, we can shut down almost half of the parties in the online phase, thereby\nsaving up to 50% in the system's operational costs. Our maliciously secure\nprotocol also enjoys similar benefits and requires only half of the parties,\nexcept for one-time verification, towards the end.\nTo showcase the practicality of the designed protocols, we benchmark popular\napplications such as deep neural networks, graph neural networks, genome\nsequence matching, and biometric matching using prototype implementations. Our\nimproved protocols aid in bringing up to 60-80% savings in monetary cost over\nprior work.",
    "descriptor": "",
    "authors": [
      "Nishat Koti",
      "Shravani Patil",
      "Arpita Patra",
      "Ajith Suresh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.12224"
  },
  {
    "id": "arXiv:2206.12225",
    "title": "Adaptive Nonlinear Regulation via Gaussian Process",
    "abstract": "The paper deals with the problem of output regulation of nonlinear systems by\npresenting a learning-based adaptive internal model-based design strategy. We\nborrow from the adaptive internal model design technique recently proposed in\n[1] and extend it by means of a Gaussian process regressor. The learning-based\nadaptation is performed by following an \"event-triggered\" logic so that hybrid\ntools are used to analyse the resulting closed-loop system. Unlike the approach\nproposed in [1] where the friend is supposed to belong to a specific\nfinite-dimensional model set, here we only require smoothness of the ideal\nsteady-state control action. The paper also presents numerical simulations\nshowing how the proposed method outperforms previous approaches.",
    "descriptor": "\nComments: Submitted to CDC2022\n",
    "authors": [
      "Lorenzo Gentilini",
      "Michelangelo Bin",
      "Lorenzo Marconi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.12225"
  },
  {
    "id": "arXiv:2206.12227",
    "title": "Adversarial Robustness of Deep Neural Networks: A Survey from a Formal  Verification Perspective",
    "abstract": "Neural networks have been widely applied in security applications such as\nspam and phishing detection, intrusion prevention, and malware detection. This\nblack-box method, however, often has uncertainty and poor explainability in\napplications. Furthermore, neural networks themselves are often vulnerable to\nadversarial attacks. For those reasons, there is a high demand for trustworthy\nand rigorous methods to verify the robustness of neural network models.\nAdversarial robustness, which concerns the reliability of a neural network when\ndealing with maliciously manipulated inputs, is one of the hottest topics in\nsecurity and machine learning. In this work, we survey existing literature in\nadversarial robustness verification for neural networks and collect 39\ndiversified research works across machine learning, security, and software\nengineering domains. We systematically analyze their approaches, including how\nrobustness is formulated, what verification techniques are used, and the\nstrengths and limitations of each technique. We provide a taxonomy from a\nformal verification perspective for a comprehensive understanding of this\ntopic. We classify the existing techniques based on property specification,\nproblem reduction, and reasoning strategies. We also demonstrate representative\ntechniques that have been applied in existing studies with a sample model.\nFinally, we discuss open questions for future research.",
    "descriptor": "",
    "authors": [
      "Mark Huasong Meng",
      "Guangdong Bai",
      "Sin Gee Teo",
      "Zhe Hou",
      "Yan Xiao",
      "Yun Lin",
      "Jin Song Dong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.12227"
  },
  {
    "id": "arXiv:2206.12229",
    "title": "Prosody Cloning in Zero-Shot Multispeaker Text-to-Speech",
    "abstract": "The cloning of a speaker's voice using an untranscribed reference sample is\none of the great advances of modern neural text-to-speech (TTS) methods.\nApproaches for mimicking the prosody of a transcribed reference audio have also\nbeen proposed recently. In this work, we bring these two tasks together for the\nfirst time through utterance level normalization in conjunction with an\nutterance level speaker embedding. We further introduce a lightweight aligner\nfor extracting fine-grained prosodic features, that can be finetuned on\nindividual samples within seconds. We show that it is possible to clone the\nvoice of a speaker as well as the prosody of a spoken reference independently\nwithout any degradation in quality and high similarity to both original voice\nand prosody, as our objective evaluation and human study show. All of our code\nand trained models are available, alongside static and interactive demos.",
    "descriptor": "",
    "authors": [
      "Florian Lux",
      "Julia Koch",
      "Ngoc Thang Vu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.12229"
  },
  {
    "id": "arXiv:2206.12230",
    "title": "Deformable CNN and Imbalance-Aware Feature Learning for Singing  Technique Classification",
    "abstract": "Singing techniques are used for expressive vocal performances by employing\ntemporal fluctuations of the timbre, the pitch, and other components of the\nvoice. Their classification is a challenging task, because of mainly two\nfactors: 1) the fluctuations in singing techniques have a wide variety and are\naffected by many factors and 2) existing datasets are imbalanced. To deal with\nthese problems, we developed a novel audio feature learning method based on\ndeformable convolution with decoupled training of the feature extractor and the\nclassifier using a class-weighted loss function. The experimental results show\nthe following: 1) the deformable convolution improves the classification\nresults, particularly when it is applied to the last two convolutional layers,\nand 2) both re-training the classifier and weighting the cross-entropy loss\nfunction by a smoothed inverse frequency enhance the classification\nperformance.",
    "descriptor": "\nComments: Accepted to INTERSPEECH2022\n",
    "authors": [
      "Yuya Yamamoto",
      "Juhan Nam",
      "Hiroko Terasawa"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.12230"
  },
  {
    "id": "arXiv:2206.12232",
    "title": "A Fundamental Limit of Distributed Hypothesis Testing Under Memoryless  Quantization",
    "abstract": "We study a distributed hypothesis testing setup where peripheral nodes send\nquantized data to the fusion center in a memoryless fashion. The\n\\emph{expected} number of bits sent by each node under the null hypothesis is\nkept limited. We characterize the optimal decay rate of the mis-detection\n(type-II error) probability provided that false alarms (type-I error) are rare,\nand study the tradeoff between the communication rate and maximal type-II error\ndecay rate. We resort to rate-distortion methods to provide upper bounds to the\ntradeoff curve and show that at high rates lattice quantization achieves\nnear-optimal performance. We also characterize the tradeoff for the case where\nnodes are allowed to record and quantize a fixed number of samples. Moreover,\nunder sum-rate constraints, we show that an upper bound to the tradeoff curve\nis obtained with a water-filling solution.",
    "descriptor": "\nComments: A short version is presented in ICC 2022, Seoul\n",
    "authors": [
      "Yunus Inan",
      "Mert Kayaalp",
      "Ali H. Sayed",
      "Emre Telatar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.12232"
  },
  {
    "id": "arXiv:2206.12233",
    "title": "Reinforcement learning based adaptive metaheuristics",
    "abstract": "Parameter adaptation, that is the capability to automatically adjust an\nalgorithm's hyperparameters depending on the problem being faced, is one of the\nmain trends in evolutionary computation applied to numerical optimization.\nWhile several handcrafted adaptation policies have been proposed over the years\nto address this problem, only few attempts have been done so far at apply\nmachine learning to learn such policies. Here, we introduce a general-purpose\nframework for performing parameter adaptation in continuous-domain\nmetaheuristics based on state-of-the-art reinforcement learning algorithms. We\ndemonstrate the applicability of this framework on two algorithms, namely\nCovariance Matrix Adaptation Evolution Strategies (CMA-ES) and Differential\nEvolution (DE), for which we learn, respectively, adaptation policies for the\nstep-size (for CMA-ES), and the scale factor and crossover rate (for DE). We\ntrain these policies on a set of 46 benchmark functions at different\ndimensionalities, with various inputs to the policies, in two settings: one\npolicy per function, and one global policy for all functions. Compared,\nrespectively, to the Cumulative Step-size Adaptation (CSA) policy and to two\nwell-known adaptive DE variants (iDE and jDE), our policies are able to produce\ncompetitive results in the majority of cases, especially in the case of DE.",
    "descriptor": "\nComments: To appear in the Genetic and Evolutionary Computation Conference (GECCO) 2022, Companion Proceedings\n",
    "authors": [
      "Michele Tessari",
      "Giovanni Iacca"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.12233"
  },
  {
    "id": "arXiv:2206.12236",
    "title": "Multi-relational Instruction Association Graph for Binary Comparison",
    "abstract": "Cross-architecture binary similarity comparison is essential in many security\napplications. Recently, researchers have proposed learning-based approaches to\nimprove comparison performance. They adopted a paradigm of instruction\npre-training, individual binary encoding, and distance-based similarity\ncomparison. However, instruction embeddings pre-trained on external code corpus\nare not universal in diverse real-world applications. And separately encoding\ncross-architecture binaries will accumulate the semantic gap of instruction\nsets, limiting the comparison accuracy. This paper proposes a novel\ncross-architecture binary similarity comparison approach with multi-relational\ninstruction association graph. We associate mono-architecture instruction\ntokens with context relevance and cross-architecture tokens with potential\nsemantic correlations from different perspectives. Then we exploit the\nrelational graph convolutional network (R-GCN) to perform type-specific graph\ninformation propagation. Our approach can bridge the gap in the\ncross-architecture instruction representation spaces while avoiding the\nexternal pre-training workload. We conduct extensive experiments on basic\nblock-level and function-level datasets to prove the superiority of our\napproach. Furthermore, evaluations on a large-scale real-world IoT malware\nreuse function collection show that our approach is valuable for identifying\nmalware propagated on IoT devices of various architectures.",
    "descriptor": "\nComments: Accepted by EAI SecureComm 2022, 20 pages, 3 figures\n",
    "authors": [
      "Qige Song",
      "Yongzheng Zhang",
      "Shuhao Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.12236"
  },
  {
    "id": "arXiv:2206.12241",
    "title": "CoSP: Co-supervised pretraining of pocket and ligand",
    "abstract": "Can we inject the pocket-ligand interaction knowledge into the pre-trained\nmodel and jointly learn their chemical space? Pretraining molecules and\nproteins has attracted considerable attention in recent years, while most of\nthese approaches focus on learning one of the chemical spaces and lack the\ninjection of biological knowledge. We propose a co-supervised pretraining\n(CoSP) framework to simultaneously learn 3D pocket and ligand representations.\nWe use a gated geometric message passing layer to model both 3D pockets and\nligands, where each node's chemical features, geometric position and\norientation are considered. To learn biological meaningful embeddings, we\ninject the pocket-ligand interaction knowledge into the pretraining model via\ncontrastive loss. Considering the specificity of molecules, we further propose\na chemical similarity-enhanced negative sampling strategy to improve the\ncontrastive learning performance. Through extensive experiments, we conclude\nthat CoSP can achieve competitive results in pocket matching, molecule property\npredictions, and virtual screening.",
    "descriptor": "",
    "authors": [
      "Zhangyang Gao",
      "Cheng Tan",
      "Lirong Wu",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.12241"
  },
  {
    "id": "arXiv:2206.12245",
    "title": "Relative Survivable Network Design",
    "abstract": "One of the most important and well-studied settings for network design is\nedge-connectivity requirements. This encompasses uniform demands such as the\nMinimum $k$-Edge-Connected Spanning Subgraph problem ($k$-ECSS), as well as\nnonuniform demands such as the Survivable Network Design problem. A weakness of\nthese formulations, though, is that we are not able to ask for fault-tolerance\nlarger than the connectivity. We introduce and study new variants of these\nproblems under a notion of relative fault-tolerance. Informally, we require not\nthat two nodes are connected if there are a bounded number of faults (as in the\nclassical setting), but that two nodes are connected if there are a bounded\nnumber of faults and the two nodes are connected in the underlying graph\npost-faults. That is, the subgraph we build must \"behave\" identically to the\nunderlying graph with respect to connectivity after bounded faults.\nWe define and introduce these problems, and provide the first approximation\nalgorithms: a $(1+4/k)$-approximation for the unweighted relative version of\n$k$-ECSS, a $2$-approximation for the weighted relative version of $k$-ECSS,\nand a $27/4$-approximation for the special case of Relative Survivable Network\nDesign with only a single demand with a connectivity requirement of $3$. To\nobtain these results, we introduce a number of technical ideas that may of\nindependent interest. First, we give a generalization of Jain's iterative\nrounding analysis that works even when the cut-requirement function is not\nweakly supermodular, but instead satisfies a weaker definition we introduce and\nterm local weak supermodularity. Second, we prove a structure theorem and\ndesign an approximation algorithm utilizing a new decomposition based on\nimportant separators, which are structures commonly used in fixed-parameter\nalgorithms that have not commonly been used in approximation algorithms.",
    "descriptor": "\nComments: 29 pages, to appear at APPROX 2022\n",
    "authors": [
      "Michael Dinitz",
      "Ama Koranteng",
      "Guy Kortsarz"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2206.12245"
  },
  {
    "id": "arXiv:2206.12247",
    "title": "Generative Datalog with Stable Negation",
    "abstract": "Extending programming languages with stochastic behaviour such as\nprobabilistic choices or random sampling has a long tradition in computer\nscience. A recent development in this direction is a declarative probabilistic\nprogramming language, proposed by Barany et al. in 2017, which operates on\nstandard relational databases. In particular, Barany et al. proposed generative\nDatalog, a probabilistic extension of Datalog that allows sampling from\ndiscrete probability distributions. Intuitively, the output of a generative\nDatalog program P on an input database D is a probability space over the\nminimal models of D and P, the so-called possible outcomes. This is a natural\ngeneralization of the (deterministic) semantics of Datalog, where the output of\na program on a database is their unique minimal model. A natural question to\nask is how generative Datalog can be enriched with the useful feature of\nnegation, which in turn leads to a strictly more expressive declarative\nprobabilistic programming language. In particular, the challenging question is\nhow the probabilistic semantics of generative Datalog with negation can be\nrobustly defined. Our goal is to provide an answer to this question by\ninterpreting negation according to the stable model semantics.",
    "descriptor": "",
    "authors": [
      "Mario Alviano",
      "Matthias Lanzinger",
      "Michael Morak",
      "Andreas Pieris"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2206.12247"
  },
  {
    "id": "arXiv:2206.12251",
    "title": "Adversarial Zoom Lens: A Novel Physical-World Attack to DNNs",
    "abstract": "Although deep neural networks (DNNs) are known to be fragile, no one has\nstudied the effects of zooming-in and zooming-out of images in the physical\nworld on DNNs performance. In this paper, we demonstrate a novel physical\nadversarial attack technique called Adversarial Zoom Lens (AdvZL), which uses a\nzoom lens to zoom in and out of pictures of the physical world, fooling DNNs\nwithout changing the characteristics of the target object. The proposed method\nis so far the only adversarial attack technique that does not add physical\nadversarial perturbation attack DNNs. In a digital environment, we construct a\ndata set based on AdvZL to verify the antagonism of equal-scale enlarged images\nto DNNs. In the physical environment, we manipulate the zoom lens to zoom in\nand out of the target object, and generate adversarial samples. The\nexperimental results demonstrate the effectiveness of AdvZL in both digital and\nphysical environments. We further analyze the antagonism of the proposed data\nset to the improved DNNs. On the other hand, we provide a guideline for defense\nagainst AdvZL by means of adversarial training. Finally, we look into the\nthreat possibilities of the proposed approach to future autonomous driving and\nvariant attack ideas similar to the proposed attack.",
    "descriptor": "",
    "authors": [
      "Chengyin Hu",
      "Weiwen Shi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.12251"
  },
  {
    "id": "arXiv:2206.12252",
    "title": "Indecision Trees: Learning Argument-Based Reasoning under Quantified  Uncertainty",
    "abstract": "Using Machine Learning systems in the real world can often be problematic,\nwith inexplicable black-box models, the assumed certainty of imperfect\nmeasurements, or providing a single classification instead of a probability\ndistribution.\nThis paper introduces Indecision Trees, a modification to Decision Trees\nwhich learn under uncertainty, can perform inference under uncertainty, provide\na robust distribution over the possible labels, and can be disassembled into a\nset of logical arguments for use in other reasoning systems.",
    "descriptor": "\nComments: 13 pages, no imagery\n",
    "authors": [
      "Jonathan S. Kent",
      "David H. Menager"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.12252"
  },
  {
    "id": "arXiv:2206.12254",
    "title": "A Manifold-based Airfoil Geometric-feature Extraction and Discrepant  Data Fusion Learning Method",
    "abstract": "Geometrical shape of airfoils, together with the corresponding flight\nconditions, are crucial factors for aerodynamic performances prediction. The\nobtained airfoils geometrical features in most existing approaches (e.g.,\ngeometrical parameters extraction, polynomial description and deep learning)\nare in Euclidean space. State-of-the-art studies showed that curves or surfaces\nof an airfoil formed a manifold in Riemannian space. Therefore, the features\nextracted by existing methods are not sufficient to reflect the\ngeometric-features of airfoils. Meanwhile, flight conditions and geometric\nfeatures are greatly discrepant with different types, the relevant knowledge of\nthe influence of these two factors that on final aerodynamic performances\npredictions must be evaluated and learned to improve prediction accuracy.\nMotivated by the advantages of manifold theory and multi-task learning, we\npropose a manifold-based airfoil geometric-feature extraction and discrepant\ndata fusion learning method (MDF) to extract geometric-features of airfoils in\nRiemannian space (we call them manifold-features) and further fuse the\nmanifold-features with flight conditions to predict aerodynamic performances.\nExperimental results show that our method could extract geometric-features of\nairfoils more accurately compared with existing methods, that the average MSE\nof re-built airfoils is reduced by 56.33%, and while keeping the same predicted\naccuracy level of CL, the MSE of CD predicted by MDF is further reduced by\n35.37%.",
    "descriptor": "",
    "authors": [
      "Yu Xiang",
      "Guangbo Zhang",
      "Liwei Hu",
      "Jun Zhang",
      "Wenyong Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2206.12254"
  },
  {
    "id": "arXiv:2206.12258",
    "title": "Content Popularity Prediction Based on Quantized Federated Bayesian  Learning in Fog Radio Access Networks",
    "abstract": "In this paper, we investigate the content popularity prediction problem in\ncache-enabled fog radio access networks (F-RANs). In order to predict the\ncontent popularity with high accuracy and low complexity, we propose a Gaussian\nprocess based regressor to model the content request pattern. Firstly, the\nrelationship between content features and popularity is captured by our\nproposed model. Then, we utilize Bayesian learning to train the model\nparameters, which is robust to overfitting. However, Bayesian methods are\nusually unable to find a closed-form expression of the posterior distribution.\nTo tackle this issue, we apply a stochastic variance reduced gradient\nHamiltonian Monte Carlo (SVRG-HMC) method to approximate the posterior\ndistribution. To utilize the computing resources of other fog access points\n(F-APs) and to reduce the communications overhead, we propose a quantized\nfederated learning (FL) framework combining with Bayesian learning. The\nquantized federated Bayesian learning framework allows each F-AP to send\ngradients to the cloud server after quantizing and encoding. It can achieve a\ntradeoff between prediction accuracy and communications overhead effectively.\nSimulation results show that the performance of our proposed policy outperforms\nthe existing policies.",
    "descriptor": "\nComments: 26 pages, 10 figures\n",
    "authors": [
      "Yunwei Tao",
      "Yanxiang Jiang",
      "Fu-Chun Zheng",
      "Pengcheng Zhu",
      "Dusit Niyato",
      "Xiaohu You"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.12258"
  },
  {
    "id": "arXiv:2206.12260",
    "title": "Label Noise-Resistant Mean Teaching for Weakly Supervised Fake News  Detection",
    "abstract": "Fake news spreads at an unprecedented speed, reaches global audiences and\nposes huge risks to users and communities. Most existing fake news detection\nalgorithms focus on building supervised training models on a large amount of\nmanually labeled data, which is expensive to acquire or often unavailable. In\nthis work, we propose a novel label noise-resistant mean teaching approach\n(LNMT) for weakly supervised fake news detection. LNMT leverages unlabeled news\nand feedback comments of users to enlarge the amount of training data and\nfacilitates model training by generating refined labels as weak supervision.\nSpecifically, LNMT automatically assigns initial weak labels to unlabeled\nsamples based on semantic correlation and emotional association between news\ncontent and the comments. Moreover, in order to suppress the noises in weak\nlabels, LNMT establishes a mean teacher framework equipped with label\npropagation and label reliability estimation. The framework measures a weak\nlabel similarity matrix between the teacher and student networks, and\npropagates different valuable weak label information to refine the weak labels.\nMeanwhile, it exploits the consistency between the output class likelihood\nvectors of the two networks to evaluate the reliability of the weak labels and\nincorporates the reliability into model optimization to alleviate the negative\neffect of noisy weak labels. Extensive experiments show the superior\nperformance of LNMT.",
    "descriptor": "",
    "authors": [
      "Jingyi Xie",
      "Jiawei Liu",
      "Zheng-Jun Zha"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.12260"
  },
  {
    "id": "arXiv:2206.12261",
    "title": "Unsupervised Sentence Simplification via Dependency Parsing",
    "abstract": "Text simplification is the task of rewriting a text so that it is readable\nand easily understood. In this paper, we propose a simple yet novel\nunsupervised sentence simplification system that harnesses parsing structures\ntogether with sentence embeddings to produce linguistically effective\nsimplifications. This means our model is capable of introducing substantial\nmodifications to simplify a sentence while maintaining its original semantics\nand adequate fluency. We establish the unsupervised state-of-the-art at 39.13\nSARI on TurkCorpus set and perform competitively against supervised baselines\non various quality metrics. Furthermore, we demonstrate our framework's\nextensibility to other languages via a proof-of-concept on Vietnamese data.\nCode for reproduction is published at \\url{https://github.com/isVy08/USDP}.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Vy Vo",
      "Weiqing Wang",
      "Wray Buntine"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.12261"
  },
  {
    "id": "arXiv:2206.12262",
    "title": "Emoji-based Fine-grained Attention Network for Sentiment Analysis in the  Microblog Comments",
    "abstract": "Microblogs have become a social platform for people to express their emotions\nin real-time, and it is a trend to analyze user emotional tendencies from the\ninformation on Microblogs. The dynamic features of emojis can affect the\nsentiment polarity of microblog texts. Since existing models seldom consider\nthe diversity of emoji sentiment polarity,the paper propose a microblog\nsentiment classification model based on ALBERT-FAET. We obtain text embedding\nvia ALBERT pretraining model and learn the inter-emoji embedding with an\nattention-based LSTM network. In addition, a fine-grained attention mechanism\nis proposed to capture the word-level interactions between plain text and\nemoji. Finally, we concatenate these features and feed them into a CNN\nclassifier to predict the sentiment labels of the microblogs. To verify the\neffectiveness of the model and the fine-grained attention network, we conduct\ncomparison experiments and ablation experiments. The comparison experiments\nshow that the model outperforms previous methods in three evaluation indicators\n(accuracy, precision, and recall) and the model can significantly improve\nsentiment classification. The ablation experiments show that compared with\nALBERT-AET, the proposed model ALBERT-FAET is better in the metrics, indicating\nthat the fine-grained attention network can understand the diversified\ninformation of emoticons.",
    "descriptor": "",
    "authors": [
      "Deng Yang",
      "Liu Kejian",
      "Yang Cheng",
      "Feng Yuanyuan",
      "Li Weihao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.12262"
  },
  {
    "id": "arXiv:2206.12270",
    "title": "Using Autoencoders on Differentially Private Federated Learning GANs",
    "abstract": "Machine learning has been applied to almost all fields of computer science\nover the past decades. The introduction of GANs allowed for new possibilities\nin fields of medical research and text prediction. However, these new fields\nwork with ever more privacy-sensitive data. In order to maintain user privacy,\na combination of federated learning, differential privacy and GANs can be used\nto work with private data without giving away a users' privacy. Recently, two\nimplementations of such combinations have been published: DP-Fed-Avg GAN and\nGS-WGAN. This paper compares their performance and introduces an alternative\nversion of DP-Fed-Avg GAN that makes use of denoising techniques to combat the\nloss in accuracy that generally occurs when applying differential privacy and\nfederated learning to GANs. We also compare the novel adaptation of denoised\nDP-Fed-Avg GAN to the state-of-the-art implementations in this field.",
    "descriptor": "",
    "authors": [
      "Gregor Schram",
      "Rui Wang",
      "Kaitai Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.12270"
  },
  {
    "id": "arXiv:2206.12272",
    "title": "Physically Consistent Learning of Conservative Lagrangian Systems with  Gaussian Processes",
    "abstract": "This paper proposes a physically consistent Gaussian Process (GP) enabling\nthe identification of uncertain Lagrangian systems. The function space is\ntailored according to the energy components of the Lagrangian and the\ndifferential equation structure, analytically guaranteeing physical and\nmathematical properties such as energy conservation and quadratic form. The\nnovel formulation of Cholesky decomposed matrix kernels allow the probabilistic\npreservation of positive definiteness. Only differential input-to-output\nmeasurements of the function map are required while Gaussian noise is permitted\nin torques, velocities, and accelerations. We demonstrate the effectiveness of\nthe approach in numerical simulation.",
    "descriptor": "\nComments: Submitted to the IEEE for possible publication at CDC22\n",
    "authors": [
      "Giulio Evangelisti",
      "Sandra Hirche"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.12272"
  },
  {
    "id": "arXiv:2206.12275",
    "title": "A Literature Review on Serverless Computing",
    "abstract": "Serverless computing is an emerging cloud computing paradigm. Moreover, it\nhas become an attractive development option for cloud-based applications for\nsoftware developers. The most significant advantage of serverless computing is\nto free software developers from the burden of complex underlying management\ntasks and allow them to focus on only the application logic implementation.\nBased on its benign characteristics and bright prospect, it has been an\nincreasingly hot topic in various scenarios, such as machine learning,\nscientific computing, video processing, and Internet of Things. However, none\nof the studies focuses on a comprehensive analysis of the current research\nstate of the art of serverless computing from the research scope and depth.\nTo fill this knowledge gap, we present a comprehensive literature review to\nsummarize the current research state of the art of serverless computing. This\nreview is based on selected 164 research papers to answer three key aspects,\ni.e., research directions (What), existing solutions (How), and platforms and\nvenues (Where). Specifically, first, we construct a taxonomy linked to research\ndirections about the serverless computing literature. Our taxonomy has 18\nresearch categories covering performance optimization, programming framework,\napplication migration, multi-cloud development, cost, testing, debugging, etc.\nSecond, we classify the related studies of each research direction and\nelaborate on their specific solutions. Third, we investigate the distributions\nof experimental platforms and publication venues for existing techniques.\nFinally, based on our analysis, we discuss some key challenges and envision\npromising opportunities for future research on the serverless platform side,\nserverless application side, and serverless computing community side.",
    "descriptor": "",
    "authors": [
      "Jinfeng Wen",
      "Zhenpeng Chen",
      "Xuanzhe Liu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.12275"
  },
  {
    "id": "arXiv:2206.12276",
    "title": "Multi-Frequency Joint Community Detection and Phase Synchronization",
    "abstract": "This paper studies the joint community detection and phase synchronization\nproblem on the \\textit{stochastic block model with relative phase}, where each\nnode is associated with a phase. This problem, with a variety of real-world\napplications, aims to recover community memberships and associated phases\nsimultaneously. By studying the maximum likelihood estimation formulation, we\nshow that this problem exhibits a \\textit{``multi-frequency''} structure. To\nthis end, two simple yet efficient algorithms that leverage information across\nmultiple frequencies are proposed. The former is a spectral method based on the\nnovel multi-frequency column-pivoted QR factorization, and the latter is an\niterative multi-frequency generalized power method. Numerical experiments\nindicate our proposed algorithms outperform state-of-the-art algorithms, in\nrecovering community memberships and associated phases.",
    "descriptor": "\nComments: 20 pages, 5 figures\n",
    "authors": [
      "Lingda Wang",
      "Zhizhen Zhao"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.12276"
  },
  {
    "id": "arXiv:2206.12279",
    "title": "AnyMorph: Learning Transferable Polices By Inferring Agent Morphology",
    "abstract": "The prototypical approach to reinforcement learning involves training\npolicies tailored to a particular agent from scratch for every new morphology.\nRecent work aims to eliminate the re-training of policies by investigating\nwhether a morphology-agnostic policy, trained on a diverse set of agents with\nsimilar task objectives, can be transferred to new agents with unseen\nmorphologies without re-training. This is a challenging problem that required\nprevious approaches to use hand-designed descriptions of the new agent's\nmorphology. Instead of hand-designing this description, we propose a\ndata-driven method that learns a representation of morphology directly from the\nreinforcement learning objective. Ours is the first reinforcement learning\nalgorithm that can train a policy to generalize to new agent morphologies\nwithout requiring a description of the agent's morphology in advance. We\nevaluate our approach on the standard benchmark for agent-agnostic control, and\nimprove over the current state of the art in zero-shot generalization to new\nagents. Importantly, our method attains good performance without an explicit\ndescription of morphology.",
    "descriptor": "\nComments: published at ICML 2022\n",
    "authors": [
      "Brandon Trabucco",
      "Mariano Phielipp",
      "Glen Berseth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.12279"
  },
  {
    "id": "arXiv:2206.12284",
    "title": "Robustness of Explanation Methods for NLP Models",
    "abstract": "Explanation methods have emerged as an important tool to highlight the\nfeatures responsible for the predictions of neural networks. There is mounting\nevidence that many explanation methods are rather unreliable and susceptible to\nmalicious manipulations. In this paper, we particularly aim to understand the\nrobustness of explanation methods in the context of text modality. We provide\ninitial insights and results towards devising a successful adversarial attack\nagainst text explanations. To our knowledge, this is the first attempt to\nevaluate the adversarial robustness of an explanation method. Our experiments\nshow the explanation method can be largely disturbed for up to 86% of the\ntested samples with small changes in the input sentence and its semantics.",
    "descriptor": "",
    "authors": [
      "Shriya Atmakuri",
      "Tejas Chheda",
      "Dinesh Kandula",
      "Nishant Yadav",
      "Taesung Lee",
      "Hessel Tuinhof"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.12284"
  },
  {
    "id": "arXiv:2206.12291",
    "title": "A Design of A Simple Yet Effective Exercise Recommendation System in  K-12 Online Learning",
    "abstract": "We propose a simple but effective method to recommend exercises with high\nquality and diversity for students. Our method is made up of three key\ncomponents: (1) candidate generation module; (2) diversity-promoting module;\nand (3) scope restriction module. The proposed method improves the overall\nrecommendation performance in terms of recall, and increases the diversity of\nthe recommended candidates by 0.81\\% compared to the baselines.",
    "descriptor": "\nComments: AIED 2022: The 23rd International Conference on Artificial Intelligence in Education (accepted)\n",
    "authors": [
      "Shuyan Huang",
      "Qiongqiong Liu",
      "Jiahao Chen",
      "Xiangen Hu",
      "Zitao Liu",
      "Weiqi Luo"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.12291"
  },
  {
    "id": "arXiv:2206.12292",
    "title": "InfoAT: Improving Adversarial Training Using the Information Bottleneck  Principle",
    "abstract": "Adversarial training (AT) has shown excellent high performance in defending\nagainst adversarial examples. Recent studies demonstrate that examples are not\nequally important to the final robustness of models during AT, that is, the\nso-called hard examples that can be attacked easily exhibit more influence than\nrobust examples on the final robustness. Therefore, guaranteeing the robustness\nof hard examples is crucial for improving the final robustness of the model.\nHowever, defining effective heuristics to search for hard examples is still\ndifficult. In this article, inspired by the information bottleneck (IB)\nprinciple, we uncover that an example with high mutual information of the input\nand its associated latent representation is more likely to be attacked. Based\non this observation, we propose a novel and effective adversarial training\nmethod (InfoAT). InfoAT is encouraged to find examples with high mutual\ninformation and exploit them efficiently to improve the final robustness of\nmodels. Experimental results show that InfoAT achieves the best robustness\namong different datasets and models in comparison with several state-of-the-art\nmethods.",
    "descriptor": "\nComments: Published in: IEEE Transactions on Neural Networks and Learning Systems ( Early Access )\n",
    "authors": [
      "Mengting Xu",
      "Tao Zhang",
      "Zhongnian Li",
      "Daoqiang Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.12292"
  },
  {
    "id": "arXiv:2206.12293",
    "title": "Text and author-level political inference using heterogeneous knowledge  representations",
    "abstract": "The inference of politically-charged information from text data is a popular\nresearch topic in Natural Language Processing (NLP) at both text- and\nauthor-level. In recent years, studies of this kind have been implemented with\nthe aid of representations from transformers such as BERT. Despite considerable\nsuccess, however, we may ask whether results may be improved even further by\ncombining transformed-based models with additional knowledge representations.\nTo shed light on this issue, the present work describes a series of experiments\nto compare alternative model configurations for political inference from text\nin both English and Portuguese languages. Results suggest that certain text\nrepresentations - in particular, the combined use of BERT pre-trained language\nmodels with a syntactic dependency model - may outperform the alternatives\nacross multiple experimental settings, making a potentially strong case for\nfurther research in the use of heterogeneous text representations in these and\npossibly other NLP tasks.",
    "descriptor": "",
    "authors": [
      "Samuel Caetano da Silva",
      "Ivandre Paraboni"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.12293"
  },
  {
    "id": "arXiv:2206.12294",
    "title": "Learning Rhetorical Structure Theory-based descriptions of observed  behaviour",
    "abstract": "In a previous paper, we have proposed a set of concepts, axiom schemata and\nalgorithms that can be used by agents to learn to describe their behaviour,\ngoals, capabilities, and environment. The current paper proposes a new set of\nconcepts, axiom schemata and algorithms that allow the agent to learn new\ndescriptions of an observed behaviour (e.g., perplexing actions), of its actor\n(e.g., undesired propositions or actions), and of its environment (e.g.,\nincompatible propositions). Each learned description (e.g., a certain action\nprevents another action from being performed in the future) is represented by a\nrelationship between entities (either propositions or actions) and is learned\nby the agent, just by observation, using domain-independent axiom schemata and\nor learning algorithms. The relations used by agents to represent the\ndescriptions they learn were inspired on the Theory of Rhetorical Structure\n(RST). The main contribution of the paper is the relation family Although,\ninspired on the RST relation Concession. The accurate definition of the\nrelations of the family Although involves a set of deontic concepts whose\ndefinition and corresponding algorithms are presented. The relations of the\nfamily Although, once extracted from the agent's observations, express surprise\nat the observed behaviour and, in certain circumstances, present a\njustification for it.\nThe paper shows results of the presented proposals in a demonstration\nscenario, using implemented software.",
    "descriptor": "",
    "authors": [
      "Luis Botelho",
      "Luis Nunes",
      "Ricardo Ribeiro",
      "Rui J. Lopes"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.12294"
  },
  {
    "id": "arXiv:2206.12296",
    "title": "Intelligent Request Strategy Design in Recommender System",
    "abstract": "Waterfall Recommender System (RS), a popular form of RS in mobile\napplications, is a stream of recommended items consisting of successive pages\nthat can be browsed by scrolling. In waterfall RS, when a user finishes\nbrowsing a page, the edge (e.g., mobile phones) would send a request to the\ncloud server to get a new page of recommendations, known as the paging request\nmechanism. RSs typically put a large number of items into one page to reduce\nexcessive resource consumption from numerous paging requests, which, however,\nwould diminish the RSs' ability to timely renew the recommendations according\nto users' real-time interest and lead to a poor user experience. Intuitively,\ninserting additional requests inside pages to update the recommendations with a\nhigher frequency can alleviate the problem. However, previous attempts,\nincluding only non-adaptive strategies (e.g., insert requests uniformly), would\neventually lead to resource overconsumption. To this end, we envision a new\nlearning task of edge intelligence named Intelligent Request Strategy Design\n(IRSD). It aims to improve the effectiveness of waterfall RSs by determining\nthe appropriate occasions of request insertion based on users' real-time\nintention. Moreover, we propose a new paradigm of adaptive request insertion\nstrategy named Uplift-based On-edge Smart Request Framework (AdaRequest).\nAdaRequest 1) captures the dynamic change of users' intentions by matching\ntheir real-time behaviors with their historical interests based on\nattention-based neural networks. 2) estimates the counterfactual uplift of user\npurchase brought by an inserted request based on causal inference. 3)\ndetermines the final request insertion strategy by maximizing the utility\nfunction under online resource constraints. We conduct extensive experiments on\nboth offline dataset and online A/B test to verify the effectiveness of\nAdaRequest.",
    "descriptor": "",
    "authors": [
      "Xufeng Qian",
      "Yue Xu",
      "Fuyu Lv",
      "Shengyu Zhang",
      "Ziwen Jiang",
      "Qingwen Liu",
      "Xiaoyi Zeng",
      "Tat-Seng Chua",
      "Fei Wu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.12296"
  },
  {
    "id": "arXiv:2206.12301",
    "title": "On the Limitations of Elo: Real-World Games, are Transitive, not  Additive",
    "abstract": "Real-world competitive games, such as chess, go, or StarCraft II, rely on Elo\nmodels to measure the strength of their players. Since these games are not\nfully transitive, using Elo implicitly assumes they have a strong transitive\ncomponent that can correctly be identified and extracted. In this study, we\ninvestigate the challenge of identifying the strength of the transitive\ncomponent in games. First, we show that Elo models can fail to extract this\ntransitive component, even in elementary transitive games. Then, based on this\nobservation, we propose an extension of the Elo score: we end up with a disc\nranking system that assigns each player two scores, which we refer to as skill\nand consistency. Finally, we propose an empirical validation on payoff matrices\ncoming from real-world games played by bots and humans.",
    "descriptor": "",
    "authors": [
      "Quentin Bertrand",
      "Wojciech Marian Czarnecki",
      "Gauthier Gidel"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.12301"
  },
  {
    "id": "arXiv:2206.12303",
    "title": "The Bounded Beam Search algorithm for the Block Relocation Problem",
    "abstract": "In this paper we deal with the restricted Block Relocation Problem. We\npresent a new lower bound and a heuristic approach for the problem. The\nproposed lower bound can be computed in polynomial time and it is provably\nbetter than some previously known lower bounds. We use it within a bounded beam\nsearch algorithm to solve the Block Relocation Problem and show that the\nconsidered heuristic approach outperforms the other existing algorithms on most\nof the instances in the literature. In order to test the approaches on\nreal-size dimensions, new large instances of the Block Relocation Problem are\nalso introduced.",
    "descriptor": "",
    "authors": [
      "Tiziano Bacci",
      "Sara Mattia",
      "Paolo Ventura"
    ],
    "subjectives": [
      "Other Computer Science (cs.OH)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2206.12303"
  },
  {
    "id": "arXiv:2206.12311",
    "title": "Bugs in Machine Learning-based Systems: A Faultload Benchmark",
    "abstract": "The rapid escalation of applying Machine Learning (ML) in various domains has\nled to paying more attention to the quality of ML components. There is then a\ngrowth of techniques and tools aiming at improving the quality of ML components\nand integrating them into the ML-based system safely. Although most of these\ntools use bugs' lifecycle, there is no standard benchmark of bugs to assess\ntheir performance, compare them and discuss their advantages and weaknesses. In\nthis study, we firstly investigate the reproducibility and verifiability of the\nbugs in ML-based systems and show the most important factors in each one. Then,\nwe explore the challenges of generating a benchmark of bugs in ML-based\nsoftware systems and provide a bug benchmark namely defect4ML that satisfies\nall criteria of standard benchmark, i.e. relevance, reproducibility, fairness,\nverifiability, and usability. This faultload benchmark contains 113 bugs\nreported by ML developers on GitHub and Stack Overflow, using two of the most\npopular ML frameworks: TensorFlow and Keras. defect4ML also addresses important\nchallenges in Software Reliability Engineering of ML-based software systems,\nlike: 1) fast changes in frameworks, by providing various bugs for different\nversions of frameworks, 2) code portability, by delivering similar bugs in\ndifferent ML frameworks, 3) bug reproducibility, by providing fully\nreproducible bugs with complete information about required dependencies and\ndata, and 4) lack of detailed information on bugs, by presenting links to the\nbugs' origins. defect4ML can be of interest to ML-based systems practitioners\nand researchers to assess their testing tools and techniques.",
    "descriptor": "",
    "authors": [
      "Mohammad Mehdi Morovati",
      "Amin Nikanjam",
      "Foutse Khomh",
      "Zhen Ming",
      "Jiang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.12311"
  },
  {
    "id": "arXiv:2206.12315",
    "title": "Augmented unprojected Krylov subspace methods from an alternative view  of an existing framework",
    "abstract": "Augmented Krylov subspace methods aid in accelerating the convergence of a\nstandard Krylov subspace method by including additional vectors in the search\nspace. These methods are commonly used in High-Performance Computing (HPC)\napplications to considerably reduce the number of matrix vector products\nrequired when building a basis for the Krylov subspace. In a recent survey on\nsubspace recycling iterative methods [Soodhalter et al, GAMM-Mitt. 2020], a\nframework was presented which describes a wide class of such augmented methods.\nThe framework describes these methods broadly in a two step process.\n$\\textit{Step one}$ involves solving a projected problem via a standard Krylov\nsubspace, or other projection method, and $\\textit{step two}$ then performs an\nadditional projection into the augmentation subspace. In this work we show that\nthe projected problem one must solve in $\\textit{step one}$ has an equivalent\nunprojected formulation. We then show how this observation allows the framework\nto be adapted to describe $\\textit{unprojected}$ augmented Krylov subspace\nmethods. We demonstrate this with two examples. We first show one can recover\nthe R$^{3}$GMRES algorithm from this view of the framework, and then we use the\nframework to derive the first unprojected augmented Full Orthogonalization\nMethod (FOM). This method allows one to recycle information from previous\nsystem solves, and we thus denote it as $\\textit{unproj rFOM}$ (unprojected\nrecycled FOM).",
    "descriptor": "\nComments: 10 pages, 1 figure\n",
    "authors": [
      "Liam Burke",
      "Kirk M. Soodhalter"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.12315"
  },
  {
    "id": "arXiv:2206.12320",
    "title": "PoCaP Corpus: A Multimodal Dataset for Smart Operating Room Speech  Assistant using Interventional Radiology Workflow Analysis",
    "abstract": "This paper presents a new multimodal interventional radiology dataset, called\nPoCaP (Port Catheter Placement) Corpus. This corpus consists of speech and\naudio signals in German, X-ray images, and system commands collected from 31\nPoCaP interventions by six surgeons with average duration of 81.4 $\\pm$ 41.0\nminutes. The corpus aims to provide a resource for developing a smart speech\nassistant in operating rooms. In particular, it may be used to develop a speech\ncontrolled system that enables surgeons to control the operation parameters\nsuch as C-arm movements and table positions. In order to record the dataset, we\nacquired consent by the institutional review board and workers council in the\nUniversity Hospital Erlangen and by the patients for data privacy. We describe\nthe recording set-up, data structure, workflow and preprocessing steps, and\nreport the first PoCaP Corpus speech recognition analysis results with 11.52\n$\\%$ word error rate using pretrained models. The findings suggest that the\ndata has the potential to build a robust command recognition system and will\nallow the development of a novel intervention support systems using speech and\nimage processing in the medical domain.",
    "descriptor": "\nComments: 8 pages, 4 figures, Text, Speech and Dialogue 2022 Conference\n",
    "authors": [
      "Kubilay Can Demir",
      "Matthias May",
      "Axel Schmid",
      "Michael Uder",
      "Katharina Breininger",
      "Tobias Weise",
      "Andreas Maier",
      "Seung Hee Yang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.12320"
  },
  {
    "id": "arXiv:2206.12322",
    "title": "How to train accurate BNNs for embedded systems?",
    "abstract": "A key enabler of deploying convolutional neural networks on\nresource-constrained embedded systems is the binary neural network (BNN). BNNs\nsave on memory and simplify computation by binarizing both features and\nweights. Unfortunately, binarization is inevitably accompanied by a severe\ndecrease in accuracy. To reduce the accuracy gap between binary and\nfull-precision networks, many repair methods have been proposed in the recent\npast, which we have classified and put into a single overview in this chapter.\nThe repair methods are divided into two main branches, training techniques and\nnetwork topology changes, which can further be split into smaller categories.\nThe latter category introduces additional cost (energy consumption or\nadditional area) for an embedded system, while the former does not. From our\noverview, we observe that progress has been made in reducing the accuracy gap,\nbut BNN papers are not aligned on what repair methods should be used to get\nhighly accurate BNNs. Therefore, this chapter contains an empirical review that\nevaluates the benefits of many repair methods in isolation over the\nResNet-20\\&CIFAR10 and ResNet-18\\&CIFAR100 benchmarks. We found three repair\ncategories most beneficial: feature binarizer, feature normalization, and\ndouble residual. Based on this review we discuss future directions and research\nopportunities. We sketch the benefit and costs associated with BNNs on embedded\nsystems because it remains to be seen whether BNNs will be able to close the\naccuracy gap while staying highly energy-efficient on resource-constrained\nembedded systems.",
    "descriptor": "",
    "authors": [
      "Floran de Putter",
      "Henk Corporaal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.12322"
  },
  {
    "id": "arXiv:2206.12325",
    "title": "ModLaNets: Learning Generalisable Dynamics via Modularity and Physical  Inductive Bias",
    "abstract": "Deep learning models are able to approximate one specific dynamical system\nbut struggle at learning generalisable dynamics, where dynamical systems obey\nthe same laws of physics but contain different numbers of elements (e.g.,\ndouble- and triple-pendulum systems). To relieve this issue, we proposed the\nModular Lagrangian Network (ModLaNet), a structural neural network framework\nwith modularity and physical inductive bias. This framework models the energy\nof each element using modularity and then construct the target dynamical system\nvia Lagrangian mechanics. Modularity is beneficial for reusing trained networks\nand reducing the scale of networks and datasets. As a result, our framework can\nlearn from the dynamics of simpler systems and extend to more complex ones,\nwhich is not feasible using other relevant physics-informed neural networks. We\nexamine our framework for modelling double-pendulum or three-body systems with\nsmall training datasets, where our models achieve the best data efficiency and\naccuracy performance compared with counterparts. We also reorganise our models\nas extensions to model multi-pendulum and multi-body systems, demonstrating the\nintriguing reusable feature of our framework.",
    "descriptor": "\nComments: Accepted by ICML 2022\n",
    "authors": [
      "Yupu Lu",
      "Shijie Lin",
      "Guanqi Chen",
      "Jia Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.12325"
  },
  {
    "id": "arXiv:2206.12327",
    "title": "Source Localization of Graph Diffusion via Variational Autoencoders for  Graph Inverse Problems",
    "abstract": "Graph diffusion problems such as the propagation of rumors, computer viruses,\nor smart grid failures are ubiquitous and societal. Hence it is usually crucial\nto identify diffusion sources according to the current graph diffusion\nobservations. Despite its tremendous necessity and significance in practice,\nsource localization, as the inverse problem of graph diffusion, is extremely\nchallenging as it is ill-posed: different sources may lead to the same graph\ndiffusion patterns. Different from most traditional source localization\nmethods, this paper focuses on a probabilistic manner to account for the\nuncertainty of different candidate sources. Such endeavors require overcoming\nchallenges including 1) the uncertainty in graph diffusion source localization\nis hard to be quantified; 2) the complex patterns of the graph diffusion\nsources are difficult to be probabilistically characterized; 3) the\ngeneralization under any underlying diffusion patterns is hard to be imposed.\nTo solve the above challenges, this paper presents a generic framework: Source\nLocalization Variational AutoEncoder (SL-VAE) for locating the diffusion\nsources under arbitrary diffusion patterns. Particularly, we propose a\nprobabilistic model that leverages the forward diffusion estimation model along\nwith deep generative models to approximate the diffusion source distribution\nfor quantifying the uncertainty. SL-VAE further utilizes prior knowledge of the\nsource-observation pairs to characterize the complex patterns of diffusion\nsources by a learned generative prior. Lastly, a unified objective that\nintegrates the forward diffusion estimation model is derived to enforce the\nmodel to generalize under arbitrary diffusion patterns. Extensive experiments\nare conducted on 7 real-world datasets to demonstrate the superiority of SL-VAE\nin reconstructing the diffusion sources by excelling other methods on average\n20% in AUC score.",
    "descriptor": "\nComments: 11 pages, accepted by SIGKDD 2022\n",
    "authors": [
      "Chen Ling",
      "Junji Jiang",
      "Junxiang Wang",
      "Liang Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.12327"
  },
  {
    "id": "arXiv:2206.12330",
    "title": "Toward multi-target self-organizing pursuit in a partially observable  Markov game",
    "abstract": "The multiple-target self-organizing pursuit (SOP) problem has wide\napplications and has been considered a challenging self-organization game for\ndistributed systems, in which intelligent agents cooperatively pursue multiple\ndynamic targets with partial observations. This work proposes a framework for\ndecentralized multi-agent systems to improve intelligent agents' search and\npursuit capabilities. We model a self-organizing system as a partially\nobservable Markov game (POMG) with the features of decentralization, partial\nobservation, and noncommunication. The proposed distributed algorithm: fuzzy\nself-organizing cooperative coevolution (FSC2) is then leveraged to resolve the\nthree challenges in multi-target SOP: distributed self-organizing search (SOS),\ndistributed task allocation, and distributed single-target pursuit. FSC2\nincludes a coordinated multi-agent deep reinforcement learning method that\nenables homogeneous agents to learn natural SOS patterns. Additionally, we\npropose a fuzzy-based distributed task allocation method, which locally\ndecomposes multi-target SOP into several single-target pursuit problems. The\ncooperative coevolution principle is employed to coordinate distributed\npursuers for each single-target pursuit problem. Therefore, the uncertainties\nof inherent partial observation and distributed decision-making in the POMG can\nbe alleviated. The experimental results demonstrate that distributed\nnoncommunicating multi-agent coordination with partial observations in all\nthree subtasks are effective, and 2048 FSC2 agents can perform efficient\nmulti-target SOP with an almost 100% capture rate.",
    "descriptor": "",
    "authors": [
      "Lijun Sun",
      "Yu-Cheng Chang",
      "Chao Lyu",
      "Ye Shi",
      "Yuhui Shi",
      "Chin-Teng Lin"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.12330"
  },
  {
    "id": "arXiv:2206.12331",
    "title": "Total Generalized Variation for Piecewise Constant Functions with  Applications in Imaging",
    "abstract": "We propose a novel discrete concept for the total generalized variation\n(TGV), which has originally been derived to reduce the staircasing effect in\nclassical total variation (TV) regularization, in image denoising problems. We\ndescribe discrete, second-order TGV for piecewise constant functions on\ntriangular meshes, thus allowing the TGV functional to be applied to more\ngeneral data structures than pixel images, and in particular in the context of\nfinite element discretizations. Particular attention is given to the\ndescription of the kernel of the TGV functional, which, in the continuous\nsetting, consists of linear polynomials. We discuss how to take advantage of\nthis kernel structure using piecewise constant functions on triangular meshes.\nNumerical experiments include denoising and inpainting problems for images\ndefined on non-standard grids, including data from a 3D scanner.",
    "descriptor": "",
    "authors": [
      "Lukas Baumg\u00e4rtner",
      "Ronny Bergmann",
      "Roland Herzog",
      "Stephan Schmidt",
      "Jos\u00e9 Vidal-N\u00fa\u00f1ez"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.12331"
  },
  {
    "id": "arXiv:2206.12336",
    "title": "Deep Generation of Heterogeneous Networks",
    "abstract": "Heterogeneous graphs are ubiquitous data structures that can inherently\ncapture multi-type and multi-modal interactions between objects. In recent\nyears, research on encoding heterogeneous graph into latent representations\nhave enjoyed a rapid increase. However, its reverse process, namely how to\nconstruct heterogeneous graphs from underlying representations and\ndistributions have not been well explored due to several challenges in 1)\nmodeling the local heterogeneous semantic distribution; 2) preserving the\ngraph-structured distributions over the local semantics; and 3) characterizing\nthe global heterogeneous graph distributions. To address these challenges, we\npropose a novel framework for heterogeneous graph generation (HGEN) that\njointly captures the semantic, structural, and global distributions of\nheterogeneous graphs. Specifically, we propose a heterogeneous walk generator\nthat hierarchically generates meta-paths and their path instances. In addition,\na novel heterogeneous graph assembler is developed that can sample and combine\nthe generated meta-path instances (e.g., walks) into heterogeneous graphs in a\nstratified manner. Theoretical analysis on the preservation of heterogeneous\ngraph patterns by the proposed generation process has been performed. Extensive\nexperiments on multiple real-world and synthetic heterogeneous graph datasets\ndemonstrate the effectiveness of the proposed HGEN in generating realistic\nheterogeneous graphs.",
    "descriptor": "\nComments: 10 pages, accepted by 2021 IEEE International Conference on Data Mining (ICDM). IEEE, 2021\n",
    "authors": [
      "Chen Ling",
      "Carl Yang",
      "Liang Zhao"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.12336"
  },
  {
    "id": "arXiv:2206.12338",
    "title": "Diegetic representation of feedback in open games",
    "abstract": "We improve the framework of open games with agency by showing how the\nplayers' counterfactual analysis giving rise to Nash equilibria can be\ndescribed in the dynamics of the game itself (hence diegetically), getting rid\nof devices such as equilibrium predicates. This new approach overlaps almost\ncompletely with the way gradient-based learners are specified and trained.\nIndeed, we show feedback propagation in games can be seen as reverse-mode\ndifferentiation, with a crucial difference explaining the distinctive character\nof the phenomenology of non-cooperative games. We outline a functorial\nconstruction of arena of games, show players form a subsystem over it, and\nprove that their `fixpoint behaviours' are Nash equilibria.",
    "descriptor": "\nComments: 17 pages, 4 figures\n",
    "authors": [
      "Matteo Capucci"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2206.12338"
  },
  {
    "id": "arXiv:2206.12340",
    "title": "How to hide your voice: Noise-cancelling bird photography blind",
    "abstract": "Getting close to birds is a great challenge in wildlife photography. Bird\nphotography blinds may be the most effective and least intrusive way. These\nessential structures can allow to visually and audibly conceal photographers\nfrom the habitat if properly designed. However, the acoustic design of the\nblinds has been overlooked. Herein, we present noise-cancelling blinds which\nallow photographing birds at close range. Firstly, we conduct a questionnaire\nin the eco-tourism centre located in Yunnan, China. Thus, we determine the\nbirders' expectations of the indoor sound environment. We then identify four\nvariables to examine the impact of architectural and acoustic decisions on\nnoise propagation. The numerical simulations are performed in the acoustic\nmodule of Comsol MultiPhysics. Minimizing the structural size and planning the\nbuilding with closed windows is a proper decision to reduce noise in the\narchitectural design process. Sound-absorbing materials reduce the acoustic\nenergy indoors, thus decreasing the outdoor noise. Sound-proofing materials\nhelp to cancel the acoustic transmission indoors to outdoors. Using\nsound-absorbing and proofing materials together is the best way to minimize\nnoise both indoors and outdoors. Our study demonstrated that photography blinds\nrequire a strong and thorough acoustic design for both human and bird\nwell-being.",
    "descriptor": "\nComments: 22 pages, 11 figures\n",
    "authors": [
      "C. Baydur",
      "B. Pu",
      "X. Xu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.12340"
  },
  {
    "id": "arXiv:2206.12342",
    "title": "HANF: Hyperparameter And Neural Architecture Search in Federated  Learning",
    "abstract": "Automated machine learning (AutoML) is an important step to make machine\nlearning models being widely applied to solve real world problems. Despite\nnumerous research advancement, machine learning methods are not fully utilized\nby industries mainly due to their data privacy and security regulations, high\ncost involved in storing and computing increasing amount of data at central\nlocation and most importantly lack of expertise. Hence, we introduce a novel\nframework, HANF - $\\textbf{H}$yperparameter $\\textbf{A}$nd $\\textbf{N}$eural\narchitecture search in $\\textbf{F}$ederated learning as a step towards building\nan AutoML framework for data distributed across several data owner servers\nwithout any need for bringing the data to a central location. HANF jointly\noptimizes a neural architecture and non-architectural hyperparameters of a\nlearning algorithm using gradient-based neural architecture search and\n$n$-armed bandit approach respectively in data distributed setting. We show\nthat HANF efficiently finds the optimized neural architecture and also tunes\nthe hyperparameters on data owner servers. Additionally, HANF can be applied in\nboth, federated and non-federated settings. Empirically, we show that HANF\nconverges towards well-suited architectures and non-architectural\nhyperparameter-sets using image-classification tasks.",
    "descriptor": "\nComments: Main paper: 8.5 pages, References: 2 pages, Supplement: 1.5 pages, Main paper: 3 figures, 3 tables, 1 algorithm, Supplement: 1 figure, 2 algorithms\n",
    "authors": [
      "Jonas Seng",
      "Pooja Prasad",
      "Devendra Singh Dhami",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.12342"
  },
  {
    "id": "arXiv:2206.12343",
    "title": "Identification of young talented individuals in the natural and life  sciences using bibliometric data",
    "abstract": "Identification of young talented individuals is not an easy task.\nCitation-based data usually need too long to accrue. In this study, we proposed\na method based on bibliometric data for the identification of young talented\nindividuals. Three different indicators and their combinations were used. An\nolder cohort with their first publication between 1999 and 2003 was used to\nfind the most suitable indicator combination. For the validation step, citation\nimpact on the level of individual papers was used. The best performing\nindicator combination was applied to the time period 2007-2011 for identifying\nyoung talented individuals who published their first paper within this time\nperiod. We produced a set of 46,200 potential talented individuals.",
    "descriptor": "\nComments: 7 pages, 3 tables, to be presented at STI 2022\n",
    "authors": [
      "Lutz Bornmann",
      "Robin Haunschild"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2206.12343"
  },
  {
    "id": "arXiv:2206.12348",
    "title": "MPC-based Imitation Learning for Safe and Human-like Autonomous Driving",
    "abstract": "To ensure user acceptance of autonomous vehicles (AVs), control systems are\nbeing developed to mimic human drivers from demonstrations of desired driving\nbehaviors. Imitation learning (IL) algorithms serve this purpose, but struggle\nto provide safety guarantees on the resulting closed-loop system trajectories.\nOn the other hand, Model Predictive Control (MPC) can handle nonlinear systems\nwith safety constraints, but realizing human-like driving with it requires\nextensive domain knowledge. This work suggests the use of a seamless\ncombination of the two techniques to learn safe AV controllers from\ndemonstrations of desired driving behaviors, by using MPC as a differentiable\ncontrol layer within a hierarchical IL policy. With this strategy, IL is\nperformed in closed-loop and end-to-end, through parameters in the MPC cost,\nmodel or constraints. Experimental results of this methodology are analyzed for\nthe design of a lane keeping control system, learned via behavioral cloning\nfrom observations (BCO), given human demonstrations on a fixed-base driving\nsimulator.",
    "descriptor": "\nComments: Accepted at the 1st Workshop on Safe Learning for Autonomous Driving (SL4AD), co-located with the 39th International Conference on Machine Learning (ICML 2022)\n",
    "authors": [
      "Flavia Sofia Acerbo",
      "Jan Swevers",
      "Tinne Tuytelaars",
      "Tong Duy Son"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.12348"
  },
  {
    "id": "arXiv:2206.12351",
    "title": "Megapixel Image Generation with Step-Unrolled Denoising Autoencoders",
    "abstract": "An ongoing trend in generative modelling research has been to push sample\nresolutions higher whilst simultaneously reducing computational requirements\nfor training and sampling. We aim to push this trend further via the\ncombination of techniques - each component representing the current pinnacle of\nefficiency in their respective areas. These include vector-quantized GAN\n(VQ-GAN), a vector-quantization (VQ) model capable of high levels of lossy -\nbut perceptually insignificant - compression; hourglass transformers, a highly\nscaleable self-attention model; and step-unrolled denoising autoencoders\n(SUNDAE), a non-autoregressive (NAR) text generative model. Unexpectedly, our\nmethod highlights weaknesses in the original formulation of hourglass\ntransformers when applied to multidimensional data. In light of this, we\npropose modifications to the resampling mechanism, applicable in any task\napplying hierarchical transformers to multidimensional data. Additionally, we\ndemonstrate the scalability of SUNDAE to long sequence lengths - four times\nlonger than prior work. Our proposed framework scales to high-resolutions\n($1024 \\times 1024$) and trains quickly (2-4 days). Crucially, the trained\nmodel produces diverse and realistic megapixel samples in approximately 2\nseconds on a consumer-grade GPU (GTX 1080Ti). In general, the framework is\nflexible: supporting an arbitrary number of sampling steps, sample-wise\nself-stopping, self-correction capabilities, conditional generation, and a NAR\nformulation that allows for arbitrary inpainting masks. We obtain FID scores of\n10.56 on FFHQ256 - close to the original VQ-GAN in less than half the sampling\nsteps - and 21.85 on FFHQ1024 in only 100 sampling steps.",
    "descriptor": "\nComments: 17 pages + 9 appendix pages. 20 figures\n",
    "authors": [
      "Alex F. McKinney",
      "Chris G. Willcocks"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.12351"
  },
  {
    "id": "arXiv:2206.12356",
    "title": "HM3D-ABO: A Photo-realistic Dataset for Object-centric Multi-view 3D  Reconstruction",
    "abstract": "Reconstructing 3D objects is an important computer vision task that has wide\napplication in AR/VR. Deep learning algorithm developed for this task usually\nrelies on an unrealistic synthetic dataset, such as ShapeNet and Things3D. On\nthe other hand, existing real-captured object-centric datasets usually do not\nhave enough annotation to enable supervised training or reliable evaluation. In\nthis technical report, we present a photo-realistic object-centric dataset\nHM3D-ABO. It is constructed by composing realistic indoor scene and realistic\nobject. For each configuration, we provide multi-view RGB observations, a\nwater-tight mesh model for the object, ground truth depth map and object mask.\nThe proposed dataset could also be useful for tasks such as camera pose\nestimation and novel-view synthesis. The dataset generation code is released at\nhttps://github.com/zhenpeiyang/HM3D-ABO.",
    "descriptor": "",
    "authors": [
      "Zhenpei Yang",
      "Zaiwei Zhang",
      "Qixing Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.12356"
  },
  {
    "id": "arXiv:2206.12358",
    "title": "Low- and Mixed-Precision Inference Accelerators",
    "abstract": "With the surging popularity of edge computing, the need to efficiently\nperform neural network inference on battery-constrained IoT devices has greatly\nincreased. While algorithmic developments enable neural networks to solve\nincreasingly more complex tasks, the deployment of these networks on edge\ndevices can be problematic due to the stringent energy, latency, and memory\nrequirements. One way to alleviate these requirements is by heavily quantizing\nthe neural network, i.e. lowering the precision of the operands. By taking\nquantization to the extreme, e.g. by using binary values, new opportunities\narise to increase the energy efficiency. Several hardware accelerators\nexploiting the opportunities of low-precision inference have been created, all\naiming at enabling neural network inference at the edge. In this chapter,\ndesign choices and their implications on the flexibility and energy efficiency\nof several accelerators supporting extremely quantized networks are reviewed.",
    "descriptor": "",
    "authors": [
      "Maarten Molendijk",
      "Floran de Putter",
      "Henk Corporaal"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2206.12358"
  },
  {
    "id": "arXiv:2206.12360",
    "title": "Cooperative Control in Eco-Driving of Electric Connected and Autonomous  Vehicles in an Un-Signalized Urban Intersection",
    "abstract": "This paper addresses the problem of finding the optimal Eco-Driving (ED)\nspeed profile of an electric Connected and Automated Vehicle (CAV) in an\nisolated urban un-signalized intersection. The problem is formulated as a\nsingle-level optimization and solved using Pontryagin's Minimum Principle\n(PMP). Analytical solutions are presented for various conflicts that occur at\nan intersection. Cooperation is introduced amongst CAVs as the ability to share\nintentions. Two levels of cooperation, namely the Cooperative ED (C-ED) and\nNon-Cooperative (NC-ED) algorithms are evaluated, in a simulation environment,\nfor energy efficiency with Intelligent Driver Model (IDM) as the baseline.",
    "descriptor": "\nComments: Submitted to the AAC 2022\n",
    "authors": [
      "Vinith Kumar Lakshmanan",
      "Antonio Sciarretta",
      "Ouafae El Ganaoui-Mourlan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.12360"
  },
  {
    "id": "arXiv:2206.12361",
    "title": "Out of distribution robustness with pre-trained Bayesian neural networks",
    "abstract": "We develop ShiftMatch, a new training-data-dependent likelihood for out of\ndistribution (OOD) robustness in Bayesian neural networks (BNNs). ShiftMatch is\ninspired by the training-data-dependent \"EmpCov\" priors from Izmailov et al.\n(2021a) and efficiently matches test-time spatial correlations to those at\ntraining time. Critically, ShiftMatch is designed to leave neural network\ntraining unchanged, allowing it to use publically available samples from\npretrained BNNs. Using pre-trained HMC samples, ShiftMatch gives strong\nperformance improvements on CIFAR-10-C, outperforms EmpCov priors, and is\nperhaps the first Bayesian method capable of convincingly outperforming plain\ndeep ensembles. ShiftMatch can be integrated with non-Bayesian methods like\ndeep ensembles, where it offers smaller, but still considerable, performance\nimprovements. Overall, Bayesian ShiftMatch gave slightly better accuracy than\nensembles with ShiftMatch, though they both had very similar log-likelihoods.",
    "descriptor": "",
    "authors": [
      "Xi Wang",
      "Laurence Aitchison"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.12361"
  },
  {
    "id": "arXiv:2206.12364",
    "title": "On Certifying and Improving Generalization to Unseen Domains",
    "abstract": "Domain Generalization (DG) aims to learn models whose performance remains\nhigh on unseen domains encountered at test-time by using data from multiple\nrelated source domains. Many existing DG algorithms reduce the divergence\nbetween source distributions in a representation space to potentially align the\nunseen domain close to the sources. This is motivated by the analysis that\nexplains generalization to unseen domains using distributional distance (such\nas the Wasserstein distance) to the sources. However, due to the openness of\nthe DG objective, it is challenging to evaluate DG algorithms comprehensively\nusing a few benchmark datasets. In particular, we demonstrate that the accuracy\nof the models trained with DG methods varies significantly across unseen\ndomains, generated from popular benchmark datasets. This highlights that the\nperformance of DG methods on a few benchmark datasets may not be representative\nof their performance on unseen domains in the wild. To overcome this roadblock,\nwe propose a universal certification framework based on distributionally robust\noptimization (DRO) that can efficiently certify the worst-case performance of\nany DG method. This enables a data-independent evaluation of a DG method\ncomplementary to the empirical evaluations on benchmark datasets. Furthermore,\nwe propose a training algorithm that can be used with any DG method to provably\nimprove their certified performance. Our empirical evaluation demonstrates the\neffectiveness of our method at significantly improving the worst-case loss\n(i.e., reducing the risk of failure of these models in the wild) without\nincurring a significant performance drop on benchmark datasets.",
    "descriptor": "",
    "authors": [
      "Akshay Mehra",
      "Bhavya Kailkhura",
      "Pin-Yu Chen",
      "Jihun Hamm"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.12364"
  },
  {
    "id": "arXiv:2206.12368",
    "title": "Using BERT Embeddings to Model Word Importance in Conversational  Transcripts for Deaf and Hard of Hearing Users",
    "abstract": "Deaf and hard of hearing individuals regularly rely on captioning while\nwatching live TV. Live TV captioning is evaluated by regulatory agencies using\nvarious caption evaluation metrics. However, caption evaluation metrics are\noften not informed by preferences of DHH users or how meaningful the captions\nare. There is a need to construct caption evaluation metrics that take the\nrelative importance of words in a transcript into account. We conducted\ncorrelation analysis between two types of word embeddings and human-annotated\nlabeled word-importance scores in existing corpus. We found that normalized\ncontextualized word embeddings generated using BERT correlated better with\nmanually annotated importance scores than word2vec-based word embeddings. We\nmake available a pairing of word embeddings and their human-annotated\nimportance scores. We also provide proof-of-concept utility by training word\nimportance models, achieving an F1-score of 0.57 in the 6-class word importance\nclassification task.",
    "descriptor": "\nComments: 5 pages, 3 tables, 1 figure\n",
    "authors": [
      "Akhter Al Amin",
      "Saad Hassan",
      "Cecilia O. Alm",
      "Matt Huenerfauth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.12368"
  },
  {
    "id": "arXiv:2206.12370",
    "title": "Online Distillation with Mixed Sample Augmentation",
    "abstract": "Mixed Sample Regularization (MSR), such as MixUp or CutMix, is a powerful\ndata augmentation strategy to generalize convolutional neural networks.\nPrevious empirical analysis has illustrated an orthogonal performance gain\nbetween MSR and the conventional offline Knowledge Distillation (KD). To be\nmore specific, student networks can be enhanced with the involvement of MSR in\nthe training stage of the sequential distillation. Yet, the interplay between\nMSR and online knowledge distillation, a stronger distillation paradigm, where\nan ensemble of peer students learn mutually from each other, remains\nunexplored. To bridge the gap, we make the first attempt at incorporating\nCutMix into online distillation, where we empirically observe a significant\nimprovement. Encouraged by this fact, we propose an even stronger MSR\nspecifically for online distillation, named as Cut^nMix. Furthermore, a novel\nonline distillation framework is designed upon Cut^nMix, to enhance the\ndistillation with feature level mutual learning and a self-ensemble teacher.\nComprehensive evaluations on CIFAR10 and CIFAR100 with six network\narchitectures show that our approach can consistently outperform\nstate-of-the-art distillation methods.",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Yiqing Shen",
      "Liwu Xu",
      "Yuzhe Yang",
      "Yaqian Li",
      "Yandong Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.12370"
  },
  {
    "id": "arXiv:2206.12372",
    "title": "QReg: On Regularization Effects of Quantization",
    "abstract": "In this paper we study the effects of quantization in DNN training. We\nhypothesize that weight quantization is a form of regularization and the amount\nof regularization is correlated with the quantization level (precision). We\nconfirm our hypothesis by providing analytical study and empirical results. By\nmodeling weight quantization as a form of additive noise to weights, we explore\nhow this noise propagates through the network at training time. We then show\nthat the magnitude of this noise is correlated with the level of quantization.\nTo confirm our analytical study, we performed an extensive list of experiments\nsummarized in this paper in which we show that the regularization effects of\nquantization can be seen in various vision tasks and models, over various\ndatasets. Based on our study, we propose that 8-bit quantization provides a\nreliable form of regularization in different vision tasks and models.",
    "descriptor": "",
    "authors": [
      "MohammadHossein AskariHemmat",
      "Reyhane Askari Hemmat",
      "Alex Hoffman",
      "Ivan Lazarevich",
      "Ehsan Saboori",
      "Olivier Mastropietro",
      "Yvon Savaria",
      "Jean-Pierre David"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.12372"
  },
  {
    "id": "arXiv:2206.12374",
    "title": "Affective Signals in a Social Media Recommender System",
    "abstract": "People come to social media to satisfy a variety of needs, such as being\ninformed, entertained and inspired, or connected to their friends and\ncommunity. Hence, to design a ranking function that gives useful and\npersonalized post recommendations, it would be helpful to be able to predict\nthe affective response a user may have to a post (e.g., entertained, informed,\nangered). This paper describes the challenges and solutions we developed to\napply Affective Computing to social media recommendation systems.\nWe address several types of challenges. First, we devise a taxonomy of\naffects that was small (for practical purposes) yet covers the important\nnuances needed for the application. Second, to collect training data for our\nmodels, we balance between signals that are already available to us (namely,\ndifferent types of user engagement) and data we collected through a carefully\ncrafted human annotation effort on 800k posts. We demonstrate that affective\nresponse information learned from this dataset improves a module in the\nrecommendation system by more than 8%. Online experimentation also demonstrates\nstatistically significant decreases in surfaced violating content and increases\nin surfaced content that users find valuable.",
    "descriptor": "",
    "authors": [
      "Jane Dwivedi-Yu",
      "Yi-Chia Wang",
      "Lijing Qin",
      "Cristian Canton-Ferrer",
      "Alon Y. Halevy"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.12374"
  },
  {
    "id": "arXiv:2206.12380",
    "title": "VIP Hashing -- Adapting to Skew in Popularity of Data on the Fly  (extended version)",
    "abstract": "All data is not equally popular. Often, some portion of data is more\nfrequently accessed than the rest, which causes a skew in popularity of the\ndata items. Adapting to this skew can improve performance, and this topic has\nbeen studied extensively in the past for disk-based settings. In this work, we\nconsider an in-memory data structure, namely hash table, and show how one can\nleverage the skew in popularity for higher performance. Hashing is a\nlow-latency operation, sensitive to the effects of caching, branch prediction,\nand code complexity among other factors. These factors make learning\nin-the-loop especially challenging as the overhead of performing any additional\noperations can be significant. In this paper, we propose VIP hashing, a fully\nonline hash table method, that uses lightweight mechanisms for learning the\nskew in popularity and adapting the hash table layout. These mechanisms are\nnon-blocking, and their overhead is controlled by sensing changes in the\npopularity distribution to dynamically switch-on/off the learning mechanism as\nneeded. We tested VIP hashing against a variety of workloads generated by\nWiscer, a homegrown hashing measurement tool, and find that it improves\nperformance in the presence of skew (22% increase in fetch operation throughput\nfor a hash table with one million keys under low skew, 77% increase under\nmedium skew) while being robust to insert and delete operations, and changing\npopularity distribution of keys. We find that VIP hashing reduces the\nend-to-end execution time of TPC-H query 9, which is the most expensive TPC-H\nquery, by 20% under medium skew.",
    "descriptor": "",
    "authors": [
      "Aarati Kakaraparthy",
      "Jignesh M. Patel",
      "Brian P. Kroth",
      "Kwanghyun Park"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2206.12380"
  },
  {
    "id": "arXiv:2206.12381",
    "title": "Defending Backdoor Attacks on Vision Transformer via Patch Processing",
    "abstract": "Vision Transformers (ViTs) have a radically different architecture with\nsignificantly less inductive bias than Convolutional Neural Networks. Along\nwith the improvement in performance, security and robustness of ViTs are also\nof great importance to study. In contrast to many recent works that exploit the\nrobustness of ViTs against adversarial examples, this paper investigates a\nrepresentative causative attack, i.e., backdoor. We first examine the\nvulnerability of ViTs against various backdoor attacks and find that ViTs are\nalso quite vulnerable to existing attacks. However, we observe that the\nclean-data accuracy and backdoor attack success rate of ViTs respond\ndistinctively to patch transformations before the positional encoding. Then,\nbased on this finding, we propose an effective method for ViTs to defend both\npatch-based and blending-based trigger backdoor attacks via patch processing.\nThe performances are evaluated on several benchmark datasets, including\nCIFAR10, GTSRB, and TinyImageNet, which show the proposed novel defense is very\nsuccessful in mitigating backdoor attacks for ViTs. To the best of our\nknowledge, this paper presents the first defensive strategy that utilizes a\nunique characteristic of ViTs against backdoor attacks.",
    "descriptor": "",
    "authors": [
      "Khoa D. Doan",
      "Yingjie Lao",
      "Peng Yang",
      "Ping Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.12381"
  },
  {
    "id": "arXiv:2206.12388",
    "title": "QAGAN: Adversarial Approach To Learning Domain Invariant Language  Features",
    "abstract": "Training models that are robust to data domain shift has gained an increasing\ninterest both in academia and industry. Question-Answering language models,\nbeing one of the typical problem in Natural Language Processing (NLP) research,\nhas received much success with the advent of large transformer models. However,\nexisting approaches mostly work under the assumption that data is drawn from\nsame distribution during training and testing which is unrealistic and\nnon-scalable in the wild.\nIn this paper, we explore adversarial training approach towards learning\ndomain-invariant features so that language models can generalize well to\nout-of-domain datasets. We also inspect various other ways to boost our model\nperformance including data augmentation by paraphrasing sentences, conditioning\nend of answer span prediction on the start word, and carefully designed\nannealing function. Our initial results show that in combination with these\nmethods, we are able to achieve $15.2\\%$ improvement in EM score and $5.6\\%$\nboost in F1 score on out-of-domain validation dataset over the baseline. We\nalso dissect our model outputs and visualize the model hidden-states by\nprojecting them onto a lower-dimensional space, and discover that our specific\nadversarial training approach indeed encourages the model to learn domain\ninvariant embedding and bring them closer in the multi-dimensional space.",
    "descriptor": "",
    "authors": [
      "Shubham Shrivastava",
      "Kaiyue Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.12388"
  },
  {
    "id": "arXiv:2206.12390",
    "title": "A Test for Evaluating Performance in Human-Computer Systems",
    "abstract": "The Turing test for comparing computer performance to that of humans is well\nknown, but, surprisingly, there is no widely used test for comparing how much\nbetter human-computer systems perform relative to humans alone, computers\nalone, or other baselines. Here, we show how to perform such a test using the\nratio of means as a measure of effect size. Then we demonstrate the use of this\ntest in three ways. First, in an analysis of 79 recently published experimental\nresults, we find that, surprisingly, over half of the studies find a decrease\nin performance, the mean and median ratios of performance improvement are both\napproximately 1 (corresponding to no improvement at all), and the maximum ratio\nis 1.36 (a 36% improvement). Second, we experimentally investigate whether a\nhigher performance improvement ratio is obtained when 100 human programmers\ngenerate software using GPT-3, a massive, state-of-the-art AI system. In this\ncase, we find a speed improvement ratio of 1.27 (a 27% improvement). Finally,\nwe find that 50 human non-programmers using GPT-3 can perform the task about as\nwell as--and less expensively than--the human programmers. In this case,\nneither the non-programmers nor the computer would have been able to perform\nthe task alone, so this is an example of a very strong form of human-computer\nsynergy.",
    "descriptor": "",
    "authors": [
      "Andres Campero",
      "Michelle Vaccaro",
      "Jaeyoon Song",
      "Haoran Wen",
      "Abdullah Almaatouq",
      "Thomas W. Malone"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.12390"
  },
  {
    "id": "arXiv:2206.12391",
    "title": "Explicit Exactly Energy-conserving Methods for Hamiltonian Systems",
    "abstract": "For Hamiltonian systems, simulation algorithms that exactly conserve\nnumerical energy or pseudo-energy have seen extensive investigation. Most\navailable methods either require the iterative solution of nonlinear algebraic\nequations at each time step, or are explicit, but where the exact conservation\nproperty depends on the exact evaluation of an integral in continuous time.\nUnder further restrictions, namely that the potential energy contribution to\nthe Hamiltonian is non-negative, newer techniques based on invariant energy\nquadratisation allow for exact numerical energy conservation and yield linearly\nimplicit updates, requiring only the solution of a linear system at each time\nstep. In this article, it is shown that, for a general class of Hamiltonian\nsystems, and under the non-negativity condition on potential energy, it is\npossible to arrive at a fully explicit method that exactly conserves numerical\nenergy. Furthermore, such methods are unconditionally stable, and are of\ncomparable computational cost to the very simplest integration methods (such as\nStormer-Verlet). A variant of this scheme leading to a conditionally-stable\nmethod is also presented, and follows from a splitting of the potential energy.\nVarious numerical results are presented, in the case of the classic test\nproblem of Fermi, Pasta and Ulam, as well as for nonlinear systems of partial\ndifferential equations, including those describing high amplitude vibration of\nstrings and plates.",
    "descriptor": "",
    "authors": [
      "Stefan Bilbao",
      "Michele Ducceschi",
      "Fabiana Zama"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.12391"
  },
  {
    "id": "arXiv:2206.12394",
    "title": "Popular Critical Matchings in the Many-to-Many Setting",
    "abstract": "We consider the many-to-many bipartite matching problem in the presence of\ntwo-sided preferences and two-sided lower quotas. The input to our problem is a\nbipartite graph G = (A U B, E), where each vertex in A U B specifies a strict\npreference ordering over its neighbors. Each vertex has an upper quota and a\nlower quota denoting the maximum and minimum number of vertices that can be\nassigned to it from its neighborhood. In the many-to-many setting with\ntwo-sided lower quotas, informally, a critical matching is a matching which\nfulfils vertex lower quotas to the maximum possible extent. This is a natural\ngeneralization of the definition of a critical matching in the one-to-one\nsetting [19]. Our goal in the given problem is to find a popular matching in\nthe set of critical matchings. A matching is popular in a given set of\nmatchings if it remains undefeated in a head-to-head election with any matching\nin that set. Here, vertices cast votes between pairs of matchings. We show that\nthere always exists a matching that is popular in the set of critical\nmatchings. We present an efficient algorithm to compute such a matching of the\nlargest size. We prove the popularity of our matching using a primal-dual\nframework",
    "descriptor": "",
    "authors": [
      "Meghana Nasre",
      "Prajakta Nimbhorkar",
      "Keshav Ranjan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.12394"
  },
  {
    "id": "arXiv:2206.12395",
    "title": "Data Leakage in Federated Averaging",
    "abstract": "Recent attacks have shown that user data can be reconstructed from FedSGD\nupdates, thus breaking privacy. However, these attacks are of limited practical\nrelevance as federated learning typically uses the FedAvg algorithm. It is\ngenerally accepted that reconstructing data from FedAvg updates is much harder\nthan FedSGD as: (i) there are unobserved intermediate weight updates, (ii) the\norder of inputs matters, and (iii) the order of labels changes every epoch. In\nthis work, we propose a new optimization-based attack which successfully\nattacks FedAvg by addressing the above challenges. First, we solve the\noptimization problem using automatic differentiation that forces a simulation\nof the client's update for the reconstructed labels and inputs so as to match\nthe received client update. Second, we address the unknown input order by\ntreating images at different epochs as independent during optimization, while\nrelating them with a permutation invariant prior. Third, we reconstruct the\nlabels by estimating the parameters of existing FedSGD attacks at every FedAvg\nstep. On the popular FEMNIST dataset, we demonstrate that on average we\nsuccessfully reconstruct >45% of the client's images from realistic FedAvg\nupdates computed on 10 local epochs of 10 batches each with 5 images, compared\nto only <10% using the baseline. These findings indicate that many real-world\nfederated learning implementations based on FedAvg are vulnerable.",
    "descriptor": "",
    "authors": [
      "Dimitar I. Dimitrov",
      "Mislav Balunovi\u0107",
      "Nikola Konstantinov",
      "Martin Vechev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.12395"
  },
  {
    "id": "arXiv:2206.12396",
    "title": "Text-Driven Stylization of Video Objects",
    "abstract": "We tackle the task of stylizing video objects in an intuitive and semantic\nmanner following a user-specified text prompt. This is a challenging task as\nthe resulting video must satisfy multiple properties: (1) it has to be\ntemporally consistent and avoid jittering or similar artifacts, (2) the\nresulting stylization must preserve both the global semantics of the object and\nits fine-grained details, and (3) it must adhere to the user-specified text\nprompt. To this end, our method stylizes an object in a video according to a\nglobal target text prompt that describes the global semantics and a local\ntarget text prompt that describes the local semantics. To modify the style of\nan object, we harness the representational power of CLIP to get a similarity\nscore between (1) the local target text and a set of local stylized views, and\n(2) a global target text and a set of stylized global views. We use a\npretrained atlas decomposition network to propagate the edits in a temporally\nconsistent manner. We demonstrate that our method can generate consistent style\nchanges in time for a variety of objects and videos, that adhere to the\nspecification of the target texts. We also show how varying the specificity of\nthe target texts, and augmenting the texts with a set of prefixes results in\nstylizations with different levels of detail. Full results are given on our\nproject webpage:\nhttps://sloeschcke.github.io/Text-Driven-Stylization-of-Video-Objects/",
    "descriptor": "",
    "authors": [
      "Sebastian Loeschcke",
      "Serge Belongie",
      "Sagie Benaim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.12396"
  },
  {
    "id": "arXiv:2206.12401",
    "title": "Debiasing Learning for Membership Inference Attacks Against Recommender  Systems",
    "abstract": "Learned recommender systems may inadvertently leak information about their\ntraining data, leading to privacy violations. We investigate privacy threats\nfaced by recommender systems through the lens of membership inference. In such\nattacks, an adversary aims to infer whether a user's data is used to train the\ntarget recommender. To achieve this, previous work has used a shadow\nrecommender to derive training data for the attack model, and then predicts the\nmembership by calculating difference vectors between users' historical\ninteractions and recommended items. State-of-the-art methods face two\nchallenging problems: (1) training data for the attack model is biased due to\nthe gap between shadow and target recommenders, and (2) hidden states in\nrecommenders are not observational, resulting in inaccurate estimations of\ndifference vectors. To address the above limitations, we propose a Debiasing\nLearning for Membership Inference Attacks against recommender systems (DL-MIA)\nframework that has four main components: (1) a difference vector generator, (2)\na disentangled encoder, (3) a weight estimator, and (4) an attack model. To\nmitigate the gap between recommenders, a variational auto-encoder (VAE) based\ndisentangled encoder is devised to identify recommender invariant and specific\nfeatures. To reduce the estimation bias, we design a weight estimator,\nassigning a truth-level score for each difference vector to indicate estimation\naccuracy. We evaluate DL-MIA against both general recommenders and sequential\nrecommenders on three real-world datasets. Experimental results show that\nDL-MIA effectively alleviates training and estimation biases simultaneously,\nand achieves state-of-the-art attack performance.",
    "descriptor": "\nComments: Accepted by KDD 2022\n",
    "authors": [
      "Zihan Wang",
      "Na Huang",
      "Fei Sun",
      "Pengjie Ren",
      "Zhumin Chen",
      "Hengliang Luo",
      "Maarten de Rijke",
      "Zhaochun Ren"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.12401"
  },
  {
    "id": "arXiv:2206.12403",
    "title": "ZSON: Zero-Shot Object-Goal Navigation using Multimodal Goal Embeddings",
    "abstract": "We present a scalable approach for learning open-world object-goal navigation\n(ObjectNav) -- the task of asking a virtual robot (agent) to find any instance\nof an object in an unexplored environment (e.g., \"find a sink\"). Our approach\nis entirely zero-shot -- i.e., it does not require ObjectNav rewards or\ndemonstrations of any kind. Instead, we train on the image-goal navigation\n(ImageNav) task, in which agents find the location where a picture (i.e., goal\nimage) was captured. Specifically, we encode goal images into a multimodal,\nsemantic embedding space to enable training semantic-goal navigation\n(SemanticNav) agents at scale in unannotated 3D environments (e.g., HM3D).\nAfter training, SemanticNav agents can be instructed to find objects described\nin free-form natural language (e.g., \"sink\", \"bathroom sink\", etc.) by\nprojecting language goals into the same multimodal, semantic embedding space.\nAs a result, our approach enables open-world ObjectNav. We extensively evaluate\nour agents on three ObjectNav datasets (Gibson, HM3D, and MP3D) and observe\nabsolute improvements in success of 4.2% - 20.0% over existing zero-shot\nmethods. For reference, these gains are similar or better than the 5%\nimprovement in success between the Habitat 2020 and 2021 ObjectNav challenge\nwinners. In an open-world setting, we discover that our agents can generalize\nto compound instructions with a room explicitly mentioned (e.g., \"Find a\nkitchen sink\") and when the target room can be inferred (e.g., \"Find a sink and\na stove\").",
    "descriptor": "",
    "authors": [
      "Arjun Majumdar",
      "Gunjan Aggarwal",
      "Bhavika Devnani",
      "Judy Hoffman",
      "Dhruv Batra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.12403"
  },
  {
    "id": "arXiv:2104.02321",
    "title": "NU-Wave: A Diffusion Probabilistic Model for Neural Audio Upsampling",
    "abstract": "In this work, we introduce NU-Wave, the first neural audio upsampling model\nto produce waveforms of sampling rate 48kHz from coarse 16kHz or 24kHz inputs,\nwhile prior works could generate only up to 16kHz. NU-Wave is the first\ndiffusion probabilistic model for audio super-resolution which is engineered\nbased on neural vocoders. NU-Wave generates high-quality audio that achieves\nhigh performance in terms of signal-to-noise ratio (SNR), log-spectral distance\n(LSD), and accuracy of the ABX test. In all cases, NU-Wave outperforms the\nbaseline models despite the substantially smaller model capacity (3.0M\nparameters) than baselines (5.4-21%). The audio samples of our model are\navailable at https://mindslab-ai.github.io/nuwave, and the code will be made\navailable soon.",
    "descriptor": "\nComments: Accepted to Interspeech 2021\n",
    "authors": [
      "Junhyeok Lee",
      "Seungu Han"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.02321"
  },
  {
    "id": "arXiv:2206.09532",
    "title": "Hands-on Wireless Sensing with Wi-Fi: A Tutorial",
    "abstract": "With the rapid development of wireless communication technology, wireless\naccess points (AP) and internet of things (IoT) devices have been widely\ndeployed in our surroundings. Various types of wireless signals (e.g., Wi-Fi,\nLoRa, LTE) are filling out our living and working spaces. Previous researches\nreveal the fact that radio waves are modulated by the spatial structure during\nthe propagation process (e.g., reflection, diffraction, and scattering) and\nsuperimposed on the receiver. This observation allows us to reconstruct the\nsurrounding environment based on received wireless signals, called \"wireless\nsensing\". Wireless sensing is an emerging technology that enables a wide range\nof applications, such as gesture recognition for human-computer interaction,\nvital signs monitoring for health care, and intrusion detection for security\nmanagement. Compared with other sensing paradigms, such as vision-based and\nIMU-based sensing, wireless sensing solutions have unique advantages such as\nhigh coverage, pervasiveness, low cost, and robustness under adverse light and\ntexture scenarios. Besides, wireless sensing solutions are generally\nlightweight in terms of both computation overhead and device size. This\ntutorial takes Wi-Fi sensing as an example. It introduces both the theoretical\nprinciples and the code implementation of data collection, signal processing,\nfeatures extraction, and model design. In addition, this tutorial highlights\nstate-of-the-art deep learning models (e.g., CNN, RNN, and adversarial learning\nmodels) and their applications in wireless sensing systems. We hope this\ntutorial will help people in other research fields to break into wireless\nsensing research and learn more about its theories, designs, and implementation\nskills, promoting prosperity in the wireless sensing research field.",
    "descriptor": "",
    "authors": [
      "Zheng Yang",
      "Yi Zhang",
      "Guoxuan Chi",
      "Guidong Zhang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.09532"
  },
  {
    "id": "arXiv:2206.11898",
    "title": "Score-based Generative Models for Calorimeter Shower Simulation",
    "abstract": "Score-based generative models are a new class of generative algorithms that\nhave been shown to produce realistic images even in high dimensional spaces,\ncurrently surpassing other state-of-the-art models for different benchmark\ncategories and applications. In this work we introduce CaloScore, a score-based\ngenerative model for collider physics applied to calorimeter shower generation.\nThree different diffusion models are investigated using the Fast Calorimeter\nSimulation Challenge 2022 dataset. CaloScore is the first application of a\nscore-based generative model in collider physics and is able to produce\nhigh-fidelity calorimeter images for all datasets, providing an alternative\nparadigm for calorimeter shower simulation.",
    "descriptor": "",
    "authors": [
      "Vinicius Mikuni",
      "Benjamin Nachman"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)"
    ],
    "url": "https://arxiv.org/abs/2206.11898"
  },
  {
    "id": "arXiv:2206.11924",
    "title": "On the complexity of packing rainbow spanning trees",
    "abstract": "One of the most important questions in matroid optimization is to find\ndisjoint common bases of two matroids. The significance of the problem is\nwell-illustrated by the long list of conjectures that can be formulated as\nspecial cases. B\\'erczi and Schwarcz showed that the problem is hard in\ngeneral, therefore identifying the borderline between tractable and intractable\ninstances is of interest.\nIn the present paper, we study the special case when one of the matroids is a\npartition matroid while the other one is a graphic matroid. This setting is\nequivalent to the problem of packing rainbow spanning trees, an extension of\nthe problem of packing arborescences in directed graphs which was answered by\nEdmonds' seminal result on disjoint arborescences. We complement his result by\nshowing that it is NP-complete to decide whether an edge-colored graph contains\ntwo disjoint rainbow spanning trees. Our complexity result holds even for the\nvery special case when the graph is the union of two spanning trees and each\ncolor class contains exactly two edges. As a corollary, we give a negative\nanswer to a question on the decomposition of oriented $k$-partition-connected\ndigraphs.",
    "descriptor": "\nComments: 11 pages, 5 figures\n",
    "authors": [
      "Krist\u00f3f B\u00e9rczi",
      "Gergely Cs\u00e1ji",
      "Tam\u00e1s Kir\u00e1ly"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2206.11924"
  },
  {
    "id": "arXiv:2206.11943",
    "title": "TIAger: Tumor-Infiltrating Lymphocyte Scoring in Breast Cancer for the  TiGER Challenge",
    "abstract": "The quantification of tumor-infiltrating lymphocytes (TILs) has been shown to\nbe an independent predictor for prognosis of breast cancer patients. Typically,\npathologists give an estimate of the proportion of the stromal region that\ncontains TILs to obtain a TILs score. The Tumor InfiltratinG lymphocytes in\nbreast cancER (TiGER) challenge, aims to assess the prognostic significance of\ncomputer-generated TILs scores for predicting survival as part of a Cox\nproportional hazards model. For this challenge, as the TIAger team, we have\ndeveloped an algorithm to first segment tumor vs. stroma, before localising the\ntumor bulk region for TILs detection. Finally, we use these outputs to generate\na TILs score for each case. On preliminary testing, our approach achieved a\ntumor-stroma weighted Dice score of 0.791 and a FROC score of 0.572 for\nlymphocytic detection. For predicting survival, our model achieved a C-index of\n0.719. These results achieved first place across the preliminary testing\nleaderboards of the TiGER challenge.",
    "descriptor": "\nComments: TiGER Challenge entry\n",
    "authors": [
      "Adam Shephard",
      "Mostafa Jahanifar",
      "Ruoyu Wang",
      "Muhammad Dawood",
      "Simon Graham",
      "Kastytis Sidlauskas",
      "Syed Ali Khurram",
      "Nasir Rajpoot",
      "Shan E Ahmed Raza"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.11943"
  },
  {
    "id": "arXiv:2206.11948",
    "title": "Risk-Constrained Nonconvex Dynamic Resource Allocation has Zero Duality  Gap",
    "abstract": "We show that risk-constrained dynamic resource allocation problems with\ngeneral integrable nonconvex instantaneous service functions exhibit zero\nduality gap. We consider risk constraints which involve convex and positively\nhomogeneous risk measures admitting dual representations with bounded risk\nenvelopes, and are strictly more general than expectations. Beyond\nexpectations, particular risk measures supported within our setting include the\nconditional value-at-risk, the mean-absolute deviation (including the\nnon-monotone case), certain distributionally robust representations and more\ngenerally all real-valued coherent risk measures on the space ${\\cal L}_{1}$.\nOur proof technique relies on risk duality in tandem with Uhl's weak extension\nof Lyapunov's convexity theorem for vector measures taking values in general\nBanach spaces.",
    "descriptor": "\nComments: 16 pages, to be submitted\n",
    "authors": [
      "Dionysios Kalogerias"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.11948"
  },
  {
    "id": "arXiv:2206.11970",
    "title": "Learning quantum symmetries with interactive quantum-classical  variational algorithms",
    "abstract": "A symmetry of a state $\\lvert \\psi \\rangle$ is a unitary operator of which\n$\\lvert \\psi \\rangle$ is an eigenvector. When $\\lvert \\psi \\rangle$ is an\nunknown state supplied by a black-box oracle, the state's symmetries serve to\ncharacterize it, and often relegate much of the desired information about\n$\\lvert \\psi \\rangle$. In this paper, we develop a variational hybrid\nquantum-classical learning scheme to systematically probe for symmetries of\n$\\lvert \\psi \\rangle$ with no a priori assumptions about the state. This\nprocedure can be used to learn various symmetries at the same time. In order to\navoid re-learning already known symmetries, we introduce an interactive\nprotocol with a classical deep neural net. The classical net thereby\nregularizes against repetitive findings and allows our algorithm to terminate\nempirically with all possible symmetries found. Our scheme can be implemented\nefficiently on average with non-local SWAP gates; we also give a less efficient\nalgorithm with only local operations, which may be more appropriate for current\nnoisy quantum devices. We demonstrate our algorithm on representative families\nof states.",
    "descriptor": "\nComments: (June 23, 2022) Preprint\n",
    "authors": [
      "Jonathan Z. Lu",
      "Rodrigo A. Bravo",
      "Kaiying Hou",
      "Gebremedhin A. Dagnew",
      "Susanne F. Yelin",
      "Khadijeh Najafi"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.11970"
  },
  {
    "id": "arXiv:2206.11973",
    "title": "Liquidity Risks in Lending Protocols (LPs): Evidence from Aave Protocol",
    "abstract": "Decentralized Finance (DeFi) can replicate most traditional financial\nactivities. Among various DeFi, Lending Protocols (LPs) resemble banks,\nallowing users to borrow and lend cryptocurrencies. By analysing stablecoin\nloans in Aave protocol, we find a small group of users with dual roles, i.e.,\nborrowers and depositors, and these users account for significant loans and\ndeposits. Therefore, potential liquidity risks can occur if these users\ncollectively withdraw deposits and initiate loans, and potential liquidity\nrisks can affect both loan-specific factors and status of Aave protocol.\nSurprisingly, liquidity risks in Aave are related to other LPs, implying\nilliquidity is infectious in DeFi.",
    "descriptor": "",
    "authors": [
      "Xiaotong Sun"
    ],
    "subjectives": [
      "Risk Management (q-fin.RM)",
      "Cryptography and Security (cs.CR)",
      "Computational Finance (q-fin.CP)",
      "Trading and Market Microstructure (q-fin.TR)"
    ],
    "url": "https://arxiv.org/abs/2206.11973"
  },
  {
    "id": "arXiv:2206.11988",
    "title": "On making optimal transport robust to all outliers",
    "abstract": "Optimal transport (OT) is known to be sensitive against outliers because of\nits marginal constraints. Outlier robust OT variants have been proposed based\non the definition that outliers are samples which are expensive to move. In\nthis paper, we show that this definition is restricted by considering the case\nwhere outliers are closer to the target measure than clean samples. We show\nthat outlier robust OT fully transports these outliers leading to poor\nperformances in practice. To tackle these outliers, we propose to detect them\nby relying on a classifier trained with adversarial training to classify source\nand target samples. A sample is then considered as an outlier if the prediction\nfrom the classifier is different from its assigned label. To decrease the\ninfluence of these outliers in the transport problem, we propose to either\nremove them from the problem or to increase the cost of moving them by using\nthe classifier prediction. We show that we successfully detect these outliers\nand that they do not influence the transport problem on several experiments\nsuch as gradient flows, generative models and label propagation.",
    "descriptor": "",
    "authors": [
      "Kilian Fatras"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2206.11988"
  },
  {
    "id": "arXiv:2206.12008",
    "title": "Three Applications of Conformal Prediction for Rating Breast Density in  Mammography",
    "abstract": "Breast cancer is the most common cancers and early detection from mammography\nscreening is crucial in improving patient outcomes. Assessing mammographic\nbreast density is clinically important as the denser breasts have higher risk\nand are more likely to occlude tumors. Manual assessment by experts is both\ntime-consuming and subject to inter-rater variability. As such, there has been\nincreased interest in the development of deep learning methods for mammographic\nbreast density assessment. Despite deep learning having demonstrated impressive\nperformance in several prediction tasks for applications in mammography,\nclinical deployment of deep learning systems in still relatively rare;\nhistorically, mammography Computer-Aided Diagnoses (CAD) have over-promised and\nfailed to deliver. This is in part due to the inability to intuitively quantify\nuncertainty of the algorithm for the clinician, which would greatly enhance\nusability. Conformal prediction is well suited to increase reliably and trust\nin deep learning tools but they lack realistic evaluations on medical datasets.\nIn this paper, we present a detailed analysis of three possible applications of\nconformal prediction applied to medical imaging tasks: distribution shift\ncharacterization, prediction quality improvement, and subgroup fairness\nanalysis. Our results show the potential of distribution-free uncertainty\nquantification techniques to enhance trust on AI algorithms and expedite their\ntranslation to usage.",
    "descriptor": "\nComments: Accepted to Workshop on Distribution-Free Uncertainty Quantification at ICML 2022\n",
    "authors": [
      "Charles Lu",
      "Ken Chang",
      "Praveer Singh",
      "Jayashree Kalpathy-Cramer"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.12008"
  },
  {
    "id": "arXiv:2206.12040",
    "title": "End-to-End Text-to-Speech Based on Latent Representation of Speaking  Styles Using Spontaneous Dialogue",
    "abstract": "The recent text-to-speech (TTS) has achieved quality comparable to that of\nhumans; however, its application in spoken dialogue has not been widely\nstudied. This study aims to realize a TTS that closely resembles human\ndialogue. First, we record and transcribe actual spontaneous dialogues. Then,\nthe proposed dialogue TTS is trained in two stages: first stage, variational\nautoencoder (VAE)-VITS or Gaussian mixture variational autoencoder (GMVAE)-VITS\nis trained, which introduces an utterance-level latent variable into\nvariational inference with adversarial learning for end-to-end text-to-speech\n(VITS), a recently proposed end-to-end TTS model. A style encoder that extracts\na latent speaking style representation from speech is trained jointly with TTS.\nIn the second stage, a style predictor is trained to predict the speaking style\nto be synthesized from dialogue history. During inference, by passing the\nspeaking style representation predicted by the style predictor to\nVAE/GMVAE-VITS, speech can be synthesized in a style appropriate to the context\nof the dialogue. Subjective evaluation results demonstrate that the proposed\nmethod outperforms the original VITS in terms of dialogue-level naturalness.",
    "descriptor": "\nComments: 5 pages, 3 figures, accepted for INTERSPEECH 2022. Audio samples: this https URL\n",
    "authors": [
      "Kentaro Mitsui",
      "Tianyu Zhao",
      "Kei Sawada",
      "Yukiya Hono",
      "Yoshihiko Nankaku",
      "Keiichi Tokuda"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2206.12040"
  },
  {
    "id": "arXiv:2206.12041",
    "title": "How many labelers do you have? A closer look at gold-standard labels",
    "abstract": "The construction of most supervised learning datasets revolves around\ncollecting multiple labels for each instance, then aggregating the labels to\nform a type of ``gold-standard.''. We question the wisdom of this pipeline by\ndeveloping a (stylized) theoretical model of this process and analyzing its\nstatistical consequences, showing how access to non-aggregated label\ninformation can make training well-calibrated models easier or -- in some cases\n-- even feasible, whereas it is impossible with only gold-standard labels. The\nentire story, however, is subtle, and the contrasts between aggregated and\nfuller label information depend on the particulars of the problem, where\nestimators that use aggregated information exhibit robust but slower rates of\nconvergence, while estimators that can effectively leverage all labels converge\nmore quickly if they have fidelity to (or can learn) the true labeling process.\nThe theory we develop in the stylized model makes several predictions for\nreal-world datasets, including when non-aggregate labels should improve\nlearning performance, which we test to corroborate the validity of our\npredictions.",
    "descriptor": "\nComments: 51 pages, 4 figures\n",
    "authors": [
      "Chen Cheng",
      "Hilal Asi",
      "John Duchi"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.12041"
  },
  {
    "id": "arXiv:2206.12045",
    "title": "Confidence Score Based Conformer Speaker Adaptation for Speech  Recognition",
    "abstract": "A key challenge for automatic speech recognition (ASR) systems is to model\nthe speaker level variability. In this paper, compact speaker dependent\nlearning hidden unit contributions (LHUC) are used to facilitate both speaker\nadaptive training (SAT) and test time unsupervised speaker adaptation for\nstate-of-the-art Conformer based end-to-end ASR systems. The sensitivity during\nadaptation to supervision error rate is reduced using confidence score based\nselection of the more \"trustworthy\" subset of speaker specific data. A\nconfidence estimation module is used to smooth the over-confident Conformer\ndecoder output probabilities before serving as confidence scores. The increased\ndata sparsity due to speaker level data selection is addressed using Bayesian\nestimation of LHUC parameters. Experiments on the 300-hour Switchboard corpus\nsuggest that the proposed LHUC-SAT Conformer with confidence score based test\ntime unsupervised adaptation outperformed the baseline speaker independent and\ni-vector adapted Conformer systems by up to 1.0%, 1.0%, and 1.2% absolute\n(9.0%, 7.9%, and 8.9% relative) word error rate (WER) reductions on the NIST\nHub5'00, RT02, and RT03 evaluation sets respectively. Consistent performance\nimprovements were retained after external Transformer and LSTM language models\nwere used for rescoring.",
    "descriptor": "\nComments: It's accepted to INTERSPEECH 2022. arXiv admin note: text overlap with arXiv:2206.11596\n",
    "authors": [
      "Jiajun Deng",
      "Xurong Xie",
      "Tianzi Wang",
      "Mingyu Cui",
      "Boyang Xue",
      "Zengrui Jin",
      "Mengzhe Geng",
      "Guinan Li",
      "Xunying Liu",
      "Helen Meng"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2206.12045"
  },
  {
    "id": "arXiv:2206.12059",
    "title": "Data Augmentation and Squeeze-and-Excitation Network on Multiple  Dimension for Sound Event Localization and Detection in Real Scenes",
    "abstract": "Performance of sound event localization and detection (SELD) in real scenes\nis limited by small size of SELD dataset, due to difficulty in obtaining\nsufficient amount of realistic multi-channel audio data recordings with\naccurate label. We used two main strategies to solve problems arising from the\nsmall real SELD dataset. First, we applied various data augmentation methods on\nall data dimensions: channel, frequency and time. We also propose original data\naugmentation method named Moderate Mixup in order to simulate situations where\nnoise floor or interfering events exist. Second, we applied\nSqueeze-and-Excitation block on channel and frequency dimensions to efficiently\nextract feature characteristics. Result of our trained models on the STARSS22\ntest dataset achieved the best ER, F1, LE, and LR of 0.53, 49.8%, 16.0deg., and\n56.2% respectively.",
    "descriptor": "\nComments: Technical Report submitted for DCASE2022 Challenge Task3\n",
    "authors": [
      "Byeong-Yun Ko",
      "Hyeonuk Nam",
      "Seong-Hu Kim",
      "Deokki Min",
      "Seung-Deok Choi",
      "Yong-Hwa Park"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2206.12059"
  },
  {
    "id": "arXiv:2206.12091",
    "title": "Using Differential Geometry to Revisit the Paradoxes of the  Instantaneous Frequen",
    "abstract": "This paper proposes a general framework to interpret the concept of\nInstantaneous Frequency (IF) in three-phase systems. The paper first recalls\nthe conventional frequency-domain analysis based on the Fourier transform as\nwell as the definition of IF which is based on the concept of analytic signals.\nThe link between analytic signals and Clarke transform of three-phase voltages\nof an ac power system is also shown. Then the well-known five paradoxes of the\nIF are stated. In the second part of the paper, an approach based on a\ngeometric interpretation of the frequency is proposed. This approach serves to\nrevisit the five IF paradoxes and explain them through a common framework. The\ncase study illustrates the features of the proposed framework based on a\nvariety of examples and on a detailed model of the IEEE 39-bus system.",
    "descriptor": "\nComments: 12\n",
    "authors": [
      "Federico Milano",
      "Georgios Tzounas",
      "Ioannis Dassios",
      "Mohammed Ahsan Adib Murad",
      "Taulant K\u00ebr\u00e7i"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)",
      "Differential Geometry (math.DG)"
    ],
    "url": "https://arxiv.org/abs/2206.12091"
  },
  {
    "id": "arXiv:2206.12097",
    "title": "Deep-Learning-Aided Distributed Clock Synchronization for Wireless  Networks",
    "abstract": "The proliferation of wireless communications networks over the past decades,\ncombined with the scarcity of the wireless spectrum, have motivated a\nsignificant effort towards increasing the throughput of wireless networks. One\nof the major factors which limits the throughput in wireless communications\nnetworks is the accuracy of the time synchronization between the nodes in the\nnetwork, as a higher throughput requires higher synchronization accuracy.\nExisting time synchronization schemes, and particularly, methods based on\npulse-coupled oscillators (PCOs), which are the focus of the current work, have\nthe advantage of simple implementation and achieve high accuracy when the nodes\nare closely located, yet tend to achieve poor synchronization performance for\ndistant nodes. In this study, we propose a robust PCO-based time\nsynchronization algorithm which retains the simple structure of existing\napproaches while operating reliably and converging quickly for both distant and\nclosely located nodes. This is achieved by augmenting PCO-based synchronization\nwith deep learning tools that are trainable in a distributed manner, thus\nallowing the nodes to train their neural network component of the\nsynchronization algorithm without requiring additional exchange of information\nor central coordination. The numerical results show that our proposed deep\nlearning-aided scheme is notably robust to propagation delays resulting from\ndeployments over large areas, and to relative clock frequency offsets. It is\nalso shown that the proposed approach rapidly attains full (i.e., clock\nfrequency and phase) synchronization for all nodes in the wireless network,\nwhile the classic model-based implementation does not.",
    "descriptor": "\nComments: under review for publication in the IEEE Transactions on Communciaitons. Copyright may be transfered without notice\n",
    "authors": [
      "Emeka Abakasanga",
      "Nir Shlezinger",
      "Ron Dabora"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.12097"
  },
  {
    "id": "arXiv:2206.12112",
    "title": "Dissecting U-net for Seismic Application: An In-Depth Study on Deep  Learning Multiple Removal",
    "abstract": "Seismic processing often requires suppressing multiples that appear when\ncollecting data. To tackle these artifacts, practitioners usually rely on Radon\ntransform-based algorithms as post-migration gather conditioning. However, such\ntraditional approaches are both time-consuming and parameter-dependent, making\nthem fairly complex. In this work, we present a deep learning-based alternative\nthat provides competitive results, while reducing its usage's complexity, and\nhence democratizing its applicability. We observe an excellent performance of\nour network when inferring complex field data, despite the fact of being solely\ntrained on synthetics. Furthermore, extensive experiments show that our\nproposal can preserve the inherent characteristics of the data, avoiding\nundesired over-smoothed results, while removing the multiples. Finally, we\nconduct an in-depth analysis of the model, where we pinpoint the effects of the\nmain hyperparameters with physical events. To the best of our knowledge, this\nstudy pioneers the unboxing of neural networks for the demultiple process,\nhelping the user to gain insights into the inside running of the network.",
    "descriptor": "",
    "authors": [
      "Ricard Durall",
      "Ammar Ghanim",
      "Norman Ettrich",
      "Janis Keuper"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.12112"
  },
  {
    "id": "arXiv:2206.12116",
    "title": "Approximating 1-Wasserstein Distance with Trees",
    "abstract": "Wasserstein distance, which measures the discrepancy between distributions,\nshows efficacy in various types of natural language processing (NLP) and\ncomputer vision (CV) applications. One of the challenges in estimating\nWasserstein distance is that it is computationally expensive and does not scale\nwell for many distribution comparison tasks. In this paper, we aim to\napproximate the 1-Wasserstein distance by the tree-Wasserstein distance (TWD),\nwhere TWD is a 1-Wasserstein distance with tree-based embedding and can be\ncomputed in linear time with respect to the number of nodes on a tree. More\nspecifically, we propose a simple yet efficient L1-regularized approach to\nlearning the weights of the edges in a tree. To this end, we first show that\nthe 1-Wasserstein approximation problem can be formulated as a distance\napproximation problem using the shortest path distance on a tree. We then show\nthat the shortest path distance can be represented by a linear model and can be\nformulated as a Lasso-based regression problem. Owing to the convex\nformulation, we can obtain a globally optimal solution efficiently. Moreover,\nwe propose a tree-sliced variant of these methods. Through experiments, we\ndemonstrated that the weighted TWD can accurately approximate the original\n1-Wasserstein distance.",
    "descriptor": "",
    "authors": [
      "Makoto Yamada",
      "Yuki Takezawa",
      "Ryoma Sato",
      "Han Bao",
      "Zornitsa Kozareva",
      "Sujith Ravi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.12116"
  },
  {
    "id": "arXiv:2206.12127",
    "title": "Implicit Channel Learning for Machine Learning Applications in 6G  Wireless Networks",
    "abstract": "With the deployment of the fifth generation (5G) wireless systems gathering\nmomentum across the world, possible technologies for 6G are under active\nresearch discussions. In particular, the role of machine learning (ML) in 6G is\nexpected to enhance and aid emerging applications such as virtual and augmented\nreality, vehicular autonomy, and computer vision. This will result in large\nsegments of wireless data traffic comprising image, video and speech. The ML\nalgorithms process these for classification/recognition/estimation through the\nlearning models located on cloud servers. This requires wireless transmission\nof data from edge devices to the cloud server. Channel estimation, handled\nseparately from recognition step, is critical for accurate learning\nperformance. Toward combining the learning for both channel and the ML data, we\nintroduce implicit channel learning to perform the ML tasks without estimating\nthe wireless channel. Here, the ML models are trained with channel-corrupted\ndatasets in place of nominal data. Without channel estimation, the proposed\napproach exhibits approximately 60% improvement in image and speech\nclassification tasks for diverse scenarios such as millimeter wave and IEEE\n802.11p vehicular channels.",
    "descriptor": "\nComments: 7Pages, submitted to IEEE\n",
    "authors": [
      "Ahmet M. Elbir",
      "Wei Shi",
      "Kumar Vijay Mishra",
      "Anastasios K. Papazafeiropoulos",
      "Symeon Chatzinotas"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.12127"
  },
  {
    "id": "arXiv:2206.12132",
    "title": "SANE-TTS: Stable And Natural End-to-End Multilingual Text-to-Speech",
    "abstract": "In this paper, we present SANE-TTS, a stable and natural end-to-end\nmultilingual TTS model. By the difficulty of obtaining multilingual corpus for\ngiven speaker, training multilingual TTS model with monolingual corpora is\nunavoidable. We introduce speaker regularization loss that improves speech\nnaturalness during cross-lingual synthesis as well as domain adversarial\ntraining, which is applied in other multilingual TTS models. Furthermore, by\nadding speaker regularization loss, replacing speaker embedding with zero\nvector in duration predictor stabilizes cross-lingual inference. With this\nreplacement, our model generates speeches with moderate rhythm regardless of\nsource speaker in cross-lingual synthesis. In MOS evaluation, SANE-TTS achieves\nnaturalness score above 3.80 both in cross-lingual and intralingual synthesis,\nwhere the ground truth score is 3.99. Also, SANE-TTS maintains speaker\nsimilarity close to that of ground truth even in cross-lingual inference. Audio\nsamples are available on our web page.",
    "descriptor": "\nComments: Accepted to Interspeech 2022\n",
    "authors": [
      "Hyunjae Cho",
      "Wonbin Jung",
      "Junhyeok Lee",
      "Sang Hoon Woo"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.12132"
  },
  {
    "id": "arXiv:2206.12136",
    "title": "Feature Representation Learning for Robust Retinal Disease Detection  from Optical Coherence Tomography Images",
    "abstract": "Ophthalmic images may contain identical-looking pathologies that can cause\nfailure in automated techniques to distinguish different retinal degenerative\ndiseases. Additionally, reliance on large annotated datasets and lack of\nknowledge distillation can restrict ML-based clinical support systems'\ndeployment in real-world environments. To improve the robustness and\ntransferability of knowledge, an enhanced feature-learning module is required\nto extract meaningful spatial representations from the retinal subspace. Such a\nmodule, if used effectively, can detect unique disease traits and differentiate\nthe severity of such retinal degenerative pathologies. In this work, we propose\na robust disease detection architecture with three learning heads, i) A\nsupervised encoder for retinal disease classification, ii) An unsupervised\ndecoder for the reconstruction of disease-specific spatial information, and\niii) A novel representation learning module for learning the similarity between\nencoder-decoder feature and enhancing the accuracy of the model. Our\nexperimental results on two publicly available OCT datasets illustrate that the\nproposed model outperforms existing state-of-the-art models in terms of\naccuracy, interpretability, and robustness for out-of-distribution retinal\ndisease detection.",
    "descriptor": "\nComments: 10 pages, 2 figures, 2 tables\n",
    "authors": [
      "Sharif Amit Kamran",
      "Khondker Fariha Hossain",
      "Alireza Tavakkoli",
      "Stewart Lee Zuckerbrod",
      "Salah A. Baker"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.12136"
  },
  {
    "id": "arXiv:2206.12141",
    "title": "Aggregated Multi-output Gaussian Processes with Knowledge Transfer  Across Domains",
    "abstract": "Aggregate data often appear in various fields such as socio-economics and\npublic security. The aggregate data are associated not with points but with\nsupports (e.g., spatial regions in a city). Since the supports may have various\ngranularities depending on attributes (e.g., poverty rate and crime rate),\nmodeling such data is not straightforward. This article offers a multi-output\nGaussian process (MoGP) model that infers functions for attributes using\nmultiple aggregate datasets of respective granularities. In the proposed model,\nthe function for each attribute is assumed to be a dependent GP modeled as a\nlinear mixing of independent latent GPs. We design an observation model with an\naggregation process for each attribute; the process is an integral of the GP\nover the corresponding support. We also introduce a prior distribution of the\nmixing weights, which allows a knowledge transfer across domains (e.g., cities)\nby sharing the prior. This is advantageous in such a situation where the\nspatially aggregated dataset in a city is too coarse to interpolate; the\nproposed model can still make accurate predictions of attributes by utilizing\naggregate datasets in other cities. The inference of the proposed model is\nbased on variational Bayes, which enables one to learn the model parameters\nusing the aggregate datasets from multiple domains. The experiments demonstrate\nthat the proposed model outperforms in the task of refining coarse-grained\naggregate data on real-world datasets: Time series of air pollutants in Beijing\nand various kinds of spatial datasets from New York City and Chicago.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Yusuke Tanaka",
      "Toshiyuki Tanaka",
      "Tomoharu Iwata",
      "Takeshi Kurashima",
      "Maya Okawa",
      "Yasunori Akagi",
      "Hiroyuki Toda"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.12141"
  },
  {
    "id": "arXiv:2206.12148",
    "title": "On Data-Driven Log-Optimal Portfolio: A Sliding Window Approach",
    "abstract": "In this paper, we propose a data-driven sliding window approach to solve a\nlog-optimal portfolio problem. In contrast to many of the existing papers, this\napproach leads to a trading strategy with time-varying portfolio weights rather\nthan fixed constant weights. We show, by conducting various empirical studies,\nthat the approach possesses a superior trading performance to the classical\nlog-optimal portfolio in the sense of having a higher cumulative rate of\nreturns.",
    "descriptor": "\nComments: To appear in the IFAC-PapersOnline (25th International Symposium on Mathematical Theory of Network and Systems)\n",
    "authors": [
      "Pei-Ting Wang",
      "Chung-Han Hsieh"
    ],
    "subjectives": [
      "Portfolio Management (q-fin.PM)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)",
      "Computational Finance (q-fin.CP)"
    ],
    "url": "https://arxiv.org/abs/2206.12148"
  },
  {
    "id": "arXiv:2206.12159",
    "title": "Data-driven discovery of novel 2D materials by deep generative models",
    "abstract": "Efficient algorithms to generate candidate crystal structures with good\nstability properties can play a key role in data-driven materials discovery.\nHere we show that a crystal diffusion variational autoencoder (CDVAE) is\ncapable of generating two-dimensional (2D) materials of high chemical and\nstructural diversity and formation energies mirroring the training structures.\nSpecifically, we train the CDVAE on 2615 2D materials with energy above the\nconvex hull $\\Delta H_{\\mathrm{hull}}< 0.3$ eV/atom, and generate 5003\nmaterials that we relax using density functional theory (DFT). We also generate\n14192 new crystals by systematic element substitution of the training\nstructures. We find that the generative model and lattice decoration approach\nare complementary and yield materials with similar stability properties but\nvery different crystal structures and chemical compositions. In total we find\n11630 predicted new 2D materials, where 8599 of these have $\\Delta\nH_{\\mathrm{hull}}< 0.3$ eV/atom as the seed structures, while 2004 are within\n50 meV of the convex hull and could potentially be synthesized. The relaxed\natomic structures of all the materials are available in the open Computational\n2D Materials Database (C2DB). Our work establishes the CDVAE as an efficient\nand reliable crystal generation machine, and significantly expands the space of\n2D materials.",
    "descriptor": "",
    "authors": [
      "Peder Lyngby",
      "Kristian Sommer Thygesen"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.12159"
  },
  {
    "id": "arXiv:2206.12162",
    "title": "Ultrafast carbon nanotube photodetectors with a zero bias bandwidth over  30 GHz",
    "abstract": "The future interconnect links in intra- and inter-chip require the\nphotodetector with high bandwidth, ultra-wide waveband, compact footprint,\nlow-cost, and compatible integration process with silicon complementary\nmetal-oxide-semiconductor (CMOS) technology. Here, we demonstrate a\nCMOS-compatible carbon nanotube (CNT) photodetector that exhibits high\nresponsivity, high bandwidth and broad spectral operation over all optical\ntelecommunication band based on high-purity CNT arrays. The ultrafast CNT\nphotodetector demonstrates the 100 Gbit/s Nyquist-shaped on-off-keying (OOK)\nsignal transmission, which can address the demand for high-speed optical\ninterconnects in and between data centers. Furthermore, the photodetector\nexhibits a zero-bias bandwidth over 30 GHz by scaling down the active area to\n20 {\\mu}m2. As the CNT photodetectors are fabricated by doping-free process, it\nalso provides a cost-effective solution to integrate CNT photonic devices with\nCNT-based CMOS integrated circuits. Our work paves a way for future CNT-based\nhigh-speed optical interconnects and optoelectronic integrated circuits\n(OEICs).",
    "descriptor": "\nComments: 40 pages with supplemental materials,5 figures\n",
    "authors": [
      "Weifeng Wu",
      "Fan Yang",
      "Xiansong Fang",
      "Xiang Cai",
      "Xiaohui Liu",
      "Fan Zhang",
      "Sheng Wang"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Emerging Technologies (cs.ET)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.12162"
  },
  {
    "id": "arXiv:2206.12180",
    "title": "Towards FPGA Implementation of Neural Network-Based Nonlinearity  Mitigation Equalizers in Coherent Optical Transmission Systems",
    "abstract": "For the first time, recurrent and feedforward neural network-based equalizers\nfor nonlinearity compensation are implemented in an FPGA, with a level of\ncomplexity comparable to that of a dispersion equalizer. We demonstrate that\nthe NN-based equalizers can outperform a 1 step-per-span DBP.",
    "descriptor": "\nComments: Accepted Oral in the European Conference on Optical Communication (ECOC) 2022\n",
    "authors": [
      "Pedro J. Freire",
      "Michael Anderson",
      "Bernhard Spinnler",
      "Thomas Bex",
      "Jaroslaw E. Prilepsky",
      "Tobias A. Eriksson",
      "Nelson Costa",
      "Wolfgang Schairer",
      "Michaela Blott",
      "Antonio Napoli",
      "Sergei K. Turitsyn"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.12180"
  },
  {
    "id": "arXiv:2206.12191",
    "title": "Computational Complexity Evaluation of Neural Network Applications in  Signal Processing",
    "abstract": "In this paper, we provide a systematic approach for assessing and comparing\nthe computational complexity of neural network layers in digital signal\nprocessing. We provide and link four software-to-hardware complexity measures,\ndefining how the different complexity metrics relate to the layers'\nhyper-parameters. This paper explains how to compute these four metrics for\nfeed-forward and recurrent layers, and defines in which case we ought to use a\nparticular metric depending on whether we characterize a more soft- or\nhardware-oriented application. One of the four metrics, called `the number of\nadditions and bit shifts (NABS)', is newly introduced for heterogeneous\nquantization. NABS characterizes the impact of not only the bitwidth used in\nthe operation but also the type of quantization used in the arithmetical\noperations. We intend this work to serve as a baseline for the different levels\n(purposes) of complexity estimation related to the neural networks' application\nin real-time digital signal processing, aiming at unifying the computational\ncomplexity estimation.",
    "descriptor": "",
    "authors": [
      "Pedro J. Freire",
      "Sasipim Srivallapanondh",
      "Antonio Napoli",
      "Jaroslaw E. Prilepsky",
      "Sergei K. Turitsyn"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Computational Complexity (cs.CC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.12191"
  },
  {
    "id": "arXiv:2206.12201",
    "title": "Experimental graybox quantum control",
    "abstract": "Understanding and controlling engineered quantum systems is key to developing\npractical quantum technology. However, given the current technological\nlimitations, such as fabrication imperfections and environmental noise, this is\nnot always possible. To address these issues, a great deal of theoretical and\nnumerical methods for quantum system identification and control have been\ndeveloped. These methods range from traditional curve fittings, which are\nlimited by the accuracy of the model that describes the system, to machine\nlearning methods, including neural networks, which provide efficient control\nsolutions but do not provide control beyond the output of the model, nor\ninsights into the underlying physical process. Here we experimentally\ndemonstrate a \"graybox\" approach for characterizing and controlling quantum\ndevices. We report superior performance over model fitting, while generating\nunitaries and Hamiltonians which are inaccessible with machine learning\ntechniques. Our approach combines prior physics knowledge with high accuracy\nmachine learning and is effective with any problem where the required\ncontrolled quantities are not directly accessible from the training set. This\nmethod naturally extends to time-dependent and open quantum systems, with\napplications in quantum noise spectroscopy and cancellation.",
    "descriptor": "",
    "authors": [
      "Akram Youssry",
      "Yang Yang",
      "Robert J. Chapman",
      "Ben Haylock",
      "Mirko Lobino",
      "Alberto Peruzzo"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Systems and Control (eess.SY)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2206.12201"
  },
  {
    "id": "arXiv:2206.12240",
    "title": "PSP: Million-level Protein Sequence Dataset for Protein Structure  Prediction",
    "abstract": "Proteins are essential component of human life and their structures are\nimportant for function and mechanism analysis. Recent work has shown the\npotential of AI-driven methods for protein structure prediction. However, the\ndevelopment of new models is restricted by the lack of dataset and benchmark\ntraining procedure. To the best of our knowledge, the existing open source\ndatasets are far less to satisfy the needs of modern protein sequence-structure\nrelated research. To solve this problem, we present the first million-level\nprotein structure prediction dataset with high coverage and diversity, named as\nPSP. This dataset consists of 570k true structure sequences (10TB) and 745k\ncomplementary distillation sequences (15TB). We provide in addition the\nbenchmark training procedure for SOTA protein structure prediction model on\nthis dataset. We validate the utility of this dataset for training by\nparticipating CAMEO contest in which our model won the first place. We hope our\nPSP dataset together with the training benchmark can enable a broader community\nof AI/biology researchers for AI-driven protein related research.",
    "descriptor": "",
    "authors": [
      "Sirui Liu",
      "Jun Zhang",
      "Haotian Chu",
      "Min Wang",
      "Boxin Xue",
      "Ningxi Ni",
      "Jialiang Yu",
      "Yuhao Xie",
      "Zhenyu Chen",
      "Mengyun Chen",
      "Yuan Liu",
      "Piya Patra",
      "Fan Xu",
      "Jie Chen",
      "Zidong Wang",
      "Lijiang Yang",
      "Fan Yu",
      "Lei Chen",
      "Yi Qin Gao"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.12240"
  },
  {
    "id": "arXiv:2206.12242",
    "title": "Intersecting near-optimal spaces: European power systems with more  resilience to weather variability",
    "abstract": "We suggest a new methodology for designing robust energy systems. For this,\nwe investigate so-called near-optimal solutions to energy system optimisation\nmodels; solutions whose objective values deviate only marginally from the\noptimum. Using a refined method for obtaining explicit geometric descriptions\nof these near-optimal feasible spaces, we find designs that are as robust as\npossible to perturbations. This contributes to the ongoing debate on how to\ndefine and work with robustness in energy systems modelling. We apply our\nmethods in an investigation using multiple decades of weather data. For the\nfirst time, we run a capacity expansion model of the European power system (one\nnode per country) with a three-hourly temporal resolution with 41 years of\nweather data. While an optimisation with 41 weather years is at the limits of\ncomputational feasibility, we use the near-optimal feasible spaces of single\nyears to gain an understanding of the design space over the full time period.\nSpecifically, we intersect all near-optimal feasible spaces for the individual\nyears in order to get designs that are likely to be feasible over the entire\ntime period. We find significant potential for flexibility, and verify the\nfeasibility of these designs by simulating the resulting dispatch problem with\nfour decades of weather data. They are characterised by a shift towards more\nonshore wind and solar power, while emitting up to 60\\% less \\ch{CO2} than a\ncost-optimal solution over that period. Our work builds on recent developments\nin the field, including techniques such as Modelling to Generate Alternatives\nand Modelling All Alternatives, and provides new insights into the geometry of\nnear-optimal feasible spaces and the importance of multi-decade weather\nvariability for energy systems design. We also provide an effective way of\nworking with a multi-decade time frame in a highly parallelised manner.",
    "descriptor": "\nComments: 38 pages, 11 figures, 2 tables\n",
    "authors": [
      "Aleksander Grochowicz",
      "Koen van Greevenbroek",
      "Fred Espen Benth",
      "Marianne Zeyringer"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.12242"
  },
  {
    "id": "arXiv:2206.12253",
    "title": "The role of rationality in integer-programming relaxations",
    "abstract": "For a finite set $X \\subset \\mathbb{Z}^d$ that can be represented as $X = Q\n\\cap \\mathbb{Z}^d$ for some polyhedron $Q$, we call $Q$ a relaxation of $X$ and\ndefine the relaxation complexity $rc(X)$ of $X$ as the least number of facets\namong all possible relaxations $Q$ of $X$. The rational relaxation complexity\n$rc_\\mathbb{Q}(X)$ restricts the definition of $rc(X)$ to rational polyhedra\n$Q$. In this article, we focus on $X = \\Delta_d$, the vertex set of the\nstandard simplex, which consists of the null vector and the standard unit\nvectors in $\\mathbb{R}^d$. We show that $rc(\\Delta_d) \\leq d$ for every $d \\geq\n5$. That is, since $rc_{\\mathbb{Q}}(\\Delta_d)=d+1$, irrationality can reduce\nthe minimal size of relaxations. This answers an open question posed by Kaibel\nand Weltge (Lower bounds on the size of integer programs without additional\nvariables, Mathematical Programming, 154(1):407-425, 2015). Moreover, we prove\nthe asymptotic statement $rc(\\Delta_d) \\in O(\\frac{d}{\\sqrt{\\log(d)}})$, which\nshows that the ratio $rc(\\Delta_d)/rc_{\\mathbb{Q}}(\\Delta_d)$ goes to $0$, as\n$d\\to \\infty$.",
    "descriptor": "",
    "authors": [
      "Manuel Aprile",
      "Gennadiy Averkov",
      "Marco Di Summa",
      "Christopher Hojny"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2206.12253"
  },
  {
    "id": "arXiv:2206.12273",
    "title": "Iterative Sound Source Localization for Unknown Number of Sources",
    "abstract": "Sound source localization aims to seek the direction of arrival (DOA) of all\nsound sources from the observed multi-channel audio. For the practical problem\nof unknown number of sources, existing localization algorithms attempt to\npredict a likelihood-based coding (i.e., spatial spectrum) and employ a\npre-determined threshold to detect the source number and corresponding DOA\nvalue. However, these threshold-based algorithms are not stable since they are\nlimited by the careful choice of threshold. To address this problem, we propose\nan iterative sound source localization approach called ISSL, which can\niteratively extract each source's DOA without threshold until the termination\ncriterion is met. Unlike threshold-based algorithms, ISSL designs an active\nsource detector network based on binary classifier to accept residual spatial\nspectrum and decide whether to stop the iteration. By doing so, our ISSL can\ndeal with an arbitrary number of sources, even more than the number of sources\nseen during the training stage. The experimental results show that our ISSL\nachieves significant performance improvements in both DOA estimation and source\nnumber detection compared with the existing threshold-based algorithms.",
    "descriptor": "\nComments: Accepted by Interspeech 2022\n",
    "authors": [
      "Yanjie Fu",
      "Meng Ge",
      "Haoran Yin",
      "Xinyuan Qian",
      "Longbiao Wang",
      "Gaoyan Zhang",
      "Jianwu Dang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.12273"
  },
  {
    "id": "arXiv:2206.12283",
    "title": "Open-source objective-oriented framework for head-related transfer  function",
    "abstract": "Throughout last 30 years, numerous head-related transfer function (HRTF)\nmodels have been developed and there are more to come. This paper describes a\nframework based on objective-oriented programming paradigm, in which each HRTF\nrepresentation method can be implemented as a separate class. Its modular\nstructure allows the source code to be conveniently shared between researchers,\nwhile common interface provides easy access to data regardless of the internal\nstructure of the classes. The paper discusses difficulties of designing the\nframework, maintaining the balance between its flexibility and finding common\nfeatures of every possible directivity representation. Exemplary use cases are\nincluded and explained. Adoption of the framework will enhance possibilities of\naccuracy comparison between various HRTF models, thus improving the evaluation\nof current and future representation methods. The framework, developed in the\nform of a MATLAB toolbox, is designed to handle not only HRTFs but also other\ntypes of spatial data, such as e.g. sound source directivity, microphone\ndirectivity, etc.",
    "descriptor": "\nComments: Not submitted anywhere in the current form\n",
    "authors": [
      "Adam Szwajcowski"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2206.12283"
  },
  {
    "id": "arXiv:2206.12285",
    "title": "Speech Quality Assessment through MOS using Non-Matching References",
    "abstract": "Human judgments obtained through Mean Opinion Scores (MOS) are the most\nreliable way to assess the quality of speech signals. However, several recent\nattempts to automatically estimate MOS using deep learning approaches lack\nrobustness and generalization capabilities, limiting their use in real-world\napplications. In this work, we present a novel framework, NORESQA-MOS, for\nestimating the MOS of a speech signal. Unlike prior works, our approach uses\nnon-matching references as a form of conditioning to ground the MOS estimation\nby neural networks. We show that NORESQA-MOS provides better generalization and\nmore robust MOS estimation than previous state-of-the-art methods such as\nDNSMOS and NISQA, even though we use a smaller training set. Moreover, we also\nshow that our generic framework can be combined with other learning methods\nsuch as self-supervised learning and can further supplement the benefits from\nthese methods.",
    "descriptor": "\nComments: To Appear, Interspeech 2022\n",
    "authors": [
      "Pranay Manocha",
      "Anurag Kumar"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2206.12285"
  },
  {
    "id": "arXiv:2206.12288",
    "title": "Optimiziation of Geometric Constellation Shaping for Wiener Phase Noise  Channels with Varying Channel Parameters",
    "abstract": "We present a novel method to investigate the effects of varying channel\nparameters on geometrically shaped constellations for communication systems\nemploying the blind phase search algorithm. We show that introduced asymmetries\nsignificantly improve performance if adapted to changing channel parameters.",
    "descriptor": "\nComments: Accepted to be presented at ECOC 2022\n",
    "authors": [
      "Andrej Rode",
      "Laurent Schmalen"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.12288"
  },
  {
    "id": "arXiv:2206.12297",
    "title": "SAQAM: Spatial Audio Quality Assessment Metric",
    "abstract": "Audio quality assessment is critical for assessing the perceptual realism of\nsounds. However, the time and expense of obtaining ''gold standard'' human\njudgments limit the availability of such data. For AR&VR, good perceived sound\nquality and localizability of sources are among the key elements to ensure\ncomplete immersion of the user. Our work introduces SAQAM which uses a\nmulti-task learning framework to assess listening quality (LQ) and\nspatialization quality (SQ) between any given pair of binaural signals without\nusing any subjective data. We model LQ by training on a simulated dataset of\ntriplet human judgments, and SQ by utilizing activation-level distances from\nnetworks trained for direction of arrival (DOA) estimation. We show that SAQAM\ncorrelates well with human responses across four diverse datasets. Since it is\na deep network, the metric is differentiable, making it suitable as a loss\nfunction for other tasks. For example, simply replacing an existing loss with\nour metric yields improvement in a speech-enhancement network.",
    "descriptor": "\nComments: To Appear, Interspeech 2022\n",
    "authors": [
      "Pranay Manocha",
      "Anurag Kumar",
      "Buye Xu",
      "Anjali Menon",
      "Israel D. Gebru",
      "Vamsi K. Ithapu",
      "Paul Calamia"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2206.12297"
  },
  {
    "id": "arXiv:2206.12300",
    "title": "Automatic extraction of coronary arteries using deep learning in  invasive coronary angiograms",
    "abstract": "Accurate extraction of coronary arteries from invasive coronary angiography\n(ICA) is important in clinical decision-making for the diagnosis and risk\nstratification of coronary artery disease (CAD). In this study, we develop a\nmethod using deep learning to automatically extract the coronary artery lumen.\nMethods. A deep learning model U-Net 3+, which incorporates the full-scale skip\nconnections and deep supervisions, was proposed for automatic extraction of\ncoronary arteries from ICAs. Transfer learning and a hybrid loss function were\nemployed in this novel coronary artery extraction framework. Results. A data\nset containing 616 ICAs obtained from 210 patients was used. In the technical\nevaluation, the U-Net 3+ achieved a Dice score of 0.8942 and a sensitivity of\n0.8735, which is higher than U-Net ++ (Dice score: 0.8814, the sensitivity of\n0.8331) and U-net (Dice score: 0.8799, the sensitivity of 0.8305). Conclusion.\nOur study demonstrates that the U-Net 3+ is superior to other segmentation\nframeworks for the automatic extraction of the coronary arteries from ICAs.\nThis result suggests great promise for clinical use.",
    "descriptor": "\nComments: 22 pages,5 figures\n",
    "authors": [
      "Yinghui Meng",
      "Zhenglong Du",
      "Chen Zhao",
      "Minghao Dong",
      "Drew Pienta",
      "Zhihui Xu",
      "Weihua Zhou"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.12300"
  },
  {
    "id": "arXiv:2206.12309",
    "title": "Analyzing the impact of SARS-CoV-2 variants on respiratory sound signals",
    "abstract": "The COVID-19 outbreak resulted in multiple waves of infections that have been\nassociated with different SARS-CoV-2 variants. Studies have reported\ndifferential impact of the variants on respiratory health of patients. We\nexplore whether acoustic signals, collected from COVID-19 subjects, show\ncomputationally distinguishable acoustic patterns suggesting a possibility to\npredict the underlying virus variant. We analyze the Coswara dataset which is\ncollected from three subject pools, namely, i) healthy, ii) COVID-19 subjects\nrecorded during the delta variant dominant period, and iii) data from COVID-19\nsubjects recorded during the omicron surge. Our findings suggest that multiple\nsound categories, such as cough, breathing, and speech, indicate significant\nacoustic feature differences when comparing COVID-19 subjects with omicron and\ndelta variants. The classification areas-under-the-curve are significantly\nabove chance for differentiating subjects infected by omicron from those\ninfected by delta. Using a score fusion from multiple sound categories, we\nobtained an area-under-the-curve of 89% and 52.4% sensitivity at 95%\nspecificity. Additionally, a hierarchical three class approach was used to\nclassify the acoustic data into healthy and COVID-19 positive, and further\nCOVID-19 subjects into delta and omicron variants providing high level of\n3-class classification accuracy. These results suggest new ways for designing\nsound based COVID-19 diagnosis approaches.",
    "descriptor": "",
    "authors": [
      "Debarpan Bhattacharya",
      "Debottam Dutta",
      "Neeraj Kumar Sharma",
      "Srikanth Raj Chetupalli",
      "Pravin Mote",
      "Sriram Ganapathy",
      "Chandrakiran C",
      "Sahiti Nori",
      "Suhail K K",
      "Sadhana Gonuguntla",
      "Murali Alagesan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.12309"
  },
  {
    "id": "arXiv:2206.12314",
    "title": "Learning sparse features can lead to overfitting in neural networks",
    "abstract": "It is widely believed that the success of deep networks lies in their ability\nto learn a meaningful representation of the features of the data. Yet,\nunderstanding when and how this feature learning improves performance remains a\nchallenge: for example, it is beneficial for modern architectures trained to\nclassify images, whereas it is detrimental for fully-connected networks trained\nfor the same task on the same data. Here we propose an explanation for this\npuzzle, by showing that feature learning can perform worse than lazy training\n(via random feature kernel or the NTK) as the former can lead to a sparser\nneural representation. Although sparsity is known to be essential for learning\nanisotropic data, it is detrimental when the target function is constant or\nsmooth along certain directions of input space. We illustrate this phenomenon\nin two settings: (i) regression of Gaussian random functions on the\nd-dimensional unit sphere and (ii) classification of benchmark datasets of\nimages. For (i), we compute the scaling of the generalization error with number\nof training points, and show that methods that do not learn features generalize\nbetter, even when the dimension of the input space is large. For (ii), we show\nempirically that learning features can indeed lead to sparse and thereby less\nsmooth representations of the image predictors. This fact is plausibly\nresponsible for deteriorating the performance, which is known to be correlated\nwith smoothness along diffeomorphisms.",
    "descriptor": "",
    "authors": [
      "Leonardo Petrini",
      "Francesco Cagnetta",
      "Eric Vanden-Eijnden",
      "Matthieu Wyart"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.12314"
  },
  {
    "id": "arXiv:2206.12333",
    "title": "Achievement and Fragility of Long-term Equitability",
    "abstract": "Equipping current decision-making tools with notions of fairness,\nequitability, or other ethically motivated outcomes, is one of the top\npriorities in recent research efforts in machine learning, AI, and\noptimization. In this paper, we investigate how to allocate limited resources\nto {locally interacting} communities in a way to maximize a pertinent notion of\nequitability. In particular, we look at the dynamic setting where the\nallocation is repeated across multiple periods (e.g., yearly), the local\ncommunities evolve in the meantime (driven by the provided allocation), and the\nallocations are modulated by feedback coming from the communities themselves.\nWe employ recent mathematical tools stemming from data-driven feedback online\noptimization, by which communities can learn their (possibly unknown)\nevolution, satisfaction, as well as they can share information with the\ndeciding bodies. We design dynamic policies that converge to an allocation that\nmaximize equitability in the long term. We further demonstrate our model and\nmethodology with realistic examples of healthcare and education subsidies\ndesign in Sub-Saharian countries. One of the key empirical takeaways from our\nsetting is that long-term equitability is fragile, in the sense that it can be\neasily lost when deciding bodies weigh in other factors (e.g., equality in\nallocation) in the allocation strategy. Moreover, a naive compromise, while not\nproviding significant advantage to the communities, can promote inequality in\nsocial outcomes.",
    "descriptor": "\nComments: 12 pages, 7 figures\n",
    "authors": [
      "Andrea Simonetto",
      "Ivano Notarnicola"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.12333"
  },
  {
    "id": "arXiv:2206.12344",
    "title": "Segmentation-free PVC for Cardiac SPECT using a Densely-connected  Multi-dimensional Dynamic Network",
    "abstract": "In nuclear imaging, limited resolution causes partial volume effects (PVEs)\nthat affect image sharpness and quantitative accuracy. Partial volume\ncorrection (PVC) methods incorporating high-resolution anatomical information\nfrom CT or MRI have been demonstrated to be effective. However, such\nanatomical-guided methods typically require tedious image registration and\nsegmentation steps. Accurately segmented organ templates are also hard to\nobtain, particularly in cardiac SPECT imaging, due to the lack of hybrid\nSPECT/CT scanners with high-end CT and associated motion artifacts. Slight\nmis-registration/mis-segmentation would result in severe degradation in image\nquality after PVC. In this work, we develop a deep-learning-based method for\nfast cardiac SPECT PVC without anatomical information and associated organ\nsegmentation. The proposed network involves a densely-connected\nmulti-dimensional dynamic mechanism, allowing the convolutional kernels to be\nadapted based on the input images, even after the network is fully trained.\nIntramyocardial blood volume (IMBV) is introduced as an additional\nclinical-relevant loss function for network optimization. The proposed network\ndemonstrated promising performance on 28 canine studies acquired on a GE\nDiscovery NM/CT 570c dedicated cardiac SPECT scanner with a 64-slice CT using\nTechnetium-99m-labeled red blood cells. This work showed that the proposed\nnetwork with densely-connected dynamic mechanism produced superior results\ncompared with the same network without such mechanism. Results also showed that\nthe proposed network without anatomical information could produce images with\nstatistically comparable IMBV measurements to the images generated by\nanatomical-guided PVC methods, which could be helpful in clinical translation.",
    "descriptor": "\nComments: 10 pages, 7 figures\n",
    "authors": [
      "Huidong Xie",
      "Zhao Liu",
      "Luyao Shi",
      "Kathleen Greco",
      "Xiongchao Chen",
      "Bo Zhou",
      "Attila Feher",
      "John C. Stendahl",
      "Nabil Boutagy",
      "Tassos C. Kyriakides",
      "Ge Wang",
      "Albert J. Sinusas",
      "Chi Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.12344"
  },
  {
    "id": "arXiv:2206.12353",
    "title": "Quantifying Inherent Randomness in Machine Learning Algorithms",
    "abstract": "Most machine learning (ML) algorithms have several stochastic elements, and\ntheir performances are affected by these sources of randomness. This paper uses\nan empirical study to systematically examine the effects of two sources:\nrandomness in model training and randomness in the partitioning of a dataset\ninto training and test subsets. We quantify and compare the magnitude of the\nvariation in predictive performance for the following ML algorithms: Random\nForests (RFs), Gradient Boosting Machines (GBMs), and Feedforward Neural\nNetworks (FFNNs). Among the different algorithms, randomness in model training\ncauses larger variation for FFNNs compared to tree-based methods. This is to be\nexpected as FFNNs have more stochastic elements that are part of their model\ninitialization and training. We also found that random splitting of datasets\nleads to higher variation compared to the inherent randomness from model\ntraining. The variation from data splitting can be a major issue if the\noriginal dataset has considerable heterogeneity.\nKeywords: Model Training, Reproducibility, Variation",
    "descriptor": "\nComments: 14 pages, 4 Figures, 5 tables\n",
    "authors": [
      "Soham Raste",
      "Rahul Singh",
      "Joel Vaughan",
      "Vijayan N. Nair"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.12353"
  },
  {
    "id": "arXiv:2206.12363",
    "title": "From Tensor Network Quantum States to Tensorial Recurrent Neural  Networks",
    "abstract": "We show that any matrix product state (MPS) can be exactly represented by a\nrecurrent neural network (RNN) with a linear memory update. We generalize this\nRNN architecture to 2D lattices using a multilinear memory update. It supports\nperfect sampling and wave function evaluation in polynomial time, and can\nrepresent an area law of entanglement entropy. Numerical evidence shows that it\ncan encode the wave function using a bond dimension lower by orders of\nmagnitude when compared to MPS, with an accuracy that can be systematically\nimproved by increasing the bond dimension.",
    "descriptor": "\nComments: 12 pages, 9 figures\n",
    "authors": [
      "Dian Wu",
      "Riccardo Rossi",
      "Filippo Vicentini",
      "Giuseppe Carleo"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Strongly Correlated Electrons (cond-mat.str-el)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.12363"
  },
  {
    "id": "arXiv:2206.12378",
    "title": "A transient equivalence between Aldous-Broder and Wilson's algorithms  and a two-stage framework for generating uniform spanning trees",
    "abstract": "The $Aldous\\text{-}Broder$ and $Wilson$ are two well-known algorithms to\ngenerate uniform spanning trees (USTs) based on random walks. This work studies\ntheir relationship while they construct random trees with the goal of reducing\nthe total time required to build the spanning tree. Using the notion of\n$branches$ $-$ paths generated by the two algorithms on particular stopping\ntimes, we show that the trees built by the two algorithms when running on a\ncomplete graph are statistically equivalent on these stopping times. This leads\nto a hybrid algorithm that can generate uniform spanning trees of complete\ngraphs faster than either of the two algorithms. An efficient two-stage\nframework is also proposed to explore this hybrid approach beyond complete\ngraphs, showing its feasibility in various examples, including transitive\ngraphs where it requires 25% less time than $Wilson$ to generate a UST.",
    "descriptor": "",
    "authors": [
      "Igor Nunes",
      "Giulio Iacobelli",
      "Daniel Ratton Figueiredo"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2206.12378"
  },
  {
    "id": "arXiv:2206.12402",
    "title": "Predicting the Stability of Hierarchical Triple Systems with  Convolutional Neural Networks",
    "abstract": "Understanding the long-term evolution of hierarchical triple systems is\nchallenging due to its inherent chaotic nature, and it requires computationally\nexpensive simulations. Here we propose a convolutional neural network model to\npredict the stability of hierarchical triples by looking at their evolution\nduring the first $5 \\times 10^5$ inner binary orbits. We employ the regularized\nfew-body code \\textsc{tsunami} to simulate $5\\times 10^6$ hierarchical triples,\nfrom which we generate a large training and test dataset. We develop twelve\ndifferent network configurations that use different combinations of the\ntriples' orbital elements and compare their performances. Our best model uses 6\ntime-series, namely, the semimajor axes ratio, the inner and outer\neccentricities, the mutual inclination and the arguments of pericenter. This\nmodel achieves an area under the curve of over $95\\%$ and informs of the\nrelevant parameters to study triple systems stability. All trained models are\nmade publicly available, allowing to predict the stability of hierarchical\ntriple systems $200$ times faster than pure $N$-body methods.",
    "descriptor": "\nComments: 10 pages, 6 figures, submitted to ApJ\n",
    "authors": [
      "Florian Lalande",
      "Alessandro Alberto Trani"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.12402"
  },
  {
    "id": "arXiv:1710.04353",
    "title": "One Password: An Encryption Scheme for Hiding Users' Register  Information",
    "abstract": "Comments: The method has not been tested in practice",
    "descriptor": "\nComments: The method has not been tested in practice\n",
    "authors": [
      "Bo Zhao",
      "Yu Zhou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/1710.04353"
  },
  {
    "id": "arXiv:1909.02102",
    "title": "Accelerated Information Gradient flow",
    "abstract": "Accelerated Information Gradient flow",
    "descriptor": "",
    "authors": [
      "Yifei Wang",
      "Wuchen Li"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Information Theory (cs.IT)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1909.02102"
  },
  {
    "id": "arXiv:1911.05999",
    "title": "Simplified and Unified Analysis of Various Learning Problems by  Reduction to Multiple-Instance Learning",
    "abstract": "Comments: Accepted at UAI2022",
    "descriptor": "\nComments: Accepted at UAI2022\n",
    "authors": [
      "Daiki Suehiro",
      "Eiji Takimoto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1911.05999"
  },
  {
    "id": "arXiv:1912.06845",
    "title": "Empirical and Instance-Dependent Estimation of Markov Chain and Mixing  Time",
    "abstract": "Comments: Full-length journal version; contains elements taken from extended abstract presented at the conference ALT'20",
    "descriptor": "\nComments: Full-length journal version; contains elements taken from extended abstract presented at the conference ALT'20\n",
    "authors": [
      "Geoffrey Wolfer"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1912.06845"
  },
  {
    "id": "arXiv:2002.05096",
    "title": "Regret Bounds for Noise-Free Kernel-Based Bandits",
    "abstract": "Comments: Conference on Learning Theory (COLT) 2022",
    "descriptor": "\nComments: Conference on Learning Theory (COLT) 2022\n",
    "authors": [
      "Sattar Vakili"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2002.05096"
  },
  {
    "id": "arXiv:2008.01459",
    "title": "Channel Estimation for RIS-Empowered Multi-User MISO Wireless  Communications",
    "abstract": "Channel Estimation for RIS-Empowered Multi-User MISO Wireless  Communications",
    "descriptor": "",
    "authors": [
      "Li Wei",
      "Chongwen Huang",
      "George C. Alexandropoulos",
      "Chau Yuen",
      "Zhaoyang Zhang",
      "M\u00e9rouane Debbah"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2008.01459"
  },
  {
    "id": "arXiv:2008.03901",
    "title": "RARTS: An Efficient First-Order Relaxed Architecture Search Method",
    "abstract": "RARTS: An Efficient First-Order Relaxed Architecture Search Method",
    "descriptor": "",
    "authors": [
      "Fanghui Xue",
      "Yingyong Qi",
      "Jack Xin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2008.03901"
  },
  {
    "id": "arXiv:2009.05131",
    "title": "Intelligent Ranking for Dynamic Restoration in Next Generation Wireless  Networks",
    "abstract": "Comments: Further research evaluation is required",
    "descriptor": "\nComments: Further research evaluation is required\n",
    "authors": [
      "Navrati Saxena",
      "Prasham Jain",
      "Abhishek Roy",
      "Harman Jit Singh",
      "Sukhdeep Singh",
      "Madhan Raj Kanagarathinam"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2009.05131"
  },
  {
    "id": "arXiv:2009.13678",
    "title": "Noise Variance Estimation Using Asymptotic Residual in Compressed  Sensing",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Ryo Hayakawa"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2009.13678"
  },
  {
    "id": "arXiv:2010.01319",
    "title": "Deep learning algorithms for solving high dimensional nonlinear backward  stochastic differential equations",
    "abstract": "Comments: 28 pages, 16 figures, 10 tables",
    "descriptor": "\nComments: 28 pages, 16 figures, 10 tables\n",
    "authors": [
      "Lorenc Kapllani",
      "Long Teng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Computational Finance (q-fin.CP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.01319"
  },
  {
    "id": "arXiv:2010.08436",
    "title": "An Accurate Low-Order Discretization Scheme for the Identity Operator in  the Magnetic Field and Combined Field Integral Equations",
    "abstract": "Comments: 12 pages, 19 figures, published in IEEE Transactions on Antennas and Propagation",
    "descriptor": "\nComments: 12 pages, 19 figures, published in IEEE Transactions on Antennas and Propagation\n",
    "authors": [
      "Jonas Kornprobst",
      "Thomas F. Eibert"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2010.08436"
  },
  {
    "id": "arXiv:2010.08757",
    "title": "A Weak-Form Combined Source Integral Equation with Explicit Inversion of  the Combined-Source Condition",
    "abstract": "Comments: 5 pages, 8 figures, published in IEEE Antennas and Wireless Propagation Letters",
    "descriptor": "\nComments: 5 pages, 8 figures, published in IEEE Antennas and Wireless Propagation Letters\n",
    "authors": [
      "Jonas Kornprobst",
      "Thomas F. Eibert"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2010.08757"
  },
  {
    "id": "arXiv:2010.08797",
    "title": "A Combined Source Integral Equation with Weak Form Combined Source  Condition",
    "abstract": "Comments: 5 pages, 8 figures, published in IEEE Transactions on Antennas and Propagation, includes fixes to a missing superscript in (5) and a sign error in (8)",
    "descriptor": "\nComments: 5 pages, 8 figures, published in IEEE Transactions on Antennas and Propagation, includes fixes to a missing superscript in (5) and a sign error in (8)\n",
    "authors": [
      "Jonas Kornprobst",
      "Thomas F. Eibert"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2010.08797"
  },
  {
    "id": "arXiv:2010.15921",
    "title": "A Spatio-temporal Track Association Algorithm Based on Marine Vessel  Automatic Identification System Data",
    "abstract": "A Spatio-temporal Track Association Algorithm Based on Marine Vessel  Automatic Identification System Data",
    "descriptor": "",
    "authors": [
      "Imtiaz Ahmed",
      "Mikyoung Jun",
      "Yu Ding"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.15921"
  },
  {
    "id": "arXiv:2011.06987",
    "title": "Multilevel Representations of Isotropic Gaussian Random Fields on the  Sphere",
    "abstract": "Multilevel Representations of Isotropic Gaussian Random Fields on the  Sphere",
    "descriptor": "",
    "authors": [
      "Markus Bachmayr",
      "Ana Djurdjevac"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2011.06987"
  },
  {
    "id": "arXiv:2101.12602",
    "title": "On the differential privacy of dynamic location obfuscation with  personalized error bounds",
    "abstract": "Comments: 5 pages, 7 figures",
    "descriptor": "\nComments: 5 pages, 7 figures\n",
    "authors": [
      "Zhang Shun",
      "Duan Benfei",
      "Chen Zhili",
      "Zhong Hong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2101.12602"
  },
  {
    "id": "arXiv:2102.05433",
    "title": "A Framework of Inertial Alternating Direction Method of Multipliers for  Non-Convex Non-Smooth Optimization",
    "abstract": "Comments: 35 pages, several parts of the paper clarified, additional experiments on a regularized NMF problem",
    "descriptor": "\nComments: 35 pages, several parts of the paper clarified, additional experiments on a regularized NMF problem\n",
    "authors": [
      "Le Thi Khanh Hien",
      "Duy Nhat Phan",
      "Nicolas Gillis"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2102.05433"
  },
  {
    "id": "arXiv:2106.03527",
    "title": "Multi-Exit Semantic Segmentation Networks",
    "abstract": "Multi-Exit Semantic Segmentation Networks",
    "descriptor": "",
    "authors": [
      "Alexandros Kouris",
      "Stylianos I. Venieris",
      "Stefanos Laskaridis",
      "Nicholas D. Lane"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.03527"
  },
  {
    "id": "arXiv:2106.10944",
    "title": "Hard hat wearing detection based on head keypoint localization",
    "abstract": "Comments: 17 pages, 9 figures and 9 tables",
    "descriptor": "\nComments: 17 pages, 9 figures and 9 tables\n",
    "authors": [
      "Bartosz W\u00f3jcik",
      "Mateusz \u017barski",
      "Kamil Ksi\u0105\u017cek",
      "Jaros\u0142aw Adam Miszczak",
      "Miros\u0142aw Jan Skibniewski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.10944"
  },
  {
    "id": "arXiv:2107.09008",
    "title": "Harmonizing the Cacophony with MIC: An Affordance-aware Framework for  Platform Moderation",
    "abstract": "Comments: 21 pages, 5 figures",
    "descriptor": "\nComments: 21 pages, 5 figures\n",
    "authors": [
      "Tanvi Bajpai",
      "Drshika Asher",
      "Anwesa Goswami",
      "Eshwar Chandrasekharan"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2107.09008"
  },
  {
    "id": "arXiv:2107.12889",
    "title": "Improved-Mask R-CNN: Towards an Accurate Generic MSK MRI instance  segmentation platform (Data from the Osteoarthritis Initiative)",
    "abstract": "Improved-Mask R-CNN: Towards an Accurate Generic MSK MRI instance  segmentation platform (Data from the Osteoarthritis Initiative)",
    "descriptor": "",
    "authors": [
      "Banafshe Felfeliyan",
      "Abhilash Hareendranathan",
      "Gregor Kuntze",
      "Jacob L. Jaremko",
      "Janet L. Ronsky"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.12889"
  },
  {
    "id": "arXiv:2108.02161",
    "title": "Localized Shape Modelling with Global Coherence: An Inverse Spectral  Approach",
    "abstract": "Comments: Accepted at SGP2022",
    "descriptor": "\nComments: Accepted at SGP2022\n",
    "authors": [
      "Marco Pegoraro",
      "Simone Melzi",
      "Umberto Castellani",
      "Riccardo Marin",
      "Emanuele Rodol\u00e0"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.02161"
  },
  {
    "id": "arXiv:2108.02299",
    "title": "Exploring D3 Implementation Challenges on Stack Overflow",
    "abstract": "Comments: Accepted as a short paper to IEEE VIS 2022",
    "descriptor": "\nComments: Accepted as a short paper to IEEE VIS 2022\n",
    "authors": [
      "Leilani Battle",
      "Danni Feng",
      "Kelli Webber"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2108.02299"
  },
  {
    "id": "arXiv:2108.02316",
    "title": "Deep Stable neural networks: large-width asymptotics and convergence  rates",
    "abstract": "Comments: Improve the proof of the main result in arXiv:2003.00394, and study convergence rates",
    "descriptor": "\nComments: Improve the proof of the main result in arXiv:2003.00394, and study convergence rates\n",
    "authors": [
      "Stefano Favaro",
      "Sandra Fortini",
      "Stefano Peluchetti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2108.02316"
  },
  {
    "id": "arXiv:2108.05075",
    "title": "Turning Your Strength against You: Detecting and Mitigating Robust and  Universal Adversarial Patch Attacks",
    "abstract": "Turning Your Strength against You: Detecting and Mitigating Robust and  Universal Adversarial Patch Attacks",
    "descriptor": "",
    "authors": [
      "Zitao Chen",
      "Pritam Dash",
      "Karthik Pattabiraman"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.05075"
  },
  {
    "id": "arXiv:2108.11571",
    "title": "GNNSampler: Bridging the Gap between Sampling Algorithms of GNN and  Hardware",
    "abstract": "Comments: Accepted by ECML-PKDD 2022",
    "descriptor": "\nComments: Accepted by ECML-PKDD 2022\n",
    "authors": [
      "Xin Liu",
      "Mingyu Yan",
      "Shuhan Song",
      "Zhengyang Lv",
      "Wenming Li",
      "Guangyu Sun",
      "Xiaochun Ye",
      "Dongrui Fan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.11571"
  },
  {
    "id": "arXiv:2108.11801",
    "title": "Unsupervised domain adaptation for clinician pose estimation and  instance segmentationin the operating room",
    "abstract": "Comments: Accepted at Elsevier Journal of Medical Image Analysis. Code is available at this https URL Supplementary video is available at this https URL",
    "descriptor": "\nComments: Accepted at Elsevier Journal of Medical Image Analysis. Code is available at this https URL Supplementary video is available at this https URL\n",
    "authors": [
      "Vinkle Srivastav",
      "Afshin Gangi",
      "Nicolas Padoy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.11801"
  },
  {
    "id": "arXiv:2109.01411",
    "title": "An Exploratory Study on Utilising the Web of Linked Data for Product  Data Mining",
    "abstract": "An Exploratory Study on Utilising the Web of Linked Data for Product  Data Mining",
    "descriptor": "",
    "authors": [
      "Ziqi Zhang",
      "Xingyi Song"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.01411"
  },
  {
    "id": "arXiv:2109.02351",
    "title": "F3: Fair and Federated Face Attribute Classification with Heterogeneous  Data",
    "abstract": "Comments: This paper is accepted as 2-page extended abstract at CODS-COMAD 2022 with title \"Fair Federated Learning for Heterogeneous Face Data\"",
    "descriptor": "\nComments: This paper is accepted as 2-page extended abstract at CODS-COMAD 2022 with title \"Fair Federated Learning for Heterogeneous Face Data\"\n",
    "authors": [
      "Samhita Kanaparthy",
      "Manisha Padala",
      "Sankarshan Damle",
      "Ravi Kiran Sarvadevabhatla",
      "Sujit Gujar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2109.02351"
  },
  {
    "id": "arXiv:2109.13069",
    "title": "Cluster Attack: Query-based Adversarial Attacks on Graphs with  Graph-Dependent Priors",
    "abstract": "Comments: IJCAI 2022 (Long Presentation)",
    "descriptor": "\nComments: IJCAI 2022 (Long Presentation)\n",
    "authors": [
      "Zhengyi Wang",
      "Zhongkai Hao",
      "Ziqiao Wang",
      "Hang Su",
      "Jun Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.13069"
  },
  {
    "id": "arXiv:2109.13714",
    "title": "MSR-NV: Neural Vocoder Using Multiple Sampling Rates",
    "abstract": "Comments: 6 pages including supplement, 3 figures, accepted for INTERSPEECH 2022. Audio samples: this https URL",
    "descriptor": "\nComments: 6 pages including supplement, 3 figures, accepted for INTERSPEECH 2022. Audio samples: this https URL\n",
    "authors": [
      "Kentaro Mitsui",
      "Kei Sawada"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2109.13714"
  },
  {
    "id": "arXiv:2109.14764",
    "title": "Gaps, Ambiguity, and Establishing Complexity-Class Containments via  Iterative Constant-Setting",
    "abstract": "Gaps, Ambiguity, and Establishing Complexity-Class Containments via  Iterative Constant-Setting",
    "descriptor": "",
    "authors": [
      "Lane A. Hemaspaandra",
      "Mandar Juvekar",
      "Arian Nadjimzadah",
      "Patrick A. Phillips"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2109.14764"
  },
  {
    "id": "arXiv:2110.06199",
    "title": "ABO: Dataset and Benchmarks for Real-World 3D Object Understanding",
    "abstract": "ABO: Dataset and Benchmarks for Real-World 3D Object Understanding",
    "descriptor": "",
    "authors": [
      "Jasmine Collins",
      "Shubham Goel",
      "Kenan Deng",
      "Achleshwar Luthra",
      "Leon Xu",
      "Erhan Gundogdu",
      "Xi Zhang",
      "Tomas F. Yago Vicente",
      "Thomas Dideriksen",
      "Himanshu Arora",
      "Matthieu Guillaumin",
      "Jitendra Malik"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2110.06199"
  },
  {
    "id": "arXiv:2110.06482",
    "title": "Parallel Deep Neural Networks Have Zero Duality Gap",
    "abstract": "Parallel Deep Neural Networks Have Zero Duality Gap",
    "descriptor": "",
    "authors": [
      "Yifei Wang",
      "Tolga Ergen",
      "Mert Pilanci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.06482"
  },
  {
    "id": "arXiv:2110.06840",
    "title": "Straddling-gates problem in multipartite quantum systems",
    "abstract": "Comments: 6 pages, 2 figures",
    "descriptor": "\nComments: 6 pages, 2 figures\n",
    "authors": [
      "Yuxuan Zhang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2110.06840"
  },
  {
    "id": "arXiv:2110.07468",
    "title": "SingGAN: Generative Adversarial Network For High-Fidelity Singing Voice  Generation",
    "abstract": "Comments: singing voice synthesis, vocoder, generative adversarial network",
    "descriptor": "\nComments: singing voice synthesis, vocoder, generative adversarial network\n",
    "authors": [
      "Rongjie Huang",
      "Chenye Cui",
      "Feiyang Chen",
      "Yi Ren",
      "Jinglin Liu",
      "Zhou Zhao",
      "Baoxing Huai",
      "Zhefeng Wang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.07468"
  },
  {
    "id": "arXiv:2110.09698",
    "title": "Neural Lexicon Reader: Reduce Pronunciation Errors in End-to-end TTS by  Leveraging External Textual Knowledge",
    "abstract": "Comments: 5 pages, 3 figures; accepted by Interspeech 2022",
    "descriptor": "\nComments: 5 pages, 3 figures; accepted by Interspeech 2022\n",
    "authors": [
      "Mutian He",
      "Jingzhou Yang",
      "Lei He",
      "Frank K. Soong"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.09698"
  },
  {
    "id": "arXiv:2110.10090",
    "title": "Inductive Biases and Variable Creation in Self-Attention Mechanisms",
    "abstract": "Comments: v2: camera-ready revisions for ICML 2022",
    "descriptor": "\nComments: v2: camera-ready revisions for ICML 2022\n",
    "authors": [
      "Benjamin L. Edelman",
      "Surbhi Goel",
      "Sham Kakade",
      "Cyril Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.10090"
  },
  {
    "id": "arXiv:2110.12177",
    "title": "Vertebrae localization, segmentation and identification using a graph  optimization and an anatomic consistency cycle",
    "abstract": "Vertebrae localization, segmentation and identification using a graph  optimization and an anatomic consistency cycle",
    "descriptor": "",
    "authors": [
      "Di Meng",
      "Edmond Boyer",
      "Sergi Pujades"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12177"
  },
  {
    "id": "arXiv:2110.13290",
    "title": "Exploring System Performance of Continual Learning for Mobile and  Embedded Sensing Applications",
    "abstract": "Comments: Accepted for publication at SEC 2021",
    "descriptor": "\nComments: Accepted for publication at SEC 2021\n",
    "authors": [
      "Young D. Kwon",
      "Jagmohan Chauhan",
      "Abhishek Kumar",
      "Pan Hui",
      "Cecilia Mascolo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2110.13290"
  },
  {
    "id": "arXiv:2111.06172",
    "title": "What was Hybrid? A Systematic Review of Hybrid Collaboration and  Meetings Research",
    "abstract": "What was Hybrid? A Systematic Review of Hybrid Collaboration and  Meetings Research",
    "descriptor": "",
    "authors": [
      "Thomas Neumayr",
      "Banu Saatci",
      "Sean Rintel",
      "Clemens Nylandsted Klokmose",
      "Mirjam Augstein"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2111.06172"
  },
  {
    "id": "arXiv:2111.10699",
    "title": "Correlation Clustering via Strong Triadic Closure Labeling: Fast  Approximation Algorithms and Practical Lower Bounds",
    "abstract": "Comments: ICML 2022",
    "descriptor": "\nComments: ICML 2022\n",
    "authors": [
      "Nate Veldt"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2111.10699"
  },
  {
    "id": "arXiv:2111.12295",
    "title": "Animal Behavior Classification via Deep Learning on Embedded Systems",
    "abstract": "Animal Behavior Classification via Deep Learning on Embedded Systems",
    "descriptor": "",
    "authors": [
      "Reza Arablouei",
      "Liang Wang",
      "Lachlan Currie",
      "Jordan Yates",
      "Flavio A. P. Alvarenga",
      "Greg J. Bishop-Hurley"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.12295"
  },
  {
    "id": "arXiv:2111.13803",
    "title": "Low-Latency Online Speaker Diarization with Graph-Based Label Generation",
    "abstract": "Comments: accepted by Odyssey 2022",
    "descriptor": "\nComments: accepted by Odyssey 2022\n",
    "authors": [
      "Yucong Zhang",
      "Qinjian Lin",
      "Weiqing Wang",
      "Lin Yang",
      "Xuyang Wang",
      "Junjie Wang",
      "Ming Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2111.13803"
  },
  {
    "id": "arXiv:2111.14625",
    "title": "Cyclic Graph Attentive Match Encoder (CGAME): A Novel Neural Network For  OD Estimation",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Guanzhou Li",
      "Yujing He",
      "Jianping Wu",
      "Duowei Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.14625"
  },
  {
    "id": "arXiv:2112.08581",
    "title": "Mathematical Runtime Analysis for the Non-Dominated Sorting Genetic  Algorithm II (NSGA-II)",
    "abstract": "Comments: This is the journal version of the paper \"Weijie Zheng, Yufei Liu, Benjamin Doerr: A First Mathematical Runtime Analysis of the Non-Dominated Sorting Genetic Algorithm II (NSGA-II). AAAI 2022. arXiv:2112.08581v3\"",
    "descriptor": "\nComments: This is the journal version of the paper \"Weijie Zheng, Yufei Liu, Benjamin Doerr: A First Mathematical Runtime Analysis of the Non-Dominated Sorting Genetic Algorithm II (NSGA-II). AAAI 2022. arXiv:2112.08581v3\"\n",
    "authors": [
      "Weijie Zheng",
      "Benjamin Doerr"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08581"
  },
  {
    "id": "arXiv:2112.11461",
    "title": "Deep Reinforcement Learning for Optimal Power Flow with Renewables Using  Graph Information",
    "abstract": "Comments: 6 pages, 7 figures",
    "descriptor": "\nComments: 6 pages, 7 figures\n",
    "authors": [
      "Jinhao Li",
      "Ruichang Zhang",
      "Hao Wang",
      "Zhi Liu",
      "Hongyang Lai",
      "Yanru Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.11461"
  },
  {
    "id": "arXiv:2201.00723",
    "title": "A Mixed-Integer Programming Approach to Training Dense Neural Networks",
    "abstract": "Comments: 25 pages",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Vrishabh Patil",
      "Yonatan Mintz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2201.00723"
  },
  {
    "id": "arXiv:2201.01389",
    "title": "Semantic Communications: Principles and Challenges",
    "abstract": "Semantic Communications: Principles and Challenges",
    "descriptor": "",
    "authors": [
      "Zhijin Qin",
      "Xiaoming Tao",
      "Jiahua Lu",
      "Wen Tong",
      "Geoffrey Ye Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2201.01389"
  },
  {
    "id": "arXiv:2201.13078",
    "title": "Lymphoma segmentation from 3D PET-CT images using a deep evidential  network",
    "abstract": "Comments: Preprint submitted to International Journal of Approximate Reasoning",
    "descriptor": "\nComments: Preprint submitted to International Journal of Approximate Reasoning\n",
    "authors": [
      "Ling Huang",
      "Su Ruan",
      "Pierre Decazes",
      "Thierry Denoeux"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.13078"
  },
  {
    "id": "arXiv:2202.00397",
    "title": "Efficient computation of the Wright function and its applications to  fractional diffusion-wave equations",
    "abstract": "Efficient computation of the Wright function and its applications to  fractional diffusion-wave equations",
    "descriptor": "",
    "authors": [
      "Lidia Aceto",
      "Fabio Durastante"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.00397"
  },
  {
    "id": "arXiv:2202.01832",
    "title": "Adversarially Robust Models may not Transfer Better: Sufficient  Conditions for Domain Transferability from the View of Regularization",
    "abstract": "Comments: ICML2022",
    "descriptor": "\nComments: ICML2022\n",
    "authors": [
      "Xiaojun Xu",
      "Jacky Yibo Zhang",
      "Evelyn Ma",
      "Danny Son",
      "Oluwasanmi Koyejo",
      "Bo Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01832"
  },
  {
    "id": "arXiv:2202.01889",
    "title": "Generalizing to New Physical Systems via Context-Informed Dynamics Model",
    "abstract": "Comments: Accepted at ICML 2022",
    "descriptor": "\nComments: Accepted at ICML 2022\n",
    "authors": [
      "Matthieu Kirchmeyer",
      "Yuan Yin",
      "J\u00e9r\u00e9mie Don\u00e0",
      "Nicolas Baskiotis",
      "Alain Rakotomamonjy",
      "Patrick Gallinari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.01889"
  },
  {
    "id": "arXiv:2202.02296",
    "title": "Graph-Coupled Oscillator Networks",
    "abstract": "Comments: ICML 2022",
    "descriptor": "\nComments: ICML 2022\n",
    "authors": [
      "T. Konstantin Rusch",
      "Benjamin P. Chamberlain",
      "James Rowbottom",
      "Siddhartha Mishra",
      "Michael M. Bronstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.02296"
  },
  {
    "id": "arXiv:2202.02444",
    "title": "Spelunking the Deep: Guaranteed Queries on General Neural Implicit  Surfaces via Range Analysis",
    "abstract": "Comments: appearing in ACM Transactions on Graphics / SIGGRAPH 2022 Journal Papers",
    "descriptor": "\nComments: appearing in ACM Transactions on Graphics / SIGGRAPH 2022 Journal Papers\n",
    "authors": [
      "Nicholas Sharp",
      "Alec Jacobson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02444"
  },
  {
    "id": "arXiv:2202.03813",
    "title": "Learning to Predict Graphs with Fused Gromov-Wasserstein Barycenters",
    "abstract": "Learning to Predict Graphs with Fused Gromov-Wasserstein Barycenters",
    "descriptor": "",
    "authors": [
      "Luc Brogat-Motte",
      "R\u00e9mi Flamary",
      "C\u00e9line Brouard",
      "Juho Rousu",
      "Florence d'Alch\u00e9-Buc"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03813"
  },
  {
    "id": "arXiv:2202.04515",
    "title": "Leverage Score Sampling for Tensor Product Matrices in Input Sparsity  Time",
    "abstract": "Leverage Score Sampling for Tensor Product Matrices in Input Sparsity  Time",
    "descriptor": "",
    "authors": [
      "David P. Woodruff",
      "Amir Zandieh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.04515"
  },
  {
    "id": "arXiv:2202.05225",
    "title": "On the Identity Problem for Unitriangular Matrices of Dimension Four",
    "abstract": "Comments: 28 pages, 2 figures",
    "descriptor": "\nComments: 28 pages, 2 figures\n",
    "authors": [
      "Ruiwen Dong"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2202.05225"
  },
  {
    "id": "arXiv:2202.05732",
    "title": "CAP-VMs: Capability-Based Isolation and Sharing for Microservices",
    "abstract": "CAP-VMs: Capability-Based Isolation and Sharing for Microservices",
    "descriptor": "",
    "authors": [
      "Vasily A. Sartakov",
      "Llu\u00eds Vilanova",
      "David Eyers",
      "Takahiro Shinagawa",
      "Peter Pietzuch"
    ],
    "subjectives": [
      "Operating Systems (cs.OS)"
    ],
    "url": "https://arxiv.org/abs/2202.05732"
  },
  {
    "id": "arXiv:2202.06264",
    "title": "A Simplified Variant of G\u00f6del's Ontological Argument",
    "abstract": "Comments: 15 pages, 4 figures",
    "descriptor": "\nComments: 15 pages, 4 figures\n",
    "authors": [
      "Christoph Benzm\u00fcller"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.06264"
  },
  {
    "id": "arXiv:2202.06428",
    "title": "Beyond Worst-Case Analysis for Root Isolation Algorithms",
    "abstract": "Comments: 9 pages, 2 figures. 2nd version: New title, corrections. 3rd version: Correction of typo in name",
    "descriptor": "\nComments: 9 pages, 2 figures. 2nd version: New title, corrections. 3rd version: Correction of typo in name\n",
    "authors": [
      "Alperen A. Erg\u00fcr",
      "Josu\u00e9 Tonelli-Cueto",
      "Elias Tsigaridas"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Symbolic Computation (cs.SC)",
      "Algebraic Geometry (math.AG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2202.06428"
  },
  {
    "id": "arXiv:2202.06483",
    "title": "BiFSMN: Binary Neural Network for Keyword Spotting",
    "abstract": "BiFSMN: Binary Neural Network for Keyword Spotting",
    "descriptor": "",
    "authors": [
      "Haotong Qin",
      "Xudong Ma",
      "Yifu Ding",
      "Xiaoyang Li",
      "Yang Zhang",
      "Yao Tian",
      "Zejun Ma",
      "Jie Luo",
      "Xianglong Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.06483"
  },
  {
    "id": "arXiv:2202.09892",
    "title": "Towards a Framework for Comparing the Complexity of Robotic Tasks",
    "abstract": "Towards a Framework for Comparing the Complexity of Robotic Tasks",
    "descriptor": "",
    "authors": [
      "Michelle Ho",
      "Alec Farid",
      "Anirudha Majumdar"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2202.09892"
  },
  {
    "id": "arXiv:2202.11776",
    "title": "The Challenge of Understanding What Users Want: Inconsistent Preferences  and Engagement Optimization",
    "abstract": "The Challenge of Understanding What Users Want: Inconsistent Preferences  and Engagement Optimization",
    "descriptor": "",
    "authors": [
      "Jon Kleinberg",
      "Sendhil Mullainathan",
      "Manish Raghavan"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2202.11776"
  },
  {
    "id": "arXiv:2203.00968",
    "title": "Direct B\u00e9zier-Based Trajectory Planner for Improved Local Exploration  of Unknown Environments",
    "abstract": "Comments: Submitted to IROS 2022",
    "descriptor": "\nComments: Submitted to IROS 2022\n",
    "authors": [
      "Lorenzo Gentilini",
      "Dario Mengoli",
      "Lorenzo Marconi"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.00968"
  },
  {
    "id": "arXiv:2203.02018",
    "title": "Zero-shot Transfer Learning on Heterogeneous Graphs via Knowledge  Transfer Networks",
    "abstract": "Zero-shot Transfer Learning on Heterogeneous Graphs via Knowledge  Transfer Networks",
    "descriptor": "",
    "authors": [
      "Minji Yoon",
      "John Palowitch",
      "Dustin Zelle",
      "Ziniu Hu",
      "Ruslan Salakhutdinov",
      "Bryan Perozzi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.02018"
  },
  {
    "id": "arXiv:2203.09829",
    "title": "Towards Representative Subset Selection for Self-Supervised Speech  Recognition",
    "abstract": "Comments: 16 pages, 8 figures",
    "descriptor": "\nComments: 16 pages, 8 figures\n",
    "authors": [
      "Abdul Hameed Azeemi",
      "Ihsan Ayyub Qazi",
      "Agha Ali Raza"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.09829"
  },
  {
    "id": "arXiv:2203.10093",
    "title": "Deep Reinforcement Learning Guided Graph Neural Networks for Brain  Network Analysis",
    "abstract": "Deep Reinforcement Learning Guided Graph Neural Networks for Brain  Network Analysis",
    "descriptor": "",
    "authors": [
      "Xusheng Zhao",
      "Jia Wu",
      "Hao Peng",
      "Amin Beheshti",
      "Jessica Monaghan",
      "David McAlpine",
      "Heivet Hernandez-Perez",
      "Mark Dras",
      "Qiong Dai",
      "Yangyang Li",
      "Philip S. Yu",
      "Lifang He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2203.10093"
  },
  {
    "id": "arXiv:2203.10115",
    "title": "Introducing causal inference in the energy-efficient building design  process",
    "abstract": "Comments: 20 pages, 9 figures",
    "descriptor": "\nComments: 20 pages, 9 figures\n",
    "authors": [
      "Xia Chen",
      "Jimmy Abualdenien",
      "Manav Mahan Singh",
      "Andr\u00e9 Borrmann",
      "Philipp Geyer"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2203.10115"
  },
  {
    "id": "arXiv:2203.11506",
    "title": "Rebalanced Siamese Contrastive Mining for Long-Tailed Recognition",
    "abstract": "Comments: Tech report",
    "descriptor": "\nComments: Tech report\n",
    "authors": [
      "Zhisheng Zhong",
      "Jiequan Cui",
      "Zeming Li",
      "Eric Lo",
      "Jian Sun",
      "Jiaya Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11506"
  },
  {
    "id": "arXiv:2203.11570",
    "title": "Conditional Generative Data Augmentation for Clinical Audio Datasets",
    "abstract": "Conditional Generative Data Augmentation for Clinical Audio Datasets",
    "descriptor": "",
    "authors": [
      "Matthias Seibold",
      "Armando Hoch",
      "Mazda Farshad",
      "Nassir Navab",
      "Philipp F\u00fcrnstahl"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.11570"
  },
  {
    "id": "arXiv:2203.12062",
    "title": "Distributionally Robust Model Predictive Control with Total Variation  Distance",
    "abstract": "Comments: Accepted to LCSS",
    "descriptor": "\nComments: Accepted to LCSS\n",
    "authors": [
      "Anushri Dixit",
      "Mohamadreza Ahmadi",
      "Joel W. Burdick"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.12062"
  },
  {
    "id": "arXiv:2203.13313",
    "title": "Deep learning for laboratory earthquake prediction and autoregressive  forecasting of fault zone stress",
    "abstract": "Comments: Under review in EPSL",
    "descriptor": "\nComments: Under review in EPSL\n",
    "authors": [
      "Laura Laurenti",
      "Elisa Tinti",
      "Fabio Galasso",
      "Luca Franco",
      "Chris Marone"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13313"
  },
  {
    "id": "arXiv:2203.15251",
    "title": "Exploring Intra- and Inter-Video Relation for Surgical Semantic Scene  Segmentation",
    "abstract": "Comments: Accepted at IEEE TMI",
    "descriptor": "\nComments: Accepted at IEEE TMI\n",
    "authors": [
      "Yueming Jin",
      "Yang Yu",
      "Cheng Chen",
      "Zixu Zhao",
      "Pheng-Ann Heng",
      "Danail Stoyanov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15251"
  },
  {
    "id": "arXiv:2204.00902",
    "title": "An objective test tool for pitch extractors' response attributes",
    "abstract": "Comments: 5 pages, 9 figures, submitted to Interspeech2022. arXiv admin note: text overlap with arXiv:2111.03629",
    "descriptor": "\nComments: 5 pages, 9 figures, submitted to Interspeech2022. arXiv admin note: text overlap with arXiv:2111.03629\n",
    "authors": [
      "Hideki Kawahara",
      "Kohei Yatabe",
      "Ken-Ichi Sakakibara",
      "Tatsuya Kitamura",
      "Hideki Banno",
      "Masanori Morise"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2204.00902"
  },
  {
    "id": "arXiv:2204.07265",
    "title": "The Rise of Intelligent Reflecting Surfaces in Integrated Sensing and  Communications Paradigms",
    "abstract": "Comments: 7pages5figures, submitted to IEEE, revised version",
    "descriptor": "\nComments: 7pages5figures, submitted to IEEE, revised version\n",
    "authors": [
      "Ahmet M. Elbir",
      "Kumar Vijay Mishra",
      "M. R. Bhavani Shankar",
      "Symeon Chatzinotas"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.07265"
  },
  {
    "id": "arXiv:2204.07662",
    "title": "A Catalogue of Concerns for Specifying Machine Learning-Enabled Systems",
    "abstract": "Comments: 14 pages, 2 figures - Accepted for publication - WER 2022 (Workshop on Requirements Engineering)",
    "descriptor": "\nComments: 14 pages, 2 figures - Accepted for publication - WER 2022 (Workshop on Requirements Engineering)\n",
    "authors": [
      "Hugo Villamizar",
      "Marcos Kalinowski",
      "Helio lopes"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2204.07662"
  },
  {
    "id": "arXiv:2204.08471",
    "title": "AI for human assessment: What do professional assessors need?",
    "abstract": "Comments: For the 2022 ACM CHI Workshop on Trust and Reliance in AI-Human Teams",
    "descriptor": "\nComments: For the 2022 ACM CHI Workshop on Trust and Reliance in AI-Human Teams\n",
    "authors": [
      "Riku Arakawa",
      "Hiromu Yakura"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.08471"
  },
  {
    "id": "arXiv:2204.09224",
    "title": "ContentVec: An Improved Self-Supervised Speech Representation by  Disentangling Speakers",
    "abstract": "ContentVec: An Improved Self-Supervised Speech Representation by  Disentangling Speakers",
    "descriptor": "",
    "authors": [
      "Kaizhi Qian",
      "Yang Zhang",
      "Heting Gao",
      "Junrui Ni",
      "Cheng-I Lai",
      "David Cox",
      "Mark Hasegawa-Johnson",
      "Shiyu Chang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.09224"
  },
  {
    "id": "arXiv:2204.09334",
    "title": "Unsupervised Domain Adaptation for Cardiac Segmentation: Towards  Structure Mutual Information Maximization",
    "abstract": "Comments: CVPR Workshop Paper",
    "descriptor": "\nComments: CVPR Workshop Paper\n",
    "authors": [
      "Changjie Lu",
      "Shen Zheng",
      "Gaurav Gupta"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.09334"
  },
  {
    "id": "arXiv:2204.11936",
    "title": "Discrete-Continuous Smoothing and Mapping",
    "abstract": "Discrete-Continuous Smoothing and Mapping",
    "descriptor": "",
    "authors": [
      "Kevin J. Doherty",
      "Ziqi Lu",
      "Kurran Singh",
      "John J. Leonard"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.11936"
  },
  {
    "id": "arXiv:2205.01863",
    "title": "Provably Confidential Language Modelling",
    "abstract": "Comments: NAACL 2022",
    "descriptor": "\nComments: NAACL 2022\n",
    "authors": [
      "Xuandong Zhao",
      "Lei Li",
      "Yu-Xiang Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01863"
  },
  {
    "id": "arXiv:2205.02599",
    "title": "Applicability of Software Reliability Growth Models to Open Source  Software",
    "abstract": "Applicability of Software Reliability Growth Models to Open Source  Software",
    "descriptor": "",
    "authors": [
      "Radoslav Micko",
      "Stanislav Chren",
      "Bruno Rossi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2205.02599"
  },
  {
    "id": "arXiv:2205.04357",
    "title": "Unified framework for Identity and Imagined Action Recognition from EEG  patterns",
    "abstract": "Unified framework for Identity and Imagined Action Recognition from EEG  patterns",
    "descriptor": "",
    "authors": [
      "Marco Buzzelli",
      "Simone Bianco",
      "Paolo Napoletano"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2205.04357"
  },
  {
    "id": "arXiv:2205.06445",
    "title": "Personalized Adversarial Data Augmentation for Dysarthric and Elderly  Speech Recognition",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2202.10290",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2202.10290\n",
    "authors": [
      "Zengrui Jin",
      "Mengzhe Geng",
      "Jiajun Deng",
      "Tianzi Wang",
      "Shujie Hu",
      "Guinan Li",
      "Xunying Liu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.06445"
  },
  {
    "id": "arXiv:2205.07326",
    "title": "Adjoint-based optimization of two-dimensional Stefan problems",
    "abstract": "Comments: 33 pages, 16 figures, preprint submitted to Journal of Computational Physics",
    "descriptor": "\nComments: 33 pages, 16 figures, preprint submitted to Journal of Computational Physics\n",
    "authors": [
      "Tomas Fullana",
      "Vincent Le Chenadec",
      "Taraneh Sayadi"
    ],
    "subjectives": [
      "Mathematical Physics (math-ph)",
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2205.07326"
  },
  {
    "id": "arXiv:2205.08821",
    "title": "Property Unlearning: A Defense Strategy Against Property Inference  Attacks",
    "abstract": "Comments: Please note: As of June 24, 2022, we have discovered some flaws in our experimental setup. The defense mechanism property unlearning is not as strong as the experimental results in the current version of the paper suggest. We will provide an updated version soon",
    "descriptor": "\nComments: Please note: As of June 24, 2022, we have discovered some flaws in our experimental setup. The defense mechanism property unlearning is not as strong as the experimental results in the current version of the paper suggest. We will provide an updated version soon\n",
    "authors": [
      "Joshua Stock",
      "Jens Wettlaufer",
      "Daniel Demmler",
      "Hannes Federrath"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.08821"
  },
  {
    "id": "arXiv:2205.09310",
    "title": "Mitigating Neural Network Overconfidence with Logit Normalization",
    "abstract": "Comments: Accepted by ICML 2022",
    "descriptor": "\nComments: Accepted by ICML 2022\n",
    "authors": [
      "Hongxin Wei",
      "Renchunzi Xie",
      "Hao Cheng",
      "Lei Feng",
      "Bo An",
      "Yixuan Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09310"
  },
  {
    "id": "arXiv:2205.09513",
    "title": "Federated learning: Applications, challenges and future directions",
    "abstract": "Comments: 35 pages, 2 figures",
    "descriptor": "\nComments: 35 pages, 2 figures\n",
    "authors": [
      "Subrato Bharati",
      "M. Rubaiyat Hossain Mondal",
      "Prajoy Podder",
      "V. B. Surya Prasath"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2205.09513"
  },
  {
    "id": "arXiv:2205.09892",
    "title": "Obfuscating the Hierarchy of a Digital IP",
    "abstract": "Obfuscating the Hierarchy of a Digital IP",
    "descriptor": "",
    "authors": [
      "Giorgi Basiashvili",
      "Zain Ul Abideen",
      "Samuel Pagliarini"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2205.09892"
  },
  {
    "id": "arXiv:2205.11418",
    "title": "On non-monomial APcN permutations over finite fields of even  characteristic",
    "abstract": "Comments: We made a revised version, where Sec 4 was revised as follows: G_alp(x) is newly introduced and Theorem 4.12 is added",
    "descriptor": "\nComments: We made a revised version, where Sec 4 was revised as follows: G_alp(x) is newly introduced and Theorem 4.12 is added\n",
    "authors": [
      "Jaeseong Jeong",
      "Namhun Koo",
      "Soonhak Kwon"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.11418"
  },
  {
    "id": "arXiv:2205.14377",
    "title": "Enhancing Quality of Pose-varied Face Restoration with Local Weak  Feature Sensing and GAN Prior",
    "abstract": "Comments: pdfLaTeX 2021, 11 pages with 15 figures",
    "descriptor": "\nComments: pdfLaTeX 2021, 11 pages with 15 figures\n",
    "authors": [
      "Kai Hu",
      "Yu Liu",
      "Renhe Liu",
      "Wei Lu",
      "Gang Yu",
      "Bin Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.14377"
  },
  {
    "id": "arXiv:2205.15236",
    "title": "RankSim: Ranking Similarity Regularization for Deep Imbalanced  Regression",
    "abstract": "Comments: Accepted to ICML 2022",
    "descriptor": "\nComments: Accepted to ICML 2022\n",
    "authors": [
      "Yu Gong",
      "Greg Mori",
      "Frederick Tung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15236"
  },
  {
    "id": "arXiv:2206.00260",
    "title": "Multi-block Min-max Bilevel Optimization with Applications in Multi-task  Deep AUC Maximization",
    "abstract": "Multi-block Min-max Bilevel Optimization with Applications in Multi-task  Deep AUC Maximization",
    "descriptor": "",
    "authors": [
      "Quanqi Hu",
      "Yongjian Zhong",
      "Tianbao Yang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.00260"
  },
  {
    "id": "arXiv:2206.00973",
    "title": "Primal-dual extrapolation methods for monotone inclusions under local  Lipschitz continuity with applications to variational inequality, conic  constrained saddle point, and convex conic optimization problems",
    "abstract": "Comments: corrected some typos",
    "descriptor": "\nComments: corrected some typos\n",
    "authors": [
      "Zhaosong Lu",
      "Sanyou Mei"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.00973"
  },
  {
    "id": "arXiv:2206.01209",
    "title": "Accelerated first-order methods for convex optimization with locally  Lipschitz continuous gradient",
    "abstract": "Comments: corrected some typos. arXiv admin note: text overlap with arXiv:2206.00973",
    "descriptor": "\nComments: corrected some typos. arXiv admin note: text overlap with arXiv:2206.00973\n",
    "authors": [
      "Zhaosong Lu",
      "Sanyou Mei"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.01209"
  },
  {
    "id": "arXiv:2206.02465",
    "title": "Virtual Homogeneity Learning: Defending against Data Heterogeneity in  Federated Learning",
    "abstract": "Virtual Homogeneity Learning: Defending against Data Heterogeneity in  Federated Learning",
    "descriptor": "",
    "authors": [
      "Zhenheng Tang",
      "Yonggang Zhang",
      "Shaohuai Shi",
      "Xin He",
      "Bo Han",
      "Xiaowen Chu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.02465"
  },
  {
    "id": "arXiv:2206.02690",
    "title": "A Survey on Sentence Embedding Models Performance for Patent Analysis",
    "abstract": "Comments: 17 pages, 4 figures",
    "descriptor": "\nComments: 17 pages, 4 figures\n",
    "authors": [
      "Hamid Bekamiri",
      "Daniel S. Hain",
      "Roman Jurowetzki"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.02690"
  },
  {
    "id": "arXiv:2206.03097",
    "title": "Locality-sensitive bucketing functions for the edit distance",
    "abstract": "Comments: 12 pages, 2 figures. To be published in WABI 2022, revised according to reviewers' comments",
    "descriptor": "\nComments: 12 pages, 2 figures. To be published in WABI 2022, revised according to reviewers' comments\n",
    "authors": [
      "Ke Chen",
      "Mingfu Shao"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.03097"
  },
  {
    "id": "arXiv:2206.03592",
    "title": "Click prediction boosting via Bayesian hyperparameter optimization based  ensemble learning pipelines",
    "abstract": "Comments: 24 pages, 3 figures, 1 algorithm, 4 equations",
    "descriptor": "\nComments: 24 pages, 3 figures, 1 algorithm, 4 equations\n",
    "authors": [
      "\u00c7a\u011fatay Demirel",
      "A. Aylin Toku\u00e7",
      "Ahmet Tezcan Tekin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03592"
  },
  {
    "id": "arXiv:2206.04033",
    "title": "High-order approximation to generalized Caputo derivatives and  generalized fractional advection-diffusion equations",
    "abstract": "Comments: 30 pages, 2 figures",
    "descriptor": "\nComments: 30 pages, 2 figures\n",
    "authors": [
      "Sarita Kumari",
      "Rajesh K. Pandey"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.04033"
  },
  {
    "id": "arXiv:2206.05311",
    "title": "Graph-in-Graph Network for Automatic Gene Ontology Description  Generation",
    "abstract": "Comments: Accepted by KDD 2022 (Research Track)",
    "descriptor": "\nComments: Accepted by KDD 2022 (Research Track)\n",
    "authors": [
      "Fenglin Liu",
      "Bang Yang",
      "Chenyu You",
      "Xian Wu",
      "Shen Ge",
      "Adelaide Woicik",
      "Sheng Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.05311"
  },
  {
    "id": "arXiv:2206.05400",
    "title": "High-Definition Map Generation Technologies For Autonomous Driving",
    "abstract": "Comments: 25 pages, 17 figures, submitted to a journal",
    "descriptor": "\nComments: 25 pages, 17 figures, submitted to a journal\n",
    "authors": [
      "Zhibin Bao",
      "Sabir Hossain",
      "Haoxiang Lang",
      "Xianke Lin"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.05400"
  },
  {
    "id": "arXiv:2206.05809",
    "title": "Geometric Policy Iteration for Markov Decision Processes",
    "abstract": "Comments: Camera ready version for SIGKDD 2022",
    "descriptor": "\nComments: Camera ready version for SIGKDD 2022\n",
    "authors": [
      "Yue Wu",
      "Jes\u00fas A. De Loera"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.05809"
  },
  {
    "id": "arXiv:2206.05814",
    "title": "Once Highly Productive, Forever Highly Productive? Full Professors'  Research Productivity from a Longitudinal Perspective",
    "abstract": "Comments: 33 pages, 6 tables, 7 figures",
    "descriptor": "\nComments: 33 pages, 6 tables, 7 figures\n",
    "authors": [
      "Marek Kwiek",
      "Wojciech Roszka"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2206.05814"
  },
  {
    "id": "arXiv:2206.06010",
    "title": "Constant-Round Linear-Broadcast Secure Computation with Penalties",
    "abstract": "Comments: 32 pages",
    "descriptor": "\nComments: 32 pages\n",
    "authors": [
      "Takeshi Nakai",
      "Kazumasa Shinagawa"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.06010"
  },
  {
    "id": "arXiv:2206.07527",
    "title": "QONNX: Representing Arbitrary-Precision Quantized Neural Networks",
    "abstract": "Comments: 9 pages, 5 figures, Contribution to 4th Workshop on Accelerated Machine Learning (AccML) at HiPEAC 2022 Conference",
    "descriptor": "\nComments: 9 pages, 5 figures, Contribution to 4th Workshop on Accelerated Machine Learning (AccML) at HiPEAC 2022 Conference\n",
    "authors": [
      "Alessandro Pappalardo",
      "Yaman Umuroglu",
      "Michaela Blott",
      "Jovan Mitrevski",
      "Ben Hawks",
      "Nhan Tran",
      "Vladimir Loncar",
      "Sioni Summers",
      "Hendrik Borras",
      "Jules Muhizi",
      "Matthew Trahms",
      "Shih-Chieh Hsu",
      "Scott Hauck",
      "Javier Duarte"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)",
      "Programming Languages (cs.PL)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.07527"
  },
  {
    "id": "arXiv:2206.08802",
    "title": "Open-Sampling: Exploring Out-of-Distribution data for Re-balancing  Long-tailed datasets",
    "abstract": "Comments: Accepted by ICML 2022",
    "descriptor": "\nComments: Accepted by ICML 2022\n",
    "authors": [
      "Hongxin Wei",
      "Lue Tao",
      "Renchunzi Xie",
      "Lei Feng",
      "Bo An"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.08802"
  },
  {
    "id": "arXiv:2206.09423",
    "title": "Efficient End-to-End AutoML via Scalable Search Space Decomposition",
    "abstract": "Comments: This paper is an extended version of the initial VolcanoML paper (li et al. VLDB 2021). arXiv admin note: substantial text overlap with arXiv:2107.08861",
    "descriptor": "\nComments: This paper is an extended version of the initial VolcanoML paper (li et al. VLDB 2021). arXiv admin note: substantial text overlap with arXiv:2107.08861\n",
    "authors": [
      "Yang Li",
      "Yu Shen",
      "Wentao Zhang",
      "Ce Zhang",
      "Bin Cui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09423"
  },
  {
    "id": "arXiv:2206.09884",
    "title": "Finding $k$-Secluded Trees Faster",
    "abstract": "Finding $k$-Secluded Trees Faster",
    "descriptor": "",
    "authors": [
      "Huib Donkers",
      "Bart M.P. Jansen",
      "Jari J.H. de Kroon"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2206.09884"
  },
  {
    "id": "arXiv:2206.09900",
    "title": "Voxel-MAE: Masked Autoencoders for Pre-training Large-scale Point Clouds",
    "abstract": "Comments: 8 pages, 1 figures",
    "descriptor": "\nComments: 8 pages, 1 figures\n",
    "authors": [
      "Chen Min",
      "Dawei Zhao",
      "Liang Xiao",
      "Yiming Nie",
      "Bin Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09900"
  },
  {
    "id": "arXiv:2206.10254",
    "title": "Towards Optimizing OCR for Accessibility",
    "abstract": "Towards Optimizing OCR for Accessibility",
    "descriptor": "",
    "authors": [
      "Peya Mowar",
      "Tanuja Ganu",
      "Saikat Guha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.10254"
  },
  {
    "id": "arXiv:2206.10348",
    "title": "Supervised learning of random quantum circuits via scalable neural  networks",
    "abstract": "Comments: 17+ pages, 18 figures",
    "descriptor": "\nComments: 17+ pages, 18 figures\n",
    "authors": [
      "S. Cantori",
      "D. Vitali",
      "S. Pilati"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10348"
  },
  {
    "id": "arXiv:2206.10462",
    "title": "The Digital Twin Landscape at the Crossroads of Predictive Maintenance,  Machine Learning and Physics Based Modeling",
    "abstract": "Comments: 21 pages, 5 figures",
    "descriptor": "\nComments: 21 pages, 5 figures\n",
    "authors": [
      "Brian Kunzer",
      "Mario Berges",
      "Artur Dubrawski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10462"
  },
  {
    "id": "arXiv:2206.10883",
    "title": "Multi-LexSum: Real-World Summaries of Civil Rights Lawsuits at Multiple  Granularities",
    "abstract": "Comments: 37 pages, 2 figures, 9 tables",
    "descriptor": "\nComments: 37 pages, 2 figures, 9 tables\n",
    "authors": [
      "Zejiang Shen",
      "Kyle Lo",
      "Lauren Yu",
      "Nathan Dahlberg",
      "Margo Schlanger",
      "Doug Downey"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.10883"
  },
  {
    "id": "arXiv:2206.11061",
    "title": "An Ontological Approach to Analysing Social Service Provisioning",
    "abstract": "Comments: Update: corrected email, header text",
    "descriptor": "\nComments: Update: corrected email, header text\n",
    "authors": [
      "Mark S. Fox",
      "Bart Gajderowicz",
      "Daniela Rosu",
      "Alina Turner",
      "Lester Lyu"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.11061"
  },
  {
    "id": "arXiv:2206.11081",
    "title": "Descent Steps of a Relation-Aware Energy Produce Heterogeneous Graph  Neural Networks",
    "abstract": "Descent Steps of a Relation-Aware Energy Produce Heterogeneous Graph  Neural Networks",
    "descriptor": "",
    "authors": [
      "Hongjoon Ahn",
      "Yongyi Yang",
      "Quan Gan",
      "David Wipf",
      "Taesup Moon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.11081"
  },
  {
    "id": "arXiv:2206.11119",
    "title": "Multi-User Linearly-Separable Distributed Computing",
    "abstract": "Comments: 57 pages, 5 figures. Submitted to IEEE Transactions on Information Theory",
    "descriptor": "\nComments: 57 pages, 5 figures. Submitted to IEEE Transactions on Information Theory\n",
    "authors": [
      "Ali Khalesi",
      "Petros Elia"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Rings and Algebras (math.RA)"
    ],
    "url": "https://arxiv.org/abs/2206.11119"
  },
  {
    "id": "arXiv:2206.11134",
    "title": "Open Vocabulary Object Detection with Proposal Mining and Prediction  Equalization",
    "abstract": "Open Vocabulary Object Detection with Proposal Mining and Prediction  Equalization",
    "descriptor": "",
    "authors": [
      "Peixian Chen",
      "Kekai Sheng",
      "Mengdan Zhang",
      "Yunhang Shen",
      "Ke Li",
      "Chunhua Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.11134"
  },
  {
    "id": "arXiv:2206.11249",
    "title": "GEMv2: Multilingual NLG Benchmarking in a Single Line of Code",
    "abstract": "GEMv2: Multilingual NLG Benchmarking in a Single Line of Code",
    "descriptor": "",
    "authors": [
      "Sebastian Gehrmann",
      "Abhik Bhattacharjee",
      "Abinaya Mahendiran",
      "Alex Wang",
      "Alexandros Papangelis",
      "Aman Madaan",
      "Angelina McMillan-Major",
      "Anna Shvets",
      "Ashish Upadhyay",
      "Bingsheng Yao",
      "Bryan Wilie",
      "Chandra Bhagavatula",
      "Chaobin You",
      "Craig Thomson",
      "Cristina Garbacea",
      "Dakuo Wang",
      "Daniel Deutsch",
      "Deyi Xiong",
      "Di Jin",
      "Dimitra Gkatzia",
      "Dragomir Radev",
      "Elizabeth Clark",
      "Esin Durmus",
      "Faisal Ladhak",
      "Filip Ginter",
      "Genta Indra Winata",
      "Hendrik Strobelt",
      "Hiroaki Hayashi",
      "Jekaterina Novikova",
      "Jenna Kanerva",
      "Jenny Chim",
      "Jiawei Zhou",
      "Jordan Clive",
      "Joshua Maynez",
      "Jo\u00e3o Sedoc",
      "Juraj Juraska",
      "Kaustubh Dhole",
      "Khyathi Raghavi Chandu",
      "Laura Perez-Beltrachini",
      "Leonardo F. R. Ribeiro",
      "Lewis Tunstall",
      "Li Zhang",
      "Mahima Pushkarna",
      "Mathias Creutz",
      "Michael White",
      "Mihir Sanjay Kale",
      "Moussa Kamal Eddine",
      "Nico Daheim",
      "Nishant Subramani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.11249"
  },
  {
    "id": "arXiv:2206.11428",
    "title": "LidarMultiNet: Unifying LiDAR Semantic Segmentation, 3D Object  Detection, and Panoptic Segmentation in a Single Multi-task Network",
    "abstract": "Comments: Official 1st Place Solution for the Waymo Open Dataset Challenges 2022 - 3D Semantic Segmentation. Official leaderboard: this https URL CVPR 2022 Workshop on Autonomous Driving: this http URL",
    "descriptor": "\nComments: Official 1st Place Solution for the Waymo Open Dataset Challenges 2022 - 3D Semantic Segmentation. Official leaderboard: this https URL CVPR 2022 Workshop on Autonomous Driving: this http URL\n",
    "authors": [
      "Dongqiangzi Ye",
      "Weijia Chen",
      "Zixiang Zhou",
      "Yufei Xie",
      "Yu Wang",
      "Panqu Wang",
      "Hassan Foroosh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.11428"
  },
  {
    "id": "arXiv:2206.11474",
    "title": "Entropy-driven Sampling and Training Scheme for Conditional Diffusion  Generation",
    "abstract": "Comments: 24 pages, 8 figures",
    "descriptor": "\nComments: 24 pages, 8 figures\n",
    "authors": [
      "Shengming Li",
      "Guangcong Zheng",
      "Hui Wang",
      "Taiping Yao",
      "Yang Chen",
      "Shoudong Ding",
      "Xi Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.11474"
  },
  {
    "id": "arXiv:2206.11499",
    "title": "Parallel Structure from Motion for UAV Images via Weighted Connected  Dominating Set",
    "abstract": "Comments: 14 pages, 11 figures",
    "descriptor": "\nComments: 14 pages, 11 figures\n",
    "authors": [
      "San Jiang",
      "Qingquan Li",
      "Wanshou Jiang",
      "Wu Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.11499"
  },
  {
    "id": "arXiv:2206.11669",
    "title": "Short-range forecasts of global precipitation using deep  learning-augmented numerical weather prediction",
    "abstract": "Short-range forecasts of global precipitation using deep  learning-augmented numerical weather prediction",
    "descriptor": "",
    "authors": [
      "Manmeet Singh",
      "Vaisakh S B",
      "Nachiketa Acharya",
      "Suryachandra A Rao",
      "Bipin Kumar",
      "Zong-Liang Yang",
      "Dev Niyogi"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.11669"
  },
  {
    "id": "arXiv:2206.11810",
    "title": "Inductive Conformal Prediction: A Straightforward Introduction with  Examples in Python",
    "abstract": "Comments: 6 pages, 11 figures, tutorial",
    "descriptor": "\nComments: 6 pages, 11 figures, tutorial\n",
    "authors": [
      "Martim Sousa"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.11810"
  },
  {
    "id": "arXiv:2206.11812",
    "title": "Formalizing the Problem of Side Effect Regularization",
    "abstract": "Comments: 13 pages, 2 figures",
    "descriptor": "\nComments: 13 pages, 2 figures\n",
    "authors": [
      "Alexander Matt Turner",
      "Aseem Saxena",
      "Prasad Tadepalli"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.11812"
  },
  {
    "id": "arXiv:2206.11826",
    "title": "Toward Clinically Assisted Colorectal Polyp Recognition via Structured  Cross-modal Representation Consistency",
    "abstract": "Comments: Early Accepted by MICCAI 2022",
    "descriptor": "\nComments: Early Accepted by MICCAI 2022\n",
    "authors": [
      "Weijie Ma",
      "Ye Zhu",
      "Ruimao Zhang",
      "Jie Yang",
      "Yiwen Hu",
      "Zhen Li",
      "Li Xiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.11826"
  }
]
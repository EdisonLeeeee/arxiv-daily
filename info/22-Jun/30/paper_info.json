[
  {
    "id": "arXiv:2206.14198",
    "title": "Predicting the Need for Blood Transfusion in Intensive Care Units with  Reinforcement Learning",
    "abstract": "As critically ill patients frequently develop anemia or coagulopathy,\ntransfusion of blood products is a frequent intervention in the Intensive Care\nUnits (ICU). However, inappropriate transfusion decisions made by physicians\nare often associated with increased risk of complications and higher hospital\ncosts. In this work, we aim to develop a decision support tool that uses\navailable patient information for transfusion decision-making on three common\nblood products (red blood cells, platelets, and fresh frozen plasma). To this\nend, we adopt an off-policy batch reinforcement learning (RL) algorithm,\nnamely, discretized Batch Constrained Q-learning, to determine the best action\n(transfusion or not) given observed patient trajectories. Simultaneously, we\nconsider different state representation approaches and reward design mechanisms\nto evaluate their impacts on policy learning. Experiments are conducted on two\nreal-world critical care datasets: the MIMIC-III and the UCSF. Results\ndemonstrate that policy recommendations on transfusion achieved comparable\nmatching against true hospital policies via accuracy and weighted importance\nsampling evaluations on the MIMIC-III dataset. Furthermore, a combination of\ntransfer learning (TL) and RL on the data-scarce UCSF dataset can provide up to\n$17.02% improvement in terms of accuracy, and up to 18.94% and 21.63%\nimprovement in jump-start and asymptotic performance in terms of weighted\nimportance sampling averaged over three transfusion tasks. Finally, simulations\non transfusion decisions suggest that the transferred RL policy could reduce\npatients' estimated 28-day mortality rate by 2.74% and decreased acuity rate by\n1.18% on the UCSF dataset.",
    "descriptor": "\nComments: Proceedings of 13th International ACM Conference on Bioinformatics, Computational Biology and Health Informatics\n",
    "authors": [
      "Yuqing Wang",
      "Yun Zhao",
      "Linda Petzold"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.14198"
  },
  {
    "id": "arXiv:2206.14200",
    "title": "ECG Heartbeat classification using deep transfer learning with  Convolutional Neural Network and STFT technique",
    "abstract": "Electrocardiogram (ECG) is a simple non-invasive measure to identify\nheart-related issues such as irregular heartbeats known as arrhythmias. While\nartificial intelligence and machine learning is being utilized in a wide range\nof healthcare related applications and datasets, many arrhythmia classifiers\nusing deep learning methods have been proposed in recent years. However, sizes\nof the available datasets from which to build and assess machine learning\nmodels is often very small and the lack of well-annotated public ECG datasets\nis evident. In this paper, we propose a deep transfer learning framework that\nis aimed to perform classification on a small size training dataset. The\nproposed method is to fine-tune a general-purpose image classifier ResNet-18\nwith MIT-BIH arrhythmia dataset in accordance with the AAMI EC57 standard. This\npaper further investigates many existing deep learning models that have failed\nto avoid data leakage against AAMI recommendations. We compare how different\ndata split methods impact the model performance. This comparison study implies\nthat future work in arrhythmia classification should follow the AAMI EC57\nstandard when using any including MIT-BIH arrhythmia dataset.",
    "descriptor": "\nComments: 14 pages, 5 figures, 4 tables, submitted to The 4th International Conference on Computing and Data Science (CONF-CDS 2022)\n",
    "authors": [
      "Minh Cao",
      "Tianqi Zhao",
      "Yanxun Li",
      "Wenhao Zhang",
      "Peyman Benharash",
      "Ramin Ramezani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14200"
  },
  {
    "id": "arXiv:2206.14201",
    "title": "$\\mathbb{Z}_p\\mathbb{Z}_{p^2}$-additive cyclic codes: kernel and rank",
    "abstract": "A code $C = \\Phi(\\mathcal{C})$ is called $\\mathbb{Z}_p\n\\mathbb{Z}_{p^2}$-linear if it's the Gray image of the $\\mathbb{Z}_p\n\\mathbb{Z}_{p^2}$-additive code $\\mathcal{C}$. In this paper, the rank and the\ndimension of the kernel of $\\mathcal{C}$ are studied. Both of the codes\n$\\langle \\Phi(\\mathcal{C}) \\rangle$ and $\\ker(\\Phi(\\mathcal{C}))$ are proven\n$\\mathbb{Z}_p \\mathbb{Z}_{p^2}$-additive cyclic codes, and their generator\npolynomials are determined. Finally, accurate values of rank and the dimension\nof the kernel of some classes of $\\mathbb{Z}_p \\mathbb{Z}_{p^2}$-additive\ncyclic codes are considered.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2206.13810\n",
    "authors": [
      "Xuan Wang",
      "Minjia Shi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.14201"
  },
  {
    "id": "arXiv:2206.14202",
    "title": "Building Matters: Spatial Variability in Machine Learning Based Thermal  Comfort Prediction in Winters",
    "abstract": "Thermal comfort in indoor environments has an enormous impact on the health,\nwell-being, and performance of occupants. Given the focus on energy efficiency\nand Internet-of-Things enabled smart buildings, machine learning (ML) is being\nincreasingly used for data-driven thermal comfort (TC) prediction. Generally,\nML-based solutions are proposed for air-conditioned or HVAC ventilated\nbuildings and the models are primarily designed for adults. On the other hand,\nnaturally ventilated (NV) buildings are the norm in most countries. They are\nalso ideal for energy conservation and long-term sustainability goals. However,\nthe indoor environment of NV buildings lacks thermal regulation and varies\nsignificantly across spatial contexts. These factors make TC prediction\nextremely challenging. Thus, determining the impact of the building environment\non the performance of TC models is important. Further, the generalization\ncapability of TC prediction models across different NV indoor spaces needs to\nbe studied. This work addresses these problems. Data is gathered through\nmonth-long field experiments conducted in 5 naturally ventilated school\nbuildings, involving 512 primary school students. The impact of spatial\nvariability on student comfort is demonstrated through variation in prediction\naccuracy (by as much as 71%). The influence of building environment on TC\nprediction is also demonstrated through variation in feature importance.\nFurther, a comparative analysis of spatial variability in model performance is\ndone for children (our dataset) and adults (ASHRAE-II database). Finally, the\ngeneralization capability of thermal comfort models in NV classrooms is\nassessed and major challenges are highlighted.",
    "descriptor": "\nComments: Accepted in SmartSys SMARTCOMP 2022\n",
    "authors": [
      "Betty Lala",
      "Srikant Manas Kala",
      "Anmol Rastogi",
      "Kunal Dahiya",
      "Hirozumi Yamaguchi",
      "Aya Hagishima"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14202"
  },
  {
    "id": "arXiv:2206.14203",
    "title": "Latent Combinational Game Design",
    "abstract": "We present an approach for generating playable games that blend a given set\nof games in a desired combination using deep generative latent variable models.\nWe refer to this approach as latent combinational game design -- latent since\nwe use learned latent representations to perform blending, combinational since\ngame blending is a combinational creativity process and game design since the\napproach generates novel, playable games. We use Gaussian Mixture Variational\nAutoencoders (GMVAEs), which use a mixture of Gaussians to model the VAE latent\nspace. Through supervised training, each component learns to encode levels from\none game and lets us define new, blended games as linear combinations of these\nlearned components. This enables generating new games that blend the input\ngames as well as control the relative proportions of each game in the blend. We\nalso extend prior work using conditional VAEs to perform blending and compare\nagainst the GMVAE. Our results show that both models can generate playable\nblended games that blend the input games in the desired proportions.",
    "descriptor": "",
    "authors": [
      "Anurag Sarkar",
      "Seth Cooper"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.14203"
  },
  {
    "id": "arXiv:2206.14233",
    "title": "Gaussian Latent Dirichlet Allocation for Discrete Human State Discovery",
    "abstract": "In this article we propose and validate an unsupervised probabilistic model,\nGaussian Latent Dirichlet Allocation (GLDA), for the problem of discrete state\ndiscovery from repeated, multivariate psychophysiological samples collected\nfrom multiple, inherently distinct, individuals. Psychology and medical\nresearch heavily involves measuring potentially related but individually\ninconclusive variables from a cohort of participants to derive diagnosis,\nnecessitating clustering analysis. Traditional probabilistic clustering models\nsuch as Gaussian Mixture Model (GMM) assume a global mixture of component\ndistributions, which may not be realistic for observations from different\npatients. The GLDA model borrows the individual-specific mixture structure from\na popular topic model Latent Dirichlet Allocation (LDA) in Natural Language\nProcessing and merges it with the Gaussian component distributions of GMM to\nsuit continuous type data. We implemented GLDA using STAN (a probabilistic\nmodeling language) and applied it on two datasets, one containing Ecological\nMomentary Assessments (EMA) and the other heart measures from electrocardiogram\nand impedance cardiograph. We found that in both datasets the GLDA-learned\nclass weights achieved significantly higher correlations with clinically\nassessed depression, anxiety, and stress scores than those produced by the\nbaseline GMM. Our findings demonstrate the advantage of GLDA over conventional\nfinite mixture models for human state discovery from repeated multivariate\ndata, likely due to better characterization of potential underlying\nbetween-participant differences. Future work is required to validate the\nutility of this model on a broader range of applications.",
    "descriptor": "",
    "authors": [
      "Congyu Wu",
      "Aaron Fisher",
      "David Schnyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14233"
  },
  {
    "id": "arXiv:2206.14236",
    "title": "A Survey on SDN \\& SDCN Traffic Measurement: Existing Approaches and  Research Challenge",
    "abstract": "Software Defined Network (SDN) is the next generation network that decouples\nthe control plane from the data plane of forwarding devices by utilizing the\nOpenFlow protocol as a communication link between the data plane and the\ncontrol plane. However, there are some security issues might be in actions on\nSDN that the attackers can take control over the SDN control plane. Thus,\ntraffic measurement is a fundamental technique of protecting SDN against the\nhigh-security threats such as DDoS, heavy hitter, superspreader as well as live\nvideo calling, QoS control, high bandwidth requirement, resource management are\nalso inevitable in SDN/Software Defined Cellular Network (SDCN). In such a\nscenario, we survey SDN traffic measurement solutions, in order to assess how\nthese solutions can make a secured, efficient and robust SDN/SDCN architecture.\nIn this paper, various types of SDN traffic measurement solutions have been\ncategorized based on network applications behaviour. Furthermore, we find out\nthe challenges related to SDN/SDCN traffic measurement and future scope of\nresearch, which will guide to design and develop more advanced traffic\nmeasurement solutions for a scalable, heterogeneous, hierarchical and widely\ndeployed SDN/SDCN in future prospects. More in details, we list out kinds of\npractical machine learning (ML) approaches to analyze how we can make\nimprovement in the traffic measurement performances. We conclude that using ML\nin SDN traffic measurement solutions will give benefit to get secured SDN/SDCN\nnetwork in complementary ways.",
    "descriptor": "",
    "authors": [
      "MD Samiul Islam",
      "Mojammel Hossain",
      "Mohammed AlMukhtar"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.14236"
  },
  {
    "id": "arXiv:2206.14244",
    "title": "Masked World Models for Visual Control",
    "abstract": "Visual model-based reinforcement learning (RL) has the potential to enable\nsample-efficient robot learning from visual observations. Yet the current\napproaches typically train a single model end-to-end for learning both visual\nrepresentations and dynamics, making it difficult to accurately model the\ninteraction between robots and small objects. In this work, we introduce a\nvisual model-based RL framework that decouples visual representation learning\nand dynamics learning. Specifically, we train an autoencoder with convolutional\nlayers and vision transformers (ViT) to reconstruct pixels given masked\nconvolutional features, and learn a latent dynamics model that operates on the\nrepresentations from the autoencoder. Moreover, to encode task-relevant\ninformation, we introduce an auxiliary reward prediction objective for the\nautoencoder. We continually update both autoencoder and dynamics model using\nonline samples collected from environment interaction. We demonstrate that our\ndecoupling approach achieves state-of-the-art performance on a variety of\nvisual robotic tasks from Meta-world and RLBench, e.g., we achieve 81.7%\nsuccess rate on 50 visual robotic manipulation tasks from Meta-world, while the\nbaseline achieves 67.9%. Code is available on the project website:\nhttps://sites.google.com/view/mwm-rl.",
    "descriptor": "\nComments: Project website: this https URL\n",
    "authors": [
      "Younggyo Seo",
      "Danijar Hafner",
      "Hao Liu",
      "Fangchen Liu",
      "Stephen James",
      "Kimin Lee",
      "Pieter Abbeel"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14244"
  },
  {
    "id": "arXiv:2206.14245",
    "title": "SImProv: Scalable Image Provenance Framework for Robust Content  Attribution",
    "abstract": "We present SImProv - a scalable image provenance framework to match a query\nimage back to a trusted database of originals and identify possible\nmanipulations on the query. SImProv consists of three stages: a scalable search\nstage for retrieving top-k most similar images; a re-ranking and\nnear-duplicated detection stage for identifying the original among the\ncandidates; and finally a manipulation detection and visualization stage for\nlocalizing regions within the query that may have been manipulated to differ\nfrom the original. SImProv is robust to benign image transformations that\ncommonly occur during online redistribution, such as artifacts due to noise and\nrecompression degradation, as well as out-of-place transformations due to image\npadding, warping, and changes in size and shape. Robustness towards\nout-of-place transformations is achieved via the end-to-end training of a\ndifferentiable warping module within the comparator architecture. We\ndemonstrate effective retrieval and manipulation detection over a dataset of\n100 million images.",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Information Forensics and Security\n",
    "authors": [
      "Alexander Black",
      "Tu Bui",
      "Simon Jenni",
      "Zhifei Zhang",
      "Viswanathan Swaminanthan",
      "John Collomosse"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.14245"
  },
  {
    "id": "arXiv:2206.14248",
    "title": "Joint Spatial Division and Multiplexing for FDD in Intelligent  Reflecting Surface-assisted Massive MIMO Systems",
    "abstract": "Intelligent reflecting surface (IRS) is a promising technology to deliver the\nhigher spectral and energy requirements in fifth-generation (5G) and beyond\nwireless networks while shaping the propagation environment. Such a design can\nbe further enhanced with massive multiple-input-multiple-output (mMIMO)\ncharacteristics towards boosting the network performance. However, channel\nreciprocity, assumed in 5G systems such as mMIMO, appears to be questioned in\npractice by recent studies on IRS. Hence, contrary to previous works, we\nconsider frequency division duplexing (FDD) to study the performance of an\nIRS-assisted mMIMO system. However, FDD is not suitable for large number of\nantennas architectures. For this reason we employ the joint spatial division\nand multiplexing (JSDM) approach exploiting the structure of the correlation of\nthe channel vectors to reduce the channel state information (CSI) uplink\nfeedback, and thus, allowing the use even of a large number of antennas at the\nbase station. JSDM entails dual-structured precoding and clustering the user\nequipments (UEs) with the same covariance matrix into groups. Specifically, we\nderive the sum spectral efficiency (SE) based on statistical CSI in terms of\nlarge-scale statistics by using the deterministic equivalent (DE) analysis\nwhile accounting for correlated Rayleigh fading. Subsequently, we formulate the\noptimization problem concerning the sum SE with respect to the reflecting\nbeamforming matrix (RBM) and the total transmit power, which can be performed\nat every several coherence intervals by taking advantage of the slow-time\nvariation of the large-scale statistics. This notable property contributes\nfurther to the decrease of the feedback overhead.",
    "descriptor": "\nComments: accepted in IEEE TVT\n",
    "authors": [
      "Anastasios Papazafeiropoulos",
      "Pandelis Kourtessis",
      "Konstantinos Ntontin",
      "Symeon Chatzinotas"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.14248"
  },
  {
    "id": "arXiv:2206.14254",
    "title": "No imputation without representation",
    "abstract": "By filling in missing values in datasets, imputation allows these datasets to\nbe used with algorithms that cannot handle missing values by themselves.\nHowever, missing values may in principle contribute useful information that is\nlost through imputation. The missing-indicator approach can be used in\ncombination with imputation to instead represent this information as a part of\nthe dataset. There are several theoretical considerations why\nmissing-indicators may or may not be beneficial, but there has not been any\nlarge-scale practical experiment on real-life datasets to test this question\nfor machine learning predictions. We perform this experiment for three\nimputation strategies and a range of different classification algorithms, on\nthe basis of twenty real-life datasets. We find that on these datasets,\nmissing-indicators generally increase classification performance. In addition,\nwe find no evidence for most algorithms that nearest neighbour and iterative\nimputation lead to better performance than simple mean/mode imputation.\nTherefore, we recommend the use of missing-indicators with mean/mode imputation\nas a safe default, with the caveat that for decision trees, pruning is\nnecessary to prevent overfitting. In a follow-up experiment, we determine\nattribute-specific missingness thresholds for each classifier above which\nmissing-indicators are more likely than not to increase classification\nperformance, and observe that these thresholds are much lower for categorical\nthan for numerical attributes. Finally, we argue that mean imputation of\nnumerical attributes may preserve some of the information from missing values,\nand we show that in the absence of missing-indicators, it can similarly be\nuseful to apply mean imputation to one-hot encoded categorical attributes\ninstead of mode imputation.",
    "descriptor": "",
    "authors": [
      "Oliver Urs Lenz",
      "Daniel Peralta",
      "Chris Cornelis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.14254"
  },
  {
    "id": "arXiv:2206.14255",
    "title": "Target alignment in truncated kernel ridge regression",
    "abstract": "Kernel ridge regression (KRR) has recently attracted renewed interest due to\nits potential for explaining the transient effects, such as double descent,\nthat emerge during neural network training. In this work, we study how the\nalignment between the target function and the kernel affects the performance of\nthe KRR. We focus on the truncated KRR (TKRR) which utilizes an additional\nparameter that controls the spectral truncation of the kernel matrix. We show\nthat for polynomial alignment, there is an \\emph{over-aligned} regime, in which\nTKRR can achieve a faster rate than what is achievable by full KRR. The rate of\nTKRR can improve all the way to the parametric rate, while that of full KRR is\ncapped at a sub-optimal value. This shows that target alignemnt can be better\nleveraged by utilizing spectral truncation in kernel methods. We also consider\nthe bandlimited alignment setting and show that the regularization surface of\nTKRR can exhibit transient effects including multiple descent and non-monotonic\nbehavior. Our results show that there is a strong and quantifable relation\nbetween the shape of the \\emph{alignment spectrum} and the generalization\nperformance of kernel methods, both in terms of rates and in finite samples.",
    "descriptor": "",
    "authors": [
      "Arash A. Amini",
      "Richard Baumgartner",
      "Dai Feng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.14255"
  },
  {
    "id": "arXiv:2206.14256",
    "title": "GAN-based Intrinsic Exploration For Sample Efficient Reinforcement  Learning",
    "abstract": "In this study, we address the problem of efficient exploration in\nreinforcement learning. Most common exploration approaches depend on random\naction selection, however these approaches do not work well in environments\nwith sparse or no rewards. We propose Generative Adversarial Network-based\nIntrinsic Reward Module that learns the distribution of the observed states and\nsends an intrinsic reward that is computed as high for states that are out of\ndistribution, in order to lead agent to unexplored states. We evaluate our\napproach in Super Mario Bros for a no reward setting and in Montezuma's Revenge\nfor a sparse reward setting and show that our approach is indeed capable of\nexploring efficiently. We discuss a few weaknesses and conclude by discussing\nfuture works.",
    "descriptor": "",
    "authors": [
      "Do\u011fay Kamar",
      "Naz\u0131m Kemal \u00dcre",
      "G\u00f6zde \u00dcnal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.14256"
  },
  {
    "id": "arXiv:2206.14261",
    "title": "Semi-supervised Contrastive Outlier removal for Pseudo Expectation  Maximization (SCOPE)",
    "abstract": "Semi-supervised learning is the problem of training an accurate predictive\nmodel by combining a small labeled dataset with a presumably much larger\nunlabeled dataset. Many methods for semi-supervised deep learning have been\ndeveloped, including pseudolabeling, consistency regularization, and\ncontrastive learning techniques. Pseudolabeling methods however are highly\nsusceptible to confounding, in which erroneous pseudolabels are assumed to be\ntrue labels in early iterations, thereby causing the model to reinforce its\nprior biases and thereby fail to generalize to strong predictive performance.\nWe present a new approach to suppress confounding errors through a method we\ndescribe as Semi-supervised Contrastive Outlier removal for Pseudo Expectation\nMaximization (SCOPE). Like basic pseudolabeling, SCOPE is related to\nExpectation Maximization (EM), a latent variable framework which can be\nextended toward understanding cluster-assumption deep semi-supervised\nalgorithms. However, unlike basic pseudolabeling which fails to adequately take\ninto account the probability of the unlabeled samples given the model, SCOPE\nintroduces an outlier suppression term designed to improve the behavior of EM\niteration given a discrimination DNN backbone in the presence of outliers. Our\nresults show that SCOPE greatly improves semi-supervised classification\naccuracy over a baseline, and furthermore when combined with consistency\nregularization achieves the highest reported accuracy for the semi-supervised\nCIFAR-10 classification task using 250 and 4000 labeled samples. Moreover, we\nshow that SCOPE reduces the prevalence of confounding errors during\npseudolabeling iterations by pruning erroneous high-confidence pseudolabeled\nsamples that would otherwise contaminate the labeled set in subsequent\nretraining iterations.",
    "descriptor": "",
    "authors": [
      "Sumeet Menon",
      "David Chapman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.14261"
  },
  {
    "id": "arXiv:2206.14262",
    "title": "Supervised Training of Conditional Monge Maps",
    "abstract": "Optimal transport (OT) theory describes general principles to define and\nselect, among many possible choices, the most efficient way to map a\nprobability measure onto another. That theory has been mostly used to estimate,\ngiven a pair of source and target probability measures $(\\mu,\\nu)$, a\nparameterized map $T_\\theta$ that can efficiently map $\\mu$ onto $\\nu$. In many\napplications, such as predicting cell responses to treatments, the data\nmeasures $\\mu,\\nu$ (features of untreated/treated cells) that define optimal\ntransport problems do not arise in isolation but are associated with a context\n$c$ (the treatment). To account for and incorporate that context in OT\nestimation, we introduce CondOT, an approach to estimate OT maps conditioned on\na context variable, using several pairs of measures $(\\mu_i, \\nu_i)$ tagged\nwith a context label $c_i$. Our goal is to % extract from a dataset of labeled\npairs $\\{(c_i, (\\mu_i, \\nu_i))\\}$ learn a global map $\\mathcal{T}_{\\theta}$\nwhich is not only expected to fit em all pairs in the dataset $\\{(c_i, (\\mu_i,\n\\nu_i))\\}$, i.e., $\\mathcal{T}_{\\theta}(c_i) \\sharp\\mu_i \\approx \\nu_i$, but\nshould generalize to produce meaningful maps\n$\\mathcal{T}_{\\theta}(c_{\\text{new}})$ conditioned on unseen contexts\n$c_{\\text{new}}$. Our approach harnesses and provides a novel usage for\npartially input convex neural networks, for which we introduce a robust and\nefficient initialization strategy inspired by Gaussian approximations. We\ndemonstrate the ability of CondOT to infer the effect of an arbitrary\ncombination of genetic or therapeutic perturbations on single cells, using only\nobservations of the effects of said perturbations separately.",
    "descriptor": "",
    "authors": [
      "Charlotte Bunne",
      "Andreas Krause",
      "Marco Cuturi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14262"
  },
  {
    "id": "arXiv:2206.14263",
    "title": "ZoDIAC: Zoneout Dropout Injection Attention Calculation",
    "abstract": "Recently the use of self-attention has yielded to state-of-the-art results in\nvision-language tasks such as image captioning as well as natural language\nunderstanding and generation (NLU and NLG) tasks and computer vision tasks such\nas image classification. This is since self-attention maps the internal\ninteractions among the elements of input source and target sequences. Although\nself-attention successfully calculates the attention values and maps the\nrelationships among the elements of input source and target sequence, yet there\nis no mechanism to control the intensity of attention. In real world, when\ncommunicating with each other face to face or vocally, we tend to express\ndifferent visual and linguistic context with various amounts of intensity. Some\nwords might carry (be spoken with) more stress and weight indicating the\nimportance of that word in the context of the whole sentence. Based on this\nintuition, we propose Zoneout Dropout Injection Attention Calculation (ZoDIAC)\nin which the intensities of attention values in the elements of the input\nsequence are calculated with respect to the context of the elements of input\nsequence. The results of our experiments reveal that employing ZoDIAC leads to\nbetter performance in comparison with the self-attention module in the\nTransformer model. The ultimate goal is to find out if we could modify\nself-attention module in the Transformer model with a method that is\npotentially extensible to other models that leverage on self-attention at their\ncore. Our findings suggest that this particular goal deserves further attention\nand investigation by the research community.\nThe code for ZoDIAC is available on www.github.com/zanyarz/zodiac .",
    "descriptor": "\nComments: This work has been submitted to SN-AIRE journal and is currently under review\n",
    "authors": [
      "Zanyar Zohourianshahzadi",
      "Jugal Kalita"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.14263"
  },
  {
    "id": "arXiv:2206.14264",
    "title": "Simple and Effective Knowledge-Driven Query Expansion for QA-Based  Product Attribute Extraction",
    "abstract": "A key challenge in attribute value extraction (AVE) from e-commerce sites is\nhow to handle a large number of attributes for diverse products. Although this\nchallenge is partially addressed by a question answering (QA) approach which\nfinds a value in product data for a given query (attribute), it does not work\neffectively for rare and ambiguous queries. We thus propose simple\nknowledge-driven query expansion based on possible answers (values) of a query\n(attribute) for QA-based AVE. We retrieve values of a query (attribute) from\nthe training data to expand the query. We train a model with two tricks,\nknowledge dropout and knowledge token mixing, which mimic the imperfection of\nthe value knowledge in testing. Experimental results on our cleaned version of\nAliExpress dataset show that our method improves the performance of AVE (+6.08\nmacro F1), especially for rare and ambiguous attributes (+7.82 and +6.86 macro\nF1, respectively).",
    "descriptor": "\nComments: Published at ACL 2022\n",
    "authors": [
      "Keiji Shinzato",
      "Naoki Yoshinaga",
      "Yandi Xia",
      "Wei-Te Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.14264"
  },
  {
    "id": "arXiv:2206.14265",
    "title": "Online Anomaly Detection Based On Reservoir Sampling and LOF for IoT  devices",
    "abstract": "The growing number of IoT devices and their use to monitor the operation of\nmachines and equipment increases interest in anomaly detection algorithms\nrunning on devices. However, the difficulty is the limitations of the available\ncomputational and memory resources on the devices. In the case of\nmicrocontrollers (MCUs), these are single megabytes of program and several\nhundred kilobytes of working memory. Consequently, algorithms must be\nappropriately matched to the capabilities of the devices. In the paper, we\nanalyse the processing pipeline for anomaly detection and implementation of the\nLocal Outliner Factor (LOF) algorithm on a MCU. We also show that it is\npossible to train such an algorithm directly on the device, which gives great\npotential to use the solution in real devices.",
    "descriptor": "",
    "authors": [
      "Tomasz Szydlo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14265"
  },
  {
    "id": "arXiv:2206.14267",
    "title": "Applications of Reinforcement Learning in Finance -- Trading with a  Double Deep Q-Network",
    "abstract": "This paper presents a Double Deep Q-Network algorithm for trading single\nassets, namely the E-mini S&P 500 continuous futures contract. We use a proven\nsetup as the foundation for our environment with multiple extensions. The\nfeatures of our trading agent are constantly being expanded to include\nadditional assets such as commodities, resulting in four models. We also\nrespond to environmental conditions, including costs and crises. Our trading\nagent is first trained for a specific time period and tested on new data and\ncompared with the long-and-hold strategy as a benchmark (market). We analyze\nthe differences between the various models and the in-sample/out-of-sample\nperformance with respect to the environment. The experimental results show that\nthe trading agent follows an appropriate behavior. It can adjust its policy to\ndifferent circumstances, such as more extensive use of the neutral position\nwhen trading costs are present. Furthermore, the net asset value exceeded that\nof the benchmark, and the agent outperformed the market in the test set. We\nprovide initial insights into the behavior of an agent in a financial domain\nusing a DDQN algorithm. The results of this study can be used for further\ndevelopment.",
    "descriptor": "",
    "authors": [
      "Frensi Zejnullahu",
      "Maurice Moser",
      "Joerg Osterrieder"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Trading and Market Microstructure (q-fin.TR)"
    ],
    "url": "https://arxiv.org/abs/2206.14267"
  },
  {
    "id": "arXiv:2206.14268",
    "title": "BertNet: Harvesting Knowledge Graphs from Pretrained Language Models",
    "abstract": "Symbolic knowledge graphs (KGs) have been constructed either by expensive\nhuman crowdsourcing or with domain-specific complex information extraction\npipelines. The emerging large pretrained language models (LMs), such as Bert,\nhave shown to implicitly encode massive knowledge which can be queried with\nproperly designed prompts. However, compared to the explicit KGs, the implict\nknowledge in the black-box LMs is often difficult to access or edit and lacks\nexplainability. In this work, we aim at harvesting symbolic KGs from the LMs, a\nnew framework for automatic KG construction empowered by the neural LMs'\nflexibility and scalability. Compared to prior works that often rely on large\nhuman annotated data or existing massive KGs, our approach requires only the\nminimal definition of relations as inputs, and hence is suitable for extracting\nknowledge of rich new relations not available before.The approach automatically\ngenerates diverse prompts, and performs efficient knowledge search within a\ngiven LM for consistent and extensive outputs. The harvested knowledge with our\napproach is substantially more accurate than with previous methods, as shown in\nboth automatic and human evaluation. As a result, we derive from diverse LMs a\nfamily of new KGs (e.g., BertNet and RoBERTaNet) that contain a richer set of\ncommonsense relations, including complex ones (e.g., \"A is capable of but not\ngood at B\"), than the human-annotated KGs (e.g., ConceptNet). Besides, the\nresulting KGs also serve as a vehicle to interpret the respective source LMs,\nleading to new insights into the varying knowledge capability of different LMs.",
    "descriptor": "\nComments: Code available at this https URL\n",
    "authors": [
      "Shibo Hao",
      "Bowen Tan",
      "Kaiwen Tang",
      "Hengzhe Zhang",
      "Eric P Xing",
      "Zhiting Hu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.14268"
  },
  {
    "id": "arXiv:2206.14270",
    "title": "Exporting Ada Software to Python and Julia",
    "abstract": "The objective is to demonstrate the making of Ada software available to\nPython and Julia programmers using GPRbuild. GPRbuild is the project manager of\nthe GNAT toolchain. With GPRbuild the making of shared object files is fully\nautomated and the software can be readily used in Python and Julia. The\napplication is the build process of PHCpack, a free and open source software\npackage to solve polynomial systems by homotopy continuation methods, written\nmainly in Ada, with components in C++, available at github at\nhttps://github.com/janverschelde/PHCpack.",
    "descriptor": "\nComments: To appear in the Ada User Journal, in the Proceedings of the Ada Devroom at FOSDEM 2022\n",
    "authors": [
      "Jan Verschelde"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.14270"
  },
  {
    "id": "arXiv:2206.14272",
    "title": "Collecting high-quality adversarial data for machine reading  comprehension tasks with humans and models in the loop",
    "abstract": "We present our experience as annotators in the creation of high-quality,\nadversarial machine-reading-comprehension data for extractive QA for Task 1 of\nthe First Workshop on Dynamic Adversarial Data Collection (DADC). DADC is an\nemergent data collection paradigm with both models and humans in the loop. We\nset up a quasi-experimental annotation design and perform quantitative analyses\nacross groups with different numbers of annotators focusing on successful\nadversarial attacks, cost analysis, and annotator confidence correlation. We\nfurther perform a qualitative analysis of our perceived difficulty of the task\ngiven the different topics of the passages in our dataset and conclude with\nrecommendations and suggestions that might be of value to people working on\nfuture DADC tasks and related annotation interfaces.",
    "descriptor": "\nComments: 8 pages, 3 figures, for more information about the shared task please go to this https URL\n",
    "authors": [
      "Damian Y. Romero Diaz",
      "Magdalena Anio\u0142",
      "John Culnan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14272"
  },
  {
    "id": "arXiv:2206.14276",
    "title": "NumS: Scalable Array Programming for the Cloud",
    "abstract": "Scientists increasingly rely on Python tools to perform scalable distributed\nmemory array operations using rich, NumPy-like expressions. However, many of\nthese tools rely on dynamic schedulers optimized for abstract task graphs,\nwhich often encounter memory and network bandwidth-related bottlenecks due to\nsub-optimal data and operator placement decisions. Tools built on the message\npassing interface (MPI), such as ScaLAPACK and SLATE, have better scaling\nproperties, but these solutions require specialized knowledge to use. In this\nwork, we present NumS, an array programming library which optimizes NumPy-like\nexpressions on task-based distributed systems. This is achieved through a novel\nscheduler called Load Simulated Hierarchical Scheduling (LSHS). LSHS is a local\nsearch method which optimizes operator placement by minimizing maximum memory\nand network load on any given node within a distributed system. Coupled with a\nheuristic for load balanced data layouts, our approach is capable of attaining\ncommunication lower bounds on some common numerical operations, and our\nempirical study shows that LSHS enhances performance on Ray by decreasing\nnetwork load by a factor of 2x, requiring 4x less memory, and reducing\nexecution time by 10x on the logistic regression problem. On terabyte-scale\ndata, NumS achieves competitive performance to SLATE on DGEMM, up to 20x\nspeedup over Dask on a key operation for tensor factorization, and a 2x speedup\non logistic regression compared to Dask ML and Spark's MLlib.",
    "descriptor": "",
    "authors": [
      "Melih Elibol",
      "Vinamra Benara",
      "Samyu Yagati",
      "Lianmin Zheng",
      "Alvin Cheung",
      "Michael I. Jordan",
      "Ion Stoica"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Mathematical Software (cs.MS)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2206.14276"
  },
  {
    "id": "arXiv:2206.14279",
    "title": "The Benefits of Hydrogen Energy Transmission and Conversion Systems to  the Renewable Power Grids: Day-ahead Unit Commitment",
    "abstract": "The curtailment of renewable energy is more frequently observed as the\nrenewable penetration levels are rising rapidly in modern power systems. It is\na waste of free and green renewable energy and implies current power grids are\nunable to accommodate more renewable sources. One major reason is that higher\npower transmission capacity is required for higher renewable penetration level.\nAnother major reason is the volatility of the renewable generation. The\nhydrogen mix or pure hydrogen pipeline can both transfer and store the energy\nin the form of hydrogen. However, its potential of accelerating renewable\nintegration has not been investigated. In this paper, hydrogen pipeline\nnetworks, combined with power-to-hydrogen (P2H) and hydrogen-to-power (H2P)\nfacilities, are organized to form a Hydrogen Energy Transmission and Conversion\nSystem (HETCS). We investigate the operation of power systems coupled with\nHETCS, and propose the day-ahead security-constrained unit commitment (SCUC)\nwith HETCS. The SCUC simulation is conducted on a modified IEEE 24-bus power\nsystem with HETCS. Simulation results show HETCS can substantially reduce the\nrenewable curtailment, CO2 emission, load payment and total operational cost.\nThis study validates the HETCS can be a promising solution to achieve net-zero\nrenewable grids.",
    "descriptor": "\nComments: 6 pages,5 figures\n",
    "authors": [
      "Jin Lu",
      "Xingpeng Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.14279"
  },
  {
    "id": "arXiv:2206.14280",
    "title": "The numerical solution of fractional integral equations via orthogonal  polynomials in fractional powers",
    "abstract": "We present a spectral method for one-sided linear fractional integral\nequations on a closed interval that achieves exponentially fast convergence for\na variety of equations, including ones with irrational order, multiple\nfractional orders, non-trivial variable coefficients, and initial-boundary\nconditions. The method uses an orthogonal basis that we refer to as Jacobi\nfractional polynomials, which are obtained from an appropriate change of\nvariable in weighted classical Jacobi polynomials. New algorithms for building\nthe matrices used to represent fractional integration operators are presented\nand compared. Even though these algorithms are unstable and require the use of\nhigh-precision computations, the spectral method nonetheless yields\nwell-conditioned linear systems and is therefore stable and efficient. For\ntime-fractional heat and wave equations, we show that our method (which is not\nsparse but uses an orthogonal basis) outperforms a sparse spectral method\n(which uses a basis that is not orthogonal) due to its superior stability.",
    "descriptor": "\nComments: 35 pages, 3 of which are references. 16 figures, all of which can be reproduced by Julia codes at this https URL\n",
    "authors": [
      "Tianyi Pu",
      "Marco Fasondini"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.14280"
  },
  {
    "id": "arXiv:2206.14282",
    "title": "Neural Integro-Differential Equations",
    "abstract": "Modeling continuous dynamical systems from discretely sampled observations is\na fundamental problem in data science. Often, such dynamics are the result of\nnon-local processes that present an integral over time. As such, these systems\nare modeled with Integro-Differential Equations (IDEs); generalizations of\ndifferential equations that comprise both an integral and a differential\ncomponent. For example, brain dynamics are not accurately modeled by\ndifferential equations since their behavior is non-Markovian, i.e. dynamics are\nin part dictated by history. Here, we introduce the Neural IDE (NIDE), a\nframework that models ordinary and integral components of IDEs using neural\nnetworks. We test NIDE on several toy and brain activity datasets and\ndemonstrate that NIDE outperforms other models, including Neural ODE. These\ntasks include time extrapolation as well as predicting dynamics from unseen\ninitial conditions, which we test on whole-cortex activity recordings in freely\nbehaving mice. Further, we show that NIDE can decompose dynamics into its\nMarkovian and non-Markovian constituents, via the learned integral operator,\nwhich we test on fMRI brain activity recordings of people on ketamine. Finally,\nthe integrand of the integral operator provides a latent space that gives\ninsight into the underlying dynamics, which we demonstrate on wide-field brain\nimaging recordings. Altogether, NIDE is a novel approach that enables modeling\nof complex non-local dynamics with neural networks.",
    "descriptor": "\nComments: 15 pages (including 4 pages Appendix), 8 figures and 4 tables\n",
    "authors": [
      "Emanuele Zappala",
      "Antonio Henrique de Oliveira Fonseca",
      "Andrew Henry Moberly",
      "Michael James Higley",
      "Chadi Abdallah",
      "Jessica Cardin",
      "David van Dijk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14282"
  },
  {
    "id": "arXiv:2206.14285",
    "title": "Lessons Learned on MPI+Threads Communication",
    "abstract": "Hybrid MPI+threads programming is gaining prominence, but, in practice,\napplications perform slower with it compared to the MPI everywhere model. The\nmost critical challenge to the parallel efficiency of MPI+threads applications\nis slow MPI_THREAD_MULTIPLE performance. MPI libraries have recently made\nsignificant strides on this front, but to exploit their capabilities, users\nmust expose the communication parallelism in their MPI+threads applications.\nRecent studies show that MPI 4.0 provides users with new performance-oriented\noptions to do so, but our evaluation of these new mechanisms shows that they\npose several challenges. An alternative design is MPI Endpoints. In this paper,\nwe present a comparison of the different designs from the perspective of MPI's\nend-users: domain scientists and application developers. We evaluate the\nmechanisms on metrics beyond performance such as usability, scope, and\nportability. Based on the lessons learned, we make a case for a future\ndirection.",
    "descriptor": "\nComments: In Proceedings of the International Conference for High-Performance Computing, Networking, Storage and Analysis (SC), Dallas, TX, USA, November 2022\n",
    "authors": [
      "Rohit Zambre",
      "Aparna Chandramowlishwaran"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.14285"
  },
  {
    "id": "arXiv:2206.14286",
    "title": "TPU-KNN: K Nearest Neighbor Search at Peak FLOP/s",
    "abstract": "This paper presents a novel nearest neighbor search algorithm achieving TPU\n(Google Tensor Processing Unit) peak performance, outperforming\nstate-of-the-art GPU algorithms with similar level of recall. The design of the\nproposed algorithm is motivated by an accurate accelerator performance model\nthat takes into account both the memory and instruction bottlenecks. Our\nalgorithm comes with an analytical guarantee of recall in expectation and does\nnot require maintaining sophisticated index data structure or tuning, making it\nsuitable for applications with frequent updates. Our work is available in the\nopen-source package of Jax and Tensorflow on TPU.",
    "descriptor": "",
    "authors": [
      "Felix Chern",
      "Blake Hechtman",
      "Andy Davis",
      "Ruiqi Guo",
      "David Majnemer",
      "Sanjiv Kumar"
    ],
    "subjectives": [
      "Performance (cs.PF)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14286"
  },
  {
    "id": "arXiv:2206.14288",
    "title": "Learning Time Delay Systems with Neural Ordinary Differential Equations",
    "abstract": "A novel way of using neural networks to learn the dynamics of time delay\nsystems from sequential data is proposed. A neural network with trainable\ndelays is used to approximate the right hand side of a delay differential\nequation. We relate the delay differential equation to an ordinary differential\nequation by discretizing the time history and train the corresponding neural\nordinary differential equation (NODE) to learn the dynamics. An example on\nlearning the dynamics of the Mackey-Glass equation using data from chaotic\nbehavior is given. After learning both the nonlinearity and the time delay, we\ndemonstrate that the bifurcation diagram of the neural network matches that of\nthe original system.",
    "descriptor": "\nComments: Submitted to 17th IFAC Workshop on Time Delay Systems. 6 pages, 8 figures\n",
    "authors": [
      "Xunbi A. Ji",
      "Gabor Orosz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2206.14288"
  },
  {
    "id": "arXiv:2206.14289",
    "title": "Stronger Together: Air-Ground Robotic Collaboration Using Semantics",
    "abstract": "In this work, we present an end-to-end heterogeneous multi-robot system\nframework where ground robots are able to localize, plan, and navigate in a\nsemantic map created in real time by a high-altitude quadrotor. The ground\nrobots choose and deconflict their targets independently, without any external\nintervention. Moreover, they perform cross-view localization by matching their\nlocal maps with the overhead map using semantics. The communication backbone is\nopportunistic and distributed, allowing the entire system to operate with no\nexternal infrastructure aside from GPS for the quadrotor. We extensively tested\nour system by performing different missions on top of our framework over\nmultiple experiments in different environments. Our ground robots travelled\nover 6 km autonomously with minimal intervention in the real world and over 96\nkm in simulation without interventions.",
    "descriptor": "\nComments: Sumbitted to RA-L and IROS\n",
    "authors": [
      "Ian D. Miller",
      "Fernando Cladera",
      "Trey Smith",
      "Camillo Jose Taylor",
      "Vijay Kumar"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.14289"
  },
  {
    "id": "arXiv:2206.14293",
    "title": "Human-Multirobot Collaborative Mobile Manipulation: the Omnid Mocobots",
    "abstract": "The Omnid human-collaborative mobile manipulators are an experimental\nplatform for testing control architectures for autonomous and\nhuman-collaborative multirobot mobile manipulation. An Omnid consists of a\nmecanum-wheel omnidirectional mobile base and a series-elastic Delta-type\nparallel manipulator, and it is a specific implementation of a broader class of\nmobile collaborative robots (\"mocobots\") suitable for safe human\nco-manipulation of delicate, flexible, and articulated payloads. Key features\nof mocobots include passive compliance, for the safety of the human and the\npayload, and high-fidelity end-effector force control independent of the\npotentially imprecise motions of the mobile base. We describe general\nconsiderations for the design of teams of mocobots; the design of the Omnids in\nlight of these considerations; manipulator and mobile base controllers to\nachieve useful multirobot collaborative behaviors; and initial experiments in\nhuman-multirobot collaborative mobile manipulation of large, unwieldy payloads.\nFor these experiments, the only communication among the humans and Omnids is\nmechanical, through the payload.",
    "descriptor": "\nComments: 8 pages, 10 figures. Videos available at this https URL Submitted to IEEE Robotics and Automation Letters (RA-L)\n",
    "authors": [
      "Matthew L. Elwin",
      "Billie Strong",
      "Randy A. Freeman",
      "Kevin M. Lynch"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.14293"
  },
  {
    "id": "arXiv:2206.14298",
    "title": "Left Heavy Tails and the Effectiveness of the Policy and Value Networks  in DNN-based best-first search for Sokoban Planning",
    "abstract": "Despite the success of practical solvers in various NP-complete domains such\nas SAT and CSP as well as using deep reinforcement learning to tackle\ntwo-player games such as Go, certain classes of PSPACE-hard planning problems\nhave remained out of reach. Even carefully designed domain-specialized solvers\ncan fail quickly due to the exponential search space on hard instances. Recent\nworks that combine traditional search methods, such as best-first search and\nMonte Carlo tree search, with Deep Neural Networks' (DNN) heuristics have shown\npromising progress and can solve a significant number of hard planning\ninstances beyond specialized solvers. To better understand why these approaches\nwork, we studied the interplay of the policy and value networks of DNN-based\nbest-first search on Sokoban and show the surprising effectiveness of the\npolicy network, further enhanced by the value network, as a guiding heuristic\nfor the search. To further understand the phenomena, we studied the cost\ndistribution of the search algorithms and found that Sokoban instances can have\nheavy-tailed runtime distributions, with tails both on the left and right-hand\nsides. In particular, for the first time, we show the existence of \\textit{left\nheavy tails} and propose an abstract tree model that can empirically explain\nthe appearance of these tails. The experiments show the critical role of the\npolicy network as a powerful heuristic guiding the search, which can lead to\nleft heavy tails with polynomial scaling by avoiding exploring exponentially\nsized subtrees. Our results also demonstrate the importance of random restarts,\nas are widely used in traditional combinatorial solvers, for DNN-based search\nmethods to avoid left and right heavy tails.",
    "descriptor": "",
    "authors": [
      "Dieqiao Feng",
      "Carla Gomes",
      "Bart Selman"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.14298"
  },
  {
    "id": "arXiv:2206.14302",
    "title": "Reinforcement Learning in Medical Image Analysis: Concepts,  Applications, Challenges, and Future Directions",
    "abstract": "Motivation: Medical image analysis involves tasks to assist physicians in\nqualitative and quantitative analysis of lesions or anatomical structures,\nsignificantly improving the accuracy and reliability of diagnosis and\nprognosis. Traditionally, these tasks are finished by physicians or medical\nphysicists and lead to two major problems: (i) low efficiency; (ii) biased by\npersonal experience. In the past decade, many machine learning methods have\nbeen applied to accelerate and automate the image analysis process. Compared to\nthe enormous deployments of supervised and unsupervised learning models,\nattempts to use reinforcement learning in medical image analysis are scarce.\nThis review article could serve as the stepping-stone for related research.\nSignificance: From our observation, though reinforcement learning has gradually\ngained momentum in recent years, many researchers in the medical analysis field\nfind it hard to understand and deploy in clinics. One cause is lacking\nwell-organized review articles targeting readers lacking professional computer\nscience backgrounds. Rather than providing a comprehensive list of all\nreinforcement learning models in medical image analysis, this paper may help\nthe readers to learn how to formulate and solve their medical image analysis\nresearch as reinforcement learning problems. Approach & Results: We selected\npublished articles from Google Scholar and PubMed. Considering the scarcity of\nrelated articles, we also included some outstanding newest preprints. The\npapers are carefully reviewed and categorized according to the type of image\nanalysis task. We first review the basic concepts and popular models of\nreinforcement learning. Then we explore the applications of reinforcement\nlearning models in landmark detection. Finally, we conclude the article by\ndiscussing the reviewed reinforcement learning approaches' limitations and\npossible improvements.",
    "descriptor": "\nComments: 30 pages, 13 figures\n",
    "authors": [
      "Mingzhe Hu",
      "Jiahan Zhang",
      "Luke Matkovic",
      "Tian Liu",
      "Xiaofeng Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14302"
  },
  {
    "id": "arXiv:2206.14304",
    "title": "Indistinguishability Obfuscation of Circuits and its Application in  Security",
    "abstract": "Under discussion in the paper is an $i\\mathcal{O}$ (indistinguishability\nobfuscator) for circuits in Nick's Class. The obfuscator is constructed by\nencoding the Branching Program given by Barrington's theorem using Multilinear\nJigsaw Puzzle framework. We will show under various indistinguishability\nhardness assumptions, the constructed obfuscator is an $i\\mathcal{O}$ for\nNick's Class. Using Fully Homomorphic Encryption, we will amplify the result\nand construct an $i\\mathcal{O}$ for $\\textbf{P}/poly$, which are circuits of\npolynomial size. Discussion on $i\\mathcal{O}$ and Functional Encryption is also\nincluded in this paper.",
    "descriptor": "",
    "authors": [
      "Shilun Li",
      "Zijing Di"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2206.14304"
  },
  {
    "id": "arXiv:2206.14314",
    "title": "Generative Neural Articulated Radiance Fields",
    "abstract": "Unsupervised learning of 3D-aware generative adversarial networks (GANs)\nusing only collections of single-view 2D photographs has very recently made\nmuch progress. These 3D GANs, however, have not been demonstrated for human\nbodies and the generated radiance fields of existing frameworks are not\ndirectly editable, limiting their applicability in downstream tasks. We propose\na solution to these challenges by developing a 3D GAN framework that learns to\ngenerate radiance fields of human bodies or faces in a canonical pose and warp\nthem using an explicit deformation field into a desired body pose or facial\nexpression. Using our framework, we demonstrate the first high-quality radiance\nfield generation results for human bodies. Moreover, we show that our\ndeformation-aware training procedure significantly improves the quality of\ngenerated bodies or faces when editing their poses or facial expressions\ncompared to a 3D GAN that is not trained with explicit deformations.",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Alexander W. Bergman",
      "Petr Kellnhofer",
      "Yifan Wang",
      "Eric R. Chan",
      "David B. Lindell",
      "Gordon Wetzstein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2206.14314"
  },
  {
    "id": "arXiv:2206.14317",
    "title": "Quantitative Verification of Opacity Properties in Security Systems",
    "abstract": "We delineate a methodology for the specification and verification of flow\nsecurity properties expressible in the opacity framework. We propose a logic,\nOpacTL , for straightforwardly expressing such properties in systems that can\nbe modelled as partially observable labelled transition systems.We develop\nverification techniques for analysing property opacity with respect to\nobservation notions. Adding a probabilistic operator to the specification\nlanguage enables quantitative analysis and verification. This analysis is\nimplemented as an extension to the PRISM model checker and illustrated via a\nnumber of examples. Finally, an alternative approach to quantifying the opacity\nproperty based on entropy is sketched.",
    "descriptor": "",
    "authors": [
      "Chunyan Mu",
      "David Clark"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.14317"
  },
  {
    "id": "arXiv:2206.14318",
    "title": "Bottleneck Low-rank Transformers for Low-resource Spoken Language  Understanding",
    "abstract": "End-to-end spoken language understanding (SLU) systems benefit from\npretraining on large corpora, followed by fine-tuning on application-specific\ndata. The resulting models are too large for on-edge applications. For\ninstance, BERT-based systems contain over 110M parameters. Observing the model\nis overparameterized, we propose lean transformer structure where the dimension\nof the attention mechanism is automatically reduced using group sparsity. We\npropose a variant where the learned attention subspace is transferred to an\nattention bottleneck layer. In a low-resource setting and without pre-training,\nthe resulting compact SLU model achieves accuracies competitive with\npre-trained large models.",
    "descriptor": "\nComments: Accepted by Interspeech 2022\n",
    "authors": [
      "Pu Wang",
      "Hugo Van hamme"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.14318"
  },
  {
    "id": "arXiv:2206.14322",
    "title": "An Empirical Study of Challenges in Converting Deep Learning Models",
    "abstract": "There is an increase in deploying Deep Learning (DL)-based software systems\nin real-world applications. Usually DL models are developed and trained using\nDL frameworks that have their own internal mechanisms/formats to represent and\ntrain DL models, and usually those formats cannot be recognized by other\nframeworks. Moreover, trained models are usually deployed in environments\ndifferent from where they were developed. To solve the interoperability issue\nand make DL models compatible with different frameworks/environments, some\nexchange formats are introduced for DL models, like ONNX and CoreML. However,\nONNX and CoreML were never empirically evaluated by the community to reveal\ntheir prediction accuracy, performance, and robustness after conversion. Poor\naccuracy or non-robust behavior of converted models may lead to poor quality of\ndeployed DL-based software systems. We conduct, in this paper, the first\nempirical study to assess ONNX and CoreML for converting trained DL models. In\nour systematic approach, two popular DL frameworks, Keras and PyTorch, are used\nto train five widely used DL models on three popular datasets. The trained\nmodels are then converted to ONNX and CoreML and transferred to two runtime\nenvironments designated for such formats, to be evaluated. We investigate the\nprediction accuracy before and after conversion. Our results unveil that the\nprediction accuracy of converted models are at the same level of originals. The\nperformance (time cost and memory consumption) of converted models are studied\nas well. The size of models are reduced after conversion, which can result in\noptimized DL-based software deployment. Converted models are generally assessed\nas robust at the same level of originals. However, obtained results show that\nCoreML models are more vulnerable to adversarial attacks compared to ONNX.",
    "descriptor": "\nComments: Accepted for publication in ICSME 2022\n",
    "authors": [
      "Moses Openja",
      "Amin Nikanjam",
      "Ahmed Haj Yahmed",
      "Foutse Khomh",
      "Zhen Ming",
      "Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14322"
  },
  {
    "id": "arXiv:2206.14326",
    "title": "Multiuser MISO PS-SWIPT Systems: Active or Passive RIS?",
    "abstract": "Reconfigurable intelligent surface (RIS)-based communication networks promise\nto improve channel capacity and energy efficiency. However, the promised\ncapacity gains could be negligible for passive RISs because of the double\npathloss effect. Active RISs can overcome this issue because they have\nreflector elements with a low-cost amplifier. This letter studies the active\nRIS-aided simultaneous wireless information and power transfer (SWIPT) in a\nmultiuser system. The users exploit power splitting (PS) to decode information\nand harvest energy simultaneously based on a realistic piecewise nonlinear\nenergy harvesting model. The goal is to minimize the base station (BS) transmit\npower by optimizing its beamformers, PS ratios, and RIS phase\nshifts/amplification factors. The simulation results show significant\nimprovements (e.g., 19% and 28%) with the maximum reflect power of 10 mW and 15\nmW, respectively, compared to the passive RIS without higher computational\ncomplexity cost. We also show the robustness of the proposed algorithm against\nimperfect channel state information.",
    "descriptor": "\nComments: Accepted for publication in the IEEE Wireless Communications Letters\n",
    "authors": [
      "Shayan Zargari",
      "Azar Hakimi",
      "Chintha Tellambura",
      "Sanjeewa Herath"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.14326"
  },
  {
    "id": "arXiv:2206.14329",
    "title": "On the R\u00e9nyi Cross-Entropy",
    "abstract": "The R\\'{e}nyi cross-entropy measure between two distributions, a\ngeneralization of the Shannon cross-entropy, was recently used as a loss\nfunction for the improved design of deep learning generative adversarial\nnetworks. In this work, we examine the properties of this measure and derive\nclosed-form expressions for it when one of the distributions is fixed and when\nboth distributions belong to the exponential family. We also analytically\ndetermine a formula for the cross-entropy rate for stationary Gaussian\nprocesses and for finite-alphabet Markov sources.",
    "descriptor": "\nComments: To appear in the Proceedings of CWIT'22\n",
    "authors": [
      "Ferenc Cole Thierrin",
      "Fady Alajaji",
      "Tam\u00e1s Linder"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14329"
  },
  {
    "id": "arXiv:2206.14330",
    "title": "Estimation of User Coordinates via Channel Charting and MUSIC",
    "abstract": "We present a new way of producing a channel chart in polar coordinates. We\nestimate the angle of arrival theta and the distance between the base station\nand the user equipment rho using the MUSIC algorithm and inverse of the root\nsum squares of channel coefficients (ISQ) or linear regression (LR). We compare\nthis method with the channel charting algorithms principal component analysis\n(PCA), Samson's method (SM), and autoencoder (AE). We show that ISQ and LR\noutperform all three in both performance and complexity. The performance of LR\nand ISQ are close, with ISQ having less complexity.",
    "descriptor": "\nComments: 5 pages, 7 figures, 2 tables\n",
    "authors": [
      "Amr Ali",
      "Ender Ayanoglu"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2206.14330"
  },
  {
    "id": "arXiv:2206.14332",
    "title": "Active Exploration via Experiment Design in Markov Chains",
    "abstract": "A key challenge in science and engineering is to design experiments to learn\nabout some unknown quantity of interest. Classical experimental design\noptimally allocates the experimental budget to maximize a notion of utility\n(e.g., reduction in uncertainty about the unknown quantity). We consider a rich\nsetting, where the experiments are associated with states in a {\\em Markov\nchain}, and we can only choose them by selecting a {\\em policy} controlling the\nstate transitions. This problem captures important applications, from\nexploration in reinforcement learning to spatial monitoring tasks. We propose\nan algorithm -- \\textsc{markov-design} -- that efficiently selects policies\nwhose measurement allocation \\emph{provably converges to the optimal one}. The\nalgorithm is sequential in nature, adapting its choice of policies\n(experiments) informed by past measurements. In addition to our theoretical\nanalysis, we showcase our framework on applications in ecological surveillance\nand pharmacology.",
    "descriptor": "",
    "authors": [
      "Mojm\u00edr Mutn\u00fd",
      "Tadeusz Janik",
      "Andreas Krause"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.14332"
  },
  {
    "id": "arXiv:2206.14337",
    "title": "Deformable Graph Transformer",
    "abstract": "Transformer-based models have been widely used and achieved state-of-the-art\nperformance in various domains such as natural language processing and computer\nvision. Recent works show that Transformers can also be generalized to\ngraph-structured data. However, the success is limited to small-scale graphs\ndue to technical challenges such as the quadratic complexity in regards to the\nnumber of nodes and non-local aggregation that often leads to inferior\ngeneralization performance to conventional graph neural networks. In this\npaper, to address these issues, we propose Deformable Graph Transformer (DGT)\nthat performs sparse attention with dynamically sampled key and value pairs.\nSpecifically, our framework first constructs multiple node sequences with\nvarious criteria to consider both structural and semantic proximity. Then, the\nsparse attention is applied to the node sequences for learning node\nrepresentations with a reduced computational cost. We also design simple and\neffective positional encodings to capture structural similarity and distance\nbetween nodes. Experiments demonstrate that our novel graph Transformer\nconsistently outperforms existing Transformer-based models and shows\ncompetitive performance compared to state-of-the-art models on 8 graph\nbenchmark datasets including large-scale graphs.",
    "descriptor": "\nComments: 12 pages, 3 figures\n",
    "authors": [
      "Jinyoung Park",
      "Seongjun Yun",
      "Hyeonjin Park",
      "Jaewoo Kang",
      "Jisu Jeong",
      "Kyung-Min Kim",
      "Jung-woo Ha",
      "Hyunwoo J. Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14337"
  },
  {
    "id": "arXiv:2206.14341",
    "title": "CoAP-DoS: An IoT Network Intrusion Dataset",
    "abstract": "The need for secure Internet of Things (IoT) devices is growing as IoT\ndevices are becoming more integrated into vital networks. Many systems rely on\nthese devices to remain available and provide reliable service. Denial of\nservice attacks against IoT devices are a real threat due to the fact these low\npower devices are very susceptible to denial-of-service attacks. Machine\nlearning enabled network intrusion detection systems are effective at\nidentifying new threats, but they require a large amount of data to work well.\nThere are many network traffic data sets but very few that focus on IoT network\ntraffic. Within the IoT network data sets there is a lack of CoAP denial of\nservice data. We propose a novel data set covering this gap. We develop a new\ndata set by collecting network traffic from real CoAP denial of service attacks\nand compare the data on multiple different machine learning classifiers. We\nshow that the data set is effective on many classifiers.",
    "descriptor": "\nComments: 6 pages, 8 figures, Publication Title: 2022 6th International Conference on Cryptography, Security and Privacy (CSP), eCF Paper Id: 1641864704381, accepted for publishing, not yet published\n",
    "authors": [
      "Jared Mathews",
      "Prosenjit Chatterjee",
      "Shankar Banik"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.14341"
  },
  {
    "id": "arXiv:2206.14342",
    "title": "Intrinsic Anomaly Detection for Multi-Variate Time Series",
    "abstract": "We introduce a novel, practically relevant variation of the anomaly detection\nproblem in multi-variate time series: intrinsic anomaly detection. It appears\nin diverse practical scenarios ranging from DevOps to IoT, where we want to\nrecognize failures of a system that operates under the influence of a\nsurrounding environment. Intrinsic anomalies are changes in the functional\ndependency structure between time series that represent an environment and time\nseries that represent the internal state of a system that is placed in said\nenvironment. We formalize this problem, provide under-studied public and new\npurpose-built data sets for it, and present methods that handle intrinsic\nanomaly detection. These address the short-coming of existing anomaly detection\nmethods that cannot differentiate between expected changes in the system's\nstate and unexpected ones, i.e., changes in the system that deviate from the\nenvironment's influence. Our most promising approach is fully unsupervised and\ncombines adversarial learning and time series representation learning, thereby\naddressing problems such as label sparsity and subjectivity, while allowing to\nnavigate and improve notoriously problematic anomaly detection data sets.",
    "descriptor": "",
    "authors": [
      "Stephan Rabanser",
      "Tim Januschowski",
      "Kashif Rasul",
      "Oliver Borchert",
      "Richard Kurle",
      "Jan Gasthaus",
      "Michael Bohlke-Schneider",
      "Nicolas Papernot",
      "Valentin Flunkert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.14342"
  },
  {
    "id": "arXiv:2206.14344",
    "title": "A New Adjacency Matrix Configuration in GCN-based Models for  Skeleton-based Action Recognition",
    "abstract": "Human skeleton data has received increasing attention in action recognition\ndue to its background robustness and high efficiency. In skeleton-based action\nrecognition, graph convolutional network (GCN) has become the mainstream\nmethod. This paper analyzes the fundamental factor for GCN-based models -- the\nadjacency matrix. We notice that most GCN-based methods conduct their adjacency\nmatrix based on the human natural skeleton structure. Based on our former work\nand analysis, we propose that the human natural skeleton structure adjacency\nmatrix is not proper for skeleton-based action recognition. We propose a new\nadjacency matrix that abandons all rigid neighbor connections but lets the\nmodel adaptively learn the relationships of joints. We conduct extensive\nexperiments and analysis with a validation model on two skeleton-based action\nrecognition datasets (NTURGBD60 and FineGYM). Comprehensive experimental\nresults and analysis reveals that 1) the most widely used human natural\nskeleton structure adjacency matrix is unsuitable in skeleton-based action\nrecognition; 2) The proposed adjacency matrix is superior in model performance,\nnoise robustness and transferability.",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Zheng Fang",
      "Xiongwei Zhang",
      "Tieyong Cao",
      "Yunfei Zheng",
      "Meng Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.14344"
  },
  {
    "id": "arXiv:2206.14346",
    "title": "A Deep Learning Approach to Create DNS Amplification Attacks",
    "abstract": "In recent years, deep learning has shown itself to be an incredibly valuable\ntool in cybersecurity as it helps network intrusion detection systems to\nclassify attacks and detect new ones. Adversarial learning is the process of\nutilizing machine learning to generate a perturbed set of inputs to then feed\nto the neural network to misclassify it. Much of the current work in the field\nof adversarial learning has been conducted in image processing and natural\nlanguage processing with a wide variety of algorithms. Two algorithms of\ninterest are the Elastic-Net Attack on Deep Neural Networks and TextAttack. In\nour experiment the EAD and TextAttack algorithms are applied to a Domain Name\nSystem amplification classifier. The algorithms are used to generate malicious\nDistributed Denial of Service adversarial examples to then feed as inputs to\nthe network intrusion detection systems neural network to classify as valid\ntraffic. We show in this work that both image processing and natural language\nprocessing adversarial learning algorithms can be applied against a network\nintrusion detection neural network.",
    "descriptor": "\nComments: 12 pages, 6 figures, Conference: to 2022 4th International Conference on Management Science and Industrial Engineering (MSIE) (MSIE 2022), DOI: this https URL, accepted to conference above, not yet published\n",
    "authors": [
      "Jared Mathews",
      "Prosenjit Chatterjee",
      "Shankar Banik",
      "Cory Nance"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.14346"
  },
  {
    "id": "arXiv:2206.14347",
    "title": "A biased random-key genetic algorithm for the home health care problem",
    "abstract": "Home health care problems consist of scheduling visits to home patients by\nhealth professionals while following a series of requirements. This paper\nstudies the Home Health Care Routing and Scheduling Problem, which comprises a\nmulti-attribute vehicle routing problem with soft time windows. Additional\nroute inter-dependency constraints apply for patients requesting multiple\nvisits, either by simultaneous visits or visits with precedence. We apply a\nmathematical programming solver to obtain lower bounds for the problem. We also\npropose a biased random-key genetic algorithm, and we study the effects of\nadditional state-of-art components recently proposed in the literature for this\ngenetic algorithm. We perform computational experiment using a publicly\navailable benchmark dataset. Regarding the previous local search-based methods,\nwe find results up to 26.1% better than those of the literature. We find\nimprovements from around 0.4% to 6.36% compared to previous results from a\nsimilar genetic algorithm.",
    "descriptor": "\nComments: 32 pages, 5 figures, submitted to International Transactions in Operational Research\n",
    "authors": [
      "Alberto Kummer",
      "Olinto de Ara\u00fajo",
      "Luciana Buriol",
      "Mauricio Resende"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.14347"
  },
  {
    "id": "arXiv:2206.14348",
    "title": "What Can Secondary Predictions Tell Us? An Exploration on  Question-Answering with SQuAD-v2.0",
    "abstract": "Performance in natural language processing, and specifically for the\nquestion-answer task, is typically measured by comparing a model\\'s most\nconfident (primary) prediction to golden answers (the ground truth). We are\nmaking the case that it is also useful to quantify how close a model came to\npredicting a correct answer even for examples that failed. We define the Golden\nRank (GR) of an example as the rank of its most confident prediction that\nexactly matches a ground truth, and show why such a match always exists. For\nthe 16 transformer models we analyzed, the majority of exactly matched golden\nanswers in secondary prediction space hover very close to the top rank. We\nrefer to secondary predictions as those ranking above 0 in descending\nconfidence probability order. We demonstrate how the GR can be used to classify\nquestions and visualize their spectrum of difficulty, from persistent near\nsuccesses to persistent extreme failures. We derive a new aggregate statistic\nover entire test sets, named the Golden Rank Interpolated Median (GRIM) that\nquantifies the proximity of failed predictions to the top choice made by the\nmodel. To develop some intuition and explore the applicability of these metrics\nwe use the Stanford Question Answering Dataset (SQuAD-2) and a few popular\ntransformer models from the Hugging Face hub. We first demonstrate that the\nGRIM is not directly correlated with the F1 and exact match (EM) scores. We\nthen calculate and visualize these scores for various transformer\narchitectures, probe their applicability in error analysis by clustering failed\npredictions, and compare how they relate to other training diagnostics such as\nthe EM and F1 scores. We finally suggest various research goals, such as\nbroadening data collection for these metrics and their possible use in\nadversarial training.",
    "descriptor": "\nComments: 18 pages, 2 appendices additional 5 pages, 16 figures\n",
    "authors": [
      "Michael Kamfonas",
      "Gabriel Alon"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14348"
  },
  {
    "id": "arXiv:2206.14349",
    "title": "Fleet-DAgger: Interactive Robot Fleet Learning with Scalable Human  Supervision",
    "abstract": "Commercial and industrial deployments of robot fleets often fall back on\nremote human teleoperators during execution when robots are at risk or unable\nto make task progress. With continual learning, interventions from the remote\npool of humans can also be used to improve the robot fleet control policy over\ntime. A central question is how to effectively allocate limited human attention\nto individual robots. Prior work addresses this in the single-robot,\nsingle-human setting. We formalize the Interactive Fleet Learning (IFL)\nsetting, in which multiple robots interactively query and learn from multiple\nhuman supervisors. We present a fully implemented open-source IFL benchmark\nsuite of GPU-accelerated Isaac Gym environments for the evaluation of IFL\nalgorithms. We propose Fleet-DAgger, a family of IFL algorithms, and compare a\nnovel Fleet-DAgger algorithm to 4 baselines in simulation. We also perform 1000\ntrials of a physical block-pushing experiment with 4 ABB YuMi robot arms.\nExperiments suggest that the allocation of humans to robots significantly\naffects robot fleet performance, and that our algorithm achieves up to 8.8x\nhigher return on human effort than baselines. See\nhttps://tinyurl.com/fleet-dagger for code, videos, and supplemental material.",
    "descriptor": "",
    "authors": [
      "Ryan Hoque",
      "Lawrence Yunliang Chen",
      "Satvik Sharma",
      "Karthik Dharmarajan",
      "Brijen Thananjeyan",
      "Pieter Abbeel",
      "Ken Goldberg"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.14349"
  },
  {
    "id": "arXiv:2206.14350",
    "title": "Convolutional Neural Network Based Partial Face Detection",
    "abstract": "Due to the massive explanation of artificial intelligence, machine learning\ntechnology is being used in various areas of our day-to-day life. In the world,\nthere are a lot of scenarios where a simple crime can be prevented before it\nmay even happen or find the person responsible for it. A face is one\ndistinctive feature that we have and can differentiate easily among many other\nspecies. But not just different species, it also plays a significant role in\ndetermining someone from the same species as us, humans. Regarding this\ncritical feature, a single problem occurs most often nowadays. When the camera\nis pointed, it cannot detect a person's face, and it becomes a poor image. On\nthe other hand, where there was a robbery and a security camera installed, the\nrobber's identity is almost indistinguishable due to the low-quality camera.\nBut just making an excellent algorithm to work and detecting a face reduces the\ncost of hardware, and it doesn't cost that much to focus on that area. Facial\nrecognition, widget control, and such can be done by detecting the face\ncorrectly. This study aims to create and enhance a machine learning model that\ncorrectly recognizes faces. Total 627 Data have been collected from different\nBangladeshi people's faces on four angels. In this work, CNN, Harr Cascade,\nCascaded CNN, Deep CNN & MTCNN are these five machine learning approaches\nimplemented to get the best accuracy of our dataset. After creating and running\nthe model, Multi-Task Convolutional Neural Network (MTCNN) achieved 96.2% best\nmodel accuracy with training data rather than other machine learning models.",
    "descriptor": "\nComments: Accepted in 7th International Conference for Convergence in Technology (I2CT), 2022, 6 pages, 7 figures\n",
    "authors": [
      "Md. Towfiqul Islam",
      "Tanzim Ahmed",
      "A.B.M. Raihanur Rashid",
      "Taminul Islam",
      "Md. Sadekur Rahman",
      "Md. Tarek Habib"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14350"
  },
  {
    "id": "arXiv:2206.14354",
    "title": "Hardness and Algorithms for Robust and Sparse Optimization",
    "abstract": "We explore algorithms and limitations for sparse optimization problems such\nas sparse linear regression and robust linear regression. The goal of the\nsparse linear regression problem is to identify a small number of key features,\nwhile the goal of the robust linear regression problem is to identify a small\nnumber of erroneous measurements. Specifically, the sparse linear regression\nproblem seeks a $k$-sparse vector $x\\in\\mathbb{R}^d$ to minimize $\\|Ax-b\\|_2$,\ngiven an input matrix $A\\in\\mathbb{R}^{n\\times d}$ and a target vector\n$b\\in\\mathbb{R}^n$, while the robust linear regression problem seeks a set $S$\nthat ignores at most $k$ rows and a vector $x$ to minimize $\\|(Ax-b)_S\\|_2$.\nWe first show bicriteria, NP-hardness of approximation for robust regression\nbuilding on the work of [OWZ15] which implies a similar result for sparse\nregression. We further show fine-grained hardness of robust regression through\na reduction from the minimum-weight $k$-clique conjecture. On the positive\nside, we give an algorithm for robust regression that achieves arbitrarily\naccurate additive error and uses runtime that closely matches the lower bound\nfrom the fine-grained hardness result, as well as an algorithm for sparse\nregression with similar runtime. Both our upper and lower bounds rely on a\ngeneral reduction from robust linear regression to sparse regression that we\nintroduce. Our algorithms, inspired by the 3SUM problem, use approximate\nnearest neighbor data structures and may be of independent interest for solving\nsparse optimization problems. For instance, we demonstrate that our techniques\ncan also be used for the well-studied sparse PCA problem.",
    "descriptor": "\nComments: ICML 2022\n",
    "authors": [
      "Eric Price",
      "Sandeep Silwal",
      "Samson Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.14354"
  },
  {
    "id": "arXiv:2206.14355",
    "title": "EBMs vs. CL: Exploring Self-Supervised Visual Pretraining for Visual  Question Answering",
    "abstract": "The availability of clean and diverse labeled data is a major roadblock for\ntraining models on complex tasks such as visual question answering (VQA). The\nextensive work on large vision-and-language models has shown that\nself-supervised learning is effective for pretraining multimodal interactions.\nIn this technical report, we focus on visual representations. We review and\nevaluate self-supervised methods to leverage unlabeled images and pretrain a\nmodel, which we then fine-tune on a custom VQA task that allows controlled\nevaluation and diagnosis. We compare energy-based models (EBMs) with\ncontrastive learning (CL). While EBMs are growing in popularity, they lack an\nevaluation on downstream tasks. We find that both EBMs and CL can learn\nrepresentations from unlabeled images that enable training a VQA model on very\nlittle annotated data. In a simple setting similar to CLEVR, we find that CL\nrepresentations also improve systematic generalization, and even match the\nperformance of representations from a larger, supervised, ImageNet-pretrained\nmodel. However, we find EBMs to be difficult to train because of instabilities\nand high variability in their results. Although EBMs prove useful for OOD\ndetection, other results on supervised energy-based training and uncertainty\ncalibration are largely negative. Overall, CL currently seems a preferable\noption over EBMs.",
    "descriptor": "",
    "authors": [
      "Violetta Shevchenko",
      "Ehsan Abbasnejad",
      "Anthony Dick",
      "Anton van den Hengel",
      "Damien Teney"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14355"
  },
  {
    "id": "arXiv:2206.14356",
    "title": "Biometric Identification Systems With Both Chosen and Generated Secret  Keys by Allowing Correlation",
    "abstract": "We propose a biometric identification system where the chosen- and\ngenerated-secret keys are used simultaneously, and investigate its fundamental\nlimits from information-theoretic perspectives. The system consists of two\nphases: enrollment and identification phases. In the enrollment phase, for each\nuser, the encoder uses a secret key, which is chosen independently, and the\nbiometric identifier to generate another secret key and a helper {data}. In the\nidentification phase, observing the biometric sequence of the identified user,\nthe decoder estimates index, chosen- and generated-secret keys of the\nidentified user based on the helper {data} stored in the system database. In\nthis study, the capacity region of such a system is characterized. In the\nproblem setting, we allow chosen- and generated-secret keys to be correlated.\nAs a result, by permitting the correlation of the two secret keys, the sum rate\nof the identification, chosen- and {generated-secret key} rates can achieve a\nlarger value compared to the case where the keys {do not correlate}. Moreover,\nthe minimum amount of the storage rate changes in accordance with both the\nidentification and chosen-secret key rates, but that of the privacy-leakage\nrate depends only on the identification rate.",
    "descriptor": "\nComments: This paper is submitted to IEICE Trans. Fundamentals\n",
    "authors": [
      "Vamoua Yachongka",
      "Hideki Yagi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.14356"
  },
  {
    "id": "arXiv:2206.14358",
    "title": "Using Twitter Data to Understand Public Perceptions of Approved versus  Off-label Use for COVID-19-related Medications",
    "abstract": "Understanding public discourse on emergency use of unproven therapeutics is\nessential to monitor safe use and combat misinformation. We developed a natural\nlanguage processing (NLP)-based pipeline to understand public perceptions of\nand stances on COVID-19-related drugs on Twitter across time. This\nretrospective study included 609,189 US-based tweets between January 29th, 2020\nand November 30th, 2021 on four drugs that gained wide public attention during\nthe COVID-19 pandemic: 1) Hydroxychloroquine and Ivermectin, drug therapies\nwith anecdotal evidence; and 2) Molnupiravir and Remdesivir, FDA-approved\ntreatment options for eligible patients. Time-trend analysis was used to\nunderstand the popularity and related events. Content and demographic analyses\nwere conducted to explore potential rationales of people's stances on each\ndrug. Time-trend analysis revealed that Hydroxychloroquine and Ivermectin\nreceived much more discussion than Molnupiravir and Remdesivir, particularly\nduring COVID-19 surges. Hydroxychloroquine and Ivermectin were highly\npoliticized, related to conspiracy theories, hearsay, celebrity effects, etc.\nThe distribution of stance between the two major US political parties was\nsignificantly different (p<0.001); Republicans were much more likely to support\nHydroxychloroquine (+55%) and Ivermectin (+30%) than Democrats. People with\nhealthcare backgrounds tended to oppose Hydroxychloroquine (+7%) more than the\ngeneral population; in contrast, the general population was more likely to\nsupport Ivermectin (+14%). We make all the data, code, and models available at\nhttps://github.com/ningkko/COVID-drug.",
    "descriptor": "\nComments: This is a preliminary version. For full paper please refer to JAMIA\n",
    "authors": [
      "Yining Hua",
      "Hang Jiang",
      "Shixu Lin",
      "Jie Yang",
      "Joseph M. Plasek",
      "David W. Bates",
      "Li Zhou"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2206.14358"
  },
  {
    "id": "arXiv:2206.14359",
    "title": "TE2Rules: Extracting Rule Lists from Tree Ensembles",
    "abstract": "Tree Ensemble (TE) models (e.g. Gradient Boosted Trees and Random Forests)\noften provide higher prediction performance compared to single decision trees.\nHowever, TE models generally lack transparency and interpretability, as humans\nhave difficulty understanding their decision logic. This paper presents a novel\napproach to convert a TE trained for a binary classification task, to a rule\nlist (RL) that is a global equivalent to the TE and is comprehensible for a\nhuman. This RL captures all necessary and sufficient conditions for decision\nmaking by the TE. Experiments on benchmark datasets demonstrate that, compared\nto state-of-the-art methods, (i) predictions from the RL generated by TE2Rules\nhave high fidelity with respect to the original TE, (ii) the RL from TE2Rules\nhas high interpretability measured by the number and the length of the decision\nrules, (iii) the run-time of TE2Rules algorithm can be reduced significantly at\nthe cost of a slightly lower fidelity, and (iv) the RL is a fast alternative to\nthe state-of-the-art rule-based instance-level outcome explanation techniques.",
    "descriptor": "",
    "authors": [
      "G Roshan Lal",
      "Xiaotong",
      "Chen",
      "Varun Mithal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.14359"
  },
  {
    "id": "arXiv:2206.14360",
    "title": "Stability Analysis for Stochastic Hybrid Inclusions",
    "abstract": "Stochastic hybrid inclusions (SHIs) address situations with the stochastic\ncontinuous evolution in a stochastic differential inclusions and random jumps\nin the difference inclusions due to the forced (the state reaching a boundary\nin the state space) and/or spontaneous (the state vector may occur\nspontaneously) transitions. An obvious characteristic of SHIs is the\nnon-uniqueness of random solutions, which can be ensured by the mild regularity\nconditions, as well as nominal robustness. Basic sufficient conditions for\nstability/recurrence in probability are usually expressed based on different\ntypes of Lyapunov functions, including Lagrange/Lyapunov/Lyapunov-Forster\nfunctions respectively for Lagrange/Lyapunov/asymptotical stability in\nprobability and Foster/Lagrange-Forster functions for recurrence, (weaker)\nrelaxed Lyapunov-based sufficient conditions including Matrosov-Foster\nfunctions and the stochastic invariance principle, as well as Lyapunov-based\nnecessary and sufficient conditions for asymptotical stability in probability\nor recurrence (i.e.,converse theorems), etc. The converse theorems involving\nsmooth Lyapunov functions are guaranteed by the sequential compactness and thus\nrobustness. In addition, the uniformity property and causality are analyzed for\nthe stabilities in probability. Hence, serving as a partial roadmap for the\ntheoretical development of SHIs, also serving as inspiration, we anticipate\nthat many of the open questions, including the prediction problem, the\nfiltering problem and the control problem, will be resolved based on the\ntechniques of SHIs.",
    "descriptor": "\nComments: 15 pages, 3 figures, 1 table\n",
    "authors": [
      "Dandan Zhang",
      "Hongye Su"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.14360"
  },
  {
    "id": "arXiv:2206.14362",
    "title": "On Lower Bounds of Error Probability for Invariant Causal Prediction",
    "abstract": "It is common practice to collect observations of feature and response pairs\nfrom different environments. A natural question is how to identify features\nthat have consistent prediction power across environments. The invariant causal\nprediction framework proposes to approach this problem through invariance,\nassuming a linear model that is invariant under different environments. In this\nwork, we make an attempt to shed light on this framework by connecting it to\nthe Gaussian multiple access channel problem. Specifically, we incorporate\noptimal code constructions and decoding methods to provide lower bounds of\nerror probability. We illustrate our findings by various simulation settings.",
    "descriptor": "\nComments: Accepted to the 2022 IEEE International Workshop on Machine Learning for Signal Processing (MLSP)\n",
    "authors": [
      "Austin Goddard",
      "Yu Xiang",
      "Ilya Soloveychik"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2206.14362"
  },
  {
    "id": "arXiv:2206.14363",
    "title": "AAE: An Active Auto-Estimator for Improving Graph Storage",
    "abstract": "Nowadays, graph becomes an increasingly popular model in many real\napplications. The efficiency of graph storage is crucial for these\napplications. Generally speaking, the tune tasks of graph storage rely on the\ndatabase administrators (DBAs) to find the best graph storage. However, DBAs\nmake the tune decisions by mainly relying on their experiences and intuition.\nDue to the limitations of DBAs's experiences, the tunes may have an uncertain\nperformance and conduct worse efficiency. In this paper, we observe that an\nestimator of graph workload has the potential to guarantee the performance of\ntune operations. Unfortunately, because of the complex characteristics of graph\nevaluation task, there exists no mature estimator for graph workload. We\nformulate the evaluation task of graph workload as a classification task and\ncarefully design the feature engineering process, including graph data\nfeatures, graph workload features and graph storage features. Considering the\ncomplex features of graph and the huge time consumption in graph workload\nexecution, it is difficult for the graph workload estimator to obtain enough\ntraining set. So, we propose an active auto-estimator (AAE) for the graph\nworkload evaluation by combining the active learning and deep learning. AAE\ncould achieve good evaluation efficiency with limited training set. We test the\ntime efficiency and evaluation accuracy of AAE with two open source graph data,\nLDBC and Freebase. Experimental results show that our estimator could\nefficiently complete the graph workload evaluation in milliseconds.",
    "descriptor": "",
    "authors": [
      "Yu Yan",
      "Man Yang",
      "Hongzhi Wang",
      "Yuzhuo Wang"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2206.14363"
  },
  {
    "id": "arXiv:2206.14366",
    "title": "Knowledge Distillation of Transformer-based Language Models Revisited",
    "abstract": "In the past few years, transformer-based pre-trained language models have\nachieved astounding success in both industry and academia. However, the large\nmodel size and high run-time latency are serious impediments to applying them\nin practice, especially on mobile phones and Internet of Things (IoT) devices.\nTo compress the model, considerable literature has grown up around the theme of\nknowledge distillation (KD) recently. Nevertheless, how KD works in\ntransformer-based models is still unclear. We tease apart the components of KD\nand propose a unified KD framework. Through the framework, systematic and\nextensive experiments that spent over 23,000 GPU hours render a comprehensive\nanalysis from the perspectives of knowledge types, matching strategies,\nwidth-depth trade-off, initialization, model size, etc. Our empirical results\nshed light on the distillation in the pre-train language model and with\nrelative significant improvement over previous state-of-the-arts(SOTA).\nFinally, we provide a best-practice guideline for the KD in transformer-based\nmodels.",
    "descriptor": "",
    "authors": [
      "Chengqiang Lu",
      "Jianwei Zhang",
      "Yunfei Chu",
      "Zhengyu Chen",
      "Jingren Zhou",
      "Fei Wu",
      "Haiqing Chen",
      "Hongxia Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.14366"
  },
  {
    "id": "arXiv:2206.14368",
    "title": "IMRSim: A Disk Simulator for Interlaced Magnetic Recording Technology",
    "abstract": "The emerging interlaced magnetic recording (IMR) technology achieves a higher\nareal density for hard disk drive (HDD) over the conventional magnetic\nrecording (CMR) technology. IMR-based HDD interlaces top tracks and bottom\ntracks, where each bottom track is overlapped with two neighboring top tracks.\nThus, top tracks can be updated without restraint, whereas bottom tracks can be\nupdated by the time-consuming read-modify-write (RMW) or other novel update\nstrategy. Therefore, the layout of the tracks between the IMR-based HDD and the\nCMR-based HDD is much different. Unfortunately, there has been no related disk\nsimulator and product available to the public, which motivates us to develop an\nopen-source IMR disk simulator to provide a platform for further research. We\nimplement the first public IMR disk simulator, called IMRSim, as a block device\ndriver in the Linux kernel, simulating the interlaced tracks and implementing\nmany state-of-the-art data placement strategies. IMRSim is built on the actual\nCMR-based HDD to precisely simulate the I/O performance of IMR drives. While\nI/O operations in CMR-based HDD are easy to visualize, update strategy and\nmulti-stage allocation strategy in IMR are inherently dynamic. Therefore, we\nfurther graphically demonstrate how IMRSim processes I/O requests in the\nvisualization mode. We release IMRSim as an open-source IMR disk simulation\ntool and hope to attract more scholars into related research on IMR technology.",
    "descriptor": "\nComments: 7 pages, 7 figures\n",
    "authors": [
      "Zhimin Zeng",
      "Xinyu Chen",
      "Laurence T Yang",
      "Jinhua Cui"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2206.14368"
  },
  {
    "id": "arXiv:2206.14369",
    "title": "Robust Online Voltage Control with an Unknown Grid Topology",
    "abstract": "Voltage control generally requires accurate information about the grid's\ntopology in order to guarantee network stability. However, accurate topology\nidentification is a challenging problem for existing methods, especially as the\ngrid is subject to increasingly frequent reconfiguration due to the adoption of\nrenewable energy. Further, running existing control mechanisms with incorrect\nnetwork information may lead to unstable control. In this work, we combine a\nnested convex body chasing algorithm with a robust predictive controller to\nachieve provably finite-time convergence to safe voltage limits in the online\nsetting where the network topology is initially unknown. Specifically, the\nonline controller does not know the true network topology and line parameters,\nbut instead must learn them over time by narrowing down the set of network\ntopologies and line parameters that are consistent with its observations and\nadjusting reactive power generation accordingly to keep voltages within desired\nsafety limits. We demonstrate the effectiveness of the approach using a case\nstudy, which shows that in practical settings the controller is indeed able to\nnarrow the set of consistent topologies quickly enough to make control\ndecisions that ensure stability.",
    "descriptor": "\nComments: Code: this https URL\n",
    "authors": [
      "Christopher Yeh",
      "Jing Yu",
      "Yuanyuan Shi",
      "Adam Wierman"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.14369"
  },
  {
    "id": "arXiv:2206.14372",
    "title": "Formalizing and Evaluating Requirements of Perception Systems for  Automated Vehicles using Spatio-Temporal Perception Logic",
    "abstract": "Automated vehicles (AV) heavily depend on robust perception systems. Current\nmethods for evaluating vision systems focus mainly on frame-by-frame\nperformance. Such evaluation methods appear to be inadequate in assessing the\nperformance of a perception subsystem when used within an AV. In this paper, we\npresent a logic -- referred to as Spatio-Temporal Perception Logic (STPL) --\nwhich utilizes both spatial and temporal modalities. STPL enables reasoning\nover perception data using spatial and temporal relations. One major advantage\nof STPL is that it facilitates basic sanity checks on the real-time performance\nof the perception system, even without ground-truth data in some cases. We\nidentify a fragment of STPL which is efficiently monitorable offline in\npolynomial time. Finally, we present a range of specifications for AV\nperception systems to highlight the types of requirements that can be expressed\nand analyzed through offline monitoring with STPL.",
    "descriptor": "\nComments: 27 pages, 12 figures, 4 tables, 5 algorithms, 3 appendixes\n",
    "authors": [
      "Mohammad Hekmatnejad",
      "Bardh Hoxha",
      "Jyotirmoy V. Deshmukh",
      "Yezhou Yang",
      "Georgios Fainekos"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2206.14372"
  },
  {
    "id": "arXiv:2206.14381",
    "title": "Exploiting Semantic Role Contextualized Video Features for  Multi-Instance Text-Video Retrieval EPIC-KITCHENS-100 Multi-Instance  Retrieval Challenge 2022",
    "abstract": "In this report, we present our approach for EPIC-KITCHENS-100 Multi-Instance\nRetrieval Challenge 2022. We first parse sentences into semantic roles\ncorresponding to verbs and nouns; then utilize self-attentions to exploit\nsemantic role contextualized video features along with textual features via\ntriplet losses in multiple embedding spaces. Our method overpasses the strong\nbaseline in normalized Discounted Cumulative Gain (nDCG), which is more\nvaluable for semantic similarity. Our submission is ranked 3rd for nDCG and\nranked 4th for mAP.",
    "descriptor": "\nComments: Ranked joint 3rd place in the Multi-Instance Retrieval Challenge at EPIC@CVPR2022\n",
    "authors": [
      "Burak Satar",
      "Hongyuan Zhu",
      "Hanwang Zhang",
      "Joo Hwee Lim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14381"
  },
  {
    "id": "arXiv:2206.14384",
    "title": "Framing Algorithmic Recourse for Anomaly Detection",
    "abstract": "The problem of algorithmic recourse has been explored for supervised machine\nlearning models, to provide more interpretable, transparent and robust outcomes\nfrom decision support systems. An unexplored area is that of algorithmic\nrecourse for anomaly detection, specifically for tabular data with only\ndiscrete feature values. Here the problem is to present a set of\ncounterfactuals that are deemed normal by the underlying anomaly detection\nmodel so that applications can utilize this information for explanation\npurposes or to recommend countermeasures. We present an approach -- Context\npreserving Algorithmic Recourse for Anomalies in Tabular data (CARAT), that is\neffective, scalable, and agnostic to the underlying anomaly detection model.\nCARAT uses a transformer based encoder-decoder model to explain an anomaly by\nfinding features with low likelihood. Subsequently semantically coherent\ncounterfactuals are generated by modifying the highlighted features, using the\noverall context of features in the anomalous instance(s). Extensive experiments\nhelp demonstrate the efficacy of CARAT.",
    "descriptor": "\nComments: ACM SigKDD 2022, Research Track\n",
    "authors": [
      "Debanjan Datta",
      "Feng Chen",
      "Naren Ramakrishnan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2206.14384"
  },
  {
    "id": "arXiv:2206.14388",
    "title": "Chinese Word Sense Embedding with SememeWSD and Synonym Set",
    "abstract": "Word embedding is a fundamental natural language processing task which can\nlearn feature of words. However, most word embedding methods assign only one\nvector to a word, even if polysemous words have multi-senses. To address this\nlimitation, we propose SememeWSD Synonym (SWSDS) model to assign a different\nvector to every sense of polysemous words with the help of word sense\ndisambiguation (WSD) and synonym set in OpenHowNet. We use the SememeWSD model,\nan unsupervised word sense disambiguation model based on OpenHowNet, to do word\nsense disambiguation and annotate the polysemous word with sense id. Then, we\nobtain top 10 synonyms of the word sense from OpenHowNet and calculate the\naverage vector of synonyms as the vector of the word sense. In experiments, We\nevaluate the SWSDS model on semantic similarity calculation with Gensim's\nwmdistance method. It achieves improvement of accuracy. We also examine the\nSememeWSD model on different BERT models to find the more effective model.",
    "descriptor": "",
    "authors": [
      "Yangxi Zhou",
      "Junping Du",
      "Zhe Xue",
      "Ang Li",
      "Zeli Guan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.14388"
  },
  {
    "id": "arXiv:2206.14389",
    "title": "Forgetting Data from Pre-trained GANs",
    "abstract": "Large pre-trained generative models are known to occasionally provide samples\nthat may be undesirable for various reasons. The standard way to mitigate this\nis to re-train the models differently. In this work, we take a different, more\ncompute-friendly approach and investigate how to post-edit a model after\ntraining so that it forgets certain kinds of samples. We provide three\ndifferent algorithms for GANs that differ on how the samples to be forgotten\nare described. Extensive evaluations on real-world image datasets show that our\nalgorithms are capable of forgetting data while retaining high generation\nquality at a fraction of the cost of full re-training.",
    "descriptor": "",
    "authors": [
      "Zhifeng Kong",
      "Kamalika Chaudhuri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.14389"
  },
  {
    "id": "arXiv:2206.14390",
    "title": "Diet Code is Healthy: Simplifying Programs for Pre-Trained Models of  Code",
    "abstract": "Pre-trained code representation models such as CodeBERT have demonstrated\nsuperior performance in a variety of software engineering tasks, yet they are\noften heavy in complexity, quadratically with the length of the input sequence.\nOur empirical analysis of CodeBERT's attention reveals that CodeBERT pays more\nattention to certain types of tokens and statements such as keywords and\ndata-relevant statements. Based on these findings, we propose DietCodeBERT,\nwhich aims at lightweight leverage of large pre-trained models for source code.\nDietCodeBERT simplifies the input program of CodeBERT with three strategies,\nnamely, word dropout, frequency filtering, and an attention-based strategy\nwhich selects statements and tokens that receive the most attention weights\nduring pre-training. Hence, it gives a substantial reduction in the\ncomputational cost without hampering the model performance. Experimental\nresults on two downstream tasks show that DietCodeBERT provides comparable\nresults to CodeBERT with 40% less computational cost in fine-tuning and\ntesting.",
    "descriptor": "\nComments: Accepted to be published in ESEC/FSE 2022\n",
    "authors": [
      "Zhaowei Zhang",
      "Hongyu Zhang",
      "Beijun Shen",
      "Xiaodong Gu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.14390"
  },
  {
    "id": "arXiv:2206.14391",
    "title": "Non-local Evasive Overtaking of Downstream Incidents in Distributed  Behavior Planning of Connected Vehicles",
    "abstract": "The prevalence of high-speed vehicle-to-everything (V2X) communication will\nlikely significantly influence the future of vehicle autonomy. In several\nautonomous driving applications, however, the role such systems will play is\nseldom understood. In this paper, we explore the role of communication signals\nin enhancing the performance of lane change assistance systems in situations\nwhere downstream bottlenecks restrict the mobility of a few lanes. Building off\nof prior work on modeling lane change incentives, we design a controller that\n1) encourages automated vehicles to subvert lanes in which distant downstream\ndelays are likely to occur, while also 2) ignoring greedy local incentives when\nsuch delays are needed to maintain a specific route. Numerical results on\ndifferent traffic conditions and penetration rates suggest that the model\nsuccessfully subverts a significant portion of delays brought about by\ndownstream bottlenecks, both globally and from the perspective of the\ncontrolled vehicles.",
    "descriptor": "",
    "authors": [
      "Abdul Rahman Kreidieh",
      "Yashar Farid",
      "Kentaro Oguchi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.14391"
  },
  {
    "id": "arXiv:2206.14397",
    "title": "Fair Machine Learning in Healthcare: A Review",
    "abstract": "Benefiting from the digitization of healthcare data and the development of\ncomputing power, machine learning methods are increasingly used in the\nhealthcare domain. Fairness problems have been identified in machine learning\nfor healthcare, resulting in an unfair allocation of limited healthcare\nresources or excessive health risks for certain groups. Therefore, addressing\nthe fairness problems has recently attracted increasing attention from the\nhealthcare community. However, the intersection of machine learning for\nhealthcare and fairness in machine learning remains understudied. In this\nreview, we build the bridge by exposing fairness problems, summarizing possible\nbiases, sorting out mitigation methods and pointing out challenges along with\nopportunities for the future.",
    "descriptor": "",
    "authors": [
      "Qizhang Feng",
      "Mengnan Du",
      "Na Zou",
      "Xia Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.14397"
  },
  {
    "id": "arXiv:2206.14401",
    "title": "Spectral-Loc: Indoor Localization using Light Spectral Information",
    "abstract": "For indoor settings, we investigate the impact of location on the spectral\ndistribution of the received light, i.e., the intensity of light for different\nwavelengths. Our investigations confirm that even under the same light source,\ndifferent locations exhibit slightly different spectral distribution due to\nreflections from their localised environment containing different materials or\ncolours. By exploiting this observation, we propose Spectral-Loc, a novel\nindoor localization system that uses light spectral information to identify the\nlocation of the device. With spectral sensors finding their way in latest\nproducts and applications, such as white balancing in smartphone photography,\nSpectral-Loc can be readily deployed without requiring any additional hardware\nor infrastructure. We prototype Spectral-Loc using a commercial-off-the-shelf\nlight spectral sensor, AS7265x, which can measure light intensity over 18\ndifferent wavelength sub-bands. We benchmark the localisation accuracy of\nSpectral-Loc against the conventional light intensity sensors that provide only\na single intensity value. Our evaluations over two different indoor spaces, a\nmeeting room and a large office space, demonstrate that use of light spectral\ninformation significantly reduces the localization error for the different\npercentiles.",
    "descriptor": "\nComments: 14 pages, 17 figures, 4 tables\n",
    "authors": [
      "Yanxiang Wang",
      "Jiawei Hu",
      "Hong Jia",
      "Wen Hu",
      "Mahbub Hassan",
      "Ashraf Uddin",
      "Brano Kusy",
      "Moustafa Youssef"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.14401"
  },
  {
    "id": "arXiv:2206.14402",
    "title": "Constructing MDP Abstractions Using Data with Formal Guarantees",
    "abstract": "This paper is concerned with a data-driven technique for constructing finite\nMarkov decision processes (MDPs) as finite abstractions of discrete-time\nstochastic control systems with unknown dynamics while providing formal\ncloseness guarantees. The proposed scheme is based on notions of stochastic\nbisimulation functions (SBF) to capture the probabilistic distance between\nstate trajectories of an unknown stochastic system and those of finite MDP. In\nour proposed setting, we first reformulate corresponding conditions of SBF as a\nrobust convex program (RCP). We then propose a scenario convex program (SCP)\nassociated to the original RCP by collecting a finite number of data from\ntrajectories of the system. We ultimately construct an SBF between the\ndata-driven finite MDP and the unknown stochastic system with a given\nconfidence level by establishing a probabilistic relation between optimal\nvalues of the SCP and the RCP. We also propose two different approaches for the\nconstruction of finite MDPs from data. We illustrate the efficacy of our\nresults over a nonlinear jet engine compressor with unknown dynamics. We\nconstruct a data-driven finite MDP as a suitable substitute of the original\nsystem to synthesize controllers maintaining the system in a safe set with some\nprobability of satisfaction and a desirable confidence level.",
    "descriptor": "\nComments: This work has been accepted at IEEE Control Systems Letters\n",
    "authors": [
      "Abolfazl Lavaei",
      "Sadegh Soudjani",
      "Emilio Frazzoli",
      "Majid Zamani"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.14402"
  },
  {
    "id": "arXiv:2206.14406",
    "title": "Standard Dual Quaternion Functions and Standard Dual Quaternion  Optimization",
    "abstract": "Dual quaternions now have wide applications in robotics, 3D motion modelling\nand control, and computer graphics. The magnitudes of dual quaternions and the\n2-norms of dual quaternion vectors are dual numbers. A total order was defined\nfor dual numbers. Thus, dual quaternion optimization problems, where objective\nand constraint functions have dual quaternion variables and dual number\nfunction values naturally arise. In this paper, we show that several common\ndual quaternion functions, such as the power function, the magnitude function,\nthe 2-norm function and the kth largest eigenvalue function of dual quaternion\nHermitian matrices, are standard dual quaternion functions, i.e., the standard\nparts of their function values depend upon only the standard parts of the dual\nquaternion variables. Furthermore, the sum, product, minimum, maximum and\ncomposite functions of two standard dual functions, the logarithm and the\nexponential of a standard unit dual quaternion functions, are still standard\ndual quaternion functions. To solve a standard dual quaternion optimization\nproblem, we only need to solve two quaternion optimization problems. Thus, if\nthe dual quaternion functions are standard, the related dual quaternion\noptimization problem is solvable.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2204.01229\n",
    "authors": [
      "Liqun Qi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.14406"
  },
  {
    "id": "arXiv:2206.14409",
    "title": "C2FTrans: Coarse-to-Fine Transformers for Medical Image Segmentation",
    "abstract": "Convolutional neural networks (CNN), the most prevailing architecture for\ndeep-learning based medical image analysis, are still functionally limited by\ntheir intrinsic inductive biases and inadequate receptive fields. Transformer,\nborn to address this issue, has drawn explosive attention in natural language\nprocessing and computer vision due to its remarkable ability in capturing\nlong-range dependency. However, most recent transformer-based methods for\nmedical image segmentation directly apply vanilla transformers as an auxiliary\nmodule in CNN-based methods, resulting in severe detail loss due to the rigid\npatch partitioning scheme in transformers. To address this problem, we propose\nC2FTrans, a novel multi-scale architecture that formulates medical image\nsegmentation as a coarse-to-fine procedure. C2FTrans mainly consists of a\ncross-scale global transformer (CGT) which addresses local contextual\nsimilarity in CNN and a boundary-aware local transformer (BLT) which overcomes\nboundary uncertainty brought by rigid patch partitioning in transformers.\nSpecifically, CGT builds global dependency across three different small-scale\nfeature maps to obtain rich global semantic features with an acceptable\ncomputational cost, while BLT captures mid-range dependency by adaptively\ngenerating windows around boundaries under the guidance of entropy to reduce\ncomputational complexity and minimize detail loss based on large-scale feature\nmaps. Extensive experimental results on three public datasets demonstrate the\nsuperior performance of C2FTrans against state-of-the-art CNN-based and\ntransformer-based methods with fewer parameters and lower FLOPs. We believe the\ndesign of C2FTrans would further inspire future work on developing efficient\nand lightweight transformers for medical image segmentation. The source code of\nthis paper is publicly available at https://github.com/xianlin7/C2FTrans.",
    "descriptor": "\nComments: submitted to IEEE Transactions on Medical Imaging\n",
    "authors": [
      "Xian Lin",
      "Zengqiang Yan",
      "Li Yu",
      "Kwang-Ting Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.14409"
  },
  {
    "id": "arXiv:2206.14413",
    "title": "The Lighter The Better: Rethinking Transformers in Medical Image  Segmentation Through Adaptive Pruning",
    "abstract": "Vision transformers have recently set off a new wave in the field of medical\nimage analysis due to their remarkable performance on various computer vision\ntasks. However, recent hybrid-/transformer-based approaches mainly focus on the\nbenefits of transformers in capturing long-range dependency while ignoring the\nissues of their daunting computational complexity, high training costs, and\nredundant dependency. In this paper, we propose to employ adaptive pruning to\ntransformers for medical image segmentation and propose a lightweight and\neffective hybrid network APFormer. To our best knowledge, this is the first\nwork on transformer pruning for medical image analysis tasks. The key features\nof APFormer mainly are self-supervised self-attention (SSA) to improve the\nconvergence of dependency establishment, Gaussian-prior relative position\nembedding (GRPE) to foster the learning of position information, and adaptive\npruning to eliminate redundant computations and perception information.\nSpecifically, SSA and GRPE consider the well-converged dependency distribution\nand the Gaussian heatmap distribution separately as the prior knowledge of\nself-attention and position embedding to ease the training of transformers and\nlay a solid foundation for the following pruning operation. Then, adaptive\ntransformer pruning, both query-wise and dependency-wise, is performed by\nadjusting the gate control parameters for both complexity reduction and\nperformance improvement. Extensive experiments on two widely-used datasets\ndemonstrate the prominent segmentation performance of APFormer against the\nstate-of-the-art methods with much fewer parameters and lower GFLOPs. More\nimportantly, we prove, through ablation studies, that adaptive pruning can work\nas a plug-n-play module for performance improvement on other\nhybrid-/transformer-based methods. Code is available at\nhttps://github.com/xianlin7/APFormer.",
    "descriptor": "\nComments: submitted to IEEE Transactions on Medical Imaging\n",
    "authors": [
      "Xian Lin",
      "Li Yu",
      "Kwang-Ting Cheng",
      "Zengqiang Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.14413"
  },
  {
    "id": "arXiv:2206.14414",
    "title": "Distributed Edge-based Video Analytics on the Move",
    "abstract": "In recent years, we have witnessed an explosive growth of data. Much of this\ndata is video data generated by security cameras, smartphones, and dash cams.\nThe timely analysis of such data is of great practical importance for many\nemerging applications, such as real-time facial recognition and object\ndetection. In this study, we address the problem of real-time in-situ video\nanalytics with dash cam videos and present EdgeDashAnalytics (EDA), an\nedge-based system that enables near real-time video analytics using a local\nnetwork of mobile devices. In particular, it simultaneously processes videos\nproduced by two dash cams of different angles with one or more mobile devices\non the move in a near real-time manner. One camera faces outward to capture the\nview in front of the vehicle, while the other camera faces inward to capture\nthe driver. The outer videos are analysed to detect potential driving hazards,\nwhile the inner videos are used to identify driver distractedness. EDA achieves\nnear real-time video analytics using resource-constrained, transient mobile\ndevices by devising and incorporating several optimisations, with a tolerable\nloss in accuracy. We have implemented EDA as an Android app and evaluated it\nusing two dash cams and several heterogeneous mobile devices with the BDD100K\ndash cam video dataset (arXiv:1805.04687 [cs.CV]) and the DMD driver monitoring\ndataset (arXiv:2008.12085 [cs.CV]). Experiment results demonstrate the\nfeasibility of real-time video analytics in terms of turnaround time and energy\nconsumption (or battery usage), using resource-constrained mobile devices on\nthe move.",
    "descriptor": "",
    "authors": [
      "Jayden King",
      "Young Choon Lee"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.14414"
  },
  {
    "id": "arXiv:2206.14415",
    "title": "Performance Analysis: Discovering Semi-Markov Models From Event Logs",
    "abstract": "Process mining methods and tools are largely used in industry to monitor and\nimprove operational processes. This paper presents a new technique to analyze\nperformance characteristics of processes using event data. Based on event\nsequences and their timestamps, semi-Markov models are discovered. The\ndiscovered models are further used for performance what-if analysis of the\nprocesses. The paper studies a trade-off between the order of models discovered\nand accuracy of representing performance information. The proposed discovery\nand analysis techniques are implemented and tested on real-world event data.",
    "descriptor": "",
    "authors": [
      "Anna Kalenkova",
      "Lewis Mitchell",
      "Matthew Roughan"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2206.14415"
  },
  {
    "id": "arXiv:2206.14418",
    "title": "Optimization-Induced Graph Implicit Nonlinear Diffusion",
    "abstract": "Due to the over-smoothing issue, most existing graph neural networks can only\ncapture limited dependencies with their inherently finite aggregation layers.\nTo overcome this limitation, we propose a new kind of graph convolution, called\nGraph Implicit Nonlinear Diffusion (GIND), which implicitly has access to\ninfinite hops of neighbors while adaptively aggregating features with nonlinear\ndiffusion to prevent over-smoothing. Notably, we show that the learned\nrepresentation can be formalized as the minimizer of an explicit convex\noptimization objective. With this property, we can theoretically characterize\nthe equilibrium of our GIND from an optimization perspective. More\ninterestingly, we can induce new structural variants by modifying the\ncorresponding optimization objective. To be specific, we can embed prior\nproperties to the equilibrium, as well as introducing skip connections to\npromote training stability. Extensive experiments show that GIND is good at\ncapturing long-range dependencies, and performs well on both homophilic and\nheterophilic graphs with nonlinear diffusion. Moreover, we show that the\noptimization-induced variants of our models can boost the performance and\nimprove training stability and efficiency as well. As a result, our GIND\nobtains significant improvements on both node-level and graph-level tasks.",
    "descriptor": "\nComments: 14 pages, 3 figures. Accepted by ICML 2022. Our code is available at this https URL\n",
    "authors": [
      "Qi Chen",
      "Yifei Wang",
      "Yisen Wang",
      "Jiansheng Yang",
      "Zhouchen Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14418"
  },
  {
    "id": "arXiv:2206.14421",
    "title": "Cyclical Kernel Adaptive Metropolis",
    "abstract": "We propose cKAM, cyclical Kernel Adaptive Metropolis, which incorporates a\ncyclical stepsize scheme to allow control for exploration and sampling. We show\nthat on a crafted bimodal distribution, existing Adaptive Metropolis type\nalgorithms would fail to converge to the true posterior distribution. We point\nout that this is because adaptive samplers estimates the local/global\ncovariance structure using past history of the chain, which will lead to\nadaptive algorithms be trapped in a local mode. We demonstrate that cKAM\nencourages exploration of the posterior distribution and allows the sampler to\nescape from a local mode, while maintaining the high performance of adaptive\nmethods.",
    "descriptor": "",
    "authors": [
      "Jianan Canal Li",
      "Yimeng Zeng",
      "Wentao Guo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.14421"
  },
  {
    "id": "arXiv:2206.14423",
    "title": "The Mutual Visibility Problem for Fat Robots",
    "abstract": "Given a set of $n \\geq 1$ unit disk robots in the Euclidean plane, we\nconsider the fundamental problem of providing mutual visibility to them: the\nrobots must reposition themselves to reach a configuration where they all see\neach other. This problem arises under obstructed visibility, where a robot\ncannot see another robot if there is a third robot on the straight line segment\nbetween them. This problem was solved by Sharma et al. [Sharma, G., Alsaedi,\nR., Busch, C., Mukhopadhyay, S.: The complete visibility problem for fat robots\nwith lights. In: ICDCN. pp. 1-4 (2018)] in the luminous robots model, where\neach robot is equipped with an externally visible light that can assume colors\nfrom a fixed set of colors, using 9 colors and $O(n)$ rounds. In this work, we\npresent an algorithm that requires only 3 colors and $O(n)$ rounds.",
    "descriptor": "",
    "authors": [
      "Rusul J. Alsaedi",
      "Joachim Gudmundsson",
      "Andr\u00e9 van Renssen"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2206.14423"
  },
  {
    "id": "arXiv:2206.14424",
    "title": "Collaborative Navigation and Manipulation of a Cable-towed Load by  Multiple Quadrupedal Robots",
    "abstract": "This paper tackles the problem of robots collaboratively towing a load with\ncables to a specified goal location while avoiding collisions in real time. The\nintroduction of cables (as opposed to rigid links) enables the robotic team to\ntravel through narrow spaces by changing its intrinsic dimensions through\nslack/taut switches of the cable. However, this is a challenging problem\nbecause of the hybrid mode switches and the dynamical coupling among multiple\nrobots and the load. Previous attempts at addressing such a problem were\nperformed offline and do not consider avoiding obstacles online. In this paper,\nwe introduce a cascaded planning scheme with a parallelized centralized\ntrajectory optimization that deals with hybrid mode switches. We additionally\ndevelop a set of decentralized planners per robot, which enables our approach\nto solve the problem of collaborative load manipulation online. We develop and\ndemonstrate one of the first collaborative autonomy framework that is able to\nmove a cable-towed load, which is too heavy to move by a single robot, through\nnarrow spaces with real-time feedback and reactive planning in experiments.",
    "descriptor": "\nComments: Extended version of the manuscript accepted to IEEE Robotics and Automation Letters (RA-L) 2022\n",
    "authors": [
      "Chenyu Yang",
      "Guo Ning Sue",
      "Zhongyu Li",
      "Lizhi Yang",
      "Haotian Shen",
      "Yufeng Chi",
      "Akshara Rai",
      "Jun Zeng",
      "Koushil Sreenath"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.14424"
  },
  {
    "id": "arXiv:2206.14429",
    "title": "Equilibria and Convergence in Fire Sale Games",
    "abstract": "The complex interactions between algorithmic trading agents can have a severe\ninfluence on the functioning of our economy, as witnessed by recent banking\ncrises and trading anomalies. A common phenomenon in these situations are\n\\emph{fire sales}, a contagious process of asset sales that trigger further\nsales. We study the existence and structure of equilibria in a game-theoretic\nmodel of fire sales. We prove that for a wide parameter range (e.g., convex\nprice impact functions), equilibria exist and form a complete lattice. This is\ncontrasted with a non-existence result for concave price impact functions.\nMoreover, we study the convergence of best-response dynamics towards equilibria\nwhen they exist. In general, best-response dynamics may cycle. However, in many\nsettings they are guaranteed to converge to the socially optimal equilibrium\nwhen starting from a natural initial state. Moreover, we discuss a simplified\nvariant of the dynamics that is less informationally demanding and converges to\nthe same equilibria. We compare the dynamics in terms of convergence speed.",
    "descriptor": "",
    "authors": [
      "Nils Bertschinger",
      "Martin Hoefer",
      "Simon Krogmann",
      "Pascal Lenzner",
      "Steffen Schuldenzucker",
      "Lisa Wilhelmi"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2206.14429"
  },
  {
    "id": "arXiv:2206.14431",
    "title": "Open Problem: Properly learning decision trees in polynomial time?",
    "abstract": "The authors recently gave an $n^{O(\\log\\log n)}$ time membership query\nalgorithm for properly learning decision trees under the uniform distribution\n(Blanc et al., 2021). The previous fastest algorithm for this problem ran in\n$n^{O(\\log n)}$ time, a consequence of Ehrenfeucht and Haussler (1989)'s\nclassic algorithm for the distribution-free setting. In this article we\nhighlight the natural open problem of obtaining a polynomial-time algorithm,\ndiscuss possible avenues towards obtaining it, and state intermediate\nmilestones that we believe are of independent interest.",
    "descriptor": "\nComments: 5 pages, to appear at the Open Problem sessions at COLT 2022\n",
    "authors": [
      "Guy Blanc",
      "Jane Lange",
      "Mingda Qiao",
      "Li-Yang Tan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.14431"
  },
  {
    "id": "arXiv:2206.14435",
    "title": "An $hp$-adaptive multi-element stochastic collocation method for  surrogate modeling with information re-use",
    "abstract": "This paper introduces an $hp$-adaptive multi-element stochastic collocation\nmethod, which additionally allows to re-use existing model evaluations during\neither $h$- or $p$-refinement. The collocation method is based on weighted Leja\nnodes. After $h$-refinement, local interpolations are stabilized by adding Leja\nnodes on each newly created sub-element in a hierarchical manner. A\ndimension-adaptive algorithm is employed for local $p$-refinement. The\nsuggested multi-element stochastic collocation method is employed in the\ncontext of forward and inverse uncertainty quantification to handle non-smooth\nor strongly localised response surfaces. Comparisons against existing\nmulti-element collocation schemes and other competing methods in five different\ntest cases verify the advantages of the suggested method in terms of accuracy\nversus computational cost.",
    "descriptor": "\nComments: 26 pages, 11 figures\n",
    "authors": [
      "Armin Galetzka",
      "Dimitrios Loukrezis",
      "Niklas Georg",
      "Herbert De Gersem",
      "Ulrich R\u00f6mer"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2206.14435"
  },
  {
    "id": "arXiv:2206.14436",
    "title": "A contraction theory approach to observer-based controller design for  glucose regulation in type 1 diabetes with intra-patient variability",
    "abstract": "While the Artificial Pancreas is effective in regulating the blood glucose in\nthe safe range of 70-180 mg/dl in type 1 diabetic patients, the high\nintra-patient variability, as well as exogenous meal disturbances, poses a\nserious challenge. The existing control algorithms thus require additional\nsafety algorithms and feed-forward actions. Moreover, the unavailability of\ninsulin sensors in Artificial Pancreas makes this task more difficult. In the\npresent work, a subcutaneous model of type 1 diabetes (T1D) is considered for\nobserver-based controller design in the framework of contraction analysis. A\nvariety of realistic multiple-meal scenarios for three virtual T1D patients\nhave been investigated with +30 % and -30 % of parametric variability. The\naverage time spent by the three T1D patients is found to be 77 %, 73 % and 76\n%, respectively. A significant reduction in the time spent in hyperglycemia\n(>180 mg/dl) is achieved without any feed-forward action for meal compensation.",
    "descriptor": "",
    "authors": [
      "Bhabani Shankar Dey",
      "Anirudh Nath",
      "Abhilash Patel",
      "Indra Narayan Kar"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.14436"
  },
  {
    "id": "arXiv:2206.14437",
    "title": "MaNi: Maximizing Mutual Information for Nuclei Cross-Domain Unsupervised  Segmentation",
    "abstract": "In this work, we propose a mutual information (MI) based unsupervised domain\nadaptation (UDA) method for the cross-domain nuclei segmentation. Nuclei vary\nsubstantially in structure and appearances across different cancer types,\nleading to a drop in performance of deep learning models when trained on one\ncancer type and tested on another. This domain shift becomes even more critical\nas accurate segmentation and quantification of nuclei is an essential\nhistopathology task for the diagnosis/ prognosis of patients and annotating\nnuclei at the pixel level for new cancer types demands extensive effort by\nmedical experts. To address this problem, we maximize the MI between labeled\nsource cancer type data and unlabeled target cancer type data for transferring\nnuclei segmentation knowledge across domains. We use the Jensen-Shanon\ndivergence bound, requiring only one negative pair per positive pair for MI\nmaximization. We evaluate our set-up for multiple modeling frameworks and on\ndifferent datasets comprising of over 20 cancer-type domain shifts and\ndemonstrate competitive performance. All the recently proposed approaches\nconsist of multiple components for improving the domain adaptation, whereas our\nproposed module is light and can be easily incorporated into other methods\n(Implementation: https://github.com/YashSharma/MaNi ).",
    "descriptor": "\nComments: Accepted at MICCAI 2022\n",
    "authors": [
      "Yash Sharma",
      "Sana Syed",
      "Donald E. Brown"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.14437"
  },
  {
    "id": "arXiv:2206.14439",
    "title": "Approximate Data Deletion in Generative Models",
    "abstract": "Users have the right to have their data deleted by third-party learned\nsystems, as codified by recent legislation such as the General Data Protection\nRegulation (GDPR) and the California Consumer Privacy Act (CCPA). Such data\ndeletion can be accomplished by full re-training, but this incurs a high\ncomputational cost for modern machine learning models. To avoid this cost, many\napproximate data deletion methods have been developed for supervised learning.\nUnsupervised learning, in contrast, remains largely an open problem when it\ncomes to (approximate or exact) efficient data deletion. In this paper, we\npropose a density-ratio-based framework for generative models. Using this\nframework, we introduce a fast method for approximate data deletion and a\nstatistical test for estimating whether or not training points have been\ndeleted. We provide theoretical guarantees under various learner assumptions\nand empirically demonstrate our methods across a variety of generative methods.",
    "descriptor": "",
    "authors": [
      "Zhifeng Kong",
      "Scott Alfeld"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.14439"
  },
  {
    "id": "arXiv:2206.14442",
    "title": "Conditioned Human Trajectory Prediction using Iterative Attention Blocks",
    "abstract": "Human motion prediction is key to understand social environments, with direct\napplications in robotics, surveillance, etc. We present a simple yet effective\npedestrian trajectory prediction model aimed at pedestrians positions\nprediction in urban-like environments conditioned by the environment: map and\nsurround agents. Our model is a neural-based architecture that can run several\nlayers of attention blocks and transformers in an iterative sequential fashion,\nallowing to capture the important features in the environment that improve\nprediction. We show that without explicit introduction of social masks,\ndynamical models, social pooling layers, or complicated graph-like structures,\nit is possible to produce on par results with SoTA models, which makes our\napproach easily extendable and configurable, depending on the data available.\nWe report results performing similarly with SoTA models on publicly available\nand extensible-used datasets with unimodal prediction metrics ADE and FDE.",
    "descriptor": "",
    "authors": [
      "Aleksey Postnikov",
      "Aleksander Gamayunov",
      "Gonzalo Ferrer"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.14442"
  },
  {
    "id": "arXiv:2206.14444",
    "title": "Geometry parameter estimation for sparse X-ray log imaging",
    "abstract": "We consider geometry parameter estimation in industrial sawmill fan-beam\nX-ray tomography. In such industrial settings, scanners do not always allow\nidentification of the location of the source-detector pair, which creates the\nissue of unknown geometry. This work considers two approaches for geometry\nestimation. Our first approach is a calibration object correlation method in\nwhich we calculate the maximum cross-correlation between a known-sized\ncalibration object image and its filtered backprojection reconstruction and use\ndifferential evolution as an optimiser. The second approach is projection\ntrajectory simulation, where we use a set of known intersection points and a\nsequential Monte Carlo method for estimating the posterior density of the\nparameters. We show numerically that a large set of parameters can be used for\nartefact-free reconstruction. We deploy Bayesian inversion with Cauchy priors\nfor synthetic and real sawmill data for detection of knots with a very low\nnumber of measurements and uncertain measurement geometry.",
    "descriptor": "",
    "authors": [
      "Angelina Senchukova",
      "Jarkko Suuronen",
      "Jere Heikkinen",
      "Lassi Roininen"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.14444"
  },
  {
    "id": "arXiv:2206.14446",
    "title": "Automatic balancing parameter selection for Tikhonov-TV regularization",
    "abstract": "This paper considers large-scale linear ill-posed inverse problems whose\nsolutions can be represented as sums of smooth and piecewise constant\ncomponents. To solve such problems we consider regularizers consisting of two\nterms that must be balanced. Namely, a Tikhonov term guarantees the smoothness\nof the smooth solution component, while a total-variation (TV) regularizer\npromotes blockiness of the non-smooth solution component. A scalar parameter\nallows to balance between these two terms and, hence, to appropriately separate\nand regularize the smooth and non-smooth components of the solution. This paper\nproposes an efficient algorithm to solve this regularization problem by the\nalternating direction method of multipliers (ADMM). Furthermore, a novel\nalgorithm for automatic choice of the balancing parameter is introduced, using\nrobust statistics. The proposed approach is supported by some theoretical\nanalysis, and numerical experiments concerned with different inverse problems\nare presented to validate the choice of the balancing parameter.",
    "descriptor": "",
    "authors": [
      "Ali Gholami",
      "Silvia Gazzola"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.14446"
  },
  {
    "id": "arXiv:2206.14451",
    "title": "SRCN3D: Sparse R-CNN 3D Surround-View Camera Object Detection and  Tracking for Autonomous Driving",
    "abstract": "Detection And Tracking of Moving Objects (DATMO) is an essential component in\nenvironmental perception for autonomous driving. While 3D detectors using\nsurround-view cameras are just flourishing, there is a growing tendency of\nusing different transformer-based methods to learn queries in 3D space from 2D\nfeature maps of perspective view. This paper proposes Sparse R-CNN 3D (SRCN3D),\na novel two-stage fully-convolutional mapping pipeline for surround-view camera\ndetection and tracking. SRCN3D adopts a cascade structure with twin-track\nupdate of both fixed number of proposal boxes and proposal latent features.\nProposal boxes are projected to perspective view so as to aggregate Region of\nInterest (RoI) local features. Based on that, proposal features are refined via\na dynamic instance interactive head, which then generates classification and\nthe offsets applied to original bounding boxes. Compared to prior arts, our\nsparse feature sampling module only utilizes local 2D features for adjustment\nof each corresponding 3D proposal box, leading to a complete sparse paradigm.\nThe proposal features and appearance features are both taken in data\nassociation process in a multi-hypotheses 3D multi-object tracking approach.\nExtensive experiments on nuScenes dataset demonstrate the effectiveness of our\nproposed SRCN3D detector and tracker. Code is available at\nhttps://github.com/synsin0/SRCN3D.",
    "descriptor": "\nComments: 9 pages, 6 figures\n",
    "authors": [
      "Yining Shi",
      "Jingyan Shen",
      "Yifan Sun",
      "Yunlong Wang",
      "Jiaxin Li",
      "Shiqi Sun",
      "Kun Jiang",
      "Diange Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.14451"
  },
  {
    "id": "arXiv:2206.14452",
    "title": "Deep Multiple Instance Learning For Forecasting Stock Trends Using  Financial News",
    "abstract": "A major source of information can be taken from financial news articles,\nwhich have some correlations about the fluctuation of stock trends. In this\npaper, we investigate the influences of financial news on the stock trends,\nfrom a multi-instance view. The intuition behind this is based on the news\nuncertainty of varying intervals of news occurrences and the lack of annotation\nin every single financial news. Under the scenario of Multiple Instance\nLearning (MIL) where training instances are arranged in bags, and a label is\nassigned for the entire bag instead of instances, we develop a flexible and\nadaptive multi-instance learning model and evaluate its ability in directional\nmovement forecast of Standard & Poors 500 index on financial news dataset.\nSpecifically, we treat each trading day as one bag, with certain amounts of\nnews happening on each trading day as instances in each bag. Experiment results\ndemonstrate that our proposed multi-instance-based framework gains outstanding\nresults in terms of the accuracy of trend prediction, compared with other\nstate-of-art approaches and baselines.",
    "descriptor": "\nComments: 17 pages, 4 figures\n",
    "authors": [
      "Yiqi Deng",
      "Siu Ming Yiu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Finance (q-fin.CP)"
    ],
    "url": "https://arxiv.org/abs/2206.14452"
  },
  {
    "id": "arXiv:2206.14453",
    "title": "Distributed Information Bottleneck for a Primitive Gaussian Diamond  Channel with Rayleigh Fading",
    "abstract": "This paper considers the distributed information bottleneck (D-IB) problem\nfor a primitive Gaussian diamond channel with two relays and Rayleigh fading.\nDue to the bottleneck constraint, it is impossible for the relays to inform the\ndestination node of the perfect channel state information (CSI) in each\nrealization. To evaluate the bottleneck rate, we provide an upper bound by\nassuming that the destination node knows the CSI and the relays can cooperate\nwith each other, and also three achievable schemes with simple symbol-by-symbol\nrelay processing and compression. Numerical results show that the lower bounds\nobtained by the proposed achievable schemes can come close to the upper bound\non a wide range of relevant system parameters.",
    "descriptor": "\nComments: 6 pages, 3 figures, this paper has been accetped by the 2022 IEEE International Symposium on Information Theory (ISIT)\n",
    "authors": [
      "Hao Xu",
      "Kai-Kit Wong",
      "Giuseppe Caire",
      "Shlomo Shamai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.14453"
  },
  {
    "id": "arXiv:2206.14464",
    "title": "SPI-GAN: Distilling Score-based Generative Models with Straight-Path  Interpolations",
    "abstract": "Score-based generative models (SGMs) are a recently proposed paradigm for\ndeep generative tasks and now show the state-of-the-art sampling performance.\nIt is known that the original SGM design solves the two problems of the\ngenerative trilemma: i) sampling quality, and ii) sampling diversity. However,\nthe last problem of the trilemma was not solved, i.e., their training/sampling\ncomplexity is notoriously high. To this end, distilling SGMs into simpler\nmodels, e.g., generative adversarial networks (GANs), is gathering much\nattention currently. We present an enhanced distillation method, called\nstraight-path interpolation GAN (SPI-GAN), which can be compared to the\nstate-of-the-art shortcut-based distillation method, called denoising diffusion\nGAN (DD-GAN). However, our method corresponds to an extreme method that does\nnot use any intermediate shortcut information of the reverse SDE path, in which\ncase DD-GAN fails to obtain good results. Nevertheless, our straight-path\ninterpolation method greatly stabilizes the overall training process. As a\nresult, SPI-GAN is one of the best models in terms of the sampling\nquality/diversity/time for CIFAR-10, CelebA-HQ-256, and LSUN-Church-256.",
    "descriptor": "",
    "authors": [
      "Jinsung Jeon",
      "Noseong Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.14464"
  },
  {
    "id": "arXiv:2206.14465",
    "title": "Intelligent Reflecting Surface for MIMO VLC: Joint Design of Surface  Configuration and Transceiver Signal Processing",
    "abstract": "With the capability of reconfiguring the wireless electromagnetic\nenvironment, intelligent reflecting surface (IRS) is a new paradigm for\ndesigning future wireless communication systems. In this paper, we consider\noptical IRS for improving the performance of visible light communication (VLC)\nunder a multiple-input and multiple-output (MIMO) setting. Specifically, we\nfocus on the downlink communication of an indoor MIMO VLC system and aim to\nminimize the mean square error (MSE) of demodulated signals at the receiver. To\nthis end, the MIMO channel gain of the IRS-aided VLC is first derived under the\npoint source assumption, based on which the MSE minimization problem is then\nformulated subject to the emission power constraints. Next, we propose an\nalternating optimization algorithm, which decomposes the original problem into\nthree subproblems, to iteratively optimize the IRS configuration, the precoding\nand detection matrices for minimizing the MSE. Moreover, theoretical analysis\non the performance of the proposed algorithm in high and low signal-to-noise\nrate (SNR) regimes is provided, revealing that the joint optimization process\ncan be simplified in such special cases, and the algorithm's convergence\nproperty and computational complexity are also discussed. Finally, numerical\nresults show that IRS-aided schemes significantly reduce the MSE as compared to\ntheir counterparts without IRS, and the proposed algorithm outperforms other\nbaseline schemes.",
    "descriptor": "",
    "authors": [
      "Shiyuan Sun",
      "Fang Yang",
      "Jian Song",
      "Rui Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.14465"
  },
  {
    "id": "arXiv:2206.14466",
    "title": "Integrating IoT-Sensing and Crowdsensing with Privacy:  Privacy-Preserving Hybrid Sensing for Smart Cities",
    "abstract": "Data sensing and gathering is an essential task for various\ninformation-driven services in smart cities. On the one hand, Internet of\nThings (IoT) sensors can be deployed at certain fixed locations to capture data\nreliably but suffer from limited sensing coverage. On the other hand, data can\nalso be gathered dynamically through crowdsensing contributed by voluntary\nusers but suffer from its unreliability and the lack of incentives for users'\ncontributions. In this paper, we explore an integrated paradigm called \"hybrid\nsensing\" that harnesses both IoT-sensing and crowdsensing in a complementary\nmanner. In hybrid sensing, users are incentivized to provide sensing data not\ncovered by IoT sensors and provide crowdsourced feedback to assist in\ncalibrating IoT-sensing. Their contributions will be rewarded with credits that\ncan be redeemed to retrieve synthesized information from the hybrid system. In\nthis paper, we develop a hybrid sensing system that supports explicit user\nprivacy -- IoT sensors are obscured physically to prevent capturing private\nuser data, and users interact with a crowdsensing server via a\nprivacy-preserving protocol to preserve their anonymity. A key application of\nour system is smart parking, by which users can inquire and find the available\nparking spaces in outdoor parking lots. We implemented our hybrid sensing\nsystem for smart parking and conducted extensive empirical evaluations.\nFinally, our hybrid sensing system can be potentially applied to other\ninformation-driven services in smart cities.",
    "descriptor": "\nComments: To appear in ACM Transactions on Internet of Things\n",
    "authors": [
      "Hanwei Zhu",
      "Sid Chi-Kin Chau",
      "Gladhi Guarddin",
      "Weifa Liang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.14466"
  },
  {
    "id": "arXiv:2206.14467",
    "title": "Single-domain Generalization in Medical Image Segmentation via Test-time  Adaptation from Shape Dictionary",
    "abstract": "Domain generalization typically requires data from multiple source domains\nfor model learning. However, such strong assumption may not always hold in\npractice, especially in medical field where the data sharing is highly\nconcerned and sometimes prohibitive due to privacy issue. This paper studies\nthe important yet challenging single domain generalization problem, in which a\nmodel is learned under the worst-case scenario with only one source domain to\ndirectly generalize to different unseen target domains. We present a novel\napproach to address this problem in medical image segmentation, which extracts\nand integrates the semantic shape prior information of segmentation that are\ninvariant across domains and can be well-captured even from single domain data\nto facilitate segmentation under distribution shifts. Besides, a test-time\nadaptation strategy with dual-consistency regularization is further devised to\npromote dynamic incorporation of these shape priors under each unseen domain to\nimprove model generalizability. Extensive experiments on two medical image\nsegmentation tasks demonstrate the consistent improvements of our method across\nvarious unseen domains, as well as its superiority over state-of-the-art\napproaches in addressing domain generalization under the worst-case scenario.",
    "descriptor": "\nComments: Accepted to AAAI 2022\n",
    "authors": [
      "Quande Liu",
      "Cheng Chen",
      "Qi Dou",
      "Pheng-Ann Heng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.14467"
  },
  {
    "id": "arXiv:2206.14468",
    "title": "Minimalist and High-performance Conversational Recommendation with  Uncertainty Estimation for User Preference",
    "abstract": "Conversational recommendation system (CRS) is emerging as a user-friendly way\nto capture users' dynamic preferences over candidate items and attributes.\nMulti-shot CRS is designed to make recommendations multiple times until the\nuser either accepts the recommendation or leaves at the end of their patience.\nExisting works are trained with reinforcement learning (RL), which may suffer\nfrom unstable learning and prohibitively high demands for computing. In this\nwork, we propose a simple and efficient CRS, MInimalist Non-reinforced\nInteractive COnversational Recommender Network (MINICORN). MINICORN models the\nepistemic uncertainty of the estimated user preference and queries the user for\nthe attribute with the highest uncertainty. The system employs a simple network\narchitecture and makes the query-vs-recommendation decision using a single\nrule. Somewhat surprisingly, this minimalist approach outperforms\nstate-of-the-art RL methods on three real-world datasets by large margins. We\nhope that MINICORN will serve as a valuable baseline for future research.",
    "descriptor": "",
    "authors": [
      "Yinan Zhang",
      "Boyang Li",
      "Yong Liu",
      "Hao Wang",
      "Chunyan Miao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.14468"
  },
  {
    "id": "arXiv:2206.14475",
    "title": "Siamese Contrastive Embedding Network for Compositional Zero-Shot  Learning",
    "abstract": "Compositional Zero-Shot Learning (CZSL) aims to recognize unseen compositions\nformed from seen state and object during training. Since the same state may be\nvarious in the visual appearance while entangled with different objects, CZSL\nis still a challenging task. Some methods recognize state and object with two\ntrained classifiers, ignoring the impact of the interaction between object and\nstate; the other methods try to learn the joint representation of the\nstate-object compositions, leading to the domain gap between seen and unseen\ncomposition sets. In this paper, we propose a novel Siamese Contrastive\nEmbedding Network (SCEN) (Code: https://github.com/XDUxyLi/SCEN-master) for\nunseen composition recognition. Considering the entanglement between state and\nobject, we embed the visual feature into a Siamese Contrastive Space to capture\nprototypes of them separately, alleviating the interaction between state and\nobject. In addition, we design a State Transition Module (STM) to increase the\ndiversity of training compositions, improving the robustness of the recognition\nmodel. Extensive experiments indicate that our method significantly outperforms\nthe state-of-the-art approaches on three challenging benchmark datasets,\nincluding the recent proposed C-QGA dataset.",
    "descriptor": "",
    "authors": [
      "Xiangyu Li",
      "Xu Yang",
      "Kun Wei",
      "Cheng Deng",
      "Muli Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.14475"
  },
  {
    "id": "arXiv:2206.14477",
    "title": "Adversarial Ensemble Training by Jointly Learning Label Dependencies and  Member Models",
    "abstract": "Training an ensemble of different sub-models has empirically proven to be an\neffective strategy to improve deep neural networks' adversarial robustness.\nCurrent ensemble training methods for image recognition usually encode the\nimage labels by one-hot vectors, which neglect dependency relationships between\nthe labels. Here we propose a novel adversarial training approach that learns\nthe conditional dependencies between labels and the model ensemble jointly. We\ntest our approach on widely used datasets MNIST, FasionMNIST and CIFAR-10.\nResults show that our approach is more robust against black-box attacks\ncompared with state-of-the-art methods. Our code is available at\nhttps://github.com/ZJLAB-AMMI/LSD.",
    "descriptor": "",
    "authors": [
      "Lele Wang",
      "Bin Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.14477"
  },
  {
    "id": "arXiv:2206.14480",
    "title": "Representation and Synthesis of C++ Programs for Generalized Planning",
    "abstract": "The paper introduces a novel representation for Generalized Planning (GP)\nproblems, and their solutions, as C++ programs. Our C++ representation allows\nto formally proving the termination of generalized plans, and to specifying\ntheir asymptotic complexity w.r.t. the number of world objects. Characterizing\nthe complexity of C++ generalized plans enables the application of a\ncombinatorial search that enumerates the space of possible GP solutions in\norder of complexity. Experimental results show that our implementation of this\napproach, which we call BFGP++, outperforms the previous GP as heuristic search\napproach for the computation of generalized plans represented as\ncompiler-styled programs. Last but not least, the execution of a C++ program on\na classical planning instance is a deterministic grounding-free and search-free\nprocess, so our C++ representation allows us to automatically validate the\ncomputed solutions on large test instances of thousands of objects, where\noff-the-shelf classical planners get stuck either in the pre-processing or in\nthe search.",
    "descriptor": "\nComments: Accepted at sixth workshop on Generalization in Planning at IJCAI-ECAI 2022\n",
    "authors": [
      "Javier Segovia-Aguas",
      "Yolanda E-Mart\u00edn",
      "Sergio Jim\u00e9nez"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.14480"
  },
  {
    "id": "arXiv:2206.14483",
    "title": "Data augmentation for learning predictive models on EEG: a systematic  comparison",
    "abstract": "The use of deep learning for electroencephalography (EEG) classification\ntasks has been rapidly growing in the last years, yet its application has been\nlimited by the relatively small size of EEG datasets. Data augmentation, which\nconsists in artificially increasing the size of the dataset during training,\nhas been a key ingredient to obtain state-of-the-art performances across\napplications such as computer vision or speech. While a few augmentation\ntransformations for EEG data have been proposed in the literature, their\npositive impact on performance across tasks remains elusive. In this work, we\npropose a unified and exhaustive analysis of the main existing EEG\naugmentations, which are compared in a common experimental setting. Our results\nhighlight the best data augmentations to consider for sleep stage\nclassification and motor imagery brain computer interfaces, showing predictive\npower improvements greater than 10% in some cases.",
    "descriptor": "\nComments: Submitted to Journal of Neural Engineering\n",
    "authors": [
      "C\u00e9dric Rommel",
      "Joseph Paillard",
      "Thomas Moreau",
      "Alexandre Gramfort"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.14483"
  },
  {
    "id": "arXiv:2206.14486",
    "title": "Beyond neural scaling laws: beating power law scaling via data pruning",
    "abstract": "Widely observed neural scaling laws, in which error falls off as a power of\nthe training set size, model size, or both, have driven substantial performance\nimprovements in deep learning. However, these improvements through scaling\nalone require considerable costs in compute and energy. Here we focus on the\nscaling of error with dataset size and show how both in theory and practice we\ncan break beyond power law scaling and reduce it to exponential scaling instead\nif we have access to a high-quality data pruning metric that ranks the order in\nwhich training examples should be discarded to achieve any pruned dataset size.\nWe then test this new exponential scaling prediction with pruned dataset size\nempirically, and indeed observe better than power law scaling performance on\nResNets trained on CIFAR-10, SVHN, and ImageNet. Given the importance of\nfinding high-quality pruning metrics, we perform the first large-scale\nbenchmarking study of ten different data pruning metrics on ImageNet. We find\nmost existing high performing metrics scale poorly to ImageNet, while the best\nare computationally intensive and require labels for every image. We therefore\ndeveloped a new simple, cheap and scalable self-supervised pruning metric that\ndemonstrates comparable performance to the best supervised metrics. Overall,\nour work suggests that the discovery of good data-pruning metrics may provide a\nviable path forward to substantially improved neural scaling laws, thereby\nreducing the resource costs of modern deep learning.",
    "descriptor": "",
    "authors": [
      "Ben Sorscher",
      "Robert Geirhos",
      "Shashank Shekhar",
      "Surya Ganguli",
      "Ari S. Morcos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.14486"
  },
  {
    "id": "arXiv:2206.14496",
    "title": "Auto-Encoder-Extreme Learning Machine Model for Boiler NOx Emission  Concentration Prediction",
    "abstract": "An automatic encoder (AE) extreme learning machine (ELM)-AE-ELM model is\nproposed to predict the NOx emission concentration based on the combination of\nmutual information algorithm (MI), AE, and ELM. First, the importance of\npractical variables is computed by the MI algorithm, and the mechanism is\nanalyzed to determine the variables related to the NOx emission concentration.\nThen, the time delay correlations between the selected variables and NOx\nemission concentration are further analyzed to reconstruct the modeling data.\nSubsequently, the AE is applied to extract hidden features within the input\nvariables. Finally, an ELM algorithm establishes the relationship between the\nNOx emission concentration and deep features. The experimental results on\npractical data indicate that the proposed model shows promising performance\ncompared to state-of-art models.",
    "descriptor": "\nComments: Accepted by Energy\n",
    "authors": [
      "Zhenhao Tang",
      "Shikui Wang",
      "Xiangying Chai",
      "Shengxian Cao",
      "Tinghui Ouyang",
      "Yang Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.14496"
  },
  {
    "id": "arXiv:2206.14498",
    "title": "Enhancing Security of Memristor Computing System Through Secure Weight  Mapping",
    "abstract": "Emerging memristor computing systems have demonstrated great promise in\nimproving the energy efficiency of neural network (NN) algorithms. The NN\nweights stored in memristor crossbars, however, may face potential theft\nattacks due to the nonvolatility of the memristor devices. In this paper, we\npropose to protect the NN weights by mapping selected columns of them in the\nform of 1's complements and leaving the other columns in their original form,\npreventing the adversary from knowing the exact representation of each weight.\nThe results show that compared with prior work, our method achieves\neffectiveness comparable to the best of them and reduces the hardware overhead\nby more than 18X.",
    "descriptor": "\nComments: 6 pages, 4 figures, accepted by IEEE ISVLSI 2022\n",
    "authors": [
      "Minhui Zou",
      "Junlong Zhou",
      "Xiaotong Cui",
      "Wei Wang",
      "Shahar Kvatinsky"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2206.14498"
  },
  {
    "id": "arXiv:2206.14501",
    "title": "Quantifying the structure of controversial discussions with unsupervised  methods: a look into the Twitter climate change conversation",
    "abstract": "Social media provides an essential platform for shaping and sharing opinions\nand consuming information in a decentralized way. However, users often interact\nwith and are exposed to information mostly aligned with their beliefs, creating\na positive feedback mechanism that reinforces those beliefs and excludes\ncontrasting ones. In this paper, we study such mechanisms by analyzing the\nsocial network dynamics of controversial Twitter discussions using unsupervised\nmethods that demand little computational power. Specifically, we focus on the\nretweet networks of the climate change conversation during 2019, when important\nclimate social movements flourished. We find echo chambers of climate believers\nand climate skeptics that we identify based solely on the users retweeted by\nthe audience (here referred to as the chamber) associated with the leading\nusers of the conversation. Users with similar (contrasting) ideological\npositions show significantly high (low)-overlapping chambers, resulting in a\nbimodal overlap distribution. Further, we uncover the ideological position of\npreviously unobserved high-impact users based on how many audience members fall\ninto either echo chamber. We classify more than half of the retweeting\npopulation as either climate believers or skeptics and find that the\ncross-group communication is negligible. Moreover, we find that, while the echo\nchamber structures are consistent throughout the year, most users inside the\necho chambers change from one week to the next, suggesting that they are a\nstable emergent property of the Twittersphere. Interestingly, we observe a high\ncorrelation between the main #FridaysForFuture strikes and the sizes of the\nclimate skeptics' echo chambers but no significant correlation with those of\nthe climate believers.",
    "descriptor": "\nComments: 25 pages (17 of main text + 8 of appendices), 11 figures\n",
    "authors": [
      "Blas Kolic",
      "Fabi\u00e1n Aguirre-L\u00f3pez",
      "Sergio Hern\u00e1ndez-Williams",
      "Guillermo Gardu\u00f1o-Hern\u00e1ndez"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.14501"
  },
  {
    "id": "arXiv:2206.14502",
    "title": "RegMixup: Mixup as a Regularizer Can Surprisingly Improve Accuracy and  Out Distribution Robustness",
    "abstract": "We show that the effectiveness of the well celebrated Mixup [Zhang et al.,\n2018] can be further improved if instead of using it as the sole learning\nobjective, it is utilized as an additional regularizer to the standard\ncross-entropy loss. This simple change not only provides much improved accuracy\nbut also significantly improves the quality of the predictive uncertainty\nestimation of Mixup in most cases under various forms of covariate shifts and\nout-of-distribution detection experiments. In fact, we observe that Mixup\nyields much degraded performance on detecting out-of-distribution samples\npossibly, as we show empirically, because of its tendency to learn models that\nexhibit high-entropy throughout; making it difficult to differentiate\nin-distribution samples from out-distribution ones. To show the efficacy of our\napproach (RegMixup), we provide thorough analyses and experiments on vision\ndatasets (ImageNet & CIFAR-10/100) and compare it with a suite of recent\napproaches for reliable uncertainty estimation.",
    "descriptor": "\nComments: 22 pages, 18 figures\n",
    "authors": [
      "Francesco Pinto",
      "Harry Yang",
      "Ser-Nam Lim",
      "Philip H.S. Torr",
      "Puneet K. Dokania"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.14502"
  },
  {
    "id": "arXiv:2206.14503",
    "title": "Content-adaptive generation and parallel compositing of volumetric depth  images for responsive visualization of large volume data",
    "abstract": "We present a content-adaptive generation and parallel compositing algorithm\nfor view-dependent explorable representations of large three-dimensional volume\ndata. Large distributed volume data are routinely produced in both numerical\nsimulations and experiments, yet it remains challenging to visualize them at\nsmooth, interactive frame rates. Volumetric Depth Images (VDIs), view-dependent\npiece wise-constant representations of volume data, offer a potential solution:\nthey are more compact and less expensive to render than the original data. So\nfar, however, there is no method to generate such representations on\ndistributed data and to automatically adapt the representation to the contents\nof the data. We propose an approach that addresses both issues by enabling\nsort-last parallel generation of VDIs with content-adaptive parameters. The\nresulting VDIs can be streamed for display, providing responsive visualization\nof large, potentially distributed, volume data.",
    "descriptor": "\nComments: 10 pages, 10 figures\n",
    "authors": [
      "Aryaman Gupta",
      "Pietro Incardona",
      "Paul Hunt",
      "Guido Reina",
      "Steffen Frey",
      "Stefan Gumhold",
      "Ulrik G\u00fcnther",
      "Ivo F. Sbalzarini"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2206.14503"
  },
  {
    "id": "arXiv:2206.14504",
    "title": "GERNERMED++: Transfer Learning in German Medical NLP",
    "abstract": "We present a statistical model for German medical natural language processing\ntrained for named entity recognition (NER) as an open, publicly available\nmodel. The work serves as a refined successor to our first GERNERMED model\nwhich is substantially outperformed by our work. We demonstrate the\neffectiveness of combining multiple techniques in order to achieve strong\nresults in entity recognition performance by the means of transfer-learning on\npretrained deep language models (LM), word-alignment and neural machine\ntranslation. Due to the sparse situation on open, public medical entity\nrecognition models for German texts, this work offers benefits to the German\nresearch community on medical NLP as a baseline model. Since our model is based\non public English data, its weights are provided without legal restrictions on\nusage and distribution. The sample code and the statistical model is available\nat: https://github.com/frankkramer-lab/GERNERMED-pp",
    "descriptor": "",
    "authors": [
      "Johann Frei",
      "Ludwig Frei-Stuber",
      "Frank Kramer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14504"
  },
  {
    "id": "arXiv:2206.14505",
    "title": "Rate Lifting for Stochastic Process Algebra: Exploiting Structural  Properties",
    "abstract": "This report presents an algorithm for determining the unknown rates in the\nsequential processes of a Stochastic Process Algebra model, provided that the\nrates in the combined flat model are given. Such a rate lifting is useful for\nmodel reengineering and model repair. Technically, the algorithm works by\nsolving systems of nonlinear equations and, if necessary, adjusting the model`s\nsynchronisation structure without changing its transition system. This report\ncontains the complete pseudo-code of the algorithm. The approach taken by the\nalgorithm exploits some structural properties of Stochastic Process Algebra\nsystems, which are formulated here for the first time and could be very\nbeneficial also in other contexts.",
    "descriptor": "",
    "authors": [
      "Markus Siegle",
      "Amin Soltanieh"
    ],
    "subjectives": [
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2206.14505"
  },
  {
    "id": "arXiv:2206.14506",
    "title": "A calculus for epistemic interactions",
    "abstract": "It plays a central role in intelligent agent systems to model agent's\nepistemic state and its change. To this end, some formal systems have been\npresented. Among them, epistemic logics focus on logic laws of different\nepistemic attributes (e.g., knowledge, belief, common knowledge, etc) and\nepistemic actions (e.g., public announcement, private announcement,\nasynchronous announcement, etc). All these systems do not involve the\ninteractive behaviours between an agent and its environment. Through enriching\nthe well-known $\\pi$-calculus, this paper presents the e-calculus, which\nprovides a concept framework to model epistemic interactions between agents\nwith epistemic states. Unlike usual process calculus, all systems in the\ne-calculus are always arranged to run at an epistemic state. To formalize\nepistemic states abstractly, a group of postulates on them are presented.\nMoreover, based on these postulates, the behaviour theory of the e-calculus is\ndeveloped in two different viewpoints.",
    "descriptor": "",
    "authors": [
      "Huili Xing",
      "Zhaohui Zhu",
      "Jinjin Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.14506"
  },
  {
    "id": "arXiv:2206.14509",
    "title": "Combinatorial and Algorithmic Aspects of Monadic Stability",
    "abstract": "Nowhere dense classes of graphs are classes of sparse graphs with rich\nstructural and algorithmic properties, however, they fail to capture even\nsimple classes of dense graphs. Monadically stable classes, originating from\nmodel theory, generalize nowhere dense classes and close them under\ntransductions, i.e. transformations defined by colorings and simple first-order\ninterpretations. In this work we aim to extend some combinatorial and\nalgorithmic properties of nowhere dense classes to monadically stable classes\nof finite graphs. We prove the following results.\n- In monadically stable classes the Ramsey numbers $R(s,t)$ are bounded from\nabove by $\\mathcal{O}(t^{s-1-\\delta})$ for some $\\delta>0$, improving the bound\n$R(s,t)\\in \\mathcal{O}(t^{s-1}/(\\log t)^{s-1})$ known for general graphs and\nthe bounds known for $k$-stable graphs when $s\\leq k$.\n- For every monadically stable class $\\mathcal{C}$ and every integer $r$,\nthere exists $\\delta > 0$ such that every graph $G \\in \\mathcal{C}$ that\ncontains an $r$-subdivision of the biclique $K_{t,t}$ as a subgraph also\ncontains $K_{t^\\delta,t^\\delta}$ as a subgraph. This generalizes earlier\nresults for nowhere dense graph classes.\n- We obtain a stronger regularity lemma for monadically stable classes of\ngraphs.\n- Finally, we show that we can compute polynomial kernels for the independent\nset and dominating set problems in powers of nowhere dense classes. Formerly,\nonly fixed-parameter tractable algorithms were known for these problems on\npowers of nowhere dense classes.",
    "descriptor": "",
    "authors": [
      "Jan Dreier",
      "Nikolas M\u00e4hlmann",
      "Amer E. Mouawad",
      "Sebastian Siebertz",
      "Alexandre Vigny"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Logic in Computer Science (cs.LO)",
      "Combinatorics (math.CO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.14509"
  },
  {
    "id": "arXiv:2206.14510",
    "title": "Continuous Switch Model and Heuristics for Mixed-Integer Problems in  Power Systems",
    "abstract": "Power systems operation and planning analyses often determine dispatch and\nplanning decisions by solving a mixed-integer nonlinear problem (MINLP) with\nbinary variables devices to the grid. Binary variables, in addition to\nnonlinear AC network constraints, make this NP-hard problem computationally\nchallenging for gradient-based methods to converge to a local minimum due to\nthe discontinuous solution space. In this work, we form an equivalent-circuit\nmodel of the MINLP decision problem by representing binary decisions as a\nrelaxed switch model. The relaxed switch model is characterized by a continuous\nfunction that preserves the physical behavior of a real-world switch. This\neffectively transforms the MINLP problem into an NLP problem by mapping the\nintegrality constraints into a relaxed indicator function. To solve the\ntransformed NLP problem, we develop homotopy and damping methods that rely on\nknowledge from the physical behavior of the switch. With these methods, we\nempirically demonstrate robust convergences for large realistic systems\n(>70,000 buses) while satisfying the non-relaxed AC behavior of the system. The\nmethodology is generalizable for various operation and planning problems,\nincluding unit commitment, transmission line switching, and shunt placement.\nExamples demonstrate superior convergence against state-of-the-art commercial\ntools and other binary-relaxation methods.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Aayushya Agarwal",
      "Amritanshu Pandey",
      "Marko Jereminov",
      "Larry Pillegi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.14510"
  },
  {
    "id": "arXiv:2206.14516",
    "title": "On Hull-Variation Problem of Equivalent Linear Codes",
    "abstract": "The intersection ${\\bf C}\\bigcap {\\bf C}^{\\perp}$ (${\\bf C}\\bigcap {\\bf\nC}^{\\perp_h}$) of a linear code ${\\bf C}$ and its Euclidean dual ${\\bf\nC}^{\\perp}$ (Hermitian dual ${\\bf C}^{\\perp_h}$) is called the Euclidean\n(Hermitian) hull of this code. Quantum error correction codes (QECCs) and\nentanglement-assisted quantum error correction (EAQEC) codes are necessary for\nquantum information processing and computation. The construction of an EAQEC\ncode from a linear code over ${\\bf F}_q$ or ${\\bf F}_{q^2}$ depends essentially\non the Euclidean hull or the Hermitian hull of this code. Therefore it is\nnatural to consider the hull-variation problem when a linear code ${\\bf C}$ is\ntransformed to an equivalent code ${\\bf v} \\cdot {\\bf C}$. In this paper a\ngeneral method to construct hull-decreasing or hull-increasing equivalent\nlinear codes is proposed. We prove that for a nonnegative integer $h$\nsatisfying $0 \\leq h \\leq n-1$, a linear $[2n, n]_q$ self-dual code is\nequivalent to a linear $h$-dimension hull code. On the opposite direction we\nprove that a linear LCD code over ${\\bf F}_{2^s}$ satisfying $d\\geq 2$ and\n$d^{\\perp} \\geq 2$ is equivalent to a linear one-dimension hull code under a\nweak condition. Several new families of negacyclic LCD codes and BCH LCD codes\nover ${\\bf F}_3$ are also constructed. Our method can be applied to the\ngeneralized Reed-Solomon codes and the generalized twisted Reed-Solomon codes\nto construct arbitrary dimension hull MDS codes. Some new EAQEC codes including\nMDS and almost MDS entanglement-assisted quantum codes are constructed. Many\nEAQEC codes over small fields are constructed from optimal Hermitian self-dual\ncodes.",
    "descriptor": "\nComments: 28 pages. arXiv admin note: text overlap with arXiv:2206.13995\n",
    "authors": [
      "Hao Chen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.14516"
  },
  {
    "id": "arXiv:2206.14519",
    "title": "Effect of Auditory Stimuli on Electroencephalography-based  Authentication",
    "abstract": "Opposed to standard authentication methods based on credentials,\nbiometric-based authentication has lately emerged as a viable paradigm for\nattaining rapid and secure authentication of users. Among the numerous\ncategories of biometric traits, electroencephalogram (EEG)-based biometrics is\nrecognized as a promising method owing to its unique characteristics. This\npaper provides an experimental evaluation of the effect of auditory stimuli\n(AS) on EEG-based biometrics by studying the following features: i) general\nchange in AS-aided EEG-based biometric authentication in comparison with\nnon-AS-aided EEG-based biometric authentication, ii) role of the language of\nthe AS and ii) influence of the conduction method of the AS. Our results show\nthat the presence of an AS can improve authentication performance by 9.27%.\nAdditionally, the performance achieved with an in-ear AS is better than that\nobtained using a bone-conducting AS. Finally, we verify that performance is\nindependent of the language of the AS. The results of this work provide a step\nforward towards designing a robust EEG-based authentication system.",
    "descriptor": "",
    "authors": [
      "Nibras Abo Alzahab",
      "Angelo Di Iorio",
      "Marco Baldi",
      "Lorenzo Scalise"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.14519"
  },
  {
    "id": "arXiv:2206.14520",
    "title": "Imaging the time series of one single referenced EEG electrode for  Epileptic Seizures Risk Analysis",
    "abstract": "The time series captured by a single scalp electrode (plus the reference\nelectrode) of refractory epileptic patients is used to forecast seizures\nsusceptibility. The time series is preprocessed, segmented, and each segment\ntransformed into an image, using three different known methods: Recurrence\nPlot, Gramian Angular Field, Markov Transition Field. The likelihood of the\noccurrence of a seizure in a future predefined time window is computed by\naveraging the output of the softmax layer of a CNN, differently from the usual\nconsideration of the output of the classification layer. By thresholding this\nlikelihood, seizure forecasting has better performance. Interestingly, for\nalmost every patient, the best threshold was different from 50%. The results\nshow that this technique can predict with good results for some seizures and\npatients. However, more tests, namely more patients and more seizures, are\nneeded to better understand the real potential of this technique.",
    "descriptor": "\nComments: 11 pages, 5 figures, 3 tables. arXiv admin note: text overlap with arXiv:2204.07034\n",
    "authors": [
      "Tiago Leal",
      "Antonio Dourado",
      "Fabio Lopes",
      "Cesar Teixeira"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.14520"
  },
  {
    "id": "arXiv:2206.14523",
    "title": "Supervised Deep Hashing for High-dimensional and Heterogeneous  Case-based Reasoning",
    "abstract": "Case-based Reasoning (CBR) on high-dimensional and heterogeneous data is a\ntrending yet challenging and computationally expensive task in the real world.\nA promising approach is to obtain low-dimensional hash codes representing cases\nand perform a similarity retrieval of cases in Hamming space. However, previous\nmethods based on data-independent hashing rely on random projections or manual\nconstruction, inapplicable to address specific data issues (e.g.,\nhigh-dimensionality and heterogeneity) due to their insensitivity to data\ncharacteristics. To address these issues, this work introduces a novel deep\nhashing network to learn similarity-preserving compact hash codes for efficient\ncase retrieval and proposes a deep-hashing-enabled CBR model HeCBR.\nSpecifically, we introduce position embedding to represent heterogeneous\nfeatures and utilize a multilinear interaction layer to obtain case embeddings,\nwhich effectively filtrates zero-valued features to tackle high-dimensionality\nand sparsity and captures inter-feature couplings. Then, we feed the case\nembeddings into fully-connected layers, and subsequently a hash layer generates\nhash codes with a quantization regularizer to control the quantization loss\nduring relaxation. To cater to incremental learning of CBR, we further propose\nan adaptive learning strategy to update the hash function. Extensive\nexperiments on public datasets show that HeCBR greatly reduces storage and\nsignificantly accelerates case retrieval. HeCBR achieves desirable performance\ncompared with the state-of-the-art CBR methods and performs significantly\nbetter than hashing-based CBR methods in classification.",
    "descriptor": "\nComments: 27 pages\n",
    "authors": [
      "Qi Zhang",
      "Liang Hu",
      "Chongyang Shi",
      "Ke Liu",
      "Longbing Cao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.14523"
  },
  {
    "id": "arXiv:2206.14526",
    "title": "Design and Optimization of Aerial-Aided Multi-Access Edge Computing  towards 6G",
    "abstract": "Ubiquity in network coverage is one of the main features of 5G and is\nexpected to be extended to the computing domain in 6G. In order to provide this\nholistic approach of ubiquity in communication and computation, an integration\nof satellite, aerial and terrestrial networks is foreseen. In particular, the\nrising amount of applications such as In-Flight Entertainment and Connectivity\nServices (IFECS) and SDN-enabled satellites renders network management more\nchallenging. Moreover, due to the stringent Quality of Service (QoS)\nrequirements edge computing gains in importance for these applications. Here,\nnetwork performance can be boosted by considering components of the aerial\nnetwork, like aircrafts, as potential Multi-Access Edge Computing (MEC) nodes.\nThus, we propose an Aerial-Aided Multi-Access Edge Computing (AA-MEC)\narchitecture that provides a framework for optimal management of computing\nresources and internet-based services in the sky. Furthermore, we formulate\noptimization problems to minimize the network latency for the two use cases of\nproviding IFECS to other aircrafts in the sky and providing services for\noffloading AI/ML-tasks from satellites. Due to the dynamic nature of the\nsatellite and aerial networks, we propose a re-configurable optimization. For\nthe transforming network we continuously identify the optimal MEC node for each\napplication and the optimal path to the destination MEC node. In summary, our\nresults demonstrate that using AA-MEC improves network latency performance by\n10.43% compared to the traditional approach of using only terrestrial MEC nodes\nfor latency-critical applications such as online gaming. Furthermore, while\ncomparing our proposed dynamic approach with a static one, we record a benefit\nof at least 6.7% decrease in flow latency for IFECS and 56.03% decrease for\ncomputation offloading.",
    "descriptor": "\nComments: Submitted to IEEE TRANSACTIONS ON AEROSPACE AND ELECTRONIC SYSTEMS\n",
    "authors": [
      "J\u00f6rg von Mankowski",
      "Emre Durmaz",
      "Arled Papa",
      "Hansini Vijayaraghavan",
      "Wolfgang Kellerer"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.14526"
  },
  {
    "id": "arXiv:2206.14527",
    "title": "Challenges of mapping Vulnerabilities and Exposures to Open-Source  Packages",
    "abstract": "Much of the current software depends on open-source components, which in turn\nhave complex dependencies on other open-source libraries. Vulnerabilities in\nopen source therefore have potentially huge impacts. The goal of this work is\nto get a quantitative overview of the frequency and evolution of existing\nvulnerabilities in popular software repositories and package managers. To this\nend, we provide an up-to-date overview of the open source landscape and its\nmost popular package managers. We discuss approaches to map entries of the\nCommon Vulnerabilities and Exposures (CVE) list to open-source libraries. Based\non this mapping approaches, we show the frequency and distribution of CVE\nentries with respect to popular programming languages.",
    "descriptor": "",
    "authors": [
      "Tobias Dam",
      "Sebastian Neumaier"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.14527"
  },
  {
    "id": "arXiv:2206.14528",
    "title": "Procrustes Analysis with Deformations: A Closed-Form Solution by  Eigenvalue Decomposition",
    "abstract": "Generalized Procrustes Analysis (GPA) is the problem of bringing multiple\nshapes into a common reference by estimating transformations. GPA has been\nextensively studied for the Euclidean and affine transformations. We introduce\nGPA with deformable transformations, which forms a much wider and difficult\nproblem. We specifically study a class of transformations called the Linear\nBasis Warps (LBWs), which contains the affine transformation and most of the\nusual deformation models, such as the Thin-Plate Spline (TPS). GPA with\ndeformations is a nonconvex underconstrained problem. We resolve the\nfundamental ambiguities of deformable GPA using two shape constraints requiring\nthe eigenvalues of the shape covariance. These eigenvalues can be computed\nindependently as a prior or posterior. We give a closed-form and optimal\nsolution to deformable GPA based on an eigenvalue decomposition. This solution\nhandles regularization, favoring smooth deformation fields. It requires the\ntransformation model to satisfy a fundamental property of free-translations,\nwhich asserts that the model can implement any translation. We show that this\nproperty fortunately holds true for most common transformation models,\nincluding the affine and TPS models. For the other models, we give another\nclosed-form solution to GPA, which agrees exactly with the first solution for\nmodels with free-translation. We give pseudo-code for computing our solution,\nleading to the proposed DefGPA method, which is fast, globally optimal and\nwidely applicable. We validate our method and compare it to previous work on\nsix diverse 2D and 3D datasets, with special care taken to choose the\nhyperparameters from cross-validation.",
    "descriptor": "\nComments: Published on International journal of computer vision (IJCV) 2022\n",
    "authors": [
      "Fang Bai",
      "Adrien Bartoli"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2206.14528"
  },
  {
    "id": "arXiv:2206.14530",
    "title": "Deep Active Visual Attention for Real-time Robot Motion Generation:  Emergence of Tool-body Assimilation and Adaptive Tool-use",
    "abstract": "Sufficiently perceiving the environment is a critical factor in robot motion\ngeneration. Although the introduction of deep visual processing models have\ncontributed in extending this ability, existing methods lack in the ability to\nactively modify what to perceive; humans perform internally during visual\ncognitive processes. This paper addresses the issue by proposing a novel robot\nmotion generation model, inspired by a human cognitive structure. The model\nincorporates a state-driven active top-down visual attention module, which\nacquires attentions that can actively change targets based on task states. We\nterm such attentions as role-based attentions, since the acquired attention\ndirected to targets that shared a coherent role throughout the motion. The\nmodel was trained on a robot tool-use task, in which the role-based attentions\nperceived the robot grippers and tool as identical end-effectors, during object\npicking and object dragging motions respectively. This is analogous to a\nbiological phenomenon called tool-body assimilation, in which one regards a\nhandled tool as an extension of one's body. The results suggested an\nimprovement of flexibility in model's visual perception, which sustained stable\nattention and motion even if it was provided with untrained tools or exposed to\nexperimenter's distractions.",
    "descriptor": "",
    "authors": [
      "Hyogo Hiruma",
      "Hiroshi Ito",
      "Hiroki Mori",
      "Tetsuya Ogata"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.14530"
  },
  {
    "id": "arXiv:2206.14532",
    "title": "Revisiting Label Smoothing and Knowledge Distillation Compatibility:  What was Missing?",
    "abstract": "This work investigates the compatibility between label smoothing (LS) and\nknowledge distillation (KD). Contemporary findings addressing this thesis\nstatement take dichotomous standpoints: Muller et al. (2019) and Shen et al.\n(2021b). Critically, there is no effort to understand and resolve these\ncontradictory findings, leaving the primal question -- to smooth or not to\nsmooth a teacher network? -- unanswered. The main contributions of our work are\nthe discovery, analysis and validation of systematic diffusion as the missing\nconcept which is instrumental in understanding and resolving these\ncontradictory findings. This systematic diffusion essentially curtails the\nbenefits of distilling from an LS-trained teacher, thereby rendering KD at\nincreased temperatures ineffective. Our discovery is comprehensively supported\nby large-scale experiments, analyses and case studies including image\nclassification, neural machine translation and compact student distillation\ntasks spanning across multiple datasets and teacher-student architectures.\nBased on our analysis, we suggest practitioners to use an LS-trained teacher\nwith a low-temperature transfer to achieve high performance students. Code and\nmodels are available at\nhttps://keshik6.github.io/revisiting-ls-kd-compatibility/",
    "descriptor": "\nComments: ICML 2022; 27 pages\n",
    "authors": [
      "Keshigeyan Chandrasegaran",
      "Ngoc-Trung Tran",
      "Yunqing Zhao",
      "Ngai-Man Cheung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14532"
  },
  {
    "id": "arXiv:2206.14534",
    "title": "When Does Group Invariant Learning Survive Spurious Correlations?",
    "abstract": "By inferring latent groups in the training data, recent works introduce\ninvariant learning to the case where environment annotations are unavailable.\nTypically, learning group invariance under a majority/minority split is\nempirically shown to be effective in improving out-of-distribution\ngeneralization on many datasets. However, theoretical guarantee for these\nmethods on learning invariant mechanisms is lacking. In this paper, we reveal\nthe insufficiency of existing group invariant learning methods in preventing\nclassifiers from depending on spurious correlations in the training set.\nSpecifically, we propose two criteria on judging such sufficiency.\nTheoretically and empirically, we show that existing methods can violate both\ncriteria and thus fail in generalizing to spurious correlation shifts.\nMotivated by this, we design a new group invariant learning method, which\nconstructs groups with statistical independence tests, and reweights samples by\ngroup label proportion to meet the criteria. Experiments on both synthetic and\nreal data demonstrate that the new method significantly outperforms existing\ngroup invariant learning methods in generalizing to spurious correlation\nshifts.",
    "descriptor": "",
    "authors": [
      "Yimeng Chen",
      "Ruibin Xiong",
      "Zhiming Ma",
      "Yanyan Lan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.14534"
  },
  {
    "id": "arXiv:2206.14538",
    "title": "vMFNet: Compositionality Meets Domain-generalised Segmentation",
    "abstract": "Training medical image segmentation models usually requires a large amount of\nlabeled data. By contrast, humans can quickly learn to accurately recognise\nanatomy of interest from medical (e.g. MRI and CT) images with some limited\nguidance. Such recognition ability can easily generalise to new images from\ndifferent clinical centres. This rapid and generalisable learning ability is\nmostly due to the compositional structure of image patterns in the human brain,\nwhich is less incorporated in medical image segmentation. In this paper, we\nmodel the compositional components (i.e. patterns) of human anatomy as\nlearnable von-Mises-Fisher (vMF) kernels, which are robust to images collected\nfrom different domains (e.g. clinical centres). The image features can be\ndecomposed to (or composed by) the components with the composing operations,\ni.e. the vMF likelihoods. The vMF likelihoods tell how likely each anatomical\npart is at each position of the image. Hence, the segmentation mask can be\npredicted based on the vMF likelihoods. Moreover, with a reconstruction module,\nunlabeled data can also be used to learn the vMF kernels and likelihoods by\nrecombining them to reconstruct the input image. Extensive experiments show\nthat the proposed vMFNet achieves improved generalisation performance on two\nbenchmarks, especially when annotations are limited. Code is publicly available\nat: https://github.com/vios-s/vMFNet.",
    "descriptor": "\nComments: Accepted by MICCAI 2022\n",
    "authors": [
      "Xiao Liu",
      "Spyridon Thermos",
      "Pedro Sanchez",
      "Alison Q. O'Neil",
      "Sotirios A. Tsaftaris"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.14538"
  },
  {
    "id": "arXiv:2206.14539",
    "title": "Current Challenges of Cyber Threat and Vulnerability Identification  Using Public Enumerations",
    "abstract": "Identification of cyber threats is one of the essential tasks for security\nteams. Currently, cyber threats can be identified using knowledge organized\ninto various formats, enumerations, and knowledge bases. This paper studies the\ncurrent challenges of identifying vulnerabilities and threats in cyberspace\nusing enumerations and data about assets. Although enumerations are used in\npractice, we point out several issues that still decrease the quality of\nvulnerability and threat identification. Since vulnerability identification\nmethods are based on network monitoring and agents, the issues are related to\nthe asset discovery, the precision of vulnerability discovery, and the amount\nof data. On the other hand, threat identification utilizes graph-based,\nnature-language, machine-learning, and ontological approaches. The current\ntrend is to propose methods that utilize tactics, techniques, and procedures\ninstead of low-level indicators of compromise to make cyber threat\nidentification more mature. Cooperation between standards from threat,\nvulnerability, and asset management is also an unresolved issue confirmed by\nanalyzing relationships between public enumerations and knowledge bases. Last,\nwe studied the usability of techniques from the MITRE ATT&CK knowledge base for\nthreat modeling using network monitoring to capture data. Although network\ntraffic is not the most used data source, it allows the modeling of almost all\ntactics from the MITRE ATT&CK.",
    "descriptor": "\nComments: The 17th International Conference on Availability, Reliability and Security (ARES 2022), 8 pages\n",
    "authors": [
      "Luk\u00e1\u0161 Sadlek",
      "Pavel \u010celeda",
      "Daniel Tovar\u0148\u00e1k"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.14539"
  },
  {
    "id": "arXiv:2206.14541",
    "title": "Why patient data cannot be easily forgotten?",
    "abstract": "Rights provisioned within data protection regulations, permit patients to\nrequest that knowledge about their information be eliminated by data holders.\nWith the advent of AI learned on data, one can imagine that such rights can\nextent to requests for forgetting knowledge of patient's data within AI models.\nHowever, forgetting patients' imaging data from AI models, is still an\nunder-explored problem. In this paper, we study the influence of patient data\non model performance and formulate two hypotheses for a patient's data: either\nthey are common and similar to other patients or form edge cases, i.e. unique\nand rare cases. We show that it is not possible to easily forget patient data.\nWe propose a targeted forgetting approach to perform patient-wise forgetting.\nExtensive experiments on the benchmark Automated Cardiac Diagnosis Challenge\ndataset showcase the improved performance of the proposed targeted forgetting\napproach as opposed to a state-of-the-art method.",
    "descriptor": "\nComments: Ruolin Su and Xiao Liu contributed equally. Accepted by MICCAI 2022\n",
    "authors": [
      "Ruolin Su",
      "Xiao Liu",
      "Sotirios A. Tsaftaris"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.14541"
  },
  {
    "id": "arXiv:2206.14542",
    "title": "Comparative Study of Inference Methods for Interpolative Decomposition",
    "abstract": "In this paper, we propose a probabilistic model with automatic relevance\ndetermination (ARD) for learning interpolative decomposition (ID), which is\ncommonly used for low-rank approximation, feature selection, and identifying\nhidden patterns in data, where the matrix factors are latent variables\nassociated with each data dimension. Prior densities with support on the\nspecified subspace are used to address the constraint for the magnitude of the\nfactored component of the observed matrix. Bayesian inference procedure based\non Gibbs sampling is employed. We evaluate the model on a variety of real-world\ndatasets including CCLE $EC50$, CCLE $IC50$, Gene Body Methylation, and\nPromoter Methylation datasets with different sizes, and dimensions, and show\nthat the proposed Bayesian ID algorithms with automatic relevance determination\nlead to smaller reconstructive errors even compared to vanilla Bayesian ID\nalgorithms with fixed latent dimension set to matrix rank.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2205.14825\n",
    "authors": [
      "Jun Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.14542"
  },
  {
    "id": "arXiv:2206.14547",
    "title": "A Novel Attack to the Permuted Kernel Problem",
    "abstract": "The Permuted Kernel Problem (PKP) asks to find a permutation of a given\nvector belonging to the kernel of a given matrix. The PKP is at the basis of\nPKP-DSS, a post-quantum signature scheme deriving from the identification\nscheme proposed by Shamir in 1989. The most efficient solver for PKP is due to\na recent paper by Koussa et al. In this paper we propose an improvement of such\nan algorithm, which we achieve by considering an additional collision search\nstep applied on kernel equations involving a small number of coordinates. We\nstudy the conditions for such equations to exist from a coding theory\nperspective, and we describe how to efficiently find them with methods borrowed\nfrom coding theory, such as information set decoding. We assess the complexity\nof the resulting algorithm and show that it outperforms previous approaches in\nseveral cases. We also show that, taking the new solver into account, the\nsecurity level of some instances of PKP-DSS turns out to be slightly\noverestimated.",
    "descriptor": "",
    "authors": [
      "Paolo Santini",
      "Marco Baldi",
      "Franco Chiaraluce"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.14547"
  },
  {
    "id": "arXiv:2206.14550",
    "title": "SALO: An Efficient Spatial Accelerator Enabling Hybrid Sparse Attention  Mechanisms for Long Sequences",
    "abstract": "The attention mechanisms of transformers effectively extract pertinent\ninformation from the input sequence. However, the quadratic complexity of\nself-attention w.r.t the sequence length incurs heavy computational and memory\nburdens, especially for tasks with long sequences. Existing accelerators face\nperformance degradation in these tasks. To this end, we propose SALO to enable\nhybrid sparse attention mechanisms for long sequences. SALO contains a data\nscheduler to map hybrid sparse attention patterns onto hardware and a spatial\naccelerator to perform the efficient attention computation. We show that SALO\nachieves 17.66x and 89.33x speedup on average compared to GPU and CPU\nimplementations, respectively, on typical workloads, i.e., Longformer and ViL.",
    "descriptor": "\nComments: Accepted by 59th DAC\n",
    "authors": [
      "Guan Shen",
      "Jieru Zhao",
      "Quan Chen",
      "Jingwen Leng",
      "Chao Li",
      "Minyi Guo"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14550"
  },
  {
    "id": "arXiv:2206.14553",
    "title": "ITLingo Research Initiative in 2022",
    "abstract": "Several surveys and studies have noticed that cost, and quality problems\nresult from mistakes that occurred in the early phases of the projects, for\ninstance: poor definition of the project vision and respective value for the\norganization; misalignment between IT and business resources; failures in\nproject management practices; or poor and low-quality technical documentation.\nThese facts have emphasized the need for improving socio-technical disciplines\nsuch as project management, enterprise architecture, requirements engineering,\nor system design. These studies also noted the need to reduce the efforts\ninvolved in traditional development processes, for example, by automating some\nhuman-intensive and error-prone tasks. This article presents the scientific\nproject we have conducted in these last years named \"ITLingo\". ITLingo is a\nresearch initiative that has proposed new languages, tools, and techniques to\nsupport users to improve such practices, mainly related to those disciplines.\nITLingo users are IT engineers and managers in multiple roles like project\nmanagers, enterprise architects, business analysts, system architects,\nrequirements engineers, or even system developers. The article describes the\ninnovative nature of the activities carried out under the ITLingo umbrella and\nidentifies future and open challenges.",
    "descriptor": "",
    "authors": [
      "Alberto Rodrigues da Silva"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.14553"
  },
  {
    "id": "arXiv:2206.14554",
    "title": "Uncertainty-aware Panoptic Segmentation",
    "abstract": "Reliable scene understanding is indispensable for modern autonomous systems.\nCurrent learning-based methods typically try to maximize their performance\nbased on segmentation metrics that only consider the quality of the\nsegmentation. However, for the safe operation of a system in the real world it\nis crucial to consider the uncertainty in the prediction as well. In this work,\nwe introduce the novel task of uncertainty-aware panoptic segmentation, which\naims to predict per-pixel semantic and instance segmentations, together with\nper-pixel uncertainty estimates. We define two novel metrics to facilitate its\nquantitative analysis, the uncertainty-aware Panoptic Quality (uPQ) and the\npanoptic Expected Calibration Error (pECE). We further propose the novel\ntop-down Evidential Panoptic Segmentation Network (EvPSNet) to solve this task.\nOur architecture employs a simple yet effective probabilistic fusion module\nthat leverages the predicted uncertainties. Additionally, we propose a new\nLov\\'asz evidential loss function to optimize the IoU for the segmentation\nutilizing the probabilities provided by deep evidential learning. Furthermore,\nwe provide several strong baselines combining state-of-the-art panoptic\nsegmentation networks with sampling-free uncertainty estimation techniques.\nExtensive evaluations show that our EvPSNet achieves the new state-of-the-art\nfor the standard Panoptic Quality (PQ), as well as for our uncertainty-aware\npanoptic metrics.",
    "descriptor": "",
    "authors": [
      "Kshitij Sirohi",
      "Sajad Marvi",
      "Daniel B\u00fcscher",
      "Wolfram Burgard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.14554"
  },
  {
    "id": "arXiv:2206.14555",
    "title": "Technical Report for CVPR 2022 LOVEU AQTC Challenge",
    "abstract": "This technical report presents the 2nd winning model for AQTC, a task newly\nintroduced in CVPR 2022 LOng-form VidEo Understanding (LOVEU) challenges. This\nchallenge faces difficulties with multi-step answers, multi-modal, and diverse\nand changing button representations in video. We address this problem by\nproposing a new context ground module attention mechanism for more effective\nfeature mapping. In addition, we also perform the analysis over the number of\nbuttons and ablation study of different step networks and video features. As a\nresult, we achieved the overall 2nd place in LOVEU competition track 3,\nspecifically the 1st place in two out of four evaluation metrics. Our code is\navailable at https://github.com/jaykim9870/ CVPR-22_LOVEU_unipyler.",
    "descriptor": "\nComments: 4 pages, 3 figures, technical report for track3 of CVPR 2022 LOVEU challenge\n",
    "authors": [
      "Hyeonyu Kim",
      "Jongeun Kim",
      "Jeonghun Kang",
      "Sanguk Park",
      "Dongchan Park",
      "Taehwan Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.14555"
  },
  {
    "id": "arXiv:2206.14556",
    "title": "Linearizing Partial Search Orders",
    "abstract": "In recent years, questions about the construction of special orderings of a\ngiven graph search were studied by several authors. On the one hand, the so\ncalled end-vertex problem introduced by Corneil et al. in 2010 asks for search\norderings ending in a special vertex. On the other hand, the problem of finding\norderings that induce a given search tree was introduced already in the 1980s\nby Hagerup and received new attention most recently by Beisegel et al. Here, we\nintroduce a generalization of some of these problems by studying the question\nwhether there is a search ordering that is a linear extension of a given\npartial order on a graph's vertex set. We show that this problem can be solved\nin polynomial time on chordal bipartite graphs for LBFS, which also implies the\nfirst polynomial-time algorithms for the end-vertex problem and two search tree\nproblems for this combination of graph class and search. Furthermore, we\npresent polynomial-time algorithms for LBFS and MCS on split graphs which\ngeneralize known results for the end-vertex and search tree problems.",
    "descriptor": "\nComments: full version of an extended abstract to be published in the Proceedings of the 48th International Workshop on Graph-Theoretic Concepts in Computer Science (WG 2022) in T\\\"ubingen\n",
    "authors": [
      "Robert Scheffler"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2206.14556"
  },
  {
    "id": "arXiv:2206.14560",
    "title": "A note on a Code-Based Signature Scheme",
    "abstract": "In this work, we exploit a serious security flaw in a code-based signature\nscheme from a 2019 work by Liu, Yang, Han and Wang. They adapt the McEliece\ncryptosystem to obtain a new scheme and, on top of this, they design an\nefficient digital signature. We show that the new encryption scheme based on\nMcEliece, even if it has longer public keys, is not more secure than the\nstandard one. Moreover, the choice of parameters for the signature leads to a\nsignificant performance improvement, but it introduces a vulnerability in the\nprotocol.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Giuseppe D'Alconzo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.14560"
  },
  {
    "id": "arXiv:2206.14562",
    "title": "Observer-Based Coordinated Tracking Control for Nonlinear Multi-Agent  Systems with Intermittent Communication under Heterogeneous Coupling  Framework",
    "abstract": "In this article, the observer-based coordinated tracking control problem for\na class of nonlinear multi-agent systems(MASs) with intermittent communication\nand information constraints is studied under dynamic switching topology. First,\na state observer is designed to estimate the unmeasurable actual state\ninformation in the system. Second, adjustable heterogeneous coupling weighting\nparameters are introduced in the dynamic switching topology, and the\ndistributed coordinated tracking control protocol under heterogeneous coupling\nframework is proposed. Then, a new Lemma is constructed to realize the\ncooperative design of observer gain, state feedback gain and heterogeneous\ncoupling gain matrices. Furthermore, the stability of the system is further\nproved, and the range of communication rate is obtained. On this basis, the\nintermittent communication mode is extended to three time interval cases,\nnamely normal communication, leader-follower communication interruption and all\nagents communication interruption, and then the distributed coordinated\ntracking control method is improved to solve this problem. Finally, simulation\nexperiments are conducted with nonlinear MASs to verify the correctness of\nmethods.",
    "descriptor": "",
    "authors": [
      "Yuhang Zhang",
      "Yulian Jiang",
      "Shenquan Wang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.14562"
  },
  {
    "id": "arXiv:2206.14567",
    "title": "Contributions to Context-Aware Smart Healthcare: A Security and Privacy  Perspective",
    "abstract": "The management of health data, from their gathering to their analysis, arises\na number of challenging issues due to their highly confidential nature. In\nparticular, this dissertation contributes to several security and privacy\nchallenges within the smart health paradigm. More concretely, we firstly\ndevelop some contributions to context-aware environments enabling smart health\nscenarios. We present an extensive analysis on the security aspects of the\nunderlying sensors and networks deployed in such environments, a novel\nuser-centred privacy framework for analysing ubiquitous computing systems, and\na complete analysis on the security and privacy challenges that need to be\nfaced to implement cognitive cities properly. Second, we contribute to process\nmining, a popular analytical field that helps analyse business processes within\norganisations. Despite its popularity within the healthcare industry, we\naddress two major issues: the high complexity of healthcare processes and the\nscarce research on privacy aspects. Regarding the first issue, we present a\nnovel process discovery algorithm with a built-in heuristic that simplifies\ncomplex processes and, regarding the second, we propose two novel\nprivacy-preserving process mining methods, which achieve a remarkable trade-off\nbetween accuracy and privacy. Last but not least, we present some smart health\napplications, namely a context-aware recommender system for routes, a platform\nsupporting early mobilization programmes in hospital settings, and a\nhealth-oriented geographic information system. The results of this dissertation\nare intended to help the research community to enhance the security of the\nintelligent environments of the future as well as the privacy of the citizens\nregarding their personal and health data.",
    "descriptor": "\nComments: Doctoral thesis\n",
    "authors": [
      "Edgar Batista"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.14567"
  },
  {
    "id": "arXiv:2206.14568",
    "title": "ADARP: A Multi Modal Dataset for Stress and Alcohol Relapse  Quantification in Real Life Setting",
    "abstract": "Stress detection and classification from wearable sensor data is an emerging\narea of research with significant implications for individuals' physical and\nmental health. In this work, we introduce a new dataset, ADARP, which contains\nphysiological data and self-report outcomes collected in real-world ambulatory\nsettings involving individuals diagnosed with alcohol use disorders. We\ndescribe the user study, present details of the dataset, establish the\nsignificant correlation between physiological data and self-reported outcomes,\ndemonstrate stress classification, and make our dataset public to facilitate\nresearch.",
    "descriptor": "",
    "authors": [
      "Ramesh Kumar Sah",
      "Michael McDonell",
      "Patricia Pendry",
      "Sara Parent",
      "Hassan Ghasemzadeh",
      "Michael J Cleveland"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.14568"
  },
  {
    "id": "arXiv:2206.14571",
    "title": "Should Social Robots in Retail Manipulate Customers?",
    "abstract": "Against the backdrop of structural changes in the retail trade, social robots\nhave found their way into retail stores and shopping malls in order to attract,\nwelcome, and greet customers; to inform them, advise them, and persuade them to\nmake a purchase. Salespeople often have a broad knowledge of their product and\nrely on offering competent and honest advice, whether it be on shoes, clothing,\nor kitchen appliances. However, some frequently use sales tricks to secure\npurchases. The question arises of how consulting and sales robots should\n\"behave\". Should they behave like human advisors and salespeople, i.e.,\noccasionally manipulate customers? Or should they be more honest and reliable\nthan us? This article tries to answer these questions. After explaining the\nbasics, it evaluates a study in this context and gives recommendations for\ncompanies that want to use consulting and sales robots. Ultimately, fair,\nhonest, and trustworthy robots in retail are a win-win situation for all\nconcerned.",
    "descriptor": "\nComments: Accepted paper of the AAAI 2022 Spring Symposium \"How Fair is Fair? Achieving Wellbeing AI\" (Stanford University)\n",
    "authors": [
      "Oliver Bendel",
      "Liliana Margarida Dos Santos Alves"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.14571"
  },
  {
    "id": "arXiv:2206.14574",
    "title": "Knowledge Graph Fusion for Language Model Fine-tuning",
    "abstract": "Language Models such as BERT have grown in popularity due to their ability to\nbe pre-trained and perform robustly on a wide range of Natural Language\nProcessing tasks. Often seen as an evolution over traditional word embedding\ntechniques, they can produce semantic representations of text, useful for tasks\nsuch as semantic similarity. However, state-of-the-art models often have high\ncomputational requirements and lack global context or domain knowledge which is\nrequired for complete language understanding. To address these limitations, we\ninvestigate the benefits of knowledge incorporation into the fine-tuning stages\nof BERT. An existing K-BERT model, which enriches sentences with triplets from\na Knowledge Graph, is adapted for the English language and extended to inject\ncontextually relevant information into sentences. As a side-effect, changes\nmade to K-BERT for accommodating the English language also extend to other\nword-based languages. Experiments conducted indicate that injected knowledge\nintroduces noise. We see statistically significant improvements for\nknowledge-driven tasks when this noise is minimised. We show evidence that,\ngiven the appropriate task, modest injection with relevant, high-quality\nknowledge is most performant.",
    "descriptor": "\nComments: Submitted to ISCMI 2022\n",
    "authors": [
      "Nimesh Bhana",
      "Terence L. van Zyl"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14574"
  },
  {
    "id": "arXiv:2206.14575",
    "title": "Why Robust Natural Language Understanding is a Challenge",
    "abstract": "With the proliferation of Deep Machine Learning into real-life applications,\na particular property of this technology has been brought to attention: Neural\nNetworks notoriously present low robustness and can be highly sensitive to\nsmall input perturbations. Recently, many methods for verifying networks'\ngeneral properties of robustness have been proposed, but they are mostly\napplied in Computer Vision. In this paper we propose a Verification method for\nNatural Language Understanding classification based on larger regions of\ninterest, and we discuss the challenges of such task. We observe that, although\nthe data is almost linearly separable, the verifier does not output positive\nresults and we explain the problems and implications.",
    "descriptor": "",
    "authors": [
      "Marco Casadio",
      "Ekaterina Komendantskaya",
      "Verena Rieser",
      "Matthew L. Daggitt",
      "Daniel Kienitz",
      "Luca Arnaboldi",
      "Wen Kokke"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.14575"
  },
  {
    "id": "arXiv:2206.14576",
    "title": "Using cognitive psychology to understand GPT-3",
    "abstract": "We study GPT-3, a recent large language model, using tools from cognitive\npsychology. More specifically, we assess GPT-3's decision-making, information\nsearch, deliberation, and causal reasoning abilities on a battery of canonical\nexperiments from the literature. We find that much of GPT-3's behavior is\nimpressive: it solves vignette-based tasks similarly or better than human\nsubjects, is able to make decent decisions from descriptions, outperforms\nhumans in a multi-armed bandit task, and shows signatures of model-based\nreinforcement learning. Yet we also find that small perturbations to\nvignette-based tasks can lead GPT-3 vastly astray, that it shows no signatures\nof directed exploration, and that it fails miserably in a causal reasoning\ntask. These results enrich our understanding of current large language models\nand pave the way for future investigations using tools from cognitive\npsychology to study increasingly capable and opaque artificial agents.",
    "descriptor": "",
    "authors": [
      "Marcel Binz",
      "Eric Schulz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14576"
  },
  {
    "id": "arXiv:2206.14578",
    "title": "Evaluating Generative Patent Language Models",
    "abstract": "This research aims to build generative language models in the patent domain\nand to evaluate the models from a human-centric perspective. The evaluation\nmetric is to calculate the ratio of keystrokes that can be saved for a user in\nan autocomplete context based on the prediction of the generative models. The\nperformance of models in different sizes can also be evaluated in such a metric\nby measuring a number of newly granted patents. On the basis of the metric, it\nis found that the largest model is not necessarily the best. Several models are\npre-trained from scratch with patent corpus and are released. The experiments\nin this manuscript focus on patent claims, but the ideas and implementation can\nbe applied to other parts of a patent document. Furthermore, this research is\nmotivated to measure how close the pre-trained language model can generate a\nnewly granted patent claim. Or, conversely, the task is to measure the\nprobabilities for the model to generate each token text given the newly granted\npatent claim. In addition, this manuscript raises several legal implications on\npatent law for potential interdisciplinary research in the future. In\nparticular, can the metric based on model prediction be a metric to measure the\nnonobviousness requirement in the patent law?",
    "descriptor": "\nComments: 12 pages, 7 figures\n",
    "authors": [
      "Jieh-Sheng Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14578"
  },
  {
    "id": "arXiv:2206.14579",
    "title": "Competence-based Multimodal Curriculum Learning for Medical Report  Generation",
    "abstract": "Medical report generation task, which targets to produce long and coherent\ndescriptions of medical images, has attracted growing research interests\nrecently. Different from the general image captioning tasks, medical report\ngeneration is more challenging for data-driven neural models. This is mainly\ndue to 1) the serious data bias and 2) the limited medical data. To alleviate\nthe data bias and make best use of available data, we propose a\nCompetence-based Multimodal Curriculum Learning framework (CMCL). Specifically,\nCMCL simulates the learning process of radiologists and optimizes the model in\na step by step manner. Firstly, CMCL estimates the difficulty of each training\ninstance and evaluates the competence of current model; Secondly, CMCL selects\nthe most suitable batch of training instances considering current model\ncompetence. By iterating above two steps, CMCL can gradually improve the\nmodel's performance. The experiments on the public IU-Xray and MIMIC-CXR\ndatasets show that CMCL can be incorporated into existing models to improve\ntheir performance.",
    "descriptor": "\nComments: Accepted by ACL 2021 (Oral)\n",
    "authors": [
      "Fenglin Liu",
      "Shen Ge",
      "Xian Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14579"
  },
  {
    "id": "arXiv:2206.14580",
    "title": "Language-specific Characteristic Assistance for Code-switching Speech  Recognition",
    "abstract": "Dual-encoder structure successfully utilizes two language-specific encoders\n(LSEs) for code-switching speech recognition. Because LSEs are initialized by\ntwo pre-trained language-specific models (LSMs), the dual-encoder structure can\nexploit sufficient monolingual data and capture the individual language\nattributes. However, existing methods have no language constraints on LSEs and\nunderutilize language-specific knowledge of LSMs. In this paper, we propose a\nlanguage-specific characteristic assistance (LSCA) method to mitigate the above\nproblems. Specifically, during training, we introduce two language-specific\nlosses as language constraints and generate corresponding language-specific\ntargets for them. During decoding, we take the decoding abilities of LSMs into\naccount by combining the output probabilities of two LSMs and the mixture model\nto obtain the final predictions. Experiments show that either the training or\ndecoding method of LSCA can improve the model's performance. Furthermore, the\nbest result can obtain up to 15.4% relative error reduction on the\ncode-switching test set by combining the training and decoding methods of LSCA.\nMoreover, the system can process code-switching speech recognition tasks well\nwithout extra shared parameters or even retraining based on two pre-trained\nLSMs by using our method.",
    "descriptor": "\nComments: Accepted by Interspeech 2022\n",
    "authors": [
      "Tongtong Song",
      "Qiang Xu",
      "Meng Ge",
      "Longbiao Wang",
      "Hao Shi",
      "Yongjie Lv",
      "Yuqin Lin",
      "Jianwu Dang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.14580"
  },
  {
    "id": "arXiv:2206.14581",
    "title": "On-device Synaptic Memory Consolidation using Fowler-Nordheim  Quantum-tunneling",
    "abstract": "Synaptic memory consolidation has been heralded as one of the key mechanisms\nfor supporting continual learning in neuromorphic Artificial Intelligence (AI)\nsystems. Here we report that a Fowler-Nordheim (FN) quantum-tunneling device\ncan implement synaptic memory consolidation similar to what can be achieved by\nalgorithmic consolidation models like the cascade and the elastic weight\nconsolidation (EWC) models. The proposed FN-synapse not only stores the\nsynaptic weight but also stores the synapse's historical usage statistic on the\ndevice itself. We also show that the operation of the FN-synapse is\nnear-optimal in terms of the synaptic lifetime and we demonstrate that a\nnetwork comprising FN-synapses outperforms a comparable EWC network for a small\nbenchmark continual learning task. With an energy footprint of femtojoules per\nsynaptic update, we believe that the proposed FN-synapse provides an\nultra-energy-efficient approach for implementing both synaptic memory\nconsolidation and persistent learning.",
    "descriptor": "",
    "authors": [
      "Mustafizur Rahman",
      "Subhankar Bose",
      "Shantanu Chakrabartty"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14581"
  },
  {
    "id": "arXiv:2206.14583",
    "title": "Benchmarking Bayesian Improved Surname Geocoding Against Machine  Learning Methods",
    "abstract": "Bayesian Improved Surname Geocoding (BISG) is the most popular method for\nproxying race/ethnicity in voter registration files that do not contain it.\nThis paper benchmarks BISG against a range of previously untested machine\nlearning alternatives, using voter files with self-reported race/ethnicity from\nCalifornia, Florida, North Carolina, and Georgia. This analysis yields three\nkey findings. First, when given the exact same inputs, BISG and machine\nlearning perform similarly for estimating aggregate racial/ethnic composition.\nSecond, machine learning outperforms BISG at individual classification of\nrace/ethnicity. Third, the performance of all methods varies substantially\nacross states. These results suggest that pre-trained machine learning models\nare preferable to BISG for individual classification. Furthermore, mixed\nresults at the precinct level and across states underscore the need for\nresearchers to empirically validate their chosen race/ethnicity proxy in their\npopulations of interest.",
    "descriptor": "",
    "authors": [
      "Ari Decter-Frain"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14583"
  },
  {
    "id": "arXiv:2206.14589",
    "title": "Finstreder: Simple and fast Spoken Language Understanding with Finite  State Transducers using modern Speech-to-Text models",
    "abstract": "In Spoken Language Understanding (SLU) the task is to extract important\ninformation from audio commands, like the intent of what a user wants the\nsystem to do and special entities like locations or numbers. This paper\npresents a simple method for embedding intents and entities into Finite State\nTransducers, and, in combination with a pretrained general-purpose\nSpeech-to-Text model, allows building SLU-models without any additional\ntraining. Building those models is very fast and only takes a few seconds. It\nis also completely language independent. With a comparison on different\nbenchmarks it is shown that this method can outperform multiple other, more\nresource demanding SLU approaches.",
    "descriptor": "",
    "authors": [
      "Daniel Bermuth",
      "Alexander Poeppel",
      "Wolfgang Reif"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.14589"
  },
  {
    "id": "arXiv:2206.14590",
    "title": "Monitoring Timed Properties (Revisited)",
    "abstract": "In this paper we revisit monitoring real-time systems with respect to\nproperties expressed either in the Metric Interval Temporal Logic or as Timed\nB\\\"uchi Automata. We offer efficient symbolic online monitoring algorithms in a\nnumber of settings, exploiting so-called zones well-known from efficient model\nchecking of Timed Automata. The settings considered include new, much\nsimplified treatment of time divergence, monitoring under timing uncertainty,\nand, extension of monitoring to offer minimum time estimates before conclusive\nverdicts can be made.",
    "descriptor": "",
    "authors": [
      "Thomas M\u00f8ller Grosen",
      "Sean Kauffman",
      "Kim Guldstrand Larsen",
      "Martin Zimmermann"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.14590"
  },
  {
    "id": "arXiv:2206.14597",
    "title": "Generative Anomaly Detection for Time Series Datasets",
    "abstract": "Traffic congestion anomaly detection is of paramount importance in\nintelligent traffic systems. The goals of transportation agencies are two-fold:\nto monitor the general traffic conditions in the area of interest and to locate\nroad segments under abnormal congestion states. Modeling congestion patterns\ncan achieve these goals for citywide roadways, which amounts to learning the\ndistribution of multivariate time series (MTS). However, existing works are\neither not scalable or unable to capture the spatial-temporal information in\nMTS simultaneously. To this end, we propose a principled and comprehensive\nframework consisting of a data-driven generative approach that can perform\ntractable density estimation for detecting traffic anomalies. Our approach\nfirst clusters segments in the feature space and then uses conditional\nnormalizing flow to identify anomalous temporal snapshots at the cluster level\nin an unsupervised setting. Then, we identify anomalies at the segment level by\nusing a kernel density estimator on the anomalous cluster. Extensive\nexperiments on synthetic datasets show that our approach significantly\noutperforms several state-of-the-art congestion anomaly detection and diagnosis\nmethods in terms of Recall and F1-Score. We also use the generative model to\nsample labeled data, which can train classifiers in a supervised setting,\nalleviating the lack of labeled data for anomaly detection in sparse settings.",
    "descriptor": "\nComments: A shorter version of the paper was accepted at the ITSC 2022\n",
    "authors": [
      "Zhuangwei Kang",
      "Ayan Mukhopadhyay",
      "Aniruddha Gokhale",
      "Shijie Wen",
      "Abhishek Dubey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.14597"
  },
  {
    "id": "arXiv:2206.14602",
    "title": "Coo: Consistency Check for Transactional Databases",
    "abstract": "In modern databases, transaction processing technology provides ACID\n(Atomicity, Consistency, Isolation, Durability) features. Consistency refers to\nthe correctness of databases and is a crucial property for many applications,\nsuch as financial and banking services. However, there exist typical challenges\nfor consistency. Theoretically, the current two definitions of consistency\nexpress quite different meanings, which are causal and sometimes controversial.\nPractically, it is notorious to check the consistency of databases, especially\nin terms of the verification cost. This paper proposes Coo, a framework to\ncheck the consistency of databases. Specifically, Coo has the following\nadvancements. First, Coo proposes partial order pair (POP) graph, which has a\nbetter expressiveness on transaction conflicts in a schedule by considering\nstateful information like Commit and Abort. By POP graph with no cycle, Coo\ndefines consistency completely. Secondly, Coo can construct inconsistent test\ncases based on POP cycles. These test cases can be used to check the\nconsistency of databases in accurate (all types of anomalies), user-friendly\n(SQL-based test), and cost-effective (one-time checking in a few minutes) ways.\nWe evaluate Coo with eleven databases, both centralized and distributed, under\nall supported isolation levels. The evaluation shows that databases did not\ncompletely follow the ANSI SQL standard (e.g., Oracle claimed to be\nserializable but appeared in some inconsistent cases), and have different\nimplementation methods and behaviors for concurrent controls (e.g., PostgreSQL,\nMySQL, and SQL Server performed quite differently at Repeatable Read level).\nCoo aids to comprehend the gap between coarse levels, finding more detailed and\ncomplete inconsistent behaviors.",
    "descriptor": "",
    "authors": [
      "Haixiang Li",
      "Yuxing Chen",
      "Xiaoyan Li"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2206.14602"
  },
  {
    "id": "arXiv:2206.14604",
    "title": "Mining Seasonal Temporal Patterns in Big Time Series",
    "abstract": "Very large time series are increasingly available from an ever wider range of\nIoT-enabled sensors, from which significant insights can be obtained through\nmining temporal patterns from them. A useful type of patterns found in many\nreal-world applications exhibits periodic occurrences, and is thus called\nseasonal temporal pattern (STP). Compared to regular patterns, mining seasonal\ntemporal patterns is more challenging since traditional measures such as\nsupport and confidence do not capture the seasonality characteristics. Further,\nthe anti-monotonicity property does not hold for STPs, and thus, resulting in\nan exponential search space. This paper presents our Frequent Seasonal Temporal\nPattern Mining from Time Series (FreqSTPfTS) solution providing: (1) The first\nsolution for seasonal temporal pattern mining (STPM) from time series that can\nmine STP at different data granularities. (2) The STPM algorithm that uses\nefficient data structures and two pruning techniques to reduce the search space\nand speed up the mining process. (3) An approximate version of STPM that uses\nmutual information, a measure of data correlation, to prune unpromising time\nseries from the search space. (4) An extensive experimental evaluation showing\nthat STPM outperforms the baseline in runtime and memory consumption, and can\nscale to big datasets. The approximate STPM is up to an order of magnitude\nfaster and less memory consuming than the baseline, while maintaining high\naccuracy.",
    "descriptor": "",
    "authors": [
      "Van Long Ho",
      "Nguyen Ho",
      "Torben Bach Pedersen"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2206.14604"
  },
  {
    "id": "arXiv:2206.14606",
    "title": "Building a Secure Software Supply Chain with GNU Guix",
    "abstract": "The software supply chain is becoming a widespread analogy to designate the\nseries of steps taken to go from source code published by developers to\nexecutables running on the users? computers. A security vulnerability in any of\nthese steps puts users at risk, and evidence shows that attacks on the supply\nchain are becoming more common. The consequences of an attack on the software\nsupply chain can be tragic in a society that relies on many interconnected\nsoftware systems, and this has led research interest as well as governmental\nincentives for supply chain security to rise.\nGNU Guix is a software deployment tool and software distribution that\nsupports provenance tracking, reproducible builds, and reproducible software\nenvironments. Unlike many software distributions, it consists exclusively of\nsource code: it provides a set of package definitions that describe how to\nbuild code from source. Together, these properties set it apart from many\ndeployment tools that center on the distribution of binaries.\nThis paper focuses on one research question: how can Guix and similar systems\nallow users to securely update their software? Guix source code is distributed\nusing the Git version control system; updating Guix-installed software packages\nmeans, first, updating the local copy of the Guix source code. Prior work on\nsecure software updates focuses on systems very different from Guix -- systems\nsuch as Debian, Fedora, or PyPI where updating consists in fetching metadata\nabout the latest binary artifacts available -- and is largely inapplicable in\nthe context of Guix. By contrast, the main threats for Guix are attacks on its\nsource code repository, which could lead users to run inauthentic code or to\ndowngrade their system. Deployment tools that more closely resemble Guix, from\nNix to Portage, either lack secure update mechanisms or suffer from\nshortcomings.\nOur main contribution is a model and tool to authenticate new Git revisions.\nWe further show how, building on Git semantics, we build protections against\ndowngrade attacks and related threats. We explain implementation choices. This\nwork has been deployed in production two years ago, giving us insight on its\nactual use at scale every day. The Git checkout authentication at its core is\napplicable beyond the specific use case of Guix, and we think it could benefit\nto developer teams that use Git.\nAs attacks on the software supply chain appear, security research is now\nlooking at every link of the supply chain. Secure updates are one important\naspect of the supply chain, but this paper also looks at the broader context:\nhow Guix models and implements the supply chain, from upstream source code to\nbinaries running on computers. While much recent work focuses on attestation --\ncertifying each link of the supply chain -- Guix takes a more radical approach:\nenabling independent verification of each step, building on reproducible\nbuilds, \"bootstrappable\" builds, and provenance tracking. The big picture shows\nhow Guix can be used as the foundation of secure software supply chains.",
    "descriptor": "",
    "authors": [
      "Ludovic Court\u00e8s"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2206.14606"
  },
  {
    "id": "arXiv:2206.14607",
    "title": "NERDA-Con: Extending NER models for Continual Learning -- Integrating  Distinct Tasks and Updating Distribution Shifts",
    "abstract": "With increasing applications in areas such as biomedical information\nextraction pipelines and social media analytics, Named Entity Recognition (NER)\nhas become an indispensable tool for knowledge extraction. However, with the\ngradual shift in language structure and vocabulary, NERs are plagued with\ndistribution shifts, making them redundant or not as profitable without\nre-training. Re-training NERs based on Large Language Models (LLMs) from\nscratch over newly acquired data poses economic disadvantages. In contrast,\nre-training only with newly acquired data will result in Catastrophic\nForgetting of previously acquired knowledge. Therefore, we propose NERDA-Con, a\npipeline for training NERs with LLM bases by incorporating the concept of\nElastic Weight Consolidation (EWC) into the NER fine-tuning NERDA pipeline. As\nwe believe our work has implications to be utilized in the pipeline of\ncontinual learning and NER, we open-source our code as well as provide the\nfine-tuning library of the same name NERDA-Con at\nhttps://github.com/SupritiVijay/NERDA-Con and\nhttps://pypi.org/project/NERDA-Con/.",
    "descriptor": "\nComments: 6 pages, 4 figures, Accepted at Workshop on Updatable Machine Learning(UpML), International Conference on Machine Learning (ICML'22)\n",
    "authors": [
      "Supriti Vijay",
      "Aman Priyanshu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.14607"
  },
  {
    "id": "arXiv:2206.14608",
    "title": "Traffic Management of Autonomous Vehicles using Policy Based Deep  Reinforcement Learning and Intelligent Routing",
    "abstract": "Deep Reinforcement Learning (DRL) uses diverse, unstructured data and makes\nRL capable of learning complex policies in high dimensional environments.\nIntelligent Transportation System (ITS) based on Autonomous Vehicles (AVs)\noffers an excellent playground for policy-based DRL. Deep learning\narchitectures solve computational challenges of traditional algorithms while\nhelping in real-world adoption and deployment of AVs. One of the main\nchallenges in AVs implementation is that it can worsen traffic congestion on\nroads if not reliably and efficiently managed. Considering each vehicle's\nholistic effect and using efficient and reliable techniques could genuinely\nhelp optimise traffic flow management and congestion reduction. For this\npurpose, we proposed a intelligent traffic control system that deals with\ncomplex traffic congestion scenarios at intersections and behind the\nintersections. We proposed a DRL-based signal control system that dynamically\nadjusts traffic signals according to the current congestion situation on\nintersections. To deal with the congestion on roads behind the intersection, we\nused re-routing technique to load balance the vehicles on road networks. To\nachieve the actual benefits of the proposed approach, we break down the data\nsilos and use all the data coming from sensors, detectors, vehicles and roads\nin combination to achieve sustainable results. We used SUMO micro-simulator for\nour simulations. The significance of our proposed approach is manifested from\nthe results.",
    "descriptor": "",
    "authors": [
      "Anum Mushtaq",
      "Irfan ul Haq",
      "Muhammad Azeem Sarwar",
      "Asifullah Khan",
      "Omair Shafiq"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.14608"
  },
  {
    "id": "arXiv:2206.14610",
    "title": "Analysis of Mixed Finite Elements for Elasticity. II. Weak stress  symmetry",
    "abstract": "We consider mixed finite element methods for linear elasticity where the\nsymmetry of the stress tensor is weakly enforced. Both an a priori and a\nposteriori error analysis are given for several known families of methods that\nare uniformly valid in the incompressible limit. Based on the Prager-Singe\nhypercircle principle, an a posteriori estimate with explicitly known constants\nis derived. The results are verified by numerical examples.",
    "descriptor": "",
    "authors": [
      "Philip L. Lederer",
      "Rolf Stenberg"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.14610"
  },
  {
    "id": "arXiv:2206.14613",
    "title": "The differential spectrum and boomerang spectrum of a class of  locally-APN functions",
    "abstract": "In this paper, we study the boomerang spectrum of the power mapping\n$F(x)=x^{k(q-1)}$ over ${\\mathbb F}_{q^2}$, where $q=p^m$, $p$ is a prime, $m$\nis a positive integer and $\\gcd(k,q+1)=1$. We first determine the differential\nspectrum of $F(x)$ and show that $F(x)$ is locally-APN. This extends a result\nof [IEEE Trans. Inf. Theory 57(12):8127-8137, 2011] from $(p,k)=(2,1)$ to\ngeneral $(p,k)$. We then determine the boomerang spectrum of $F(x)$ by making\nuse of its differential spectrum, which shows that the boomerang uniformity of\n$F(x)$ is 4 if $p=2$ and $m$ is odd and otherwise it is 2. Our results not only\ngeneralize the results in [Des. Codes Cryptogr. 89:2627-2636, 2021] and\n[arXiv:2203.00485, 2022] but also extend the example $x^{45}$ over ${\\mathbb\nF}_{2^8}$ in [Des. Codes Cryptogr. 89:2627-2636, 2021] into an infinite class\nof power mappings with boomerang uniformity 2.",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Zhao Hu",
      "Nian Li",
      "Linjie Xu",
      "Xiangyong Zeng",
      "Xiaohu Tang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.14613"
  },
  {
    "id": "arXiv:2206.14614",
    "title": "AGENT: An Adaptive Grouping Entrapping Method of Flocking Systems",
    "abstract": "This study proposes a distributed algorithm that makes agents' adaptive\ngrouping entrap multiple targets via automatic decision making, smooth\nflocking, and well-distributed entrapping. Agents make their own decisions\nabout which targets to surround based on environmental information. An improved\nartificial potential field method is proposed to enable agents to smoothly and\nnaturally change the formation to adapt to the environment. The proposed\nstrategies guarantee that the coordination of swarm agents develops the\nphenomenon of multiple targets entrapping at the swarm level. We validate the\nperformance of the proposed method using simulation experiments and design\nindicators for the analysis of these simulation and physical experiments.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Chen Wang",
      "Minqiang Gu",
      "Wenxi Kuang",
      "Dongliang Wang",
      "Weicheng Luo",
      "Zhaohui Shi",
      "Zhun Fan"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.14614"
  },
  {
    "id": "arXiv:2206.14615",
    "title": "Quantification of Deep Neural Network Prediction Uncertainties for VVUQ  of Machine Learning Models",
    "abstract": "Recent performance breakthroughs in Artificial intelligence (AI) and Machine\nlearning (ML), especially advances in Deep learning (DL), the availability of\npowerful, easy-to-use ML libraries (e.g., scikit-learn, TensorFlow, PyTorch.),\nand increasing computational power have led to unprecedented interest in AI/ML\namong nuclear engineers. For physics-based computational models, Verification,\nValidation and Uncertainty Quantification (VVUQ) have been very widely\ninvestigated and a lot of methodologies have been developed. However, VVUQ of\nML models has been relatively less studied, especially in nuclear engineering.\nIn this work, we focus on UQ of ML models as a preliminary step of ML VVUQ,\nmore specifically, Deep Neural Networks (DNNs) because they are the most widely\nused supervised ML algorithm for both regression and classification tasks. This\nwork aims at quantifying the prediction, or approximation uncertainties of DNNs\nwhen they are used as surrogate models for expensive physical models. Three\ntechniques for UQ of DNNs are compared, namely Monte Carlo Dropout (MCD), Deep\nEnsembles (DE) and Bayesian Neural Networks (BNNs). Two nuclear engineering\nexamples are used to benchmark these methods, (1) time-dependent fission gas\nrelease data using the Bison code, and (2) void fraction simulation based on\nthe BFBT benchmark using the TRACE code. It was found that the three methods\ntypically require different DNN architectures and hyperparameters to optimize\ntheir performance. The UQ results also depend on the amount of training data\navailable and the nature of the data. Overall, all these three methods can\nprovide reasonable estimations of the approximation uncertainties. The\nuncertainties are generally smaller when the mean predictions are close to the\ntest data, while the BNN methods usually produce larger uncertainties than MCD\nand DE.",
    "descriptor": "\nComments: 33 pages, 4 tables, 13 figures\n",
    "authors": [
      "Mahmoud Yaseen",
      "Xu Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14615"
  },
  {
    "id": "arXiv:2206.14617",
    "title": "Perspective (In)consistency of Paint by Text",
    "abstract": "Type \"a sea otter with a pearl earring by Johannes Vermeer\" or \"a photo of a\nteddy bear on a skateboard in Times Square\" into OpenAI's DALL-E-2\npaint-by-text synthesis engine and you will not be disappointed by the\ndelightful and eerily pertinent results. The ability to synthesize highly\nrealistic images -- with seemingly no limitation other than our imagination --\nis sure to yield many exciting and creative applications. These images are also\nlikely to pose new challenges to the photo-forensic community. Motivated by the\nfact that paint by text is not based on explicit geometric modeling, and the\nhuman visual system's often obliviousness to even glaring geometric\ninconsistencies, we provide an initial exploration of the perspective\nconsistency of DALL-E-2 synthesized images to determine if geometric-based\nforensic analyses will prove fruitful in detecting this new breed of synthetic\nmedia.",
    "descriptor": "",
    "authors": [
      "Hany Farid"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.14617"
  },
  {
    "id": "arXiv:2206.14619",
    "title": "A Multilingual Dataset of COVID-19 Vaccination Attitudes on Twitter",
    "abstract": "Vaccine hesitancy is considered as one main cause of the stagnant uptake\nratio of COVID-19 vaccines in Europe and the US where vaccines are sufficiently\nsupplied. Fast and accurate grasp of public attitudes toward vaccination is\ncritical to address vaccine hesitancy, and social media platforms have proved\nto be an effective source of public opinions. In this paper, we describe the\ncollection and release of a dataset of tweets related to COVID-19 vaccines.\nThis dataset consists of the IDs of 2,198,090 tweets collected from Western\nEurope, 17,934 of which are annotated with the originators' vaccination\nstances. Our annotation will facilitate using and developing data-driven models\nto extract vaccination attitudes from social media posts and thus further\nconfirm the power of social media in public health surveillance. To lay the\ngroundwork for future research, we not only perform statistical analysis and\nvisualisation of our dataset, but also evaluate and compare the performance of\nestablished text-based benchmarks in vaccination stance extraction. We\ndemonstrate one potential use of our data in practice in tracking the temporal\nchanges of public COVID-19 vaccination attitudes.",
    "descriptor": "",
    "authors": [
      "Ninghan Chen",
      "Xihui Chen",
      "Jun Pang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.14619"
  },
  {
    "id": "arXiv:2206.14621",
    "title": "Extracting Weighted Finite Automata from Recurrent Neural Networks for  Natural Languages",
    "abstract": "Recurrent Neural Networks (RNNs) have achieved tremendous success in\nsequential data processing. However, it is quite challenging to interpret and\nverify RNNs' behaviors directly. To this end, many efforts have been made to\nextract finite automata from RNNs. Existing approaches such as exact learning\nare effective in extracting finite-state models to characterize the state\ndynamics of RNNs for formal languages, but are limited in the scalability to\nprocess natural languages. Compositional approaches that are scablable to\nnatural languages fall short in extraction precision. In this paper, we\nidentify the transition sparsity problem that heavily impacts the extraction\nprecision. To address this problem, we propose a transition rule extraction\napproach, which is scalable to natural language processing models and effective\nin improving extraction precision. Specifically, we propose an empirical method\nto complement the missing rules in the transition diagram. In addition, we\nfurther adjust the transition matrices to enhance the context-aware ability of\nthe extracted weighted finite automaton (WFA). Finally, we propose two data\naugmentation tactics to track more dynamic behaviors of the target RNN.\nExperiments on two popular natural language datasets show that our method can\nextract WFA from RNN for natural language processing with better precision than\nexisting approaches.",
    "descriptor": "\nComments: Accepted by ICFEM 2022\n",
    "authors": [
      "Zeming Wei",
      "Xiyue Zhang",
      "Meng Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14621"
  },
  {
    "id": "arXiv:2206.14625",
    "title": "From Kernel Methods to Neural Networks: A Unifying Variational  Formulation",
    "abstract": "The minimization of a data-fidelity term and an additive regularization\nfunctional gives rise to a powerful framework for supervised learning. In this\npaper, we present a unifying regularization functional that depends on an\noperator and on a generic Radon-domain norm. We establish the existence of a\nminimizer and give the parametric form of the solution(s) under very mild\nassumptions. When the norm is Hilbertian, the proposed formulation yields a\nsolution that involves radial-basis functions and is compatible with the\nclassical methods of machine learning. By contrast, for the total-variation\nnorm, the solution takes the form of a two-layer neural network with an\nactivation function that is determined by the regularization operator. In\nparticular, we retrieve the popular ReLU networks by letting the operator be\nthe Laplacian. We also characterize the solution for the intermediate\nregularization norms $\\|\\cdot\\|=\\|\\cdot\\|_{L_p}$ with $p\\in(1,2]$. Our\nframework offers guarantees of universal approximation for a broad family of\nregularization operators or, equivalently, for a wide variety of shallow neural\nnetworks, including the cases (such as ReLU) where the activation function is\nincreasing polynomially. It also explains the favorable role of bias and skip\nconnections in neural architectures.",
    "descriptor": "",
    "authors": [
      "Michael Unser"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Functional Analysis (math.FA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.14625"
  },
  {
    "id": "arXiv:2206.14635",
    "title": "Prespecified-time observer-based distributed control of battery energy  storage systems",
    "abstract": "This paper studies the state-of-charge (SoC) balancing and the total\ncharging/discharging power tracking issues for battery energy storage systems\n(BESSs) with multiple distributed heterogeneous battery units. Different from\nthe traditional cooperative control strategies based on the asymptotical or\nfinite-time distributed observers, two distributed prespecified-time observers\nare proposed to estimate average battery units state and average desired power,\nrespectively, which can be determined in advance and independent of initial\nstates or control parameters. Finally, two simulation examples are given to\nverify the effectiveness and superiority of the proposed control strategy.",
    "descriptor": "",
    "authors": [
      "Wu Yang",
      "Shu-Ming Liang",
      "Yan-Wu Wang",
      "Zhi-Wei Liu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.14635"
  },
  {
    "id": "arXiv:2206.14637",
    "title": "Assessing Intel's Memory Bandwidth Allocation for resource limitation in  real-time systems",
    "abstract": "Industries are recently considering the adoption of cloud computing for\nhosting safety critical applications. However, the use of multicore processors\nusually adopted in the cloud introduces temporal anomalies due to contention\nfor shared resources, such as the memory subsystem. In this paper we explore\nthe potential of Intel's Memory Bandwidth Allocation (MBA) technology,\navailable on Xeon Scalable processors. By adopting a systematic measurement\napproach on real hardware, we assess the indirect memory bandwidth limitation\nachievable by applying MBA delays, showing that only given delay values (namely\n70, 80 and 90) are effective in our setting. We also test the derived bandwidth\nassured to a hypothetical critical core when interfering cores (e.g.,\ngenerating a concurrent memory access workload) are present on the same\nmachine. Our results can support designers by providing understanding of impact\nof the shared memory to enable predictable progress of safety critical\napplications in cloud environments.",
    "descriptor": "\nComments: 8 pages, to appear in proceedings of \"The 25th International Symposium On Real-Time Distributed Computing ISORC\"\n",
    "authors": [
      "Giorgio Farina",
      "Gautam Gala",
      "Marcello Cinque",
      "Gerhard Fohler"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2206.14637"
  },
  {
    "id": "arXiv:2206.14641",
    "title": "Implicit and fully discrete approximation of the supercooled Stefan  problem in the presence of blow-ups",
    "abstract": "We consider two implicit approximation schemes of the one-dimensional\nsupercooled Stefan problem and prove their convergence, even in the presence of\nfinite time blow-ups. All proofs are based on a probabilistic reformulation\nrecently considered in the literature. The first scheme is a version of the\ntime-stepping scheme studied in V. Kaushansky, C. Reisinger, M. Shkolnikov, and\nZ. Q. Song, arXiv:2010.05281, 2020, but here the flux over the free boundary\nand its velocity are coupled implicitly. Moreover, we extend the analysis to\nmore general driving processes than Brownian motion. The second scheme is a\nDonsker-type approximation, also interpretable as an implicit finite difference\nscheme, for which global convergence is shown under minor technical conditions.\nWith stronger assumptions, which apply in cases without blow-ups, we obtain\nadditionally a convergence rate arbitrarily close to 1/2. Our numerical results\nsuggest that this rate also holds for less regular solutions, in contrast to\nexplicit schemes, and allow a sharper resolution of the discontinuous free\nboundary in the blow-up regime.",
    "descriptor": "",
    "authors": [
      "Christa Cuchiero",
      "Christoph Reisinger",
      "Stefan Rigger"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2206.14641"
  },
  {
    "id": "arXiv:2206.14647",
    "title": "Meta-Wrapper: Differentiable Wrapping Operator for User Interest  Selection in CTR Prediction",
    "abstract": "Click-through rate (CTR) prediction, whose goal is to predict the probability\nof the user to click on an item, has become increasingly significant in the\nrecommender systems. Recently, some deep learning models with the ability to\nautomatically extract the user interest from his/her behaviors have achieved\ngreat success. In these work, the attention mechanism is used to select the\nuser interested items in historical behaviors, improving the performance of the\nCTR predictor. Normally, these attentive modules can be jointly trained with\nthe base predictor by using gradient descents. In this paper, we regard user\ninterest modeling as a feature selection problem, which we call user interest\nselection. For such a problem, we propose a novel approach under the framework\nof the wrapper method, which is named Meta-Wrapper. More specifically, we use a\ndifferentiable module as our wrapping operator and then recast its learning\nproblem as a continuous bilevel optimization. Moreover, we use a meta-learning\nalgorithm to solve the optimization and theoretically prove its convergence.\nMeanwhile, we also provide theoretical analysis to show that our proposed\nmethod 1) efficiencies the wrapper-based feature selection, and 2) achieves\nbetter resistance to overfitting. Finally, extensive experiments on three\npublic datasets manifest the superiority of our method in boosting the\nperformance of CTR prediction.",
    "descriptor": "",
    "authors": [
      "Tianwei Cao",
      "Qianqian Xu",
      "Zhiyong Yang",
      "Qingming Huang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.14647"
  },
  {
    "id": "arXiv:2206.14648",
    "title": "Two-Stage Neural Contextual Bandits for Personalised News Recommendation",
    "abstract": "We consider the problem of personalised news recommendation where each user\nconsumes news in a sequential fashion. Existing personalised news\nrecommendation methods focus on exploiting user interests and ignores\nexploration in recommendation, which leads to biased feedback loops and hurt\nrecommendation quality in the long term. We build on contextual bandits\nrecommendation strategies which naturally address the exploitation-exploration\ntrade-off. The main challenges are the computational efficiency for exploring\nthe large-scale item space and utilising the deep representations with\nuncertainty. We propose a two-stage hierarchical topic-news deep contextual\nbandits framework to efficiently learn user preferences when there are many\nnews items. We use deep learning representations for users and news, and\ngeneralise the neural upper confidence bound (UCB) policies to generalised\nadditive UCB and bilinear UCB. Empirical results on a large-scale news\nrecommendation dataset show that our proposed policies are efficient and\noutperform the baseline bandit policies.",
    "descriptor": "",
    "authors": [
      "Mengyan Zhang",
      "Thanh Nguyen-Tang",
      "Fangzhao Wu",
      "Zhenyu He",
      "Xing Xie",
      "Cheng Soon Ong"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14648"
  },
  {
    "id": "arXiv:2206.14649",
    "title": "Cooperative Retriever and Ranker in Deep Recommenders",
    "abstract": "Deep recommender systems jointly leverage the retrieval and ranking\noperations to generate the recommendation result. The retriever targets\nselecting a small set of relevant candidates from the entire items with high\nefficiency; while the ranker, usually more precise but time-consuming, is\nsupposed to identify the best items out of the retrieved candidates with high\nprecision. However, the retriever and ranker are usually trained in\npoorly-cooperative ways, leading to limited recommendation performances when\nworking as an entirety. In this work, we propose a novel DRS training framework\nCoRR(short for Cooperative Retriever and Ranker), where the retriever and\nranker can be mutually reinforced. On one hand, the retriever is learned from\nrecommendation data and the ranker via knowledge distillation; knowing that the\nranker is more precise, the knowledge distillation may provide extra\nweak-supervision signals for the improvement of retrieval quality. On the other\nhand, the ranker is trained by learning to discriminate the truth positive\nitems from hard negative candidates sampled from the retriever. With the\niteration going on, the ranker may become more precise, which in return gives\nrise to informative training signals for the retriever; meanwhile, with the\nimprovement of retriever, harder negative candidates can be sampled, which\ncontributes to a higher discriminative capability of the ranker. To facilitate\nthe effective conduct of CoRR, an asymptotic-unbiased approximation of KL\ndivergence is introduced for the knowledge distillation over sampled items;\nbesides, a scalable and adaptive strategy is developed to efficiently sample\nfrom the retriever. Comprehensive experimental studies are performed over four\nlarge-scale benchmark datasets, where CoRR improves the overall recommendation\nquality resulting from the cooperation between retriever and ranker.",
    "descriptor": "",
    "authors": [
      "Xu Huang",
      "Defu Lian",
      "Jin Chen",
      "Zheng Liu",
      "Xing Xie",
      "Enhong Chen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14649"
  },
  {
    "id": "arXiv:2206.14651",
    "title": "BoT-SORT: Robust Associations Multi-Pedestrian Tracking",
    "abstract": "The goal of multi-object tracking (MOT) is detecting and tracking all the\nobjects in a scene, while keeping a unique identifier for each object. In this\npaper, we present a new robust state-of-the-art tracker, which can combine the\nadvantages of motion and appearance information, along with camera-motion\ncompensation, and a more accurate Kalman filter state vector. Our new trackers\nBoT-SORT, and BoT-SORT-ReID rank first in the datasets of MOTChallenge [29, 11]\non both MOT17 and MOT20 test sets, in terms of all the main MOT metrics: MOTA,\nIDF1, and HOTA. For MOT17: 80.5 MOTA, 80.2 IDF1, and 65.0 HOTA are achieved.\nThe source code and the pre-trained models are available at\nhttps://github.com/NirAharon/BOT-SORT",
    "descriptor": "",
    "authors": [
      "Nir Aharon",
      "Roy Orfaig",
      "Ben-Zion Bobrovsky"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.14651"
  },
  {
    "id": "arXiv:2206.14658",
    "title": "Cut Inner Layers: A Structured Pruning Strategy for Efficient U-Net GANs",
    "abstract": "Pruning effectively compresses overparameterized models. Despite the success\nof pruning methods for discriminative models, applying them for generative\nmodels has been relatively rarely approached. This study conducts structured\npruning on U-Net generators of conditional GANs. A per-layer sensitivity\nanalysis confirms that many unnecessary filters exist in the innermost layers\nnear the bottleneck and can be substantially pruned. Based on this observation,\nwe prune these filters from multiple inner layers or suggest alternative\narchitectures by completely eliminating the layers. We evaluate our approach\nwith Pix2Pix for image-to-image translation and Wav2Lip for speech-driven\ntalking face generation. Our method outperforms global pruning baselines,\ndemonstrating the importance of properly considering where to prune for U-Net\ngenerators.",
    "descriptor": "\nComments: ICML Workshop on Hardware Aware Efficient Training, 2022\n",
    "authors": [
      "Bo-Kyeong Kim",
      "Shinkook Choi",
      "Hancheol Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.14658"
  },
  {
    "id": "arXiv:2206.14659",
    "title": "Language-Based Audio Retrieval with Converging Tied Layers and  Contrastive Loss",
    "abstract": "In this paper, we tackle the new Language-Based Audio Retrieval task proposed\nin DCASE 2022. Firstly, we introduce a simple, scalable architecture which ties\nboth the audio and text encoder together. Secondly, we show that using this\narchitecture along with contrastive loss allows the model to significantly beat\nthe performance of the baseline model. Finally, in addition to having an\nextremely low training memory requirement, we are able to use pretrained models\nas it is without needing to finetune them. We test our methods and show that\nusing a combination of our methods beats the baseline scores significantly.",
    "descriptor": "",
    "authors": [
      "Andrew Koh",
      "Eng Siong Chng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.14659"
  },
  {
    "id": "arXiv:2206.14660",
    "title": "The THUEE System Description for the IARPA OpenASR21 Challenge",
    "abstract": "This paper describes the THUEE team's speech recognition system for the IARPA\nOpen Automatic Speech Recognition Challenge (OpenASR21), with further\nexperiment explorations. We achieve outstanding results under both the\nConstrained and Constrained-plus training conditions. For the Constrained\ntraining condition, we construct our basic ASR system based on the standard\nhybrid architecture. To alleviate the Out-Of-Vocabulary (OOV) problem, we\nextend the pronunciation lexicon using Grapheme-to-Phoneme (G2P) techniques for\nboth OOV and potential new words. Standard acoustic model structures such as\nCNN-TDNN-F and CNN-TDNN-F-A are adopted. In addition, multiple data\naugmentation techniques are applied. For the Constrained-plus training\ncondition, we use the self-supervised learning framework wav2vec2.0. We\nexperiment with various fine-tuning techniques with the Connectionist Temporal\nClassification (CTC) criterion on top of the publicly available pre-trained\nmodel XLSR-53. We find that the frontend feature extractor plays an important\nrole when applying the wav2vec2.0 pre-trained model to the encoder-decoder\nbased CTC/Attention ASR architecture. Extra improvements can be achieved by\nusing the CTC model finetuned in the target language as the frontend feature\nextractor.",
    "descriptor": "\nComments: accepted by INTERSPEECH 2022\n",
    "authors": [
      "Jing Zhao",
      "Haoyu Wang",
      "Jinpeng Li",
      "Shuzhou Chai",
      "Guan-Bo Wang",
      "Guoguo Chen",
      "Wei-Qiang Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.14660"
  },
  {
    "id": "arXiv:2206.14661",
    "title": "Online vs. Offline Adaptive Domain Randomization Benchmark",
    "abstract": "Physics simulators have shown great promise for conveniently learning\nreinforcement learning policies in safe, unconstrained environments. However,\ntransferring the acquired knowledge to the real world can be challenging due to\nthe reality gap. To this end, several methods have been recently proposed to\nautomatically tune simulator parameters with posterior distributions given real\ndata, for use with domain randomization at training time. These approaches have\nbeen shown to work for various robotic tasks under different settings and\nassumptions. Nevertheless, existing literature lacks a thorough comparison of\nexisting adaptive domain randomization methods with respect to transfer\nperformance and real-data efficiency. In this work, we present an open\nbenchmark for both offline and online methods (SimOpt, BayRn, DROID, DROPO), to\nshed light on which are most suitable for each setting and task at hand. We\nfound that online methods are limited by the quality of the currently learned\npolicy for the next iteration, while offline methods may sometimes fail when\nreplaying trajectories in simulation with open-loop commands. The code used\nwill be released at https://github.com/gabrieletiboni/adr-benchmark.",
    "descriptor": "\nComments: 15 pages, 6 figures\n",
    "authors": [
      "Gabriele Tiboni",
      "Karol Arndt",
      "Giuseppe Averta",
      "Ville Kyrki",
      "Tatiana Tommasi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14661"
  },
  {
    "id": "arXiv:2206.14666",
    "title": "Conditionally Elicitable Dynamic Risk Measures for Deep Reinforcement  Learning",
    "abstract": "We propose a novel framework to solve risk-sensitive reinforcement learning\n(RL) problems where the agent optimises time-consistent dynamic spectral risk\nmeasures. Based on the notion of conditional elicitability, our methodology\nconstructs (strictly consistent) scoring functions that are used as penalizers\nin the estimation procedure. Our contribution is threefold: we (i) devise an\nefficient approach to estimate a class of dynamic spectral risk measures with\ndeep neural networks, (ii) prove that these dynamic spectral risk measures may\nbe approximated to any arbitrary accuracy using deep neural networks, and (iii)\ndevelop a risk-sensitive actor-critic algorithm that uses full episodes and\ndoes not require any additional nested transitions. We compare our conceptually\nimproved reinforcement learning algorithm with the nested simulation approach\nand illustrate its performance in two settings: statistical arbitrage and\nportfolio allocation on both simulated and real data.",
    "descriptor": "\nComments: 35 pages, 7 figures\n",
    "authors": [
      "Anthony Coache",
      "Sebastian Jaimungal",
      "\u00c1lvaro Cartea"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Finance (q-fin.CP)",
      "Portfolio Management (q-fin.PM)",
      "Risk Management (q-fin.RM)",
      "Trading and Market Microstructure (q-fin.TR)"
    ],
    "url": "https://arxiv.org/abs/2206.14666"
  },
  {
    "id": "arXiv:2206.14669",
    "title": "Towards a Data-Driven Requirements Engineering Approach: Automatic  Analysis of User Reviews",
    "abstract": "We are concerned by Data Driven Requirements Engineering, and in particular\nthe consideration of user's reviews. These online reviews are a rich source of\ninformation for extracting new needs and improvement requests. In this work, we\nprovide an automated analysis using CamemBERT, which is a state-of-the-art\nlanguage model in French. We created a multi-label classification dataset of\n6000 user reviews from three applications in the Health & Fitness field. The\nresults are encouraging and suggest that it's possible to identify\nautomatically the reviews concerning requests for new features.\nDataset is available at:\nhttps://github.com/Jl-wei/APIA2022-French-user-reviews-classification-dataset.",
    "descriptor": "\nComments: 7th National Conference on Practical Applications of Artificial Intelligence, 2022. Saint-\\'Etienne, France. article in English and French, 4 pages each\n",
    "authors": [
      "Jialiang Wei",
      "Anne-Lise Courbis",
      "Thomas Lambolais",
      "Binbin Xu",
      "Pierre Louis Bernard",
      "G\u00e9rard Dray"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.14669"
  },
  {
    "id": "arXiv:2206.14672",
    "title": "Is it possible not to cheat on the Turing Test: Exploring the potential  and challenges for true natural language 'understanding' by computers",
    "abstract": "Recent hype surrounding the increasing sophistication of language processing\nmodels has renewed optimism regarding machines achieving a human-like command\nof natural language. The area of natural language understanding in artificial\nintelligence claims to have been making great strides in this area, however,\nthe lack of conceptual clarity in how 'understanding' is used in this and other\ndisciplines have made it difficult to discern how close we actually are. A\ncomprehensive, interdisciplinary overview of current approaches and remaining\nchallenges is yet to be carried out. Beyond linguistic knowledge, this requires\nconsidering our species-specific capabilities to categorize, memorize, label\nand communicate our (sufficiently similar) embodied and situated experiences.\nMoreover, gauging the practical constraints requires critically analyzing the\ntechnical capabilities of current models, as well as deeper philosophical\nreflection on theoretical possibilities and limitations. In this paper, I unite\nall of these perspectives -- the philosophical, cognitive-linguistic, and\ntechnical -- to unpack the challenges involved in reaching true (human-like)\nlanguage understanding. By unpacking the theoretical assumptions inherent in\ncurrent approaches, I hope to illustrate how far we actually are from achieving\nthis goal, if indeed it is the goal.",
    "descriptor": "\nComments: Shortened version of master's thesis, under review by Journal of Artificial Intelligence and Consciousness\n",
    "authors": [
      "Lize Alberts"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.14672"
  },
  {
    "id": "arXiv:2206.14683",
    "title": "Computer-aided diagnosis and prediction in brain disorders",
    "abstract": "Computer-aided methods have shown added value for diagnosing and predicting\nbrain disorders and can thus support decision making in clinical care and\ntreatment planning. This chapter will provide insight into the type of methods,\ntheir working, their input data - such as cognitive tests, imaging and genetic\ndata - and the types of output they provide. We will focus on specific use\ncases for diagnosis, i.e. estimating the current 'condition' of the patient,\nsuch as early detection and diagnosis of dementia, differential diagnosis of\nbrain tumours, and decision making in stroke. Regarding prediction, i.e.\nestimation of the future 'condition' of the patient, we will zoom in on use\ncases such as predicting the disease course in multiple sclerosis and\npredicting patient outcomes after treatment in brain cancer. Furthermore, based\non these use cases, we will assess the current state-of-the-art methodology and\nhighlight current efforts on benchmarking of these methods and the importance\nof open science therein. Finally, we assess the current clinical impact of\ncomputer-aided methods and discuss the required next steps to increase clinical\nimpact.",
    "descriptor": "",
    "authors": [
      "Vikram Venkatraghavan",
      "Sebastian R. van der Voort",
      "Daniel Bos",
      "Marion Smits",
      "Frederik Barkhof",
      "Wiro J. Niessen",
      "Stefan Klein",
      "Esther E. Bron"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2206.14683"
  },
  {
    "id": "arXiv:2206.14684",
    "title": "Smoothed Analysis of Social Choice Revisited",
    "abstract": "A canonical problem in voting theory is: which voting rule should we use to\naggregate voters' preferences into a collective decision over alternatives?\nWhen applying the axiomatic approach to evaluate and compare voting rules, we\nare faced with prohibitive impossibilities. However, these impossibilities\noccur under the assumption that voters' preferences (collectively called a\nprofile) will be worst-case with respect to the desired criterion. In this\npaper, we study the axiomatic approach slightly \\emph{beyond} the worst-case:\nwe present and apply a \"smoothed\" model of the voting setting, which assumes\nthat while inputs (profiles) may be worst-case, all inputs will be perturbed by\na small amount of noise. In defining and analyzing our noise model, we do not\naim to substantially technically innovate on Lirong Xia's recently-proposed\nsmoothed model of social choice; rather, we offer an alternative model and\napproach to analyzing it that aims to strike a different balance of simplicity\nand technical generality, and to correspond closely to Spielman and Teng's\n(2004) original work on smoothed analysis. Within our model, we then give\nsimple proofs of smoothed-satisfaction or smoothed-violation of several axioms\nand paradoxes, including most of those studied by Xia as well as some\npreviously unstudied. Novel results include smoothed analysis of Arrow's\ntheorem and analyses of the axioms Consistency and Independence of Irrelevant\nAlternatives. In independent work from a recent paper by Xia (2022), we also\nshow the smoothed-satisfaction of coalition-based notions of\nStrategy-Proofness, Monotonocity, and Participation. A final, central component\nof our contributions are the high-level insights and future directions we\nidentify based on this work, which we describe in detail to maximally\nfacilitate additional research in this area.",
    "descriptor": "",
    "authors": [
      "Bailey Flanigan",
      "Daniel Halpern",
      "Alexandros Psomas"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2206.14684"
  },
  {
    "id": "arXiv:2206.14687",
    "title": "Multi-scale Physical Representations for Approximating PDE Solutions  with Graph Neural Operators",
    "abstract": "Representing physical signals at different scales is among the most\nchallenging problems in engineering. Several multi-scale modeling tools have\nbeen developed to describe physical systems governed by \\emph{Partial\nDifferential Equations} (PDEs). These tools are at the crossroad of principled\nphysical models and numerical schema. Recently, data-driven models have been\nintroduced to speed-up the approximation of PDE solutions compared to numerical\nsolvers. Among these recent data-driven methods, neural integral operators are\na class that learn a mapping between function spaces. These functions are\ndiscretized on graphs (meshes) which are appropriate for modeling interactions\nin physical phenomena. In this work, we study three multi-resolution schema\nwith integral kernel operators that can be approximated with \\emph{Message\nPassing Graph Neural Networks} (MPGNNs). To validate our study, we make\nextensive MPGNNs experiments with well-chosen metrics considering steady and\nunsteady PDEs.",
    "descriptor": "\nComments: ICLR 2022 Workshop on Geometrical and Topological Representation Learning\n",
    "authors": [
      "L\u00e9on Migus",
      "Yuan Yin",
      "Jocelyn Ahmed Mazari",
      "Patrick Gallinari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.14687"
  },
  {
    "id": "arXiv:2206.14697",
    "title": "Hidden Parameter Recurrent State Space Models For Changing Dynamics  Scenarios",
    "abstract": "Recurrent State-space models (RSSMs) are highly expressive models for\nlearning patterns in time series data and system identification. However, these\nmodels assume that the dynamics are fixed and unchanging, which is rarely the\ncase in real-world scenarios. Many control applications often exhibit tasks\nwith similar but not identical dynamics which can be modeled as a latent\nvariable. We introduce the Hidden Parameter Recurrent State Space Models\n(HiP-RSSMs), a framework that parametrizes a family of related dynamical\nsystems with a low-dimensional set of latent factors. We present a simple and\neffective way of learning and performing inference over this Gaussian graphical\nmodel that avoids approximations like variational inference. We show that\nHiP-RSSMs outperforms RSSMs and competing multi-task models on several\nchallenging robotic benchmarks both on real-world systems and simulations.",
    "descriptor": "\nComments: Published at the International Conference on Learning Representations, ICLR 2022\n",
    "authors": [
      "Vaisakh Shaj",
      "Dieter Buchler",
      "Rohit Sonker",
      "Philipp Becker",
      "Gerhard Neumann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.14697"
  },
  {
    "id": "arXiv:2206.14698",
    "title": "There and Back Again: On Applying Data Reduction Rules by Undoing Others",
    "abstract": "Data reduction rules are an established method in the algorithmic toolbox for\ntackling computationally challenging problems. A data reduction rule is a\npolynomial-time algorithm that, given a problem instance as input, outputs an\nequivalent, typically smaller instance of the same problem. The application of\ndata reduction rules during the preprocessing of problem instances allows in\nmany cases to considerably shrink their size, or even solve them directly.\nCommonly, these data reduction rules are applied exhaustively and in some fixed\norder to obtain irreducible instances. It was often observed that by changing\nthe order of the rules, different irreducible instances can be obtained. We\npropose to \"undo\" data reduction rules on irreducible instances, by which they\nbecome larger, and then subsequently apply data reduction rules again to shrink\nthem. We show that this somewhat counter-intuitive approach can lead to\nsignificantly smaller irreducible instances. The process of undoing data\nreduction rules is not limited to \"rolling back\" data reduction rules applied\nto the instance during preprocessing. Instead, we formulate so-called backward\nrules, which essentially undo a data reduction rule, but without using any\ninformation about which data reduction rules were applied to it previously. In\nparticular, based on the example of Vertex Cover we propose two methods\napplying backward rules to shrink the instances further. In our experiments we\nshow that this way smaller irreducible instances consisting of real-world\ngraphs from the SNAP and DIMACS datasets can be computed.",
    "descriptor": "\nComments: extended abstract to appear at ESA 2022\n",
    "authors": [
      "Aleksander Figiel",
      "Vincent Froese",
      "Andr\u00e9 Nichterlein",
      "Rolf Niedermeier"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.14698"
  },
  {
    "id": "arXiv:2206.14700",
    "title": "Decomposition of Industrial Systems for Energy Efficiency Optimization  with OptTopo",
    "abstract": "The operation of industrial facilities is a broad field for optimization.\nIndustrial plants are often a) composed of several components, b) linked using\nnetwork technology, c) physically interconnected and d) complex regarding the\neffect of set-points and operating points in every entity. This leads to the\npossibility of overall optimization but also to a high complexity of the\nemerging optimization problems. The decomposition of complex systems allows the\nmodeling of individual models which can be structured according to the physical\ntopology. A method for energy performance indicators (EnPI) helps to formulate\nan optimization problem. The optimization algorithm OptTopo achieves efficient\nset-points by traversing a graph representation of the overall system.",
    "descriptor": "",
    "authors": [
      "Gregor Thiele",
      "Theresa Johanni",
      "David Sommer",
      "J\u00f6rg Kr\u00fcger"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.14700"
  },
  {
    "id": "arXiv:2206.14701",
    "title": "Debiasing architectural decision-making: a workshop-based training  approach",
    "abstract": "Cognitive biases distort the process of rational decision-making, including\narchitectural decision-making. So far, no method has been empirically proven to\nreduce the impact of cognitive biases on architectural decision-making. We\nconducted an experiment in which 44 master's degree graduate students took\npart. Divided into 12 teams, they created two designs - before and after a\ndebiasing workshop. We recorded this process and analysed how the participants\ndiscussed their decisions. In most cases (10 out of 12 groups), the teams'\nreasoning improved after the workshop. Thus, we show that debiasing\narchitectural decision-making is an attainable goal and provide a simple\ndebiasing treatment that could easily be used when training software\npractitioners.",
    "descriptor": "\nComments: Preprint of the paper accepted to the ECSA 2022 conference\n",
    "authors": [
      "Klara Borowa",
      "Maria Jarek",
      "Gabriela Mystkowska",
      "Weronika Paszko",
      "Andrzej Zalewski"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.14701"
  },
  {
    "id": "arXiv:2206.14702",
    "title": "Interventional Contrastive Learning with Meta Semantic Regularizer",
    "abstract": "Contrastive learning (CL)-based self-supervised learning models learn visual\nrepresentations in a pairwise manner. Although the prevailing CL model has\nachieved great progress, in this paper, we uncover an ever-overlooked\nphenomenon: When the CL model is trained with full images, the performance\ntested in full images is better than that in foreground areas; when the CL\nmodel is trained with foreground areas, the performance tested in full images\nis worse than that in foreground areas. This observation reveals that\nbackgrounds in images may interfere with the model learning semantic\ninformation and their influence has not been fully eliminated. To tackle this\nissue, we build a Structural Causal Model (SCM) to model the background as a\nconfounder. We propose a backdoor adjustment-based regularization method,\nnamely Interventional Contrastive Learning with Meta Semantic Regularizer\n(ICL-MSR), to perform causal intervention towards the proposed SCM. ICL-MSR can\nbe incorporated into any existing CL methods to alleviate background\ndistractions from representation learning. Theoretically, we prove that ICL-MSR\nachieves a tighter error bound. Empirically, our experiments on multiple\nbenchmark datasets demonstrate that ICL-MSR is able to improve the performances\nof different state-of-the-art CL methods.",
    "descriptor": "\nComments: Accepted by ICML 2022\n",
    "authors": [
      "Wenwen Qiang",
      "Jiangmeng Li",
      "Changwen Zheng",
      "Bing Su",
      "Hui Xiong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.14702"
  },
  {
    "id": "arXiv:2206.14707",
    "title": "An Embedding Framework for the Design and Analysis of Consistent  Polyhedral Surrogates",
    "abstract": "We formalize and study the natural approach of designing convex surrogate\nloss functions via embeddings, for problems such as classification, ranking, or\nstructured prediction. In this approach, one embeds each of the finitely many\npredictions (e.g. rankings) as a point in $R^d$, assigns the original loss\nvalues to these points, and \"convexifies\" the loss in some way to obtain a\nsurrogate. We establish a strong connection between this approach and\npolyhedral (piecewise-linear convex) surrogate losses: every discrete loss is\nembedded by some polyhedral loss, and every polyhedral loss embeds some\ndiscrete loss. Moreover, an embedding gives rise to a consistent link function\nas well as linear surrogate regret bounds. Our results are constructive, as we\nillustrate with several examples. In particular, our framework gives succinct\nproofs of consistency or inconsistency for various polyhedral surrogates in the\nliterature, and for inconsistent surrogates, it further reveals the discrete\nlosses for which these surrogates are consistent. We go on to show additional\nstructure of embeddings, such as the equivalence of embedding and matching\nBayes risks, and the equivalence of various notions of non-redudancy. Using\nthese results, we establish that indirect elicitation, a necessary condition\nfor consistency, is also sufficient when working with polyhedral surrogates.",
    "descriptor": "\nComments: Based heavily on arXiv posts 1907.07330 and 2110.14031\n",
    "authors": [
      "Jessie Finocchiaro",
      "Rafael M. Frongillo",
      "Bo Waggoner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2206.14707"
  },
  {
    "id": "arXiv:2206.14709",
    "title": "An extensible Benchmarking Graph-Mesh dataset for studying Steady-State  Incompressible Navier-Stokes Equations",
    "abstract": "Recent progress in \\emph{Geometric Deep Learning} (GDL) has shown its\npotential to provide powerful data-driven models. This gives momentum to\nexplore new methods for learning physical systems governed by \\emph{Partial\nDifferential Equations} (PDEs) from Graph-Mesh data. However, despite the\nefforts and recent achievements, several research directions remain unexplored\nand progress is still far from satisfying the physical requirements of\nreal-world phenomena. One of the major impediments is the absence of\nbenchmarking datasets and common physics evaluation protocols. In this paper,\nwe propose a 2-D graph-mesh dataset to study the airflow over airfoils at high\nReynolds regime (from $10^6$ and beyond). We also introduce metrics on the\nstress forces over the airfoil in order to evaluate GDL models on important\nphysical quantities. Moreover, we provide extensive GDL baselines.",
    "descriptor": "\nComments: ICLR 2022 Workshop on Geometrical and Topological Representation Learning\n",
    "authors": [
      "Florent Bonnet",
      "Jocelyn Ahmed Mazari",
      "Thibaut Munzer",
      "Pierre Yser",
      "Patrick Gallinari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.14709"
  },
  {
    "id": "arXiv:2206.14716",
    "title": "Improving Deliberation by Text-Only and Semi-Supervised Training",
    "abstract": "Text-only and semi-supervised training based on audio-only data has gained\npopularity recently due to the wide availability of unlabeled text and speech\ndata. In this work, we propose incorporating text-only and semi-supervised\ntraining into an attention-based deliberation model. By incorporating text-only\ndata in training a bidirectional encoder representation from transformer (BERT)\nfor the deliberation text encoder, and large-scale text-to-speech and\naudio-only utterances using joint acoustic and text decoder (JATD) and\nsemi-supervised training, we achieved 4%-12% WER reduction for various tasks\ncompared to the baseline deliberation. Compared to a state-of-the-art language\nmodel (LM) rescoring method, the deliberation model reduces the Google Voice\nSearch WER by 11% relative. We show that the deliberation model also achieves a\npositive human side-by-side evaluation compared to the state-of-the-art LM\nrescorer with reasonable endpointer latencies.",
    "descriptor": "\nComments: Accepted by Interspeech 2022\n",
    "authors": [
      "Ke Hu",
      "Tara N. Sainath",
      "Yanzhang He",
      "Rohit Prabhavalkar",
      "Trevor Strohman",
      "Sepand Mavandadi",
      "Weiran Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.14716"
  },
  {
    "id": "arXiv:2206.14718",
    "title": "LViT: Language meets Vision Transformer in Medical Image Segmentation",
    "abstract": "Deep learning has been widely used in medical image segmentation and other\naspects. However, the performance of existing medical image segmentation models\nhas been limited by the challenge of obtaining sufficient number of\nhigh-quality data with the high cost of data annotation. To overcome the\nlimitation, we propose a new vision-language medical image segmentation model\nLViT (Language meets Vision Transformer). In our model, medical text annotation\nis introduced to compensate for the quality deficiency in image data. In\naddition, the text information can guide the generation of pseudo labels to a\ncertain extent and further guarantee the quality of pseudo labels in\nsemi-supervised learning. We also propose the Exponential Pseudo label\nIteration mechanism (EPI) to help extend the semi-supervised version of LViT\nand the Pixel-Level Attention Module (PLAM) to preserve local features of\nimages. In our model, LV (Language-Vision) loss is designed to supervise the\ntraining of unlabeled images using text information directly. To validate the\nperformance of LViT, we construct multimodal medical segmentation datasets\n(image + text) containing pathological images, X-rays,etc. Experimental results\nshow that our proposed LViT has better segmentation performance in both fully\nand semi-supervised conditions. Code and datasets are available at\nhttps://github.com/HUANGLIZI/LViT.",
    "descriptor": "",
    "authors": [
      "Zihan Li",
      "Yunxiang Li",
      "Qingde Li",
      "You Zhang",
      "Puyang Wang",
      "Dazhou Guo",
      "Le Lu",
      "Dakai Jin",
      "Qingqi Hong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.14718"
  },
  {
    "id": "arXiv:2206.14719",
    "title": "Trial2Vec: Zero-Shot Clinical Trial Document Similarity Search using  Self-Supervision",
    "abstract": "Clinical trials are essential for drug development but are extremely\nexpensive and time-consuming to conduct. It is beneficial to study similar\nhistorical trials when designing a clinical trial. However, lengthy trial\ndocuments and lack of labeled data make trial similarity search difficult. We\npropose a zero-shot clinical trial retrieval method, Trial2Vec, which learns\nthrough self-supervision without annotating similar clinical trials.\nSpecifically, the meta-structure of trial documents (e.g., title, eligibility\ncriteria, target disease) along with clinical knowledge (e.g., UMLS knowledge\nbase https://www.nlm.nih.gov/research/umls/index.html) are leveraged to\nautomatically generate contrastive samples. Besides, Trial2Vec encodes trial\ndocuments considering meta-structure thus producing compact embeddings\naggregating multi-aspect information from the whole document. We show that our\nmethod yields medically interpretable embeddings by visualization and it gets a\n15% average improvement over the best baselines on precision/recall for trial\nretrieval, which is evaluated on our labeled 1600 trial pairs. In addition, we\nprove the pre-trained embeddings benefit the downstream trial outcome\nprediction task over 240k trials.",
    "descriptor": "",
    "authors": [
      "Zifeng Wang",
      "Jimeng Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14719"
  },
  {
    "id": "arXiv:2206.14723",
    "title": "DrumGAN VST: A Plugin for Drum Sound Analysis/Synthesis With  Autoencoding Generative Adversarial Networks",
    "abstract": "In contemporary popular music production, drum sound design is commonly\nperformed by cumbersome browsing and processing of pre-recorded samples in\nsound libraries. One can also use specialized synthesis hardware, typically\ncontrolled through low-level, musically meaningless parameters. Today, the\nfield of Deep Learning offers methods to control the synthesis process via\nlearned high-level features and allows generating a wide variety of sounds. In\nthis paper, we present DrumGAN VST, a plugin for synthesizing drum sounds using\na Generative Adversarial Network. DrumGAN VST operates on 44.1 kHz sample-rate\naudio, offers independent and continuous instrument class controls, and\nfeatures an encoding neural network that maps sounds into the GAN's latent\nspace, enabling resynthesis and manipulation of pre-existing drum sounds. We\nprovide numerous sound examples and a demo of the proposed VST plugin.",
    "descriptor": "\nComments: 7 pages, 2 figures, 3 tables, ICML2022 Machine Learning for Audio Synthesis (MLAS) Workshop, for sound examples visit this https URL\n",
    "authors": [
      "Javier Nistal",
      "Cyran Aouameur",
      "Ithan Velarde",
      "Stefan Lattner"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.14723"
  },
  {
    "id": "arXiv:2206.14724",
    "title": "Private Graph Extraction via Feature Explanations",
    "abstract": "Privacy and interpretability are two of the important ingredients for\nachieving trustworthy machine learning. We study the interplay of these two\naspects in graph machine learning through graph reconstruction attacks. The\ngoal of the adversary here is to reconstruct the graph structure of the\ntraining data given access to model explanations. Based on the different kinds\nof auxiliary information available to the adversary, we propose several graph\nreconstruction attacks. We show that additional knowledge of post-hoc feature\nexplanations substantially increases the success rate of these attacks.\nFurther, we investigate in detail the differences between attack performance\nwith respect to three different classes of explanation methods for graph neural\nnetworks: gradient-based, perturbation-based, and surrogate model-based\nmethods. While gradient-based explanations reveal the most in terms of the\ngraph structure, we find that these explanations do not always score high in\nutility. For the other two classes of explanations, privacy leakage increases\nwith an increase in explanation utility. Finally, we propose a defense based on\na randomized response mechanism for releasing the explanations which\nsubstantially reduces the attack success rate. Our anonymized code is\navailable.",
    "descriptor": "",
    "authors": [
      "Iyiola E. Olatunji",
      "Mandeep Rathee",
      "Thorben Funke",
      "Megha Khosla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.14724"
  },
  {
    "id": "arXiv:2206.14729",
    "title": "longhorns at DADC 2022: How many linguists does it take to fool a  Question Answering model? A systematic approach to adversarial attacks",
    "abstract": "Developing methods to adversarially challenge NLP systems is a promising\navenue for improving both model performance and interpretability. Here, we\ndescribe the approach of the team \"longhorns\" on Task 1 of the The First\nWorkshop on Dynamic Adversarial Data Collection (DADC), which asked teams to\nmanually fool a model on an Extractive Question Answering task. Our team\nfinished first, with a model error rate of 62%. We advocate for a systematic,\nlinguistically informed approach to formulating adversarial questions, and we\ndescribe the results of our pilot experiments, as well as our official\nsubmission.",
    "descriptor": "\nComments: Accepted at DADC2022\n",
    "authors": [
      "Venelin Kovatchev",
      "Trina Chatterjee",
      "Venkata S Govindarajan",
      "Jifan Chen",
      "Eunsol Choi",
      "Gabriella Chronis",
      "Anubrata Das",
      "Katrin Erk",
      "Matthew Lease",
      "Junyi Jessy Li",
      "Yating Wu",
      "Kyle Mahowald"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.14729"
  },
  {
    "id": "arXiv:2206.14735",
    "title": "GO-Surf: Neural Feature Grid Optimization for Fast, High-Fidelity RGB-D  Surface Reconstruction",
    "abstract": "We present GO-Surf, a direct feature grid optimization method for accurate\nand fast surface reconstruction from RGB-D sequences. We model the underlying\nscene with a learned hierarchical feature voxel grid that encapsulates\nmulti-level geometric and appearance local information. Feature vectors are\ndirectly optimized such that after being tri-linearly interpolated, decoded by\ntwo shallow MLPs into signed distance and radiance values, and rendered via\nsurface volume rendering, the discrepancy between synthesized and observed\nRGB/depth values is minimized. Our supervision signals -- RGB, depth and\napproximate SDF -- can be obtained directly from input images without any need\nfor fusion or post-processing. We formulate a novel SDF gradient regularization\nterm that encourages surface smoothness and hole filling while maintaining high\nfrequency details. GO-Surf can optimize sequences of $1$-$2$K frames in\n$15$-$45$ minutes, a speedup of $\\times60$ over NeuralRGB-D, the most related\napproach based on an MLP representation, while maintaining on par performance\non standard benchmarks. Project page: https://jingwenwang95.github.io/go_surf/",
    "descriptor": "\nComments: First two authors contributed equally. Project page: this https URL\n",
    "authors": [
      "Jingwen Wang",
      "Tymoteusz Bleja",
      "Lourdes Agapito"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.14735"
  },
  {
    "id": "arXiv:2206.14737",
    "title": "A Consensus-Based Load-Balancing Algorithm for Sharded Blockchains",
    "abstract": "Public blockchains are decentralized networks where each participating node\nexecutes the same decision-making process. This form of decentralization does\nnot scale well because the same data are stored on each network node, and\nbecause all nodes must validate each transaction prior to their confirmation.\nOne solution approach decomposes the nodes of a blockchain network into subsets\ncalled \"shards\", each shard processing and storing disjoint sets of\ntransactions in parallel. To fully benefit from the parallelism of sharded\nblockchains, the processing load of shards must be evenly distributed. However,\nthe problem of computing balanced workloads is theoretically hard and further\ncomplicated in practice as transaction processing times are unknown prior to be\nassigned to shards. In this paper we introduce a dynamic workload-balancing\nalgorithm where the allocation strategy of transactions to shards is\nperiodically adapted based on the recent workload history of shards. Our\nalgorithm is an adaptation to sharded blockchains of a consensus-based\nload-balancing algorithm. It is a fully distributed algorithm inline with\nnetwork based applications such as blockchains. Some preliminary results are\nreported based on simulations that shard transactions of three well-known\nblockchain platforms.",
    "descriptor": "",
    "authors": [
      "M. Toulouse",
      "H. K. Dai",
      "Q. L. Nguyen"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.14737"
  },
  {
    "id": "arXiv:2206.14741",
    "title": "Modeling Teams Performance Using Deep Representational Learning on  Graphs",
    "abstract": "The large majority of human activities require collaborations within and\nacross formal or informal teams. Our understanding of how the collaborative\nefforts spent by teams relate to their performance is still a matter of debate.\nTeamwork results in a highly interconnected ecosystem of potentially\noverlapping components where tasks are performed in interaction with team\nmembers and across other teams. To tackle this problem, we propose a graph\nneural network model designed to predict a team's performance while identifying\nthe drivers that determine such an outcome. In particular, the model is based\non three architectural channels: topological, centrality, and contextual which\ncapture different factors potentially shaping teams' success. We endow the\nmodel with two attention mechanisms to boost model performance and allow\ninterpretability. A first mechanism allows pinpointing key members inside the\nteam. A second mechanism allows us to quantify the contributions of the three\ndriver effects in determining the outcome performance. We test model\nperformance on a wide range of domains outperforming most of the classical and\nneural baselines considered. Moreover, we include synthetic datasets\nspecifically designed to validate how the model disentangles the intended\nproperties on which our model vastly outperforms baselines.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Francesco Carli",
      "Pietro Foini",
      "Nicol\u00f2 Gozzi",
      "Nicola Perra",
      "Rossano Schifanella"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14741"
  },
  {
    "id": "arXiv:2206.14743",
    "title": "Key Factors of Wireless Real-Time Networks -- From Dependability to  Timeliness",
    "abstract": "Offering support for real-time communications on top of a wireless network\ninfrastructure is both a hot topic and still an open challenge. Wireless\nnetworks are not on the same level of safety, dependability, and timeliness\nobserved in the wired realm, but they are evolving towards it. Instead of\nfocusing on the results that need to be delivered, the key factors of wireless\nreal-time networks are on the foundation of the network operation, defining\ntheir capability of being dependable, safe, and timely on their roots. IEEE\n802.15.4 and ISA100.11a are part of this context, which we show how to be\nstrengthened. From dealing with network inaccessibility to touching the needs\nof reliable communication protocols to ensure the safe and sound exchange of\ninformation, this white paper describes how we can go from dependability to\ntimeliness. This is achieved by visiting the roots of the network operation for\nsecuring the provided communication service as a dependable, safe, and timely\nasset for industrial automation.\nKeywords: Dependability, Safety, Timeliness, Resilience, Real-Time Wireless\nNetworks, Industrial Automation.",
    "descriptor": "",
    "authors": [
      "Jeferson L. R. Souza",
      "Frank Siqueira"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.14743"
  },
  {
    "id": "arXiv:2206.14749",
    "title": "An Auto-Regressive Formulation for Smoothing and Moving Mean with  Exponentially Tapered Windows",
    "abstract": "We investigate an auto-regressive formulation for the problem of smoothing\ntime-series by manipulating the inherent objective function of the traditional\nmoving mean smoothers. Not only the auto-regressive smoothers enforce a higher\ndegree of smoothing, they are just as efficient as the traditional moving means\nand can be optimized accordingly with respect to the input dataset.\nInterestingly, the auto-regressive models result in moving means with\nexponentially tapered windows.",
    "descriptor": "",
    "authors": [
      "Kaan Gokcesu",
      "Hakan Gokcesu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.14749"
  },
  {
    "id": "arXiv:2206.14754",
    "title": "Distilling Model Failures as Directions in Latent Space",
    "abstract": "Existing methods for isolating hard subpopulations and spurious correlations\nin datasets often require human intervention. This can make these methods\nlabor-intensive and dataset-specific. To address these shortcomings, we present\na scalable method for automatically distilling a model's failure modes.\nSpecifically, we harness linear classifiers to identify consistent error\npatterns, and, in turn, induce a natural representation of these failure modes\nas directions within the feature space. We demonstrate that this framework\nallows us to discover and automatically caption challenging subpopulations\nwithin the training dataset, and intervene to improve the model's performance\non these subpopulations. Code available at\nhttps://github.com/MadryLab/failure-directions",
    "descriptor": "",
    "authors": [
      "Saachi Jain",
      "Hannah Lawrence",
      "Ankur Moitra",
      "Aleksander Madry"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14754"
  },
  {
    "id": "arXiv:2206.14759",
    "title": "How Train-Test Leakage Affects Zero-shot Retrieval",
    "abstract": "Neural retrieval models are often trained on (subsets of) the millions of\nqueries of the MS MARCO / ORCAS datasets and then tested on the 250 Robust04\nqueries or other TREC benchmarks with often only 50 queries. In such setups,\nmany of the few test queries can be very similar to queries from the huge\ntraining data -- in fact, 69% of the Robust04 queries have near-duplicates in\nMS MARCO / ORCAS. We investigate the impact of this unintended train-test\nleakage by training neural retrieval models on combinations of a fixed number\nof MS MARCO / ORCAS queries that are highly similar to the actual test queries\nand an increasing number of other queries. We find that leakage can improve\neffectiveness and even change the ranking of systems. However, these effects\ndiminish as the amount of leakage among all training instances decreases and\nthus becomes more realistic.",
    "descriptor": "",
    "authors": [
      "Maik Fr\u00f6be",
      "Christopher Akiki",
      "Martin Potthast",
      "Matthias Hagen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.14759"
  },
  {
    "id": "arXiv:2206.14761",
    "title": "Accelerating Parallel Write via Deeply Integrating Predictive Lossy  Compression with HDF5",
    "abstract": "Lossy compression is one of the most efficient solutions to reduce storage\noverhead and improve I/O performance for HPC applications. However, existing\nparallel I/O libraries cannot fully utilize lossy compression to accelerate\nparallel write due to the lack of deep understanding on compression-write\nperformance. To this end, we propose to deeply integrate predictive lossy\ncompression with HDF5 to significantly improve the parallel-write performance.\nSpecifically, we propose analytical models to predict the time of compression\nand parallel write before the actual compression to enable compression-write\noverlapping. We also introduce an extra space in the process to handle possible\ndata overflows resulting from prediction uncertainty in compression ratios.\nMoreover, we propose an optimization to reorder the compression tasks to\nincrease the overlapping efficiency. Experiments with up to 4,096 cores from\nSummit show that our solution improves the write performance by up to 4.5X and\n2.9X over the non-compression and lossy compression solutions, respectively,\nwith only 1.5% storage overhead (compared to original data) on two real-world\nHPC applications.",
    "descriptor": "\nComments: 13 pages, 18 figures, accepted by ACM/IEEE SC'22\n",
    "authors": [
      "Sian Jin",
      "Dingwen Tao",
      "Houjun Tang",
      "Sheng Di",
      "Suren Byna",
      "Zarija Lukic",
      "Franck Cappello"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2206.14761"
  },
  {
    "id": "arXiv:2206.14764",
    "title": "Potential Technical Debt and Its Resolution in Code Reviews: An  Exploratory Study of the OpenStack and Qt Communities",
    "abstract": "Technical Debt (TD) refers to the situation where developers make trade-offs\nto achieve short-term goals at the expense of long-term code quality, which can\nhave a negative impact on the quality of software systems. In the context of\ncode review, such sub-optimal implementations have chances to be timely\nresolved during the review process before the code is merged. Therefore, we\ncould consider them as Potential Technical Debt (PTD) since PTD will evolve\ninto TD when it is injected into software systems without being resolved. To\ndate, little is known about the extent to which PTD is identified in code\nreviews. To this end, we conducted an exploratory study in an attempt to\nunderstand the nature of PTD in code reviews and track down the resolution of\nPTD after being identified. We randomly collected 2,030 review comments from\nthe Nova project of OpenStack and the Qt Base project of Qt. We then manually\nchecked these review comments, and obtained 163 PTD-related review comments for\nfurther analysis. Our results show that: (1) PTD can be identified in code\nreviews but is not prevalent. (2) Design, defect, documentation, requirement,\ntest, and code PTD are identified in code reviews, in which code and\ndocumentation PTD are the dominant. (3) 81.0% of the PTD identified in code\nreviews has been resolved by developers, and 78.0% of the resolved TD was\nresolved by developers within a week. (4) Code refactoring is the main practice\nused by developers to resolve the PTD identified in code reviews. Our findings\nindicate that: (1) review-based detection of PTD is seen as one of the\ntrustworthy mechanisms in development, and (2) there is still a significant\nproportion of PTD (19.0%) remaining unresolved when injected into the software\nsystems. Practitioners and researchers should establish effective strategies to\nmanage and resolve PTD in development.",
    "descriptor": "\nComments: The 16th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)\n",
    "authors": [
      "Liming Fu",
      "Peng Liang",
      "Zeeshan Rasheed",
      "Zengyang Li",
      "Amjed Tahir",
      "Xiaofeng Han"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.14764"
  },
  {
    "id": "arXiv:2206.14767",
    "title": "Verified Causal Broadcast with Liquid Haskell",
    "abstract": "Protocols to ensure that messages are delivered in causal order are a\nubiquitous building block of distributed systems. For instance, key-value\nstores can use causally ordered message delivery to ensure causal consistency\n-- a sweet spot in the availability/consistency trade-off space -- and\nreplicated data structures rely on the existence of an underlying\ncausally-ordered messaging layer to ensure that geo-distributed replicas\neventually converge to the same state. A causal delivery protocol ensures that\nwhen a message is delivered to a process, any causally preceding messages sent\nto the same process have already been delivered to it. While causal message\ndelivery protocols are widely used in distributed systems, verification of the\ncorrectness of those protocols is less common, much less machine-checked proofs\nabout executable implementations.\nWe implemented a standard causal broadcast protocol in Haskell and used the\nLiquid Haskell solver-aided verification system to express and mechanically\nprove that messages will never be delivered to a process in an order that\nviolates causality. To do so, we express a process-local causal delivery\nproperty using refinement types, and we prove that it holds of our\nimplementation using Liquid Haskell's theorem-proving facilities, resulting in\nthe first machine-checked proof of correctness of an executable causal\nbroadcast implementation. We then put our verified causal broadcast\nimplementation to work as the foundation of a distributed key-value store\nimplemented in Haskell.",
    "descriptor": "",
    "authors": [
      "Patrick Redmond",
      "Gan Shen",
      "Niki Vazou",
      "Lindsey Kuper"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.14767"
  },
  {
    "id": "arXiv:2206.14772",
    "title": "IBP Regularization for Verified Adversarial Robustness via  Branch-and-Bound",
    "abstract": "Recent works have tried to increase the verifiability of adversarially\ntrained networks by running the attacks over domains larger than the original\nperturbations and adding various regularization terms to the objective.\nHowever, these algorithms either underperform or require complex and expensive\nstage-wise training procedures, hindering their practical applicability. We\npresent IBP-R, a novel verified training algorithm that is both simple and\neffective. IBP-R induces network verifiability by coupling adversarial attacks\non enlarged domains with a regularization term, based on inexpensive interval\nbound propagation, that minimizes the gap between the non-convex verification\nproblem and its approximations. By leveraging recent branch-and-bound\nframeworks, we show that IBP-R obtains state-of-the-art verified\nrobustness-accuracy trade-offs for small perturbations on CIFAR-10 while\ntraining significantly faster than relevant previous work. Additionally, we\npresent UPB, a novel branching strategy that, relying on a simple heuristic\nbased on $\\beta$-CROWN, reduces the cost of state-of-the-art branching\nalgorithms while yielding splits of comparable quality.",
    "descriptor": "\nComments: ICML 2022 Workshop on Formal Verification of Machine Learning\n",
    "authors": [
      "Alessandro De Palma",
      "Rudy Bunel",
      "Krishnamurthy Dvijotham",
      "M. Pawan Kumar",
      "Robert Stanforth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.14772"
  },
  {
    "id": "arXiv:2206.14774",
    "title": "TweetNLP: Cutting-Edge Natural Language Processing for Social Media",
    "abstract": "In this paper we present TweetNLP, an integrated platform for Natural\nLanguage Processing (NLP) in social media. TweetNLP supports a diverse set of\nNLP tasks, including generic focus areas such as sentiment analysis and named\nentity recognition, as well as social media-specific tasks such as emoji\nprediction and offensive language identification. Task-specific systems are\npowered by reasonably-sized Transformer-based language models specialized on\nsocial media text (in particular, Twitter) which can be run without the need\nfor dedicated hardware or cloud services. The main contributions of TweetNLP\nare: (1) an integrated Python library for a modern toolkit supporting social\nmedia analysis using our various task-specific models adapted to the social\ndomain; (2) an interactive online demo for codeless experimentation using our\nmodels; and (3) a tutorial covering a wide variety of typical social media\napplications.",
    "descriptor": "\nComments: Demo paper. TweetNLP: this https URL\n",
    "authors": [
      "Jose Camacho-Collados",
      "Kiamehr Rezaee",
      "Talayeh Riahi",
      "Asahi Ushio",
      "Daniel Loureiro",
      "Dimosthenis Antypas",
      "Joanne Boisson",
      "Luis Espinosa-Anke",
      "Fangyu Liu",
      "Eugenio Mart\u00ednez-C\u00e1mara",
      "Gonzalo Medina",
      "Thomas Buhrmann",
      "Leonardo Neves",
      "Francesco Barbieri"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.14774"
  },
  {
    "id": "arXiv:2206.14777",
    "title": "System-level Simulation of Reconfigurable Intelligent Surface assisted  Wireless Communications System",
    "abstract": "Reconfigurable intelligent surface (RIS) is an emerging technique employing\nmetasurface to reflect the signal from the source node to the destination node.\nBy smartly reconfiguring the electromagnetic (EM) properties of the metasurface\nand adjusting the EM parameters of the reflected radio waves, RIS can turn the\nuncontrollable propagation environment into an artificially reconfigurable\nspace, and thus, can significantly increase the communications capacity and\nimprove the coverage of the system. In this paper, we investigate the far field\nchannel in which the line-of-sight (LOS) propagation is dominant. We propose an\nantenna model that can characterize the radiation patterns of realistic RIS\nelements, and consider the signal power received from the two-hop path through\nRIS. System-level simulations of network performance under various scenarios\nand parameter.",
    "descriptor": "",
    "authors": [
      "Qi Gu",
      "Dan Wu",
      "Xin Su",
      "Hanning Wang",
      "Jingyuan Cui",
      "Yifei Yuan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.14777"
  },
  {
    "id": "arXiv:2206.14782",
    "title": "Implementation of Ethereum Accounts and Transactions on Embedded IoT  Devices",
    "abstract": "The growing interest in Internet of Things (IoT) and Industrial IoT (IIoT)\nposes the challenge of finding robust solutions for the certification and\nnotarization of data produced and collected by embedded devices. The blockchain\nand distributed ledger technologies represent a promising solution to address\nthese issues, but rise other questions, for example regarding their practical\nfeasibility. In fact, IoT devices have limited resources and, consequently, may\nnot be able to easily perform all the operations required to participate in a\nblockchain. In this paper we propose a minimal architecture to allow IoT\ndevices performing data certification and notarization on the Ethereum\nblockchain. We develop a hardware-software platform through which a lightweight\ndevice (e.g., an IoT sensor), holding a secret key and the associated public\naddress, produces signed transactions, which are then submitted to the\nblockchain network. This guarantees data integrity and authenticity and, on the\nother hand, minimizes the computational burden on the lightweight device. To\nshow the practicality of the proposed approach, we report and discuss the\nresults of benchmarks performed on ARM Cortex-M4 hardware architectures,\nsending transactions over the Ropsten testnet. Our results show that all the\nnecessary operations can be performed with small latency, thus proving that an\nIoT device can directly interact with the blockchain, without apparent\nbottlenecks.",
    "descriptor": "",
    "authors": [
      "Giulia Rafaiani",
      "Paolo Santini",
      "Marco Baldi",
      "Franco Chiaraluce"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.14782"
  },
  {
    "id": "arXiv:2206.14786",
    "title": "ENS-10: A Dataset For Post-Processing Ensemble Weather Forecast",
    "abstract": "Post-processing ensemble prediction systems can improve weather forecasting,\nespecially for extreme event prediction. In recent years, different machine\nlearning models have been developed to improve the quality of the\npost-processing step. However, these models heavily rely on the data and\ngenerating such ensemble members requires multiple runs of numerical weather\nprediction models, at high computational cost. This paper introduces the ENS-10\ndataset, consisting of ten ensemble members spread over 20 years (1998-2017).\nThe ensemble members are generated by perturbing numerical weather simulations\nto capture the chaotic behavior of the Earth. To represent the\nthree-dimensional state of the atmosphere, ENS-10 provides the most relevant\natmospheric variables in 11 distinct pressure levels as well as the surface at\n0.5-degree resolution. The dataset targets the prediction correction task at\n48-hour lead time, which is essentially improving the forecast quality by\nremoving the biases of the ensemble members. To this end, ENS-10 provides the\nweather variables for forecast lead times T=0, 24, and 48 hours (two data\npoints per week). We provide a set of baselines for this task on ENS-10 and\ncompare their performance in correcting the prediction of different weather\nvariables. We also assess our baselines for predicting extreme events using our\ndataset. The ENS-10 dataset is available under the Creative Commons Attribution\n4.0 International (CC BY 4.0) licence.",
    "descriptor": "",
    "authors": [
      "Saleh Ashkboos",
      "Langwen Huang",
      "Nikoli Dryden",
      "Tal Ben-Nun",
      "Peter Dueben",
      "Lukas Gianinazzi",
      "Luca Kummer",
      "Torsten Hoefler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.14786"
  },
  {
    "id": "arXiv:2206.14796",
    "title": "On the Robustness of Dialogue History Representation in Conversational  Question Answering: A Comprehensive Study and a New Prompt-based Method",
    "abstract": "Most works on modeling the conversation history in Conversational Question\nAnswering (CQA) report a single main result on a common CQA benchmark. While\nexisting models show impressive results on CQA leaderboards, it remains unclear\nwhether they are robust to shifts in setting (sometimes to more realistic\nones), training data size (e.g. from large to small sets) and domain. In this\nwork, we design and conduct the first large-scale robustness study of history\nmodeling approaches for CQA. We find that high benchmark scores do not\nnecessarily translate to strong robustness, and that various methods can\nperform extremely differently under different settings. Equipped with the\ninsights from our study, we design a novel prompt-based history modeling\napproach, and demonstrate its strong robustness across various settings. Our\napproach is inspired by existing methods that highlight historic answers in the\npassage. However, instead of highlighting by modifying the passage token\nembeddings, we add textual prompts directly in the passage text. Our approach\nis simple, easy-to-plug into practically any model, and highly effective, thus\nwe recommend it as a starting point for future model developers. We also hope\nthat our study and insights will raise awareness to the importance of\nrobustness-focused evaluation, in addition to obtaining high leaderboard\nscores, leading to better CQA systems.",
    "descriptor": "\nComments: First two authors contributed equally to this work. Our code and data will be released at: this https URL\n",
    "authors": [
      "Zorik Gekhman",
      "Nadav Oved",
      "Orgad Keller",
      "Idan Szpektor",
      "Roi Reichart"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14796"
  },
  {
    "id": "arXiv:2206.14797",
    "title": "3D-Aware Video Generation",
    "abstract": "Generative models have emerged as an essential building block for many image\nsynthesis and editing tasks. Recent advances in this field have also enabled\nhigh-quality 3D or video content to be generated that exhibits either\nmulti-view or temporal consistency. With our work, we explore 4D generative\nadversarial networks (GANs) that learn unconditional generation of 3D-aware\nvideos. By combining neural implicit representations with time-aware\ndiscriminator, we develop a GAN framework that synthesizes 3D video supervised\nonly with monocular videos. We show that our method learns a rich embedding of\ndecomposable 3D structures and motions that enables new visual effects of\nspatio-temporal renderings while producing imagery with quality comparable to\nthat of existing 3D or video GANs.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Sherwin Bahmani",
      "Jeong Joon Park",
      "Despoina Paschalidou",
      "Hao Tang",
      "Gordon Wetzstein",
      "Leonidas Guibas",
      "Luc Van Gool",
      "Radu Timofte"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14797"
  },
  {
    "id": "arXiv:2206.14800",
    "title": "Understanding Generalization via Leave-One-Out Conditional Mutual  Information",
    "abstract": "We study the mutual information between (certain summaries of) the output of\na learning algorithm and its $n$ training data, conditional on a supersample of\n$n+1$ i.i.d. data from which the training data is chosen at random without\nreplacement. These leave-one-out variants of the conditional mutual information\n(CMI) of an algorithm (Steinke and Zakynthinou, 2020) are also seen to control\nthe mean generalization error of learning algorithms with bounded loss\nfunctions. For learning algorithms achieving zero empirical risk under 0-1 loss\n(i.e., interpolating algorithms), we provide an explicit connection between\nleave-one-out CMI and the classical leave-one-out error estimate of the risk.\nUsing this connection, we obtain upper and lower bounds on risk in terms of the\n(evaluated) leave-one-out CMI. When the limiting risk is constant or decays\npolynomially, the bounds converge to within a constant factor of two. As an\napplication, we analyze the population risk of the one-inclusion graph\nalgorithm, a general-purpose transductive learning algorithm for VC classes in\nthe realizable setting. Using leave-one-out CMI, we match the optimal bound for\nlearning VC classes in the realizable setting, answering an open challenge\nraised by Steinke and Zakynthinou (2020). Finally, in order to understand the\nrole of leave-one-out CMI in studying generalization, we place leave-one-out\nCMI in a hierarchy of measures, with a novel unconditional mutual information\nat the root. For 0-1 loss and interpolating learning algorithms, this mutual\ninformation is observed to be precisely the risk.",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Mahdi Haghifam",
      "Shay Moran",
      "Daniel M. Roy",
      "Gintare Karolina Dziugaite"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14800"
  },
  {
    "id": "arXiv:2206.14801",
    "title": "Meta-Learning over Time for Destination Prediction Tasks",
    "abstract": "A need to understand and predict vehicles' behavior underlies both public and\nprivate goals in the transportation domain, including urban planning and\nmanagement, ride-sharing services, and intelligent transportation systems.\nIndividuals' preferences and intended destinations vary throughout the day,\nweek, and year: for example, bars are most popular in the evenings, and beaches\nare most popular in the summer. Despite this principle, we note that recent\nstudies on a popular benchmark dataset from Porto, Portugal have found, at\nbest, only marginal improvements in predictive performance from incorporating\ntemporal information. We propose an approach based on hypernetworks, a variant\nof meta-learning (\"learning to learn\") in which a neural network learns to\nchange its own weights in response to an input. In our case, the weights\nresponsible for destination prediction vary with the metadata, in particular\nthe time, of the input trajectory. The time-conditioned weights notably improve\nthe model's error relative to ablation studies and comparable prior work, and\nwe confirm our hypothesis that knowledge of time should improve prediction of a\nvehicle's intended destination.",
    "descriptor": "\nComments: 10 pages, 8 figures. Submitted to SIGSPATIAL 2022\n",
    "authors": [
      "Mark Tenzer",
      "Zeeshan Rasheed",
      "Khurram Shafique",
      "Nuno Vasconcelos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14801"
  },
  {
    "id": "arXiv:2206.14802",
    "title": "Visual Foresight With a Local Dynamics Model",
    "abstract": "Model-free policy learning has been shown to be capable of learning\nmanipulation policies which can solve long-time horizon tasks using single-step\nmanipulation primitives. However, training these policies is a time-consuming\nprocess requiring large amounts of data. We propose the Local Dynamics Model\n(LDM) which efficiently learns the state-transition function for these\nmanipulation primitives. By combining the LDM with model-free policy learning,\nwe can learn policies which can solve complex manipulation tasks using one-step\nlookahead planning. We show that the LDM is both more sample-efficient and\noutperforms other model architectures. When combined with planning, we can\noutperform other model-based and model-free policies on several challenging\nmanipulation tasks in simulation.",
    "descriptor": "",
    "authors": [
      "Colin Kohler",
      "Robert Platt"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14802"
  },
  {
    "id": "arXiv:2206.12012",
    "title": "Hausdorff Distance between Norm Balls and their Linear Maps",
    "abstract": "We consider the problem of computing the (two-sided) Hausdorff distance\nbetween the unit $p_1$ and $p_2$ norm balls in finite dimensional Euclidean\nspace for $1 < p_1 < p_2 \\leq \\infty$, and derive a closed-form formula for the\nsame. When the two different norm balls are transformed via a common linear\nmap, we obtain several estimates for the Hausdorff distance between the\nresulting convex sets. These estimates upper bound the Hausdorff distance or\nits expectation, depending on whether the linear map is arbitrary or random. We\nthen generalize the developments for the Hausdorff distance between two\nset-valued integrals obtained by applying a parametric family of linear maps to\nthe unit norm balls, and then taking the Minkowski sums of the resulting sets\nin a limiting sense. To illustrate an application, we show that the problem of\ncomputing the Hausdorff distance between the reach sets of a linear dynamical\nsystem with different unit norm ball-valued input uncertainties, reduces to\nthis set-valued integral setting.",
    "descriptor": "",
    "authors": [
      "Shadi Haddad",
      "Abhishek Halder"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Geometry (cs.CG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.12012"
  },
  {
    "id": "arXiv:2206.14213",
    "title": "Improved resource-tunable near-term quantum algorithms for transition  probabilities, with applications in physics and variational quantum linear  algebra",
    "abstract": "Transition amplitudes and transition probabilities are relevant to many areas\nof physics simulation, including the calculation of response properties and\ncorrelation functions. These quantities are also closely related to solving\nlinear systems of equations in quantum linear algebra. Here we present three\nrelated algorithms for calculating transition probabilities with respect to\narbitrary operators and states. First, we extend a previously published\nshort-depth algorithm, allowing for the two input quantum states to be\nnon-orthogonal. The extension comes at the cost of one ancilla qubit and at\nmost only a constant four additional two-qubit gates. Building on this first\nprocedure, we then derive a higher-depth approach based on Trotterization and\nRichardson extrapolation that requires fewer circuit evaluations. Third, we\nintroduce a tunable approach that in effect interpolates between the low-depth\nmethod and the method of fewer circuit evaluations. This tunability between\ncircuit depth and measurement complexity allows the algorithm to be tailored to\nspecific hardware characteristics. Finally, we implement proof-of-principle\nnumerics for toy models in physics and chemistry and for use a subroutine in\nvariational quantum linear solving (VQLS). The primary benefits of our\napproaches are that (a) arbitrary non-orthogonal states may now be used with\nnegligible increases in quantum resources, (b) we entirely avoid subroutines\nsuch as the Hadamard test that may require three-qubit gates to be decomposed,\nand (c) in some cases fewer quantum circuit evaluations are required as\ncompared to the previous state-of-the-art in NISQ algorithms for transition\nprobabilities.",
    "descriptor": "\nComments: 12 pages, 5 figures\n",
    "authors": [
      "Nicolas PD Sawaya",
      "Joonsuk Huh"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Other Condensed Matter (cond-mat.other)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.14213"
  },
  {
    "id": "arXiv:2206.14234",
    "title": "PyEPO: A PyTorch-based End-to-End Predict-then-Optimize Library for  Linear and Integer Programming",
    "abstract": "In deterministic optimization, it is typically assumed that all parameters of\nthe problem are fixed and known. In practice, however, some parameters may be a\npriori unknown but can be estimated from historical data. A typical\npredict-then-optimize approach separates predictions and optimization into two\nstages. Recently, end-to-end predict-then-optimize has become an attractive\nalternative. In this work, we present the PyEPO package, a PyTorch-based\nend-to-end predict-then-optimize library in Python. To the best of our\nknowledge, PyEPO (pronounced like \"pineapple\" with a silent \"n\") is the first\nsuch generic tool for linear and integer programming with predicted objective\nfunction coefficients. It provides two base algorithms: the first is based on\nthe convex surrogate loss function from the seminal work of Elmachtoub & Grigas\n(2021), and the second is based on the differentiable black-box solver approach\nof Vlastelica et al. (2019). PyEPO provides a simple interface for the\ndefinition of new optimization problems, the implementation of state-of-the-art\npredict-then-optimize training algorithms, the use of custom neural network\narchitectures, and the comparison of end-to-end approaches with the two-stage\napproach. PyEPO enables us to conduct a comprehensive set of experiments\ncomparing a number of end-to-end and two-stage approaches along axes such as\nprediction accuracy, decision quality, and running time on problems such as\nShortest Path, Multiple Knapsack, and the Traveling Salesperson Problem. We\ndiscuss some empirical insights from these experiments which could guide future\nresearch. PyEPO and its documentation are available at\nhttps://github.com/khalil-research/PyEPO.",
    "descriptor": "",
    "authors": [
      "Bo Tang",
      "Elias B. Khalil"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14234"
  },
  {
    "id": "arXiv:2206.14273",
    "title": "Asymptotic bounds for the number of closed and privileged words",
    "abstract": "A word $w$ has a border $u$ if $u$ is a non-empty proper prefix and suffix of\n$u$. A word $w$ is said to be \\emph{closed} if $|w| \\leq 1$ or if $w$ has a\nborder that occurs exactly twice in $w$. A word $w$ is said to be\n\\emph{privileged} if $|w| \\leq 1$ or if $w$ has a privileged border that occurs\nexactly twice in $w$. Let $C_k(n)$ (resp. $P_k(n)$) be the number of length-$n$\nclosed (resp. privileged) words over a $k$-letter alphabet. In this paper we\nimprove existing upper and lower bounds on $C_k(n)$ and $P_k(n)$. We prove that\n$C_k(n) \\in \\Theta(\\frac{k^n}{n})$. Let $\\log_k^{\\circ 0}(n) = n$ and\n$\\log_k^{\\circ j}(n) = \\log_k(\\log_k^{\\circ j-1}(n))$ for $j\\geq 1$. We also\nprove that for all $j\\geq 0$ there exist constants $N_j$, $c_j$, and $c_j'$\nsuch that \\[c_j\\frac{k^n}{n\\log_k^{\\circ j}(n)\\prod_{i=1}^j\\log_k^{\\circ\ni}(n)}\\leq P_k(n) \\leq c_j'\\frac{k^n}{n\\prod_{i=1}^j\\log_k^{\\circ i}(n)}\\] for\nall $n>N_j$.",
    "descriptor": "",
    "authors": [
      "Daniel Gabric"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2206.14273"
  },
  {
    "id": "arXiv:2206.14278",
    "title": "A Perturbation Bound on the Subspace Estimator from Canonical  Projections",
    "abstract": "This paper derives a perturbation bound on the optimal subspace estimator\nobtained from a subset of its canonical projections contaminated by noise. This\nfundamental result has important implications in matrix completion, subspace\nclustering, and related problems.",
    "descriptor": "\nComments: To appear in Proc. of IEEE, ISIT 2022\n",
    "authors": [
      "Karan Srivastava",
      "Daniel L. Pimentel-Alarc\u00f3n"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14278"
  },
  {
    "id": "arXiv:2206.14284",
    "title": "Optimal Estimation of Generic Dynamics by Path-Dependent Neural Jump  ODEs",
    "abstract": "This paper studies the problem of forecasting general stochastic processes\nusing an extension of the Neural Jump ODE (NJ-ODE) framework. While NJ-ODE was\nthe first framework to establish convergence guarantees for the prediction of\nirregularly observed time-series, these results were limited to data stemming\nfrom It\\^o-diffusions with complete observations, in particular Markov\nprocesses where all coordinates are observed simultaneously. In this work, we\ngeneralise these results to generic, possibly non-Markovian or discontinuous,\nstochastic processes with incomplete observations, by utilising the\nreconstruction properties of the signature transform. These theoretical results\nare supported by empirical studies, where it is shown that the path-dependent\nNJ-ODE outperforms the original NJ-ODE framework in the case of non-Markovian\ndata.",
    "descriptor": "",
    "authors": [
      "Florian Krach",
      "Marc N\u00fcbel",
      "Josef Teichmann"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2206.14284"
  },
  {
    "id": "arXiv:2206.14305",
    "title": "Multistep Automated Data Labelling Procedure (MADLaP) for Thyroid  Nodules on Ultrasound: An Artificial Intelligence Approach for Automating  Image Annotation",
    "abstract": "Machine learning (ML) for diagnosis of thyroid nodules on ultrasound is an\nactive area of research. However, ML tools require large, well-labelled\ndatasets, the curation of which is time-consuming and labor-intensive. The\npurpose of our study was to develop and test a deep-learning-based tool to\nfacilitate and automate the data annotation process for thyroid nodules; we\nnamed our tool Multistep Automated Data Labelling Procedure (MADLaP). MADLaP\nwas designed to take multiple inputs included pathology reports, ultrasound\nimages, and radiology reports. Using multiple step-wise modules including\nrule-based natural language processing, deep-learning-based imaging\nsegmentation, and optical character recognition, MADLaP automatically\nidentified images of a specific thyroid nodule and correctly assigned a\npathology label. The model was developed using a training set of 378 patients\nacross our health system and tested on a separate set of 93 patients. Ground\ntruths for both sets were selected by an experienced radiologist. Performance\nmetrics including yield (how many labeled images the model produced) and\naccuracy (percentage correct) were measured using the test set. MADLaP achieved\na yield of 63% and an accuracy of 83%. The yield progressively increased as the\ninput data moved through each module, while accuracy peaked part way through.\nError analysis showed that inputs from certain examination sites had lower\naccuracy (40%) than the other sites (90%, 100%). MADLaP successfully created\ncurated datasets of labeled ultrasound images of thyroid nodules. While\naccurate, the relatively suboptimal yield of MADLaP exposed some challenges\nwhen trying to automatically label radiology images from heterogeneous sources.\nThe complex task of image curation and annotation could be automated, allowing\nfor enrichment of larger datasets for use in machine learning development.",
    "descriptor": "",
    "authors": [
      "Jikai Zhang",
      "Maciej M. Mazurowski",
      "Brian C. Allen",
      "Benjamin Wildman-Torbiner"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2206.14305"
  },
  {
    "id": "arXiv:2206.14323",
    "title": "A wideband generalization of the near-field region for extremely large  phased-arrays",
    "abstract": "The narrowband and far-field assumption in conventional wireless system\ndesign leads to a mismatch with the optimal beamforming required for wideband\nand near-field systems. This discrepancy is exacerbated for larger apertures\nand bandwidths. To characterize the behavior of near-field and wideband\nsystems, we derive the beamforming gain expression achieved by a frequency-flat\nphased array designed for plane-wave propagation. To determine the far-field to\nnear-field boundary for a wideband system, we propose a frequency-selective\ndistance metric. The proposed far-field threshold increases for frequencies\naway from the center frequency. The analysis results in a fundamental upper\nbound on the product of the array aperture and the system bandwidth. We present\nnumerical results to illustrate how the gain threshold affects the maximum\nusable bandwidth for the n260 and n261 5G NR bands.",
    "descriptor": "",
    "authors": [
      "Nitish Deshpande",
      "Miguel R. Castellanos",
      "Saeed R. Khosravirad",
      "Jinfeng Du",
      "Harish Viswanathan",
      "Robert W. Heath Jr"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.14323"
  },
  {
    "id": "arXiv:2206.14331",
    "title": "Spherical Channels for Modeling Atomic Interactions",
    "abstract": "Modeling the energy and forces of atomic systems is a fundamental problem in\ncomputational chemistry with the potential to help address many of the world's\nmost pressing problems, including those related to energy scarcity and climate\nchange. These calculations are traditionally performed using Density Functional\nTheory, which is computationally very expensive. Machine learning has the\npotential to dramatically improve the efficiency of these calculations from\ndays or hours to seconds. We propose the Spherical Channel Network (SCN) to\nmodel atomic energies and forces. The SCN is a graph neural network where nodes\nrepresent atoms and edges their neighboring atoms. The atom embeddings are a\nset of spherical functions, called spherical channels, represented using\nspherical harmonics. We demonstrate, that by rotating the embeddings based on\nthe 3D edge orientation, more information may be utilized while maintaining the\nrotational equivariance of the messages. While equivariance is a desirable\nproperty, we find that by relaxing this constraint in both message passing and\naggregation, improved accuracy may be achieved. We demonstrate state-of-the-art\nresults on the large-scale Open Catalyst 2020 dataset in both energy and force\nprediction for numerous tasks and metrics.",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "C. Lawrence Zitnick",
      "Abhishek Das",
      "Adeesh Kolluru",
      "Janice Lan",
      "Muhammed Shuaibi",
      "Anuroop Sriram",
      "Zachary Ulissi",
      "Brandon Wood"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.14331"
  },
  {
    "id": "arXiv:2206.14357",
    "title": "Comparing Conventional Pitch Detection Algorithms with a Neural Network  Approach",
    "abstract": "Despite much research, traditional methods to pitch prediction are still not\nperfect. With the emergence of neural networks (NNs), researchers hope to\ncreate a NN-based pitch predictor that outperforms traditional methods. Three\npitch detection algorithms (PDAs), pYIN, YAAPT, and CREPE are compared in this\npaper. pYIN and YAAPT are conventional approaches considering time domain and\nfrequency domain processing. CREPE utilizes a data-trained deep convolutional\nneural network to estimate pitch. It involves 6 densely connected convolutional\nhidden layers and determines pitch probabilities for a given input signal. The\nperformance of CREPE representing neural network pitch predictors is compared\nto more classical approaches represented by pYIN and YAAPT. The figure of merit\n(FOM) will include the amount of unvoiced-to-voiced errors, voiced-to-voiced\nerrors, gross pitch errors, and fine pitch errors.",
    "descriptor": "\nComments: 6 pages, 11 figures\n",
    "authors": [
      "Anja Kroon"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.14357"
  },
  {
    "id": "arXiv:2206.14371",
    "title": "Matryoshka: Stealing Functionality of Private ML Data by Hiding Models  in Model",
    "abstract": "In this paper, we present a novel insider attack called Matryoshka, which\nemploys an irrelevant scheduled-to-publish DNN model as a carrier model for\ncovert transmission of multiple secret models which memorize the functionality\nof private ML data stored in local data centers. Instead of treating the\nparameters of the carrier model as bit strings and applying conventional\nsteganography, we devise a novel parameter sharing approach which exploits the\nlearning capacity of the carrier model for information hiding. Matryoshka\nsimultaneously achieves: (i) High Capacity -- With almost no utility loss of\nthe carrier model, Matryoshka can hide a 26x larger secret model or 8 secret\nmodels of diverse architectures spanning different application domains in the\ncarrier model, neither of which can be done with existing steganography\ntechniques; (ii) Decoding Efficiency -- once downloading the published carrier\nmodel, an outside colluder can exclusively decode the hidden models from the\ncarrier model with only several integer secrets and the knowledge of the hidden\nmodel architecture; (iii) Effectiveness -- Moreover, almost all the recovered\nmodels have similar performance as if it were trained independently on the\nprivate data; (iv) Robustness -- Information redundancy is naturally\nimplemented to achieve resilience against common post-processing techniques on\nthe carrier before its publishing; (v) Covertness -- A model inspector with\ndifferent levels of prior knowledge could hardly differentiate a carrier model\nfrom a normal model.",
    "descriptor": "\nComments: A preprint work\n",
    "authors": [
      "Xudong Pan",
      "Yifan Yan",
      "Shengyao Zhang",
      "Mi Zhang",
      "Min Yang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14371"
  },
  {
    "id": "arXiv:2206.14373",
    "title": "Theoretical Perspectives on Deep Learning Methods in Inverse Problems",
    "abstract": "In recent years, there have been significant advances in the use of deep\nlearning methods in inverse problems such as denoising, compressive sensing,\ninpainting, and super-resolution. While this line of works has predominantly\nbeen driven by practical algorithms and experiments, it has also given rise to\na variety of intriguing theoretical problems. In this paper, we survey some of\nthe prominent theoretical developments in this line of works, focusing in\nparticular on generative priors, untrained neural network priors, and unfolding\nalgorithms. In addition to summarizing existing results in these topics, we\nhighlight several ongoing challenges and open problems.",
    "descriptor": "",
    "authors": [
      "Jonathan Scarlett",
      "Reinhard Heckel",
      "Miguel R. D. Rodrigues",
      "Paul Hand",
      "Yonina C. Eldar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2206.14373"
  },
  {
    "id": "arXiv:2206.14376",
    "title": "A note on the Tuza constant $c_k$ for small $k$",
    "abstract": "For a hypergraph $H$, the transversal is a subset of vertices whose\nintersection with every edge is nonempty. The cardinality of a minimum\ntransversal is the transversal number of $H$, denoted by $\\tau(H)$. The Tuza\nconstant $c_k$ is defined as $\\sup{\\tau(H)/ (m+n)}$, where $H$ ranges over all\n$k$-uniform hypergrpahs, with $m$ and $n$ begin the number of edges and\nvertices, respectively. We give upper and lower bounds on $c_k$, for $7\\leq\nk\\leq 17$.",
    "descriptor": "\nComments: 5 pages, 1 figure, 2 tables\n",
    "authors": [
      "Yun-Shan Lu",
      "Hung-Lung Wang"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2206.14376"
  },
  {
    "id": "arXiv:2206.14379",
    "title": "A projection method for porous media flow",
    "abstract": "Flow through porous, elastically deforming media is present in a variety of\nnatural contexts ranging from large-scale geophysics to cellular biology. In\nthe case of incompressible constituents, the porefluid pressure acts as a\nLagrange multiplier to satisfy the resulting constraint on fluid divergence.\nThe resulting system of equations is a possibly non-linear saddle-point problem\nand difficult to solve numerically, requiring nonlinear implicit solvers or\nflux-splitting methods. Here, we present a method for the simulation of flow\nthrough porous media and its coupled elastic deformation. The pore pressure\nfield is calculated at each time step by correcting trial velocities in a\nmanner similar to Chorin projection methods. We demonstrate the method's\nsecond-order convergence in space and time and show its application to phase\nseparating neo-Hookean gels.",
    "descriptor": "\nComments: 16 pages, 3 figures\n",
    "authors": [
      "Nicholas J. Derr",
      "Chris H. Rycroft"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Soft Condensed Matter (cond-mat.soft)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.14379"
  },
  {
    "id": "arXiv:2206.14383",
    "title": "Overview of Deep Learning-based CSI Feedback in Massive MIMO Systems",
    "abstract": "Many performance gains achieved by massive multiple-input and multiple-output\ndepend on the accuracy of the downlink channel state information (CSI) at the\ntransmitter (base station), which is usually obtained by estimating at the\nreceiver (user terminal) and feeding back to the transmitter. The overhead of\nCSI feedback occupies substantial uplink bandwidth resources, especially when\nthe number of the transmit antennas is large. Deep learning (DL)-based CSI\nfeedback refers to CSI compression and reconstruction by a DL-based autoencoder\nand can greatly reduce feedback overhead. In this paper, a comprehensive\noverview of state-of-the-art research on this topic is provided, beginning with\nbasic DL concepts widely used in CSI feedback and then categorizing and\ndescribing some existing DL-based feedback works. The focus is on novel neural\nnetwork architectures and utilization of communication expert knowledge to\nimprove CSI feedback accuracy. Works on bit-level CSI feedback and joint design\nof CSI feedback with other communication modules are also introduced, and some\npractical issues, including training dataset collection, online training,\ncomplexity, generalization, and standardization effect, are discussed. At the\nend of the paper, some challenges and potential research directions associated\nwith DL-based CSI feedback in future wireless communication systems are\nidentified.",
    "descriptor": "\nComments: 28 pages, 33 figures, 6 tables. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Jiajia Guo",
      "Chao-Kai Wen",
      "Shi Jin",
      "Geoffrey Ye Li"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14383"
  },
  {
    "id": "arXiv:2206.14420",
    "title": "Robust optimization for quantum reinforcement learning control using  partial observations",
    "abstract": "The current quantum reinforcement learning control models often assume that\nthe quantum states are known a priori for control optimization. However, full\nobservation of quantum state is experimentally infeasible due to the\nexponential scaling of the number of required quantum measurements on the\nnumber of qubits. In this paper, we investigate a robust reinforcement learning\nmethod using partial observations to overcome this difficulty. This control\nscheme is compatible with near-term quantum devices, where the noise is\nprevalent and predetermining the dynamics of quantum state is practically\nimpossible. We show that this simplified control scheme can achieve similar or\neven better performance when compared to the conventional methods relying on\nfull observation. We demonstrate the effectiveness of this scheme on examples\nof quantum state control and quantum approximate optimization algorithm. It has\nbeen shown that high-fidelity state control can be achieved even if the noise\namplitude is at the same level as the control amplitude. Besides, an acceptable\nlevel of optimization accuracy can be achieved for QAOA with noisy control\nHamiltonian. This robust control optimization model can be trained to\ncompensate the uncertainties in practical quantum computing.",
    "descriptor": "",
    "authors": [
      "Chen Jiang",
      "Yu Pan",
      "Zheng-Guang Wu",
      "Qing Gao",
      "Daoyi Dong"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.14420"
  },
  {
    "id": "arXiv:2206.14430",
    "title": "Social Media and Democracy",
    "abstract": "We study the ability of a social media platform with a political agenda to\ninfluence voting outcomes. Our benchmark is Condorcet's jury theorem, which\nstates that the likelihood of a correct decision under majority voting\nincreases with the number of voters. We show how information manipulation by a\nsocial media platform can overturn the jury theorem, thereby undermining\ndemocracy. We also show that sometimes the platform can do so only by providing\ninformation that is biased in the opposite direction of its preferred outcome.\nFinally, we compare manipulation of voting outcomes through social media to\nmanipulation through traditional media.",
    "descriptor": "",
    "authors": [
      "Ronen Gradwohl",
      "Yuval Heller",
      "Arye Hillman"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2206.14430"
  },
  {
    "id": "arXiv:2206.14449",
    "title": "Hypothesis Testing for Differentially Private Linear Regression",
    "abstract": "In this work, we design differentially private hypothesis tests for the\nfollowing problems in the general linear model: testing a linear relationship\nand testing for the presence of mixtures. The majority of our hypothesis tests\nare based on differentially private versions of the $F$-statistic for the\ngeneral linear model framework, which are uniformly most powerful unbiased in\nthe non-private setting. We also present other tests for these problems, one of\nwhich is based on the differentially private nonparametric tests of Couch,\nKazan, Shi, Bray, and Groce (CCS 2019), which is especially suited for the\nsmall dataset regime. We show that the differentially private $F$-statistic\nconverges to the asymptotic distribution of its non-private counterpart. As a\ncorollary, the statistical power of the differentially private $F$-statistic\nconverges to the statistical power of the non-private $F$-statistic. Through a\nsuite of Monte Carlo based experiments, we show that our tests achieve desired\nsignificance levels and have a high power that approaches the power of the\nnon-private tests as we increase sample sizes or the privacy-loss parameter. We\nalso show when our tests outperform existing methods in the literature.",
    "descriptor": "\nComments: 62 pages, 18 figures\n",
    "authors": [
      "Daniel Alabi",
      "Salil Vadhan"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.14449"
  },
  {
    "id": "arXiv:2206.14476",
    "title": "Can Push-forward Generative Models Fit Multimodal Distributions?",
    "abstract": "Many generative models synthesize data by transforming a standard Gaussian\nrandom variable using a deterministic neural network. Among these models are\nthe Variational Autoencoders and the Generative Adversarial Networks. In this\nwork, we call them \"push-forward\" models and study their expressivity. We show\nthat the Lipschitz constant of these generative networks has to be large in\norder to fit multimodal distributions. More precisely, we show that the total\nvariation distance and the Kullback-Leibler divergence between the generated\nand the data distribution are bounded from below by a constant depending on the\nmode separation and the Lipschitz constant. Since constraining the Lipschitz\nconstants of neural networks is a common way to stabilize generative models,\nthere is a provable trade-off between the ability of push-forward models to\napproximate multimodal distributions and the stability of their training. We\nvalidate our findings on one-dimensional and image datasets and empirically\nshow that generative models consisting of stacked networks with stochastic\ninput at each step, such as diffusion models do not suffer of such limitations.",
    "descriptor": "\nComments: Submitted to the Thirty-sixth Conference on Neural Information Processing Systems\n",
    "authors": [
      "Antoine Salmona",
      "Valentin de Bortoli",
      "Julie Delon",
      "Agn\u00e8s Desolneux"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14476"
  },
  {
    "id": "arXiv:2206.14484",
    "title": "On the relation of order theory and computation in terms of  denumerability",
    "abstract": "Computability on uncountable sets has no standard formalization, unlike that\non countable sets, which is given by Turing machines. Some of the approaches to\ndefine computability in these sets rely on order-theoretic structures to\ntranslate such notions from Turing machines to uncountable spaces. Since these\nmachines are used as a baseline for computability in these approaches,\ncountability restrictions on the ordered structures are fundamental. Here, we\naim to combine the theories of computability with order theory in order to\nstudy how the usual countability restrictions in these approaches are related\nto order density properties and functional characterizations of the order\nstructure in terms of multi-utilities.",
    "descriptor": "",
    "authors": [
      "Pedro Hack",
      "Daniel A. Braun",
      "Sebastian Gottwald"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.14484"
  },
  {
    "id": "arXiv:2206.14507",
    "title": "Variational Quantum Approximate Support Vector Machine With Inference  Transfer",
    "abstract": "A kernel-based quantum classifier is the most interesting and powerful\nquantum machine learning technique for hyperlinear classification of complex\ndata, which can be easily realized in shallow-depth quantum circuits such as a\nSWAP test classifier. Surprisingly, a support vector machine can be realized\ninherently and explicitly on these circuits by introduction of a variational\nscheme to map the quadratic optimization problem of the SVM theory to a\nquantum-classical variational optimization problem. This scheme is realized\nwith parameterized quantum circuits (PQC) to create a nonuniform weight vector\nto index qubits that can evaluate training loss and classification score in a\nlinear time. We train the classical parameters of this Variational Quantum\nApproximate Support Vector Machine (VQASVM), which can be transferred to many\ncopies of other VQASVM decision inference circuits for classification of new\nquery data. Our VQASVM algorithm is experimented with toy example data sets on\ncloud-based quantum machines for feasibility evaluation, and numerically\ninvestigated to evaluate its performance on a standard iris flower data set.\nThe accuracy of iris data classification reached 98.8%.",
    "descriptor": "\nComments: 21 pages, 5 figures\n",
    "authors": [
      "Siheon Park",
      "Daniel K. Park",
      "June-Koo Kevin Rhee"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14507"
  },
  {
    "id": "arXiv:2206.14524",
    "title": "A light-weight full-band speech enhancement model",
    "abstract": "Deep neural network based full-band speech enhancement systems face\nchallenges of high demand of computational resources and imbalanced frequency\ndistribution. In this paper, a light-weight full-band model is proposed with\ntwo dedicated strategies, i.e., a learnable spectral compression mapping for\nmore effective high-band spectral information compression, and the utilization\nof the multi-head attention mechanism for more effective modeling of the global\nspectral pattern. Experiments validate the efficacy of the proposed strategies\nand show that the proposed model achieves competitive performance with only\n0.89M parameters.",
    "descriptor": "",
    "authors": [
      "Qinwen Hu",
      "Zhongshu Hou",
      "Xiaohuai Le",
      "Jing Lu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2206.14524"
  },
  {
    "id": "arXiv:2206.14566",
    "title": "Massively Increasing the number of Antibody-Virus Interactions across  Studies",
    "abstract": "A central challenge in every field of biology is to use existing measurements\nto predict the outcomes of future experiments. In this work, we consider the\nwealth of antibody inhibition data against variants of the influenza virus. Due\nto this virus's genetic diversity and evolvability, the variants examined in\none study will often have little-to-no overlap with other studies, making it\ndifficult to discern common patterns or unify datasets for further analysis. To\nthat end, we develop a computational framework that predicts how an antibody or\nserum would inhibit any variant from any other study. We use this framework to\ngreatly expand 7 influenza datasets utilizing hemagglutination inhibition,\nvalidating our method upon 200,000 existing measurements and predicting more\nthan 2,000,000 new values along with their prediction uncertainties. This\ndata-driven approach does not require any information beyond each virus's name\nand measurements, and even datasets with as few as 5 viruses can be expanded,\nmaking this approach widely applicable. Future influenza studies using\nhemagglutination inhibition can directly utilize our curated datasets to\npredict newly measured antibody responses against ~80 H3N2 influenza viruses\nfrom 1968-2011, whereas immunological studies utilizing other viruses or a\ndifferent assay only need to find a single partially-overlapping dataset to\nextend their work. In essence, this approach enables a shift in perspective\nwhen analyzing data from \"what you see is what you get\" into \"what anyone sees\nis what everyone gets.\"",
    "descriptor": "",
    "authors": [
      "Tal Einav",
      "Rong Ma"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2206.14566"
  },
  {
    "id": "arXiv:2206.14599",
    "title": "Information geometry of excess and housekeeping entropy production",
    "abstract": "A nonequilibrium system is characterized by a set of thermodynamic forces and\nfluxes, which give rise to entropy production (EP). We demonstrate that these\nforces and fluxes have an information-geometric structure, which allows us to\ndecompose EP into nonnegative contributions from different types of forces. We\nfocus on the excess and housekeeping decomposition, which reflects\ncontributions from conservative and nonconservative forces, in the general\nsetting of discrete systems (linear master equations and nonlinear chemical\ndynamics). Unlike the nonadiabatic/adiabatic (Hatano-Sasa) approach, our\ndecomposition is always well-defined, including in systems with odd variables\nand nonlinear systems without steady states. It is also operationally\nmeaningful, leading to far-from-equilibrium thermodynamic uncertainty relations\nand speed limits.",
    "descriptor": "",
    "authors": [
      "Artemy Kolchinsky",
      "Andreas Dechant",
      "Kohei Yoshimura",
      "Sosuke Ito"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.14599"
  },
  {
    "id": "arXiv:2206.14605",
    "title": "Auditing Ranked Voting Elections with Dirichlet-Tree Models: First Steps",
    "abstract": "Ranked voting systems, such as instant-runoff voting (IRV) and single\ntransferable vote (STV), are used in many places around the world. They are\nmore complex than plurality and scoring rules, presenting a challenge for\nauditing their outcomes: there is no known risk-limiting audit (RLA) method for\nSTV other than a full hand count.\nWe present a new approach to auditing ranked systems that uses a statistical\nmodel, a Dirichlet-tree, that can cope with high-dimensional parameters in a\ncomputationally efficient manner. We demonstrate this approach with a\nballot-polling Bayesian audit for IRV elections. Although the technique is not\nknown to be risk-limiting, we suggest some strategies that might allow it to be\ncalibrated to limit risk.",
    "descriptor": "\nComments: 5 pages, 2 figures, accepted for E-Vote-ID 2022\n",
    "authors": [
      "Floyd Everest",
      "Michelle Blom",
      "Philip B. Stark",
      "Peter J. Stuckey",
      "Vanessa Teague",
      "Damjan Vukcevic"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.14605"
  },
  {
    "id": "arXiv:2206.14618",
    "title": "On the Prediction Network Architecture in RNN-T for ASR",
    "abstract": "RNN-T models have gained popularity in the literature and in commercial\nsystems because of their competitiveness and capability of operating in online\nstreaming mode. In this work, we conduct an extensive study comparing several\nprediction network architectures for both monotonic and original RNN-T models.\nWe compare 4 types of prediction networks based on a common state-of-the-art\nConformer encoder and report results obtained on Librispeech and an internal\nmedical conversation data set. Our study covers both offline batch-mode and\nonline streaming scenarios. In contrast to some previous works, our results\nshow that Transformer does not always outperform LSTM when used as prediction\nnetwork along with Conformer encoder. Inspired by our scoreboard, we propose a\nnew simple prediction network architecture, N-Concat, that outperforms the\nothers in our on-line streaming benchmark. Transformer and n-gram reduced\narchitectures perform very similarly yet with some important distinct behaviour\nin terms of previous context. Overall we obtained up to 4.1 % relative WER\nimprovement compared to our LSTM baseline, while reducing prediction network\nparameters by nearly an order of magnitude (8.4 times).",
    "descriptor": "\nComments: To appear at Interspeech 2022\n",
    "authors": [
      "Dario Albesano",
      "Jes\u00fas Andr\u00e9s-Ferrer",
      "Nicola Ferri",
      "Puming Zhan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.14618"
  },
  {
    "id": "arXiv:2206.14623",
    "title": "Contextual Density Ratio for Language Model Biasing of Sequence to  Sequence ASR Systems",
    "abstract": "End-2-end (E2E) models have become increasingly popular in some ASR tasks\nbecause of their performance and advantages. These E2E models directly\napproximate the posterior distribution of tokens given the acoustic inputs.\nConsequently, the E2E systems implicitly define a language model (LM) over the\noutput tokens, which makes the exploitation of independently trained language\nmodels less straightforward than in conventional ASR systems. This makes it\ndifficult to dynamically adapt E2E ASR system to contextual profiles for better\nrecognizing special words such as named entities. In this work, we propose a\ncontextual density ratio approach for both training a contextual aware E2E\nmodel and adapting the language model to named entities. We apply the\naforementioned technique to an E2E ASR system, which transcribes doctor and\npatient conversations, for better adapting the E2E system to the names in the\nconversations. Our proposed technique achieves a relative improvement of up to\n46.5% on the names over an E2E baseline without degrading the overall\nrecognition accuracy of the whole test set. Moreover, it also surpasses a\ncontextual shallow fusion baseline by 22.1 % relative.",
    "descriptor": "\nComments: Interspeech 2021 (draft)\n",
    "authors": [
      "Jes\u00fas Andr\u00e9s-Ferrer",
      "Dario Albesano",
      "Puming Zhan",
      "Paul Vozila"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.14623"
  },
  {
    "id": "arXiv:2206.14639",
    "title": "DDKtor: Automatic Diadochokinetic Speech Analysis",
    "abstract": "Diadochokinetic speech tasks (DDK), in which participants repeatedly produce\nsyllables, are commonly used as part of the assessment of speech motor\nimpairments. These studies rely on manual analyses that are time-intensive,\nsubjective, and provide only a coarse-grained picture of speech. This paper\npresents two deep neural network models that automatically segment consonants\nand vowels from unannotated, untranscribed speech. Both models work on the raw\nwaveform and use convolutional layers for feature extraction. The first model\nis based on an LSTM classifier followed by fully connected layers, while the\nsecond model adds more convolutional layers followed by fully connected layers.\nThese segmentations predicted by the models are used to obtain measures of\nspeech rate and sound duration. Results on a young healthy individuals dataset\nshow that our LSTM model outperforms the current state-of-the-art systems and\nperforms comparably to trained human annotators. Moreover, the LSTM model also\npresents comparable results to trained human annotators when evaluated on\nunseen older individuals with Parkinson's Disease dataset.",
    "descriptor": "\nComments: Accepted to Interspeech 2022\n",
    "authors": [
      "Yael Segal",
      "Kasia Hitczenko",
      "Matthew Goldrick",
      "Adam Buchwald",
      "Angela Roberts",
      "Joseph Keshet"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2206.14639"
  },
  {
    "id": "arXiv:2206.14643",
    "title": "Simple and Effective Multi-sentence TTS with Expressive and Coherent  Prosody",
    "abstract": "Generating expressive and contextually appropriate prosody remains a\nchallenge for modern text-to-speech (TTS) systems. This is particularly evident\nfor long, multi-sentence inputs. In this paper, we examine simple extensions to\na Transformer-based FastSpeech-like system, with the goal of improving prosody\nfor multi-sentence TTS. We find that long context, powerful text features, and\ntraining on multi-speaker data all improve prosody. More interestingly, they\nresult in synergies. Long context disambiguates prosody, improves coherence,\nand plays to the strengths of Transformers. Fine-tuning word-level features\nfrom a powerful language model, such as BERT, appears to profit from more\ntraining data, readily available in a multi-speaker setting. We look into\nobjective metrics on pausing and pacing and perform thorough subjective\nevaluations for speech naturalness. Our main system, which incorporates all the\nextensions, achieves consistently strong results, including statistically\nsignificant improvements in speech naturalness over all its competitors.",
    "descriptor": "\nComments: Accepted to be published in the Proceedings of InterSpeech 2022\n",
    "authors": [
      "Peter Makarov",
      "Ammar Abbas",
      "Mateusz \u0141ajszczak",
      "Arnaud Joly",
      "Sri Karlapati",
      "Alexis Moinet",
      "Thomas Drugman",
      "Penny Karanasou"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.14643"
  },
  {
    "id": "arXiv:2206.14674",
    "title": "Signature Methods in Machine Learning",
    "abstract": "Signature-based techniques give mathematical insight into the interactions\nbetween complex streams of evolving data. These insights can be quite naturally\ntranslated into numerical approaches to understanding streamed data, and\nperhaps because of their mathematical precision, have proved useful in\nanalysing streamed data in situations where the data is irregular, and not\nstationary, and the dimension of the data and the sample sizes are both\nmoderate.\nUnderstanding streamed multi-modal data is exponential: a word in $n$ letters\nfrom an alphabet of size $d$ can be any one of $d^n$ messages. Signatures\nremove the exponential amount of noise that arises from sampling irregularity,\nbut an exponential amount of information still remain. This survey aims to stay\nin the domain where that exponential scaling can be managed directly.\nScalability issues are an important challenge in many problems but would\nrequire another survey article and further ideas. This survey describes a range\nof contexts where the data sets are small enough to remove the possibility of\nmassive machine learning, and the existence of small sets of context free and\nprincipled features can be used effectively.\nThe mathematical nature of the tools can make their use intimidating to\nnon-mathematicians. The examples presented in this article are intended to\nbridge this communication gap and provide tractable working examples drawn from\nthe machine learning context. Notebooks are available online for several of\nthese examples. This survey builds on the earlier paper of Ilya Chevryev and\nAndrey Kormilitzin which had broadly similar aims at an earlier point in the\ndevelopment of this machinery. This article illustrates how the theoretical\ninsights offered by signatures are simply realised in the analysis of\napplication data in a way that is largely agnostic to the data type.",
    "descriptor": "",
    "authors": [
      "Terry Lyons",
      "Andrew D. McLeod"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Classical Analysis and ODEs (math.CA)",
      "Numerical Analysis (math.NA)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2206.14674"
  },
  {
    "id": "arXiv:2206.14678",
    "title": "BiometryNet: Landmark-based Fetal Biometry Estimation from Standard  Ultrasound Planes",
    "abstract": "Fetal growth assessment from ultrasound is based on a few biometric\nmeasurements that are performed manually and assessed relative to the expected\ngestational age. Reliable biometry estimation depends on the precise detection\nof landmarks in standard ultrasound planes. Manual annotation can be\ntime-consuming and operator dependent task, and may results in high\nmeasurements variability. Existing methods for automatic fetal biometry rely on\ninitial automatic fetal structure segmentation followed by geometric landmark\ndetection. However, segmentation annotations are time-consuming and may be\ninaccurate, and landmark detection requires developing measurement-specific\ngeometric methods. This paper describes BiometryNet, an end-to-end landmark\nregression framework for fetal biometry estimation that overcomes these\nlimitations. It includes a novel Dynamic Orientation Determination (DOD) method\nfor enforcing measurement-specific orientation consistency during network\ntraining. DOD reduces variabilities in network training, increases landmark\nlocalization accuracy, thus yields accurate and robust biometric measurements.\nTo validate our method, we assembled a dataset of 3,398 ultrasound images from\n1,829 subjects acquired in three clinical sites with seven different ultrasound\ndevices. Comparison and cross-validation of three different biometric\nmeasurements on two independent datasets shows that BiometryNet is robust and\nyields accurate measurements whose errors are lower than the clinically\npermissible errors, outperforming other existing automated biometry estimation\nmethods. Code is available at\nhttps://github.com/netanellavisdris/fetalbiometry.",
    "descriptor": "\nComments: 13 pages, 6 figures, Accepted to MICCAI 2022\n",
    "authors": [
      "Netanell Avisdris",
      "Leo Joskowicz",
      "Brian Dromey",
      "Anna L. David",
      "Donald M. Peebles",
      "Danail Stoyanov",
      "Dafna Ben Bashat",
      "Sophia Bano"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14678"
  },
  {
    "id": "arXiv:2206.14706",
    "title": "Molecular information theory meets protein folding",
    "abstract": "We propose an application of molecular information theory to analyze the\nfolding of single domain proteins. We analyze results from various areas of\nprotein science, such as sequence-based potentials, reduced amino acid\nalphabets, backbone configurational entropy, secondary structure content,\nresidue burial layers, and mutational studies of protein stability changes. We\nfound that the average information contained in the sequences of evolved\nproteins is very close to the average information needed to specify a fold ~2.2\n$\\pm$ 0.3 bits/(site operation). The effective alphabet size in evolved\nproteins equals the effective number of conformations of a residue in the\ncompact unfolded state at around 5. We calculated an energy-to-information\nconversion efficiency upon folding of around 50%, lower than the theoretical\nlimit of 70%, but much higher than human built macroscopic machines. We propose\na simple mapping between molecular information theory and energy landscape\ntheory and explore the connections between sequence evolution, configurational\nentropy and the energetics of protein folding.",
    "descriptor": "\nComments: 33pages, 2 figures, plus supporting information\n",
    "authors": [
      "Ignacio E. S\u00e1nchez",
      "Ezequiel A. Galpern",
      "Mart\u00edn M. Garibaldi",
      "Diego U. Ferreiro"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.14706"
  },
  {
    "id": "arXiv:2206.14713",
    "title": "CONVIQT: Contrastive Video Quality Estimator",
    "abstract": "Perceptual video quality assessment (VQA) is an integral component of many\nstreaming and video sharing platforms. Here we consider the problem of learning\nperceptually relevant video quality representations in a self-supervised\nmanner. Distortion type identification and degradation level determination is\nemployed as an auxiliary task to train a deep learning model containing a deep\nConvolutional Neural Network (CNN) that extracts spatial features, as well as a\nrecurrent unit that captures temporal information. The model is trained using a\ncontrastive loss and we therefore refer to this training framework and\nresulting model as CONtrastive VIdeo Quality EstimaTor (CONVIQT). During\ntesting, the weights of the trained model are frozen, and a linear regressor\nmaps the learned features to quality scores in a no-reference (NR) setting. We\nconduct comprehensive evaluations of the proposed model on multiple VQA\ndatabases by analyzing the correlations between model predictions and\nground-truth quality ratings, and achieve competitive performance when compared\nto state-of-the-art NR-VQA models, even though it is not trained on those\ndatabases. Our ablation experiments demonstrate that the learned\nrepresentations are highly robust and generalize well across synthetic and\nrealistic distortions. Our results indicate that compelling representations\nwith perceptual bearing can be obtained using self-supervised learning. The\nimplementations used in this work have been made available at\nhttps://github.com/pavancm/CONVIQT.",
    "descriptor": "",
    "authors": [
      "Pavan C. Madhusudana",
      "Neil Birkbeck",
      "Yilin Wang",
      "Balu Adsumilli",
      "Alan C. Bovik"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2206.14713"
  },
  {
    "id": "arXiv:2206.14738",
    "title": "Finding $k$-community structures in special graph classes",
    "abstract": "For a fixed integer $k\\ge 2$, a $k$-community structure in an undirected\ngraph is a partition of its vertex set into $k$ sets (called communities), each\nof size at least two, such that every vertex of the graph has proportionally at\nleast as many neighbours in its own community as in any other community. In\nthis paper, we present a necessary and sufficient condition for a forest $F$ to\nadmit a $k$-community structure, for any integer $k\\ge 2$. Furthermore, if such\na $k$-community exists, it can be found in polynomial time. This generalises a\nresult of Bazgan et al. (2018), who showed that all trees of size at least\nfour, except stars, admit a $2$-community that can be found in polynomial time.\nWe also show that, if communities are allowed to have size one, then every\nforest with at least $k\\geq 2$ vertices admits a $k$-community structure that\ncan be found in polynomial time. We then consider threshold graphs and show\nthat every such connected graph admits a $2$-community structure if and only if\nit is not isomorphic to a star; also, if such a $2$-community structure exists,\nit can be found in polynomial time. Finally, we introduce a new infinite family\nof connected graphs that do not admit any $2$-community structure (even if\ncommunities are allowed to have size one). Such a family was presented in\nBazgan et al. (2020), but its graphs all contained an even number of vertices.\nThe graphs in our new family may contain an even or an odd number of vertices.",
    "descriptor": "\nComments: 14 pages, 11 figures\n",
    "authors": [
      "Narmina Baghirova",
      "Cl\u00e9ment Dallard",
      "Bernard Ries",
      "David Schindl"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2206.14738"
  },
  {
    "id": "arXiv:2206.14740",
    "title": "Saturating systems and the rank covering radius",
    "abstract": "We introduce the concept of a rank saturating system and outline its\ncorrespondence to a rank-metric code with a given covering radius. We consider\nthe problem of finding the value of $s_{q^m/q}(k,\\rho)$, which is the minimum\n$\\mathbb{F}_q$-dimension of a $q$-system in $\\mathbb{F}_{q^m}^k$ which is rank\n$\\rho$-saturating. This is equivalent to the covering problem in the rank\nmetric. We obtain upper and lower bounds on $s_{q^m/q}(k,\\rho)$ and evaluate it\nfor certain values of $k$ and $\\rho$. We give constructions of rank\n$\\rho$-saturating systems suggested from geometry.",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Matteo Bonini",
      "Martino Borello",
      "Eimear Byrne"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.14740"
  },
  {
    "id": "arXiv:2206.14746",
    "title": "Placenta Segmentation in Ultrasound Imaging: Addressing Sources of  Uncertainty and Limited Field-of-View",
    "abstract": "Automatic segmentation of the placenta in fetal ultrasound (US) is\nchallenging due to the (i) high diversity of placenta appearance, (ii) the\nrestricted quality in US resulting in highly variable reference annotations,\nand (iii) the limited field-of-view of US prohibiting whole placenta assessment\nat late gestation. In this work, we address these three challenges with a\nmulti-task learning approach that combines the classification of placental\nlocation (e.g., anterior, posterior) and semantic placenta segmentation in a\nsingle convolutional neural network. Through the classification task the model\ncan learn from larger and more diverse datasets while improving the accuracy of\nthe segmentation task in particular in limited training set conditions. With\nthis approach we investigate the variability in annotations from multiple\nraters and show that our automatic segmentations (Dice of 0.86 for anterior and\n0.83 for posterior placentas) achieve human-level performance as compared to\nintra- and inter-observer variability. Lastly, our approach can deliver whole\nplacenta segmentation using a multi-view US acquisition pipeline consisting of\nthree stages: multi-probe image acquisition, image fusion and image\nsegmentation. This results in high quality segmentation of larger structures\nsuch as the placenta in US with reduced image artifacts which are beyond the\nfield-of-view of single probes.",
    "descriptor": "\nComments: 21 pages (18 + appendix), 13 figures (9 + appendix)\n",
    "authors": [
      "Veronika A. Zimmer",
      "Alberto Gomez",
      "Emily Skelton",
      "Robert Wright",
      "Gavin Wheeler",
      "Shujie Deng",
      "Nooshin Ghavami",
      "Karen Lloyd",
      "Jacqueline Matthew",
      "Bernhard Kainz",
      "Daniel Rueckert",
      "Joseph V. Hajnal",
      "Julia A. Schnabel"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.14746"
  },
  {
    "id": "arXiv:2206.14753",
    "title": "A phase field electro-chemo-mechanical formulation for predicting void  evolution at the Li-electrolyte interface in all-solid-state batteries",
    "abstract": "We present a mechanistic theory for predicting void evolution in the Li metal\nelectrode during the charge and discharge of all-solid-state battery cells. A\nphase field formulation is developed to model vacancy annihilation and\nnucleation, and to enable the tracking of the void-Li metal interface. This is\ncoupled with a viscoplastic description of Li deformation, to capture creep\neffects, and a mass transfer formulation accounting for substitutional (bulk\nand surface) Li diffusion and current-driven flux. Moreover, we incorporate the\ninteraction between the electrode and the solid electrolyte, resolving the\ncoupled electro-chemical-mechanical problem in both domains. This enables\npredicting the electrolyte current distribution and thus the emergence of local\ncurrent 'hot spots', which act as precursors for dendrite formation and cell\ndeath. The theoretical framework is numerically implemented, and single and\nmultiple void case studies are carried out to predict the evolution of voids\nand current hot spots as a function of the applied pressure, material\nproperties and charge (magnitude and cycle history). For both plating and\nstripping, insight is gained into the interplay between bulk diffusion, Li\ndissolution and deposition, creep, and the nucleation and annihilation of\nvacancies. The model is shown to capture the main experimental observations,\nincluding not only key features of electrolyte current and void morphology but\nalso the sensitivity to the applied current, the role of pressure in increasing\nthe electrode-electrolyte contact area, and the dominance of creep over vacancy\ndiffusion.",
    "descriptor": "",
    "authors": [
      "Y. Zhao",
      "R. Wang",
      "E. Mart\u00ednez-Pa\u00f1eda"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Applied Physics (physics.app-ph)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.14753"
  },
  {
    "id": "arXiv:2206.14760",
    "title": "A hybrid level-based learning swarm algorithm with mutation operator for  solving large-scale cardinality-constrained portfolio optimization problems",
    "abstract": "In this work, we propose a hybrid variant of the level-based learning swarm\noptimizer (LLSO) for solving large-scale portfolio optimization problems. Our\ngoal is to maximize a modified formulation of the Sharpe ratio subject to\ncardinality, box and budget constraints. The algorithm involves a projection\noperator to deal with these three constraints simultaneously and we implicitly\ncontrol transaction costs thanks to a rebalancing constraint. We also introduce\na suitable exact penalty function to manage the turnover constraint. In\naddition, we develop an ad hoc mutation operator to modify candidate exemplars\nin the highest level of the swarm. The experimental results, using three\nlarge-scale data sets, show that the inclusion of this procedure improves the\naccuracy of the solutions. Then, a comparison with other variants of the LLSO\nalgorithm and two state-of-the-art swarm optimizers points out the outstanding\nperformance of the proposed solver in terms of exploration capabilities and\nsolution quality. Finally, we assess the profitability of the portfolio\nallocation strategy in the last five years using an investible pool of 1119\nconstituents from the MSCI World Index.",
    "descriptor": "\nComments: Submitted\n",
    "authors": [
      "Massimiliano Kaucic",
      "Filippo Piccotto",
      "Gabriele Sbaiz",
      "Giorgio Valentinuz"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.14760"
  },
  {
    "id": "arXiv:2206.14780",
    "title": "A numerically robust, parallel-friendly variant of BiCGSTAB for the  semi-implicit integration of the viscous term in Smoothed Particle  Hydrodynamics",
    "abstract": "Implicit integration of the viscous term can significantly improve\nperformance in computational fluid dynamics for highly viscous fluids such as\nlava. We show improvements over our previous proposal for semi-implicit viscous\nintegration in Smoothed Particle Hydrodynamics, extending it to support a wider\nrange of boundary models. Due to the resulting loss of matrix symmetry, a key\nadvancement is a more robust version of the biconjugate gradient stabilized\nmethod to solve the linear systems, that is also better suited for\nparallelization in both shared-memory and distributed-memory systems. The\nadvantages of the new solver are demostrated in applications with both\nNewtonian and non-Newtonian fluids, covering both the numerical aspect\n(improved convergence thanks to the possibility to use more accurate boundary\nmodel) and the computing aspect (with excellent strong scaling and satisfactory\nweak scaling).",
    "descriptor": "",
    "authors": [
      "Giuseppe Bilotta",
      "Vito Zago",
      "Veronica Centorrino",
      "Robert A. Dalrymple",
      "Alexis H\u00e9rault",
      "Ciro Del Negro",
      "Elie Saikali"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.14780"
  },
  {
    "id": "arXiv:2206.14791",
    "title": "When Optimal Transport Meets Information Geometry",
    "abstract": "Information geometry and optimal transport are two distinct geometric\nframeworks for modeling families of probability measures. During the recent\nyears, there has been a surge of research endeavors that cut across these two\nareas and explore their links and interactions. This paper is intended to\nprovide an (incomplete) survey of these works, including entropy-regularized\ntransport, divergence functions arising from $c$-duality, density manifolds and\ntransport information geometry, the para-K\\\"ahler and K\\\"ahler geometries\nunderlying optimal transport and the regularity theory for its solutions. Some\noutstanding questions that would be of interest to audience of both these two\ndisciplines are posed. Our piece also serves as an introduction to the Special\nIssue on Optimal Transport of the journal Information Geometry.",
    "descriptor": "\nComments: 33 pages, 2 figures, to appear in Information Geometry\n",
    "authors": [
      "Gabriel Khan",
      "Jun Zhang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Information Theory (cs.IT)",
      "Differential Geometry (math.DG)"
    ],
    "url": "https://arxiv.org/abs/2206.14791"
  },
  {
    "id": "arXiv:2206.14794",
    "title": "LinearAlifold: Linear-Time Consensus Structure Prediction for RNA  Alignments",
    "abstract": "Predicting the consensus structure of a set of aligned RNA homologs is a\nconvenient method to find conserved structures in an RNA genome, which has\napplications in SARS-CoV-2 diagnostics and therapeutics. However, the\nstate-of-the-art algorithm for this task, RNAalifold, is prohibitively slow for\nlong sequences, due to a cubic scaling with the sequence length, and even\nslower when analyzing many such sequences, due to a superlinear scaling with\nthe number of homologs, taking 4 days on 200 SARS-CoV variants. We present\nLinearAlifold, an efficient algorithm for folding aligned RNA homologs that\nscales linearly with both the sequence length and the number of sequences,\nbased on our recent work LinearFold that folds a single RNA in linear time. Our\nwork is orders of magnitude faster than RNAalifold (e.g., 0.5 hours on the\nabove 200 sequences or 316 times speedup) and achieves comparable accuracies\ncompared to a database of known structures. More interestingly, LinearAlifold's\nprediction on SARS-CoV-2 correlates well with experimentally determined\nstructures, outperforming RNAalifold. Finally, LinearAlifold supports three\nmodes: minimum free energy (MFE), partition function, and stochastic sampling,\neach of which takes under an hour for hundreds of SARS-CoV variants, while only\nthe MFE mode of RNAalifold works for them, taking days or weeks.",
    "descriptor": "",
    "authors": [
      "Liang Zhang",
      "Sizhen Li",
      "He Zhang",
      "David H. Mathews",
      "Liang Huang"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Data Structures and Algorithms (cs.DS)",
      "Biological Physics (physics.bio-ph)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2206.14794"
  },
  {
    "id": "arXiv:2206.14798",
    "title": "Generalized Permutants and Graph GENEOs",
    "abstract": "In this paper we establish a bridge between Topological Data Analysis and\nGeometric Deep Learning, adapting the topological theory of group equivariant\nnon-expansive operators (GENEOs) to act on the space of all graphs weighted on\nvertices or edges. This is done by showing how the general concept of GENEO can\nbe used to transform graphs and to give information about their structure. This\nrequires the introduction of the new concepts of generalized permutant and\ngeneralized permutant measure and the mathematical proof that these concepts\nallow us to build GENEOs between graphs. An experimental section concludes the\npaper, illustrating the possible use of our operators to extract information\nfrom graphs. This paper is part of a line of research devoted to developing a\ncompositional and geometric theory of GENEOs for Geometric Deep Learning.",
    "descriptor": "\nComments: 15 pages, 4 figures\n",
    "authors": [
      "Faraz Ahmad",
      "Massimo Ferri",
      "Patrizio Frosini"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14798"
  },
  {
    "id": "arXiv:1711.02123",
    "title": "Consistency of Maximum Likelihood for Continuous-Space Network Models I",
    "abstract": "Comments: 17 pages",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Cosma Rohilla Shalizi",
      "Dena Marie Asta"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/1711.02123"
  },
  {
    "id": "arXiv:2003.02161",
    "title": "The Online Min-Sum Set Cover Problem",
    "abstract": "Comments: A preliminary version of this article appeared in the Proceedings of the 47th International Colloquium on Automata, Languages and Programming (ICALP 2020)",
    "descriptor": "\nComments: A preliminary version of this article appeared in the Proceedings of the 47th International Colloquium on Automata, Languages and Programming (ICALP 2020)\n",
    "authors": [
      "Dimitris Fotakis",
      "Loukas Kavouras",
      "Grigorios Koumoutsos",
      "Stratis Skoulakis",
      "Manolis Vardas"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2003.02161"
  },
  {
    "id": "arXiv:2005.01699",
    "title": "Depth-2 Neural Networks Under a Data-Poisoning Attack",
    "abstract": "Comments: 32 page, 7 figures",
    "descriptor": "\nComments: 32 page, 7 figures\n",
    "authors": [
      "Sayar Karmakar",
      "Anirbit Mukherjee",
      "Theodore Papamarkou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2005.01699"
  },
  {
    "id": "arXiv:2005.14407",
    "title": "Two-Hop Connectivity to the Roadside in a VANET Under the Random  Connection Model",
    "abstract": "Comments: 5 pages, 5 figures",
    "descriptor": "\nComments: 5 pages, 5 figures\n",
    "authors": [
      "Alexander P. Kartun-Giles",
      "Konstantinos Koufos",
      "Xiao Lu",
      "Dusit Niyato"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2005.14407"
  },
  {
    "id": "arXiv:2007.12652",
    "title": "MurTree: Optimal Classification Trees via Dynamic Programming and Search",
    "abstract": "MurTree: Optimal Classification Trees via Dynamic Programming and Search",
    "descriptor": "",
    "authors": [
      "Emir Demirovi\u0107",
      "Anna Lukina",
      "Emmanuel Hebrard",
      "Jeffrey Chan",
      "James Bailey",
      "Christopher Leckie",
      "Kotagiri Ramamohanarao",
      "Peter J. Stuckey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.12652"
  },
  {
    "id": "arXiv:2008.01681",
    "title": "SoloGAN: Multi-domain Multimodal Unpaired Image-to-Image Translation via  a Single Generative Adversarial Network",
    "abstract": "Comments: pages 14, 15 figures",
    "descriptor": "\nComments: pages 14, 15 figures\n",
    "authors": [
      "Shihua Huang",
      "Cheng He",
      "Ran Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2008.01681"
  },
  {
    "id": "arXiv:2009.14108",
    "title": "Align-RUDDER: Learning From Few Demonstrations by Reward Redistribution",
    "abstract": "Comments: Github: this https URL, YouTube: this https URL",
    "descriptor": "\nComments: Github: this https URL, YouTube: this https URL\n",
    "authors": [
      "Vihang P. Patil",
      "Markus Hofmarcher",
      "Marius-Constantin Dinu",
      "Matthias Dorfer",
      "Patrick M. Blies",
      "Johannes Brandstetter",
      "Jose A. Arjona-Medina",
      "Sepp Hochreiter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.14108"
  },
  {
    "id": "arXiv:2010.14663",
    "title": "Mutual Borders and Overlaps",
    "abstract": "Mutual Borders and Overlaps",
    "descriptor": "",
    "authors": [
      "Daniel Gabric"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2010.14663"
  },
  {
    "id": "arXiv:2011.10709",
    "title": "Deep Learning for Channel Sensing and Hybrid Precoding in TDD Massive  MIMO OFDM Systems",
    "abstract": "Comments: 15 Pages, 16 figures, Accepted at IEEE Transactions in Wireless Communications",
    "descriptor": "\nComments: 15 Pages, 16 figures, Accepted at IEEE Transactions in Wireless Communications\n",
    "authors": [
      "Kareem M. Attiah",
      "Foad Sohrabi",
      "Wei Yu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2011.10709"
  },
  {
    "id": "arXiv:2012.09401",
    "title": "Zoom-to-Inpaint: Image Inpainting with High-Frequency Details",
    "abstract": "Comments: Accepted to CVPRW 2022",
    "descriptor": "\nComments: Accepted to CVPRW 2022\n",
    "authors": [
      "Soo Ye Kim",
      "Kfir Aberman",
      "Nori Kanazawa",
      "Rahul Garg",
      "Neal Wadhwa",
      "Huiwen Chang",
      "Nikhil Karnad",
      "Munchurl Kim",
      "Orly Liba"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.09401"
  },
  {
    "id": "arXiv:2101.07711",
    "title": "Resource Bisimilarity in Petri Nets is Decidable",
    "abstract": "Comments: Typos fixed",
    "descriptor": "\nComments: Typos fixed\n",
    "authors": [
      "Irina Lomazova",
      "Vladimir Bashkin",
      "Petr Jan\u010dar"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2101.07711"
  },
  {
    "id": "arXiv:2101.08169",
    "title": "mt5se: An Open Source Framework for Building Autonomous Trading Robots",
    "abstract": "Comments: This paper replaces an old version of the framework, called mt5b3, which is now deprecated",
    "descriptor": "\nComments: This paper replaces an old version of the framework, called mt5b3, which is now deprecated\n",
    "authors": [
      "Paulo Andr\u00e9 Lima de Castro"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2101.08169"
  },
  {
    "id": "arXiv:2101.12115",
    "title": "Model-Based Policy Search Using Monte Carlo Gradient Estimation with  Real Systems Application",
    "abstract": "Comments: Accepted in IEEE Transactions on Robotics",
    "descriptor": "\nComments: Accepted in IEEE Transactions on Robotics\n",
    "authors": [
      "Fabio Amadio",
      "Alberto Dalla Libera",
      "Riccardo Antonello",
      "Daniel Nikovski",
      "Ruggero Carli",
      "Diego Romeres"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2101.12115"
  },
  {
    "id": "arXiv:2102.05571",
    "title": "Inferring Cyber Threat Intelligence -- A Knowledge Graph-based Approach",
    "abstract": "Comments: 18 pages",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Nidhi Rastogi",
      "Sharmishtha Dutta",
      "Ryan Christian",
      "Jared Gridley",
      "Mohammad Zaki",
      "Alex Gittens",
      "Charu Aggarwal"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.05571"
  },
  {
    "id": "arXiv:2102.09337",
    "title": "Reinforcement Learning for Datacenter Congestion Control",
    "abstract": "Comments: Presented at IAAI 2022",
    "descriptor": "\nComments: Presented at IAAI 2022\n",
    "authors": [
      "Chen Tessler",
      "Yuval Shpigelman",
      "Gal Dalal",
      "Amit Mandelbaum",
      "Doron Haritan Kazakov",
      "Benjamin Fuhrer",
      "Gal Chechik",
      "Shie Mannor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2102.09337"
  },
  {
    "id": "arXiv:2102.11075",
    "title": "SENTINEL: Taming Uncertainty with Ensemble-based Distributional  Reinforcement Learning",
    "abstract": "Comments: 22 pages, 10 figures, 8 tables Accepted for UAI2022",
    "descriptor": "\nComments: 22 pages, 10 figures, 8 tables Accepted for UAI2022\n",
    "authors": [
      "Hannes Eriksson",
      "Debabrota Basu",
      "Mina Alibeigi",
      "Christos Dimitrakakis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.11075"
  },
  {
    "id": "arXiv:2103.02554",
    "title": "Enabling Visual Action Planning for Object Manipulation through Latent  Space Roadmap",
    "abstract": "Enabling Visual Action Planning for Object Manipulation through Latent  Space Roadmap",
    "descriptor": "",
    "authors": [
      "Martina Lippi",
      "Petra Poklukar",
      "Michael C. Welle",
      "Anastasia Varava",
      "Hang Yin",
      "Alessandro Marino",
      "Danica Kragic"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.02554"
  },
  {
    "id": "arXiv:2103.03827",
    "title": "Multi-Session Visual SLAM for Illumination Invariant Re-Localization in  Indoor Environments",
    "abstract": "Comments: 20 pages, 7 figures",
    "descriptor": "\nComments: 20 pages, 7 figures\n",
    "authors": [
      "Mathieu Labb\u00e9",
      "Fran\u00e7ois Michaud"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.03827"
  },
  {
    "id": "arXiv:2103.06879",
    "title": "CoMoGAN: continuous model-guided image-to-image translation",
    "abstract": "Comments: CVPR 2021 oral",
    "descriptor": "\nComments: CVPR 2021 oral\n",
    "authors": [
      "Fabio Pizzati",
      "Pietro Cerri",
      "Raoul de Charette"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.06879"
  },
  {
    "id": "arXiv:2103.13756",
    "title": "The landscape of software for tensor computations",
    "abstract": "The landscape of software for tensor computations",
    "descriptor": "",
    "authors": [
      "Christos Psarras",
      "Lars Karlsson",
      "Jiajia Li",
      "Paolo Bientinesi"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2103.13756"
  },
  {
    "id": "arXiv:2104.03775",
    "title": "Geometry-based Distance Decomposition for Monocular 3D Object Detection",
    "abstract": "Comments: Accepted to ICCV 2021. Code: this https URL",
    "descriptor": "\nComments: Accepted to ICCV 2021. Code: this https URL\n",
    "authors": [
      "Xuepeng Shi",
      "Qi Ye",
      "Xiaozhi Chen",
      "Chuangrong Chen",
      "Zhixiang Chen",
      "Tae-Kyun Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.03775"
  },
  {
    "id": "arXiv:2104.09194",
    "title": "Synthesizing Diverse and Physically Stable Grasps with Arbitrary Hand  Structures using Differentiable Force Closure Estimator",
    "abstract": "Comments: Accepted by IEEE Robotics and Automation Letters (RA-L) Special Issue: Robotic Grasping and Manipulation Challenges and Progress",
    "descriptor": "\nComments: Accepted by IEEE Robotics and Automation Letters (RA-L) Special Issue: Robotic Grasping and Manipulation Challenges and Progress\n",
    "authors": [
      "Tengyu Liu",
      "Zeyu Liu",
      "Ziyuan Jiao",
      "Yixin Zhu",
      "Song-Chun Zhu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2104.09194"
  },
  {
    "id": "arXiv:2105.03726",
    "title": "Mental Models of Adversarial Machine Learning",
    "abstract": "Comments: accepted at SOUPS 2022",
    "descriptor": "\nComments: accepted at SOUPS 2022\n",
    "authors": [
      "Lukas Bieringer",
      "Kathrin Grosse",
      "Michael Backes",
      "Battista Biggio",
      "Katharina Krombholz"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.03726"
  },
  {
    "id": "arXiv:2105.09121",
    "title": "Single-Layer Vision Transformers for More Accurate Early Exits with Less  Overhead",
    "abstract": "Comments: Accepted by Neural Networks journal",
    "descriptor": "\nComments: Accepted by Neural Networks journal\n",
    "authors": [
      "Arian Bakhtiarnia",
      "Qi Zhang",
      "Alexandros Iosifidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.09121"
  },
  {
    "id": "arXiv:2106.00706",
    "title": "A Non-stiff Summation-By-Parts Finite Difference Method for the Scalar  Wave Equation in Second Order Form: Characteristic Boundary Conditions and  Nonlinear Interfaces",
    "abstract": "Comments: 40 pages, 7 figures",
    "descriptor": "\nComments: 40 pages, 7 figures\n",
    "authors": [
      "Brittany A Erickson",
      "Jeremy E Kozdon",
      "Tobias W Harvey"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.00706"
  },
  {
    "id": "arXiv:2106.00967",
    "title": "Multiresolution Equivariant Graph Variational Autoencoder",
    "abstract": "Multiresolution Equivariant Graph Variational Autoencoder",
    "descriptor": "",
    "authors": [
      "Truong Son Hy",
      "Risi Kondor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.00967"
  },
  {
    "id": "arXiv:2106.09109",
    "title": "QuantumFed: A Federated Learning Framework for Collaborative Quantum  Training",
    "abstract": "Comments: Under revision",
    "descriptor": "\nComments: Under revision\n",
    "authors": [
      "Qi Xia",
      "Qun Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.09109"
  },
  {
    "id": "arXiv:2106.10339",
    "title": "Statistical Evaluation of Privacy-preserving Publication and Sharing of  Three Types of COVID-19 Pandemic Data: Methods and Case Studies",
    "abstract": "Statistical Evaluation of Privacy-preserving Publication and Sharing of  Three Types of COVID-19 Pandemic Data: Methods and Case Studies",
    "descriptor": "",
    "authors": [
      "Fang Liu",
      "Dong Wang",
      "Tian Yan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.10339"
  },
  {
    "id": "arXiv:2106.15314",
    "title": "The cityseer Python package for pedestrian-scale network-based urban  analysis",
    "abstract": "Comments: Revision incorporating comments from reviewers",
    "descriptor": "\nComments: Revision incorporating comments from reviewers\n",
    "authors": [
      "Gareth D. Simons"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.15314"
  },
  {
    "id": "arXiv:2106.15515",
    "title": "What Is Consciousness? Artificial Intelligence, Real Intelligence,  Quantum Mind, And Qualia",
    "abstract": "What Is Consciousness? Artificial Intelligence, Real Intelligence,  Quantum Mind, And Qualia",
    "descriptor": "",
    "authors": [
      "Stuart A. Kauffman",
      "Andrea Roli"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Artificial Intelligence (cs.AI)",
      "Biological Physics (physics.bio-ph)",
      "History and Philosophy of Physics (physics.hist-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.15515"
  },
  {
    "id": "arXiv:2106.16091",
    "title": "Exploring the Latent Space of Autoencoders with Interventional Assays",
    "abstract": "Comments: Under review for NeurIPS 2022",
    "descriptor": "\nComments: Under review for NeurIPS 2022\n",
    "authors": [
      "Felix Leeb",
      "Stefan Bauer",
      "Michel Besserve",
      "Bernhard Sch\u00f6lkopf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.16091"
  },
  {
    "id": "arXiv:2107.10458",
    "title": "The Public Good index for games with several levels of approval in the  input and output",
    "abstract": "Comments: 16 pages; typos corrected",
    "descriptor": "\nComments: 16 pages; typos corrected\n",
    "authors": [
      "Sascha Kurz"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2107.10458"
  },
  {
    "id": "arXiv:2107.10844",
    "title": "DOVE: Learning Deformable 3D Objects by Watching Videos",
    "abstract": "Comments: Project Page: this https URL",
    "descriptor": "\nComments: Project Page: this https URL\n",
    "authors": [
      "Shangzhe Wu",
      "Tomas Jakab",
      "Christian Rupprecht",
      "Andrea Vedaldi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.10844"
  },
  {
    "id": "arXiv:2107.14229",
    "title": "Physics-informed Guided Disentanglement in Generative Networks",
    "abstract": "Comments: Journal submission",
    "descriptor": "\nComments: Journal submission\n",
    "authors": [
      "Fabio Pizzati",
      "Pietro Cerri",
      "Raoul de Charette"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.14229"
  },
  {
    "id": "arXiv:2108.02501",
    "title": "Locally Interpretable One-Class Anomaly Detection for Credit Card Fraud  Detection",
    "abstract": "Comments: 6 pages, 5 figures, 2 tables. Accepted to the 26th International Conference on Technologies and Applications of Artificial Intelligence (TAAI 2021). Best Paper Award",
    "descriptor": "\nComments: 6 pages, 5 figures, 2 tables. Accepted to the 26th International Conference on Technologies and Applications of Artificial Intelligence (TAAI 2021). Best Paper Award\n",
    "authors": [
      "Tungyu Wu",
      "Youting Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.02501"
  },
  {
    "id": "arXiv:2108.06009",
    "title": "Non-imaging real-time detection and tracking of fast-moving objects  using a single-pixel detector",
    "abstract": "Non-imaging real-time detection and tracking of fast-moving objects  using a single-pixel detector",
    "descriptor": "",
    "authors": [
      "Fengming Zhou"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.06009"
  },
  {
    "id": "arXiv:2108.07413",
    "title": "Cross-Image Region Mining with Region Prototypical Network for Weakly  Supervised Segmentation",
    "abstract": "Cross-Image Region Mining with Region Prototypical Network for Weakly  Supervised Segmentation",
    "descriptor": "",
    "authors": [
      "Weide Liu",
      "Xiangfei Kong",
      "Tzu-Yi Hung",
      "Guosheng Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.07413"
  },
  {
    "id": "arXiv:2108.08518",
    "title": "Few-shot Segmentation with Optimal Transport Matching and Message Flow",
    "abstract": "Few-shot Segmentation with Optimal Transport Matching and Message Flow",
    "descriptor": "",
    "authors": [
      "Weide Liu",
      "Chi Zhang",
      "Henghui Ding",
      "Tzu-Yi Hung",
      "Guosheng Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.08518"
  },
  {
    "id": "arXiv:2109.05547",
    "title": "Some variational recipes for quantum field theories",
    "abstract": "Comments: 28 pages, many figures. v2: modified style, add references, clear typos. v3: significant change, authors added",
    "descriptor": "\nComments: 28 pages, many figures. v2: modified style, add references, clear typos. v3: significant change, authors added\n",
    "authors": [
      "Junyu Liu",
      "Zimu Li",
      "Han Zheng",
      "Xiao Yuan",
      "Jinzhao Sun"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Theory (hep-th)"
    ],
    "url": "https://arxiv.org/abs/2109.05547"
  },
  {
    "id": "arXiv:2109.08549",
    "title": "Measuring Fairness under Unawareness of Sensitive Attributes: A  Quantification-Based Approach",
    "abstract": "Measuring Fairness under Unawareness of Sensitive Attributes: A  Quantification-Based Approach",
    "descriptor": "",
    "authors": [
      "Alessandro Fabris",
      "Andrea Esuli",
      "Alejandro Moreo",
      "Fabrizio Sebastiani"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.08549"
  },
  {
    "id": "arXiv:2109.09444",
    "title": "When Do Extended Physics-Informed Neural Networks (XPINNs) Improve  Generalization?",
    "abstract": "Comments: Accepted to be published in SIAM Journal on Scientific Computing (SISC)",
    "descriptor": "\nComments: Accepted to be published in SIAM Journal on Scientific Computing (SISC)\n",
    "authors": [
      "Zheyuan Hu",
      "Ameya D. Jagtap",
      "George Em Karniadakis",
      "Kenji Kawaguchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.09444"
  },
  {
    "id": "arXiv:2109.10380",
    "title": "Deep Policies for Online Bipartite Matching: A Reinforcement Learning  Approach",
    "abstract": "Deep Policies for Online Bipartite Matching: A Reinforcement Learning  Approach",
    "descriptor": "",
    "authors": [
      "Mohammad Ali Alomrani",
      "Reza Moravej",
      "Elias B. Khalil"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.10380"
  },
  {
    "id": "arXiv:2109.10903",
    "title": "In-network Computation for Large-scale Federated Learning over Wireless  Edge Networks",
    "abstract": "Comments: This work is partly presented in arXiv:2109.10489",
    "descriptor": "\nComments: This work is partly presented in arXiv:2109.10489\n",
    "authors": [
      "Thinh Quang Dinh",
      "Diep N. Nguyen",
      "Dinh Thai Hoang",
      "Pham Tran Vu",
      "Eryk Dutkiewicz"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2109.10903"
  },
  {
    "id": "arXiv:2109.14187",
    "title": "REFLACX, a dataset of reports and eye-tracking data for localization of  abnormalities in chest x-rays",
    "abstract": "Comments: Supplementary material included as ancillary files. Update 1: added clarifications and a graph showing the time correlation between gaze and report. Update 2: This preprint has not undergone peer review or any post-submission improvements or corrections. The Version of Record of this article is published in Scientific Data, and is available online at this https URL",
    "descriptor": "\nComments: Supplementary material included as ancillary files. Update 1: added clarifications and a graph showing the time correlation between gaze and report. Update 2: This preprint has not undergone peer review or any post-submission improvements or corrections. The Version of Record of this article is published in Scientific Data, and is available online at this https URL\n",
    "authors": [
      "Ricardo Bigolin Lanfredi",
      "Mingyuan Zhang",
      "William F. Auffermann",
      "Jessica Chan",
      "Phuong-Anh T. Duong",
      "Vivek Srikumar",
      "Trafton Drew",
      "Joyce D. Schroeder",
      "Tolga Tasdizen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.14187"
  },
  {
    "id": "arXiv:2109.14989",
    "title": "Structural Persistence in Language Models: Priming as a Window into  Abstract Language Representations",
    "abstract": "Comments: Published in TACL, MIT Press",
    "descriptor": "\nComments: Published in TACL, MIT Press\n",
    "authors": [
      "Arabella Sinclair",
      "Jaap Jumelet",
      "Willem Zuidema",
      "Raquel Fern\u00e1ndez"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.14989"
  },
  {
    "id": "arXiv:2109.15295",
    "title": "Deciding All Behavioral Equivalences at Once: A Game for  Linear-Time--Branching-Time Spectroscopy",
    "abstract": "Comments: Extended and revised version of TACAS21-paper \"A Game for Linear-time--Branching-time Spectroscopy\"",
    "descriptor": "\nComments: Extended and revised version of TACAS21-paper \"A Game for Linear-time--Branching-time Spectroscopy\"\n",
    "authors": [
      "Benjamin Bisping",
      "David N. Jansen",
      "Uwe Nestmann"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2109.15295"
  },
  {
    "id": "arXiv:2110.01530",
    "title": "Discovering Synergies for Robot Manipulation with Multi-Task  Reinforcement Learning",
    "abstract": "Discovering Synergies for Robot Manipulation with Multi-Task  Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Zhanpeng He",
      "Matei Ciocarlie"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.01530"
  },
  {
    "id": "arXiv:2110.01889",
    "title": "Deep Neural Networks and Tabular Data: A Survey",
    "abstract": "Deep Neural Networks and Tabular Data: A Survey",
    "descriptor": "",
    "authors": [
      "Vadim Borisov",
      "Tobias Leemann",
      "Kathrin Se\u00dfler",
      "Johannes Haug",
      "Martin Pawelczyk",
      "Gjergji Kasneci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.01889"
  },
  {
    "id": "arXiv:2110.02642",
    "title": "Anomaly Transformer: Time Series Anomaly Detection with Association  Discrepancy",
    "abstract": "Anomaly Transformer: Time Series Anomaly Detection with Association  Discrepancy",
    "descriptor": "",
    "authors": [
      "Jiehui Xu",
      "Haixu Wu",
      "Jianmin Wang",
      "Mingsheng Long"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02642"
  },
  {
    "id": "arXiv:2110.03122",
    "title": "Faster algorithm for Unique $(k,2)$-CSP",
    "abstract": "Faster algorithm for Unique $(k,2)$-CSP",
    "descriptor": "",
    "authors": [
      "Or Zamir"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.03122"
  },
  {
    "id": "arXiv:2110.03426",
    "title": "Fast learning from label proportions with small bags",
    "abstract": "Comments: Accepted to ICIP 2022",
    "descriptor": "\nComments: Accepted to ICIP 2022\n",
    "authors": [
      "Denis Baru\u010di\u0107",
      "Jan Kybic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03426"
  },
  {
    "id": "arXiv:2110.03593",
    "title": "TranSalNet: Towards perceptually relevant visual saliency prediction",
    "abstract": "Comments: Source code: this https URL",
    "descriptor": "\nComments: Source code: this https URL\n",
    "authors": [
      "Jianxun Lou",
      "Hanhe Lin",
      "David Marshall",
      "Dietmar Saupe",
      "Hantao Liu"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.03593"
  },
  {
    "id": "arXiv:2110.05330",
    "title": "Edge-wise funnel output synchronization of heterogeneous agents with  relative degree one",
    "abstract": "Comments: 14 pages, 3 figures",
    "descriptor": "\nComments: 14 pages, 3 figures\n",
    "authors": [
      "Jin Gyu Lee",
      "Thomas Berger",
      "Stephan Trenn",
      "Hyungbo Shim"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.05330"
  },
  {
    "id": "arXiv:2110.05568",
    "title": "Improving Stability of Low-Inertia Systems using Virtual Induction  Machine Synchronization for Grid-Following Converters",
    "abstract": "Improving Stability of Low-Inertia Systems using Virtual Induction  Machine Synchronization for Grid-Following Converters",
    "descriptor": "",
    "authors": [
      "Ognjen Stanojev",
      "Uros Markovic",
      "Petros Aristidou",
      "Gabriela Hug"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.05568"
  },
  {
    "id": "arXiv:2110.05942",
    "title": "Resolution of the Linear-Bounded Automata Question",
    "abstract": "Comments: A response to Mr. Preu's commentary added. Accuracies improved. A few typos will be corrected future",
    "descriptor": "\nComments: A response to Mr. Preu's commentary added. Accuracies improved. A few typos will be corrected future\n",
    "authors": [
      "Tianrong Lin"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2110.05942"
  },
  {
    "id": "arXiv:2110.07275",
    "title": "Order Constraints in Optimal Transport",
    "abstract": "Comments: To appear in Proceedings of ICML 2022. Main Paper + Supplementary",
    "descriptor": "\nComments: To appear in Proceedings of ICML 2022. Main Paper + Supplementary\n",
    "authors": [
      "Fabian Lim",
      "Laura Wynter",
      "Shiau Hong Lim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.07275"
  },
  {
    "id": "arXiv:2110.08232",
    "title": "Fire Together Wire Together: A Dynamic Pruning Approach with  Self-Supervised Mask Prediction",
    "abstract": "Fire Together Wire Together: A Dynamic Pruning Approach with  Self-Supervised Mask Prediction",
    "descriptor": "",
    "authors": [
      "Sara Elkerdawy",
      "Mostafa Elhoushi",
      "Hong Zhang",
      "Nilanjan Ray"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08232"
  },
  {
    "id": "arXiv:2110.08634",
    "title": "Towards Robust Waveform-Based Acoustic Models",
    "abstract": "Towards Robust Waveform-Based Acoustic Models",
    "descriptor": "",
    "authors": [
      "Dino Oglic",
      "Zoran Cvetkovic",
      "Peter Sollich",
      "Steve Renals",
      "Bin Yu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.08634"
  },
  {
    "id": "arXiv:2110.08811",
    "title": "Attention W-Net: Improved Skip Connections for better Representations",
    "abstract": "Comments: Accepted at ICPR'22",
    "descriptor": "\nComments: Accepted at ICPR'22\n",
    "authors": [
      "Shikhar Mohan",
      "Saumik Bhattacharya",
      "Sayantari Ghosh"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08811"
  },
  {
    "id": "arXiv:2110.14185",
    "title": "Massive MIMO NOMA with Wavelet Pulse Shaping to Minimize Undesired  Channel Interference",
    "abstract": "Comments: 8 pages, 3 figures, ICT Express (Accepted 9 June 2022)",
    "descriptor": "\nComments: 8 pages, 3 figures, ICT Express (Accepted 9 June 2022)\n",
    "authors": [
      "Muneeb Ahmad",
      "Soo Young Shin"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.14185"
  },
  {
    "id": "arXiv:2110.15449",
    "title": "Privacy-Preserving Inference on the Ratio of Two Gaussians Using Sums",
    "abstract": "Privacy-Preserving Inference on the Ratio of Two Gaussians Using Sums",
    "descriptor": "",
    "authors": [
      "Jingang Miao",
      "Yiming Paul Li"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Cryptography and Security (cs.CR)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2110.15449"
  },
  {
    "id": "arXiv:2111.01874",
    "title": "Numerical Smoothing with Hierarchical Adaptive Sparse Grids and  Quasi-Monte Carlo Methods for Efficient Option Pricing",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2003.05708",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2003.05708\n",
    "authors": [
      "Christian Bayer",
      "Chiheb Ben Hammouda",
      "Ra\u00fal Tempone"
    ],
    "subjectives": [
      "Computational Finance (q-fin.CP)",
      "Computational Complexity (cs.CC)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Numerical Analysis (math.NA)",
      "Pricing of Securities (q-fin.PR)"
    ],
    "url": "https://arxiv.org/abs/2111.01874"
  },
  {
    "id": "arXiv:2111.04793",
    "title": "Modularity and Combination of Associative Commutative Congruence Closure  Algorithms enriched with Semantic Properties",
    "abstract": "Modularity and Combination of Associative Commutative Congruence Closure  Algorithms enriched with Semantic Properties",
    "descriptor": "",
    "authors": [
      "Deepak Kapur"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2111.04793"
  },
  {
    "id": "arXiv:2111.06368",
    "title": "Should Type Theory replace Set Theory as the Foundation of Mathematics",
    "abstract": "Should Type Theory replace Set Theory as the Foundation of Mathematics",
    "descriptor": "",
    "authors": [
      "Thorsten Altenkirch"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2111.06368"
  },
  {
    "id": "arXiv:2111.08191",
    "title": "CoCA-MDD: A Coupled Cross-Attention based Framework for Streaming  Mispronunciation Detection and Diagnosis",
    "abstract": "Comments: 5 pages, 4 figures, Accepted by INTERSPEECH 2022",
    "descriptor": "\nComments: 5 pages, 4 figures, Accepted by INTERSPEECH 2022\n",
    "authors": [
      "Nianzu Zheng",
      "Liqun Deng",
      "Wenyong Huang",
      "Yu Ting Yeung",
      "Baohua Xu",
      "Yuanyuan Guo",
      "Yasheng Wang",
      "Xiao Chen",
      "Xin Jiang",
      "Qun Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.08191"
  },
  {
    "id": "arXiv:2111.10196",
    "title": "Towards Traffic Scene Description: The Semantic Scene Graph",
    "abstract": "Towards Traffic Scene Description: The Semantic Scene Graph",
    "descriptor": "",
    "authors": [
      "Maximilian Zipfl",
      "J. Marius Z\u00f6llner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.10196"
  },
  {
    "id": "arXiv:2111.10352",
    "title": "On the power of adaptivity in statistical adversaries",
    "abstract": "Comments: To appear in COLT 2022. Updated with reviewer feedback",
    "descriptor": "\nComments: To appear in COLT 2022. Updated with reviewer feedback\n",
    "authors": [
      "Guy Blanc",
      "Jane Lange",
      "Ali Malik",
      "Li-Yang Tan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.10352"
  },
  {
    "id": "arXiv:2111.11866",
    "title": "4D Segmentation Algorithm with application to 3D+time Image Segmentation",
    "abstract": "4D Segmentation Algorithm with application to 3D+time Image Segmentation",
    "descriptor": "",
    "authors": [
      "Markjoe Olunna Uba",
      "Karol Mikula",
      "Seol Ah Park"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.11866"
  },
  {
    "id": "arXiv:2111.12370",
    "title": "Uniform Convergence Rates for Lipschitz Learning on Graphs",
    "abstract": "Uniform Convergence Rates for Lipschitz Learning on Graphs",
    "descriptor": "",
    "authors": [
      "Leon Bungert",
      "Jeff Calder",
      "Tim Roith"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2111.12370"
  },
  {
    "id": "arXiv:2111.12490",
    "title": "Matching Learned Causal Effects of Neural Networks with Domain Priors",
    "abstract": "Comments: Accepted at International Conference on Machine Learning (ICML'22)",
    "descriptor": "\nComments: Accepted at International Conference on Machine Learning (ICML'22)\n",
    "authors": [
      "Sai Srinivas Kancheti",
      "Abbavaram Gowtham Reddy",
      "Vineeth N Balasubramanian",
      "Amit Sharma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.12490"
  },
  {
    "id": "arXiv:2111.14737",
    "title": "Beyond Time-Average Convergence: Near-Optimal Uncoupled Online Learning  via Clairvoyant Multiplicative Weights Update",
    "abstract": "Comments: Expanded on the uncoupled online nature of the dynamics",
    "descriptor": "\nComments: Expanded on the uncoupled online nature of the dynamics\n",
    "authors": [
      "Georgios Piliouras",
      "Ryann Sim",
      "Stratis Skoulakis"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2111.14737"
  },
  {
    "id": "arXiv:2112.05640",
    "title": "Fast and scalable neuroevolution deep learning architecture search for  multivariate anomaly detection",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2108.03585",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2108.03585\n",
    "authors": [
      "M.Pietro\u0144",
      "D.\u017burek",
      "K.Faber",
      "R.Corizzo"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.05640"
  },
  {
    "id": "arXiv:2112.06500",
    "title": "On Nash Equilibria in Normal-Form Games With Vectorial Payoffs",
    "abstract": "On Nash Equilibria in Normal-Form Games With Vectorial Payoffs",
    "descriptor": "",
    "authors": [
      "Willem R\u00f6pke",
      "Diederik M. Roijers",
      "Ann Now\u00e9",
      "Roxana R\u0103dulescu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2112.06500"
  },
  {
    "id": "arXiv:2112.09560",
    "title": "Dynamic resource allocation for efficient parallel CFD simulations",
    "abstract": "Comments: 27 pages, 15 figures",
    "descriptor": "\nComments: 27 pages, 15 figures\n",
    "authors": [
      "G. Houzeaux",
      "R.M. Badia",
      "R. Borrell",
      "D. Dosimont",
      "J. Ejarque",
      "M. Garcia-Gasulla",
      "V. L\u00f3pez"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.09560"
  },
  {
    "id": "arXiv:2112.13478",
    "title": "Video Joint Modelling Based on Hierarchical Transformer for  Co-summarization",
    "abstract": "Video Joint Modelling Based on Hierarchical Transformer for  Co-summarization",
    "descriptor": "",
    "authors": [
      "Li Haopeng",
      "Ke Qiuhong",
      "Gong Mingming",
      "Zhang Rui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.13478"
  },
  {
    "id": "arXiv:2201.00058",
    "title": "Representation Topology Divergence: A Method for Comparing Neural  Network Representations",
    "abstract": "Representation Topology Divergence: A Method for Comparing Neural  Network Representations",
    "descriptor": "",
    "authors": [
      "Serguei Barannikov",
      "Ilya Trofimov",
      "Nikita Balabin",
      "Evgeny Burnaev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.00058"
  },
  {
    "id": "arXiv:2201.00874",
    "title": "Technical Report: Bundling Linked Data Structures for Linearizable Range  Queries",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2012.15438",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2012.15438\n",
    "authors": [
      "Jacob Nelson-Slivon",
      "Ahmed Hassan",
      "Roberto Palmieri"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Databases (cs.DB)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2201.00874"
  },
  {
    "id": "arXiv:2201.00995",
    "title": "Fundamental Limitations of Control and Filtering in Continuous-Time  Systems: An Information-Theoretic Analysis",
    "abstract": "Comments: Dapeng Li and Neng Wan contributed equally to this paper",
    "descriptor": "\nComments: Dapeng Li and Neng Wan contributed equally to this paper\n",
    "authors": [
      "Neng Wan",
      "Dapeng Li",
      "Naira Hovakimyan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2201.00995"
  },
  {
    "id": "arXiv:2201.10443",
    "title": "Certifying algorithms and relevant properties of Reversible Primitive  Permutations with Lean",
    "abstract": "Comments: 17 pages, 13 figures. Authors' version of this https URL",
    "descriptor": "\nComments: 17 pages, 13 figures. Authors' version of this https URL\n",
    "authors": [
      "Giacomo Maletto",
      "Luca Roversi"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2201.10443"
  },
  {
    "id": "arXiv:2201.11726",
    "title": "Search Trajectories Networks of Multiobjective Evolutionary Algorithms",
    "abstract": "Search Trajectories Networks of Multiobjective Evolutionary Algorithms",
    "descriptor": "",
    "authors": [
      "Yuri Lavinas",
      "Claus Aranha",
      "Gabriela Ochoa"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11726"
  },
  {
    "id": "arXiv:2201.12023",
    "title": "Alpa: Automating Inter- and Intra-Operator Parallelism for Distributed  Deep Learning",
    "abstract": "Comments: OSDI 2022",
    "descriptor": "\nComments: OSDI 2022\n",
    "authors": [
      "Lianmin Zheng",
      "Zhuohan Li",
      "Hao Zhang",
      "Yonghao Zhuang",
      "Zhifeng Chen",
      "Yanping Huang",
      "Yida Wang",
      "Yuanzhong Xu",
      "Danyang Zhuo",
      "Eric P. Xing",
      "Joseph E. Gonzalez",
      "Ion Stoica"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2201.12023"
  },
  {
    "id": "arXiv:2201.12155",
    "title": "Reducing language context confusion for end-to-end code-switching  automatic speech recognition",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2010.14798,the paper has been accepted by Insterspeech 2022",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2010.14798,the paper has been accepted by Insterspeech 2022\n",
    "authors": [
      "Shuai Zhang",
      "Jiangyan Yi",
      "Zhengkun Tian",
      "Jianhua Tao",
      "Yu Ting Yeung",
      "Liqun Deng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2201.12155"
  },
  {
    "id": "arXiv:2201.12417",
    "title": "Why Should I Trust You, Bellman? The Bellman Error is a Poor Replacement  for Value Error",
    "abstract": "Comments: ICML 2022",
    "descriptor": "\nComments: ICML 2022\n",
    "authors": [
      "Scott Fujimoto",
      "David Meger",
      "Doina Precup",
      "Ofir Nachum",
      "Shixiang Shane Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.12417"
  },
  {
    "id": "arXiv:2201.12910",
    "title": "Sparse Centroid-Encoder: A Nonlinear Model for Feature Selection",
    "abstract": "Comments: 13 pages,56 figures, 5 tables. Used 12 data sets and 5 state-of-the-art models for comparison",
    "descriptor": "\nComments: 13 pages,56 figures, 5 tables. Used 12 data sets and 5 state-of-the-art models for comparison\n",
    "authors": [
      "Tomojit Ghosh",
      "Michael Kirby"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.12910"
  },
  {
    "id": "arXiv:2202.02190",
    "title": "An Overview of Ultra-WideBand (UWB) Standards and Organizations (IEEE  802.15.4, FiRa, Apple): Interoperability Aspects and Future Research  Directions",
    "abstract": "Comments: 23 pages, 20 figures, 15 tables",
    "descriptor": "\nComments: 23 pages, 20 figures, 15 tables\n",
    "authors": [
      "Dieter Coppens",
      "Adnan Shahid",
      "Sam Lemey",
      "Ben Van Herbruggen Chris Marshall",
      "Eli De Poorter"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.02190"
  },
  {
    "id": "arXiv:2202.02396",
    "title": "A Temporal-Difference Approach to Policy Gradient Estimation",
    "abstract": "A Temporal-Difference Approach to Policy Gradient Estimation",
    "descriptor": "",
    "authors": [
      "Samuele Tosatto",
      "Andrew Patterson",
      "Martha White",
      "A. Rupam Mahmood"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02396"
  },
  {
    "id": "arXiv:2202.02448",
    "title": "Linear Model Against Malicious Adversaries with Local Differential  Privacy",
    "abstract": "Linear Model Against Malicious Adversaries with Local Differential  Privacy",
    "descriptor": "",
    "authors": [
      "Guanhong Miao",
      "A. Adam Ding",
      "Samuel S. Wu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.02448"
  },
  {
    "id": "arXiv:2202.03299",
    "title": "Training OOD Detectors in their Natural Habitats",
    "abstract": "Comments: Accepted to International Conference on Machine Learning (ICML) 2022",
    "descriptor": "\nComments: Accepted to International Conference on Machine Learning (ICML) 2022\n",
    "authors": [
      "Julian Katz-Samuels",
      "Julia Nakhleh",
      "Robert Nowak",
      "Yixuan Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03299"
  },
  {
    "id": "arXiv:2202.03609",
    "title": "Backdoor Detection in Reinforcement Learning",
    "abstract": "Backdoor Detection in Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Junfeng Guo",
      "Ang Li",
      "Cong Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03609"
  },
  {
    "id": "arXiv:2202.04589",
    "title": "Adjoint-aided inference of Gaussian process driven differential  equations",
    "abstract": "Comments: 18 pages, 8 figures",
    "descriptor": "\nComments: 18 pages, 8 figures\n",
    "authors": [
      "Paterne Gahungu",
      "Christopher W Lanyon",
      "Mauricio A Alvarez",
      "Engineer Bainomugisha",
      "Michael Smith",
      "Richard D. Wilkinson"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04589"
  },
  {
    "id": "arXiv:2202.06442",
    "title": "Fast algorithm for overcomplete order-3 tensor decomposition",
    "abstract": "Comments: 59 pages, accepted by COLT 2022",
    "descriptor": "\nComments: 59 pages, accepted by COLT 2022\n",
    "authors": [
      "Jingqiu Ding",
      "Tommaso d'Orsi",
      "Chih-Hung Liu",
      "Stefan Tiegel",
      "David Steurer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.06442"
  },
  {
    "id": "arXiv:2202.08603",
    "title": "Cross-Silo Heterogeneous Model Federated Multitask Learning",
    "abstract": "Cross-Silo Heterogeneous Model Federated Multitask Learning",
    "descriptor": "",
    "authors": [
      "Xingjian Cao",
      "Zonghang Li",
      "Hongfang Yu",
      "Gang Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08603"
  },
  {
    "id": "arXiv:2202.09064",
    "title": "Can Interpretable Reinforcement Learning Manage Prosperity Your Way?",
    "abstract": "Can Interpretable Reinforcement Learning Manage Prosperity Your Way?",
    "descriptor": "",
    "authors": [
      "Charl Maree",
      "Christian Omlin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.09064"
  },
  {
    "id": "arXiv:2202.10018",
    "title": "Secret Key-based Authentication With Passive Eavesdropper for Scalar  Gaussian Sources",
    "abstract": "Comments: This work is presented at ISIT 2022",
    "descriptor": "\nComments: This work is presented at ISIT 2022\n",
    "authors": [
      "Vamoua Yachongka",
      "Hideki Yagi",
      "Yasutada Oohama"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.10018"
  },
  {
    "id": "arXiv:2202.12369",
    "title": "On Monocular Depth Estimation and Uncertainty Quantification using  Classification Approaches for Regression",
    "abstract": "Comments: 4 pages (main paper), 2 pages (supp.) Main paper is accepted at ICIP 2022",
    "descriptor": "\nComments: 4 pages (main paper), 2 pages (supp.) Main paper is accepted at ICIP 2022\n",
    "authors": [
      "Xuanlong Yu",
      "Gianni Franchi",
      "Emanuel Aldea"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12369"
  },
  {
    "id": "arXiv:2202.13903",
    "title": "Bayesian Structure Learning with Generative Flow Networks",
    "abstract": "Bayesian Structure Learning with Generative Flow Networks",
    "descriptor": "",
    "authors": [
      "Tristan Deleu",
      "Ant\u00f3nio G\u00f3is",
      "Chris Emezue",
      "Mansi Rankawat",
      "Simon Lacoste-Julien",
      "Stefan Bauer",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.13903"
  },
  {
    "id": "arXiv:2203.00472",
    "title": "DMF-Net: A decoupling-style multi-band fusion model for full-band speech  enhancement",
    "abstract": "DMF-Net: A decoupling-style multi-band fusion model for full-band speech  enhancement",
    "descriptor": "",
    "authors": [
      "Guochen Yu",
      "Yuansheng Guan",
      "Weixin Meng",
      "Chengshi Zheng",
      "Hui Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.00472"
  },
  {
    "id": "arXiv:2203.06105",
    "title": "A summary on the UD Kalman Filter",
    "abstract": "Comments: 12 pages, compendium of some key algorithms for UD Kalman filtering",
    "descriptor": "\nComments: 12 pages, compendium of some key algorithms for UD Kalman filtering\n",
    "authors": [
      "J. Humberto Ramos",
      "Kevin Brink",
      "Prashant Ganesh",
      "John E. Hurtado"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.06105"
  },
  {
    "id": "arXiv:2203.09023",
    "title": "Measuring Consumer Perceived Warm-Glow for Technology Adoption Modeling",
    "abstract": "Measuring Consumer Perceived Warm-Glow for Technology Adoption Modeling",
    "descriptor": "",
    "authors": [
      "Antonios Saravanos",
      "Dongnanzi Zheng",
      "Stavros Zervoudakis"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.09023"
  },
  {
    "id": "arXiv:2203.09728",
    "title": "On the Problem of Undirected st-connectivity",
    "abstract": "On the Problem of Undirected st-connectivity",
    "descriptor": "",
    "authors": [
      "Shilun Li",
      "Alex Lee"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2203.09728"
  },
  {
    "id": "arXiv:2203.11086",
    "title": "Overcoming Oscillations in Quantization-Aware Training",
    "abstract": "Comments: Published as oral paper at ICML 2022",
    "descriptor": "\nComments: Published as oral paper at ICML 2022\n",
    "authors": [
      "Markus Nagel",
      "Marios Fournarakis",
      "Yelysei Bondarenko",
      "Tijmen Blankevoort"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11086"
  },
  {
    "id": "arXiv:2203.11476",
    "title": "Modeling speech recognition and synthesis simultaneously: Encoding and  decoding lexical and sublexical semantic information into speech with no  direct access to speech data",
    "abstract": "Comments: Interspeech 2022",
    "descriptor": "\nComments: Interspeech 2022\n",
    "authors": [
      "Ga\u0161per Begu\u0161",
      "Alan Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.11476"
  },
  {
    "id": "arXiv:2203.15405",
    "title": "Automatic Detection of Speech Sound Disorder in Child Speech Using  Posterior-based Speaker Representations",
    "abstract": "Comments: Accepted to Interspeech 2022",
    "descriptor": "\nComments: Accepted to Interspeech 2022\n",
    "authors": [
      "Si-Ioi Ng",
      "Cymie Wing-Yee Ng",
      "Jiarui Wang",
      "Tan Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2203.15405"
  },
  {
    "id": "arXiv:2203.15431",
    "title": "Investigating Self-supervised Pretraining Frameworks for Pathological  Speech Recognition",
    "abstract": "Comments: Accepted to INTERSPEECH 2022",
    "descriptor": "\nComments: Accepted to INTERSPEECH 2022\n",
    "authors": [
      "Lester Phillip Violeta",
      "Wen-Chin Huang",
      "Tomoki Toda"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.15431"
  },
  {
    "id": "arXiv:2203.15467",
    "title": "Graded Monads and Behavioural Equivalence Games",
    "abstract": "Graded Monads and Behavioural Equivalence Games",
    "descriptor": "",
    "authors": [
      "Harsh Beohar",
      "Chase Ford",
      "Barbara K\u00f6nig",
      "Stefan Milius",
      "Lutz Schr\u00f6der"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2203.15467"
  },
  {
    "id": "arXiv:2203.15683",
    "title": "DRSpeech: Degradation-Robust Text-to-Speech Synthesis with Frame-Level  and Utterance-Level Acoustic Representation Learning",
    "abstract": "Comments: Accepted to INTERSPEECH 2022",
    "descriptor": "\nComments: Accepted to INTERSPEECH 2022\n",
    "authors": [
      "Takaaki Saeki",
      "Kentaro Tachibana",
      "Ryuichi Yamamoto"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.15683"
  },
  {
    "id": "arXiv:2203.15865",
    "title": "On Triangulation as a Form of Self-Supervision for 3D Human Pose  Estimation",
    "abstract": "On Triangulation as a Form of Self-Supervision for 3D Human Pose  Estimation",
    "descriptor": "",
    "authors": [
      "Soumava Kumar Roy",
      "Leonardo Citraro",
      "Sina Honari",
      "Pascal Fua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15865"
  },
  {
    "id": "arXiv:2203.16294",
    "title": "Acoustics-specific Piano Velocity Estimation",
    "abstract": "Comments: Submitted at MMSP 2022",
    "descriptor": "\nComments: Submitted at MMSP 2022\n",
    "authors": [
      "Federico Simonetta",
      "Stavros Ntalampiras",
      "Federico Avanzini"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.16294"
  },
  {
    "id": "arXiv:2204.01345",
    "title": "MOSRA: Joint Mean Opinion Score and Room Acoustics Speech Quality  Assessment",
    "abstract": "Comments: Submitted to Interspeech 2022",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Karl El Hajal",
      "Milos Cernak",
      "Pablo Mainar"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2204.01345"
  },
  {
    "id": "arXiv:2204.02152",
    "title": "UTMOS: UTokyo-SaruLab System for VoiceMOS Challenge 2022",
    "abstract": "Comments: Accepted to INTERSPEECH 2022",
    "descriptor": "\nComments: Accepted to INTERSPEECH 2022\n",
    "authors": [
      "Takaaki Saeki",
      "Detai Xin",
      "Wataru Nakata",
      "Tomoki Koriyama",
      "Shinnosuke Takamichi",
      "Hiroshi Saruwatari"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.02152"
  },
  {
    "id": "arXiv:2204.02320",
    "title": "Learning Generalizable Dexterous Manipulation from Human Grasp  Affordance",
    "abstract": "Comments: project page: this https URL",
    "descriptor": "\nComments: project page: this https URL\n",
    "authors": [
      "Yueh-Hua Wu",
      "Jiashun Wang",
      "Xiaolong Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.02320"
  },
  {
    "id": "arXiv:2204.03484",
    "title": "Commitment games with conditional information disclosure",
    "abstract": "Comments: Accepted at the Games, Agents, and Incentives Workshop at AAMAS 2022",
    "descriptor": "\nComments: Accepted at the Games, Agents, and Incentives Workshop at AAMAS 2022\n",
    "authors": [
      "Anthony DiGiovanni",
      "Jesse Clifton"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2204.03484"
  },
  {
    "id": "arXiv:2204.03804",
    "title": "A Learnable Variational Model for Joint Multimodal MRI Reconstruction  and Synthesis",
    "abstract": "Comments: Provisional Accepted by MICCAI2022",
    "descriptor": "\nComments: Provisional Accepted by MICCAI2022\n",
    "authors": [
      "Wanyu Bian",
      "Qingchao Zhang",
      "Xiaojing Ye",
      "Yunmei Chen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2204.03804"
  },
  {
    "id": "arXiv:2204.04841",
    "title": "Autonomous Mobile Clinics: Empowering Affordable Anywhere Anytime  Healthcare Access",
    "abstract": "Comments: 5 pages, 1 figure",
    "descriptor": "\nComments: 5 pages, 1 figure\n",
    "authors": [
      "Shaoshan Liu",
      "Yuzhang Huang",
      "Leiyu Shi"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.04841"
  },
  {
    "id": "arXiv:2204.08499",
    "title": "DeepCore: A Comprehensive Library for Coreset Selection in Deep Learning",
    "abstract": "Comments: DEXA 2022",
    "descriptor": "\nComments: DEXA 2022\n",
    "authors": [
      "Chengcheng Guo",
      "Bo Zhao",
      "Yanbing Bai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.08499"
  },
  {
    "id": "arXiv:2204.10348",
    "title": "Simulate Time-integrated Coarse-grained Molecular Dynamics with  Geometric Machine Learning",
    "abstract": "Comments: 23 pages, 10 figures",
    "descriptor": "\nComments: 23 pages, 10 figures\n",
    "authors": [
      "Xiang Fu",
      "Tian Xie",
      "Nathan J. Rebello",
      "Bradley D. Olsen",
      "Tommi Jaakkola"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2204.10348"
  },
  {
    "id": "arXiv:2204.13742",
    "title": "Twin-width and Limits of Tractability of FO Model Checking on Geometric  Graphs",
    "abstract": "Comments: technical corrections",
    "descriptor": "\nComments: technical corrections\n",
    "authors": [
      "Petr Hlin\u011bn\u00fd",
      "Filip Pokr\u00fdvka"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2204.13742"
  },
  {
    "id": "arXiv:2204.13792",
    "title": "Probabilistic Models for Manufacturing Lead Times",
    "abstract": "Probabilistic Models for Manufacturing Lead Times",
    "descriptor": "",
    "authors": [
      "Recep Yusuf Bekci",
      "Yacine Mahdid",
      "Jinling Xing",
      "Nikita Letov",
      "Ying Zhang",
      "Zahid Pasha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.13792"
  },
  {
    "id": "arXiv:2205.01373",
    "title": "Copy Motion From One to Another: Fake Motion Video Generation",
    "abstract": "Comments: 9 pages, 4 figures",
    "descriptor": "\nComments: 9 pages, 4 figures\n",
    "authors": [
      "Zhenguang Liu",
      "Sifan Wu",
      "Chejian Xu",
      "Xiang Wang",
      "Lei Zhu",
      "Shuang Wu",
      "Fuli Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.01373"
  },
  {
    "id": "arXiv:2205.03238",
    "title": "Ultra-sensitive Flexible Sponge-Sensor Array for Muscle Activities  Detection and Human Limb Motion Recognition",
    "abstract": "Comments: 17 pages, 6 figures",
    "descriptor": "\nComments: 17 pages, 6 figures\n",
    "authors": [
      "Jiao Suo",
      "Yifan Liu",
      "Clio Cheng",
      "Keer Wang",
      "Meng Chen",
      "Ho-yin Chan",
      "Roy Vellaisamy",
      "Ning Xi",
      "Vivian W. Q. Lou",
      "Wen Jung Li"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.03238"
  },
  {
    "id": "arXiv:2205.07890",
    "title": "On the Difficulty of Defending Self-Supervised Learning against Model  Extraction",
    "abstract": "Comments: Accepted at ICML 2022",
    "descriptor": "\nComments: Accepted at ICML 2022\n",
    "authors": [
      "Adam Dziedzic",
      "Nikita Dhawan",
      "Muhammad Ahmad Kaleem",
      "Jonas Guan",
      "Nicolas Papernot"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.07890"
  },
  {
    "id": "arXiv:2205.09974",
    "title": "Diagnosis and Prognosis of COVID-19 Disease Using Routine Blood Values  and LogNNet Neural Network",
    "abstract": "Comments: 28 pages, 10 figures, 12 Tables",
    "descriptor": "\nComments: 28 pages, 10 figures, 12 Tables\n",
    "authors": [
      "Mehmet Tahir Huyut",
      "Andrei Velichko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Medical Physics (physics.med-ph)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2205.09974"
  },
  {
    "id": "arXiv:2205.14831",
    "title": "Temporal Multiresolution Graph Neural Networks For Epidemic Prediction",
    "abstract": "Temporal Multiresolution Graph Neural Networks For Epidemic Prediction",
    "descriptor": "",
    "authors": [
      "Truong Son Hy",
      "Viet Bach Nguyen",
      "Long Tran-Thanh",
      "Risi Kondor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2205.14831"
  },
  {
    "id": "arXiv:2205.14969",
    "title": "Guided Diffusion Model for Adversarial Purification",
    "abstract": "Guided Diffusion Model for Adversarial Purification",
    "descriptor": "",
    "authors": [
      "Jinyi Wang",
      "Zhaoyang Lyu",
      "Dahua Lin",
      "Bo Dai",
      "Hongfei Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.14969"
  },
  {
    "id": "arXiv:2205.15466",
    "title": "Data Banzhaf: A Data Valuation Framework with Maximal Robustness to  Learning Stochasticity",
    "abstract": "Data Banzhaf: A Data Valuation Framework with Maximal Robustness to  Learning Stochasticity",
    "descriptor": "",
    "authors": [
      "Tianhao Wang",
      "Ruoxi Jia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.15466"
  },
  {
    "id": "arXiv:2205.15688",
    "title": "Self-Supervised Learning for Building Damage Assessment from Large-scale  xBD Satellite Imagery Benchmark Datasets",
    "abstract": "Comments: 14 pages, 7 figures, DEXA 2022",
    "descriptor": "\nComments: 14 pages, 7 figures, DEXA 2022\n",
    "authors": [
      "Zaishuo Xia",
      "Zelin Li",
      "Yanbing Bai",
      "Jinze Yu",
      "Bruno Adriano"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.15688"
  },
  {
    "id": "arXiv:2205.15812",
    "title": "GateNLP-UShef at SemEval-2022 Task 8: Entity-Enriched Siamese  Transformer for Multilingual News Article Similarity",
    "abstract": "Comments: Accepted at SemEval-2022 Task 8: Multilingual News Article Similarity (co-located with NAACL 2022)",
    "descriptor": "\nComments: Accepted at SemEval-2022 Task 8: Multilingual News Article Similarity (co-located with NAACL 2022)\n",
    "authors": [
      "Iknoor Singh",
      "Yue Li",
      "Melissa Thong",
      "Carolina Scarton"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2205.15812"
  },
  {
    "id": "arXiv:2206.00242",
    "title": "CrossCBR: Cross-view Contrastive Learning for Bundle Recommendation",
    "abstract": "Comments: 9 pages, 5 figures, 5 tables",
    "descriptor": "\nComments: 9 pages, 5 figures, 5 tables\n",
    "authors": [
      "Yunshan Ma",
      "Yingzhi He",
      "An Zhang",
      "Xiang Wang",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.00242"
  },
  {
    "id": "arXiv:2206.02477",
    "title": "Optimal Stopping Theory for a Distributionally Robust Seller",
    "abstract": "Comments: Revised version that accounts for overlap with earlier work (not by the authors)",
    "descriptor": "\nComments: Revised version that accounts for overlap with earlier work (not by the authors)\n",
    "authors": [
      "Pieter Kleer",
      "Johan van Leeuwaarden"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.02477"
  },
  {
    "id": "arXiv:2206.02583",
    "title": "Consensus Learning for Cooperative Multi-Agent Reinforcement Learning",
    "abstract": "Comments: 12 pages, 10 figures, 1 table",
    "descriptor": "\nComments: 12 pages, 10 figures, 1 table\n",
    "authors": [
      "Zhiwei Xu",
      "Bin Zhang",
      "Dapeng Li",
      "Zeren Zhang",
      "Guangchong Zhou",
      "Guoliang Fan"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02583"
  },
  {
    "id": "arXiv:2206.02891",
    "title": "A Justice-Based Framework for the Analysis of Algorithmic  Fairness-Utility Trade-Offs",
    "abstract": "A Justice-Based Framework for the Analysis of Algorithmic  Fairness-Utility Trade-Offs",
    "descriptor": "",
    "authors": [
      "Corinna Hertweck",
      "Joachim Baumann",
      "Michele Loi",
      "Eleonora Vigan\u00f2",
      "Christoph Heitz"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02891"
  },
  {
    "id": "arXiv:2206.02897",
    "title": "Distributive Justice as the Foundational Premise of Fair ML:  Unification, Extension, and Interpretation of Group Fairness Metrics",
    "abstract": "Distributive Justice as the Foundational Premise of Fair ML:  Unification, Extension, and Interpretation of Group Fairness Metrics",
    "descriptor": "",
    "authors": [
      "Joachim Baumann",
      "Corinna Hertweck",
      "Michele Loi",
      "Christoph Heitz"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02897"
  },
  {
    "id": "arXiv:2206.03935",
    "title": "Dual-Distribution Discrepancy for Anomaly Detection in Chest X-Rays",
    "abstract": "Comments: Early Accepted to MICCAI 2022",
    "descriptor": "\nComments: Early Accepted to MICCAI 2022\n",
    "authors": [
      "Yu Cai",
      "Hao Chen",
      "Xin Yang",
      "Yu Zhou",
      "Kwang-Ting Cheng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.03935"
  },
  {
    "id": "arXiv:2206.04310",
    "title": "GSmooth: Certified Robustness against Semantic Transformations via  Generalized Randomized Smoothing",
    "abstract": "GSmooth: Certified Robustness against Semantic Transformations via  Generalized Randomized Smoothing",
    "descriptor": "",
    "authors": [
      "Zhongkai Hao",
      "Chengyang Ying",
      "Yinpeng Dong",
      "Hang Su",
      "Jun Zhu",
      "Jian Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.04310"
  },
  {
    "id": "arXiv:2206.05077",
    "title": "Tensor Train for Global Optimization Problems in Robotics",
    "abstract": "Comments: 26 pages, 21 figures",
    "descriptor": "\nComments: 26 pages, 21 figures\n",
    "authors": [
      "Suhan Shetty",
      "Teguh Lembono",
      "Tobias Loew",
      "Sylvain Calinon"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.05077"
  },
  {
    "id": "arXiv:2206.06281",
    "title": "Cumulative culture spontaneously emerges in artificial navigators who  are social and memory-guided",
    "abstract": "Cumulative culture spontaneously emerges in artificial navigators who  are social and memory-guided",
    "descriptor": "",
    "authors": [
      "Edwin S. Dalmaijer"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.06281"
  },
  {
    "id": "arXiv:2206.07543",
    "title": "P-Index",
    "abstract": "Comments: Improved Sections: The P-Index, An automated partition of contributions, Essence of the P-Index, Implications, References. Added Sections: Enhancement, A novel concept. Added Fig.: Fig. 3",
    "descriptor": "\nComments: Improved Sections: The P-Index, An automated partition of contributions, Essence of the P-Index, Implications, References. Added Sections: Enhancement, A novel concept. Added Fig.: Fig. 3\n",
    "authors": [
      "Shiva P. Pudasaini"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.07543"
  },
  {
    "id": "arXiv:2206.08705",
    "title": "Explainability's Gain is Optimality's Loss? -- How Explanations Bias  Decision-making",
    "abstract": "Comments: To appear in the Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society (AIES '22)",
    "descriptor": "\nComments: To appear in the Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society (AIES '22)\n",
    "authors": [
      "Charles Wan",
      "Rodrigo Belo",
      "Leid Zejnilovi\u0107"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.08705"
  },
  {
    "id": "arXiv:2206.08804",
    "title": "Truly Unordered Probabilistic Rule Sets for Multi-class Classification",
    "abstract": "Comments: Accepted for publication at ECMLPKDD 2022 - submitted version with author added",
    "descriptor": "\nComments: Accepted for publication at ECMLPKDD 2022 - submitted version with author added\n",
    "authors": [
      "Lincen Yang",
      "Matthijs van Leeuwen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.08804"
  },
  {
    "id": "arXiv:2206.10397",
    "title": "Neural Moving Horizon Estimation for Robust Flight Control",
    "abstract": "Neural Moving Horizon Estimation for Robust Flight Control",
    "descriptor": "",
    "authors": [
      "Bingheng Wang",
      "Zhengtian Ma",
      "Shupeng Lai",
      "Lin Zhao"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.10397"
  },
  {
    "id": "arXiv:2206.10805",
    "title": "Jointist: Joint Learning for Multi-instrument Transcription and Its  Applications",
    "abstract": "Comments: Submitted to ISMIR",
    "descriptor": "\nComments: Submitted to ISMIR\n",
    "authors": [
      "Kin Wai Cheuk",
      "Keunwoo Choi",
      "Qiuqiang Kong",
      "Bochen Li",
      "Minz Won",
      "Amy Hung",
      "Ju-Chiang Wang",
      "Dorien Herremans"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.10805"
  },
  {
    "id": "arXiv:2206.10910",
    "title": "SpA-Former: Transformer image shadow detection and removal via spatial  attention",
    "abstract": "SpA-Former: Transformer image shadow detection and removal via spatial  attention",
    "descriptor": "",
    "authors": [
      "Xiao Feng Zhang",
      "Chao Chen Gu",
      "Shan Ying Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10910"
  },
  {
    "id": "arXiv:2206.11048",
    "title": "Automated GI tract segmentation using deep learning",
    "abstract": "Comments: 9 pages, 10 figures",
    "descriptor": "\nComments: 9 pages, 10 figures\n",
    "authors": [
      "Manhar Sharma"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.11048"
  },
  {
    "id": "arXiv:2206.11706",
    "title": "A Temporal Extension of Latent Dirichlet Allocation for Unsupervised  Acoustic Unit Discovery",
    "abstract": "A Temporal Extension of Latent Dirichlet Allocation for Unsupervised  Acoustic Unit Discovery",
    "descriptor": "",
    "authors": [
      "Werner van der Merwe",
      "Herman Kamper",
      "Johan du Preez"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.11706"
  },
  {
    "id": "arXiv:2206.11756",
    "title": "Membership Problems in Finite Groups",
    "abstract": "Comments: A short version will appear in the proceedings of MFCS 2022",
    "descriptor": "\nComments: A short version will appear in the proceedings of MFCS 2022\n",
    "authors": [
      "Markus Lohrey",
      "Andreas Rosowski",
      "Georg Zetzsche"
    ],
    "subjectives": [
      "Group Theory (math.GR)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2206.11756"
  },
  {
    "id": "arXiv:2206.12076",
    "title": "Synthesizing Rolling Bearing Fault Samples in New Conditions: A  framework based on a modified CGAN",
    "abstract": "Comments: 19 pages",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Maryam Ahang",
      "Masoud Jalayer",
      "Ardeshir Shojaeinasab",
      "Oluwaseyi Ogunfowora",
      "Todd Charter",
      "Homayoun Najjaran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.12076"
  },
  {
    "id": "arXiv:2206.12233",
    "title": "Reinforcement learning based adaptive metaheuristics",
    "abstract": "Comments: To appear in the Genetic and Evolutionary Computation Conference (GECCO) 2022, Companion Proceedings",
    "descriptor": "\nComments: To appear in the Genetic and Evolutionary Computation Conference (GECCO) 2022, Companion Proceedings\n",
    "authors": [
      "Michele Tessari",
      "Giovanni Iacca"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.12233"
  },
  {
    "id": "arXiv:2206.12288",
    "title": "Optimization of Geometric Constellation Shaping for Wiener Phase Noise  Channels with Varying Channel Parameters",
    "abstract": "Comments: Accepted to be presented at ECOC 2022",
    "descriptor": "\nComments: Accepted to be presented at ECOC 2022\n",
    "authors": [
      "Andrej Rode",
      "Laurent Schmalen"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.12288"
  },
  {
    "id": "arXiv:2206.12390",
    "title": "A Test for Evaluating Performance in Human-Computer Systems",
    "abstract": "Comments: Corrected typos and references",
    "descriptor": "\nComments: Corrected typos and references\n",
    "authors": [
      "Andres Campero",
      "Michelle Vaccaro",
      "Jaeyoon Song",
      "Haoran Wen",
      "Abdullah Almaatouq",
      "Thomas W. Malone"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.12390"
  },
  {
    "id": "arXiv:2206.12486",
    "title": "Variational Bayesian inference for CP tensor completion with side  information",
    "abstract": "Comments: added 1 citation",
    "descriptor": "\nComments: added 1 citation\n",
    "authors": [
      "Stanislav Budzinskiy",
      "Nikolai Zamarashkin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2206.12486"
  },
  {
    "id": "arXiv:2206.12759",
    "title": "Low-resource Accent Classification in Geographically-proximate Settings:  A Forensic and Sociophonetics Perspective",
    "abstract": "Comments: INTERSPEECH 2022",
    "descriptor": "\nComments: INTERSPEECH 2022\n",
    "authors": [
      "Qingcheng Zeng",
      "Dading Chong",
      "Peilin Zhou",
      "Jie Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.12759"
  },
  {
    "id": "arXiv:2206.12832",
    "title": "Prediction Errors for Penalized Regressions based on Generalized  Approximate Message Passing",
    "abstract": "Comments: 69 pages, 13 figures, review paper for Journal of Physics A",
    "descriptor": "\nComments: 69 pages, 13 figures, review paper for Journal of Physics A\n",
    "authors": [
      "Ayaka Sakata"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.12832"
  },
  {
    "id": "arXiv:2206.12896",
    "title": "On the Impossibility of Decomposing Binary Matroids",
    "abstract": "On the Impossibility of Decomposing Binary Matroids",
    "descriptor": "",
    "authors": [
      "Marilena Leichter",
      "Benjamin Moseley",
      "Kirk Pruhs"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2206.12896"
  },
  {
    "id": "arXiv:2206.13441",
    "title": "EMVLight: a Multi-agent Reinforcement Learning Framework for an  Emergency Vehicle Decentralized Routing and Traffic Signal Control System",
    "abstract": "Comments: 19 figures, 10 tables. Manuscript extended on previous work arXiv:2109.05429, arXiv:2111.00278",
    "descriptor": "\nComments: 19 figures, 10 tables. Manuscript extended on previous work arXiv:2109.05429, arXiv:2111.00278\n",
    "authors": [
      "Haoran Su",
      "Yaofeng D. Zhong",
      "Joseph Y.J. Chow",
      "Biswadip Dey",
      "Li Jin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.13441"
  },
  {
    "id": "arXiv:2206.13731",
    "title": "On two-variable guarded fragment logic with expressive local Presburger  constraints",
    "abstract": "On two-variable guarded fragment logic with expressive local Presburger  constraints",
    "descriptor": "",
    "authors": [
      "Chia-Hsuan Lu",
      "Tony Tan"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.13731"
  },
  {
    "id": "arXiv:2206.13995",
    "title": "New MDS Entanglement-Assisted Quantum Codes from MDS Hermitian  Self-Orthogonal Codes",
    "abstract": "Comments: 17 pages, MDS quantum codes can be transformed to MDS Entanglement-assisted quantum codes with nonzero c parameters directly",
    "descriptor": "\nComments: 17 pages, MDS quantum codes can be transformed to MDS Entanglement-assisted quantum codes with nonzero c parameters directly\n",
    "authors": [
      "Hao Chen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.13995"
  },
  {
    "id": "arXiv:2206.14053",
    "title": "Bengali Common Voice Speech Dataset for Automatic Speech Recognition",
    "abstract": "Bengali Common Voice Speech Dataset for Automatic Speech Recognition",
    "descriptor": "",
    "authors": [
      "Samiul Alam",
      "Asif Sushmit",
      "Zaowad Abdullah",
      "Shahrin Nakkhatra",
      "MD. Nazmuddoha Ansary",
      "Syed Mobassir Hossen",
      "Sazia Morshed Mehnaz",
      "Tahsin Reasat",
      "Ahmed Imtiaz Humayun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.14053"
  },
  {
    "id": "arXiv:2206.14175",
    "title": "InvAASTCluster: On Applying Invariant-Based Program Clustering to  Introductory Programming Assignments",
    "abstract": "Comments: 21 pages, 6 Figures, 4 Tables. GitHub repo: this https URL",
    "descriptor": "\nComments: 21 pages, 6 Figures, 4 Tables. GitHub repo: this https URL\n",
    "authors": [
      "Pedro Orvalho",
      "Mikol\u00e1\u0161 Janota",
      "Vasco Manquinho"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2206.14175"
  }
]
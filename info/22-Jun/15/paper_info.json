[
  {
    "id": "arXiv:2206.06367",
    "title": "Does a Technique for Building Multimodal Representation Matter? --  Comparative Analysis",
    "abstract": "Creating a meaningful representation by fusing single modalities (e.g., text,\nimages, or audio) is the core concept of multimodal learning. Although several\ntechniques for building multimodal representations have been proven successful,\nthey have not been compared yet. Therefore it has been ambiguous which\ntechnique can be expected to yield the best results in a given scenario and\nwhat factors should be considered while choosing such a technique. This paper\nexplores the most common techniques for building multimodal data\nrepresentations -- the late fusion, the early fusion, and the sketch, and\ncompares them in classification tasks. Experiments are conducted on three\ndatasets: Amazon Reviews, MovieLens25M, and MovieLens1M datasets. In general,\nour results confirm that multimodal representations are able to boost the\nperformance of unimodal models from 0.919 to 0.969 of accuracy on Amazon\nReviews and 0.907 to 0.918 of AUC on MovieLens25M. However, experiments on both\nMovieLens datasets indicate the importance of the meaningful input data to the\ngiven task. In this article, we show that the choice of the technique for\nbuilding multimodal representation is crucial to obtain the highest possible\nmodel's performance, that comes with the proper modalities combination. Such\nchoice relies on: the influence that each modality has on the analyzed machine\nlearning (ML) problem; the type of the ML task; the memory constraints while\ntraining and predicting phase.",
    "descriptor": "",
    "authors": [
      "Maciej Paw\u0142owski",
      "Anna Wr\u00f3blewska",
      "Sylwia Sysko-Roma\u0144czuk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06367"
  },
  {
    "id": "arXiv:2206.06369",
    "title": "Dynamic stability of power grids -- new datasets for Graph Neural  Networks",
    "abstract": "One of the key challenges for the success of the energy transition towards\nrenewable energies is the analysis of the dynamic stability of power grids.\nHowever, dynamic solutions are intractable and exceedingly expensive for large\ngrids. Graph Neural Networks (GNNs) are a promising method to reduce the\ncomputational effort of predicting dynamic stability of power grids, however\ndatasets of appropriate complexity and size do not yet exist. We introduce two\nnew datasets of synthetically generated power grids. For each grid, the dynamic\nstability has been estimated using Monte-Carlo simulations. The datasets have\n10 times more grids than previously published. To evaluate the potential for\nreal-world applications, we demonstrate the successful prediction on a Texan\npower grid model. The performance can be improved to surprisingly high levels\nby training more complex models on more data. Furthermore, the investigated\ngrids have different sizes, enabling the application of out-of-distribution\nevaluation and transfer learning from a small to a large domain. We invite the\ncommunity to improve our benchmark models and thus aid the energy transition\nwith better tools.",
    "descriptor": "\nComments: 9 pages + references and appendix, 5 figures\n",
    "authors": [
      "Christian Nauck",
      "Michael Lindner",
      "Konstantin Sch\u00fcrholt",
      "Frank Hellmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2206.06369"
  },
  {
    "id": "arXiv:2206.06370",
    "title": "Don't \"research fast and break things\": On the ethics of Computational  Social Science",
    "abstract": "This article is concerned with setting up practical guardrails within the\nresearch activities and environments of CSS. It aims to provide CSS scholars,\nas well as policymakers and other stakeholders who apply CSS methods, with the\ncritical and constructive means needed to ensure that their practices are\nethical, trustworthy, and responsible. It begins by providing a taxonomy of the\nethical challenges faced by researchers in the field of CSS. These are\nchallenges related to (1) the treatment of research subjects, (2) the impacts\nof CSS research on affected individuals and communities, (3) the quality of CSS\nresearch and to its epistemological status, (4) research integrity, and (5)\nresearch equity. Taking these challenges as a motivation for cultural\ntransformation, it then argues for the end-to-end incorporation of habits of\nresponsible research and innovation (RRI) into CSS practices, focusing on the\nrole that contextual considerations, anticipatory reflection, impact\nassessment, public engagement, and justifiable and well-documented action\nshould play across the research lifecycle. In proposing the inclusion of habits\nof RRI in CSS practices, the chapter lays out several practical steps needed\nfor ethical, trustworthy, and responsible CSS research activities. These\ninclude stakeholder engagement processes, research impact assessments, data\nlifecycle documentation, bias self-assessments, and transparent research\nreporting protocols.",
    "descriptor": "",
    "authors": [
      "David Leslie"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computation and Language (cs.CL)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.06370"
  },
  {
    "id": "arXiv:2206.06371",
    "title": "Darknet Traffic Classification and Adversarial Attacks",
    "abstract": "The anonymous nature of darknets is commonly exploited for illegal\nactivities. Previous research has employed machine learning and deep learning\ntechniques to automate the detection of darknet traffic in an attempt to block\nthese criminal activities. This research aims to improve darknet traffic\ndetection by assessing Support Vector Machines (SVM), Random Forest (RF),\nConvolutional Neural Networks (CNN), and Auxiliary-Classifier Generative\nAdversarial Networks (AC-GAN) for classification of such traffic and the\nunderlying application types. We find that our RF model outperforms the\nstate-of-the-art machine learning techniques used in prior work with the\nCIC-Darknet2020 dataset. To evaluate the robustness of our RF classifier, we\nobfuscate select application type classes to simulate realistic adversarial\nattack scenarios. We demonstrate that our best-performing classifier can be\ndefeated by such attacks, and we consider ways to deal with such adversarial\nattacks.",
    "descriptor": "",
    "authors": [
      "Nhien Rust-Nguyen",
      "Mark Stamp"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06371"
  },
  {
    "id": "arXiv:2206.06383",
    "title": "An Exploration of Post-Editing Effectiveness in Text Summarization",
    "abstract": "Automatic summarization methods are efficient but can suffer from low\nquality. In comparison, manual summarization is expensive but produces higher\nquality. Can humans and AI collaborate to improve summarization performance? In\nsimilar text generation tasks (e.g., machine translation), human-AI\ncollaboration in the form of \"post-editing\" AI-generated text reduces human\nworkload and improves the quality of AI output. Therefore, we explored whether\npost-editing offers advantages in text summarization. Specifically, we\nconducted an experiment with 72 participants, comparing post-editing provided\nsummaries with manual summarization for summary quality, human efficiency, and\nuser experience on formal (XSum news) and informal (Reddit posts) text. This\nstudy sheds valuable insights on when post-editing is useful for text\nsummarization: it helped in some cases (e.g., when participants lacked domain\nknowledge) but not in others (e.g., when provided summaries include inaccurate\ninformation). Participants' different editing strategies and needs for\nassistance offer implications for future human-AI summarization systems.",
    "descriptor": "\nComments: 18 pages, 21 figures\n",
    "authors": [
      "Vivian Lai",
      "Alison Smith-Renner",
      "Ke Zhang",
      "Ruijia Cheng",
      "Wenjuan Zhang",
      "Joel Tetreault",
      "Alejandro Jaimes"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.06383"
  },
  {
    "id": "arXiv:2206.06401",
    "title": "GoAutoBash: Golang-based Multi-Thread Automatic Pull-Execute Framework  with GitHub Webhooks And Queuing Strategy",
    "abstract": "Recently, more and more server tasks are done using full automation,\nincluding grading tasks for students in the college courses, integrating tasks\nfor programmers in big projects and server-based transactions, and\nvisualization tasks for researchers in a data-dense topic. Using automation on\nservers provides a great possibility for reducing the burden on manual tasks.\nAlthough server tools like CI/CD for continuous integration and Hexo for\nautomated blog deployment have been developed, they're highly dedicated to\ncertain functionalities and thus lack general usage. In this paper, we\nintroduce a Golang-based automation framework that reacts to the events\nhappening on GitHub in a multi-thread approach. This framework utilizes a queue\nto arrange the tasks submitted and execute each task with a thread in a\npreemptive manner. We then use the project GoAutoGrader to illustrate a\nspecific implementation of this framework and its value in implementing\nhigh-freedom server applications. As Golang is developing in a rapid way\nbecause of its incredible parallel programming efficiency and a super-easy way\nto learn on the basis of C-like programming languages, we decide to develop\nthis system in Golang.",
    "descriptor": "\nComments: Accepted by EPCE'22\n",
    "authors": [
      "Hao Bai"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.06401"
  },
  {
    "id": "arXiv:2206.06404",
    "title": "Compositional Mixture Representations for Vision and Text",
    "abstract": "Learning a common representation space between vision and language allows\ndeep networks to relate objects in the image to the corresponding semantic\nmeaning. We present a model that learns a shared Gaussian mixture\nrepresentation imposing the compositionality of the text onto the visual domain\nwithout having explicit location supervision. By combining the spatial\ntransformer with a representation learning approach we learn to split images\ninto separately encoded patches to associate visual and textual representations\nin an interpretable manner. On variations of MNIST and CIFAR10, our model is\nable to perform weakly supervised object detection and demonstrates its ability\nto extrapolate to unseen combination of objects.",
    "descriptor": "\nComments: Workshop on Learning with Limited Labelled Data for Image and Video Understanding (L3D-IVU), CVPR 2022\n",
    "authors": [
      "Stephan Alaniz",
      "Marco Federici",
      "Zeynep Akata"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06404"
  },
  {
    "id": "arXiv:2206.06406",
    "title": "Consent verification monitoring",
    "abstract": "Advances in service personalization are driven by low-cost data collection\nand processing, in addition to the wide variety of third-party frameworks for\nauthentication, storage, and marketing. New privacy regulations, such as the\nGeneral Data Protection Regulation (GDPR) and the California Consumer Privacy\nAct (CCPA), increasingly require organizations to explicitly state their data\npractices in privacy policies. When data practices change, a new version of the\npolicy is released. This can occur a few times a year, when data collection or\nprocessing requirements are rapidly changing. Consent evolution raises specific\nchallenges to ensuring GDPR compliance. We propose a formal consent framework\nto support organizations, data users and data subjects in their understanding\nof policy evolution under a consent regime that supports both the retroactive\nand non-retroactive granting and withdrawal of consent. The contributions\ninclude: (i) a formal framework to reason about data collection and access\nunder multiple consent granting and revocation scenarios; (ii) a scripting\nlanguage that implements the consent framework for encoding and executing\ndifferent scenarios; (iii) five consent evolution use cases that illustrate how\norganizations would evolve their policies using this framework; and (iv) a\nscalability evaluation of the reasoning framework. The framework models are\nused to verify when user consent prevents or detects unauthorized data\ncollection and access. The framework can be integrated into a runtime\narchitecture to monitor policy violations as data practices evolve in\nreal-time. The framework was evaluated using the five use cases and a\nsimulation to measure the framework scalability. The simulation results show\nthat the approach is computationally scalable for use in runtime consent\nmonitoring under a standard model of data collection and access, and practice\nand policy evolution.",
    "descriptor": "\nComments: Accepted 5 October 2021 to ACM Transactions on Software Engineering and Methodology (TOSEM), to appear in print in January 2023 issue\n",
    "authors": [
      "Marco Robol",
      "Travis D. Breaux",
      "Elda Paja",
      "Paolo Giorgini"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.06406"
  },
  {
    "id": "arXiv:2206.06410",
    "title": "Estimating Causal Effects Under Image Confounding Bias with an  Application to Poverty in Africa",
    "abstract": "Observational studies of causal effects require adjustment for confounding\nfactors. In the tabular setting, where these factors are well-defined, separate\nrandom variables, the effect of confounding is well understood. However, in\npublic policy, ecology, and in medicine, decisions are often made in\nnon-tabular settings, informed by patterns or objects detected in images (e.g.,\nmaps, satellite or tomography imagery). Using such imagery for causal inference\npresents an opportunity because objects in the image may be related to the\ntreatment and outcome of interest. In these cases, we rely on the images to\nadjust for confounding but observed data do not directly label the existence of\nthe important objects. Motivated by real-world applications, we formalize this\nchallenge, how it can be handled, and what conditions are sufficient to\nidentify and estimate causal effects. We analyze finite-sample performance\nusing simulation experiments, estimating effects using a propensity adjustment\nalgorithm that employs a machine learning model to estimate the image\nconfounding. Our experiments also examine sensitivity to misspecification of\nthe image pattern mechanism. Finally, we use our methodology to estimate the\neffects of policy interventions on poverty in African communities from\nsatellite imagery.",
    "descriptor": "",
    "authors": [
      "Connor T. Jerzak",
      "Fredrik Johansson",
      "Adel Daoud"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06410"
  },
  {
    "id": "arXiv:2206.06417",
    "title": "Image-based Treatment Effect Heterogeneity",
    "abstract": "Randomized controlled trials (RCTs) are considered the gold standard for\nestimating the effects of interventions. Recent work has studied effect\nheterogeneity in RCTs by conditioning estimates on tabular variables such as\nage and ethnicity. However, such variables are often only observed near the\ntime of the experiment and may fail to capture historical or geographical\nreasons for effect variation. When experiment units are associated with a\nparticular location, satellite imagery can provide such historical and\ngeographical information, yet there is no method which incorporates it for\ndescribing effect heterogeneity. In this paper, we develop such a method which\nestimates, using a deep probabilistic modeling framework, the clusters of\nimages having the same distribution over treatment effects. We compare the\nproposed methods against alternatives in simulation and in an application to\nestimating the effects of an anti-poverty intervention in Uganda. A causal\nregularization penalty is introduced to ensure reliability of the cluster model\nin recovering Average Treatment Effects (ATEs). Finally, we discuss\nfeasibility, limitations, and the applicability of these methods to other\ndomains, such as medicine and climate science, where image information is\nprevalent. We make code for all modeling strategies publicly available in an\nopen-source software package.",
    "descriptor": "",
    "authors": [
      "Connor T. Jerzak",
      "Fredrik Johansson",
      "Adel Daoud"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06417"
  },
  {
    "id": "arXiv:2206.06419",
    "title": "A Relative Church-Turing-Deutsch Thesis from Special Relativity and  Undecidability",
    "abstract": "Beginning with Turing's seminal work in 1950, artificial intelligence\nproposes that consciousness can be simulated by a Turing machine. This implies\na potential theory of everything where the universe is a simulation on a\ncomputer, which begs the question of whether we can prove we exist in a\nsimulation. In this work, we construct a relative model of computation where a\ncomputable \\textit{local} machine is simulated by a \\textit{global}, classical\nTuring machine. We show that the problem of the local machine computing\n\\textbf{simulation properties} of its global simulator is undecidable in the\nsame sense as the Halting problem. Then, we show that computing the time,\nspace, or error accumulated by the global simulator are simulation properties\nand therefore are undecidable. These simulation properties give rise to special\nrelativistic effects in the relative model which we use to construct a relative\nChurch-Turing-Deutsch thesis where a global, classical Turing machine computes\nquantum mechanics for a local machine with the same constant-time local\ncomputational complexity as experienced in our universe.",
    "descriptor": "\nComments: All feedback and comments will be greatly appreciated\n",
    "authors": [
      "Blake Wilson",
      "Ethan Dickey",
      "Vaishnavi Iyer",
      "Sabre Kais"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Artificial Intelligence (cs.AI)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.06419"
  },
  {
    "id": "arXiv:2206.06420",
    "title": "GraphMLP: A Graph MLP-Like Architecture for 3D Human Pose Estimation",
    "abstract": "Modern multi-layer perceptron (MLP) models have shown competitive results in\nlearning visual representations without self-attention. However, existing MLP\nmodels are not good at capturing local details and lack prior knowledge of\nhuman configurations, which limits their modeling power for skeletal\nrepresentation learning. To address these issues, we propose a simple yet\neffective graph-reinforced MLP-Like architecture, named GraphMLP, that combines\nMLPs and graph convolutional networks (GCNs) in a global-local-graphical\nunified architecture for 3D human pose estimation. GraphMLP incorporates the\ngraph structure of human bodies into an MLP model to meet the domain-specific\ndemand while also allowing for both local and global spatial interactions.\nExtensive experiments show that the proposed GraphMLP achieves state-of-the-art\nperformance on two datasets, i.e., Human3.6M and MPI-INF-3DHP. Our source code\nand pretrained models will be publicly available.",
    "descriptor": "",
    "authors": [
      "Wenhao Li",
      "Hong Liu",
      "Tianyu Guo",
      "Hao Tang",
      "Runwei Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06420"
  },
  {
    "id": "arXiv:2206.06423",
    "title": "Hate Speech and Counter Speech Detection: Conversational Context Does  Matter",
    "abstract": "Hate speech is plaguing the cyberspace along with user-generated content.\nThis paper investigates the role of conversational context in the annotation\nand detection of online hate and counter speech, where context is defined as\nthe preceding comment in a conversation thread. We created a context-aware\ndataset for a 3-way classification task on Reddit comments: hate speech,\ncounter speech, or neutral. Our analyses indicate that context is critical to\nidentify hate and counter speech: human judgments change for most comments\ndepending on whether we show annotators the context. A linguistic analysis\ndraws insights into the language people use to express hate and counter speech.\nExperimental results show that neural networks obtain significantly better\nresults if context is taken into account. We also present qualitative error\nanalyses shedding light into (a) when and why context is beneficial and (b) the\nremaining errors made by our best model when context is taken into account.",
    "descriptor": "\nComments: Accepted by NAACL 2022\n",
    "authors": [
      "Xinchen Yu",
      "Eduardo Blanco",
      "Lingzi Hong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.06423"
  },
  {
    "id": "arXiv:2206.06424",
    "title": "Look, Radiate, and Learn: Self-supervised Localisation via Radio-Visual  Correspondence",
    "abstract": "Next generation cellular networks will implement radio sensing functions\nalongside customary communications, thereby enabling unprecedented worldwide\nsensing coverage outdoors. Deep learning has revolutionised computer vision but\nhas had limited application to radio perception tasks, in part due to lack of\nsystematic datasets and benchmarks dedicated to the study of the performance\nand promise of radio sensing. To address this gap, we present MaxRay: a\nsynthetic radio-visual dataset and benchmark that facilitate precise target\nlocalisation in radio. We further propose to learn to localise targets in radio\nwithout supervision by extracting self-coordinates from radio-visual\ncorrespondence. We use such self-supervised coordinates to train a radio\nlocaliser network. We characterise our performance against a number of\nstate-of-the-art baselines. Our results indicate that accurate radio target\nlocalisation can be automatically learned from paired radio-visual data without\nlabels, which is highly relevant to empirical data. This opens the door for\nvast data scalability and may prove key to realising the promise of robust\nradio sensing atop a unified perception-communication cellular infrastructure.\nDataset will be hosted on IEEE DataPort.",
    "descriptor": "",
    "authors": [
      "Mohammed Alloulah",
      "Maximilian Arnold"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.06424"
  },
  {
    "id": "arXiv:2206.06426",
    "title": "Provably Efficient Offline Reinforcement Learning with Trajectory-Wise  Reward",
    "abstract": "The remarkable success of reinforcement learning (RL) heavily relies on\nobserving the reward of every visited state-action pair. In many real world\napplications, however, an agent can observe only a score that represents the\nquality of the whole trajectory, which is referred to as the {\\em\ntrajectory-wise reward}. In such a situation, it is difficult for standard RL\nmethods to well utilize trajectory-wise reward, and large bias and variance\nerrors can be incurred in policy evaluation. In this work, we propose a novel\noffline RL algorithm, called Pessimistic vAlue iteRaTion with rEward\nDecomposition (PARTED), which decomposes the trajectory return into per-step\nproxy rewards via least-squares-based reward redistribution, and then performs\npessimistic value iteration based on the learned proxy reward. To ensure the\nvalue functions constructed by PARTED are always pessimistic with respect to\nthe optimal ones, we design a new penalty term to offset the uncertainty of the\nproxy reward. For general episodic MDPs with large state space, we show that\nPARTED with overparameterized neural network function approximation achieves an\n$\\tilde{\\mathcal{O}}(D_{\\text{eff}}H^2/\\sqrt{N})$ suboptimality, where $H$ is\nthe length of episode, $N$ is the total number of samples, and $D_{\\text{eff}}$\nis the effective dimension of the neural tangent kernel matrix. To further\nillustrate the result, we show that PARTED achieves an\n$\\tilde{\\mathcal{O}}(dH^3/\\sqrt{N})$ suboptimality with linear MDPs, where $d$\nis the feature dimension, which matches with that with neural network function\napproximation, when $D_{\\text{eff}}=dH$. To the best of our knowledge, PARTED\nis the first offline RL algorithm that is provably efficient in general MDP\nwith trajectory-wise reward.",
    "descriptor": "\nComments: Submitted for conference publication\n",
    "authors": [
      "Tengyu Xu",
      "Yingbin Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.06426"
  },
  {
    "id": "arXiv:2206.06427",
    "title": "A Multi-purpose Real Haze Benchmark with Quantifiable Haze Levels and  Ground Truth",
    "abstract": "Imagery collected from outdoor visual environments is often degraded due to\nthe presence of dense smoke or haze. A key challenge for research in scene\nunderstanding in these degraded visual environments (DVE) is the lack of\nrepresentative benchmark datasets. These datasets are required to evaluate\nstate-of-the-art object recognition and other computer vision algorithms in\ndegraded settings. In this paper, we address some of these limitations by\nintroducing the first paired real image benchmark dataset with hazy and\nhaze-free images, and in-situ haze density measurements. This dataset was\nproduced in a controlled environment with professional smoke generating\nmachines that covered the entire scene, and consists of images captured from\nthe perspective of both an unmanned aerial vehicle (UAV) and an unmanned ground\nvehicle (UGV). We also evaluate a set of representative state-of-the-art\ndehazing approaches as well as object detectors on the dataset. The full\ndataset presented in this paper, including the ground truth object\nclassification bounding boxes and haze density measurements, is provided for\nthe community to evaluate their algorithms at: https://a2i2-archangel.vision. A\nsubset of this dataset has been used for the Object Detection in Haze Track of\nCVPR UG2 2022 challenge.",
    "descriptor": "",
    "authors": [
      "Priya Narayanan",
      "Xin Hu",
      "Zhenyu Wu",
      "Matthew D Thielke",
      "John G Rogers",
      "Andre V Harrison",
      "John A D'Agostino",
      "James D Brown",
      "Long P Quang",
      "James R Uplinger",
      "Heesung Kwon",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06427"
  },
  {
    "id": "arXiv:2206.06428",
    "title": "VSC-WebGPU: A Selenium-based VS Code Extension For Local Edit And Cloud  Compilation on WebGPU",
    "abstract": "With the rapid development of information transmission, Software as a Service\n(SaaS) is developing at a rapid speed that everything originally local tends to\nbe transplanted onto servers and executed on the cloud. WebGPU is such a SaaS\nsystem that it holds the GPU-equipped server to execute students' CUDA code and\nreleases the RESTful front-end website for students to write their code on.\nHowever, programming on an HTML-based interface is not satisfactory due to a\nlack of syntax highlighting and automatic keyword complement. On the other\nside, Visual Studio Code is now becoming the most popular programming interface\ndue to its strong community and eclectic functionalities. Thus, we propose such\na system that, students write code locally using VS Code with its\ncoding-auxiliary extensions, and push the code to WebGPU with only one button\npressed using our VSC-WebGPU extension. The extension is divided into 4 parts:\nthe login process for automatically logging the student into WebGPU, the pull\nprocess that pulls the code down to the local workspace, the push process that\ncopies the code to the browser for compiling and running, and the exit process\nto exit the browser and close the connection. This 4-step architecture is also\napplicable for any other automated tools to push local code to\nauthorization-required SaaS systems using Web automata.",
    "descriptor": "\nComments: Published by IEEE on conference ICFTIC'21\n",
    "authors": [
      "Hao Bai"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.06428"
  },
  {
    "id": "arXiv:2206.06430",
    "title": "A Training Method For VideoPose3D With Ideology of Action Recognition",
    "abstract": "Action recognition and pose estimation from videos are closely related to\nunderstand human motions, but more literature focuses on how to solve pose\nestimation tasks alone from action recognition. This research shows a faster\nand more flexible training method for VideoPose3D which is based on action\nrecognition. This model is fed with the same type of action as the type that\nwill be estimated, and different types of actions can be trained separately.\nEvidence has shown that, for common pose-estimation tasks, this model requires\na relatively small amount of data to carry out similar results with the\noriginal research, and for action-oriented tasks, it outperforms the original\nresearch by 4.5% with a limited receptive field size and training epoch on\nVelocity Error of MPJPE. This model can handle both action-oriented and common\npose-estimation problems.",
    "descriptor": "\nComments: Published by IEEE, on conference CONF-SPML\n",
    "authors": [
      "Hao Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06430"
  },
  {
    "id": "arXiv:2206.06434",
    "title": "SmartGD: A Self-Challenging Generative Adversarial Network for Graph  Drawing",
    "abstract": "A multitude of studies have been conducted on graph drawing, but many\nexisting methods only focus on optimizing particular aesthetic aspects of graph\nlayout. Given a graph, generating a good layout that satisfies certain human\naesthetic preference remains a challenging task, especially if such preference\ncan not be expressed as a differentiable objective function. In this paper, we\npropose a student-teacher GAN-based graph drawing framework, SmartGD, which\nlearns to draw graphs just like how humans learn to perform tasks. The student\nnetwork in the SmartGD learns graph drawing by imitating good layout examples,\nwhile the teacher network in SmartGD is responsible for providing ratings\nregarding the goodness of the generated layouts. When there is a lack of\nconcrete aesthetic criteria to specify what constitutes a good layout, the\nstudent network can learn from the good layout examples. On the other hand,\nwhen the goodness of a layout can be assessed by quantitative criteria (even if\nnot differentiable), the student network can use it as a concrete goal to\noptimize the target aesthetics. To accomplish the goal, we propose a novel\nvariant of GAN, self-challenging GAN, to learn the optimal layout distribution\nwith respect to any aesthetic criterion, whether the criterion is\ndifferentiable or not. The proposed graph drawing framework can not only draw\ngraphs in a similar style as the good layout examples but also optimize the\ngraph layouts according to any given aesthetic criteria when available. Once\nthe model is trained, it can be used to visualize arbitrary graphs according to\nthe style of the example layouts or the chosen aesthetic criteria. The\ncomprehensive experimental studies show that SmartGD outperforms 12 benchmark\nmethods according to the commonly agreed metrics.",
    "descriptor": "",
    "authors": [
      "Xiaoqi Wang",
      "Kevin Yen",
      "Yifan Hu",
      "Han-Wei Shen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06434"
  },
  {
    "id": "arXiv:2206.06435",
    "title": "ICP Algorithm: Theory, Practice And Its SLAM-oriented Taxonomy",
    "abstract": "The Iterative Closest Point (ICP) algorithm is one of the most important\nalgorithms for geometric alignment of three-dimensional surface registration,\nwhich is frequently used in computer vision tasks, including the Simultaneous\nLocalization And Mapping (SLAM) tasks. In this paper, we illustrate the\ntheoretical principles of the ICP algorithm, how it can be used in surface\nregistration tasks, and the traditional taxonomy of the variants of the ICP\nalgorithm. As SLAM is becoming a popular topic, we also introduce a\nSLAM-oriented taxonomy of the ICP algorithm, based on the characteristics of\neach type of SLAM task, including whether the SLAM task is online or not and\nwhether the landmarks are present as features in the SLAM task. We make a\nsynthesis of each type of SLAM task by comparing several up-to-date research\npapers and analyzing their implementation details.",
    "descriptor": "\nComments: Accepted by CONF-CDS'22\n",
    "authors": [
      "Hao Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06435"
  },
  {
    "id": "arXiv:2206.06437",
    "title": "Distribution of Quantum Circuits Over General Quantum Networks",
    "abstract": "Near-term quantum computers can hold only a small number of qubits. One way\nto facilitate large-scale quantum computations is through a distributed network\nof quantum computers. In this work, we consider the problem of distributing\nquantum programs represented as quantum circuits across a quantum network of\nheterogeneous quantum computers, in a way that minimizes the overall\ncommunication cost required to execute the distributed circuit. We consider two\nways of communicating: cat-entanglement that creates linked copies of qubits\nacross pairs of computers, and teleportation. The heterogeneous computers\nimpose constraints on cat-entanglement and teleportation operations that can be\nchosen by an algorithm. We first focus on a special case that only allows\ncat-entanglements and not teleportations for communication. We provide a\ntwo-step heuristic for solving this specialized setting: (i) finding an\nassignment of qubits to computers using Tabu search, and (ii) using an\niterative greedy algorithm designed for a constrained version of the set cover\nproblem to determine cat-entanglement operations required to execute gates\nlocally.\nFor the general case, which allows both forms of communication, we propose\ntwo algorithms that subdivide the quantum circuit into several portions and\napply the heuristic for the specialized setting on each portion. Teleportations\nare then used to stitch together the solutions for each portion. Finally, we\nsimulate our algorithms on a wide range of randomly generated quantum networks\nand circuits, and study the properties of their results with respect to several\nvarying parameters.",
    "descriptor": "",
    "authors": [
      "Ranjani G Sundaram",
      "Himanshu Gupta",
      "C. R. Ramakrishnan"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.06437"
  },
  {
    "id": "arXiv:2206.06440",
    "title": "An Abstract View on Optimizations in Propositional Frameworks",
    "abstract": "Search-optimization problems are plentiful in scientific and engineering\ndomains. Artificial intelligence has long contributed to the development of\nsearch algorithms and declarative programming languages geared towards solving\nand modeling search-optimization problems. Automated reasoning and knowledge\nrepresentation are the subfields of AI that are particularly vested in these\ndevelopments. Many popular automated reasoning paradigms provide users with\nlanguages supporting optimization statements: MaxSAT or answer set programming,\nto name a few. These paradigms vary significantly in their languages and in the\nways they express quality conditions on computed solutions. Here we propose a\nunifying framework of so-called weight systems that eliminates syntactic\ndistinctions between paradigms and allows us to see essential similarities and\ndifferences between optimization statements provided by paradigms. This\nunifying outlook has a significant simplifying and explanatory potential in the\nstudies of optimization and modularity in automated reasoning and knowledge\nrepresentation providing technical means for bridging distinct formalisms and\ndeveloping translational solvers. Under consideration in Theory and Practice of\nLogic Programming (TPLP).",
    "descriptor": "\nComments: Under consideration in Theory and Practice of Logic Programming (TPLP)\n",
    "authors": [
      "Yuliya Lierler"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.06440"
  },
  {
    "id": "arXiv:2206.06443",
    "title": "The impact of NFT profile pictures within social network communities",
    "abstract": "This paper presents an analysis of the role of social media, specifically\nTwitter, in the context of non-fungible tokens, better known as NFTs. Such\nemerging technology framing the creation and exchange of digital object,\nstarted years ago with early projects such as \"CryptoPunks\" and since early\n2021, has received an increasing interest by a community of people creating,\nbuying, selling NFT's and by the media reporting to the general public. In this\nwork it is shown how the landscape of one class of projects, specifically those\nused as social media profile pictures, has become mainstream with leading\nprojects such as \"Bored Ape Yacht Club\", \"Cool Cats\" and \"Doodles\". This work\nillustrates how heterogeneous data was collected from the Ethereum blockchain\nand Twitter and then analysed using algorithms and state-of-art metrics related\nto graphs. The initial results show that from a social network perspective, the\ncollections of most popular NFTs can be considered as a single community around\nNFTs. Thus, while each project has its own value and volume of exchange, on a\nsocial level all of them are primarily influenced by the evolution of values\nand trades of \"Bored Ape Yacht Club\" collection.",
    "descriptor": "\nComments: Paper submitted and under review to the ACM International Conference on Information Technology for Social Good (GoodIT'22), September 07--09, 2022, Cyprus\n",
    "authors": [
      "Simone Casale-Brunet",
      "Mirko Zichichi",
      "Lee Hutchinson",
      "Marco Mattavelli",
      "Stefano Ferretti"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.06443"
  },
  {
    "id": "arXiv:2206.06444",
    "title": "A Methodological Framework for the Comparative Evaluation of Multiple  Imputation Methods: Multiple Imputation of Race, Ethnicity and Body Mass  Index in the U.S. National COVID Cohort Collaborative",
    "abstract": "While electronic health records are a rich data source for biomedical\nresearch, these systems are not implemented uniformly across healthcare\nsettings and significant data may be missing due to healthcare fragmentation\nand lack of interoperability between siloed electronic health records.\nConsidering that the deletion of cases with missing data may introduce severe\nbias in the subsequent analysis, several authors prefer applying a multiple\nimputation strategy to recover the missing information. Unfortunately, although\nseveral literature works have documented promising results by using any of the\ndifferent multiple imputation algorithms that are now freely available for\nresearch, there is no consensus on which MI algorithm works best. Beside the\nchoice of the MI strategy, the choice of the imputation algorithm and its\napplication settings are also both crucial and challenging. In this paper,\ninspired by the seminal works of Rubin and van Buuren, we propose a\nmethodological framework that may be applied to evaluate and compare several\nmultiple imputation techniques, with the aim to choose the most valid for\ncomputing inferences in a clinical research work. Our framework has been\napplied to validate, and extend on a larger cohort, the results we presented in\na previous literature study, where we evaluated the influence of crucial\npatients' descriptors and COVID-19 severity in patients with type 2 diabetes\nmellitus whose data is provided by the National COVID Cohort Collaborative\nEnclave.",
    "descriptor": "",
    "authors": [
      "Elena Casiraghi",
      "Rachel Wong",
      "Margaret Hall",
      "Ben Coleman",
      "Marco Notaro",
      "Michael D. Evans",
      "Jena S. Tronieri",
      "Hannah Blau",
      "Bryan Laraway",
      "Tiffany J. Callahan",
      "Lauren E. Chan",
      "Carolyn T. Bramante",
      "John B. Buse",
      "Richard A. Moffitt",
      "Til Sturmer",
      "Steven G. Johnson",
      "Yu Raymond Shao",
      "Justin Reese",
      "Peter N. Robinson",
      "Alberto Paccanaro",
      "Giorgio Valentini",
      "Jared D. Huling",
      "Kenneth Wilkins",
      "Tell Bennet",
      "Christopher Chute",
      "Peter DeWitt",
      "Kenneth Gersing",
      "Andrew Girvin",
      "Melissa Haendel",
      "Jeremy Harper",
      "Janos Hajagos",
      "Stephanie Hong",
      "Emily Pfaff",
      "Jane Reusch",
      "Corneliu Antoniescu",
      "Kimberly Robaski"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2206.06444"
  },
  {
    "id": "arXiv:2206.06455",
    "title": "Robust space-time finite element error estimates for parabolic  distributed optimal control problems with energy regularization",
    "abstract": "We consider space-time tracking optimal control problems for linear\npara\\-bo\\-lic initial boundary value problems that are given in the space-time\ncylinder $Q = \\Omega \\times (0,T)$, and that are controlled by the right-hand\nside $z_\\varrho$ from the Bochner space $L^2(0,T;H^{-1}(\\Omega))$. So it is\nnatural to replace the usual $L^2(Q)$ norm regularization by the energy\nregularization in the $L^2(0,T;H^{-1}(\\Omega))$ norm. We derive a priori\nestimates for the error $\\|\\widetilde{u}_{\\varrho h} - \\bar{u}\\|_{L^2(Q)}$\nbetween the computed state $\\widetilde{u}_{\\varrho h}$ and the desired state\n$\\bar{u}$ in terms of the regularization parameter $\\varrho$ and the space-time\nfinite element mesh-size $h$, and depending on the regularity of the desired\nstate $\\bar{u}$. These estimates lead to the optimal choice $\\varrho = h^2$.\nThe approximate state $\\widetilde{u}_{\\varrho h}$ is computed by means of a\nspace-time finite element method using piecewise linear and continuous basis\nfunctions on completely unstructured simplicial meshes for $Q$. The theoretical\nresults are quantitatively illustrated by a series of numerical examples in two\nand three space dimensions.",
    "descriptor": "",
    "authors": [
      "Ulrich Langer",
      "Olaf Steinbach",
      "Huidong Yang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.06455"
  },
  {
    "id": "arXiv:2206.06456",
    "title": "A comparison of partial information decompositions using data from real  and simulated layer 5b pyramidal cells",
    "abstract": "Partial information decomposition allows the joint mutual information between\nan output and a set of inputs to be divided into components that are\nsynergistic or shared or unique to each input. We consider five different\ndecompositions and compare their results on data from layer 5b pyramidal cells\nin two different studies. The first study was of the amplification of somatic\naction potential output by apical dendritic input and its regulation by\ndendritic inhibition. We find that two of the decompositions produce much\nlarger estimates of synergy and shared information than the others, as well as\nlarge levels of unique misinformation. When within-neuron differences in the\ncomponents are examined, the five methods produce more similar results for all\nbut the shared information component, for which two methods produce a different\nstatistical conclusion from the others. There are some differences in the\nexpression of unique information asymmetry among the methods. It is\nsignificantly larger, on average, under dendritic inhibition. Three of the\nmethods support a previous conclusion that apical amplification is reduced by\ndendritic inhibition. The second study used a detailed compartmental model to\nproduce action potentials for many combinations of the numbers of basal and\napical synaptic inputs. Two analyses of decompositions are conducted on subsets\nof the data. In the first, the decompositions reveal a bifurcation in unique\ninformation asymmetry. For three of the methods this suggests that apical drive\nswitches to basal drive as the strength of the basal input increases, while the\nother two show changing mixtures of information and misinformation.\nDecompositions produced using the second set of subsets show that all five\ndecompositions provide support for properties of cooperative\ncontext-sensitivity - to varying extents.",
    "descriptor": "\nComments: 27 pages, 11 figures\n",
    "authors": [
      "Jim W. Kay",
      "Jan M. Schulz",
      "W.A. Phillips"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2206.06456"
  },
  {
    "id": "arXiv:2206.06457",
    "title": "A Privacy Glossary for Cloud Computing",
    "abstract": "Cloud computing is an evolving paradigm that is frequently changing the way\nhumans share, store, and access their information in digital format. While\ncloud computing offers tremendous benefits (e.g., efficiency, flexibility, and\nreduced costs), it also brings both security and privacy challenges. Although\ncloud security has been extensively defined and developed, privacy protections\nin cloud environments are often described in abstract or vague language, which\nmakes it difficult to interpret and implement. In this study, we propose an\ninitial approach of developing a privacy glossary for cloud computing that\nprovides a consistent and comprehensive set of terminologies for cloud privacy.\nWe believe that this systematic and structured privacy glossary could serve as\na first step towards implementing requirements for privacy protections in cloud\ncomputing, as well as providing more effective and consistent language in cloud\nprivacy to researchers and professionals in the future.",
    "descriptor": "",
    "authors": [
      "Tian Wang",
      "Masooda Bashir"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.06457"
  },
  {
    "id": "arXiv:2206.06460",
    "title": "MetaTPTrans: A Meta Learning Approach for Multilingual Code  Representation Learning",
    "abstract": "Representation learning of source code is essential for applying machine\nlearning to software engineering tasks. Learning code representation across\ndifferent programming languages has been shown to be more effective than\nlearning from single-language datasets, since more training data from\nmulti-language datasets improves the model's ability to extract\nlanguage-agnostic information from source code. However, existing\nmulti-language models overlook the language-specific information which is\ncrucial for downstream tasks that is training on multi-language datasets, while\nonly focusing on learning shared parameters among the different languages. To\naddress this problem, we propose MetaTPTrans, a meta learning approach for\nmultilingual code representation learning. MetaTPTrans generates different\nparameters for the feature extractor according to the specific programming\nlanguage of the input source code snippet, enabling the model to learn both\nlanguage-agnostics and language-specific information. Experimental results show\nthat MetaTPTrans improves the F1 score of state-of-the-art approaches\nsignificantly by up to 2.40 percentage points for code summarization, a\nlanguage-agnostic task; and the prediction accuracy of Top-1 (Top-5) by up to\n7.32 (13.15) percentage points for code completion, a language-specific task.",
    "descriptor": "\nComments: Technical report\n",
    "authors": [
      "Weiguo Pian",
      "Hanyu Peng",
      "Xunzhu Tang",
      "Tiezhu Sun",
      "Haoye Tian",
      "Andrew Habib",
      "Jacques Klein",
      "Tegawend\u00e9 F. Bissyand\u00e9"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.06460"
  },
  {
    "id": "arXiv:2206.06461",
    "title": "Self-Supervised Representation Learning With MUlti-Segmental  Informational Coding (MUSIC)",
    "abstract": "Self-supervised representation learning maps high-dimensional data into a\nmeaningful embedding space, where samples of similar semantic contents are\nclose to each other. Most of the recent representation learning methods\nmaximize cosine similarity or minimize the distance between the embedding\nfeatures of different views from the same sample usually on the $l2$ normalized\nunit hypersphere. To prevent the trivial solutions that all samples have the\nsame embedding feature, various techniques have been developed, such as\ncontrastive learning, stop gradient, variance and covariance regularization,\netc. In this study, we propose MUlti-Segmental Informational Coding (MUSIC) for\nself-supervised representation learning. MUSIC divides the embedding feature\ninto multiple segments that discriminatively partition samples into different\nsemantic clusters and different segments focus on different partition\nprinciples. Information theory measurements are directly used to optimize MUSIC\nand theoretically guarantee trivial solutions are avoided. MUSIC does not\ndepend on commonly used techniques, such as memory bank or large batches,\nasymmetry networks, gradient stopping, momentum weight updating, etc, making\nthe training framework flexible. Our experiments demonstrate that MUSIC\nachieves better results than most related Barlow Twins and VICReg methods on\nImageNet classification with linear probing, and requires neither deep\nprojectors nor large feature dimensions. Code will be made available.",
    "descriptor": "",
    "authors": [
      "Chuang Niu",
      "Ge Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.06461"
  },
  {
    "id": "arXiv:2206.06466",
    "title": "Revisiting the Shape-Bias of Deep Learning for Dermoscopic Skin Lesion  Classification",
    "abstract": "It is generally believed that the human visual system is biased towards the\nrecognition of shapes rather than textures. This assumption has led to a\ngrowing body of work aiming to align deep models' decision-making processes\nwith the fundamental properties of human vision. The reliance on shape features\nis primarily expected to improve the robustness of these models under covariate\nshift. In this paper, we revisit the significance of shape-biases for the\nclassification of skin lesion images. Our analysis shows that different skin\nlesion datasets exhibit varying biases towards individual image features.\nInterestingly, despite deep feature extractors being inclined towards learning\nentangled features for skin lesion classification, individual features can\nstill be decoded from this entangled representation. This indicates that these\nfeatures are still represented in the learnt embedding spaces of the models,\nbut not used for classification. In addition, the spectral analysis of\ndifferent datasets shows that in contrast to common visual recognition,\ndermoscopic skin lesion classification, by nature, is reliant on complex\nfeature combinations beyond shape-bias. As a natural consequence, shifting away\nfrom the prevalent desire of shape-biasing models can even improve skin lesion\nclassifiers in some cases.",
    "descriptor": "\nComments: Submitted preprint accepted for MIUA 2022\n",
    "authors": [
      "Adriano Lucieri",
      "Fabian Schmeisser",
      "Christoph Peter Balada",
      "Shoaib Ahmed Siddiqui",
      "Andreas Dengel",
      "Sheraz Ahmed"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06466"
  },
  {
    "id": "arXiv:2206.06468",
    "title": "Stable Relationships",
    "abstract": "We study a dynamic model of the relationship between two people where the\nstates depend on the \"power\" in the relationship. We perform a comprehensive\nanalysis of stability of the system, and determine a set of conditions under\nwhich stable relationships are possible. In particular, stable relationships\ncan occur if both people are dominant, but the sum of dominances is below a\nbound determined by the model's parameters. Stable relationships can also occur\nif one person is dominant and the other is submissive, provided the level of\ndominance exceeds the level of submissiveness but not beyond a threshold. We\nalso conclude that a stable relationship is not possible if both people are\nsubmissive. While our model is motivated by a social or romantic relationship,\nit can also be applied to professional or business relationships as well as\ndiplomatic relationships between nations.",
    "descriptor": "",
    "authors": [
      "Sam Ganzfried"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.06468"
  },
  {
    "id": "arXiv:2206.06469",
    "title": "Invariant Structure Learning for Better Generalization and Causal  Explainability",
    "abstract": "Learning the causal structure behind data is invaluable for improving\ngeneralization and obtaining high-quality explanations. We propose a novel\nframework, Invariant Structure Learning (ISL), that is designed to improve\ncausal structure discovery by utilizing generalization as an indication. ISL\nsplits the data into different environments, and learns a structure that is\ninvariant to the target across different environments by imposing a consistency\nconstraint. An aggregation mechanism then selects the optimal classifier based\non a graph structure that reflects the causal mechanisms in the data more\naccurately compared to the structures learnt from individual environments.\nFurthermore, we extend ISL to a self-supervised learning setting where accurate\ncausal structure discovery does not rely on any labels. This self-supervised\nISL utilizes invariant causality proposals by iteratively setting different\nnodes as targets. On synthetic and real-world datasets, we demonstrate that ISL\naccurately discovers the causal structure, outperforms alternative methods, and\nyields superior generalization for datasets with significant distribution\nshifts.",
    "descriptor": "\nComments: 16 pages (including Appendix), 4 figures\n",
    "authors": [
      "Yunhao Ge",
      "Sercan \u00d6. Arik",
      "Jinsung Yoon",
      "Ao Xu",
      "Laurent Itti",
      "Tomas Pfister"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.06469"
  },
  {
    "id": "arXiv:2206.06473",
    "title": "A Dilemma for Solomonoff Prediction",
    "abstract": "The framework of Solomonoff prediction assigns prior probability to\nhypotheses inversely proportional to their Kolmogorov complexity. There are two\nwell-known problems. First, the Solomonoff prior is relative to a choice of\nUniversal Turing machine. Second, the Solomonoff prior is not computable.\nHowever, there are responses to both problems. Different Solomonoff priors\nconverge with more and more data. Further, there are computable approximations\nto the Solomonoff prior. I argue that there is a tension between these two\nresponses. This is because computable approximations to Solomonoff prediction\ndo not always converge.",
    "descriptor": "\nComments: 25 pages. Forthcoming in Philosophy of Science\n",
    "authors": [
      "Sven Neth"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2206.06473"
  },
  {
    "id": "arXiv:2206.06476",
    "title": "Explainable Mixed Data Representation and Lossless Visualization Toolkit  for Knowledge Discovery",
    "abstract": "Developing Machine Learning (ML) algorithms for heterogeneous/mixed data is a\nlongstanding problem. Many ML algorithms are not applicable to mixed data,\nwhich include numeric and non-numeric data, text, graphs and so on to generate\ninterpretable models. Another longstanding problem is developing algorithms for\nlossless visualization of multidimensional mixed data. The further progress in\nML heavily depends on success interpretable ML algorithms for mixed data and\nlossless interpretable visualization of multidimensional data. The later allows\ndeveloping interpretable ML models using visual knowledge discovery by\nend-users, who can bring valuable domain knowledge which is absent in the\ntraining data. The challenges for mixed data include: (1) generating numeric\ncoding schemes for non-numeric attributes for numeric ML algorithms to provide\naccurate and interpretable ML models, (2) generating methods for lossless\nvisualization of n-D non-numeric data and visual rule discovery in these\nvisualizations. This paper presents a classification of mixed data types,\nanalyzes their importance for ML and present the developed experimental toolkit\nto deal with mixed data. It combines the Data Types Editor, VisCanvas data\nvisualization and rule discovery system which is available on GitHub.",
    "descriptor": "\nComments: 8 pages, 15 figures\n",
    "authors": [
      "Boris Kovalerchuk",
      "Elijah McCoy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06476"
  },
  {
    "id": "arXiv:2206.06477",
    "title": "Multivariate Information Theory Uncovers Synergistic Subsystems of the  Human Cerebral Cortex",
    "abstract": "One of the most well-established tools for modeling the brain as a complex\nsystem is the functional connectivity network, which examines the correlations\nbetween pairs of interacting brain regions. While powerful, the network model\nis limited by the restriction that only pairwise dependencies are visible and\npotentially higher-order structures are missed. In this work, we explore how\nmultivariate information theory can reveal higher-order, synergistic\ndependencies in the human brain. Using the O-information, a measure of whether\nthe structure of a system is redundancy- or synergy-dominated, we show that\nsynergistic subsystems are widespread in the human brain. We provide a\nmathematical analysis of the O-information to locate it within a larger\ntaxonomy of multivariate complexity measures. We also show the O-information is\nrelated to a previously established measure, the Tononi-Sporns-Edelman\ncomplexity, and can be understood as an expected difference in integration\nbetween system scales. Highly synergistic subsystems typically sit between\ncanonical functional networks, and may serve to integrate those networks. We\nthen use simulated annealing to find maximally synergistic subsystems, finding\nthat such systems typically comprise $\\approx$10 brain regions, also recruited\nfrom multiple canonical brain systems. Though ubiquitous, highly synergistic\nsubsystems are invisible when considering pairwise functional connectivity,\nsuggesting that higher-order dependencies form a kind of ``shadow structure\"\nthat has been unrecognized by established network-based analyses. We assert\nthat higher-order interactions in the brain represent a vast and under-explored\nspace that, made accessible with tools of multivariate information theory, may\noffer novel scientific insights.",
    "descriptor": "\nComments: 13 pages, 5 figures, 74 references\n",
    "authors": [
      "Thomas F. Varley",
      "Maria Pope",
      "Joshua Faskowitz",
      "Olaf Sporns"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Neurons and Cognition (q-bio.NC)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2206.06477"
  },
  {
    "id": "arXiv:2206.06479",
    "title": "Robust Distillation for Worst-class Performance",
    "abstract": "Knowledge distillation has proven to be an effective technique in improving\nthe performance a student model using predictions from a teacher model.\nHowever, recent work has shown that gains in average efficiency are not uniform\nacross subgroups in the data, and in particular can often come at the cost of\naccuracy on rare subgroups and classes. To preserve strong performance across\nclasses that may follow a long-tailed distribution, we develop distillation\ntechniques that are tailored to improve the student's worst-class performance.\nSpecifically, we introduce robust optimization objectives in different\ncombinations for the teacher and student, and further allow for training with\nany tradeoff between the overall accuracy and the robust worst-class objective.\nWe show empirically that our robust distillation techniques not only achieve\nbetter worst-class performance, but also lead to Pareto improvement in the\ntradeoff between overall performance and worst-class performance compared to\nother baseline methods. Theoretically, we provide insights into what makes a\ngood teacher when the goal is to train a robust student.",
    "descriptor": "",
    "authors": [
      "Serena Wang",
      "Harikrishna Narasimhan",
      "Yichen Zhou",
      "Sara Hooker",
      "Michal Lukasik",
      "Aditya Krishna Menon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06479"
  },
  {
    "id": "arXiv:2206.06481",
    "title": "RigNeRF: Fully Controllable Neural 3D Portraits",
    "abstract": "Volumetric neural rendering methods, such as neural radiance fields (NeRFs),\nhave enabled photo-realistic novel view synthesis. However, in their standard\nform, NeRFs do not support the editing of objects, such as a human head, within\na scene. In this work, we propose RigNeRF, a system that goes beyond just novel\nview synthesis and enables full control of head pose and facial expressions\nlearned from a single portrait video. We model changes in head pose and facial\nexpressions using a deformation field that is guided by a 3D morphable face\nmodel (3DMM). The 3DMM effectively acts as a prior for RigNeRF that learns to\npredict only residuals to the 3DMM deformations and allows us to render novel\n(rigid) poses and (non-rigid) expressions that were not present in the input\nsequence. Using only a smartphone-captured short video of a subject for\ntraining, we demonstrate the effectiveness of our method on free view synthesis\nof a portrait scene with explicit head pose and expression controls. The\nproject page can be found here:\nthis http URL",
    "descriptor": "\nComments: The project page can be found here: this http URL\n",
    "authors": [
      "ShahRukh Athar",
      "Zexiang Xu",
      "Kalyan Sunkavalli",
      "Eli Shechtman",
      "Zhixin Shu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06481"
  },
  {
    "id": "arXiv:2206.06484",
    "title": "On Image Segmentation With Noisy Labels: Characterization and Volume  Properties of the Optimal Solutions to Accuracy and Dice",
    "abstract": "We study two of the most popular performance metrics in medical image\nsegmentation, Accuracy and Dice, when the target labels are noisy. For both\nmetrics, several statements related to characterization and volume properties\nof the set of optimal segmentations are proved, and associated experiments are\nprovided. Our main insights are: (i) the volume of the solutions to both\nmetrics may deviate significantly from the expected volume of the target, (ii)\nthe volume of a solution to Accuracy is always less than or equal to the volume\nof a solution to Dice and (iii) the optimal solutions to both of these metrics\ncoincide when the set of feasible segmentations is constrained to the set of\nsegmentations with the volume equal to the expected volume of the target.",
    "descriptor": "",
    "authors": [
      "Marcus Nordstr\u00f6m",
      "Henrik Hult",
      "Jonas S\u00f6derberg",
      "Fredrik L\u00f6fman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06484"
  },
  {
    "id": "arXiv:2206.06485",
    "title": "What Should I Know? Using Meta-gradient Descent for Predictive Feature  Discovery in a Single Stream of Experience",
    "abstract": "In computational reinforcement learning, a growing body of work seeks to\nconstruct an agent's perception of the world through predictions of future\nsensations; predictions about environment observations are used as additional\ninput features to enable better goal-directed decision-making. An open\nchallenge in this line of work is determining from the infinitely many\npredictions that the agent could possibly make which predictions might best\nsupport decision-making. This challenge is especially apparent in continual\nlearning problems where a single stream of experience is available to a\nsingular agent. As a primary contribution, we introduce a meta-gradient descent\nprocess by which an agent learns 1) what predictions to make, 2) the estimates\nfor its chosen predictions, and 3) how to use those estimates to generate\npolicies that maximize future reward -- all during a single ongoing process of\ncontinual learning. In this manuscript we consider predictions expressed as\nGeneral Value Functions: temporally extended estimates of the accumulation of a\nfuture signal. We demonstrate that through interaction with the environment an\nagent can independently select predictions that resolve partial-observability,\nresulting in performance similar to expertly specified GVFs. By learning,\nrather than manually specifying these predictions, we enable the agent to\nidentify useful predictions in a self-supervised manner, taking a step towards\ntruly autonomous systems.",
    "descriptor": "",
    "authors": [
      "Alexandra Kearney",
      "Anna Koop",
      "Johannes G\u00fcnther",
      "Patrick M. Pilarski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.06485"
  },
  {
    "id": "arXiv:2206.06487",
    "title": "The Modality Focusing Hypothesis: On the Blink of Multimodal Knowledge  Distillation",
    "abstract": "Multimodal knowledge distillation (KD) extends traditional knowledge\ndistillation to the area of multimodal learning. One common practice is to\nadopt a well-performed multimodal network as the teacher in the hope that it\ncan transfer its full knowledge to a unimodal student for performance\nimprovement. In this paper, we investigate the efficacy of multimodal KD. We\nbegin by providing two failure cases of it and demonstrate that KD is not a\nuniversal cure in multimodal knowledge transfer. We present the modality Venn\ndiagram to understand modality relationships and the modality focusing\nhypothesis revealing the decisive factor in the efficacy of multimodal KD.\nExperimental results on 6 multimodal datasets help justify our hypothesis,\ndiagnose failure cases, and point directions to improve distillation\nperformance.",
    "descriptor": "",
    "authors": [
      "Zihui Xue",
      "Zhengqi Gao",
      "Sucheng Ren",
      "Hang Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06487"
  },
  {
    "id": "arXiv:2206.06488",
    "title": "Multimodal Learning with Transformers: A Survey",
    "abstract": "Transformer is a promising neural network learner, and has achieved great\nsuccess in various machine learning tasks. Thanks to the recent prevalence of\nmultimodal applications and big data, Transformer-based multimodal learning has\nbecome a hot topic in AI research. This paper presents a comprehensive survey\nof Transformer techniques oriented at multimodal data. The main contents of\nthis survey include: (1) a background of multimodal learning, Transformer\necosystem, and the multimodal big data era, (2) a theoretical review of Vanilla\nTransformer, Vision Transformer, and multimodal Transformers, from a\ngeometrically topological perspective, (3) a review of multimodal Transformer\napplications, via two important paradigms, i.e., for multimodal pretraining and\nfor specific multimodal tasks, (4) a summary of the common challenges and\ndesigns shared by the multimodal Transformer models and applications, and (5) a\ndiscussion of open problems and potential research directions for the\ncommunity.",
    "descriptor": "",
    "authors": [
      "Peng Xu",
      "Xiatian Zhu",
      "David A. Clifton"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06488"
  },
  {
    "id": "arXiv:2206.06489",
    "title": "BEHAVIOR in Habitat 2.0: Simulator-Independent Logical Task Description  for Benchmarking Embodied AI Agents",
    "abstract": "Robots excel in performing repetitive and precision-sensitive tasks in\ncontrolled environments such as warehouses and factories, but have not been yet\nextended to embodied AI agents providing assistance in household tasks.\nInspired by the catalyzing effect that benchmarks have played in the AI fields\nsuch as computer vision and natural language processing, the community is\nlooking for new benchmarks for embodied AI. Prior work in embodied AI benchmark\ndefines tasks using a different formalism, often specific to one environment,\nsimulator or domain, making it hard to develop general and comparable\nsolutions. In this work, we bring a subset of BEHAVIOR activities into Habitat\n2.0 to benefit from its fast simulation speed, as a first step towards\ndemonstrating the ease of adapting activities defined in the logic space into\ndifferent simulators.",
    "descriptor": "",
    "authors": [
      "Ziang Liu",
      "Roberto Mart\u00edn-Mart\u00edn",
      "Fei Xia",
      "Jiajun Wu",
      "Li Fei-Fei"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.06489"
  },
  {
    "id": "arXiv:2206.06490",
    "title": "Learning Task-Independent Game State Representations from Unlabeled  Images",
    "abstract": "Self-supervised learning (SSL) techniques have been widely used to learn\ncompact and informative representations from high-dimensional complex data. In\nmany computer vision tasks, such as image classification, such methods achieve\nstate-of-the-art results that surpass supervised learning approaches. In this\npaper, we investigate whether SSL methods can be leveraged for the task of\nlearning accurate state representations of games, and if so, to what extent.\nFor this purpose, we collect game footage frames and corresponding sequences of\ngames' internal state from three different 3D games: VizDoom, the CARLA racing\nsimulator and the Google Research Football Environment. We train an image\nencoder with three widely used SSL algorithms using solely the raw frames, and\nthen attempt to recover the internal state variables from the learned\nrepresentations. Our results across all three games showcase significantly\nhigher correlation between SSL representations and the game's internal state\ncompared to pre-trained baseline models such as ImageNet. Such findings suggest\nthat SSL-based visual encoders can yield general -- not tailored to a specific\ntask -- yet informative game representations solely from game pixel\ninformation. Such representations can, in turn, form the basis for boosting the\nperformance of downstream learning tasks in games, including gameplaying,\ncontent generation and player modeling.",
    "descriptor": "\nComments: Conference on Games (CoG) 2022\n",
    "authors": [
      "Chintan Trivedi",
      "Konstantinos Makantasis",
      "Antonios Liapis",
      "Georgios N. Yannakakis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06490"
  },
  {
    "id": "arXiv:2206.06493",
    "title": "A novel reconstruction attack on foreign-trade official statistics, with  a Brazilian case study",
    "abstract": "In this paper we describe, formalize, implement, and experimentally evaluate\na novel transaction re-identification attack against official foreign-trade\nstatistics releases in Brazil. The attack's goal is to re-identify the\nimporters of foreign-trade transactions (by revealing the identity of the\ncompany performing that transaction), which consequently violates those\nimporters' fiscal secrecy (by revealing sensitive information: the value and\nvolume of traded goods). We provide a mathematical formalization of this fiscal\nsecrecy problem using principles from the framework of quantitative information\nflow (QIF), then carefully identify the main sources of imprecision in the\nofficial data releases used as auxiliary information in the attack, and model\ntransaction re-construction as a linear optimization problem solvable through\ninteger linear programming (ILP). We show that this problem is NP-complete, and\nprovide a methodology to identify tractable instances. We exemplify the\nfeasibility of our attack by performing 2,003 transaction re-identifications\nthat in total amount to more than \\$137M, and affect 348 Brazilian companies.\nFurther, since similar statistics are produced by other statistical agencies,\nour attack is of broader concern.",
    "descriptor": "\nComments: 35 pages\n",
    "authors": [
      "Danilo Fabrino Favato",
      "Gabriel Coutinho",
      "M\u00e1rio S. Alvim",
      "Natasha Fernandes"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Econometrics (econ.EM)"
    ],
    "url": "https://arxiv.org/abs/2206.06493"
  },
  {
    "id": "arXiv:2206.06496",
    "title": "Towards Alternative Techniques for Improving Adversarial Robustness:  Analysis of Adversarial Training at a Spectrum of Perturbations",
    "abstract": "Adversarial training (AT) and its variants have spearheaded progress in\nimproving neural network robustness to adversarial perturbations and common\ncorruptions in the last few years. Algorithm design of AT and its variants are\nfocused on training models at a specified perturbation strength $\\epsilon$ and\nonly using the feedback from the performance of that $\\epsilon$-robust model to\nimprove the algorithm. In this work, we focus on models, trained on a spectrum\nof $\\epsilon$ values. We analyze three perspectives: model performance,\nintermediate feature precision and convolution filter sensitivity. In each, we\nidentify alternative improvements to AT that otherwise wouldn't have been\napparent at a single $\\epsilon$. Specifically, we find that for a PGD attack at\nsome strength $\\delta$, there is an AT model at some slightly larger strength\n$\\epsilon$, but no greater, that generalizes best to it. Hence, we propose\noverdesigning for robustness where we suggest training models at an $\\epsilon$\njust above $\\delta$. Second, we observe (across various $\\epsilon$ values) that\nrobustness is highly sensitive to the precision of intermediate features and\nparticularly those after the first and second layer. Thus, we propose adding a\nsimple quantization to defenses that improves accuracy on seen and unseen\nadaptive attacks. Third, we analyze convolution filters of each layer of models\nat increasing $\\epsilon$ and notice that those of the first and second layer\nmay be solely responsible for amplifying input perturbations. We present our\nfindings and demonstrate our techniques through experiments with ResNet and\nWideResNet models on the CIFAR-10 and CIFAR-10-C datasets.",
    "descriptor": "",
    "authors": [
      "Kaustubh Sridhar",
      "Souradeep Dutta",
      "Ramneet Kaur",
      "James Weimer",
      "Oleg Sokolsky",
      "Insup Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06496"
  },
  {
    "id": "arXiv:2206.06501",
    "title": "Optimal Clipping and Magnitude-aware Differentiation for Improved  Quantization-aware Training",
    "abstract": "Data clipping is crucial in reducing noise in quantization operations and\nimproving the achievable accuracy of quantization-aware training (QAT). Current\npractices rely on heuristics to set clipping threshold scalars and cannot be\nshown to be optimal. We propose Optimally Clipped Tensors And Vectors (OCTAV),\na recursive algorithm to determine MSE-optimal clipping scalars. Derived from\nthe fast Newton-Raphson method, OCTAV finds optimal clipping scalars on the\nfly, for every tensor, at every iteration of the QAT routine. Thus, the QAT\nalgorithm is formulated with provably minimum quantization noise at each step.\nIn addition, we reveal limitations in common gradient estimation techniques in\nQAT and propose magnitude-aware differentiation as a remedy to further improve\naccuracy. Experimentally, OCTAV-enabled QAT achieves state-of-the-art accuracy\non multiple tasks. These include training-from-scratch and retraining ResNets\nand MobileNets on ImageNet, and Squad fine-tuning using BERT models, where\nOCTAV-enabled QAT consistently preserves accuracy at low precision\n(4-to-6-bits). Our results require no modifications to the baseline training\nrecipe, except for the insertion of quantization operations where appropriate.",
    "descriptor": "\nComments: Published as a spotlight paper at ICML 2022. Paper contains 16 pages, 5 figures, and 6 tables\n",
    "authors": [
      "Charbel Sakr",
      "Steve Dai",
      "Rangharajan Venkatesan",
      "Brian Zimmer",
      "William J. Dally",
      "Brucek Khailany"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06501"
  },
  {
    "id": "arXiv:2206.06506",
    "title": "Spiking Neural Networks for Frame-based and Event-based Single Object  Localization",
    "abstract": "Spiking neural networks have shown much promise as an energy-efficient\nalternative to artificial neural networks. However, understanding the impacts\nof sensor noises and input encodings on the network activity and performance\nremains difficult with common neuromorphic vision baselines like\nclassification. Therefore, we propose a spiking neural network approach for\nsingle object localization trained using surrogate gradient descent, for frame-\nand event-based sensors. We compare our method with similar artificial neural\nnetworks and show that our model has competitive/better performance in\naccuracy, robustness against various corruptions, and has lower energy\nconsumption. Moreover, we study the impact of neural coding schemes for static\nimages in accuracy, robustness, and energy efficiency. Our observations differ\nimportantly from previous studies on bio-plausible learning rules, which helps\nin the design of surrogate gradient trained architectures, and offers insight\nto design priorities in future neuromorphic technologies in terms of noise\ncharacteristics and data encoding methods.",
    "descriptor": "\nComments: 21 pages, 12 figures\n",
    "authors": [
      "Sami Barchid",
      "Jos\u00e9 Mennesson",
      "Jason Eshraghian",
      "Chaabane Dj\u00e9raba",
      "Mohammed Bennamoun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06506"
  },
  {
    "id": "arXiv:2206.06510",
    "title": "Generalizable Method for Face Anti-Spoofing with Semi-Supervised  Learning",
    "abstract": "Face anti-spoofing has drawn a lot of attention due to the high security\nrequirements in biometric authentication systems. Bringing face biometric to\ncommercial hardware became mostly dependent on developing reliable methods for\ndetecting fake login sessions without specialized sensors. Current CNN-based\nmethod perform well on the domains they were trained for, but often show poor\ngeneralization on previously unseen datasets. In this paper we describe a\nmethod for utilizing unsupervised pretraining for improving performance across\nmultiple datasets without any adaptation, introduce the Entry Antispoofing\nDataset for supervised fine-tuning, and propose a multi-class auxiliary\nclassification layer for augmenting the binary classification task of detecting\nspoofing attempts with explicit interpretable signals. We demonstrate the\nefficiency of our model by achieving state-of-the-art results on cross-dataset\ntesting on MSU-MFSD, Replay-Attack, and OULU-NPU datasets.",
    "descriptor": "",
    "authors": [
      "Nikolay Sergievskiy",
      "Roman Vlasov",
      "Roman Trusov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06510"
  },
  {
    "id": "arXiv:2206.06512",
    "title": "Algorithms for Parallel Generic $hp$-adaptive Finite Element Software",
    "abstract": "The $hp$-adaptive finite element method (FEM) - where one independently\nchooses the mesh size ($h$) and polynomial degree ($p$) to be used on each cell\n- has long been known to have better theoretical convergence properties than\neither $h$- or $p$-adaptive methods alone. However, it is not widely used,\nowing at least in parts to the difficulty of the underlying algorithms and the\nlack of widely usable implementations. This is particularly true when used with\ncontinuous finite elements.\nHerein, we discuss algorithms that are necessary for a comprehensive and\ngeneric implementation of $hp$-adaptive finite element methods on\ndistributed-memory, parallel machines. In particular, we will present a\nmulti-stage algorithm for the unique enumeration of degrees of freedom (DoFs)\nsuitable for continuous finite element spaces, describe considerations for\nweighted load balancing, and discuss the transfer of variable size data between\nprocesses. We illustrate the performance of our algorithms with numerical\nexamples, and demonstrate that they scale reasonably up to at least 16,384\nMessage Passing Interface (MPI) processes.\nWe provide a reference implementation of our algorithms as part of the\nopen-source library deal.II.",
    "descriptor": "\nComments: 25 pages, 10 figures\n",
    "authors": [
      "Marc Fehling",
      "Wolfgang Bangerth"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2206.06512"
  },
  {
    "id": "arXiv:2206.06513",
    "title": "Fiberwise dimensionality reduction of topologically complex data with  vector bundles",
    "abstract": "Datasets with non-trivial large scale topology can be hard to embed in\nlow-dimensional Euclidean space with existing dimensionality reduction\nalgorithms. We propose to model topologically complex datasets using vector\nbundles, in such a way that the base space accounts for the large scale\ntopology, while the fibers account for the local geometry. This allows one to\nreduce the dimensionality of the fibers, while preserving the large scale\ntopology. We formalize this point of view, and, as an application, we describe\nan algorithm which takes as input a dataset together with an initial\nrepresentation of it in Euclidean space, assumed to recover part of its large\nscale topology, and outputs a new representation that integrates local\nrepresentations, obtained through local linear dimensionality reduction, along\nthe initial global representation. We demonstrate this algorithm on examples\ncoming from dynamical systems and chemistry. In these examples, our algorithm\nis able to learn topologically faithful embeddings of the data in lower target\ndimension than various well known metric-based dimensionality reduction\nalgorithms.",
    "descriptor": "\nComments: 15 pages + 5 pages appendix, 9 figures + 1 table\n",
    "authors": [
      "Luis Scoccola",
      "Jose A. Perea"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Machine Learning (cs.LG)",
      "Algebraic Topology (math.AT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.06513"
  },
  {
    "id": "arXiv:2206.06518",
    "title": "Estimating Pose from Pressure Data for Smart Beds with Deep Image-based  Pose Estimators",
    "abstract": "In-bed pose estimation has shown value in fields such as hospital patient\nmonitoring, sleep studies, and smart homes. In this paper, we explore different\nstrategies for detecting body pose from highly ambiguous pressure data, with\nthe aid of pre-existing pose estimators. We examine the performance of\npre-trained pose estimators by using them either directly or by re-training\nthem on two pressure datasets. We also explore other strategies utilizing a\nlearnable pre-processing domain adaptation step, which transforms the vague\npressure maps to a representation closer to the expected input space of common\npurpose pose estimation modules. Accordingly, we used a fully convolutional\nnetwork with multiple scales to provide the pose-specific characteristics of\nthe pressure maps to the pre-trained pose estimation module. Our complete\nanalysis of different approaches shows that the combination of learnable\npre-processing module along with re-training pre-existing image-based pose\nestimators on the pressure data is able to overcome issues such as highly vague\npressure points to achieve very high pose estimation accuracy.",
    "descriptor": "\nComments: The version of record of this article, first published in Applied Intelligence, is available online at Publisher's website this https URL arXiv admin note: substantial text overlap with arXiv:1908.08919\n",
    "authors": [
      "Vandad Davoodnia",
      "Saeed Ghorbani",
      "Ali Etemad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06518"
  },
  {
    "id": "arXiv:2206.06520",
    "title": "Memory-Based Model Editing at Scale",
    "abstract": "Even the largest neural networks make errors, and once-correct predictions\ncan become invalid as the world changes. Model editors make local updates to\nthe behavior of base (pre-trained) models to inject updated knowledge or\ncorrect undesirable behaviors. Existing model editors have shown promise, but\nalso suffer from insufficient expressiveness: they struggle to accurately model\nan edit's intended scope (examples affected by the edit), leading to inaccurate\npredictions for test inputs loosely related to the edit, and they often fail\naltogether after many edits. As a higher-capacity alternative, we propose\nSemi-Parametric Editing with a Retrieval-Augmented Counterfactual Model\n(SERAC), which stores edits in an explicit memory and learns to reason over\nthem to modulate the base model's predictions as needed. To enable more\nrigorous evaluation of model editors, we introduce three challenging language\nmodel editing problems based on question answering, fact-checking, and dialogue\ngeneration. We find that only SERAC achieves high performance on all three\nproblems, consistently outperforming existing approaches to model editing by a\nsignificant margin. Code, data, and additional project information will be made\navailable at https://sites.google.com/view/serac-editing.",
    "descriptor": "\nComments: ICML 2022. Project site at this https URL\n",
    "authors": [
      "Eric Mitchell",
      "Charles Lin",
      "Antoine Bosselut",
      "Christopher D. Manning",
      "Chelsea Finn"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.06520"
  },
  {
    "id": "arXiv:2206.06522",
    "title": "LST: Ladder Side-Tuning for Parameter and Memory Efficient Transfer  Learning",
    "abstract": "Fine-tuning large pre-trained models on downstream tasks has been adopted in\na variety of domains recently. However, it is costly to update the entire\nparameter set of large pre-trained models. Although recently proposed\nparameter-efficient transfer learning (PETL) techniques allow updating a small\nsubset of parameters (e.g. only using 2% of parameters) inside a pre-trained\nbackbone network for a new task, they only reduce the training memory\nrequirement by up to 30%. This is because the gradient computation for the\ntrainable parameters still requires backpropagation through the large\npre-trained backbone model. To address this, we propose Ladder Side-Tuning\n(LST), a new PETL technique that reduces training memory requirements by more\nsubstantial amounts. Unlike existing parameter-efficient methods that insert\nadditional parameters inside backbone networks, we train a ladder side network,\na small and separate network that takes intermediate activations as input via\nshortcut connections (ladders) from backbone networks and makes predictions.\nLST has significantly lower memory requirements than previous methods, because\nit does not require backpropagation through the backbone network, but instead\nonly through the side network and ladder connections. We evaluate our method\nwith various models (T5, CLIP-T5) on both NLP (GLUE) and vision-language (VQA,\nGQA, NLVR2, MSCOCO) tasks. LST saves 69% of the memory costs to fine-tune the\nwhole network, while other methods only save 26% of that in similar parameter\nusages (hence, 2.7x more memory savings). Moreover, LST achieves higher\naccuracy than Adapter and LoRA in a low-memory regime. To further show the\nadvantage of this better memory efficiency, we also apply LST to larger T5\nmodels (T5-large, T5-3B), attaining better GLUE performance than full\nfine-tuning and other PETL methods. The exact same trend also holds in our\nexperiments on VL tasks.",
    "descriptor": "\nComments: 13 pages; our code is available at: this https URL\n",
    "authors": [
      "Yi-Lin Sung",
      "Jaemin Cho",
      "Mohit Bansal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06522"
  },
  {
    "id": "arXiv:2206.06530",
    "title": "MACQ: A Holistic View of Model Acquisition Techniques",
    "abstract": "For over three decades, the planning community has explored countless methods\nfor data-driven model acquisition. These range in sophistication (e.g., simple\nset operations to full-blown reformulations), methodology (e.g., logic-based\nvs. planing-based), and assumptions (e.g., fully vs. partially observable).\nWith no fewer than 43 publications in the space, it can be overwhelming to\nunderstand what approach could or should be applied in a new setting. We\npresent a holistic characterization of the action model acquisition space and\nfurther introduce a unifying framework for automated action model acquisition.\nWe have re-implemented some of the landmark approaches in the area, and our\ncharacterization of all the techniques offers deep insight into the research\nopportunities that remain; i.e., those settings where no technique is capable\nof solving.",
    "descriptor": "\nComments: 8 pages, 7 figures, KEPS Workshop Submission\n",
    "authors": [
      "Ethan Callanan",
      "Rebecca De Venezia",
      "Victoria Armstrong",
      "Alison Paredes",
      "Tathagata Chakraborti",
      "Christian Muise"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.06530"
  },
  {
    "id": "arXiv:2206.06533",
    "title": "3D scene reconstruction from monocular spherical video with motion  parallax",
    "abstract": "In this paper, we describe a method to capture nearly entirely spherical (360\ndegree) depth information using two adjacent frames from a single spherical\nvideo with motion parallax. After illustrating a spherical depth information\nretrieval using two spherical cameras, we demonstrate monocular spherical\nstereo by using stabilized first-person video footage. Experiments demonstrated\nthat the depth information was retrieved on up to 97% of the entire sphere in\nsolid angle. At a speed of 30 km/h, we were able to estimate the depth of an\nobject located over 30 m from the camera. We also reconstructed the 3D\nstructures (point cloud) using the obtained depth data and confirmed the\nstructures can be clearly observed. We can apply this method to 3D structure\nretrieval of surrounding environments such as 1) previsualization, location\nhunting/planning of a film, 2) real scene/computer graphics synthesis and 3)\nmotion capture. Thanks to its simplicity, this method can be applied to various\nvideos. As there is no pre-condition other than to be a 360 video with motion\nparallax, we can use any 360 videos including those on the Internet to\nreconstruct the surrounding environments. The cameras can be lightweight enough\nto be mounted on a drone. We also demonstrated such applications.",
    "descriptor": "\nComments: 13 pages, 18 figures\n",
    "authors": [
      "Kenji Tanaka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.06533"
  },
  {
    "id": "arXiv:2206.06537",
    "title": "A software toolkit and hardware platform for investigating and comparing  robot autonomy algorithms in simulation and reality",
    "abstract": "We describe a software framework and a hardware platform used in tandem for\nthe design and analysis of robot autonomy algorithms in simulation and reality.\nThe software, which is open source, containerized, and operating system (OS)\nindependent, has three main components: a ROS 2 interface to a C++ vehicle\nsimulation framework (Chrono), which provides high-fidelity wheeled/tracked\nvehicle and sensor simulation; a basic ROS 2-based autonomy stack for algorithm\ndesign and testing; and, a development ecosystem which enables visualization,\nand hardware-in-the-loop experimentation in perception, state estimation, path\nplanning, and controls. The accompanying hardware platform is a 1/6th scale\nvehicle augmented with reconfigurable mountings for computing, sensing, and\ntracking. Its purpose is to allow algorithms and sensor configurations to be\nphysically tested and improved. Since this vehicle platform has a digital twin\nwithin the simulation environment, one can test and compare the same algorithms\nand autonomy stack in simulation and reality. This platform has been built with\nan eye towards characterizing and managing the simulation-to-reality gap.\nHerein, we describe how this platform is set up, deployed, and used to improve\nautonomy for mobility applications.",
    "descriptor": "",
    "authors": [
      "Asher Elmquist",
      "Aaron Young",
      "Ishaan Mahajan",
      "Kyle Fahey",
      "Abhiraj Dashora",
      "Sriram Ashokkumar",
      "Stefan Caldararu",
      "Victor Freire",
      "Xiangru Xu",
      "Radu Serban",
      "Dan Negrut"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.06537"
  },
  {
    "id": "arXiv:2206.06544",
    "title": "A Survey of Automated Data Augmentation Algorithms for Deep  Learning-based Image Classication Tasks",
    "abstract": "In recent years, one of the most popular techniques in the computer vision\ncommunity has been the deep learning technique. As a data-driven technique,\ndeep model requires enormous amounts of accurately labelled training data,\nwhich is often inaccessible in many real-world applications. A data-space\nsolution is Data Augmentation (DA), that can artificially generate new images\nout of original samples. Image augmentation strategies can vary by dataset, as\ndifferent data types might require different augmentations to facilitate model\ntraining. However, the design of DA policies has been largely decided by the\nhuman experts with domain knowledge, which is considered to be highly\nsubjective and error-prone. To mitigate such problem, a novel direction is to\nautomatically learn the image augmentation policies from the given dataset\nusing Automated Data Augmentation (AutoDA) techniques. The goal of AutoDA\nmodels is to find the optimal DA policies that can maximize the model\nperformance gains. This survey discusses the underlying reasons of the\nemergence of AutoDA technology from the perspective of image classification. We\nidentify three key components of a standard AutoDA model: a search space, a\nsearch algorithm and an evaluation function. Based on their architecture, we\nprovide a systematic taxonomy of existing image AutoDA approaches. This paper\npresents the major works in AutoDA field, discussing their pros and cons, and\nproposing several potential directions for future improvements.",
    "descriptor": "\nComments: 68 pages, 9 figures. Submitted to Knowledge and Information Systems (KAIS)\n",
    "authors": [
      "Zihan Yang",
      "Richard O. Sinnott",
      "James Bailey",
      "Qiuhong Ke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06544"
  },
  {
    "id": "arXiv:2206.06549",
    "title": "Using Defect Prediction to Improve the Bug Detection Capability of  Search-Based Software Testing",
    "abstract": "Automated test generators, such as search based software testing (SBST)\ntechniques, replace the tedious and expensive task of manually writing test\ncases. SBST techniques are effective at generating tests with high code\ncoverage. However, is high code coverage sufficient to maximise the number of\nbugs found? We argue that SBST needs to be focused to search for test cases in\ndefective areas rather in non-defective areas of the code in order to maximise\nthe likelihood of discovering the bugs. Defect prediction algorithms give\nuseful information about the bug-prone areas in software. Therefore, we\nformulate the objective of this thesis: \\textit{Improve the bug detection\ncapability of SBST by incorporating defect prediction information}. To achieve\nthis, we devise two research objectives, i.e., 1) Develop a novel approach\n(SBST$_{CL}$) that allocates time budget to classes based on the likelihood of\nclasses being defective, and 2) Develop a novel strategy (SBST$_{ML}$) to guide\nthe underlying search algorithm (i.e., genetic algorithm) towards the defective\nareas in a class. Through empirical evaluation on 434 real reported bugs in the\nDefects4J dataset, we demonstrate that our novel approach, SBST$_{CL}$, is\nsignificantly more efficient than the state of the art SBST when they are given\na tight time budget in a resource constrained environment.",
    "descriptor": "\nComments: 5 pages, 2 figures\n",
    "authors": [
      "Anjana Perera"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.06549"
  },
  {
    "id": "arXiv:2206.06550",
    "title": "Automated Testing of Image Captioning Systems",
    "abstract": "Image captioning (IC) systems, which automatically generate a text\ndescription of the salient objects in an image (real or synthetic), have seen\ngreat progress over the past few years due to the development of deep neural\nnetworks. IC plays an indispensable role in human society, for example,\nlabeling massive photos for scientific studies and assisting visually-impaired\npeople in perceiving the world. However, even the top-notch IC systems, such as\nMicrosoft Azure Cognitive Services and IBM Image Caption Generator, may return\nincorrect results, leading to the omission of important objects, deep\nmisunderstanding, and threats to personal safety.\nTo address this problem, we propose MetaIC, the \\textit{first} metamorphic\ntesting approach to validate IC systems. Our core idea is that the object names\nshould exhibit directional changes after object insertion. Specifically, MetaIC\n(1) extracts objects from existing images to construct an object corpus; (2)\ninserts an object into an image via novel object resizing and location tuning\nalgorithms; and (3) reports image pairs whose captions do not exhibit\ndifferences in an expected way. In our evaluation, we use MetaIC to test one\nwidely-adopted image captioning API and five state-of-the-art (SOTA) image\ncaptioning models. Using 1,000 seeds, MetaIC successfully reports 16,825\nerroneous issues with high precision (84.9\\%-98.4\\%). There are three kinds of\nerrors: misclassification, omission, and incorrect quantity. We visualize the\nerrors reported by MetaIC, which shows that flexible overlapping setting\nfacilitates IC testing by increasing and diversifying the reported errors. In\naddition, MetaIC can be further generalized to detect label errors in the\ntraining dataset, which has successfully detected 151 incorrect labels in MS\nCOCO Caption, a standard dataset in image captioning.",
    "descriptor": "",
    "authors": [
      "Boxi Yu",
      "Zhiqing Zhong",
      "Xinran Qin",
      "Jiayi Yao",
      "Yuancheng Wang",
      "Pinjia He"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.06550"
  },
  {
    "id": "arXiv:2206.06553",
    "title": "Safe Output Feedback Motion Planning from Images via Learned Perception  Modules and Contraction Theory",
    "abstract": "We present a motion planning algorithm for a class of uncertain\ncontrol-affine nonlinear systems which guarantees runtime safety and goal\nreachability when using high-dimensional sensor measurements (e.g., RGB-D\nimages) and a learned perception module in the feedback control loop. First,\ngiven a dataset of states and observations, we train a perception system that\nseeks to invert a subset of the state from an observation, and estimate an\nupper bound on the perception error which is valid with high probability in a\ntrusted domain near the data. Next, we use contraction theory to design a\nstabilizing state feedback controller and a convergent dynamic state observer\nwhich uses the learned perception system to update its state estimate. We\nderive a bound on the trajectory tracking error when this controller is\nsubjected to errors in the dynamics and incorrect state estimates. Finally, we\nintegrate this bound into a sampling-based motion planner, guiding it to return\ntrajectories that can be safely tracked at runtime using sensor data. We\ndemonstrate our approach in simulation on a 4D car, a 6D planar quadrotor, and\na 17D manipulation task with RGB(-D) sensor measurements, demonstrating that\nour method safely and reliably steers the system to the goal, while baselines\nthat fail to consider the trusted domain or state estimation errors can be\nunsafe.",
    "descriptor": "\nComments: Workshop on the Algorithmic Foundations of Robotics (WAFR) XV, 2022, College Park, MD, USA (accepted)\n",
    "authors": [
      "Glen Chou",
      "Necmiye Ozay",
      "Dmitry Berenson"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.06553"
  },
  {
    "id": "arXiv:2206.06556",
    "title": "F3 Hand: A Versatile Robot Hand Inspired by Human Thumb and Index  Fingers",
    "abstract": "It is challenging to grasp various objects with varying sizes and shapes with\na single robot hand. To address this, we propose a new robot hand called the\n'F3 hand' inspired by the complex movements of human index finger and thumb.\nThe F3 hand attempts to realize complex human-like grasping movements by\ncombining a parallel motion finger and a rotational motion finger with an\nadaptive function. In order to confirm the performance of our hand, we attached\nit to a mobile manipulator - the Toyota Human Support Robot (HSR) and conducted\ngrasping experiments. In our results, we show that it is able to grasp all YCB\nobjects (82 in total), including washers with outer diameters as small as\n6.4mm. We also built a system for intuitive operation with a 3D mouse and grasp\nan additional 24 objects, including small toothpicks and paper clips and large\npitchers and cracker boxes. The F3 hand is able to achieve a 98% success rate\nin grasping even under imprecise control and positional offsets. Furthermore,\nowing to the finger's adaptive function, we demonstrate characteristics of the\nF3 hand that facilitate the grasping of soft objects such as strawberries in a\ndesirable posture.",
    "descriptor": "\nComments: 8 pages. Accepted at IEEE RO-MAN 2022. An accompanying video is available at this https URL\n",
    "authors": [
      "Naoki Fukaya",
      "Avinash Ummadisingu",
      "Guilherme Maeda",
      "Shin-ichi Maeda"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.06556"
  },
  {
    "id": "arXiv:2206.06561",
    "title": "FreeKD: Free-direction Knowledge Distillation for Graph Neural Networks",
    "abstract": "Knowledge distillation (KD) has demonstrated its effectiveness to boost the\nperformance of graph neural networks (GNNs), where its goal is to distill\nknowledge from a deeper teacher GNN into a shallower student GNN. However, it\nis actually difficult to train a satisfactory teacher GNN due to the well-known\nover-parametrized and over-smoothing issues, leading to invalid knowledge\ntransfer in practical applications. In this paper, we propose the first\nFree-direction Knowledge Distillation framework via Reinforcement learning for\nGNNs, called FreeKD, which is no longer required to provide a deeper\nwell-optimized teacher GNN. The core idea of our work is to collaboratively\nbuild two shallower GNNs in an effort to exchange knowledge between them via\nreinforcement learning in a hierarchical way. As we observe that one typical\nGNN model often has better and worse performances at different nodes during\ntraining, we devise a dynamic and free-direction knowledge transfer strategy\nthat consists of two levels of actions: 1) node-level action determines the\ndirections of knowledge transfer between the corresponding nodes of two\nnetworks; and then 2) structure-level action determines which of the local\nstructures generated by the node-level actions to be propagated. In essence,\nour FreeKD is a general and principled framework which can be naturally\ncompatible with GNNs of different architectures. Extensive experiments on five\nbenchmark datasets demonstrate our FreeKD outperforms two base GNNs in a large\nmargin, and shows its efficacy to various GNNs. More surprisingly, our FreeKD\nhas comparable or even better performance than traditional KD algorithms that\ndistill knowledge from a deeper and stronger teacher GNN.",
    "descriptor": "\nComments: 10 pages, 5 figures, accepted to KDD 2022\n",
    "authors": [
      "Kaituo Feng",
      "Changsheng Li",
      "Ye Yuan",
      "Guoren Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06561"
  },
  {
    "id": "arXiv:2206.06563",
    "title": "Zeroth-Order Topological Insights into Iterative Magnitude Pruning",
    "abstract": "Modern-day neural networks are famously large, yet also highly redundant and\ncompressible; there exist numerous pruning strategies in the deep learning\nliterature that yield over 90% sparser sub-networks of fully-trained, dense\narchitectures while still maintaining their original accuracies. Amongst these\nmany methods though -- thanks to its conceptual simplicity, ease of\nimplementation, and efficacy -- Iterative Magnitude Pruning (IMP) dominates in\npractice and is the de facto baseline to beat in the pruning community.\nHowever, theoretical explanations as to why a simplistic method such as IMP\nworks at all are few and limited. In this work, we leverage the notion of\npersistent homology to gain insights into the workings of IMP and show that it\ninherently encourages retention of those weights which preserve topological\ninformation in a trained network. Subsequently, we also provide bounds on how\nmuch different networks can be pruned while perfectly preserving their zeroth\norder topological features, and present a modified version of IMP to do the\nsame.",
    "descriptor": "\nComments: Presented (with proceedings) at ICML 2022 Workshop on Topology, Algebra, and Geometry in Machine Learning. 16 pages, 5 figures\n",
    "authors": [
      "Aishwarya Balwani",
      "Jakob Krzyston"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Algebraic Topology (math.AT)"
    ],
    "url": "https://arxiv.org/abs/2206.06563"
  },
  {
    "id": "arXiv:2206.06565",
    "title": "LIFT: Language-Interfaced Fine-Tuning for Non-Language Machine Learning  Tasks",
    "abstract": "Fine-tuning pretrained language models (LMs) without making any architectural\nchanges has become a norm for learning various language downstream tasks.\nHowever, for non-language downstream tasks, a common practice is to employ\ntask-specific designs for input, output layers, and loss functions. For\ninstance, it is possible to fine-tune an LM into an MNIST classifier by\nreplacing the word embedding layer with an image patch embedding layer, the\nword token output layer with a 10-way output layer, and the word prediction\nloss with a 10-way classification loss, respectively. A natural question\narises: can LM fine-tuning solve non-language downstream tasks without changing\nthe model architecture or loss function? To answer this, we propose\nLanguage-Interfaced Fine-Tuning (LIFT) and study its efficacy and limitations\nby conducting an extensive empirical study on a suite of non-language\nclassification and regression tasks. LIFT does not make any changes to the\nmodel architecture or loss function, and it solely relies on the natural\nlanguage interface, enabling \"no-code machine learning with LMs.\" We find that\nLIFT performs relatively well across a wide range of low-dimensional\nclassification and regression tasks, matching the performances of the best\nbaselines in many cases, especially for the classification tasks. We report the\nexperimental results on the fundamental properties of LIFT, including its\ninductive bias, sample efficiency, ability to extrapolate, robustness to\noutliers and label noise, and generalization. We also analyze a few\nproperties/techniques specific to LIFT, e.g., context-aware learning via\nappropriate prompting, quantification of predictive uncertainty, and two-stage\nfine-tuning. Our code is available at\nhttps://github.com/UW-Madison-Lee-Lab/LanguageInterfacedFineTuning.",
    "descriptor": "",
    "authors": [
      "Tuan Dinh",
      "Yuchen Zeng",
      "Ruisu Zhang",
      "Ziqian Lin",
      "Shashank Rajput",
      "Michael Gira",
      "Jy-yong Sohn",
      "Dimitris Papailiopoulos",
      "Kangwook Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.06565"
  },
  {
    "id": "arXiv:2206.06568",
    "title": "Distributed and Distribution-Robust Meta Reinforcement Learning  (D2-RMRL) for Data Pre-storing and Routing in Cube Satellite Networks",
    "abstract": "In this paper, the problem of data pre-storing and routing in dynamic,\nresource-constrained cube satellite networks is studied. In such a network,\neach cube satellite delivers requested data to user clusters under its\ncoverage. A group of ground gateways will route and pre-store certain data to\nthe satellites, such that the ground users can be directly served with the\npre-stored data. This pre-storing and routing design problem is formulated as a\ndecentralized Markov decision process (Dec-MDP) in which we seek to find the\noptimal strategy that maximizes the pre-store hit rate, i.e., the fraction of\nusers being directly served with the pre-stored data. To obtain the optimal\nstrategy, a distributed distribution-robust meta reinforcement learning\n(D2-RMRL) algorithm is proposed that consists of three key ingredients:\nvalue-decomposition for achieving the global optimum in distributed setting\nwith minimum communication overhead, meta learning to obtain the optimal\ninitial to reduce the training time under dynamic conditions, and pre-training\nto further speed up the meta training procedure. Simulation results show that,\nusing the proposed value decomposition and meta training techniques, the\nsatellite networks can achieve a 31.8% improvement of the pre-store hits and a\n40.7% improvement of the convergence speed, compared to a baseline\nreinforcement learning algorithm. Moreover, the use of the proposed\npre-training mechanism helps to shorten the meta-learning procedure by up to\n43.7%.",
    "descriptor": "",
    "authors": [
      "Ye Hu",
      "Xiaodong Wang",
      "Walid Saad"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.06568"
  },
  {
    "id": "arXiv:2206.06573",
    "title": "Speech intelligibility of simulated hearing loss sounds and its  prediction using the Gammachirp Envelope Similarity Index (GESI)",
    "abstract": "In the present study, speech intelligibility (SI) experiments were performed\nusing simulated hearing loss (HL) sounds in laboratory and remote environments\nto clarify the effects of peripheral dysfunction. Noisy speech sounds were\nprocessed to simulate the average HL of 70- and 80-year-olds using Wadai\nHearing Impairment Simulator (WHIS). These sounds were presented to normal\nhearing (NH) listeners whose cognitive function could be assumed to be normal.\nThe results showed that the divergence was larger in the remote experiments\nthan in the laboratory ones. However, the remote results could be equalized to\nthe laboratory ones, mostly through data screening using the results of tone\npip tests prepared on the experimental web page. In addition, a newly proposed\nobjective intelligibility measure (OIM) called the Gammachirp Envelope\nSimilarity Index (GESI) explained the psychometric functions in the laboratory\nand remote experiments fairly well. GESI has the potential to explain the SI of\nHI listeners by properly setting HL parameters.",
    "descriptor": "\nComments: This paper was submitted to Interspeech 2022\n",
    "authors": [
      "Toshio Irino",
      "Honoka Tamaru",
      "Ayako Yamamoto"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.06573"
  },
  {
    "id": "arXiv:2206.06577",
    "title": "Physics Informed Neural Fields for Smoke Reconstruction with Sparse Data",
    "abstract": "High-fidelity reconstruction of fluids from sparse multiview RGB videos\nremains a formidable challenge due to the complexity of the underlying physics\nas well as complex occlusion and lighting in captures. Existing solutions\neither assume knowledge of obstacles and lighting, or only focus on simple\nfluid scenes without obstacles or complex lighting, and thus are unsuitable for\nreal-world scenes with unknown lighting or arbitrary obstacles. We present the\nfirst method to reconstruct dynamic fluid by leveraging the governing physics\n(ie, Navier -Stokes equations) in an end-to-end optimization from sparse videos\nwithout taking lighting conditions, geometry information, or boundary\nconditions as input. We provide a continuous spatio-temporal scene\nrepresentation using neural networks as the ansatz of density and velocity\nsolution functions for fluids as well as the radiance field for static objects.\nWith a hybrid architecture that separates static and dynamic contents, fluid\ninteractions with static obstacles are reconstructed for the first time without\nadditional geometry input or human labeling. By augmenting time-varying neural\nradiance fields with physics-informed deep learning, our method benefits from\nthe supervision of images and physical priors. To achieve robust optimization\nfrom sparse views, we introduced a layer-by-layer growing strategy to\nprogressively increase the network capacity. Using progressively growing models\nwith a new regularization term, we manage to disentangle density-color\nambiguity in radiance fields without overfitting. A pretrained\ndensity-to-velocity fluid model is leveraged in addition as the data prior to\navoid suboptimal velocity which underestimates vorticity but trivially fulfills\nphysical equations. Our method exhibits high-quality results with relaxed\nconstraints and strong flexibility on a representative set of synthetic and\nreal flow captures.",
    "descriptor": "\nComments: accepted to ACM Transactions On Graphics (SIGGRAPH 2022), further info:\\url{this https URL}\n",
    "authors": [
      "Mengyu Chu",
      "Lingjie Liu",
      "Quan Zheng",
      "Erik Franz",
      "Hans-Peter Seidel",
      "Christian Theobalt",
      "Rhaleb Zayer"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06577"
  },
  {
    "id": "arXiv:2206.06581",
    "title": "CHQ-Summ: A Dataset for Consumer Healthcare Question Summarization",
    "abstract": "The quest for seeking health information has swamped the web with consumers'\nhealth-related questions. Generally, consumers use overly descriptive and\nperipheral information to express their medical condition or other healthcare\nneeds, contributing to the challenges of natural language understanding. One\nway to address this challenge is to summarize the questions and distill the key\ninformation of the original question. To address this issue, we introduce a new\ndataset, CHQ-Summ that contains 1507 domain-expert annotated consumer health\nquestions and corresponding summaries. The dataset is derived from the\ncommunity question-answering forum and therefore provides a valuable resource\nfor understanding consumer health-related posts on social media. We benchmark\nthe dataset on multiple state-of-the-art summarization models to show the\neffectiveness of the dataset.",
    "descriptor": "",
    "authors": [
      "Shweta Yadav",
      "Deepak Gupta",
      "Dina Demner-Fushman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.06581"
  },
  {
    "id": "arXiv:2206.06583",
    "title": "Exploring evolution-based & -free protein language models as protein  function predictors",
    "abstract": "Large-scale Protein Language Models (PLMs) have improved performance in\nprotein prediction tasks, ranging from 3D structure prediction to various\nfunction predictions. In particular, AlphaFold, a ground-breaking AI system,\ncould potentially reshape structural biology. However, the utility of the PLM\nmodule in AlphaFold, Evoformer, has not been explored beyond structure\nprediction. In this paper, we investigate the representation ability of three\npopular PLMs: ESM-1b (single sequence), MSA-Transformer (multiple sequence\nalignment) and Evoformer (structural), with a special focus on Evoformer.\nSpecifically, we aim to answer the following key questions: (\\romannumeral1)\nDoes the Evoformer trained as part of AlphaFold produce representations\namenable to predicting protein function? (\\romannumeral2) If yes, can Evoformer\nreplace ESM-1b and MSA-Transformer? (\\romannumeral3) How much do these PLMs\nrely on evolution-related protein data? In this regard, are they complementary\nto each other? We compare these models by empirical study along with new\ninsights and conclusions.Finally, we release code and datasets for\nreproducibility.",
    "descriptor": "",
    "authors": [
      "Mingyang Hu",
      "Fajie Yuan",
      "Kevin K. Yang",
      "Fusong Ju",
      "Jin Su",
      "Hui Wang",
      "Fei Yang",
      "Qiuyang Ding"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2206.06583"
  },
  {
    "id": "arXiv:2206.06586",
    "title": "FreeTransfer-X: Safe and Label-Free Cross-Lingual Transfer from  Off-the-Shelf Models",
    "abstract": "Cross-lingual transfer (CLT) is of various applications. However, labeled\ncross-lingual corpus is expensive or even inaccessible, especially in the\nfields where labels are private, such as diagnostic results of symptoms in\nmedicine and user profiles in business. Nevertheless, there are off-the-shelf\nmodels in these sensitive fields. Instead of pursuing the original labels, a\nworkaround for CLT is to transfer knowledge from the off-the-shelf models\nwithout labels. To this end, we define a novel CLT problem named FreeTransfer-X\nthat aims to achieve knowledge transfer from the off-the-shelf models in\nrich-resource languages. To address the problem, we propose a 2-step knowledge\ndistillation (KD, Hinton et al., 2015) framework based on multilingual\npre-trained language models (mPLM). The significant improvement over strong\nneural machine translation (NMT) baselines demonstrates the effectiveness of\nthe proposed method. In addition to reducing annotation cost and protecting\nprivate labels, the proposed method is compatible with different networks and\neasy to be deployed. Finally, a range of analyses indicate the great potential\nof the proposed method.",
    "descriptor": "\nComments: to appear in the findings of NAACL 2022\n",
    "authors": [
      "Yinpeng Guo",
      "Liangyou Li",
      "Xin Jiang",
      "Qun Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.06586"
  },
  {
    "id": "arXiv:2206.06587",
    "title": "Learning Enhanced Representations for Tabular Data via Neighborhood  Propagation",
    "abstract": "Prediction over tabular data is an essential and fundamental problem in many\nimportant downstream tasks. However, existing methods either take a data\ninstance of the table independently as input or do not fully utilize the\nmulti-rows features and labels to directly change and enhance the target data\nrepresentations. In this paper, we propose to 1) construct a hypergraph from\nrelevant data instance retrieval to model the cross-row and cross-column\npatterns of those instances, and 2) perform message Propagation to Enhance the\ntarget data instance representation for Tabular prediction tasks. Specifically,\nour specially-designed message propagation step benefits from 1) fusion of\nlabel and features during propagation, and 2) locality-aware high-order feature\ninteractions. Experiments on two important tabular data prediction tasks\nvalidate the superiority of the proposed PET model against other baselines.\nAdditionally, we demonstrate the effectiveness of the model components and the\nfeature enhancement ability of PET via various ablation studies and\nvisualizations. The code is included in https://github.com/KounianhuaDu/PET.",
    "descriptor": "",
    "authors": [
      "Kounianhua Du",
      "Weinan Zhang",
      "Ruiwen Zhou",
      "Yangkun Wang",
      "Xilong Zhao",
      "Jiarui Jin",
      "Quan Gan",
      "Zheng Zhang",
      "David Wipf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.06587"
  },
  {
    "id": "arXiv:2206.06588",
    "title": "Shopping Queries Dataset: A Large-Scale ESCI Benchmark for Improving  Product Search",
    "abstract": "Improving the quality of search results can significantly enhance users\nexperience and engagement with search engines. In spite of several recent\nadvancements in the fields of machine learning and data mining, correctly\nclassifying items for a particular user search query has been a long-standing\nchallenge, which still has a large room for improvement. This paper introduces\nthe \"Shopping Queries Dataset\", a large dataset of difficult Amazon search\nqueries and results, publicly released with the aim of fostering research in\nimproving the quality of search results. The dataset contains around 130\nthousand unique queries and 2.6 million manually labeled (query,product)\nrelevance judgements. The dataset is multilingual with queries in English,\nJapanese, and Spanish. The Shopping Queries Dataset is being used in one of the\nKDDCup'22 challenges. In this paper, we describe the dataset and present three\nevaluation tasks along with baseline results: (i) ranking the results list,\n(ii) classifying product results into relevance categories, and (iii)\nidentifying substitute products for a given query. We anticipate that this data\nwill become the gold standard for future research in the topic of product\nsearch.",
    "descriptor": "",
    "authors": [
      "Chandan K. Reddy",
      "Llu\u00eds M\u00e0rquez",
      "Fran Valero",
      "Nikhil Rao",
      "Hugo Zaragoza",
      "Sambaran Bandyopadhyay",
      "Arnab Biswas",
      "Anlu Xing",
      "Karthik Subbian"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06588"
  },
  {
    "id": "arXiv:2206.06592",
    "title": "Downlink Power Allocation in Massive MIMO via Deep Learning: Adversarial  Attacks and Training",
    "abstract": "The successful emergence of deep learning (DL) in wireless system\napplications has raised concerns about new security-related challenges. One\nsuch security challenge is adversarial attacks. Although there has been much\nwork demonstrating the susceptibility of DL-based classification tasks to\nadversarial attacks, regression-based problems in the context of a wireless\nsystem have not been studied so far from an attack perspective. The aim of this\npaper is twofold: (i) we consider a regression problem in a wireless setting\nand show that adversarial attacks can break the DL-based approach and (ii) we\nanalyze the effectiveness of adversarial training as a defensive technique in\nadversarial settings and show that the robustness of DL-based wireless system\nagainst attacks improves significantly. Specifically, the wireless application\nconsidered in this paper is the DL-based power allocation in the downlink of a\nmulticell massive multi-input-multi-output system, where the goal of the attack\nis to yield an infeasible solution by the DL model. We extend the\ngradient-based adversarial attacks: fast gradient sign method (FGSM), momentum\niterative FGSM, and projected gradient descent method to analyze the\nsusceptibility of the considered wireless application with and without\nadversarial training. We analyze the deep neural network (DNN) models\nperformance against these attacks, where the adversarial perturbations are\ncrafted using both the white-box and black-box attacks.",
    "descriptor": "\nComments: 13 pages, 14 figures, published in IEEE Transactions on Cognitive Communications and Networking\n",
    "authors": [
      "B. R. Manoj",
      "Meysam Sadeghi",
      "Erik G. Larsson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.06592"
  },
  {
    "id": "arXiv:2206.06593",
    "title": "On Finite-Sample Identifiability of Contrastive Learning-Based Nonlinear  Independent Component Analysis",
    "abstract": "Nonlinear independent component analysis (nICA) aims at recovering\nstatistically independent latent components that are mixed by unknown nonlinear\nfunctions. Central to nICA is the identifiability of the latent components,\nwhich had been elusive until very recently. Specifically, Hyv\\\"arinen et al.\nhave shown that the nonlinearly mixed latent components are identifiable (up to\noften inconsequential ambiguities) under a generalized contrastive learning\n(GCL) formulation, given that the latent components are independent conditioned\non a certain auxiliary variable. The GCL-based identifiability of nICA is\nelegant, and establishes interesting connections between nICA and popular\nunsupervised/self-supervised learning paradigms in representation learning,\ncausal learning, and factor disentanglement. However, existing identifiability\nanalyses of nICA all build upon an unlimited sample assumption and the use of\nideal universal function learners -- which creates a non-negligible gap between\ntheory and practice.\nClosing the gap is a nontrivial challenge, as there is a lack of established\n``textbook'' routine for finite sample analysis of such unsupervised problems.\nThis work puts forth a finite-sample identifiability analysis of GCL-based\nnICA. Our analytical framework judiciously combines the properties of the GCL\nloss function, statistical generalization analysis, and numerical\ndifferentiation. Our framework also takes the learning function's approximation\nerror into consideration, and reveals an intuitive trade-off between the\ncomplexity and expressiveness of the employed function learner. Numerical\nexperiments are used to validate the theorems.",
    "descriptor": "\nComments: Accepted to ICML 2022, 19 pages, 4 figures\n",
    "authors": [
      "Qi Lyu",
      "Xiao Fu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.06593"
  },
  {
    "id": "arXiv:2206.06594",
    "title": "Computing Real Numbers with Large-Population Protocols Having a  Continuum of Equilibria",
    "abstract": "Bournez, Fraigniaud, and Koegler defined a number in [0,1] as computable by\ntheir Large-Population Protocol (LPP) model, if the proportion of agents in a\nset of marked states converges to said number over time as the population grows\nto infinity. The notion, however, restricts the ordinary differential equations\n(ODEs) associated with an LPP to have only finitely many equilibria. This\nrestriction places an intrinsic limitation on the model. As a result, a number\nis computable by an LPP if and only if it is algebraic, namely, not a single\ntranscendental number can be computed under this notion.\nIn this paper, we lift the finitary requirement on equilibria. That is, we\nconsider systems with a continuum of equilibria. We show that essentially all\nnumbers in [0,1] that are computable by bounded general-purpose analog\ncomputers (GPACs) or chemical reaction networks (CRNs) can also be computed by\nLPPs under this new definition. This implies a rich series of numbers (e.g.,\nthe reciprocal of Euler's constant, $\\pi/4$, Euler's $\\gamma$, Catalan's\nconstant, and Dottie number) are all computable by LPPs. Our proof is\nconstructive: We develop an algorithm that transfers bounded GPACs/CRNs into\nLPPs. Our algorithm also fixes a gap in Bournez et al.'s construction of LPPs\ndesigned to compute any arbitrary algebraic number in [0,1].",
    "descriptor": "",
    "authors": [
      "Xiang Huang",
      "Rachel N. Huls"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.06594"
  },
  {
    "id": "arXiv:2206.06597",
    "title": "Permutation Search of Tensor Network Structures via Local Sampling",
    "abstract": "Recent works put much effort into tensor network structure search (TN-SS),\naiming to select suitable tensor network (TN) structures, involving the\nTN-ranks, formats, and so on, for the decomposition or learning tasks. In this\npaper, we consider a practical variant of TN-SS, dubbed TN permutation search\n(TN-PS), in which we search for good mappings from tensor modes onto TN\nvertices (core tensors) for compact TN representations. We conduct a\ntheoretical investigation of TN-PS and propose a practically-efficient\nalgorithm to resolve the problem. Theoretically, we prove the counting and\nmetric properties of search spaces of TN-PS, analyzing for the first time the\nimpact of TN structures on these unique properties. Numerically, we propose a\nnovel meta-heuristic algorithm, in which the searching is done by randomly\nsampling in a neighborhood established in our theory, and then recurrently\nupdating the neighborhood until convergence. Numerical results demonstrate that\nthe new algorithm can reduce the required model size of TNs in extensive\nbenchmarks, implying the improvement in the expressive power of TNs.\nFurthermore, the computational cost for the new algorithm is significantly less\nthan that in~\\cite{li2020evolutionary}.",
    "descriptor": "\nComments: Accepted by ICML 2022\n",
    "authors": [
      "Chao Li",
      "Junhua Zeng",
      "Zerui Tao",
      "Qibin Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06597"
  },
  {
    "id": "arXiv:2206.06602",
    "title": "Deep Isolation Forest for Anomaly Detection",
    "abstract": "Isolation forest (iForest) has been emerging as arguably the most popular\nanomaly detector in recent years. It iteratively performs axis-parallel data\nspace partition in a tree structure to isolate deviated data objects from the\nother data, with the isolation difficulty of the objects defined as anomaly\nscores. iForest shows effective performance across popular dataset benchmarks,\nbut its axis-parallel-based linear data partition is ineffective in handling\nhard anomalies in high-dimensional/non-linear-separable data space, and even\nworse, it leads to a notorious algorithmic bias that assigns unexpectedly large\nanomaly scores to artefact regions. There have been several extensions of\niForest, but they still focus on linear data partition, failing to effectively\nisolate those hard anomalies. This paper introduces a novel extension of\niForest, deep isolation forest. Our method offers a comprehensive isolation\nmethod that can arbitrarily partition the data at any random direction and\nangle on subspaces of any size, effectively avoiding the algorithmic bias in\nthe linear partition. Further, it requires only randomly initialised neural\nnetworks (i.e., no optimisation is required in our method) to ensure the\nfreedom of the partition. In doing so, desired randomness and diversity in both\nrandom network-based representations and random partition-based isolation can\nbe fully leveraged to significantly enhance the isolation ensemble-based\nanomaly detection. Also, our approach offers a data-type-agnostic anomaly\ndetection solution. It is versatile to detect anomalies in different types of\ndata by simply plugging in corresponding randomly initialised neural networks\nin the feature mapping. Extensive empirical results on a large collection of\nreal-world datasets show that our model achieves substantial improvement over\nstate-of-the-art isolation-based and non-isolation-based anomaly detection\nmodels.",
    "descriptor": "\nComments: submission of KDD 2022, 12 pages, 7 figures; the source code is released at this https URL\n",
    "authors": [
      "Hongzuo Xu",
      "Guansong Pang",
      "Yijie Wang",
      "Yongjun Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06602"
  },
  {
    "id": "arXiv:2206.06604",
    "title": "WHIS: Hearing impairment simulator based on the gammachirp auditory  filterbank",
    "abstract": "A new version of a hearing impairment simulator (WHIS) was implemented based\non a revised version of the gammachirp filterbank (GCFB), which incorporates\nfast frame-based processing, absolute threshold (AT), an audiogram of a\nhearing-impaired (HI) listener, and a parameter to control the cochlear\ninput-output (IO) function. The parameter referred to as the compression health\n$\\alpha$ controlled the slope of the IO function to range from normal hearing\n(NH) listeners to HI listeners, without largely changing the total hearing loss\n(HL). The new WHIS was designed provide an NH listener the same EPs as those of\na target HI listener.The analysis part of WHIS was almost the same as that of\nthe revised GCFB, except that the IO function was used instead of the gain\nfunction. We proposed two synthesis methods: a direct time-varying filter for\nperceptually small distortion and a filterbank analysis-synthesis for further\nHI simulations including temporal smearing. We evaluated the WHIS family and a\nCambridge version of the HL simulator (CamHLS) in terms of differences in the\nIO function and spectral distance. The IO functions were simulated fairly well\nat $\\alpha$ less than 0.5 but not at $\\alpha$ equal to 1. Thus, it is difficult\nto simulate the HL when the IO function is sufficiently healthy. This is a\nfundamental limit of any existing HL simulator as well as WHIS. The new WHIS\nyielded a smaller spectral distortion than CamHLS and was fairly compatible\nwith the previous version.",
    "descriptor": "\nComments: This paper was submitted to Trends in Hearing on Jun 5, 2022\n",
    "authors": [
      "Toshio Irino"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.06604"
  },
  {
    "id": "arXiv:2206.06605",
    "title": "Bayesian Channel Estimation for Intelligent Reflecting Surface-Aided  mmWave Massive MIMO Systems With Semi-Passive Elements",
    "abstract": "In this paper, we propose a Bayesian channel estimator for intelligent\nreflecting surface-aided (IRS-aided) millimeter wave (mmWave) massive\nmultiple-input multiple-output (MIMO) systems with semi-passive elements that\ncan receive the signal in the active sensing mode. Ultimately, our goal is to\nminimize the channel estimation error using the received signal at the base\nstation and additional information acquired from a small number of active\nsensors at the IRS. Unlike recent works on channel estimation with semi-passive\nelements that require both uplink and downlink training signals to estimate the\nUE-IRS and IRS-BS links, we only use uplink training signals to estimate all\nthe links. To compute the minimum mean squared error (MMSE) estimates of all\nthe links, we propose a novel variational inference-sparse Bayesian learning\n(VI-SBL) channel estimator that performs approximate posterior inference on the\nchannel using VI with the mean-field approximation under the SBL framework. The\nsimulation results show that VI-SBL outperforms the state-of-the-art baselines\nfor IRS with passive reflecting elements in terms of the channel estimation\naccuracy, training overhead, and spectral efficiency. Furthermore, VI-SBL with\nsemi-passive elements is shown to be more energy-efficient than the baselines\nwith passive reflecting elements while employing a small number of low-cost\nactive sensors.",
    "descriptor": "\nComments: submitted to IEEE Transactions on Wireless Communications\n",
    "authors": [
      "In-soo Kim",
      "Mehdi Bennis",
      "Jaeky Oh",
      "Jaehoon Chung",
      "Junil Choi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.06605"
  },
  {
    "id": "arXiv:2206.06606",
    "title": "Astock: A New Dataset and Automated Stock Trading based on  Stock-specific News Analyzing Model",
    "abstract": "Natural Language Processing(NLP) demonstrates a great potential to support\nfinancial decision-making by analyzing the text from social media or news\noutlets. In this work, we build a platform to study the NLP-aided stock\nauto-trading algorithms systematically. In contrast to the previous work, our\nplatform is characterized by three features: (1) We provide financial news for\neach specific stock. (2) We provide various stock factors for each stock. (3)\nWe evaluate performance from more financial-relevant metrics. Such a design\nallows us to develop and evaluate NLP-aided stock auto-trading algorithms in a\nmore realistic setting. In addition to designing an evaluation platform and\ndataset collection, we also made a technical contribution by proposing a system\nto automatically learn a good feature representation from various input\ninformation. The key to our algorithm is a method called semantic role labeling\nPooling (SRLP), which leverages Semantic Role Labeling (SRL) to create a\ncompact representation of each news paragraph. Based on SRLP, we further\nincorporate other stock factors to make the final prediction. In addition, we\npropose a self-supervised learning strategy based on SRLP to enhance the\nout-of-distribution generalization performance of our system. Through our\nexperimental study, we show that the proposed method achieves better\nperformance and outperforms all the baselines' annualized rate of return as\nwell as the maximum drawdown of the CSI300 index and XIN9 index on real\ntrading. Our Astock dataset and code are available at\nhttps://github.com/JinanZou/Astock.",
    "descriptor": "",
    "authors": [
      "Jinan Zou",
      "Haiyao Cao",
      "Lingqiao Liu",
      "Yuhao Lin",
      "Ehsan Abbasnejad",
      "Javen Qinfeng Shi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06606"
  },
  {
    "id": "arXiv:2206.06607",
    "title": "Plug-and-Play Pseudo Label Correction Network for Unsupervised Person  Re-identification",
    "abstract": "Clustering-based methods, which alternate between the generation of pseudo\nlabels and the optimization of the feature extraction network, play a dominant\nrole in both unsupervised learning (USL) and unsupervised domain adaptive (UDA)\nperson re-identification (Re-ID). To alleviate the adverse effect of noisy\npseudo labels, the existing methods either abandon unreliable labels or refine\nthe pseudo labels via mutual learning or label propagation. However, a great\nmany erroneous labels are still accumulated because these methods mostly adopt\ntraditional unsupervised clustering algorithms which rely on certain\nassumptions on data distribution and fail to capture the distribution of\ncomplex real-world data. In this paper, we propose the plug-and-play\ngraph-based pseudo label correction network (GLC) to refine the pseudo labels\nin the manner of supervised clustering. GLC is trained to perceive the varying\ndata distribution at each epoch of the self-training with the supervision of\ninitial pseudo labels generated by any clustering method. It can learn to\nrectify the initial noisy labels by means of the relationship constraints\nbetween samples on the k Nearest Neighbor (kNN) graph and early-stop training\nstrategy. Specifically, GLC learns to aggregate node features from neighbors\nand predict whether the nodes should be linked on the graph. Besides, GLC is\noptimized with 'early stop' before the noisy labels are severely memorized to\nprevent overfitting to noisy pseudo labels. Consequently, GLC improves the\nquality of pseudo labels though the supervision signals contain some noise,\nleading to better Re-ID performance. Extensive experiments in USL and UDA\nperson Re-ID on Market-1501 and MSMT17 show that our method is widely\ncompatible with various clustering-based methods and promotes the\nstate-of-the-art performance consistently.",
    "descriptor": "\nComments: 19 pages,9 figures\n",
    "authors": [
      "Tianyi Yan",
      "Kuan Zhu",
      "Haiyun guo",
      "Guibo Zhu",
      "Ming Tang",
      "Jinqiao Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06607"
  },
  {
    "id": "arXiv:2206.06608",
    "title": "Label Matching Semi-Supervised Object Detection",
    "abstract": "Semi-supervised object detection has made significant progress with the\ndevelopment of mean teacher driven self-training. Despite the promising\nresults, the label mismatch problem is not yet fully explored in the previous\nworks, leading to severe confirmation bias during self-training. In this paper,\nwe delve into this problem and propose a simple yet effective LabelMatch\nframework from two different yet complementary perspectives, i.e.,\ndistribution-level and instance-level. For the former one, it is reasonable to\napproximate the class distribution of the unlabeled data from that of the\nlabeled data according to Monte Carlo Sampling. Guided by this weakly\nsupervision cue, we introduce a re-distribution mean teacher, which leverages\nadaptive label-distribution-aware confidence thresholds to generate unbiased\npseudo labels to drive student learning. For the latter one, there exists an\noverlooked label assignment ambiguity problem across teacher-student models. To\nremedy this issue, we present a novel label assignment mechanism for\nself-training framework, namely proposal self-assignment, which injects the\nproposals from student into teacher and generates accurate pseudo labels to\nmatch each proposal in the student model accordingly. Experiments on both\nMS-COCO and PASCAL-VOC datasets demonstrate the considerable superiority of our\nproposed framework to other state-of-the-arts. Code will be available at\nhttps://github.com/hikvision-research/SSOD.",
    "descriptor": "\nComments: To appear in CVPR 2022. Code is coming soon: this https URL\n",
    "authors": [
      "Binbin Chen",
      "Weijie Chen",
      "Shicai Yang",
      "Yunyi Xuan",
      "Jie Song",
      "Di Xie",
      "Shiliang Pu",
      "Mingli Song",
      "Yueting Zhuang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06608"
  },
  {
    "id": "arXiv:2206.06611",
    "title": "Accelerating CPU-based Sparse General Matrix Multiplication with Binary  Row Merging",
    "abstract": "Sparse general matrix multiplication (SpGEMM) is a fundamental building block\nfor many real-world applications. Since SpGEMM is a well-known memory-bounded\napplication with vast and irregular memory accesses, considering the memory\naccess efficiency is of critical importance for optimizing SpGEMM. Yet, the\nexisting methods put less consideration into the memory subsystem and achieved\nsuboptimal performance. In this paper, we thoroughly analyze the memory access\npatterns of SpGEMM and their influences on the memory subsystem. Based on the\nanalysis, we propose a novel and more efficient accumulation method named\nBRMerge for the multi-core CPU architectures.\nThe BRMerge accumulation method follows the row-wise dataflow. It first\naccesses the $B$ matrix, generates the intermediate lists for one output row,\nand stores these intermediate lists in a consecutive memory space, which is\nimplemented by a ping-pong buffer. It then immediately merges these\nintermediate lists generated in the previous phase two by two in a tree-like\nhierarchy between two ping-pong buffers. The architectural benefits of BRMerge\nare 1) streaming access patterns, 2) minimized TLB cache misses, and 3)\nreasonably high L1/L2 cache hit rates, which result in both low access latency\nand high bandwidth utilization when performing SpGEMM. Based on the BRMerge\naccumulation method, we propose two SpGEMM libraries named BRMerge-Upper and\nBRMerge-Precise, which use different allocation methods. Performance\nevaluations with 26 commonly used benchmarks on two CPU servers show that the\nproposed SpGEMM libraries significantly outperform the state-of-the-art SpGEMM\nlibraries.",
    "descriptor": "\nComments: This work has been submitted to the IEEE Access since May 31, 2022, and is currently under review by the IEEE Access. 15 pages, 6 fgures, 2 tables\n",
    "authors": [
      "Zhaoyang Du",
      "Yijin Guan",
      "Tianchan Guan",
      "Dimin Niu",
      "Hongzhong Zheng",
      "Yuan Xie"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Mathematical Software (cs.MS)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2206.06611"
  },
  {
    "id": "arXiv:2206.06614",
    "title": "Transformers are Meta-Reinforcement Learners",
    "abstract": "The transformer architecture and variants presented remarkable success across\nmany machine learning tasks in recent years. This success is intrinsically\nrelated to the capability of handling long sequences and the presence of\ncontext-dependent weights from the attention mechanism. We argue that these\ncapabilities suit the central role of a Meta-Reinforcement Learning algorithm.\nIndeed, a meta-RL agent needs to infer the task from a sequence of\ntrajectories. Furthermore, it requires a fast adaptation strategy to adapt its\npolicy for a new task -- which can be achieved using the self-attention\nmechanism. In this work, we present TrMRL (Transformers for Meta-Reinforcement\nLearning), a meta-RL agent that mimics the memory reinstatement mechanism using\nthe transformer architecture. It associates the recent past of working memories\nto build an episodic memory recursively through the transformer layers. We show\nthat the self-attention computes a consensus representation that minimizes the\nBayes Risk at each layer and provides meaningful features to compute the best\nactions. We conducted experiments in high-dimensional continuous control\nenvironments for locomotion and dexterous manipulation. Results show that TrMRL\npresents comparable or superior asymptotic performance, sample efficiency, and\nout-of-distribution generalization compared to the baselines in these\nenvironments.",
    "descriptor": "\nComments: Published at the International Conference on Machine Learning (ICML) 2022\n",
    "authors": [
      "Luckeciano C. Melo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.06614"
  },
  {
    "id": "arXiv:2206.06615",
    "title": "Several Classes of New MDS Codes with Arbitrary-Dimensional Hulls and  Their Applications",
    "abstract": "Hulls of linear codes have a vital effect in coding theory.\nArbitrary-dimensional hull and one-dimensional hull are helpful for the\nconstruction of EAQECCs and determining the complexity of some algorithms etc.,\nrespectively. In this paper, we present some constructions from generalized\nReed-Solomn codes and extend generalized Reed-Solomn codes, and determine the\ndimension of their hulls. Then, we get five new MDS codes with new parameters\nand we also give a more systematic and convenient method to construct two\nclasses of codes that have already appeared before. And finally, we construct\nEAQECCs and EAQMDS codes using five classes of these seven MDS codes with\narbitrary hulls, and the remaining two classes have one-dimensional hulls.",
    "descriptor": "\nComments: 30 pages, 2 tables\n",
    "authors": [
      "Yang Li",
      "Shixin Zhu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.06615"
  },
  {
    "id": "arXiv:2206.06618",
    "title": "Solving the capacitated vehicle routing problem with timing windows  using rollouts and MAX-SAT",
    "abstract": "The vehicle routing problem is a well known class of NP-hard combinatorial\noptimisation problems in literature. Traditional solution methods involve\neither carefully designed heuristics, or time-consuming metaheuristics. Recent\nwork in reinforcement learning has been a promising alternative approach, but\nhas found it difficult to compete with traditional methods in terms of solution\nquality. This paper proposes a hybrid approach that combines reinforcement\nlearning, policy rollouts, and a satisfiability solver to enable a tunable\ntradeoff between computation times and solution quality. Results on a popular\npublic data set show that the algorithm is able to produce solutions closer to\noptimal levels than existing learning based approaches, and with shorter\ncomputation times than meta-heuristics. The approach requires minimal design\neffort and is able to solve unseen problems of arbitrary scale without\nadditional training. Furthermore, the methodology is generalisable to other\ncombinatorial optimisation problems.",
    "descriptor": "\nComments: 6 pages, 2 figures\n",
    "authors": [
      "Harshad Khadilkar"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.06618"
  },
  {
    "id": "arXiv:2206.06619",
    "title": "TransVG++: End-to-End Visual Grounding with Language Conditioned Vision  Transformer",
    "abstract": "In this work, we explore neat yet effective Transformer-based frameworks for\nvisual grounding. The previous methods generally address the core problem of\nvisual grounding, i.e., multi-modal fusion and reasoning, with\nmanually-designed mechanisms. Such heuristic designs are not only complicated\nbut also make models easily overfit specific data distributions. To avoid this,\nwe first propose TransVG, which establishes multi-modal correspondences by\nTransformers and localizes referred regions by directly regressing box\ncoordinates. We empirically show that complicated fusion modules can be\nreplaced by a simple stack of Transformer encoder layers with higher\nperformance. However, the core fusion Transformer in TransVG is stand-alone\nagainst uni-modal encoders, and thus should be trained from scratch on limited\nvisual grounding data, which makes it hard to be optimized and leads to\nsub-optimal performance. To this end, we further introduce TransVG++ to make\ntwo-fold improvements. For one thing, we upgrade our framework to a purely\nTransformer-based one by leveraging Vision Transformer (ViT) for vision feature\nencoding. For another, we devise Language Conditioned Vision Transformer that\nremoves external fusion modules and reuses the uni-modal ViT for\nvision-language fusion at the intermediate layers. We conduct extensive\nexperiments on five prevalent datasets, and report a series of state-of-the-art\nrecords.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2104.08541\n",
    "authors": [
      "Jiajun Deng",
      "Zhengyuan Yang",
      "Daqing Liu",
      "Tianlang Chen",
      "Wengang Zhou",
      "Yanyong Zhang",
      "Houqiang Li",
      "Wanli Ouyang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06619"
  },
  {
    "id": "arXiv:2206.06620",
    "title": "Slimmable Domain Adaptation",
    "abstract": "Vanilla unsupervised domain adaptation methods tend to optimize the model\nwith fixed neural architecture, which is not very practical in real-world\nscenarios since the target data is usually processed by different\nresource-limited devices. It is therefore of great necessity to facilitate\narchitecture adaptation across various devices. In this paper, we introduce a\nsimple framework, Slimmable Domain Adaptation, to improve cross-domain\ngeneralization with a weight-sharing model bank, from which models of different\ncapacities can be sampled to accommodate different accuracy-efficiency\ntrade-offs. The main challenge in this framework lies in simultaneously\nboosting the adaptation performance of numerous models in the model bank. To\ntackle this problem, we develop a Stochastic EnsEmble Distillation method to\nfully exploit the complementary knowledge in the model bank for inter-model\ninteraction. Nevertheless, considering the optimization conflict between\ninter-model interaction and intra-model adaptation, we augment the existing\nbi-classifier domain confusion architecture into an Optimization-Separated\nTri-Classifier counterpart. After optimizing the model bank, architecture\nadaptation is leveraged via our proposed Unsupervised Performance Evaluation\nMetric. Under various resource constraints, our framework surpasses other\ncompeting approaches by a very large margin on multiple benchmarks. It is also\nworth emphasizing that our framework can preserve the performance improvement\nagainst the source-only model even when the computing complexity is reduced to\n$1/64$. Code will be available at https://github.com/hikvision-research/SlimDA.",
    "descriptor": "\nComments: To appear in CVPR 2022. Code is coming soon: this https URL\n",
    "authors": [
      "Rang Meng",
      "Weijie Chen",
      "Shicai Yang",
      "Jie Song",
      "Luojun Lin",
      "Di Xie",
      "Shiliang Pu",
      "Xinchao Wang",
      "Mingli Song",
      "Yueting Zhuang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06620"
  },
  {
    "id": "arXiv:2206.06629",
    "title": "Semantic-Discriminative Mixup for Generalizable Sensor-based  Cross-domain Activity Recognition",
    "abstract": "It is expensive and time-consuming to collect sufficient labeled data to\nbuild human activity recognition (HAR) models. Training on existing data often\nmakes the model biased towards the distribution of the training data, thus the\nmodel might perform terribly on test data with different distributions.\nAlthough existing efforts on transfer learning and domain adaptation try to\nsolve the above problem, they still need access to unlabeled data on the target\ndomain, which may not be possible in real scenarios. Few works pay attention to\ntraining a model that can generalize well to unseen target domains for HAR. In\nthis paper, we propose a novel method called Semantic-Discriminative Mixup\n(SDMix) for generalizable cross-domain HAR. Firstly, we introduce\nsemantic-aware Mixup that considers the activity semantic ranges to overcome\nthe semantic inconsistency brought by domain differences. Secondly, we\nintroduce the large margin loss to enhance the discrimination of Mixup to\nprevent misclassification brought by noisy virtual labels. Comprehensive\ngeneralization experiments on five public datasets demonstrate that our SDMix\nsubstantially outperforms the state-of-the-art approaches with 6% average\naccuracy improvement on cross-person, cross-dataset, and cross-position HAR.",
    "descriptor": "\nComments: To be presented at UbiComp 2022; Accepted by Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies (IMWUT)\n",
    "authors": [
      "Wang Lu",
      "Jindong Wang",
      "Yiqiang Chen",
      "Sinno Jialin Pan",
      "Chunyu Hu",
      "Xin Qin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.06629"
  },
  {
    "id": "arXiv:2206.06635",
    "title": "CVR-LSE: Compact Vectorization Representation of Local Static  Environments for Unmanned Ground Vehicles",
    "abstract": "According to the requirement of general static obstacle detection, this paper\nproposes a compact vectorization representation approach of local static\nenvironments for unmanned ground vehicles. At first, by fusing the data of\nLiDAR and IMU, high-frequency pose information is obtained. Then, through the\ntwo-dimensional (2D) obstacle points generation, the process of grid map\nmaintenance with a fixed size is proposed. Finally, the local static\nenvironment is described via multiple convex polygons, which is realized\nthroungh the double threshold-based boundary simplification and the convex\npolygon segmentation. Our proposed approach has been applied in a practical\ndriverless project in the park, and the qualitative experimental results on\ntypical scenes verify the effectiveness and robustness. In addition, the\nquantitative evaluation shows the superior performance on making use of fewer\nnumber of points information (decreased by about 60%) to represent the local\nstatic environment compared with the traditional grid map-based methods.\nFurthermore, the performance of running time (15ms) shows that the proposed\napproach can be used for real-time local static environment perception. The\ncorresponding code can be accessed at https://github.com/ghm0819/cvr_lse.",
    "descriptor": "",
    "authors": [
      "Haiming Gao",
      "Qibo Qiu",
      "Wei Hua",
      "Xuebo Zhang",
      "Zhengyong Han",
      "Shun Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.06635"
  },
  {
    "id": "arXiv:2206.06637",
    "title": "RF-Next: Efficient Receptive Field Search for Convolutional Neural  Networks",
    "abstract": "Temporal/spatial receptive fields of models play an important role in\nsequential/spatial tasks. Large receptive fields facilitate long-term\nrelations, while small receptive fields help to capture the local details.\nExisting methods construct models with hand-designed receptive fields in\nlayers. Can we effectively search for receptive field combinations to replace\nhand-designed patterns? To answer this question, we propose to find better\nreceptive field combinations through a global-to-local search scheme. Our\nsearch scheme exploits both global search to find the coarse combinations and\nlocal search to get the refined receptive field combinations further. The\nglobal search finds possible coarse combinations other than human-designed\npatterns. On top of the global search, we propose an expectation-guided\niterative local search scheme to refine combinations effectively. Our RF-Next\nmodels, plugging receptive field search to various models, boost the\nperformance on many tasks, e.g., temporal action segmentation, object\ndetection, instance segmentation, and speech synthesis. The source code is\npublicly available on this http URL",
    "descriptor": "\nComments: Accepted by TPAMI. arXiv admin note: substantial text overlap with arXiv:2101.00910\n",
    "authors": [
      "Shanghua Gao",
      "Zhong-Yu Li",
      "Qi Han",
      "Ming-Ming Cheng",
      "Liang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06637"
  },
  {
    "id": "arXiv:2206.06640",
    "title": "Confidence Score for Source-Free Unsupervised Domain Adaptation",
    "abstract": "Source-free unsupervised domain adaptation (SFUDA) aims to obtain high\nperformance in the unlabeled target domain using the pre-trained source model,\nnot the source data. Existing SFUDA methods assign the same importance to all\ntarget samples, which is vulnerable to incorrect pseudo-labels. To\ndifferentiate between sample importance, in this study, we propose a novel\nsample-wise confidence score, the Joint Model-Data Structure (JMDS) score for\nSFUDA. Unlike existing confidence scores that use only one of the source or\ntarget domain knowledge, the JMDS score uses both knowledge. We then propose a\nConfidence score Weighting Adaptation using the JMDS (CoWA-JMDS) framework for\nSFUDA. CoWA-JMDS consists of the JMDS scores as sample weights and weight Mixup\nthat is our proposed variant of Mixup. Weight Mixup promotes the model make\nmore use of the target domain knowledge. The experimental results show that the\nJMDS score outperforms the existing confidence scores. Moreover, CoWA-JMDS\nachieves state-of-the-art performance on various SFUDA scenarios: closed, open,\nand partial-set scenarios.",
    "descriptor": "\nComments: ICML 2022 camera ready\n",
    "authors": [
      "Jonghyun Lee",
      "Dahuin Jung",
      "Junho Yim",
      "Sungroh Yoon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06640"
  },
  {
    "id": "arXiv:2206.06642",
    "title": "Future Internet Congestion Control: The Diminishing Feedback Problem",
    "abstract": "It is increasingly difficult for Internet congestion control mechanisms to\nobtain the feedback that they need. This lack of feedback can have severe\nperformance implications, and it is bound to become worse. In the long run, the\nproblem may only be fixable by fundamentally changing the way congestion\ncontrol is done in the Internet. We substantiate this claim by looking at the\nevolution of the Internet's infrastructure over the past thirty years, and by\nexamining the most common behavior of Internet traffic. Considering the goals\nthat congestion control mechanisms are intended to address, and taking into\naccount contextual developments in the Internet ecosystem, we arrive at\nconclusions and recommendations about possible future congestion control design\ndirections. In particular, we argue that congestion control mechanisms should\nmove away from their strict \"end-to-end\" adherence. This change would benefit\nfrom avoiding a \"one size fits all circumstances\" approach, and moving towards\na more selective set of mechanisms that will result in a better performing\nInternet. We will also discuss how this future vision differs from today's use\nof Performance Enhancing Proxies (PEPs).",
    "descriptor": "\nComments: Accepted for publication in IEEE Communications Magazine, 2022 (Open Call Article)\n",
    "authors": [
      "Michael Welzl",
      "Peyman Teymoori",
      "Safiqul Islam",
      "David Hutchison",
      "Stein Gjessing"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.06642"
  },
  {
    "id": "arXiv:2206.06646",
    "title": "Network-Controlled Physical-Layer Security: Enhancing Secrecy Through  Friendly Jamming",
    "abstract": "The broadcasting nature of the wireless medium makes exposure to\neavesdroppers a potential threat. Physical Layer Security (PLS) has been widely\nrecognized as a promising security measure complementary to encryption. It has\nrecently been demonstrated that PLS can be implemented using off-the-shelf\nequipment by spectrum-programming enhanced Software-Defined Networking (SDN),\nwhere a network controller is able to execute intelligent access point (AP)\nselection algorithms such that PLS can be achieved and secrecy capacity\noptimized. In this paper, we provide a basic system model for such\nimplementations. We also introduce a novel secrecy capacity optimization\nalgorithm, in which we combine intelligent AP selection with the addition of\nFriendly Jamming (FJ) by the not-selected AP.",
    "descriptor": "",
    "authors": [
      "Sayed Amir Hoseini",
      "Parastoo Sadeghi",
      "Faycal Bouhafs",
      "Neda Aboutorab",
      "Frank den Hartog"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.06646"
  },
  {
    "id": "arXiv:2206.06650",
    "title": "Semi-Private Computation of Data Similarity with Controlled Leakage",
    "abstract": "Consider two data providers that want to contribute data to a certain\nlearning model. Recent works have shown that the value of the data of one of\nthe providers is dependent on the similarity with the data owned by the other\nprovider. It would thus be beneficial if the two providers can calculate the\nsimilarity of their data, while keeping the actual data private. In this work,\nwe devise multiparty computation-protocols to compute similarity of two data\nsets based on correlation, while offering controllable privacy guarantees. We\nconsider a simple model with two participating providers and develop methods to\ncompute exact and approximate correlation, respectively, with controlled\ninformation leakage. Both protocols have computational and communication\ncomplexities that are linear in the number of data samples. We also provide\ngeneral bounds on the maximal error in the approximation case, and analyse the\nresulting errors for practical parameter choices.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Ren\u00e9 B\u00f8dker Christensen",
      "Shashi Raj Pandey",
      "Petar Popovski"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.06650"
  },
  {
    "id": "arXiv:2206.06658",
    "title": "A novel MDPSO-SVR hybrid model for feature selection in electricity  consumption forecasting",
    "abstract": "Electricity consumption forecasting has vital importance for the energy\nplanning of a country. Of the enabling machine learning models, support vector\nregression (SVR) has been widely used to set up forecasting models due to its\nsuperior generalization for unseen data. However, one key procedure for the\npredictive modeling is feature selection, which might hurt the prediction\naccuracy if improper features were selected. In this regard, a modified\ndiscrete particle swarm optimization (MDPSO) was employed for feature selection\nin this study, and then MDPSO-SVR hybrid mode was built to predict future\nelectricity consumption. Compared with other well-established counterparts,\nMDPSO-SVR model consistently performs best in two real-world electricity\nconsumption datasets, which indicates that MDPSO for feature selection can\nimprove the prediction accuracy and the SVR equipped with the MDPSO can be a\npromised alternative for electricity consumption forecasting.",
    "descriptor": "",
    "authors": [
      "Xiaoyuan Zhang",
      "Yanmei Huang",
      "Changrui Deng",
      "Yukun Bao"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.06658"
  },
  {
    "id": "arXiv:2206.06661",
    "title": "SoTeacher: A Student-oriented Teacher Network Training Framework for  Knowledge Distillation",
    "abstract": "How to train an ideal teacher for knowledge distillation is still an open\nproblem. It has been widely observed that a teacher minimizing the empirical\nrisk not necessarily yields the best performing student, suggesting a\nfundamental discrepancy between the common practice in teacher network training\nand the distillation objective. To fill this gap, we propose a novel\nstudent-oriented teacher network training framework SoTeacher, inspired by\nrecent findings that student performance hinges on teacher's capability to\napproximate the true label distribution of training samples. We theoretically\nestablished that (1) the empirical risk minimizer with proper scoring rules as\nloss function can provably approximate the true label distribution of training\ndata if the hypothesis function is locally Lipschitz continuous around training\nsamples; and (2) when data augmentation is employed for training, an additional\nconstraint is required that the minimizer has to produce consistent predictions\nacross augmented views of the same training input. In light of our theory,\nSoTeacher renovates the empirical risk minimization by incorporating Lipschitz\nregularization and consistency regularization. It is worth mentioning that\nSoTeacher is applicable to almost all teacher-student architecture pairs,\nrequires no prior knowledge of the student upon teacher's training, and induces\nalmost no computation overhead. Experiments on two benchmark datasets confirm\nthat SoTeacher can improve student performance significantly and consistently\nacross various knowledge distillation algorithms and teacher-student pairs.",
    "descriptor": "",
    "authors": [
      "Chengyu Dong",
      "Liyuan Liu",
      "Jingbo Shang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.06661"
  },
  {
    "id": "arXiv:2206.06662",
    "title": "Learning Best Combination for Efficient N:M Sparsity",
    "abstract": "By forcing at most N out of M consecutive weights to be non-zero, the recent\nN:M network sparsity has received increasing attention for its two attractive\nadvantages: 1) Promising performance at a high sparsity. 2) Significant\nspeedups on NVIDIA A100 GPUs. Recent studies require an expensive pre-training\nphase or a heavy dense-gradient computation. In this paper, we show that the\nN:M learning can be naturally characterized as a combinatorial problem which\nsearches for the best combination candidate within a finite collection.\nMotivated by this characteristic, we solve N:M sparsity in an efficient\ndivide-and-conquer manner. First, we divide the weight vector into\n$C_{\\text{M}}^{\\text{N}}$ combination subsets of a fixed size N. Then, we\nconquer the combinatorial problem by assigning each combination a learnable\nscore that is jointly optimized with its associate weights. We prove that the\nintroduced scoring mechanism can well model the relative importance between\ncombination subsets. And by gradually removing low-scored subsets, N:M\nfine-grained sparsity can be efficiently optimized during the normal training\nphase. Comprehensive experiments demonstrate that our learning best combination\n(LBC) performs consistently better than off-the-shelf N:M sparsity methods\nacross various networks. Our code is released at\n\\url{https://github.com/zyxxmu/LBC}.",
    "descriptor": "\nComments: 12 pages, 3 figures\n",
    "authors": [
      "Yuxin Zhang",
      "Mingbao Lin",
      "Zhihang Lin",
      "Yiting Luo",
      "Ke Li",
      "Fei Chao",
      "Yongjian Wu",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06662"
  },
  {
    "id": "arXiv:2206.06664",
    "title": "Hybrid Projection Methods for Solution Decomposition in Large-scale  Bayesian Inverse Problems",
    "abstract": "We develop hybrid projection methods for computing solutions to large-scale\ninverse problems, where the solution represents a sum of different stochastic\ncomponents. Such scenarios arise in many imaging applications (e.g., anomaly\ndetection in atmospheric emissions tomography) where the reconstructed solution\ncan be represented as a combination of two or more components and each\ncomponent contains different smoothness or stochastic properties. In a\ndeterministic inversion or inverse modeling framework, these assumptions\ncorrespond to different regularization terms for each solution in the sum.\nAlthough various prior assumptions can be included in our framework, we focus\non the scenario where the solution is a sum of a sparse solution and a smooth\nsolution. For computing solution estimates, we develop hybrid projection\nmethods for solution decomposition that are based on a combined flexible and\ngeneralized Golub-Kahan processes. This approach integrates techniques from the\ngeneralized Golub-Kahan bidiagonalization and the flexible Krylov methods. The\nbenefits of the proposed methods are that the decomposition of the solution can\nbe done iteratively, and the regularization terms and regularization parameters\nare adaptively chosen at each iteration. Numerical results from photoacoustic\ntomography and atmospheric inverse modeling demonstrate the potential for these\nmethods to be used for anomaly detection.",
    "descriptor": "",
    "authors": [
      "Julianne Chung",
      "Jiahua Jiang",
      "Scot M. Miller",
      "Arvind K. Saibaba"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.06664"
  },
  {
    "id": "arXiv:2206.06665",
    "title": "Online Easy Example Mining for Weakly-supervised Gland Segmentation from  Histology Images",
    "abstract": "Developing an AI-assisted gland segmentation method from histology images is\ncritical for automatic cancer diagnosis and prognosis; however, the high cost\nof pixel-level annotations hinders its applications to broader diseases.\nExisting weakly-supervised semantic segmentation methods in computer vision\nachieve degenerative results for gland segmentation, since the characteristics\nand problems of glandular datasets are different from general object datasets.\nWe observe that, unlike natural images, the key problem with histology images\nis the confusion of classes owning to morphological homogeneity and low color\ncontrast among different tissues. To this end, we propose a novel method Online\nEasy Example Mining (OEEM) that encourages the network to focus on credible\nsupervision signals rather than noisy signals, therefore mitigating the\ninfluence of inevitable false predictions in pseudo-masks. According to the\ncharacteristics of glandular datasets, we design a strong framework for gland\nsegmentation. Our results exceed many fully-supervised methods and\nweakly-supervised methods for gland segmentation over 4.4% and 6.04% at mIoU,\nrespectively. Code is available at https://github.com/xmed-lab/OEEM.",
    "descriptor": "\nComments: MICCAI 2022 Accepeted\n",
    "authors": [
      "Yi Li",
      "Yiduo Yu",
      "Yiwen Zou",
      "Tianqi Xiang",
      "Xiaomeng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.06665"
  },
  {
    "id": "arXiv:2206.06666",
    "title": "Effect of money heterogeneity on resource dependency in complex networks",
    "abstract": "Exchange of resources among individual components of a system is fundamental\nto systems like a social network of humans and a network of cities and\nvillages. For various reasons, the human society has come up with the notion of\n\\emph{money} as a proxy for the resources. Here we extend the model of resource\ndependencies in networks, proposed in\n[\\href{https://journals.aps.org/pre/abstract/10.1103/PhysRevE.102.062304}{Phys.\nRev. E {\\bf 102}, 062304 (2020)}], by incorporating the notion of money so that\nthe vertices of a network can sell and buy required resources among themselves.\nWe simulate the model using the configuration model as a substrate for\nhomogeneous as well as heterogeneous degree distributions and using various\nexchange strategies. We show that a moderate amount of initial heterogeneity in\nthe money on the vertices can significantly improve the survivability of\nScale-free networks but not that of homogeneous networks like the Erd{\\H\no}s-R{\\'e}nyi network.",
    "descriptor": "\nComments: 8 pages, 6 Figures\n",
    "authors": [
      "Harshit Agrawal",
      "Ashwin Lahorkar",
      "Snehal M. Shekatkar"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2206.06666"
  },
  {
    "id": "arXiv:2206.06668",
    "title": "Automatic compile-time synthesis of entropy-optimal Boltzmann samplers",
    "abstract": "We present a famework for the automatic compilation of multi-parametric\nBoltzmann samplers for algebraic data types in Haskell. Our framework uses\nTemplate Haskell to synthesise efficient, entropy-optimal samplers generating\nrandom instances of user-declared algebraic data types. Users can control the\noutcome distribution through a pure, declarative interface. For instance, users\ncan control the mean size and constructor frequencies of generated objects. We\nillustrate the effectiveness of our framework through a prototype\ngeneric-boltzmann-brain library showing that it is possible to control\nthousands of different parameters in systems of tens of thousands of ADTs. Our\nprototype framework synthesises Boltzmann samplers capable of rapidly\ngenerating random objects of sizes in the millions.",
    "descriptor": "",
    "authors": [
      "Maciej Bendkowski"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.06668"
  },
  {
    "id": "arXiv:2206.06669",
    "title": "Snakes and Ladder Logic: PLC-VBS, a PLC Control Logic Vulnerability  Discovery Tool",
    "abstract": "Cyber security risk assessments provide a pivotal starting point towards the\nunderstanding of existing risk exposure, through which suitable mitigation\nstrategies can be formed. Where risk is viewed as a product of threat,\nvulnerability, and impact, understanding each element is of equal importance.\nThis can be a challenge in Industrial Control System (ICS) environments, where\nadopted technologies are typically not only bespoke, but interact directly with\nthe physical world. To date, existing vulnerability identification has focused\non traditional vulnerability categories. While this provides risk assessors\nwith a baseline understanding, and the ability to hypothesize on potential\nresulting impacts, it is high level, operating at a level of abstraction that\nwould be viewed as incomplete within a traditional information system context.\nThe work presented in this paper takes the understanding of ICS device\nvulnerabilities one step further. It offers a tool, PLC-VBS, that helps\nidentify Programmable Logic Controller (PLC) vulnerabilities, specifically\nwithin logic used to monitor, control, and automate operational processes.\nPLC-VBS gives risk assessors a more coherent picture about the potential impact\nshould the identified vulnerabilities be exploited; this applies specifically\nto operational process elements.",
    "descriptor": "",
    "authors": [
      "Sam Maesschalck",
      "Alexander Staves",
      "Richard Derbyshire",
      "Benjamin Green",
      "David Hutchinson"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.06669"
  },
  {
    "id": "arXiv:2206.06670",
    "title": "PROACT: Parallel Multi-Miner Proof of Accumulated Trust Protocol for  Internet of Drones",
    "abstract": "Several types of networks that comprise unmanned aerial vehicles (UAV or\ndrone) are being utilized in important applications such as emergency response,\nenvironment and infrastructure monitoring, defense and security, and commerce.\nIn such networks, swarms of UAVs cooperate in executing one or more missions to\nachieve the application's objectives. The UAVs communicate with terrestrial\nnetworks by connecting to fixed or mobile ground control stations (GCS). The\nability of drones to connect to online applications and offer services to\nInternet users has led to the proliferation of the Internet of Drones (IoD).\nHowever, IoD applications are highly vulnerable to many types of cyberattacks.\nHence, mechanisms must be deployed to secure the IoD operations and data.\nRecently, the blockchain has been proposed as a solution to detect and prevent\nmalicious attacks on the UAV network (UAVN). Due to the UAV's limited\nresources, it becomes a challenge to integrate the blockchain into the IoD. In\nthis paper, we propose a model that enables a drone to store the important data\nthat it requires during its flight within a lightweight blockchain system. In\naddition, we propose a new blockchain consensus mechanism in which several\nminers produce their blocks in parallel, which decreases the time needed to add\ntransactions securely to the blockchain and meets the requirements of\ndelay-sensitive applications. Our simulations prove the advantages of the\nproposed model in decreasing the transaction-to-blockchain delay, the average\ndrone energy consumption, and the blockchain block size as compared to other\nIoD blockchain systems.",
    "descriptor": "\nComments: 45 pages, 9 Figures, 2 Tables, accepted for publication at Elsevier Vehicular Communications Journal\n",
    "authors": [
      "Khaleel Mershad"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.06670"
  },
  {
    "id": "arXiv:2206.06672",
    "title": "Energy Flows: Towards Determinant-Free Training of Normalizing Flows",
    "abstract": "Normalizing flows are a popular approach for constructing probabilistic and\ngenerative models. However, maximum likelihood training of flows is challenging\ndue to the need to calculate computationally expensive determinants of\nJacobians. This paper takes steps towards addressing this challenge by\nintroducing an approach for determinant-free training of flows inspired by\ntwo-sample testing. Central to our framework is the energy objective, a\nmultidimensional extension of proper scoring rules that admits efficient\nestimators based on random projections and that outperforms a range of\nalternative two-sample objectives that can be derived in our framework.\nCrucially, the energy objective and its alternatives do not require calculating\ndeterminants and therefore support general flow architectures that are not\nwell-suited to maximum likelihood training (e.g., densely connected networks).\nWe empirically demonstrate that energy flows achieve competitive generative\nmodeling performance while maintaining fast generation and posterior inference.",
    "descriptor": "\nComments: 10 pages, 2 figures, 6 tables, 3 pages appendix\n",
    "authors": [
      "Phillip Si",
      "Volodymyr Kuleshov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.06672"
  },
  {
    "id": "arXiv:2206.06674",
    "title": "Severe Damage Recovery in Evolving Soft Robots through Differentiable  Programming",
    "abstract": "Biological systems are very robust to morphological damage, but artificial\nsystems (robots) are currently not. In this paper we present a system based on\nneural cellular automata, in which locomoting robots are evolved and then given\nthe ability to regenerate their morphology from damage through gradient-based\ntraining. Our approach thus combines the benefits of evolution to discover a\nwide range of different robot morphologies, with the efficiency of supervised\ntraining for robustness through differentiable update rules. The resulting\nneural cellular automata are able to grow virtual robots capable of regaining\nmore than 80\\% of their functionality, even after severe types of morphological\ndamage.",
    "descriptor": "\nComments: Genetic Programming and Evolvable Machines (GENP). arXiv admin note: substantial text overlap with arXiv:2102.02579\n",
    "authors": [
      "Kazuya Horibe",
      "Kathryn Walker",
      "Rasmus Berg Palm",
      "Shyam Sudhakaran",
      "Sebastian Risi"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Populations and Evolution (q-bio.PE)",
      "Tissues and Organs (q-bio.TO)"
    ],
    "url": "https://arxiv.org/abs/2206.06674"
  },
  {
    "id": "arXiv:2206.06676",
    "title": "Efficient Private Storage of Sparse Machine Learning Data",
    "abstract": "We consider the problem of maintaining sparsity in private distributed\nstorage of confidential machine learning data. In many applications, e.g., face\nrecognition, the data used in machine learning algorithms is represented by\nsparse matrices which can be stored and processed efficiently. However,\nmechanisms maintaining perfect information-theoretic privacy require encoding\nthe sparse matrices into randomized dense matrices. It has been shown that,\nunder some restrictions on the storage nodes, sparsity can be maintained at the\nexpense of relaxing the perfect information-theoretic privacy requirement,\ni.e., allowing some information leakage. In this work, we lift the restrictions\nimposed on the storage nodes and show that there exists a trade-off between\nsparsity and the achievable privacy guarantees. We focus on the setting of\nnon-colluding nodes and construct a coding scheme that encodes the sparse input\nmatrices into matrices with the desired sparsity level while limiting the\ninformation leakage.",
    "descriptor": "\nComments: 6 pages, 2 figures, submitted to IEEE for possible publication\n",
    "authors": [
      "Marvin Xhemrishi",
      "Maximilian Egger",
      "Rawad Bitar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.06676"
  },
  {
    "id": "arXiv:2206.06677",
    "title": "Abstraction-Based Segmental Simulation of Chemical Reaction Network",
    "abstract": "Simulating chemical reaction networks is often computationally demanding, in\nparticular due to stiffness. We propose a novel simulation scheme where long\nruns are not simulated as a whole but assembled from shorter precomputed\nsegments of simulation runs. On the one hand, this speeds up the simulation\nprocess to obtain multiple runs since we can reuse the segments. On the other\nhand, questions on diversity and genuineness of our runs arise. However, we\nensure that we generate runs close to their true distribution by generating an\nappropriate abstraction of the original system and utilizing it in the\nsimulation process. Interestingly, as a by-product, we also obtain a yet more\nefficient simulation scheme, yielding runs over the system's abstraction. These\nprovide a very faithful approximation of concrete runs on the desired level of\ngranularity, at a low cost. Our experiments demonstrate the speedups in the\nsimulations while preserving key dynamical as well as quantitative properties.",
    "descriptor": "\nComments: Accepted to Computational Methods in Systems Biology 2022\n",
    "authors": [
      "Martin Helfrich",
      "Milan \u010ce\u0161ka",
      "Jan K\u0159et\u00ednsk\u00fd",
      "\u0160tefan Marti\u010dek"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.06677"
  },
  {
    "id": "arXiv:2206.06679",
    "title": "Matching Pursuit Based Scheduling for Over-the-Air Federated Learning",
    "abstract": "This paper develops a class of low-complexity device scheduling algorithms\nfor over-the-air federated learning via the method of matching pursuit. The\nproposed scheme tracks closely the close-to-optimal performance achieved by\ndifference-of-convex programming, and outperforms significantly the well-known\nbenchmark algorithms based on convex relaxation. Compared to the\nstate-of-the-art, the proposed scheme poses a drastically lower computational\nload on the system: For $K$ devices and $N$ antennas at the parameter server,\nthe benchmark complexity scales with $\\left(N^2+K\\right)^3 + N^6$ while the\ncomplexity of the proposed scheme scales with $K^p N^q$ for some $0 < p,q \\leq\n2$. The efficiency of the proposed scheme is confirmed via numerical\nexperiments on the CIFAR-10 dataset.",
    "descriptor": "\nComments: 46 Pages and 10 Figures\n",
    "authors": [
      "Ali Bereyhi",
      "Adela Vagollari",
      "Saba Asaad",
      "Ralf R. M\u00fcller",
      "Wolfgang Gerstacker",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06679"
  },
  {
    "id": "arXiv:2206.06680",
    "title": "Exploring speaker enrolment for few-shot personalisation in emotional  vocalisation prediction",
    "abstract": "In this work, we explore a novel few-shot personalisation architecture for\nemotional vocalisation prediction. The core contribution is an `enrolment'\nencoder which utilises two unlabelled samples of the target speaker to adjust\nthe output of the emotion encoder; the adjustment is based on dot-product\nattention, thus effectively functioning as a form of `soft' feature selection.\nThe emotion and enrolment encoders are based on two standard audio\narchitectures: CNN14 and CNN10. The two encoders are further guided to forget\nor learn auxiliary emotion and/or speaker information. Our best approach\nachieves a CCC of $.650$ on the ExVo Few-Shot dev set, a $2.5\\%$ increase over\nour baseline CNN14 CCC of $.634$.",
    "descriptor": "\nComments: Proceedings of the ICML Expressive Vocalizations Workshop and Competition held in conjunction with the $\\mathit{39}^{th}$ International Conference on Machine Learning, Copyright 2022 by the author(s)\n",
    "authors": [
      "Andreas Triantafyllopoulos",
      "Meishu Song",
      "Zijiang Yang",
      "Xin Jing",
      "Bj\u00f6rn W. Schuller"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06680"
  },
  {
    "id": "arXiv:2206.06685",
    "title": "Causal Discovery for Fairness",
    "abstract": "It is crucial to consider the social and ethical consequences of AI and ML\nbased decisions for the safe and acceptable use of these emerging technologies.\nFairness, in particular, guarantees that the ML decisions do not result in\ndiscrimination against individuals or minorities. Identifying and measuring\nreliably fairness/discrimination is better achieved using causality which\nconsiders the causal relation, beyond mere association, between the sensitive\nattribute (e.g. gender, race, religion, etc.) and the decision (e.g. job\nhiring, loan granting, etc.). The big impediment to the use of causality to\naddress fairness, however, is the unavailability of the causal model (typically\nrepresented as a causal graph). Existing causal approaches to fairness in the\nliterature do not address this problem and assume that the causal model is\navailable. In this paper, we do not make such assumption and we review the\nmajor algorithms to discover causal relations from observable data. This study\nfocuses on causal discovery and its impact on fairness. In particular, we show\nhow different causal discovery approaches may result in different causal models\nand, most importantly, how even slight differences between causal models can\nhave significant impact on fairness/discrimination conclusions. These results\nare consolidated by empirical analysis using synthetic and standard fairness\nbenchmark datasets. The main goal of this study is to highlight the importance\nof the causal discovery step to appropriately address fairness using causality.",
    "descriptor": "",
    "authors": [
      "R\u016bta Binkyt\u0117-Sadauskien\u0117",
      "Karima Makhlouf",
      "Carlos Pinz\u00f3n",
      "Sami Zhioua",
      "Catuscia Palamidessi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2206.06685"
  },
  {
    "id": "arXiv:2206.06694",
    "title": "ISLES 2022: A multi-center magnetic resonance imaging stroke lesion  segmentation dataset",
    "abstract": "Magnetic resonance imaging (MRI) is a central modality for stroke imaging. It\nis used upon patient admission to make treatment decisions such as selecting\npatients for intravenous thrombolysis or endovascular therapy. MRI is later\nused in the duration of hospital stay to predict outcome by visualizing infarct\ncore size and location. Furthermore, it may be used to characterize stroke\netiology, e.g. differentiation between (cardio)-embolic and non-embolic stroke.\nComputer based automated medical image processing is increasingly finding its\nway into clinical routine. Previous iterations of the Ischemic Stroke Lesion\nSegmentation (ISLES) challenge have aided in the generation of identifying\nbenchmark methods for acute and sub-acute ischemic stroke lesion segmentation.\nHere we introduce an expert-annotated, multicenter MRI dataset for segmentation\nof acute to subacute stroke lesions. This dataset comprises 400 multi-vendor\nMRI cases with high variability in stroke lesion size, quantity and location.\nIt is split into a training dataset of n=250 and a test dataset of n=150. All\ntraining data will be made publicly available. The test dataset will be used\nfor model validation only and will not be released to the public. This dataset\nserves as the foundation of the ISLES 2022 challenge with the goal of finding\nalgorithmic methods to enable the development and benchmarking of robust and\naccurate segmentation algorithms for ischemic stroke.",
    "descriptor": "\nComments: 12 pages, 2 figures\n",
    "authors": [
      "Moritz Roman Hernandez Petzsche",
      "Ezequiel de la Rosa",
      "Uta Hanning",
      "Roland Wiest",
      "Waldo Enrique Valenzuela Pinilla",
      "Mauricio Reyes",
      "Maria Ines Meyer",
      "Sook-Lei Liew",
      "Florian Kofler",
      "Ivan Ezhov",
      "David Robben",
      "Alexander Hutton",
      "Tassilo Friedrich",
      "Teresa Zarth",
      "Johannes B\u00fcrkle",
      "Anh Baran",
      "Bjoern Menze",
      "Gabriel Broocks",
      "Lukas Meyer",
      "Claus Zimmer",
      "Tobias Boeckh-Behrens",
      "Maria Berndt",
      "Benno Ikenberg",
      "Benedikt Wiestler",
      "Jan S. Kirschke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06694"
  },
  {
    "id": "arXiv:2206.06705",
    "title": "Task Transfer and Domain Adaptation for Zero-Shot Question Answering",
    "abstract": "Pretrained language models have shown success in various areas of natural\nlanguage processing, including reading comprehension tasks. However, when\napplying machine learning methods to new domains, labeled data may not always\nbe available. To address this, we use supervised pretraining on source-domain\ndata to reduce sample complexity on domain-specific downstream tasks. We\nevaluate zero-shot performance on domain-specific reading comprehension tasks\nby combining task transfer with domain adaptation to fine-tune a pretrained\nmodel with no labelled data from the target task. Our approach outperforms\nDomain-Adaptive Pretraining on downstream domain-specific reading comprehension\ntasks in 3 out of 4 domains.",
    "descriptor": "\nComments: NAACL 2022 Deep Learning for Low-Resource NLP Workshop Paper\n",
    "authors": [
      "Xiang Pan",
      "Alex Sheng",
      "David Shimshoni",
      "Aditya Singhal",
      "Sara Rosenthal",
      "Avirup Sil"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06705"
  },
  {
    "id": "arXiv:2206.06706",
    "title": "An analysis of retracted papers in Computer Science",
    "abstract": "Context: The retraction of research papers, for whatever reason, is a growing\nphenomenon. However, although retracted paper information is publicly available\nvia publishers, it is somewhat distributed and inconsistent. Objective: The aim\nis to assess: (i) the extent and nature of retracted research in Computer\nScience (CS) (ii) the post-retraction citation behaviour of retracted works and\n(iii) the potential impact on systematic reviews and mapping studies. Method:\nWe analyse the Retraction Watch database and take citation information from the\nWeb of Science and Google scholar. Results: We find that of the 33,955 entries\nin the Retraction watch database (16 May 2022), 2,816 are classified as CS,\ni.e., approximately 8.3%. For CS, 56% of retracted papers, provide little or no\ninformation as to the reasons. This contrasts with 26% for other disciplines.\nThere is also a remarkable disparity between different publishers, a tendency\nfor multiple versions of a retracted paper over and above the Version of Record\n(VoR), and for new citations long after a paper is officially retracted.\nConclusions: Unfortunately retraction seems to be a sufficiently common outcome\nfor a scientific paper that we as a research community need to take it more\nseriously, e.g., standardising procedures and taxonomies across publishers and\nthe provision of appropriate research tools. Finally, we recommend particular\ncaution when undertaking secondary analyses and meta-analyses which are at risk\nof becoming contaminated by these problem primary studies.",
    "descriptor": "\nComments: This is a preprint of the paper submitted to PLOS ONE\n",
    "authors": [
      "Martin Shepperd",
      "Leila Yousefi"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.06706"
  },
  {
    "id": "arXiv:2206.06712",
    "title": "Visual Radial Basis Q-Network",
    "abstract": "While reinforcement learning (RL) from raw images has been largely\ninvestigated in the last decade, existing approaches still suffer from a number\nof constraints. The high input dimension is often handled using either expert\nknowledge to extract handcrafted features or environment encoding through\nconvolutional networks. Both solutions require numerous parameters to be\noptimized. In contrast, we propose a generic method to extract sparse features\nfrom raw images with few trainable parameters. We achieved this using a Radial\nBasis Function Network (RBFN) directly on raw image. We evaluate the\nperformance of the proposed approach for visual extraction in Q-learning tasks\nin the Vizdoom environment. Then, we compare our results with two Deep\nQ-Network, one trained directly on images and another one trained on feature\nextracted by a pretrained auto-encoder. We show that the proposed approach\nprovides similar or, in some cases, even better performances with fewer\ntrainable parameters while being conceptually simpler.",
    "descriptor": "\nComments: This paper has been accepted for publication at the 3rd International Conference on Pattern Recognition and Artificial Intelligence, ICPRAI 2022. \\c{opyright}Springer Nature 2022\n",
    "authors": [
      "Julien Hautot",
      "C\u00e9line Teuliere",
      "Nourddine Azzaoui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06712"
  },
  {
    "id": "arXiv:2206.06714",
    "title": "Interpretable Gait Recognition by Granger Causality",
    "abstract": "Which joint interactions in the human gait cycle can be used as biometric\ncharacteristics? Most current methods on gait recognition suffer from the lack\nof interpretability. We propose an interpretable feature representation of gait\nsequences by the graphical Granger causal inference. Gait sequence of a person\nin the standardized motion capture format, constituting a set of 3D joint\nspatial trajectories, is envisaged as a causal system of joints interacting in\ntime. We apply the graphical Granger model (GGM) to obtain the so-called\nGranger causal graph among joints as a discriminative and visually\ninterpretable representation of a person's gait. We evaluate eleven distance\nfunctions in the GGM feature space by established classification and\nclass-separability evaluation metrics. Our experiments indicate that, depending\non the metric, the most appropriate distance functions for the GGM are the\ntotal norm distance and the Ky-Fan 1-norm distance. Experiments also show that\nthe GGM is able to detect the most discriminative joint interactions and that\nit outperforms five related interpretable models in correct classification rate\nand in Davies-Bouldin index. The proposed GGM model can serve as a\ncomplementary tool for gait analysis in kinesiology or for gait recognition in\nvideo surveillance.",
    "descriptor": "\nComments: Preprint. Full paper accepted at the IEEE/IAPR International Conference on Pattern Recognition (ICPR), Montreal, Canada, August 2022. 7 pages\n",
    "authors": [
      "Michal Balazia",
      "Katerina Hlavackova-Schindler",
      "Petr Sojka",
      "Claudia Plant"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06714"
  },
  {
    "id": "arXiv:2206.06715",
    "title": "Semi-signed neural fitting for surface reconstruction from unoriented  point clouds",
    "abstract": "Reconstructing 3D geometry from \\emph{unoriented} point clouds can benefit\nmany downstream tasks. Recent methods mostly adopt a neural shape\nrepresentation with a neural network to represent a signed distance field and\nfit the point cloud with an unsigned supervision. However, we observe that\nusing unsigned supervision may cause severe ambiguities and often leads to\n\\emph{unexpected} failures such as generating undesired surfaces in free space\nwhen reconstructing complex structures and struggle with reconstructing\naccurate surfaces. To reconstruct a better signed distance field, we propose\nsemi-signed neural fitting (SSN-Fitting), which consists of a semi-signed\nsupervision and a loss-based region sampling strategy. Our key insight is that\nsigned supervision is more informative and regions that are obviously outside\nthe object can be easily determined. Meanwhile, a novel importance sampling is\nproposed to accelerate the optimization and better reconstruct the fine\ndetails. Specifically, we voxelize and partition the object space into\n\\emph{sign-known} and \\emph{sign-uncertain} regions, in which different\nsupervisions are applied. Also, we adaptively adjust the sampling rate of each\nvoxel according to the tracked reconstruction loss, so that the network can\nfocus more on the complex under-fitting regions. We conduct extensive\nexperiments to demonstrate that SSN-Fitting achieves state-of-the-art\nperformance under different settings on multiple datasets, including clean,\ndensity-varying, and noisy data.",
    "descriptor": "",
    "authors": [
      "Runsong Zhu",
      "Di Kang",
      "Ka-Hei Hui",
      "Yue Qian",
      "Xuefei Zhe",
      "Zhen Dong",
      "Linchao Bao",
      "Chi-Wing Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06715"
  },
  {
    "id": "arXiv:2206.06716",
    "title": "A Neural Network-Based Energy Management System for PV-Battery Based  Microgrids",
    "abstract": "A neural network-based energy management system (NN-EMS) has been proposed in\nthis paper for islanded ac microgrids fed by multiple PV-battery based\ndistributed generators (DG). The stochastic and unequal irradiation results in\nunequal PV output, which causes an unequal state-of-charge (SoC) among the\nbatteries of the DGs. This effect may cause the difference in the SoCs to\nincrease considerably over time, leading to some batteries reaching their SoC\nlimits. These batteries would no longer be able to control the dc-link of the\nhybrid grid forming DG. The proposed NN-EMS ensures SoC balancing by learning\nan optimal state-action mapping using the outputs of an optimal power flow\n(OPF). The training dataset has been generated by executing a mixed-integer\nlinear programming based OPF for droop-based island microgrids considering a\npractical generation-load profile. The resultant NN-EMS controller inherits the\ninformation of optimal states and the network behaviour. Compared to\ntraditional time-ahead centralized methods, the proposed strategy does not\nrequire accurate generation-load forecasting. Further, it can also respond to\nthe variations in the PV power in near-real-time without resorting to solving\nan OPF. The proposed NN-EMS controller has been validated by case studies on a\nCIGRE LV microgrid containing PV-battery hybrid DGs. The proposed concept can\nalso be extended to synthesize decentralized controllers that can cooperate\namong themselves to achieve a global objective without communication.",
    "descriptor": "\nComments: 10 pages, 15 figures\n",
    "authors": [
      "Yusuf Gupta",
      "Mohammad Amin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.06716"
  },
  {
    "id": "arXiv:2206.06719",
    "title": "Stein Variational Goal Generation For Reinforcement Learning in Hard  Exploration Problems",
    "abstract": "Multi-goal Reinforcement Learning has recently attracted a large amount of\nresearch interest. By allowing experience to be shared between related training\ntasks, this setting favors generalization for new tasks at test time, whenever\nsome smoothness exists in the considered representation space of goals.\nHowever, in settings with discontinuities in state or goal spaces (e.g. walls\nin a maze), a majority of goals are difficult to reach, due to the sparsity of\nrewards in the absence of expert knowledge. This implies hard exploration, for\nwhich some curriculum of goals must be discovered, to help agents learn by\nadapting training tasks to their current capabilities. Building on recent\nautomatic curriculum learning techniques for goal-conditioned policies, we\npropose a novel approach: Stein Variational Goal Generation (SVGG), which seeks\nat preferably sampling new goals in the zone of proximal development of the\nagent, by leveraging a learned model of its abilities, and a goal distribution\nmodeled as particles in the exploration space. Our approach relies on Stein\nVariational Gradient Descent to dynamically attract the goal sampling\ndistribution in areas of appropriate difficulty. We demonstrate the\nperformances of the approach, in terms of success coverage in the goal space,\ncompared to recent state-of-the-art RL methods for hard exploration problems.",
    "descriptor": "",
    "authors": [
      "Nicolas Castanet",
      "Sylvain Lamprier",
      "Olivier Sigaud"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06719"
  },
  {
    "id": "arXiv:2206.06722",
    "title": "Specification sketching for Linear Temporal Logic",
    "abstract": "Virtually all verification and synthesis techniques assume that the formal\nspecifications are readily available, functionally correct, and fully match the\nengineer's understanding of the given system. However, this assumption is often\nunrealistic in practice: formalizing system requirements is notoriously\ndifficult, error-prone, and requires substantial training. To alleviate this\nsevere hurdle, we propose a fundamentally novel approach to writing formal\nspecifications, named specification sketching for Linear Temporal Logic (LTL).\nThe key idea is that an engineer can provide a partial LTL formula, called an\nLTL sketch, where parts that are hard to formalize can be left out. Given a set\nof examples describing system behaviors that the specification should or should\nnot allow, the task of a so-called sketching algorithm is then to complete a\ngiven sketch such that the resulting LTL formula is consistent with the\nexamples. We show that deciding whether a sketch can be completed falls into\nthe complexity class NP and present two SAT-based sketching algorithms. We also\ndemonstrate that sketching is a practical approach to writing formal\nspecifications using a prototype implementation.",
    "descriptor": "",
    "authors": [
      "Simon Lutz",
      "Daniel Neider",
      "Rajarshi Roy"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.06722"
  },
  {
    "id": "arXiv:2206.06723",
    "title": "Development of a hybrid method for stock trading based on TOPSIS, EMD  and ELM",
    "abstract": "Deciding when to buy or sell a stock is not an easy task because the market\nis hard to predict, being influenced by political and economic factors. Thus,\nmethodologies based on computational intelligence have been applied to this\nchallenging problem. In this work, every day the stocks are ranked by technique\nfor order preference by similarity to ideal solution (TOPSIS) using technical\nanalysis criteria, and the most suitable stock is selected for purchase. Even\nso, it may occur that the market is not favorable to purchase on certain days,\nor even, the TOPSIS make an incorrect selection. To improve the selection,\nanother method should be used. So, a hybrid model composed of empirical mode\ndecomposition (EMD) and extreme learning machine (ELM) is proposed. The EMD\ndecomposes the series into several sub-series, and thus the main omponent\n(trend) is extracted. This component is processed by the ELM, which performs\nthe prediction of the next element of component. If the value predicted by the\nELM is greater than the last value, then the purchase of the stock is\nconfirmed. The method was applied in a universe of 50 stocks in the Brazilian\nmarket. The selection made by TOPSIS showed promising results when compared to\nthe random selection and the return generated by the Bovespa index.\nConfirmation with the EMD-ELM hybrid model was able to increase the percentage\nof profit tradings.",
    "descriptor": "",
    "authors": [
      "Elivelto Ebermam",
      "Helder Knidel",
      "Renato A. Krohling"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.06723"
  },
  {
    "id": "arXiv:2206.06724",
    "title": "Modelling Guidance in Software Engineering: A Systematic Literature  Review",
    "abstract": "Despite potential benefits in Software Engineering (SE), adoption of software\nmodelling in industry is low. Technical issues such as tool support have gained\nsignificant research before, but individual guidance and training have received\nlittle attention. As a first step towards providing the necessary guidance in\nmodelling, we conduct a systematic literature review (SLR) to explore the\ncurrent state of the art. We searched academic literature for modelling\nguidance, and selected 25 papers for full-text screening through three rounds\nof selection. We find research on modelling guidance to be fragmented, with\ninconsistent usage of terminology, and a lack of empirical validation or\nsupporting evidence. We outline the different dimensions commonly used to\nprovide guidance on software modelling. Additionally, we provide definitions of\nthe three terms modelling method, style, and guideline as current literature\nlacks a well-defined distinction between them. These definitions can help\ndistinguishing between important concepts and provide precise modelling\nguidance.",
    "descriptor": "\nComments: Submitted to a journal\n",
    "authors": [
      "Shalini Chakraborty",
      "Grischa Liebel"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.06724"
  },
  {
    "id": "arXiv:2206.06731",
    "title": "Learning Dense Features for Point Cloud Registration Using Graph  Attention Network",
    "abstract": "Point cloud registration is a fundamental task in many applications such as\nlocalization, mapping, tracking, and reconstruction. The successful\nregistration relies on extracting robust and discriminative geometric features.\nExisting learning-based methods require high computing capacity for processing\na large number of raw points at the same time. Although these approaches\nachieve convincing results, they are difficult to apply in real-world\nsituations due to high computational costs. In this paper, we introduce a\nframework that efficiently and economically extracts dense features using graph\nattention network for point cloud matching and registration (DFGAT). The\ndetector of the DFGAT is responsible for finding highly reliable key points in\nlarge raw data sets. The descriptor of the DFGAT takes these key points\ncombined with their neighbors to extract invariant density features in\npreparation for the matching. The graph attention network uses the attention\nmechanism that enriches the relationships between point clouds. Finally, we\nconsider this as an optimal transport problem and use the Sinkhorn algorithm to\nfind positive and negative matches. We perform thorough tests on the KITTI\ndataset and evaluate the effectiveness of this approach. The results show that\nthis method with the efficiently compact keypoint selection and description can\nachieve the best performance matching metrics and reach highest success ratio\nof 99.88% registration in comparison with other state-of-the-art approaches.",
    "descriptor": "\nComments: This draft is submitted\n",
    "authors": [
      "Lai Dang Quoc Vinh",
      "Sarvar Hussain Nengroo",
      "Hojun Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06731"
  },
  {
    "id": "arXiv:2206.06737",
    "title": "Adversarial Vulnerability of Randomized Ensembles",
    "abstract": "Despite the tremendous success of deep neural networks across various tasks,\ntheir vulnerability to imperceptible adversarial perturbations has hindered\ntheir deployment in the real world. Recently, works on randomized ensembles\nhave empirically demonstrated significant improvements in adversarial\nrobustness over standard adversarially trained (AT) models with minimal\ncomputational overhead, making them a promising solution for safety-critical\nresource-constrained applications. However, this impressive performance raises\nthe question: Are these robustness gains provided by randomized ensembles real?\nIn this work we address this question both theoretically and empirically. We\nfirst establish theoretically that commonly employed robustness evaluation\nmethods such as adaptive PGD provide a false sense of security in this setting.\nSubsequently, we propose a theoretically-sound and efficient adversarial attack\nalgorithm (ARC) capable of compromising random ensembles even in cases where\nadaptive PGD fails to do so. We conduct comprehensive experiments across a\nvariety of network architectures, training schemes, datasets, and norms to\nsupport our claims, and empirically establish that randomized ensembles are in\nfact more vulnerable to $\\ell_p$-bounded adversarial perturbations than even\nstandard AT models. Our code can be found at https://github.com/hsndbk4/ARC.",
    "descriptor": "\nComments: Published as a conference paper in ICML 2022\n",
    "authors": [
      "Hassan Dbouk",
      "Naresh R. Shanbhag"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06737"
  },
  {
    "id": "arXiv:2206.06738",
    "title": "Four Years of FAccT: A Reflexive, Mixed-Methods Analysis of Research  Contributions, Shortcomings, and Future Prospects",
    "abstract": "Fairness, Accountability, and Transparency (FAccT) for socio-technical\nsystems has been a thriving area of research in recent years. An ACM conference\nbearing the same name has been the central venue for scholars in this area to\ncome together, provide peer feedback to one another, and publish their work.\nThis reflexive study aims to shed light on FAccT's activities to date and\nidentify major gaps and opportunities for translating contributions into\nbroader positive impact. To this end, we utilize a mixed-methods research\ndesign. On the qualitative front, we develop a protocol for reviewing and\ncoding prior FAccT papers, tracing their distribution of topics, methods,\ndatasets, and disciplinary roots. We also design and administer a questionnaire\nto reflect the voices of FAccT community members and affiliates on a wide range\nof topics. On the quantitative front, we use the full text and citation network\nassociated with prior FAccT publications to provide further evidence about\ntopics and values represented in FAccT. We organize the findings from our\nanalysis into four main dimensions: the themes present in FAccT scholarship,\nthe values that underpin the work, the impact of the contributions both within\nacademic circles and beyond, and the practices and informal norms of the\ncommunity that has formed around FAccT. Finally, our work identifies several\nsuggestions on directions for change, as voiced by community members.",
    "descriptor": "\nComments: 26 pages, 5 figures, to be published in 2022 ACM Conference on Fairness, Accountability, and Transparency\n",
    "authors": [
      "Benjamin Laufer",
      "Sameer Jain",
      "A. Feder Cooper",
      "Jon Kleinberg",
      "Hoda Heidari"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Digital Libraries (cs.DL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.06738"
  },
  {
    "id": "arXiv:2206.06741",
    "title": "Recurrent Transformer Variational Autoencoders for Multi-Action Motion  Synthesis",
    "abstract": "We consider the problem of synthesizing multi-action human motion sequences\nof arbitrary lengths. Existing approaches have mastered motion sequence\ngeneration in single-action scenarios, but fail to generalize to multi-action\nand arbitrary-length sequences. We fill this gap by proposing a novel efficient\napproach that leverages the expressiveness of Recurrent Transformers and\ngenerative richness of conditional Variational Autoencoders. The proposed\niterative approach is able to generate smooth and realistic human motion\nsequences with an arbitrary number of actions and frames while doing so in\nlinear space and time. We train and evaluate the proposed approach on PROX\ndataset which we augment with ground-truth action labels. Experimental\nevaluation shows significant improvements in FID score and semantic consistency\nmetrics compared to the state-of-the-art.",
    "descriptor": "\nComments: accepted at Transformers for Vision workshop at CVPR 2022\n",
    "authors": [
      "Rania Briq",
      "Chuhang Zou",
      "Leonid Pishchulin",
      "Chris Broaddus",
      "Juergen Gall"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06741"
  },
  {
    "id": "arXiv:2206.06743",
    "title": "Weakly-Supervised Crack Detection",
    "abstract": "Pixel-level crack segmentation is widely studied due to its high impact on\nbuilding and road inspections. Recent studies have made significant\nimprovements in accuracy, but overlooked the annotation cost bottleneck. To\nresolve this issue, we reformulate the crack segmentation problem as a\nweakly-supervised problem, and propose a two-branched inference framework and\nan annotation refinement module that requires no additional data, in order to\ncounteract the loss in annotation quality. Experimental results confirm the\neffectiveness of the proposed method in crack segmentation as well as other\ntarget domains.",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Intelligent Transportation Systems\n",
    "authors": [
      "Yuki Inoue",
      "Hiroto Nagayoshi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06743"
  },
  {
    "id": "arXiv:2206.06744",
    "title": "Counting Markov Equivalent Directed Acyclic Graphs Consistent with  Background Knowledge",
    "abstract": "A polynomial-time exact algorithm for counting the number of directed acyclic\ngraphs in a Markov equivalence class was recently given by Wien\\\"obst, Bannach,\nand Li\\'skiewicz (AAAI 2021). In this paper, we consider the more general\nproblem of counting the number of directed acyclic graphs in a Markov\nequivalence class when the directions of some of the edges are also fixed (this\nsetting arises, for example, when interventional data is partially available).\nThis problem has been shown in earlier work to be complexity-theoretically\nhard. In contrast, we show that the problem is nevertheless tractable in an\ninteresting class of instances, by establishing that it is ``fixed-parameter\ntractable''. In particular, our counting algorithm runs in time that is bounded\nby a polynomial in the size of the graph, where the degree of the polynomial\ndoes \\emph{not} depend upon the number of additional edges provided as input.",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Vidya Sagar Sharma"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Artificial Intelligence (cs.AI)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06744"
  },
  {
    "id": "arXiv:2206.06745",
    "title": "Time Optimization of Constrained Control for a Thermoelectric Solid  System with a Peltier Element",
    "abstract": "A solid system consisting of two heat conducting cylinders with a\nthermoelectric converter (Peltier element) between them is considered. A\nnonlinear model, which was previously verified by authors, is used to design a\nconstrained control law that allows us to achieve a steady-state distribution\nof the temperature in one of the cylinders in much less time than the\ncharacteristic time of transient processes. The initial-boundary value problem\nis exactly linearized over temperature by means of feedback linearization.\nAlthough the resulting system is nonlinear in a control function, it is\npossible to construct a finite-dimensional approximation based on analytical\nsolution of the corresponding eigenproblem for a constant control signal. The\ntime-optimal control problem is studied numerically by using this eigenfunction\ndecomposition. To construct admissible control laws, an auxiliary unconstrained\noptimization problem is introduced. Its cost functional represents a weighted\nsum of temperature deviation from the desired zero distribution and a penalty\nfor violating an electric power constraint. The control time interval is split\ninto several parts, and on each subinterval the control signal is taken\nconstant. The optimal piecewise constant feedforward control is found\nnumerically by applying the gradient descent method. We analyze the proposed\ncontrol law with respect to the shortest admissible time of the process.",
    "descriptor": "",
    "authors": [
      "Alexander Gavrikov",
      "Georgy Kostin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Materials Science (cond-mat.mtrl-sci)"
    ],
    "url": "https://arxiv.org/abs/2206.06745"
  },
  {
    "id": "arXiv:2206.06747",
    "title": "Learning from Uncurated Regular Expressions",
    "abstract": "Significant work has been done on learning regular expressions from a set of\ndata values. Depending on the domain, this approach can be very successful.\nHowever, significant time is required to learn these expressions and the\nresulting expressions can either become very complex or inaccurate in the\npresence of dirty data. The alternative of manually writing regular expressions\nbecomes unattractive when faced with a large number of values which must be\nmatched.\nAs an alternative, we propose learning from a large corpus of manually\nauthored, but uncurated regular expressions mined from a public repository. The\nadvantage of this approach is that we are able to extract salient features from\na set of strings with limited overhead to feature engineering. Since the set of\nregular expressions covers a wide range of application domains, we expect them\nto widely applicable.\nTo demonstrate the potential effectiveness of our approach, we train a model\nusing the extracted corpus of regular expressions for the class of semantic\ntype classification. While our approach generally yields results that are\ninferior to the state of the art, our training data is much smaller and simpler\nand a closer analysis of the performance results suggests this approach holds\nsignificant promise. We also demonstrate the possibility of using uncurated\nregular expressions for unsupervised learning.",
    "descriptor": "",
    "authors": [
      "Michael J. Mior"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2206.06747"
  },
  {
    "id": "arXiv:2206.06754",
    "title": "Expressiveness within Sequence Datalog",
    "abstract": "Motivated by old and new applications, we investigate Datalog as a language\nfor sequence databases. We reconsider classical features of Datalog programs,\nsuch as negation, recursion, intermediate predicates, and relations of higher\narities. We also consider new features that are useful for sequences, notably,\nequations between path expressions, and \"packing\". Our goal is to clarify the\nrelative expressiveness of all these different features, in the context of\nsequences. Towards our goal, we establish a number of redundancy and\nprimitivity results, showing that certain features can, or cannot, be expressed\nin terms of other features. These results paint a complete picture of the\nexpressiveness relationships among all possible Sequence Datalog fragments that\ncan be formed using the six features that we consider.",
    "descriptor": "\nComments: This paper is the extended version of a paper presented at PODS 2021\n",
    "authors": [
      "Heba Aamer",
      "Jan Hidders",
      "Jan Paredaens",
      "Jan Van den Bussche"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2206.06754"
  },
  {
    "id": "arXiv:2206.06757",
    "title": "RoSGAS: Adaptive Social Bot Detection with Reinforced Self-Supervised  GNN Architecture Search",
    "abstract": "Social bots are referred to as the automated accounts on social networks that\nmake attempts to behave like human. While Graph Neural Networks (GNNs) has been\nmassively applied to the field of social bot detection, a huge amount of domain\nexpertise and prior knowledge is heavily engaged in the state-of-the art\napproaches to design a dedicated neural network architecture for a specific\nclassification task. Involving oversized nodes and network layers in the model\ndesign, however, usually causes the over-smoothing problem and the lack of\nembedding discrimination. In this paper, we propose RoSGAS, a novel Reinforced\nand Self-supervised GNN Architecture Search framework to adaptively pinpoint\nthe most suitable multi-hop neighborhood and the number of layers in the GNN\narchitecture. More specifically, we consider the social bot detection problem\nas a user-centric subgraph embedding and classification task. We exploit\nheterogeneous information network to present the user connectivity by\nleveraging account metadata, relationships, behavioral features and content\nfeatures. RoSGAS uses a multi-agent deep reinforcement learning (RL) mechanism\nfor navigating the search of optimal neighborhood and network layers to learn\nindividually the subgraph embedding for each target user. A nearest neighbor\nmechanism is developed for accelerating the RL training process, and RoSGAS can\nlearn more discriminative subgraph embedding with the aid of self-supervised\nlearning. Experiments on 5 Twitter datasets show that RoSGAS outperforms the\nstate-of-the-art approaches in terms of accuracy, training efficiency and\nstability, and has better generalization when handling unseen samples.",
    "descriptor": "\nComments: 32 pages, 12 figures\n",
    "authors": [
      "Yingguang Yang",
      "Renyu Yang",
      "Yangyang Li",
      "Kai Cui",
      "Zhiqin Yang",
      "Yue Wang",
      "Jie Xu",
      "Haiyong Xie"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06757"
  },
  {
    "id": "arXiv:2206.06758",
    "title": "Universally Expressive Communication in Multi-Agent Reinforcement  Learning",
    "abstract": "Allowing agents to share information through communication is crucial for\nsolving complex tasks in multi-agent reinforcement learning. In this work, we\nconsider the question of whether a given communication protocol can express an\narbitrary policy. By observing that many existing protocols can be viewed as\ninstances of graph neural networks (GNNs), we demonstrate the equivalence of\njoint action selection to node labelling. With standard GNN approaches provably\nlimited in their expressive capacity, we draw from existing GNN literature and\nconsider augmenting agent observations with: (1) unique agent IDs and (2)\nrandom noise. We provide a theoretical analysis as to how these approaches\nyield universally expressive communication, and also prove them capable of\ntargeting arbitrary sets of actions for identical agents. Empirically, these\naugmentations are found to improve performance on tasks where expressive\ncommunication is required, whilst, in general, the optimal communication\nprotocol is found to be task-dependent.",
    "descriptor": "\nComments: Submitted to NeurIPS 2022\n",
    "authors": [
      "Matthew Morris",
      "Thomas D. Barrett",
      "Arnu Pretorius"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06758"
  },
  {
    "id": "arXiv:2206.06761",
    "title": "Exploring Adversarial Attacks and Defenses in Vision Transformers  trained with DINO",
    "abstract": "This work conducts the first analysis on the robustness against adversarial\nattacks on self-supervised Vision Transformers trained using DINO. First, we\nevaluate whether features learned through self-supervision are more robust to\nadversarial attacks than those emerging from supervised learning. Then, we\npresent properties arising for attacks in the latent space. Finally, we\nevaluate whether three well-known defense strategies can increase adversarial\nrobustness in downstream tasks by only fine-tuning the classification head to\nprovide robustness even in view of limited compute resources. These defense\nstrategies are: Adversarial Training, Ensemble Adversarial Training and\nEnsemble of Specialized Networks.",
    "descriptor": "\nComments: 6 pages workshop paper accepted at AdvML Frontiers (ICML 2022)\n",
    "authors": [
      "Javier Rando",
      "Nasib Naimi",
      "Thomas Baumann",
      "Max Mathys"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.06761"
  },
  {
    "id": "arXiv:2206.06767",
    "title": "Performance Analysis of SWIPT Relay Networks over Arbitrary Dependent  Fading Channels",
    "abstract": "In this paper, we investigate the impact of fading channel correlation on the\nperformance of dual-hop decode-and-forward (DF) simultaneous wireless\ninformation and power transfer (SWIPT) relay networks. More specifically, by\nconsidering the power splitting-based relaying (PSR) protocol for the energy\nharvesting (EH) process, we quantify the effect of positive and negative\ndependency between the source-to-relay (SR) and relay-to-destination (RD) links\non key performance metrics such as ergodic capacity and outage probability. To\nthis end, we first represent general formulations for the cumulative\ndistribution function (CDF) of the product of two arbitrary random variables,\nexploiting copula theory. This is used to derive the closed-form expressions of\nthe ergodic capacity and outage probability in a SWIPT relay network under\ncorrelated Nakagami-m fading channels. Monte-Carlo (MC) simulation results are\nprovided throughout to validate the correctness of the developed analytical\nresults, showing that the system performance significantly improves under\npositive dependence in the SR-RD links, compared to the case of negative\ndependence and independent links. Results further demonstrate that the\nefficiency of the ergodic capacity and outage probability ameliorates as the\nfading severity reduces for the PSR protocol.",
    "descriptor": "",
    "authors": [
      "Farshad Rostami Ghadi",
      "F. Javier Lopez-Martinez"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.06767"
  },
  {
    "id": "arXiv:2206.06769",
    "title": "Muntjac -- Open Source Multicore RV64 Linux-capable SoC",
    "abstract": "Muntjac is an open-source collection of components which can be used to build\na multicore, Linux-capable system-on-chip. This includes a 64-bit RISC-V core,\na cache subsystem, and TileLink interconnect allowing cache-coherent multicore\nconfigurations. Each component is easy to understand, verify, and extend, with\nmost being configurable enough to be useful across a wide range of\napplications.",
    "descriptor": "\nComments: To be published in the First Workshop on Open-Source Computer Architecture Research\n",
    "authors": [
      "Xuan Guo",
      "Daniel Bates",
      "Robert Mullins",
      "Alex Bradbury"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2206.06769"
  },
  {
    "id": "arXiv:2206.06775",
    "title": "DeepEmotex: Classifying Emotion in Text Messages using Deep Transfer  Learning",
    "abstract": "Transfer learning has been widely used in natural language processing through\ndeep pretrained language models, such as Bidirectional Encoder Representations\nfrom Transformers and Universal Sentence Encoder. Despite the great success,\nlanguage models get overfitted when applied to small datasets and are prone to\nforgetting when fine-tuned with a classifier. To remedy this problem of\nforgetting in transferring deep pretrained language models from one domain to\nanother domain, existing efforts explore fine-tuning methods to forget less. We\npropose DeepEmotex an effective sequential transfer learning method to detect\nemotion in text. To avoid forgetting problem, the fine-tuning step is\ninstrumented by a large amount of emotion-labeled data collected from Twitter.\nWe conduct an experimental study using both curated Twitter data sets and\nbenchmark data sets. DeepEmotex models achieve over 91% accuracy for\nmulti-class emotion classification on test dataset. We evaluate the performance\nof the fine-tuned DeepEmotex models in classifying emotion in EmoInt and\nStimulus benchmark datasets. The models correctly classify emotion in 73% of\nthe instances in the benchmark datasets. The proposed DeepEmotex-BERT model\noutperforms Bi-LSTM result on the benchmark datasets by 23%. We also study the\neffect of the size of the fine-tuning dataset on the accuracy of our models.\nOur evaluation results show that fine-tuning with a large set of\nemotion-labeled data improves both the robustness and effectiveness of the\nresulting target task model.",
    "descriptor": "",
    "authors": [
      "Maryam Hasan",
      "Elke Rundensteiner",
      "Emmanuel Agu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06775"
  },
  {
    "id": "arXiv:2206.06779",
    "title": "Quantitative performance evaluation of Bayesian neural networks",
    "abstract": "Due to the growing adoption of deep neural networks in many fields of science\nand engineering, modeling and estimating their uncertainties has become of\nprimary importance. Various approaches have been investigated including\nBayesian neural networks, ensembles, deterministic approximations, amongst\nothers. Despite the growing litterature about uncertainty quantification in\ndeep learning, the quality of the uncertainty estimates remains an open\nquestion. In this work, we attempt to assess the performance of several\nalgorithms on sampling and regression tasks by evaluating the quality of the\nconfidence regions and how well the generated samples are representative of the\nunknown target distribution. Towards this end, several sampling and regression\ntasks are considered, and the selected algorithms are compared in terms of\ncoverage probabilities, kernelized Stein discrepancies, and maximum mean\ndiscrepancies.",
    "descriptor": "",
    "authors": [
      "Brian Staber",
      "S\u00e9bastien da Veiga"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06779"
  },
  {
    "id": "arXiv:2206.06780",
    "title": "Memory-Oriented Design-Space Exploration of Edge-AI Hardware for XR  Applications",
    "abstract": "Low-Power Edge-AI capabilities are essential for on-device extended reality\n(XR) applications to support the vision of Metaverse. In this work, we\ninvestigate two representative XR workloads: (i) Hand detection and (ii) Eye\nsegmentation, for hardware design space exploration. For both applications, we\ntrain deep neural networks and analyze the impact of quantization and hardware\nspecific bottlenecks. Through simulations, we evaluate a CPU and two systolic\ninference accelerator implementations. Next, we compare these hardware\nsolutions with advanced technology nodes. The impact of integrating\nstate-of-the-art emerging non-volatile memory technology (STT/SOT/VGSOT MRAM)\ninto the XR-AI inference pipeline is evaluated. We found that significant\nenergy benefits (>=80%) can be achieved for hand detection (IPS=40) and eye\nsegmentation (IPS=6) by introducing non-volatile memory in the memory hierarchy\nfor designs at 7nm node while meeting minimum IPS (inference per second).\nMoreover, we can realize substantial reduction in area (>=30%) owing to the\nsmall form factor of MRAM compared to traditional SRAM.",
    "descriptor": "",
    "authors": [
      "Vivek Parmar",
      "Syed Shakib Sarwar",
      "Ziyun Li",
      "Hsien-Hsin S. Lee",
      "Barbara De Salvo",
      "Manan Suri"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.06780"
  },
  {
    "id": "arXiv:2206.06783",
    "title": "Characteristic Mode Decomposition Using the Scattering Dyadic in  Arbitrary Full-Wave Solvers",
    "abstract": "Characteristic modes are formulated using the scattering dyadic, which maps\nincident plane waves to scattered far fields generated by an object of\narbitrary material composition. Numerical construction of the scattering dyadic\nusing arbitrary full-wave electromagnetic solvers is demonstrated in examples\ninvolving a variety of dielectric and magnetic materials. Wrapper functions for\ncomputing characteristic modes in method-of-moments, finite-difference time\ndomain, and finite element solvers are provided as supplementary material.",
    "descriptor": "\nComments: 10 pages, 10 figures, with supplementary material (github)\n",
    "authors": [
      "Miloslav Capek",
      "Johan Lundgren",
      "Mats Gustafsson",
      "Kurt Schab",
      "Lukas Jelinek"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Classical Physics (physics.class-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.06783"
  },
  {
    "id": "arXiv:2206.06789",
    "title": "PhML-DyR: A Physics-Informed ML framework for Dynamic Reconfiguration in  Power Systems",
    "abstract": "A transformation of the US electricity sector is underway with aggressive\ntargets to achieve 100% carbon pollution-free electricity by 2035. To achieve\nthis objective while maintaining a safe and reliable power grid, new operating\nparadigms are needed, of computationally fast and accurate decision making in a\ndynamic and uncertain environment. We propose a novel physics-informed machine\nlearning framework for the decision of dynamic grid reconfiguration (PhML-DyR),\na key task in power systems. Dynamic reconfiguration (DyR) is a process by\nwhich switch-states are dynamically set so as to lead to an optimal grid\ntopology that minimizes line losses. To address the underlying computational\ncomplexities of NP-hardness due to the mixed nature of the decision variables,\nwe propose the use of physics-informed ML (PhML) which integrates both\noperating constraints and topological and connectivity constraints into a\nneural network framework. Our PhML approach learns to simultaneously optimize\ngrid topology and generator dispatch to meet loads, increase efficiency, and\nremain within safe operating limits. We demonstrate the effectiveness of\nPhML-DyR on a canonical grid, showing a reduction in electricity loss by 23%,\nand improved voltage profiles. We also show a reduction in constraint\nviolations by an order of magnitude as well as in training time using PhML-DyR.",
    "descriptor": "",
    "authors": [
      "Rabab Haider",
      "Anuradha M. Annaswamy"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06789"
  },
  {
    "id": "arXiv:2206.06793",
    "title": "How to Agree to Disagree: Managing Ontological Perspectives using  Standpoint Logic",
    "abstract": "The importance of taking individual, potentially conflicting perspectives\ninto account when dealing with knowledge has been widely recognised. Many\nexisting ontology management approaches fully merge knowledge perspectives,\nwhich may require weakening in order to maintain consistency; others represent\nthe distinct views in an entirely detached way.\nAs an alternative, we propose Standpoint Logic, a simple, yet versatile\nmulti-modal logic ``add-on'' for existing KR languages intended for the\nintegrated representation of domain knowledge relative to diverse, possibly\nconflicting standpoints, which can be hierarchically organised, combined and\nput in relation to each other.\nStarting from the generic framework of First-Order Standpoint Logic (FOSL),\nwe subsequently focus our attention on the fragment of sentential formulas, for\nwhich we provide a polytime translation into the standpoint-free version. This\nresult yields decidability and favourable complexities for a variety of highly\nexpressive decidable fragments of first-order logic. Using some elaborate\nencoding tricks, we then establish a similar translation for the very\nexpressive description logic SROIQb_s underlying the OWL 2 DL ontology\nlanguage. By virtue of this result, existing highly optimised OWL reasoners can\nbe used to provide practical reasoning support for ontology languages extended\nby standpoint modelling.",
    "descriptor": "",
    "authors": [
      "Luc\u00eda G\u00f3mez \u00c1lvarez",
      "Sebastian Rudolph",
      "Hannes Strass"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.06793"
  },
  {
    "id": "arXiv:2206.06796",
    "title": "Open-Ended Learning Strategies for Learning Complex Locomotion Skills",
    "abstract": "Teaching robots to learn diverse locomotion skills under complex\nthree-dimensional environmental settings via Reinforcement Learning (RL) is\nstill challenging. It has been shown that training agents in simple settings\nbefore moving them on to complex settings improves the training process, but so\nfar only in the context of relatively simple locomotion skills. In this work,\nwe adapt the Enhanced Paired Open-Ended Trailblazer (ePOET) approach to train\nmore complex agents to walk efficiently on complex three-dimensional terrains.\nFirst, to generate more rugged and diverse three-dimensional training terrains\nwith increasing complexity, we extend the Compositional Pattern Producing\nNetworks - Neuroevolution of Augmenting Topologies (CPPN-NEAT) approach and\ninclude randomized shapes. Second, we combine ePOET with Soft Actor-Critic\noff-policy optimization, yielding ePOET-SAC, to ensure that the agent could\nlearn more diverse skills to solve more challenging tasks. Our experimental\nresults show that the newly generated three-dimensional terrains have\nsufficient diversity and complexity to guide learning, that ePOET successfully\nlearns complex locomotion skills on these terrains, and that our proposed\nePOET-SAC approach slightly improves upon ePOET.",
    "descriptor": "",
    "authors": [
      "Fangqin Zhou",
      "Joaquin Vanschoren"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.06796"
  },
  {
    "id": "arXiv:2206.06800",
    "title": "Artificial Neural Network For Transient Stability Assessment: A Review",
    "abstract": "Integration of large-scale renewable energy sources and increasing\nuncertainty has drastically changed the dynamics of power system and has\nconsequently brought various challenges. Rapid transient stability assessment\nof modern power system is a vital requirement for accurate power system\nplanning and operation. The conventional methods are unable to fulfil this\nrequirement. Therefore, novel approaches are required in this regard. Machine\nleaning approaches such as artificial neural network can play a significant\nrole in this regard. Therefore, this paper aims to review the application of\nartificial neural network for transient stability assessment of power systems.\nIt is believed that this work will provide a solid foundation for researchers\nin the domain of machine learning applications to power system security and\nstability.",
    "descriptor": "",
    "authors": [
      "Umair Shahzad"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.06800"
  },
  {
    "id": "arXiv:2206.06801",
    "title": "Peripheral Vision Transformer",
    "abstract": "Human vision possesses a special type of visual processing systems called\nperipheral vision. Partitioning the entire visual field into multiple contour\nregions based on the distance to the center of our gaze, the peripheral vision\nprovides us the ability to perceive various visual features at different\nregions. In this work, we take a biologically inspired approach and explore to\nmodel peripheral vision in deep neural networks for visual recognition. We\npropose to incorporate peripheral position encoding to the multi-head\nself-attention layers to let the network learn to partition the visual field\ninto diverse peripheral regions given training data. We evaluate the proposed\nnetwork, dubbed PerViT, on the large-scale ImageNet dataset and systematically\ninvestigate the inner workings of the model for machine perception, showing\nthat the network learns to perceive visual data similarly to the way that human\nvision does. The state-of-the-art performance in image classification task\nacross various model sizes demonstrates the efficacy of the proposed method.",
    "descriptor": "\nComments: Technical report\n",
    "authors": [
      "Juhong Min",
      "Yucheng Zhao",
      "Chong Luo",
      "Minsu Cho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06801"
  },
  {
    "id": "arXiv:2206.06803",
    "title": "Asymmetric Dual-Decoder U-Net for Joint Rain and Haze Removal",
    "abstract": "This work studies the joint rain and haze removal problem. In real-life\nscenarios, rain and haze, two often co-occurring common weather phenomena, can\ngreatly degrade the clarity and quality of the scene images, leading to a\nperformance drop in the visual applications, such as autonomous driving.\nHowever, jointly removing the rain and haze in scene images is ill-posed and\nchallenging, where the existence of haze and rain and the change of atmosphere\nlight, can both degrade the scene information. Current methods focus on the\ncontamination removal part, thus ignoring the restoration of the scene\ninformation affected by the change of atmospheric light. We propose a novel\ndeep neural network, named Asymmetric Dual-decoder U-Net (ADU-Net), to address\nthe aforementioned challenge. The ADU-Net produces both the contamination\nresidual and the scene residual to efficiently remove the rain and haze while\npreserving the fidelity of the scene information. Extensive experiments show\nour work outperforms the existing state-of-the-art methods by a considerable\nmargin in both synthetic data and real-world data benchmarks, including\nRainCityscapes, BID Rain, and SPA-Data. For instance, we improve the\nstate-of-the-art PSNR value by 2.26/4.57 on the RainCityscapes/SPA-Data,\nrespectively.\nCodes will be made available freely to the research community.",
    "descriptor": "\nComments: 12 pages, 35 figures\n",
    "authors": [
      "Yuan Feng",
      "Yaojun Hu",
      "Pengfei Fang",
      "Yanhong Yang",
      "Sheng Liu",
      "Shengyong Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.06803"
  },
  {
    "id": "arXiv:2206.06804",
    "title": "Recommender Transformers with Behavior Pathways",
    "abstract": "Sequential recommendation requires the recommender to capture the evolving\nbehavior characteristics from logged user behavior data for accurate\nrecommendations. However, user behavior sequences are viewed as a script with\nmultiple ongoing threads intertwined. We find that only a small set of pivotal\nbehaviors can be evolved into the user's future action. As a result, the future\nbehavior of the user is hard to predict. We conclude this characteristic for\nsequential behaviors of each user as the Behavior Pathway. Different users have\ntheir unique behavior pathways. Among existing sequential models, transformers\nhave shown great capacity in capturing global-dependent characteristics.\nHowever, these models mainly provide a dense distribution over all previous\nbehaviors using the self-attention mechanism, making the final predictions\noverwhelmed by the trivial behaviors not adjusted to each user. In this paper,\nwe build the Recommender Transformer (RETR) with a novel Pathway Attention\nmechanism. RETR can dynamically plan the behavior pathway specified for each\nuser, and sparingly activate the network through this behavior pathway to\neffectively capture evolving patterns useful for recommendation. The key design\nis a learned binary route to prevent the behavior pathway from being\noverwhelmed by trivial behaviors. We empirically verify the effectiveness of\nRETR on seven real-world datasets and RETR yields state-of-the-art performance.",
    "descriptor": "",
    "authors": [
      "Zhiyu Yao",
      "Xinyang Chen",
      "Sinan Wang",
      "Qinyan Dai",
      "Yumeng Li",
      "Tanchao Zhu",
      "Mingsheng Long"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06804"
  },
  {
    "id": "arXiv:2206.06807",
    "title": "The Causal Structure of Semantic Ambiguities",
    "abstract": "Ambiguity is a natural language phenomenon occurring at different levels of\nsyntax, semantics, and pragmatics. It is widely studied; in Psycholinguistics,\nfor instance, we have a variety of competing studies for the human\ndisambiguation processes. These studies are empirical and based on eyetracking\nmeasurements. Here we take first steps towards formalizing these processes for\nsemantic ambiguities where we identified the presence of two features: (1)\njoint plausibility degrees of different possible interpretations, (2) causal\nstructures according to which certain words play a more substantial role in the\nprocesses. The novel sheaf-theoretic model of definite causality developed by\nGogioso and Pinzani in QPL 2021 offers tools to model and reason about these\nfeatures. We applied this theory to a dataset of ambiguous phrases extracted\nfrom Psycholinguistics literature and their human plausibility judgements\ncollected by us using the Amazon Mechanical Turk engine. We measured the causal\nfractions of different disambiguation orders within the phrases and discovered\ntwo prominent orders: from subject to verb in the subject-verb and from object\nto verb in the verb object phrases. We also found evidence for delay in the\ndisambiguation of polysemous vs homonymous verbs, again compatible with\nPsycholinguistic findings.",
    "descriptor": "",
    "authors": [
      "Daphne Wang",
      "Mehrnoosh Sadrzadeh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.06807"
  },
  {
    "id": "arXiv:2206.06810",
    "title": "Adversarially Robust Multi-Armed Bandit Algorithm with  Variance-Dependent Regret Bounds",
    "abstract": "This paper considers the multi-armed bandit (MAB) problem and provides a new\nbest-of-both-worlds (BOBW) algorithm that works nearly optimally in both\nstochastic and adversarial settings. In stochastic settings, some existing BOBW\nalgorithms achieve tight gap-dependent regret bounds of $O(\\sum_{i: \\Delta_i>0}\n\\frac{\\log T}{\\Delta_i})$ for suboptimality gap $\\Delta_i$ of arm $i$ and time\nhorizon $T$. As Audibert et al. [2007] have shown, however, that the\nperformance can be improved in stochastic environments with low-variance arms.\nIn fact, they have provided a stochastic MAB algorithm with\ngap-variance-dependent regret bounds of $O(\\sum_{i: \\Delta_i>0}\n(\\frac{\\sigma_i^2}{\\Delta_i} + 1) \\log T )$ for loss variance $\\sigma_i^2$ of\narm $i$. In this paper, we propose the first BOBW algorithm with\ngap-variance-dependent bounds, showing that the variance information can be\nused even in the possibly adversarial environment. Further, the leading\nconstant factor in our gap-variance dependent bound is only (almost) twice the\nvalue for the lower bound. Additionally, the proposed algorithm enjoys multiple\ndata-dependent regret bounds in adversarial settings and works well in\nstochastic settings with adversarial corruptions. The proposed algorithm is\nbased on the follow-the-regularized-leader method and employs adaptive learning\nrates that depend on the empirical prediction error of the loss, which leads to\ngap-variance-dependent regret bounds reflecting the variance of the arms.",
    "descriptor": "\nComments: Accepted for presentation at the 35th Annual Conference on Learning Theory (COLT 2022). Only the extended abstract will appear in the conference proceedings\n",
    "authors": [
      "Shinji Ito",
      "Taira Tsuchiya",
      "Junya Honda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06810"
  },
  {
    "id": "arXiv:2206.06814",
    "title": "Data security as a top priority in the digital world: preserve data  value by being proactive and thinking security first",
    "abstract": "Today, large amounts of data are being continuously produced, collected, and\nexchanged between systems. As the number of devices, systems and data produced\ngrows up, the risk of security breaches increases. This is all the more\nrelevant in times of COVID-19, which has affected not only the health and lives\nof human beings' but also the lifestyle of society, i.e., the digital\nenvironment has replaced the physical. This has led to an increase in cyber\nsecurity threats of various nature. While security breaches and different\nsecurity protection mechanisms have been widely covered in the literature, the\nconcept of a primitive artifact such as data management system seems to have\nbeen more neglected by researchers and practitioners. But are data management\nsystems always protected by default? Previous research and regular updates on\ndata leakages suggest that the number and nature of these vulnerabilities are\nhigh. It also refers to little or no DBMS protection, especially in case of\nNoSQL, which are thus vulnerable to attacks. The aim of this paper is to\nexamine whether traditional vulnerability registries provide a sufficiently\ncomprehensive view of DBMS security, or they should be intensively and\ndynamically inspected by DBMS owners by referring to Internet of Things Search\nEngines moving towards a sustainable and resilient digitized environment. The\npaper brings attention to this problem and makes the reader think about data\nsecurity before looking for and introducing more advanced security and\nprotection mechanisms, which, in the absence of the above, may bring no value.",
    "descriptor": "\nComments: This paper is expected to be published in Research and Innovation Forum 2022, edited by Anna Visvizi, Orlando Troisi, Mara Grimaldi, 2022, Springer Nature Switzerland AG (Gewerbestrasse 11, 6330 Cham, Switzerland) reproduced with permission of Springer Nature Switzerland AG. Once the final authenticated version will become available online, this version will be substituted by it\n",
    "authors": [
      "Anastasija Nikiforova"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Cryptography and Security (cs.CR)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2206.06814"
  },
  {
    "id": "arXiv:2206.06818",
    "title": "Disentangled Federated Learning for Tackling Attributes Skew via  Invariant Aggregation and Diversity Transferring",
    "abstract": "Attributes skew hinders the current federated learning (FL) frameworks from\nconsistent optimization directions among the clients, which inevitably leads to\nperformance reduction and unstable convergence. The core problems lie in that:\n1) Domain-specific attributes, which are non-causal and only locally valid, are\nindeliberately mixed into global aggregation. 2) The one-stage optimizations of\nentangled attributes cannot simultaneously satisfy two conflicting objectives,\ni.e., generalization and personalization. To cope with these, we proposed\ndisentangled federated learning (DFL) to disentangle the domain-specific and\ncross-invariant attributes into two complementary branches, which are trained\nby the proposed alternating local-global optimization independently.\nImportantly, convergence analysis proves that the FL system can be stably\nconverged even if incomplete client models participate in the global\naggregation, which greatly expands the application scope of FL. Extensive\nexperiments verify that DFL facilitates FL with higher performance, better\ninterpretability, and faster convergence rate, compared with SOTA FL methods on\nboth manually synthesized and realistic attributes skew datasets.",
    "descriptor": "",
    "authors": [
      "Zhengquan Luo",
      "Yunlong Wang",
      "Zilei Wang",
      "Zhenan Sun",
      "Tieniu Tan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.06818"
  },
  {
    "id": "arXiv:2206.06826",
    "title": "Tailored max-out networks for learning convex PWQ functions",
    "abstract": "Convex piecewise quadratic (PWQ) functions frequently appear in control and\nelsewhere. For instance, it is well-known that the optimal value function (OVF)\nas well as Q-functions for linear MPC are convex PWQ functions. Now, in\nlearning-based control, these functions are often represented with the help of\nartificial neural networks (NN). In this context, a recurring question is how\nto choose the topology of the NN in terms of depth, width, and activations in\norder to enable efficient learning. An elegant answer to that question could be\na topology that, in principle, allows to exactly describe the function to be\nlearned. Such solutions are already available for related problems. In fact,\nsuitable topologies are known for piecewise affine (PWA) functions that can,\nfor example, reflect the optimal control law in linear MPC. Following this\ndirection, we show in this paper that convex PWQ functions can be exactly\ndescribed by max-out-NN with only one hidden layer and two neurons.",
    "descriptor": "\nComments: 7 pages, 7 figures\n",
    "authors": [
      "Dieter Teichrib",
      "Moritz Schulze Darup"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06826"
  },
  {
    "id": "arXiv:2206.06827",
    "title": "Variance Reduction for Policy-Gradient Methods via Empirical Variance  Minimization",
    "abstract": "Policy-gradient methods in Reinforcement Learning(RL) are very universal and\nwidely applied in practice but their performance suffers from the high variance\nof the gradient estimate. Several procedures were proposed to reduce it\nincluding actor-critic(AC) and advantage actor-critic(A2C) methods. Recently\nthe approaches have got new perspective due to the introduction of Deep RL:\nboth new control variates(CV) and new sub-sampling procedures became available\nin the setting of complex models like neural networks. The vital part of\nCV-based methods is the goal functional for the training of the CV, the most\npopular one is the least-squares criterion of A2C. Despite its practical\nsuccess, the criterion is not the only one possible. In this paper we for the\nfirst time investigate the performance of the one called Empirical\nVariance(EV). We observe in the experiments that not only EV-criterion performs\nnot worse than A2C but sometimes can be considerably better. Apart from that,\nwe also prove some theoretical guarantees of the actual variance reduction\nunder very general assumptions and show that A2C least-squares goal functional\nis an upper bound for EV goal. Our experiments indicate that in terms of\nvariance reduction EV-based methods are much better than A2C and allow stronger\nvariance reduction.",
    "descriptor": "",
    "authors": [
      "Kaledin Maxim",
      "Golubev Alexander",
      "Belomestny Denis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06827"
  },
  {
    "id": "arXiv:2206.06829",
    "title": "Efficient Decoder-free Object Detection with Transformers",
    "abstract": "Vision transformers (ViTs) are changing the landscape of object detection\napproaches. A natural usage of ViTs in detection is to replace the CNN-based\nbackbone with a transformer-based backbone, which is straightforward and\neffective, with the price of bringing considerable computation burden for\ninference. More subtle usage is the DETR family, which eliminates the need for\nmany hand-designed components in object detection but introduces a decoder\ndemanding an extra-long time to converge. As a result, transformer-based object\ndetection can not prevail in large-scale applications. To overcome these\nissues, we propose a novel decoder-free fully transformer-based (DFFT) object\ndetector, achieving high efficiency in both training and inference stages, for\nthe first time. We simplify objection detection into an encoder-only\nsingle-level anchor-based dense prediction problem by centering around two\nentry points: 1) Eliminate the training-inefficient decoder and leverage two\nstrong encoders to preserve the accuracy of single-level feature map\nprediction; 2) Explore low-level semantic features for the detection task with\nlimited computational resources. In particular, we design a novel lightweight\ndetection-oriented transformer backbone that efficiently captures low-level\nfeatures with rich semantics based on a well-conceived ablation study.\nExtensive experiments on the MS COCO benchmark demonstrate that DFFT_SMALL\noutperforms DETR by 2.5% AP with 28% computation cost reduction and more than\n$10\\times$ fewer training epochs. Compared with the cutting-edge anchor-based\ndetector RetinaNet, DFFT_SMALL obtains over 5.5% AP gain while cutting down 70%\ncomputation cost.",
    "descriptor": "",
    "authors": [
      "Peixian Chen",
      "Mengdan Zhang",
      "Yunhang Shen",
      "Kekai Sheng",
      "Yuting Gao",
      "Xing Sun",
      "Ke Li",
      "Chunhua Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06829"
  },
  {
    "id": "arXiv:2206.06834",
    "title": "Distributed Coordination of Charging Stations Considering Aggregate EV  Power Flexibility",
    "abstract": "In recent years, electric vehicle (EV) charging stations have witnessed a\nrapid growth. However, effective management of charging stations is challenging\ndue to individual EV owners' privacy concerns, competing interests of different\nstations, and the coupling distribution network constraints. To cope with this\nchallenge, this paper proposes a two-stage scheme. In the first stage, the\naggregate EV power flexibility region is derived by solving an optimization\nproblem. We prove that any trajectory within the obtained region corresponds to\nat least one feasible EV dispatch strategy. By submitting this flexibility\nregion instead of the detailed EV data to the charging station operator, EV\nowners' privacy can be preserved and the computational burden can be reduced.\nIn the second stage, a distributed coordination mechanism with a clear physical\ninterpretation is developed with consideration of AC power flow constraints. We\nprove that the proposed mechanism is guaranteed to converge to the centralized\noptimum. Case studies validate the theoretical results. Comprehensive\nperformance comparisons are carried out to demonstrate the advantages of the\nproposed scheme.",
    "descriptor": "\nComments: 11 pages, 14 figures\n",
    "authors": [
      "Dongxiang Yan",
      "Chengbin Ma",
      "Yue Chen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.06834"
  },
  {
    "id": "arXiv:2206.06836",
    "title": "\"hasSignification()\": une nouvelle fonction de distance pour soutenir la  d\u00e9tection de donn\u00e9es personnelles",
    "abstract": "Today with Big Data and data lakes, we are faced of a mass of data that is\nvery difficult to manage it manually. The protection of personal data in this\ncontext requires an automatic analysis for data discovery. Storing the names of\nattributes already analyzed in a knowledge base could optimize this automatic\ndiscovery. To have a better knowledge base, we should not store any attributes\nwhose name does not make sense. In this article, to check if the name of an\nattribute has a meaning, we propose a solution that calculate the distances\nbetween this name and the words in a dictionary. Our studies on the distance\nfunctions like N-Gram, Jaro-Winkler and Levenshtein show limits to set an\nacceptance threshold for an attribute in the knowledge base. In order to\novercome these limitations, our solution aims to strengthen the score\ncalculation by using an exponential function based on the longest sequence. In\naddition, a double scan in dictionary is also proposed in order to process the\nattributes which have a compound name.",
    "descriptor": "\nComments: in French language\n",
    "authors": [
      "Amine Mrabet",
      "Ali Hassan",
      "Patrice Darmon"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2206.06836"
  },
  {
    "id": "arXiv:2206.06838",
    "title": "Architectural patterns for handling runtime uncertainty of data-driven  models in safety-critical perception",
    "abstract": "Data-driven models (DDM) based on machine learning and other AI techniques\nplay an important role in the perception of increasingly autonomous systems.\nDue to the merely implicit definition of their behavior mainly based on the\ndata used for training, DDM outputs are subject to uncertainty. This poses a\nchallenge with respect to the realization of safety-critical perception tasks\nby means of DDMs. A promising approach to tackling this challenge is to\nestimate the uncertainty in the current situation during operation and adapt\nthe system behavior accordingly. In previous work, we focused on runtime\nestimation of uncertainty and discussed approaches for handling uncertainty\nestimations. In this paper, we present additional architectural patterns for\nhandling uncertainty. Furthermore, we evaluate the four patterns qualitatively\nand quantitatively with respect to safety and performance gains. For the\nquantitative evaluation, we consider a distance controller for vehicle\nplatooning where performance gains are measured by considering how much the\ndistance can be reduced in different operational situations. We conclude that\nthe consideration of context information of the driving situation makes it\npossible to accept more or less uncertainty depending on the inherent risk of\nthe situation, which results in performance gains.",
    "descriptor": "",
    "authors": [
      "Janek Gro\u00df",
      "Rasmus Adler",
      "Michael Kl\u00e4s",
      "Jan Reich",
      "Lisa J\u00f6ckel",
      "Roman Gansch"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06838"
  },
  {
    "id": "arXiv:2206.06841",
    "title": "Robust Reinforcement Learning with Distributional Risk-averse  formulation",
    "abstract": "Robust Reinforcement Learning tries to make predictions more robust to\nchanges in the dynamics or rewards of the system. This problem is particularly\nimportant when the dynamics and rewards of the environment are estimated from\nthe data. In this paper, we approximate the Robust Reinforcement Learning\nconstrained with a $\\Phi$-divergence using an approximate Risk-Averse\nformulation. We show that the classical Reinforcement Learning formulation can\nbe robustified using standard deviation penalization of the objective. Two\nalgorithms based on Distributional Reinforcement Learning, one for discrete and\none for continuous action spaces are proposed and tested in a classical Gym\nenvironment to demonstrate the robustness of the algorithms.",
    "descriptor": "",
    "authors": [
      "Pierre Clavier",
      "St\u00e9phanie Allassoni\u00e8re",
      "Erwan Le Pennec"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.06841"
  },
  {
    "id": "arXiv:2206.06854",
    "title": "When adversarial attacks become interpretable counterfactual  explanations",
    "abstract": "We argue that, when learning a 1-Lipschitz neural network with the dual loss\nof an optimal transportation problem, the gradient of the model is both the\ndirection of the transportation plan and the direction to the closest\nadversarial attack. Traveling along the gradient to the decision boundary is no\nmore an adversarial attack but becomes a counterfactual explanation, explicitly\ntransporting from one class to the other. Through extensive experiments on XAI\nmetrics, we find that the simple saliency map method, applied on such networks,\nbecomes a reliable explanation, and outperforms the state-of-the-art\nexplanation approaches on unconstrained models. The proposed networks were\nalready known to be certifiably robust, and we prove that they are also\nexplainable with a fast and simple method.",
    "descriptor": "",
    "authors": [
      "Mathieu Serrurier",
      "Franck Mamalet",
      "Thomas Fel",
      "Louis B\u00e9thune",
      "Thibaut Boissin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.06854"
  },
  {
    "id": "arXiv:2206.06855",
    "title": "A new convergence proof for approximations of the Stefan problem",
    "abstract": "We consider the Stefan problem, firstly with regular data and secondly with\nirregular data. In both cases is given a proof for the convergence of an\napproximation obtained by regularising the problem. These proofs are based on\nweak formulations and on compactness results in some Sobolev spaces with\nnegative exponents.",
    "descriptor": "",
    "authors": [
      "Robert Eymard",
      "Thierry Gallou \u00cbt"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.06855"
  },
  {
    "id": "arXiv:2206.06868",
    "title": "Natural Language Sentence Generation from API Specifications",
    "abstract": "APIs are everywhere; they provide access to automation solutions that could\nhelp businesses automate some of their tasks. Unfortunately, they may not be\naccessible to the business users who need them but are not equipped with the\nnecessary technical skills to leverage them. Wrapping these APIs with chatbot\ncapabilities is one solution to make these automation solutions interactive. In\nthis work, we propose a system to generate sentences to train intent\nrecognition models, a crucial component within chatbots to understand natural\nlanguage utterances from users. Evaluation of our approach based on deep\nlearning models showed promising and inspiring results, and the\nhuman-in-the-loop interaction will provide further improvement on the system.",
    "descriptor": "",
    "authors": [
      "Siyu Huo",
      "Kushal Mukherjee",
      "Jayachandu Bandlamudi",
      "Vatche Isahagian",
      "Vinod Muthusamy",
      "Yara Rizk"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.06868"
  },
  {
    "id": "arXiv:2206.06872",
    "title": "On Provably Robust Meta-Bayesian Optimization",
    "abstract": "Bayesian optimization (BO) has become popular for sequential optimization of\nblack-box functions. When BO is used to optimize a target function, we often\nhave access to previous evaluations of potentially related functions. This begs\nthe question as to whether we can leverage these previous experiences to\naccelerate the current BO task through meta-learning (meta-BO), while ensuring\nrobustness against potentially harmful dissimilar tasks that could sabotage the\nconvergence of BO. This paper introduces two scalable and provably robust\nmeta-BO algorithms: robust meta-Gaussian process-upper confidence bound\n(RM-GP-UCB) and RM-GP-Thompson sampling (RM-GP-TS). We prove that both\nalgorithms are asymptotically no-regret even when some or all previous tasks\nare dissimilar to the current task, and show that RM-GP-UCB enjoys a better\ntheoretical robustness than RM-GP-TS. We also exploit the theoretical\nguarantees to optimize the weights assigned to individual previous tasks\nthrough regret minimization via online learning, which diminishes the impact of\ndissimilar tasks and hence further enhances the robustness. Empirical\nevaluations show that (a) RM-GP-UCB performs effectively and consistently\nacross various applications, and (b) RM-GP-TS, despite being less robust than\nRM-GP-UCB both in theory and in practice, performs competitively in some\nscenarios with less dissimilar tasks and is more computationally efficient.",
    "descriptor": "\nComments: Accepted to 38th Conference on Uncertainty in Artificial Intelligence (UAI 2022), Extended version with proofs and additional experimental details and results, 31 pages\n",
    "authors": [
      "Zhongxiang Dai",
      "Yizhou Chen",
      "Haibin Yu",
      "Bryan Kian Hsiang Low",
      "Patrick Jaillet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.06872"
  },
  {
    "id": "arXiv:2206.06873",
    "title": "A Data-Driven Simulation of the New York State Foster Care System",
    "abstract": "We introduce an analytic pipeline to model and simulate youth trajectories\nthrough the New York state foster care system. Our goal in doing so is to\nforecast how proposed interventions may impact the foster care system's ability\nto achieve it's stated goals \\emph{before these interventions are actually\nimplemented and impact the lives of thousands of youth}. Here, we focus on two\nspecific stated goals of the system: racial equity, and, as codified most\nrecently by the 2018 Family First Prevention Services Act (FFPSA), a focus on\nkeeping all youth out of foster care. We also focus on one specific potential\nintervention -- a predictive model, proposed in prior work and implemented\nelsewhere in the U.S., which aims to determine whether or not a youth is in\nneed of care. We use our method to explore how the implementation of this\npredictive model in New York would impact racial equity and the number of youth\nin care. While our findings, as in any simulation model, ultimately rely on\nmodeling assumptions, we find evidence that the model would not necessarily\nachieve either goal. Primarily, then, we aim to further promote the use of\ndata-driven simulation to help understand the ramifications of algorithmic\ninterventions in public systems.",
    "descriptor": "\nComments: 15 pages, 7 figure, ACM FAccT 2022\n",
    "authors": [
      "Yuhao Du",
      "Stefania Ionescu",
      "Melanie Sage",
      "Kenneth Joseph"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.06873"
  },
  {
    "id": "arXiv:2206.06874",
    "title": "Does Open Access Really Increase Impact? A Large-Scale Randomized  Analysis",
    "abstract": "The Open Access Citation Advantage (OACA) has been a major topic of\ndiscussion in the literature over the past twenty years. In this paper, we\npropose a method to constitute a control group to isolate the OACA effect.\nThus, we compared citation impact (MNCS) of 2,458,378 publications in fully OA\njournals to that (weighted MNCS) of a control group of non-OA publications\n(\\#10,310,842). Similarly, we did the same exercise for OA publications in\nhybrid journals (\\#1,024,430) and their control group (\\#11,533,001), over the\nperiod 2010-2020. The results showed that there is no OACA for publications in\nfully OA journals, and that there is rather a disadvantage. Conversely, the\nOACA seems to be a reality in hybrid journals, suggesting that a better\naccessibility in this context tends to improve the visibility of publications.\nThe lack of OACA for publications in fully OA journals is to be expected, as a\ngreat proportion of OA journals are newly created and less attractive to\nhigh-impact senior researchers.Another striking result of this paper is the\nfall of the OACA from 2016. The citation advantage fell from 70% to 9% between\n2016 and 2020 (for publications in hybrid journals). We wonder if this fall is\nlinked to the increase in the notoriety of pirate sites (eg Sci-Hub) from 2016.\nIn other words, the democratization of pirate sites instantly cancels the\npositive effect of OA publication insofar as the question of access to\nscientific content no longer arises.",
    "descriptor": "",
    "authors": [
      "Abdelghani Maddi",
      "David Sapinho"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Physics and Society (physics.soc-ph)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2206.06874"
  },
  {
    "id": "arXiv:2206.06878",
    "title": "Temporal Multimodal Multivariate Learning",
    "abstract": "We introduce temporal multimodal multivariate learning, a new family of\ndecision making models that can indirectly learn and transfer online\ninformation from simultaneous observations of a probability distribution with\nmore than one peak or more than one outcome variable from one time stage to\nanother. We approximate the posterior by sequentially removing additional\nuncertainties across different variables and time, based on data-physics driven\ncorrelation, to address a broader class of challenging time-dependent\ndecision-making problems under uncertainty. Extensive experiments on real-world\ndatasets ( i.e., urban traffic data and hurricane ensemble forecasting data)\ndemonstrate the superior performance of the proposed targeted decision-making\nover the state-of-the-art baseline prediction methods across various settings.",
    "descriptor": "\nComments: 11 pages, 12 figures, SIGKDD Conference on Knowledge Discovery and Data Mining,\n",
    "authors": [
      "Hyoshin Park",
      "Justice Darko",
      "Niharika Deshpande",
      "Venktesh Pandey",
      "Hui Su",
      "Masahiro Ono",
      "Dedrick Barkely",
      "Larkin Folsom",
      "Derek Posselt",
      "Steve Chien"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.06878"
  },
  {
    "id": "arXiv:2206.06879",
    "title": "Creating a Secure Underlay for the Internet",
    "abstract": "Adversaries can exploit inter-domain routing vulnerabilities to intercept\ncommunication and compromise the security of critical Internet applications.\nMeanwhile the deployment of secure routing solutions such as Border Gateway\nProtocol Security (BGPsec) and Scalability, Control and Isolation On\nNext-generation networks (SCION) are still limited. How can we leverage\nemerging secure routing backbones and extend their security properties to the\nbroader Internet?\nWe design and deploy an architecture to bootstrap secure routing. Our key\ninsight is to abstract the secure routing backbone as a virtual Autonomous\nSystem (AS), called Secure Backbone AS (SBAS). While SBAS appears as one AS to\nthe Internet, it is a federated network where routes are exchanged between\nparticipants using a secure backbone. SBAS makes BGP announcements for its\ncustomers' IP prefixes at multiple locations (referred to as Points of Presence\nor PoPs) allowing traffic from non-participating hosts to be routed to a nearby\nSBAS PoP (where it is then routed over the secure backbone to the true prefix\nowner). In this manner, we are the first to integrate a federated secure\nnon-BGP routing backbone with the BGP-speaking Internet.\nWe present a real-world deployment of our architecture that uses SCIONLab to\nemulate the secure backbone and the PEERING framework to make BGP announcements\nto the Internet. A combination of real-world attacks and Internet-scale\nsimulations shows that SBAS substantially reduces the threat of routing\nattacks. Finally, we survey network operators to better understand optimal\ngovernance and incentive models.",
    "descriptor": "\nComments: Usenix Security 2022\n",
    "authors": [
      "Henry Birge-Lee",
      "Joel Wanner",
      "Grace Cimaszewski",
      "Jonghoon Kwon",
      "Liang Wang",
      "Francois Wirz",
      "Prateek Mittal",
      "Adrian Perrig",
      "Yixin Sun"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.06879"
  },
  {
    "id": "arXiv:2206.06882",
    "title": "An Accurate HDDL Domain Learning Algorithm from Partial and Noisy  Observations",
    "abstract": "The Hierarchical Task Network ({\\sf HTN}) formalism is very expressive and\nused to express a wide variety of planning problems. In contrast to the\nclassical {\\sf STRIPS} formalism in which only the action model needs to be\nspecified, the {\\sf HTN} formalism requires to specify, in addition, the tasks\nof the problem and their decomposition into subtasks, called {\\sf HTN} methods.\nFor this reason, hand-encoding {\\sf HTN} problems is considered more difficult\nand more error-prone by experts than classical planning problem. To tackle this\nproblem, we propose a new approach (HierAMLSI) based on grammar induction to\nacquire {\\sf HTN} planning domain knowledge, by learning action models and {\\sf\nHTN} methods with their preconditions. Unlike other approaches, HierAMLSI is\nable to learn both actions and methods with noisy and partial inputs\nobservation with a high level or accuracy.",
    "descriptor": "",
    "authors": [
      "M. Grand",
      "H. Fiorino",
      "D. Pellier"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.06882"
  },
  {
    "id": "arXiv:2206.06888",
    "title": "CERT: Continual Pre-Training on Sketches for Library-Oriented Code  Generation",
    "abstract": "Code generation is a longstanding challenge, aiming to generate a code\nsnippet based on a natural language description. Usually, expensive text-code\npaired data is essential for training a code generation model. Recently, thanks\nto the success of pre-training techniques, large language models are trained on\nlarge-scale unlabelled code corpora and perform well in code generation. In\nthis paper, we investigate how to leverage an unlabelled code corpus to train a\nmodel for library-oriented code generation. Since it is a common practice for\nprogrammers to reuse third-party libraries, in which case the text-code paired\ndata are harder to obtain due to the huge number of libraries. We observe that\nlibrary-oriented code snippets are more likely to share similar code sketches.\nHence, we present CERT with two steps: a sketcher generates the sketch, then a\ngenerator fills the details in the sketch. Both the sketcher and the generator\nare continually pre-trained upon a base model using unlabelled data.\nFurthermore, we craft two benchmarks named PandasEval and NumpyEval to evaluate\nlibrary-oriented code generation. Experimental results demonstrate the\nimpressive performance of CERT. For example, it surpasses the base model by an\nabsolute 15.67% improvement in terms of pass@1 on PandasEval. Our work is\navailable at https://github.com/microsoft/PyCodeGPT.",
    "descriptor": "\nComments: Accepted for publication at IJCAI-ECAI 2022\n",
    "authors": [
      "Daoguang Zan",
      "Bei Chen",
      "Dejian Yang",
      "Zeqi Lin",
      "Minsu Kim",
      "Bei Guan",
      "Yongji Wang",
      "Weizhu Chen",
      "Jian-Guang Lou"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2206.06888"
  },
  {
    "id": "arXiv:2206.06890",
    "title": "RDU: A Region-based Approach to Form-style Document Understanding",
    "abstract": "Key Information Extraction (KIE) is aimed at extracting structured\ninformation (e.g. key-value pairs) from form-style documents (e.g. invoices),\nwhich makes an important step towards intelligent document understanding.\nPrevious approaches generally tackle KIE by sequence tagging, which faces\ndifficulty to process non-flatten sequences, especially for table-text mixed\ndocuments. These approaches also suffer from the trouble of pre-defining a\nfixed set of labels for each type of documents, as well as the label imbalance\nissue. In this work, we assume Optical Character Recognition (OCR) has been\napplied to input documents, and reformulate the KIE task as a region prediction\nproblem in the two-dimensional (2D) space given a target field. Following this\nnew setup, we develop a new KIE model named Region-based Document Understanding\n(RDU) that takes as input the text content and corresponding coordinates of a\ndocument, and tries to predict the result by localizing a bounding-box-like\nregion. Our RDU first applies a layout-aware BERT equipped with a soft layout\nattention masking and bias mechanism to incorporate layout information into the\nrepresentations. Then, a list of candidate regions is generated from the\nrepresentations via a Region Proposal Module inspired by computer vision models\nwidely applied for object detection. Finally, a Region Categorization Module\nand a Region Selection Module are adopted to judge whether a proposed region is\nvalid and select the one with the largest probability from all proposed regions\nrespectively. Experiments on four types of form-style documents show that our\nproposed method can achieve impressive results. In addition, our RDU model can\nbe trained with different document types seamlessly, which is especially\nhelpful over low-resource documents.",
    "descriptor": "\nComments: Work in process\n",
    "authors": [
      "Fengbin Zhu",
      "Chao Wang",
      "Wenqiang Lei",
      "Ziyang Liu",
      "Tat Seng Chua"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.06890"
  },
  {
    "id": "arXiv:2206.06897",
    "title": "On the Message Passing Efficiency of Polar and Low-Density Parity-Check  Decoders",
    "abstract": "This study focuses on the efficiency of message-passing-based decoding\nalgorithms for polar and low-density parity-check (LDPC) codes. Both successive\ncancellation (SC) and belief propagation (BP) decoding algorithms are studied\nunder the message-passing framework. Counter-intuitively, SC decoding\ndemonstrates the highest decoding efficiency, although it was considered a weak\ndecoder regarding error-correction performance. We analyze the\ncomplexity-performance tradeoff to dynamically track the decoding efficiency,\nwhere the complexity is measured by the number of messages passed (NMP), and\nthe performance is measured by the statistical distance to the maximum a\nposteriori (MAP) estimate. This study offers new insight into the contribution\nof each message passing in decoding, and compares various decoding algorithms\non a message-by-message level. The analysis corroborates recent results on\nterabits-per-second polar SC decoders, and might shed light on better\nscheduling strategies.",
    "descriptor": "",
    "authors": [
      "Dawei Yin",
      "Yuan Li",
      "Xianbin Wang",
      "Jiajie Tong",
      "Huazi Zhang",
      "Jun Wang",
      "Guanghui Wang",
      "Guiying Yan",
      "Zhiming Ma"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.06897"
  },
  {
    "id": "arXiv:2206.06900",
    "title": "Grad-GradaGrad? A Non-Monotone Adaptive Stochastic Gradient Method",
    "abstract": "The classical AdaGrad method adapts the learning rate by dividing by the\nsquare root of a sum of squared gradients. Because this sum on the denominator\nis increasing, the method can only decrease step sizes over time, and requires\na learning rate scaling hyper-parameter to be carefully tuned. To overcome this\nrestriction, we introduce GradaGrad, a method in the same family that naturally\ngrows or shrinks the learning rate based on a different accumulation in the\ndenominator, one that can both increase and decrease. We show that it obeys a\nsimilar convergence rate as AdaGrad and demonstrate its non-monotone adaptation\ncapability with experiments.",
    "descriptor": "",
    "authors": [
      "Aaron Defazio",
      "Baoyu Zhou",
      "Lin Xiao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.06900"
  },
  {
    "id": "arXiv:2206.06901",
    "title": "Conservative Hamiltonian Monte Carlo",
    "abstract": "We introduce a new class of Hamiltonian Monte Carlo (HMC) algorithm called\nConservative Hamiltonian Monte Carlo (CHMC), where energy-preserving\nintegrators, derived from the Discrete Multiplier Method, are used instead of\nsymplectic integrators. Due to the volume being no longer preserved under such\na proposal map, a correction involving the determinant of the Jacobian of the\nproposal map is introduced within the acceptance probability of HMC. For a\n$p$-th order accurate energy-preserving integrator using a time step size\n$\\tau$, we show that CHMC satisfies stationarity without detailed balance.\nMoreover, we show that CHMC satisfies approximate stationarity with an error of\n$\\mathcal{O}(\\tau^{(m+1)p})$ if the determinant of the Jacobian is truncated to\nits first $m+1$ terms of its Taylor polynomial in $\\tau^p$. We also establish a\nlower bound on the acceptance probability of CHMC which depends only on the\ndesired tolerance $\\delta$ for the energy error and approximate determinant. In\nparticular, a cost-effective and gradient-free version of CHMC is obtained by\napproximating the determinant of the Jacobian as unity, leading to an\n$\\mathcal{O}(\\tau^p)$ error to the stationary distribution and a lower bound on\nthe acceptance probability depending only on $\\delta$. Furthermore, numerical\nexperiments show increased performance in acceptance probability and\nconvergence to the stationary distribution for the Gradient-free CHMC over HMC\nin high dimensional problems.",
    "descriptor": "\nComments: 24 pages, 18 figures\n",
    "authors": [
      "Geoffrey McGregor",
      "Andy T.S. Wan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computation (stat.CO)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2206.06901"
  },
  {
    "id": "arXiv:2206.06903",
    "title": "A Local Optima Network Analysis of the Feedforward Neural Architecture  Space",
    "abstract": "This study investigates the use of local optima network (LON) analysis, a\nderivative of the fitness landscape of candidate solutions, to characterise and\nvisualise the neural architecture space. The search space of feedforward neural\nnetwork architectures with up to three layers, each with up to 10 neurons, is\nfully enumerated by evaluating trained model performance on a selection of data\nsets. Extracted LONs, while heterogeneous across data sets, all exhibit simple\nglobal structures, with single global funnels in all cases but one. These\nresults yield early indication that LONs may provide a viable paradigm by which\nto analyse and optimise neural architectures.",
    "descriptor": "\nComments: A version of this paper has been accepted for publication at IJCNN'22\n",
    "authors": [
      "Isak Potgieter",
      "Christopher W. Cleghorn",
      "Anna S. Bosman"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06903"
  },
  {
    "id": "arXiv:2206.06908",
    "title": "LPCSE: Neural Speech Enhancement through Linear Predictive Coding",
    "abstract": "The increasingly stringent requirement on quality-of-experience in 5G/B5G\ncommunication systems has led to the emerging neural speech enhancement\ntechniques, which however have been developed in isolation from the existing\nexpert-rule based models of speech pronunciation and distortion, such as the\nclassic Linear Predictive Coding (LPC) speech model because it is difficult to\nintegrate the models with auto-differentiable machine learning frameworks. In\nthis paper, to improve the efficiency of neural speech enhancement, we\nintroduce an LPC-based speech enhancement (LPCSE) architecture, which leverages\nthe strong inductive biases in the LPC speech model in conjunction with the\nexpressive power of neural networks. Differentiable end-to-end learning is\nachieved in LPCSE via two novel blocks: a block that utilizes the expert rules\nto reduce the computational overhead when integrating the LPC speech model into\nneural networks, and a block that ensures the stability of the model and avoids\nexploding gradients in end-to-end training by mapping the Linear prediction\ncoefficients to the filter poles. The experimental results show that LPCSE\nsuccessfully restores the formants of the speeches distorted by transmission\nloss, and outperforms two existing neural speech enhancement methods of\ncomparable neural network sizes in terms of the Perceptual evaluation of speech\nquality (PESQ) and Short-Time Objective Intelligibility (STOI) on the LJ Speech\ncorpus.",
    "descriptor": "",
    "authors": [
      "Yang Liu",
      "Na Tang",
      "Xiaoli Chu",
      "Yang Yang",
      "Jun Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.06908"
  },
  {
    "id": "arXiv:2206.06909",
    "title": "Krylov subspace residual and restarting for certain second order  differential equations",
    "abstract": "We propose algorithms for efficient time integration of large systems of\noscillatory second order ordinary differential equations (ODEs) whose solution\ncan be expressed in terms of trigonometric matrix functions. Our algorithms are\nbased on a residual notion for second order ODEs, which allows to extend the\n``residual-time restarting'' Krylov subspace framework -- which was recently\nintroduced for exponential and $\\varphi$-functions occurring in time\nintegration of first order ODEs -- to our setting. We then show that the\ncomputational cost can be further reduced in many cases by using our restarting\nin the Gautschi cosine scheme. We analyze residual convergence in terms of\nFaber and Chebyshev series and supplement these theoretical results by\nnumerical experiments illustrating the efficiency of the proposed methods.",
    "descriptor": "",
    "authors": [
      "M.A. Botchev",
      "L.A. Knizhnerman",
      "M. Schweitzer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.06909"
  },
  {
    "id": "arXiv:2206.06918",
    "title": "varFEM: variational formulation based programming for finite element  methods in Matlab",
    "abstract": "This paper summarizes the development of varFEM, which provides a realization\nof the programming style in FreeFEM by using the Matlab language.",
    "descriptor": "\nComments: FreeFEM\n",
    "authors": [
      "Yue Yu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.06918"
  },
  {
    "id": "arXiv:2206.06920",
    "title": "Manifold Alignment-Based Multi-Fidelity Reduced-Order Modeling Applied  to Structural Analysis",
    "abstract": "This work presents the application of a recently developed parametric,\nnon-intrusive, and multi-fidelity reduced-order modeling method on\nhigh-dimensional displacement and stress fields arising from the structural\nanalysis of geometries that differ in the size of discretization and structural\ntopology.The proposed approach leverages manifold alignment to fuse\ninconsistent field outputs from high- and low-fidelity simulations by\nindividually projecting their solution onto a common subspace. The\neffectiveness of the method is demonstrated on two multi-fidelity scenarios\ninvolving the structural analysis of a benchmark wing geometry. Results show\nthat outputs from structural simulations using incompatible grids, or related\nyet different topologies, are easily combined into a single predictive model,\nthus eliminating the need for additional pre-processing of the data. The new\nmulti-fidelity reduced-order model achieves a relatively higher predictive\naccuracy at a lower computational cost when compared to a single-fidelity\nmodel.",
    "descriptor": "\nComments: The peer-reviewed and corrected version of this article has been accepted for publication in the Structural and Multidisciplinary Optimization Journal\n",
    "authors": [
      "Christian Perron",
      "Darshan Sarojini",
      "Dushhyanth Rajaram",
      "Jason Corman",
      "Dimitri Mavris"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06920"
  },
  {
    "id": "arXiv:2206.06922",
    "title": "Object Scene Representation Transformer",
    "abstract": "A compositional understanding of the world in terms of objects and their\ngeometry in 3D space is considered a cornerstone of human cognition.\nFacilitating the learning of such a representation in neural networks holds\npromise for substantially improving labeled data efficiency. As a key step in\nthis direction, we make progress on the problem of learning 3D-consistent\ndecompositions of complex scenes into individual objects in an unsupervised\nfashion. We introduce Object Scene Representation Transformer (OSRT), a\n3D-centric model in which individual object representations naturally emerge\nthrough novel view synthesis. OSRT scales to significantly more complex scenes\nwith larger diversity of objects and backgrounds than existing methods. At the\nsame time, it is multiple orders of magnitude faster at compositional rendering\nthanks to its light field parametrization and the novel Slot Mixer decoder. We\nbelieve this work will not only accelerate future architecture exploration and\nscaling efforts, but it will also serve as a useful tool for both\nobject-centric as well as neural scene representation learning communities.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Mehdi S. M. Sajjadi",
      "Daniel Duckworth",
      "Aravindh Mahendran",
      "Sjoerd van Steenkiste",
      "Filip Paveti\u0107",
      "Mario Lu\u010di\u0107",
      "Leonidas J. Guibas",
      "Klaus Greff",
      "Thomas Kipf"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06922"
  },
  {
    "id": "arXiv:2206.06923",
    "title": "A Multi-task Framework for Infrared Small Target Detection and  Segmentation",
    "abstract": "Due to the complicated background and noise of infrared images, infrared\nsmall target detection is one of the most difficult problems in the field of\ncomputer vision. In most existing studies, semantic segmentation methods are\ntypically used to achieve better results. The centroid of each target is\ncalculated from the segmentation map as the detection result. In contrast, we\npropose a novel end-to-end framework for infrared small target detection and\nsegmentation in this paper. First, with the use of UNet as the backbone to\nmaintain resolution and semantic information, our model can achieve a higher\ndetection accuracy than other state-of-the-art methods by attaching a simple\nanchor-free head. Then, a pyramid pool module is used to further extract\nfeatures and improve the precision of target segmentation. Next, we use\nsemantic segmentation tasks that pay more attention to pixel-level features to\nassist in the training process of object detection, which increases the average\nprecision and allows the model to detect some targets that were previously not\ndetectable. Furthermore, we develop a multi-task framework for infrared small\ntarget detection and segmentation. Our multi-task learning model reduces\ncomplexity by nearly half and speeds up inference by nearly twice compared to\nthe composite single-task model, while maintaining accuracy. The code and\nmodels are publicly available at https://github.com/Chenastron/MTUNet.",
    "descriptor": "",
    "authors": [
      "Yuhang Chen",
      "Liyuan Li",
      "Xin Liu",
      "Xiaofeng Su",
      "Fansheng Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06923"
  },
  {
    "id": "arXiv:2206.06924",
    "title": "The Maximum Linear Arrangement for trees under projectivity and  planarity",
    "abstract": "The Maximum Linear Arrangement problem (MaxLA) consists of finding a mapping\n$\\pi$ from the $n$ vertices of a graph $G$ to distinct consecutive integers\nthat maximizes $D_{\\pi}(G)=\\sum_{uv\\in E(G)}|\\pi(u) - \\pi(v)|$. In this\nsetting, vertices are considered to lie on a horizontal line and edges are\ndrawn as semicircles above the line. There exist variants of MaxLA in which the\narrangements are constrained. In the planar variant edge crossings are\nforbidden. In the projective variant for rooted trees arrangements are planar\nand the root cannot be covered by any edge. Here we present $O(n)$-time and\n$O(n)$-space algorithms that solve Planar and Projective MaxLA for trees. We\nalso prove several properties of maximum projective and planar arrangements.",
    "descriptor": "",
    "authors": [
      "Llu\u00eds Alemany-Puig",
      "Juan Luis Esteban",
      "Ramon Ferrer-i-Cancho"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computation and Language (cs.CL)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2206.06924"
  },
  {
    "id": "arXiv:2206.06925",
    "title": "Towards a secured smart IoT using light weight blockchain: An aim to  secure Pharmacy Products",
    "abstract": "Blockchain has proven a very developed and secured technology. It ensures\ndata integrity with authentic connected nodes. Now-a-days, blockchain with IoT\nis a great combination for secured and smart end to end product delivery. This\nobservation has motivated the research to develop a conceptual model to provide\na secure pharmaceutical product delivery by developing a IoT integrated with\nlightweight blockchain. The undeveloped and most of the developing countries\nare facing problems such as drug counterfeits, shortages, opiates and tracking\nthem became difficult because of less transparency. Also, nature sensitive\nmedicines need to be stored under controlled temperature known as cold-chain\nshipping. The storage of these information in the recent software is done in\nthe centralized databases that is prone to data manipulations and hacks. Due to\nless production drugs needed to be imported with maintaining drug supply chain\nregulations by law. This paper proposes a lightweight blockchain model for\npharmaceutical industries by using IoT. This model ensures traceability of\ndrugs within a very simple way which is less complex compared to the existing\nones.",
    "descriptor": "\nComments: 9 pages 3 figures\n",
    "authors": [
      "Md. Faruk Abdullah Al Sohan",
      "Samiur Rahman Khan",
      "Nusrat Jahan Anannya",
      "Md Taimur Ahad"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.06925"
  },
  {
    "id": "arXiv:2206.06929",
    "title": "Scaling ResNets in the Large-depth Regime",
    "abstract": "Deep ResNets are recognized for achieving state-of-the-art results in complex\nmachine learning tasks. However, the remarkable performance of these\narchitectures relies on a training procedure that needs to be carefully crafted\nto avoid vanishing or exploding gradients, particularly as the depth $L$\nincreases. No consensus has been reached on how to mitigate this issue,\nalthough a widely discussed strategy consists in scaling the output of each\nlayer by a factor $\\alpha_L$. We show in a probabilistic setting that with\nstandard i.i.d. initializations, the only non-trivial dynamics is for $\\alpha_L\n= 1/\\sqrt{L}$ (other choices lead either to explosion or to identity mapping).\nThis scaling factor corresponds in the continuous-time limit to a neural\nstochastic differential equation, contrarily to a widespread interpretation\nthat deep ResNets are discretizations of neural ordinary differential\nequations. By contrast, in the latter regime, stability is obtained with\nspecific correlated initializations and $\\alpha_L = 1/L$. Our analysis suggests\na strong interplay between scaling and regularity of the weights as a function\nof the layer index. Finally, in a series of experiments, we exhibit a\ncontinuous range of regimes driven by these two parameters, which jointly\nimpact performance before and after training.",
    "descriptor": "\nComments: 43 pages, 9 figures\n",
    "authors": [
      "Pierre Marion",
      "Adeline Fermanian",
      "G\u00e9rard Biau",
      "Jean-Philippe Vert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.06929"
  },
  {
    "id": "arXiv:2206.06930",
    "title": "Comprehending and Ordering Semantics for Image Captioning",
    "abstract": "Comprehending the rich semantics in an image and ordering them in linguistic\norder are essential to compose a visually-grounded and linguistically coherent\ndescription for image captioning. Modern techniques commonly capitalize on a\npre-trained object detector/classifier to mine the semantics in an image, while\nleaving the inherent linguistic ordering of semantics under-exploited. In this\npaper, we propose a new recipe of Transformer-style structure, namely\nComprehending and Ordering Semantics Networks (COS-Net), that novelly unifies\nan enriched semantic comprehending and a learnable semantic ordering processes\ninto a single architecture. Technically, we initially utilize a cross-modal\nretrieval model to search the relevant sentences of each image, and all words\nin the searched sentences are taken as primary semantic cues. Next, a novel\nsemantic comprehender is devised to filter out the irrelevant semantic words in\nprimary semantic cues, and meanwhile infer the missing relevant semantic words\nvisually grounded in the image. After that, we feed all the screened and\nenriched semantic words into a semantic ranker, which learns to allocate all\nsemantic words in linguistic order as humans. Such sequence of ordered semantic\nwords are further integrated with visual tokens of images to trigger sentence\ngeneration. Empirical evidences show that COS-Net clearly surpasses the\nstate-of-the-art approaches on COCO and achieves to-date the best CIDEr score\nof 141.1% on Karpathy test split. Source code is available at\n\\url{https://github.com/YehLi/xmodaler/tree/master/configs/image_caption/cosnet}.",
    "descriptor": "\nComments: CVPR 2022; Code is publicly available at: this https URL\n",
    "authors": [
      "Yehao Li",
      "Yingwei Pan",
      "Ting Yao",
      "Tao Mei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2206.06930"
  },
  {
    "id": "arXiv:2206.06931",
    "title": "Stand-Alone Inter-Frame Attention in Video Models",
    "abstract": "Motion, as the uniqueness of a video, has been critical to the development of\nvideo understanding models. Modern deep learning models leverage motion by\neither executing spatio-temporal 3D convolutions, factorizing 3D convolutions\ninto spatial and temporal convolutions separately, or computing self-attention\nalong temporal dimension. The implicit assumption behind such successes is that\nthe feature maps across consecutive frames can be nicely aggregated.\nNevertheless, the assumption may not always hold especially for the regions\nwith large deformation. In this paper, we present a new recipe of inter-frame\nattention block, namely Stand-alone Inter-Frame Attention (SIFA), that novelly\ndelves into the deformation across frames to estimate local self-attention on\neach spatial location. Technically, SIFA remoulds the deformable design via\nre-scaling the offset predictions by the difference between two frames. Taking\neach spatial location in the current frame as the query, the locally deformable\nneighbors in the next frame are regarded as the keys/values. Then, SIFA\nmeasures the similarity between query and keys as stand-alone attention to\nweighted average the values for temporal aggregation. We further plug SIFA\nblock into ConvNets and Vision Transformer, respectively, to devise SIFA-Net\nand SIFA-Transformer. Extensive experiments conducted on four video datasets\ndemonstrate the superiority of SIFA-Net and SIFA-Transformer as stronger\nbackbones. More remarkably, SIFA-Transformer achieves an accuracy of 83.1% on\nKinetics-400 dataset. Source code is available at\n\\url{https://github.com/FuchenUSTC/SIFA}.",
    "descriptor": "\nComments: CVPR 2022; Code is publicly available at: this https URL\n",
    "authors": [
      "Fuchen Long",
      "Zhaofan Qiu",
      "Yingwei Pan",
      "Ting Yao",
      "Jiebo Luo",
      "Tao Mei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2206.06931"
  },
  {
    "id": "arXiv:2206.06934",
    "title": "A Layered Reference Model for Penetration Testing with Reinforcement  Learning and Attack Graphs",
    "abstract": "This paper considers key challenges to using reinforcement learning (RL) with\nattack graphs to automate penetration testing in real-world applications from a\nsystems perspective. RL approaches to automated penetration testing are\nactively being developed, but there is no consensus view on the representation\nof computer networks with which RL should be interacting. Moreover, there are\nsignificant open challenges to how those representations can be grounded to the\nreal networks where RL solution methods are applied. This paper elaborates on\nrepresentation and grounding using topic challenges of interacting with real\nnetworks in real-time, emulating realistic adversary behavior, and handling\nunstable, evolving networks. These challenges are both practical and\nmathematical, and they directly concern the reliability and dependability of\npenetration testing systems. This paper proposes a layered reference model to\nhelp organize related research and engineering efforts. The presented layered\nreference model contrasts traditional models of attack graph workflows because\nit is not scoped to a sequential, feed-forward generation and analysis process,\nbut to broader aspects of lifecycle and continuous deployment. Researchers and\npractitioners can use the presented layered reference model as a\nfirst-principles outline to help orient the systems engineering of their\npenetration testing systems.",
    "descriptor": "",
    "authors": [
      "Tyler Cody"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.06934"
  },
  {
    "id": "arXiv:2206.06935",
    "title": "OSN Dashboard Tool For Sentiment Analysis",
    "abstract": "The amount of opinionated data on the internet is rapidly increasing. More\nand more people are sharing their ideas and opinions in reviews, discussion\nforums, microblogs and general social media. As opinions are central in all\nhuman activities, sentiment analysis has been applied to gain insights in this\ntype of data. There are proposed several approaches for sentiment\nclassification. The major drawback is the lack of standardized solutions for\nclassification and high-level visualization. In this study, a sentiment\nanalyzer dashboard for online social networking analysis is proposed. This, to\nenable people gaining insights in topics interesting to them. The tool allows\nusers to run the desired sentiment analysis algorithm in the dashboard. In\naddition to providing several visualization types, the dashboard facilitates\nraw data results from the sentiment classification which can be downloaded for\nfurther analysis.",
    "descriptor": "\nComments: Keywords Sentiment Analysis Machine Learning Twitter Opinion Mining Polarity Assessment\n",
    "authors": [
      "Andreas Kilde Lien",
      "Lars Martin Randem",
      "Hans Petter Fauchald Taralrud",
      "Maryam Edalati"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.06935"
  },
  {
    "id": "arXiv:2206.06936",
    "title": "Worst-case Design for RIS-aided Over-the-air Computation with Imperfect  CSI",
    "abstract": "Over-the-air computation (AirComp) enables fast wireless data aggregation at\nthe receiver through concurrent transmission by sensors in the application of\nInternet-of-Things (IoT). To further improve the performance of AirComp under\nunfavorable propagation channel conditions, we consider the problem of\ncomputation distortion minimization in a reconfigurable intelligent surface\n(RIS)-aided AirComp system. In particular, we take into account an additive\nbounded uncertainty of the channel state information (CSI) and the total power\nconstraint, and jointly optimize the transceiver (Tx-Rx) and the RIS phase\ndesign from the perspective of worst-case robustness by minimizing the mean\nsquared error (MSE) of the computation. To solve this intractable nonconvex\nproblem, we develop an efficient alternating algorithm where both solutions to\nthe robust sub-problem and to the joint design of Tx-Rx and RIS are obtained in\nclosed forms. Simulation results demonstrate the effectiveness of the proposed\nmethod.",
    "descriptor": "",
    "authors": [
      "Wenhui Zhang",
      "Jindan Xu",
      "Wei Xu",
      "Xiaohu You",
      "Weijie Fu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.06936"
  },
  {
    "id": "arXiv:2206.06938",
    "title": "Cloud Property Graph: Connecting Cloud Security Assessments with Static  Code Analysis",
    "abstract": "In this paper, we present the Cloud Property Graph (CloudPG), which bridges\nthe gap between static code analysis and runtime security assessment of cloud\nservices. The CloudPG is able to resolve data flows between cloud applications\ndeployed on different resources, and contextualizes the graph with runtime\ninformation, such as encryption settings. To provide a vendor- and\ntechnology-independent representation of a cloud service's security posture,\nthe graph is based on an ontology of cloud resources, their functionalities and\nsecurity features. We show, using an example, that our CloudPG framework can be\nused by security experts to identify weaknesses in their cloud deployments,\nspanning multiple vendors or technologies, such as AWS, Azure and Kubernetes.\nThis includes misconfigurations, such as publicly accessible storages or\nundesired data flows within a cloud service, as restricted by regulations such\nas GDPR.",
    "descriptor": "",
    "authors": [
      "Christian Banse",
      "Immanuel Kunz",
      "Angelika Schneider",
      "Konrad Weiss"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.06938"
  },
  {
    "id": "arXiv:2206.06940",
    "title": "Generating Exact Optimal Designs via Particle Swarm Optimization:  Assessing Efficacy and Efficiency via Case Study",
    "abstract": "In this study we address existing deficiencies in the literature on\napplications of Particle Swarm Optimization to generate optimal designs. We\npresent the results of a large computer study in which we bench-mark both\nefficiency and efficacy of PSO to generate high quality candidate designs for\nsmall-exact response surface scenarios commonly encountered by industrial\npractitioners. A preferred version of PSO is demonstrated and recommended.\nFurther, in contrast to popular local optimizers such as the coordinate\nexchange, PSO is demonstrated to, even in a single run, generate highly\nefficient designs with large probability at small computing cost. Therefore, it\nappears beneficial for more practitioners to adopt and use PSO as tool for\ngenerating candidate experimental designs.",
    "descriptor": "",
    "authors": [
      "Stephen J. Walsh",
      "John J. Borkowski"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2206.06940"
  },
  {
    "id": "arXiv:2206.06943",
    "title": "Solving Invariant Generation for Unsolvable Loops",
    "abstract": "Automatically generating invariants, key to computer-aided analysis of\nprobabilistic and deterministic programs and compiler optimisation, is a\nchallenging open problem. Whilst the problem is in general undecidable, the\ngoal is settled for restricted classes of loops. For the class of solvable\nloops, introduced by Kapur and Rodr\\'iguez-Carbonell in 2004, one can\nautomatically compute invariants from closed-form solutions of recurrence\nequations that model the loop behaviour. In this paper we establish a technique\nfor invariant synthesis for loops that are not solvable, termed unsolvable\nloops. Our approach automatically partitions the program variables and\nidentifies the so-called defective variables that characterise unsolvability.\nWe further present a novel technique that automatically synthesises\npolynomials, in the defective variables, that admit closed-form solutions and\nthus lead to polynomial loop invariants. Our implementation and experiments\ndemonstrate both the feasibility and applicability of our approach to both\ndeterministic and probabilistic programs.",
    "descriptor": "",
    "authors": [
      "Daneshvar Amrollahi",
      "Ezio Bartocci",
      "George Kenison",
      "Laura Kov\u00e1cs",
      "Marcel Moosbrugger",
      "Miroslav Stankovi\u010d"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2206.06943"
  },
  {
    "id": "arXiv:2206.06948",
    "title": "Monitoring Urban Forests from Auto-Generated Segmentation Maps",
    "abstract": "We present and evaluate a weakly-supervised methodology to quantify the\nspatio-temporal distribution of urban forests based on remotely sensed data\nwith close-to-zero human interaction. Successfully training machine learning\nmodels for semantic segmentation typically depends on the availability of\nhigh-quality labels. We evaluate the benefit of high-resolution,\nthree-dimensional point cloud data (LiDAR) as source of noisy labels in order\nto train models for the localization of trees in orthophotos. As proof of\nconcept we sense Hurricane Sandy's impact on urban forests in Coney Island, New\nYork City (NYC) and reference it to less impacted urban space in Brooklyn, NYC.",
    "descriptor": "\nComments: accepted for presentation and publication at IGARSS 2022\n",
    "authors": [
      "Conrad M Albrecht",
      "Chenying Liu",
      "Yi Wang",
      "Levente Klein",
      "Xiao Xiang Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06948"
  },
  {
    "id": "arXiv:2206.06952",
    "title": "FETILDA: An Effective Framework For Fin-tuned Embeddings For Long  Financial Text Documents",
    "abstract": "Unstructured data, especially text, continues to grow rapidly in various\ndomains. In particular, in the financial sphere, there is a wealth of\naccumulated unstructured financial data, such as the textual disclosure\ndocuments that companies submit on a regular basis to regulatory agencies, such\nas the Securities and Exchange Commission (SEC). These documents are typically\nvery long and tend to contain valuable soft information about a company's\nperformance. It is therefore of great interest to learn predictive models from\nthese long textual documents, especially for forecasting numerical key\nperformance indicators (KPIs). Whereas there has been a great progress in\npre-trained language models (LMs) that learn from tremendously large corpora of\ntextual data, they still struggle in terms of effective representations for\nlong documents. Our work fills this critical need, namely how to develop better\nmodels to extract useful information from long textual documents and learn\neffective features that can leverage the soft financial and risk information\nfor text regression (prediction) tasks. In this paper, we propose and implement\na deep learning framework that splits long documents into chunks and utilizes\npre-trained LMs to process and aggregate the chunks into vector\nrepresentations, followed by self-attention to extract valuable document-level\nfeatures. We evaluate our model on a collection of 10-K public disclosure\nreports from US banks, and another dataset of reports submitted by US\ncompanies. Overall, our framework outperforms strong baseline methods for\ntextual modeling as well as a baseline regression model using only numerical\ndata. Our work provides better insights into how utilizing pre-trained\ndomain-specific and fine-tuned long-input LMs in representing long documents\ncan improve the quality of representation of textual data, and therefore, help\nin improving predictive analyses.",
    "descriptor": "\nComments: 10 pages, 9 figures, 7 tables\n",
    "authors": [
      "Bolun \"Namir\" Xia",
      "Vipula D. Rawte",
      "Mohammed J. Zaki",
      "Aparna Gupta"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06952"
  },
  {
    "id": "arXiv:2206.06957",
    "title": "Continual-Learning-as-a-Service (CLaaS): On-Demand Efficient Adaptation  of Predictive Models",
    "abstract": "Predictive machine learning models nowadays are often updated in a stateless\nand expensive way. The two main future trends for companies that want to build\nmachine learning-based applications and systems are real-time inference and\ncontinual updating. Unfortunately, both trends require a mature infrastructure\nthat is hard and costly to realize on-premise. This paper defines a novel\nsoftware service and model delivery infrastructure termed Continual\nLearning-as-a-Service (CLaaS) to address these issues. Specifically, it\nembraces continual machine learning and continuous integration techniques. It\nprovides support for model updating and validation tools for data scientists\nwithout an on-premise solution and in an efficient, stateful and easy-to-use\nmanner. Finally, this CL model service is easy to encapsulate in any machine\nlearning infrastructure or cloud system. This paper presents the design and\nimplementation of a CLaaS instantiation, called LiquidBrain, evaluated in two\nreal-world scenarios. The former is a robotic object recognition setting using\nthe CORe50 dataset while the latter is a named category and attribute\nprediction using the DeepFashion-C dataset in the fashion domain. Our\npreliminary results suggest the usability and efficiency of the Continual\nLearning model services and the effectiveness of the solution in addressing\nreal-world use-cases regardless of where the computation happens in the\ncontinuum Edge-Cloud.",
    "descriptor": "",
    "authors": [
      "Rudy Semola",
      "Vincenzo Lomonaco",
      "Davide Bacciu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.06957"
  },
  {
    "id": "arXiv:2206.06959",
    "title": "AuxMix: Semi-Supervised Learning with Unconstrained Unlabeled Data",
    "abstract": "Semi-supervised learning (SSL) has seen great strides when labeled data is\nscarce but unlabeled data is abundant. Critically, most recent work assume that\nsuch unlabeled data is drawn from the same distribution as the labeled data. In\nthis work, we show that state-of-the-art SSL algorithms suffer a degradation in\nperformance in the presence of unlabeled auxiliary data that does not\nnecessarily possess the same class distribution as the labeled set. We term\nthis problem as Auxiliary-SSL and propose AuxMix, an algorithm that leverages\nself-supervised learning tasks to learn generic features in order to mask\nauxiliary data that are not semantically similar to the labeled set. We also\npropose to regularize learning by maximizing the predicted entropy for\ndissimilar auxiliary samples. We show an improvement of 5% over existing\nbaselines on a ResNet-50 model when trained on CIFAR10 dataset with 4k labeled\nsamples and all unlabeled data is drawn from the Tiny-ImageNet dataset. We\nreport competitive results on several datasets and conduct ablation studies.",
    "descriptor": "\nComments: CVPR2022\n",
    "authors": [
      "Amin Banitalebi-Dehkordi",
      "Pratik Gujjar",
      "Yong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06959"
  },
  {
    "id": "arXiv:2206.06960",
    "title": "ABCinML: Anticipatory Bias Correction in Machine Learning Applications",
    "abstract": "The idealization of a static machine-learned model, trained once and deployed\nforever, is not practical. As input distributions change over time, the model\nwill not only lose accuracy, any constraints to reduce bias against a protected\nclass may fail to work as intended. Thus, researchers have begun to explore\nways to maintain algorithmic fairness over time. One line of work focuses on\ndynamic learning: retraining after each batch, and the other on robust learning\nwhich tries to make algorithms robust against all possible future changes.\nDynamic learning seeks to reduce biases soon after they have occurred and\nrobust learning often yields (overly) conservative models. We propose an\nanticipatory dynamic learning approach for correcting the algorithm to mitigate\nbias before it occurs. Specifically, we make use of anticipations regarding the\nrelative distributions of population subgroups (e.g., relative ratios of male\nand female applicants) in the next cycle to identify the right parameters for\nan importance weighing fairness approach. Results from experiments over\nmultiple real-world datasets suggest that this approach has promise for\nanticipatory bias correction.",
    "descriptor": "",
    "authors": [
      "Abdulaziz A. Almuzaini",
      "Chidansh A. Bhatt",
      "David M. Pennock",
      "Vivek K. Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06960"
  },
  {
    "id": "arXiv:2206.06965",
    "title": "Deep Reinforcement Learning for Exact Combinatorial Optimization:  Learning to Branch",
    "abstract": "Branch-and-bound is a systematic enumerative method for combinatorial\noptimization, where the performance highly relies on the variable selection\nstrategy. State-of-the-art handcrafted heuristic strategies suffer from\nrelatively slow inference time for each selection, while the current machine\nlearning methods require a significant amount of labeled data. We propose a new\napproach for solving the data labeling and inference latency issues in\ncombinatorial optimization based on the use of the reinforcement learning (RL)\nparadigm. We use imitation learning to bootstrap an RL agent and then use\nProximal Policy Optimization (PPO) to further explore global optimal actions.\nThen, a value network is used to run Monte-Carlo tree search (MCTS) to enhance\nthe policy network. We evaluate the performance of our method on four different\ncategories of combinatorial optimization problems and show that our approach\nperforms strongly compared to the state-of-the-art machine learning and\nheuristics based methods.",
    "descriptor": "\nComments: ICPR 2022 Oral\n",
    "authors": [
      "Tianyu Zhang",
      "Amin Banitalebi-Dehkordi",
      "Yong Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.06965"
  },
  {
    "id": "arXiv:2206.06968",
    "title": "On the necessity of the inf-sup condition for a mixed finite element  formulation",
    "abstract": "We study a non standard mixed formulation of the Poisson problem, sometimes\nknown as dual mixed formulation. For reasons related to the equilibration of\nthe flux, we use finite elements that are conforming in H(div) for the\napproximation of the gradients, even if the formulation would allow for\ndiscontinuous finite elements. The scheme is not uniformly inf-sup stable, but\nwe can show existence and uniqueness of the solution, as well as optimal error\nestimates for the gradient variable when suitable regularity assumptions are\nmade. Several additional remarks complete the paper, shedding some light on the\nsources of instability for mixed formulations.",
    "descriptor": "",
    "authors": [
      "Fleurianne Bertrand",
      "Daniele Boffi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.06968"
  },
  {
    "id": "arXiv:2206.06971",
    "title": "Conditioning of linear systems arising from penalty methods",
    "abstract": "Penalizing incompressibility in the Stokes problem leads, under mild\nassumptions, to matrices with condition numbers $\\kappa =\\mathcal{O}\n(\\varepsilon ^{-1}h^{-2})$, $\\varepsilon =$ penalty parameter $<<1$, and $ h= $\nmesh width $<1$. Although $\\kappa =\\mathcal{O}(\\varepsilon ^{-1}h^{-2}) $ is\nlarge, practical tests seldom report difficulty in solving these systems. In\nthe SPD case, using the conjugate gradient method, this is usually explained by\nspectral gaps occurring in the penalized coefficient matrix. Herein we point\nout a second contributing factor. Since the solution is approximately\nincompressible, solution components in the eigenspaces associated with the\npenalty terms can be small. As a result, the effective condition number can be\nmuch smaller than the standard condition number.",
    "descriptor": "",
    "authors": [
      "William Layton",
      "Shuxian Xu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.06971"
  },
  {
    "id": "arXiv:2206.06973",
    "title": "Two-terminal source coding with common sum reconstruction",
    "abstract": "We present the problem of two-terminal source coding with Common Sum\nReconstruction (CSR). Consider two terminals, each with access to one of two\ncorrelated sources. Both terminals want to reconstruct the sum of the two\nsources under some average distortion constraint, and the reconstructions at\ntwo terminals must be identical with high probability. In this paper, we\ndevelop inner and outer bounds to the achievable rate distortion region of the\nCSR problem for a doubly symmetric binary source. We employ existing\nachievability results for Steinberg's common reconstruction and Wyner-Ziv's\nsource coding with side information problems, and an achievability result for\nthe lossy version of Korner-Marton's modulo-two sum computation problem.",
    "descriptor": "\nComments: This paper was presented at the IEEE International Symposium on Information Theory (ISIT), Helsinki, Finland, June 2022\n",
    "authors": [
      "Tharindu Adikari",
      "Stark Draper"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06973"
  },
  {
    "id": "arXiv:2206.06975",
    "title": "DeepTPI: Test Point Insertion with Deep Reinforcement Learning",
    "abstract": "Test point insertion (TPI) is a widely used technique for testability\nenhancement, especially for logic built-in self-test (LBIST) due to its\nrelatively low fault coverage. In this paper, we propose a novel TPI approach\nbased on deep reinforcement learning (DRL), named DeepTPI. Unlike previous\nlearning-based solutions that formulate the TPI task as a supervised-learning\nproblem, we train a novel DRL agent, instantiated as the combination of a graph\nneural network (GNN) and a Deep Q-Learning network (DQN), to maximize the test\ncoverage improvement. Specifically, we model circuits as directed graphs and\ndesign a graph-based value network to estimate the action values for inserting\ndifferent test points. The policy of the DRL agent is defined as selecting the\naction with the maximum value. Moreover, we apply the general node embeddings\nfrom a pre-trained model to enhance node features, and propose a dedicated\ntestability-aware attention mechanism for the value network. Experimental\nresults on circuits with various scales show that DeepTPI significantly\nimproves test coverage compared to the commercial DFT tool. The code of this\nwork is available at https://github.com/cure-lab/DeepTPI.",
    "descriptor": "\nComments: Accepted by ITC 2022\n",
    "authors": [
      "Zhengyuan Shi",
      "Min Li",
      "Sadaf Khan",
      "Liuzheng Wang",
      "Naixing Wang",
      "Yu Huang",
      "Qiang Xu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06975"
  },
  {
    "id": "arXiv:2206.06976",
    "title": "Resource Allocation for Compression-aided Federated Learning with High  Distortion Rate",
    "abstract": "Recently, a considerable amount of works have been made to tackle the\ncommunication burden in federated learning (FL) (e.g., model quantization, data\nsparsification, and model compression). However, the existing methods, that\nboost the communication efficiency in FL, result in a considerable trade-off\nbetween communication efficiency and global convergence rate. We formulate an\noptimization problem for compression-aided FL, which captures the relationship\nbetween the distortion rate, number of participating IoT devices, and\nconvergence rate. Following that, the objective function is to minimize the\ntotal transmission time for FL convergence. Because the problem is non-convex,\nwe propose to decompose it into sub-problems. Based on the property of a FL\nmodel, we first determine the number of IoT devices participating in the FL\nprocess. Then, the communication between IoT devices and the server is\noptimized by efficiently allocating wireless resources based on a coalition\ngame. Our theoretical analysis shows that, by actively controlling the number\nof participating IoT devices, we can avoid the training divergence of\ncompression-aided FL while maintaining the communication efficiency.",
    "descriptor": "\nComments: 6 pages, 4 figures, conference\n",
    "authors": [
      "Xuan-Tung Nguyen",
      "Minh-Duong Nguyen",
      "Quoc-Viet Pham",
      "Vinh-Quang Do",
      "Won-Joo Hwang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06976"
  },
  {
    "id": "arXiv:2206.06978",
    "title": "Low-Latency MAC Design for Pairwise Random Networks",
    "abstract": "Feasibility of using unlicensed spectrum for ultra reliable low latency\ncommunications (URLLC) is still a question for beyond 5G wireless networks. Low\nlatency access to the channel and efficiently sharing spectrum among the\nmultiple users are the main requirements for exploiting unlicensed spectrum for\nURLLC. Listen before talk and back-off procedures implemented to avoid the\ncollisions in channel access hinder the low latency communication. In this\npaper, we propose a novel low-latency medium access control (MAC) scheme based\non the collision resolution for a pairwise random wireless network. We use\ngeometric sequence decomposition for collision resolution among the competing\nusers. This enables the system to tackle collisions and thus removing the need\nfor carrier sensing and back-off procedures. This saves time in obtaining\naccess to the channel and improves the efficiency of the system. We implement\nour approach in the synchronized time slotted system and show that it yields\nsignificant improvement over existing MAC schemes.",
    "descriptor": "\nComments: Accepted in IEEE VTC Spring 2022\n",
    "authors": [
      "Irshad A. Meer",
      "Woong-Hee Lee",
      "Mustafa Ozger",
      "Cicek Cavdar",
      "Ki Won Sung"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.06978"
  },
  {
    "id": "arXiv:2206.06979",
    "title": "Edge Graph Neural Networks for Massive MIMO Detection",
    "abstract": "Massive Multiple-Input Multiple-Out (MIMO) detection is an important problem\nin modern wireless communication systems. While traditional Belief Propagation\n(BP) detectors perform poorly on loopy graphs, the recent Graph Neural Networks\n(GNNs)-based method can overcome the drawbacks of BP and achieve superior\nperformance. Nevertheless, direct use of GNN ignores the importance of edge\nattributes and suffers from high computation overhead using a fully connected\ngraph structure. In this paper, we propose an efficient GNN-inspired algorithm,\ncalled the Edge Graph Neural Network (EGNN), to detect MIMO signals. We first\ncompute graph edge weights through channel correlation and then leverage the\nobtained weights as a metric to evaluate the importance of neighbors of each\nnode. Moreover, we design an adaptive Edge Drop (ED) scheme to sparsify the\ngraph such that computational cost can be significantly reduced. Experimental\nresults demonstrate that our proposed EGNN achieves better or comparable\nperformance to popular MIMO detection methods for different modulation schemes\nand costs the least detection time compared to GNN-based approaches.",
    "descriptor": "",
    "authors": [
      "Hongyi Li",
      "Junxiang Wang",
      "Yongchao Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.06979"
  },
  {
    "id": "arXiv:2206.06980",
    "title": "Survey on the State-of-the-Art in Device-to-Device Communication: A  Resource Allocation Perspective",
    "abstract": "Device to Device (D2D) communication takes advantage of the proximity between\nthe communicating devices in order to achieve efficient resource utilization,\nimproved throughput and energy efficiency, simultaneous serviceability and\nreduced latency. One of the main characteristics of D2D communication is reuse\nof the frequency resource in order to improve spectral efficiency of the\nsystem. Nevertheless, frequency reuse introduces significantly high\ninterference levels thus necessitating efficient resource allocation algorithms\nthat can enable simultaneous communication sessions through effective channel\nand/or power allocation. This survey paper presents a comprehensive\ninvestigation of the state-of-the-art resource allocation algorithms in D2D\ncommunication underlaying cellular networks. The surveyed algorithms are\nevaluated based on heterogeneous parameters which constitute the elementary\nfeatures of a resource allocation algorithm in D2D paradigm. Additionally, in\norder to familiarize the readers with the basic design of the surveyed resource\nallocation algorithms, brief description of the mode of operation of each\nalgorithm is presented. The surveyed algorithms are divided into four\ncategories based on their technical doctrine i.e., conventional optimization\nbased, Non-Orthogonal-Multiple-Access (NOMA) based, game theory based and\nmachine learning based techniques. Towards the end, several open challenges are\nremarked as the future research directions in resource allocation for D2D\ncommunication.",
    "descriptor": "\nComments: 29 pages, 5 figures,\n",
    "authors": [
      "Tariq Islam",
      "Cheolhyeon Kwon"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.06980"
  },
  {
    "id": "arXiv:2206.06986",
    "title": "Exploring Representation of Horn Clauses using GNNs",
    "abstract": "Learning program semantics from raw source code is challenging due to the\ncomplexity of real-world programming language syntax and due to the difficulty\nof reconstructing long-distance relational information implicitly represented\nin programs using identifiers. Addressing the first point, we consider\nConstrained Horn Clauses (CHCs) as a standard representation of program\nverification problems, providing a simple and programming language-independent\nsyntax. For the second challenge, we explore graph representations of CHCs, and\npropose a new Relational Hypergraph Neural Network (R-HyGNN) architecture to\nlearn program features. We introduce two different graph representations of\nCHCs. One is called constraint graph (CG), and emphasizes syntactic information\nof CHCs by translating the symbols and their relations in CHCs as typed nodes\nand binary edges, respectively, and constructing the constraints as abstract\nsyntax trees. The second one is called control- and data-flow hypergraph\n(CDHG), and emphasizes semantic information of CHCs by representing the control\nand data flow through ternary hyperedges. We then propose a new GNN\narchitecture, R-HyGNN, extending Relational Graph Convolutional Networks, to\nhandle hypergraphs. To evaluate the ability of R-HyGNN to extract semantic\ninformation from programs, we use R-HyGNNs to train models on the two graph\nrepresentations, and on five proxy tasks with increasing difficulty, using\nbenchmarks from CHC-COMP 2021 as training data. The most difficult proxy task\nrequires the model to predict the occurrence of clauses in counter-examples,\nwhich subsumes satisfiability of CHCs. CDHG achieves 90.59% accuracy in this\ntask. Furthermore, R-HyGNN has perfect predictions on one of the graphs\nconsisting of more than 290 clauses. Overall, our experiments indicate that\nR-HyGNN can capture intricate program features for guiding verification\nproblems.",
    "descriptor": "",
    "authors": [
      "Chencheng Liang",
      "Philipp R\u00fcmmer",
      "Marc Brockschmidt"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06986"
  },
  {
    "id": "arXiv:2206.06988",
    "title": "The Complexity of Finding Fair Many-to-One Matchings",
    "abstract": "We analyze the (parameterized) computational complexity of \"fair\" variants of\nbipartite many-to-one matching, where each vertex from the \"left\" side is\nmatched to exactly one vertex and each vertex from the \"right\" side may be\nmatched to multiple vertices. We want to find a \"fair\" matching, in which each\nvertex from the right side is matched to a \"fair\" set of vertices. Assuming\nthat each vertex from the left side has one color modeling its attribute, we\nstudy two fairness criteria. In one of them, we deem a vertex set fair if for\nany two colors, the difference between the numbers of their occurrences does\nnot exceed a given threshold. Fairness is relevant when finding many-to-one\nmatchings between students and colleges, voters and constituencies, and\napplicants and firms. Here colors may model sociodemographic attributes, party\nmemberships, and qualifications, respectively.\nWe show that finding a fair many-to-one matching is NP-hard even for three\ncolors and maximum degree five. Our main contribution is the design of\nfixed-parameter tractable algorithms with respect to the number of vertices on\nthe right side. Our algorithms make use of a variety of techniques including\ncolor coding. At the core lie integer linear programs encoding Hall like\nconditions. To establish the correctness of our integer programs, we prove a\nnew separation result, inspired by Frank's separation theorem [Frank, Discrete\nMath. 1982], which may also be of independent interest. We further obtain\ncomplete complexity dichotomies regarding the number of colors and the maximum\ndegree of each side.",
    "descriptor": "\nComments: Accepted to ICALP'22\n",
    "authors": [
      "Niclas Boehmer",
      "Tomohiro Koana"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2206.06988"
  },
  {
    "id": "arXiv:2206.06992",
    "title": "An Experimental Investigation of Part-Of-Speech Taggers for Vietnamese",
    "abstract": "Part-of-speech (POS) tagging plays an important role in Natural Language\nProcessing (NLP). Its applications can be found in many NLP tasks such as named\nentity recognition, syntactic parsing, dependency parsing and text chunking. In\nthe investigation conducted in this paper, we utilize the technologies of two\nwidely-used toolkits, ClearNLP and Stanford POS Tagger, as well as develop two\nnew POS taggers for Vietnamese, then compare them to three well-known\nVietnamese taggers, namely JVnTagger, vnTagger and RDRPOSTagger. We make a\nsystematic comparison to find out the tagger having the best performance. We\nalso design a new feature set to measure the performance of the statistical\ntaggers. Our new taggers built from Stanford Tagger and ClearNLP with the new\nfeature set can outperform all other current Vietnamese taggers in term of\ntagging accuracy. Moreover, we also analyze the affection of some features to\nthe performance of statistical taggers. Lastly, the experimental results also\nreveal that the transformation-based tagger, RDRPOSTagger, can run\nsignificantly faster than any other statistical tagger.",
    "descriptor": "",
    "authors": [
      "Tuan-Phong Nguyen",
      "Quoc-Tuan Truong",
      "Xuan-Nam Nguyen",
      "Anh-Cuong Le"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.06992"
  },
  {
    "id": "arXiv:2206.06994",
    "title": "ProcTHOR: Large-Scale Embodied AI Using Procedural Generation",
    "abstract": "Massive datasets and high-capacity models have driven many recent\nadvancements in computer vision and natural language understanding. This work\npresents a platform to enable similar success stories in Embodied AI. We\npropose ProcTHOR, a framework for procedural generation of Embodied AI\nenvironments. ProcTHOR enables us to sample arbitrarily large datasets of\ndiverse, interactive, customizable, and performant virtual environments to\ntrain and evaluate embodied agents across navigation, interaction, and\nmanipulation tasks. We demonstrate the power and potential of ProcTHOR via a\nsample of 10,000 generated houses and a simple neural model. Models trained\nusing only RGB images on ProcTHOR, with no explicit mapping and no human task\nsupervision produce state-of-the-art results across 6 embodied AI benchmarks\nfor navigation, rearrangement, and arm manipulation, including the presently\nrunning Habitat 2022, AI2-THOR Rearrangement 2022, and RoboTHOR challenges. We\nalso demonstrate strong 0-shot results on these benchmarks, via pre-training on\nProcTHOR with no fine-tuning on the downstream benchmark, often beating\nprevious state-of-the-art systems that access the downstream training data.",
    "descriptor": "\nComments: ProcTHOR website: this https URL\n",
    "authors": [
      "Matt Deitke",
      "Eli VanderBilt",
      "Alvaro Herrasti",
      "Luca Weihs",
      "Jordi Salvador",
      "Kiana Ehsani",
      "Winson Han",
      "Eric Kolve",
      "Ali Farhadi",
      "Aniruddha Kembhavi",
      "Roozbeh Mottaghi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.06994"
  },
  {
    "id": "arXiv:2206.06997",
    "title": "A Note on Low-Pass Filter Conditioning for Current-Mode Control",
    "abstract": "The low-pass filter is a classic control conditioning approach for\nhigh-frequency current-mode control. However, no existing literature discusses\nthe large-signal stability criterion for the current-mode control with low-pass\nfilters. This paper provides a mathematically rigorous large-signal stability\ncriterion. The result can directly benefit the practical engineering\nimplementation of the low-pass filter in high-frequency current-mode control.",
    "descriptor": "",
    "authors": [
      "Xiaofan Cui",
      "Al-Thaddeus Avestruz"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.06997"
  },
  {
    "id": "arXiv:2206.07005",
    "title": "Beyond-Cell Communications via HAPS-RIS",
    "abstract": "The ever-increasing number of users and new services in urban regions can\nlead terrestrial base stations (BSs) to become overloaded and, consequently,\nsome users to go unserved. Compounding this, users in urban areas can face\nsevere shadowing and blockages, which means that some users do not receive a\ndesired quality of service (QoS). Motivated by the energy and cost benefits of\nreconfigurable intelligent surfaces (RIS) and the advantages of high altitude\nplatform stations (HAPS), including their wide footprint and strong\nline-of-sight (LoS) links, we propose a solution to service the stranded users\nusing the RISaided HAPS. More specifically, we propose to service the stranded\nusers by a dedicated control station (CS) via a HAPS equipped with RIS\n(HAPS-RIS). Through this approach, users are not restricted from being serviced\nby the cell they belong to; hence, we refer to this approach as beyond-cell\ncommunication. As we demonstrate in this paper, beyond-cell communication works\nin tandem with legacy terrestrial networks to support uncovered or unserved\nusers. Optimal transmit power and RIS unit assignment strategies for the users\nbased on different network objectives are introduced. Numerical results\ndemonstrate the benefits of the proposed beyond-cell communication approach.\nMoreover, the results provide insights into the different optimization\nobjectives and their interplay with minimum quality-of-service (QoS) and\nnetwork resources, such as transmit power and the number of reflectors.",
    "descriptor": "\nComments: 6 pages, 5 fugures, submitted to Globecom 2022\n",
    "authors": [
      "Safwan Alfattani",
      "Animesh Yadav",
      "Halim Yanikomeroglu",
      "Abbas Yongacoglu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.07005"
  },
  {
    "id": "arXiv:2206.07007",
    "title": "Polarization Diversity-enabled LOS/NLOS Identification via Carrier Phase  Measurements",
    "abstract": "Provision of accurate localization is an increasingly important feature of\nwireless networks. To this end, reliable distinction between line-of-sight\n(LOS) and non-LOS (NLOS) radio links is necessary to avoid degenerative\nlocalization estimation biases. Interestingly, LOS and NLOS transmissions\naffect differently the polarization of receive signals. In this work, we\nleverage this phenomenon to propose a threshold-based LOS/NLOS classifier\nexploiting weighted differential carrier phase measurements over a single link\nwith different polarization configurations. Operation in full and limited\npolarization diversity systems are both possible. We develop a framework for\nassessing the performance of the proposed classifier, and show through\nsimulations the performance impact of the reflecting materials in NLOS\nscenarios. For instance, the classifier is far more efficient in NLOS scenarios\nwith wooden reflectors than in those with metallic reflectors. Numerical\nresults evince the potential performance gains from exploiting full\npolarization diversity, properly weighting the differential carrier phase\nmeasurements, and using multi-signal/tone transmissions. Finally, we show that\nthe optimum decision threshold is inversely proportional to the path power gain\nin dB, while it does not depend significantly on the material of potential NLOS\nreflectors.",
    "descriptor": "\nComments: submitted to IEEE TCOM\n",
    "authors": [
      "Onel L. A. L\u00f3pez",
      "Dileep Kumar",
      "Antti T\u00f6lli"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.07007"
  },
  {
    "id": "arXiv:2206.07008",
    "title": "Constellation Design for Deep Joint Source-Channel Coding",
    "abstract": "Deep learning-based joint source-channel coding (JSCC) has shown excellent\nperformance in image and feature transmission. However, the output values of\nthe JSCC encoder are continuous, which makes the constellation of modulation\ncomplex and dense. It is hard and expensive to design radio frequency chains\nfor transmitting such full-resolution constellation points. In this paper, two\nmethods of mapping the full-resolution constellation to finite constellation\nare proposed for real system implementation. The constellation mapping results\nof the proposed methods correspond to regular constellation and irregular\nconstellation, respectively. We apply the methods to existing deep JSCC models\nand evaluate them on AWGN channels with different signal-to-noise ratios\n(SNRs). Experimental results show that the proposed methods outperform the\ntraditional uniform quadrature amplitude modulation (QAM) constellation mapping\nmethod by only adding a few additional parameters.",
    "descriptor": "",
    "authors": [
      "Mengyang Wang",
      "Jiahui Li",
      "Mengyao Ma",
      "Xiaopeng Fan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.07008"
  },
  {
    "id": "arXiv:2206.07009",
    "title": "Private Set Matching Protocols",
    "abstract": "We introduce Private Set Matching (PSM) problems, in which a client aims to\ndetermine whether a collection of sets owned by a server matches her interest.\nExisting privacy-preserving cryptographic primitives cannot solve PSM problems\nefficiently without harming privacy. We propose a new modular framework that\nenables designers to build privacy-friendly PSM systems that output one bit:\nwhether a server set or collection of server sets matches the client's set,\nwhile guaranteeing privacy of client and server sets. The communication cost of\nour protocols scales linearly with the size of the client's set and is\nindependent of the number of server sets and their total size. We demonstrate\nthe potential of our framework by designing and implementing novel solutions\nfor two real-world PSM problems: determining whether a dataset has chemical\ncompounds of interest, and determining whether a document collection has\nrelevant documents. Our evaluation shows that our privacy gain comes at a\nreasonable communication and computation cost.",
    "descriptor": "",
    "authors": [
      "Kasra EdalatNejad",
      "Mathilde Raynal",
      "Wouter Lueks",
      "Carmela Troncoso"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.07009"
  },
  {
    "id": "arXiv:2206.07010",
    "title": "A Hierarchical-DBSCAN Method for Extracting Microservices from  Monolithic Applications",
    "abstract": "The microservices architectural style offers many advantages such as\nscalability, reusability and ease of maintainability. As such microservices has\nbecome a common architectural choice when developing new applications. Hence,\nto benefit from these advantages, monolithic applications need to be redesigned\nin order to migrate to a microservice based architecture. Due to the inherent\ncomplexity and high costs related to this process, it is crucial to automate\nthis task. In this paper, we propose a method that can identify potential\nmicroservices from a given monolithic application. Our method takes as input\nthe source code of the source application in order to measure the similarities\nand dependencies between all of the classes in the system using their\ninteractions and the domain terminology employed within the code. These\nsimilarity values are then used with a variant of a density-based clustering\nalgorithm to generate a hierarchical structure of the recommended microservices\nwhile identifying potential outlier classes. We provide an empirical evaluation\nof our approach through different experimental settings including a comparison\nwith existing human-designed microservices and a comparison with 5 baselines.\nThe results show that our method succeeds in generating microservices that are\noverall more cohesive and that have fewer interactions in-between them with up\nto 0.9 of precision score when compared to human-designed microservices.",
    "descriptor": "",
    "authors": [
      "Khaled Sellami",
      "Mohamed Aymen Saied",
      "Ali Ouni"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.07010"
  },
  {
    "id": "arXiv:2206.07011",
    "title": "Consistent Video Instance Segmentation with Inter-Frame Recurrent  Attention",
    "abstract": "Video instance segmentation aims at predicting object segmentation masks for\neach frame, as well as associating the instances across multiple frames. Recent\nend-to-end video instance segmentation methods are capable of performing object\nsegmentation and instance association together in a direct parallel sequence\ndecoding/prediction framework. Although these methods generally predict higher\nquality object segmentation masks, they can fail to associate instances in\nchallenging cases because they do not explicitly model the temporal instance\nconsistency for adjacent frames. We propose a consistent end-to-end video\ninstance segmentation framework with Inter-Frame Recurrent Attention to model\nboth the temporal instance consistency for adjacent frames and the global\ntemporal context. Our extensive experiments demonstrate that the Inter-Frame\nRecurrent Attention significantly improves temporal instance consistency while\nmaintaining the quality of the object segmentation masks. Our model achieves\nstate-of-the-art accuracy on both YouTubeVIS-2019 (62.1\\%) and YouTubeVIS-2021\n(54.7\\%) datasets. In addition, quantitative and qualitative results show that\nthe proposed methods predict more temporally consistent instance segmentation\nmasks.",
    "descriptor": "\nComments: 11 pages, 5 figures, 4 tables\n",
    "authors": [
      "Quanzeng You",
      "Jiang Wang",
      "Peng Chu",
      "Andre Abrantes",
      "Zicheng Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.07011"
  },
  {
    "id": "arXiv:2206.07012",
    "title": "Frequency Throttling Side-Channel Attack",
    "abstract": "Modern processors dynamically control their operating frequency to optimize\nresource utilization, maximize energy savings, and to conform to system-defined\nconstraints. If, during the execution of a software workload, the running\naverage of any electrical or thermal parameter exceeds its corresponding\npredefined threshold value, the power management architecture will reactively\nadjust CPU frequency to ensure safe operating conditions. In this paper, we\ndemonstrate how such power management-based CPU throttling activity forms a\nsource of timing side-channel information leakage, which can be exploited by an\nattacker to infer secret data from a constant-cycle victim workload. We\nhighlight the fact that a constant-cycle implementation of code does not\nnecessarily guarantee its constant execution on different data inputs with\nrespect to wall clock time. This is because existing throttling mechanisms\nperform data-dependent frequency adjustments, which in turn make the running\ntime of the code also data-dependent. The proposed frequency throttling\nside-channel analysis attack can be launched by kernel-space attackers and\nuser-space attackers, thus compromising security guarantees provided by\nisolation boundaries. We validate our attack methodology across different\nsystems by performing experiments on a constant-cycle implementation of the\nAES-128 algorithm. The results of our experimental evaluations demonstrate how\nthe attacker can successfully recover the targeted AES key by correlating the\ncollected timing side-channel traces with the corresponding timing estimates\nfor different key guesses, under frequency throttling. Finally, we discuss\ndifferent options to mitigate the threat posed by frequency throttling\nside-channel attacks, as well as their advantages and disadvantages.",
    "descriptor": "",
    "authors": [
      "Chen Liu",
      "Abhishek Chakraborty",
      "Nikhil Chawla",
      "Neer Roggel"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.07012"
  },
  {
    "id": "arXiv:2206.07018",
    "title": "Turning a Curse Into a Blessing: Enabling Clean-Data-Free Defenses by  Model Inversion",
    "abstract": "It is becoming increasingly common to utilize pre-trained models provided by\nthird parties due to their convenience. At the same time, however, these models\nmay be vulnerable to both poisoning and evasion attacks. We introduce an\nalgorithmic framework that can mitigate potential security vulnerabilities in a\npre-trained model when clean data from its training distribution is unavailable\nto the defender. The framework reverse-engineers samples from a given\npre-trained model. The resulting synthetic samples can then be used as a\nsubstitute for clean data to perform various defenses. We consider two\nimportant attack scenarios -- backdoor attacks and evasion attacks -- to\nshowcase the utility of synthesized samples. For both attacks, we show that\nwhen supplied with our synthetic data, the state-of-the-art defenses perform\ncomparably or sometimes even better than the case when it's supplied with the\nsame amount of clean data.",
    "descriptor": "",
    "authors": [
      "Si Chen",
      "Yi Zeng",
      "Won Park",
      "Ruoxi Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.07018"
  },
  {
    "id": "arXiv:2206.07019",
    "title": "An Attack Resilient PUF-based Authentication Mechanism for Distributed  Systems",
    "abstract": "In most PUF-based authentication schemes, a central server is usually engaged\nto verify the response of the device's PUF to challenge bit-streams. However,\nthe server availability may be intermittent in practice. To tackle such an\nissue, this paper proposes a new protocol for supporting distributed\nauthentication while avoiding vulnerability to information leakage where CRPs\ncould be retrieved from hacked devices and collectively used to model the PUF.\nThe main idea is to provision for scrambling the challenge bit-stream in a way\nthat is dependent on the verifier. The scrambling pattern varies per\nauthentication round for each device and independently across devices. In\nessence, the scrambling function becomes node- and packet-specific and the\nresponse received by two verifiers of one device for the same challenge\nbit-stream could vary. Thus, neither the scrambling function can be reverted,\nnor the PUF can be modeled even by a collusive set of malicious nodes. The\nvalidation results using data of an FPGA-based implementation demonstrate the\neffectiveness of our approach in thwarting PUF modeling attacks by collusive\nactors. We also discuss the approach resiliency against impersonation, Sybil,\nand reverse engineering attacks.",
    "descriptor": "",
    "authors": [
      "Mohammad Ebrahimabadi",
      "Mohamed Younis",
      "Wassila Lalouani",
      "Naghmeh Karimi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.07019"
  },
  {
    "id": "arXiv:2206.07021",
    "title": "Federated Optimization Algorithms with Random Reshuffling and Gradient  Compression",
    "abstract": "Gradient compression is a popular technique for improving communication\ncomplexity of stochastic first-order methods in distributed training of machine\nlearning models. However, the existing works consider only with-replacement\nsampling of stochastic gradients. In contrast, it is well-known in practice and\nrecently confirmed in theory that stochastic methods based on\nwithout-replacement sampling, e.g., Random Reshuffling (RR) method, perform\nbetter than ones that sample the gradients with-replacement. In this work, we\nclose this gap in the literature and provide the first analysis of methods with\ngradient compression and without-replacement sampling. We first develop a\ndistributed variant of random reshuffling with gradient compression (Q-RR), and\nshow how to reduce the variance coming from gradient quantization through the\nuse of control iterates. Next, to have a better fit to Federated Learning\napplications, we incorporate local computation and propose a variant of Q-RR\ncalled Q-NASTYA. Q-NASTYA uses local gradient steps and different local and\nglobal stepsizes. Next, we show how to reduce compression variance in this\nsetting as well. Finally, we prove the convergence results for the proposed\nmethods and outline several settings in which they improve upon existing\nalgorithms.",
    "descriptor": "\nComments: 55 pages, 1 figure\n",
    "authors": [
      "Abdurakhmon Sadiev",
      "Grigory Malinovsky",
      "Eduard Gorbunov",
      "Igor Sokolov",
      "Ahmed Khaled",
      "Konstantin Burlachenko",
      "Peter Richt\u00e1rik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.07021"
  },
  {
    "id": "arXiv:2206.07023",
    "title": "SBERT studies Meaning Representations: Decomposing Sentence Embeddings  into Explainable AMR Meaning Features",
    "abstract": "Metrics for graph-based meaning representations (e.g., Abstract Meaning\nRepresentation, AMR) can help us uncover key semantic aspects in which two\nsentences are similar to each other. However, such metrics tend to be slow,\nrely on parsers, and do not reach state-of-the-art performance when rating\nsentence similarity. On the other hand, models based on large-pretrained\nlanguage models, such as S(entence)BERT, show high correlation to human\nsimilarity ratings, but lack interpretability.\nIn this paper, we aim at the best of these two worlds, by creating similarity\nmetrics that are highly effective, while also providing an interpretable\nrationale for their rating. Our approach works in two steps: We first select\nAMR graph metrics that measure meaning similarity of sentences with respect to\nkey semantic facets, such as, i.a., semantic roles, negation, or\nquantification. Second, we employ these metrics to induce Semantically\nStructured Sentence BERT embeddings (S$^3$BERT), which are composed of\ndifferent meaning aspects captured in different sub-spaces. In our experimental\nstudies, we show that our approach offers a valuable balance between\nperformance and interpretability.",
    "descriptor": "",
    "authors": [
      "Juri Opitz",
      "Anette Frank"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.07023"
  },
  {
    "id": "arXiv:2206.07025",
    "title": "A deterministic view on explicit data-driven (M)PC",
    "abstract": "We show that the explicit realization of data-driven predictive control (DPC)\nfor linear deterministic systems is more tractable than previously thought. To\nthis end, we compare the optimal control problems (OCP) corresponding to\ndeterministic DPC and classical model predictive control (MPC), specify its\nclose relation, and systematically eliminate ambiguity inherent in DPC. As a\ncentral result, we find that the explicit solutions to these types of DPC and\nMPC are of exactly the same complexity. We illustrate our results with two\nnumerical examples highlighting features of our approach.",
    "descriptor": "\nComments: 7 pages, 2 figure, submitted to 61st IEE Conference on Decision and Control 2022\n",
    "authors": [
      "Manuel Kl\u00e4dtke",
      "Dieter Teichrib",
      "Nils Schl\u00fcter",
      "Moritz Schulze Darup"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.07025"
  },
  {
    "id": "arXiv:2206.07026",
    "title": "Computational linguistics and Natural Language Processing",
    "abstract": "This chapter provides an introduction to computational linguistics methods,\nwith focus on their applications to the practice and study of translation. It\ncovers computational models, methods and tools for collection, storage,\nindexing and analysis of linguistic data in the context of translation, and\ndiscusses the main methodological issues and challenges in this field. While an\nexhaustive review of existing computational linguistics methods and tools is\nbeyond the scope of this chapter, we describe the most representative\napproaches, and illustrate them with descriptions of typical applications.",
    "descriptor": "\nComments: This is the unedited author's copy of a text which appeared as a chapter in \"The Routledge Handbook of Translation and Methodology'', edited by F Zanettin and C Rundle (2022)\n",
    "authors": [
      "Saturnino Luz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.07026"
  },
  {
    "id": "arXiv:2206.07028",
    "title": "Learning 3D Object Shape and Layout without 3D Supervision",
    "abstract": "A 3D scene consists of a set of objects, each with a shape and a layout\ngiving their position in space. Understanding 3D scenes from 2D images is an\nimportant goal, with applications in robotics and graphics. While there have\nbeen recent advances in predicting 3D shape and layout from a single image,\nmost approaches rely on 3D ground truth for training which is expensive to\ncollect at scale. We overcome these limitations and propose a method that\nlearns to predict 3D shape and layout for objects without any ground truth\nshape or layout information: instead we rely on multi-view images with 2D\nsupervision which can more easily be collected at scale. Through extensive\nexperiments on 3D Warehouse, Hypersim, and ScanNet we demonstrate that our\napproach scales to large datasets of realistic images, and compares favorably\nto methods relying on 3D ground truth. On Hypersim and ScanNet where reliable\n3D ground truth is not available, our approach outperforms supervised\napproaches trained on smaller and less diverse datasets.",
    "descriptor": "\nComments: CVPR 2022, project page: this https URL\n",
    "authors": [
      "Georgia Gkioxari",
      "Nikhila Ravi",
      "Justin Johnson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.07028"
  },
  {
    "id": "arXiv:2206.07036",
    "title": "Accurate 3D Body Shape Regression using Metric and Semantic Attributes",
    "abstract": "While methods that regress 3D human meshes from images have progressed\nrapidly, the estimated body shapes often do not capture the true human shape.\nThis is problematic since, for many applications, accurate body shape is as\nimportant as pose. The key reason that body shape accuracy lags pose accuracy\nis the lack of data. While humans can label 2D joints, and these constrain 3D\npose, it is not so easy to \"label\" 3D body shape. Since paired data with images\nand 3D body shape are rare, we exploit two sources of information: (1) we\ncollect internet images of diverse \"fashion\" models together with a small set\nof anthropometric measurements; (2) we collect linguistic shape attributes for\na wide range of 3D body meshes and the model images. Taken together, these\ndatasets provide sufficient constraints to infer dense 3D shape. We exploit the\nanthropometric measurements and linguistic shape attributes in several novel\nways to train a neural network, called SHAPY, that regresses 3D human pose and\nshape from an RGB image. We evaluate SHAPY on public benchmarks, but note that\nthey either lack significant body shape variation, ground-truth shape, or\nclothing variation. Thus, we collect a new dataset for evaluating 3D human\nshape estimation, called HBW, containing photos of \"Human Bodies in the Wild\"\nfor which we have ground-truth 3D body scans. On this new benchmark, SHAPY\nsignificantly outperforms state-of-the-art methods on the task of 3D body shape\nestimation. This is the first demonstration that 3D body shape regression from\nimages can be trained from easy-to-obtain anthropometric measurements and\nlinguistic shape attributes. Our model and data are available at:\nshapy.is.tue.mpg.de",
    "descriptor": "\nComments: First two authors contributed equally\n",
    "authors": [
      "Vasileios Choutas",
      "Lea Muller",
      "Chun-Hao P. Huang",
      "Siyu Tang",
      "Dimitrios Tzionas",
      "Michael J. Black"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.07036"
  },
  {
    "id": "arXiv:2206.07038",
    "title": "AnimeSR: Learning Real-World Super-Resolution Models for Animation  Videos",
    "abstract": "This paper studies the problem of real-world video super-resolution (VSR) for\nanimation videos, and reveals three key improvements for practical animation\nVSR. First, recent real-world super-resolution approaches typically rely on\ndegradation simulation using basic operators without any learning capability,\nsuch as blur, noise, and compression. In this work, we propose to learn such\nbasic operators from real low-quality animation videos, and incorporate the\nlearned ones into the degradation generation pipeline. Such\nneural-network-based basic operators could help to better capture the\ndistribution of real degradations. Second, a large-scale high-quality animation\nvideo dataset, AVC, is built to facilitate comprehensive training and\nevaluations for animation VSR. Third, we further investigate an efficient\nmulti-scale network structure. It takes advantage of the efficiency of\nunidirectional recurrent networks and the effectiveness of sliding-window-based\nmethods. Thanks to the above delicate designs, our method, AnimeSR, is capable\nof restoring real-world low-quality animation videos effectively and\nefficiently, achieving superior performance to previous state-of-the-art\nmethods.",
    "descriptor": "\nComments: Tech Report. Codes and a high-resolution version of this paper will be available at this https URL\n",
    "authors": [
      "Yanze Wu",
      "Xintao Wang",
      "Gen Li",
      "Ying Shan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.07038"
  },
  {
    "id": "arXiv:2206.07041",
    "title": "Learning Behavior Representations Through Multi-Timescale Bootstrapping",
    "abstract": "Natural behavior consists of dynamics that are both unpredictable, can switch\nsuddenly, and unfold over many different timescales. While some success has\nbeen found in building representations of behavior under constrained or\nsimplified task-based conditions, many of these models cannot be applied to\nfree and naturalistic settings due to the fact that they assume a single scale\nof temporal dynamics. In this work, we introduce Bootstrap Across Multiple\nScales (BAMS), a multi-scale representation learning model for behavior: we\ncombine a pooling module that aggregates features extracted over encoders with\ndifferent temporal receptive fields, and design a set of latent objectives to\nbootstrap the representations in each respective space to encourage\ndisentanglement across different timescales. We first apply our method on a\ndataset of quadrupeds navigating in different terrain types, and show that our\nmodel captures the temporal complexity of behavior. We then apply our method to\nthe MABe 2022 Multi-agent behavior challenge, where our model ranks 3rd overall\nand 1st on two subtasks, and show the importance of incorporating\nmulti-timescales when analyzing behavior.",
    "descriptor": "",
    "authors": [
      "Mehdi Azabou",
      "Michael Mendelson",
      "Maks Sorokin",
      "Shantanu Thakoor",
      "Nauman Ahad",
      "Carolina Urzay",
      "Eva L. Dyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.07041"
  },
  {
    "id": "arXiv:2206.07042",
    "title": "Cross-Chain State Machine Replication",
    "abstract": "This paper considers the classical state machine replication (SMR) problem in\na distributed system model inspired by cross-chain exchanges. We propose a\nnovel SMR protocol adapted for this model. Each state machine transition takes\n$O(n)$ message delays, where $n$ is the number of active participants, of which\nany number may be Byzantine. This protocol makes novel use of path signatures\nto keep replicas consistent. This protocol design cleanly separates application\nlogic from fault-tolerance, providing a systematic way to replace complex\nad-hoc cross-chain protocols with a more principled approach.",
    "descriptor": "",
    "authors": [
      "Yingjie Xue",
      "Maurice Herlihy"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.07042"
  },
  {
    "id": "arXiv:2206.07043",
    "title": "Text Generation with Text-Editing Models",
    "abstract": "Text-editing models have recently become a prominent alternative to seq2seq\nmodels for monolingual text-generation tasks such as grammatical error\ncorrection, simplification, and style transfer. These tasks share a common\ntrait - they exhibit a large amount of textual overlap between the source and\ntarget texts. Text-editing models take advantage of this observation and learn\nto generate the output by predicting edit operations applied to the source\nsequence. In contrast, seq2seq models generate outputs word-by-word from\nscratch thus making them slow at inference time. Text-editing models provide\nseveral benefits over seq2seq models including faster inference speed, higher\nsample efficiency, and better control and interpretability of the outputs. This\ntutorial provides a comprehensive overview of text-editing models and current\nstate-of-the-art approaches, and analyzes their pros and cons. We discuss\nchallenges related to productionization and how these models can be used to\nmitigate hallucination and bias, both pressing challenges in the field of text\ngeneration.",
    "descriptor": "\nComments: Accepted as a tutorial at NAACL 2022\n",
    "authors": [
      "Eric Malmi",
      "Yue Dong",
      "Jonathan Mallinson",
      "Aleksandr Chuklin",
      "Jakub Adamek",
      "Daniil Mirylenka",
      "Felix Stahlberg",
      "Sebastian Krause",
      "Shankar Kumar",
      "Aliaksei Severyn"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.07043"
  },
  {
    "id": "arXiv:2206.07045",
    "title": "ReCo: Retrieve and Co-segment for Zero-shot Transfer",
    "abstract": "Semantic segmentation has a broad range of applications, but its real-world\nimpact has been significantly limited by the prohibitive annotation costs\nnecessary to enable deployment. Segmentation methods that forgo supervision can\nside-step these costs, but exhibit the inconvenient requirement to provide\nlabelled examples from the target distribution to assign concept names to\npredictions. An alternative line of work in language-image pre-training has\nrecently demonstrated the potential to produce models that can both assign\nnames across large vocabularies of concepts and enable zero-shot transfer for\nclassification, but do not demonstrate commensurate segmentation abilities. In\nthis work, we strive to achieve a synthesis of these two approaches that\ncombines their strengths. We leverage the retrieval abilities of one such\nlanguage-image pre-trained model, CLIP, to dynamically curate training sets\nfrom unlabelled images for arbitrary collections of concept names, and leverage\nthe robust correspondences offered by modern image representations to\nco-segment entities among the resulting collections. The synthetic segment\ncollections are then employed to construct a segmentation model (without\nrequiring pixel labels) whose knowledge of concepts is inherited from the\nscalable pre-training process of CLIP. We demonstrate that our approach, termed\nRetrieve and Co-segment (ReCo) performs favourably to unsupervised segmentation\napproaches while inheriting the convenience of nameable predictions and\nzero-shot transfer. We also demonstrate ReCo's ability to generate specialist\nsegmenters for extremely rare objects.",
    "descriptor": "\nComments: Tech report. Code: this https URL\n",
    "authors": [
      "Gyungin Shin",
      "Weidi Xie",
      "Samuel Albanie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.07045"
  },
  {
    "id": "arXiv:2206.07047",
    "title": "RGB-Multispectral Matching: Dataset, Learning Methodology, Evaluation",
    "abstract": "We address the problem of registering synchronized color (RGB) and\nmulti-spectral (MS) images featuring very different resolution by solving\nstereo matching correspondences. Purposely, we introduce a novel RGB-MS dataset\nframing 13 different scenes in indoor environments and providing a total of 34\nimage pairs annotated with semi-dense, high-resolution ground-truth labels in\nthe form of disparity maps. To tackle the task, we propose a deep learning\narchitecture trained in a self-supervised manner by exploiting a further RGB\ncamera, required only during training data acquisition. In this setup, we can\nconveniently learn cross-modal matching in the absence of ground-truth labels\nby distilling knowledge from an easier RGB-RGB matching task based on a\ncollection of about 11K unlabeled image triplets. Experiments show that the\nproposed pipeline sets a good performance bar (1.16 pixels average registration\nerror) for future research on this novel, challenging task.",
    "descriptor": "\nComments: CVPR 2022, New Orleans. Project page: this https URL\n",
    "authors": [
      "Fabio Tosi",
      "Pierluigi Zama Ramirez",
      "Matteo Poggi",
      "Samuele Salti",
      "Stefano Mattoccia",
      "Luigi Di Stefano"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.07047"
  },
  {
    "id": "arXiv:2206.06372",
    "title": "Acceleration of cerebral blood flow and arterial transit time maps  estimation from multiple post-labeling delay arterial spin-labeled MRI via  deep learning",
    "abstract": "Purpose: Arterial spin labeling (ASL) perfusion imaging indicates direct and\nabsolute measurement of cerebral blood flow (CBF). Arterial transit time (ATT)\nis a related physiological parameter reflecting the duration for the labeled\nspins to reach the brain region of interest. Multiple post-labeling delay\n(PLDs) can provide robust measures of both CBF and ATT, allowing for\noptimization of regional CBF modeling based on ATT. The prolonged acquisition\ntime can potentially reduce the quality and accuracy of the CBF and ATT\nestimation. We proposed a novel network to significantly reduce the number of\nPLDs with higher signal-to-noise ratio (SNR). Method: CBF and ATT estimations\nwere performed for one PLD and two PLDs sepa-rately. Each model was trained\nindependently to learn the nonlinear transformation from perfusion weighted\nimage (PWI) to CBF and ATT images. Results: Both one-PLD and two-PLD models\noutperformed the conventional method visually on CBF and two-PLD model showed\nmore accurate structure on ATT estima-tion. The proposed method significantly\nreduces the number of PLDs from 6 to 2 on ATT and even to single PLD on CBF\nwithout sacrificing the SNR. Conclusion: It is feasible to generate CBF and ATT\nmaps with reduced PLDs using deep learning with high quality.",
    "descriptor": "",
    "authors": [
      "Yiran Li",
      "Ze Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06372"
  },
  {
    "id": "arXiv:2206.06422",
    "title": "Symbolic Regression in Materials Science: Discovering Interatomic  Potentials from Data",
    "abstract": "Particle-based modeling of materials at atomic scale plays an important role\nin the development of new materials and understanding of their properties. The\naccuracy of particle simulations is determined by interatomic potentials, which\nallow to calculate the potential energy of an atomic system as a function of\natomic coordinates and potentially other properties. First-principles-based ab\ninitio potentials can reach arbitrary levels of accuracy, however their\naplicability is limited by their high computational cost.\nMachine learning (ML) has recently emerged as an effective way to offset the\nhigh computational costs of ab initio atomic potentials by replacing expensive\nmodels with highly efficient surrogates trained on electronic structure data.\nAmong a plethora of current methods, symbolic regression (SR) is gaining\ntraction as a powerful \"white-box\" approach for discovering functional forms of\ninteratomic potentials.\nThis contribution discusses the role of symbolic regression in Materials\nScience (MS) and offers a comprehensive overview of current methodological\nchallenges and state-of-the-art results. A genetic programming-based approach\nfor modeling atomic potentials from raw data (consisting of snapshots of atomic\npositions and associated potential energy) is presented and empirically\nvalidated on ab initio electronic structure data.",
    "descriptor": "\nComments: Submitted to the GPTP XIX Workshop, June 2-4 2022, University of Michigan, Ann Arbor, Michigan\n",
    "authors": [
      "Bogdan Burlacu",
      "Michael Kommenda",
      "Gabriel Kronberger",
      "Stephan Winkler",
      "Michael Affenzeller"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.06422"
  },
  {
    "id": "arXiv:2206.06441",
    "title": "Reconstruction of smooth shape defects in waveguides using locally  resonant frequencies",
    "abstract": "This article aims to present a new method to reconstruct slowly varying width\ndefects in 2D waveguides using locally resonant frequencies. At these\nfrequencies, locally resonant modes propagate in the waveguide under the form\nof Airy functions depending on a parameter called the locally resonant point.\nIn this particular point, the local width of the waveguide is known and its\nlocation can be recovered from boundary measurements of the wavefield. Using\nthe same process for different frequencies, we produce a good approximation of\nthe width in all the waveguide. Given multi-frequency measurements taken at the\nsurface of the waveguide, we provide a L \\infty-stable explicit method to\nreconstruct the width of the waveguide. We finally validate our method on\nnumerical data, and we discuss its applications and limits.",
    "descriptor": "",
    "authors": [
      "Ang\u00e8le Niclas",
      "Laurent Seppecher"
    ],
    "subjectives": [
      "Mathematical Physics (math-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.06441"
  },
  {
    "id": "arXiv:2206.06445",
    "title": "Fitting Segmentation Networks on Varying Image Resolutions using  Splatting",
    "abstract": "Data used in image segmentation are not always defined on the same grid. This\nis particularly true for medical images, where the resolution, field-of-view\nand orientation can differ across channels and subjects. Images and labels are\ntherefore commonly resampled onto the same grid, as a pre-processing step.\nHowever, the resampling operation introduces partial volume effects and\nblurring, thereby changing the effective resolution and reducing the contrast\nbetween structures. In this paper we propose a splat layer, which automatically\nhandles resolution mismatches in the input data. This layer pushes each image\nonto a mean space where the forward pass is performed. As the splat operator is\nthe adjoint to the resampling operator, the mean-space prediction can be pulled\nback to the native label space, where the loss function is computed. Thus, the\nneed for explicit resolution adjustment using interpolation is removed. We show\non two publicly available datasets, with simulated and real multi-modal\nmagnetic resonance images, that this model improves segmentation results\ncompared to resampling as a pre-processing step.",
    "descriptor": "\nComments: Accepted for MIUA 2022\n",
    "authors": [
      "Mikael Brudfors",
      "Yael Balbastre",
      "John Ashburner",
      "Geraint Rees",
      "Parashkev Nachev",
      "Sebastien Ourselin",
      "M. Jorge Cardoso"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06445"
  },
  {
    "id": "arXiv:2206.06446",
    "title": "Multiband Massive IoT: A Learning Approach to Infrastructure Deployment",
    "abstract": "We consider a novel ultra-narrowband (UNB) low-power wide-area network\n(LPWAN) architecture design for uplink transmission of a massive number of\nInternet of Things (IoT) devices over multiple multiplexing bands. An IoT\ndevice can randomly choose any of the multiplexing bands to transmit its\npacket. Due to hardware constraints, a base station (BS) is able to listen to\nonly one multiplexing band. Our main objective is to maximize the packet\ndecoding probability (PDP) by optimizing the placement of the BSs and frequency\nassignment of BSs to multiplexing bands. We develop two online approaches that\nadapt to the environment based on the statistics of (un)successful packets at\nthe BSs. The first approach is based on a predefined model of the environment,\nwhile the second approach is measurement-based model-free approach, which is\napplicable to any environment. The benefit of the model-based approach is a\nlower training complexity, at the risk of a poor fit in a model-incompatible\nenvironment. The simulation results show that our proposed approaches to band\nassignment and BS placement offer significant improvement in PDP over baseline\nrandom approaches and perform closely to the theoretical upper bound.",
    "descriptor": "\nComments: Accepted for publication in IEEE TWC\n",
    "authors": [
      "Enes Krijestorac",
      "Ghaith Hattab",
      "Petar Popovski",
      "Danijela Cabric"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.06446"
  },
  {
    "id": "arXiv:2206.06448",
    "title": "Assessing Privacy Leakage in Synthetic 3-D PET Imaging using Transversal  GAN",
    "abstract": "Training computer-vision related algorithms on medical images for disease\ndiagnosis or image segmentation is difficult in large part due to privacy\nconcerns. For this reason, generative image models are highly sought after to\nfacilitate data sharing. However, 3-D generative models are understudied, and\ninvestigation of their privacy leakage is needed. We introduce our 3-D\ngenerative model, Transversal GAN (TrGAN), using head & neck PET images which\nare conditioned on tumour masks as a case study. We define quantitative\nmeasures of image fidelity, utility and privacy for our model. These metrics\nare evaluated in the course of training to identify ideal fidelity, utility and\nprivacy trade-offs and establish the relationships between these parameters. We\nshow that the discriminator of the TrGAN is vulnerable to attack, and that an\nattacker can identify which samples were used in training with almost perfect\naccuracy (AUC = 0.99). We also show that an attacker with access to only the\ngenerator cannot reliably classify whether a sample had been used for training\n(AUC = 0.51). This suggests that TrGAN generators, but not discriminators, may\nbe used for sharing synthetic 3-D PET data with minimal privacy risk while\nmaintaining good utility and fidelity.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2111.01866\n",
    "authors": [
      "Robert V. Bergen",
      "Jean-Francois Rajotte",
      "Fereshteh Yousefirizi",
      "Arman Rahmim",
      "Raymond T. Ng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06448"
  },
  {
    "id": "arXiv:2206.06451",
    "title": "The Kolmogorov Infinite Dimensional Equation in a Hilbert space Via Deep  Learning Methods",
    "abstract": "We consider the nonlinear Kolmogorov equation posed in a Hilbert space H, not\nnecessarily of finite dimension. This model was recently studied by Cox et al.\n[24] in the framework of weak convergence rates of stochastic wave models.\nHere, we propose a complementary approach by providing an infinite-dimensional\nDeep Learning method to approximate suitable solutions of this model. Based in\nthe work by Hure, Pham and Warin [45] concerning the finite dimensional case,\nand our previous work [20] dealing with L\\'evy based processes, we generalize\nan Euler scheme and consistency results for the Forward Backward Stochastic\nDifferential Equations to the infinite dimensional Hilbert valued case. Since\nour framework is general, we require the recently developed DeepOnets neural\nnetworks [21, 51] to describe in detail the approximation procedure. Also, the\nframework developed by Fuhrman and Tessitore [35] to fully describe the\nstochastic approximations will be adapted to our setting",
    "descriptor": "\nComments: 42 pages\n",
    "authors": [
      "Javier Castro"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.06451"
  },
  {
    "id": "arXiv:2206.06462",
    "title": "Density Estimation with Autoregressive Bayesian Predictives",
    "abstract": "Bayesian methods are a popular choice for statistical inference in small-data\nregimes due to the regularization effect induced by the prior, which serves to\ncounteract overfitting. In the context of density estimation, the standard\nBayesian approach is to target the posterior predictive. In general, direct\nestimation of the posterior predictive is intractable and so methods typically\nresort to approximating the posterior distribution as an intermediate step. The\nrecent development of recursive predictive copula updates, however, has made it\npossible to perform tractable predictive density estimation without the need\nfor posterior approximation. Although these estimators are computationally\nappealing, they tend to struggle on non-smooth data distributions. This is\nlargely due to the comparatively restrictive form of the likelihood models from\nwhich the proposed copula updates were derived. To address this shortcoming, we\nconsider a Bayesian nonparametric model with an autoregressive likelihood\ndecomposition and Gaussian process prior, which yields a data-dependent\nbandwidth parameter in the copula update. Further, we formulate a novel\nparameterization of the bandwidth using an autoregressive neural network that\nmaps the data into a latent space, and is thus able to capture more complex\ndependencies in the data. Our extensions increase the modelling capacity of\nexisting recursive Bayesian density estimators, achieving state-of-the-art\nresults on tabular data sets.",
    "descriptor": "",
    "authors": [
      "Sahra Ghalebikesabi",
      "Chris Holmes",
      "Edwin Fong",
      "Brieuc Lehmann"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2206.06462"
  },
  {
    "id": "arXiv:2206.06486",
    "title": "Mapping fNIRS to fMRI with Neural Data Augmentation and Machine Learning  Models",
    "abstract": "Advances in neuroimaging techniques have provided us novel insights into\nunderstanding how the human mind works. Functional magnetic resonance imaging\n(fMRI) is the most popular and widely used neuroimaging technique, and there is\ngrowing interest in fMRI-based markers of individual differences. However, its\nutility is often limited due to its high cost and difficulty acquiring from\nspecific populations, including children and infants. Surrogate markers, or\nneural correlates of fMRI markers, would have important practical implications,\nbut we have few stand-alone predictors for the fMRI markers. Here, using\nmachine learning (ML) models and data augmentation, we predicted well-validated\nfMRI markers of human cognition from multivariate patterns of functional\nnear-infrared spectroscopy (fNIRS), a portable and relatively inexpensive\noptical neuroimaging technique. We recruited 50 human participants who\nperformed two cognitive tasks (stop signal task and probabilistic reversal\nlearning task), while neural activation was measured with either fNIRS or fMRI\nat each of the total two visits. Using ML models and data augmentation, we\ncould predict the well-established fMRI markers of response inhibition or\nprediction error signals from 48-channel fNIRS activation in the prefrontal\ncortex. These results suggest that fNIRS might offer a surrogate marker of fMRI\nactivation, which would broaden our understanding of various populations,\nincluding infants.",
    "descriptor": "\nComments: NeurIPS 2020 Workshop on BabyMind\n",
    "authors": [
      "Jihyun Hur",
      "Jaeyeong Yang",
      "Hoyoung Doh",
      "Woo-Young Ahn"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06486"
  },
  {
    "id": "arXiv:2206.06526",
    "title": "Overparametrized linear dimensionality reductions: From projection  pursuit to two-layer neural networks",
    "abstract": "Given a cloud of $n$ data points in $\\mathbb{R}^d$, consider all projections\nonto $m$-dimensional subspaces of $\\mathbb{R}^d$ and, for each such projection,\nthe empirical distribution of the projected points. What does this collection\nof probability distributions look like when $n,d$ grow large?\nWe consider this question under the null model in which the points are i.i.d.\nstandard Gaussian vectors, focusing on the asymptotic regime in which\n$n,d\\to\\infty$, with $n/d\\to\\alpha\\in (0,\\infty)$, while $m$ is fixed. Denoting\nby $\\mathscr{F}_{m, \\alpha}$ the set of probability distributions in\n$\\mathbb{R}^m$ that arise as low-dimensional projections in this limit, we\nestablish new inner and outer bounds on $\\mathscr{F}_{m, \\alpha}$. In\nparticular, we characterize the Wasserstein radius of $\\mathscr{F}_{m,\\alpha}$\nup to logarithmic factors, and determine it exactly for $m=1$. We also prove\nsharp bounds in terms of Kullback-Leibler divergence and R\\'{e}nyi information\ndimension.\nThe previous question has application to unsupervised learning methods, such\nas projection pursuit and independent component analysis. We introduce a\nversion of the same problem that is relevant for supervised learning, and prove\na sharp Wasserstein radius bound. As an application, we establish an upper\nbound on the interpolation threshold of two-layers neural networks with $m$\nhidden neurons.",
    "descriptor": "\nComments: 53 pages, 1 figure, an earlier version of this paper was accepted for presentation at the Conference on Learning Theory (COLT) 2022\n",
    "authors": [
      "Andrea Montanari",
      "Kangjie Zhou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06526"
  },
  {
    "id": "arXiv:2206.06531",
    "title": "A Stochastic Proximal Method for Nonsmooth Regularized Finite Sum  Optimization",
    "abstract": "We consider the problem of training a deep neural network with nonsmooth\nregularization to retrieve a sparse and efficient sub-structure. Our\nregularizer is only assumed to be lower semi-continuous and prox-bounded. We\ncombine an adaptive quadratic regularization approach with proximal stochastic\ngradient principles to derive a new solver, called SR2, whose convergence and\nworst-case complexity are established without knowledge or approximation of the\ngradient's Lipschitz constant. We formulate a stopping criteria that ensures an\nappropriate first-order stationarity measure converges to zero under certain\nconditions. We establish a worst-case iteration complexity of\n$\\mathcal{O}(\\epsilon^{-2})$ that matches those of related methods like\nProxGEN, where the learning rate is assumed to be related to the Lipschitz\nconstant. Our experiments on network instances trained on CIFAR-10 and\nCIFAR-100 with $\\ell_1$ and $\\ell_0$ regularizations show that SR2 consistently\nachieves higher sparsity and accuracy than related methods such as ProxGEN and\nProxSGD.",
    "descriptor": "",
    "authors": [
      "Dounia Lakhmiri",
      "Dominique Orban",
      "Andrea Lodi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.06531"
  },
  {
    "id": "arXiv:2206.06536",
    "title": "On Learning the Dynamical Response of Nonlinear Control Systems with  Deep Operator Networks",
    "abstract": "We propose a Deep Operator Network~(DeepONet) framework to learn the dynamic\nresponse of continuous-time nonlinear control systems from data. To this end,\nwe first construct and train a DeepONet that approximates the control system's\nlocal solution operator. Then, we design a numerical scheme that recursively\nuses the trained DeepONet to simulate the control system's long/medium-term\ndynamic response for given control inputs and initial conditions. We accompany\nthe proposed scheme with an estimate for the error bound of the associated\ncumulative error. Furthermore, we design a data-driven Runge-Kutta~(RK)\nexplicit scheme that uses the DeepONet forward pass and automatic\ndifferentiation to better approximate the system's response when the numerical\nscheme's step size is sufficiently small. Numerical experiments on the\npredator-prey, pendulum, and cart pole systems confirm that our DeepONet\nframework learns to approximate the dynamic response of nonlinear control\nsystems effectively.",
    "descriptor": "",
    "authors": [
      "Guang Li",
      "Christian Moya",
      "Zecheng Zhang"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.06536"
  },
  {
    "id": "arXiv:2206.06541",
    "title": "Pixel-by-pixel Mean Opinion Score (pMOS) for No-Reference Image Quality  Assessment",
    "abstract": "Deep-learning based techniques have contributed to the remarkable progress in\nthe field of automatic image quality assessment (IQA). Existing IQA methods are\ndesigned to measure the quality of an image in terms of Mean Opinion Score\n(MOS) at the image-level (i.e. the whole image) or at the patch-level (dividing\nthe image into multiple units and measuring quality of each patch). Some\napplications may require assessing the quality at the pixel-level (i.e. MOS\nvalue for each pixel), however, this is not possible in case of existing\ntechniques as the spatial information is lost owing to their network\nstructures. This paper proposes an IQA algorithm that can measure the MOS at\nthe pixel-level, in addition to the image-level MOS. The proposed algorithm\nconsists of three core parts, namely: i) Local IQA; ii) Region of Interest\n(ROI) prediction; iii) High-level feature embedding. The Local IQA part outputs\nthe MOS at the pixel-level, or pixel-by-pixel MOS - we term it 'pMOS'. The ROI\nprediction part outputs weights that characterize the relative importance of\nregion when calculating the image-level IQA. The high-level feature embedding\npart extracts high-level image features which are then embedded into the Local\nIQA part. In other words, the proposed algorithm yields three outputs: the pMOS\nwhich represents MOS for each pixel, the weights from the ROI indicating the\nrelative importance of region, and finally the image-level MOS that is obtained\nby the weighted sum of pMOS and ROI values. The image-level MOS thus obtained\nby utilizing pMOS and ROI weights shows superior performance compared to the\nexisting popular IQA techniques. In addition, visualization results indicate\nthat predicted pMOS and ROI outputs are reasonably aligned with the general\nprinciples of the human visual system (HVS).",
    "descriptor": "",
    "authors": [
      "Wook-Hyung Kim",
      "Cheul-hee Hahm",
      "Anant Baijal",
      "Namuk Kim",
      "Ilhyun Cho",
      "Jayoon Koo"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2206.06541"
  },
  {
    "id": "arXiv:2206.06557",
    "title": "An efficient decoder for a linear distance quantum LDPC code",
    "abstract": "Recent developments have shown the existence of quantum low-density parity\ncheck (qLDPC) codes with constant rate and linear distance. A natural question\nconcerns the efficient decodability of these codes. In this paper, we present a\nlinear time decoder for the recent quantum Tanner codes construction of\nasymptotically good qLDPC codes, which can correct all errors of weight up to a\nconstant fraction of the blocklength. Our decoder is an iterative algorithm\nwhich searches for corrections within constant-sized regions. At each step, the\ncorrections are found by reducing a locally defined and efficiently computable\ncost function which serves as a proxy for the weight of the remaining error.",
    "descriptor": "\nComments: 36 pages, 6 figures\n",
    "authors": [
      "Shouzhen Gu",
      "Christopher A. Pattison",
      "Eugene Tang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.06557"
  },
  {
    "id": "arXiv:2206.06575",
    "title": "Med-DANet: Dynamic Architecture Network for Efficient Medical Volumetric  Segmentation",
    "abstract": "For 3D medical image (e.g. CT and MRI) segmentation, the difficulty of\nsegmenting each slice in a clinical case varies greatly. Previous research on\nvolumetric medical image segmentation in a slice-by-slice manner conventionally\nuse the identical 2D deep neural network to segment all the slices of the same\ncase, ignoring the data heterogeneity among image slices. In this paper, we\nfocus on multi-modal 3D MRI brain tumor segmentation and propose a dynamic\narchitecture network named Med-DANet based on adaptive model selection to\nachieve effective accuracy and efficiency trade-off. For each slice of the\ninput 3D MRI volume, our proposed method learns a slice-specific decision by\nthe Decision Network to dynamically select a suitable model from the predefined\nModel Bank for the subsequent 2D segmentation task. Extensive experimental\nresults on both BraTS 2019 and 2020 datasets show that our proposed method\nachieves comparable or better results than previous state-of-the-art methods\nfor 3D MRI brain tumor segmentation with much less model complexity. Compared\nwith the state-of-the-art 3D method TransBTS, the proposed framework improves\nthe model efficiency by up to 3.5x without sacrificing the accuracy. Our code\nwill be publicly available soon.",
    "descriptor": "",
    "authors": [
      "Wenxuan Wang",
      "Chen Chen",
      "Jing Wang",
      "Sen Zha",
      "Yan Zhang",
      "Jiangyun Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06575"
  },
  {
    "id": "arXiv:2206.06584",
    "title": "Probabilistic Conformal Prediction Using Conditional Random Samples",
    "abstract": "This paper proposes probabilistic conformal prediction (PCP), a predictive\ninference algorithm that estimates a target variable by a discontinuous\npredictive set. Given inputs, PCP construct the predictive set based on random\nsamples from an estimated generative model. It is efficient and compatible with\neither explicit or implicit conditional generative models. Theoretically, we\nshow that PCP guarantees correct marginal coverage with finite samples.\nEmpirically, we study PCP on a variety of simulated and real datasets. Compared\nto existing methods for conformal inference, PCP provides sharper predictive\nsets.",
    "descriptor": "",
    "authors": [
      "Zhendong Wang",
      "Ruijiang Gao",
      "Mingzhang Yin",
      "Mingyuan Zhou",
      "David M. Blei"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2206.06584"
  },
  {
    "id": "arXiv:2206.06598",
    "title": "CorticalFlow$^{++}$: Boosting Cortical Surface Reconstruction Accuracy,  Regularity, and Interoperability",
    "abstract": "The problem of Cortical Surface Reconstruction from magnetic resonance\nimaging has been traditionally addressed using lengthy pipelines of image\nprocessing techniques like FreeSurfer, CAT, or CIVET. These frameworks require\nvery long runtimes deemed unfeasible for real-time applications and unpractical\nfor large-scale studies. Recently, supervised deep learning approaches have\nbeen introduced to speed up this task cutting down the reconstruction time from\nhours to seconds. Using the state-of-the-art CorticalFlow model as a blueprint,\nthis paper proposes three modifications to improve its accuracy and\ninteroperability with existing surface analysis tools, while not sacrificing\nits fast inference time and low GPU memory consumption. First, we employ a more\naccurate ODE solver to reduce the diffeomorphic mapping approximation error.\nSecond, we devise a routine to produce smoother template meshes avoiding mesh\nartifacts caused by sharp edges in CorticalFlow's convex-hull based template.\nLast, we recast pial surface prediction as the deformation of the predicted\nwhite surface leading to a one-to-one mapping between white and pial surface\nvertices. This mapping is essential to many existing surface analysis tools for\ncortical morphometry. We name the resulting method CorticalFlow$^{++}$. Using\nlarge-scale datasets, we demonstrate the proposed changes provide more\ngeometric accuracy and surface regularity while keeping the reconstruction time\nand GPU memory requirements almost unchanged.",
    "descriptor": "",
    "authors": [
      "Rodrigo Santa Cruz",
      "L\u00e9o Lebrat",
      "Darren Fu",
      "Pierrick Bourgeat",
      "Jurgen Fripp",
      "Clinton Fookes",
      "Olivier Salvado"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06598"
  },
  {
    "id": "arXiv:2206.06623",
    "title": "ULTRA: Uncertainty-aware Label Distribution Learning for Breast Tumor  Cellularity Assessment",
    "abstract": "Neoadjuvant therapy (NAT) for breast cancer is a common treatment option in\nclinical practice. Tumor cellularity (TC), which represents the percentage of\ninvasive tumors in the tumor bed, has been widely used to quantify the response\nof breast cancer to NAT. Therefore, automatic TC estimation is significant in\nclinical practice. However, existing state-of-the-art methods usually take it\nas a TC score regression problem, which ignores the ambiguity of TC labels\ncaused by subjective assessment or multiple raters. In this paper, to\nefficiently leverage the label ambiguities, we proposed an Uncertainty-aware\nLabel disTRibution leArning (ULTRA) framework for automatic TC estimation. The\nproposed ULTRA first converted the single-value TC labels to discrete label\ndistributions, which effectively models the ambiguity among all possible TC\nlabels. Furthermore, the network learned TC label distributions by minimizing\nthe Kullback-Leibler (KL) divergence between the predicted and ground-truth TC\nlabel distributions, which better supervised the model to leverage the\nambiguity of TC labels. Moreover, the ULTRA mimicked the multi-rater fusion\nprocess in clinical practice with a multi-branch feature fusion module to\nfurther explore the uncertainties of TC labels. We evaluated the ULTRA on the\npublic BreastPathQ dataset. The experimental results demonstrate that the ULTRA\noutperformed the regression-based methods for a large margin and achieved\nstate-of-the-art results. The code will be available from\nhttps://github.com/PerceptionComputingLab/ULTRA",
    "descriptor": "\nComments: Paper accepted by MICCAI 2022\n",
    "authors": [
      "Xiangyu Li",
      "Xinjie Liang",
      "Gongning Luo",
      "Wei Wang",
      "Kuanquan Wang",
      "Shuo Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06623"
  },
  {
    "id": "arXiv:2206.06632",
    "title": "Explainable AI for High Energy Physics",
    "abstract": "Neural Networks are ubiquitous in high energy physics research. However,\nthese highly nonlinear parameterized functions are treated as \\textit{black\nboxes}- whose inner workings to convey information and build the desired\ninput-output relationship are often intractable. Explainable AI (xAI) methods\ncan be useful in determining a neural model's relationship with data toward\nmaking it \\textit{interpretable} by establishing a quantitative and tractable\nrelationship between the input and the model's output. In this letter of\ninterest, we explore the potential of using xAI methods in the context of\nproblems in high energy physics.",
    "descriptor": "\nComments: Contribution to Snowmass 2021\n",
    "authors": [
      "Mark S. Neubauer",
      "Avik Roy"
    ],
    "subjectives": [
      "High Energy Physics - Experiment (hep-ex)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.06632"
  },
  {
    "id": "arXiv:2206.06636",
    "title": "Provably-secure randomness generation from switching probability of  magnetic tunnel junctions",
    "abstract": "In recent years, true random number generators (TRNGs) based on magnetic\ntunnelling junction (MTJ) have become increasingly attractive. This is because\nMTJ-based TRNGs offer some advantages over traditional CMOS-based TRNGs, such\nas smaller area and simpler structure. However, there has been no work thus far\nthat quantified the quality of the raw output of an MTJ-based TRNG and\nperformed suitable randomness extraction to produce provably-secure random\nbits, unlike their CMOS-based counterparts. In this work, we implement an\nMTJ-based TRNG and characterise the entropy of the raw output. Using this\ninformation, we perform post-processing to extract a set of random bits which\nare provably-secure.",
    "descriptor": "\nComments: 6 pages, all comments are welcome\n",
    "authors": [
      "Hong Jie Ng",
      "Shuhan Yang",
      "Zhaoyang Yao",
      "Hyunsoo Yang",
      "Charles C.-W. Lim"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2206.06636"
  },
  {
    "id": "arXiv:2206.06644",
    "title": "SpecNet2: Orthogonalization-free spectral embedding by neural networks",
    "abstract": "Spectral methods which represent data points by eigenvectors of kernel\nmatrices or graph Laplacian matrices have been a primary tool in unsupervised\ndata analysis. In many application scenarios, parametrizing the spectral\nembedding by a neural network that can be trained over batches of data samples\ngives a promising way to achieve automatic out-of-sample extension as well as\ncomputational scalability. Such an approach was taken in the original paper of\nSpectralNet (Shaham et al. 2018), which we call SpecNet1. The current paper\nintroduces a new neural network approach, named SpecNet2, to compute spectral\nembedding which optimizes an equivalent objective of the eigen-problem and\nremoves the orthogonalization layer in SpecNet1. SpecNet2 also allows\nseparating the sampling of rows and columns of the graph affinity matrix by\ntracking the neighbors of each data point through the gradient formula.\nTheoretically, we show that any local minimizer of the new\northogonalization-free objective reveals the leading eigenvectors. Furthermore,\nglobal convergence for this new orthogonalization-free objective using a\nbatch-based gradient descent method is proved. Numerical experiments\ndemonstrate the improved performance and computational efficiency of SpecNet2\non simulated data and image datasets.",
    "descriptor": "",
    "authors": [
      "Ziyu Chen",
      "Yingzhou Li",
      "Xiuyuan Cheng"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06644"
  },
  {
    "id": "arXiv:2206.06652",
    "title": "Involution game with spatio-temporal heterogeneity of social resources",
    "abstract": "When group members claim a portion of limited resources, it is tempting to\ninvest more effort to get a larger share. However, if everyone acts similarly,\nthey all get the same piece they would obtain without extra effort. This is the\ninvolution game dilemma that can be detected in several real-life situations.\nIt is also a realistic assumption that resources are not uniform in space and\ntime, which may influence the system's resulting involution level. We here\nintroduce spatio-temporal heterogeneity of social resources and explore their\nconsequences on involution. When spatial heterogeneity is applied, network\nreciprocity can mitigate the involution for rich resources, which would be\ncritical otherwise in a homogeneous population. Interestingly, when the\nresource level is modest, spatial heterogeneity causes more intensive\ninvolution in a system where most cooperator agents, who want to keep\ninvestment at a low level, are present. This picture is partly the opposite in\nthe extreme case when more investment is less effective. Spatial heterogeneity\ncan also produce a counterintuitive effect when the presence of alternative\nresource levels cannot explain the emergence of involution. If we apply\ntemporal heterogeneity additionally, then the impact of spatial heterogeneity\npractically vanishes, and we turn back to the behavior observed in a\nhomogeneous population earlier. Our observations are also supported by solving\nthe corresponding replicator equations numerically.",
    "descriptor": "\nComments: 18 pages, 6 figures\n",
    "authors": [
      "Chaoqian Wang",
      "Attila Szolnoki"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computer Science and Game Theory (cs.GT)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ],
    "url": "https://arxiv.org/abs/2206.06652"
  },
  {
    "id": "arXiv:2206.06654",
    "title": "The Kidneys Are Not All Normal: Investigating the Speckle Distributions  of Transplanted Kidneys",
    "abstract": "Modelling ultrasound speckle has generated considerable interest for its\nability to characterize tissue properties. As speckle is dependent on the\nunderlying tissue architecture, modelling it may aid in tasks like segmentation\nor disease detection. However, for the transplanted kidney where ultrasound is\ncommonly used to investigate dysfunction, it is currently unknown which\nstatistical distribution best characterises such speckle. This is especially\ntrue for the regions of the transplanted kidney: the cortex, the medulla and\nthe central echogenic complex. Furthermore, it is unclear how these\ndistributions vary by patient variables such as age, sex, body mass index,\nprimary disease, or donor type. These traits may influence speckle modelling\ngiven their influence on kidney anatomy. We are the first to investigate these\ntwo aims. N=821 kidney transplant recipient B-mode images were automatically\nsegmented into the cortex, medulla, and central echogenic complex using a\nneural network. Seven distinct probability distributions were fitted to each\nregion. The Rayleigh and Nakagami distributions had model parameters that\ndiffered significantly between the three regions (p <= 0.05). While both had\nexcellent goodness of fit, the Nakagami had higher Kullbeck-Leibler divergence.\nRecipient age correlated weakly with scale in the cortex (Omega: rho = 0.11, p\n= 0.004), while body mass index correlated weakly with shape in the medulla (m:\nrho = 0.08, p = 0.04). Neither sex, primary disease, nor donor type\ndemonstrated any correlation. We propose the Nakagami distribution be used to\ncharacterize transplanted kidneys regionally independent of disease etiology\nand most patient characteristics based on our findings.",
    "descriptor": "\nComments: 25 pages, 2 figures, 3 tables\n",
    "authors": [
      "Rohit Singla",
      "Ricky Hu",
      "Cailin Ringstrom",
      "Victoria Lessoway",
      "Janice Reid",
      "Christopher Nguan",
      "Robert Rohling"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.06654"
  },
  {
    "id": "arXiv:2206.06657",
    "title": "The Open Kidney Ultrasound Data Set",
    "abstract": "Ultrasound use is because of its low cost, non-ionizing, and non-invasive\ncharacteristics, and has established itself as a cornerstone radiological\nexamination. Research on ultrasound applications has also expanded, especially\nwith image analysis with machine learning. However, ultrasound data are\nfrequently restricted to closed data sets, with only a few openly available.\nDespite being a frequently examined organ, the kidney lacks a publicly\navailable ultrasonography data set. The proposed Open Kidney Ultrasound Data\nSet is the first publicly available set of kidney B-mode ultrasound data that\nincludes annotations for multi-class semantic segmentation. It is based on data\nretrospectively collected in a 5-year period from over 500 patients with a mean\nage of 53.2 +/- 14.7 years, body mass index of 27.0 +/- 5.4 kg/m2, and most\ncommon primary diseases being diabetes mellitus, IgA nephropathy, and\nhypertension. There are labels for the view and fine-grained manual annotations\nfrom two expert sonographers. Notably, this data includes native and\ntransplanted kidneys. Initial benchmarking measurements are performed,\ndemonstrating a state-of-the-art algorithm achieving a Dice Sorenson\nCoefficient of 0.74 for the kidney capsule. This data set is a high-quality\ndata set, including two sets of expert annotations, with a larger breadth of\nimages than previously available. In increasing access to kidney ultrasound\ndata, future researchers may be able to create novel image analysis techniques\nfor tissue characterization, disease detection, and prognostication.",
    "descriptor": "\nComments: 18 pages, 5 tables\n",
    "authors": [
      "Rohit Singla",
      "Cailin Ringstrom",
      "Grace Hu",
      "Victoria Lessoway",
      "Janice Reid",
      "Christopher Nguan",
      "Robert Rohling"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06657"
  },
  {
    "id": "arXiv:2206.06663",
    "title": "Quantitative Imaging Principles Improves Medical Image Learning",
    "abstract": "Fundamental differences between natural and medical images have recently\nfavored the use of self-supervised learning (SSL) over ImageNet transfer\nlearning for medical image applications. Differences between image types are\nprimarily due to the imaging modality and medical images utilize a wide range\nof physics based techniques while natural images are captured using only\nvisible light. While many have demonstrated that SSL on medical images has\nresulted in better downstream task performance, our work suggests that more\nperformance can be gained. The scientific principles which are used to acquire\nmedical images are not often considered when constructing learning problems.\nFor this reason, we propose incorporating quantitative imaging principles\nduring generative SSL to improve image quality and quantitative biological\naccuracy. We show that this training schema results in better starting states\nfor downstream supervised training on limited data. Our model also generates\nimages that validate on clinical quantitative analysis software.",
    "descriptor": "",
    "authors": [
      "Lambert T. Leong",
      "Michael C. Wong",
      "Yannik Glaser",
      "Thomas Wolfgruber",
      "Steven B. Heymsfield",
      "Peter Sadwoski",
      "John A. Shepherd"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.06663"
  },
  {
    "id": "arXiv:2206.06686",
    "title": "Bandwidth Enables Generalization in Quantum Kernel Models",
    "abstract": "Quantum computers are known to provide speedups over classical\nstate-of-the-art machine learning methods in some specialized settings. For\nexample, quantum kernel methods have been shown to provide an exponential\nspeedup on a learning version of the discrete logarithm problem. Understanding\nthe generalization of quantum models is essential to realizing similar speedups\non problems of practical interest. Recent results demonstrate that\ngeneralization is hindered by the exponential size of the quantum feature\nspace. Although these results suggest that quantum models cannot generalize\nwhen the number of qubits is large, in this paper we show that these results\nrely on overly restrictive assumptions. We consider a wider class of models by\nvarying a hyperparameter that we call quantum kernel bandwidth. We analyze the\nlarge-qubit limit and provide explicit formulas for the generalization of a\nquantum model that can be solved in closed form. Specifically, we show that\nchanging the value of the bandwidth can take a model from provably not being\nable to generalize to any target function to good generalization for\nwell-aligned targets. Our analysis shows how the bandwidth controls the\nspectrum of the kernel integral operator and thereby the inductive bias of the\nmodel. We demonstrate empirically that our theory correctly predicts how\nvarying the bandwidth affects generalization of quantum models on challenging\ndatasets, including those far outside our theoretical assumptions. We discuss\nthe implications of our results for quantum advantage in machine learning.",
    "descriptor": "",
    "authors": [
      "Abdulkadir Canatar",
      "Evan Peters",
      "Cengiz Pehlevan",
      "Stefan M. Wild",
      "Ruslan Shaydulin"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06686"
  },
  {
    "id": "arXiv:2206.06692",
    "title": "COVIDHunter: COVID-19 pandemic wave prediction and mitigation via  seasonality-aware modeling",
    "abstract": "Early detection and isolation of COVID-19 patients are essential for\nsuccessful implementation of mitigation strategies and eventually curbing the\ndisease spread. With a limited number of daily COVID-19 tests performed in\nevery country, simulating the COVID-19 spread along with the potential effect\nof each mitigation strategy currently remains one of the most effective ways in\nmanaging the healthcare system and guiding policy-makers. We introduce\nCOVIDHunter, a flexible and accurate COVID-19 outbreak simulation model that\nevaluates the current mitigation measures that are applied to a region,\npredicts COVID-19 statistics (the daily number of cases, hospitalizations, and\ndeaths), and provides suggestions on what strength the upcoming mitigation\nmeasure should be. The key idea of COVIDHunter is to quantify the spread of\nCOVID-19 in a geographical region by simulating the average number of new\ninfections caused by an infected person considering the effect of external\nfactors, such as environmental conditions (e.g., climate, temperature,\nhumidity), different variants of concern, vaccination rate, and mitigation\nmeasures. Using Switzerland as a case study, COVIDHunter estimates that we are\nexperiencing a deadly new wave that will peak on 26 January 2022, which is very\nsimilar in numbers to the wave we had in February 2020. The policy-makers have\nonly one choice that is to increase the strength of the currently applied\nmitigation measures for 30 days. Unlike existing models, the COVIDHunter model\naccurately monitors and predicts the daily number of cases, hospitalizations,\nand deaths due to COVID-19. Our model is flexible to configure and simple to\nmodify for modeling different scenarios under different environmental\nconditions and mitigation measures. We release the source code of the\nCOVIDHunter implementation at https://github.com/CMU-SAFARI/COVIDHunter.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2102.03667\n",
    "authors": [
      "Mohammed Alser",
      "Jeremie S. Kim",
      "Nour Almadhoun Alserr",
      "Stefan W. Tell",
      "Onur Mutlu"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)",
      "Physics and Society (physics.soc-ph)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2206.06692"
  },
  {
    "id": "arXiv:2206.06699",
    "title": "Generalizing experimental findings: identification beyond adjustments",
    "abstract": "We aim to generalize the results of a randomized controlled trial (RCT) to a\ntarget population with the help of some observational data. This is a problem\nof causal effect identification with multiple data sources. Challenges arise\nwhen the RCT is conducted in a context that differs from the target population.\nEarlier research has focused on cases where the estimates from the RCT can be\nadjusted by observational data in order to remove the selection bias and other\ndomain specific differences. We consider examples where the experimental\nfindings cannot be generalized by an adjustment and show that the\ngeneralization may still be possible by other identification strategies that\ncan be derived by applying do-calculus. The obtained identifying functionals\nfor these examples contain trapdoor variables of a new type. The value of a\ntrapdoor variable needs to be fixed in the estimation and the choice of the\nvalue may have a major effect on the bias and accuracy of estimates, which is\nalso seen in simulations. The presented results expand the scope of settings\nwhere the generalization of experimental findings is doable",
    "descriptor": "",
    "authors": [
      "Juha Karvanen"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06699"
  },
  {
    "id": "arXiv:2206.06701",
    "title": "CNN-based Classification Framework for Tissues of Lung with Additional  Information",
    "abstract": "Interstitial lung diseases are a large group of heterogeneous diseases\ncharacterized by different degrees of alveolitis and pulmonary fibrosis.\nAccurately diagnosing these diseases has significant guiding value for\nformulating treatment plans. Although previous work has produced impressive\nresults in classifying interstitial lung diseases, there is still room for\nimproving the accuracy of these techniques, mainly to enhance automated\ndecision-making. In order to improve the classification precision, our study\nproposes a convolutional neural networks-based framework with additional\ninformation. Firstly, ILD images are added with their medical information by\nre-scaling the original image in Hounsfield Units. Secondly, a modified CNN\nmodel is used to produce a vector of classification probability for each\ntissue. Thirdly, location information of the input image, consisting of the\noccurrence frequencies of different diseases in the CT scans on certain\nlocations, is used to calculate a location weight vector. Finally, the Hadamard\nproduct between two vectors is used to produce a decision vector for the\nprediction. Compared to the state-of-the-art methods, the results using a\npublicly available ILD database show the potential of predicting these using\ndifferent additional information.",
    "descriptor": "",
    "authors": [
      "Huafeng Hu",
      "Ruijie Ye",
      "Jeyarajan Thiyagalingam",
      "Frans Coenen",
      "Jionglong Su"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06701"
  },
  {
    "id": "arXiv:2206.06711",
    "title": "Conformal Off-Policy Prediction",
    "abstract": "Off-policy evaluation is critical in a number of applications where new\npolicies need to be evaluated offline before online deployment. Most existing\nmethods focus on the expected return, define the target parameter through\naveraging and provide a point estimator only. In this paper, we develop a novel\nprocedure to produce reliable interval estimators for a target policy's return\nstarting from any initial state. Our proposal accounts for the variability of\nthe return around its expectation, focuses on the individual effect and offers\nvalid uncertainty quantification. Our main idea lies in designing a pseudo\npolicy that generates subsamples as if they were sampled from the target policy\nso that existing conformal prediction algorithms are applicable to prediction\ninterval construction. Our methods are justified by theories, synthetic data\nand real data from short-video platforms.",
    "descriptor": "",
    "authors": [
      "Yingying Zhang",
      "Chengchun Shi",
      "Shikai Luo"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06711"
  },
  {
    "id": "arXiv:2206.06720",
    "title": "Deep Variational Implicit Processes",
    "abstract": "Implicit processes (IPs) are a generalization of Gaussian processes (GPs).\nIPs may lack a closed-form expression but are easy to sample from. Examples\ninclude, among others, Bayesian neural networks or neural samplers. IPs can be\nused as priors over functions, resulting in flexible models with\nwell-calibrated prediction uncertainty estimates. Methods based on IPs usually\ncarry out function-space approximate inference, which overcomes some of the\ndifficulties of parameter-space approximate inference. Nevertheless, the\napproximations employed often limit the expressiveness of the final model,\nresulting, \\emph{e.g.}, in a Gaussian predictive distribution, which can be\nrestrictive. We propose here a multi-layer generalization of IPs called the\nDeep Variational Implicit process (DVIP). This generalization is similar to\nthat of deep GPs over GPs, but it is more flexible due to the use of IPs as the\nprior distribution over the latent functions. We describe a scalable\nvariational inference algorithm for training DVIP and show that it outperforms\nprevious IP-based methods and also deep GPs. We support these claims via\nextensive regression and classification experiments. We also evaluate DVIP on\nlarge datasets with up to several million data instances to illustrate its good\nscalability and performance.",
    "descriptor": "",
    "authors": [
      "Luis A. Ortega",
      "Sim\u00f3n Rodr\u00edguez Santana",
      "Daniel Hern\u00e1ndez-Lobato"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06720"
  },
  {
    "id": "arXiv:2206.06725",
    "title": "Automated SSIM Regression for Detection and Quantification of Motion  Artefacts in Brain MR Images",
    "abstract": "Motion artefacts in magnetic resonance brain images are a crucial issue. The\nassessment of MR image quality is fundamental before proceeding with the\nclinical diagnosis. If the motion artefacts alter a correct delineation of\nstructure and substructures of the brain, lesions, tumours and so on, the\npatients need to be re-scanned. Otherwise, neuro-radiologists could report an\ninaccurate or incorrect diagnosis. The first step right after scanning a\npatient is the \"\\textit{image quality assessment}\" in order to decide if the\nacquired images are diagnostically acceptable. An automated image quality\nassessment based on the structural similarity index (SSIM) regression through a\nresidual neural network has been proposed here, with the possibility to perform\nalso the classification in different groups - by subdividing with SSIM ranges.\nThis method predicts SSIM values of an input image in the absence of a\nreference ground truth image. The networks were able to detect motion\nartefacts, and the best performance for the regression and classification task\nhas always been achieved with ResNet-18 with contrast augmentation. Mean and\nstandard deviation of residuals' distribution were $\\mu=-0.0009$ and\n$\\sigma=0.0139$, respectively. Whilst for the classification task in 3, 5 and\n10 classes, the best accuracies were 97, 95 and 89\\%, respectively. The\nobtained results show that the proposed method could be a tool in supporting\nneuro-radiologists and radiographers in evaluating the image quality before the\ndiagnosis.",
    "descriptor": "",
    "authors": [
      "Alessandro Sciarra",
      "Soumick Chatterjee",
      "Max D\u00fcnnwald",
      "Giuseppe Placidi",
      "Andreas N\u00fcrnberger",
      "Oliver Speck",
      "Steffen Oeltze-Jafra"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.06725"
  },
  {
    "id": "arXiv:2206.06730",
    "title": "Automated Precision Localization of Peripherally Inserted Central  Catheter Tip through Model-Agnostic Multi-Stage Networks",
    "abstract": "Peripherally inserted central catheters (PICCs) have been widely used as one\nof the representative central venous lines (CVCs) due to their long-term\nintravascular access with low infectivity. However, PICCs have a fatal drawback\nof a high frequency of tip mispositions, increasing the risk of puncture,\nembolism, and complications such as cardiac arrhythmias. To automatically and\nprecisely detect it, various attempts have been made by using the latest deep\nlearning (DL) technologies. However, even with these approaches, it is still\npractically difficult to determine the tip location because the multiple\nfragments phenomenon (MFP) occurs in the process of predicting and extracting\nthe PICC line required before predicting the tip. This study aimed to develop a\nsystem generally applied to existing models and to restore the PICC line more\nexactly by removing the MFs of the model output, thereby precisely localizing\nthe actual tip position for detecting its disposition. To achieve this, we\nproposed a multi-stage DL-based framework post-processing the PICC line\nextraction result of the existing technology. The performance was compared by\neach root mean squared error (RMSE) and MFP incidence rate according to whether\nor not MFCN is applied to five conventional models. In internal validation,\nwhen MFCN was applied to the existing single model, MFP was improved by an\naverage of 45%. The RMSE was improved by over 63% from an average of 26.85mm\n(17.16 to 35.80mm) to 9.72mm (9.37 to 10.98mm). In external validation, when\nMFCN was applied, the MFP incidence rate decreased by an average of 32% and the\nRMSE decreased by an average of 65\\%. Therefore, by applying the proposed MFCN,\nwe observed the significant/consistent detection performance improvement of\nPICC tip location compared to the existing model.",
    "descriptor": "\nComments: Subin Park and Yoon Ki Cha have contributed equally to this work as the co-first author. Kyung-Su Kim (kskim.doc@gmail.com) and Myung Jin Chung (mj1.chung@samsung.com) have contributed equally to this work as the co-corresponding author\n",
    "authors": [
      "Subin Park",
      "Yoon Ki Cha",
      "Soyoung Park",
      "Kyung-Su Kim",
      "Myung Jin Chung"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06730"
  },
  {
    "id": "arXiv:2206.06774",
    "title": "Supervised Dictionary Learning with Auxiliary Covariates",
    "abstract": "Supervised dictionary learning (SDL) is a classical machine learning method\nthat simultaneously seeks feature extraction and classification tasks, which\nare not necessarily a priori aligned objectives. The goal of SDL is to learn a\nclass-discriminative dictionary, which is a set of latent feature vectors that\ncan well-explain both the features as well as labels of observed data. In this\npaper, we provide a systematic study of SDL, including the theory, algorithm,\nand applications of SDL. First, we provide a novel framework that `lifts' SDL\nas a convex problem in a combined factor space and propose a low-rank projected\ngradient descent algorithm that converges exponentially to the global minimizer\nof the objective. We also formulate generative models of SDL and provide global\nestimation guarantees of the true parameters depending on the hyperparameter\nregime. Second, viewed as a nonconvex constrained optimization problem, we\nprovided an efficient block coordinate descent algorithm for SDL that is\nguaranteed to find an $\\varepsilon$-stationary point of the objective in\n$O(\\varepsilon^{-1}(\\log \\varepsilon^{-1})^{2})$ iterations. For the\ncorresponding generative model, we establish a novel non-asymptotic local\nconsistency result for constrained and regularized maximum likelihood\nestimation problems, which may be of independent interest. Third, we apply SDL\nfor imbalanced document classification by supervised topic modeling and also\nfor pneumonia detection from chest X-ray images. We also provide simulation\nstudies to demonstrate that SDL becomes more effective when there is a\ndiscrepancy between the best reconstructive and the best discriminative\ndictionaries.",
    "descriptor": "\nComments: 61 pages, 12 figures, 5 tables\n",
    "authors": [
      "Joowon Lee",
      "Hanbaek Lyu",
      "Weixin Yao"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2206.06774"
  },
  {
    "id": "arXiv:2206.06776",
    "title": "Non-mean-field Vicsek-type models for collective behaviour",
    "abstract": "We consider interacting particle dynamics with Vicsek type interactions, and\ntheir macroscopic PDE limit, in the non-mean-field regime; that is, we consider\nthe case in which each particle/agent in the system interacts only with a\nprescribed subset of the particles in the system (for example, those within a\ncertain distance). In this non-mean-field regime the influence between agents\n(i.e. the interaction term) can be normalised either by the total number of\nagents in the system (\\textit{global scaling}) or by the number of agents with\nwhich the particle is effectively interacting (\\textit{local scaling}). We\ncompare the behaviour of the globally scaled and the locally scaled systems in\nmany respects, considering for each scaling both the PDE and the corresponding\nparticle model. In particular we observe that both the locally and globally\nscaled particle system exhibit pattern formation (i.e. formation of\ntravelling-wave-like solutions) within certain parameter regimes, and generally\ndisplay similar dynamics. The same is not true of the corresponding PDE models.\nIndeed, while both PDE models have multiple stationary states, for the globally\nscaled PDE such (space-homogeneous) equilibria are unstable for certain\nparameter regimes, with the instability leading to travelling wave solutions,\nwhile they are always stable for the locally scaled one, which never produces\ntravelling waves. This observation is based on a careful numerical study of the\nmodel, supported by further analysis.",
    "descriptor": "\nComments: 44 pages\n",
    "authors": [
      "P. Butt\u00e0",
      "B. Goddard",
      "T. M. Hodgson",
      "M. Ottobre",
      "K.J. Painter"
    ],
    "subjectives": [
      "Pattern Formation and Solitons (nlin.PS)",
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2206.06776"
  },
  {
    "id": "arXiv:2206.06784",
    "title": "Stochastic Event-triggered Variational Bayesian Filtering",
    "abstract": "This paper proposes an event-triggered variational Bayesian filter for remote\nstate estimation with unknown and time-varying noise covariances. After\npresetting multiple nominal process noise covariances and an initial\nmeasurement noise covariance, a variational Bayesian method and a fixed-point\niteration method are utilized to jointly estimate the posterior state vector\nand the unknown noise covariances under a stochastic event-triggered mechanism.\nThe proposed algorithm ensures low communication loads and excellent estimation\nperformances for a wide range of unknown noise covariances. Finally, the\nperformance of the proposed algorithm is demonstrated by tracking simulations\nof a vehicle.",
    "descriptor": "",
    "authors": [
      "Xiaoxu Lv",
      "Peihu Duan",
      "Zhisheng Duan",
      "Guanrong Chen",
      "Ling Shi"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.06784"
  },
  {
    "id": "arXiv:2206.06788",
    "title": "Physics-driven Deep Learning for PET/MRI",
    "abstract": "In this paper, we review physics- and data-driven reconstruction techniques\nfor simultaneous positron emission tomography (PET) / magnetic resonance\nimaging (MRI) systems, which have significant advantages for clinical imaging\nof cancer, neurological disorders, and heart disease. These reconstruction\napproaches utilize priors, either structural or statistical, together with a\nphysics-based description of the PET system response. However, due to the\nnested representation of the forward problem, direct PET/MRI reconstruction is\na nonlinear problem. We elucidate how a multi-faceted approach accommodates\nhybrid data- and physics-driven machine learning for reconstruction of 3D\nPET/MRI, summarizing important deep learning developments made in the last 5\nyears to address attenuation correction, scattering, low photon counts, and\ndata consistency. We also describe how applications of these multi-modality\napproaches extend beyond PET/MRI to improving accuracy in radiation therapy\nplanning. We conclude by discussing opportunities for extending the current\nstate-of-the-art following the latest trends in physics- and deep\nlearning-based computational imaging and next-generation detector hardware.",
    "descriptor": "\nComments: under review\n",
    "authors": [
      "Abhejit Rajagopal",
      "Andrew P. Leynes",
      "Nicholas Dwork",
      "Jessica E. Scholey",
      "Thomas A. Hope",
      "Peder E. Z. Larson"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.06788"
  },
  {
    "id": "arXiv:2206.06795",
    "title": "The Dynamics of Riemannian Robbins-Monro Algorithms",
    "abstract": "Many important learning algorithms, such as stochastic gradient methods, are\noften deployed to solve nonlinear problems on Riemannian manifolds. Motivated\nby these applications, we propose a family of Riemannian algorithms\ngeneralizing and extending the seminal stochastic approximation framework of\nRobbins and Monro. Compared to their Euclidean counterparts, Riemannian\niterative algorithms are much less understood due to the lack of a global\nlinear structure on the manifold. We overcome this difficulty by introducing an\nextended Fermi coordinate frame which allows us to map the asymptotic behavior\nof the proposed Riemannian Robbins-Monro (RRM) class of algorithms to that of\nan associated deterministic dynamical system under very mild assumptions on the\nunderlying manifold. In so doing, we provide a general template of almost sure\nconvergence results that mirrors and extends the existing theory for Euclidean\nRobbins-Monro schemes, albeit with a significantly more involved analysis that\nrequires a number of new geometric ingredients. We showcase the flexibility of\nthe proposed RRM framework by using it to establish the convergence of a\nretraction-based analogue of the popular optimistic / extra-gradient methods\nfor solving minimization problems and games, and we provide a unified treatment\nfor their convergence.",
    "descriptor": "",
    "authors": [
      "Mohammad Reza Karimi",
      "Ya-Ping Hsieh",
      "Panayotis Mertikopoulos",
      "Andreas Krause"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.06795"
  },
  {
    "id": "arXiv:2206.06811",
    "title": "Adversarial Audio Synthesis with Complex-valued Polynomial Networks",
    "abstract": "Time-frequency (TF) representations in audio synthesis have been increasingly\nmodeled with real-valued networks. However, overlooking the complex-valued\nnature of TF representations can result in suboptimal performance and require\nadditional modules (e.g., for modeling the phase). To this end, we introduce\ncomplex-valued polynomial networks, called APOLLO, that integrate such\ncomplex-valued representations in a natural way. Concretely, APOLLO captures\nhigh-order correlations of the input elements using high-order tensors as\nscaling parameters. By leveraging standard tensor decompositions, we derive\ndifferent architectures and enable modeling richer correlations. We outline\nsuch architectures and showcase their performance in audio generation across\nfour benchmarks. As a highlight, APOLLO results in $17.5\\%$ improvement over\nadversarial methods and $8.2\\%$ over the state-of-the-art diffusion models on\nSC09 dataset in audio generation. Our models can encourage the systematic\ndesign of other efficient architectures on the complex field.",
    "descriptor": "\nComments: Accepted as oral presentation in Workshop on Machine Learning for Audio Synthesis at ICML 2022\n",
    "authors": [
      "Yongtao Wu",
      "Grigorios G Chrysos",
      "Volkan Cevher"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06811"
  },
  {
    "id": "arXiv:2206.06813",
    "title": "Learning towards Synchronous Network Memorizability and Generalizability  for Continual Segmentation across Multiple Sites",
    "abstract": "In clinical practice, a segmentation network is often required to continually\nlearn on a sequential data stream from multiple sites rather than a\nconsolidated set, due to the storage cost and privacy restriction. However,\nduring the continual learning process, existing methods are usually restricted\nin either network memorizability on previous sites or generalizability on\nunseen sites. This paper aims to tackle the challenging problem of Synchronous\nMemorizability and Generalizability (SMG) and to simultaneously improve\nperformance on both previous and unseen sites, with a novel proposed\nSMG-learning framework. First, we propose a Synchronous Gradient Alignment\n(SGA) objective, which \\emph{not only} promotes the network memorizability by\nenforcing coordinated optimization for a small exemplar set from previous sites\n(called replay buffer), \\emph{but also} enhances the generalizability by\nfacilitating site-invariance under simulated domain shift. Second, to simplify\nthe optimization of SGA objective, we design a Dual-Meta algorithm that\napproximates the SGA objective as dual meta-objectives for optimization without\nexpensive computation overhead. Third, for efficient rehearsal, we configure\nthe replay buffer comprehensively considering additional inter-site diversity\nto reduce redundancy. Experiments on prostate MRI data sequentially acquired\nfrom six institutes demonstrate that our method can simultaneously achieve\nhigher memorizability and generalizability over state-of-the-art methods. Code\nis available at https://github.com/jingyzhang/SMG-Learning.",
    "descriptor": "\nComments: Early accepted in MICCAI2022\n",
    "authors": [
      "Jingyang Zhang",
      "Peng Xue",
      "Ran Gu",
      "Yuning Gu",
      "Mianxin Liu",
      "Yongsheng Pan",
      "Zhiming Cui",
      "Jiawei Huang",
      "Lei Ma",
      "Dinggang Shen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06813"
  },
  {
    "id": "arXiv:2206.06817",
    "title": "Physics-Informed Transfer Learning Strategy to Accelerate Unsteady Fluid  Flow Simulations",
    "abstract": "Since the derivation of the Navier Stokes equations, it has become possible\nto numerically solve real world viscous flow problems (computational fluid\ndynamics (CFD)). However, despite the rapid advancements in the performance of\ncentral processing units (CPUs), the computational cost of simulating transient\nflows with extremely small time/grid scale physics is still unrealistic. In\nrecent years, machine learning (ML) technology has received significant\nattention across industries, and this big wave has propagated various interests\nin the fluid dynamics community. Recent ML CFD studies have revealed that\ncompletely suppressing the increase in error with the increase in interval\nbetween the training and prediction times in data driven methods is\nunrealistic. The development of a practical CFD acceleration methodology that\napplies ML is a remaining issue. Therefore, the objectives of this study were\ndeveloping a realistic ML strategy based on a physics-informed transfer\nlearning and validating the accuracy and acceleration performance of this\nstrategy using an unsteady CFD dataset. This strategy can determine the timing\nof transfer learning while monitoring the residuals of the governing equations\nin a cross coupling computation framework. Consequently, our hypothesis that\ncontinuous fluid flow time series prediction is feasible was validated, as the\nintermediate CFD simulations periodically not only reduce the increased\nresiduals but also update the network parameters. Notably, the cross coupling\nstrategy with a grid based network model does not compromise the simulation\naccuracy for computational acceleration. The simulation was accelerated by 1.8\ntimes in the laminar counterflow CFD dataset condition including the parameter\nupdating time. Open source CFD software OpenFOAM and open-source ML software\nTensorFlow were used in this feasibility study.",
    "descriptor": "\nComments: 16 pages, 15 figures\n",
    "authors": [
      "Joongoo Jeon",
      "Juhyeong Lee",
      "Hamidreza Eivazi",
      "Ricardo Vinuesa",
      "Sung Joong Kim"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06817"
  },
  {
    "id": "arXiv:2206.06821",
    "title": "DoWhy-GCM: An extension of DoWhy for causal inference in graphical  causal models",
    "abstract": "We introduce DoWhy-GCM, an extension of the DoWhy Python library, that\nleverages graphical causal models. Unlike existing causality libraries, which\nmainly focus on effect estimation questions, with DoWhy-GCM, users can ask a\nwide range of additional causal questions, such as identifying the root causes\nof outliers and distributional changes, causal structure learning, attributing\ncausal influences, and diagnosis of causal structures. To this end, DoWhy-GCM\nusers first model cause-effect relations between variables in a system under\nstudy through a graphical causal model, fit the causal mechanisms of variables\nnext, and then ask the causal question. All these steps take only a few lines\nof code in DoWhy-GCM.\nThe library is available at https://github.com/py-why/dowhy.",
    "descriptor": "",
    "authors": [
      "Patrick Bl\u00f6baum",
      "Peter G\u00f6tz",
      "Kailash Budhathoki",
      "Atalanti A. Mastakouri",
      "Dominik Janzing"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Artificial Intelligence (cs.AI)",
      "Mathematical Software (cs.MS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.06821"
  },
  {
    "id": "arXiv:2206.06847",
    "title": "On the Finite-Time Performance of the Knowledge Gradient Algorithm",
    "abstract": "The knowledge gradient (KG) algorithm is a popular and effective algorithm\nfor the best arm identification (BAI) problem. Due to the complex calculation\nof KG, theoretical analysis of this algorithm is difficult, and existing\nresults are mostly about the asymptotic performance of it, e.g., consistency,\nasymptotic sample allocation, etc. In this research, we present new theoretical\nresults about the finite-time performance of the KG algorithm. Under\nindependent and normally distributed rewards, we derive lower bounds and upper\nbounds for the probability of error and simple regret of the algorithm. With\nthese bounds, existing asymptotic results become simple corollaries. We also\nshow the performance of the algorithm for the multi-armed bandit (MAB) problem.\nThese developments not only extend the existing analysis of the KG algorithm,\nbut can also be used to analyze other improvement-based algorithms. Last, we\nuse numerical experiments to further demonstrate the finite-time behavior of\nthe KG algorithm.",
    "descriptor": "",
    "authors": [
      "Yanwen Li",
      "Siyang Gao"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06847"
  },
  {
    "id": "arXiv:2206.06849",
    "title": "On the Gauss-Manin Connection and Real Singularities",
    "abstract": "We prove that to each real singularity $f: (\\mathbb{R}^{n+1}, 0) \\to\n(\\mathbb{R}, 0)$ one can associate two systems of differential equations\n$\\mathfrak{g}^{k\\pm}_f$ which are pushforwards in the category of\n$\\mathcal{D}$-modules over $\\mathbb{R}^{\\pm}$, of the sheaf of real analytic\nfunctions on the total space of the positive, respectively negative, Milnor\nfibration. We prove that for $k=0$ if $f$ is an isolated singularity then\n$\\mathfrak{g}^{\\pm}$ determines the the $n$-th homology groups of the positive,\nrespectively negative, Milnor fibre. We then calculate $\\mathfrak{g}^{+}$ for\nordinary quadratic singularities and prove that under certain conditions on the\nchoice of morsification, one recovers the top homology groups of the Milnor\nfibers of any isolated singularity $f$. As an application we construct a\npublic-key encryption scheme based on morsification of singularities.",
    "descriptor": "",
    "authors": [
      "Lars Andersen"
    ],
    "subjectives": [
      "Algebraic Geometry (math.AG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.06849"
  },
  {
    "id": "arXiv:2206.06862",
    "title": "Evaluating histopathology transfer learning with ChampKit",
    "abstract": "Histopathology remains the gold standard for diagnosis of various cancers.\nRecent advances in computer vision, specifically deep learning, have\nfacilitated the analysis of histopathology images for various tasks, including\nimmune cell detection and microsatellite instability classification. The\nstate-of-the-art for each task often employs base architectures that have been\npretrained for image classification on ImageNet. The standard approach to\ndevelop classifiers in histopathology tends to focus narrowly on optimizing\nmodels for a single task, not considering the aspects of modeling innovations\nthat improve generalization across tasks. Here we present ChampKit\n(Comprehensive Histopathology Assessment of Model Predictions toolKit): an\nextensible, fully reproducible benchmarking toolkit that consists of a broad\ncollection of patch-level image classification tasks across different cancers.\nChampKit enables a way to systematically document the performance impact of\nproposed improvements in models and methodology. ChampKit source code and data\nare freely accessible at https://github.com/kaczmarj/champkit .",
    "descriptor": "\nComments: Submitted to NeurIPS 2022 Track on Datasets and Benchmarks. Source code available at this https URL\n",
    "authors": [
      "Jakub R. Kaczmarzyk",
      "Tahsin M. Kurc",
      "Shahira Abousamra",
      "Rajarsi Gupta",
      "Joel H. Saltz",
      "Peter K. Koo"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.06862"
  },
  {
    "id": "arXiv:2206.06863",
    "title": "How are policy gradient methods affected by the limits of control?",
    "abstract": "We study stochastic policy gradient methods from the perspective of\ncontrol-theoretic limitations. Our main result is that ill-conditioned linear\nsystems in the sense of Doyle inevitably lead to noisy gradient estimates. We\nalso give an example of a class of stable systems in which policy gradient\nmethods suffer from the curse of dimensionality. Our results apply to both\nstate feedback and partially observed systems.",
    "descriptor": "",
    "authors": [
      "Ingvar Ziemann",
      "Anastasios Tsiamis",
      "Henrik Sandberg",
      "Nikolai Matni"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06863"
  },
  {
    "id": "arXiv:2206.06866",
    "title": "EXPTIME-hardness of higher-dimensional Minkowski spacetime",
    "abstract": "We prove the EXPTIME-hardness of the validity problem for the basic temporal\nlogic on Minkowski spacetime with more than one space dimension. We prove this\nresult for both the lightspeed-or-slower and the slower-than-light\naccessibility relations (and for both the irreflexive and the reflexive\nversions of these relations). As an auxiliary result, we prove the\nEXPTIME-hardness of validity on any frame for which there exists an embedding\nof the infinite complete binary tree satisfying certain conditions. The proof\nis by a reduction from the two-player corridor-tiling game.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Robin Hirsch",
      "Brett McLean"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.06866"
  },
  {
    "id": "arXiv:2206.06885",
    "title": "Neural interval-censored Cox regression with feature selection",
    "abstract": "The classical Cox model emerged in 1972 promoting breakthroughs in how\npatient prognosis is quantified using time-to-event analysis in biomedicine.\nOne of the most useful characteristics of the model for practitioners is the\ninterpretability of the variables in the analysis. However, this comes at the\nprice of introducing strong assumptions concerning the functional form of the\nregression model. To break this gap, this paper aims to exploit the\nexplainability advantages of the classical Cox model in the setting of\ninterval-censoring using a new Lasso neural network that simultaneously selects\nthe most relevant variables while quantifying non-linear relations between\npredictors and survival times. The gain of the new method is illustrated\nempirically in an extensive simulation study with examples that involve linear\nand non-linear ground dependencies. We also demonstrate the performance of our\nstrategy in the analysis of physiological, clinical and accelerometer data from\nthe NHANES 2003-2006 waves to predict the effect of physical activity on the\nsurvival of patients. Our method outperforms the prior results in the\nliterature that use the traditional Cox model.",
    "descriptor": "",
    "authors": [
      "Carlos Garc\u00eda Meixide",
      "Marcos Matabuena",
      "Michael R. Kosorok"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2206.06885"
  },
  {
    "id": "arXiv:2206.06886",
    "title": "Space-efficient Quantization Method for Reversible Markov Chains",
    "abstract": "In a seminal paper, Szegedy showed how to construct a quantum walk $W(P)$ for\nany reversible Markov chain $P$ such that its eigenvector with eigenphase $0$\nis a quantum sample of the limiting distribution of the random walk and its\neigenphase gap is quadratically larger than the spectral gap of $P$. The\nstandard construction of Szegedy's quantum walk requires an ancilla register of\nHilbert-space dimension equal to the size of the state space of the Markov\nchain. We show that it is possible to avoid this doubling of state space for\ncertain Markov chains that employ a symmetric proposal probability and a\nsubsequent accept/reject probability to sample from the Gibbs distribution. For\nsuch Markov chains, we give a quantization method which requires an ancilla\nregister of dimension equal to only the number of different energy values,\nwhich is often significantly smaller than the size of the state space. To\naccomplish this, we develop a technique for block encoding Hadamard products of\nmatrices which may be of wider interest.",
    "descriptor": "",
    "authors": [
      "Chen-Fu Chiang",
      "Anirban Chowdhury",
      "Pawel Wocjan"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2206.06886"
  },
  {
    "id": "arXiv:2206.06942",
    "title": "Boolean dimension and dim-boundedness: Planar cover graph with a zero",
    "abstract": "In 1989, Ne\\v{s}et\\v{r}il and Pudl\\'ak posed the following challenging\nquestion: Do planar posets have bounded Boolean dimension? We show that every\nposet with a planar cover graph and a unique minimal element has Boolean\ndimension at most 13. As a consequence, we are able to show that there is a\nreachability labeling scheme with labels consisting of $O(\\log n)$ bits for\nplanar digraphs with a single source. The best known scheme for general planar\ndigraphs uses labels with $O(\\log^2 n)$ bits [Thorup JACM 2004], and it remains\nopen to determine whether a scheme using labels with $O(\\log n)$ bits exists.\nThe Boolean dimension result is proved in tandem with a second result showing\nthat the dimension of a poset with a planar cover graph and a unique minimal\nelement is bounded by a linear function of its standard example number.\nHowever, one of the major challenges in dimension theory is to determine\nwhether dimension is bounded in terms of standard example number for all posets\nwith planar cover graphs.",
    "descriptor": "",
    "authors": [
      "Piotr Micek",
      "Heather C. Smith Blake",
      "William T. Trotter"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2206.06942"
  },
  {
    "id": "arXiv:2206.06947",
    "title": "K-Space Transformer for Fast MRIReconstruction with Implicit  Representation",
    "abstract": "This paper considers the problem of fast MRI reconstruction. We propose a\nnovel Transformer-based framework for directly processing the sparsely sampled\nsignals in k-space, going beyond the limitation of regular grids as ConvNets\ndo. We adopt an implicit representation of spectrogram, treating spatial\ncoordinates as inputs, and dynamically query the partially observed\nmeasurements to complete the spectrogram, i.e. learning the inductive bias in\nk-space. To strive a balance between computational cost and reconstruction\nquality, we build an hierarchical structure with low-resolution and\nhigh-resolution decoders respectively. To validate the necessity of our\nproposed modules, we have conducted extensive experiments on two public\ndatasets, and demonstrate superior or comparable performance over\nstate-of-the-art approaches.",
    "descriptor": "",
    "authors": [
      "Ziheng Zhao",
      "Tianjiao Zhang",
      "Weidi Xie",
      "Yanfeng Wang",
      "Ya Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06947"
  },
  {
    "id": "arXiv:2206.06970",
    "title": "Highly Efficient Structural Learning of Sparse Staged Trees",
    "abstract": "Several structural learning algorithms for staged tree models, an asymmetric\nextension of Bayesian networks, have been defined. However, they do not scale\nefficiently as the number of variables considered increases. Here we introduce\nthe first scalable structural learning algorithm for staged trees, which\nsearches over a space of models where only a small number of dependencies can\nbe imposed. A simulation study as well as a real-world application illustrate\nour routines and the practical use of such data-learned staged trees.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2203.04390\n",
    "authors": [
      "Manuele Leonelli",
      "Gherardo Varando"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06970"
  },
  {
    "id": "arXiv:2206.06996",
    "title": "Vascular fluid-structure interaction: unified continuum formulation,  image-based mesh generation pipeline, and scalable fully implicit solver  technology",
    "abstract": "We propose a computational framework for vascular fluid-structure interaction\n(FSI), focusing on biomechanical modeling, geometric modeling, and solver\ntechnology. The biomechanical model is constructed based on the unified\ncontinuum formulation. We highlight that the chosen time integration scheme\ndiffers from existing implicit FSI integration methods in that it is indeed\nsecond-order accurate, does not suffer from the overshoot phenomenon, and\noptimally dissipates high-frequency modes in both subproblems. We propose a\npipeline for generating subject-specific meshes for FSI analysis for\nanatomically realistic geometric modeling. Unlike most existing methodologies\nthat operate directly on the wall surface mesh, our pipeline starts from the\nimage segmentation stage. With high-quality surface meshes obtained, the\nvolumetric meshes are then generated, guaranteeing a boundary-layered mesh in\nthe fluid subdomain and a matching mesh across the fluid-solid interface. In\nthe last, we propose a combined suite of nonlinear and linear solver\ntechnologies. Invoking a segregated algorithm within the Newton-Raphson\niteration, the problem reduces to solving two linear systems in the\nmulti-corrector stage. The first linear system can be addressed by the\nalgebraic multigrid (AMG) method. The matrix related to the balance equations\npresents a two-by-two block structure in both subproblems. Using the Schur\ncomplement reduction (SCR) technique reduces the problem to solving matrices of\nsmaller sizes of the elliptic type, and the AMG method again becomes a natural\ncandidate. The benefit of the unified formulation is demonstrated in\nparallelizing the solution algorithms as the number of unknowns matches in both\nsubdomains. We use the Greenshields-Weller benchmark as well as a\npatient-specific vascular model to demonstrate the robustness, efficiency, and\nscalability of the overall FSI solver technology.",
    "descriptor": "",
    "authors": [
      "Ju Liu",
      "Jiayi Huang",
      "Qingshuang Lu",
      "Yujie Sun"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Numerical Analysis (math.NA)",
      "Biological Physics (physics.bio-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.06996"
  },
  {
    "id": "arXiv:2206.07015",
    "title": "SS-GNN: A Simple-Structured Graph Neural Network for Affinity Prediction",
    "abstract": "Efficient and effective drug-target binding affinity (DTBA) prediction is a\nchallenging task due to the limited computational resources in practical\napplications and is a crucial basis for drug screening. Inspired by the good\nrepresentation ability of graph neural networks (GNNs), we propose a\nsimple-structured GNN model named SS-GNN to accurately predict DTBA. By\nconstructing a single undirected graph based on a distance threshold to\nrepresent protein-ligand interactions, the scale of the graph data is greatly\nreduced. Moreover, ignoring covalent bonds in the protein further reduces the\ncomputational cost of the model. The GNN-MLP module takes the latent feature\nextraction of atoms and edges in the graph as two mutually independent\nprocesses. We also develop an edge-based atom-pair feature aggregation method\nto represent complex interactions and a graph pooling-based method to predict\nthe binding affinity of the complex. We achieve state-of-the-art prediction\nperformance using a simple model (with only 0.6M parameters) without\nintroducing complicated geometric feature descriptions. SS-GNN achieves\nPearson's Rp=0.853 on the PDBbind v2016 core set, outperforming\nstate-of-the-art GNN-based methods by 5.2%. Moreover, the simplified model\nstructure and concise data processing procedure improve the prediction\nefficiency of the model. For a typical protein-ligand complex, affinity\nprediction takes only 0.2 ms. All codes are freely accessible at\nhttps://github.com/xianyuco/SS-GNN.",
    "descriptor": "",
    "authors": [
      "Shuke Zhang",
      "Yanzhao Jin",
      "Tianmeng Liu",
      "Qi Wang",
      "Zhaohui Zhang",
      "Shuliang Zhao",
      "Bo Shan"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.07015"
  },
  {
    "id": "arXiv:1911.08164",
    "title": "Adaptive Greedy versus Non-adaptive Greedy for Influence Maximization",
    "abstract": "Comments: 26 pages, 0 figure, accepted at JAIR'22: Journal of Artificial Intelligence Research 74 (2022) 303-351; A short version of this paper was accepted at AAAI'20: Thirty-Fourth AAAI Conference on Artificial Intelligence",
    "descriptor": "\nComments: 26 pages, 0 figure, accepted at JAIR'22: Journal of Artificial Intelligence Research 74 (2022) 303-351; A short version of this paper was accepted at AAAI'20: Thirty-Fourth AAAI Conference on Artificial Intelligence\n",
    "authors": [
      "Wei Chen",
      "Binghui Peng",
      "Grant Schoenebeck",
      "Biaoshuai Tao"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/1911.08164"
  },
  {
    "id": "arXiv:2006.05933",
    "title": "AMEIR: Automatic Behavior Modeling, Interaction Exploration and MLP  Investigation in the Recommender System",
    "abstract": "AMEIR: Automatic Behavior Modeling, Interaction Exploration and MLP  Investigation in the Recommender System",
    "descriptor": "",
    "authors": [
      "Pengyu Zhao",
      "Kecheng Xiao",
      "Yuanxing Zhang",
      "Kaigui Bian",
      "Wei Yan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.05933"
  },
  {
    "id": "arXiv:2006.10653",
    "title": "Precise expressions for random projections: Low-rank approximation and  randomized Newton",
    "abstract": "Comments: This version of the paper includes a correction to the assumptions in a technical result, Theorem 2. None of the other claims are affected by this change. The conference version of this paper does not include the correction, so we recommend to cite this arXiv version when referencing Theorem 2",
    "descriptor": "\nComments: This version of the paper includes a correction to the assumptions in a technical result, Theorem 2. None of the other claims are affected by this change. The conference version of this paper does not include the correction, so we recommend to cite this arXiv version when referencing Theorem 2\n",
    "authors": [
      "Micha\u0142 Derezi\u0144ski",
      "Feynman Liang",
      "Zhenyu Liao",
      "Michael W. Mahoney"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.10653"
  },
  {
    "id": "arXiv:2006.16190",
    "title": "Reachability in arborescence packings",
    "abstract": "Reachability in arborescence packings",
    "descriptor": "",
    "authors": [
      "Florian H\u00f6rsch",
      "Zolt\u00e1n Szigeti"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2006.16190"
  },
  {
    "id": "arXiv:2009.04614",
    "title": "End-to-end Kernel Learning via Generative Random Fourier Features",
    "abstract": "Comments: update revised version",
    "descriptor": "\nComments: update revised version\n",
    "authors": [
      "Kun Fang",
      "Fanghui Liu",
      "Xiaolin Huang",
      "Jie Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.04614"
  },
  {
    "id": "arXiv:2009.05144",
    "title": "Auto-encoders for Track Reconstruction in Drift Chambers for CLAS12",
    "abstract": "Auto-encoders for Track Reconstruction in Drift Chambers for CLAS12",
    "descriptor": "",
    "authors": [
      "Gagik Gavalian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Instrumentation and Detectors (physics.ins-det)"
    ],
    "url": "https://arxiv.org/abs/2009.05144"
  },
  {
    "id": "arXiv:2009.10670",
    "title": "On the proliferation of support vectors in high dimensions",
    "abstract": "On the proliferation of support vectors in high dimensions",
    "descriptor": "",
    "authors": [
      "Daniel Hsu",
      "Vidya Muthukumar",
      "Ji Xu"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.10670"
  },
  {
    "id": "arXiv:2009.13819",
    "title": "The Shapley Value of Inconsistency Measures for Functional Dependencies",
    "abstract": "The Shapley Value of Inconsistency Measures for Functional Dependencies",
    "descriptor": "",
    "authors": [
      "Ester Livshits",
      "Benny Kimelfeld"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2009.13819"
  },
  {
    "id": "arXiv:2010.05171",
    "title": "fairseq S2T: Fast Speech-to-Text Modeling with fairseq",
    "abstract": "Comments: Post-conference updates (accepted to AACL 2020 Demo)",
    "descriptor": "\nComments: Post-conference updates (accepted to AACL 2020 Demo)\n",
    "authors": [
      "Changhan Wang",
      "Yun Tang",
      "Xutai Ma",
      "Anne Wu",
      "Sravya Popuri",
      "Dmytro Okhonko",
      "Juan Pino"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2010.05171"
  },
  {
    "id": "arXiv:2011.05001",
    "title": "Integral Probability Metric based Regularization for Optimal Transport",
    "abstract": "Integral Probability Metric based Regularization for Optimal Transport",
    "descriptor": "",
    "authors": [
      "Piyushi Manupriya",
      "J. Saketha Nath",
      "Pratik Jawanpuria"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2011.05001"
  },
  {
    "id": "arXiv:2101.09741",
    "title": "An optimal gradient method for smooth strongly convex minimization",
    "abstract": "Comments: Accepted for publication in Mathematical Programming. Codes available at this https URL (symbolic verifications and numerical experiments)",
    "descriptor": "\nComments: Accepted for publication in Mathematical Programming. Codes available at this https URL (symbolic verifications and numerical experiments)\n",
    "authors": [
      "Adrien Taylor",
      "Yoel Drori"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2101.09741"
  },
  {
    "id": "arXiv:2102.04965",
    "title": "How Unique Is a Face: An Investigative Study",
    "abstract": "Comments: Preprint. Full paper accepted at the IEEE/IAPR International Conference on Pattern Recognition (ICPR), Milan, Italy, Jan 2021. 6 pages",
    "descriptor": "\nComments: Preprint. Full paper accepted at the IEEE/IAPR International Conference on Pattern Recognition (ICPR), Milan, Italy, Jan 2021. 6 pages\n",
    "authors": [
      "Michal Balazia",
      "S L Happy",
      "Francois Bremond",
      "Antitza Dantcheva"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.04965"
  },
  {
    "id": "arXiv:2102.09703",
    "title": "Near-Optimal Randomized Exploration for Tabular Markov Decision  Processes",
    "abstract": "Comments: 39 pages",
    "descriptor": "\nComments: 39 pages\n",
    "authors": [
      "Zhihan Xiong",
      "Ruoqi Shen",
      "Qiwen Cui",
      "Maryam Fazel",
      "Simon S. Du"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.09703"
  },
  {
    "id": "arXiv:2103.00055",
    "title": "Image-Based Trajectory Tracking through Unknown Environments without  Absolute Positioning",
    "abstract": "Comments: to be published in IEEE/ASME Transactions on Mechatronics",
    "descriptor": "\nComments: to be published in IEEE/ASME Transactions on Mechatronics\n",
    "authors": [
      "Shiyu Feng",
      "Zixuan Wu",
      "Yipu Zhao",
      "Patricio A. Vela"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2103.00055"
  },
  {
    "id": "arXiv:2103.00306",
    "title": "Checking the admissibility of odd-vertex pairings is hard",
    "abstract": "Checking the admissibility of odd-vertex pairings is hard",
    "descriptor": "",
    "authors": [
      "Florian H\u00f6rsch"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2103.00306"
  },
  {
    "id": "arXiv:2103.09118",
    "title": "Balancing Biases and Preserving Privacy on Balanced Faces in the Wild",
    "abstract": "Balancing Biases and Preserving Privacy on Balanced Faces in the Wild",
    "descriptor": "",
    "authors": [
      "Joseph P Robinson",
      "Can Qin",
      "Yann Henon",
      "Samson Timoner",
      "Yun Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.09118"
  },
  {
    "id": "arXiv:2103.11102",
    "title": "Projection-free Distributed Online Learning with Sublinear Communication  Complexity",
    "abstract": "Comments: This version was submitted to JMLR on November 23, 2021",
    "descriptor": "\nComments: This version was submitted to JMLR on November 23, 2021\n",
    "authors": [
      "Yuanyu Wan",
      "Guanghui Wang",
      "Wei-Wei Tu",
      "Lijun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.11102"
  },
  {
    "id": "arXiv:2104.10548",
    "title": "A note on some information-theoretic divergences between Zeta  distributions",
    "abstract": "Comments: 12 pages, 1 table, 1 figure",
    "descriptor": "\nComments: 12 pages, 1 table, 1 figure\n",
    "authors": [
      "Frank Nielsen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2104.10548"
  },
  {
    "id": "arXiv:2104.14895",
    "title": "On the Undesired Equilibria Induced by Control Barrier Function Based  Quadratic Programs",
    "abstract": "Comments: Submitted for review at Automatica",
    "descriptor": "\nComments: Submitted for review at Automatica\n",
    "authors": [
      "Xiao Tan",
      "Dimos V. Dimarogonas"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2104.14895"
  },
  {
    "id": "arXiv:2105.11335",
    "title": "Low-Rank Hankel Tensor Completion for Traffic Speed Estimation",
    "abstract": "Low-Rank Hankel Tensor Completion for Traffic Speed Estimation",
    "descriptor": "",
    "authors": [
      "Xudong Wang",
      "Yuankai Wu",
      "Dingyi Zhuang",
      "Lijun Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.11335"
  },
  {
    "id": "arXiv:2106.02886",
    "title": "Context-Aware Sparse Deep Coordination Graphs",
    "abstract": "Context-Aware Sparse Deep Coordination Graphs",
    "descriptor": "",
    "authors": [
      "Tonghan Wang",
      "Liang Zeng",
      "Weijun Dong",
      "Qianlan Yang",
      "Yang Yu",
      "Chongjie Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02886"
  },
  {
    "id": "arXiv:2106.06685",
    "title": "Adversarial Robustness via Fisher-Rao Regularization",
    "abstract": "Comments: IEEE Transactions on Pattern Analysis and Machine Intelligence (Early Access)",
    "descriptor": "\nComments: IEEE Transactions on Pattern Analysis and Machine Intelligence (Early Access)\n",
    "authors": [
      "Marine Picot",
      "Francisco Messina",
      "Malik Boudiaf",
      "Fabrice Labeau",
      "Ismail Ben Ayed",
      "Pablo Piantanida"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.06685"
  },
  {
    "id": "arXiv:2106.09028",
    "title": "Exponential Error Convergence in Data Classification with Optimized  Random Features: Acceleration by Quantum Machine Learning",
    "abstract": "Comments: 42 pages, no figure",
    "descriptor": "\nComments: 42 pages, no figure\n",
    "authors": [
      "Hayata Yamasaki",
      "Sho Sonoda"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.09028"
  },
  {
    "id": "arXiv:2106.14049",
    "title": "Identifying High Accuracy Regions in Traffic Camera Images to Enhance  the Estimation of Road Traffic Metrics: A Quadtree-Based Method",
    "abstract": "Comments: Transportation Research Record (2022)",
    "descriptor": "\nComments: Transportation Research Record (2022)\n",
    "authors": [
      "Yue Lin",
      "Ningchuan Xiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.14049"
  },
  {
    "id": "arXiv:2107.00630",
    "title": "Variational Diffusion Models",
    "abstract": "Comments: Published at NeurIPS'21. Camera-ready version, with code URL",
    "descriptor": "\nComments: Published at NeurIPS'21. Camera-ready version, with code URL\n",
    "authors": [
      "Diederik P. Kingma",
      "Tim Salimans",
      "Ben Poole",
      "Jonathan Ho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.00630"
  },
  {
    "id": "arXiv:2107.06263",
    "title": "CMT: Convolutional Neural Networks Meet Vision Transformers",
    "abstract": "Comments: Accepted in CVPR 2022",
    "descriptor": "\nComments: Accepted in CVPR 2022\n",
    "authors": [
      "Jianyuan Guo",
      "Kai Han",
      "Han Wu",
      "Yehui Tang",
      "Xinghao Chen",
      "Yunhe Wang",
      "Chang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.06263"
  },
  {
    "id": "arXiv:2108.02235",
    "title": "Dynamic Relevance Learning for Few-Shot Object Detection",
    "abstract": "Comments: 12 pages, 8 figures, 7 tables, submitted to IEEE Transactions on Neural Networks and Learning Systems",
    "descriptor": "\nComments: 12 pages, 8 figures, 7 tables, submitted to IEEE Transactions on Neural Networks and Learning Systems\n",
    "authors": [
      "Weijie Liu",
      "Chong Wang",
      "Haohe Li",
      "Shenghao Yu",
      "Jiangbo Qian",
      "Jun Wang",
      "Jiafei Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.02235"
  },
  {
    "id": "arXiv:2108.04303",
    "title": "Canonical Noise Distributions and Private Hypothesis Tests",
    "abstract": "Comments: 25 pages + references and appendix. 4 figues",
    "descriptor": "\nComments: 25 pages + references and appendix. 4 figues\n",
    "authors": [
      "Jordan Awan",
      "Salil Vadhan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2108.04303"
  },
  {
    "id": "arXiv:2108.04416",
    "title": "Improved Parallel Algorithm for Minimum Cost Submodular Cover Problem",
    "abstract": "Comments: Our paper has been accepted to 35th Annual Conference on Learning Theory",
    "descriptor": "\nComments: Our paper has been accepted to 35th Annual Conference on Learning Theory\n",
    "authors": [
      "Yingli Ran",
      "Zhao Zhang",
      "Shaojie Tang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2108.04416"
  },
  {
    "id": "arXiv:2109.00643",
    "title": "Using Temperature Sensitivity to Estimate Shiftable Electricity Demand:  Implications for power system investments and climate change",
    "abstract": "Comments: 23 pages, plus 16 pages supplement, 4 figures, 1 table, plus supplementary tables and figures",
    "descriptor": "\nComments: 23 pages, plus 16 pages supplement, 4 figures, 1 table, plus supplementary tables and figures\n",
    "authors": [
      "Michael J. Roberts",
      "Sisi Zhang",
      "Eleanor Yuan",
      "James Jones",
      "Matthias Fripp"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "General Economics (econ.GN)"
    ],
    "url": "https://arxiv.org/abs/2109.00643"
  },
  {
    "id": "arXiv:2109.02494",
    "title": "Stable Gabor phase retrieval in Gaussian shift-invariant spaces via  biorthogonality",
    "abstract": "Comments: 44 pages, 9 figures",
    "descriptor": "\nComments: 44 pages, 9 figures\n",
    "authors": [
      "Philipp Grohs",
      "Lukas Liehr"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.02494"
  },
  {
    "id": "arXiv:2109.06709",
    "title": "QKD parameter estimation by two-universal hashing",
    "abstract": "QKD parameter estimation by two-universal hashing",
    "descriptor": "",
    "authors": [
      "Dimiter Ostrev"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2109.06709"
  },
  {
    "id": "arXiv:2109.07767",
    "title": "Gaussian Broadcast Channels under Heterogeneous Blocklength Constraints",
    "abstract": "Comments: 5 figures, submitted to IEEE TCOM",
    "descriptor": "\nComments: 5 figures, submitted to IEEE TCOM\n",
    "authors": [
      "Pin-Hsun Lin",
      "Shih-Chun Lin",
      "Peng-Wei Chen",
      "Marcel Mross",
      "Eduard A. Jorswieck"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2109.07767"
  },
  {
    "id": "arXiv:2109.09808",
    "title": "Integrated Construction of Multimodal Atlases with Structural  Connectomes in the Space of Riemannian Metrics",
    "abstract": "Comments: Accepted for publication at the Journal of Machine Learning for Biomedical Imaging (MELBA) this https URL arXiv admin note: substantial text overlap with arXiv:2103.05730",
    "descriptor": "\nComments: Accepted for publication at the Journal of Machine Learning for Biomedical Imaging (MELBA) this https URL arXiv admin note: substantial text overlap with arXiv:2103.05730\n",
    "authors": [
      "Kristen M. Campbell",
      "Haocheng Dai",
      "Zhe Su",
      "Martin Bauer",
      "P. Thomas Fletcher",
      "Sarang C. Joshi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.09808"
  },
  {
    "id": "arXiv:2109.09818",
    "title": "Skin Deep Unlearning: Artefact and Instrument Debiasing in the Context  of Melanoma Classification",
    "abstract": "Comments: 9 pages, accepted to ICML 2022",
    "descriptor": "\nComments: 9 pages, accepted to ICML 2022\n",
    "authors": [
      "Peter J. Bevan",
      "Amir Atapour-Abarghouei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.09818"
  },
  {
    "id": "arXiv:2109.12581",
    "title": "A Stacking Ensemble Approach for Supervised Video Summarization",
    "abstract": "A Stacking Ensemble Approach for Supervised Video Summarization",
    "descriptor": "",
    "authors": [
      "Yubo An",
      "Shenghui Zhao",
      "Guoqiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2109.12581"
  },
  {
    "id": "arXiv:2110.01528",
    "title": "Large Batch Experience Replay",
    "abstract": "Comments: 24 pages, 12 figures, ICML 2022 - long presentation",
    "descriptor": "\nComments: 24 pages, 12 figures, ICML 2022 - long presentation\n",
    "authors": [
      "Thibault Lahire",
      "Matthieu Geist",
      "Emmanuel Rachelson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.01528"
  },
  {
    "id": "arXiv:2110.01833",
    "title": "Hierarchical Primitive Composition: Simultaneous Activation of Skills  with Inconsistent Action Dimensions in Multiple Hierarchies",
    "abstract": "Comments: Accepted to RAL-IROS 2022",
    "descriptor": "\nComments: Accepted to RAL-IROS 2022\n",
    "authors": [
      "Jeong-Hoon Lee",
      "Jongeun Choi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.01833"
  },
  {
    "id": "arXiv:2110.02027",
    "title": "ProGCL: Rethinking Hard Negative Mining in Graph Contrastive Learning",
    "abstract": "Comments: Accetpted at ICML 2022",
    "descriptor": "\nComments: Accetpted at ICML 2022\n",
    "authors": [
      "Jun Xia",
      "Lirong Wu",
      "Ge Wang",
      "Jintao Chen",
      "Stan Z.Li"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.02027"
  },
  {
    "id": "arXiv:2110.04828",
    "title": "FLAME: Facial Landmark Heatmap Activated Multimodal Gaze Estimation",
    "abstract": "Comments: Preprint. Final paper accepted at the 17th IEEE International Conference on Advanced Video and Signal-based Surveillance, AVSS 2021, Virtual, November 16-19, 2021. 8 pages",
    "descriptor": "\nComments: Preprint. Final paper accepted at the 17th IEEE International Conference on Advanced Video and Signal-based Surveillance, AVSS 2021, Virtual, November 16-19, 2021. 8 pages\n",
    "authors": [
      "Neelabh Sinha",
      "Michal Balazia",
      "Francois Bremond"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04828"
  },
  {
    "id": "arXiv:2110.07037",
    "title": "Solving multiscale steady radiative transfer equation using neural  networks with uniform stability",
    "abstract": "Solving multiscale steady radiative transfer equation using neural  networks with uniform stability",
    "descriptor": "",
    "authors": [
      "Yulong Lu",
      "Li Wang",
      "Wuzhe Xu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.07037"
  },
  {
    "id": "arXiv:2110.09712",
    "title": "Realistic Actor-Critic: A Framework for Balance Between Value  Overestimation and Underestimation",
    "abstract": "Comments: This work has been submitted to the Springer for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the Springer for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Sicen Li",
      "Qinyun Tang",
      "Yiming Pang",
      "Xinmeng Ma",
      "Gang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09712"
  },
  {
    "id": "arXiv:2110.11309",
    "title": "Fast Model Editing at Scale",
    "abstract": "Comments: ICLR 2022. View implementation and additional project info at this https URL",
    "descriptor": "\nComments: ICLR 2022. View implementation and additional project info at this https URL\n",
    "authors": [
      "Eric Mitchell",
      "Charles Lin",
      "Antoine Bosselut",
      "Chelsea Finn",
      "Christopher D. Manning"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.11309"
  },
  {
    "id": "arXiv:2110.13389",
    "title": "A Normalized Gaussian Wasserstein Distance for Tiny Object Detection",
    "abstract": "Comments: Codes are available at: this https URL Its expanded work is accepted by the ISPRS J P & RS (this https URL)",
    "descriptor": "\nComments: Codes are available at: this https URL Its expanded work is accepted by the ISPRS J P & RS (this https URL)\n",
    "authors": [
      "Jinwang Wang",
      "Chang Xu",
      "Wen Yang",
      "Lei Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.13389"
  },
  {
    "id": "arXiv:2110.14109",
    "title": "Eigencurve: Optimal Learning Rate Schedule for SGD on Quadratic  Objectives with Skewed Hessian Spectrums",
    "abstract": "Comments: Published at ICLR 2022",
    "descriptor": "\nComments: Published at ICLR 2022\n",
    "authors": [
      "Rui Pan",
      "Haishan Ye",
      "Tong Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.14109"
  },
  {
    "id": "arXiv:2110.14968",
    "title": "DocScanner: Robust Document Image Rectification with Progressive  Learning",
    "abstract": "DocScanner: Robust Document Image Rectification with Progressive  Learning",
    "descriptor": "",
    "authors": [
      "Hao Feng",
      "Wengang Zhou",
      "Jiajun Deng",
      "Qi Tian",
      "Houqiang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.14968"
  },
  {
    "id": "arXiv:2110.15165",
    "title": "Extracting Expert's Goals by What-if Interpretable Modeling",
    "abstract": "Extracting Expert's Goals by What-if Interpretable Modeling",
    "descriptor": "",
    "authors": [
      "Chun-Hao Chang",
      "George Alexandru Adam",
      "Rich Caruana",
      "Anna Goldenberg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15165"
  },
  {
    "id": "arXiv:2111.00242",
    "title": "Self-Supervised Speech Denoising Using Only Noisy Audio Signals",
    "abstract": "Comments: 5 pages, 3 figures, 2 tables",
    "descriptor": "\nComments: 5 pages, 3 figures, 2 tables\n",
    "authors": [
      "Jiasong Wu",
      "Qingchun Li",
      "Guanyu Yang",
      "Lotfi Senhadji",
      "Huazhong Shu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2111.00242"
  },
  {
    "id": "arXiv:2111.01983",
    "title": "Obvious Manipulability of Voting Rules",
    "abstract": "Obvious Manipulability of Voting Rules",
    "descriptor": "",
    "authors": [
      "Haris Aziz",
      "Alexander Lam"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2111.01983"
  },
  {
    "id": "arXiv:2111.04878",
    "title": "Automated generation of 0D and 1D reduced-order models of  patient-specific blood flow",
    "abstract": "Automated generation of 0D and 1D reduced-order models of  patient-specific blood flow",
    "descriptor": "",
    "authors": [
      "Martin R. Pfaller",
      "Jonathan Pham",
      "Aekaansh Verma",
      "Luca Pegolotti",
      "Nathan M. Wilson",
      "David W. Parker",
      "Weiguang Yang",
      "Alison L. Marsden"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2111.04878"
  },
  {
    "id": "arXiv:2111.07941",
    "title": "Distribution Compression in Near-linear Time",
    "abstract": "Comments: Accepted to ICLR 2022; An outdated proof of Theorem 2 was previously included in the appendix; this oversight is corrected in this version",
    "descriptor": "\nComments: Accepted to ICLR 2022; An outdated proof of Theorem 2 was previously included in the appendix; this oversight is corrected in this version\n",
    "authors": [
      "Abhishek Shetty",
      "Raaz Dwivedi",
      "Lester Mackey"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2111.07941"
  },
  {
    "id": "arXiv:2111.08500",
    "title": "Patent Data for Engineering Design: A Critical Review and Future  Directions",
    "abstract": "Comments: Accepted by JCISE",
    "descriptor": "\nComments: Accepted by JCISE\n",
    "authors": [
      "Shuo Jiang",
      "Serhad Sarica",
      "Binyang Song",
      "Jie Hu",
      "Jianxi Luo"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.08500"
  },
  {
    "id": "arXiv:2111.09515",
    "title": "Range-Aware Attention Network for LiDAR-based 3D Object Detection with  Auxiliary Point Density Level Estimation",
    "abstract": "Range-Aware Attention Network for LiDAR-based 3D Object Detection with  Auxiliary Point Density Level Estimation",
    "descriptor": "",
    "authors": [
      "Yantao Lu",
      "Xuetao Hao",
      "Yilan Li",
      "Weiheng Chai",
      "Shiqi Sun",
      "Senem Velipasalar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.09515"
  },
  {
    "id": "arXiv:2111.09571",
    "title": "Person Re-identification Method Based on Color Attack and Joint Defence",
    "abstract": "Comments: Accepted by CVPR2022 Workshops (this https URL)",
    "descriptor": "\nComments: Accepted by CVPR2022 Workshops (this https URL)\n",
    "authors": [
      "Yunpeng Gong",
      "Liqing Huang",
      "Lifei Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.09571"
  },
  {
    "id": "arXiv:2112.02874",
    "title": "Parametric Channel Estimation for LoS Dominated Holographic Massive MIMO  Systems",
    "abstract": "Comments: 30 pages, 10 figures",
    "descriptor": "\nComments: 30 pages, 10 figures\n",
    "authors": [
      "Mojtaba Ghermezcheshmeh",
      "Vahid Jamali",
      "Haris Gacanin",
      "Nikola Zlatanov"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.02874"
  },
  {
    "id": "arXiv:2112.04643",
    "title": "Autoregressive Quantile Flows for Predictive Uncertainty Estimation",
    "abstract": "Comments: 9 pages, 4 figures, 6 tables (main body) additional 5 pages, 3 figures, 5 tables (appendix)",
    "descriptor": "\nComments: 9 pages, 4 figures, 6 tables (main body) additional 5 pages, 3 figures, 5 tables (appendix)\n",
    "authors": [
      "Phillip Si",
      "Allan Bishop",
      "Volodymyr Kuleshov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.04643"
  },
  {
    "id": "arXiv:2112.05120",
    "title": "On Convergence of Federated Averaging Langevin Dynamics",
    "abstract": "On Convergence of Federated Averaging Langevin Dynamics",
    "descriptor": "",
    "authors": [
      "Wei Deng",
      "Qian Zhang",
      "Yi-An Ma",
      "Zhao Song",
      "Guang Lin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.05120"
  },
  {
    "id": "arXiv:2112.05261",
    "title": "Equivariant Quantum Graph Circuits",
    "abstract": "Comments: To be presented at ICML 2022 - uploading camera-ready version",
    "descriptor": "\nComments: To be presented at ICML 2022 - uploading camera-ready version\n",
    "authors": [
      "P\u00e9ter Mernyei",
      "Konstantinos Meichanetzidis",
      "\u0130smail \u0130lkan Ceylan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.05261"
  },
  {
    "id": "arXiv:2112.09655",
    "title": "Distillation of RL Policies with Formal Guarantees via Variational  Abstraction of Markov Decision Processes (Technical Report)",
    "abstract": "Comments: AAAI 2022, technical report including supplementary material (10 pages main text, 14 pages appendix)",
    "descriptor": "\nComments: AAAI 2022, technical report including supplementary material (10 pages main text, 14 pages appendix)\n",
    "authors": [
      "Florent Delgrange",
      "Ann Now\u00e9",
      "Guillermo A. P\u00e9rez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.09655"
  },
  {
    "id": "arXiv:2112.09988",
    "title": "Smooth Model Predictive Path Integral Control without Smoothing",
    "abstract": "Comments: Our video can be found at this https URL",
    "descriptor": "\nComments: Our video can be found at this https URL\n",
    "authors": [
      "Taekyung Kim",
      "Gyuhyun Park",
      "Kiho Kwak",
      "Jihwan Bae",
      "Wonsuk Lee"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.09988"
  },
  {
    "id": "arXiv:2112.10844",
    "title": "Encoding Hierarchical Information in Neural Networks helps in  Subpopulation Shift",
    "abstract": "Comments: 15 pages, 7 figures",
    "descriptor": "\nComments: 15 pages, 7 figures\n",
    "authors": [
      "Amitangshu Mukherjee",
      "Isha Garg",
      "Kaushik Roy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.10844"
  },
  {
    "id": "arXiv:2112.13610",
    "title": "CUGE: A Chinese Language Understanding and Generation Evaluation  Benchmark",
    "abstract": "Comments: We add two new datasets, including grammatical error correction dataset YACLC from Beijing Language and Culture University, and reading comprehension dataset GCRC from Shanxi University, and also improve the description consistency of all datasets",
    "descriptor": "\nComments: We add two new datasets, including grammatical error correction dataset YACLC from Beijing Language and Culture University, and reading comprehension dataset GCRC from Shanxi University, and also improve the description consistency of all datasets\n",
    "authors": [
      "Yuan Yao",
      "Qingxiu Dong",
      "Jian Guan",
      "Boxi Cao",
      "Zhengyan Zhang",
      "Chaojun Xiao",
      "Xiaozhi Wang",
      "Fanchao Qi",
      "Junwei Bao",
      "Jinran Nie",
      "Zheni Zeng",
      "Yuxian Gu",
      "Kun Zhou",
      "Xuancheng Huang",
      "Wenhao Li",
      "Shuhuai Ren",
      "Jinliang Lu",
      "Chengqiang Xu",
      "Huadong Wang",
      "Guoyang Zeng",
      "Zile Zhou",
      "Jiajun Zhang",
      "Juanzi Li",
      "Minlie Huang",
      "Rui Yan",
      "Xiaodong He",
      "Xiaojun Wan",
      "Xin Zhao",
      "Xu Sun",
      "Yang Liu",
      "Zhiyuan Liu",
      "Xianpei Han",
      "Erhong Yang",
      "Zhifang Sui",
      "Maosong Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.13610"
  },
  {
    "id": "arXiv:2112.15099",
    "title": "KIND: an Italian Multi-Domain Dataset for Named Entity Recognition",
    "abstract": "KIND: an Italian Multi-Domain Dataset for Named Entity Recognition",
    "descriptor": "",
    "authors": [
      "Teresa Paccosi",
      "Alessio Palmero Aprosio"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.15099"
  },
  {
    "id": "arXiv:2201.01840",
    "title": "A Theoretically Novel Trade-off for Sparse Secret-key Generation",
    "abstract": "A Theoretically Novel Trade-off for Sparse Secret-key Generation",
    "descriptor": "",
    "authors": [
      "Makan Zamanipour"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.01840"
  },
  {
    "id": "arXiv:2201.01841",
    "title": "Cyber-Physical-Systems and Secrecy Outage Probability: Revisited",
    "abstract": "Cyber-Physical-Systems and Secrecy Outage Probability: Revisited",
    "descriptor": "",
    "authors": [
      "Makan Zamanipour"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.01841"
  },
  {
    "id": "arXiv:2201.01842",
    "title": "Adversarial Robustness in Cognitive Radio Networks",
    "abstract": "Adversarial Robustness in Cognitive Radio Networks",
    "descriptor": "",
    "authors": [
      "Makan Zamanipour"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2201.01842"
  },
  {
    "id": "arXiv:2201.03201",
    "title": "Fusing Blockchain and AI with Metaverse: A Survey",
    "abstract": "Fusing Blockchain and AI with Metaverse: A Survey",
    "descriptor": "",
    "authors": [
      "Qinglin Yang",
      "Yetong Zhao",
      "Huawei Huang",
      "Zehui Xiong",
      "Jiawen Kang",
      "Zibin Zheng"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2201.03201"
  },
  {
    "id": "arXiv:2201.05431",
    "title": "Molecular Noise In Synaptic Communication",
    "abstract": "Comments: 16 pages, 13 figures, 2 tables. Accepted for publication in the IEEE Transactions on NanoBioscience. This article is the extended journal version of the conference paper arXiv:2109.14986",
    "descriptor": "\nComments: 16 pages, 13 figures, 2 tables. Accepted for publication in the IEEE Transactions on NanoBioscience. This article is the extended journal version of the conference paper arXiv:2109.14986\n",
    "authors": [
      "Sebastian Lotter",
      "Maximilian Sch\u00e4fer",
      "Robert Schober"
    ],
    "subjectives": [
      "Subcellular Processes (q-bio.SC)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2201.05431"
  },
  {
    "id": "arXiv:2201.06061",
    "title": "PETS-SWINF: A regression method that considers images with metadata  based Neural Network for pawpularity prediction on 2021 Kaggle Competition  \"PetFinder.my\"",
    "abstract": "Comments: 8 pages, 10 figures",
    "descriptor": "\nComments: 8 pages, 10 figures\n",
    "authors": [
      "Yizheng Wang",
      "Yinghua Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.06061"
  },
  {
    "id": "arXiv:2201.06628",
    "title": "Predicting waves in fluids with deep neural network",
    "abstract": "Comments: 24 pages",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Indu Kant Deo",
      "Rajeev Jaiman"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.06628"
  },
  {
    "id": "arXiv:2201.09932",
    "title": "Learning Optimal Fair Classification Trees",
    "abstract": "Learning Optimal Fair Classification Trees",
    "descriptor": "",
    "authors": [
      "Nathanael Jo",
      "Sina Aghaei",
      "Jack Benson",
      "Andr\u00e9s G\u00f3mez",
      "Phebe Vayanos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2201.09932"
  },
  {
    "id": "arXiv:2201.11903",
    "title": "Chain of Thought Prompting Elicits Reasoning in Large Language Models",
    "abstract": "Chain of Thought Prompting Elicits Reasoning in Large Language Models",
    "descriptor": "",
    "authors": [
      "Jason Wei",
      "Xuezhi Wang",
      "Dale Schuurmans",
      "Maarten Bosma",
      "Brian Ichter",
      "Fei Xia",
      "Ed Chi",
      "Quoc Le",
      "Denny Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11903"
  },
  {
    "id": "arXiv:2202.00449",
    "title": "A Consistent and Efficient Evaluation Strategy for Attribution Methods",
    "abstract": "Comments: 26 pages. Accepted at ICML 2022",
    "descriptor": "\nComments: 26 pages. Accepted at ICML 2022\n",
    "authors": [
      "Yao Rong",
      "Tobias Leemann",
      "Vadim Borisov",
      "Gjergji Kasneci",
      "Enkelejda Kasneci"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00449"
  },
  {
    "id": "arXiv:2202.03377",
    "title": "Benchmarking and Analyzing Point Cloud Classification under Corruptions",
    "abstract": "Comments: ICML 2022; Code and dataset are available at this https URL",
    "descriptor": "\nComments: ICML 2022; Code and dataset are available at this https URL\n",
    "authors": [
      "Jiawei Ren",
      "Liang Pan",
      "Ziwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03377"
  },
  {
    "id": "arXiv:2202.04165",
    "title": "Instantaneous and limiting behavior of an n-node blockchain under cyber  attacks from a single hacker",
    "abstract": "Instantaneous and limiting behavior of an n-node blockchain under cyber  attacks from a single hacker",
    "descriptor": "",
    "authors": [
      "Xiufeng Xu",
      "Liang Hong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Optimization and Control (math.OC)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2202.04165"
  },
  {
    "id": "arXiv:2202.04732",
    "title": "Online Learning to Transport via the Minimal Selection Principle",
    "abstract": "Comments: 23 pages",
    "descriptor": "\nComments: 23 pages\n",
    "authors": [
      "Wenxuan Guo",
      "YoonHaeng Hur",
      "Tengyuan Liang",
      "Christopher Ryan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.04732"
  },
  {
    "id": "arXiv:2202.05587",
    "title": "Formal verification of iterative convergence of numerical algorithms",
    "abstract": "Formal verification of iterative convergence of numerical algorithms",
    "descriptor": "",
    "authors": [
      "Mohit Tekriwal",
      "Joshua Miller",
      "Jean-Baptiste Jeannin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.05587"
  },
  {
    "id": "arXiv:2202.06526",
    "title": "Benign Overfitting in Two-layer Convolutional Neural Networks",
    "abstract": "Comments: 42 pages, 1 figure. Version 3 improves the presentation and adds a comparison with a concurrent work",
    "descriptor": "\nComments: 42 pages, 1 figure. Version 3 improves the presentation and adds a comparison with a concurrent work\n",
    "authors": [
      "Yuan Cao",
      "Zixiang Chen",
      "Mikhail Belkin",
      "Quanquan Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.06526"
  },
  {
    "id": "arXiv:2202.06875",
    "title": "Visual Acoustic Matching",
    "abstract": "Comments: Project page: this https URL Accepted at CVPR 2022",
    "descriptor": "\nComments: Project page: this https URL Accepted at CVPR 2022\n",
    "authors": [
      "Changan Chen",
      "Ruohan Gao",
      "Paul Calamia",
      "Kristen Grauman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.06875"
  },
  {
    "id": "arXiv:2202.07707",
    "title": "On the Role of Channel Capacity in Learning Gaussian Mixture Models",
    "abstract": "Comments: COLT 2022",
    "descriptor": "\nComments: COLT 2022\n",
    "authors": [
      "Elad Romanov",
      "Tamir Bendory",
      "Or Ordentlich"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.07707"
  },
  {
    "id": "arXiv:2202.07765",
    "title": "General-purpose, long-context autoregressive modeling with Perceiver AR",
    "abstract": "Comments: ICML 2022",
    "descriptor": "\nComments: ICML 2022\n",
    "authors": [
      "Curtis Hawthorne",
      "Andrew Jaegle",
      "C\u0103t\u0103lina Cangea",
      "Sebastian Borgeaud",
      "Charlie Nash",
      "Mateusz Malinowski",
      "Sander Dieleman",
      "Oriol Vinyals",
      "Matthew Botvinick",
      "Ian Simon",
      "Hannah Sheahan",
      "Neil Zeghidour",
      "Jean-Baptiste Alayrac",
      "Jo\u00e3o Carreira",
      "Jesse Engel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.07765"
  },
  {
    "id": "arXiv:2202.07919",
    "title": "HousE: Knowledge Graph Embedding with Householder Parameterization",
    "abstract": "Comments: accepted by ICML 2022",
    "descriptor": "\nComments: accepted by ICML 2022\n",
    "authors": [
      "Rui Li",
      "Jianan Zhao",
      "Chaozhuo Li",
      "Di He",
      "Yiqi Wang",
      "Yuming Liu",
      "Hao Sun",
      "Senzhang Wang",
      "Weiwei Deng",
      "Yanming Shen",
      "Xing Xie",
      "Qi Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.07919"
  },
  {
    "id": "arXiv:2202.10574",
    "title": "A Multi-Agent Reinforcement Learning Framework for Off-Policy Evaluation  in Two-sided Markets",
    "abstract": "A Multi-Agent Reinforcement Learning Framework for Off-Policy Evaluation  in Two-sided Markets",
    "descriptor": "",
    "authors": [
      "Chengchun Shi",
      "Runzhe Wan",
      "Ge Song",
      "Shikai Luo",
      "Rui Song",
      "Hongtu Zhu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.10574"
  },
  {
    "id": "arXiv:2202.12396",
    "title": "Finite-Sum Coupled Compositional Stochastic Optimization: Theory and  Applications",
    "abstract": "Comments: ICML 2022",
    "descriptor": "\nComments: ICML 2022\n",
    "authors": [
      "Bokun Wang",
      "Tianbao Yang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12396"
  },
  {
    "id": "arXiv:2202.13367",
    "title": "Age Optimal Sampling Under Unknown Delay Statistics",
    "abstract": "Comments: Fix typos and wrong proofs; Add discussions about the independent work",
    "descriptor": "\nComments: Fix typos and wrong proofs; Add discussions about the independent work\n",
    "authors": [
      "Haoyue Tang",
      "Yuchao Chen",
      "Jintao Wang",
      "Pengkun Yang",
      "Leandros Tassiulas"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.13367"
  },
  {
    "id": "arXiv:2203.01157",
    "title": "Artificial Concepts of Artificial Intelligence: Institutional Compliance  and Resistance in AI Startups",
    "abstract": "Artificial Concepts of Artificial Intelligence: Institutional Compliance  and Resistance in AI Startups",
    "descriptor": "",
    "authors": [
      "Amy A. Winecoff",
      "Elizabeth Anne Watkins"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.01157"
  },
  {
    "id": "arXiv:2203.03319",
    "title": "Few Induced Disjoint Paths for $H$-Free Graphs",
    "abstract": "Few Induced Disjoint Paths for $H$-Free Graphs",
    "descriptor": "",
    "authors": [
      "Barnaby Martin",
      "Dani\u00ebl Paulusma",
      "Siani Smith",
      "Erik Jan van Leeuwen"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2203.03319"
  },
  {
    "id": "arXiv:2203.06803",
    "title": "Learning Markov Games with Adversarial Opponents: Efficient Algorithms  and Fundamental Limits",
    "abstract": "Comments: fix typos and add additional reference",
    "descriptor": "\nComments: fix typos and add additional reference\n",
    "authors": [
      "Qinghua Liu",
      "Yuanhao Wang",
      "Chi Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.06803"
  },
  {
    "id": "arXiv:2203.09175",
    "title": "Generalized Classification of Satellite Image Time Series with Thermal  Positional Encoding",
    "abstract": "Comments: In proceedings of the 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops",
    "descriptor": "\nComments: In proceedings of the 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops\n",
    "authors": [
      "Joachim Nyborg",
      "Charlotte Pelletier",
      "Ira Assent"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.09175"
  },
  {
    "id": "arXiv:2203.11470",
    "title": "Safety of Sampled-Data Systems with Control Barrier Functions via  Approximate Discrete Time Models",
    "abstract": "Comments: 8 pages, 4 figures, submitted to 2022 Conference on Decision & Control (CDC)",
    "descriptor": "\nComments: 8 pages, 4 figures, submitted to 2022 Conference on Decision & Control (CDC)\n",
    "authors": [
      "Andrew J. Taylor",
      "Victor D. Dorobantu",
      "Ryan K. Cosner",
      "Yisong Yue",
      "Aaron D. Ames"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.11470"
  },
  {
    "id": "arXiv:2203.14261",
    "title": "The Lattice-Theoretic Essence of PropertyDirected Reachability Analysis",
    "abstract": "Comments: 37 pages",
    "descriptor": "\nComments: 37 pages\n",
    "authors": [
      "Mayuko Kori",
      "Natsuki Urabe",
      "Shin-ya Katsumata",
      "Kohei Suenaga",
      "Ichiro Hasuo"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2203.14261"
  },
  {
    "id": "arXiv:2204.03113",
    "title": "P4BID: Information Flow Control in P4",
    "abstract": "P4BID: Information Flow Control in P4",
    "descriptor": "",
    "authors": [
      "Karuna Grewal",
      "Loris D'Antoni",
      "Justin Hsu"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2204.03113"
  },
  {
    "id": "arXiv:2204.04187",
    "title": "A Low-Cost Robot Science Kit for Education with Symbolic Regression for  Hypothesis Discovery and Validation",
    "abstract": "A Low-Cost Robot Science Kit for Education with Symbolic Regression for  Hypothesis Discovery and Validation",
    "descriptor": "",
    "authors": [
      "Logan Saar",
      "Haotong Liang",
      "Alex Wang",
      "Austin McDannald",
      "Efrain Rodriguez",
      "Ichiro Takeuchi",
      "A. Gilad Kusne"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.04187"
  },
  {
    "id": "arXiv:2204.04501",
    "title": "Explain yourself! Effects of Explanations in Human-Robot Interaction",
    "abstract": "Comments: Accepted at 2022 31st IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)",
    "descriptor": "\nComments: Accepted at 2022 31st IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)\n",
    "authors": [
      "Jakob Ambsdorf",
      "Alina Munir",
      "Yiyao Wei",
      "Klaas Degkwitz",
      "Harm Matthias Harms",
      "Susanne Stannek",
      "Kyra Ahrens",
      "Dennis Becker",
      "Erik Strahl",
      "Tom Weber",
      "Stefan Wermter"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04501"
  },
  {
    "id": "arXiv:2204.05381",
    "title": "Self-supervised Vision Transformers for Joint SAR-optical Representation  Learning",
    "abstract": "Comments: 4 pages, 1 figure; IGARSS 2022",
    "descriptor": "\nComments: 4 pages, 1 figure; IGARSS 2022\n",
    "authors": [
      "Yi Wang",
      "Conrad M Albrecht",
      "Xiao Xiang Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.05381"
  },
  {
    "id": "arXiv:2204.05515",
    "title": "CLMLF:A Contrastive Learning and Multi-Layer Fusion Method for  Multimodal Sentiment Detection",
    "abstract": "Comments: Accepted to Findings of NAACL 2022",
    "descriptor": "\nComments: Accepted to Findings of NAACL 2022\n",
    "authors": [
      "Zhen Li",
      "Bing Xu",
      "Conghui Zhu",
      "Tiejun Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.05515"
  },
  {
    "id": "arXiv:2204.06364",
    "title": "Mitigating Bias in Facial Analysis Systems by Incorporating Label  Diversity",
    "abstract": "Mitigating Bias in Facial Analysis Systems by Incorporating Label  Diversity",
    "descriptor": "",
    "authors": [
      "Camila Kolling",
      "Victor Araujo",
      "Adriano Veloso",
      "Soraia Raupp Musse"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.06364"
  },
  {
    "id": "arXiv:2204.08945",
    "title": "Missingness Bias in Model Debugging",
    "abstract": "Comments: Published at ICLR 2022",
    "descriptor": "\nComments: Published at ICLR 2022\n",
    "authors": [
      "Saachi Jain",
      "Hadi Salman",
      "Eric Wong",
      "Pengchuan Zhang",
      "Vibhav Vineet",
      "Sai Vemprala",
      "Aleksander Madry"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.08945"
  },
  {
    "id": "arXiv:2204.09787",
    "title": "Reinforcement Learning from Partial Observation: Linear Function  Approximation with Provable Sample Efficiency",
    "abstract": "Reinforcement Learning from Partial Observation: Linear Function  Approximation with Provable Sample Efficiency",
    "descriptor": "",
    "authors": [
      "Qi Cai",
      "Zhuoran Yang",
      "Zhaoran Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.09787"
  },
  {
    "id": "arXiv:2204.10511",
    "title": "Keypoint based Sign Language Translation without Glosses",
    "abstract": "Comments: 14 pages, 5 figures",
    "descriptor": "\nComments: 14 pages, 5 figures\n",
    "authors": [
      "Youngmin Kim",
      "Minji Kwak",
      "Dain Lee",
      "Yeongeun Kim",
      "Hyeongboo Baek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.10511"
  },
  {
    "id": "arXiv:2204.12721",
    "title": "Regularized Box-Simplex Games and Dynamic Decremental Bipartite Matching",
    "abstract": "Comments: Accepted at ICALP'22",
    "descriptor": "\nComments: Accepted at ICALP'22\n",
    "authors": [
      "Arun Jambulapati",
      "Yujia Jin",
      "Aaron Sidford",
      "Kevin Tian"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2204.12721"
  },
  {
    "id": "arXiv:2204.13881",
    "title": "Analysis of A New Variable Time-stepping Time Filter Algorithm for The  Unsteady Stokes/Darcy Model",
    "abstract": "Analysis of A New Variable Time-stepping Time Filter Algorithm for The  Unsteady Stokes/Darcy Model",
    "descriptor": "",
    "authors": [
      "Yi Qin",
      "Yang Wang",
      "Yi Li",
      "Jian Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.13881"
  },
  {
    "id": "arXiv:2204.14042",
    "title": "Gathering on an Infinite Triangular Grid with Limited Visibility",
    "abstract": "Gathering on an Infinite Triangular Grid with Limited Visibility",
    "descriptor": "",
    "authors": [
      "Pritam Goswami",
      "Satakshi Ghosh",
      "Avisek Sharma",
      "Buddhadeb Sau"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2204.14042"
  },
  {
    "id": "arXiv:2205.01917",
    "title": "CoCa: Contrastive Captioners are Image-Text Foundation Models",
    "abstract": "Comments: Preprint",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Jiahui Yu",
      "Zirui Wang",
      "Vijay Vasudevan",
      "Legg Yeung",
      "Mojtaba Seyedhosseini",
      "Yonghui Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2205.01917"
  },
  {
    "id": "arXiv:2205.02418",
    "title": "Quasi-SMC based on MPC for a constrained continuous-time nonlinear  system with external disturbances",
    "abstract": "Quasi-SMC based on MPC for a constrained continuous-time nonlinear  system with external disturbances",
    "descriptor": "",
    "authors": [
      "Huan Meng"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.02418"
  },
  {
    "id": "arXiv:2205.02428",
    "title": "ActorRL: A Novel Multi-level Receptive Fields Adversary Reinforcement  Learning for Automoumous Intersection Management",
    "abstract": "ActorRL: A Novel Multi-level Receptive Fields Adversary Reinforcement  Learning for Automoumous Intersection Management",
    "descriptor": "",
    "authors": [
      "Guanzhou Li",
      "Jianping Wu",
      "Yujing He"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.02428"
  },
  {
    "id": "arXiv:2205.02959",
    "title": "Semi-Supervised Imitation Learning of Team Policies from Suboptimal  Demonstrations",
    "abstract": "Comments: Extended version of an identically-titled paper accepted at IJCAI 2022",
    "descriptor": "\nComments: Extended version of an identically-titled paper accepted at IJCAI 2022\n",
    "authors": [
      "Sangwon Seo",
      "Vaibhav V. Unhelkar"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2205.02959"
  },
  {
    "id": "arXiv:2205.03883",
    "title": "WKGM: Weight-K-space Generative Model for Parallel Imaging  Reconstruction",
    "abstract": "Comments: 10pages, 13 figures",
    "descriptor": "\nComments: 10pages, 13 figures\n",
    "authors": [
      "Zongjiang Tu",
      "Die Liu",
      "Xiaoqing Wang",
      "Chen Jiang",
      "Minghui Zhang",
      "Shanshan Wang",
      "Qiegen Liu",
      "Dong Liang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.03883"
  },
  {
    "id": "arXiv:2205.05232",
    "title": "Linear average-case complexity of algorithmic problems in groups",
    "abstract": "Comments: 21 pages",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Alexander Olshanskii",
      "Vladimir Shpilrain"
    ],
    "subjectives": [
      "Group Theory (math.GR)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2205.05232"
  },
  {
    "id": "arXiv:2205.06257",
    "title": "Coded Data Rebalancing for Distributed Data Storage Systems with Cyclic  Storage",
    "abstract": "Comments: 27 pages",
    "descriptor": "\nComments: 27 pages\n",
    "authors": [
      "Athreya Chandramouli",
      "Abhinav Vaishya",
      "Prasad Krishnan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2205.06257"
  },
  {
    "id": "arXiv:2205.07403",
    "title": "PillarNet: Real-Time and High-Performance Pillar-based 3D Object  Detection",
    "abstract": "PillarNet: Real-Time and High-Performance Pillar-based 3D Object  Detection",
    "descriptor": "",
    "authors": [
      "Guangsheng Shi",
      "Ruifeng Li",
      "Chao Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.07403"
  },
  {
    "id": "arXiv:2205.07428",
    "title": "On the Convergence of the Shapley Value in Parametric Bayesian Learning  Games",
    "abstract": "Comments: Accepted to the 39th International Conference on Machine Learning (ICML 2022). Extended version with derivations",
    "descriptor": "\nComments: Accepted to the 39th International Conference on Machine Learning (ICML 2022). Extended version with derivations\n",
    "authors": [
      "Lucas Agussurja",
      "Xinyi Xu",
      "Bryan Kian Hsiang Low"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.07428"
  },
  {
    "id": "arXiv:2205.09015",
    "title": "Ramsey Quantifiers over Automatic Structures: Complexity and  Applications to Verification",
    "abstract": "Ramsey Quantifiers over Automatic Structures: Complexity and  Applications to Verification",
    "descriptor": "",
    "authors": [
      "Pascal Bergstr\u00e4\u00dfer",
      "Moses Ganardi",
      "Anthony W. Lin",
      "Georg Zetzsche"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2205.09015"
  },
  {
    "id": "arXiv:2205.09219",
    "title": "A Classification of $G$-invariant Shallow Neural Networks",
    "abstract": "Comments: 29 pages, 8 figures; edited metadata only, paper and abstract unchanged",
    "descriptor": "\nComments: 29 pages, 8 figures; edited metadata only, paper and abstract unchanged\n",
    "authors": [
      "Devanshu Agrawal",
      "James Ostrowski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.09219"
  },
  {
    "id": "arXiv:2205.09510",
    "title": "An Introduction to Quantum Machine Learning for Engineers",
    "abstract": "Comments: The current version will appear on Foundations and Trends in Signal Processing",
    "descriptor": "\nComments: The current version will appear on Foundations and Trends in Signal Processing\n",
    "authors": [
      "Osvaldo Simeone"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09510"
  },
  {
    "id": "arXiv:2205.10155",
    "title": "Large-Signal Stability Analysis of Current-Mode DC-DC Converters",
    "abstract": "Comments: Updated to add acknowledgement for Professor Peter Seiler",
    "descriptor": "\nComments: Updated to add acknowledgement for Professor Peter Seiler\n",
    "authors": [
      "Xiaofan Cui",
      "Al-Thaddeus Avestruz"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2205.10155"
  },
  {
    "id": "arXiv:2205.11121",
    "title": "A normal approximation for joint frequency estimatation under Local  Differential Privacy",
    "abstract": "Comments: Preliminary development, draft",
    "descriptor": "\nComments: Preliminary development, draft\n",
    "authors": [
      "Thomas Carette"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Databases (cs.DB)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2205.11121"
  },
  {
    "id": "arXiv:2205.11283",
    "title": "SelfReformer: Self-Refined Network with Transformer for Salient Object  Detection",
    "abstract": "SelfReformer: Self-Refined Network with Transformer for Salient Object  Detection",
    "descriptor": "",
    "authors": [
      "Yi Ke Yun",
      "Weisi Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11283"
  },
  {
    "id": "arXiv:2205.11609",
    "title": "A fuzzy feedback linearization scheme applied to vibration control of a  smart structure",
    "abstract": "Comments: References added. This is a slightly updated version of the work presented at CONEM 2014 - VIII Congresso Nacional de Engenharia Mec\\^anica, 2014, Uberl\\^andia",
    "descriptor": "\nComments: References added. This is a slightly updated version of the work presented at CONEM 2014 - VIII Congresso Nacional de Engenharia Mec\\^anica, 2014, Uberl\\^andia\n",
    "authors": [
      "Roberta Varela de Albuquerque Her\u00f4ncio",
      "Jo\u00e3o Deodato Batista dos Santos",
      "Wallace Moreira Bessa",
      "Aline Souza de Paula",
      "Marcelo Amorim Savi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2205.11609"
  },
  {
    "id": "arXiv:2205.12442",
    "title": "Lyapunov function approach for approximation algorithm design and  analysis: with applications in submodular maximization",
    "abstract": "Lyapunov function approach for approximation algorithm design and  analysis: with applications in submodular maximization",
    "descriptor": "",
    "authors": [
      "Donglei Du"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.12442"
  },
  {
    "id": "arXiv:2205.12907",
    "title": "Highly efficient energy-conserving moment method for the  multi-dimensional Vlasov-Maxwell system",
    "abstract": "Highly efficient energy-conserving moment method for the  multi-dimensional Vlasov-Maxwell system",
    "descriptor": "",
    "authors": [
      "Tianai Yin",
      "Xinghui Zhong",
      "Yanli Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.12907"
  },
  {
    "id": "arXiv:2205.14258",
    "title": "On the Symmetries of Deep Learning Models and their Internal  Representations",
    "abstract": "Comments: CG and DB contributed equally. V2: clarified relationship between metric $\\mu_{\\mathrm{CKA}}$ and existing instances of CKA",
    "descriptor": "\nComments: CG and DB contributed equally. V2: clarified relationship between metric $\\mu_{\\mathrm{CKA}}$ and existing instances of CKA\n",
    "authors": [
      "Charles Godfrey",
      "Davis Brown",
      "Tegan Emerson",
      "Henry Kvinge"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.14258"
  },
  {
    "id": "arXiv:2205.14374",
    "title": "Syntax-Guided Program Reduction for Understanding Neural Code  Intelligence Models",
    "abstract": "Comments: The 6th ACM SIGPLAN International Symposium on Machine Programming (MAPS'22); Related to arXiv:2202.06474",
    "descriptor": "\nComments: The 6th ACM SIGPLAN International Symposium on Machine Programming (MAPS'22); Related to arXiv:2202.06474\n",
    "authors": [
      "Md Rafiqul Islam Rabin",
      "Aftab Hussain",
      "Mohammad Amin Alipour"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2205.14374"
  },
  {
    "id": "arXiv:2205.14798",
    "title": "Random Rank: The One and Only Strategyproof and Proportionally Fair  Randomized Facility Location Mechanism",
    "abstract": "Random Rank: The One and Only Strategyproof and Proportionally Fair  Randomized Facility Location Mechanism",
    "descriptor": "",
    "authors": [
      "Haris Aziz",
      "Alexander Lam",
      "Mashbat Suzuki",
      "Toby Walsh"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2205.14798"
  },
  {
    "id": "arXiv:2205.15060",
    "title": "Duplex Conversation: Towards Human-like Interaction in Spoken Dialogue  Systems",
    "abstract": "Comments: Accepted by KDD 2022, ADS track",
    "descriptor": "\nComments: Accepted by KDD 2022, ADS track\n",
    "authors": [
      "Ting-En Lin",
      "Yuchuan Wu",
      "Fei Huang",
      "Luo Si",
      "Jian Sun",
      "Yongbin Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.15060"
  },
  {
    "id": "arXiv:2205.15117",
    "title": "OOD Link Prediction Generalization Capabilities of Message-Passing GNNs  in Larger Test Graphs",
    "abstract": "Comments: Under submission",
    "descriptor": "\nComments: Under submission\n",
    "authors": [
      "Yangze Zhou",
      "Gitta Kutyniok",
      "Bruno Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.15117"
  },
  {
    "id": "arXiv:2206.00303",
    "title": "Predecessor Features",
    "abstract": "Comments: Accepted to RLDM 2022",
    "descriptor": "\nComments: Accepted to RLDM 2022\n",
    "authors": [
      "Duncan Bailey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.00303"
  },
  {
    "id": "arXiv:2206.00338",
    "title": "CellCentroidFormer: Combining Self-attention and Convolution for Cell  Detection",
    "abstract": "Comments: Accepted at MIUA 2022; Added experiments with CircleNets and extended figure captions",
    "descriptor": "\nComments: Accepted at MIUA 2022; Added experiments with CircleNets and extended figure captions\n",
    "authors": [
      "Royden Wagner",
      "Karl Rohr"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.00338"
  },
  {
    "id": "arXiv:2206.00594",
    "title": "Sparse graphs with bounded induced cycle packing number have logarithmic  treewidth",
    "abstract": "Comments: 27 pages, 6 figures. v2: references updated",
    "descriptor": "\nComments: 27 pages, 6 figures. v2: references updated\n",
    "authors": [
      "Marthe Bonamy",
      "\u00c9douard Bonnet",
      "Hugues D\u00e9pr\u00e9s",
      "Louis Esperet",
      "Colin Geniet",
      "Claire Hilaire",
      "St\u00e9phan Thomass\u00e9",
      "Alexandra Wesolek"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.00594"
  },
  {
    "id": "arXiv:2206.00702",
    "title": "Fast and Precise: Adjusting Planning Horizon with Adaptive Subgoal  Search",
    "abstract": "Fast and Precise: Adjusting Planning Horizon with Adaptive Subgoal  Search",
    "descriptor": "",
    "authors": [
      "Micha\u0142 Zawalski",
      "Micha\u0142 Tyrolski",
      "Konrad Czechowski",
      "Damian Stachura",
      "Piotr Pi\u0119kos",
      "Tomasz Odrzyg\u00f3\u017ad\u017a",
      "Yuhuai Wu",
      "\u0141ukasz Kuci\u0144ski",
      "Piotr Mi\u0142o\u015b"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00702"
  },
  {
    "id": "arXiv:2206.01191",
    "title": "EfficientFormer: Vision Transformers at MobileNet Speed",
    "abstract": "EfficientFormer: Vision Transformers at MobileNet Speed",
    "descriptor": "",
    "authors": [
      "Yanyu Li",
      "Geng Yuan",
      "Yang Wen",
      "Eric Hu",
      "Georgios Evangelidis",
      "Sergey Tulyakov",
      "Yanzhi Wang",
      "Jian Ren"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01191"
  },
  {
    "id": "arXiv:2206.01319",
    "title": "Learning Unbiased Transferability for Domain Adaptation by Uncertainty  Modeling",
    "abstract": "Comments: version 1",
    "descriptor": "\nComments: version 1\n",
    "authors": [
      "Jian Hu",
      "Haowen Zhong",
      "Junchi Yan",
      "Shaogang Gong",
      "Guile Wu",
      "Fei Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01319"
  },
  {
    "id": "arXiv:2206.03001",
    "title": "PP-OCRv3: More Attempts for the Improvement of Ultra Lightweight OCR  System",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2109.03144",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2109.03144\n",
    "authors": [
      "Chenxia Li",
      "Weiwei Liu",
      "Ruoyu Guo",
      "Xiaoting Yin",
      "Kaitao Jiang",
      "Yongkun Du",
      "Yuning Du",
      "Lingfeng Zhu",
      "Baohua Lai",
      "Xiaoguang Hu",
      "Dianhai Yu",
      "Yanjun Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.03001"
  },
  {
    "id": "arXiv:2206.03010",
    "title": "MS-RNN: A Flexible Multi-Scale Framework for Spatiotemporal Predictive  Learning",
    "abstract": "MS-RNN: A Flexible Multi-Scale Framework for Spatiotemporal Predictive  Learning",
    "descriptor": "",
    "authors": [
      "Zhifeng Ma",
      "Hao Zhang",
      "Jie Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.03010"
  },
  {
    "id": "arXiv:2206.03027",
    "title": "Learning Symbolic Operators: A Neurosymbolic Solution for Autonomous  Disassembly of Electric Vehicle Battery",
    "abstract": "Learning Symbolic Operators: A Neurosymbolic Solution for Autonomous  Disassembly of Electric Vehicle Battery",
    "descriptor": "",
    "authors": [
      "Yidong Du",
      "Wenshuo Wang",
      "Zhigang Wang",
      "Hua Yang",
      "Haitao Wang",
      "Yinghao Cai",
      "Ming Chen"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.03027"
  },
  {
    "id": "arXiv:2206.03113",
    "title": "Wavelet Prior Attention Learning in Axial Inpainting Network",
    "abstract": "Wavelet Prior Attention Learning in Axial Inpainting Network",
    "descriptor": "",
    "authors": [
      "Chenjie Cao",
      "Chengrong Wang",
      "Yuntao Zhang",
      "Yanwei Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.03113"
  },
  {
    "id": "arXiv:2206.03356",
    "title": "Position Paper: Online Modeling for Offline Planning",
    "abstract": "Position Paper: Online Modeling for Offline Planning",
    "descriptor": "",
    "authors": [
      "Eyal Weiss",
      "Gal A. Kaminka"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.03356"
  },
  {
    "id": "arXiv:2206.03487",
    "title": "Formalization of the principles of brain Programming (Brain Principles  Programming)",
    "abstract": "Comments: 28 pages, in Russian, 4 figures",
    "descriptor": "\nComments: 28 pages, in Russian, 4 figures\n",
    "authors": [
      "E.E. Vityaev",
      "A.G. Kolonin",
      "A.V. Kurpatov A.A. Molchanov"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.03487"
  },
  {
    "id": "arXiv:2206.03826",
    "title": "Towards Understanding Why Mask-Reconstruction Pretraining Helps in  Downstream Tasks",
    "abstract": "Towards Understanding Why Mask-Reconstruction Pretraining Helps in  Downstream Tasks",
    "descriptor": "",
    "authors": [
      "Jiachun Pan",
      "Pan Zhou",
      "Shuicheng Yan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.03826"
  },
  {
    "id": "arXiv:2206.03861",
    "title": "Decentralized Online Regularized Learning Over Random Time-Varying  Graphs",
    "abstract": "Decentralized Online Regularized Learning Over Random Time-Varying  Graphs",
    "descriptor": "",
    "authors": [
      "Xiwei Zhang",
      "Tao Li",
      "Xiaozheng Fu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.03861"
  },
  {
    "id": "arXiv:2206.03950",
    "title": "Transfer learning to decode brain states reflecting the relationship  between cognitive tasks",
    "abstract": "Transfer learning to decode brain states reflecting the relationship  between cognitive tasks",
    "descriptor": "",
    "authors": [
      "Youzhi Qu",
      "Xinyao Jian",
      "Wenxin Che",
      "Penghui Du",
      "Kai Fu",
      "Quanying Liu"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03950"
  },
  {
    "id": "arXiv:2206.04166",
    "title": "Planning with Dynamically Estimated Action Costs",
    "abstract": "Comments: 3 figures, 2 tables",
    "descriptor": "\nComments: 3 figures, 2 tables\n",
    "authors": [
      "Eyal Weiss",
      "Gal A. Kaminka"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2206.04166"
  },
  {
    "id": "arXiv:2206.04573",
    "title": "Simple lessons from complex learning: what a neural network model learns  about cosmic structure formation",
    "abstract": "Comments: 13 pages, 8 figures",
    "descriptor": "\nComments: 13 pages, 8 figures\n",
    "authors": [
      "Drew Jamieson",
      "Yin Li",
      "Siyu He",
      "Francisco Villaescusa-Navarro",
      "Shirley Ho",
      "Renan Alves de Oliveira",
      "David N. Spergel"
    ],
    "subjectives": [
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04573"
  },
  {
    "id": "arXiv:2206.04594",
    "title": "Field Level Neural Network Emulator for Cosmological N-body Simulations",
    "abstract": "Comments: 11 pages, 4 figures",
    "descriptor": "\nComments: 11 pages, 4 figures\n",
    "authors": [
      "Drew Jamieson",
      "Yin Li",
      "Renan Alves de Oliveira",
      "Francisco Villaescusa-Navarro",
      "Shirley Ho",
      "David N. Spergel"
    ],
    "subjectives": [
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04594"
  },
  {
    "id": "arXiv:2206.04673",
    "title": "Neural Prompt Search",
    "abstract": "Comments: Code: this https URL",
    "descriptor": "\nComments: Code: this https URL\n",
    "authors": [
      "Yuanhan Zhang",
      "Kaiyang Zhou",
      "Ziwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04673"
  },
  {
    "id": "arXiv:2206.04843",
    "title": "Neural Laplace: Learning diverse classes of differential equations in  the Laplace domain",
    "abstract": "Comments: Proceedings of the 39th International Conference on Machine Learning, Baltimore, Maryland, USA, PMLR 162, 2022. Copyright 2022 by the author(s)",
    "descriptor": "\nComments: Proceedings of the 39th International Conference on Machine Learning, Baltimore, Maryland, USA, PMLR 162, 2022. Copyright 2022 by the author(s)\n",
    "authors": [
      "Samuel Holt",
      "Zhaozhi Qian",
      "Mihaela van der Schaar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.04843"
  },
  {
    "id": "arXiv:2206.04869",
    "title": "Ask to Know More: Generating Counterfactual Explanations for Fake Claims",
    "abstract": "Comments: 11 pages",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Shih-Chieh Dai",
      "Yi-Li Hsu",
      "Aiping Xiong",
      "Lun-Wei Ku"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.04869"
  },
  {
    "id": "arXiv:2206.05092",
    "title": "Learning self-calibrated optic disc and cup segmentation from  multi-rater annotations",
    "abstract": "Learning self-calibrated optic disc and cup segmentation from  multi-rater annotations",
    "descriptor": "",
    "authors": [
      "Junde Wu",
      "Huihui Fang",
      "Fangxin Shang",
      "Zhaowei Wang",
      "Dalu Yang",
      "Wenshuo Zhou",
      "Yehui Yang",
      "Yanwu Xu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.05092"
  },
  {
    "id": "arXiv:2206.05240",
    "title": "ROI Constrained Bidding via Curriculum-Guided Bayesian Reinforcement  Learning",
    "abstract": "Comments: Accepted by SIGKDD 2022",
    "descriptor": "\nComments: Accepted by SIGKDD 2022\n",
    "authors": [
      "Haozhe Wang",
      "Chao Du",
      "Panyan Fang",
      "Shuo Yuan",
      "Xuming He",
      "Liang Wang",
      "Bo Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.05240"
  },
  {
    "id": "arXiv:2206.05273",
    "title": "A General Framework for the Representation of Function and Affordance: A  Cognitive, Causal, and Grounded Approach, and a Step Toward AGI",
    "abstract": "Comments: 66 pages, 49 figures",
    "descriptor": "\nComments: 66 pages, 49 figures\n",
    "authors": [
      "Seng-Beng Ho"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.05273"
  },
  {
    "id": "arXiv:2206.05494",
    "title": "Parallelization of Software Systems Test Case Selection Algorithm Based  on Singular Value Decomposition",
    "abstract": "Comments: The 11th Seminar on Linear Algebra and its Applications",
    "descriptor": "\nComments: The 11th Seminar on Linear Algebra and its Applications\n",
    "authors": [
      "Mahdi Movahedian Moghaddam"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.05494"
  },
  {
    "id": "arXiv:2206.05596",
    "title": "Neural Network-based Flight Control Systems: Present and Future",
    "abstract": "Comments: 163 pages",
    "descriptor": "\nComments: 163 pages\n",
    "authors": [
      "Seyyed Ali Emami",
      "Paolo Castaldi",
      "Afshin Banazadeh"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.05596"
  },
  {
    "id": "arXiv:2206.05644",
    "title": "Monte Carlo with Soft Constraints: the Surface Augmented Sampler",
    "abstract": "Monte Carlo with Soft Constraints: the Surface Augmented Sampler",
    "descriptor": "",
    "authors": [
      "Ildebrando Magnani"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2206.05644"
  },
  {
    "id": "arXiv:2206.05675",
    "title": "A Survey on Uncertainty Reasoning and Quantification for Decision  Making: Belief Theory Meets Deep Learning",
    "abstract": "Comments: First four authors contributed equally",
    "descriptor": "\nComments: First four authors contributed equally\n",
    "authors": [
      "Zhen Guo",
      "Zelin Wan",
      "Qisheng Zhang",
      "Xujiang Zhao",
      "Feng Chen",
      "Jin-Hee Cho",
      "Qi Zhang",
      "Lance M. Kaplan",
      "Dong H. Jeong",
      "Audun J\u00f8sang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05675"
  },
  {
    "id": "arXiv:2206.05700",
    "title": "A Functional Information Perspective on Model Interpretation",
    "abstract": "Comments: Accepted to ICML 2022",
    "descriptor": "\nComments: Accepted to ICML 2022\n",
    "authors": [
      "Itai Gat",
      "Nitay Calderon",
      "Roi Reichart",
      "Tamir Hazan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05700"
  },
  {
    "id": "arXiv:2206.05730",
    "title": "Object Occlusion of Adding New Categories in Objection Detection",
    "abstract": "Object Occlusion of Adding New Categories in Objection Detection",
    "descriptor": "",
    "authors": [
      "Boyang Deng",
      "Meiyan Lin",
      "Shoulun Long"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.05730"
  },
  {
    "id": "arXiv:2206.05777",
    "title": "The YiTrans End-to-End Speech Translation System for IWSLT 2022 Offline  Shared Task",
    "abstract": "Comments: 11 pages",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Ziqiang Zhang",
      "Junyi Ao",
      "Long Zhou",
      "Shujie Liu",
      "Furu Wei",
      "Jinyu Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.05777"
  },
  {
    "id": "arXiv:2206.05802",
    "title": "Self-critiquing models for assisting human evaluators",
    "abstract": "Self-critiquing models for assisting human evaluators",
    "descriptor": "",
    "authors": [
      "William Saunders",
      "Catherine Yeh",
      "Jeff Wu",
      "Steven Bills",
      "Long Ouyang",
      "Jonathan Ward",
      "Jan Leike"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05802"
  },
  {
    "id": "arXiv:2206.05895",
    "title": "Latent Diffusion Energy-Based Model for Interpretable Text Modeling",
    "abstract": "Comments: ICML 2022",
    "descriptor": "\nComments: ICML 2022\n",
    "authors": [
      "Peiyu Yu",
      "Sirui Xie",
      "Xiaojian Ma",
      "Baoxiong Jia",
      "Bo Pang",
      "Ruiqi Gao",
      "Yixin Zhu",
      "Song-Chun Zhu",
      "Ying Nian Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.05895"
  },
  {
    "id": "arXiv:2206.05896",
    "title": "Improve Ranking Correlation of Super-net through Training Scheme from  One-shot NAS to Few-shot NAS",
    "abstract": "Improve Ranking Correlation of Super-net through Training Scheme from  One-shot NAS to Few-shot NAS",
    "descriptor": "",
    "authors": [
      "Jiawei Liu",
      "Kaiyu Zhang",
      "Weitai Hu",
      "Qing Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.05896"
  },
  {
    "id": "arXiv:2206.05963",
    "title": "ATDN vSLAM: An all-through Deep Learning-Based Solution for Visual  Simultaneous Localization and Mapping",
    "abstract": "Comments: Submitted to Periodica Polytechnica Electrical Engineering 11 pages",
    "descriptor": "\nComments: Submitted to Periodica Polytechnica Electrical Engineering 11 pages\n",
    "authors": [
      "M\u00e1ty\u00e1s Sz\u00e1nt\u00f3",
      "Gy\u00f6rgy R. Bog\u00e1r",
      "L\u00e1szl\u00f3 Vajta"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.05963"
  },
  {
    "id": "arXiv:2206.05981",
    "title": "Efficient Human-in-the-loop System for Guiding DNNs Attention",
    "abstract": "Comments: 13 pages, 11 figures",
    "descriptor": "\nComments: 13 pages, 11 figures\n",
    "authors": [
      "Yi He",
      "Xi Yang",
      "Chia-Ming Chang",
      "Haoran Xie",
      "Takeo Igarashi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05981"
  },
  {
    "id": "arXiv:2206.06031",
    "title": "A universal synthetic dataset for machine learning on spectroscopic data",
    "abstract": "Comments: 8 pages, 2 figures, 2 tables",
    "descriptor": "\nComments: 8 pages, 2 figures, 2 tables\n",
    "authors": [
      "Jan Schuetzke",
      "Nathan J. Szymanski",
      "Markus Reischl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Materials Science (cond-mat.mtrl-sci)"
    ],
    "url": "https://arxiv.org/abs/2206.06031"
  },
  {
    "id": "arXiv:2206.06067",
    "title": "Better Teacher Better Student: Dynamic Prior Knowledge for Knowledge  Distillation",
    "abstract": "Better Teacher Better Student: Dynamic Prior Knowledge for Knowledge  Distillation",
    "descriptor": "",
    "authors": [
      "Zengyu Qiu",
      "Xinzhu Ma",
      "Kunlin Yang",
      "Chunya Liu",
      "Jun Hou",
      "Shuai Yi",
      "Wanli Ouyang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06067"
  },
  {
    "id": "arXiv:2206.06175",
    "title": "Generation of Patient-specific Structured Hexahedral Mesh of Aortic  Aneurysm Wall",
    "abstract": "Comments: Medical Image Computing and Computer Assisted Intervention MICCAI 2022 Computational Biomechanics for Medicine Workshop",
    "descriptor": "\nComments: Medical Image Computing and Computer Assisted Intervention MICCAI 2022 Computational Biomechanics for Medicine Workshop\n",
    "authors": [
      "Farah Alkhatib",
      "George C. Bourantas",
      "Adam Wittek",
      "Karol Miller"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2206.06175"
  },
  {
    "id": "arXiv:2206.06202",
    "title": "Constraint Guided Gradient Descent: Guided Training with Inequality  Constraints",
    "abstract": "Comments: 9 pages, 1 figure, 1 table Comments: corrected typo in author list",
    "descriptor": "\nComments: 9 pages, 1 figure, 1 table Comments: corrected typo in author list\n",
    "authors": [
      "Quinten Van Baelen",
      "Peter Karsmakers"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.06202"
  },
  {
    "id": "arXiv:2206.06258",
    "title": "Featurized Query R-CNN",
    "abstract": "Comments: Tech Report",
    "descriptor": "\nComments: Tech Report\n",
    "authors": [
      "Wenqiang Zhang",
      "Tianheng Cheng",
      "Xinggang Wang",
      "Shaoyu Chen",
      "Qian Zhang",
      "Wenyu Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06258"
  },
  {
    "id": "arXiv:2206.06308",
    "title": "Knowledge Graph Construction and Its Application in Automatic Radiology  Report Generation from Radiologist's Dictation",
    "abstract": "Knowledge Graph Construction and Its Application in Automatic Radiology  Report Generation from Radiologist's Dictation",
    "descriptor": "",
    "authors": [
      "Kaveri Kale",
      "Pushpak Bhattacharyya",
      "Aditya Shetty",
      "Milind Gune",
      "Kush Shrivastava",
      "Rustom Lawyer",
      "Spriha Biswas"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.06308"
  },
  {
    "id": "arXiv:2206.06350",
    "title": "Significant Engagement Community Search on Temporal Networks: Concepts  and Algorithms",
    "abstract": "Comments: 22 pages, 26 figures",
    "descriptor": "\nComments: 22 pages, 26 figures\n",
    "authors": [
      "Yifei Zhang",
      "Longlong Lin",
      "Pingpeng Yuan",
      "Hai Jin"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.06350"
  }
]
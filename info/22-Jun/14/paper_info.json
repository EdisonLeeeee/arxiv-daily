[
  {
    "id": "arXiv:2206.05267",
    "title": "CONTINUER: Maintaining Distributed DNN Services During Edge Failures",
    "abstract": "Partitioning and deploying Deep Neural Networks (DNNs) across edge nodes may\nbe used to meet performance objectives of applications. However, the failure of\na single node may result in cascading failures that will adversely impact the\ndelivery of the service and will result in failure to meet specific objectives.\nThe impact of these failures needs to be minimised at runtime. Three techniques\nare explored in this paper, namely repartitioning, early-exit and\nskip-connection. When an edge node fails, the repartitioning technique will\nrepartition and redeploy the DNN thus avoiding the failed nodes. The early-exit\ntechnique makes provision for a request to exit (early) before the failed node.\nThe skip connection technique dynamically routes the request by skipping the\nfailed nodes. This paper will leverage trade-offs in accuracy, end-to-end\nlatency and downtime for selecting the best technique given user-defined\nobjectives (accuracy, latency and downtime thresholds) when an edge node fails.\nTo this end, CONTINUER is developed. Two key activities of the framework are\nestimating the accuracy and latency when using the techniques for distributed\nDNNs and selecting the best technique. It is demonstrated on a lab-based\nexperimental testbed that CONTINUER estimates accuracy and latency when using\nthe techniques with no more than an average error of 0.28% and 13.06%,\nrespectively and selects the suitable technique with a low overhead of no more\nthan 16.82 milliseconds and an accuracy of up to 99.86%.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Ayesha Abdul Majeed",
      "Peter Kilpatrick",
      "Ivor Spence",
      "Blesson Varghese"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05267"
  },
  {
    "id": "arXiv:2206.05268",
    "title": "A heuristic method for data allocation and task scheduling on  heterogeneous multiprocessor systems under memory constraints",
    "abstract": "Computing workflows in heterogeneous multiprocessor systems are frequently\nmodeled as directed acyclic graphs of tasks and data blocks, which represent\ncomputational modules and their dependencies in the form of data produced by a\ntask and used by others. However, for some workflows, such as the task schedule\nin a digital signal processor may run out of memory by exposing too much\nparallelism. This paper focuses on the data allocation and task scheduling\nproblem under memory constraints, and concentrates on shared memory platforms.\nWe first propose an integer linear programming model to formulate the problem.\nThen we consider the problem as an extended flexible job shop scheduling\nproblem, while trying to minimize the critical path of the graph. To solve this\nproblem, we propose a tabu search algorithm (TS) which combines several\ndistinguished features such as a greedy initial solution construction method\nand a mixed neighborhood evaluation strategy based on exact evaluation and\napproximate evaluation methods. Experimental results on randomly generated\ninstances show that the the proposed TS algorithm can obtain relatively\nhigh-quality solutions in a reasonable computational time. In specific, the\ntabu search method averagely improves the makespan by 5-25\\% compared to the\nclassical load balancing algorithm that are widely used in the literature.\nBesides, some key features of TS are also analyzed to identify its success\nfactors.",
    "descriptor": "",
    "authors": [
      "Junwen Ding",
      "Liangcai Song",
      "Siyuan Li",
      "Chen Wu",
      "Ronghua He",
      "Zhouxing Su",
      "Zhipeng L\u00fc"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.05268"
  },
  {
    "id": "arXiv:2206.05269",
    "title": "MapReduce for Counting Word Frequencies with MPI and GPUs",
    "abstract": "In this project, the goal was to use the Julia programming language and\nparallelization to write a fast map reduce algorithm to count word frequencies\nacross large numbers of documents. We first implement the word frequency\ncounter algorithm on a CPU using two processes with MPI. Then, we create\nanother implementation, but on a GPU using the Julia CUDA library, though not\nusing the in built map reduce algorithm within FoldsCUDA.jl. After doing this,\nwe apply our CPU and GPU algorithms to count the frequencies of words in\nspeeches given by Presidents George W Bush, Barack H Obama, Donald J Trump, and\nJoseph R Biden with the aim of finding patterns in word choice that could be\nused to uniquely identify each President. We find that each President does have\ncertain words that they use distinctly more often than their fellow Presidents,\nand these words are not surprising given the political climate at the time.\nThe goal of this project was to create faster MapReduce algorithms in Julia\non the CPU and GPU than the ones that have already been written previously. We\npresent some simple cases of mapping functions where our GPU algorithm\noutperforms Julia's FoldsCUDA implementation. We also discuss ideas for further\noptimizations in the case of counting word frequencies in documents and for\nthese specific mapping functions.",
    "descriptor": "",
    "authors": [
      "Nithin Kavi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.05269"
  },
  {
    "id": "arXiv:2206.05273",
    "title": "A General Framework for the Representation of Function and Affordance: A  Cognitive, Causal, and Grounded Approach, and a Step Toward AGI",
    "abstract": "In AI research, so far, the attention paid to the characterization and\nrepresentation of function and affordance has been sporadic and sparse, even\nthough this aspect features prominently in an intelligent system's functioning.\nIn the sporadic and sparse, though commendable efforts so far devoted to the\ncharacterization and understanding of function and affordance, there has also\nbeen no general framework that could unify all the different use domains and\nsituations related to the representation and application of functional\nconcepts. This paper develops just such a general framework, with an approach\nthat emphasizes the fact that the representations involved must be explicitly\ncognitive and conceptual, and they must also contain causal characterizations\nof the events and processes involved, as well as employ conceptual constructs\nthat are grounded in the referents to which they refer, in order to achieve\nmaximal generality. The basic genera framework is described, along with a set\nof basic guiding principles with regards to representation of functionality. To\nproperly and adequately characterize and represent functionality, a descriptive\nrepresentation language is needed. This language is defined and developed, and\nmany examples of its use are described. The general framework is developed\nbased on an extension of the general language meaning representational\nframework called conceptual dependency. To support the general characterization\nand representation of functionality, the basic conceptual dependency framework\nis enhanced with representational devices called structure anchor and\nconceptual dependency elaboration, together with the definition of a set of\nground level concepts. These novel representational constructs are defined,\ndeveloped, and described. A general framework dealing with functionality would\nrepresent a major step toward achieving Artificial General Intelligence.",
    "descriptor": "\nComments: 66 pages, 48 figures\n",
    "authors": [
      "Seng-Beng Ho"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.05273"
  },
  {
    "id": "arXiv:2206.05274",
    "title": "50 Years of Computational Complexity: Hao Wang and the Theory of  Computation",
    "abstract": "If Turing's groundbreaking paper in 1936 laid the foundation of the theory of\ncomputation (ToC), it is no exaggeration to say that Cook's paper in 1971, \"The\ncomplexity of theorem proving procedures\", [4] has pioneered the study of\ncomputational complexity. So computational complexity, as an independent\nresearch field, is 50 years old now (2021) if we date from Cook's article. This\nyear coincides with the 100th birthday of Cook's mentor Hao Wang, one of the\nmost important logicians. This paper traces the origin of computational\ncomplexity, and meanwhile, tries to sort out the instrumental role that Wang\nplayed in the process.",
    "descriptor": "",
    "authors": [
      "Nick Zhang"
    ],
    "subjectives": [
      "General Literature (cs.GL)"
    ],
    "url": "https://arxiv.org/abs/2206.05274"
  },
  {
    "id": "arXiv:2206.05275",
    "title": "Spatial-temporal Concept based Explanation of 3D ConvNets",
    "abstract": "Recent studies have achieved outstanding success in explaining 2D image\nrecognition ConvNets. On the other hand, due to the computation cost and\ncomplexity of video data, the explanation of 3D video recognition ConvNets is\nrelatively less studied. In this paper, we present a 3D ACE (Automatic\nConcept-based Explanation) framework for interpreting 3D ConvNets. In our\napproach: (1) videos are represented using high-level supervoxels, which is\nstraightforward for human to understand; and (2) the interpreting framework\nestimates a score for each voxel, which reflects its importance in the decision\nprocedure. Experiments show that our method can discover spatial-temporal\nconcepts of different importance-levels, and thus can explore the influence of\nthe concepts on a target task, such as action classification, in-depth. The\ncodes are publicly available.",
    "descriptor": "",
    "authors": [
      "Ying Ji",
      "Yu Wang",
      "Kensaku Mori",
      "Jien Kato"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.05275"
  },
  {
    "id": "arXiv:2206.05276",
    "title": "Game-Theoretic Neyman-Pearson Detection to Combat Strategic Evasion",
    "abstract": "The security in networked systems depends greatly on recognizing and\nidentifying adversarial behaviors. Traditional detection methods focus on\nspecific categories of attacks and have become inadequate for increasingly\nstealthy and deceptive attacks that are designed to bypass detection\nstrategically. This work aims to develop a holistic theory to countermeasure\nsuch evasive attacks. We focus on extending a fundamental class of\nstatistical-based detection methods based on Neyman-Pearson's (NP) hypothesis\ntesting formulation. We propose game-theoretic frameworks to capture the\nconflicting relationship between a strategic evasive attacker and an\nevasion-aware NP detector. By analyzing both the equilibrium behaviors of the\nattacker and the NP detector, we characterize their performance using\nEquilibrium Receiver-Operational-Characteristic (EROC) curves. We show that the\nevasion-aware NP detectors outperform the passive ones in the way that the\nformer can act strategically against the attacker's behavior and adaptively\nmodify their decision rules based on the received messages. In addition, we\nextend our framework to a sequential setting where the user sends out\nidentically distributed messages. We corroborate the analytical results with a\ncase study of anomaly detection.",
    "descriptor": "",
    "authors": [
      "Yinan Hu",
      "Quanyan Zhu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.05276"
  },
  {
    "id": "arXiv:2206.05281",
    "title": "Less Is More: Linear Layers on CLIP Features as Powerful VizWiz Model",
    "abstract": "Current architectures for multi-modality tasks such as visual question\nanswering suffer from their high complexity. As a result, these architectures\nare difficult to train and require high computational resources. To address\nthese problems we present a CLIP-based architecture that does not require any\nfine-tuning of the feature extractors. A simple linear classifier is used on\nthe concatenated features of the image and text encoder. During training an\nauxiliary loss is added which operates on the answer types. The resulting\nclassification is then used as an attention gate on the answer class selection.\nOn the VizWiz 2022 Visual Question Answering Challenge we achieve 60.15 %\naccuracy on Task 1: Predict Answer to a Visual Question and AP score of 83.78 %\non Task 2: Predict Answerability of a Visual Question.",
    "descriptor": "\nComments: VizWiz Grand Challenge: Describing Images and Videos Taken by Blind People (CVPR Workshop 2022)\n",
    "authors": [
      "Fabian Deuser",
      "Konrad Habel",
      "Philipp J. R\u00f6sch",
      "Norbert Oswald"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05281"
  },
  {
    "id": "arXiv:2206.05282",
    "title": "Learning to Estimate Shapley Values with Vision Transformers",
    "abstract": "Transformers have become a default architecture in computer vision, but\nunderstanding what drives their predictions remains a challenging problem.\nCurrent explanation approaches rely on attention values or input gradients, but\nthese give a limited understanding of a model's dependencies. Shapley values\noffer a theoretically sound alternative, but their computational cost makes\nthem impractical for large, high-dimensional models. In this work, we aim to\nmake Shapley values practical for vision transformers (ViTs). To do so, we\nfirst leverage an attention masking approach to evaluate ViTs with partial\ninformation, and we then develop a procedure for generating Shapley value\nexplanations via a separate, learned explainer model. Our experiments compare\nShapley values to many baseline methods (e.g., attention rollout, GradCAM,\nLRP), and we find that our approach provides more accurate explanations than\nany existing method for ViTs.",
    "descriptor": "",
    "authors": [
      "Ian Covert",
      "Chanwoo Kim",
      "Su-In Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05282"
  },
  {
    "id": "arXiv:2206.05286",
    "title": "AHD ConvNet for Speech Emotion Classification",
    "abstract": "Accomplishments in the field of artificial intelligence are utilized in the\nadvancement of computing and making of intelligent machines for facilitating\nmankind and improving user experience. Emotions are rudimentary for people,\naffecting thinking and ordinary exercises like correspondence, learning and\ndirection. Speech emotion recognition is domain of interest in this regard and\nin this work, we propose a novel mel spectrogram learning approach in which our\nmodel uses the datapoints to learn emotions from the given wav form voice notes\nin the popular CREMA-D dataset. Our model uses log mel-spectrogram as feature\nwith number of mels = 64. It took less training time compared to other\napproaches used to address the problem of emotion speech recognition.",
    "descriptor": "",
    "authors": [
      "Asfand Ali",
      "Danial Nasir",
      "Mohammad Hassan Jawad"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.05286"
  },
  {
    "id": "arXiv:2206.05291",
    "title": "ProActive: Self-Attentive Temporal Point Process Flows for Activity  Sequences",
    "abstract": "Any human activity can be represented as a temporal sequence of actions\nperformed to achieve a certain goal. Unlike machine-made time series, these\naction sequences are highly disparate as the time taken to finish a similar\naction might vary between different persons. Therefore, understanding the\ndynamics of these sequences is essential for many downstream tasks such as\nactivity length prediction, goal prediction, etc. Existing neural approaches\nthat model an activity sequence are either limited to visual data or are task\nspecific, i.e., limited to next action or goal prediction. In this paper, we\npresent ProActive, a neural marked temporal point process (MTPP) framework for\nmodeling the continuous-time distribution of actions in an activity sequence\nwhile simultaneously addressing three high-impact problems -- next action\nprediction, sequence-goal prediction, and end-to-end sequence generation.\nSpecifically, we utilize a self-attention module with temporal normalizing\nflows to model the influence and the inter-arrival times between actions in a\nsequence. Moreover, for time-sensitive prediction, we perform an early\ndetection of sequence goal via a constrained margin-based optimization\nprocedure. This in-turn allows ProActive to predict the sequence goal using a\nlimited number of actions. Extensive experiments on sequences derived from\nthree activity recognition datasets show the significant accuracy boost of\nProActive over the state-of-the-art in terms of action and goal prediction, and\nthe first-ever application of end-to-end action sequence generation.",
    "descriptor": "\nComments: KDD 2022\n",
    "authors": [
      "Vinayak Gupta",
      "Srikanta Bedathur"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05291"
  },
  {
    "id": "arXiv:2206.05309",
    "title": "EigenFairing: 3D Model Fairing using Image Coherence",
    "abstract": "A surface is often modeled as a triangulated mesh of 3D points and textures\nassociated with faces of the mesh. The 3D points could be either sampled from\nrange data or derived from a set of images using a stereo or\nStructure-from-Motion algorithm. When the points do not lie at critical points\nof maximum curvature or discontinuities of the real surface, faces of the mesh\ndo not lie close to the modeled surface. This results in textural artifacts,\nand the model is not perfectly coherent with a set of actual images -- the ones\nthat are used to texture-map its mesh. This paper presents a technique for\nperfecting the 3D surface model by repositioning its vertices so that it is\ncoherent with a set of observed images of the object. The textural artifacts\nand incoherence with images are due to the non-planarity of a surface patch\nbeing approximated by a planar face, as observed from multiple viewpoints.\nImage areas from the viewpoints are used to represent texture for the patch in\nEigenspace. The Eigenspace representation captures variations of texture, which\nwe seek to minimize. A coherence measure based on the difference between the\nface textures reconstructed from Eigenspace and the actual images is used to\nreposition the vertices so that the model is improved or faired. We refer to\nthis technique of model refinement as EigenFairing, by which the model is\nfaired, both geometrically and texturally, to better approximate the real\nsurface.",
    "descriptor": "\nComments: British Machine Vision Conference, BMVC 2004, Kingston, UK, September 7-9, 2004\n",
    "authors": [
      "Pragyana Mishra",
      "Omead Amidi",
      "Takeo Kanade"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2206.05309"
  },
  {
    "id": "arXiv:2206.05311",
    "title": "Graph-in-Graph Network for Automatic Gene Ontology Description  Generation",
    "abstract": "Gene Ontology (GO) is the primary gene function knowledge base that enables\ncomputational tasks in biomedicine. The basic element of GO is a term, which\nincludes a set of genes with the same function. Existing research efforts of GO\nmainly focus on predicting gene term associations. Other tasks, such as\ngenerating descriptions of new terms, are rarely pursued. In this paper, we\npropose a novel task: GO term description generation. This task aims to\nautomatically generate a sentence that describes the function of a GO term\nbelonging to one of the three categories, i.e., molecular function, biological\nprocess, and cellular component. To address this task, we propose a\nGraph-in-Graph network that can efficiently leverage the structural information\nof GO. The proposed network introduces a two-layer graph: the first layer is a\ngraph of GO terms where each node is also a graph (gene graph). Such a\nGraph-in-Graph network can derive the biological functions of GO terms and\ngenerate proper descriptions. To validate the effectiveness of the proposed\nnetwork, we build three large-scale benchmark datasets. By incorporating the\nproposed Graph-in-Graph network, the performances of seven different\nsequence-to-sequence models can be substantially boosted across all evaluation\nmetrics, with up to 34.7%, 14.5%, and 39.1% relative improvements in BLEU,\nROUGE-L, and METEOR, respectively.",
    "descriptor": "\nComments: Accepted by KDD 2022 (Research Track)\n",
    "authors": [
      "Fenglin Liu",
      "Bang Yang",
      "Chenyu You",
      "Xian Wu",
      "Shen Ge",
      "Adelaide Woicik",
      "Sheng Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.05311"
  },
  {
    "id": "arXiv:2206.05312",
    "title": "Vehicle-To-Pedestrian Communication Feedback Module: A Study on  Increasing Legibility, Public Acceptance and Trust",
    "abstract": "Vehicle pedestrian communication is extremely important when developing\nautonomy for an autonomous vehicle. Enabling bidirectional nonverbal\ncommunication between pedestrians and autonomous vehicles will lead to an\nimprovement of pedestrians' safety in autonomous driving. If a pedestrian wants\nto communicate, the autonomous vehicle should provide feedback to the human\nabout what it is about to do. The user study presented in this paper\ninvestigated several possible options for an external vehicle display for\neffective nonverbal communication between an autonomous vehicle and a human.\nThe result of this study will guide the development of the feedback module in\nfuture studies, optimizing for public acceptance and trust in the autonomous\nvehicle's decision while being legible to the widest range of potential users.\nThe results of this study show that participants prefer symbols over text,\nlights and road projection. Additionally, participants prefer the combination\nof symbols and text as interaction modes to be displayed if the autonomous\nvehicle is not driving. Further, the results show that the text interaction\nmode option \"Safe to cross\" should be used combined with the symbol interaction\nmode option that displays a symbol of a walking person. We plan to elaborate\nand focus on the selected interaction modes via Virtual Reality and in the real\nworld in ongoing and future studies.",
    "descriptor": "",
    "authors": [
      "Melanie Schmidt-Wolf",
      "David Feil-Seifer"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.05312"
  },
  {
    "id": "arXiv:2206.05314",
    "title": "Large-Scale Retrieval for Reinforcement Learning",
    "abstract": "Effective decision making involves flexibly relating past experiences and\nrelevant contextual information to a novel situation. In deep reinforcement\nlearning, the dominant paradigm is for an agent to amortise information that\nhelps decision-making into its network weights via gradient descent on training\nlosses. Here, we pursue an alternative approach in which agents can utilise\nlarge-scale context-sensitive database lookups to support their parametric\ncomputations. This allows agents to directly learn in an end-to-end manner to\nutilise relevant information to inform their outputs. In addition, new\ninformation can be attended to by the agent, without retraining, by simply\naugmenting the retrieval dataset. We study this approach in Go, a challenging\ngame for which the vast combinatorial state space privileges generalisation\nover direct matching to past experiences. We leverage fast, approximate nearest\nneighbor techniques in order to retrieve relevant data from a set of tens of\nmillions of expert demonstration states. Attending to this information provides\na significant boost to prediction accuracy and game-play performance over\nsimply using these demonstrations as training trajectories, providing a\ncompelling demonstration of the value of large-scale retrieval in reinforcement\nlearning agents.",
    "descriptor": "\nComments: Preprint, 16 pages\n",
    "authors": [
      "Peter C. Humphreys",
      "Arthur Guez",
      "Olivier Tieleman",
      "Laurent Sifre",
      "Th\u00e9ophane Weber",
      "Timothy Lillicrap"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.05314"
  },
  {
    "id": "arXiv:2206.05317",
    "title": "Intrinsic dimensionality and generalization properties of the  $\\mathcal{R}$-norm inductive bias",
    "abstract": "We study the structural and statistical properties of $\\mathcal{R}$-norm\nminimizing interpolants of datasets labeled by specific target functions. The\n$\\mathcal{R}$-norm is the basis of an inductive bias for two-layer neural\nnetworks, recently introduced to capture the functional effect of controlling\nthe size of network weights, independently of the network width. We find that\nthese interpolants are intrinsically multivariate functions, even when there\nare ridge functions that fit the data, and also that the $\\mathcal{R}$-norm\ninductive bias is not sufficient for achieving statistically optimal\ngeneralization for certain learning problems. Altogether, these results shed\nnew light on an inductive bias that is connected to practical neural network\ntraining.",
    "descriptor": "\nComments: 34 pages\n",
    "authors": [
      "Clayton Sanford",
      "Navid Ardeshir",
      "Daniel Hsu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05317"
  },
  {
    "id": "arXiv:2206.05319",
    "title": "Object Instance Identification in Dynamic Environments",
    "abstract": "We study the problem of identifying object instances in a dynamic environment\nwhere people interact with the objects. In such an environment, objects'\nappearance changes dynamically by interaction with other entities, occlusion by\nhands, background change, etc. This leads to a larger intra-instance variation\nof appearance than in static environments. To discover the challenges in this\nsetting, we newly built a benchmark of more than 1,500 instances built on the\nEPIC-KITCHENS dataset which includes natural activities and conducted an\nextensive analysis of it. Experimental results suggest that (i) robustness\nagainst instance-specific appearance change (ii) integration of low-level\n(e.g., color, texture) and high-level (e.g., object category) features (iii)\nforeground feature selection on overlapping objects are required for further\nimprovement.",
    "descriptor": "\nComments: Joint 1st Ego4D and 10th EPIC Workshop (EPIC@CVPR2022) Extended Abstract\n",
    "authors": [
      "Takuma Yagi",
      "Md Tasnimul Hasan",
      "Yoichi Sato"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.05319"
  },
  {
    "id": "arXiv:2206.05323",
    "title": "Memory Classifiers: Two-stage Classification for Robustness in Machine  Learning",
    "abstract": "The performance of machine learning models can significantly degrade under\ndistribution shifts of the data. We propose a new method for classification\nwhich can improve robustness to distribution shifts, by combining expert\nknowledge about the ``high-level\" structure of the data with standard\nclassifiers. Specifically, we introduce two-stage classifiers called\n\\textit{memory classifiers}. First, these identify prototypical data points --\n\\textit{memories} -- to cluster the training data. This step is based on\nfeatures designed with expert guidance; for instance, for image data they can\nbe extracted using digital image processing algorithms. Then, within each\ncluster, we learn local classifiers based on finer discriminating features, via\nstandard models like deep neural networks. We establish generalization bounds\nfor memory classifiers. We illustrate in experiments that they can improve\ngeneralization and robustness to distribution shifts on image datasets. We show\nimprovements which push beyond standard data augmentation techniques.",
    "descriptor": "",
    "authors": [
      "Souradeep Dutta",
      "Yahan Yang",
      "Elena Bernardis",
      "Edgar Dobriban",
      "Insup Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.05323"
  },
  {
    "id": "arXiv:2206.05330",
    "title": "The Gender Gap in Scholarly Self-Promotion on Social Media",
    "abstract": "Self-promotion in science is ubiquitous but not exercised to the same extent\nby everyone. It is unclear whether there are gender differences in the\nfrequency of self-promotion or the benefits individuals get from it. Here, we\nexamine gender differences in scholarly self-promotion using 7M Tweet mentions\nof 539K research papers published in 2018 by 1.3M authors. Our analysis shows\nthat female authors are significantly less likely than male authors to promote\ntheir papers, even after controlling for a number of important factors\nincluding journal impact, affiliation prestige, author productivity and number\nof citations, authorship position, number of coauthors, and research topics.\nThe magnitude of the gender gap is more strongly impacted by papers' journal\nimpact than by authors' affiliation prestige, their previous productivity, or\nacademic discipline. In particular, male scholars are 60\\% more likely to\nself-promote than comparable female scholars papers published in journals with\nvery high impact factor, whereas the same probability is only 28\\% for\npublications in low impact journals. Although women self-promote less often\noverall, when they do, their papers receive slightly more mentions on Twitter.\nOur findings offer the first large-scale evidence for the gender gap in\nscholarly self-promotion online and unpack details about the circumstances\nunder which discrepancies in self-promotion are the most substantial, helping\ninform policy aimed at closing the gender gap in visibility and recognition.",
    "descriptor": "",
    "authors": [
      "Hao Peng",
      "Misha Teplitskiy",
      "Daniel M. Romero",
      "Em\u0151ke-\u00c1gnes Horv\u00e1t"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.05330"
  },
  {
    "id": "arXiv:2206.05335",
    "title": "Synthetic Over-sampling for Imbalanced Node Classification with Graph  Neural Networks",
    "abstract": "In recent years, graph neural networks (GNNs) have achieved state-of-the-art\nperformance for node classification. However, most existing GNNs would suffer\nfrom the graph imbalance problem. In many real-world scenarios, node classes\nare imbalanced, with some majority classes making up most parts of the graph.\nThe message propagation mechanism in GNNs would further amplify the dominance\nof those majority classes, resulting in sub-optimal classification performance.\nIn this work, we seek to address this problem by generating pseudo instances of\nminority classes to balance the training data, extending previous\nover-sampling-based techniques. This task is non-trivial, as those techniques\nare designed with the assumption that instances are independent. Neglection of\nrelation information would complicate this oversampling process. Furthermore,\nthe node classification task typically takes the semi-supervised setting with\nonly a few labeled nodes, providing insufficient supervision for the generation\nof minority instances. Generated new nodes of low quality would harm the\ntrained classifier. In this work, we address these difficulties by synthesizing\nnew nodes in a constructed embedding space, which encodes both node attributes\nand topology information. Furthermore, an edge generator is trained\nsimultaneously to model the graph structure and provide relations for new\nsamples. To further improve the data efficiency, we also explore synthesizing\nmixed ``in-between'' nodes to utilize nodes from the majority class in this\nover-sampling process. Experiments on real-world datasets validate the\neffectiveness of our proposed framework.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2103.08826\n",
    "authors": [
      "Tianxiang Zhao",
      "Xiang Zhang",
      "Suhang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.05335"
  },
  {
    "id": "arXiv:2206.05336",
    "title": "How much can one learn from a single solution of a PDE?",
    "abstract": "Linear evolution PDE $\\partial_t u(x,t) = -\\mathcal{L} u$, where\n$\\mathcal{L}$ is a strongly elliptic operator independent of time, is studied\nas an example to show if one can superpose snapshots of a single (or a finite\nnumber of) solution(s) to construct an arbitrary solution. Our study shows that\nit depends on the growth rate of the eigenvalues, $\\mu_n$, of $\\mathcal{L}$ in\nterms of $n$. When the statement is true, a simple data-driven approach for\nmodel reduction and approximation of an arbitrary solution of a PDE without\nknowing the underlying PDE is designed. Numerical experiments are presented to\ncorroborate our analysis.",
    "descriptor": "",
    "authors": [
      "Hongkai Zhao",
      "Yimin Zhong"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.05336"
  },
  {
    "id": "arXiv:2206.05339",
    "title": "Characterizing Properties and Trade-offs of Centralized Delegation  Mechanisms in Liquid Democracy",
    "abstract": "Liquid democracy is a form of transitive delegative democracy that has\nreceived a flurry of scholarly attention from the computer science community in\nrecent years. In its simplest form, every agent starts with one vote and may\nhave other votes assigned to them via delegation from other agents. They can\nchoose to delegate all votes assigned to them to another agent or vote directly\nwith all votes assigned to them. However, many proposed realizations of liquid\ndemocracy allow for agents to express their delegation/voting preferences in\nmore complex ways (e.g., a ranked list of potential delegates) and employ a\ncentralized delegation mechanism to compute the final vote tally. In doing so,\ncentralized delegation mechanisms can make decisions that affect the outcome of\na vote and where/whether agents are able to delegate their votes. Much of the\nanalysis thus far has focused on the ability of these mechanisms to make a\ncorrect choice. We extend this analysis by introducing and formalizing other\nimportant properties of a centralized delegation mechanism in liquid democracy\nwith respect to crucial features such as accountability, transparency,\nexplainability, fairness, and user agency. In addition, we evaluate existing\nmethods in terms of these properties, show how some prior work can be augmented\nto achieve desirable properties, prove impossibility results for achieving\ncertain sets of properties simultaneously, and highlight directions for future\nwork.",
    "descriptor": "\nComments: 10 pages, 4 figures, to appear in ACM FAccT 2022\n",
    "authors": [
      "Brian Brubach",
      "Audrey Ballarin",
      "Heeba Nazeer"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2206.05339"
  },
  {
    "id": "arXiv:2206.05344",
    "title": "Differentiable Rendering of Neural SDFs through Reparameterization",
    "abstract": "We present a method to automatically compute correct gradients with respect\nto geometric scene parameters in neural SDF renderers. Recent physically-based\ndifferentiable rendering techniques for meshes have used edge-sampling to\nhandle discontinuities, particularly at object silhouettes, but SDFs do not\nhave a simple parametric form amenable to sampling. Instead, our approach\nbuilds on area-sampling techniques and develops a continuous warping function\nfor SDFs to account for these discontinuities. Our method leverages the\ndistance to surface encoded in an SDF and uses quadrature on sphere tracer\npoints to compute this warping function. We further show that this can be done\nby subsampling the points to make the method tractable for neural SDFs. Our\ndifferentiable renderer can be used to optimize neural shapes from multi-view\nimages and produces comparable 3D reconstructions to recent SDF-based inverse\nrendering methods, without the need for 2D segmentation masks to guide the\ngeometry optimization and no volumetric approximations to the geometry.",
    "descriptor": "",
    "authors": [
      "Sai Praveen Bangaru",
      "Micha\u00ebl Gharbi",
      "Tzu-Mao Li",
      "Fujun Luan",
      "Kalyan Sunkavalli",
      "Milo\u0161 Ha\u0161an",
      "Sai Bi",
      "Zexiang Xu",
      "Gilbert Bernstein",
      "Fr\u00e9do Durand"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.05344"
  },
  {
    "id": "arXiv:2206.05352",
    "title": "Cross-TOP: Zero-Shot Cross-Schema Task-Oriented Parsing",
    "abstract": "Deep learning methods have enabled task-oriented semantic parsing of\nincreasingly complex utterances. However, a single model is still typically\ntrained and deployed for each task separately, requiring labeled training data\nfor each, which makes it challenging to support new tasks, even within a single\nbusiness vertical (e.g., food-ordering or travel booking). In this paper we\ndescribe Cross-TOP (Cross-Schema Task-Oriented Parsing), a zero-shot method for\ncomplex semantic parsing in a given vertical. By leveraging the fact that user\nrequests from the same vertical share lexical and semantic similarities, a\nsingle cross-schema parser is trained to service an arbitrary number of tasks,\nseen or unseen, within a vertical. We show that Cross-TOP can achieve high\naccuracy on a previously unseen task without requiring any additional training\ndata, thereby providing a scalable way to bootstrap semantic parsers for new\ntasks. As part of this work we release the FoodOrdering dataset, a\ntask-oriented parsing dataset in the food-ordering vertical, with utterances\nand annotations derived from five schemas, each from a different restaurant\nmenu.",
    "descriptor": "\nComments: Accepted for publication at NAACL 2022 workshop DeepLo, \"Deep Learning for Low-Resource NLP\"\n",
    "authors": [
      "Melanie Rubino",
      "Nicolas Guenon des Mesnards",
      "Uday Shah",
      "Nanjiang Jiang",
      "Weiqi Sun",
      "Konstantine Arkoudas"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05352"
  },
  {
    "id": "arXiv:2206.05353",
    "title": "Hamiltonian Quasigeodesics yield Nets",
    "abstract": "This note establishes that every polyhedron that has a Hamiltonian\nquasigeodesic can be edge-unfolded to a net.",
    "descriptor": "\nComments: 6 pages, 3 figures, 5 references\n",
    "authors": [
      "Joseph O'Rourke"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2206.05353"
  },
  {
    "id": "arXiv:2206.05355",
    "title": "Social Practices for Social Driven Conversations in Serious Games",
    "abstract": "This paper describes the model of social practice as a theoretical framework\nto manage conversation with the specific goal of training physicians in\ncommunicative skills. To this aim, the domain reasoner that manages the\nconversation in the Communicate! \\cite{jeuring} serious game is taken as a\nbasis. Because the choice of a specific Social Practice to follow in a\nsituation is non-trivial we use a probabilistic model for the selection of\nsocial practices as a step toward the implementation of an agent architecture\ncompliant with the social practice model.",
    "descriptor": "",
    "authors": [
      "Agnese Augello",
      "Manuel Gentile",
      "Frank Dignum"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.05355"
  },
  {
    "id": "arXiv:2206.05356",
    "title": "A Speedup Theorem for Asynchronous Computation with Applications to  Consensus and Approximate Agreement",
    "abstract": "We study two fundamental problems of distributed computing, consensus and\napproximate agreement, through a novel approach for proving lower bounds and\nimpossibility results, that we call the asynchronous speedup theorem. For a\ngiven $n$-process task $\\Pi$ and a given computational model $M$, we define a\nnew task, called the closure of $\\Pi$ with respect to $M$. The asynchronous\nspeedup theorem states that if a task $\\Pi$ is solvable in $t\\geq 1$ rounds in\n$M$, then its closure w.r.t. $M$ is solvable in $t-1$ rounds in $M$. We prove\nthis theorem for iterated models, as long as the model allows solo executions.\nWe illustrate the power of our asynchronous speedup theorem by providing a new\nproof of the wait-free impossibility of consensus using read/write registers,\nand a new proof of the wait-free impossibility of solving consensus using\nregisters and test&set objects for $n>2$. The proof is merely by showing that,\nin each case, the closure of consensus (w.r.t. the corresponding model) is\nconsensus itself. Our main application is the study of the power of additional\nobjects, namely test&set and binary consensus, for wait-free solving\napproximate agreement faster. By analyzing the closure of approximate agreement\nw.r.t. each of the two models, we show that while these objects are more\npowerful than read/write registers from the computability perspective, they are\nnot more powerful as far as helping solving approximate agreement faster is\nconcerned.",
    "descriptor": "",
    "authors": [
      "Pierre Fraigniaud",
      "Ami Paz",
      "Sergio Rajsbaum"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.05356"
  },
  {
    "id": "arXiv:2206.05357",
    "title": "Anchor-Changing Regularized Natural Policy Gradient for Multi-Objective  Reinforcement Learning",
    "abstract": "We study policy optimization for Markov decision processes (MDPs) with\nmultiple reward value functions, which are to be jointly optimized according to\ngiven criteria such as proportional fairness (smooth concave scalarization),\nhard constraints (constrained MDP), and max-min trade-off. We propose an\nAnchor-changing Regularized Natural Policy Gradient (ARNPG) framework, which\ncan systematically incorporate ideas from well-performing first-order methods\ninto the design of policy optimization algorithms for multi-objective MDP\nproblems. Theoretically, the designed algorithms based on the ARNPG framework\nachieve $\\tilde{O}(1/T)$ global convergence with exact gradients. Empirically,\nthe ARNPG-guided algorithms also demonstrate superior performance compared to\nsome existing policy gradient-based approaches in both exact gradients and\nsample-based scenarios.",
    "descriptor": "",
    "authors": [
      "Ruida Zhou",
      "Tao Liu",
      "Dileep Kalathil",
      "P. R. Kumar",
      "Chao Tian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.05357"
  },
  {
    "id": "arXiv:2206.05359",
    "title": "Blades: A Simulator for Attacks and Defenses in Federated Learning",
    "abstract": "Federated learning enables distributed training across a set of clients,\nwithout requiring any of the participants to reveal their private training data\nto a centralized entity or each other. Due to the nature of decentralized\nexecution, federated learning is vulnerable to attacks from adversarial\n(Byzantine) clients by modifying the local updates to their desires. Therefore,\nit is important to develop robust federated learning algorithms that can defend\nByzantine clients without losing model convergence and performance. In the\nstudy of robustness problems, a simulator can simplify and accelerate the\nimplementation and evaluation of attack and defense strategies. However, there\nis a lack of open-source simulators to meet such needs. Herein, we present\nBlades, a scalable, extensible, and easily configurable simulator to assist\nresearchers and developers in efficiently implementing and validating novel\nstrategies against baseline algorithms in robust federated learning. Blades is\nbuilt upon a versatile distributed framework Ray, making it effortless to\nparallelize single machine code from a single CPU to multi-core, multi-GPU, or\nmulti-node with minimal configurations. Blades contains built-in\nimplementations of representative attack and defense strategies and provides\nuser-friendly interfaces to easily incorporate new ideas. We maintain the\nsource code and documents at https://github.com/bladesteam/blades.",
    "descriptor": "",
    "authors": [
      "Shenghui Li",
      "Li Ju",
      "Tianru Zhang",
      "Edith Ngai",
      "Thiemo Voigt"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.05359"
  },
  {
    "id": "arXiv:2206.05361",
    "title": "Object as a Service (OaaS): Enabling Object Abstraction in Serverless  Clouds",
    "abstract": "Function as a Service (FaaS) paradigm is getting widespread and is envisioned\nto be the next generation of cloud computing systems that mitigates the burden\nfor programmers and cloud solution architects. However, FaaS does not\nexplicitly deal with the data, and developers have to intervene and undergo the\nburden of managing the application data, often, via separate cloud services\n(e.g., AWS RDS). We overcome this problem of FaaS by borrowing the notion of\nobject from the object-oriented programming into the serverless systems. We\npropose a new paradigm on top of the function abstraction, known as Object as a\nService (OaaS), that offers encapsulation and abstraction benefits. The OaaS\nincorporates the application data into the object abstraction and relieves the\ndevelopers from dealing with separate cloud services for the data management.\nIt also unlocks opportunities for built-in optimization features, such as\nsoftware reusability, data locality, and caching. Moreover, OaaS enables\ndataflow programming such that the developers define a workflow of functions\ntransparently without getting involved into the synchronization and parallelism\naspects. We implemented a prototype of the OaaS platform that is low-overhead\nand scalable. We evaluated it under real-world settings in terms of the\nease-of-use, imposed overhead, and scalability. The results demonstrate that\nOaaS streamlines cloud programming and offers scalability with a minor overhead\nto the underlying cloud system.",
    "descriptor": "",
    "authors": [
      "Pawissanutt Lertpongrujikorn",
      "Mohsen Amini Salehi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.05361"
  },
  {
    "id": "arXiv:2206.05365",
    "title": "Object Detection, Recognition, Deep Learning, and the Universal Law of  Generalization",
    "abstract": "Object detection and recognition are fundamental functions underlying the\nsuccess of species. Because the appearance of an object exhibits a large\nvariability, the brain has to group these different stimuli under the same\nobject identity, a process of generalization. Does the process of\ngeneralization follow some general principles or is it an ad-hoc\n\"bag-of-tricks\"? The Universal Law of Generalization provided evidence that\ngeneralization follows similar properties across a variety of species and\ntasks. Here we test the hypothesis that the internal representations underlying\ngeneralization reflect the natural properties of object detection and\nrecognition in our environment rather than the specifics of the system solving\nthese problems. By training a deep-neural-network with images of \"clear\" and\n\"camouflaged\" animals, we found that with a proper choice of category\nprototypes, the generalization functions are monotone decreasing, similar to\nthe generalization functions of biological systems. Our findings support the\nhypothesis of the study.",
    "descriptor": "",
    "authors": [
      "Faris B. Rustom",
      "Haluk \u00d6\u011fmen",
      "Arash Yazdanbakhsh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.05365"
  },
  {
    "id": "arXiv:2206.05367",
    "title": "Research Software Publication Policy Case Study",
    "abstract": "Research software is increasingly recognized as a vital component of the\nscholarly record. Journals offer authors the opportunity to publish research\nsoftware papers, but often have different requirements for how these\npublications should be structured and how code should be verified. In this\nshort case study we gather data from 20 Physical Science journals to trace the\nfrequency, quality control, and publishing criteria for software papers. Our\ngoal with the case study is to provide a proof-of-concept for doing descriptive\nempirical work with software publication policies across numerous domains of\nscience and engineering. In the narrative we therefore provide descriptive\nstatistics showing how these journals differ in criteria required for\narchiving, linking, verifying, and documenting software as part of a formal\npublication. The contribution of this preliminary work is twofold: 1. We\nprovide case study of Physical Science research software publications over\ntime; 2. We demonstrate the use of a new survey method for analyzing research\nsoftware publication policies. In our conclusion, we describe how comparative\nresearch into software publication policies can provide better criteria and\nrequirements for an emerging software publication landscape.",
    "descriptor": "",
    "authors": [
      "Nic Weber"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2206.05367"
  },
  {
    "id": "arXiv:2206.05368",
    "title": "Learning to Rank Rationales for Explainable Recommendation",
    "abstract": "State-of-the-art recommender system (RS) mostly rely on complex deep neural\nnetwork (DNN) model structure, which makes it difficult to provide explanations\nalong with RS decisions. Previous researchers have proved that providing\nexplanations along with recommended items can help users make informed\ndecisions and improve their trust towards the uninterpretable blackbox system.\nIn model-agnostic explainable recommendation, system designers deploy a\nseparate explanation model to take as input from the decision model, and\ngenerate explanations to meet the goal of persuasiveness. In this work, we\nexplore the task of ranking textual rationales (supporting evidences) for\nmodel-agnostic explainable recommendation. Most of existing rationales ranking\nalgorithms only utilize the rationale IDs and interaction matrices to build\nlatent factor representations; and the semantic information within the textual\nrationales are not learned effectively. We argue that such design is suboptimal\nas the important semantic information within the textual rationales may be used\nto better profile user preferences and item features. Seeing this gap, we\npropose a model named Semantic-Enhanced Bayesian Personalized Explanation\nRanking (SE-BPER) to effectively combine the interaction information and\nsemantic information. SE-BPER first initializes the latent factor\nrepresentations with contextualized embeddings generated by transformer model,\nthen optimizes them with the interaction data. Extensive experiments show that\nsuch methodology improves the rationales ranking performance while simplifying\nthe model training process (fewer hyperparameters and faster convergence). We\nconclude that the optimal way to combine semantic and interaction information\nremains an open question in the task of rationales ranking.",
    "descriptor": "",
    "authors": [
      "Zhichao Xu",
      "Yi Han",
      "Tao Yang",
      "Anh Tran",
      "Qingyao Ai"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.05368"
  },
  {
    "id": "arXiv:2206.05370",
    "title": "A multi-objective constrained POMDP model for breast cancer screening",
    "abstract": "Breast cancer is a common and deadly disease, but it is often curable when\ndiagnosed early. While most countries have large-scale screening programs,\nthere is no consensus on a single globally accepted policy for breast cancer\nscreening. The complex nature of the disease; limited availability of screening\nmethods such as mammography, magnetic resonance imaging (MRI), and ultrasound\nscreening; and public health policies all factor into the development of\nscreening policies. Resource availability concerns necessitate the design of\npolicies which conform to a budget, a problem which can be modelled as a\nconstrained partially observable Markov decision process (CPOMDP). In this\nstudy, we propose a multi-objective CPOMDP model for breast cancer screening\nwith two objectives: minimize the lifetime risk of dying due to breast cancer\nand maximize the quality-adjusted life years. Additionally, we consider an\nexpanded action space which allows for screening methods beyond mammography.\nEach action has a unique impact on quality-adjusted life years and lifetime\nrisk, as well as a unique cost. Our results reveal the Pareto frontier of\noptimal solutions for average and high risk patients at different budget\nlevels, which can be used by decision makers to set policies in practice.",
    "descriptor": "",
    "authors": [
      "Can Kavaklioglu",
      "Mucahit Cevik",
      "Robert Helmeczi",
      "Davood Pirayesh Neghab"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.05370"
  },
  {
    "id": "arXiv:2206.05375",
    "title": "Generalizable Neural Radiance Fields for Novel View Synthesis with  Transformer",
    "abstract": "We propose a Transformer-based NeRF (TransNeRF) to learn a generic neural\nradiance field conditioned on observed-view images for the novel view synthesis\ntask. By contrast, existing MLP-based NeRFs are not able to directly receive\nobserved views with an arbitrary number and require an auxiliary pooling-based\noperation to fuse source-view information, resulting in the missing of\ncomplicated relationships between source views and the target rendering view.\nFurthermore, current approaches process each 3D point individually and ignore\nthe local consistency of a radiance field scene representation. These\nlimitations potentially can reduce their performance in challenging real-world\napplications where large differences between source views and a novel rendering\nview may exist. To address these challenges, our TransNeRF utilizes the\nattention mechanism to naturally decode deep associations of an arbitrary\nnumber of source views into a coordinate-based scene representation. Local\nconsistency of shape and appearance are considered in the ray-cast space and\nthe surrounding-view space within a unified Transformer network. Experiments\ndemonstrate that our TransNeRF, trained on a wide variety of scenes, can\nachieve better performance in comparison to state-of-the-art image-based neural\nrendering methods in both scene-agnostic and per-scene finetuning scenarios\nespecially when there is a considerable gap between source views and a\nrendering view.",
    "descriptor": "",
    "authors": [
      "Dan Wang",
      "Xinrui Cui",
      "Septimiu Salcudean",
      "Z. Jane Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.05375"
  },
  {
    "id": "arXiv:2206.05377",
    "title": "Fast building segmentation from satellite imagery and few local labels",
    "abstract": "Innovations in computer vision algorithms for satellite image analysis can\nenable us to explore global challenges such as urbanization and land use change\nat the planetary level. However, domain shift problems are a common occurrence\nwhen trying to replicate models that drive these analyses to new areas,\nparticularly in the developing world. If a model is trained with imagery and\nlabels from one location, then it usually will not generalize well to new\nlocations where the content of the imagery and data distributions are\ndifferent. In this work, we consider the setting in which we have a single\nlarge satellite imagery scene over which we want to solve an applied problem --\nbuilding footprint segmentation. Here, we do not necessarily need to worry\nabout creating a model that generalizes past the borders of our scene but can\ninstead train a local model. We show that surprisingly few labels are needed to\nsolve the building segmentation problem with very high-resolution (0.5m/px)\nsatellite imagery with this setting in mind. Our best model trained with just\n527 sparse polygon annotations (an equivalent of 1500 x 1500 densely labeled\npixels) has a recall of 0.87 over held out footprints and a R2 of 0.93 on the\ntask of counting the number of buildings in 200 x 200-meter windows. We apply\nour models over high-resolution imagery in Amman, Jordan in a case study on\nurban change detection.",
    "descriptor": "\nComments: Accepted at EarthVision 2022\n",
    "authors": [
      "Caleb Robinson",
      "Anthony Ortiz",
      "Hogeun Park",
      "Nancy Lozano Gracia",
      "Jon Kher Kaw",
      "Tina Sederholm",
      "Rahul Dodhia",
      "Juan M. Lavista Ferres"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05377"
  },
  {
    "id": "arXiv:2206.05379",
    "title": "A Benchmark for Compositional Visual Reasoning",
    "abstract": "A fundamental component of human vision is our ability to parse complex\nvisual scenes and judge the relations between their constituent objects. AI\nbenchmarks for visual reasoning have driven rapid progress in recent years with\nstate-of-the-art systems now reaching human accuracy on some of these\nbenchmarks. Yet, a major gap remains in terms of the sample efficiency with\nwhich humans and AI systems learn new visual reasoning tasks. Humans'\nremarkable efficiency at learning has been at least partially attributed to\ntheir ability to harness compositionality -- such that they can efficiently\ntake advantage of previously gained knowledge when learning new tasks. Here, we\nintroduce a novel visual reasoning benchmark, Compositional Visual Relations\n(CVR), to drive progress towards the development of more data-efficient\nlearning algorithms. We take inspiration from fluidic intelligence and\nnon-verbal reasoning tests and describe a novel method for creating\ncompositions of abstract rules and associated image datasets at scale. Our\nproposed benchmark includes measures of sample efficiency, generalization and\ntransfer across task rules, as well as the ability to leverage\ncompositionality. We systematically evaluate modern neural architectures and\nfind that, surprisingly, convolutional architectures surpass transformer-based\narchitectures across all performance measures in most data regimes. However,\nall computational models are a lot less data efficient compared to humans even\nafter learning informative visual representations using self-supervision.\nOverall, we hope that our challenge will spur interest in the development of\nneural architectures that can learn to harness compositionality toward more\nefficient learning.",
    "descriptor": "",
    "authors": [
      "Aimen Zerroug",
      "Mohit Vaishnav",
      "Julien Colin",
      "Sebastian Musslick",
      "Thomas Serre"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.05379"
  },
  {
    "id": "arXiv:2206.05380",
    "title": "Learning Imbalanced Datasets with Maximum Margin Loss",
    "abstract": "A learning algorithm referred to as Maximum Margin (MM) is proposed for\nconsidering the class-imbalance data learning issue: the trained model tends to\npredict the majority of classes rather than the minority ones. That is,\nunderfitting for minority classes seems to be one of the challenges of\ngeneralization. For a good generalization of the minority classes, we design a\nnew Maximum Margin (MM) loss function, motivated by minimizing a margin-based\ngeneralization bound through the shifting decision bound. The\ntheoretically-principled label-distribution-aware margin (LDAM) loss was\nsuccessfully applied with prior strategies such as re-weighting or re-sampling\nalong with the effective training schedule. However, they did not investigate\nthe maximum margin loss function yet. In this study, we investigate the\nperformances of two types of hard maximum margin-based decision boundary shift\nwith LDAM's training schedule on artificially imbalanced CIFAR-10/100 for fair\ncomparisons and effectiveness.",
    "descriptor": "",
    "authors": [
      "Haeyong Kang",
      "Thang Vu",
      "Chang D. Yoo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.05380"
  },
  {
    "id": "arXiv:2206.05381",
    "title": "Trivariate Spline Collocation Methods for Numerical Solution to 3D  Monge-Amp\u00e8re Equation",
    "abstract": "We use trivariate spline functions for the numerical solution of the\nDirichlet problem of the 3D elliptic Monge-Amp\\'ere equation. Mainly we use the\nspline collocation method introduced in \\cite{LL21} to numerically solve\niterative Poisson equations and use an averaged algorithm to ensure the\nconvergence of the iterations. We shall also establish the rate of convergence\nunder a sufficient condition and provide some numerical evidence to show the\nnumerical rates. Then we present many computational results to demonstrate that\nthis approach works very well. In particular, we tested many known convex\nsolutions as well as nonconvex solutions over convex and nonconvex domains and\ncompared them with several existing numerical methods to show the efficiency\nand effectiveness of our approach.",
    "descriptor": "",
    "authors": [
      "Ming-Jun Lai",
      "Jinsil Lee"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2206.05381"
  },
  {
    "id": "arXiv:2206.05389",
    "title": "High order two-grid finite difference methods for interface and internal  layer problems",
    "abstract": "Second order accurate Cartesian grid methods have been well developed for\ninterface problems in the literature. However, it is challenging to develop\nthird or higher order accurate methods for problems with curved interfaces and\ninternal boundaries. In this paper, alternative approaches based on two\ndifferent grids are developed for some interface and internal layer problems,\nwhich are different from adaptive mesh refinement (AMR) techniques. For one\ndimensional, or two-dimensional problems with straight interfaces or boundary\nlayers that are parallel to one of the axes, the discussion is relatively easy.\nOne of challenges is how to construct a fourth order compact finite difference\nscheme at boarder grid points that connect two meshes. A two-grid method that\nemploys a second order discretization near the interface in the fine mesh and a\nfourth order discretization away from the interface in the coarse and boarder\ngrid points is proposed. For two dimensional problems with a curved interface\nor an internal layer, a level set representation is utilized for which we can\nbuild a fine mesh within a tube $|\\varphi({\\bf x}) | \\le \\delta h$ of the\ninterface. A new super-third seven-point discretization that can guarantee the\ndiscrete maximum principle has been developed at hanging nodes. The coefficient\nmatrices of the finite difference equations developed in this paper are\nM-matrices, which leads to the convergence of the finite difference schemes.\nNon-trivial numerical examples presented in this paper have confirmed the\ndesired accuracy and convergence.",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Zhilin Li",
      "Kejia Pan",
      "Juan Ruiz"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.05389"
  },
  {
    "id": "arXiv:2206.05390",
    "title": "Transformer-based Self-Supervised Fish Segmentation in Underwater Videos",
    "abstract": "Underwater fish segmentation to estimate fish body measurements is still\nlargely unsolved due to the complex underwater environment. Relying on\nfully-supervised segmentation models requires collecting per-pixel labels,\nwhich is time-consuming and prone to overfitting. Self-supervised learning\nmethods can help avoid the requirement of large annotated training datasets,\nhowever, to be useful in real-world applications, they should achieve good\nsegmentation quality. In this paper, we introduce a Transformer-based method\nthat uses self-supervision for high-quality fish segmentation. Our proposed\nmodel is trained on videos -- without any annotations -- to perform fish\nsegmentation in underwater videos taken in situ in the wild. We show that when\ntrained on a set of underwater videos from one dataset, the proposed model\nsurpasses previous CNN-based and Transformer-based self-supervised methods and\nachieves performance relatively close to supervised methods on two new unseen\nunderwater video datasets. This demonstrates the great generalisability of our\nmodel and the fact that it does not need a pre-trained model. In addition, we\nshow that, due to its dense representation learning, our model is\ncompute-efficient. We provide quantitative and qualitative results that\ndemonstrate our model's significant capabilities.",
    "descriptor": "\nComments: 11 pages, 6 figures. Submitted to the journal, International Journal of Intelligent Systems\n",
    "authors": [
      "Alzayat Saleh",
      "Marcus Sheaves",
      "Dean Jerry",
      "Mostafa Rahimi Azghadi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.05390"
  },
  {
    "id": "arXiv:2206.05394",
    "title": "Applications of Deep Learning in Fish Habitat Monitoring: A Tutorial and  Survey",
    "abstract": "Marine ecosystems and their fish habitats are becoming increasingly important\ndue to their integral role in providing a valuable food source and conservation\noutcomes. Due to their remote and difficult to access nature, marine\nenvironments and fish habitats are often monitored using underwater cameras.\nThese cameras generate a massive volume of digital data, which cannot be\nefficiently analysed by current manual processing methods, which involve a\nhuman observer. DL is a cutting-edge AI technology that has demonstrated\nunprecedented performance in analysing visual data. Despite its application to\na myriad of domains, its use in underwater fish habitat monitoring remains\nunder explored. In this paper, we provide a tutorial that covers the key\nconcepts of DL, which help the reader grasp a high-level understanding of how\nDL works. The tutorial also explains a step-by-step procedure on how DL\nalgorithms should be developed for challenging applications such as underwater\nfish monitoring. In addition, we provide a comprehensive survey of key deep\nlearning techniques for fish habitat monitoring including classification,\ncounting, localization, and segmentation. Furthermore, we survey publicly\navailable underwater fish datasets, and compare various DL techniques in the\nunderwater fish monitoring domains. We also discuss some challenges and\nopportunities in the emerging field of deep learning for fish habitat\nprocessing. This paper is written to serve as a tutorial for marine scientists\nwho would like to grasp a high-level understanding of DL, develop it for their\napplications by following our step-by-step tutorial, and see how it is evolving\nto facilitate their research efforts. At the same time, it is suitable for\ncomputer scientists who would like to survey state-of-the-art DL-based\nmethodologies for fish habitat monitoring.",
    "descriptor": "\nComments: 26 pages, 7 figures. Submitted to the journal, Expert Systems With Applications\n",
    "authors": [
      "Alzayat Saleh",
      "Marcus Sheaves",
      "Dean Jerry",
      "Mostafa Rahimi Azghadi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.05394"
  },
  {
    "id": "arXiv:2206.05395",
    "title": "Why is constrained neural language generation particularly challenging?",
    "abstract": "Recent advances in deep neural language models combined with the capacity of\nlarge scale datasets have accelerated the development of natural language\ngeneration systems that produce fluent and coherent texts (to various degrees\nof success) in a multitude of tasks and application contexts. However,\ncontrolling the output of these models for desired user and task needs is still\nan open challenge. This is crucial not only to customizing the content and\nstyle of the generated language, but also to their safe and reliable deployment\nin the real world. We present an extensive survey on the emerging topic of\nconstrained neural language generation in which we formally define and\ncategorize the problems of natural language generation by distinguishing\nbetween conditions and constraints (the latter being testable conditions on the\noutput text instead of the input), present constrained text generation tasks,\nand review existing methods and evaluation metrics for constrained text\ngeneration. Our aim is to highlight recent progress and trends in this emerging\nfield, informing on the most promising directions and limitations towards\nadvancing the state-of-the-art of constrained neural language generation\nresearch.",
    "descriptor": "\nComments: This survey is specifically focused on constrained neural language generation. For a more general survey of NLG literature, please see \"Neural language generation: Formulation, methods, and evaluation\" at arXiv:2007.15780\n",
    "authors": [
      "Cristina Garbacea",
      "Qiaozhu Mei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.05395"
  },
  {
    "id": "arXiv:2206.05397",
    "title": "Software Engineering in Australasia",
    "abstract": "Six months ago an important call was made for researchers globally to provide\ninsights into the way Software Engineering is done in their region. Heeding\nthis call we hereby outline the position Software Engineering in Australasia\n(New Zealand and Australia). This article first considers the software\ndevelopment methods practices and tools that are popular in the Australasian\nsoftware engineering community. We then briefly review the particular strengths\nof software engineering researchers in Australasia. Finally we make an open\ncall for collaborators by reflecting on our current position and identifying\nfuture opportunities",
    "descriptor": "\nComments: Journal article, 1 figure, 3 pages\n",
    "authors": [
      "Sherlock A. Licorish",
      "Christoph Treude",
      "John Grundy",
      "Chakkrit Tantithamthavorn",
      "Kelly Blincoe",
      "Stephen MacDonell",
      "Li Li",
      "Jean-Guy Schneider"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.05397"
  },
  {
    "id": "arXiv:2206.05398",
    "title": "E$^2$PN: Efficient SE(3)-Equivariant Point Network",
    "abstract": "This paper proposes a new point-cloud convolution structure that learns\nSE(3)-equivariant features. Compared with existing SE(3)-equivariant networks,\nour design is lightweight, simple, and flexible to be incorporated into general\npoint-cloud learning networks. We strike a balance between the complexity and\ncapacity of our model by selecting an unconventional domain for the feature\nmaps. We further reduce the computational load by properly discretizing\n$\\mathbb{R}^3$ to fully leverage the rotational symmetry. Moreover, we employ a\npermutation layer to recover the full SE(3) group from its quotient space.\nExperiments show that our method achieves comparable or superior performance in\nvarious tasks while consuming much less memory and running faster than existing\nwork. The proposed method can foster the adoption of equivariant feature\nlearning in various practical applications based on point clouds and inspire\nfuture developments of equivariant feature learning for real-world\napplications.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Minghan Zhu",
      "Maani Ghaffari",
      "William A. Clark",
      "Huei Peng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.05398"
  },
  {
    "id": "arXiv:2206.05399",
    "title": "Building a Personalized Dialogue System with Prompt-Tuning",
    "abstract": "Dialogue systems without consistent responses are not fascinating. In this\nstudy, we build a dialogue system that can respond based on a given character\nsetting (persona) to bring consistency. Considering the trend of the rapidly\nincreasing scale of language models, we propose an approach that uses\nprompt-tuning, which has low learning costs, on pre-trained large-scale\nlanguage models. The results of automatic and manual evaluations in English and\nJapanese show that it is possible to build a dialogue system with more natural\nand personalized responses using less computational resources than fine-tuning.",
    "descriptor": "\nComments: Accepted to NAACL 2022 SRW\n",
    "authors": [
      "Tomohito Kasahara",
      "Daisuke Kawahara",
      "Nguyen Tung",
      "Shengzhe Li",
      "Kenta Shinzato",
      "Toshinori Sato"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.05399"
  },
  {
    "id": "arXiv:2206.05400",
    "title": "High-Definition Map Generation Technologies For Autonomous Driving: A  Review",
    "abstract": "Autonomous driving has been among the most popular and challenging topics in\nthe past few years. On the road to achieving full autonomy, researchers have\nutilized various sensors, such as LiDAR, camera, Inertial Measurement Unit\n(IMU), and GPS, and developed intelligent algorithms for autonomous driving\napplications such as object detection, object segmentation, obstacle avoidance,\nand path planning. High-definition (HD) maps have drawn lots of attention in\nrecent years. Because of the high precision and informative level of HD maps in\nlocalization, it has immediately become one of the critical components of\nautonomous driving. From big organizations like Baidu Apollo, NVIDIA, and\nTomTom to individual researchers, researchers have created HD maps for\ndifferent scenes and purposes for autonomous driving. It is necessary to review\nthe state-of-the-art methods for HD map generation. This paper reviews recent\nHD map generation technologies that leverage both 2D and 3D map generation.\nThis review introduces the concept of HD maps and their usefulness in\nautonomous driving and gives a detailed overview of HD map generation\ntechniques. We will also discuss the limitations of the current HD map\ngeneration technologies to motivate future research.",
    "descriptor": "\nComments: 25 pages, 17 figures, submitted to IEEE Transactions on Intelligent Vehicles\n",
    "authors": [
      "Zhibin Bao",
      "Sabir Hossain",
      "Haoxiang Lang",
      "Xianke Lin"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.05400"
  },
  {
    "id": "arXiv:2206.05406",
    "title": "Rethinking the Defense Against Free-rider Attack From the Perspective of  Model Weight Evolving Frequency",
    "abstract": "Federated learning (FL) is a distributed machine learning approach where\nmultiple clients collaboratively train a joint model without exchanging their\ndata. Despite FL's unprecedented success in data privacy-preserving, its\nvulnerability to free-rider attacks has attracted increasing attention.\nExisting defenses may be ineffective against highly camouflaged or high\npercentages of free riders. To address these challenges, we reconsider the\ndefense from a novel perspective, i.e., model weight evolving\nfrequency.Empirically, we gain a novel insight that during the FL's training,\nthe model weight evolving frequency of free-riders and that of benign clients\nare significantly different. Inspired by this insight, we propose a novel\ndefense method based on the model Weight Evolving Frequency, referred to as\nWEF-Defense.Specifically, we first collect the weight evolving frequency\n(defined as WEF-Matrix) during local training. For each client, it uploads the\nlocal model's WEF-Matrix to the server together with its model weight for each\niteration. The server then separates free-riders from benign clients based on\nthe difference in the WEF-Matrix. Finally, the server uses a personalized\napproach to provide different global models for corresponding clients.\nComprehensive experiments conducted on five datasets and five models\ndemonstrate that WEF-Defense achieves better defense effectiveness than the\nstate-of-the-art baselines.",
    "descriptor": "",
    "authors": [
      "Jinyin Chen",
      "Mingjun Li",
      "Tao Liu",
      "Haibin Zheng",
      "Yao Cheng",
      "Changting Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.05406"
  },
  {
    "id": "arXiv:2206.05407",
    "title": "Opportunistic Routing aided Cooperative Communication MRC Network with  Energy-Harvesting Nodes",
    "abstract": "In this paper, we consider a multi-hop cooperative network founded on two\nenergy-harvesting (EH) decode-and-forward (DF) relays which are provided with\nharvest-store-use (HSU) architecture to harvest energy from the ambience using\nthe energy buffers. For the sake of boosting the data delivery in this network,\nmaximal ratio combining (MRC) at destination to combine the signals received\nfrom source and relays, as well as an opportunistic routing (OR) algorithm\nwhich considers channel status information, location and energy buffer status\nof relays is proposed. With applying discrete-time continuous-state space\nMarkov chain model (DCSMC), the algorithm-based theoretical expression for\nlimiting distribution of stored energy in infinite-size buffer is derived.\nFurther more, with using both the limiting distributions of energy buffers and\nthe probability of transmitter candidates set, the algorithm-based theoretical\nexpressions for outage probability, throughput and timesolt cost for each data\nof the network are obtained. The simulation results are presented to validate\nthe derived algorithm-based theoretical expressions.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2205.06482\n",
    "authors": [
      "Lei Teng",
      "Wannian An",
      "Chen Dong",
      "Xiaodong Xu",
      "Boxiao Han"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.05407"
  },
  {
    "id": "arXiv:2206.05408",
    "title": "Multi-instrument Music Synthesis with Spectrogram Diffusion",
    "abstract": "An ideal music synthesizer should be both interactive and expressive,\ngenerating high-fidelity audio in realtime for arbitrary combinations of\ninstruments and notes. Recent neural synthesizers have exhibited a tradeoff\nbetween domain-specific models that offer detailed control of only specific\ninstruments, or raw waveform models that can train on all of music but with\nminimal control and slow generation.\nIn this work, we focus on a middle ground of neural synthesizers that can\ngenerate audio from MIDI sequences with arbitrary combinations of instruments\nin realtime. This enables training on a wide range of transcription datasets\nwith a single model, which in turn offers note-level control of composition and\ninstrumentation across a wide range of instruments.\nWe use a simple two-stage process: MIDI to spectrograms with an\nencoder-decoder Transformer, then spectrograms to audio with a generative\nadversarial network (GAN) spectrogram inverter. We compare training the decoder\nas an autoregressive model and as a Denoising Diffusion Probabilistic Model\n(DDPM) and find that the DDPM approach is superior both qualitatively and as\nmeasured by audio reconstruction and Fr\\'echet distance metrics.\nGiven the interactivity and generality of this approach, we find this to be a\npromising first step towards interactive and expressive neural synthesis for\narbitrary combinations of instruments and notes.",
    "descriptor": "",
    "authors": [
      "Curtis Hawthorne",
      "Ian Simon",
      "Adam Roberts",
      "Neil Zeghidour",
      "Josh Gardner",
      "Ethan Manilow",
      "Jesse Engel"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.05408"
  },
  {
    "id": "arXiv:2206.05414",
    "title": "Downlink Power Minimization in Intelligent Reconfigurable Surface-Aided  Security Classification Wireless Communications System",
    "abstract": "User privacy protection is considered a critical issue in wireless networks,\nwhich drives the demand for various secure information interaction techniques.\nIn this paper, we introduce an intelligent reflecting surface (IRS)-aided\nsecurity classification wireless communication system, which reduces the\ntransmit power of the base station (BS) by classifying users with different\nsecurity requirements. Specifically, we divide the users into confidential\nsubscribers with secure communication requirements and general communication\nusers with simple communication requirements. During the communication period,\nwe guarantee the secure rate of the confidential subscribers while ensuring the\nservice quality of the general communication users, thereby reducing the\ntransmit power of the BS. To realize such a secure and green information\ntransmission, the BS implements a beamforming design on the transmitted signal\nsuperimposed with artificial noise (AN) and then broadcasts it to users with\nthe assistance of the IRS's reflection. We develop an alternating optimization\nframework to minimize the BS downlink power with respect to the active\nbeamformers of the BS, the AN vector at the BS, and the reflection phase shifts\nof the IRS. A successive convex approximation (SCA) method is proposed so that\nthe nonconvex beamforming problems can be converted to tractable convex forms.\nThe simulation results demonstrate that the proposed algorithm is convergent\nand can reduce the transmit power by 20\\% compared to the best benchmark\nscheme.",
    "descriptor": "\nComments: 13 pages, 9 figures, Accepted by IEEE Systems Journal\n",
    "authors": [
      "Jintao Xing",
      "Tiejun Lv",
      "Yashuai Cao",
      "Jie Zeng",
      "Pingmu Huang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.05414"
  },
  {
    "id": "arXiv:2206.05416",
    "title": "Semi-Supervised Hierarchical Graph Classification",
    "abstract": "Node classification and graph classification are two graph learning problems\nthat predict the class label of a node and the class label of a graph\nrespectively. A node of a graph usually represents a real-world entity, e.g., a\nuser in a social network, or a document in a document citation network. In this\nwork, we consider a more challenging but practically useful setting, in which a\nnode itself is a graph instance. This leads to a hierarchical graph perspective\nwhich arises in many domains such as social network, biological network and\ndocument collection. We study the node classification problem in the\nhierarchical graph where a 'node' is a graph instance. As labels are usually\nlimited, we design a novel semi-supervised solution named SEAL-CI. SEAL-CI\nadopts an iterative framework that takes turns to update two modules, one\nworking at the graph instance level and the other at the hierarchical graph\nlevel. To enforce a consistency among different levels of hierarchical graph,\nwe propose the Hierarchical Graph Mutual Information (HGMI) and further present\na way to compute HGMI with theoretical guarantee. We demonstrate the\neffectiveness of this hierarchical graph modeling and the proposed SEAL-CI\nmethod on text and social network data.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:1904.05003\n",
    "authors": [
      "Jia Li",
      "Yongfeng Huang",
      "Heng Chang",
      "Yu Rong"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05416"
  },
  {
    "id": "arXiv:2206.05418",
    "title": "SAIBench: Benchmarking AI for Science",
    "abstract": "Scientific research communities are embracing AI-based solutions to target\ntractable scientific tasks and improve research workflows. However, the\ndevelopment and evaluation of such solutions are scattered across multiple\ndisciplines. We formalize the problem of scientific AI benchmarking, and\npropose a system called SAIBench in the hope of unifying the efforts and\nenabling low-friction on-boarding of new disciplines. The system approaches\nthis goal with SAIL, a domain-specific language to decouple research problems,\nAI models, ranking criteria, and software/hardware configuration into reusable\nmodules. We show that this approach is flexible and can adapt to problems, AI\nmodels, and evaluation methods defined in different perspectives. The project\nhomepage is https://www.computercouncil.org/SAIBench",
    "descriptor": "\nComments: Published in BenchCouncil Transactions on Benchmarks, Standards and Evaluations (TBench)\n",
    "authors": [
      "Yatao Li",
      "Jianfeng Zhan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.05418"
  },
  {
    "id": "arXiv:2206.05420",
    "title": "VAC2: Visual Analysis of Combined Causality in Event Sequences",
    "abstract": "Identifying causality behind complex systems plays a significant role in\ndifferent domains, such as decision making, policy implementations, and\nmanagement recommendations. However, existing causality studies on temporal\nevent sequences data mainly focus on individual causal discovery, which is\nincapable of exploiting combined causality. To fill the absence of combined\ncauses discovery on temporal event sequence data,eliminating and recruiting\nprinciples are defined to balance the effectiveness and controllability on\ncause combinations. We also leverage the Granger causality algorithm based on\nthe reactive point processes to describe impelling or inhibiting behavior\npatterns among entities. In addition, we design an informative and aesthetic\nvisual metaphor of \"electrocircuit\" to encode aggregated causality for ensuring\nour causality visualization is non-overlapping and non-intersecting. Diverse\nsorting strategies and aggregation layout are also embedded into our\nparallel-based, directed and weighted hypergraph for illustrating combined\ncausality. Our developed combined causality visual analysis system can help\nusers effectively explore combined causes as well as an individual cause. This\ninteractive system supports multi-level causality exploration with diverse\nordering strategies and a focus and context technique to help users obtain\ndifferent levels of information abstraction. The usefulness and effectiveness\nof the system are further evaluated by conducting a pilot user study and two\ncase studies on event sequence data.",
    "descriptor": "",
    "authors": [
      "Sujia Zhu",
      "Yue Shen",
      "Zihao Zhu",
      "Wang Xia",
      "Baofeng Chang",
      "Ronghua Liang",
      "Guodao Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.05420"
  },
  {
    "id": "arXiv:2206.05421",
    "title": "Greedy Relaxations of the Sparsest Permutation Algorithm",
    "abstract": "There has been an increasing interest in methods that exploit permutation\nreasoning to search for directed acyclic causal models, including the \"Ordering\nSearch\" of Teyssier and Kohler and GSP of Solus, Wang and Uhler. We extend the\nmethods of the latter by a permutation-based operation, tuck, and develop a\nclass of algorithms, namely GRaSP, that are efficient and pointwise consistent\nunder increasingly weaker assumptions than faithfulness. The most relaxed form\nof GRaSP outperforms many state-of-the-art causal search algorithms in\nsimulation, allowing efficient and accurate search even for dense graphs and\ngraphs with more than 100 variables.",
    "descriptor": "\nComments: 36 pages, 16 figures, 4 tables, 2 algorithms, accepted, UAI (Uncertainty in Artificial Intelligence) 2022\n",
    "authors": [
      "Wai-Yin Lam",
      "Bryan Andrews",
      "Joseph Ramsey"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.05421"
  },
  {
    "id": "arXiv:2206.05422",
    "title": "Access Control of Semantic Segmentation Models Using Encrypted Feature  Maps",
    "abstract": "In this paper, we propose an access control method with a secret key for\nsemantic segmentation models for the first time so that unauthorized users\nwithout a secret key cannot benefit from the performance of trained models. The\nmethod enables us not only to provide a high segmentation performance to\nauthorized users but to also degrade the performance for unauthorized users. We\nfirst point out that, for the application of semantic segmentation,\nconventional access control methods which use encrypted images for\nclassification tasks are not directly applicable due to performance\ndegradation. Accordingly, in this paper, selected feature maps are encrypted\nwith a secret key for training and testing models, instead of input images. In\nan experiment, the protected models allowed authorized users to obtain almost\nthe same performance as that of non-protected models but also with robustness\nagainst unauthorized access without a key.",
    "descriptor": "",
    "authors": [
      "Hiroki Ito",
      "AprilPyone MaungMaung",
      "Sayaka Shiota",
      "Hitoshi Kiya"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.05422"
  },
  {
    "id": "arXiv:2206.05424",
    "title": "Precise Affordance Annotation for Egocentric Action Video Datasets",
    "abstract": "Object affordance is an important concept in human-object interaction,\nproviding information on action possibilities based on human motor capacity and\nobjects' physical property thus benefiting tasks such as action anticipation\nand robot imitation learning. However, existing datasets often: 1) mix up\naffordance with object functionality; 2) confuse affordance with goal-related\naction; and 3) ignore human motor capacity. This paper proposes an efficient\nannotation scheme to address these issues by combining goal-irrelevant motor\nactions and grasp types as affordance labels and introducing the concept of\nmechanical action to represent the action possibilities between two objects. We\nprovide new annotations by applying this scheme to the EPIC-KITCHENS dataset\nand test our annotation with tasks such as affordance recognition. We\nqualitatively verify that models trained with our annotation can distinguish\naffordance and mechanical actions.",
    "descriptor": "\nComments: Technical report for CVPR 2022 EPIC-Ego4D Workshop\n",
    "authors": [
      "Zecheng Yu",
      "Yifei Huang",
      "Ryosuke Furuta",
      "Takuma Yagi",
      "Yusuke Goutsu",
      "Yoichi Sato"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.05424"
  },
  {
    "id": "arXiv:2206.05426",
    "title": "Multi-party Holomeetings: Toward a New Era of Low-Cost Volumetric  Holographic Meetings in Virtual Reality",
    "abstract": "Fueled by advances in multi-party communications, increasingly mature\nimmersive technologies being adopted, and the COVID-19 pandemic, a new wave of\nsocial virtual reality (VR) platforms have emerged to support socialization,\ninteraction, and collaboration among multiple remote users who are integrated\ninto shared virtual environments. Social VR aims to increase levels of\n(co-)presence and interaction quality by overcoming the limitations of 2D\nwindowed representations in traditional multi-party video conferencing tools,\nalthough most existing solutions rely on 3D avatars to represent users. This\narticle presents a social VR platform that supports real-time volumetric\nholographic representations of users that are based on point clouds captured by\noff-the-shelf RGB-D sensors, and it analyzes the platform's potential for\nconducting interactive holomeetings (i.e., holoconferencing scenarios). This\nwork evaluates such a platform's performance and readiness for conducting\nmeetings with up to four users, and it provides insights into aspects of the\nuser experience when using single-camera and low-cost capture systems in\nscenarios with both frontal and side viewpoints. Overall, the obtained results\nconfirm the platform's maturity and the potential of holographic communications\nfor conducting interactive multi-party meetings, even when using low-cost\nsystems and single-camera capture systems in scenarios where users are sitting\nor have a limited translational movement along the X, Y, and Z axes within the\n3D virtual environment (commonly known as 3 Degrees of Freedom plus, 3DoF+)",
    "descriptor": "\nComments: 36 pages\n",
    "authors": [
      "Sergi Fern\u00e1ndez",
      "Mario Montagud",
      "Gianluca Cernigliaro",
      "David Rinc\u00f3n"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.05426"
  },
  {
    "id": "arXiv:2206.05431",
    "title": "Learned reconstruction with convergence guarantees",
    "abstract": "In recent years, deep learning has achieved remarkable empirical success for\nimage reconstruction. This has catalyzed an ongoing quest for precise\ncharacterization of correctness and reliability of data-driven methods in\ncritical use-cases, for instance in medical imaging. Notwithstanding the\nexcellent performance and efficacy of deep learning-based methods, concerns\nhave been raised regarding their stability, or lack thereof, with serious\npractical implications. Significant advances have been made in recent years to\nunravel the inner workings of data-driven image recovery methods, challenging\ntheir widely perceived black-box nature. In this article, we will specify\nrelevant notions of convergence for data-driven image reconstruction, which\nwill form the basis of a survey of learned methods with mathematically rigorous\nreconstruction guarantees. An example that is highlighted is the role of ICNN,\noffering the possibility to combine the power of deep learning with classical\nconvex regularization theory for devising methods that are provably convergent.\nThis survey article is aimed at both methodological researchers seeking to\nadvance the frontiers of our understanding of data-driven image reconstruction\nmethods as well as practitioners, by providing an accessible description of\nconvergence concepts and by placing some of the existing empirical practices on\na solid mathematical foundation.",
    "descriptor": "",
    "authors": [
      "Subhadip Mukherjee",
      "Andreas Hauptmann",
      "Ozan \u00d6ktem",
      "Marcelo Pereyra",
      "Carola-Bibiane Sch\u00f6nlieb"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05431"
  },
  {
    "id": "arXiv:2206.05432",
    "title": "Luminance-Guided Chrominance Image Enhancement for HEVC Intra Coding",
    "abstract": "In this paper, we propose a luminance-guided chrominance image enhancement\nconvolutional neural network for HEVC intra coding. Specifically, we firstly\ndevelop a gated recursive asymmetric-convolution block to restore each degraded\nchrominance image, which generates an intermediate output. Then, guided by the\nluminance image, the quality of this intermediate output is further improved,\nwhich finally produces the high-quality chrominance image. When our proposed\nmethod is adopted in the compression of color images with HEVC intra coding, it\nachieves 28.96% and 16.74% BD-rate gains over HEVC for the U and V images,\nrespectively, which accordingly demonstrate its superiority.",
    "descriptor": "\nComments: ISCAS 2022\n",
    "authors": [
      "Hewei Liu",
      "Renwei Yang",
      "Shuyuan Zhu",
      "Xing Wen",
      "Bing Zeng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.05432"
  },
  {
    "id": "arXiv:2206.05437",
    "title": "ACMP: Allen-Cahn Message Passing for Graph Neural Networks with Particle  Phase Transition",
    "abstract": "Neural message passing is a basic feature extraction unit for\ngraph-structured data that takes account of the impact of neighboring node\nfeatures in network propagation from one layer to the next. We model such\nprocess by an interacting particle system with attractive and repulsive forces\nand the Allen-Cahn force arising in the modeling of phase transition. The\nsystem is a reaction-diffusion process which can separate particles to\ndifferent clusters. This induces an Allen-Cahn message passing (ACMP) for graph\nneural networks where the numerical iteration for the solution constitutes the\nmessage passing propagation. The mechanism behind ACMP is phase transition of\nparticles which enables the formation of multi-clusters and thus GNNs\nprediction for node classification. ACMP can propel the network depth to\nhundreds of layers with theoretically proven strictly positive lower bound of\nthe Dirichlet energy. It thus provides a deep model of GNNs which circumvents\nthe common GNN problem of oversmoothing. Experiments for various real node\nclassification datasets, with possible high homophily difficulty, show the GNNs\nwith ACMP can achieve state of the art performance with no decay of Dirichlet\nenergy.",
    "descriptor": "",
    "authors": [
      "Yuelin Wang",
      "Kai Yi",
      "Xinliang Liu",
      "Yu Guang Wang",
      "Shi Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2206.05437"
  },
  {
    "id": "arXiv:2206.05438",
    "title": "Guaranteeing Timed Opacity using Parametric Timed Model Checking",
    "abstract": "Information leakage can have dramatic consequences on systems security. Among\nharmful information leaks, the timing information leakage occurs whenever an\nattacker successfully deduces confidential internal information. In this work,\nwe consider that the attacker has access (only) to the system execution time.\nWe address the following timed opacity problem: given a timed system, a private\nlocation and a final location, synthesize the execution times from the initial\nlocation to the final location for which one cannot deduce whether the system\nwent through the private location. We also consider the full timed opacity\nproblem, asking whether the system is opaque for all execution times. We show\nthat these problems are decidable for timed automata (TAs) but become\nundecidable when one adds parameters, yielding parametric timed automata\n(PTAs). We identify a subclass with some decidability results. We then devise\nan algorithm for synthesizing PTAs parameter valuations guaranteeing that the\nresulting TA is opaque. We finally show that our method can also apply to\nprogram analysis.",
    "descriptor": "\nComments: This is the author version of the manuscript of the same name published in ACM Transactions on Software Engineering and Methodology (ToSEM). This work is partially supported by the ANR national research program PACS (ANR-14-CE28-0002), by the ANR-NRF research program ProMiS (ANR-19-CE25-0015), and by ERATO HASUO Metamathematics for Systems Design Project (No. JPMJER1603), JST. arXiv admin note: substantial text overlap with arXiv:1907.00537\n",
    "authors": [
      "\u00c9tienne Andr\u00e9",
      "Didier Lime",
      "Dylan Marinho",
      "Jun Sun"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.05438"
  },
  {
    "id": "arXiv:2206.05442",
    "title": "A Dataset and Benchmark for Automatically Answering and Generating  Machine Learning Final Exams",
    "abstract": "Can a machine learn machine learning? We propose to answer this question\nusing the same criteria we use to answer a similar question: can a human learn\nmachine learning? We automatically answer MIT final exams in Introduction to\nMachine Learning at a human level. The course is a large undergraduate class\nwith around five hundred students each semester. Recently, program synthesis\nand few-shot learning solved university-level problem set questions in\nmathematics and STEM courses at a human level. In this work, we solve questions\nfrom final exams that differ from problem sets in several ways: the questions\nare longer, have multiple parts, are more complicated, and span a broader set\nof topics. We provide a new dataset and benchmark of questions from eight MIT\nIntroduction to Machine Learning final exams between Fall 2017 and Spring 2022\nand provide code for automatically answering these questions and generating new\nquestions. We perform ablation studies comparing zero-shot learning with\nfew-shot learning, chain-of-thought prompting, GPT-3 pre-trained on text and\nCodex fine-tuned on code on a range of machine learning topics and find that\nfew-shot learning methods perform best. We make our data and code publicly\navailable for the machine learning community.",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Sarah Zhang",
      "Reece Shuttleworth",
      "Derek Austin",
      "Yann Hicke",
      "Leonard Tang",
      "Sathwik Karnik",
      "Darnell Granberry",
      "Iddo Drori"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05442"
  },
  {
    "id": "arXiv:2206.05446",
    "title": "A Decomposition-Based Approach for Evaluating Inter-Annotator  Disagreement in Narrative Analysis",
    "abstract": "In this work, we explore sources of inter-annotator disagreement in narrative\nanalysis, in light of the question of whether or not a narrative plot exists in\nthe text. For this purpose, we present a method for a conceptual decomposition\nof an existing annotation into two separate levels: (1) \\textbf{whether} or not\na narrative plot exists in the text, and (2) \\textbf{which} plot elements exist\nin the text. We apply this method to an existing dataset of sentences annotated\nwith three different narrative plot elements: \\textit{Complication},\n\\textit{Resolution} and \\textit{Success}. We then employ statistical analysis\nin order to quantify how much of the inter-annotator disagreement can be\nexplained by each of the two levels. We further perform a qualitative analysis\nof disagreement cases in each level, observing several sources of disagreement,\nsuch as text ambiguity, scheme definition and personal differences between the\nannotators. The insights gathered on the dataset may serve to reduce\ninter-annotator disagreement in future annotation endeavors. We conclude with a\nbroader discussion on the potential implications of our approach in studying\nand evaluating inter-annotator disagreement in other settings.",
    "descriptor": "",
    "authors": [
      "Effi Levi",
      "Shaul R. Shenhav"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.05446"
  },
  {
    "id": "arXiv:2206.05447",
    "title": "Enhancing Explainability of Hyperparameter Optimization via Bayesian  Algorithm Execution",
    "abstract": "Despite all the benefits of automated hyperparameter optimization (HPO), most\nmodern HPO algorithms are black-boxes themselves. This makes it difficult to\nunderstand the decision process which lead to the selected configuration,\nreduces trust in HPO, and thus hinders its broad adoption. Here, we study the\ncombination of HPO with interpretable machine learning (IML) methods such as\npartial dependence plots. However, if such methods are naively applied to the\nexperimental data of the HPO process in a post-hoc manner, the underlying\nsampling bias of the optimizer can distort interpretations. We propose a\nmodified HPO method which efficiently balances the search for the global\noptimum w.r.t. predictive performance and the reliable estimation of IML\nexplanations of an underlying black-box function by coupling Bayesian\noptimization and Bayesian Algorithm Execution. On benchmark cases of both\nsynthetic objectives and HPO of a neural network, we demonstrate that our\nmethod returns more reliable explanations of the underlying black-box without a\nloss of optimization performance.",
    "descriptor": "",
    "authors": [
      "Julia Moosbauer",
      "Giuseppe Casalicchio",
      "Marius Lindauer",
      "Bernd Bischl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.05447"
  },
  {
    "id": "arXiv:2206.05454",
    "title": "A General framework for PAC-Bayes Bounds for Meta-Learning",
    "abstract": "Meta learning automatically infers an inductive bias, that includes the\nhyperparameter of the base-learning algorithm, by observing data from a finite\nnumber of related tasks. This paper studies PAC-Bayes bounds on meta\ngeneralization gap. The meta-generalization gap comprises two sources of\ngeneralization gaps: the environment-level and task-level gaps resulting from\nobservation of a finite number of tasks and data samples per task,\nrespectively. In this paper, by upper bounding arbitrary convex functions,\nwhich link the expected and empirical losses at the environment and also\nper-task levels, we obtain new PAC-Bayes bounds. Using these bounds, we develop\nnew PAC-Bayes meta-learning algorithms. Numerical examples demonstrate the\nmerits of the proposed novel bounds and algorithm in comparison to prior\nPAC-Bayes bounds for meta-learning.",
    "descriptor": "",
    "authors": [
      "Arezou Rezazadeh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.05454"
  },
  {
    "id": "arXiv:2206.05457",
    "title": "Testing Ocean Software with Metamorphic Testing",
    "abstract": "Advancing ocean science has a significant impact to the development of the\nworld, from operating a safe navigation for vessels to maintaining a healthy\nand diverse ocean ecosystem. Various ocean software systems have been\nextensively adopted for different purposes, for instance, predicting hourly sea\nlevel elevation across shorelines, simulating large-scale ocean circulations,\nas well as integrating into Earth system models for weather forecasts and\nclimate projections. Regardless of their significance, guaranteeing the\ntrustworthiness of ocean software and modelling systems is a long-standing\nchallenge. The testing of ocean software suffers a lot from the so-called\noracle problem, which refers to the absence of test oracles mainly due to the\nnonlinear interactions of multiple physical variables and the high complexity\nin computation. In the ocean, observed tidal signals are distorted by\nnon-deterministic physical variables, hindering us from knowing the \"true\"\nastronomical tidal constituents existing in the timeseries. In this paper, we\npresent how to test tidal analysis and prediction (TAP) software based on\nmetamorphic testing (MT), a simple yet effective testing approach to the oracle\nproblem. In particular, we construct metamorphic relations from the periodic\nproperty of astronomical tide, and then use them to successfully detect a\nreal-life defect in an open-source TAP software. We also conduct a series of\nexperiments to further demonstrate the applicability and effectiveness of MT in\nthe testing of TAP software. Our study not only justifies the potential of MT\nin testing more complex ocean software and modelling systems, but also can be\nexpanded to assess and improve the quality of a broader range of scientific\nsimulation software systems.",
    "descriptor": "\nComments: 7 pages, 3 tables\n",
    "authors": [
      "Quang-Hung Luu",
      "Huai Liu",
      "Tsong Yueh Chen",
      "Hai L. Vu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.05457"
  },
  {
    "id": "arXiv:2206.05459",
    "title": "NPU-Accelerated Imitation Learning for Thermal Optimization of  QoS-Constrained Heterogeneous Multi-Cores",
    "abstract": "Application migration and dynamic voltage and frequency scaling (DVFS) are\nindispensable means for fully exploiting the available potential in thermal\noptimization of a heterogeneous clustered multi-core processor under\nuser-defined quality of service (QoS) targets. However, selecting the core to\nexecute each application and the voltage/frequency (V/f) levels of each cluster\nis a complex problem because 1) the diverse characteristics and QoS targets of\napplications require different optimizations, and 2) per-cluster DVFS requires\na global optimization considering all running applications. State-of-the-art\nresource management techniques for power or temperature minimization either\nrely on measurements that are often not available (such as power) or fail to\nconsider all the dimensions of the problem (e.g., by using simplified\nanalytical models). Imitation learning (IL) enables to use the optimality of an\noracle policy, yet at low run-time overhead, by training a model from oracle\ndemonstrations. We are the first to employ IL for temperature minimization\nunder QoS targets. We tackle the complexity by training a neural network (NN)\nand accelerate the NN inference using a neural processing unit (NPU). While\nsuch NN accelerators are becoming increasingly widespread on end devices, they\nare so far only used to accelerate user applications. In contrast, we use an\nexisting accelerator on a real platform to accelerate NN-based resource\nmanagement. Our evaluation on a HiKey 970 board with an Arm big.LITTLE CPU and\nan NPU shows significant temperature reductions at a negligible run-time\noverhead, with unseen applications and different cooling than used for\ntraining.",
    "descriptor": "",
    "authors": [
      "Martin Rapp",
      "Heba Khdr",
      "Nikita Krohmer",
      "J\u00f6rg Henkel"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2206.05459"
  },
  {
    "id": "arXiv:2206.05460",
    "title": "Hierarchical Conditional Variational Autoencoder Based Acoustic Anomaly  Detection",
    "abstract": "This paper aims to develop an acoustic signal-based unsupervised anomaly\ndetection method for automatic machine monitoring. Existing approaches such as\ndeep autoencoder (DAE), variational autoencoder (VAE), conditional variational\nautoencoder (CVAE) etc. have limited representation capabilities in the latent\nspace and, hence, poor anomaly detection performance. Different models have to\nbe trained for each different kind of machines to accurately perform the\nanomaly detection task. To solve this issue, we propose a new method named as\nhierarchical conditional variational autoencoder (HCVAE). This method utilizes\navailable taxonomic hierarchical knowledge about industrial facility to refine\nthe latent space representation. This knowledge helps model to improve the\nanomaly detection performance as well. We demonstrated the generalization\ncapability of a single HCVAE model for different types of machines by using\nappropriate conditions. Additionally, to show the practicability of the\nproposed approach, (i) we evaluated HCVAE model on different domain and (ii) we\nchecked the effect of partial hierarchical knowledge. Our results show that\nHCVAE method validates both of these points, and it outperforms the baseline\nsystem on anomaly detection task by utmost 15 % on the AUC score metric.",
    "descriptor": "",
    "authors": [
      "Harsh Purohit",
      "Takashi Endo",
      "Masaaki Yamamoto",
      "Yohei Kawaguchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.05460"
  },
  {
    "id": "arXiv:2206.05468",
    "title": "Network Function Computation With Different Secure Conditions",
    "abstract": "In this paper, we investigate function computation problems under different\nsecure conditions over a network with multiple source nodes and a single sink\nnode which desires a function of all source messages without error. A\nwiretapper has access to some edges of the network. Based on different\npractical requirements, we consider two secure conditions named as secure and\nuser secure respectively. The main parameter concerned here is the computing\nrate, which is the average times of the target function that can be computed\nsecurely or user securely without error for one use of the network. In the\nsecure case, a new upper bound which is tighter than the previous one is\nprovided for arithmetic sum functions and arbitrary networks. Moreover, we show\nthat the improved upper bound is strictly tight for tree-like networks. In the\nuser secure case, we give a sufficient and necessary condition for the\nexistence of user secure network codes and obtain an upper bound for the\ncomputation capacity.",
    "descriptor": "\nComments: 10 pages, 3 figures\n",
    "authors": [
      "Min Xu",
      "Gennian Ge",
      "Minqian Liu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.05468"
  },
  {
    "id": "arXiv:2206.05473",
    "title": "Comparative Snippet Generation",
    "abstract": "We model product reviews to generate comparative responses consisting of\npositive and negative experiences regarding the product. Specifically, we\ngenerate a single-sentence, comparative response from a given positive and a\nnegative opinion. We contribute the first dataset for this task of Comparative\nSnippet Generation from contrasting opinions regarding a product, and a\nperformance analysis of a pre-trained BERT model to generate such snippets.",
    "descriptor": "",
    "authors": [
      "Saurabh Jain",
      "Yisong Miao",
      "Min-Yen Kan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.05473"
  },
  {
    "id": "arXiv:2206.05475",
    "title": "Reducing Capacity Gap in Knowledge Distillation with Review Mechanism  for Crowd Counting",
    "abstract": "The lightweight crowd counting models, in particular knowledge distillation\n(KD) based models, have attracted rising attention in recent years due to their\nsuperiority on computational efficiency and hardware requirement. However,\nexisting KD based models usually suffer from the capacity gap issue, resulting\nin the performance of the student network being limited by the teacher network.\nIn this paper, we address this issue by introducing a novel review mechanism\nfollowing KD models, motivated by the review mechanism of human-beings during\nthe study. Thus, the proposed model is dubbed ReviewKD. The proposed model\nconsists of an instruction phase and a review phase, where we firstly exploit a\nwell-trained heavy teacher network to transfer its latent feature to a\nlightweight student network in the instruction phase, then in the review phase\nyield a refined estimate of the density map based on the learned feature\nthrough a review mechanism. The effectiveness of ReviewKD is demonstrated by a\nset of experiments over six benchmark datasets via comparing to the\nstate-of-the-art models. Numerical results show that ReviewKD outperforms\nexisting lightweight models for crowd counting, and can effectively alleviate\nthe capacity gap issue, and particularly has the performance beyond the teacher\nnetwork. Besides the lightweight models, we also show that the suggested review\nmechanism can be used as a plug-and-play module to further boost the\nperformance of a kind of heavy crowd counting models without modifying the\nneural network architecture and introducing any additional model parameter.",
    "descriptor": "",
    "authors": [
      "Yunxin Liu",
      "Qiaosi Yi",
      "Jinshan Zeng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2206.05475"
  },
  {
    "id": "arXiv:2206.05476",
    "title": "Sampling-based Estimation of the Number of Distinct Values in  Distributed Environment",
    "abstract": "In data mining, estimating the number of distinct values (NDV) is a\nfundamental problem with various applications. Existing methods for estimating\nNDV can be broadly classified into two categories: i) scanning-based methods,\nwhich scan the entire data and maintain a sketch to approximate NDV; and ii)\nsampling-based methods, which estimate NDV using sampling data rather than\naccessing the entire data warehouse. Scanning-based methods achieve a lower\napproximation error at the cost of higher I/O and more time. Sampling-based\nestimation is preferable in applications with a large data volume and a\npermissible error restriction due to its higher scalability. However, while the\nsampling-based method is more effective on a single machine, it is less\npractical in a distributed environment with massive data volumes. For obtaining\nthe final NDV estimators, the entire sample must be transferred throughout the\ndistributed system, incurring a prohibitive communication cost when the sample\nrate is significant. This paper proposes a novel sketch-based distributed\nmethod that achieves sub-linear communication costs for distributed\nsampling-based NDV estimation under mild assumptions. Our method leverages a\nsketch-based algorithm to estimate the sample's {\\em frequency of frequency} in\nthe {\\em distributed streaming model}, which is compatible with most classical\nsampling-based NDV estimators. Additionally, we provide theoretical evidence\nfor our method's ability to minimize communication costs in the worst-case\nscenario. Extensive experiments show that our method saves orders of magnitude\nin communication costs compared to existing sampling- and sketch-based methods.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Jiajun Li",
      "Zhewei Wei",
      "Bolin Ding",
      "Xiening Dai",
      "Lu Lu",
      "Jingren Zhou"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2206.05476"
  },
  {
    "id": "arXiv:2206.05478",
    "title": "Monitoring and Proactive Management of QoS Levels in Pervasive  Applications",
    "abstract": "The advent of Edge Computing (EC) as a promising paradigm that provides\nmultiple computation and analytics capabilities close to data sources opens new\npathways for novel applications. Nonetheless, the limited computational\ncapabilities of EC nodes and the expectation of ensuring high levels of QoS\nduring tasks execution impose strict requirements for innovative management\napproaches. Motivated by the need of maintaining a minimum level of QoS during\nEC nodes functioning, we elaborate a distributed and intelligent\ndecision-making approach for tasks scheduling. Our aim is to enhance the\nbehavior of EC nodes making them capable of securing high QoS levels. We\npropose that nodes continuously monitor QoS levels and systematically evaluate\nthe probability of violating them to proactively decide some tasks to be\noffloaded to peer nodes or Cloud. We present, describe and evaluate the\nproposed scheme through multiple experimental scenarios revealing its\nperformance and the benefits of the envisioned monitoring mechanism when\nserving processing requests in very dynamic environments like the EC.",
    "descriptor": "",
    "authors": [
      "Georgios Boulougaris",
      "Kostas Kolomvatsos"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05478"
  },
  {
    "id": "arXiv:2206.05480",
    "title": "CodeS: A Distribution Shift Benchmark Dataset for Source Code Learning",
    "abstract": "Over the past few years, deep learning (DL) has been continuously expanding\nits applications and becoming a driving force for large-scale source code\nanalysis in the big code era. Distribution shift, where the test set follows a\ndifferent distribution from the training set, has been a longstanding challenge\nfor the reliable deployment of DL models due to the unexpected accuracy\ndegradation. Although recent progress on distribution shift benchmarking has\nbeen made in domains such as computer vision and natural language process.\nLimited progress has been made on distribution shift analysis and benchmarking\nfor source code tasks, on which there comes a strong demand due to both its\nvolume and its important role in supporting the foundations of almost all\nindustrial sectors. To fill this gap, this paper initiates to propose CodeS, a\ndistribution shift benchmark dataset, for source code learning. Specifically,\nCodeS supports 2 programming languages (i.e., Java and Python) and 5 types of\ncode distribution shifts (i.e., task, programmer, time-stamp, token, and CST).\nTo the best of our knowledge, we are the first to define the code\nrepresentation-based distribution shifts. In the experiments, we first evaluate\nthe effectiveness of existing out-of-distribution detectors and the\nreasonability of the distribution shift definitions and then measure the model\ngeneralization of popular code learning models (e.g., CodeBERT) on\nclassification task. The results demonstrate that 1) only softmax score-based\nOOD detectors perform well on CodeS, 2) distribution shift causes the accuracy\ndegradation in all code classification models, 3) representation-based\ndistribution shifts have a higher impact on the model than others, and 4)\npre-trained models are more resistant to distribution shifts. We make CodeS\npublicly available, enabling follow-up research on the quality assessment of\ncode learning models.",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Qiang Hu",
      "Yuejun Guo",
      "Xiaofei Xie",
      "Maxime Cordy",
      "Lei Ma",
      "Mike Papadakis",
      "Yves Le Traon"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.05480"
  },
  {
    "id": "arXiv:2206.05483",
    "title": "Bilateral Dependency Optimization: Defending Against Model-inversion  Attacks",
    "abstract": "Through using only a well-trained classifier, model-inversion (MI) attacks\ncan recover the data used for training the classifier, leading to the privacy\nleakage of the training data. To defend against MI attacks, previous work\nutilizes a unilateral dependency optimization strategy, i.e., minimizing the\ndependency between inputs (i.e., features) and outputs (i.e., labels) during\ntraining the classifier. However, such a minimization process conflicts with\nminimizing the supervised loss that aims to maximize the dependency between\ninputs and outputs, causing an explicit trade-off between model robustness\nagainst MI attacks and model utility on classification tasks. In this paper, we\naim to minimize the dependency between the latent representations and the\ninputs while maximizing the dependency between latent representations and the\noutputs, named a bilateral dependency optimization (BiDO) strategy. In\nparticular, we use the dependency constraints as a universally applicable\nregularizer in addition to commonly used losses for deep neural networks (e.g.,\ncross-entropy), which can be instantiated with appropriate dependency criteria\naccording to different tasks. To verify the efficacy of our strategy, we\npropose two implementations of BiDO, by using two different dependency\nmeasures: BiDO with constrained covariance (BiDO-COCO) and BiDO with\nHilbert-Schmidt Independence Criterion (BiDO-HSIC). Experiments show that BiDO\nachieves the state-of-the-art defense performance for a variety of datasets,\nclassifiers, and MI attacks while suffering a minor classification-accuracy\ndrop compared to the well-trained classifier with no defense, which lights up a\nnovel road to defend against MI attacks.",
    "descriptor": "\nComments: Accepted to KDD 2022 (Research Track)\n",
    "authors": [
      "Xiong Peng",
      "Feng Liu",
      "Jingfen Zhang",
      "Long Lan",
      "Junjie Ye",
      "Tongliang Liu",
      "Bo Han"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05483"
  },
  {
    "id": "arXiv:2206.05488",
    "title": "Kaggle Kinship Recognition Challenge: Introduction of Convolution-Free  Model to boost conventional",
    "abstract": "This work aims to explore a convolution-free base classifier that can be used\nto widen the variations of the conventional ensemble classifier. Specifically,\nwe propose Vision Transformers as base classifiers to combine with CNNs for a\nunique ensemble solution in Kaggle kinship recognition. In this paper, we\nverify our proposed idea by implementing and optimizing variants of the Vision\nTransformer model on top of the existing CNN models. The combined models\nachieve better scores than conventional ensemble classifiers based solely on\nCNN variants. We demonstrate that highly optimized CNN ensembles publicly\navailable on the Kaggle Discussion board can easily achieve a significant boost\nin ROC score by simply ensemble with variants of the Vision Transformer model\ndue to low correlation.",
    "descriptor": "",
    "authors": [
      "Mingchuan Tian",
      "Guangway Teng",
      "Yipeng Bao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.05488"
  },
  {
    "id": "arXiv:2206.05490",
    "title": "Discovery and density estimation of latent confounders in Bayesian  networks with evidence lower bound",
    "abstract": "Discovering and parameterising latent confounders represent important and\nchallenging problems in causal structure learning and density estimation\nrespectively. In this paper, we focus on both discovering and learning the\ndistribution of latent confounders. This task requires solutions that come from\ndifferent areas of statistics and machine learning. We combine elements of\nvariational Bayesian methods, expectation-maximisation, hill-climbing search,\nand structure learning under the assumption of causal insufficiency. We propose\ntwo learning strategies; one that maximises model selection accuracy, and\nanother that improves computational efficiency in exchange for minor reductions\nin accuracy. The former strategy is suitable for small networks and the latter\nfor moderate size networks. Both learning strategies perform well relative to\nexisting solutions.",
    "descriptor": "",
    "authors": [
      "Kiattikun Chobtham",
      "Anthony C. Constantinou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05490"
  },
  {
    "id": "arXiv:2206.05494",
    "title": "Parallelization of Software Systems Test case Selection Algorithm Based  on Single Value Decomposition",
    "abstract": "When developing a software system, a change in one part of the system may\nlead to unwanted changes in other parts of the system. These affected parts may\ninterfere with system performance, so regression testing is used to deal with\nthese disorders. This test seeks to re-measure these sections to prevent these\nabnormalities, but it is difficult to identify these sections for\nre-examination. We try to cluster the changes of our software system based on\nthe system constructor functions by singular value decomposition, to be able to\nuse to identify these parts during a new change, to perform the test again. In\norder to increase efficiency, our calculations were performed in parallel on\nshared memory systems so that by increasing the scale of software systems, an\noptimal answer could be obtained.",
    "descriptor": "",
    "authors": [
      "Mahdi Movahedian Moghaddam"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.05494"
  },
  {
    "id": "arXiv:2206.05495",
    "title": "DRAformer: Differentially Reconstructed Attention Transformer for  Time-Series Forecasting",
    "abstract": "Time-series forecasting plays an important role in many real-world scenarios,\nsuch as equipment life cycle forecasting, weather forecasting, and traffic flow\nforecasting. It can be observed from recent research that a variety of\ntransformer-based models have shown remarkable results in time-series\nforecasting. However, there are still some issues that limit the ability of\ntransformer-based models on time-series forecasting tasks: (i) learning\ndirectly on raw data is susceptible to noise due to its complex and unstable\nfeature representation; (ii) the self-attention mechanisms pay insufficient\nattention to changing features and temporal dependencies. In order to solve\nthese two problems, we propose a transformer-based differentially reconstructed\nattention model DRAformer. Specifically, DRAformer has the following\ninnovations: (i) learning against differenced sequences, which preserves clear\nand stable sequence features by differencing and highlights the changing\nproperties of sequences; (ii) the reconstructed attention: integrated distance\nattention exhibits sequential distance through a learnable Gaussian kernel,\ndistributed difference attention calculates distribution difference by mapping\nthe difference sequence to the adaptive feature space, and the combination of\nthe two effectively focuses on the sequences with prominent associations; (iii)\nthe reconstructed decoder input, which extracts sequence features by\nintegrating variation information and temporal correlations, thereby obtaining\na more comprehensive sequence representation. Extensive experiments on four\nlarge-scale datasets demonstrate that DRAformer outperforms state-of-the-art\nbaselines.",
    "descriptor": "",
    "authors": [
      "Benhan Li",
      "Shengdong Du",
      "Tianrui Li",
      "Jie Hu",
      "Zhen Jia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.05495"
  },
  {
    "id": "arXiv:2206.05496",
    "title": "An Evaluation of OCR on Egocentric Data",
    "abstract": "In this paper, we evaluate state-of-the-art OCR methods on Egocentric data.\nWe annotate text in EPIC-KITCHENS images, and demonstrate that existing OCR\nmethods struggle with rotated text, which is frequently observed on objects\nbeing handled. We introduce a simple rotate-and-merge procedure which can be\napplied to pre-trained OCR models that halves the normalized edit distance\nerror. This suggests that future OCR attempts should incorporate rotation into\nmodel design and training procedures.",
    "descriptor": "\nComments: Extended Abstract, EPIC workshop at CVPR 22\n",
    "authors": [
      "Valentin Popescu",
      "Dima Damen",
      "Toby Perrett"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.05496"
  },
  {
    "id": "arXiv:2206.05497",
    "title": "Learning to Generate Levels by Imitating Evolution",
    "abstract": "Search-based procedural content generation (PCG) is a well-known method used\nfor level generation in games. Its key advantage is that it is generic and able\nto satisfy functional constraints. However, due to the heavy computational\ncosts to run these algorithms online, search-based PCG is rarely utilized for\nreal-time generation. In this paper, we introduce a new type of iterative level\ngenerator using machine learning. We train a model to imitate the evolutionary\nprocess and use the model to generate levels. This trained model is able to\nmodify noisy levels sequentially to create better levels without the need for a\nfitness function during inference. We evaluate our trained models on a 2D maze\ngeneration task. We compare several different versions of the method: training\nthe models either at the end of evolution (normal evolution) or every 100\ngenerations (assisted evolution) and using the model as a mutation function\nduring evolution. Using the assisted evolution process, the final trained\nmodels are able to generate mazes with a success rate of 99% and high diversity\nof 86%. This work opens the door to a new way of learning level generators\nguided by the evolutionary process and perhaps will increase the adoption of\nsearch-based PCG in the game industry.",
    "descriptor": "\nComments: 8 pages, 6 figures, submitted to PCGWorkshop 2022 at FDG 2022\n",
    "authors": [
      "Ahmed Khalifa",
      "Michael Cerny Green",
      "Julian Togelius"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.05497"
  },
  {
    "id": "arXiv:2206.05498",
    "title": "A Review of Causality for Learning Algorithms in Medical Image Analysis",
    "abstract": "Medical image analysis is a vibrant research area that offers doctors and\nmedical practitioners invaluable insight and the ability to accurately diagnose\nand monitor disease. Machine learning provides an additional boost for this\narea. However, machine learning for medical image analysis is particularly\nvulnerable to natural biases like domain shifts that affect algorithmic\nperformance and robustness. In this paper we analyze machine learning for\nmedical image analysis within the framework of Technology Readiness Levels and\nreview how causal analysis methods can fill a gap when creating robust and\nadaptable medical image analysis algorithms. We review methods using causality\nin medical imaging AI/ML and find that causal analysis has the potential to\nmitigate critical problems for clinical translation but that uptake and\nclinical downstream research has been limited so far.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Athanasios Vlontzos",
      "Daniel Rueckert",
      "Bernhard Kainz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "General Literature (cs.GL)"
    ],
    "url": "https://arxiv.org/abs/2206.05498"
  },
  {
    "id": "arXiv:2206.05499",
    "title": "Soft-mask: Adaptive Substructure Extractions for Graph Neural Networks",
    "abstract": "For learning graph representations, not all detailed structures within a\ngraph are relevant to the given graph tasks. Task-relevant structures can be\n$localized$ or $sparse$ which are only involved in subgraphs or characterized\nby the interactions of subgraphs (a hierarchical perspective). A graph neural\nnetwork should be able to efficiently extract task-relevant structures and be\ninvariant to irrelevant parts, which is challenging for general message passing\nGNNs. In this work, we propose to learn graph representations from a sequence\nof subgraphs of the original graph to better capture task-relevant\nsubstructures or hierarchical structures and skip $noisy$ parts. To this end,\nwe design soft-mask GNN layer to extract desired subgraphs through the mask\nmechanism. The soft-mask is defined in a continuous space to maintain the\ndifferentiability and characterize the weights of different parts. Compared\nwith existing subgraph or hierarchical representation learning methods and\ngraph pooling operations, the soft-mask GNN layer is not limited by the fixed\nsample or drop ratio, and therefore is more flexible to extract subgraphs with\narbitrary sizes. Extensive experiments on public graph benchmarks show that\nsoft-mask mechanism brings performance improvements. And it also provides\ninterpretability where visualizing the values of masks in each layer allows us\nto have an insight into the structures learned by the model.",
    "descriptor": "\nComments: The Web Conference (WWW), 2021\n",
    "authors": [
      "Mingqi Yang",
      "Yanming Shen",
      "Heng Qi",
      "Baocai Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05499"
  },
  {
    "id": "arXiv:2206.05503",
    "title": "Rust: The Programming Language for Safety and Performance",
    "abstract": "Rust is a young programming language gaining increased attention from\nsoftware developers since it was introduced to the world by Mozilla in 2010. In\nthis study, we attempt to answer several research questions. Does Rust deserve\nsuch increased attention? What is there in Rust that is attracting programmers\nto this new language? Safety and performance were among the very first promises\nof Rust, as was claimed by its early developers. Is Rust a safe language with\nhigh performance? Have these claims been achieved? To answer these questions,\nwe surveyed and analyzed recent research on Rust and research that benchmarks\nRust with other available prominent programming languages. The results show\nthat Rust deserves the increased interest by programmers, and recent\nexperimental results in benchmarking research show Rust's overall superiority\nover other well-established languages in terms of performance, safety, and\nsecurity. Even though this study was not comprehensive (and more work must be\ndone in this area), it informs the programming and research communities on the\npromising features of Rust as the language of choice for the future.",
    "descriptor": "\nComments: 9 pages, 3 figures, 2 programming code listings\n",
    "authors": [
      "William Bugden",
      "Ayman Alahmar"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2206.05503"
  },
  {
    "id": "arXiv:2206.05504",
    "title": "Modeling of High and Low Resistant States in Single Defect Atomristors",
    "abstract": "Resistance-change random access memory (RRAM) devices are nanoscale\nmetal-insulator-metal structures that can store information in their resistance\nstates, namely the high resistance (HRS) and low resistance (LRS) states. They\nare a potential candidate for a universal memory as these non-volatile memory\nelements can offer fast-switching, long retention and switching cycles, and\nadditionally, are also suitable for direct applications in neuromorphic\ncomputing. In this study, we first present a model to analyze different\nresistance states of RRAM devices or so-called \"atomristors\" that utilize novel\n2D materials as the switching materials instead of insulators. The developed\nmodel is then used to study the electrical characteristics of a single defect\nmonolayer MoS$_{2}$ memristor. The change in the device resistance between the\nHRS and LRS is associated to the change in the tunneling probability when the\nvacancy defects in the 2D material are substituted by the metal atoms from the\nelectrodes. The distortion due to defects and substituted metal atom is\ncaptured in the 1D potential energy profile by averaging the effect along the\ntransverse direction. This simplification enables us to model single defect\nmemristors with a less extensive quantum transport model while taking into\naccount the presence of defects.",
    "descriptor": "",
    "authors": [
      "Yuvraj Misra",
      "Tarun Kumar Agarwal"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2206.05504"
  },
  {
    "id": "arXiv:2206.05506",
    "title": "Channel Estimation for Massive MIMO systems using Tensor Cores in GPU",
    "abstract": "For efficient use of Massive MIMO systems, fast and accurate channel\nestimation is very important. But the Large-scale antenna array presence\nrequires high pilot overhead for high accuracy of estimation. Also, when used\nwith software-based processing systems like CPUs and GPUs, high processing\nlatency becomes a major issue. To reduce Pilot overhead, a Pilot transmission\nscheme in combination with PN Sequence correlation based channel estimation\nscheme is implemented. Then, to deal with the issue of high processing latency,\nTensor Cores in Nvidia GPUs are used for computing the channel estimation.\nExperiments are performed by using Nvidia V100 GPU in the ORBIT Testbed to show\nthe performance of the Pilot transmission scheme. By varying factors like PN\nsequence length, Channel Impulse Response length, number of multiplexed\ntransmitters, and scale of MIMO, the accuracy and processing latency of Tensor\nCore implementation of the Channel Estimation is evaluated.",
    "descriptor": "\nComments: This paper has been submitted and accepted at IEEE INFOCOM CNERT 2022 Workshop. A DOI, IEEE copyright will be added as soon as paper is published. This project was funded by the NSF \"COSMOS\" Project under grant number CNS-1827923\n",
    "authors": [
      "Bhargav Gokalgandhi",
      "Ivan Seskar"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.05506"
  },
  {
    "id": "arXiv:2206.05507",
    "title": "Federated Learning with GAN-based Data Synthesis for Non-IID Clients",
    "abstract": "Federated learning (FL) has recently emerged as a popular privacy-preserving\ncollaborative learning paradigm. However, it suffers from the non-independent\nand identically distributed (non-IID) data among clients. In this paper, we\npropose a novel framework, named Synthetic Data Aided Federated Learning\n(SDA-FL), to resolve this non-IID challenge by sharing synthetic data.\nSpecifically, each client pretrains a local generative adversarial network\n(GAN) to generate differentially private synthetic data, which are uploaded to\nthe parameter server (PS) to construct a global shared synthetic dataset. To\ngenerate confident pseudo labels for the synthetic dataset, we also propose an\niterative pseudo labeling mechanism performed by the PS. A combination of the\nlocal private dataset and synthetic dataset with confident pseudo labels leads\nto nearly identical data distributions among clients, which improves the\nconsistency among local models and benefits the global aggregation. Extensive\nexperiments evidence that the proposed framework outperforms the baseline\nmethods by a large margin in several benchmark datasets under both the\nsupervised and semi-supervised settings.",
    "descriptor": "\nComments: 8 pages. To be published in the International Workshop on Trustworthy Federated Learning in Conjunction with IJCAI 2022 (FL-IJCAI'22)\n",
    "authors": [
      "Zijian Li",
      "Jiawei Shao",
      "Yuyi Mao",
      "Jessie Hui Wang",
      "Jun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05507"
  },
  {
    "id": "arXiv:2206.05510",
    "title": "An Algorithm for Exact Numerical Age-of-Information Evaluation in  Multi-Agent Systems",
    "abstract": "We present an algorithm for the numerical evaluation of the state-space\ndistribution of an Age-of-Information network. Given enough computational\nresources, the evaluation can be performed to an arbitrary high precision. An\nAge-of-Information network is described by a vector of natural numbers, that\ntrack how outdated status information from various agents is. Our algorithm\nyields the means to determine any moment of the corresponding stochastic\nprocess. This can be extremely valuable for cases in which the network consists\nof controllers that communicate with one another, as it potentially allows for\nless conservative control behavior. It also enables the comparison of different\npolicies regarding their performance (minimizing the average\nAge-of-Information) to a much more accurate degree than was possible before.\nThis is illustrated using the conventional MaxWeight policy and the optimal\npolicy. We also validate and compare the algorithm with\nMonte-Carlo-Simulations.",
    "descriptor": "",
    "authors": [
      "Richard Schoeffauer",
      "Gerhard Wunder"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2206.05510"
  },
  {
    "id": "arXiv:2206.05511",
    "title": "Improving the Adversarial Robustness of NLP Models by Information  Bottleneck",
    "abstract": "Existing studies have demonstrated that adversarial examples can be directly\nattributed to the presence of non-robust features, which are highly predictive,\nbut can be easily manipulated by adversaries to fool NLP models. In this study,\nwe explore the feasibility of capturing task-specific robust features, while\neliminating the non-robust ones by using the information bottleneck theory.\nThrough extensive experiments, we show that the models trained with our\ninformation bottleneck-based method are able to achieve a significant\nimprovement in robust accuracy, exceeding performances of all the previously\nreported defense methods while suffering almost no performance drop in clean\naccuracy on SST-2, AGNEWS and IMDB datasets.",
    "descriptor": "",
    "authors": [
      "Cenyuan Zhang",
      "Xiang Zhou",
      "Yixin Wan",
      "Xiaoqing Zheng",
      "Kai-Wei Chang",
      "Cho-Jui Hsieh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.05511"
  },
  {
    "id": "arXiv:2206.05514",
    "title": "Toward Real-world Single Image Deraining: A New Benchmark and Beyond",
    "abstract": "Single image deraining (SID) in real scenarios attracts increasing attention\nin recent years. Due to the difficulty in obtaining real-world rainy/clean\nimage pairs, previous real datasets suffer from low-resolution images,\nhomogeneous rain streaks, limited background variation, and even misalignment\nof image pairs, resulting in incomprehensive evaluation of SID methods. To\naddress these issues, we establish a new high-quality dataset named\nRealRain-1k, consisting of $1,120$ high-resolution paired clean and rainy\nimages with low- and high-density rain streaks, respectively. Images in\nRealRain-1k are automatically generated from a large number of real-world rainy\nvideo clips through a simple yet effective rain density-controllable filtering\nmethod, and have good properties of high image resolution, background\ndiversity, rain streaks variety, and strict spatial alignment. RealRain-1k also\nprovides abundant rain streak layers as a byproduct, enabling us to build a\nlarge-scale synthetic dataset named SynRain-13k by pasting the rain streak\nlayers on abundant natural images. Based on them and existing datasets, we\nbenchmark more than 10 representative SID methods on three tracks: (1) fully\nsupervised learning on RealRain-1k, (2) domain generalization to real datasets,\nand (3) syn-to-real transfer learning. The experimental results (1) show the\ndifference of representative methods in image restoration performance and model\ncomplexity, (2) validate the significance of the proposed datasets for model\ngeneralization, and (3) provide useful insights on the superiority of learning\nfrom diverse domains and shed lights on the future research on real-world SID.\nThe datasets will be released at https://github.com/hiker-lw/RealRain-1k",
    "descriptor": "",
    "authors": [
      "Wei Li",
      "Qiming Zhang",
      "Jing Zhang",
      "Zhen Huang",
      "Xinmei Tian",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.05514"
  },
  {
    "id": "arXiv:2206.05518",
    "title": "Investigation of Ensemble features of Self-Supervised Pretrained Models  for Automatic Speech Recognition",
    "abstract": "Self-supervised learning (SSL) based models have been shown to generate\npowerful representations that can be used to improve the performance of\ndownstream speech tasks. Several state-of-the-art SSL models are available, and\neach of these models optimizes a different loss which gives rise to the\npossibility of their features being complementary. This paper proposes using an\nensemble of such SSL representations and models, which exploits the\ncomplementary nature of the features extracted by the various pretrained\nmodels. We hypothesize that this results in a richer feature representation and\nshows results for the ASR downstream task. To this end, we use three SSL models\nthat have shown excellent results on ASR tasks, namely HuBERT, Wav2vec2.0, and\nWaveLM. We explore the ensemble of models fine-tuned for the ASR task and the\nensemble of features using the embeddings obtained from the pre-trained models\nfor a downstream ASR task. We get improved performance over individual models\nand pre-trained features using Librispeech(100h) and WSJ dataset for the\ndownstream tasks.",
    "descriptor": "\nComments: 4 pages , 2 figures,submitted to interspeech 2022\n",
    "authors": [
      "A Arunkumar",
      "Vrunda N Sukhadia",
      "S. Umesh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.05518"
  },
  {
    "id": "arXiv:2206.05519",
    "title": "Bridging the Gap Between Training and Inference of Bayesian Controllable  Language Models",
    "abstract": "Large-scale pre-trained language models have achieved great success on\nnatural language generation tasks. However, it is difficult to control the\npre-trained language models to generate sentences with the desired attribute\nsuch as topic and sentiment, etc. Recently, Bayesian Controllable Language\nModels (BCLMs) have been shown to be efficient in controllable language\ngeneration. Rather than fine-tuning the parameters of pre-trained language\nmodels, BCLMs use external discriminators to guide the generation of\npre-trained language models. However, the mismatch between training and\ninference of BCLMs limits the performance of the models. To address the\nproblem, in this work we propose a \"Gemini Discriminator\" for controllable\nlanguage generation which alleviates the mismatch problem with a small\ncomputational cost. We tested our method on two controllable language\ngeneration tasks: sentiment control and topic control. On both tasks, our\nmethod reached achieved new state-of-the-art results in automatic and human\nevaluations.",
    "descriptor": "\nComments: Submitted to Neurips 2022\n",
    "authors": [
      "Han Liu",
      "Bingning Wang",
      "Ting Yao",
      "Haijin Liang",
      "Jianjin Xu",
      "Xiaolin Hu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.05519"
  },
  {
    "id": "arXiv:2206.05520",
    "title": "A Two-stage Method for Non-extreme Value Salt-and-Pepper Noise Removal",
    "abstract": "There are several previous methods based on neural network can have great\nperformance in denoising salt and pepper noise. However, those methods are\nbased on a hypothesis that the value of salt and pepper noise is exactly 0 and\n255. It is not true in the real world. The result of those methods deviate\nsharply when the value is different from 0 and 255. To overcome this weakness,\nour method aims at designing a convolutional neural network to detect the noise\npixels in a wider range of value and then a filter is used to modify pixel\nvalue to 0, which is beneficial for further filtering. Additionally, another\nconvolutional neural network is used to conduct the denoising and restoration\nwork.",
    "descriptor": "\nComments: UESTC course project\n",
    "authors": [
      "Renwei Yang",
      "YiKe Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.05520"
  },
  {
    "id": "arXiv:2206.05521",
    "title": "Model-based Offline Imitation Learning with Non-expert Data",
    "abstract": "Although Behavioral Cloning (BC) in theory suffers compounding errors, its\nscalability and simplicity still makes it an attractive imitation learning\nalgorithm. In contrast, imitation approaches with adversarial training\ntypically does not share the same problem, but necessitates interactions with\nthe environment. Meanwhile, most imitation learning methods only utilises\noptimal datasets, which could be significantly more expensive to obtain than\nits suboptimal counterpart. A question that arises is, can we utilise the\nsuboptimal dataset in a principled manner, which otherwise would have been\nidle? We propose a scalable model-based offline imitation learning algorithmic\nframework that leverages datasets collected by both suboptimal and optimal\npolicies, and show that its worst case suboptimality becomes linear in the time\nhorizon with respect to the expert samples. We empirically validate our\ntheoretical results and show that the proposed method \\textit{always}\noutperforms BC in the low data regime on simulated continuous control domains",
    "descriptor": "",
    "authors": [
      "Jeongwon Park",
      "Lin Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.05521"
  },
  {
    "id": "arXiv:2206.05522",
    "title": "The Effects of Spatial Configuration on Relative Translation Gain  Thresholds in Redireced Walking",
    "abstract": "In this study, we explore how spatial configurations can be reflected in\ndetermining the threshold range of Relative Translation Gains (RTGs), a\ntranslation gain-based Redirected Walking (RDW) technique that scales the\nuser's movement in Virtual Reality (VR) in different ratios for width and\ndepth. While previous works have shown that various cognitive factors or\nindividual differences influence the RDW threshold, constructive studies\ninvestigating the impact of the environmental composition on the RDW threshold\nwith regard to the user's visual perception were lacking. Therefore, we\nexamined the effect of spatial configurations on the RTG threshold by analyzing\nthe participant's responses and gaze distribution data in two user studies. The\nfirst study concerned the size of the virtual room and the existence of objects\nwithin it, and the second study focused on the combined impact of room size and\nthe spatial layout. Our results show that three compositions of spatial\nconfiguration (size, object existence, spatial layout) significantly affect the\nRTG threshold range. Based on our findings, we proposed virtual space rescaling\nguidelines to increase the range of adjustable movable space with RTGs for\ndevelopers: placing distractors in the room, setting the perceived movable\nspace to be larger than the adjusted movable space if it's an empty room, and\navoid placing objects together as centered layout. Our findings can be used to\nadaptively rescale VR users' space according to the target virtual space's\nconfiguration with a unified coordinate system that enables the utilization of\nphysical objects in a virtual scene.",
    "descriptor": "\nComments: 21 pages, 11 figures, Submitted to Springer VR Journal\n",
    "authors": [
      "Dooyoung Kim",
      "Seonji Kim",
      "Jae-eun Shin",
      "Boram Yoon",
      "Jinwook Kim",
      "Jeongmi Lee",
      "Woontack Woo"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.05522"
  },
  {
    "id": "arXiv:2206.05524",
    "title": "Multiple RISs-Aided Networks: Performance Analysis and Optimization",
    "abstract": "This paper analyzes the performance of multiple reconfigurable intelligent\nsurfaces (RISs)-aided networks. The paper also provides some optimization\nresults on the number of reflecting elements on RISs and the optimal placement\nof RISs. We first derive accurate closed-form approximations for RIS channels'\ndistributions assuming independent non-identically distributed (i.ni.d.)\nNakagami-\\emph{m} fading environment. Then, the approximate expressions for\noutage probability (OP) and average symbol error probability are derived in\nclosed-form. Furthermore, to get more insights into the system performance, we\nderive the asymptotic OP at the high signal-to-noise ratio regime and provide\nclosed-form expressions for the system diversity order and coding gain.\nFinally, the accuracy of our theoretical analysis is validated through\nMonte-Carlo simulations. The obtained results show that the considered RIS\nscenario can provide a diversity order of $\\frac{a}{2}K$, where $a$ is a\nfunction of the Nakagami fading parameter $m$ and the number of meta-surface\nelements $N$, and $K$ is the number of RISs.",
    "descriptor": "",
    "authors": [
      "Mahmoud Aldababsa",
      "Anas M. Salhab",
      "Ali Arshad Nasir",
      "Monjed H. Samuh",
      "Daniel Benevides da Costa"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.05524"
  },
  {
    "id": "arXiv:2206.05530",
    "title": "Memorization-Dilation: Modeling Neural Collapse Under Noise",
    "abstract": "The notion of neural collapse refers to several emergent phenomena that have\nbeen empirically observed across various canonical classification problems.\nDuring the terminal phase of training a deep neural network, the feature\nembedding of all examples of the same class tend to collapse to a single\nrepresentation, and the features of different classes tend to separate as much\nas possible. Neural collapse is often studied through a simplified model,\ncalled the unconstrained feature representation, in which the model is assumed\nto have \"infinite expressivity\" and can map each data point to any arbitrary\nrepresentation. In this work, we propose a more realistic variant of the\nunconstrained feature representation that takes the limited expressivity of the\nnetwork into account. Empirical evidence suggests that the memorization of\nnoisy data points leads to a degradation (dilation) of the neural collapse.\nUsing a model of the memorization-dilation (M-D) phenomenon, we show one\nmechanism by which different losses lead to different performances of the\ntrained network on noisy data. Our proofs reveal why label smoothing, a\nmodification of cross-entropy empirically observed to produce a regularization\neffect, leads to improved generalization in classification tasks.",
    "descriptor": "",
    "authors": [
      "Duc Anh Nguyen",
      "Ron Levie",
      "Julian Lienen",
      "Gitta Kutyniok",
      "Eyke H\u00fcllermeier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05530"
  },
  {
    "id": "arXiv:2206.05531",
    "title": "A Novel Meshless Method Based on the Virtual Construction of Node  Control Domains for Porous Flow Problems",
    "abstract": "In this paper, a novel meshless method satisfying local mass conservation is\ndeveloped by virtually constructing the node control domains. By defining the\nconnectable node cloud, this novel meshless method uses the integral of the\ndiffusion term and generalized difference operators to calculate the node\ncontrol volumes by ensuring the local mass conservation. This novel method only\nfocuses on the volume of the node control domain rather than the specific\nshape, so the construction of node control domains is called virtual, which\nwill not increase the computational cost. To our knowledge, this is the first\ntime to construct node control volumes in the meshless framework, so this novel\nmethod is named a node control domains-based meshless method, abbreviated as\nNCDMM, which can also be regarded as an extended finite volume method (EFVM).\nTaking two-phase porous flow problems as an example, the NCDMM discrete schemes\nmeeting the local mass conservation are derived by integrating the generalized\nfinite difference schemes of governing equations at each node control volume.\nFinally, existing commonly used low-order finite volume method (FVM) based\nnonlinear solvers for various porous flow models can be directly employed in\nthe proposed NCDMM, significantly facilitating the general-purpose applications\nof the NCDMM. Theoretically, the proposed NCDMM has the advantages of previous\nmeshless methods for discretizing computational domains with complex\ngeometries, as well as the advantages of traditional low-order FVMs for stably\nhandling a variety of porous flow problems with local mass conservation. Three\nnumerical cases are implemented to test the computational accuracy, efficiency,\nconvergence, and good adaptability to the calculation domain with complex\ngeometry and complex boundary conditions.",
    "descriptor": "",
    "authors": [
      "Xiang Rao"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.05531"
  },
  {
    "id": "arXiv:2206.05532",
    "title": "Detecting Context-Aware Deviations in Process Executions",
    "abstract": "A deviation detection aims to detect deviating process instances, e.g.,\npatients in the healthcare process and products in the manufacturing process. A\nbusiness process of an organization is executed in various contextual\nsituations, e.g., a COVID-19 pandemic in the case of hospitals and a lack of\nsemiconductor chip shortage in the case of automobile companies. Thus,\ncontext-aware deviation detection is essential to provide relevant insights.\nHowever, existing work 1) does not provide a systematic way of incorporating\nvarious contexts, 2) is tailored to a specific approach without using an\nextensive pool of existing deviation detection techniques, and 3) does not\ndistinguish positive and negative contexts that justify and refute deviation,\nrespectively. In this work, we provide a framework to bridge the aforementioned\ngaps. We have implemented the proposed framework as a web service that can be\nextended to various contexts and deviation detection methods. We have evaluated\nthe effectiveness of the proposed framework by conducting experiments using 255\ndifferent contextual scenarios.",
    "descriptor": "",
    "authors": [
      "Gyunam Park",
      "Janik-Vasily Benzin",
      "Wil M. P. van der Aalst"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.05532"
  },
  {
    "id": "arXiv:2206.05533",
    "title": "Rare event failure test case generation in Learning-Enabled-Controllers",
    "abstract": "Machine learning models have prevalent applications in many real-world\nproblems, which increases the importance of correctness in the behaviour of\nthese trained models. Finding a good test case that can reveal the potential\nfailure in these trained systems can help to retrain these models to increase\ntheir correctness. For a well-trained model, the occurrence of a failure is\nrare. Consequently, searching these rare scenarios by evaluating each sample in\ninput search space or randomized search would be costly and sometimes\nintractable due to large search space, limited computational resources, and\navailable time. In this paper, we tried to address this challenge of finding\nthese failure scenarios faster than traditional randomized search. The central\nidea of our approach is to separate the input data space in region of high\nfailure probability and region of low/minimal failure probability based on the\nobservation made by training data, data drawn from real-world statistics, and\nknowledge from a domain expert. Using these information, we can design a\ngenerative model from which we can generate scenarios that have a high\nlikelihood to reveal the potential failure. We evaluated this approach on two\ndifferent experimental scenarios and able to speed up the discovery of such\nfailures a thousand-fold faster than the traditional randomized search.",
    "descriptor": "",
    "authors": [
      "Harsh Vardhan",
      "Janos Sztipanovits"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05533"
  },
  {
    "id": "arXiv:2206.05539",
    "title": "A Simplified Un-Supervised Learning Based Approach for Ink Mismatch  Detection in Handwritten Hyper-Spectral Document Images",
    "abstract": "Hyper-spectral imaging has become the latest trend in the field of optical\nimaging systems. Among various other applications, hyper-spectral imaging has\nbeen widely used for analysis of printed and handwritten documents. This paper\nproposes an efficient technique for estimating the number of different but\nvisibly similar inks present in a Hyper spectral Document Image. Our approach\nis based on un-supervised learning and does not require any prior knowledge of\nthe dataset. The algorithm was tested on the iVision HHID dataset and has\nachieved comparable results with the state of the algorithms present in the\nliterature. This work can prove to be effective when employed during the early\nstages of forgery detection in Hyper-spectral Document Images.",
    "descriptor": "",
    "authors": [
      "Muhammad Farhan Humayun",
      "Hassan Waseem Malik",
      "Ahmed Ahsan Alvi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05539"
  },
  {
    "id": "arXiv:2206.05542",
    "title": "Surround-View Cameras based Holistic Visual Perception for Automated  Driving",
    "abstract": "The formation of eyes led to the big bang of evolution. The dynamics changed\nfrom a primitive organism waiting for the food to come into contact for eating\nfood being sought after by visual sensors. The human eye is one of the most\nsophisticated developments of evolution, but it still has defects. Humans have\nevolved a biological perception algorithm capable of driving cars, operating\nmachinery, piloting aircraft, and navigating ships over millions of years.\nAutomating these capabilities for computers is critical for various\napplications, including self-driving cars, augmented reality, and architectural\nsurveying. Near-field visual perception in the context of self-driving cars can\nperceive the environment in a range of $0-10$ meters and 360{\\deg} coverage\naround the vehicle. It is a critical decision-making component in the\ndevelopment of safer automated driving. Recent advances in computer vision and\ndeep learning, in conjunction with high-quality sensors such as cameras and\nLiDARs, have fueled mature visual perception solutions. Until now, far-field\nperception has been the primary focus. Another significant issue is the limited\nprocessing power available for developing real-time applications. Because of\nthis bottleneck, there is frequently a trade-off between performance and\nrun-time efficiency. We concentrate on the following issues in order to address\nthem: 1) Developing near-field perception algorithms with high performance and\nlow computational complexity for various visual perception tasks such as\ngeometric and semantic tasks using convolutional neural networks. 2) Using\nMulti-Task Learning to overcome computational bottlenecks by sharing initial\nconvolutional layers between tasks and developing optimization strategies that\nbalance tasks.",
    "descriptor": "\nComments: Doctoral thesis\n",
    "authors": [
      "Varun Ravi Kumar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.05542"
  },
  {
    "id": "arXiv:2206.05543",
    "title": "Optimized sparse approximate inverse smoothers for solving Laplacian  linear systems",
    "abstract": "In this paper we propose and analyze new efficient sparse approximate inverse\n(SPAI) smoothers for solving the two-dimensional (2D) and three-dimensional\n(3D) Laplacian linear system with geometric multigrid methods. Local Fourier\nanalysis shows that our proposed SPAI smoother for 2D achieves a much smaller\nsmoothing factor than the state-of-the-art SPAI smoother studied in [Bolten,\nM., Huckle, T.K. and Kravvaritis, C.D., 2016. Sparse matrix approximations for\nmultigrid methods. Linear Algebra and its Applications, 502, pp.58-76.]. The\nproposed SPAI smoother for 3D cases provides smaller optimal smoothing factor\nthan that of weighted Jacobi smoother. Numerical results validate our\ntheoretical conclusions and illustrate the high-efficiency and\nhigh-effectiveness of our proposed SPAI smoothers. Such SPAI smoothers have the\nadvantage of inherent parallelism. The MATLAB codes for implementing our\nproposed algorithms are publicly available online at\nthis http URL .",
    "descriptor": "\nComments: 21 pages, 3 figures,1 table\n",
    "authors": [
      "Yunhui He",
      "Jun Liu",
      "Xiang-Sheng Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.05543"
  },
  {
    "id": "arXiv:2206.05548",
    "title": "The Impact Of Social Media In The Fight Against The Spread Of  Coronavirus (Covid-19) Pandemic In Anambra State, Nigeria",
    "abstract": "This study examined the impact of social media in the fight against the\nspread of coronavirus (COVID-19) pandemic in Anambra state, Nigeria. The key\nobjectives are to: find out if the numbers of social media users increased in\nAnambra state since the wake of coronavirus pandemic; find out if the social\nmedia is being utilised in the fight against the spread of coronavirus pandemic\nin Anambra state; find out how the social media is being utilised in the fight\nagainst the spread of coronavirus pandemic in Anambra state; and discover the\nimpact of social media in the fight against the spread of coronavirus pandemic\nin Anambra State. It was anchored on Agenda Setting Theory, and the\nTechnological Determinism Theory (TDT). The study was designed as a survey with\nclose-ended questionnaire distributed to 400 respondents. The findings of this\nstudy revealed that usage and accessibility of social media increased in\nAnambra state because of coronavirus pandemic. It also revealed that the social\nmedia is being utilised by individuals, NGOs and government in the fight\nagainst the spread of coronavirus in Anambra state. The study also found that\nthe social media is being utilised to gather and disseminate information,\nstudy, transact businesses, among other things. The finding also showed that\nthe social media has positive impact in the fight against the spread of\ncoronavirus in Anambra state. The study concluded that social media has much\nbenefits than negative impact, and should be used to contain the spread of\ncoronavirus. It, among other things, recommended training and empowerment of\nthe citizens on effective utilisation of social media to create impact in the\nsociety.",
    "descriptor": "",
    "authors": [
      "Onuegbu Okechukwu Christopher",
      "Joseph Oluchukwu Wogu",
      "Jude Agbo"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.05548"
  },
  {
    "id": "arXiv:2206.05550",
    "title": "Web-Based Platform for Evaluation of Resilient and Transactive  Smart-Grids",
    "abstract": "Today's smart-grids have seen a clear rise in new ways of energy generation,\ntransmission, and storage. This has not only introduced a huge degree of\nvariability, but also a continual shift away from traditionally centralized\ngeneration and storage to distributed energy resources (DERs). In addition, the\ndistributed sensors, energy generators and storage devices, and networking have\nled to a huge increase in attack vectors that make the grid vulnerable to a\nvariety of attacks. The interconnection between computational and physical\ncomponents through a largely open, IP-based communication network enables an\nattacker to cause physical damage through remote cyber-attacks or attack on\nsoftware-controlled grid operations via physical- or cyber-attacks. Transactive\nEnergy (TE) is an emerging approach for managing increasing DERs in the\nsmart-grids through economic and control techniques. Transactive Smart-Grids\nuse the TE approach to improve grid reliability and efficiency. However,\nskepticism remains in their full-scale viability for ensuring grid reliability.\nIn addition, different TE approaches, in specific situations, can lead to very\ndifferent outcomes in grid operations. In this paper, we present a\ncomprehensive web-based platform for evaluating resilience of smart-grids\nagainst a variety of cyber- and physical-attacks and evaluating impact of\nvarious TE approaches on grid performance. We also provide several case-studies\ndemonstrating evaluation of TE approaches as well as grid resilience against\ncyber and physical attacks.",
    "descriptor": "",
    "authors": [
      "Himanshu Neema",
      "Harsh Vardhan",
      "Carlos Barreto",
      "Xenofon Koutsoukos"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Computers and Society (cs.CY)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.05550"
  },
  {
    "id": "arXiv:2206.05552",
    "title": "Strategies to Maintain Voltage on Long, Lightly Loaded Feeders with  Widespread Residential Level 2 Plug-in Electric Vehicle Charging",
    "abstract": "Long, lightly loaded feeders serving residential loads may begin to\nexperience voltage excursions as plug-in electric vehicle (PEV) penetration\nincreases. Residential PEV charging tends to occur during peak-load hours on\nresidential feeders, leading to increased peak loads and potential voltage\nexcursions. To avoid voltage excursions, two PEV charging control strategies\nwere investigated using the IEEE 34-bus feeder. The first strategy shifts PEV\ncharging energy from peak hours to off-peak hours; the other strategy allows\nPEVs to provide reactive power support. Undervoltage excursions seen in a\nsimulation of uncontrolled charging of 200 PEVs were improved dramatically when\nthese two control strategies were used. The minimum voltage on the feeder\nimproved from 0.855 pu when PEV charging was uncontrolled to 0.959 pu when both\ncontrol strategies were applied together.",
    "descriptor": "",
    "authors": [
      "Don Scoffield",
      "John Smart",
      "Timothy Pennington",
      "C. Birk Jones",
      "Matthew Lave",
      "Anudeep Medam",
      "Bhaskar Mitra"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.05552"
  },
  {
    "id": "arXiv:2206.05554",
    "title": "Incremental Information Gain Mining Of Temporal Relational Streams",
    "abstract": "This paper studies the problem of mining for data values with high\ninformation gain in relational tables. High information gain can help data\nanalysts and secondary data mining algorithms gain insights into strong\nstatistical dependencies and causality relationship between key metrics. In\nthis paper, we will study the problem of high information gain identification\nfor scenarios involving temporal relations where new records are added\ncontinuously to the relations. We show that information gain can be efficiently\nmaintained in an incremental fashion, making it possible to monitor\ncontinuously high information gain values.",
    "descriptor": "",
    "authors": [
      "Ken Pu",
      "Limin Ma"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.05554"
  },
  {
    "id": "arXiv:2206.05555",
    "title": "A Unified Continuous Learning Framework for Multi-modal Knowledge  Discovery and Pre-training",
    "abstract": "Multi-modal pre-training and knowledge discovery are two important research\ntopics in multi-modal machine learning. Nevertheless, none of existing works\nmake attempts to link knowledge discovery with knowledge guided multi-modal\npre-training. In this paper, we propose to unify them into a continuous\nlearning framework for mutual improvement. Taking the open-domain uni-modal\ndatasets of images and texts as input, we maintain a knowledge graph as the\nfoundation to support these two tasks. For knowledge discovery, a pre-trained\nmodel is used to identify cross-modal links on the graph. For model\npre-training, the knowledge graph is used as the external knowledge to guide\nthe model updating. These two steps are iteratively performed in our framework\nfor continuous learning. The experimental results on MS-COCO and Flickr30K with\nrespect to both knowledge discovery and the pre-trained model validate the\neffectiveness of our framework.",
    "descriptor": "",
    "authors": [
      "Zhihao Fan",
      "Zhongyu Wei",
      "Jingjing Chen",
      "Siyuan Wang",
      "Zejun Li",
      "Jiarong Xu",
      "Xuanjing Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.05555"
  },
  {
    "id": "arXiv:2206.05558",
    "title": "Communication-Efficient Robust Federated Learning with Noisy Labels",
    "abstract": "Federated learning (FL) is a promising privacy-preserving machine learning\nparadigm over distributed located data. In FL, the data is kept locally by each\nuser. This protects the user privacy, but also makes the server difficult to\nverify data quality, especially if the data are correctly labeled. Training\nwith corrupted labels is harmful to the federated learning task; however,\nlittle attention has been paid to FL in the case of label noise. In this paper,\nwe focus on this problem and propose a learning-based reweighting approach to\nmitigate the effect of noisy labels in FL. More precisely, we tuned a weight\nfor each training sample such that the learned model has optimal generalization\nperformance over a validation set. More formally, the process can be formulated\nas a Federated Bilevel Optimization problem. Bilevel optimization problem is a\ntype of optimization problem with two levels of entangled problems. The\nnon-distributed bilevel problems have witnessed notable progress recently with\nnew efficient algorithms. However, solving bilevel optimization problems under\nthe Federated Learning setting is under-investigated. We identify that the high\ncommunication cost in hypergradient evaluation is the major bottleneck. So we\npropose \\textit{Comm-FedBiO} to solve the general Federated Bilevel\nOptimization problems; more specifically, we propose two\ncommunication-efficient subroutines to estimate the hypergradient. Convergence\nanalysis of the proposed algorithms is also provided. Finally, we apply the\nproposed algorithms to solve the noisy label problem. Our approach has shown\nsuperior performance on several real-world datasets compared to various\nbaselines.",
    "descriptor": "\nComments: To appear in KDD 2022\n",
    "authors": [
      "Junyi Li",
      "Jian Pei",
      "Heng Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05558"
  },
  {
    "id": "arXiv:2206.05562",
    "title": "Parameter Convex Neural Networks",
    "abstract": "Deep learning utilizing deep neural networks (DNNs) has achieved a lot of\nsuccess recently in many important areas such as computer vision, natural\nlanguage processing, and recommendation systems. The lack of convexity for DNNs\nhas been seen as a major disadvantage of many optimization methods, such as\nstochastic gradient descent, which greatly reduces the genelization of neural\nnetwork applications. We realize that the convexity make sense in the neural\nnetwork and propose the exponential multilayer neural network (EMLP), a class\nof parameter convex neural network (PCNN) which is convex with regard to the\nparameters of the neural network under some conditions that can be realized.\nBesides, we propose the convexity metric for the two-layer EGCN and test the\naccuracy when the convexity metric changes. For late experiments, we use the\nsame architecture to make the exponential graph convolutional network (EGCN)\nand do the experiment on the graph classificaion dataset in which our model\nEGCN performs better than the graph convolutional network (GCN) and the graph\nattention network (GAT).",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Jingcheng Zhou",
      "Wei Wei",
      "Xing Li",
      "Bowen Pang",
      "Zhiming Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.05562"
  },
  {
    "id": "arXiv:2206.05564",
    "title": "gDDIM: Generalized denoising diffusion implicit models",
    "abstract": "Our goal is to extend the denoising diffusion implicit model (DDIM) to\ngeneral diffusion models~(DMs). Instead of constructing a non-Markov noising\nprocess as in the original DDIM paper, we examine the mechanism of DDIM from a\nnumerical perspective. We discover that the DDIM can be obtained by using some\nspecific approximations of the score when solving the corresponding stochastic\ndifferential equation. We present an interpretation of the accelerating effects\nof DDIM that also explains the advantages of a deterministic sampling scheme\nover the stochastic one for fast sampling. Building on this insight, we extend\nDDIM to general DMs with a small but delicate modification in parameterizing\nthe score network. When applied to the critically-damped Langevin diffusion\nmodel, a new type of diffusion model proposed recently by augmenting the\ndiffusion process with velocity, our algorithm achieves an FID score of 2.28,\non CIFAR10, with only 50 number of score function evaluations~(NFEs) and an FID\nscore of 2.87 with only 27 NFEs, better than all existing methods with the same\nNFEs. Code is available at https://github.com/qsh-zh/gDDIM",
    "descriptor": "\nComments: 26 pages, 9 figures, implementation this https URL\n",
    "authors": [
      "Qinsheng Zhang",
      "Molei Tao",
      "Yongxin Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05564"
  },
  {
    "id": "arXiv:2206.05565",
    "title": "NeuGuard: Lightweight Neuron-Guided Defense against Membership Inference  Attacks",
    "abstract": "Membership inference attacks (MIAs) against machine learning models can lead\nto serious privacy risks for the training dataset used in the model training.\nIn this paper, we propose a novel and effective Neuron-Guided Defense method\nnamed NeuGuard against membership inference attacks (MIAs). We identify a key\nweakness in existing defense mechanisms against MIAs wherein they cannot\nsimultaneously defend against two commonly used neural network based MIAs,\nindicating that these two attacks should be separately evaluated to assure the\ndefense effectiveness. We propose NeuGuard, a new defense approach that jointly\ncontrols the output and inner neurons' activation with the object to guide the\nmodel output of training set and testing set to have close distributions.\nNeuGuard consists of class-wise variance minimization targeting restricting the\nfinal output neurons and layer-wise balanced output control aiming to constrain\nthe inner neurons in each layer. We evaluate NeuGuard and compare it with\nstate-of-the-art defenses against two neural network based MIAs, five strongest\nmetric based MIAs including the newly proposed label-only MIA on three\nbenchmark datasets. Results show that NeuGuard outperforms the state-of-the-art\ndefenses by offering much improved utility-privacy trade-off, generality, and\noverhead.",
    "descriptor": "",
    "authors": [
      "Nuo Xu",
      "Binghui Wang",
      "Ran Ran",
      "Wujie Wen",
      "Parv Venkitasubramaniam"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05565"
  },
  {
    "id": "arXiv:2206.05568",
    "title": "Bounded strategic reasoning explains crisis emergence in multi-agent  market games",
    "abstract": "The efficient market hypothesis (EMH), based on rational expectations and\nmarket equilibrium, is the dominant perspective for modelling economic markets.\nHowever, the most notable critique of the EMH is the inability to model periods\nof out-of-equilibrium behaviour in the absence of any significant external\nnews. When such dynamics emerge endogenously, the traditional economic\nframeworks provide no explanation for such behaviour and the deviation from\nequilibrium. This work offers an alternate perspective explaining the\nendogenous emergence of punctuated out-of-equilibrium dynamics based on bounded\nrational agents. In a concise market entrance game, we show how boundedly\nrational strategic reasoning can lead to endogenously emerging crises,\nexhibiting fat tails in \"returns\". We also show how other common stylised facts\nof economic markets, such as clustered volatility, can be explained due to\nagent diversity (or lack thereof) and the varying learning updates across the\nagents. This work explains various stylised facts and crisis emergence in\neconomic markets, in the absence of any external news, based purely on agent\ninteractions and bounded rational reasoning.",
    "descriptor": "\nComments: 10 pages + 7 page appendix, 7 figures\n",
    "authors": [
      "Benjamin Patrick Evans",
      "Mikhail Prokopenko"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Computer Science and Game Theory (cs.GT)",
      "General Economics (econ.GN)",
      "Computational Finance (q-fin.CP)"
    ],
    "url": "https://arxiv.org/abs/2206.05568"
  },
  {
    "id": "arXiv:2206.05570",
    "title": "A Two-Dimensional FFT Precoded Filter Bank Scheme",
    "abstract": "This work proposes a new precoded filter bank (FB) system via a\ntwo-dimensional (2D) fast Fourier transform (2D-FFT). Its structure is similar\nto Orthogonal Time Frequency Space (OTFS) systems, where the OFDM transmitter\nis changed to a filter bank multi-carrier (FBMC) one, thus obtaining a lower\nout-of-band emission. The complex orthogonality of the FBMC transmission is\nguaranteed by using precoding based on a discrete Fourier transform, which is\nalso used to implement the two-dimensional fast Fourier transform. Through the\nuse of a global transmission matrix, we propose a hybrid receiver for the new\nsystem. First, a frequency domain equalization is performed, followed by an\ninterference cancellation on the delay-Doppler domain. The simulation results\nshow that the proposed system obtains an error performance similar to other\nOTFS systems, and superior performance as compared to other precoded FBMC\nsystems.",
    "descriptor": "",
    "authors": [
      "R. Pereira Junior",
      "C. A. F. da Rocha",
      "B. S. Chang",
      "D. Le Ruyet"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.05570"
  },
  {
    "id": "arXiv:2206.05573",
    "title": "Learning Model Preconditions for Planning with Multiple Models",
    "abstract": "Different models can provide differing levels of fidelity when a robot is\nplanning. Analytical models are often fast to evaluate but only work in limited\nranges of conditions. Meanwhile, physics simulators are effective at modeling\ncomplex interactions between objects but are typically more computationally\nexpensive. Learning when to switch between the various models can greatly\nimprove the speed of planning and task success reliability. In this work, we\nlearn model deviation estimators (MDEs) to predict the error between real-world\nstates and the states outputted by transition models. MDEs can be used to\ndefine a model precondition that describes which transitions are accurately\nmodeled. We then propose a planner that uses the learned model preconditions to\nswitch between various models in order to use models in conditions where they\nare accurate, prioritizing faster models when possible. We evaluate our method\non two real-world tasks: placing a rod into a box and placing a rod into a\nclosed drawer.",
    "descriptor": "\nComments: Presented at Conference on Robot Learning (CoRL 2021). Revised for clarity\n",
    "authors": [
      "Alex LaGrassa",
      "Oliver Kroemer"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.05573"
  },
  {
    "id": "arXiv:2206.05577",
    "title": "Local Randomized Neural Networks with Discontinuous Galerkin Methods for  Partial Differential Equations",
    "abstract": "Randomized neural networks (RNN) are a variation of neural networks in which\nthe hidden-layer parameters are fixed to randomly assigned values and the\noutput-layer parameters are obtained by solving a linear system by least\nsquares. This improves the efficiency without degrading the accuracy of the\nneural network. In this paper, we combine the idea of the local RNN (LRNN) and\nthe discontinuous Galerkin (DG) approach for solving partial differential\nequations. RNNs are used to approximate the solution on the subdomains, and the\nDG formulation is used to glue them together. Taking the Poisson problem as a\nmodel, we propose three numerical schemes and provide the convergence analyses.\nThen we extend the ideas to time-dependent problems. Taking the heat equation\nas a model, three space-time LRNN with DG formulations are proposed. Finally,\nwe present numerical tests to demonstrate the performance of the methods\ndeveloped herein. We compare the proposed methods with the finite element\nmethod and the usual DG method. The LRNN-DG methods can achieve better accuracy\nunder the same degrees of freedom, signifying that this new approach has a\ngreat potential for solving partial differential equations.",
    "descriptor": "",
    "authors": [
      "Jingbo Sun",
      "Suchuan Dong",
      "Fei Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.05577"
  },
  {
    "id": "arXiv:2206.05579",
    "title": "Online Paging with Heterogeneous Cache Slots",
    "abstract": "It is natural to generalize the $k$-Server problem by allowing each request\nto specify not only a point $p$, but also a subset $S$ of servers that may\nserve it. To attack this generalization, we focus on uniform and star metrics.\nFor uniform metrics, the problem is equivalent to a generalization of Paging in\nwhich each request specifies not only a page $p$, but also a subset $S$ of\ncache slots, and is satisfied by having a copy of $p$ in some slot in $S$. We\ncall this problem Slot-Heterogeneous Paging.\nWe parameterize the problem by specifying an arbitrary family ${\\cal S}\n\\subseteq 2^{[k]}$, and restricting the sets $S$ to ${\\cal S}$. If all request\nsets are allowed (${\\cal S}=2^{[k]}$), the optimal deterministic and randomized\ncompetitive ratios are exponentially worse than for standard Paging (${\\cal\nS}=\\{[k]\\}$). As a function of $|{\\cal S}|$ and the cache size $k$, the optimal\ndeterministic ratio is polynomial: at most $O(k^2|{\\cal S}|)$ and at least\n$\\Omega(\\sqrt{|{\\cal S}|})$. For any laminar family ${\\cal S}$ of height $h$,\nthe optimal ratios are $O(hk)$ (deterministic) and $O(h^2\\log k)$ (randomized).\nThe special case that we call All-or-One Paging extends standard Paging by\nallowing each request to specify a specific slot to put the requested page in.\nFor All-or-One Paging the optimal competitive ratios are $\\Theta(k)$\n(deterministic) and $\\Theta(\\log k)$ (randomized), while the offline problem is\nNP-hard. We extend the deterministic upper bound to the weighted variant of\nAll-Or-One Paging (a generalization of standard Weighted Paging), showing that\nit is also $\\Theta(k)$.",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Marek Chrobak",
      "Samuel Haney",
      "Mehraneh Liaee",
      "Debmalya Panigrahi",
      "Rajmohan Rajaraman",
      "Ravi Sundaram",
      "Neal E. Young"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.05579"
  },
  {
    "id": "arXiv:2206.05584",
    "title": "Modeling and Optimization of a Longitudinally-Distributed Global Solar  Grid",
    "abstract": "Our simulation-based experiments are aimed to demonstrate a use case on the\nfeasibility of fulfillment of global energy demand by primarily relying on\nsolar energy through the integration of a longitudinally-distributed grid.\nThese experiments demonstrate the availability of simulation technologies, good\napproximation models of grid components, and data for simulation. We also\nexperimented with integrating different tools to create realistic simulations\nas we are currently developing a detailed tool-chain for experimentation. These\nexperiments consist of a network of model houses at different locations in the\nworld, each producing and consuming only solar energy. The model includes\nhouses, various appliances, appliance usage schedules, regional weather\ninformation, floor area, HVAC systems, population, number of houses in the\nregion, and other parameters to imitate a real-world scenario. Data gathered\nfrom the power system simulation is used to develop optimization models to find\nthe optimal solar panel area required at the different locations to satisfy\nenergy demands in different scenarios.",
    "descriptor": "",
    "authors": [
      "Harsh Vardhan",
      "Neal M Sarkar",
      "Himanshu Neema"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.05584"
  },
  {
    "id": "arXiv:2206.05588",
    "title": "Neighborhoods of binary self-dual codes",
    "abstract": "In this paper, we introduce the neighborhood of binary self-dual codes.\nFurther, we show that for codelength divisible by $8$ such a neighborhood\nconsists of three self-dual codes, two of them are doubly-even and one is\nalways singly-even. We investigate the relationship between neighboring codes.\nFinally, we prove that no better Type I code exists than the best possible Type\nII code of the same length.",
    "descriptor": "",
    "authors": [
      "Carolin Hannusch",
      "S. Roland Major"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2206.05588"
  },
  {
    "id": "arXiv:2206.05589",
    "title": "Determinable and interpretable network representation for link  prediction",
    "abstract": "As an intuitive description of complex physical, social, or brain systems,\ncomplex networks have fascinated scientists for decades. Recently, to abstract\na network's structural and dynamical attributes for utilization, network\nrepresentation has been one focus, mapping a network or its substructures (like\nnodes) into a low-dimensional vector space. Since the current methods are\nmostly based on machine learning, a black box of an input-output data fitting\nmechanism, generally the space's dimension is indeterminable and its elements\nare not interpreted. Although massive efforts to cope with this issue have\nincluded, for example, automated machine learning by computer scientists and\ncomputational theory by mathematics, the root causes still remain unresolved.\nGiven that, from a physical perspective, this article proposes two determinable\nand interpretable node representation methods. To evaluate their effectiveness\nand generalization, this article further proposes Adaptive and Interpretable\nProbS (AIProbS), a network-based model that can utilize node representations\nfor link prediction. Experimental results showed that the AIProbS can reach\nstate-of-the-art precision beyond baseline models, and by and large it can make\na good trade-off with machine learning-based models on precision, determinacy,\nand interpretability, indicating that physical methods could also play a large\nrole in the study of network representation.",
    "descriptor": "",
    "authors": [
      "Yue Deng"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2206.05589"
  },
  {
    "id": "arXiv:2206.05592",
    "title": "Homunculus: Auto-Generating Efficient Data-Plane ML Pipelines for  Datacenter Networks",
    "abstract": "Support for Machine Learning (ML) applications in networks has significantly\nimproved over the last decade. The availability of public datasets and\nprogrammable switching fabrics (including low-level languages to program them)\npresent a full-stack to the programmer for deploying in-network ML. However,\nthe diversity of tools involved, coupled with complex optimization tasks of ML\nmodel design and hyperparameter tuning while complying with the network\nconstraints (like throughput and latency), put the onus on the network operator\nto be an expert in ML, network design, and programmable hardware. This\nmulti-faceted nature of in-network tools and expertise in ML and hardware is a\nroadblock for ML to become mainstream in networks, today.\nWe present Homunculus, a high-level framework that enables network operators\nto specify their ML requirements in a declarative, rather than imperative way.\nHomunculus takes as input, the training data and accompanying network\nconstraints, and automatically generates and installs a suitable model onto the\nunderlying switching hardware. It performs model design-space exploration,\ntraining, and platform code-generation as compiler stages, leaving network\noperators to focus on acquiring high-quality network data. Our evaluations on\nreal-world ML applications show that Homunculus's generated models achieve up\nto 12% better F1 score compared to hand-tuned alternatives, while requiring\nonly 30 lines of single-script code on average. We further demonstrate the\nperformance of the generated models on emerging per-packet ML platforms to\nshowcase its timely and practical significance.",
    "descriptor": "\nComments: 12 pages, 7 figures, 5 tables\n",
    "authors": [
      "Tushar Swamy",
      "Annus Zulfiqar",
      "Luigi Nardi",
      "Muhammad Shahbaz",
      "Kunle Olukotun"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.05592"
  },
  {
    "id": "arXiv:2206.05596",
    "title": "Neural Network-based Flight Control Systems: \\newline Present and Future",
    "abstract": "As the first review in this field, this paper presents an in-depth\nmathematical view of Intelligent Flight Control Systems (IFCSs), particularly\nthose based on artificial neural networks. The rapid evolution of IFCSs in the\nlast two decades in both the methodological and technical aspects necessitates\na comprehensive view of them to better demonstrate the current stage and the\ncrucial remaining steps towards developing a truly intelligent flight\nmanagement unit. To this end, in this paper, we will provide a detailed\nmathematical view of Neural Network (NN)-based flight control systems and the\nchallenging problems that still remain. The paper will cover both the\nmodel-based and model-free IFCSs. The model-based methods consist of the basic\nfeedback error learning scheme, the pseudocontrol strategy, and the neural\nbackstepping method. Besides, different approaches to analyze the closed-loop\nstability in IFCSs, their requirements, and their limitations will be discussed\nin detail. Various supplementary features, which can be integrated with a basic\nIFCS such as the fault-tolerance capability, the consideration of system\nconstraints, and the combination of NNs with other robust and adaptive elements\nlike disturbance observers, would be covered, as well. On the other hand,\nconcerning model-free flight controllers, both the indirect and direct adaptive\ncontrol systems including indirect adaptive control using NN-based system\nidentification, the approximate dynamic programming using NN, and the\nreinforcement learning-based adaptive optimal control will be carefully\naddressed. Finally, by demonstrating a well-organized view of the current stage\nin the development of IFCSs, the challenging issues, which are critical to be\naddressed in the future, are thoroughly identified.",
    "descriptor": "\nComments: 163 pages\n",
    "authors": [
      "Seyyed Ali Emami",
      "Paolo Castaldi",
      "Afshin Banazadeh"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.05596"
  },
  {
    "id": "arXiv:2206.05597",
    "title": "Lower Bounds for Sorting 16, 17, and 18 Elements",
    "abstract": "It is a long-standing open question to determine the minimum number of\ncomparisons $S(n)$ that suffice to sort an array of $n$ elements. Indeed,\nbefore this work $S(n)$ has been known only for $n\\leq 22$ with the exception\nfor $n=16$, $17$, and $18$. In this work, we fill that gap by proving that\nsorting $n=16$, $17$, and $18$ elements requires $46$, $50$, and $54$\ncomparisons respectively. This fully determines $S(n)$ for these values and\ndisproves a conjecture by Knuth that $S(16) = 45$. Moreover, we show that for\nsorting $28$ elements at least 99 comparisons are needed. We obtain our result\nvia an exhaustive computer search which extends previous work by Wells (1965)\nand Peczarski (2002, 2004, 2007, 2012). Our progress is both based on advances\nin hardware and on novel algorithmic ideas such as applying a bidirectional\nsearch to this problem.",
    "descriptor": "",
    "authors": [
      "Florian Stober",
      "Armin Wei\u00df"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.05597"
  },
  {
    "id": "arXiv:2206.05600",
    "title": "Narratives: the Unforeseen Influencer of Privacy Concerns",
    "abstract": "Privacy requirements are increasingly growing in importance as new privacy\nregulations are enacted. To adequately manage privacy requirements,\norganizations not only need to comply with privacy regulations, but also\nconsider user privacy concerns. In this exploratory study, we used Reddit as a\nsource to understand users' privacy concerns regarding software applications.\nWe collected 4.5 million posts from Reddit and classified 129075 privacy\nrelated posts, which is a non-negligible number of privacy discussions. Next,\nwe clustered these posts and identified 9 main areas of privacy concerns. We\nuse the concept of narratives from economics (i.e., posts that can go viral) to\nexplain the phenomenon of what and when users change in their discussion of\nprivacy. We further found that privacy discussions change over time and privacy\nregulatory events have a short term impact on such discussions. However,\nnarratives have a notable impact on what and when users discussed about\nprivacy. Considering narratives could guide software organizations in eliciting\nthe relevant privacy concerns before developing them as privacy requirements.",
    "descriptor": "\nComments: 13 pages, to be published in 30th IEEE International Requirements Engineering Conference (RE'22)\n",
    "authors": [
      "Ze Shi Li",
      "Manish Sihag",
      "Nowshin Nawar Arony",
      "Joao Bezerra Junior",
      "Thanh Phan",
      "Neil Ernst",
      "Daniela Damian"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.05600"
  },
  {
    "id": "arXiv:2206.05601",
    "title": "Simple Kinesthetic Haptics for Object Recognition",
    "abstract": "Object recognition is an essential capability when performing various tasks.\nHumans naturally use either or both visual and tactile perception to extract\nobject class and properties. Typical approaches for robots, however, require\ncomplex visual systems or multiple high-density tactile sensors which can be\nhighly expensive. In addition, they usually require actual collection of a\nlarge dataset from real objects through direct interaction. In this paper, we\npropose a kinesthetic-based object recognition method that can be performed\nwith any multi-fingered robotic hand in which the kinematics is known. The\nmethod does not require tactile sensors and is based on observing grasps of the\nobjects. We utilize a unique and frame invariant parameterization of grasps to\nlearn instances of object shapes. To train a classifier, training data is\ngenerated rapidly and solely in a computational process without interaction\nwith real objects. We then propose and compare between two iterative algorithms\nthat can integrate any trained classifier. The classifiers and algorithms are\nindependent of any particular robot hand and, therefore, can be exerted on\nvarious ones. We show in experiments, that with few grasps, the algorithms\nacquire accurate classification. Furthermore, we show that the object\nrecognition approach is scalable to objects of various sizes. Similarly, a\nglobal classifier is trained to identify general geometries (e.g., an ellipsoid\nor a box) rather than particular ones and demonstrated on a large set of\nobjects. Full scale experiments and analysis are provided to show the\nperformance of the method.",
    "descriptor": "",
    "authors": [
      "Avishai Sintov",
      "Inbar Ben-David"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.05601"
  },
  {
    "id": "arXiv:2206.05602",
    "title": "RadNet: Incident Prediction in Spatio-Temporal Road Graph Networks Using  Traffic Forecasting",
    "abstract": "Efficient and accurate incident prediction in spatio-temporal systems is\ncritical to minimize service downtime and optimize performance. This work aims\nto utilize historic data to predict and diagnose incidents using\nspatio-temporal forecasting. We consider the specific use case of road traffic\nsystems where incidents take the form of anomalous events, such as accidents or\nbroken-down vehicles. To tackle this, we develop a neural model, called RadNet,\nwhich forecasts system parameters such as average vehicle speeds for a future\ntimestep. As such systems largely follow daily or weekly periodicity, we\ncompare RadNet's predictions against historical averages to label incidents.\nUnlike prior work, RadNet infers spatial and temporal trends in both\npermutations, finally combining the dense representations before forecasting.\nThis facilitates informed inference and more accurate incident detection.\nExperiments with two publicly available and a new road traffic dataset\ndemonstrate that the proposed model gives up to 8% higher prediction F1 scores\ncompared to the state-of-the-art methods.",
    "descriptor": "\nComments: Accepted in IJCAI 2022 - Workshop on AI for Time Series Analysis\n",
    "authors": [
      "Shreshth Tuli",
      "Matthew R. Wilkinson",
      "Chris Kettell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05602"
  },
  {
    "id": "arXiv:2206.05603",
    "title": "Can the Language of the Collation be Translated into the Language of the  Stemma? Using Machine Translation for Witness Localization",
    "abstract": "Stemmatology is a subfield of philology where one approach to understand the\ncopy-history of textual variants of a text (witnesses of a tradition) is to\ngenerate an evolutionary tree. Computational methods are partly shared between\nthe sister discipline of phylogenetics and stemmatology. In 2022, a surveypaper\nin nature communications found that Deep Learning (DL), which otherwise has\nbrought about major improvements in many fields (Krohn et al 2020) has had only\nminor successes in phylogenetics and that \"it is difficult to conceive of an\nend-to-end DL model to directly estimate phylogenetic trees from raw data in\nthe near future\"(Sapoval et al. 2022, p.8). In stemmatology, there is to date\nno known DL approach at all. In this paper, we present a new DL approach to\nplacement of manuscripts on a stemma and demonstrate its potential. This could\nbe extended to phylogenetics where the universal code of DNA might be an even\nbetter prerequisite for the method using sequence to sequence based neural\nnetworks in order to retrieve tree distances.",
    "descriptor": "\nComments: 10 pages, 1 figure, 2 tables\n",
    "authors": [
      "Armin Hoenen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2206.05603"
  },
  {
    "id": "arXiv:2206.05605",
    "title": "Interest Flooding Attacks in Named Data Networking: Survey of Existing  Solutions, Open Issues, Requirements and Future Directions (Extended version)",
    "abstract": "Named Data Networking (NDN) is a prominent realization of the vision of\nInformation-Centric Networking. The NDN architecture adopts name-based routing\nand location-independent data retrieval. Among other important features, NDN\nintegrates security mechanisms and focuses on protecting the content rather\nthan the communications channels. Along with a new architecture come new\nthreats and NDN is no exception. NDN is a potential target for new network\nattacks such as Interest Flooding Attacks (IFAs). Attackers take advantage of\nIFA to launch (D)DoS attacks in NDN. Many IFA detection and mitigation\nsolutions have been proposed in the literature. However, there is no\ncomprehensive review study of these solutions that has been proposed so far.\nTherefore, in this paper, we propose a survey of the various IFAs with a\ndetailed comparative study of all the relevant proposed solutions as\ncounter-measures against IFAs. We also review the requirements for a complete\nand efficient IFA solution and pinpoint the various issues encountered by IFA\ndetection and mitigation mechanisms through a series of attack scenarios.\nFinally, in this survey, we offer an analysis of the open issues and future\nresearch directions regarding IFAs. This manuscript consists of an extended\nversion of the paper published in ACM Computing Surveys:\nhttps://dl.acm.org/doi/10.1145/3539730.",
    "descriptor": "\nComments: Just accepted, ACM Computing Surveys(CSUR) 2022, 46 pages, 18 figures\n",
    "authors": [
      "Ahmed Benmoussa",
      "Chaker Abdelaziz Kerrache",
      "Nasreddine Lagraa",
      "Spyridon Mastorakis",
      "Abderrahmane Lakas",
      "Abdou el Karim Tahari"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.05605"
  },
  {
    "id": "arXiv:2206.05608",
    "title": "Gradient Boosting Performs Low-Rank Gaussian Process Inference",
    "abstract": "This paper shows that gradient boosting based on symmetric decision trees can\nbe equivalently reformulated as a kernel method that converges to the solution\nof a certain Kernel Ridgeless Regression problem. Thus, for low-rank kernels,\nwe obtain the convergence to a Gaussian Process' posterior mean, which, in\nturn, allows us to easily transform gradient boosting into a sampler from the\nposterior to provide better knowledge uncertainty estimates through Monte-Carlo\nestimation of the posterior variance. We show that the proposed sampler allows\nfor better knowledge uncertainty estimates leading to improved out-of-domain\ndetection.",
    "descriptor": "",
    "authors": [
      "Aleksei Ustimenko",
      "Artem Beliakov",
      "Liudmila Prokhorenkova"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.05608"
  },
  {
    "id": "arXiv:2206.05616",
    "title": "Is Kernel Code Different From Non-Kernel Code? A Case Study of BSD  Family Operating Systems",
    "abstract": "Code churn and code velocity describe the evolution of a code base. Current\nresearch quantifies and studies code churn and velocity at a high level of\nabstraction, often at the overall project level or even at the level of an\nentire company. We argue that such an approach ignores noticeable differences\namong the subsystems of large projects. We conducted an exploratory study on\nfour BSD family operating systems: DragonFlyBSD, FreeBSD, NetBSD, and OpenBSD.\nWe mine 797,879 commits to characterize code churn in terms of the annual\ngrowth rate, commit types, change type ratio, and size taxonomy of commits for\ndifferent subsystems (kernel, non-kernel, and mixed). We also investigate\ndifferences among various code review periods, i.e., time-to-first-response,\ntime-to-accept, and time-to-merge, as indicators of code velocity. Our study\nprovides empirical evidence that quantifiable evolutionary code characteristics\nat a global system scope fail to take into account significant individual\ndifferences that exist at a subsystem level. We found that while there exist\nsimilarities in the code base growth rate and distribution of commit types\n(neutral, additive, and subtractive) across BSD subsystems, (a) most commits\ncontain kernel or non-kernel code exclusively, (b) kernel commits are larger\nthan non-kernel commits, and (c) code reviews for kernel code take longer than\nnon-kernel code.",
    "descriptor": "\nComments: 13 pages. To be published in 38th IEEE International Conference on Software Maintenance and Evolution (ICSME 2022), Oct 3-7, 2022, Limassol, Cyprus\n",
    "authors": [
      "Gunnar Kudrjavets",
      "Jeff Thomas",
      "Nachiappan Nagappan",
      "Ayushi Rastogi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Operating Systems (cs.OS)"
    ],
    "url": "https://arxiv.org/abs/2206.05616"
  },
  {
    "id": "arXiv:2206.05617",
    "title": "Federated Learning with Research Prototypes for Multi-Center MRI-based  Detection of Prostate Cancer with Diverse Histopathology",
    "abstract": "Early prostate cancer detection and staging from MRI are extremely\nchallenging tasks for both radiologists and deep learning algorithms, but the\npotential to learn from large and diverse datasets remains a promising avenue\nto increase their generalization capability both within- and across clinics. To\nenable this for prototype-stage algorithms, where the majority of existing\nresearch remains, in this paper we introduce a flexible federated learning\nframework for cross-site training, validation, and evaluation of deep prostate\ncancer detection algorithms. Our approach utilizes an abstracted representation\nof the model architecture and data, which allows unpolished prototype deep\nlearning models to be trained without modification using the NVFlare federated\nlearning framework. Our results show increases in prostate cancer detection and\nclassification accuracy using a specialized neural network model and diverse\nprostate biopsy data collected at two University of California research\nhospitals, demonstrating the efficacy of our approach in adapting to different\ndatasets and improving MR-biomarker discovery. We open-source our FLtools\nsystem, which can be easily adapted to other deep learning projects for medical\nimaging.",
    "descriptor": "\nComments: under review\n",
    "authors": [
      "Abhejit Rajagopal",
      "Ekaterina Redekop",
      "Anil Kemisetti",
      "Rushi Kulkarni",
      "Steven Raman",
      "Kirti Magudia",
      "Corey W. Arnold",
      "Peder E. Z. Larson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Tissues and Organs (q-bio.TO)"
    ],
    "url": "https://arxiv.org/abs/2206.05617"
  },
  {
    "id": "arXiv:2206.05619",
    "title": "Deep Learning Models for Automated Classification of Dog Emotional  States from Facial Expressions",
    "abstract": "Similarly to humans, facial expressions in animals are closely linked with\nemotional states. However, in contrast to the human domain, automated\nrecognition of emotional states from facial expressions in animals is\nunderexplored, mainly due to difficulties in data collection and establishment\nof ground truth concerning emotional states of non-verbal users. We apply\nrecent deep learning techniques to classify (positive) anticipation and\n(negative) frustration of dogs on a dataset collected in a controlled\nexperimental setting. We explore the suitability of different backbones (e.g.\nResNet, ViT) under different supervisions to this task, and find that features\nof a self-supervised pretrained ViT (DINO-ViT) are superior to the other\nalternatives. To the best of our knowledge, this work is the first to address\nthe task of automatic classification of canine emotions on data acquired in a\ncontrolled experiment.",
    "descriptor": "",
    "authors": [
      "Tali Boneh-Shitrit",
      "Shir Amir",
      "Annika Bremhorst",
      "Daniel S. Mills",
      "Stefanie Riemer",
      "Dror Fried",
      "Anna Zamansky"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.05619"
  },
  {
    "id": "arXiv:2206.05625",
    "title": "A Review on Plastic Artificial Neural Networks: Exploring the  Intersection between Neural Architecture Search and Continual Learning",
    "abstract": "Despite the significant advances achieved in Artificial Neural Networks\n(ANNs), their design process remains notoriously tedious, depending primarily\non intuition, experience and trial-and-error. This human-dependent process is\noften time-consuming and prone to errors. Furthermore, the models are generally\nbound to their training contexts, with no considerations of changes to their\nsurrounding environments. Continual adaptability and automation of neural\nnetworks is of paramount importance to several domains where model\naccessibility is limited after deployment (e.g IoT devices, self-driving\nvehicles, etc). Additionally, even accessible models require frequent\nmaintenance post-deployment to overcome issues such as Concept/Data Drift,\nwhich can be cumbersome and restrictive. The current state of the art on\nadaptive ANNs is still a premature area of research; nevertheless, Neural\nArchitecture Search (NAS), a form of AutoML, and Continual Learning (CL) have\nrecently gained an increasing momentum in the Deep Learning research field,\naiming to provide more robust and adaptive ANN development frameworks. This\nstudy is the first extensive review on the intersection between AutoML and CL,\noutlining research directions for the different methods that can facilitate\nfull automation and lifelong plasticity in ANNs.",
    "descriptor": "",
    "authors": [
      "Mohamed Shahawy",
      "Elhadj Benkhelifa",
      "David White"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.05625"
  },
  {
    "id": "arXiv:2206.05629",
    "title": "Governing for Free: Rule Process Effects on Reddit Moderator Motivations",
    "abstract": "Developing a strong community requires empowered leadership capable of\novercoming governance challenges. New online platforms have given users\nopportunities to practice governance through content moderation roles. The over\n2.8 million \"subreddit\" communities on Reddit are governed by hundreds of\nthousands of volunteer moderators, many of whom have no training or prior\nexperience in a governing role. While moderators often devote daily time to\ncommunity maintenance and cope with the emotional effects of hate comments or\ndisturbing content, Reddit provides no compensation for this position. Thus,\nmoderators' internal motivations and desire to continue filling this role is\ncritical for their community. Drawing upon the relationship between governance\nprocedures and internalized motivation, we investigate how the processes\nthrough which subreddit moderators generate community rules increase\nmoderators' motivation through the meeting of social-psychological needs:\nProcedural Justice and Self Determination, and Self-Other Merging. Preliminary\nanalysis of survey data from 620 moderators across Reddit shows a correlation\nbetween moderators' administrative behaviors and the social-psychological needs\nunderpinning their motivations. Understanding these relationships will allow us\nto empower moderators to build engaging and cooperative online communities.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Hannah M Wang",
      "Beril Bulat",
      "Stephen Fujimoto",
      "Seth Frey"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.05629"
  },
  {
    "id": "arXiv:2206.05630",
    "title": "Mathematical Theory of Bayesian Statistics for Unknown Information  Source",
    "abstract": "In statistical inference, uncertainty is unknown and all models are wrong. A\nperson who makes a statistical model and a prior distribution is simultaneously\naware that they are fictional and virtual candidates. In order to study such\ncases, several statistical measures have been constructed, such as cross\nvalidation, information criteria, and marginal likelihood, however, their\nmathematical properties have not yet been completely clarified when statistical\nmodels are under- and over- parametrized. In this paper, we introduce a place\nof mathematical theory of Bayesian statistics for unknown uncertainty, on which\nwe show general properties of cross validation, information criteria, and\nmarginal likelihood. The derived theory holds even if an unknown uncertainty is\nunrealizable by a statistical morel or even if the posterior distribution\ncannot be approximated by any normal distribution, hence it gives a helpful\nstandpoint for a person who cannot believe in any specific model and prior. The\nresults are followings. (1) There exists a more precise statistical measure of\nthe generalization loss than leave-one-out cross validation and information\ncriterion based on the mathematical properties of them. (2) There exists a more\nefficient approximation method of the free energy, which is the minus log\nmarginal likelihood, even if the posterior distribution cannot be approximated\nby any normal distribution. (3) And the prior distributions optimized by the\ncross validation and the widely applicable information criterion are\nasymptotically equivalent to each other, which are different from that by the\nmarginal likelihood.",
    "descriptor": "",
    "authors": [
      "Sumio Watanabe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2206.05630"
  },
  {
    "id": "arXiv:2206.05634",
    "title": "Random Access-based Multiuser Computation Offloading for Devices in IoT  Applications",
    "abstract": "In various Internet-of-Things (IoT) applications, a number of devices and\nsensors are used to collect data sets. As devices become more capable and\nsmarter, they can not only collect data sets, but also process them locally.\nHowever, since most devices would be limited in terms of computing power and\nenergy, they can take advantage of offloading so that their tasks can be\ncarried out at mobile edge computing (MEC) servers. In this paper, we discuss\ncomputation offloading for devices in IoT applications. In particular, we\nconsider users or devices with sporadic tasks, where optimizing resource\nallocation between offloading devices and coordinating for multiuser offloading\nbecomes inefficient. Thus, we propose a two-stage offloading approach that is\nfriendly to devices with sporadic tasks as it employs multichannel random\naccess for offloading requests with low signaling overhead. The stability of\nthe two-stage offloading approach is considered with methods to stabilize the\nsystem. We also analyze the latency outage probability as a performance index\nfrom a device perspective.",
    "descriptor": "\nComments: 10 pages, 8 figures, to appear in IEEE IoTJ\n",
    "authors": [
      "Jinho Choi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.05634"
  },
  {
    "id": "arXiv:2206.05637",
    "title": "Convergence and Stability of Coupled Belief--Strategy Learning Dynamics  in Continuous Games",
    "abstract": "We propose a learning dynamics to model how strategic agents repeatedly play\na continuous game while relying on an information platform to learn an unknown\npayoff-relevant parameter. In each time step, the platform updates a belief\nestimate of the parameter based on players' strategies and realized payoffs\nusing Bayes's rule. Then, players adopt a generic learning rule to adjust their\nstrategies based on the updated belief. We present results on the convergence\nof beliefs and strategies and the properties of convergent fixed points of the\ndynamics. We obtain sufficient and necessary conditions for the existence of\nglobally stable fixed points. We also provide sufficient conditions for the\nlocal stability of fixed points. These results provide an approach to analyzing\nthe long-term outcomes that arise from the interplay between Bayesian belief\nlearning and strategy learning in games, and enable us to characterize\nconditions under which learning leads to a complete information equilibrium.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2109.00719\n",
    "authors": [
      "Manxi Wu",
      "Saurabh Amin",
      "Asuman Ozdaglar"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2206.05637"
  },
  {
    "id": "arXiv:2206.05641",
    "title": "An Unsupervised Deep-Learning Method for Bone Age Assessment",
    "abstract": "The bone age, reflecting the degree of development of the bones, can be used\nto predict the adult height and detect endocrine diseases of children. Both\nexaminations of radiologists and variability of operators have a significant\nimpact on bone age assessment. To decrease human intervention , machine\nlearning algorithms are used to assess the bone age automatically. However,\nconventional supervised deep-learning methods need pre-labeled data. In this\npaper, based on the convolutional auto-encoder with constraints (CCAE), an\nunsupervised deep-learning model proposed in the classification of the\nfingerprint, we propose this model for the classification of the bone age and\nbaptize it BA-CCAE. In the proposed BA-CCAE model, the key regions of the raw\nX-ray images of the bone age are encoded, yielding the latent vectors. The\nK-means clustering algorithm is used to obtain the final classifications by\ngrouping the latent vectors of the bone images. A set of experiments on the\nRadiological Society of North America pediatric bone age dataset (RSNA) show\nthat the accuracy of classifications at 48-month intervals is 76.15%. Although\nthe accuracy now is lower than most of the existing supervised models, the\nproposed BA-CCAE model can establish the classification of bone age without any\npre-labeled data, and to the best of our knowledge, the proposed BA-CCAE is one\nof the few trails using the unsupervised deep-learning method for the bone age\nassessment.",
    "descriptor": "",
    "authors": [
      "Hao Zhu",
      "Wan-Jing Nie",
      "Yue-Jie Hou",
      "Qi-Meng Du",
      "Si-Jing Li",
      "Chi-Chun Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.05641"
  },
  {
    "id": "arXiv:2206.05643",
    "title": "Density Regression and Uncertainty Quantification with Bayesian Deep  Noise Neural Networks",
    "abstract": "Deep neural network (DNN) models have achieved state-of-the-art predictive\naccuracy in a wide range of supervised learning applications. However,\naccurately quantifying the uncertainty in DNN predictions remains a challenging\ntask. For continuous outcome variables, an even more difficult problem is to\nestimate the predictive density function, which not only provides a natural\nquantification of the predictive uncertainty, but also fully captures the\nrandom variation in the outcome. In this work, we propose the Bayesian Deep\nNoise Neural Network (B-DeepNoise), which generalizes standard Bayesian DNNs by\nextending the random noise variable from the output layer to all hidden layers.\nThe latent random noise equips B-DeepNoise with the flexibility to approximate\nhighly complex predictive distributions and accurately quantify predictive\nuncertainty. For posterior computation, the unique structure of B-DeepNoise\nleads to a closed-form Gibbs sampling algorithm that iteratively simulates from\nthe posterior full conditional distributions of the model parameters,\ncircumventing computationally intensive Metropolis-Hastings methods. A\ntheoretical analysis of B-DeepNoise establishes a recursive representation of\nthe predictive distribution and decomposes the predictive variance with respect\nto the latent parameters. We evaluate B-DeepNoise against existing methods on\nbenchmark regression datasets, demonstrating its superior performance in terms\nof prediction accuracy, uncertainty quantification accuracy, and uncertainty\nquantification efficiency. To illustrate our method's usefulness in scientific\nstudies, we apply B-DeepNoise to predict general intelligence from neuroimaging\nfeatures in the Adolescent Brain Cognitive Development (ABCD) project.",
    "descriptor": "",
    "authors": [
      "Daiwei Zhang",
      "Tianci Liu",
      "Jian Kang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.05643"
  },
  {
    "id": "arXiv:2206.05648",
    "title": "Indirect-Instant Attention Optimization for Crowd Counting in Dense  Scenes",
    "abstract": "One of appealing approaches to guiding learnable parameter optimization, such\nas feature maps, is global attention, which enlightens network intelligence at\na fraction of the cost. However, its loss calculation process still falls\nshort: 1)We can only produce one-dimensional 'pseudo labels' for attention,\nsince the artificial threshold involved in the procedure is not robust; 2) The\nattention awaiting loss calculation is necessarily high-dimensional, and\ndecreasing it by convolution will inevitably introduce additional learnable\nparameters, thus confusing the source of the loss. To this end, we devise a\nsimple but efficient Indirect-Instant Attention Optimization (IIAO) module\nbased on SoftMax-Attention , which transforms high-dimensional attention map\ninto a one-dimensional feature map in the mathematical sense for loss\ncalculation midway through the network, while automatically providing adaptive\nmulti-scale fusion to feature pyramid module. The special transformation yields\nrelatively coarse features and, originally, the predictive fallibility of\nregions varies by crowd density distribution, so we tailor the Regional\nCorrelation Loss (RCLoss) to retrieve continuous error-prone regions and smooth\nspatial information . Extensive experiments have proven that our approach\nsurpasses previous SOTA methods in many benchmark datasets.",
    "descriptor": "",
    "authors": [
      "Suyu Han",
      "Guodong Wang",
      "Donghua Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.05648"
  },
  {
    "id": "arXiv:2206.05649",
    "title": "TileGen: Tileable, Controllable Material Generation and Capture",
    "abstract": "Recent methods (e.g. MaterialGAN) have used unconditional GANs to generate\nper-pixel material maps, or as a prior to reconstruct materials from input\nphotographs. These models can generate varied random material appearance, but\ndo not have any mechanism to constrain the generated material to a specific\ncategory or to control the coarse structure of the generated material, such as\nthe exact brick layout on a brick wall. Furthermore, materials reconstructed\nfrom a single input photo commonly have artifacts and are generally not\ntileable, which limits their use in practical content creation pipelines. We\npropose TileGen, a generative model for SVBRDFs that is specific to a material\ncategory, always tileable, and optionally conditional on a provided input\nstructure pattern. TileGen is a variant of StyleGAN whose architecture is\nmodified to always produce tileable (periodic) material maps. In addition to\nthe standard \"style\" latent code, TileGen can optionally take a condition\nimage, giving a user direct control over the dominant spatial (and optionally\ncolor) features of the material. For example, in brick materials, the user can\nspecify a brick layout and the brick color, or in leather materials, the\nlocations of wrinkles and folds. Our inverse rendering approach can find a\nmaterial perceptually matching a single target photograph by optimization. This\nreconstruction can also be conditional on a user-provided pattern. The\nresulting materials are tileable, can be larger than the target image, and are\neditable by varying the condition.",
    "descriptor": "\nComments: 18 pages, 19 figures\n",
    "authors": [
      "Xilong Zhou",
      "Milo\u0161 Ha\u0161an",
      "Valentin Deschaintre",
      "Paul Guerrero",
      "Kalyan Sunkavalli",
      "Nima Kalantari"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.05649"
  },
  {
    "id": "arXiv:2206.05651",
    "title": "STD-NET: Search of Image Steganalytic Deep-learning Architecture via  Hierarchical Tensor Decomposition",
    "abstract": "Recent studies shows that the majority of existing deep steganalysis models\nhave a large amount of redundancy, which leads to a huge waste of storage and\ncomputing resources. The existing model compression method cannot flexibly\ncompress the convolutional layer in residual shortcut block so that a\nsatisfactory shrinking rate cannot be obtained. In this paper, we propose\nSTD-NET, an unsupervised deep-learning architecture search approach via\nhierarchical tensor decomposition for image steganalysis. Our proposed strategy\nwill not be restricted by various residual connections, since this strategy\ndoes not change the number of input and output channels of the convolution\nblock. We propose a normalized distortion threshold to evaluate the sensitivity\nof each involved convolutional layer of the base model to guide STD-NET to\ncompress target network in an efficient and unsupervised approach, and obtain\ntwo network structures of different shapes with low computation cost and\nsimilar performance compared with the original one. Extensive experiments have\nconfirmed that, on one hand, our model can achieve comparable or even better\ndetection performance in various steganalytic scenarios due to the great\nadaptivity of the obtained network architecture. On the other hand, the\nexperimental results also demonstrate that our proposed strategy is more\nefficient and can remove more redundancy compared with previous steganalytic\nnetwork compression methods.",
    "descriptor": "\nComments: Submitted to IEEE T-DSC\n",
    "authors": [
      "Shunquan Tan",
      "Qiushi Li",
      "Laiyuan Li",
      "Bin Li",
      "Jiwu Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2206.05651"
  },
  {
    "id": "arXiv:2206.05652",
    "title": "Dealing with Sparse Rewards in Continuous Control Robotics via  Heavy-Tailed Policies",
    "abstract": "In this paper, we present a novel Heavy-Tailed Stochastic Policy Gradient\n(HT-PSG) algorithm to deal with the challenges of sparse rewards in continuous\ncontrol problems. Sparse reward is common in continuous control robotics tasks\nsuch as manipulation and navigation, and makes the learning problem hard due to\nnon-trivial estimation of value functions over the state space. This demands\neither reward shaping or expert demonstrations for the sparse reward\nenvironment. However, obtaining high-quality demonstrations is quite expensive\nand sometimes even impossible. We propose a heavy-tailed policy parametrization\nalong with a modified momentum-based policy gradient tracking scheme (HT-SPG)\nto induce a stable exploratory behavior to the algorithm. The proposed\nalgorithm does not require access to expert demonstrations. We test the\nperformance of HT-SPG on various benchmark tasks of continuous control with\nsparse rewards such as 1D Mario, Pathological Mountain Car, Sparse Pendulum in\nOpenAI Gym, and Sparse MuJoCo environments (Hopper-v2). We show consistent\nperformance improvement across all tasks in terms of high average cumulative\nreward. HT-SPG also demonstrates improved convergence speed with minimum\nsamples, thereby emphasizing the sample efficiency of our proposed algorithm.",
    "descriptor": "",
    "authors": [
      "Souradip Chakraborty",
      "Amrit Singh Bedi",
      "Alec Koppel",
      "Pratap Tokekar",
      "Dinesh Manocha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.05652"
  },
  {
    "id": "arXiv:2206.05654",
    "title": "A Matrix Decomposition Model Based on Feature Factors in Movie  Recommendation System",
    "abstract": "Matrix Factorization (MF) is one of the most successful Collaborative\nFiltering (CF) techniques used in recommender systems due to its effectiveness\nand ability to deal with very large user-item rating matrix. Among them, matrix\ndecomposition method mainly uses the interactions records between users and\nitems to predict ratings. Based on the characteristic attributes of items and\nusers, this paper proposes a UISVD++ model that fuses the type attributes of\nmovies and the age attributes of users into MF framework. Project and user\nrepresentations in MF are enriched by projecting each user's age attribute and\neach movie's type attribute into the same potential factor space as users and\nitems. Finally, the MovieLens-100K and MovieLens-1M datasets were used to\ncompare with the traditional SVD++ and other models. The results show that the\nproposed model can achieve the best recommendation performance and better\npredict user ratings under all backgrounds.",
    "descriptor": "\nComments: 8 pages, 5 figures, 7 tables\n",
    "authors": [
      "Dan Liu",
      "Hou-biao Li"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.05654"
  },
  {
    "id": "arXiv:2206.05657",
    "title": "LUEM : Local User Engagement Maximization in Networks",
    "abstract": "Understanding a social network is a fundamental problem in social network\nanalysis because of its numerous applications. Recently, user engagement in\nnetworks has received extensive attention from many research groups. However,\nmost user engagement models focus on global user engagement to maximize (or\nminimize) the number of engaged users. In this study, we formulate the\nso-called Local User Engagement Maximization (LUEM) problem. We prove that the\nLUEM problem is NP-hard. To obtain high-quality results, we propose an\napproximation algorithm that incorporates a traditional hill-climbing method.\nTo improve efficiency, we propose an efficient pruning strategy while\nmaintaining effectiveness. In addition, by observing the relationship between\nthe degree and user engagement, we propose an efficient heuristic algorithm\nthat preserves effectiveness. Finally, we conducted extensive experiments on\nten real-world networks to demonstrate the superiority of the proposed\nalgorithms. We observed that the proposed algorithm achieved up to 605% more\nengaged users compared to the best baseline algorithms.",
    "descriptor": "",
    "authors": [
      "Junghoon Kim",
      "Jungeun Kim",
      "Hyun Ji Jeong",
      "Sungsu Lim"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.05657"
  },
  {
    "id": "arXiv:2206.05658",
    "title": "Fine-tuning Pre-trained Language Models with Noise Stability  Regularization",
    "abstract": "The advent of large-scale pre-trained language models has contributed greatly\nto the recent progress in natural language processing. Many state-of-the-art\nlanguage models are first trained on a large text corpus and then fine-tuned on\ndownstream tasks. Despite its recent success and wide adoption, fine-tuning a\npre-trained language model often suffers from overfitting, which leads to poor\ngeneralizability due to the extremely high complexity of the model and the\nlimited training samples from downstream tasks. To address this problem, we\npropose a novel and effective fine-tuning framework, named Layerwise Noise\nStability Regularization (LNSR). Specifically, we propose to inject the\nstandard Gaussian noise or In-manifold noise and regularize hidden\nrepresentations of the fine-tuned model. We first provide theoretical analyses\nto support the efficacy of our method. We then demonstrate the advantages of\nthe proposed method over other state-of-the-art algorithms including L2-SP,\nMixout and SMART. While these previous works only verify the effectiveness of\ntheir methods on relatively simple text classification tasks, we also verify\nthe effectiveness of our method on question answering tasks, where the target\nproblem is much more difficult and more training examples are available.\nFurthermore, extensive experimental results indicate that the proposed\nalgorithm can not only enhance the in-domain performance of the language models\nbut also improve the domain generalization performance on out-of-domain data.",
    "descriptor": "\nComments: Preprint. Under Review\n",
    "authors": [
      "Hang Hua",
      "Xingjian Li",
      "Dejing Dou",
      "Cheng-Zhong Xu",
      "Jiebo Luo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.05658"
  },
  {
    "id": "arXiv:2206.05662",
    "title": "Resilience for Distributed Consensus with Constraints",
    "abstract": "This paper proposes a new approach that enables multi-agent systems to\nachieve resilient constrained consensus in the presence of Byzantine attacks,\nin contrast to existing literature that is only applicable for unconstrained\nresilient consensus problems. The key enabler for our approach is a new device\ncalled a $(\\gamma_i,\\alpha_i)$-resilient convex combination, which allows\nnormal agents in the network to utilize their locally available information to\nautomatically isolate the impact of the Byzantine agents. Such a resilient\nconvex combination is computable through linear programming, whose complexity\nscales well with the size of the overall system. By employing this new device\nto multi-agent systems, we introduce redundancy conditions under which\nresilient constrained consensus can be achieved with an exponential convergence\nrate. We also provide insights on the design of a network such that the\nredundancy conditions are satisfied. We validate all the proposed results\nthrough theoretical proofs. Finally, numerical simulations and an application\nexample of safe multi-agent learning are provided to demonstrate the\neffectiveness of the proposed results.",
    "descriptor": "\nComments: 15 pages, 8 figures\n",
    "authors": [
      "Xuan Wang",
      "Shaoshuai Mou",
      "Shreyas Sundaram"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.05662"
  },
  {
    "id": "arXiv:2206.05664",
    "title": "An Efficient Method for Sample Adversarial Perturbations against  Nonlinear Support Vector Machines",
    "abstract": "Adversarial perturbations have drawn great attentions in various machine\nlearning models. In this paper, we investigate the sample adversarial\nperturbations for nonlinear support vector machines (SVMs). Due to the implicit\nform of the nonlinear functions mapping data to the feature space, it is\ndifficult to obtain the explicit form of the adversarial perturbations. By\nexploring the special property of nonlinear SVMs, we transform the optimization\nproblem of attacking nonlinear SVMs into a nonlinear KKT system. Such a system\ncan be solved by various numerical methods. Numerical results show that our\nmethod is efficient in computing adversarial perturbations.",
    "descriptor": "",
    "authors": [
      "Wen Su",
      "Qingna Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.05664"
  },
  {
    "id": "arXiv:2206.05668",
    "title": "Federated Learning on Riemannian Manifolds",
    "abstract": "Federated learning (FL) has found many important applications in\nsmart-phone-APP based machine learning applications. Although many algorithms\nhave been studied for FL, to the best of our knowledge, algorithms for FL with\nnonconvex constraints have not been studied. This paper studies FL over\nRiemannian manifolds, which finds important applications such as federated PCA\nand federated kPCA. We propose a Riemannian federated SVRG (RFedSVRG) method to\nsolve federated optimization over Riemannian manifolds. We analyze its\nconvergence rate under different scenarios. Numerical experiments are conducted\nto compare RFedSVRG with the Riemannian counterparts of FedAvg and FedProx. We\nobserved from the numerical experiments that the advantages of RFedSVRG are\nsignificant.",
    "descriptor": "",
    "authors": [
      "Jiaxiang Li",
      "Shiqian Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.05668"
  },
  {
    "id": "arXiv:2206.05669",
    "title": "Universality and approximation bounds for echo state networks with  random weights",
    "abstract": "We study the uniform approximation of echo state networks with randomly\ngenerated internal weights. These models, in which only the readout weights are\noptimized during training, have made empirical success in learning dynamical\nsystems. We address the representational capacity of these models by showing\nthat they are universal under weak conditions. Our main result gives a\nsufficient condition for the activation function and a sampling procedure for\nthe internal weights so that echo state networks can approximate any continuous\ncasual time-invariant operators with high probability. In particular, for ReLU\nactivation, we quantify the approximation error of echo state networks for\nsufficiently regular operators.",
    "descriptor": "",
    "authors": [
      "Zhen Li",
      "Yunfei Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.05669"
  },
  {
    "id": "arXiv:2206.05671",
    "title": "Reinforcement Learning for Vision-based Object Manipulation with  Non-parametric Policy and Action Primitives",
    "abstract": "The object manipulation is a crucial ability for a service robot, but it is\nhard to solve with reinforcement learning due to some reasons such as sample\nefficiency. In this paper, to tackle this object manipulation, we propose a\nnovel framework, AP-NPQL (Non-Parametric Q Learning with Action Primitives),\nthat can efficiently solve the object manipulation with visual input and sparse\nreward, by utilizing a non-parametric policy for reinforcement learning and\nappropriate behavior prior for the object manipulation. We evaluate the\nefficiency and the performance of the proposed AP-NPQL for four object\nmanipulation tasks on simulation (pushing plate, stacking box, flipping cup,\nand picking and placing plate), and it turns out that our AP-NPQL outperforms\nthe state-of-the-art algorithms based on parametric policy and behavior prior\nin terms of learning time and task success rate. We also successfully transfer\nand validate the learned policy of the plate pick-and-place task to the real\nrobot in a sim-to-real manner.",
    "descriptor": "",
    "authors": [
      "Dongwon Son",
      "Myungsin Kim",
      "Jaecheol Sim",
      "Wonsik Shin"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.05671"
  },
  {
    "id": "arXiv:2206.05675",
    "title": "A Survey on Uncertainty Reasoning and Quantification for Decision  Making: Belief Theory Meets Deep Learning",
    "abstract": "An in-depth understanding of uncertainty is the first step to making\neffective decisions under uncertainty. Deep/machine learning (ML/DL) has been\nhugely leveraged to solve complex problems involved with processing\nhigh-dimensional data. However, reasoning and quantifying different types of\nuncertainties to achieve effective decision-making have been much less explored\nin ML/DL than in other Artificial Intelligence (AI) domains. In particular,\nbelief/evidence theories have been studied in KRR since the 1960s to reason and\nmeasure uncertainties to enhance decision-making effectiveness. We found that\nonly a few studies have leveraged the mature uncertainty research in\nbelief/evidence theories in ML/DL to tackle complex problems under different\ntypes of uncertainty. In this survey paper, we discuss several popular belief\ntheories and their core ideas dealing with uncertainty causes and types and\nquantifying them, along with the discussions of their applicability in ML/DL.\nIn addition, we discuss three main approaches that leverage belief theories in\nDeep Neural Networks (DNNs), including Evidential DNNs, Fuzzy DNNs, and Rough\nDNNs, in terms of their uncertainty causes, types, and quantification methods\nalong with their applicability in diverse problem domains. Based on our\nin-depth survey, we discuss insights, lessons learned, limitations of the\ncurrent state-of-the-art bridging belief theories and ML/DL, and finally,\nfuture research directions.",
    "descriptor": "\nComments: First four authors contributed equally. Submitted to ACM Computing Surveys\n",
    "authors": [
      "Zhen Guo",
      "Zelin Wan",
      "Qisheng Zhang",
      "Xujiang Zhao",
      "Feng Chen",
      "Jin-Hee Cho",
      "Qi Zhang",
      "Lance M. Kaplan",
      "Dong H. Jeong",
      "Audun J\u00f8sang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05675"
  },
  {
    "id": "arXiv:2206.05676",
    "title": "VeriBlock: A Blockchain-Based Verifiable Trust Management Architecture  with Provable Interactions",
    "abstract": "There has been considerable advancement in the use of blockchain for trust\nmanagement in large-scale dynamic systems. In such systems, blockchain is\nmainly used to store the trust score or trust-related information of\ninteractions among the various entities. However, present trust management\narchitectures using blockchain lack verifiable interactions among the entities\non which the trust score is calculated. In this paper, we propose a\nblockchain-based trust management framework that allows independent trust\nproviders to implement different trust metrics on a common set of trust\nevidence and provide individual trust value. We employ geo-location as proof of\ninteraction. Some of the existing proposals rely upon geo-location data, but\nthey do not support trust calculation by multiple trust providers. Instead,\nthey can only support a centralised system. Our proposed architecture does not\ndepend upon a single centralised third-party entity to ensure trusted\ninteractions. Our architecture is supported by provable interactions that can\neasily be verified using blockchain. Therefore, it allows a high degree of\nconfidence in trust management by ensuring the actual interactions between the\nentities. We provide a detailed design and development of the architecture\nusing real-world use case examples. The proof of prototype was implemented on\nthe Ethereum blockchain platform. Experimental results demonstrate that the\nemployment of independent trust providers adequately provides a high degree of\ntrust scores and that the proposed architecture can be used in a real-world\nenvironment.",
    "descriptor": "",
    "authors": [
      "Shantanu Pal",
      "Ambrose Hill",
      "Tahiry Rabehaja",
      "Michael Hitchens"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.05676"
  },
  {
    "id": "arXiv:2206.05678",
    "title": "Security of Machine Learning-Based Anomaly Detection in Cyber Physical  Systems",
    "abstract": "In this study, we focus on the impact of adversarial attacks on deep\nlearning-based anomaly detection in CPS networks and implement a mitigation\napproach against the attack by retraining models using adversarial samples. We\nuse the Bot-IoT and Modbus IoT datasets to represent the two CPS networks. We\ntrain deep learning models and generate adversarial samples using these\ndatasets. These datasets are captured from IoT and Industrial IoT (IIoT)\nnetworks. They both provide samples of normal and attack activities. The deep\nlearning model trained with these datasets showed high accuracy in detecting\nattacks. An Artificial Neural Network (ANN) is adopted with one input layer,\nfour intermediate layers, and one output layer. The output layer has two nodes\nrepresenting the binary classification results. To generate adversarial samples\nfor the experiment, we used a function called the `fast_gradient_method' from\nthe Cleverhans library. The experimental result demonstrates the influence of\nFGSM adversarial samples on the accuracy of the predictions and proves the\neffectiveness of using the retrained model to defend against adversarial\nattacks.",
    "descriptor": "",
    "authors": [
      "Zahra Jadidi",
      "Shantanu Pal",
      "Nithesh Nayak K",
      "Arawinkumaar Selvakkumar",
      "Chih-Chia Chang",
      "Maedeh Beheshti",
      "Alireza Jolfaei"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.05678"
  },
  {
    "id": "arXiv:2206.05679",
    "title": "Exploration of Enterprise Server Data to Assess Ease of Modeling System  Behavior",
    "abstract": "Enterprise networks are one of the major targets for cyber attacks due to the\nvast amount of sensitive and valuable data they contain. A common approach to\ndetecting attacks in the enterprise environment relies on modeling the behavior\nof users and systems to identify unexpected deviations. The feasibility of this\napproach crucially depends on how well attack-related events can be isolated\nfrom benign and mundane system activities. Despite the significant focus on\nend-user systems, the background behavior of servers running critical services\nfor the enterprise is less studied. To guide the design of detection methods\ntailored for servers, in this work, we examine system event records from 46\nservers in a large enterprise obtained over a duration of ten weeks. We analyze\nthe rareness characteristics and the similarity of the provenance relations in\nthe event log data. Our findings show that server activity, in general, is\nhighly variant over time and dissimilar across different types of servers.\nHowever, careful consideration of profiling window of historical events and\nservice level grouping of servers improve rareness measurements by 24.5%.\nFurther, utilizing better contextual representations, the similarity in\nprovenance relationships could be improved. An important implication of our\nfindings is that detection techniques developed considering experimental setups\nwith non-representative characteristics may perform poorly in practice.",
    "descriptor": "",
    "authors": [
      "Enes Altinisik",
      "Husrev Taha Sencar",
      "Mohamed Nabeel",
      "Issa Khalil",
      "Ting Yu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.05679"
  },
  {
    "id": "arXiv:2206.05682",
    "title": "Balancing Bias and Variance for Active Weakly Supervised Learning",
    "abstract": "As a widely used weakly supervised learning scheme, modern multiple instance\nlearning (MIL) models achieve competitive performance at the bag level.\nHowever, instance-level prediction, which is essential for many important\napplications, remains largely unsatisfactory. We propose to conduct novel\nactive deep multiple instance learning that samples a small subset of\ninformative instances for annotation, aiming to significantly boost the\ninstance-level prediction. A variance regularized loss function is designed to\nproperly balance the bias and variance of instance-level predictions, aiming to\neffectively accommodate the highly imbalanced instance distribution in MIL and\nother fundamental challenges. Instead of directly minimizing the variance\nregularized loss that is non-convex, we optimize a distributionally robust bag\nlevel likelihood as its convex surrogate. The robust bag likelihood provides a\ngood approximation of the variance based MIL loss with a strong theoretical\nguarantee. It also automatically balances bias and variance, making it\neffective to identify the potentially positive instances to support active\nsampling. The robust bag likelihood can be naturally integrated with a deep\narchitecture to support deep model training using mini-batches of\npositive-negative bag pairs. Finally, a novel P-F sampling function is\ndeveloped that combines a probability vector and predicted instance scores,\nobtained by optimizing the robust bag likelihood. By leveraging the key MIL\nassumption, the sampling function can explore the most challenging bags and\neffectively detect their positive instances for annotation, which significantly\nimproves the instance-level prediction. Experiments conducted over multiple\nreal-world datasets clearly demonstrate the state-of-the-art instance-level\nprediction achieved by the proposed model.",
    "descriptor": "\nComments: KDD2022\n",
    "authors": [
      "Hitesh Sapkota",
      "Qi Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05682"
  },
  {
    "id": "arXiv:2206.05683",
    "title": "APT-36K: A Large-scale Benchmark for Animal Pose Estimation and Tracking",
    "abstract": "Animal pose estimation and tracking (APT) is a fundamental task for detecting\nand tracking animal keypoints from a sequence of video frames. Previous\nanimal-related datasets focus either on animal tracking or single-frame animal\npose estimation, and never on both aspects. The lack of APT datasets hinders\nthe development and evaluation of video-based animal pose estimation and\ntracking methods, limiting real-world applications, e.g., understanding animal\nbehavior in wildlife conservation. To fill this gap, we make the first step and\npropose APT-36K, i.e., the first large-scale benchmark for animal pose\nestimation and tracking. Specifically, APT-36K consists of 2,400 video clips\ncollected and filtered from 30 animal species with 15 frames for each video,\nresulting in 36,000 frames in total. After manual annotation and careful\ndouble-check, high-quality keypoint and tracking annotations are provided for\nall the animal instances. Based on APT-36K, we benchmark several representative\nmodels on the following three tracks: (1) supervised animal pose estimation on\na single frame under intra- and inter-domain transfer learning settings, (2)\ninter-species domain generalization test for unseen animals, and (3) animal\npose estimation with animal tracking. Based on the experimental results, we\ngain some empirical insights and show that APT-36K provides a valuable animal\npose estimation and tracking benchmark, offering new challenges and\nopportunities for future research. The code and dataset will be made publicly\navailable at https://github.com/pandorgan/APT-36K.",
    "descriptor": "",
    "authors": [
      "Yuxiang Yang",
      "Junjie Yang",
      "Yufei Xu",
      "Jing Zhang",
      "Long Lan",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.05683"
  },
  {
    "id": "arXiv:2206.05684",
    "title": "Knowledge as Fruits of Ignorance: A global Free Energy Principle of our  way of thinking",
    "abstract": "In this second article, we show a simple use of the Ignorance as defined in\n\"Jaynes & Shannon's Constrained Ignorance and Surprise\". By giving an example\nabout the journey of a person, we believe to show some simple, obvious but\nmathematically encoded philosophical implications about how we could think,\nlearn and memorize. In this basic model we will separate how we learn from\nIgnorance, and how we anticipate the world using Bayes formula, both should\nhowever be more entangled to best reflect reality. In fact, as we have seen\nafter achieving this work, applying Ignorance on the system constituting a\nperson finally turns out to be the global approach of its local counterpart on\nsystems like neurons, cells and other complex probabilistic systems, described\nusing the free energy principle, a much more complex and detailed approach. The\naim of this article is therefore to show, as seen from a person, another aspect\nof the application of the free energy principle which represents the\nconstrained Shannon's entropy, and leads to Bayes'formula. We show that, using\nonly ignorance as a single quantity, and its minimization as the main process,\nwe can take into account his understandings, assertions, doubts and assumptions\nabout how he perceives the world, by describing them mathematically.",
    "descriptor": "\nComments: More about information theory applied to philosophy. However, as for the Free energy principle, the application of this is large and could be applied in any field requiring probabilities\n",
    "authors": [
      "Cailleteau Thomas"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Biological Physics (physics.bio-ph)",
      "History and Philosophy of Physics (physics.hist-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.05684"
  },
  {
    "id": "arXiv:2206.05687",
    "title": "DRNet: Decomposition and Reconstruction Network for Remote Physiological  Measurement",
    "abstract": "Remote photoplethysmography (rPPG) based physiological measurement has great\napplication values in affective computing, non-contact health monitoring,\ntelehealth monitoring, etc, which has become increasingly important especially\nduring the COVID-19 pandemic. Existing methods are generally divided into two\ngroups. The first focuses on mining the subtle blood volume pulse (BVP) signals\nfrom face videos, but seldom explicitly models the noises that dominate face\nvideo content. They are susceptible to the noises and may suffer from poor\ngeneralization ability in unseen scenarios. The second focuses on modeling\nnoisy data directly, resulting in suboptimal performance due to the lack of\nregularity of these severe random noises. In this paper, we propose a\nDecomposition and Reconstruction Network (DRNet) focusing on the modeling of\nphysiological features rather than noisy data. A novel cycle loss is proposed\nto constrain the periodicity of physiological information. Besides, a\nplug-and-play Spatial Attention Block (SAB) is proposed to enhance features\nalong with the spatial location information. Furthermore, an efficient Patch\nCropping (PC) augmentation strategy is proposed to synthesize augmented samples\nwith different noise and features. Extensive experiments on different public\ndatasets as well as the cross-database testing demonstrate the effectiveness of\nour approach.",
    "descriptor": "",
    "authors": [
      "Yuhang Dong",
      "Gongping Yang",
      "Yilong Yin"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.05687"
  },
  {
    "id": "arXiv:2206.05692",
    "title": "tBDFS: Temporal Graph Neural Network Leveraging DFS",
    "abstract": "Temporal graph neural networks (temporal GNNs) have been widely researched,\nreaching state-of-the-art results on multiple prediction tasks. A common\napproach employed by most previous works is to apply a layer that aggregates\ninformation from the historical neighbors of a node. Taking a different\nresearch direction, in this work, we propose tBDFS -- a novel temporal GNN\narchitecture. tBDFS applies a layer that efficiently aggregates information\nfrom temporal paths to a given (target) node in the graph. For each given node,\nthe aggregation is applied in two stages: (1) A single representation is\nlearned for each temporal path ending in that node, and (2) all path\nrepresentations are aggregated into a final node representation. Overall, our\ngoal is not to add new information to a node, but rather observe the same exact\ninformation in a new perspective. This allows our model to directly observe\npatterns that are path-oriented rather than neighborhood-oriented. This can be\nthought as a Depth-First Search (DFS) traversal over the temporal graph,\ncompared to the popular Breath-First Search (BFS) traversal that is applied in\nprevious works. We evaluate tBDFS over multiple link prediction tasks and show\nits favorable performance compared to state-of-the-art baselines. To the best\nof our knowledge, we are the first to apply a temporal-DFS neural network.",
    "descriptor": "\nComments: 9 pages, 2 figures, 2 tables\n",
    "authors": [
      "Uriel Singer",
      "Haggai Roitman",
      "Ido Guy",
      "Kira Radinsky"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05692"
  },
  {
    "id": "arXiv:2206.05694",
    "title": "RL-EA: A Reinforcement Learning-Based Evolutionary Algorithm Framework  for Electromagnetic Detection Satellite Scheduling Problem",
    "abstract": "The study of electromagnetic detection satellite scheduling problem (EDSSP)\nhas attracted attention due to the detection requirements for a large number of\ntargets. This paper proposes a mixed-integer programming model for the EDSSP\nproblem and an evolutionary algorithm framework based on reinforcement learning\n(RL-EA). Numerous factors that affect electromagnetic detection are considered\nin the model, such as detection mode, bandwidth, and other factors. The\nevolutionary algorithm framework based on reinforcement learning uses the\nQ-learning framework, and each individual in the population is regarded as an\nagent. Based on the proposed framework, a Q-learning-based genetic\nalgorithm(QGA) is designed. Q-learning is used to guide the population search\nprocess by choosing variation operators. In the algorithm, we design a reward\nfunction to update the Q value. According to the problem characteristics, a new\ncombination of <state, action> is proposed. The QGA also uses an elite\nindividual retention strategy to improve search performance. After that, a task\ntime window selection algorithm is proposed To evaluate the performance of\npopulation evolution. Various scales experiments are used to examine the\nplanning effect of the proposed algorithm. Through the experimental\nverification of multiple instances, it can be seen that the QGA can solve the\nEDSSP problem effectively. Compared with the state-of-the-art algorithms, the\nQGA algorithm performs better in several aspects.",
    "descriptor": "\nComments: 25 pages, 6 figures\n",
    "authors": [
      "Yanjie Song",
      "Luona Wei",
      "Qing Yang",
      "Jian Wu",
      "Lining Xing",
      "Yingwu Chen"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.05694"
  },
  {
    "id": "arXiv:2206.05696",
    "title": "Grounding in social media: An approach to building a chit-chat dialogue  model",
    "abstract": "Building open-domain dialogue systems capable of rich human-like\nconversational ability is one of the fundamental challenges in language\ngeneration. However, even with recent advancements in the field, existing\nopen-domain generative models fail to capture and utilize external knowledge,\nleading to repetitive or generic responses to unseen utterances. Current work\non knowledge-grounded dialogue generation primarily focuses on persona\nincorporation or searching a fact-based structured knowledge source such as\nWikipedia. Our method takes a broader and simpler approach, which aims to\nimprove the raw conversation ability of the system by mimicking the human\nresponse behavior through casual interactions found on social media. Utilizing\na joint retriever-generator setup, the model queries a large set of filtered\ncomment data from Reddit to act as additional context for the seq2seq\ngenerator. Automatic and human evaluations on open-domain dialogue datasets\ndemonstrate the effectiveness of our approach.",
    "descriptor": "\nComments: Accepted to NAACL 2022 SRW\n",
    "authors": [
      "Ritvik Choudhary",
      "Daisuke Kawahara"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.05696"
  },
  {
    "id": "arXiv:2206.05697",
    "title": "Scheduling Delays and Curtailment for Household Appliances with  Deterministic Load Profiles using MPC",
    "abstract": "Smart home appliances can time-shift and curtail their power demand to assist\ndemand side management or allow operation with limited power, as in an off-grid\napplication. This paper proposes a scheduling process to start appliances with\ntime-varying deterministic load profiles. Self-triggered model predictive\ncontrol is used to limit the household net power demand below a given\nthreshold. Meanwhile, deterministic load profiles are more difficult to\nschedule compared to variable charging or thermal loads because system failure\nwill occur once power demand is not satisfied. The proposed scheme formulates\nthe decision of the load shifting time as a continuous optimization problem,\nand an inhomogeneous time grid system is introduced to handle the optimization\nof different appliances and their consensus at this resolution. The efficacy of\nthe proposed scheme is studied by numerical comparison with a mixed-integer MPC\ncontroller and by a case study of three home appliances and an interruptible\nwashing machine.",
    "descriptor": "",
    "authors": [
      "Yingzhao Lian",
      "Yuning Jiang",
      "Colin N. Jones",
      "Daniel F. Opila"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.05697"
  },
  {
    "id": "arXiv:2206.05699",
    "title": "Quality-Driven Energy-Efficient Big Data Aggregation in WBANs",
    "abstract": "In the Internet-of-Things (IoT) era, the development of Wireless Body Area\nNetworks (WBANs) and their applications in big data infrastructure has gotten a\nlot of attention from the medical research community. Since sensor nodes are\nlow-powered devices that require heterogeneous Quality-of-Service (QoS),\nmanaging large amounts of medical data is critical in WBANs. Therefore,\neffectively aggregating a large volume of medical data is important. In this\ncontext, we propose a quality-driven and energy-efficient big data aggregation\napproach for cloud-assisted WBANs. For both intra-BAN (Phase I) and inter-BAN\n(Phase II) communications, the aggregation approach is cost-effective.\nExtensive simulation results show that the proposed approach DEBA greatly\nimproves network efficiency in terms of aggregation delay and cost as compared\nto existing schemes.",
    "descriptor": "",
    "authors": [
      "Amit Samanta",
      "Tri Gia Nguyen"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.05699"
  },
  {
    "id": "arXiv:2206.05700",
    "title": "A Functional Information Perspective on Model Interpretation",
    "abstract": "Contemporary predictive models are hard to interpret as their deep nets\nexploit numerous complex relations between input elements. This work suggests a\ntheoretical framework for model interpretability by measuring the contribution\nof relevant features to the functional entropy of the network with respect to\nthe input. We rely on the log-Sobolev inequality that bounds the functional\nentropy by the functional Fisher information with respect to the covariance of\nthe data. This provides a principled way to measure the amount of information\ncontribution of a subset of features to the decision function. Through\nextensive experiments, we show that our method surpasses existing\ninterpretability sampling-based methods on various data signals such as image,\ntext, and audio.",
    "descriptor": "\nComments: Accepted to ICML 2022\n",
    "authors": [
      "Itai Gat",
      "Nitay Calderon",
      "Roi Reichart",
      "Tamir Hazan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05700"
  },
  {
    "id": "arXiv:2206.05703",
    "title": "PAC-Net: A Model Pruning Approach to Inductive Transfer Learning",
    "abstract": "Inductive transfer learning aims to learn from a small amount of training\ndata for the target task by utilizing a pre-trained model from the source task.\nMost strategies that involve large-scale deep learning models adopt\ninitialization with the pre-trained model and fine-tuning for the target task.\nHowever, when using over-parameterized models, we can often prune the model\nwithout sacrificing the accuracy of the source task. This motivates us to adopt\nmodel pruning for transfer learning with deep learning models. In this paper,\nwe propose PAC-Net, a simple yet effective approach for transfer learning based\non pruning. PAC-Net consists of three steps: Prune, Allocate, and Calibrate\n(PAC). The main idea behind these steps is to identify essential weights for\nthe source task, fine-tune on the source task by updating the essential\nweights, and then calibrate on the target task by updating the remaining\nredundant weights. Under the various and extensive set of inductive transfer\nlearning experiments, we show that our method achieves state-of-the-art\nperformance by a large margin.",
    "descriptor": "\nComments: In Proceedings of the 39th International Conference on Machine Learning, Baltimore, Maryland, USA, PMLR 162, 2022\n",
    "authors": [
      "Sanghoon Myung",
      "In Huh",
      "Wonik Jang",
      "Jae Myung Choe",
      "Jisu Ryu",
      "Dae Sin Kim",
      "Kee-Eung Kim",
      "Changwook Jeong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Physics (physics.comp-ph)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.05703"
  },
  {
    "id": "arXiv:2206.05706",
    "title": "CoSe-Co: Text Conditioned Generative CommonSense Contextualizer",
    "abstract": "Pre-trained Language Models (PTLMs) have been shown to perform well on\nnatural language tasks. Many prior works have leveraged structured commonsense\npresent in the form of entities linked through labeled relations in Knowledge\nGraphs (KGs) to assist PTLMs. Retrieval approaches use KG as a separate static\nmodule which limits coverage since KGs contain finite knowledge. Generative\nmethods train PTLMs on KG triples to improve the scale at which knowledge can\nbe obtained. However, training on symbolic KG entities limits their\napplicability in tasks involving natural language text where they ignore\noverall context. To mitigate this, we propose a CommonSense Contextualizer\n(CoSe-Co) conditioned on sentences as input to make it generically usable in\ntasks for generating knowledge relevant to the overall context of input text.\nTo train CoSe-Co, we propose a novel dataset comprising of sentence and\ncommonsense knowledge pairs. The knowledge inferred by CoSe-Co is diverse and\ncontain novel entities not present in the underlying KG. We augment generated\nknowledge in Multi-Choice QA and Open-ended CommonSense Reasoning tasks leading\nto improvements over current best methods on CSQA, ARC, QASC and OBQA datasets.\nWe also demonstrate its applicability in improving performance of a baseline\nmodel for paraphrase generation task.",
    "descriptor": "\nComments: Accepted at NAACL 2022 (main conference)\n",
    "authors": [
      "Rachit Bansal",
      "Milan Aggarwal",
      "Sumit Bhatia",
      "Jivat Neet Kaur",
      "Balaji Krishnamurthy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.05706"
  },
  {
    "id": "arXiv:2206.05707",
    "title": "DPCN++: Differentiable Phase Correlation Network for Versatile Pose  Registration",
    "abstract": "Pose registration is critical in vision and robotics. This paper focuses on\nthe challenging task of initialization-free pose registration up to 7DoF for\nhomogeneous and heterogeneous measurements. While recent learning-based methods\nshow promise using differentiable solvers, they either rely on heuristically\ndefined correspondences or are prone to local minima. We present a\ndifferentiable phase correlation (DPC) solver that is globally convergent and\ncorrespondence-free. When combined with simple feature extraction networks, our\ngeneral framework DPCN++ allows for versatile pose registration with arbitrary\ninitialization. Specifically, the feature extraction networks first learn dense\nfeature grids from a pair of homogeneous/heterogeneous measurements. These\nfeature grids are then transformed into a translation and scale invariant\nspectrum representation based on Fourier transform and spherical radial\naggregation, decoupling translation and scale from rotation. Next, the\nrotation, scale, and translation are independently and efficiently estimated in\nthe spectrum step-by-step using the DPC solver. The entire pipeline is\ndifferentiable and trained end-to-end. We evaluate DCPN++ on a wide range of\nregistration tasks taking different input modalities, including 2D bird's-eye\nview images, 3D object and scene measurements, and medical images. Experimental\nresults demonstrate that DCPN++ outperforms both classical and learning-based\nbaselines, especially on partially observed and heterogeneous measurements.",
    "descriptor": "",
    "authors": [
      "Zexi Chen",
      "Yiyi Liao",
      "Haozhe Du",
      "Haodong Zhang",
      "Xuecheng Xu",
      "Haojian Lu",
      "Rong Xiong",
      "Yue Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.05707"
  },
  {
    "id": "arXiv:2206.05708",
    "title": "Narrowing the Gap: Improved Detector Training with Noisy Location  Annotations",
    "abstract": "Deep learning methods require massive of annotated data for optimizing\nparameters. For example, datasets attached with accurate bounding box\nannotations are essential for modern object detection tasks. However, labeling\nwith such pixel-wise accuracy is laborious and time-consuming, and elaborate\nlabeling procedures are indispensable for reducing man-made noise, involving\nannotation review and acceptance testing. In this paper, we focus on the impact\nof noisy location annotations on the performance of object detection approaches\nand aim to, on the user side, reduce the adverse effect of the noise. First,\nnoticeable performance degradation is experimentally observed for both\none-stage and two-stage detectors when noise is introduced to the bounding box\nannotations. For instance, our synthesized noise results in performance\ndecrease from 38.9% AP to 33.6% AP for FCOS detector on COCO test split, and\n37.8%AP to 33.7%AP for Faster R-CNN. Second, a self-correction technique based\non a Bayesian filter for prediction ensemble is proposed to better exploit the\nnoisy location annotations following a Teacher-Student learning paradigm.\nExperiments for both synthesized and real-world scenarios consistently\ndemonstrate the effectiveness of our approach, e.g., our method increases the\ndegraded performance of the FCOS detector from 33.6% AP to 35.6% AP on COCO.",
    "descriptor": "",
    "authors": [
      "Shaoru Wang",
      "Jin Gao",
      "Bing Li",
      "Weiming Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.05708"
  },
  {
    "id": "arXiv:2206.05710",
    "title": "Age of Information: A Two-Sensor Status Update System Monitoring The  Same Process",
    "abstract": "This work studies the average age of information (AoI) of a monitoring system\nin which two sensors are sensing the same physical process and update status to\na common monitor using their dedicated channels. Generally, using redundant\ndevices to update the status of a process can improve the information\ntimeliness at the monitor, but the disordered arrivals of updates also make the\nAoI analysis challenging. To that end, we model the system as two M/M/1/1\nparallel status updating queues. By leveraging tools from stochastic hybrid\nsystem (SHS), we provide a general approach to analyze the average AoI, whereas\na closed-form expression can be obtained when the status arrival rates and/or\nthe service rates are the same for the two sensors. Numerical results validate\nthe correctness of the theoretical analysis.",
    "descriptor": "",
    "authors": [
      "Tianqing Yang",
      "Zhengchuan Chen",
      "Howard H. Yang",
      "Min Wang",
      "Yunjian Jia",
      "Tony Q. S. Quek"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.05710"
  },
  {
    "id": "arXiv:2206.05712",
    "title": "Graph-based Spatial Transformer with Memory Replay for Multi-future  Pedestrian Trajectory Prediction",
    "abstract": "Pedestrian trajectory prediction is an essential and challenging task for a\nvariety of real-life applications such as autonomous driving and robotic motion\nplanning. Besides generating a single future path, predicting multiple\nplausible future paths is becoming popular in some recent work on trajectory\nprediction. However, existing methods typically emphasize spatial interactions\nbetween pedestrians and surrounding areas but ignore the smoothness and\ntemporal consistency of predictions. Our model aims to forecast multiple paths\nbased on a historical trajectory by modeling multi-scale graph-based spatial\ntransformers combined with a trajectory smoothing algorithm named ``Memory\nReplay'' utilizing a memory graph. Our method can comprehensively exploit the\nspatial information as well as correct the temporally inconsistent trajectories\n(e.g., sharp turns). We also propose a new evaluation metric named ``Percentage\nof Trajectory Usage'' to evaluate the comprehensiveness of diverse multi-future\npredictions. Our extensive experiments show that the proposed model achieves\nstate-of-the-art performance on multi-future prediction and competitive results\nfor single-future prediction. Code released at\nhttps://github.com/Jacobieee/ST-MR.",
    "descriptor": "\nComments: This paper has been accepted by CVPR 2022. Reference: Li, L., Pagnucco, M. and Song, Y., 2022. Graph-Based Spatial Transformer With Memory Replay for Multi-Future Pedestrian Trajectory Prediction. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 2231-2241)\n",
    "authors": [
      "Lihuan Li",
      "Maurice Pagnucco",
      "Yang Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.05712"
  },
  {
    "id": "arXiv:2206.05713",
    "title": "Federated Graph Attention Network for Rumor Detection",
    "abstract": "With the development of network technology, many social media are\nflourishing. Due to imperfect Internet regulation, the spread of false rumors\nhas become a common problem on those social platforms. Social platforms can\ngenerate rumor data in their operation process, but existing rumor detection\nmodels are all constructed for a single social platform, which ignores the\nvalue of cross-platform rumor. This paper combines the federated learning\nparadigm with the bidirectional graph attention network rumor detection model\nand proposes the federated graph attention network(FedGAT) model for rumor\ndetection. Taking the advantages of horizontal federated learning for\ncross-platform rumor detection, the security of each social platform's data\ninformation can be ensured. We construct both the server-side and client-side\nmodels as a bidirectional graph attention network rumor detection model in the\nfederated learning paradigm framework. The local model on the client-side can\ntrain and verify the rumor data of the social platform in the iterative\nprocess, while the model on the server-side only plays the role of aggregating\nthe characteristics of different social platform models and does not\nparticipate in the training of the model. Finally, we conduct simulation\nexperiments on the rumor datasets and the experimental results show that the\nfederated graph attention network model proposed in this paper is effective for\ncross-platform rumor detection.",
    "descriptor": "\nComments: 19 pages, 5 figures\n",
    "authors": [
      "Huidong Wang",
      "Chuanzheng Bai",
      "Jinli Yao"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.05713"
  },
  {
    "id": "arXiv:2206.05714",
    "title": "Integrating High-Resolution Tactile Sensing into Grasp Stability  Prediction",
    "abstract": "We investigate how high-resolution tactile sensors can be utilized in\ncombination with vision and depth sensing, to improve grasp stability\nprediction. Recent advances in simulating high-resolution tactile sensing, in\nparticular the TACTO simulator, enabled us to evaluate how neural networks can\nbe trained with a combination of sensing modalities. With the large amounts of\ndata needed to train large neural networks, robotic simulators provide a fast\nway to automate the data collection process. We expand on the existing work\nthrough an ablation study and an increased set of objects taken from the YCB\nbenchmark set. Our results indicate that while the combination of vision,\ndepth, and tactile sensing provides the best prediction results on known\nobjects, the network fails to generalize to unknown objects. Our work also\naddresses existing issues with robotic grasping in tactile simulation and how\nto overcome them.",
    "descriptor": "\nComments: 8 pages, 6 figures\n",
    "authors": [
      "Lachlan Chumbley",
      "Morris Gu",
      "Rhys Newbury",
      "Jurgen Leitner",
      "Akansel Cosgun"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.05714"
  },
  {
    "id": "arXiv:2206.05716",
    "title": "Divergences on Monads for Relational Program Logics",
    "abstract": "Several relational program logics have been introduced for integrating\nreasoning about relational properties of programs and measurement of\nquantitative difference between computational effects. Towards a general\nframework for such logics, in this paper, we formalize quantitative difference\nbetween computational effects as divergence on monad, then develop a relational\nprogram logic acRL that supports generic computational effects and divergences\non them. To give a categorical semantics of acRL supporting divergences, we\ngive a method to obtain graded strong relational liftings from divergences on\nmonads. We derive two instantiations of acRL for the verification of 1) various\ndifferential privacy of higher-order functional probabilistic programs and 2)\ndifference of distribution of costs between higher-order functional programs\nwith probabilistic choice and cost counting operations.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Tetsuya Sato",
      "Shin-ya Katsumata"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2206.05716"
  },
  {
    "id": "arXiv:2206.05717",
    "title": "Crowd Localization from Gaussian Mixture Scoped Knowledge and Scoped  Teacher",
    "abstract": "Crowd localization is to predict each instance head position in crowd\nscenarios. Since the distance of instances being to the camera are variant,\nthere exists tremendous gaps among scales of instances within an image, which\nis called the intrinsic scale shift. The core reason of intrinsic scale shift\nbeing one of the most essential issues in crowd localization is that it is\nubiquitous in crowd scenes and makes scale distribution chaotic.\nTo this end, the paper concentrates on access to tackle the chaos of the\nscale distribution incurred by intrinsic scale shift. We propose Gaussian\nMixture Scope (GMS) to regularize the chaotic scale distribution. Concretely,\nthe GMS utilizes a Gaussian mixture distribution to adapt to scale distribution\nand decouples the mixture model into sub-normal distributions to regularize the\nchaos within the sub-distributions. Then, an alignment is introduced to\nregularize the chaos among sub-distributions. However, despite that GMS is\neffective in regularizing the data distribution, it amounts to dislodging the\nhard samples in training set, which incurs overfitting. We assert that it is\nblamed on the block of transferring the latent knowledge exploited by GMS from\ndata to model. Therefore, a Scoped Teacher playing a role of bridge in\nknowledge transform is proposed. What' s more, the consistency regularization\nis also introduced to implement knowledge transform. To that effect, the\nfurther constraints are deployed on Scoped Teacher to derive feature\nconsistence between teacher and student end.\nWith proposed GMS and Scoped Teacher implemented on five mainstream datasets\nof crowd localization, the extensive experiments demonstrate the superiority of\nour work. Moreover, comparing with existing crowd locators, our work achieves\nstate-of-the-art via F1-meansure comprehensively on five datasets.",
    "descriptor": "",
    "authors": [
      "Juncheng Wang",
      "Junyu Gao",
      "Yuan Yuan",
      "Qi Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.05717"
  },
  {
    "id": "arXiv:2206.05723",
    "title": "Communication-Efficient Federated Learning over MIMO Multiple Access  Channels",
    "abstract": "Communication efficiency is of importance for wireless federated learning\nsystems. In this paper, we propose a communication-efficient strategy for\nfederated learning over multiple-input multiple-output (MIMO) multiple access\nchannels (MACs). The proposed strategy comprises two components. When sending a\nlocally computed gradient, each device compresses a high dimensional local\ngradient to multiple lower-dimensional gradient vectors using block\nsparsification. When receiving a superposition of the compressed local\ngradients via a MIMO-MAC, a parameter server (PS) performs a joint MIMO\ndetection and the sparse local-gradient recovery. Inspired by the turbo\ndecoding principle, our joint detection-and-recovery algorithm accurately\nrecovers the high-dimensional local gradients by iteratively exchanging their\nbeliefs for MIMO detection and sparse local gradient recovery outputs. We then\nanalyze the reconstruction error of the proposed algorithm and its impact on\nthe convergence rate of federated learning. From simulations, our gradient\ncompression and joint detection-and-recovery methods diminish the communication\ncost significantly while achieving identical classification accuracy for the\ncase without any compression.",
    "descriptor": "",
    "authors": [
      "Yo-Seb Jeon",
      "Mohammad Mohammadi Amiri",
      "Namyoon Lee"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.05723"
  },
  {
    "id": "arXiv:2206.05728",
    "title": "Arena-Bench: A Benchmarking Suite for Obstacle Avoidance Approaches in  Highly Dynamic Environments",
    "abstract": "The ability to autonomously navigate safely, especially within dynamic\nenvironments, is paramount for mobile robotics. In recent years, DRL approaches\nhave shown superior performance in dynamic obstacle avoidance. However, these\nlearning-based approaches are often developed in specially designed simulation\nenvironments and are hard to test against conventional planning approaches.\nFurthermore, the integration and deployment of these approaches into real\nrobotic platforms are not yet completely solved. In this paper, we present\nArena-bench, a benchmark suite to train, test, and evaluate navigation planners\non different robotic platforms within 3D environments. It provides tools to\ndesign and generate highly dynamic evaluation worlds, scenarios, and tasks for\nautonomous navigation and is fully integrated into the robot operating system.\nTo demonstrate the functionalities of our suite, we trained a DRL agent on our\nplatform and compared it against a variety of existing different model-based\nand learning-based navigation approaches on a variety of relevant metrics.\nFinally, we deployed the approaches towards real robots and demonstrated the\nreproducibility of the results. The code is publicly available at\ngithub.com/ignc-research/arena-bench.",
    "descriptor": "\nComments: Accepted for publication in Robotics and Automation Letters (RA-L), 2022, 8 pages, 6 figures\n",
    "authors": [
      "Linh K\u00e4stner",
      "Teham Bhuiyan",
      "Tuan Anh Le",
      "Elias Treis",
      "Johannes Cox",
      "Boris Meinardus",
      "Jacek Kmiecik",
      "Reyk Carstens",
      "Duc Pichel",
      "Bassel Fatloun",
      "Niloufar Khorsandi",
      "Jens Lambrecht"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.05728"
  },
  {
    "id": "arXiv:2206.05730",
    "title": "Object Occlusion Of Adding New Category In Objection Detection",
    "abstract": "Building instance detection models that are data efficient and can handle\nrare object categories is an important challenge in computer vision. But data\ncollection methods and metrics are lack of research towards real scenarios\napplication using neural network. Here, we perform a systematic study of the\nObject Occlusion data collection and augmentation methods where we imitate\nobject occlusion relationship in target scenarios. However, we find that the\nsimple mechanism of object occlusion is good enough and can provide acceptable\naccuracy in real scenarios adding new category. We illustate that only adding\n15 images of new category in a half million training dataset with hundreds\ncategories, can give this new category 95% accuracy in unseen test dataset\nincluding thousands of images of this category.",
    "descriptor": "",
    "authors": [
      "Boyang Deng",
      "Meiyan Lin",
      "Shoulun Long"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.05730"
  },
  {
    "id": "arXiv:2206.05731",
    "title": "Human Mobility Prediction with Causal and Spatial-constrained Multi-task  Network",
    "abstract": "Modeling human mobility helps to understand how people are accessing\nresources and physically contacting with each other in cities, and thus\ncontributes to various applications such as urban planning, epidemic control,\nand location-based advertisement. Next location prediction is one decisive task\nin individual human mobility modeling and is usually viewed as sequence\nmodeling, solved with Markov or RNN-based methods. However, the existing models\npaid little attention to the logic of individual travel decisions and the\nreproducibility of the collective behavior of population. To this end, we\npropose a Causal and Spatial-constrained Long and Short-term Learner (CSLSL)\nfor next location prediction. CSLSL utilizes a causal structure based on\nmulti-task learning to explicitly model the\n\"when$\\rightarrow$what$\\rightarrow$where\", a.k.a.\n\"time$\\rightarrow$activity$\\rightarrow$location\" decision logic. We next\npropose a spatial-constrained loss function as an auxiliary task, to ensure the\nconsistency between the predicted and actual spatial distribution of travelers'\ndestinations. Moreover, CSLSL adopts modules named Long and Short-term Capturer\n(LSC) to learn the transition regularities across different time spans.\nExtensive experiments on three real-world datasets show a 33.4% performance\nimprovement of CSLSL over baselines and confirm the effectiveness of\nintroducing the causality and consistency constraints. The implementation is\navailable at https://github.com/urbanmobility/CSLSL.",
    "descriptor": "\nComments: Accepted by KDD2022, the Research Track\n",
    "authors": [
      "Zongyuan Huang",
      "Shengyuan Xu",
      "Menghan Wang",
      "Hansi Wu",
      "Yanyan Xu",
      "Yaohui Jin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.05731"
  },
  {
    "id": "arXiv:2206.05733",
    "title": "Finite-Time Analysis of Fully Decentralized Single-Timescale  Actor-Critic",
    "abstract": "Decentralized Actor-Critic (AC) algorithms have been widely utilized for\nmulti-agent reinforcement learning (MARL) and have achieved remarkable success.\nApart from its empirical success, the theoretical convergence property of\ndecentralized AC algorithms is largely unexplored. The existing finite-time\nconvergence results are derived based on either double-loop update or\ntwo-timescale step sizes rule, which is not often adopted in real\nimplementation. In this work, we introduce a fully decentralized AC algorithm,\nwhere actor, critic, and global reward estimator are updated in an alternating\nmanner with step sizes being of the same order, namely, we adopt the\n\\emph{single-timescale} update. Theoretically, using linear approximation for\nvalue and reward estimation, we show that our algorithm has sample complexity\nof $\\tilde{\\mathcal{O}}(\\epsilon^{-2})$ under Markovian sampling, which matches\nthe optimal complexity with double-loop implementation (here,\n$\\tilde{\\mathcal{O}}$ hides a log term). The sample complexity can be improved\nto ${\\mathcal{O}}(\\epsilon^{-2})$ under the i.i.d. sampling scheme. The central\nto establishing our complexity results is \\emph{the hidden smoothness of the\noptimal critic variable} we revealed. We also provide a local action\nprivacy-preserving version of our algorithm and its analysis. Finally, we\nconduct experiments to show the superiority of our algorithm over the existing\ndecentralized AC algorithms.",
    "descriptor": "",
    "authors": [
      "Qijun Luo",
      "Xiao Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.05733"
  },
  {
    "id": "arXiv:2206.05735",
    "title": "Fusing Feature Engineering and Deep Learning: A Case Study for Malware  Classification",
    "abstract": "Machine learning has become an appealing signature-less approach to detect\nand classify malware because of its ability to generalize to never-before-seen\nsamples and to handle large volumes of data. While traditional feature-based\napproaches rely on the manual design of hand-crafted features based on experts\nknowledge of the domain, deep learning approaches replace the manual feature\nengineering process by an underlying system, typically consisting of a neural\nnetwork with multiple layers, that perform both feature learning and\nclassification altogether. However, the combination of both approaches could\nsubstantially enhance detection systems. In this paper we present an hybrid\napproach to address the task of malware classification by fusing multiple types\nof features defined by experts and features learned through deep learning from\nraw data. In particular, our approach relies on deep learning to extract N-gram\nlike features from the assembly language instructions and the bytes of malware,\nand texture patterns and shapelet-based features from malware\\'s grayscale\nimage representation and structural entropy, respectively. These deep features\nare later passed as input to a gradient boosting model that combines the deep\nfeatures and the hand-crafted features using an early-fusion mechanism. The\nsuitability of our approach has been evaluated on the Microsoft Malware\nClassification Challenge benchmark and results show that the proposed solution\nachieves state-of-the-art performance and outperforms gradient boosting and\ndeep learning methods in the literature.",
    "descriptor": "",
    "authors": [
      "Daniel Gibert",
      "Carles Mateu",
      "Jordi Planes",
      "Quan Le"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.05735"
  },
  {
    "id": "arXiv:2206.05737",
    "title": "SparseNeuS: Fast Generalizable Neural Surface Reconstruction from Sparse  views",
    "abstract": "We introduce SparseNeuS, a novel neural rendering based method for the task\nof surface reconstruction from multi-view images. This task becomes more\ndifficult when only sparse images are provided as input, a scenario where\nexisting neural reconstruction approaches usually produce incomplete or\ndistorted results. Moreover, their inability of generalizing to unseen new\nscenes impedes their application in practice. Contrarily, SparseNeuS can\ngeneralize to new scenes and work well with sparse images (as few as 2 or 3).\nSparseNeuS adopts signed distance function (SDF) as the surface representation,\nand learns generalizable priors from image features by introducing geometry\nencoding volumes for generic surface prediction. Moreover, several strategies\nare introduced to effectively leverage sparse views for high-quality\nreconstruction, including 1) a multi-level geometry reasoning framework to\nrecover the surfaces in a coarse-to-fine manner; 2) a multi-scale color\nblending scheme for more reliable color prediction; 3) a consistency-aware\nfine-tuning scheme to control the inconsistent regions caused by occlusion and\nnoise. Extensive experiments demonstrate that our approach not only outperforms\nthe state-of-the-art methods, but also exhibits good efficiency,\ngeneralizability, and flexibility.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Xiaoxiao Long",
      "Cheng Lin",
      "Peng Wang",
      "Taku Komura",
      "Wenping Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.05737"
  },
  {
    "id": "arXiv:2206.05741",
    "title": "Multimodal Fake News Detection with Adaptive Unimodal Representation  Aggregation",
    "abstract": "The development of Internet technology has continuously intensified the\nspread and destructive power of rumors and fake news. Previous researches on\nmultimedia fake news detection include a series of complex feature extraction\nand fusion networks to achieve feature alignment between images and texts.\nHowever, what the multimodal features are composed of and how features from\ndifferent modalities affect the decision-making process are still open\nquestions. We present AURA, a multimodal fake news detection network with\nAdaptive Unimodal Representation Aggregation. We first extract representations\nrespectively from image pattern, image semantics and text, and multimodal\nrepresentations are generated by sending the semantic and linguistic\nrepresentations into an expert network. Then, we perform coarse-level fake news\ndetection and cross-modal cosistency learning according to the unimodal and\nmultimodal representations. The classification and consistency scores are\nmapped into modality-aware attention scores that readjust the features.\nFinally, we aggregation and classify the weighted features for refined fake\nnews detection. Comprehensive experiments on Weibo and Gossipcop prove that\nAURA can successfully beat several state-of-the-art FND schemes, where the\noverall prediction accuracy and the recall of fake news is steadily improved.",
    "descriptor": "\nComments: Submitted to MMSP 2022. Authors are from Fudan University, Shanghai University and Chinese Academy of Sciences\n",
    "authors": [
      "Qichao Ying",
      "Yangming Zhou",
      "Zhenxing Qian",
      "Dan Zeng",
      "Shiming Ge"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.05741"
  },
  {
    "id": "arXiv:2206.05743",
    "title": "Evolutionary Multi-Task Injection Testing on Web Application Firewalls",
    "abstract": "Web application firewall (WAF) plays an integral role nowadays to protect web\napplications from various malicious injection attacks such as SQL injection,\nXML injection, and PHP injection, to name a few. However, given the evolving\nsophistication of injection attacks and the increasing complexity of tuning a\nWAF, it is challenging to ensure that the WAF is free of injection\nvulnerabilities such that it will block all malicious injection attacks without\nwrongly affecting the legitimate message. Automatically testing the WAF is,\ntherefore, a timely and essential task. In this paper, we propose DaNuoYi, an\nautomatic injection testing tool that simultaneously generates test inputs for\nmultiple types of injection attacks on a WAF. Our basic idea derives from the\ncross-lingual translation in the natural language processing domain. In\nparticular, test inputs for different types of injection attacks are\nsyntactically different but may be semantically similar. Sharing semantic\nknowledge across multiple programming languages can thus stimulate the\ngeneration of more sophisticated test inputs and discovering injection\nvulnerabilities of the WAF that are otherwise difficult to find. To this end,\nin DaNuoYi, we train several injection translation models by using multi-task\nlearning that translates the test inputs between any pair of injection attacks.\nThe model is then used by a novel multi-task evolutionary algorithm to\nco-evolve test inputs for different types of injection attacks facilitated by a\nshared mating pool and domain-specific mutation operators at each generation.\nWe conduct experiments on three real-world open-source WAFs and six types of\ninjection attacks, the results reveal that DaNuoYi generates up to 3.8x and\n5.78x more valid test inputs (i.e., bypassing the underlying WAF) than its\nstate-of-the-art single-task counterparts and the context-free grammar-based\ninjection construction.",
    "descriptor": "",
    "authors": [
      "Ke Li",
      "Heng Yang",
      "Willem Visser"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.05743"
  },
  {
    "id": "arXiv:2206.05747",
    "title": "Learning to Detect with Constant False Alarm Rate",
    "abstract": "We consider the use of machine learning for hypothesis testing with an\nemphasis on target detection. Classical model-based solutions rely on comparing\nlikelihoods. These are sensitive to imperfect models and are often\ncomputationally expensive. In contrast, data-driven machine learning is often\nmore robust and yields classifiers with fixed computational complexity. Learned\ndetectors usually provide high accuracy with low complexity but do not have a\nconstant false alarm rate (CFAR) as required in many applications. To close\nthis gap, we propose to add a term to the loss function that promotes similar\ndistributions of the detector under any null hypothesis scenario. Experiments\nshow that our approach leads to near CFAR detectors with similar accuracy as\ntheir competitors.",
    "descriptor": "",
    "authors": [
      "Tzvi Diskin",
      "Uri Okun",
      "Ami Wiesel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.05747"
  },
  {
    "id": "arXiv:2206.05749",
    "title": "Regularization Penalty Optimization for Addressing Data Quality Variance  in OoD Algorithms",
    "abstract": "Due to the poor generalization performance of traditional empirical risk\nminimization (ERM) in the case of distributional shift, Out-of-Distribution\n(OoD) generalization algorithms receive increasing attention. However, OoD\ngeneralization algorithms overlook the great variance in the quality of\ntraining data, which significantly compromises the accuracy of these methods.\nIn this paper, we theoretically reveal the relationship between training data\nquality and algorithm performance and analyze the optimal regularization scheme\nfor Lipschitz regularized invariant risk minimization. A novel algorithm is\nproposed based on the theoretical results to alleviate the influence of\nlow-quality data at both the sample level and the domain level. The experiments\non both the regression and classification benchmarks validate the effectiveness\nof our method with statistical significance.",
    "descriptor": "",
    "authors": [
      "Runpeng Yu",
      "Hong Zhu",
      "Kaican Li",
      "Lanqing Hong",
      "Rui Zhang",
      "Nanyang Ye",
      "Shao-Lun Huang",
      "Xiuqiang He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05749"
  },
  {
    "id": "arXiv:2206.05750",
    "title": "Matching options to tasks using Option-Indexed Hierarchical  Reinforcement Learning",
    "abstract": "The options framework in Hierarchical Reinforcement Learning breaks down\noverall goals into a combination of options or simpler tasks and associated\npolicies, allowing for abstraction in the action space. Ideally, these options\ncan be reused across different higher-level goals; indeed, such reuse is\nnecessary to realize the vision of a continual learning agent that can\neffectively leverage its prior experience. Previous approaches have only\nproposed limited forms of transfer of prelearned options to new task settings.\nWe propose a novel option indexing approach to hierarchical learning (OI-HRL),\nwhere we learn an affinity function between options and the items present in\nthe environment. This allows us to effectively reuse a large library of\npretrained options, in zero-shot generalization at test time, by restricting\ngoal-directed learning to only those options relevant to the task at hand. We\ndevelop a meta-training loop that learns the representations of options and\nenvironments over a series of HRL problems, by incorporating feedback about the\nrelevance of retrieved options to the higher-level goal. We evaluate OI-HRL in\ntwo simulated settings - the CraftWorld and AI2THOR environments - and show\nthat we achieve performance competitive with oracular baselines, and\nsubstantial gains over a baseline that has the entire option pool available for\nlearning the hierarchical policy.",
    "descriptor": "\nComments: 10 pages, 4 figures\n",
    "authors": [
      "Kushal Chauhan",
      "Soumya Chatterjee",
      "Akash Reddy",
      "Balaraman Ravindran",
      "Pradeep Shenoy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05750"
  },
  {
    "id": "arXiv:2206.05751",
    "title": "Consistent Attack: Universal Adversarial Perturbation on Embodied Vision  Navigation",
    "abstract": "Embodied agents in vision navigation coupled with deep neural networks have\nattracted increasing attention. However, deep neural networks are vulnerable to\nmalicious adversarial noises, which may potentially cause catastrophic failures\nin Embodied Vision Navigation. Among these adversarial noises, universal\nadversarial perturbations (UAP), i.e., the image-agnostic perturbation applied\non each frame received by the agent, are more critical for Embodied Vision\nNavigation since they are computation-efficient and application-practical\nduring the attack. However, existing UAP methods do not consider the system\ndynamics of Embodied Vision Navigation. For extending UAP in the sequential\ndecision setting, we formulate the disturbed environment under the universal\nnoise $\\delta$, as a $\\delta$-disturbed Markov Decision Process ($\\delta$-MDP).\nBased on the formulation, we analyze the properties of $\\delta$-MDP and propose\ntwo novel Consistent Attack methods for attacking Embodied agents, which first\nconsider the dynamic of the MDP by estimating the disturbed Q function and the\ndisturbed distribution. In spite of victim models, our Consistent Attack can\ncause a significant drop in the performance for the Goalpoint task in habitat.\nExtensive experimental results indicate that there exist potential risks for\napplying Embodied Vision Navigation methods to the real world.",
    "descriptor": "",
    "authors": [
      "You Qiaoben",
      "Chengyang Ying",
      "Xinning Zhou",
      "Hang Su",
      "Jun Zhu",
      "Bo Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.05751"
  },
  {
    "id": "arXiv:2206.05753",
    "title": "Concurrent Learning Based Adaptive Control of Euler Lagrange Systems  with Guaranteed Parameter Convergence",
    "abstract": "This work presents a solution to the adaptive tracking control of Euler\nLagrange systems with guaranteed tracking and parameter estimation error\nconvergence. Specifically a concurrent learning based update rule fused by the\nfiltered version of the desired system dynamics in conjunction with a desired\nstate based regression matrix has been utilized to ensure that both the\nposition tracking error and parameter estimation error terms converge to origin\nexponentially. As the regression matrix used in proposed controller makes use\nof the desired versions of the system states, an initial, sufficiently exciting\nmemory stack can be formed from the knowledge of the desired system trajectory\na priori, thus removing the initial excitation condition required for the\npreviously proposed concurrent learning based controllers in the literature.\nThe output feedback versions of the proposed method where only the position\nmeasurements are available for the controller design, (for both gradient and\ncomposite type adaptions) are also presented in order to illustrate the\nmodularity of the proposed method. The stability and boundedness of the closed\nloop signals for all the proposed controllers are ensured via Lyapunov based\nanalysis. %Trajectory tracking control of a class of fully actuated Euler\nLagrange systems is considered in this work. System dynamics is considered to\nbe subject to parametric uncertainties and on--line identification uncertain\nmodel parameters is also aimed. When compared with the relevant past research,\nvia a novel approach, desired states are proposed to be used in forming the\nregression matrix and a desired compensation based concurrent learning type\nadaptive update rule is designed. Via utilizing novel Lyapunov analysis,\nsemi--global exponential convergence of both tracking and parameter\nidentification error to the origin is ensured.",
    "descriptor": "\nComments: no figures\n",
    "authors": [
      "Erkan Zergeroglu",
      "Enver Tatlicioglu",
      "Serhat Obuz"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.05753"
  },
  {
    "id": "arXiv:2206.05759",
    "title": "Pliable Private Information Retrieval",
    "abstract": "We formulate a new variant of the private information retrieval (PIR) problem\nwhere the user is pliable, i.e., interested in any message from a desired\nsubset of the available dataset, denoted as pliable private information\nretrieval (PPIR). We consider a setup where a dataset consisting of $f$\nmessages is replicated in $n$ noncolluding databases and classified into\n$\\Gamma$ classes. For this setup, the user wishes to retrieve any $\\lambda\\geq\n1$ messages from multiple desired classes, i.e., $\\eta\\geq 1$, while revealing\nno information about the identity of the desired classes to the databases. We\nterm this problem multi-message PPIR (M-PPIR) and introduce the single-message\nPPIR (PPIR) problem as an elementary special case of M-PPIR. We first derive\nconverse bounds on the M-PPIR rate, which is defined as the ratio of the\ndesired amount of information and the total amount of downloaded information,\nfollowed by the corresponding achievable schemes. As a result, we show that the\nPPIR capacity, i.e., the maximum achievable PPIR rate, for $n$ noncolluding\ndatabases matches the capacity of PIR with $n$ databases and $\\Gamma$ messages.\nThus, enabling flexibility, i.e., pliability, where privacy is only guaranteed\nfor classes, but not for messages as in classical PIR, allows to trade-off\nprivacy versus download rate. A similar insight is shown to hold for the\ngeneral case of M-PPIR.",
    "descriptor": "\nComments: 23 pages, 3 figures, 3 tables, submitted for possible publication\n",
    "authors": [
      "Sarah A. Obead",
      "J\u00f6rg Kliewer"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.05759"
  },
  {
    "id": "arXiv:2206.05761",
    "title": "Fully GPU resident wavelet-based adaptive gridding: application to  two-dimensional finite volume hydrodynamic modelling",
    "abstract": "First order finite volume (FV1) models that use uniform grids are often used\nin computational engineering, but may become prohibitively costly to run on a\nfine resolution and/or large areas. To reduce these costs, FV1 models have\nadopted adaptive gridding or parallelisation on graphics processing units\n(GPU). FV1 models that combine adaptive gridding and parallelisation usually\ngenerate the adaptive grid on the central processing unit (CPU), yielding extra\ncosts for data transfer between the CPU and the GPU. This paper presents a\ncomputational innovation that avoids these costs by enabling GPU resident\nadaptive gridding, based on the multiresolution analysis (MRA) of Haar wavelets\n(HWs). It combines the indexing of Z order curves, to ensure coalesced access\nof GPU memory, and a newly adopted Parallel Tree Traversal (PTT) that minimises\nwarp divergence of GPU threads. The resulting GPU resident adaptive gridding\nmethod is presented as part of a parallelised, HWFV1 hydrodynamic model\n(GPU-HWFV1). The model's runtime performance is benchmarked against its CPU\npredecessor (CPU-HWFV1) and a GPU-FV1 uniform grid model for a range of test\ncases ran on the finest resolution grid accessible to the HWFV1 models. Tests\ndemonstrate the robustness of the results. As for runtime performance,\nGPU-HWFV1 is up to 400x faster than CPU-HWFV1, while remaining 30x faster than\nGPU-FV1 especially in applications that require increased depth in the grid\nresolution and high sensitivity to resolution refinement. The findings are\nsignificant, making a strong case for applying the proposed GPU resident\nadaptive gridding method to further speed-up FV1 models.",
    "descriptor": "\nComments: 32 pages\n",
    "authors": [
      "Alovya Ahmed Chowdhury",
      "Georges Kesserwani",
      "Charles Roug\u00e9",
      "Paul Richmond"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2206.05761"
  },
  {
    "id": "arXiv:2206.05763",
    "title": "SeATrans: Learning Segmentation-Assisted diagnosis model via Transforme",
    "abstract": "Clinically, the accurate annotation of lesions/tissues can significantly\nfacilitate the disease diagnosis. For example, the segmentation of optic\ndisc/cup (OD/OC) on fundus image would facilitate the glaucoma diagnosis, the\nsegmentation of skin lesions on dermoscopic images is helpful to the melanoma\ndiagnosis, etc. With the advancement of deep learning techniques, a wide range\nof methods proved the lesions/tissues segmentation can also facilitate the\nautomated disease diagnosis models. However, existing methods are limited in\nthe sense that they can only capture static regional correlations in the\nimages. Inspired by the global and dynamic nature of Vision Transformer, in\nthis paper, we propose Segmentation-Assisted diagnosis Transformer (SeATrans)\nto transfer the segmentation knowledge to the disease diagnosis network.\nSpecifically, we first propose an asymmetric multi-scale interaction strategy\nto correlate each single low-level diagnosis feature with multi-scale\nsegmentation features. Then, an effective strategy called SeA-block is adopted\nto vitalize diagnosis feature via correlated segmentation features. To model\nthe segmentation-diagnosis interaction, SeA-block first embeds the diagnosis\nfeature based on the segmentation information via the encoder, and then\ntransfers the embedding back to the diagnosis feature space by a decoder.\nExperimental results demonstrate that SeATrans surpasses a wide range of\nstate-of-the-art (SOTA) segmentation-assisted diagnosis methods on several\ndisease diagnosis tasks.",
    "descriptor": "",
    "authors": [
      "Junde Wu",
      "Huihui Fang",
      "Fangxin Shang",
      "Dalu Yang",
      "Zhaowei Wang",
      "Jing Gao",
      "Yehui Yang",
      "Yanwu Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.05763"
  },
  {
    "id": "arXiv:2206.05764",
    "title": "Mining Multi-Label Samples from Single Positive Labels",
    "abstract": "Conditional generative adversarial networks (cGANs) have shown superior\nresults in class-conditional generation tasks. In order to simultaneously\ncontrol multiple conditions, cGANs require multi-label training datasets, where\nmultiple labels can be assigned to each data instance. Nevertheless, the\ntremendous annotation cost limits the accessibility of multi-label datasets in\nthe real-world scenarios. Hence, we explore the practical setting called single\npositive setting, where each data instance is annotated by only one positive\nlabel with no explicit negative labels. To generate multi-label data in the\nsingle positive setting, we propose a novel sampling approach called\nsingle-to-multi-label (S2M) sampling, based on the Markov chain Monte Carlo\nmethod. As a widely applicable \"add-on\" method, our proposed S2M sampling\nenables existing unconditional and conditional GANs to draw high-quality\nmulti-label data with a minimal annotation cost. Extensive experiments on real\nimage datasets verify the effectiveness and correctness of our method, even\nwhen compared to a model trained with fully annotated datasets.",
    "descriptor": "",
    "authors": [
      "Youngin Cho",
      "Daejin Kim",
      "Mohammad Azam Khan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.05764"
  },
  {
    "id": "arXiv:2206.05765",
    "title": "A Semantic Consistency Feature Alignment Object Detection Model Based on  Mixed-Class Distribution Metrics",
    "abstract": "Unsupervised domain adaptation is critical in various computer vision tasks,\nsuch as object detection, instance segmentation, etc. They attempt to reduce\ndomain bias-induced performance degradation while also promoting model\napplication speed. Previous works in domain adaptation object detection attempt\nto align image-level and instance-level shifts to eventually minimize the\ndomain discrepancy, but they may align single-class features to mixed-class\nfeatures in image-level domain adaptation because each image in the object\ndetection task may be more than one class and object. In order to achieve\nsingle-class with single-class alignment and mixed-class with mixed-class\nalignment, we treat the mixed-class of the feature as a new class and propose a\nmixed-classes $H-divergence$ for object detection to achieve homogenous feature\nalignment and reduce negative transfer. Then, a Semantic Consistency Feature\nAlignment Model (SCFAM) based on mixed-classes $H-divergence$ was also\npresented. To improve single-class and mixed-class semantic information and\naccomplish semantic separation, the SCFAM model proposes Semantic Prediction\nModels (SPM) and Semantic Bridging Components (SBC). And the weight of the pix\ndomain discriminator loss is then changed based on the SPM result to reduce\nsample imbalance. Extensive unsupervised domain adaption experiments on widely\nused datasets illustrate our proposed approach's robust object detection in\ndomain bias settings.",
    "descriptor": "",
    "authors": [
      "Lijun Gou",
      "Jinrong Yang",
      "Hangcheng Yu",
      "Pan Wang",
      "Xiaoping Li",
      "Chao Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.05765"
  },
  {
    "id": "arXiv:2206.05771",
    "title": "Human-Following and -guiding in Crowded Environments using Semantic  Deep-Reinforcement-Learning for Mobile Service Robots",
    "abstract": "Assistance robots have gained widespread attention in various industries such\nas logistics and human assistance. The tasks of guiding or following a human in\na crowded environment such as airports or train stations to carry weight or\ngoods is still an open problem. In these use cases, the robot is not only\nrequired to intelligently interact with humans, but also to navigate safely\namong crowds. Thus, especially highly dynamic environments pose a grand\nchallenge due to the volatile behavior patterns and unpredictable movements of\nhumans. In this paper, we propose a Deep-Reinforcement-Learning-based agent for\nhuman-guiding and -following tasks in crowded environments. Therefore, we\nincorporate semantic information to provide the agent with high-level\ninformation like the social states of humans, safety models, and class types.\nWe evaluate our proposed approach against a benchmark approach without semantic\ninformation and demonstrated enhanced navigational safety and robustness.\nMoreover, we demonstrate that the agent could learn to adapt its behavior to\nhumans, which improves the human-robot interaction significantly.",
    "descriptor": "\nComments: IEEE International Conference on Robotics and Automation 2022, 7 pages, 4 figures\n",
    "authors": [
      "Linh K\u00e4stner",
      "Bassel Fatloun",
      "Zhengcheng Shen",
      "Daniel Gawrisch",
      "Jens Lambrecht"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.05771"
  },
  {
    "id": "arXiv:2206.05772",
    "title": "Distributed Differential Privacy in Multi-Armed Bandits",
    "abstract": "We consider the standard $K$-armed bandit problem under a distributed trust\nmodel of differential privacy (DP), which enables to guarantee privacy without\na trustworthy server. Under this trust model, previous work largely focus on\nachieving privacy using a shuffle protocol, where a batch of users data are\nrandomly permuted before sending to a central server. This protocol achieves\n($\\epsilon,\\delta$) or approximate-DP guarantee by sacrificing an additional\nadditive $O\\!\\left(\\!\\frac{K\\log T\\sqrt{\\log(1/\\delta)}}{\\epsilon}\\!\\right)\\!$\ncost in $T$-step cumulative regret. In contrast, the optimal privacy cost for\nachieving a stronger ($\\epsilon,0$) or pure-DP guarantee under the widely used\ncentral trust model is only $\\Theta\\!\\left(\\!\\frac{K\\log\nT}{\\epsilon}\\!\\right)\\!$, where, however, a trusted server is required. In this\nwork, we aim to obtain a pure-DP guarantee under distributed trust model while\nsacrificing no more regret than that under central trust model. We achieve this\nby designing a generic bandit algorithm based on successive arm elimination,\nwhere privacy is guaranteed by corrupting rewards with an equivalent discrete\nLaplace noise ensured by a secure computation protocol. We also show that our\nalgorithm, when instantiated with Skellam noise and the secure protocol,\nensures \\emph{R\\'{e}nyi differential privacy} -- a stronger notion than\napproximate DP -- under distributed trust model with a privacy cost of\n$O\\!\\left(\\!\\frac{K\\sqrt{\\log T}}{\\epsilon}\\!\\right)\\!$.",
    "descriptor": "",
    "authors": [
      "Sayak Ray Chowdhury",
      "Xingyu Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.05772"
  },
  {
    "id": "arXiv:2206.05775",
    "title": "Imagination-augmented Navigation Based on 2D Laser Sensor Observations",
    "abstract": "Autonomous navigation of mobile robots is an essential task for various\nindustries. Sensor data is crucial to ensure safe and reliable navigation.\nHowever, sensor observations are often limited by different factors.\nImagination can assist to enhance the view and aid navigation in dangerous or\nunknown situations where only limited sensor observation is available. In this\npaper, we propose an imagination-enhanced navigation based on 2D semantic laser\nscan data. The system contains an imagination module, which can predict the\nentire occupied area of the object. The imagination module is trained in a\nsupervised manner using a collected training dataset from a 2D simulator. Four\ndifferent imagination models are trained, and the imagination results are\nevaluated. Subsequently, the imagination results are integrated into the local\nand global cost map to benefit the navigation procedure. The approach is\nvalidated on three different test maps, with seven different paths for each\nmap. The quality and numeric results showed that the agent with the imagination\nmodule could generate more reliable paths without passing beneath the object,\nwith the cost of a longer path and slower velocity.",
    "descriptor": "\nComments: 7 pages, 9 figures\n",
    "authors": [
      "Zhengcheng Shen",
      "Linh K\u00e4stner",
      "Magdalena Yordanova",
      "Jens Lambrecht"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.05775"
  },
  {
    "id": "arXiv:2206.05776",
    "title": "The Rough Topology for Numerical Data",
    "abstract": "In this paper, we give a generalization of the rough topology and the core to\nnumerical data by classifying objects in terms of the attribute values. New\napproach to find the core for numerical data is discussed. Then a measurement\nto find whether an attribute is in the core or not is given. This new method\nfor finding the core is used for attribute reduction. It is tested and compared\nby using machine learning algorithms. Finally, the algorithms and codes to\nconvert a data to pertinent data and to find core is also provided.",
    "descriptor": "\nComments: comments welcome, preliminary version\n",
    "authors": [
      "U\u011fur Yi\u011fit"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05776"
  },
  {
    "id": "arXiv:2206.05777",
    "title": "The YiTrans End-to-End Speech Translation System for IWSLT 2022 Offline  Shared Task",
    "abstract": "This paper describes the submission of our end-to-end YiTrans speech\ntranslation system for the IWSLT 2022 offline task, which translates from\nEnglish audio to German, Chinese, and Japanese. The YiTrans system is built on\nlarge-scale pre-trained encoder-decoder models. More specifically, we first\ndesign a multi-stage pre-training strategy to build a multi-modality model with\na large amount of labeled and unlabeled data. We then fine-tune the\ncorresponding components of the model for the downstream speech translation\ntasks. Moreover, we make various efforts to improve performance, such as data\nfiltering, data augmentation, speech segmentation, model ensemble, and so on.\nExperimental results show that our YiTrans system obtains a significant\nimprovement than the strong baseline on three translation directions, and it\nachieves +5.2 BLEU improvements over last year's optimal end-to-end system on\ntst2021 English-German. Our final submissions rank first on English-German and\nEnglish-Chinese end-to-end systems in terms of the automatic evaluation metric.\nWe make our code and models publicly available.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Ziqiang Zhang",
      "Junyi Ao",
      "Shujie Liu",
      "Furu Wei",
      "Jinyu Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.05777"
  },
  {
    "id": "arXiv:2206.05778",
    "title": "Learning-Based Data Storage [Vision] (Technical Report)",
    "abstract": "Deep neural network (DNN) and its variants have been extensively used for a\nwide spectrum of real applications such as image classification, face/speech\nrecognition, fraud detection, and so on. In addition to many important machine\nlearning tasks, as artificial networks emulating the way brain cells function,\nDNNs also show the capability of storing non-linear relationships between input\nand output data, which exhibits the potential of storing data via DNNs. We\nenvision a new paradigm of data storage, \"DNN-as-a-Database\", where data are\nencoded in well-trained machine learning models. Compared with conventional\ndata storage that directly records data in raw formats, learning-based\nstructures (e.g., DNN) can implicitly encode data pairs of inputs and outputs\nand compute/materialize actual output data of different resolutions only if\ninput data are provided. This new paradigm can greatly enhance the data\nsecurity by allowing flexible data privacy settings on different levels,\nachieve low space consumption and fast computation with the acceleration of new\nhardware (e.g., Diffractive Neural Network and AI chips), and can be\ngeneralized to distributed DNN-based storage/computing. In this paper, we\npropose this novel concept of learning-based data storage, which utilizes a\nlearning structure called learning-based memory unit (LMU), to store, organize,\nand retrieve data. As a case study, we use DNNs as the engine in the LMU, and\nstudy the data capacity and accuracy of the DNN-based data storage. Our\npreliminary experimental results show the feasibility of the learning-based\ndata storage by achieving high (100%) accuracy of the DNN storage. We explore\nand design effective solutions to utilize the DNN-based data storage to manage\nand query relational tables. We discuss how to generalize our solutions to\nother data types (e.g., graphs) and environments such as distributed DNN\nstorage/computing.",
    "descriptor": "\nComments: 10 pages, 10 figures\n",
    "authors": [
      "Xiang Lian",
      "Xiaofei Zhang"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05778"
  },
  {
    "id": "arXiv:2206.05786",
    "title": "MLLess: Achieving Cost Efficiency in Serverless Machine Learning  Training",
    "abstract": "Function-as-a-Service (FaaS) has raised a growing interest in how to \"tame\"\nserverless computing to enable domain-specific use cases such as data-intensive\napplications and machine learning (ML), to name a few. Recently, several\nsystems have been implemented for training ML models. Certainly, these research\narticles are significant steps in the correct direction. However, they do not\ncompletely answer the nagging question of when serverless ML training can be\nmore cost-effective compared to traditional \"serverful\" computing. To help in\nthis endeavor, we propose MLLess, a FaaS-based ML training prototype built atop\nIBM Cloud Functions. To boost cost-efficiency, MLLess implements two innovative\noptimizations tailored to the traits of serverless computing: on one hand, a\nsignificance filter, to make indirect communication more effective, and on the\nother hand, a scale-in auto-tuner, to reduce cost by benefiting from the FaaS\nsub-second billing model (often per 100ms). Our results certify that MLLess can\nbe 15X faster than serverful ML systems at a lower cost for sparse ML models\nthat exhibit fast convergence such as sparse logistic regression and matrix\nfactorization. Furthermore, our results show that MLLess can easily scale out\nto increasingly large fleets of serverless workers.",
    "descriptor": "",
    "authors": [
      "Pablo Gimeno Sarroca",
      "Marc S\u00e1nchez-Artigas"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.05786"
  },
  {
    "id": "arXiv:2206.05787",
    "title": "A Probabilistic Machine Learning Approach to Scheduling Parallel Loops  with Bayesian Optimization",
    "abstract": "This paper proposes Bayesian optimization augmented factoring self-scheduling\n(BO FSS), a new parallel loop scheduling strategy. BO FSS is an automatic\ntuning variant of the factoring self-scheduling (FSS) algorithm and is based on\nBayesian optimization (BO), a black-box optimization algorithm. Its core idea\nis to automatically tune the internal parameter of FSS by solving an\noptimization problem using BO. The tuning procedure only requires online\nexecution time measurement of the target loop. In order to apply BO, we model\nthe execution time using two Gaussian process (GP) probabilistic machine\nlearning models. Notably, we propose a locality-aware GP model, which assumes\nthat the temporal locality effect resembles an exponentially decreasing\nfunction. By accurately modeling the temporal locality effect, our\nlocality-aware GP model accelerates the convergence of BO. We implemented BO\nFSS on the GCC implementation of the OpenMP standard and evaluated its\nperformance against other scheduling algorithms. Also, to quantify our method's\nperformance variation on different workloads, or workload-robustness in our\nterms, we measure the minimax regret. According to the minimax regret, BO FSS\nshows more consistent performance than other algorithms. Within the considered\nworkloads, BO FSS improves the execution time of FSS by as much as 22% and 5%\non average.",
    "descriptor": "\nComments: Part of TPDS Special Section on Parallel and Distributed Computing Techniques for AI, ML, and DL\n",
    "authors": [
      "Kyurae Kim",
      "Youngjae Kim",
      "Sungyong Park"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2206.05787"
  },
  {
    "id": "arXiv:2206.05790",
    "title": "Data Augmentation for Intent Classification",
    "abstract": "Training accurate intent classifiers requires labeled data, which can be\ncostly to obtain. Data augmentation methods may ameliorate this issue, but the\nquality of the generated data varies significantly across techniques. We study\nthe process of systematically producing pseudo-labeled data given a small seed\nset using a wide variety of data augmentation techniques, including mixing\nmethods together. We find that while certain methods dramatically improve\nqualitative and quantitative performance, other methods have minimal or even\nnegative impact. We also analyze key considerations when implementing data\naugmentation methods in production.",
    "descriptor": "\nComments: 8 pages, 3 tables. Accepted to NeurIPs 2021 Data-centric AI Workshop\n",
    "authors": [
      "Derek Chen",
      "Claire Yin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.05790"
  },
  {
    "id": "arXiv:2206.05794",
    "title": "SGD Noise and Implicit Low-Rank Bias in Deep Neural Networks",
    "abstract": "We analyze deep ReLU neural networks trained with mini-batch Stochastic\nGradient Descent (SGD) and weight decay. We study the source of SGD noise and\nprove that when training with weight decay, the only solutions of SGD at\nconvergence are zero functions. Furthermore, we show, both theoretically and\nempirically, that when training a neural network using SGD with weight decay\nand small batch size, the resulting weight matrices are expected to be of small\nrank. Our analysis relies on a minimal set of assumptions and the neural\nnetworks may be arbitrarily wide or deep, and may include residual connections,\nas well as batch normalization layers.",
    "descriptor": "",
    "authors": [
      "Tomer Galanti",
      "Tomaso Poggio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.05794"
  },
  {
    "id": "arXiv:2206.05802",
    "title": "Self-critiquing models for assisting human evaluators",
    "abstract": "We fine-tune large language models to write natural language critiques\n(natural language critical comments) using behavioral cloning. On a topic-based\nsummarization task, critiques written by our models help humans find flaws in\nsummaries that they would have otherwise missed. Our models help find naturally\noccurring flaws in both model and human written summaries, and intentional\nflaws in summaries written by humans to be deliberately misleading. We study\nscaling properties of critiquing with both topic-based summarization and\nsynthetic tasks. Larger models write more helpful critiques, and on most tasks,\nare better at self-critiquing, despite having harder-to-critique outputs.\nLarger models can also integrate their own self-critiques as feedback, refining\ntheir own summaries into better ones. Finally, we motivate and introduce a\nframework for comparing critiquing ability to generation and discrimination\nability. Our measurements suggest that even large models may still have\nrelevant knowledge they cannot or do not articulate as critiques. These results\nare a proof of concept for using AI-assisted human feedback to scale the\nsupervision of machine learning systems to tasks that are difficult for humans\nto evaluate directly. We release our training datasets, as well as samples from\nour critique assistance experiments.",
    "descriptor": "",
    "authors": [
      "William Saunders",
      "Catherine Yeh",
      "Jeff Wu",
      "Steven Bills",
      "Long Ouyang",
      "Jonathan Ward",
      "Jan Leike"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05802"
  },
  {
    "id": "arXiv:2206.05805",
    "title": "Optimal Quaternary Locally Repairable Codes Attaining the Singleton-like  Bound",
    "abstract": "Recent years, several new types of codes were introduced to provide\nfault-tolerance and guarantee system reliability in distributed storage\nsystems, among which locally repairable codes (LRCs for short) have played an\nimportant role.\nA linear code is said to have locality $r$ if each of its code symbols can be\nrepaired by accessing at most $r$ other code symbols. For an LRC with length\n$n$, dimension $k$ and locality $r$, its minimum distance $d$ was proved to\nsatisfy the Singleton-like bound $d\\leq n-k-\\lceil k/r\\rceil+2$. Since then,\nmany works have been done for constructing LRCs meeting the Singleton-like\nbound over small fields.\nIn this paper, we study quaternary LRCs meeting Singleton-like bound through\na parity-check matrix approach. Using tools from finite geometry, we provide\nsome new necessary conditions for LRCs being optimal. From this, we prove that\nthere are $27$ different classes of parameters for optimal quaternary LRCs.\nMoreover, for each class, explicit constructions of corresponding optimal\nquaternary LRCs are presented.",
    "descriptor": "\nComments: 23 pages, the Chinese version of this paper will appear in SCIENTIA SINICA Mathematica (DOI: 10.1360/SSM-2022-0041)\n",
    "authors": [
      "Yuanxiao Xi",
      "Xiangliang Kong",
      "Gennian Ge"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.05805"
  },
  {
    "id": "arXiv:2206.05807",
    "title": "Over-Generation Cannot Be Rewarded: Length-Adaptive Average Lagging for  Simultaneous Speech Translation",
    "abstract": "Simultaneous speech translation (SimulST) systems aim at generating their\noutput with the lowest possible latency, which is normally computed in terms of\nAverage Lagging (AL). In this paper we highlight that, despite its widespread\nadoption, AL provides underestimated scores for systems that generate longer\npredictions compared to the corresponding references. We also show that this\nproblem has practical relevance, as recent SimulST systems have indeed a\ntendency to over-generate. As a solution, we propose LAAL (Length-Adaptive\nAverage Lagging), a modified version of the metric that takes into account the\nover-generation phenomenon and allows for unbiased evaluation of both\nunder-/over-generating systems.",
    "descriptor": "\nComments: AutoSimTrans Workshop @ NAACL2022\n",
    "authors": [
      "Sara Papi",
      "Marco Gaido",
      "Matteo Negri",
      "Marco Turchi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.05807"
  },
  {
    "id": "arXiv:2206.05809",
    "title": "Geometric Policy Iteration for Markov Decision Processes",
    "abstract": "Recently discovered polyhedral structures of the value function for finite\nstate-action discounted Markov decision processes (MDP) shed light on\nunderstanding the success of reinforcement learning. We investigate the value\nfunction polytope in greater detail and characterize the polytope boundary\nusing a hyperplane arrangement. We further show that the value space is a union\nof finitely many cells of the same hyperplane arrangement and relate it to the\npolytope of the classical linear programming formulation for MDPs. Inspired by\nthese geometric properties, we propose a new algorithm, \\emph{Geometric Policy\nIteration} (GPI), to solve discounted MDPs. GPI updates the policy of a single\nstate by switching to an action that is mapped to the boundary of the value\nfunction polytope, followed by an immediate update of the value function. This\nnew update rule aims at a faster value improvement without compromising\ncomputational efficiency. Moreover, our algorithm allows asynchronous updates\nof state values which is more flexible and advantageous compared to traditional\npolicy iteration when the state set is large. We prove that the complexity of\nGPI achieves the best known bound $\\bigO{\\frac{|\\actions|}{1 - \\gamma}\\log\n\\frac{1}{1-\\gamma}}$ of policy iteration and empirically demonstrate the\nstrength of GPI on MDPs of various sizes.",
    "descriptor": "\nComments: KDD2022\n",
    "authors": [
      "Yue Wu",
      "Jes\u00fas A. De Loera"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.05809"
  },
  {
    "id": "arXiv:2206.05810",
    "title": "Analysis of Branch Specialization and its Application in Image  Decomposition",
    "abstract": "Branched neural networks have been used extensively for a variety of tasks.\nBranches are sub-parts of the model that perform independent processing\nfollowed by aggregation. It is known that this setting induces a phenomenon\ncalled Branch Specialization, where different branches become experts in\ndifferent sub-tasks. Such observations were qualitative by nature. In this\nwork, we present a methodological analysis of Branch Specialization. We explain\nthe role of gradient descent in this phenomenon. We show that branched\ngenerative networks naturally decompose animal images to meaningful channels of\nfur, whiskers and spots and face images to channels such as different\nillumination components and face parts.",
    "descriptor": "",
    "authors": [
      "Jonathan Brokman",
      "Guy Gilboa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.05810"
  },
  {
    "id": "arXiv:2206.05813",
    "title": "A Rewriting Logic Semantics and Statistical Analysis for Probabilistic  Event-B",
    "abstract": "Probabilistic specifications are fast gaining ground as a tool for\nstatistical modeling of probabilistic systems. One of the main goals of formal\nmethods in this domain is to ensure that specific behavior is present or absent\nin the system, up to a certain confidence threshold, regardless of the way it\noperates amid uncertain information. This paper presents a rewriting logic\nsemantics for a probabilistic extension of Event-B, a proof-based formal method\nfor discrete systems modeling. The proposed semantics adequately captures the\nthree sources of probabilistic behavior, namely, probabilistic assignments,\nparameters, and concurrency. Hence, simulation and probabilistic temporal\nverification become automatically available for probabilistic Event-B models.\nThe approach takes as input a probabilistic Event-B specification, and outputs\na probabilistic rewrite theory that is fully executable in PMaude and can be\nstatistically tested against quantitative metrics. The approach is illustrated\nwith examples in the paper.",
    "descriptor": "",
    "authors": [
      "Carlos Olarte",
      "Camilo Rocha",
      "Daniel Osorio"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.05813"
  },
  {
    "id": "arXiv:2206.05814",
    "title": "Once Highly Productive, Forever Highly Productive? Full Professors'  Research Productivity from a Longitudinal Perspective",
    "abstract": "This longitudinal study explores persistence in research productivity over\ntime. We examine the trajectories of the academic careers of 2,326 current full\nprofessors in 14 STEMM disciplines, studying their lifetime biographical\nhistories and publication histories. Every full professor is compared in terms\nof productivity classes (top, middle, bottom) with their peers at earlier\ncareer stages. We used prestige-normalized productivity in which more weight is\ngiven to articles in high-impact than in low-impact journals, recognizing the\nhighly stratified nature of academic science. Our results show that membership\nin top productivity classes is to a large extent determined by being in these\nclasses earlier. Half of the current top productive full professors belonged to\ntop productivity classes throughout their academic careers. Half of the top\nproductive assistant professors continued as top productive associate\nprofessors, and half of the top productive associate professors continued as\ntop productive full professors (52.6% and 50.8%). Top-to-bottom and\nbottom-to-top transitions in productivity classes occurred marginally. The\ncombination of biographical and demographic data with raw Scopus publication\ndata from the past 50 years (N=1 million) made it possible to assign all full\nprofessors retrospective to different productivity, promotion age, and\npromotion speed classes. In logistic regression models, two powerful predictors\nof belonging to the top productivity class for full professors were being\nhighly productive as assistant professors and as associate professors\n(increasing the odds by 180% and 360%). Neither gender nor age (biological or\nacademic) emerged as statistically significant.",
    "descriptor": "\nComments: 33 pages, 6 tables, 7 figures\n",
    "authors": [
      "Marek Kwiek",
      "Wojciech Roszka"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2206.05814"
  },
  {
    "id": "arXiv:2206.05818",
    "title": "An Industry 4.0 example: real-time quality control for steel-based mass  production using Machine Learning on non-invasive sensor data",
    "abstract": "Insufficient steel quality in mass production can cause extremely costly\ndamage to tooling, production downtimes and low quality products. Automatic,\nfast and cheap strategies to estimate essential material properties for quality\ncontrol, risk mitigation and the prediction of faults are highly desirable. In\nthis work we analyse a high throughput production line of steel-based products.\nCurrently, the material quality is checked using manual destructive testing,\nwhich is slow, wasteful and covers only a tiny fraction of the material. To\nachieve complete testing coverage our industrial collaborator developed a\ncontactless, non-invasive, electromagnetic sensor to measure all material\nduring production in real-time. Our contribution is three-fold: 1) We show in a\ncontrolled experiment that the sensor can distinguish steel with deliberately\naltered properties. 2) 48 steel coils were fully measured non-invasively and\nadditional destructive tests were conducted on samples to serve as ground\ntruth. A linear model is fitted to predict from the non-invasive measurements\ntwo key material properties (yield strength and tensile strength) that normally\nare obtained by destructive tests. The performance is evaluated in\nleave-one-coil-out cross-validation. 3) The resulting model is used to analyse\nthe material properties and the relationship with logged product faults on real\nproduction data of ~108 km of processed material measured with the non-invasive\nsensor. The model achieves an excellent performance (F3-score of 0.95)\npredicting material running out of specifications for the tensile strength. The\ncombination of model predictions and logged product faults shows that if a\nsignificant percentage of estimated yield stress values is out of\nspecification, the risk of product faults is high. Our analysis demonstrates\npromising directions for real-time quality control, risk monitoring and fault\ndetection.",
    "descriptor": "\nComments: Accepted at IJCNN 2022\n",
    "authors": [
      "Michiel Straat",
      "Kevin Koster",
      "Nick Goet",
      "Kerstin Bunte"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.05818"
  },
  {
    "id": "arXiv:2206.05821",
    "title": "RSSD: Defend against Ransomware with Hardware-Isolated Network-Storage  Codesign and Post-Attack Analysis",
    "abstract": "Encryption ransomware has become a notorious malware. It encrypts user data\non storage devices like solid-state drives (SSDs) and demands a ransom to\nrestore data for users. To bypass existing defenses, ransomware would keep\nevolving and performing new attack models. For instance, we identify and\nvalidate three new attacks, including (1) garbage-collection (GC) attack that\nexploits storage capacity and keeps writing data to trigger GC and force SSDs\nto release the retained data; (2) timing attack that intentionally slows down\nthe pace of encrypting data and hides its I/O patterns to escape existing\ndefense; (3) trimming attack that utilizes the trim command available in SSDs\nto physically erase data.\nTo enhance the robustness of SSDs against these attacks, we propose RSSD, a\nransomware-aware SSD. It redesigns the flash management of SSDs for enabling\nthe hardware-assisted logging, which can conservatively retain older versions\nof user data and received storage operations in time order with low overhead.\nIt also employs hardware-isolated NVMe over Ethernet to expand local storage\ncapacity by transparently offloading the logs to remote cloud/servers in a\nsecure manner. RSSD enables post-attack analysis by building a trusted evidence\nchain of storage operations to assist the investigation of ransomware attacks.\nWe develop RSSD with a real-world SSD FPGA board. Our evaluation shows that\nRSSD can defend against new and future ransomware attacks, while introducing\nnegligible performance overhead.",
    "descriptor": "\nComments: This extended abstract is 2 pages containing 2 Figures. This abstract was presented at the 2022 Non-Volatile Memories Workshop (NVMW'22) and the full paper was published at ASPLOS 2022\n",
    "authors": [
      "Benjamin Reidys",
      "Peng Liu",
      "Jian Huang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2206.05821"
  },
  {
    "id": "arXiv:2206.05825",
    "title": "A Unified Approach to Reinforcement Learning, Quantal Response  Equilibria, and Two-Player Zero-Sum Games",
    "abstract": "Algorithms designed for single-agent reinforcement learning (RL) generally\nfail to converge to equilibria in two-player zero-sum (2p0s) games. Conversely,\ngame-theoretic algorithms for approximating Nash and quantal response\nequilibria (QREs) in 2p0s games are not typically competitive for RL and can be\ndifficult to scale. As a result, algorithms for these two cases are generally\ndeveloped and evaluated separately. In this work, we show that a single\nalgorithm -- a simple extension to mirror descent with proximal regularization\nthat we call magnetic mirror descent (MMD) -- can produce strong results in\nboth settings, despite their fundamental differences. From a theoretical\nstandpoint, we prove that MMD converges linearly to QREs in extensive-form\ngames -- this is the first time linear convergence has been proven for a first\norder solver. Moreover, applied as a tabular Nash equilibrium solver via\nself-play, we show empirically that MMD produces results competitive with CFR\nin both normal-form and extensive-form games with full feedback (this is the\nfirst time that a standard RL algorithm has done so) and also that MMD\nempirically converges in black-box feedback settings. Furthermore, for\nsingle-agent deep RL, on a small collection of Atari and Mujoco games, we show\nthat MMD can produce results competitive with those of PPO. Lastly, for\nmulti-agent deep RL, we show MMD can outperform NFSP in 3x3 Abrupt Dark Hex.",
    "descriptor": "",
    "authors": [
      "Samuel Sokota",
      "Ryan D'Orazio",
      "J. Zico Kolter",
      "Nicolas Loizou",
      "Marc Lanctot",
      "Ioannis Mitliagkas",
      "Noam Brown",
      "Christian Kroer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2206.05825"
  },
  {
    "id": "arXiv:2206.05827",
    "title": "Case-Based Inverse Reinforcement Learning Using Temporal Coherence",
    "abstract": "Providing expert trajectories in the context of Imitation Learning is often\nexpensive and time-consuming. The goal must therefore be to create algorithms\nwhich require as little expert data as possible. In this paper we present an\nalgorithm that imitates the higher-level strategy of the expert rather than\njust imitating the expert on action level, which we hypothesize requires less\nexpert data and makes training more stable. As a prior, we assume that the\nhigher-level strategy is to reach an unknown target state area, which we\nhypothesize is a valid prior for many domains in Reinforcement Learning. The\ntarget state area is unknown, but since the expert has demonstrated how to\nreach it, the agent tries to reach states similar to the expert. Building on\nthe idea of Temporal Coherence, our algorithm trains a neural network to\npredict whether two states are similar, in the sense that they may occur close\nin time. During inference, the agent compares its current state with expert\nstates from a Case Base for similarity. The results show that our approach can\nstill learn a near-optimal policy in settings with very little expert data,\nwhere algorithms that try to imitate the expert at the action level can no\nlonger do so.",
    "descriptor": "\nComments: accepted at ICCBR\n",
    "authors": [
      "Jonas N\u00fc\u00dflein",
      "Steffen Illium",
      "Robert M\u00fcller",
      "Thomas Gabor",
      "Claudia Linnhoff-Popien"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05827"
  },
  {
    "id": "arXiv:2206.05830",
    "title": "Stochastic Gradient Descent without Full Data Shuffle",
    "abstract": "Stochastic gradient descent (SGD) is the cornerstone of modern machine\nlearning (ML) systems. Despite its computational efficiency, SGD requires\nrandom data access that is inherently inefficient when implemented in systems\nthat rely on block-addressable secondary storage such as HDD and SSD, e.g.,\nTensorFlow/PyTorch and in-DB ML systems over large files. To address this\nimpedance mismatch, various data shuffling strategies have been proposed to\nbalance the convergence rate of SGD (which favors randomness) and its I/O\nperformance (which favors sequential access).\nIn this paper, we first conduct a systematic empirical study on existing data\nshuffling strategies, which reveals that all existing strategies have room for\nimprovement -- they all suffer in terms of I/O performance or convergence rate.\nWith this in mind, we propose a simple but novel hierarchical data shuffling\nstrategy, CorgiPile. Compared with existing strategies, CorgiPile avoids a full\ndata shuffle while maintaining comparable convergence rate of SGD as if a full\nshuffle were performed. We provide a non-trivial theoretical analysis of\nCorgiPile on its convergence behavior. We further integrate CorgiPile into\nPyTorch by designing new parallel/distributed shuffle operators inside a new\nCorgiPileDataSet API. We also integrate CorgiPile into PostgreSQL by\nintroducing three new physical operators with optimizations. Our experimental\nresults show that CorgiPile can achieve comparable convergence rate with the\nfull shuffle based SGD for both deep learning and generalized linear models.\nFor deep learning models on ImageNet dataset, CorgiPile is 1.5X faster than\nPyTorch with full data shuffle. For in-DB ML with linear models, CorgiPile is\n1.6X-12.8X faster than two state-of-the-art in-DB ML systems, Apache MADlib and\nBismarck, on both HDD and SSD.",
    "descriptor": "\nComments: This technical report is an extension of our SIGMOD 2022 paper titled \"In-Database Machine Learning with CorgiPile: Stochastic Gradient Descent without Full Data Shuffle\". this https URL\n",
    "authors": [
      "Lijie Xu",
      "Shuang Qiu",
      "Binhang Yuan",
      "Jiawei Jiang",
      "Cedric Renggli",
      "Shaoduo Gan",
      "Kaan Kara",
      "Guoliang Li",
      "Ji Liu",
      "Wentao Wu",
      "Jieping Ye",
      "Ce Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05830"
  },
  {
    "id": "arXiv:2206.05833",
    "title": "COLD Fusion: Calibrated and Ordinal Latent Distribution Fusion for  Uncertainty-Aware Multimodal Emotion Recognition",
    "abstract": "Automatically recognising apparent emotions from face and voice is hard, in\npart because of various sources of uncertainty, including in the input data and\nthe labels used in a machine learning framework. This paper introduces an\nuncertainty-aware audiovisual fusion approach that quantifies modality-wise\nuncertainty towards emotion prediction. To this end, we propose a novel fusion\nframework in which we first learn latent distributions over audiovisual\ntemporal context vectors separately, and then constrain the variance vectors of\nunimodal latent distributions so that they represent the amount of information\neach modality provides w.r.t. emotion recognition. In particular, we impose\nCalibration and Ordinal Ranking constraints on the variance vectors of\naudiovisual latent distributions. When well-calibrated, modality-wise\nuncertainty scores indicate how much their corresponding predictions may differ\nfrom the ground truth labels. Well-ranked uncertainty scores allow the ordinal\nranking of different frames across the modalities. To jointly impose both these\nconstraints, we propose a softmax distributional matching loss. In both\nclassification and regression settings, we compare our uncertainty-aware fusion\nmodel with standard model-agnostic fusion baselines. Our evaluation on two\nemotion recognition corpora, AVEC 2019 CES and IEMOCAP, shows that audiovisual\nemotion recognition can considerably benefit from well-calibrated and\nwell-ranked latent uncertainty measures.",
    "descriptor": "",
    "authors": [
      "Mani Kumar Tellamekala",
      "Shahin Amiriparian",
      "Bj\u00f6rn W. Schuller",
      "Elisabeth Andr\u00e9",
      "Timo Giesbrecht",
      "Michel Valstar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2206.05833"
  },
  {
    "id": "arXiv:2206.05836",
    "title": "GLIPv2: Unifying Localization and Vision-Language Understanding",
    "abstract": "We present GLIPv2, a grounded VL understanding model, that serves both\nlocalization tasks (e.g., object detection, instance segmentation) and\nVision-Language (VL) understanding tasks (e.g., VQA, image captioning). GLIPv2\nelegantly unifies localization pre-training and Vision-Language Pre-training\n(VLP) with three pre-training tasks: phrase grounding as a VL reformulation of\nthe detection task, region-word contrastive learning as a novel region-word\nlevel contrastive learning task, and the masked language modeling. This\nunification not only simplifies the previous multi-stage VLP procedure but also\nachieves mutual benefits between localization and understanding tasks.\nExperimental results show that a single GLIPv2 model (all model weights are\nshared) achieves near SoTA performance on various localization and\nunderstanding tasks. The model also shows (1) strong zero-shot and few-shot\nadaption performance on open-vocabulary object detection tasks and (2) superior\ngrounding capability on VL understanding tasks. Code will be released at\nhttps://github.com/microsoft/GLIP.",
    "descriptor": "\nComments: Code will be released at this https URL\n",
    "authors": [
      "Haotian Zhang",
      "Pengchuan Zhang",
      "Xiaowei Hu",
      "Yen-Chun Chen",
      "Liunian Harold Li",
      "Xiyang Dai",
      "Lijuan Wang",
      "Lu Yuan",
      "Jenq-Neng Hwang",
      "Jianfeng Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2206.05836"
  },
  {
    "id": "arXiv:2206.05837",
    "title": "NeuralODF: Learning Omnidirectional Distance Fields for 3D Shape  Representation",
    "abstract": "In visual computing, 3D geometry is represented in many different forms\nincluding meshes, point clouds, voxel grids, level sets, and depth images. Each\nrepresentation is suited for different tasks thus making the transformation of\none representation into another (forward map) an important and common problem.\nWe propose Omnidirectional Distance Fields (ODFs), a new 3D shape\nrepresentation that encodes geometry by storing the depth to the object's\nsurface from any 3D position in any viewing direction. Since rays are the\nfundamental unit of an ODF, it can be used to easily transform to and from\ncommon 3D representations like meshes or point clouds. Different from level set\nmethods that are limited to representing closed surfaces, ODFs are unsigned and\ncan thus model open surfaces (e.g., garments). We demonstrate that ODFs can be\neffectively learned with a neural network (NeuralODF) despite the inherent\ndiscontinuities at occlusion boundaries. We also introduce efficient forward\nmapping algorithms for transforming ODFs to and from common 3D representations.\nSpecifically, we introduce an efficient Jumping Cubes algorithm for generating\nmeshes from ODFs. Experiments demonstrate that NeuralODF can learn to capture\nhigh-quality shape by overfitting to a single object, and also learn to\ngeneralize on common shape categories.",
    "descriptor": "",
    "authors": [
      "Trevor Houchens",
      "Cheng-You Lu",
      "Shivam Duggal",
      "Rao Fu",
      "Srinath Sridhar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.05837"
  },
  {
    "id": "arXiv:2206.05840",
    "title": "GAN based Data Augmentation to Resolve Class Imbalance",
    "abstract": "The number of credit card fraud has been growing as technology grows and\npeople can take advantage of it. Therefore, it is very important to implement a\nrobust and effective method to detect such frauds. The machine learning\nalgorithms are appropriate for these tasks since they try to maximize the\naccuracy of predictions and hence can be relied upon. However, there is an\nimpending flaw where in machine learning models may not perform well due to the\npresence of an imbalance across classes distribution within the sample set. So,\nin many related tasks, the datasets have a very small number of observed fraud\ncases (sometimes around 1 percent positive fraud instances found). Therefore,\nthis imbalance presence may impact any learning model's behavior by predicting\nall labels as the majority class, hence allowing no scope for generalization in\nthe predictions made by the model. We trained Generative Adversarial\nNetwork(GAN) to generate a large number of convincing (and reliable) synthetic\nexamples of the minority class that can be used to alleviate the class\nimbalance within the training set and hence generalize the learning of the data\nmore effectively.",
    "descriptor": "",
    "authors": [
      "Sairamvinay Vijayaraghavan",
      "Terry Guan",
      "Jason",
      "Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.05840"
  },
  {
    "id": "arXiv:2206.05842",
    "title": "Efficiency Comparison of AI classification algorithms for Image  Detection and Recognition in Real-time",
    "abstract": "Face detection and identification is the most difficult and often used task\nin Artificial Intelligence systems. The goal of this study is to present and\ncompare the results of several face detection and recognition algorithms used\nin the system. This system begins with a training image of a human, then\ncontinues on to the test image, identifying the face, comparing it to the\ntrained face, and finally classifying it using OpenCV classifiers. This\nresearch will discuss the most effective and successful tactics used in the\nsystem, which are implemented using Python, OpenCV, and Matplotlib. It may also\nbe used in locations with CCTV, such as public spaces, shopping malls, and ATM\nbooths.",
    "descriptor": "",
    "authors": [
      "Musarrat Saberin Nipun",
      "Rejwan Bin Sulaiman",
      "Amer Kareem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.05842"
  },
  {
    "id": "arXiv:2206.05843",
    "title": "A Graph Transformation Strategy for Optimizing SpTRSV",
    "abstract": "Sparse triangular solve (SpTRSV) is an extensively studied computational\nkernel. An important obstacle in parallel SpTRSV implementations is that in\nsome parts of a sparse matrix the computation is serial. By transforming the\ndependency graph, it is possible to increase the parallelism of the parts that\nlack it. In this work, we present an approach to increase the parallelism\ndegree of a sparse matrix, discuss its limitations and possible improvements,\nand we compare it to a previous manual approach. The results provide several\nhints on how to craft a collection of strategies to transform a dependency\ngraph.",
    "descriptor": "\nComments: 8 pages, 6 figures. Published in BA\\c{S}ARIM 2022 this https URL\n",
    "authors": [
      "Buse Y\u0131lmaz",
      "Abd\u00fclkadir Furkan Y\u0131ld\u0131z"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.05843"
  },
  {
    "id": "arXiv:2206.05844",
    "title": "FisheyeEX: Polar Outpainting for Extending the FoV of Fisheye Lens",
    "abstract": "Fisheye lens gains increasing applications in computational photography and\nassisted driving because of its wide field of view (FoV). However, the fisheye\nimage generally contains invalid black regions induced by its imaging model. In\nthis paper, we present a FisheyeEX method that extends the FoV of the fisheye\nlens by outpainting the invalid regions, improving the integrity of captured\nscenes. Compared with the rectangle and undistorted image, there are two\nchallenges for fisheye image outpainting: irregular painting regions and\ndistortion synthesis. Observing the radial symmetry of the fisheye image, we\nfirst propose a polar outpainting strategy to extrapolate the coherent\nsemantics from the center to the outside region. Such an outpainting manner\nconsiders the distribution pattern of radial distortion and the circle\nboundary, boosting a more reasonable completion direction. For the distortion\nsynthesis, we propose a spiral distortion-aware perception module, in which the\nlearning path keeps consistent with the distortion prior of the fisheye image.\nSubsequently, a scene revision module rearranges the generated pixels with the\nestimated distortion to match the fisheye image, thus extending the FoV. In the\nexperiment, we evaluate the proposed FisheyeEX on three popular outdoor\ndatasets: Cityscapes, BDD100k, and KITTI, and one real-world fisheye image\ndataset. The results demonstrate that our approach significantly outperforms\nthe state-of-the-art methods, gaining around 27% more content beyond the\noriginal fisheye image.",
    "descriptor": "",
    "authors": [
      "Kang Liao",
      "Chunyu Lin",
      "Yunchao Wei",
      "Yao Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.05844"
  },
  {
    "id": "arXiv:2206.05846",
    "title": "InBiaseD: Inductive Bias Distillation to Improve Generalization and  Robustness through Shape-awareness",
    "abstract": "Humans rely less on spurious correlations and trivial cues, such as texture,\ncompared to deep neural networks which lead to better generalization and\nrobustness. It can be attributed to the prior knowledge or the high-level\ncognitive inductive bias present in the brain. Therefore, introducing\nmeaningful inductive bias to neural networks can help learn more generic and\nhigh-level representations and alleviate some of the shortcomings. We propose\nInBiaseD to distill inductive bias and bring shape-awareness to the neural\nnetworks. Our method includes a bias alignment objective that enforces the\nnetworks to learn more generic representations that are less vulnerable to\nunintended cues in the data which results in improved generalization\nperformance. InBiaseD is less susceptible to shortcut learning and also\nexhibits lower texture bias. The better representations also aid in improving\nrobustness to adversarial attacks and we hence plugin InBiaseD seamlessly into\nthe existing adversarial training schemes to show a better trade-off between\ngeneralization and robustness.",
    "descriptor": "\nComments: Accepted at 1st Conference on Lifelong Learning Agents (CoLLAs 2022)\n",
    "authors": [
      "Shruthi Gowda",
      "Bahram Zonooz",
      "Elahe Arani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05846"
  },
  {
    "id": "arXiv:2206.05849",
    "title": "Explicit exponential Runge-Kutta methods for semilinear  integro-differential equations",
    "abstract": "The aim of this paper is to construct and analyze explicit exponential\nRunge-Kutta methods for the temporal discretization of linear and semilinear\nintegro-differential equations. By expanding the errors of the numerical method\nin terms of the solution, we derive order conditions that form the basis of our\nerror bounds for integro-differential equations. The order conditions are\nfurther used for constructing numerical methods. The convergence analysis is\nperformed in a Hilbert space setting, where the smoothing effect of the\nresolvent family is heavily used. For the linear case, we derive the order\nconditions for general order $p$ and prove convergence of order $p$, whenever\nthese conditions are satisfied. In the semilinear case, we consider in addition\nspatial discretization by a spectral Galerkin method, and we require locally\nLipschitz continuous nonlinearities. We derive the order conditions for orders\none and two, construct methods satisfying these conditions and prove their\nconvergence. Finally, some numerical experiments illustrating our theoretical\nresults are given.",
    "descriptor": "",
    "authors": [
      "Alexander Ostermann",
      "Fardin Saedpanah",
      "Nasrin Vaisi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.05849"
  },
  {
    "id": "arXiv:2206.05850",
    "title": "Achieving Zero Constraint Violation for Constrained Reinforcement  Learning via Conservative Natural Policy Gradient Primal-Dual Algorithm",
    "abstract": "We consider the problem of constrained Markov decision process (CMDP) in\ncontinuous state-actions spaces where the goal is to maximize the expected\ncumulative reward subject to some constraints. We propose a novel Conservative\nNatural Policy Gradient Primal-Dual Algorithm (C-NPG-PD) to achieve zero\nconstraint violation while achieving state of the art convergence results for\nthe objective value function. For general policy parametrization, we prove\nconvergence of value function to global optimal upto an approximation error due\nto restricted policy class. We even improve the sample complexity of existing\nconstrained NPG-PD algorithm \\cite{Ding2020} from $\\mathcal{O}(1/\\epsilon^6)$\nto $\\mathcal{O}(1/\\epsilon^4)$. To the best of our knowledge, this is the first\nwork to establish zero constraint violation with Natural policy gradient style\nalgorithms for infinite horizon discounted CMDPs. We demonstrate the merits of\nproposed algorithm via experimental evaluations.",
    "descriptor": "",
    "authors": [
      "Qinbo Bai",
      "Amrit Singh Bedi",
      "Vaneet Aggarwal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.05850"
  },
  {
    "id": "arXiv:2206.05852",
    "title": "ChordMixer: A Scalable Neural Attention Model for Sequences with  Different Lengths",
    "abstract": "Sequential data naturally have different lengths in many domains, with some\nvery long sequences. As an important modeling tool, neural attention should\ncapture long-range interaction in such sequences. However, most existing neural\nattention models admit only short sequences, or they have to employ chunking or\npadding to enforce a constant input length. Here we propose a simple neural\nnetwork building block called ChordMixer which can model the attention for long\nsequences with variable lengths. Each ChordMixer block consists of a\nposition-wise rotation layer without learnable parameters and an element-wise\nMLP layer. Repeatedly applying such blocks forms an effective network backbone\nthat mixes the input signals towards the learning targets. We have tested\nChordMixer on the synthetic adding problem, long document classification, and\nDNA sequence-based taxonomy classification. The experiment results show that\nour method substantially outperforms other neural attention models.",
    "descriptor": "",
    "authors": [
      "Ruslan Khalitov",
      "Tong Yu",
      "Lei Cheng",
      "Zhirong Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05852"
  },
  {
    "id": "arXiv:2206.05853",
    "title": "Modeling Generalized Specialist Approach To Train Quality Resilient  Snapshot Ensemble",
    "abstract": "Convolutional neural networks (CNNs) apply well with food image recognition\ndue to the ability to learn discriminative visual features. Nevertheless,\nrecognizing distorted images is challenging for existing CNNs. Hence, the study\nmodelled a generalized specialist approach to train a quality resilient\nensemble. The approach aids the models in the ensemble framework retain general\nskills of recognizing clean images and shallow skills of classifying noisy\nimages with one deep expertise area on a particular distortion. Subsequently, a\nnovel data augmentation random quality mixup (RQMixUp) is combined with\nsnapshot ensembling to train G-Specialist. During each training cycle of\nG-Specialist, a model is fine-tuned on the synthetic images generated by\nRQMixup, intermixing clean and distorted images of a particular distortion at a\nrandomly chosen level. Resultantly, each snapshot in the ensemble gained\nexpertise on several distortion levels, with shallow skills on other quality\ndistortions. Next, the filter outputs from diverse experts were fused for\nhigher accuracy. The learning process has no additional cost due to a single\ntraining process to train experts, compatible with a wide range of supervised\nCNNs for transfer learning. Finally, the experimental analysis on three\nreal-world food and a Malaysian food database showed significant improvement\nfor distorted images with competitive classification performance on pristine\nfood images.",
    "descriptor": "",
    "authors": [
      "Ghalib Ahmed Tahir",
      "Chu Kiong Loo",
      "Zongying Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.05853"
  },
  {
    "id": "arXiv:2206.05859",
    "title": "A Directed-Evolution Method for Sparsification and Compression of Neural  Networks with Application to Object Identification and Segmentation and  considerations of optimal quantization using small number of bits",
    "abstract": "This work introduces Directed-Evolution (DE) method for sparsification of\nneural networks, where the relevance of parameters to the network accuracy is\ndirectly assessed and the parameters that produce the least effect on accuracy\nwhen tentatively zeroed are indeed zeroed. DE method avoids a potentially\ncombinatorial explosion of all possible candidate sets of parameters to be\nzeroed in large networks by mimicking evolution in the natural world. DE uses a\ndistillation context [5]. In this context, the original network is the teacher\nand DE evolves the student neural network to the sparsification goal while\nmaintaining minimal divergence between teacher and student. After the desired\nsparsification level is reached in each layer of the network by DE, a variety\nof quantization alternatives are used on the surviving parameters to find the\nlowest number of bits for their representation with acceptable loss of\naccuracy. A procedure to find optimal distribution of quantization levels in\neach sparsified layer is presented. Suitable final lossless encoding of the\nsurviving quantized parameters is used for the final parameter representation.\nDE was used in sample of representative neural networks using MNIST,\nFashionMNIST and COCO data sets with progressive larger networks. An 80 classes\nYOLOv3 with more than 60 million parameters network trained on COCO dataset\nreached 90% sparsification and correctly identifies and segments all objects\nidentified by the original network with more than 80% confidence using 4bit\nparameter quantization. Compression between 40x and 80x. It has not escaped the\nauthors that techniques from different methods can be nested. Once the best\nparameter set for sparsification is identified in a cycle of DE, a decision on\nzeroing only a sub-set of those parameters can be made using a combination of\ncriteria like parameter magnitude and Hessian approximations.",
    "descriptor": "\nComments: 12 pages total, 5 figures, 2 appendices\n",
    "authors": [
      "Luiz M Franca-Neto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.05859"
  },
  {
    "id": "arXiv:2206.05860",
    "title": "IGN : Implicit Generative Networks",
    "abstract": "In this work, we build recent advances in distributional reinforcement\nlearning to give a state-of-art distributional variant of the model based on\nthe IQN. We achieve this by using the GAN model's generator and discriminator\nfunction with the quantile regression to approximate the full quantile value\nfor the state-action return distribution. We demonstrate improved performance\non our baseline dataset - 57 Atari 2600 games in the ALE. Also, we use our\nalgorithm to show the state-of-art training performance of risk-sensitive\npolicies in Atari games with the policy optimization and evaluation.",
    "descriptor": "",
    "authors": [
      "Haozheng Luo",
      "Tianyi Wu",
      "Feiyu Han",
      "Zhijun Yan",
      "Jianfen Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.05860"
  },
  {
    "id": "arXiv:2206.05862",
    "title": "X-Risk Analysis for AI Research",
    "abstract": "Artificial intelligence (AI) has the potential to greatly improve society,\nbut as with any powerful technology, it comes with heightened risks and\nresponsibilities. Current AI research lacks a systematic discussion of how to\nmanage long-tail risks from AI systems, including speculative long-term risks.\nKeeping in mind that AI may be integral to improving humanity's long-term\npotential, there is some concern that building ever more intelligent and\npowerful AI systems could eventually result in systems that are more powerful\nthan us; some say this is like playing with fire and speculate that this could\ncreate existential risks (x-risks). To add precision and ground these\ndiscussions, we review a collection of time-tested concepts from hazard\nanalysis and systems safety, which have been designed to steer large processes\nin safer directions. We then discuss how AI researchers can realistically have\nlong-term impacts on the safety of AI systems. Finally, we discuss how to\nrobustly shape the processes that will affect the balance between safety and\ngeneral capabilities.",
    "descriptor": "",
    "authors": [
      "Dan Hendrycks",
      "Mantas Mazeika"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.05862"
  },
  {
    "id": "arXiv:2206.05866",
    "title": "TC-SfM: Robust Track-Community-Based Structure-from-Motion",
    "abstract": "Structure-from-Motion (SfM) aims to recover 3D scene structures and camera\nposes based on the correspondences between input images, and thus the ambiguity\ncaused by duplicate structures (i.e., different structures with strong visual\nresemblance) always results in incorrect camera poses and 3D structures. To\ndeal with the ambiguity, most existing studies resort to additional constraint\ninformation or implicit inference by analyzing two-view geometries or feature\npoints. In this paper, we propose to exploit high-level information in the\nscene, i.e., the spatial contextual information of local regions, to guide the\nreconstruction. Specifically, a novel structure is proposed, namely,\n{\\textit{track-community}}, in which each community consists of a group of\ntracks and represents a local segment in the scene. A community detection\nalgorithm is used to partition the scene into several segments. Then, the\npotential ambiguous segments are detected by analyzing the neighborhood of\ntracks and corrected by checking the pose consistency. Finally, we perform\npartial reconstruction on each segment and align them with a novel\nbidirectional consistency cost function which considers both 3D-3D\ncorrespondences and pairwise relative camera poses. Experimental results\ndemonstrate that our approach can robustly alleviate reconstruction failure\nresulting from visually indistinguishable structures and accurately merge the\npartial reconstructions.",
    "descriptor": "",
    "authors": [
      "Lei Wang",
      "Linlin Ge",
      "Shan Luo",
      "Zihan Yan",
      "Zhaopeng Cui",
      "Jieqing Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.05866"
  },
  {
    "id": "arXiv:2206.05869",
    "title": "On the Convergence to a Global Solution of Shuffling-Type Gradient  Algorithms",
    "abstract": "Stochastic gradient descent (SGD) algorithm is the method of choice in many\nmachine learning tasks thanks to its scalability and efficiency in dealing with\nlarge-scale problems. In this paper, we focus on the shuffling version of SGD\nwhich matches the mainstream practical heuristics. We show the convergence to a\nglobal solution of shuffling SGD for a class of non-convex functions under\nover-parameterized settings. Our analysis employs more relaxed non-convex\nassumptions than previous literature. Nevertheless, we maintain the desired\ncomputational complexity as shuffling SGD has achieved in the general convex\nsetting.",
    "descriptor": "\nComments: 19 pages, 1 figure\n",
    "authors": [
      "Lam M. Nguyen",
      "Trang H. Tran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.05869"
  },
  {
    "id": "arXiv:2206.05871",
    "title": "Causal Inference-Based Root Cause Analysis for Online Service Systems  with Intervention Recognition",
    "abstract": "Fault diagnosis is critical in many domains, as faults may lead to safety\nthreats or economic losses. In the field of online service systems, operators\nrely on enormous monitoring data to detect and mitigate failures. Quickly\nrecognizing a small set of root cause indicators for the underlying fault can\nsave much time for failure mitigation. In this paper, we formulate the root\ncause analysis problem as a new causal inference task named intervention\nrecognition. We proposed a novel unsupervised causal inference-based method\nnamed Causal Inference-based Root Cause Analysis (CIRCA). The core idea is a\nsufficient condition for a monitoring variable to be a root cause indicator,\ni.e., the change of probability distribution conditioned on the parents in the\nCausal Bayesian Network (CBN). Towards the application in online service\nsystems, CIRCA constructs a graph among monitoring metrics based on the\nknowledge of system architecture and a set of causal assumptions. The\nsimulation study illustrates the theoretical reliability of CIRCA. The\nperformance on a real-world dataset further shows that CIRCA can improve the\nrecall of the top-1 recommendation by 25% over the best baseline method.",
    "descriptor": "\nComments: Accepted at KDD 2022 Applied Data Science Track\n",
    "authors": [
      "Mingjie Li",
      "Zeyan Li",
      "Kanglin Yin",
      "Xiaohui Nie",
      "Wenchi Zhang",
      "Kaixin Sui",
      "Dan Pei"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.05871"
  },
  {
    "id": "arXiv:2206.05872",
    "title": "Resource Allocation and 3D Trajectory Design for Power-Efficient  IRS-Assisted UAV-NOMA Communications",
    "abstract": "In this paper, an intelligent reflecting surface (IRS) is introduced to\nassist an unmanned aerial vehicle (UAV) communication system based on\nnon-orthogonal multiple access (NOMA) for serving multiple ground users. We aim\nto minimize the average total system energy consumption by jointly designing\nthe resource allocation strategy, the three dimensional (3D) trajectory of the\nUAV, as well as the phase control at the IRS. The design is formulated as a\nnon-convex optimization problem taking into account the maximum tolerable\noutage probability constraint and the individual minimum data rate requirement.\nTo circumvent the intractability of the design problem due to the\naltitude-dependent Rician fading in UAV-to-user links, we adopt the deep neural\nnetwork (DNN) approach to accurately approximate the corresponding effective\nchannel gains, which facilitates the development of a low-complexity suboptimal\niterative algorithm via dividing the formulated problem into two subproblems\nand address them alternatingly. Numerical results demonstrate that the proposed\nalgorithm can converge to an effective solution within a small number of\niterations and illustrate some interesting insights: (1) IRS enables a highly\nflexible UAV's 3D trajectory design via recycling the dissipated radio signal\nfor improving the achievable system data rate and reducing the flight power\nconsumption of the UAV; (2) IRS provides a rich array gain through passive\nbeamforming in the reflection link, which can substantially reduce the required\ncommunication power for guaranteeing the required quality-of-service (QoS); (3)\nOptimizing the altitude of UAV's trajectory can effectively exploit the\noutage-guaranteed effective channel gain to save the total required\ncommunication power enabling power-efficient UAV communications.",
    "descriptor": "",
    "authors": [
      "Yuanxin Cai",
      "Zhiqiang Wei",
      "Shaokang Hu",
      "Chang Liu",
      "Derrick Wing Kwan Ng",
      "Jinhong Yuan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.05872"
  },
  {
    "id": "arXiv:2206.05876",
    "title": "Description and Discussion on DCASE 2022 Challenge Task 2: Unsupervised  Anomalous Sound Detection for Machine Condition Monitoring Applying Domain  Generalization Techniques",
    "abstract": "We present the task description of the Detection and Classification of\nAcoustic Scenes and Events (DCASE) 2022 Challenge Task 2: \"Unsupervised\nanomalous sound detection (ASD) for machine condition monitoring applying\ndomain generalization techniques\". Domain shifts are a critical problem for the\napplication of ASD systems. Because domain shifts can change the acoustic\ncharacteristics of data, a model trained in a source domain performs poorly for\na target domain. In DCASE 2021 Challenge Task 2, we organized an ASD task for\nhandling domain shifts. In this task, it was assumed that the occurrences of\ndomain shifts are known. However, in practice, the domain of each sample may\nnot be given, and the domain shifts can occur implicitly. In 2022 Task 2, we\nfocus on domain generalization techniques that detects anomalies regardless of\nthe domain shifts. Specifically, the domain of each sample is not given in the\ntest data and only one threshold is allowed for all domains. We will add\nchallenge results and analysis of the submissions after the challenge\nsubmission deadline.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2106.04492\n",
    "authors": [
      "Kota Dohi",
      "Keisuke Imoto",
      "Noboru Harada",
      "Daisuke Niizumi",
      "Yuma Koizumi",
      "Tomoya Nishida",
      "Harsh Purohit",
      "Takashi Endo",
      "Masaaki Yamamoto",
      "Yohei Kawaguchi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.05876"
  },
  {
    "id": "arXiv:2206.05879",
    "title": "Fair Division with Two-Sided Preferences",
    "abstract": "We study a fair division setting in which a number of players are to be\nfairly distributed among a set of teams. In our model, not only do the teams\nhave preferences over the players as in the canonical fair division setting,\nbut the players also have preferences over the teams. We focus on guaranteeing\nenvy-freeness up to one player (EF1) for the teams together with a stability\ncondition for both sides. We show that an allocation satisfying EF1, swap\nstability, and individual stability always exists and can be computed in\npolynomial time, even when teams may have positive or negative values for\nplayers. Similarly, a balanced and swap stable allocation that satisfies a\nrelaxation of EF1 can be computed efficiently. In addition, when teams have\nnonnegative values for players, we prove that an EF1 and Pareto optimal\nallocation exists, and such an allocation can be found in polynomial time if\nthe valuations are binary.",
    "descriptor": "",
    "authors": [
      "Ayumi Igarashi",
      "Yasushi Kawase",
      "Warut Suksompong",
      "Hanna Sumita"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2206.05879"
  },
  {
    "id": "arXiv:2206.05880",
    "title": "Confident Sinkhorn Allocation for Pseudo-Labeling",
    "abstract": "Semi-supervised learning is a critical tool in reducing machine learning's\ndependence on labeled data. It has, however, been applied primarily to image\nand language data, by exploiting the inherent spatial and semantic structure\ntherein. These methods do not apply to tabular data because these domain\nstructures are not available. Existing pseudo-labeling (PL) methods can be\neffective for tabular data but are vulnerable to noise samples and to greedy\nassignments given a predefined threshold which is unknown. This paper addresses\nthis problem by proposing a Confident Sinkhorn Allocation (CSA), which assigns\nlabels to only samples with high confidence scores and learns the best label\nallocation via optimal transport. CSA outperforms the current state-of-the-art\nin this practically important area.",
    "descriptor": "\nComments: 23 pages\n",
    "authors": [
      "Vu Nguyen",
      "Sachin Farfade",
      "Anton van den Hengel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05880"
  },
  {
    "id": "arXiv:2206.05881",
    "title": "Computation Offloading and Resource Allocation in F-RANs: A Federated  Deep Reinforcement Learning Approach",
    "abstract": "The fog radio access network (F-RAN) is a promising technology in which the\nuser mobile devices (MDs) can offload computation tasks to the nearby fog\naccess points (F-APs). Due to the limited resource of F-APs, it is important to\ndesign an efficient task offloading scheme. In this paper, by considering\ntime-varying network environment, a dynamic computation offloading and resource\nallocation problem in F-RANs is formulated to minimize the task execution delay\nand energy consumption of MDs. To solve the problem, a federated deep\nreinforcement learning (DRL) based algorithm is proposed, where the deep\ndeterministic policy gradient (DDPG) algorithm performs computation offloading\nand resource allocation in each F-AP. Federated learning is exploited to train\nthe DDPG agents in order to decrease the computing complexity of training\nprocess and protect the user privacy. Simulation results show that the proposed\nfederated DDPG algorithm can achieve lower task execution delay and energy\nconsumption of MDs more quickly compared with the other existing strategies.",
    "descriptor": "\nComments: This paper has been accepted by IEEE ICC 2022\n",
    "authors": [
      "Lingling Zhang",
      "Yanxiang Jiang",
      "Fu-Chun Zheng",
      "Mehdi Bennis",
      "Xiaohu You"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.05881"
  },
  {
    "id": "arXiv:2206.05885",
    "title": "Auction-Promoted Trading for Multiple Federated Learning Services in  UAV-Aided Networks",
    "abstract": "Federated learning (FL) represents a promising distributed machine learning\nparadigm that allows smart devices to collaboratively train a shared model via\nproviding local data sets. However, problems considering multiple co-existing\nFL services and different types of service providers are rarely studied. In\nthis paper, we investigate a multiple FL service trading problem in Unmanned\nAerial Vehicle (UAV)-aided networks, where FL service demanders (FLSDs) aim to\npurchase various data sets from feasible clients (smart devices, e.g.,\nsmartphones, smart vehicles), and model aggregation services from UAVs, to\nfulfill their requirements. An auction-based trading market is established to\nfacilitate the trading among three parties, i.e., FLSDs acting as buyers,\ndistributed located client groups acting as data-sellers, and UAVs acting as\nUAV-sellers. The proposed auction is formalized as a 0-1 integer programming\nproblem, aiming to maximize the overall buyers' revenue via investigating\nwinner determination and payment rule design. Specifically, since two seller\ntypes (data-sellers and UAV-sellers) are considered, an interesting idea\nintegrating seller pair and joint bid is introduced, which turns diverse\nsellers into virtual seller pairs. Vickrey-Clarke-Groves (VCG)-based, and\none-sided matching-based mechanisms are proposed, respectively, where the\nformer achieves the optimal solutions, which, however, is computationally\nintractable. While the latter can obtain suboptimal solutions that approach to\nthe optimal ones, with low computational complexity, especially upon\nconsidering a large number of participants. Significant properties such as\ntruthfulness and individual rationality are comprehensively analyzed for both\nmechanisms. Extensive experimental results verify the properties and\ndemonstrate that our proposed mechanisms outperform representative methods\nsignificantly.",
    "descriptor": "\nComments: 14 pages,6 figures\n",
    "authors": [
      "Zhipeng Cheng",
      "Minghui Liwang",
      "Xiaoyu Xia",
      "Minghui Min",
      "Xianbin Wang",
      "Xiaojiang Du"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2206.05885"
  },
  {
    "id": "arXiv:2206.05888",
    "title": "Adaptive Multi-robot Implicit Control of Heterogeneous Herds",
    "abstract": "This paper presents a novel control strategy to herd groups of\nnon-cooperative evaders by means of a team of robotic herders. In herding\nproblems, the motion of the evaders is typically determined by strongly\nnonlinear and heterogeneous reactive dynamics, which makes the development of\nflexible control solutions a challenging problem. In this context, we propose\nImplicit Control, an approach that leverages numerical analysis theory to find\nsuitable herding inputs even when the nonlinearities in the evaders' dynamics\nyield to implicit equations. The intuition behind this methodology consists in\ndriving the input, rather than computing it, towards the unknown value that\nachieves the desired dynamic behavior of the herd. The same idea is exploited\nto develop an adaptation law, with stability guarantees, that copes with\nuncertainties in the herd's models. Moreover, our solution is completed with a\nnovel caging technique based on uncertainty models and Control Barrier\nFunctions (CBFs), together with a distributed estimator to overcome the need of\ncomplete perfect measurements. Different simulations and experiments validate\nthe generality and flexibility of the proposal.",
    "descriptor": "\nComments: This paper has been accepted for publication in the IEEE Transactions on Robotics\n",
    "authors": [
      "Eduardo Sebasti\u00e1n",
      "Eduardo Montijano",
      "Carlos Sag\u00fc\u00e9s"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.05888"
  },
  {
    "id": "arXiv:2206.05891",
    "title": "Accelerating Federated Learning via Sampling Anchor Clients with Large  Batches",
    "abstract": "Using large batches in recent federated learning studies has improved\nconvergence rates, but it requires additional computation overhead compared to\nusing small batches. To overcome this limitation, we propose a unified\nframework FedAMD, which disjoints the participants into anchor and miner groups\nbased on time-varying probabilities. Each client in the anchor group computes\nthe gradient using a large batch, which is regarded as its bullseye. Clients in\nthe miner group perform multiple local updates using serial mini-batches, and\neach local update is also indirectly regulated by the global target derived\nfrom the average of clients' bullseyes. As a result, the miner group follows a\nnear-optimal update towards the global minimizer, adapted to update the global\nmodel. Measured by $\\epsilon$-approximation, FedAMD achieves a convergence rate\nof $O(1/\\epsilon)$ under non-convex objectives by sampling an anchor with a\nconstant probability. The theoretical result considerably surpasses the\nstate-of-the-art algorithm BVR-L-SGD at $O(1/\\epsilon^{3/2})$, while FedAMD\nreduces at least $O(1/\\epsilon)$ communication overhead. Empirical studies on\nreal-world datasets validate the effectiveness of FedAMD and demonstrate the\nsuperiority of our proposed algorithm.",
    "descriptor": "",
    "authors": [
      "Feijie Wu",
      "Song Guo",
      "Zhihao Qu",
      "Shiqi He",
      "Ziming Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.05891"
  },
  {
    "id": "arXiv:2206.05893",
    "title": "Deploying Convolutional Networks on Untrusted Platforms Using 2D  Holographic Reduced Representations",
    "abstract": "Due to the computational cost of running inference for a neural network, the\nneed to deploy the inferential steps on a third party's compute environment or\nhardware is common. If the third party is not fully trusted, it is desirable to\nobfuscate the nature of the inputs and outputs, so that the third party can not\neasily determine what specific task is being performed. Provably secure\nprotocols for leveraging an untrusted party exist but are too computational\ndemanding to run in practice. We instead explore a different strategy of fast,\nheuristic security that we call Connectionist Symbolic Pseudo Secrets. By\nleveraging Holographic Reduced Representations (HRR), we create a neural\nnetwork with a pseudo-encryption style defense that empirically shows\nrobustness to attack, even under threat models that unrealistically favor the\nadversary.",
    "descriptor": "\nComments: To appear in the Proceedings of the 39 th International Conference on Machine Learning, Baltimore, Maryland, USA, PMLR 162, 2022\n",
    "authors": [
      "Mohammad Mahmudul Alam",
      "Edward Raff",
      "Tim Oates",
      "James Holt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.05893"
  },
  {
    "id": "arXiv:2206.05894",
    "title": "Content Popularity Prediction in Fog-RANs: A Clustered Federated  Learning Based Approach",
    "abstract": "In this paper, the content popularity prediction problem in fog radio access\nnetworks (F-RANs) is investigated. Based on clustered federated learning, we\npropose a novel mobility-aware popularity prediction policy, which integrates\ncontent popularities in terms of local users and mobile users. For local users,\nthe content popularity is predicted by learning the hidden representations of\nlocal users and contents. Initial features of local users and contents are\ngenerated by incorporating neighbor information with self information. Then,\ndual-channel neural network (DCNN) model is introduced to learn the hidden\nrepresentations by producing deep latent features from initial features. For\nmobile users, the content popularity is predicted via user preference learning.\nIn order to distinguish regional variations of content popularity, clustered\nfederated learning (CFL) is employed, which enables fog access points (F-APs)\nwith similar regional types to benefit from one another and provides a more\nspecialized DCNN model for each F-AP. Simulation results show that our proposed\npolicy achieves significant performance improvement over the traditional\npolicies.",
    "descriptor": "\nComments: 6 pages, 3 figures. This paper has been accepted by IEEE ICC 2022\n",
    "authors": [
      "Zhiheng Wang",
      "Yanxiang Jiang",
      "Fu-Chun Zheng",
      "Mehdi Bennis",
      "Xiaohu You"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.05894"
  },
  {
    "id": "arXiv:2206.05895",
    "title": "Latent Diffusion Energy-Based Model for Interpretable Text Modeling",
    "abstract": "Latent space Energy-Based Models (EBMs), also known as energy-based priors,\nhave drawn growing interests in generative modeling. Fueled by its flexibility\nin the formulation and strong modeling power of the latent space, recent works\nbuilt upon it have made interesting attempts aiming at the interpretability of\ntext modeling. However, latent space EBMs also inherit some flaws from EBMs in\ndata space; the degenerate MCMC sampling quality in practice can lead to poor\ngeneration quality and instability in training, especially on data with complex\nlatent structures. Inspired by the recent efforts that leverage diffusion\nrecovery likelihood learning as a cure for the sampling issue, we introduce a\nnovel symbiosis between the diffusion models and latent space EBMs in a\nvariational learning framework, coined as the latent diffusion energy-based\nmodel. We develop a geometric clustering-based regularization jointly with the\ninformation bottleneck to further improve the quality of the learned latent\nspace. Experiments on several challenging tasks demonstrate the superior\nperformance of our model on interpretable text modeling over strong\ncounterparts.",
    "descriptor": "\nComments: ICML 2022\n",
    "authors": [
      "Peiyu Yu",
      "Sirui Xie",
      "Xiaojian Ma",
      "Baoxiong Jia",
      "Bo Pang",
      "Ruigi Gao",
      "Yixin Zhu",
      "Song-Chun Zhu",
      "Ying Nian Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.05895"
  },
  {
    "id": "arXiv:2206.05896",
    "title": "Improve Ranking Correlation of Super-net through Training Scheme from  One-shot NAS to Few-shot NAS",
    "abstract": "The algorithms of one-shot neural architecture search (NAS) have been widely\nused to reduce the computation. However, because of the interference among the\nsubnets which weights are shared, the subnets inherited from these super-net\ntrained by those algorithms have poor consistency in precision ranking. To\naddress this problem, we propose a step-by-step training super-net scheme from\none-shot NAS to few-shot NAS. In the training scheme, we training super-net by\nthe one-shot way firstly, and then we disentangles the weights of super-net by\nsplitting that to multi-subnets and training them gradually. Finally, our\nmethod ranks 4th place in the CVPR2022 Lightweight NAS Challenge Track1. Our\ncode is available at\nhttps://github.com/liujiawei2333/CVPR2022-NAScompetition-Track-1-4th-solution.",
    "descriptor": "",
    "authors": [
      "Jiawei Liu",
      "Kaiyu Zhang",
      "Weitai Hu",
      "Qing Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.05896"
  },
  {
    "id": "arXiv:2206.05897",
    "title": "GradICON: Approximate Diffeomorphisms via Gradient Inverse Consistency",
    "abstract": "Many registration approaches exist with early work focusing on\noptimization-based approaches for image pairs. Recent work focuses on deep\nregistration networks to predict spatial transformations. In both cases,\ncommonly used non-parametric registration models, which estimate transformation\nfunctions instead of low-dimensional transformation parameters, require\nchoosing a suitable regularizer (to encourage smooth transformations) and its\nparameters. This makes models difficult to tune and restricts deformations to\nthe deformation space permissible by the chosen regularizer. While\ndeep-learning models for optical flow exist that do not regularize\ntransformations and instead entirely rely on the data these might not yield\ndiffeomorphic transformations which are desirable for medical image\nregistration. In this work, we therefore develop GradICON building upon the\nunsupervised ICON deep-learning registration approach, which only uses\ninverse-consistency for regularization. However, in contrast to ICON, we prove\nand empirically verify that using a gradient inverse-consistency loss not only\nsignificantly improves convergence, but also results in a similar implicit\nregularization of the resulting transformation map. Synthetic experiments and\nexperiments on magnetic resonance (MR) knee images and computed tomography (CT)\nlung images show the excellent performance of GradICON. We achieve\nstate-of-the-art (SOTA) accuracy while retaining a simple registration\nformulation, which is practically important.",
    "descriptor": "",
    "authors": [
      "Lin Tian",
      "Hastings Greer",
      "Fran\u00e7ois-Xavier Vialard",
      "Roland Kwitt",
      "Ra\u00fal San Jos\u00e9 Est\u00e9par",
      "Marc Niethammer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.05897"
  },
  {
    "id": "arXiv:2206.05898",
    "title": "Pixel to Binary Embedding Towards Robustness for CNNs",
    "abstract": "There are several problems with the robustness of Convolutional Neural\nNetworks (CNNs). For example, the prediction of CNNs can be changed by adding a\nsmall magnitude of noise to an input, and the performances of CNNs are degraded\nwhen the distribution of input is shifted by a transformation never seen during\ntraining (e.g., the blur effect). There are approaches to replace pixel values\nwith binary embeddings to tackle the problem of adversarial perturbations,\nwhich successfully improve robustness. In this work, we propose Pixel to Binary\nEmbedding (P2BE) to improve the robustness of CNNs. P2BE is a learnable binary\nembedding method as opposed to previous hand-coded binary embedding methods.\nP2BE outperforms other binary embedding methods in robustness against\nadversarial perturbations and visual corruptions that are not shown during\ntraining.",
    "descriptor": "\nComments: Accepted to ICPR2022\n",
    "authors": [
      "Ikki Kishida",
      "Hideki Nakayama"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05898"
  },
  {
    "id": "arXiv:2206.05900",
    "title": "Provable Benefit of Multitask Representation Learning in Reinforcement  Learning",
    "abstract": "As representation learning becomes a powerful technique to reduce sample\ncomplexity in reinforcement learning (RL) in practice, theoretical\nunderstanding of its advantage is still limited. In this paper, we\ntheoretically characterize the benefit of representation learning under the\nlow-rank Markov decision process (MDP) model. We first study multitask low-rank\nRL (as upstream training), where all tasks share a common representation, and\npropose a new multitask reward-free algorithm called REFUEL. REFUEL learns both\nthe transition kernel and the near-optimal policy for each task, and outputs a\nwell-learned representation for downstream tasks. Our result demonstrates that\nmultitask representation learning is provably more sample-efficient than\nlearning each task individually, as long as the total number of tasks is above\na certain threshold. We then study the downstream RL in both online and offline\nsettings, where the agent is assigned with a new task sharing the same\nrepresentation as the upstream tasks. For both online and offline settings, we\ndevelop a sample-efficient algorithm, and show that it finds a near-optimal\npolicy with the suboptimality gap bounded by the sum of the estimation error of\nthe learned representation in upstream and a vanishing term as the number of\ndownstream samples becomes large. Our downstream results of online and offline\nRL further capture the benefit of employing the learned representation from\nupstream as opposed to learning the representation of the low-rank model\ndirectly. To the best of our knowledge, this is the first theoretical study\nthat characterizes the benefit of representation learning in exploration-based\nreward-free multitask RL for both upstream and downstream tasks.",
    "descriptor": "\nComments: Submitted for publication\n",
    "authors": [
      "Yuan Cheng",
      "Songtao Feng",
      "Jing Yang",
      "Hong Zhang",
      "Yingbin Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.05900"
  },
  {
    "id": "arXiv:2206.05903",
    "title": "Geometrically Guided Integrated Gradients",
    "abstract": "Interpretability methods for deep neural networks mainly focus on the\nsensitivity of the class score with respect to the original or perturbed input,\nusually measured using actual or modified gradients. Some methods also use a\nmodel-agnostic approach to understanding the rationale behind every prediction.\nIn this paper, we argue and demonstrate that local geometry of the model\nparameter space relative to the input can also be beneficial for improved\npost-hoc explanations. To achieve this goal, we introduce an interpretability\nmethod called \"geometrically-guided integrated gradients\" that builds on top of\nthe gradient calculation along a linear path as traditionally used in\nintegrated gradient methods. However, instead of integrating gradient\ninformation, our method explores the model's dynamic behavior from multiple\nscaled versions of the input and captures the best possible attribution for\neach input. We demonstrate through extensive experiments that the proposed\napproach outperforms vanilla and integrated gradients in subjective and\nquantitative assessment. We also propose a \"model perturbation\" sanity check to\ncomplement the traditionally used \"model randomization\" test.",
    "descriptor": "\nComments: 18 pages, 23 Figures\n",
    "authors": [
      "Md Mahfuzur Rahman",
      "Noah Lewis",
      "Sergey Plis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05903"
  },
  {
    "id": "arXiv:2206.05904",
    "title": "Superiority of GNN over NN in generalizing bandlimited functions",
    "abstract": "We constructively show, via rigorous mathematical arguments, that GNN\narchitectures outperform those of NN in approximating bandlimited functions on\ncompact $d$-dimensional Euclidean grids. We show that the former only need\n$\\mathcal{M}$ sampled functional values in order to achieve a uniform\napproximation error of $O_{d}(2^{-\\mathcal{M}^{1/d}})$ and that this error rate\nis optimal, in the sense that, NNs might achieve worse.",
    "descriptor": "",
    "authors": [
      "A. Martina Neuman",
      "Rongrong Wang",
      "Yuying Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.05904"
  },
  {
    "id": "arXiv:2206.05909",
    "title": "Local distance preserving auto-encoders using Continuous k-Nearest  Neighbours graphs",
    "abstract": "Auto-encoder models that preserve similarities in the data are a popular tool\nin representation learning. In this paper we introduce several auto-encoder\nmodels that preserve local distances when mapping from the data space to the\nlatent space. We use a local distance preserving loss that is based on the\ncontinuous k-nearest neighbours graph which is known to capture topological\nfeatures at all scales simultaneously. To improve training performance, we\nformulate learning as a constraint optimisation problem with local distance\npreservation as the main objective and reconstruction accuracy as a constraint.\nWe generalise this approach to hierarchical variational auto-encoders thus\nlearning generative models with geometrically consistent latent and data\nspaces. Our method provides state-of-the-art performance across several\nstandard datasets and evaluation metrics.",
    "descriptor": "",
    "authors": [
      "Nutan Chen",
      "Patrick van der Smagt",
      "Botond Cseke"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05909"
  },
  {
    "id": "arXiv:2206.05912",
    "title": "INDIGO: Intrinsic Multimodality for Domain Generalization",
    "abstract": "For models to generalize under unseen domains (a.k.a domain generalization),\nit is crucial to learn feature representations that are domain-agnostic and\ncapture the underlying semantics that makes up an object category. Recent\nadvances towards weakly supervised vision-language models that learn holistic\nrepresentations from cheap weakly supervised noisy text annotations have shown\ntheir ability on semantic understanding by capturing object characteristics\nthat generalize under different domains. However, when multiple source domains\nare involved, the cost of curating textual annotations for every image in the\ndataset can blow up several times, depending on their number. This makes the\nprocess tedious and infeasible, hindering us from directly using these\nsupervised vision-language approaches to achieve the best generalization on an\nunseen domain. Motivated from this, we study how multimodal information from\nexisting pre-trained multimodal networks can be leveraged in an \"intrinsic\" way\nto make systems generalize under unseen domains. To this end, we propose\nIntriNsic multimodality for DomaIn GeneralizatiOn (INDIGO), a simple and\nelegant way of leveraging the intrinsic modality present in these pre-trained\nmultimodal networks along with the visual modality to enhance generalization to\nunseen domains at test-time. We experiment on several Domain Generalization\nsettings (ClosedDG, OpenDG, and Limited sources) and show state-of-the-art\ngeneralization performance on unseen domains. Further, we provide a thorough\nanalysis to develop a holistic understanding of INDIGO.",
    "descriptor": "\nComments: Under Submission\n",
    "authors": [
      "Puneet Mangla",
      "Shivam Chandhok",
      "Milan Aggarwal",
      "Vineeth N Balasubramanian",
      "Balaji Krishnamurthy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.05912"
  },
  {
    "id": "arXiv:2206.05916",
    "title": "Why Quantization Improves Generalization: NTK of Binary Weight Neural  Networks",
    "abstract": "Quantized neural networks have drawn a lot of attention as they reduce the\nspace and computational complexity during the inference. Moreover, there has\nbeen folklore that quantization acts as an implicit regularizer and thus can\nimprove the generalizability of neural networks, yet no existing work\nformalizes this interesting folklore. In this paper, we take the binary weights\nin a neural network as random variables under stochastic rounding, and study\nthe distribution propagation over different layers in the neural network. We\npropose a quasi neural network to approximate the distribution propagation,\nwhich is a neural network with continuous parameters and smooth activation\nfunction. We derive the neural tangent kernel (NTK) for this quasi neural\nnetwork, and show that the eigenvalue of NTK decays at approximately\nexponential rate, which is comparable to that of Gaussian kernel with\nrandomized scale. This in turn indicates that the Reproducing Kernel Hilbert\nSpace (RKHS) of a binary weight neural network covers a strict subset of\nfunctions compared with the one with real value weights. We use experiments to\nverify that the quasi neural network we proposed can well approximate binary\nweight neural network. Furthermore, binary weight neural network gives a lower\ngeneralization gap compared with real value weight neural network, which is\nsimilar to the difference between Gaussian kernel and Laplace kernel.",
    "descriptor": "\nComments: 44 pages, 4 figures\n",
    "authors": [
      "Kaiqi Zhang",
      "Ming Yin",
      "Yu-Xiang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05916"
  },
  {
    "id": "arXiv:2206.05917",
    "title": "Signed interval graphs and bigraphs: A generalization of interval graphs  and bigraphs",
    "abstract": "In this paper, we define and characterize signed interval graphs and bigraphs\nintroducing the concept of negative interval. Also we have shown that these\nclasses of graphs are respectively a generalization of well known classes of\ninterval graphs and interval bigraphs. In this context we have observed that\nsigned interval graphs coincide with the complement of Threshold tolerance\ngraphs(co-TT graphs) introduced by Monma, Reed and Trotter \\cite{22}. Finally,\nwe have solved the open problem of forbidden induced subgraph characterization\nof co-TT graphs posed by them in the same paper.",
    "descriptor": "",
    "authors": [
      "Ashok Kumar Das",
      "Indrajit Paul"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2206.05917"
  },
  {
    "id": "arXiv:2206.05922",
    "title": "From Perception to Programs: Regularize, Overparameterize, and Amortize",
    "abstract": "Toward combining inductive reasoning with perception abilities, we develop\ntechniques for neurosymbolic program synthesis where perceptual input is first\nparsed by neural nets into a low-dimensional interpretable representation,\nwhich is then processed by a synthesized program. We explore several techniques\nfor relaxing the problem and jointly learning all modules end-to-end with\ngradient descent: multitask learning; amortized inference;\noverparameterization; and a differentiable strategy for penalizing lengthy\nprograms. Collectedly this toolbox improves the stability of gradient-guided\nprogram search, and suggests ways of learning both how to perceive input as\ndiscrete abstractions, and how to symbolically process those abstractions as\nprograms.",
    "descriptor": "",
    "authors": [
      "Hao Tang",
      "Kevin Ellis"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.05922"
  },
  {
    "id": "arXiv:2206.05927",
    "title": "LinK3D: Linear Keypoints Representation for 3D LiDAR Point Cloud",
    "abstract": "Feature extraction and matching are the basic parts of many computer vision\ntasks, such as 2D or 3D object detection, recognition, and registration. As we\nall know, 2D feature extraction and matching have already been achieved great\nsuccess. Unfortunately, in the field of 3D, the current methods fail to support\nthe extensive application of 3D LiDAR sensors in vision tasks, due to the poor\ndescriptiveness and inefficiency. To address this limitation, we propose a\nnovel 3D feature representation method: Linear Keypoints representation for 3D\nLiDAR point cloud, called LinK3D. The novelty of LinK3D lies in that it fully\nconsiders the characteristics (such as sparsity, complexity of scenarios) of\nLiDAR point cloud, and represents current keypoint with its robust neighbor\nkeypoints, which provide strong constraint on the description of current\nkeypoint. The proposed LinK3D has been evaluated on two public datasets (i.e.,\nKITTI, Steven VLP16), and the experimental results show that our method greatly\noutperforms the state-of-the-arts in matching performance. More importantly,\nLinK3D shows excellent real-time performance (based on the frequence 10 Hz of\nLiDAR). LinK3D only takes an average of 32 milliseconds to extract features\nfrom the point cloud collected by a 64-ray laser beam, and takes merely about 8\nmilliseconds to match two LiDAR scans when executed in a notebook with an Intel\nCore i7 @2.2 GHz processor. Moreover, our method can be widely extended to a\nvariety of 3D vision applications. In this paper, we has applied our LinK3D to\n3D registration, LiDAR odometry and place recognition tasks, and achieved\ncompetitive results compared with the state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Yunge Cui",
      "Yinlong Zhang",
      "Jiahua Dong",
      "Haibo Sun",
      "Feng Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.05927"
  },
  {
    "id": "arXiv:2206.05928",
    "title": "Compressive Clustering with an Optical Processing Unit",
    "abstract": "We explore the use of Optical Processing Units (OPU) to compute random\nFourier features for sketching, and adapt the overall compressive clustering\npipeline to this setting. We also propose some tools to help tuning a critical\nhyper-parameter of compressive clustering.",
    "descriptor": "",
    "authors": [
      "Luc Giffon",
      "R\u00e9mi Gribonval"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.05928"
  },
  {
    "id": "arXiv:2206.05929",
    "title": "Improvement of Serial Approach to Anomalous Sound Detection by  Incorporating Two Binary Cross-Entropies for Outlier Exposure",
    "abstract": "Anomalous sound detection systems must detect unknown, atypical sounds using\nonly normal audio data. Conventional methods use the serial method, a\ncombination of outlier exposure (OE), which classifies normal and\npseudo-anomalous data and obtains embedding, and inlier modeling (IM), which\nmodels the probability distribution of the embedding. Although the serial\nmethod shows high performance due to the powerful feature extraction of OE and\nthe robustness of IM, OE still has a problem that doesn't work well when the\nnormal and pseudo-anomalous data are too similar or too different. To\nexplicitly distinguish these data, the proposed method uses multi-task learning\nof two binary cross-entropies when training OE. The first is a loss that\nclassifies the sound of the target machine to which product it is emitted from,\nwhich deals with the case where the normal data and the pseudo-anomalous data\nare too similar. The second is a loss that identifies whether the sound is\nemitted from the target machine or not, which deals with the case where the\nnormal data and the pseudo-anomalous data are too different. We perform our\nexperiments with DCASE 2021 Task~2 dataset. Our proposed single-model method\noutperforms the top-ranked method, which combines multiple models, by 2.1% in\nAUC.",
    "descriptor": "\nComments: 5 pages, 3 figures, 3 tables, EUSIPCO 2022\n",
    "authors": [
      "Ibuki Kuroyanagi",
      "Tomoki Hayashi",
      "Kazuya Takeda",
      "Tomoki Toda"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.05929"
  },
  {
    "id": "arXiv:2206.05930",
    "title": "Faster Optimization-Based Meta-Learning Adaptation Phase",
    "abstract": "Neural networks require a large amount of annotated data to learn.\nMeta-learning algorithms propose a way to decrease the number of training\nsamples to only a few. One of the most prominent optimization-based\nmeta-learning algorithms is Model-Agnostic Meta-Learning (MAML). However, the\nkey procedure of adaptation to new tasks in MAML is quite slow. In this work we\npropose an improvement to MAML meta-learning algorithm. We introduce Lambda\npatterns by which we restrict which weight are updated in the network during\nthe adaptation phase. This makes it possible to skip certain gradient\ncomputations. The fastest pattern is selected given an allowed quality\ndegradation threshold parameter. In certain cases, quality improvement is\npossible by a careful pattern selection. The experiments conducted have shown\nthat via Lambda adaptation pattern selection, it is possible to significantly\nimprove the MAML method in the following areas: adaptation time has been\ndecreased by a factor of 3 with minimal accuracy loss; accuracy for one-step\nadaptation has been substantially improved.",
    "descriptor": "",
    "authors": [
      "Kostiantyn Khabarlak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.05930"
  },
  {
    "id": "arXiv:2206.05941",
    "title": "Towards Universal Sequence Representation Learning for Recommender  Systems",
    "abstract": "In order to develop effective sequential recommenders, a series of sequence\nrepresentation learning (SRL) methods are proposed to model historical user\nbehaviors. Most existing SRL methods rely on explicit item IDs for developing\nthe sequence models to better capture user preference. Though effective to some\nextent, these methods are difficult to be transferred to new recommendation\nscenarios, due to the limitation by explicitly modeling item IDs. To tackle\nthis issue, we present a novel universal sequence representation learning\napproach, named UniSRec. The proposed approach utilizes the associated\ndescription text of items to learn transferable representations across\ndifferent recommendation scenarios. For learning universal item\nrepresentations, we design a lightweight item encoding architecture based on\nparametric whitening and mixture-of-experts enhanced adaptor. For learning\nuniversal sequence representations, we introduce two contrastive pre-training\ntasks by sampling multi-domain negatives. With the pre-trained universal\nsequence representation model, our approach can be effectively transferred to\nnew recommendation domains or platforms in a parameter-efficient way, under\neither inductive or transductive settings. Extensive experiments conducted on\nreal-world datasets demonstrate the effectiveness of the proposed approach.\nEspecially, our approach also leads to a performance improvement in a\ncross-platform setting, showing the strong transferability of the proposed\nuniversal SRL method. The code and pre-trained model are available at:\nhttps://github.com/RUCAIBox/UniSRec.",
    "descriptor": "\nComments: Accepted by KDD 2022 Research Track\n",
    "authors": [
      "Yupeng Hou",
      "Shanlei Mu",
      "Wayne Xin Zhao",
      "Yaliang Li",
      "Bolin Ding",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05941"
  },
  {
    "id": "arXiv:2206.05942",
    "title": "Private Synthetic Data with Hierarchical Structure",
    "abstract": "We study the problem of differentially private synthetic data generation for\nhierarchical datasets in which individual data points are grouped together\n(e.g., people within households). In particular, to measure the similarity\nbetween the synthetic dataset and the underlying private one, we frame our\nobjective under the problem of private query release, generating a synthetic\ndataset that preserves answers for some collection of queries (i.e., statistics\nlike mean aggregate counts). However, while the application of private\nsynthetic data to the problem of query release has been well studied, such\nresearch is restricted to non-hierarchical data domains, raising the initial\nquestion -- what queries are important when considering data of this form?\nMoreover, it has not yet been established how one can generate synthetic data\nat both the group and individual-level while capturing such statistics. In\nlight of these challenges, we first formalize the problem of hierarchical query\nrelease, in which the goal is to release a collection of statistics for some\nhierarchical dataset. Specifically, we provide a general set of statistical\nqueries that captures relationships between attributes at both the group and\nindividual-level. Subsequently, we introduce private synthetic data algorithms\nfor hierarchical query release and evaluate them on hierarchical datasets\nderived from the American Community Survey and Allegheny Family Screening Tool\ndata. Finally, we look to the American Community Survey, whose inherent\nhierarchical structure gives rise to another set of domain-specific queries\nthat we run experiments with.",
    "descriptor": "",
    "authors": [
      "Terrance Liu",
      "Zhiwei Steven Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05942"
  },
  {
    "id": "arXiv:2206.05947",
    "title": "Lazy and Fast Greedy MAP Inference for Determinantal Point Process",
    "abstract": "The maximum a posteriori (MAP) inference for determinantal point processes\n(DPPs) is crucial for selecting diverse items in many machine learning\napplications. Although DPP MAP inference is NP-hard, the greedy algorithm often\nfinds high-quality solutions, and many researchers have studied its efficient\nimplementation. One classical and practical method is the lazy greedy\nalgorithm, which is applicable to general submodular function maximization,\nwhile a recent fast greedy algorithm based on the Cholesky factorization is\nmore efficient for DPP MAP inference. This paper presents how to combine the\nideas of \"lazy\" and \"fast\", which have been considered incompatible in the\nliterature. Our lazy and fast greedy algorithm achieves almost the same time\ncomplexity as the current best one and runs faster in practice. The idea of\n\"lazy + fast\" is extendable to other greedy-type algorithms. We also give a\nfast version of the double greedy algorithm for unconstrained DPP MAP\ninference. Experiments validate the effectiveness of our acceleration ideas.",
    "descriptor": "",
    "authors": [
      "Shinichi Hemmi",
      "Taihei Oki",
      "Shinsaku Sakaue",
      "Kaito Fujii",
      "Satoru Iwata"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05947"
  },
  {
    "id": "arXiv:2206.05949",
    "title": "Toward Ambient Intelligence: Federated Edge Learning with Task-Oriented  Sensing, Computation, and Communication Integration",
    "abstract": "In this paper, we address the problem of joint sensing, computation, and\ncommunication (SC$^{2}$) resource allocation for federated edge learning (FEEL)\nvia a concrete case study of human motion recognition based on wireless sensing\nin ambient intelligence. First, by analyzing the wireless sensing process in\nhuman motion recognition, we find that there exists a thresholding value for\nthe sensing transmit power, exceeding which yields sensing data samples with\napproximately the same satisfactory quality. Then, the joint SC$^{2}$ resource\nallocation problem is cast to maximize the convergence speed of FEEL, under the\nconstraints on training time, energy supply, and sensing quality of each edge\ndevice. Solving this problem entails solving two subproblems in order: the\nfirst one reduces to determine the joint sensing and communication resource\nallocation that maximizes the total number of samples that can be sensed during\nthe entire training process; the second one concerns the partition of the\nattained total number of sensed samples over all the communication rounds to\ndetermine the batch size at each round for convergence speed maximization. The\nfirst subproblem on joint sensing and communication resource allocation is\nconverted to a single-variable optimization problem by exploiting the derived\nrelation between different control variables (resources), which thus allows an\nefficient solution via one-dimensional grid search. For the second subproblem,\nit is found that the number of samples to be sensed (or batch size) at each\nround is a decreasing function of the loss function value attained at the\nround. Based on this relationship, the approximate optimal batch size at each\ncommunication round is derived in closed-form as a function of the round index.\nFinally, extensive simulation results are provided to validate the superiority\nof the proposed joint SC$^{2}$ resource allocation scheme.",
    "descriptor": "\nComments: 13 pages, submitted to IEEE for possible publication\n",
    "authors": [
      "Peixi Liu",
      "Guangxu Zhu",
      "Shuai Wang",
      "Wei Jiang",
      "Wu Luo",
      "H. Vincent Poor",
      "Shuguang Cui"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.05949"
  },
  {
    "id": "arXiv:2206.05950",
    "title": "Deadline-constrained Multi-resource Task Mapping and Allocation for  Edge-Cloud Systems",
    "abstract": "In an edge-cloud system, mobile devices can offload their computation\nintensive tasks to an edge or cloud server to guarantee the quality of service\nor satisfy task deadline requirements. However, it is challenging to determine\nwhere tasks should be offloaded and processed, and how much network and\ncomputation resources should be allocated to them, such that a system with\nlimited resources can obtain a maximum profit while meeting the deadlines. A\nkey challenge in this problem is that the network and computation resources\ncould be allocated on different servers, since the server to which a task is\noffloaded (e.g., a server with an access point) may be different from the\nserver on which the task is eventually processed. To address this challenge, we\nfirst formulate the task mapping and resource allocation problem as a\nnon-convex Mixed-Integer Nonlinear Programming (MINLP) problem, known as\nNP-hard. We then propose a zero-slack based greedy algorithm (ZSG) and a linear\ndiscretization method (LDM) to solve this MINLP problem. Experiment results\nwith various synthetic tasksets show that ZSG has an average of $2.98\\%$ worse\nperformance than LDM with a minimum unit of 5 but has an average of $6.88\\%$\nbetter performance than LDM with a minimum unit of 15.",
    "descriptor": "",
    "authors": [
      "Chuanchao Gao",
      "Aryaman Shaan",
      "Arvind Easwaran"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.05950"
  },
  {
    "id": "arXiv:2206.05952",
    "title": "SIXO: Smoothing Inference with Twisted Objectives",
    "abstract": "Sequential Monte Carlo (SMC) is an inference algorithm for state space models\nthat approximates the posterior by sampling from a sequence of intermediate\ntarget distributions. The target distributions are often chosen to be the\nfiltering distributions, but these ignore information from future observations,\nleading to practical and theoretical limitations in inference and model\nlearning. We introduce SIXO, a method that instead learns targets that\napproximate the smoothing distributions, incorporating information from all\nobservations. The key idea is to use density ratio estimation to fit functions\nthat warp the filtering distributions into the smoothing distributions. We then\nuse SMC with these learned targets to define a variational objective for model\nand proposal learning. SIXO yields provably tighter log marginal lower bounds\nand offers significantly more accurate posterior inferences and parameter\nestimates in a variety of domains.",
    "descriptor": "",
    "authors": [
      "Dieterich Lawson",
      "Allan Ravent\u00f3s",
      "Andrew Warrington",
      "Scott Linderman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.05952"
  },
  {
    "id": "arXiv:2206.05954",
    "title": "Scalable Exploration for Neural Online Learning to Rank with Perturbed  Feedback",
    "abstract": "Deep neural networks (DNNs) demonstrate significant advantages in improving\nranking performance in retrieval tasks. Driven by the recent technical\ndevelopments in optimization and generalization of DNNs, learning a neural\nranking model online from its interactions with users becomes possible.\nHowever, the required exploration for model learning has to be performed in the\nentire neural network parameter space, which is prohibitively expensive and\nlimits the application of such online solutions in practice.\nIn this work, we propose an efficient exploration strategy for online\ninteractive neural ranker learning based on the idea of bootstrapping. Our\nsolution employs an ensemble of ranking models trained with perturbed user\nclick feedback. The proposed method eliminates explicit confidence set\nconstruction and the associated computational overhead, which enables the\nonline neural rankers' training to be efficiently executed in practice with\ntheoretical guarantees. Extensive comparisons with an array of state-of-the-art\nOL2R algorithms on two public learning to rank benchmark datasets demonstrate\nthe effectiveness and computational efficiency of our proposed neural OL2R\nsolution.",
    "descriptor": "",
    "authors": [
      "Yiling Jia",
      "Hongning Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.05954"
  },
  {
    "id": "arXiv:2206.05957",
    "title": "The $\\aleph$-Calculus: A declarative model of reversible programming",
    "abstract": "A novel model of reversible computing, the $\\aleph$-calculus, is introduced.\nIt is declarative, reversible-Turing complete, and has a local term-rewriting\nsemantics. Unlike previously demonstrated reversible term-rewriting systems, it\ndoes not require the accumulation of history data. Terms in the\n$\\aleph$-calculus, in combination with the program definitions, encapsulate all\nprogram state. An interpreter was also written.",
    "descriptor": "\nComments: 7 pages, 1 listing, 14th Conference on Reversible Computation\n",
    "authors": [
      "Hannah Earley"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2206.05957"
  },
  {
    "id": "arXiv:2206.05959",
    "title": "A Live Extensible Ontology of Quality Factors for Textual Requirements",
    "abstract": "Quality factors like passive voice or sentence length are commonly used in\nresearch and practice to evaluate the quality of natural language requirements\nsince they indicate defects in requirements artifacts that potentially\npropagate to later stages in the development life cycle. However, as a research\ncommunity, we still lack a holistic perspective on quality factors. This\ninhibits not only a comprehensive understanding of the existing body of\nknowledge but also the effective use and evolution of these factors. To this\nend, we propose an ontology of quality factors for textual requirements, which\nincludes (1) a structure framing quality factors and related elements and (2) a\ncentral repository and web interface making these factors publicly accessible\nand usable. We contribute the first version of both by applying a rigorous\nontology development method to 105 eligible primary studies and construct a\nfirst version of the repository and interface. We illustrate the usability of\nthe ontology and invite fellow researchers to a joint community effort to\ncomplete and maintain this knowledge repository. We envision our ontology to\nreflect the community's harmonized perception of requirements quality factors,\nguide reporting of new quality factors, and provide central access to the\ncurrent body of knowledge.",
    "descriptor": "\nComments: 7 pages, 1 figure, requirements engineering conference\n",
    "authors": [
      "Julian Frattini",
      "Lloyd Montgomery",
      "Jannik Fischbach",
      "Michael Unterkalmsteiner",
      "Daniel Mendez",
      "Davide Fucci"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.05959"
  },
  {
    "id": "arXiv:2206.05961",
    "title": "A Survey on Automated Driving System Testing: Landscapes and Trends",
    "abstract": "Automated Driving Systems (ADS) have made great achievements in recent years\nthanks to the efforts from both academia and industry. A typical ADS is\ncomposed of multiple modules, including sensing, perception, planning and\ncontrol, which brings together the latest advances in multiple domains. Despite\nthese achievements, safety assurance of the systems is still of great\nsignificance, since the unsafe behavior of ADS can bring catastrophic\nconsequences and unacceptable economic and social losses. Testing is an\nimportant approach to system validation for the deployment in practice; in the\ncontext of ADS, it is extremely challenging, due to the system complexity and\nmultidisciplinarity. There has been a great deal of literature that focuses on\nthe testing of ADS, and a number of surveys have also emerged to summarize the\ntechnical advances. However, most of these surveys focus on the system-level\ntesting that is performed within software simulators, and thereby ignore the\ndistinct features of individual modules. In this paper, we provide a\ncomprehensive survey on the existing ADS testing literature, which takes into\naccount both module-level and system-level testing. Specifically, we make the\nfollowing contributions: (1) we build a threat model that reveals the potential\nsafety threats for each module of an ADS; (2) we survey the module-level\ntesting techniques for ADS and highlight the technical differences affected by\nthe properties of the modules; (3) we also survey the system-level testing\ntechniques, but we focus on empirical studies that take a bird's-eye view on\nthe system, the problems due to the collaborations between modules, and the\ngaps between ADS testing in simulators and real world; (4) we identify the\nchallenges and opportunities in ADS testing, which facilitates the future\nresearch in this field.",
    "descriptor": "",
    "authors": [
      "Shuncheng Tang",
      "Zhenya Zhang",
      "Yi Zhang",
      "Jixiang Zhou",
      "Yan Guo",
      "Shuang Liu",
      "Shengjian Guo",
      "Yan-Fu Li",
      "Lei Ma",
      "Yinxing Xue",
      "Yang Liu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.05961"
  },
  {
    "id": "arXiv:2206.05962",
    "title": "PRO-TIP: Phantom for RObust automatic ultrasound calibration by TIP  detection",
    "abstract": "We propose a novel method to automatically calibrate tracked ultrasound\nprobes. To this end we design a custom phantom consisting of nine cones with\ndifferent heights. The tips are used as key points to be matched between\nmultiple sweeps. We extract them using a convolutional neural network to\nsegment the cones in every ultrasound frame and then track them across the\nsweep. The calibration is robustly estimated using RANSAC and later refined\nemploying image based techniques. Our phantom can be 3D-printed and offers many\nadvantages over state-of-the-art methods. The phantom design and algorithm code\nare freely available online. Since our phantom does not require a tracking\ntarget on itself, ease of use is improved over currently used techniques. The\nfully automatic method generalizes to new probes and different vendors, as\nshown in our experiments. Our approach produces results comparable to\ncalibrations obtained by a domain expert.",
    "descriptor": "\nComments: This preprint was submitted to MICCAI 2022. The Version of Record of this contribution will be published in Springer LNCS\n",
    "authors": [
      "Matteo Ronchetti",
      "Julia Rackerseder",
      "Maria Tirindelli",
      "Mehrdad Salehi",
      "Nassir Navab",
      "Wolfgang Wein",
      "Oliver Zettinig"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.05962"
  },
  {
    "id": "arXiv:2206.05963",
    "title": "ATDN vSLAM: An all-through Deep Learning-Based Solution for Visual  Simultaneous Localization and Mapping",
    "abstract": "In this paper, a novel solution is introduced for visual Simultaneous\nLocalization and Mapping (vSLAM) that is built up of Deep Learning components.\nThe proposed architecture is a highly modular framework in which each component\noffers state of the art results in their respective fields of vision-based deep\nlearning solutions. The paper shows that with the synergic integration of these\nindividual building blocks, a functioning and efficient all-through deep neural\n(ATDN) vSLAM system can be created. The Embedding Distance Loss function is\nintroduced and using it the ATDN architecture is trained. The resulting system\nmanaged to achieve 4.4% translation and 0.0176 deg/m rotational error on a\nsubset of the KITTI dataset. The proposed architecture can be used for\nefficient and low-latency autonomous driving (AD) aiding database creation as\nwell as a basis for autonomous vehicle (AV) control.",
    "descriptor": "\nComments: Submitted to Periodica Polytechnica Electrical Engineering 11 pages\n",
    "authors": [
      "M\u00e1ty\u00e1s Sz\u00e1nt\u00f3",
      "Gy\u00f6rgy R. Bog\u00e1r",
      "L\u00e1szl\u00f3 Vajta"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.05963"
  },
  {
    "id": "arXiv:2206.05964",
    "title": "Techno Economic Modeling for Agrivoltaics: Can Agrivoltaics be more  profitable than Ground mounted PV?",
    "abstract": "Agrivoltaics (AV) is a dual land-use approach to collocate solar energy\ngeneration with agriculture for preserving the terrestrial ecosystem and\nenabling food-energy-water synergies. Here, we present a systematic approach to\nmodel the economic performance of AV relative to standalone ground-mounted PV\n(GMPV) and explore how the module design configuration can affect the dual\nfood-energy economic performance. A remarkably simple criterion for economic\nfeasibility is quantified that relates the land preservation cost to dual\nfood-energy profit. We explore case studies including both high and low value\ncrops under fixed tilt bifacial modules oriented either along the conventional\nNorth/South (N/S) facings or vertical East/West (E/W) facings. For each module\nconfiguration, the array density is varied to explore an economically feasible\ndesign space relative to GMPV for a range of module to land cost ratio (M_L) -\na location-specific indicator relating the module technology (hardware and\ninstallation) costs to the soft (land acquisition, tax, overheads, etc.) costs.\nTo offset a typically higher AV module cost needed to preserve the cropland,\nboth E/W and N/S orientated modules favor high value crops, reduced (<60%)\nmodule density, and higher M_L (>25). In contrast, higher module density and an\nincreased feed-in-tariff (FIT) relative to GMPV are desirable at lower M_L. The\neconomic trends vary sharply for M_L< 10 but tend to saturate for M_L> 20. For\nlow value crops, ~15% additional FIT can enable economic equivalence to GMPV at\nstandard module density. The proposed modeling framework can provide a valuable\ntool for AV stakeholders to assess, predict, and optimize the techno-economic\ndesign for AV",
    "descriptor": "\nComments: Submitted to IEEE Journal of Photovoltaics\n",
    "authors": [
      "Habeel Alam",
      "Muhammad Ashraful Alam",
      "Nauman Zafar Butt"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.05964"
  },
  {
    "id": "arXiv:2206.05966",
    "title": "Coordinating Monetary Contributions in Participatory Budgeting",
    "abstract": "We formalize a framework for coordinating the funding of projects and sharing\nthe costs among agents with quasi-linear utility functions and individual\nbudgets. Our model contains the classical discrete participatory budgeting\nmodel as a special case, while capturing other well-motivated problems. We\npropose several important axioms and objectives and study how well they can be\nsimultaneously satisfied. One of our main results is that whereas welfare\nmaximization admits an FPTAS, welfare maximization subject to a well-motivated\nand very weak participation requirement leads to a strong inapproximability\nresult. We show that this result is bypassed if we consider some natural\nrestricted valuations or when we take an average-case heuristic approach.",
    "descriptor": "",
    "authors": [
      "Haris Aziz",
      "Sujit Gujar",
      "Manisha Padala",
      "Mashbat Suzuki",
      "Jeremy Vollen"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Computational Complexity (cs.CC)",
      "Multiagent Systems (cs.MA)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2206.05966"
  },
  {
    "id": "arXiv:2206.05967",
    "title": "GoToNet: Fast Monocular Scene Exposure and Exploration",
    "abstract": "Autonomous scene exposure and exploration, especially in localization or\ncommunication-denied areas, useful for finding targets in unknown scenes,\nremains a challenging problem in computer navigation. In this work, we present\na novel method for real-time environment exploration, whose only requirements\nare a visually similar dataset for pre-training, enough lighting in the scene,\nand an on-board forward-looking RGB camera for environmental sensing. As\nopposed to existing methods, our method requires only one look (image) to make\na good tactical decision, and therefore works at a non-growing, constant time.\nTwo direction predictions, characterized by pixels dubbed the Goto and Lookat\npixels, comprise the core of our method. These pixels encode the recommended\nflight instructions in the following way: the Goto pixel defines the direction\nin which the agent should move by one distance unit, and the Lookat pixel\ndefines the direction in which the camera should be pointing at in the next\nstep. These flying-instruction pixels are optimized to expose the largest\namount of currently unexplored areas.\nOur method presents a novel deep learning-based navigation approach that is\nable to solve this problem and demonstrate its ability in an even more\ncomplicated setup, i.e., when computational power is limited. In addition, we\npropose a way to generate a navigation-oriented dataset, enabling efficient\ntraining of our method using RGB and depth images. Tests conducted in a\nsimulator evaluating both the sparse pixels' coordinations inferring process,\nand 2D and 3D test flights aimed to unveil areas and decrease distances to\ntargets achieve promising results. Comparison against a state-of-the-art\nalgorithm shows our method is able to overperform it, that while measuring the\nnew voxels per camera pose, minimum distance to target, percentage of surface\nvoxels seen, and compute time metrics.",
    "descriptor": "",
    "authors": [
      "Tom Avrech",
      "Evgenii Zheltonozhskii",
      "Chaim Baskin",
      "Ehud Rivlin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05967"
  },
  {
    "id": "arXiv:2206.05968",
    "title": "Entropic Weighted Rank Function",
    "abstract": "It is known that the entropy function over a set of jointly distributed\nrandom variables is a submodular set function. However, not any submodular\nfunction is of this form. In this paper, we consider a family of submodular set\nfunctions, called weighted rank functions of matroids, and study the necessary\nor sufficient conditions under which they are entropic. We prove that weighted\nrank functions are located on the boundary of the submodularity cone. For the\nrepresentable matroids over a characteristic 2 field, we show that the integer\nvalued weighted rank functions are entropic. We derive a necessary condition\nfor constant weight rank functions to be entropic and show that for the case of\ngraphic matroids, this condition is indeed sufficient. Since these functions\ngeneralize the rank of a matroid, our findings generalize some of the results\nof Abbe et. al. about entropic properties of the rank function of matroids.",
    "descriptor": "",
    "authors": [
      "Mohammad Rashid",
      "Elahe Ghasemi",
      "Javad B.Ebrahimi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.05968"
  },
  {
    "id": "arXiv:2206.05970",
    "title": "One Size Fits All: Hypernetwork for Tunable Image Restoration",
    "abstract": "We introduce a novel approach for tunable image restoration that achieves the\naccuracy of multiple models, each optimized for a different level of\ndegradation, with exactly the same number of parameters as a single model. Our\nmodel can be optimized to restore as many degradation levels as required with a\nconstant number of parameters and for various image restoration tasks.\nExperiments on real-world datasets show that our approach achieves state-of-the\nart results in denoising, DeJPEG and super-resolution with respect to existing\ntunable models, allowing smoother and more accurate fitting over a wider range\nof degradation levels.",
    "descriptor": "",
    "authors": [
      "Shai Aharon",
      "Gil Ben-Artzi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.05970"
  },
  {
    "id": "arXiv:2206.05971",
    "title": "Biologically Inspired Neural Path Finding",
    "abstract": "The human brain can be considered to be a graphical structure comprising of\ntens of billions of biological neurons connected by synapses. It has the\nremarkable ability to automatically re-route information flow through alternate\npaths in case some neurons are damaged. Moreover, the brain is capable of\nretaining information and applying it to similar but completely unseen\nscenarios. In this paper, we take inspiration from these attributes of the\nbrain, to develop a computational framework to find the optimal low cost path\nbetween a source node and a destination node in a generalized graph. We show\nthat our framework is capable of handling unseen graphs at test time. Moreover,\nit can find alternate optimal paths, when nodes are arbitrarily added or\nremoved during inference, while maintaining a fixed prediction time. Code is\navailable here: https://github.com/hangligit/pathfinding",
    "descriptor": "",
    "authors": [
      "Hang Li",
      "Qadeer Khan",
      "Volker Tresp",
      "Daniel Cremers"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.05971"
  },
  {
    "id": "arXiv:2206.05972",
    "title": "EmProx: Neural Network Performance Estimation For Neural Architecture  Search",
    "abstract": "Common Neural Architecture Search methods generate large amounts of candidate\narchitectures that need training in order to assess their performance and find\nan optimal architecture. To minimize the search time we use different\nperformance estimation strategies. The effectiveness of such strategies varies\nin terms of accuracy and fit and query time. This study proposes a new method,\nEmProx Score (Embedding Proximity Score). Similar to Neural Architecture\nOptimization (NAO), this method maps candidate architectures to a continuous\nembedding space using an encoder-decoder framework. The performance of\ncandidates is then estimated using weighted kNN based on the embedding vectors\nof architectures of which the performance is known. Performance estimations of\nthis method are comparable to the MLP performance predictor used in NAO in\nterms of accuracy, while being nearly nine times faster to train compared to\nNAO. Benchmarking against other performance estimation strategies currently\nused shows similar to better accuracy, while being five up to eighty times\nfaster.",
    "descriptor": "",
    "authors": [
      "G.G.H. Franken",
      "P. Singh",
      "J. Vanschoren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05972"
  },
  {
    "id": "arXiv:2206.05973",
    "title": "A Sahlqvist-style Correspondence Theorem for Linear-time Temporal Logic",
    "abstract": "The language of modal logic is capable of expressing first-order conditions\non Kripke frames. The classic result by Henrik Sahlqvist identifies a\nsignificant class of modal formulas for which first-order conditions -- or\nSahlqvist correspondents -- can be find in an effective, algorithmic way.\nRecent works have successfully extended this classic result to more complex\nmodal languages. In this paper, we pursue a similar line and develop a\nSahlqvist-style correspondence theorem for Linear-time Temporal Logic (LTL),\nwhich is one of the most widely used formal languages for temporal\nspecification. LTL extends the syntax of basic modal logic with dedicated\ntemporal operators Next X and Until U . As a result, the complexity of the\nclass of formulas that have first-order correspondents also increases\naccordingly. In this paper, we identify a significant class of LTL Sahlqvist\nformulas built by using modal operators F , G, X, and U . The main result of\nthis paper is to prove the correspondence of LTL Sahlqvist formulas to frame\nconditions that are definable in first-order language.",
    "descriptor": "\nComments: 15 pages + 1 page of references\n",
    "authors": [
      "Rui Li",
      "Francesco Belardinelli"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.05973"
  },
  {
    "id": "arXiv:2206.05975",
    "title": "On the Learning of Non-Autoregressive Transformers",
    "abstract": "Non-autoregressive Transformer (NAT) is a family of text generation models,\nwhich aims to reduce the decoding latency by predicting the whole sentences in\nparallel. However, such latency reduction sacrifices the ability to capture\nleft-to-right dependencies, thereby making NAT learning very challenging. In\nthis paper, we present theoretical and empirical analyses to reveal the\nchallenges of NAT learning and propose a unified perspective to understand\nexisting successes. First, we show that simply training NAT by maximizing the\nlikelihood can lead to an approximation of marginal distributions but drops all\ndependencies between tokens, where the dropped information can be measured by\nthe dataset's conditional total correlation. Second, we formalize many previous\nobjectives in a unified framework and show that their success can be concluded\nas maximizing the likelihood on a proxy distribution, leading to a reduced\ninformation loss. Empirical studies show that our perspective can explain the\nphenomena in NAT learning and guide the design of new training methods.",
    "descriptor": "\nComments: accepted at ICML2022\n",
    "authors": [
      "Fei Huang",
      "Tianhua Tao",
      "Hao Zhou",
      "Lei Li",
      "Minlie Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.05975"
  },
  {
    "id": "arXiv:2206.05981",
    "title": "Efficient Human-in-the-loop System for Guiding DNNs Attention",
    "abstract": "Attention guidance is an approach to addressing dataset bias in deep\nlearning, where the model relies on incorrect features to make decisions.\nFocusing on image classification tasks, we propose an efficient\nhuman-in-the-loop system to interactively direct the attention of classifiers\nto the regions specified by users, thereby reducing the influence of\nco-occurrence bias and improving the transferability and interpretability of a\nDNN. Previous approaches for attention guidance require the preparation of\npixel-level annotations and are not designed as interactive systems. We present\na new interactive method to allow users to annotate images with simple clicks,\nand study a novel active learning strategy to significantly reduce the number\nof annotations. We conducted both a numerical evaluation and a user study to\nevaluate the proposed system on multiple datasets. Compared to the existing\nnon-active-learning approach which usually relies on huge amounts of\npolygon-based segmentation masks to fine-tune or train the DNNs, our system can\nsave lots of labor and money and obtain a fine-tuned network that works better\neven when the dataset is biased. The experiment results indicate that the\nproposed system is efficient, reasonable, and reliable.",
    "descriptor": "\nComments: 13 pages, 11 figures\n",
    "authors": [
      "Yi He",
      "Xi Yang",
      "Chia-Ming Chang",
      "Haoran Xie",
      "Takeo Igarashi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05981"
  },
  {
    "id": "arXiv:2206.05982",
    "title": "Learning Fashion Compatibility from In-the-wild Images",
    "abstract": "Complementary fashion recommendation aims at identifying items from different\ncategories (e.g. shirt, footwear, etc.) that \"go well together\" as an outfit.\nMost existing approaches learn representation for this task using labeled\noutfit datasets containing manually curated compatible item combinations. In\nthis work, we propose to learn representations for compatibility prediction\nfrom in-the-wild street fashion images through self-supervised learning by\nleveraging the fact that people often wear compatible outfits. Our pretext task\nis formulated such that the representations of different items worn by the same\nperson are closer compared to those worn by other people. Additionally, to\nreduce the domain gap between in-the-wild and catalog images during inference,\nwe introduce an adversarial loss that minimizes the difference in feature\ndistribution between the two domains. We conduct our experiments on two popular\nfashion compatibility benchmarks - Polyvore and Polyvore-Disjoint outfits, and\noutperform existing self-supervised approaches, particularly significant in\ncross-dataset setting where training and testing images are from different\nsources.",
    "descriptor": "\nComments: Accepted to ICPR 2022\n",
    "authors": [
      "Additya Popli",
      "Vijay Kumar",
      "Sujit Jos",
      "Saraansh Tandon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.05982"
  },
  {
    "id": "arXiv:2206.05983",
    "title": "Reduction and Observer Design for a Grey-Box Model in Continuous  Pharmaceutical Manufacturing",
    "abstract": "In this contribution, a novel Reduced Order Model (ROM) formulation of the\ngrey-box model proposed in Elkhashap et al. (2020a) for the pharmaceutical\ncontinuous vibrated fluid bed dryer (VFBD) is presented. The ROM exploits the\n$\\mathcal{H}_2$-norm projection-based model order reduction method after a\nspecial solution formulation of the model's infinite-dimensional part. This is\nmainly by introducing a vector field mapping between the model parts casting\nthe semi-discretized PDE into a bilinear form. The ROM produced is then\nintegrated into an nonlinear Kalman Filtering-based observer design also\nhandling the estimation of the model's algebraic variables. Evaluations of the\nFOM, ROM, ROM-based observer variants, and the FOM-based observer are performed\nusing Monte-Carlo simulations as well as simulations based on experimental data\nof the real system. It is shown that the ROM could reproduce the FOM states\naccurately with a relative mean square error below $0.3\\,\\%$ for the\nexperimental data simulation. This is while reaching a computational-time\nreduction up to a factor of $40$. The ROM-based observer with algebraic states\ncorrection is shown (using Monte-Carlo simulations) to be able to converge to\nthe true values for all cases regardless of initialization. Moreover, it is\nalso shown that the performance degradation of the observer due to reduction is\npractically insignificant. This is while the computational speedup of the\nobserver due to reduction reached a factor of more than third order of\nmagnitude.",
    "descriptor": "\nComments: Accepted for publication at the IFAC Workshop on Control of Systems Governed by Partial Differential Equations (CPDE) 2022\n",
    "authors": [
      "Ahmed Elkhashap",
      "Dirk Abel"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.05983"
  },
  {
    "id": "arXiv:2206.05985",
    "title": "Modeling the Machine Learning Multiverse",
    "abstract": "Amid mounting concern about the reliability and credibility of machine\nlearning research, we present a principled framework for making robust and\ngeneralizable claims: the Multiverse Analysis. Our framework builds upon the\nMultiverse Analysis (Steegen et al., 2016) introduced in response to\npsychology's own reproducibility crisis. To efficiently explore\nhigh-dimensional and often continuous ML search spaces, we model the multiverse\nwith a Gaussian Process surrogate and apply Bayesian experimental design. Our\nframework is designed to facilitate drawing robust scientific conclusions about\nmodel performance, and thus our approach focuses on exploration rather than\nconventional optimization. In the first of two case studies, we investigate\ndisputed claims about the relative merit of adaptive optimizers. Second, we\nsynthesize conflicting research on the effect of learning rate on the large\nbatch training generalization gap. For the machine learning community, the\nMultiverse Analysis is a simple and effective technique for identifying robust\nclaims, for increasing transparency, and a step toward improved\nreproducibility.",
    "descriptor": "",
    "authors": [
      "Samuel J. Bell",
      "Onno P. Kampman",
      "Jesse Dodge",
      "Neil D. Lawrence"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2206.05985"
  },
  {
    "id": "arXiv:2206.05988",
    "title": "High-Dimensional Bayesian Optimization with Constraints: Application to  Powder Weighing",
    "abstract": "Bayesian optimization works effectively optimizing parameters in black-box\nproblems. However, this method did not work for high-dimensional parameters in\nlimited trials. Parameters can be efficiently explored by nonlinearly embedding\nthem into a low-dimensional space; however, the constraints cannot be\nconsidered. We proposed combining parameter decomposition by introducing\ndisentangled representation learning into nonlinear embedding to consider both\nknown equality and unknown inequality constraints in high-dimensional Bayesian\noptimization. We applied the proposed method to a powder weighing task as a\nusage scenario. Based on the experimental results, the proposed method\nconsiders the constraints and contributes to reducing the number of trials by\napproximately 66% compared to manual parameter tuning.",
    "descriptor": "\nComments: 14 pages, 6 figures, accepted to PDPTA 2022\n",
    "authors": [
      "Shoki Miyagawa",
      "Atsuyoshi Yano",
      "Naoko Sawada",
      "Isamu Ogawa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05988"
  },
  {
    "id": "arXiv:2206.05990",
    "title": "Multi-Agent Neural Rewriter for Vehicle Routing with Limited Disclosure  of Costs",
    "abstract": "We interpret solving the multi-vehicle routing problem as a team Markov game\nwith partially observable costs. For a given set of customers to serve, the\nplaying agents (vehicles) have the common goal to determine the team-optimal\nagent routes with minimal total cost. Each agent thereby observes only its own\ncost. Our multi-agent reinforcement learning approach, the so-called\nmulti-agent Neural Rewriter, builds on the single-agent Neural Rewriter to\nsolve the problem by iteratively rewriting solutions. Parallel agent action\nexecution and partial observability require new rewriting rules for the game.\nWe propose the introduction of a so-called pool in the system which serves as a\ncollection point for unvisited nodes. It enables agents to act simultaneously\nand exchange nodes in a conflict-free manner. We realize limited disclosure of\nagent-specific costs by only sharing them during learning. During inference,\neach agents acts decentrally, solely based on its own cost. First empirical\nresults on small problem sizes demonstrate that we reach a performance close to\nthe employed OR-Tools benchmark which operates in the perfect cost information\nsetting.",
    "descriptor": "",
    "authors": [
      "Nathalie Paul",
      "Tim Wirtz",
      "Stefan Wrobel",
      "Alexander Kister"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2206.05990"
  },
  {
    "id": "arXiv:2206.05994",
    "title": "Discretization and Stabilization of Energy-Based Controller for Period  Switching Control and Flexible Scheduling",
    "abstract": "Emerging advanced control applications, with increased complexity in software\nbut limited computing resources, suggest that real-time controllers should have\nadaptable designs. These control strategies also should be designed with\nconsideration of the run-time behavior of the system. One of such research\nattempts is to design the controller along with the task scheduler, known as\ncontrol-scheduling co-design, for more predictable timing behavior as well as\nsurviving system overloads. Unlike traditional controller designs, which have\nequal-distance sampling periods, the co-design approach increases the system\nflexibility and resilience by explicitly considering timing properties, for\nexample using an event-based controller or with multiple sampling times\n(non-uniform sampling and control). Within this context, we introduce the first\nwork on the discretization of an energy-based controller that can switch\narbitrarily between multiple periods and adjust the control parameters\naccordingly without destabilizing the system. A digital controller design based\non this paradigm for a DC motor with an elastic load as an example is\nintroduced and the stability condition is given based on the proposed Lyapunov\nfunction. The method is evaluated with various computer-based simulations which\ndemonstrate its effectiveness.",
    "descriptor": "\nComments: Accepted to 2022 American Control Conference (ACC), 6 pages, 8 figures\n",
    "authors": [
      "Seyed Amir Tafrishi",
      "Xiaotian Dai",
      "Yasuhisa Hirata",
      "Alan Burns"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.05994"
  },
  {
    "id": "arXiv:2206.05997",
    "title": "Analysis of function approximation and stability of general DNNs in  directed acyclic graphs using un-rectifying analysis",
    "abstract": "A general lack of understanding pertaining to deep feedforward neural\nnetworks (DNNs) can be attributed partly to a lack of tools with which to\nanalyze the composition of non-linear functions, and partly to a lack of\nmathematical models applicable to the diversity of DNN architectures. In this\npaper, we made a number of basic assumptions pertaining to activation\nfunctions, non-linear transformations, and DNN architectures in order to use\nthe un-rectifying method to analyze DNNs via directed acyclic graphs (DAGs).\nDNNs that satisfy these assumptions are referred to as general DNNs. Our\nconstruction of an analytic graph was based on an axiomatic method in which\nDAGs are built from the bottom-up through the application of atomic operations\nto basic elements in accordance with regulatory rules. This approach allows us\nto derive the properties of general DNNs via mathematical induction. We show\nthat using the proposed approach, some properties hold true for general DNNs\ncan be derived. This analysis advances our understanding of network functions\nand could promote further theoretical insights if the host of analytical tools\nfor graphs can be leveraged.",
    "descriptor": "\nComments: 26 pages, 14 figures\n",
    "authors": [
      "Wen-Liang Hwang",
      "Shih-Shuo Tung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05997"
  },
  {
    "id": "arXiv:2206.06003",
    "title": "Deconfounding Duration Bias in Watch-time Prediction for Video  Recommendation",
    "abstract": "Watch-time prediction remains to be a key factor in reinforcing user\nengagement via video recommendations. It has become increasingly important\ngiven the ever-growing popularity of online videos. However, prediction of\nwatch time not only depends on the match between the user and the video but is\noften mislead by the duration of the video itself. With the goal of improving\nwatch time, recommendation is always biased towards videos with long duration.\nModels trained on this imbalanced data face the risk of bias amplification,\nwhich misguides platforms to over-recommend videos with long duration but\noverlook the underlying user interests.\nThis paper presents the first work to study duration bias in watch-time\nprediction for video recommendation. We employ a causal graph illuminating that\nduration is a confounding factor that concurrently affects video exposure and\nwatch-time prediction -- the first effect on video causes the bias issue and\nshould be eliminated, while the second effect on watch time originates from\nvideo intrinsic characteristics and should be preserved. To remove the\nundesired bias but leverage the natural effect, we propose a Duration\nDeconfounded Quantile-based (D2Q) watch-time prediction framework, which allows\nfor scalability to perform on industry production systems. Through extensive\noffline evaluation and live experiments, we showcase the effectiveness of this\nduration-deconfounding framework by significantly outperforming the\nstate-of-the-art baselines. We have fully launched our approach on Kuaishou\nApp, which has substantially improved real-time video consumption due to more\naccurate watch-time predictions.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Ruohan Zhan",
      "Changhua Pei",
      "Qiang Su",
      "Jianfeng Wen",
      "Xueliang Wang",
      "Guanyu Mu",
      "Dong Zheng",
      "Peng Jiang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.06003"
  },
  {
    "id": "arXiv:2206.06007",
    "title": "Intrinsically motivated option learning: a comparative study of recent  methods",
    "abstract": "Options represent a framework for reasoning across multiple time scales in\nreinforcement learning (RL). With the recent active interest in the\nunsupervised learning paradigm in the RL research community, the option\nframework was adapted to utilize the concept of empowerment, which corresponds\nto the amount of influence the agent has on the environment and its ability to\nperceive this influence, and which can be optimized without any supervision\nprovided by the environment's reward structure. Many recent papers modify this\nconcept in various ways achieving commendable results. Through these various\nmodifications, however, the initial context of empowerment is often lost. In\nthis work we offer a comparative study of such papers through the lens of the\noriginal empowerment principle.",
    "descriptor": "\nComments: Accepted for presentation at the 2021 29th Telecommunications Forum (TELFOR), Belgrade, Serbia\n",
    "authors": [
      "Djordje Bo\u017ei\u0107",
      "Predrag Tadi\u0107",
      "Mladen Nikoli\u0107"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.06007"
  },
  {
    "id": "arXiv:2206.06008",
    "title": "Towards a Roadmap for Trustworthy Dynamic Systems-of-Systems",
    "abstract": "This paper gives insights into the DynaSoS project, which aims to propose a\ncross-domain roadmap for systems engineering research into trustworthy dynamic\nsystems-of-systems with autonomous components. The project follows a\nmethodology that combines interviews and workshops with experts from various\ndomains and a literature review. In this paper, we motivate the project,\ndiscuss five application areas with their drivers and visions, and draw initial\nconclusions with respect to challenges that a research roadmap should address.\nOur goal is to share initial results with the research community about the\nDynaSoS project and invite them to contribute to the derivation of the research\nroadmap.",
    "descriptor": "\nComments: 6 pages, 0 figure, 6 references, preprint, paper accepted to the folowing conference: SERP'22 - The 20th Int'l Conf on Software Engineering Research and Practice (part of the 2022 World Congress in Computer Science, Computer Engineering, & Applied Computing (CSCE'22)) this https URL\n",
    "authors": [
      "Rasmus Adler",
      "Frank Elberzhager",
      "Julien Siebert"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.06008"
  },
  {
    "id": "arXiv:2206.06009",
    "title": "Relative Policy-Transition Optimization for Fast Policy Transfer",
    "abstract": "We consider the problem of policy transfer between two Markov Decision\nProcesses (MDPs). We introduce a lemma based on existing theoretical results in\nreinforcement learning (RL) to measure the relativity between two arbitrary\nMDPs, that is the difference between any two cumulative expected returns\ndefined on different policies and environment dynamics. Based on this lemma, we\npropose two new algorithms referred to as Relative Policy Optimization (RPO)\nand Relative Transition Optimization (RTO), which can offer fast policy\ntransfer and dynamics modeling, respectively. RPO updates the policy using the\nrelative policy gradient to transfer the policy evaluated in one environment to\nmaximize the return in another, while RTO updates the parameterized dynamics\nmodel (if there exists) using the relative transition gradient to reduce the\ngap between the dynamics of the two environments. Then, integrating the two\nalgorithms offers the complete algorithm Relative Policy-Transition\nOptimization (RPTO), in which the policy interacts with the two environments\nsimultaneously, such that data collections from two environments, policy and\ntransition updates are completed in one closed loop to form a principled\nlearning framework for policy transfer. We demonstrate the effectiveness of\nRPTO in OpenAI gym's classic control tasks by creating policy transfer problems\nvia variant dynamics.",
    "descriptor": "",
    "authors": [
      "Lei Han",
      "Jiawei Xu",
      "Cheng Zhou",
      "Yizheng Zhang",
      "Zhengyou Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.06009"
  },
  {
    "id": "arXiv:2206.06010",
    "title": "Constant-Round Linear-Broadcast Secure Computation with Penalties",
    "abstract": "It is known that Bitcoin enables achieving fairness in secure computation by\nimposing monetary penalties on adversarial parties. This functionality is\ncalled secure computation with penalties. Bentov and Kumaresan (Crypto 2014)\nintroduced the claim-or-refund functionality that can be implemented via\nBitcoin. They achieved secure computation with penalties with $O(n)$ rounds and\n$O(n)$ broadcasts for any function, where $n$ is the number of parties. After\nthat, Kumaresan and Bentov (CCS 2014) showed a constant-round protocol.\nUnfortunately, this protocol requires $O(n^2)$ broadcasts. As far as we know,\nno protocol achieves $O(1)$ rounds and $O(n)$ broadcasts based on Bitcoin. This\nwork accomplishes such efficiency in secure computation with penalties. We\nfirst show a protocol in a slightly relaxed setting called secure computation\nwith non-equivalent penalties. This setting is the same as secure computation\nwith penalties except that every honest party receives more than a\npredetermined amount of compensation, while the previous one requires that\nevery honest party receives the same amount of compensation. Namely, our\nsetting allows the compensations for honest parties to be non-equivalent.\nMoreover, we present a technique to remove the non-equivalence of our protocol\nwithout sacrificing efficiency. We then propose a new ideal functionality\ncalled claim-refund-or-give that can be implemented via Bitcoin.",
    "descriptor": "\nComments: 32 pages\n",
    "authors": [
      "Takeshi Nakai",
      "Kazumasa Shinagawa"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.06010"
  },
  {
    "id": "arXiv:2206.06011",
    "title": "Reinforcement Learning-based Placement of Charging Stations in Urban  Road Networks",
    "abstract": "The transition from conventional mobility to electromobility largely depends\non charging infrastructure availability and optimal placement.This paper\nexamines the optimal placement of charging stations in urban areas. We maximise\nthe charging infrastructure supply over the area and minimise waiting, travel,\nand charging times while setting budget constraints. Moreover, we include the\npossibility of charging vehicles at home to obtain a more refined estimation of\nthe actual charging demand throughout the urban area. We formulate the\nPlacement of Charging Stations problem as a non-linear integer optimisation\nproblem that seeks the optimal positions for charging stations and the optimal\nnumber of charging piles of different charging types. We design a novel Deep\nReinforcement Learning approach to solve the charging station placement problem\n(PCRL). Extensive experiments on real-world datasets show how the PCRL reduces\nthe waiting and travel time while increasing the benefit of the charging plan\ncompared to five baselines. Compared to the existing infrastructure, we can\nreduce the waiting time by up to 97% and increase the benefit up to 497%.",
    "descriptor": "\nComments: 9 pages, 9 figures, definitive version published in the proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD '22)\n",
    "authors": [
      "Leonie von Wahl",
      "Nicolas Tempelmeier",
      "Ashutosh Sao",
      "Elena Demidova"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.06011"
  },
  {
    "id": "arXiv:2206.06014",
    "title": "Exploring and Exploiting Hubness Priors for High-Quality GAN Latent  Sampling",
    "abstract": "Despite the extensive studies on Generative Adversarial Networks (GANs), how\nto reliably sample high-quality images from their latent spaces remains an\nunder-explored topic. In this paper, we propose a novel GAN latent sampling\nmethod by exploring and exploiting the hubness priors of GAN latent\ndistributions. Our key insight is that the high dimensionality of the GAN\nlatent space will inevitably lead to the emergence of hub latents that usually\nhave much larger sampling densities than other latents in the latent space. As\na result, these hub latents are better trained and thus contribute more to the\nsynthesis of high-quality images. Unlike the a posterior \"cherry-picking\", our\nmethod is highly efficient as it is an a priori method that identifies\nhigh-quality latents before the synthesis of images. Furthermore, we show that\nthe well-known but purely empirical truncation trick is a naive approximation\nto the central clustering effect of hub latents, which not only uncovers the\nrationale of the truncation trick, but also indicates the superiority and\nfundamentality of our method. Extensive experimental results demonstrate the\neffectiveness of the proposed method.",
    "descriptor": "\nComments: Accepted at ICML 2022. Our code is available at: this https URL\n",
    "authors": [
      "Yuanbang Liang",
      "Jing Wu",
      "Yu-Kun Lai",
      "Yipeng Qin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06014"
  },
  {
    "id": "arXiv:2206.06015",
    "title": "No-Regret Learning in Games with Noisy Feedback: Faster Rates and  Adaptivity via Learning Rate Separation",
    "abstract": "We examine the problem of regret minimization when the learner is involved in\na continuous game with other optimizing agents: in this case, if all players\nfollow a no-regret algorithm, it is possible to achieve significantly lower\nregret relative to fully adversarial environments. We study this problem in the\ncontext of variationally stable games (a class of continuous games which\nincludes all convex-concave and monotone games), and when the players only have\naccess to noisy estimates of their individual payoff gradients. If the noise is\nadditive, the game-theoretic and purely adversarial settings enjoy similar\nregret guarantees; however, if the noise is multiplicative, we show that the\nlearners can, in fact, achieve constant regret. We achieve this faster rate via\nan optimistic gradient scheme with learning rate separation -- that is, the\nmethod's extrapolation and update steps are tuned to different schedules,\ndepending on the noise profile. Subsequently, to eliminate the need for\ndelicate hyperparameter tuning, we propose a fully adaptive method that\nsmoothly interpolates between worst- and best-case regret guarantees.",
    "descriptor": "",
    "authors": [
      "Yu-Guan Hsieh",
      "Kimon Antonakopoulos",
      "Volkan Cevher",
      "Panayotis Mertikopoulos"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06015"
  },
  {
    "id": "arXiv:2206.06019",
    "title": "SBvote: Scalable Self-Tallying Blockchain-Based Voting",
    "abstract": "Decentralized electronic voting solutions represent a promising advancement\nin electronic voting. One of the e-voting paradigms, the self-tallying scheme,\noffers strong protection of the voters' privacy while making the whole voting\nprocess verifiable. Decentralized smart contract platforms became interesting\npractical instantiation of the immutable bulletin board that this scheme\nrequires to preserve its properties. Existing smart contract-based approaches\nemploying the self-tallying scheme (such as OVN or BBB-Voting) are only\nsuitable for a boardroom voting scenario due to their scalability limitation.\nThe goal of our work is to build on existing solutions to achieve scalability\nwithout losing privacy guarantees and verifiability. We present SBvote, a\nblockchain-based self-tallying voting protocol that is scalable in the number\nof voters and therefore suitable for large-scale elections. The evaluation of\nour proof-of-concept implementation shows that the protocol's scalability is\nlimited only by the underlying blockchain platform. We evaluated the\nscalability of SBvote on two public smart contract platforms -- Gnosis and\nHarmony. Despite the limitations imposed by the throughput of the blockchain\nplatform, SBvote can accommodate elections with millions of voters.",
    "descriptor": "",
    "authors": [
      "Ivana Stan\u010d\u00edkov\u00e1",
      "Ivan Homoliak"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.06019"
  },
  {
    "id": "arXiv:2206.06022",
    "title": "Machine Learning Training on a Real Processing-in-Memory System",
    "abstract": "Training machine learning algorithms is a computationally intensive process,\nwhich is frequently memory-bound due to repeatedly accessing large training\ndatasets. As a result, processor-centric systems (e.g., CPU, GPU) suffer from\ncostly data movement between memory units and processing units, which consumes\nlarge amounts of energy and execution cycles. Memory-centric computing systems,\ni.e., computing systems with processing-in-memory (PIM) capabilities, can\nalleviate this data movement bottleneck.\nOur goal is to understand the potential of modern general-purpose PIM\narchitectures to accelerate machine learning training. To do so, we (1)\nimplement several representative classic machine learning algorithms (namely,\nlinear regression, logistic regression, decision tree, K-means clustering) on a\nreal-world general-purpose PIM architecture, (2) characterize them in terms of\naccuracy, performance and scaling, and (3) compare to their counterpart\nimplementations on CPU and GPU. Our experimental evaluation on a memory-centric\ncomputing system with more than 2500 PIM cores shows that general-purpose PIM\narchitectures can greatly accelerate memory-bound machine learning workloads,\nwhen the necessary operations and datatypes are natively supported by PIM\nhardware.\nTo our knowledge, our work is the first one to evaluate training of machine\nlearning algorithms on a real-world general-purpose PIM architecture.",
    "descriptor": "\nComments: This extended abstract appears as an invited paper at the 2022 IEEE Computer Society Annual Symposium on VLSI (ISVLSI)\n",
    "authors": [
      "Juan G\u00f3mez-Luna",
      "Yuxin Guo",
      "Sylvan Brocard",
      "Julien Legriel",
      "Remy Cimadomo",
      "Geraldo F. Oliveira",
      "Gagandeep Singh",
      "Onur Mutlu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06022"
  },
  {
    "id": "arXiv:2206.06023",
    "title": "TriMix: Virtual embeddings and self-consistency for self-supervised  learning",
    "abstract": "Self-supervised Learning (SSL) has recently gained much attention due to the\nhigh cost and data limitation in the training of supervised learning models.\nThe current paradigm in the SSL is to utilize data augmentation at the input\nspace to create different views of the same images and train a model to\nmaximize the representations between similar images and minimize them for\ndifferent ones. While this approach achieves state-of-the-art (SOTA) results in\nvarious downstream tasks, it still lakes the opportunity to investigate the\nlatent space augmentation. This paper proposes TriMix, a novel concept for SSL\nthat generates virtual embeddings through linear interpolation of the data,\nthus providing the model with novel representations. Our strategy focuses on\ntraining the model to extract the original embeddings from virtual ones, hence,\nbetter representation learning. Additionally, we propose a self-consistency\nterm that improves the consistency between the virtual and actual embeddings.\nWe validate TriMix on eight benchmark datasets consisting of natural and\nmedical images with an improvement of 2.71% and 0.41% better than the\nsecond-best models for both data types. Further, our approach outperformed the\ncurrent methods in semi-supervised learning, particularly in low data regimes.\nBesides, our pre-trained models showed better transfer to other datasets.",
    "descriptor": "",
    "authors": [
      "Tariq Bdair",
      "Hossam Abdelhamid",
      "Nassir Navab",
      "Shadi Albarqouni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.06023"
  },
  {
    "id": "arXiv:2206.06025",
    "title": "Rethinking: Deep-learning-based Demodulation and Decoding",
    "abstract": "In this paper, we focus on the demodulation/decoding of the complex\nmodulations/codes that approach the Shannon capacity. Theoretically, the\nmaximum likelihood (ML) algorithm can achieve the optimal error performance\nwhereas it has $\\mathcal{O}(2^k)$ demodulation/decoding complexity with $k$\ndenoting the number of information bits. Recent progress in deep learning\nprovides a new direction to tackle the demodulation and the decoding. The\npurpose of this paper is to analyze the feasibility of the neural network to\ndemodulate/decode the complex modulations/codes close to the Shannon capacity\nand characterize the error performance and the complexity of the neural\nnetwork. Regarding the neural network demodulator, we use the golden angle\nmodulation (GAM), a promising modulation format that can offer the Shannon\ncapacity approaching performance, to evaluate the demodulator. It is observed\nthat the neural network demodulator can get a close performance to the ML-based\nmethod while it suffers from the lower complexity order in the low-order GAM.\nRegarding the neural network decoder, we use the Gaussian codebook, achieving\nthe Shannon capacity, to evaluate the decoder. We also observe that the neural\nnetwork decoder achieves the error performance close to the ML decoder with a\nmuch lower complexity order in the small Gaussian codebook. Limited by the\ncurrent training resources, we cannot evaluate the performance of the\nhigh-order modulation and the long codeword. But, based on the results of the\nlow-order GAM and the small Gaussian codebook, we boldly give our conjecture:\nthe neural network demodulator/decoder is a strong candidate approach for\ndemodulating/decoding the complex modulations/codes close to the Shannon\ncapacity owing to the error performance of the near-ML algorithm and the lower\ncomplexity.",
    "descriptor": "",
    "authors": [
      "Boxiang He",
      "Zitao Wu",
      "Fanggang Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.06025"
  },
  {
    "id": "arXiv:2206.06027",
    "title": "Adversarial Models Towards Data Availability and Integrity of  Distributed State Estimation for Industrial IoT-Based Smart Grid",
    "abstract": "Security issue of distributed state estimation (DSE) is an important prospect\nfor the rapidly growing smart grid ecosystem. Any coordinated cyberattack\ntargeting the distributed system of state estimators can cause unrestrained\nestimation errors and can lead to a myriad of security risks, including failure\nof power system operation. This article explores the security threats of a\nsmart grid arising from the exploitation of DSE vulnerabilities. To this aim,\nnovel adversarial strategies based on two-stage data availability and integrity\nattacks are proposed towards a distributed industrial Internet of Things-based\nsmart grid. The former's attack goal is to prevent boundary data exchange among\ndistributed control centers, while the latter's attack goal is to inject a\nfalsified data to cause local and global system unobservability. The proposed\nframework is evaluated on IEEE standard 14-bus system and benchmarked against\nthe state-of-the-art research. Experimental results show that the proposed\ntwo-stage cyberattack results in an estimated error of approximately 34.74%\ncompared to an error of the order of 10^-3 under normal operating conditions.",
    "descriptor": "\nComments: 11 pages (DC), Journal manuscript\n",
    "authors": [
      "Haftu Tasew Reda",
      "Abdun Mahmood",
      "Adnan Anwar",
      "Naveen Chilamkurti"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.06027"
  },
  {
    "id": "arXiv:2206.06029",
    "title": "Mediators: Conversational Agents Explaining NLP Model Behavior",
    "abstract": "The human-centric explainable artificial intelligence (HCXAI) community has\nraised the need for framing the explanation process as a conversation between\nhuman and machine. In this position paper, we establish desiderata for\nMediators, text-based conversational agents which are capable of explaining the\nbehavior of neural models interactively using natural language. From the\nperspective of natural language processing (NLP) research, we engineer a\nblueprint of such a Mediator for the task of sentiment analysis and assess how\nfar along current research is on the path towards dialogue-based explanations.",
    "descriptor": "\nComments: Accepted to IJCAI-ECAI 2022 Workshop on Explainable Artificial Intelligence (XAI)\n",
    "authors": [
      "Nils Feldhus",
      "Ajay Madhavan Ravichandran",
      "Sebastian M\u00f6ller"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06029"
  },
  {
    "id": "arXiv:2206.06031",
    "title": "A universal synthetic dataset for machine learning on spectroscopic data",
    "abstract": "To assist in the development of machine learning methods for automated\nclassification of spectroscopic data, we have generated a universal synthetic\ndataset that can be used for model validation. This dataset contains artificial\nspectra designed to represent experimental measurements from techniques\nincluding X-ray diffraction, nuclear magnetic resonance, and Raman\nspectroscopy. The dataset generation process features customizable parameters,\nsuch as scan length and peak count, which can be adjusted to fit the problem at\nhand. As an initial benchmark, we simulated a dataset containing 35,000 spectra\nbased on 500 unique classes. To automate the classification of this data, eight\ndifferent machine learning architectures were evaluated. From the results, we\nshed light on which factors are most critical to achieve optimal performance\nfor the classification task. The scripts used to generate synthetic spectra, as\nwell as our benchmark dataset and evaluation routines, are made publicly\navailable to aid in the development of improved machine learning models for\nspectroscopic analysis.",
    "descriptor": "\nComments: 8 pages, 2 figures, 2 tables\n",
    "authors": [
      "Jan Schuetzke",
      "Nathan J. Szymanski",
      "Markus Reischl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Materials Science (cond-mat.mtrl-sci)"
    ],
    "url": "https://arxiv.org/abs/2206.06031"
  },
  {
    "id": "arXiv:2206.06033",
    "title": "Automatic Contact Tracing using Bluetooth Low Energy Signals and IMU  Sensor Readings",
    "abstract": "In this report, we present our solution to the challenge provided by the SFI\nCentre for Machine Learning (ML-Labs) in which the distance between two phones\nneeds to be estimated. It is a modified version of the NIST Too Close For Too\nLong (TC4TL) Challenge, as the time aspect is excluded. We propose a\nfeature-based approach based on Bluetooth RSSI and IMU sensory data, that\noutperforms the previous state of the art by a significant margin, reducing the\nerror down to 0.071. We perform an ablation study of our model that reveals\ninteresting insights about the relationship between the distance and the\nBluetooth RSSI readings.",
    "descriptor": "",
    "authors": [
      "Suriyadeepan Ramamoorthy",
      "Joyce Mahon",
      "Michael O'Mahony",
      "Jean Francois Itangayenda",
      "Tendai Mukande",
      "Tlamelo Makati"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.06033"
  },
  {
    "id": "arXiv:2206.06043",
    "title": "Combining BMC and Fuzzing Techniques for Finding Software  Vulnerabilities in Concurrent Programs",
    "abstract": "Finding software vulnerabilities in concurrent programs is a challenging task\ndue to the size of the state-space exploration, as the number of interleavings\ngrows exponentially with the number of program threads and statements. We\npropose and evaluate EBF (Ensembles of Bounded Model Checking with Fuzzing) --\na technique that combines Bounded Model Checking (BMC) and Gray-Box Fuzzing\n(GBF) to find software vulnerabilities in concurrent programs. Since there are\nno publicly-available GBF tools for concurrent code, we first propose a novel\nconcurrency-aware gray-box fuzzer that explores different thread schedules by\ninstrumenting the code under test with random delays controlled by the fuzzing\nengine. Then, we build an ensemble of one BMC and one GBF tool in the following\nway. On the one hand, when the BMC tool in the ensemble returns a\ncounterexample, we use it as a seed for our GBF tool, thus increasing the\nlikelihood of executing paths guarded by complex mathematical expressions. On\nthe other hand, we aggregate the outcomes of the BMC and GBF tools in the\nensemble using a decision matrix, thus improving the accuracy of EBF. We\nevaluate EBF against state-of-the-art pure BMC tools and show that it can\ngenerate up to 14.9% more correct verification witnesses than BMC alone.\nFurthermore, we demonstrate the efficacy of our concurrency-aware GBF by\nshowing that it can find 21.4% of the vulnerabilities in our evaluation suite,\nwhile non-concurrency-aware GBF tools can only find 0.55%. Finally, thanks to\nour concurrency-aware GBF tool, EBF detects a data race in the open-source\nwolfMqtt library, which demonstrates its effectiveness in finding\nvulnerabilities in real-world software.",
    "descriptor": "",
    "authors": [
      "Fatimah K. Aljaafari",
      "Rafael Menezes",
      "Edoardo Manino",
      "Fedor Shmarov",
      "Mustafa M. Mustafa",
      "Lucas C. Cordeiro"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.06043"
  },
  {
    "id": "arXiv:2206.06046",
    "title": "Local Dependence and Guarding",
    "abstract": "We study LFD, a base logic of functional dependence introduced by Baltag and\nvan Benthem (2021) and its connections with the guarded fragment GF of\nfirst-order logic. Like other logics of dependence, the semantics of LFD uses\nteams: sets of permissible variable assignments. What sets LFD apart is its\nability to express local dependence between variables and local dependence of\nstatements on variables.\nKnown features of LFD include decidability, explicit axiomatization, finite\nmodel property, and a bisimulation characterization. Others, including the\ncomplexity of satisfiability, remained open so far. More generally, what has\nbeen lacking is a good understanding of what makes the LFD approach to\ndependence computationally well-behaved, and how it relates to other decidable\nlogics. In particular, how do allowing variable dependencies and guarding\nquantifiers compare as logical devices?\nWe provide a new compositional translation from GF into LFD, and conversely,\nwe translate LFD into GF in an `almost compositional' manner. Using these two\ntranslations, we transfer known results about GF to LFD in a uniform manner,\nyielding, e.g., tight complexity bounds for LFD satisfiability, as well as\nCraig interpolation. Conversely, e.g., the finite model property of LFD\ntransfers to GF. Thus, local dependence and guarding turn out to be intricately\nentangled notions.",
    "descriptor": "\nComments: Proceedings of AIML 2022\n",
    "authors": [
      "Johan van Benthem",
      "Balder ten Cate",
      "Raoul Koudijs"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.06046"
  },
  {
    "id": "arXiv:2206.06047",
    "title": "Neuromorphic Wireless Cognition: Event-Driven Semantic Communications  for Remote Inference",
    "abstract": "Neuromorphic computing is an emerging computing paradigm that moves away from\nbatched processing towards the online, event-driven, processing of streaming\ndata. Neuromorphic chips, when coupled with spike-based sensors, can inherently\nadapt to the \"semantics\" of the data distribution by consuming energy only when\nrelevant events are recorded in the timing of spikes and by proving a\nlow-latency response to changing conditions in the environment. This paper\nproposes an end-to-end design for a neuromorphic wireless Internet-of-Things\nsystem that integrates spike-based sensing, processing, and communication. In\nthe proposed NeuroComm system, each sensing device is equipped with a\nneuromorphic sensor, a spiking neural network (SNN), and an impulse radio\ntransmitter with multiple antennas. Transmission takes place over a shared\nfading channel to a receiver equipped with a multi-antenna impulse radio\nreceiver and with an SNN. In order to enable adaptation of the receiver to the\nfading channel conditions, we introduce a hypernetwork to control the weights\nof the decoding SNN using pilots. Pilots, encoding SNNs, decoding SNN, and\nhypernetwork are jointly trained across multiple channel realizations. The\nproposed system is shown to significantly improve over conventional frame-based\ndigital solutions, as well as over alternative non-adaptive training methods,\nin terms of time-to-accuracy and energy consumption metrics.",
    "descriptor": "\nComments: submitted\n",
    "authors": [
      "Jiechen Chen",
      "Nicolas Skatchkovsky",
      "Osvaldo Simeone"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.06047"
  },
  {
    "id": "arXiv:2206.06049",
    "title": "Characterising Modal Formulas with Examples",
    "abstract": "We initiate the study of finite characterizations and exact learnability of\nmodal languages. A finite characterization of a modal formula w.r.t. a set of\nformulas is a finite set of finite models (labelled either positive or\nnegative) which distinguishes this formula from every other formula from that\nset. A modal language L admits finite characterisations if every L-formula has\na finite characterization w.r.t. L. This definition can be applied not only to\nthe basic modal logic K, but to arbitrary normal modal logics. We show that a\nnormal modal logic admits finite characterisations (for the full modal\nlanguage) iff it is locally tabular. This shows that finite characterizations\nwith respect to the full modal language are rare, and hence motivates the study\nof finite characterizations for fragments of the full modal language. Our main\nresult is that the positive modal language without the truth-constants $\\top$\nand $\\bot$ admits finite characterisations. Moreover, we show that this result\nis essentially optimal: finite characterizations no longer exist when the\nlanguage is extended with the truth constant $\\bot$ or with all but very\nlimited forms of negation.",
    "descriptor": "\nComments: AIML 2022 short presentation\n",
    "authors": [
      "Balder ten Cate",
      "Raoul Koudijs"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.06049"
  },
  {
    "id": "arXiv:2206.06053",
    "title": "KATKA: A KRAKEN-like tool with $k$ given at query time",
    "abstract": "We describe a new tool, KATKA, that stores a phylogenetic tree $T$ such that\nlater, given a query $P$ and an integer $k$, it can quickly return the root of\nthe smallest subtree of $T$ containing all the genomes in which the $k$-mer $P\n[i..i + k - 1]$ occurs, for $1 \\leq i \\leq m - k + 1$. This is similar to\nKRAKEN's functionality but with $k$ given at query time instead of at\nconstruction time.",
    "descriptor": "",
    "authors": [
      "Travis Gagie",
      "Sana Kashgouli"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.06053"
  },
  {
    "id": "arXiv:2206.06054",
    "title": "Specifying and Testing $k$-Safety Properties for Machine-Learning Models",
    "abstract": "Machine-learning models are becoming increasingly prevalent in our lives, for\ninstance assisting in image-classification or decision-making tasks.\nConsequently, the reliability of these models is of critical importance and has\nresulted in the development of numerous approaches for validating and verifying\ntheir robustness and fairness. However, beyond such specific properties, it is\nchallenging to specify, let alone check, general functional-correctness\nexpectations from models. In this paper, we take inspiration from\nspecifications used in formal methods, expressing functional-correctness\nproperties by reasoning about $k$ different executions, so-called $k$-safety\nproperties. Considering a credit-screening model of a bank, the expected\nproperty that \"if a person is denied a loan and their income decreases, they\nshould still be denied the loan\" is a 2-safety property. Here, we show the wide\napplicability of $k$-safety properties for machine-learning models and present\nthe first specification language for expressing them. We also operationalize\nthe language in a framework for automatically validating such properties using\nmetamorphic testing. Our experiments show that our framework is effective in\nidentifying property violations, and that detected bugs could be used to train\nbetter models.",
    "descriptor": "",
    "authors": [
      "Maria Christakis",
      "Hasan Ferit Eniser",
      "J\u00f6rg Hoffmann",
      "Adish Singla",
      "Valentin W\u00fcstholz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.06054"
  },
  {
    "id": "arXiv:2206.06057",
    "title": "Low-complexity deep learning frameworks for acoustic scene  classification",
    "abstract": "In this report, we presents low-complexity deep learning frameworks for\nacoustic scene classification (ASC). The proposed frameworks can be separated\ninto four main steps: Front-end spectrogram extraction, online data\naugmentation, back-end classification, and late fusion of predicted\nprobabilities. In particular, we initially transform audio recordings into Mel,\nGammatone, and CQT spectrograms. Next, data augmentation methods of Random\nCropping, Specaugment, and Mixup are then applied to generate augmented\nspectrograms before being fed into deep learning based classifiers. Finally, to\nachieve the best performance, we fuse probabilities which obtained from three\nindividual classifiers, which are independently-trained with three type of\nspectrograms. Our experiments conducted on DCASE 2022 Task 1 Development\ndataset have fullfiled the requirement of low-complexity and achieved the best\nclassification accuracy of 60.1%, improving DCASE baseline by 17.2%.",
    "descriptor": "",
    "authors": [
      "Lam Pham",
      "Dat Ngo",
      "Anahid Jalali",
      "Alexander Schindler"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.06057"
  },
  {
    "id": "arXiv:2206.06061",
    "title": "Sequential Convex Programming for Optimal Line of Sight Steering in  Agile Missions",
    "abstract": "The trend toward onboard autonomy and spacecraft minimization present\nsignificant potential for advances in efficient Line of Sight management by\nmaking optimal use of the limited torque resources available. At SENER\nAeroespacial, we are implementing AOCS algorithms capable of providing agility\nin different observation scenarios in which the exploitation of the resources\nis fundamental for the mission success. In this contribution, we present an\nin-house optimization toolbox for onboard guidance, the SENER Optimization\nToolbox, and we propose its use for online attitude guidance of an agile\nspace-craft using Control Moment Gyroscopes. We propose different optimization\nschemes based on Sequential Convex Programming aiming for reducing the\ncomputational burden for real-time implementations. The results highlight the\npotential for performance improvements when making use of embedded optimal\ncontrol for fast slew maneuvers: with proposed schemes, we find solutions that\nimplicitly manage singularities and are up to 12.2% faster than classical\nbang-bang maneuvers while increasing the smoothness of the trajectories to\nminimize the excitation of flexible modes.",
    "descriptor": "",
    "authors": [
      "Jes\u00fas Ram\u00edrez",
      "Lukas Hewing"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.06061"
  },
  {
    "id": "arXiv:2206.06063",
    "title": "An Asymptotic Preserving and Energy Stable Scheme for the Barotropic  Euler System in the Incompressible Limit",
    "abstract": "An asymptotic preserving and energy stable scheme for the barotropic Euler\nsystem under the low Mach number scaling is designed and analysed. A velocity\nshift proportional to the pressure gradient is introduced in the convective\nfluxes, which leads to the dissipation of mechanical energy and the entropy\nstability at all Mach numbers. The resolution of the semi-implicit in time and\nupwind in space fully-discrete scheme involves two steps: solution of an\nelliptic problem for the density and an explicit evaluation for the velocity.\nThe proposed scheme possess several physically relevant attributes, such as the\npositivity of density, the entropy stability and the consistency with the weak\nformulation of the continuous Euler system. The AP property of the scheme,\ni.e.\\ the boundedness of the mesh parameters with respect to the Mach number\nand its consistency with the incompressible limit system, is shown rigorously.\nThe results of extensive case studies are presented to substantiate the\nrobustness and efficacy of the proposed scheme as well as the theoretical\nclaims.",
    "descriptor": "\nComments: 31 pages\n",
    "authors": [
      "K. R. Arun",
      "Rahuldev Ghorai",
      "Mainak Kar"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.06063"
  },
  {
    "id": "arXiv:2206.06067",
    "title": "Better Teacher Better Student: Dynamic Prior Knowledge for Knowledge  Distillation",
    "abstract": "Knowledge distillation (KD) has shown very promising capabilities in\ntransferring learning representations from large models (teachers) to small\nmodels (students). However, as the capacity gap between students and teachers\nbecomes larger, existing KD methods fail to achieve better results. Our work\nshows that the 'prior knowledge' is vital to KD, especially when applying large\nteachers. Particularly, we propose the dynamic prior knowledge (DPK), which\nintegrates part of the teacher's features as the prior knowledge before the\nfeature distillation. This means that our method also takes the teacher's\nfeature as `input', not just `target'. Besides, we dynamically adjust the ratio\nof the prior knowledge during the training phase according to the feature gap,\nthus guiding the student in an appropriate difficulty. To evaluate the proposed\nmethod, we conduct extensive experiments on two image classification benchmarks\n(i.e. CIFAR100 and ImageNet) and an object detection benchmark (i.e. MS COCO).\nThe results demonstrate the superiority of our method in performance under\nvarying settings. More importantly, our DPK makes the performance of the\nstudent model is positively correlated with that of the teacher model, which\nmeans that we can further boost the accuracy of students by applying larger\nteachers. Our codes will be publicly available for the reproducibility.",
    "descriptor": "",
    "authors": [
      "Zengyu Qiu",
      "Xinzhu Ma",
      "Kunlin Yang",
      "Chunya Liu",
      "Jun Hou",
      "Shuai Yi",
      "Wanli Ouyang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06067"
  },
  {
    "id": "arXiv:2206.06069",
    "title": "Box constraints and weighted sparsity regularization for identifying  sources in elliptic PDEs",
    "abstract": "We explore the possibility for using boundary data to identify sources in\nelliptic PDEs. Even though the associated forward operator has a large null\nspace, it turns out that box constraints, combined with weighted sparsity\nregularization, can enable rather accurate recovery of sources with constant\nmagnitude/strength. In addition, for sources with varying strength, the support\nof the inverse solution will be a subset of the support of the true source. We\npresent both an analysis of the problem and a series of numerical experiments.\nOur work only addresses discretized problems.\nThis investigation is motivated by several applications: interpretation of\nEEG and ECG data, recovering mass distributions from measurements of\ngravitational fields, crack determination and inverse scattering. We develop\nthe methodology and analysis in terms of Euclidean spaces, and our results can\ntherefore be applied to many problems. For example, the results are equally\napplicable to models involving the screened Poisson equation as to models using\nthe Helmholtz equation, with both large and small wave numbers.",
    "descriptor": "",
    "authors": [
      "Ole L\u00f8seth Elvetun",
      "Bj\u00f8rn Fredrik Nielsen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.06069"
  },
  {
    "id": "arXiv:2206.06072",
    "title": "Rank Diminishing in Deep Neural Networks",
    "abstract": "The rank of neural networks measures information flowing across layers. It is\nan instance of a key structural condition that applies across broad domains of\nmachine learning. In particular, the assumption of low-rank feature\nrepresentations leads to algorithmic developments in many architectures. For\nneural networks, however, the intrinsic mechanism that yields low-rank\nstructures remains vague and unclear. To fill this gap, we perform a rigorous\nstudy on the behavior of network rank, focusing particularly on the notion of\nrank deficiency. We theoretically establish a universal monotonic decreasing\nproperty of network rank from the basic rules of differential and algebraic\ncomposition, and uncover rank deficiency of network blocks and deep function\ncoupling. By virtue of our numerical tools, we provide the first empirical\nanalysis of the per-layer behavior of network rank in practical settings, i.e.,\nResNets, deep MLPs, and Transformers on ImageNet. These empirical results are\nin direct accord with our theory. Furthermore, we reveal a novel phenomenon of\nindependence deficit caused by the rank deficiency of deep networks, where\nclassification confidence of a given category can be linearly decided by the\nconfidence of a handful of other categories. The theoretical results of this\nwork, together with the empirical findings, may advance understanding of the\ninherent principles of deep neural networks.",
    "descriptor": "\nComments: 31 pages, 12 figures\n",
    "authors": [
      "Ruili Feng",
      "Kecheng Zheng",
      "Yukun Huang",
      "Deli Zhao",
      "Michael Jordan",
      "Zheng-Jun Zha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.06072"
  },
  {
    "id": "arXiv:2206.06074",
    "title": "On Connections between Opacity and Security in Linear Systems",
    "abstract": "Opacity and attack detectability are important properties for any system as\nthey allow the states to remain private and malicious attacks to be detected,\nrespectively. In this paper, we show that a fundamental trade-off exists\nbetween these properties for a linear dynamical system, in the sense that if an\nopaque system is subjected to attacks, all attacks cannot be detected. We first\ncharacterize the opacity conditions for the system in terms of its weakly\nunobservable subspace (WUS) and show that the number of opaque states is\nproportional to the size of the WUS. Further, we establish conditions under\nwhich increasing the opaque sets also increases the set of undetectable\nattacks. This highlights a fundamental trade-off between security and privacy.\nWe demonstrate application of our results on a remotely controlled automotive\nsystem.",
    "descriptor": "\nComments: 8 pages, 3 figures. Submitted for publication to the IEEE Conference on Decision and Control (CDC) 2022\n",
    "authors": [
      "Varkey M. John",
      "Vaibhav Katewa"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2206.06074"
  },
  {
    "id": "arXiv:2206.06079",
    "title": "OHM: GPU Based Occupancy Map Generation",
    "abstract": "Occupancy grid maps (OGMs) are fundamental to most systems for autonomous\nrobotic navigation. However, CPU-based implementations struggle to keep up with\ndata rates from modern 3D lidar sensors, and provide little capacity for modern\nextensions which maintain richer voxel representations. This paper presents\nOHM, our open source, GPU-based OGM framework. We show how the algorithms can\nbe mapped to GPU resources, resolving difficulties with contention to obtain a\nsuccessful implementation. The implementation supports many modern OGM\nalgorithms including NDT-OM, NDT-TM, decay-rate and TSDF. A thorough\nperformance evaluation is presented based on tracked and quadruped UGV\nplatforms and UAVs, and data sets from both outdoor and subterranean\nenvironments. The results demonstrate excellent performance improvements both\noffline, and for online processing in embedded platforms. Finally, we describe\nhow OHM was a key enabler for the UGV navigation solution for our entry in the\nDARPA Subterranean Challenge, which placed second at the Final Event.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Kazys Stepanas",
      "Jason Williams",
      "Emili Hern\u00e1ndez",
      "Fabio Ruetz",
      "Thomas Hines"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.06079"
  },
  {
    "id": "arXiv:2206.06082",
    "title": "Graph Comparison Based on Adjacency Function Matrix",
    "abstract": "In this paper, we present a new metric distance for comparing two large\ngraphs to find similarities and differences between them based on one of the\nmost important graph structural properties, which is Node Adjacency\nInformation, for all vertices in the graph. Then, we defined a new function and\nsome parameters to find the distance of two large graphs using different\nneighbors of vertices. There are some methods which they focused on the other\nfeatures of graphs to obtain the distance between them, but some of them are\nNode Correspondence which means their node set have the same size. However, in\nthis paper, we introduce a new method which can find the distance between two\nlarge graphs with different size of node set.",
    "descriptor": "",
    "authors": [
      "Arefe Alikhani",
      "Farzad Didehvar"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2206.06082"
  },
  {
    "id": "arXiv:2206.06083",
    "title": "Dataset: Dependency Networks of Open Source Libraries Available Through  CocoaPods, Carthage and Swift PM",
    "abstract": "Third party libraries are used to integrate existing solutions for common\nproblems and help speed up development. The use of third party libraries,\nhowever, can carry risks, for example through vulnerabilities in these\nlibraries. Studying the dependency networks of package managers lets us better\nunderstand and mitigate these risks. So far, the dependency networks of the\nthree most important package managers of the Apple ecosystem, CocoaPods,\nCarthage and Swift PM, have not been studied. We analysed the dependencies for\nall publicly available open source libraries up to December 2021 and compiled a\ndataset containing the dependency networks of all three package managers. The\ndependency networks can be used to analyse how vulnerabilities are propagated\nthrough transitive dependencies. In order to ease the tracing of vulnerable\nlibraries we also queried the NVD database and included publicly reported\nvulnerabilities for these libraries in the dataset.",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Kristiina Rahkema",
      "Dietmar Pfahl"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.06083"
  },
  {
    "id": "arXiv:2206.06088",
    "title": "Social Practices: a Complete Formalization",
    "abstract": "Multi-agent models are a suitable starting point to model complex social\ninteractions. However, as the complexity of the systems increase, we argue that\nnovel modeling approaches are needed that can deal with inter-dependencies at\ndifferent levels of society, where many heterogeneous parties (software agents,\nrobots, humans) are interacting and reacting to each other. In this paper, we\npresent a formalization of a social framework for agents based on the concept\nof Social Practices as high level specifications of normal (expected) behavior\nin a given social context. We argue that social practices facilitate the\npractical reasoning of agents in standard social interactions. Thus they can\nsupport deliberations for complex situations just like conventions and norms.\nHowever, they also come with a social context that gives handles for social\nplanning and deliberation in top of the normal functional deliberation. The\nmain goal of this paper is to give a formalization of social practices that can\nbe used as a basis for implementations and defining precise structures within\nwhich social learning can take place.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1809.08751\n",
    "authors": [
      "Frank Dignum"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2206.06088"
  },
  {
    "id": "arXiv:2206.06089",
    "title": "Graph Neural Networks Intersect Probabilistic Graphical Models: A Survey",
    "abstract": "Graphs are a powerful data structure to represent relational data and are\nwidely used to describe complex real-world data structures. Probabilistic\nGraphical Models (PGMs) have been well-developed in the past years to\nmathematically model real-world scenarios in compact graphical representations\nof distributions of variables. Graph Neural Networks (GNNs) are new inference\nmethods developed in recent years and are attracting growing attention due to\ntheir effectiveness and flexibility in solving inference and learning problems\nover graph-structured data. These two powerful approaches have different\nadvantages in capturing relations from observations and how they conduct\nmessage passing, and they can benefit each other in various tasks. In this\nsurvey, we broadly study the intersection of GNNs and PGMs. Specifically, we\nfirst discuss how GNNs can benefit from learning structured representations in\nPGMs, generate explainable predictions by PGMs, and how PGMs can infer object\nrelationships. Then we discuss how GNNs are implemented in PGMs for more\nefficient inference and structure learning. In the end, we summarize the\nbenchmark datasets used in recent studies and discuss promising future\ndirections.",
    "descriptor": "",
    "authors": [
      "Chenqing Hua"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06089"
  },
  {
    "id": "arXiv:2206.06091",
    "title": "Towards Autonomous Grading In The Real World",
    "abstract": "In this work, we aim to tackle the problem of autonomous grading, where a\ndozer is required to flatten an uneven area. In addition, we explore methods\nfor bridging the gap between a simulated environment and real scenarios. We\ndesign both a realistic physical simulation and a scaled real prototype\nenvironment mimicking the real dozer dynamics and sensory information. We\nestablish heuristics and learning strategies in order to solve the problem.\nThrough extensive experimentation, we show that although heuristics are capable\nof tackling the problem in a clean and noise-free simulated environment, they\nfail catastrophically when facing real world scenarios. As the heuristics are\ncapable of successfully solving the task in the simulated environment, we show\nthey can be leveraged to guide a learning agent which can generalize and solve\nthe task both in simulation and in a scaled prototype environment.",
    "descriptor": "\nComments: 7 pages, submitted to IEEE-IROS2022\n",
    "authors": [
      "Yakov Miron",
      "Chana Ross",
      "Yuval Goldfracht",
      "Chen Tessler",
      "Dotan Di Castro"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06091"
  },
  {
    "id": "arXiv:2206.06098",
    "title": "A comparative study of back propagation and its alternatives on  multilayer perceptrons",
    "abstract": "The de facto algorithm for training the back pass of a feedforward neural\nnetwork is backpropagation (BP). The use of almost-everywhere differentiable\nactivation functions made it efficient and effective to propagate the gradient\nbackwards through layers of deep neural networks. However, in recent years,\nthere has been much research in alternatives to backpropagation. This analysis\nhas largely focused on reaching state-of-the-art accuracy in multilayer\nperceptrons (MLPs) and convolutional neural networks (CNNs). In this paper, we\nanalyze the stability and similarity of predictions and neurons in MLPs and\npropose a new variation of one of the algorithms.",
    "descriptor": "",
    "authors": [
      "John Waldo"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06098"
  },
  {
    "id": "arXiv:2206.06100",
    "title": "AR-NeRF: Unsupervised Learning of Depth and Defocus Effects from Natural  Images with Aperture Rendering Neural Radiance Fields",
    "abstract": "Fully unsupervised 3D representation learning has gained attention owing to\nits advantages in data collection. A successful approach involves a\nviewpoint-aware approach that learns an image distribution based on generative\nmodels (e.g., generative adversarial networks (GANs)) while generating various\nview images based on 3D-aware models (e.g., neural radiance fields (NeRFs)).\nHowever, they require images with various views for training, and consequently,\ntheir application to datasets with few or limited viewpoints remains a\nchallenge. As a complementary approach, an aperture rendering GAN (AR-GAN) that\nemploys a defocus cue was proposed. However, an AR-GAN is a CNN-based model and\nrepresents a defocus independently from a viewpoint change despite its high\ncorrelation, which is one of the reasons for its performance. As an alternative\nto an AR-GAN, we propose an aperture rendering NeRF (AR-NeRF), which can\nutilize viewpoint and defocus cues in a unified manner by representing both\nfactors in a common ray-tracing framework. Moreover, to learn defocus-aware and\ndefocus-independent representations in a disentangled manner, we propose\naperture randomized training, for which we learn to generate images while\nrandomizing the aperture size and latent codes independently. During our\nexperiments, we applied AR-NeRF to various natural image datasets, including\nflower, bird, and face images, the results of which demonstrate the utility of\nAR-NeRF for unsupervised learning of the depth and defocus effects.",
    "descriptor": "\nComments: Accepted to CVPR 2022. Project page: this https URL\n",
    "authors": [
      "Takuhiro Kaneko"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.06100"
  },
  {
    "id": "arXiv:2206.06102",
    "title": "Bin stretching with migration on two hierarchical machines",
    "abstract": "In this paper, we consider semi-online scheduling with migration on two\nhierarchical machines, with the purpose of minimizing the makespan. The meaning\nof two hierarchical machines is that one of the machines can run any job, while\nthe other machine can only run specific jobs. Every instance also has a fixed\nparameter M \\geq 0, known as the migration factor. Jobs are presented one by\none. Each new job has to be assigned to a machine when it arrives, and at the\nsame time it is possible to modify the assignment of previously assigned jobs,\nsuch that the moved jobs have a total size not exceeding M times the size of\nthe new job.\nThe semi-online variant studied here is called bin stretching. In this\nproblem, the optimal makespan is provided to the scheduler in advance. This is\nstill a non-trivial variant for any migration factor M \\geq 0. We prove tight\nbounds on the competitive ratio for any migration factor M, where the design\nand analysis is split into several cases, based on the value of M, and the\nresulting competitive ratio. Unlike the online variant with migration for two\nhierarchical machines, this case allows an online approximation scheme.",
    "descriptor": "",
    "authors": [
      "Islam Akaria",
      "Leah Epstein"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.06102"
  },
  {
    "id": "arXiv:2206.06103",
    "title": "Learning Feature Disentanglement and Dynamic Fusion for Recaptured Image  Forensic",
    "abstract": "Image recapture seriously breaks the fairness of artificial intelligent (AI)\nsystems, which deceives the system by recapturing others' images. Most of the\nexisting recapture models can only address a single pattern of recapture (e.g.,\nmoire, edge, artifact, and others) based on the datasets with simulated\nrecaptured images using fixed electronic devices. In this paper, we explicitly\nredefine image recapture forensic task as four patterns of image recapture\nrecognition, i.e., moire recapture, edge recapture, artifact recapture, and\nother recapture. Meanwhile, we propose a novel Feature Disentanglement and\nDynamic Fusion (FDDF) model to adaptively learn the most effective recapture\nfeature representation for covering different recapture pattern recognition.\nFurthermore, we collect a large-scale Real-scene Universal Recapture (RUR)\ndataset containing various recapture patterns, which is about five times the\nnumber of previously published datasets. To the best of our knowledge, we are\nthe first to propose a general model and a general real-scene large-scale\ndataset for recaptured image forensic. Extensive experiments show that our\nproposed FDDF can achieve state-of-the-art performance on the RUR dataset.",
    "descriptor": "\nComments: Accepted by CVPR2022 workshop\n",
    "authors": [
      "Shuyu Miao",
      "Lin Zheng",
      "Hong Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06103"
  },
  {
    "id": "arXiv:2206.06111",
    "title": "Extending Process Discovery with Model Complexity Optimization and  Cyclic States Identification: Application to Healthcare Processes",
    "abstract": "Within Process mining, discovery techniques had made it possible to construct\nbusiness process models automatically from event logs. However, results often\ndo not achieve the balance between model complexity and its fitting accuracy,\nso there is a need for manual model adjusting. The paper presents an approach\nto process mining providing semi-automatic support to model optimization based\non the combined assessment of the model complexity and fitness. To balance\nbetween the two ingredients, a model simplification approach is proposed, which\nessentially abstracts the raw model at the desired granularity. Additionally,\nwe introduce a concept of meta-states, a cycle collapsing in the model, which\ncan potentially simplify the model and interpret it. We aim to demonstrate the\ncapabilities of the technological solution using three datasets from different\napplications in the healthcare domain. They are remote monitoring process for\npatients with arterial hypertension and workflows of healthcare workers during\nthe COVID-19 pandemic. A case study also investigates the use of various\ncomplexity measures and different ways of solution application providing\ninsights on better practices in improving interpretability and\ncomplexity/fitness balance in process models.",
    "descriptor": "",
    "authors": [
      "Liubov O. Elkhovskaya",
      "Alexander D. Kshenin",
      "Marina A. Balakhontceva",
      "Sergey V. Kovalchuk"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06111"
  },
  {
    "id": "arXiv:2206.06112",
    "title": "Vision-State Fusion: Improving Deep Neural Networks for Autonomous  Robotics",
    "abstract": "Vision-based perception tasks fulfill a paramount role in robotics,\nfacilitating solutions to many challenging scenarios, such as acrobatics\nmaneuvers of autonomous unmanned aerial vehicles (UAVs) and robot-assisted high\nprecision surgery. Most control-oriented and egocentric perception problems are\ncommonly solved by taking advantage of the robot state estimation as an\nauxiliary input, particularly when artificial intelligence comes into the\npicture. In this work, we propose to apply a similar approach for the first\ntime - to the best of our knowledge - to allocentric perception tasks, where\nthe target variables refer to an external subject. We prove how our general and\nintuitive methodology improves the regression performance of deep convolutional\nneural networks (CNNs) with ambiguous problems such as the allocentric 3D pose\nestimation. By analyzing three highly-different use cases, spanning from\ngrasping with a robotic arm to following a human subject with a pocket-sized\nUAV, our results consistently improve the R2 metric up to +0.514 compared to\ntheir stateless baselines. Finally, we validate the in-field performance of a\nclosed-loop autonomous pocket-sized UAV in the human pose estimation task. Our\nresults show a significant reduction, i.e., 24% on average, on the mean\nabsolute error of our stateful CNN.",
    "descriptor": "\nComments: 8 pages, 8 figures\n",
    "authors": [
      "Elia Cereda",
      "Stefano Bonato",
      "Mirko Nava",
      "Alessandro Giusti",
      "Daniele Palossi"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.06112"
  },
  {
    "id": "arXiv:2206.06113",
    "title": "Addressing the \"Leaky Pipeline\": A Review and Categorisation of Actions  to Recruit and Retain Women in Computing Education",
    "abstract": "Gender imbalance in computing education is a well-known issue around the\nworld. The term \"leaky pipeline\" is often used to describe the lack of\nretention of women before they progress to senior roles. Numerous initiatives\nhave targeted the problem of the leaky pipeline in recent decades. This paper\nprovides a comprehensive review of initiatives related to techniques used to\nboost recruitment and retention of women in undergraduate computing and related\ncourses in higher education. The primary aim was to identify interventions or\ninitiatives (which we called \"actions\") that have shown some effectiveness. A\nsecondary objective was to structure our findings as a categorisation, in order\nto enable future action discussion, comparison and planning. A particular\nchallenge faced in a significant portion of the work was the lack of\nevaluation: i.e. the assessment of the direct relationship between the\ninitiatives and the outcomes on retention or recruitment. The actions were\ncategorised into four groups: Policy, Pedagogy, Influence and Support and\nPromotion and Engagement. Policy actions need support and potentially\nstructural change at institution level. Pedagogy actions are initiatives\nrelated to the teaching of computing courses. The Influence and Support\ncategory includes actions associated with ways to influence women to choose\ncomputing and once enrolled to support and encourage them to stay. Finally,\nPromotion and Engagement actions are initiatives to promote computing based\ncourses and involve engagement and outreach activities. We present our\ncategorisation, identifying the literature related to actions under each\ncategory and subcategory. We discuss the challenges with evaluating the direct\nimpact of actions and outline how this work leads towards the next phase of our\nwork - a toolkit of actions to promote retention and recruitment of women in\ncomputing undergraduate courses.",
    "descriptor": "\nComments: 13 pages, 1 figure, 1 table\n",
    "authors": [
      "Alina Berry",
      "Susan McKeever",
      "Brenda Murphy",
      "Sarah Jane Delany"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.06113"
  },
  {
    "id": "arXiv:2206.06117",
    "title": "Optimizing musical chord inversions using the cartesian coordinate  system",
    "abstract": "In classical music and in any genre of contemporary music, the tonal elements\nor notes used for playing are the same. The numerous possibilities of chords\nfor a given instance in a piece make the playing, in general, very intricate,\nand advanced. The theory sounds quite trivial, yet the application has vast\noptions, each leading to inarguably different outcomes, characterized by\nscientific and musical principles. Chords and their importance are\nself-explanatory. A chord is a bunch of notes played together. As far as\nscientists are concerned, it is a set of tonal frequencies ringing together\nresulting in a consonant/dissonant sound. It is well-known that the notes of a\nchord can be rearranged to come up with various voicings (1) of the same chord\nwhich enables a composer/player to choose the most optimal one to convey the\nemotion they wish to convey. Though there are numerous possibilities, it is\nscientific to think that there is just one appropriate voicing for a particular\nsituation of tonal movements. In this study, we attempt to find the optimal\nvoicings by considering chords to be points in a 3-dimensional cartesian\ncoordinate system and further the fundamental understanding of mathematics in\nmusic theory.",
    "descriptor": "\nComments: 9 pages, 5 tables\n",
    "authors": [
      "Steve Mathew D A"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.06117"
  },
  {
    "id": "arXiv:2206.06119",
    "title": "Satellite-based high-resolution maps of cocoa planted area for C\u00f4te  d'Ivoire and Ghana",
    "abstract": "C\\^ote d'Ivoire and Ghana, the world's largest producers of cocoa, account\nfor two thirds of the global cocoa production. In both countries, cocoa is the\nprimary perennial crop, providing income to almost two million farmers. Yet\nprecise maps of cocoa planted area are missing, hindering accurate\nquantification of expansion in protected areas, production and yields, and\nlimiting information available for improved sustainability governance. Here, we\ncombine cocoa plantation data with publicly available satellite imagery in a\ndeep learning framework and create high-resolution maps of cocoa plantations\nfor both countries, validated in situ. Our results suggest that cocoa\ncultivation is an underlying driver of over 37% and 13% of forest loss in\nprotected areas in C\\^ote d'Ivoire and Ghana, respectively, and that official\nreports substantially underestimate the planted area, up to 40% in Ghana. These\nmaps serve as a crucial building block to advance understanding of conservation\nand economic development in cocoa producing regions.",
    "descriptor": "",
    "authors": [
      "Nikolai Kalischek",
      "Nico Lang",
      "C\u00e9cile Renier",
      "Rodrigo Caye Daudt",
      "Thomas Addoah",
      "William Thompson",
      "Wilma J. Blaser-Hart",
      "Rachael Garrett",
      "Konrad Schindler",
      "Jan D. Wegner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.06119"
  },
  {
    "id": "arXiv:2206.06120",
    "title": "Translating automated brain tumour phenotyping to clinical neuroimaging",
    "abstract": "Background: The complex heterogeneity of brain tumours is increasingly\nrecognized to demand data of magnitudes and richness only fully-inclusive,\nlarge-scale collections drawn from routine clinical care could plausibly offer.\nThis is a task contemporary machine learning could facilitate, especially in\nneuroimaging, but its ability to deal with incomplete data common in real world\nclinical practice remains unknown. Here we apply state-of-the-art methods to\nlarge scale, multi-site MRI data to quantify the comparative fidelity of\nautomated tumour segmentation models replicating the various levels of\ncompleteness observed in clinical reality.\nMethods: We compare deep learning (nnU-Net-derived) tumour segmentation\nmodels with all possible combinations of T1, contrast-enhanced T1, T2, and\nFLAIR imaging sequences, trained and validated with five-fold cross-validation\non the 2021 BraTS-RSNA glioma population of 1251 patients, and tested on a\ndiverse, real-world 50 patient sample.\nResults: Models trained on incomplete data segmented lesions well, often\nequivalently to those trained on complete data, exhibiting Dice coefficients of\n0.907 (single sequence) to 0.945 (full datasets) for whole tumours, and 0.701\n(single sequence) to 0.891 (full datasets) for component tissue types.\nIncomplete data segmentation models could accurately detect enhancing tumour in\nthe absence of contrast imaging, quantifying its volume with an R2 between\n0.95-0.97.\nConclusions: Deep learning segmentation models characterize tumours well when\nmissing data and can even detect enhancing tissue without the use of contrast.\nThis suggests translation to clinical practice, where incomplete data is\ncommon, may be easier than hitherto believed, and may be of value in reducing\ndependence on contrast use.",
    "descriptor": "\nComments: 29 pages, 6 figures, 4 supplementary tables\n",
    "authors": [
      "James K Ruffle",
      "Samia Mohinta",
      "Robert J Gray",
      "Harpreet Hyare",
      "Parashkev Nachev"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Tissues and Organs (q-bio.TO)"
    ],
    "url": "https://arxiv.org/abs/2206.06120"
  },
  {
    "id": "arXiv:2206.06122",
    "title": "Singular Value Fine-tuning: Few-shot Segmentation requires  Few-parameters Fine-tuning",
    "abstract": "Freezing the pre-trained backbone has become a standard paradigm to avoid\noverfitting in few-shot segmentation. In this paper, we rethink the paradigm\nand explore a new regime: {\\em fine-tuning a small part of parameters in the\nbackbone}. We present a solution to overcome the overfitting problem, leading\nto better model generalization on learning novel classes. Our method decomposes\nbackbone parameters into three successive matrices via the Singular Value\nDecomposition (SVD), then {\\em only fine-tunes the singular values} and keeps\nothers frozen. The above design allows the model to adjust feature\nrepresentations on novel classes while maintaining semantic clues within the\npre-trained backbone. We evaluate our {\\em Singular Value Fine-tuning (SVF)}\napproach on various few-shot segmentation methods with different backbones. We\nachieve state-of-the-art results on both Pascal-5$^i$ and COCO-20$^i$ across\n1-shot and 5-shot settings. Hopefully, this simple baseline will encourage\nresearchers to rethink the role of backbone fine-tuning in few-shot settings.\nThe source code and models will be available at\n\\url{https://github.com/syp2ysy/SVF}.",
    "descriptor": "",
    "authors": [
      "Yanpeng Sun",
      "Qiang Chen",
      "Xiangyu He",
      "Jian Wang",
      "Haocheng Feng",
      "Junyu Han",
      "Errui Ding",
      "Jian Cheng",
      "Zechao Li",
      "Jingdong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06122"
  },
  {
    "id": "arXiv:2206.06124",
    "title": "Causal Discovery in Hawkes Processes by Minimum Description Length",
    "abstract": "Hawkes processes are a special class of temporal point processes which\nexhibit a natural notion of causality, as occurrence of events in the past may\nincrease the probability of events in the future. Discovery of the underlying\ninfluence network among the dimensions of multi-dimensional temporal processes\nis of high importance in disciplines where a high-frequency data is to model,\ne.g. in financial data or in seismological data. This paper approaches the\nproblem of learning Granger-causal network in multi-dimensional Hawkes\nprocesses. We formulate this problem as a model selection task in which we\nfollow the minimum description length (MDL) principle. Moreover, we propose a\ngeneral algorithm for MDL-based inference using a Monte-Carlo method and we use\nit for our causal discovery problem. We compare our algorithm with the\nstate-of-the-art baseline methods on synthetic and real-world financial data.\nThe synthetic experiments demonstrate superiority of our method incausal graph\ndiscovery compared to the baseline methods with respect to the size of the\ndata. The results of experiments with the G-7 bonds price data are consistent\nwith the experts knowledge.",
    "descriptor": "\nComments: 10 pages, 3 figures; Will be published in Proceedings of the 36th AAAI Conference\n",
    "authors": [
      "Amirkasra Jalaldoust",
      "Katerina Hlavackova-Schindler",
      "Claudia Plant"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2206.06124"
  },
  {
    "id": "arXiv:2206.06126",
    "title": "Robust Time Series Denoising with Learnable Wavelet Packet Transform",
    "abstract": "In many applications, signal denoising is often the first pre-processing step\nbefore any subsequent analysis or learning task. In this paper, we propose to\napply a deep learning denoising model inspired by a signal processing, a\nlearnable version of wavelet packet transform. The proposed algorithm has\nsignficant learning capabilities with few interpretable parameters and has an\nintuitive initialisation. We propose a post-learning modification of the\nparameters to adapt the denoising to different noise levels. We evaluate the\nperformance of the proposed methodology on two case studies and compare it to\nother state of the art approaches, including wavelet schrinkage denoising,\nconvolutional neural network, autoencoder and U-net deep models. The first case\nstudy is based on designed functions that have typically been used to study\ndenoising properties of the algorithms. The second case study is an audio\nbackground removal task. We demonstrate how the proposed algorithm relates to\nthe universality of signal processing methods and the learning capabilities of\ndeep learning approaches. In particular, we evaluate the obtained denoising\nperformances on structured noisy signals inside and outside the classes used\nfor training. In addition to having good performance in denoising signals\ninside and outside to the training class, our method shows to be particularly\nrobust when different noise levels, noise types and artifacts are added.",
    "descriptor": "\nComments: 15 pages, 13 figures, 8 tables\n",
    "authors": [
      "Gaetan Frusque",
      "Olga Fink"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.06126"
  },
  {
    "id": "arXiv:2206.06128",
    "title": "Agents facilitate one category of human empathy through task difficulty",
    "abstract": "One way to improve the relationship between humans and anthropomorphic agents\nis to have humans empathize with the agents. In this study, we focused on a\ntask between agents and humans. We experimentally investigated hypotheses\nstating that task difficulty and task content facilitate human empathy. The\nexperiment was a two-way analysis of variance (ANOVA) with four conditions:\ntask difficulty (high, low) and task content (competitive, cooperative). The\nresults showed no main effect for the task content factor and a significant\nmain effect for the task difficulty factor. In addition, pre-task empathy\ntoward the agent decreased after the task. The ANOVA showed that one category\nof empathy toward the agent increased when the task difficulty was higher than\nwhen it was lower.This indicated that this category of empathy was more likely\nto be affected by the task. The task itself used can be an important factor\nwhen manipulating each category of empathy.",
    "descriptor": "\nComments: Accepted by RO-MAN2022, 7 pages, 5 figures, 3 tables\n",
    "authors": [
      "Takahiro Tsumura",
      "Seiji Yamada"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.06128"
  },
  {
    "id": "arXiv:2206.06129",
    "title": "A Synapse-Threshold Synergistic Learning Approach for Spiking Neural  Networks",
    "abstract": "Spiking neural networks (SNNs) have demonstrated excellent capabilities in\nvarious intelligent scenarios. Most existing methods for training SNNs are\nbased on the concept of synaptic plasticity; however, learning in the realistic\nbrain also utilizes intrinsic non-synaptic mechanisms of neurons. The spike\nthreshold of biological neurons is a critical intrinsic neuronal feature that\nexhibits rich dynamics on a millisecond timescale and has been proposed as an\nunderlying mechanism that facilitates neural information processing. In this\nstudy, we develop a novel synergistic learning approach that simultaneously\ntrains synaptic weights and spike thresholds in SNNs. SNNs trained with\nsynapse-threshold synergistic learning (STL-SNNs) achieve significantly higher\naccuracies on various static and neuromorphic datasets than SNNs trained with\ntwo single-learning models of the synaptic learning (SL) and the threshold\nlearning (TL). During training, the synergistic learning approach optimizes\nneural thresholds, providing the network with stable signal transmission via\nappropriate firing rates. Further analysis indicates that STL-SNNs are robust\nto noisy data and exhibit low energy consumption for deep network structures.\nAdditionally, the performance of STL-SNN can be further improved by introducing\na generalized joint decision framework (JDF). Overall, our findings indicate\nthat biologically plausible synergies between synaptic and intrinsic\nnon-synaptic mechanisms may provide a promising approach for developing highly\nefficient SNN learning methods.",
    "descriptor": "\nComments: 13 pages, 9 figures, submitted to the IEEE Transactions on Neural Networks and Learning Systems (TNNLS)\n",
    "authors": [
      "Hongze Sun",
      "Wuque Cai",
      "Baoxin Yang",
      "Yan Cui",
      "Yang Xia",
      "Dezhong Yao",
      "Daqing Guo"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2206.06129"
  },
  {
    "id": "arXiv:2206.06134",
    "title": "Dynamics of opinion polarization",
    "abstract": "For decades, researchers have been trying to understand how people form their\nopinions. This quest has become even more pressing with the widespread usage of\nonline social networks and social media, which seem to amplify the already\nexisting phenomenon of polarization. In this work, we study the problem of\npolarization assuming that opinions evolve according to the popular\nFriedkin-Johnsen (FJ) model. The FJ model is one of the few existing opinion\ndynamics models that has been validated on small/medium-sized social groups.\nFirst, we carry out a comprehensive survey of the FJ model in the literature\n(distinguishing its main variants) and of the many polarization metrics\navailable, deriving an invariant relation among them. Secondly, we derive the\nconditions under which the FJ variants are able to induce opinion polarization\nin a social network, as a function of the social ties between the nodes and\ntheir individual susceptibility to the opinion of others. Thirdly, we discuss a\nmethodology for finding concrete opinion vectors that are able to bring the\nnetwork to a polarized state. Finally, our analytical results are applied to\ntwo real social network graphs, showing how our theoretical findings can be\nused to identify polarizing conditions under various configurations.",
    "descriptor": "\nComments: 45 pages, 8 figures\n",
    "authors": [
      "E. Biondi",
      "C. Boldrini",
      "A. Passarella",
      "M. Conti"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.06134"
  },
  {
    "id": "arXiv:2206.06135",
    "title": "Flexible Differentiable Optimization via Model Transformations",
    "abstract": "We introduce DiffOpt.jl, a Julia library to differentiate through the\nsolution of convex optimization problems with respect to arbitrary parameters\npresent in the objective and/or constraints. The library builds upon\nMathOptInterface, thus leveraging the rich ecosystem of solvers and composing\nwell with modelling languages like JuMP. DiffOpt offers both forward and\nreverse differentiation modes, enabling multiple use cases from hyperparameter\noptimization to backpropagation and sensitivity analysis, bridging constrained\noptimization with end-to-end differentiable programming.",
    "descriptor": "",
    "authors": [
      "Akshay Sharma",
      "Mathieu Besan\u00e7on",
      "Joaquim Dias Garcia",
      "Beno\u00eet Legat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Mathematical Software (cs.MS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.06135"
  },
  {
    "id": "arXiv:2206.06137",
    "title": "Absolute Expressiveness of Subgraph Motif Centrality Measures",
    "abstract": "In graph-based applications, a common task is to pinpoint the most important\nor ``central'' vertex in a (directed or undirected) graph, or rank the vertices\nof a graph according to their importance. To this end, a plethora of so-called\ncentrality measures have been proposed in the literature that assess which\nvertices in a graph are the most important ones. Riveros and Salas, in an ICDT\n2020 paper, proposed a family of centrality measures based on the following\nintuitive principle: the importance of a vertex in a graph is relative to the\nnumber of ``relevant'' connected subgraphs, known as subgraph motifs,\nsurrounding it. We refer to the measures derived from the above principle as\nsubgraph motif measures. It has been convincingly argued that subgraph motif\nmeasures are well-suited for graph database applications. Although the ICDT\npaper studied several favourable properties enjoyed by subgraph motif measures,\ntheir absolute expressiveness remains largely unexplored. The goal of this work\nis to precisely characterize the absolute expressiveness of the family of\nsubgraph motif measures.",
    "descriptor": "",
    "authors": [
      "Andreas Pieris",
      "Jorge Salas"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2206.06137"
  },
  {
    "id": "arXiv:2206.06141",
    "title": "Am I No Good? Towards Detecting Perceived Burdensomeness and Thwarted  Belongingness from Suicide Notes",
    "abstract": "The World Health Organization (WHO) has emphasized the importance of\nsignificantly accelerating suicide prevention efforts to fulfill the United\nNations' Sustainable Development Goal (SDG) objective of 2030. In this paper,\nwe present an end-to-end multitask system to address a novel task of detection\nof two interpersonal risk factors of suicide, Perceived Burdensomeness (PB) and\nThwarted Belongingness (TB) from suicide notes. We also introduce a manually\ntranslated code-mixed suicide notes corpus, CoMCEASE-v2.0, based on the\nbenchmark CEASE-v2.0 dataset, annotated with temporal orientation, PB and TB\nlabels. We exploit the temporal orientation and emotion information in the\nsuicide notes to boost overall performance. For comprehensive evaluation of our\nproposed method, we compare it to several state-of-the-art approaches on the\nexisting CEASE-v2.0 dataset and the newly announced CoMCEASE-v2.0 dataset.\nEmpirical evaluation suggests that temporal and emotional information can\nsubstantially improve the detection of PB and TB.",
    "descriptor": "\nComments: Accepted for publication at IJCAI-ECAI 2022 (AI for Good Track)\n",
    "authors": [
      "Soumitra Ghosh",
      "Asif Ekbal",
      "Pushpak Bhattacharyya"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.06141"
  },
  {
    "id": "arXiv:2206.06147",
    "title": "A DSEL for High Throughput and Low Latency Software-Defined Radio on  Multicore CPUs",
    "abstract": "This article presents a new Domain Specific Embedded Language (DSEL)\ndedicated to Software-Defined Radio (SDR). From a set of carefully designed\ncomponents, it enables to build efficient software digital communication\nsystems, able to take advantage of the parallelism of modern processor\narchitectures, in a straightforward and safe manner for the programmer. In\nparticular, proposed DSEL enables the combination of pipelining and sequence\nduplication techniques to extract both temporal and spatial parallelism from\ndigital communication systems. We leverage the DSEL capabilities on a real use\ncase: a fully digital transceiver for the widely used DVB-S2 standard designed\nentirely in software. Through evaluation, we show how proposed software DVB-S2\ntransceiver is able to get the most from modern, high-end multicore CPU\ntargets.",
    "descriptor": "",
    "authors": [
      "Adrien Cassagne",
      "Romain Tajan",
      "Olivier Aumage",
      "Camille Leroux",
      "Denis Barthou",
      "Christophe J\u00e9go"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.06147"
  },
  {
    "id": "arXiv:2206.06149",
    "title": "Tackling Algorithmic Disability Discrimination in the Hiring Process: An  Ethical, Legal and Technical Analysis",
    "abstract": "Tackling algorithmic discrimination against persons with disabilities (PWDs)\ndemands a distinctive approach that is fundamentally different to that applied\nto other protected characteristics, due to particular ethical, legal, and\ntechnical challenges. We address these challenges specifically in the context\nof artificial intelligence (AI) systems used in hiring processes (or automated\nhiring systems, AHSs), in which automated assessment procedures are subject to\nunique ethical and legal considerations and have an undeniable adverse impact\non PWDs. In this paper, we discuss concerns and opportunities raised by\nAI-driven hiring in relation to disability discrimination. Ultimately, we aim\nto encourage further research into this topic. Hence, we establish some\nstarting points and design a roadmap for ethicists, lawmakers, advocates as\nwell as AI practitioners alike.",
    "descriptor": "\nComments: FAccT 2022 proceedings\n",
    "authors": [
      "Maarten Buyl",
      "Christina Cociancig",
      "Cristina Frattone",
      "Nele Roekens"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.06149"
  },
  {
    "id": "arXiv:2206.06150",
    "title": "Spectral analysis of high order continuous FEM for hyperbolic PDEs on  triangular meshes: influence of approximation, stabilization, and  time-stepping",
    "abstract": "In this work we study various continuous finite element discretization for\ntwo dimensional hyperbolic partial differential equations, varying the\npolynomial space (Lagrangian on equispaced, Lagrangian on quadrature points\n(Cubature) and Bernstein), the stabilization techniques (streamline-upwind\nPetrov-Galerkin, continuous interior penalty, orthogonal subscale\nstabilization) and the time discretization (Runge-Kutta (RK), strong stability\npreserving RK and deferred correction). This is an extension of the one\ndimensional study by Michel S. et al J. Sci. Comput. (2021), whose results do\nnot hold in multi-dimensional frameworks. The study ranks these schemes based\non efficiency (most of them are mass-matrix free), stability and dispersion\nerror, providing the best CFL and stabilization coefficients. The challenges in\ntwo-dimensions are related to the Fourier analysis. Here, we perform it on two\ntypes of periodic triangular meshes varying the angle of the advection, and we\ncombine all the results for a general stability analysis. Furthermore, we\nintroduce additional high order viscosity to stabilize the discontinuities, in\norder to show how to use these methods for tests of practical interest. All the\ntheoretical results are thoroughly validated numerically both on linear and\nnon-linear problems, and error-CPU time curves are provided. Our final\nconclusions suggest that Cubature elements combined with SSPRK and OSS\nstabilization is the most promising combination.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2103.16158\n",
    "authors": [
      "Sixtine Michel",
      "Davide Torlo",
      "Mario Ricchiuto",
      "R\u00e9mi Abgrall"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.06150"
  },
  {
    "id": "arXiv:2206.06155",
    "title": "Concept Identification for Complex Engineering Datasets",
    "abstract": "Finding meaningful concepts in engineering application datasets which allow\nfor a sensible grouping of designs is very helpful in many contexts. It allows\nfor determining different groups of designs with similar properties and\nprovides useful knowledge in the engineering decision making process. Also, it\nopens the route for further refinements of specific design candidates which\nexhibit certain characteristic features. In this work, an approach to define\nmeaningful and consistent concepts in an existing engineering dataset is\npresented. The designs in the dataset are characterized by a multitude of\nfeatures such as design parameters, geometrical properties or performance\nvalues of the design for various boundary conditions. In the proposed approach\nthe complete feature set is partitioned into several subsets called description\nspaces. The definition of the concepts respects this partitioning which leads\nto several desired properties of the identified concepts, which cannot be\nachieved with state-of-the-art clustering or concept identification approaches.\nA novel concept quality measure is proposed, which provides an objective value\nfor a given definition of concepts in a dataset. The usefulness of the measure\nis demonstrated by considering a realistic engineering dataset consisting of\nabout 2500 airfoil profiles where the performance values (lift and drag) for\nthree different operating conditions were obtained by a computational fluid\ndynamics simulation. A numerical optimization procedure is employed which\nmaximizes the concept quality measure, and finds meaningful concepts for\ndifferent setups of the description spaces while also incorporating user\npreference. It is demonstrated how these concepts can be used to select\narchetypal representatives of the dataset which exhibit characteristic features\nof each concept.",
    "descriptor": "\nComments: 18 pages, 14 figures, submitted to Advanced Engineering Informatics\n",
    "authors": [
      "Felix Lanfermann",
      "Sebastian Schmitt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06155"
  },
  {
    "id": "arXiv:2206.06157",
    "title": "Towards Target High-Utility Itemsets",
    "abstract": "For applied intelligence, utility-driven pattern discovery algorithms can\nidentify insightful and useful patterns in databases. However, in these\ntechniques for pattern discovery, the number of patterns can be huge, and the\nuser is often only interested in a few of those patterns. Hence, targeted\nhigh-utility itemset mining has emerged as a key research topic, where the aim\nis to find a subset of patterns that meet a targeted pattern constraint instead\nof all patterns. This is a challenging task because efficiently finding\ntailored patterns in a very large search space requires a targeted mining\nalgorithm. A first algorithm called TargetUM has been proposed, which adopts an\napproach similar to post-processing using a tree structure, but the running\ntime and memory consumption are unsatisfactory in many situations. In this\npaper, we address this issue by proposing a novel list-based algorithm with\npattern matching mechanism, named THUIM (Targeted High-Utility Itemset Mining),\nwhich can quickly match high-utility itemsets during the mining process to\nselect the targeted patterns. Extensive experiments were conducted on different\ndatasets to compare the performance of the proposed algorithm with\nstate-of-the-art algorithms. Results show that THUIM performs very well in\nterms of runtime and memory consumption, and has good scalability compared to\nTargetUM.",
    "descriptor": "\nComments: Preprint. 6 figures, 5 tables\n",
    "authors": [
      "Jinbao Miao",
      "Wensheng Gan",
      "Shicheng Wan",
      "Yongdong Wu",
      "Philippe Fournier-Viger"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.06157"
  },
  {
    "id": "arXiv:2206.06158",
    "title": "A Semi Empirical Approach to a Physically Based Aging Model for Home  Energy Management Systems",
    "abstract": "A growing interest in the study of aging related phenomena in lithium-ion\nbatteries is propelled by the increasing utilization of energy storage systems\nin electric vehicles and in buildings as stationery energy accumulators paired\nwith renewable energy sources. This paper proposes a mixed-degradation model\napproach that combines the benefits of a semi-empirical approach with that of a\nphysics-based model. This enables easy calibration for different battery\nchemistries, the ability to extrapolate when necessary, and is computationally\nefficient enough to be coupled with real-time running control systems. To\ndemonstrate the effectiveness of the proposed approach, the effect of two\ndifferent control strategies in a smart home energy management system is\ndemonstrated on the aging of a Lithium iron phosphate (LFP) battery.",
    "descriptor": "",
    "authors": [
      "Cory Miller",
      "Mithun Goutham",
      "Xiaoling Chen",
      "Prasad Dev Hanumalagutti",
      "Rachel Blaser",
      "Stephanie Stockar"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.06158"
  },
  {
    "id": "arXiv:2206.06164",
    "title": "Metric Program Synthesis for Inverse CSG",
    "abstract": "In this paper, we present a new method for solving the inverse constructive\nsolid geometry (CSG) problem, which aims to generate a programmatic\nrepresentation of a scene from its unstructured representation (e.g., a raster\nimage). Our method, called metric program synthesis, hinges on the observation\nthat many programs in the inverse CSG domain produce similar (but not\nidentical) images. Based on this observation, we propose clustering programs\nbased on a distance metric and constructing a version space that compactly\nrepresents \"approximately correct\" programs. Given a \"close enough\" program\nsampled from this version space, our approach uses a distance-guided repair\nalgorithm to find a program that exactly matches the given image.\nWe have implemented our proposed metric program synthesis technique in a tool\ncalled SyMetric and evaluate it in the inverse CSG domain. Our evaluation on 40\nbenchmarks shows that SyMetric can effectively solve inverse CSG problems that\nare beyond scope for existing synthesis techniques. In particular, SyMetric\nsolves 78% of these benchmarks whereas the closest competitor can only solve\n8%. Our evaluation also shows the benefits of similarity-based clustering and\nother salient features of our approach through a series of ablation studies.",
    "descriptor": "",
    "authors": [
      "John Feser",
      "Isil Dillig",
      "Armando Solar-Lezama"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2206.06164"
  },
  {
    "id": "arXiv:2206.06165",
    "title": "The Classification of Optical Galaxy Morphology Using Unsupervised  Learning Techniques",
    "abstract": "The advent of large scale, data intensive astronomical surveys has caused the\nviability of human-based galaxy morphology classification methods to come into\nquestion. Put simply, too much astronomical data is being produced for\nscientists to visually label. Attempts have been made to crowd-source this work\nby recruiting volunteers from the general public. However, even these efforts\nwill soon fail to keep up with data produced by modern surveys. Unsupervised\nlearning techniques do not require existing labels to classify data and could\npave the way to unplanned discoveries. Therefore, this paper aims to implement\nunsupervised learning algorithms to classify the Galaxy Zoo DECaLS dataset\nwithout human supervision. First, a convolutional autoencoder was implemented\nas a feature extractor. The extracted features were then clustered via k-means,\nfuzzy c-means and agglomerative clustering to provide classifications. The\nresults were compared to the volunteer classifications of the Galaxy Zoo DECaLS\ndataset. Agglomerative clustering generally produced the best results, however,\nthe performance gain over k-means clustering was not significant. With the\nappropriate optimizations, this approach could be used to provide\nclassifications for the better performing Galaxy Zoo DECaLS decision tree\nquestions. Ultimately, this unsupervised learning approach provided valuable\ninsights and results that were useful to scientists.",
    "descriptor": "\nComments: 6 pages, to be presented at the International Conference on Electrical, Computer and Energy Technologies (ICECET 2022) 20-22 July 2022, Prague-Czech Republic\n",
    "authors": [
      "Ezra Fielding",
      "Clement N. Nyirenda",
      "Mattia Vaccari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)"
    ],
    "url": "https://arxiv.org/abs/2206.06165"
  },
  {
    "id": "arXiv:2206.06168",
    "title": "2nd Place Solution for ICCV 2021 VIPriors Image Classification  Challenge: An Attract-and-Repulse Learning Approach",
    "abstract": "Convolutional neural networks (CNNs) have achieved significant success in\nimage classification by utilizing large-scale datasets. However, it is still of\ngreat challenge to learn from scratch on small-scale datasets efficiently and\neffectively. With limited training datasets, the concepts of categories will be\nambiguous since the over-parameterized CNNs tend to simply memorize the\ndataset, leading to poor generalization capacity. Therefore, it is crucial to\nstudy how to learn more discriminative representations while avoiding\nover-fitting. Since the concepts of categories tend to be ambiguous, it is\nimportant to catch more individual-wise information. Thus, we propose a new\nframework, termed Attract-and-Repulse, which consists of Contrastive\nRegularization (CR) to enrich the feature representations, Symmetric Cross\nEntropy (SCE) to balance the fitting for different classes and Mean Teacher to\ncalibrate label information. Specifically, SCE and CR learn discriminative\nrepresentations while alleviating over-fitting by the adaptive trade-off\nbetween the information of classes (attract) and instances (repulse). After\nthat, Mean Teacher is used to further improve the performance via calibrating\nmore accurate soft pseudo labels. Sufficient experiments validate the\neffectiveness of the Attract-and-Repulse framework. Together with other\nstrategies, such as aggressive data augmentation, TenCrop inference, and models\nensembling, we achieve the second place in ICCV 2021 VIPriors Image\nClassification Challenge.",
    "descriptor": "\nComments: 2nd Place Solution for ICCV 2021 VIPriors Image Classification Challenge\n",
    "authors": [
      "Yilu Guo",
      "Shicai Yang",
      "Weijie Chen",
      "Liang Ma",
      "Di Xie",
      "Shiliang Pu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06168"
  },
  {
    "id": "arXiv:2206.06169",
    "title": "iCITRIS: Causal Representation Learning for Instantaneous Temporal  Effects",
    "abstract": "Causal representation learning is the task of identifying the underlying\ncausal variables and their relations from high-dimensional observations, such\nas images. Recent work has shown that one can reconstruct the causal variables\nfrom temporal sequences of observations under the assumption that there are no\ninstantaneous causal relations between them. In practical applications,\nhowever, our measurement or frame rate might be slower than many of the causal\neffects. This effectively creates \"instantaneous\" effects and invalidates\nprevious identifiability results. To address this issue, we propose iCITRIS, a\ncausal representation learning method that can handle instantaneous effects in\ntemporal sequences when given perfect interventions with known intervention\ntargets. iCITRIS identifies the causal factors from temporal observations,\nwhile simultaneously using a differentiable causal discovery method to learn\ntheir causal graph. In experiments on three video datasets, iCITRIS accurately\nidentifies the causal factors and their causal graph.",
    "descriptor": "",
    "authors": [
      "Phillip Lippe",
      "Sara Magliacane",
      "Sindy L\u00f6we",
      "Yuki M. Asano",
      "Taco Cohen",
      "Efstratios Gavves"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.06169"
  },
  {
    "id": "arXiv:2206.06171",
    "title": "Vildehaye: A Family of Versatile, Widely-Applicable, and Field-Proven  Lightweight Wildlife Tracking and Sensing Tags",
    "abstract": "We describe the design and implementation of Vildehaye, a family of\nversatile, widely-applicable, and field-proven tags for wildlife sensing and\nradio tracking. The family includes 6 distinct hardware designs for tags, 3\nadd-on boards, a programming adapter, and base stations; modular firmware for\ntags and base stations (both standalone low-power embedded base stations and\nbase stations tethered to a computer running Linux or Windows); and desktop\nsoftware for programming and configuring tags, monitoring tags, and downloading\nand processing sensor data. The tags are versatile: they support multiple\npacket formats, data rates, and frequency bands; they can be configured for\nminimum mass (down to less than 1g), making them applicable to a wide range of\nflying and terrestrial animals, or for inclusion of important sensors and large\nmemories; they can transmit packets compatible with time-of-arrival\ntransmitter-localization systems, tag identification and state packets, and\nthey can reliably upload sensor data through their radio link. The system has\nbeen designed, upgraded, and maintained as an academic research project, but it\nhas been extensively used by 5 different groups of ecologists in 4 countries\nover a period of 5 years. More than 7100 tags have been produced and most of\nthese have been deployed. Production used 41 manufacturing runs. The tags have\nbeen used in studies that so far resulted in 9 scientific publications in\necology (including in Science). The paper describes innovative design aspects\nof Vildehaye, field-use experiences, and lessons from the design,\nimplementation, and maintenance of the system. Both the hardware and software\nof the system are open.",
    "descriptor": "\nComments: Accepted version of IPSN 2022 paper\n",
    "authors": [
      "Sivan Toledo",
      "Shai Mendel",
      "Anat Levi",
      "Yoni Vortman",
      "Wiebke Ullmann",
      "Lena-Rosa Scherer",
      "Jan Pufelski",
      "Frank van Maarseveen",
      "Bas Denissen",
      "Allert Bijleveld",
      "Yotam Orchan",
      "Yoav Bartan",
      "Sivan Margalit",
      "Idan Talmon",
      "Ran Nathan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.06171"
  },
  {
    "id": "arXiv:2206.06173",
    "title": "LiVeR: Lightweight Vehicle Detection and Classification in Real-Time",
    "abstract": "Detection and classification of vehicles are very significant components in\nan Intelligent-Transportation System. Existing solutions not only use\nheavy-weight and costly equipment, but also largely depend on constant cloud\n(Internet) connectivity, as well as adequate uninterrupted power-supply. Such\ndependencies make these solutions fundamentally impractical considering the\npossible adversities of outdoor environment as well as requirement of\ncorrelated wide-area operation. For practical use, apart from being technically\nsound and accurate, a solution has to be lightweight, cost-effective,\neasy-to-install, flexible as well as supporting efficient time-correlated\ncoverage over large area. In this work we propose an IoT-assisted strategy to\nfulfil all these goals together. We adopt a top-down approach where we first\nintroduce a lightweight framework for time-correlated low-cost wide-area\nmeasurement and then reuse the concept for developing the individual\nmeasurement units. Our extensive outdoor measurement studies and trace-based\nsimulation on the empirical data show about 98% accuracy in vehicle detection\nand upto 93% of accuracy in classification of the vehicles over moderately busy\nurban roads.",
    "descriptor": "",
    "authors": [
      "Chandra Shekhar",
      "Jagnyashini Debadarshini",
      "Sudipta Saha"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06173"
  },
  {
    "id": "arXiv:2206.06174",
    "title": "Predicting Corporate Risk by Jointly Modeling Company Networks and  Dialogues in Earnings Conference Calls",
    "abstract": "More and more researchers focus on studying company risk prediction based on\nearnings conference calls because of their free form and rich information.\nHowever, existing research does not take speaker role information into account.\nBesides, current research does not fully consider the impact of inter-company\nrelationships on company risk. The only study integrating company networks and\nearnings conference calls constructs companies in an undirected graph, which\ndoes not meet the requirement of no temporal information leakage for prediction\ntasks. To solve the above problems, we propose a new model -- Temporal Virtual\nGraph Neural Network (TVGNN), to incorporate earnings conference calls and\ncompany networks for company risk prediction. Our model incorporates the\nspeaker's role information in the dialogue modeling for the first time. In\naddition, we design a new method to construct company networks that can ensure\nno temporal information leakage in the graph. The experimental results show\nthat the proposed model exceeds all baselines. The case study shows that the\nprediction results of the model are interpretable.",
    "descriptor": "",
    "authors": [
      "Yunxin Sang",
      "Yang Bao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06174"
  },
  {
    "id": "arXiv:2206.06175",
    "title": "Generation of Patient-specific Structured Hexahedral Mesh of Aortic  Aneurysm Wall",
    "abstract": "Abdominal Aortic Aneurysm (AAA) is an enlargement in the lower part of the\nmain artery Aorta by 1.5 times its normal diameter. AAA can cause death if\nrupture occurs. Elective surgeries are recommended to prevent rupture based on\ngeometrical measurements of AAA diameter and diameter growth rate. Reliability\nof these geometric parameters to predict the AAA rupture risk has been\nquestioned, and biomechanical assessment has been proposed to distinguish\nbetween patients with high and low risk of rupture. Stress in aneurysm wall is\nthe main variable of interest in such assessment. Most studies use finite\nelement method to compute AAA stress. This requires discretising\npatient-specific geometry (aneurysm wall and intraluminal thrombus ILT) into\nfinite elements/meshes. Tetrahedral elements are most commonly used as they can\nbe generated in seemingly automated and effortless way. In practice, however,\ndue to complex aneurysm geometry, the process tends to require time consuming\nmesh optimisation to ensure sufficiently high quality of tetrahedral elements.\nFurthermore, ensuring solution convergence requires large number of tetrahedral\nelements, which leads to long computation times. In this study, we focus on\ngeneration of hexahedral meshes as they are known to provide converged solution\nfor smaller number of elements than tetrahedral meshes. Generation of\nhexahedral meshes for continua with complex/irregular geometry, such as\naneurysms, requires analyst interaction. We propose a procedure for generating\nhigh quality patient-specific hexahedral discretisation of aneurysm wall using\nthe algorithms available in commercial software package for mesh generation.\nFor aneurysm cases, we demonstrate that the procedure facilitates\npatient-specific mesh generation within timeframe consistent with clinical\nworkflow constraints while requiring only limited input from the analyst.",
    "descriptor": "\nComments: Medical Image Computing and Computer Assisted Intervention MICCAI 2022 Computational Biomechanics for Medicine Workshop\n",
    "authors": [
      "Farah Alkhatib",
      "George C. Bourantas",
      "Adam Wittek",
      "Karol Miller"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2206.06175"
  },
  {
    "id": "arXiv:2206.06177",
    "title": "Transductive CLIP with Class-Conditional Contrastive Learning",
    "abstract": "Inspired by the remarkable zero-shot generalization capacity of\nvision-language pre-trained model, we seek to leverage the supervision from\nCLIP model to alleviate the burden of data labeling. However, such supervision\ninevitably contains the label noise, which significantly degrades the\ndiscriminative power of the classification model. In this work, we propose\nTransductive CLIP, a novel framework for learning a classification network with\nnoisy labels from scratch. Firstly, a class-conditional contrastive learning\nmechanism is proposed to mitigate the reliance on pseudo labels and boost the\ntolerance to noisy labels. Secondly, ensemble labels is adopted as a pseudo\nlabel updating strategy to stabilize the training of deep neural networks with\nnoisy labels. This framework can reduce the impact of noisy labels from CLIP\nmodel effectively by combining both techniques. Experiments on multiple\nbenchmark datasets demonstrate the substantial improvements over other\nstate-of-the-art methods.",
    "descriptor": "\nComments: Published in IEEE ICASSP 2022\n",
    "authors": [
      "Junchu Huang",
      "Weijie Chen",
      "Shicai Yang",
      "Di Xie",
      "Shiliang Pu",
      "Yueting Zhuang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.06177"
  },
  {
    "id": "arXiv:2206.06178",
    "title": "EGRU: Event-based GRU for activity-sparse inference and learning",
    "abstract": "The scalability of recurrent neural networks (RNNs) is hindered by the\nsequential dependence of each time step's computation on the previous time\nstep's output. Therefore, one way to speed up and scale RNNs is to reduce the\ncomputation required at each time step independent of model size and task. In\nthis paper, we propose a model that reformulates Gated Recurrent Units (GRU) as\nan event-based activity-sparse model that we call the Event-based GRU (EGRU),\nwhere units compute updates only on receipt of input events (event-based) from\nother units. When combined with having only a small fraction of the units\nactive at a time (activity-sparse), this model has the potential to be vastly\nmore compute efficient than current RNNs. Notably, activity-sparsity in our\nmodel also translates into sparse parameter updates during gradient descent,\nextending this compute efficiency to the training phase. We show that the EGRU\ndemonstrates competitive performance compared to state-of-the-art recurrent\nnetwork models in real-world tasks, including language modeling while\nmaintaining high activity sparsity naturally during inference and training.\nThis sets the stage for the next generation of recurrent networks that are\nscalable and more suitable for novel neuromorphic hardware.",
    "descriptor": "",
    "authors": [
      "Anand Subramoney",
      "Khaleelulla Khan Nazeer",
      "Mark Sch\u00f6ne",
      "Christian Mayr",
      "David Kappel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.06178"
  },
  {
    "id": "arXiv:2206.06182",
    "title": "AI-based Data Preparation and Data Analytics in Healthcare: The Case of  Diabetes",
    "abstract": "The Associazione Medici Diabetologi (AMD) collects and manages one of the\nlargest worldwide-available collections of diabetic patient records, also known\nas the AMD database. This paper presents the initial results of an ongoing\nproject whose focus is the application of Artificial Intelligence and Machine\nLearning techniques for conceptualizing, cleaning, and analyzing such an\nimportant and valuable dataset, with the goal of providing predictive insights\nto better support diabetologists in their diagnostic and therapeutic choices.",
    "descriptor": "\nComments: The work has been presented at the conference Ital-IA 2022 (this https URL)\n",
    "authors": [
      "Marianna Maranghi",
      "Aris Anagnostopoulos",
      "Irene Cannistraci",
      "Ioannis Chatzigiannakis",
      "Federico Croce",
      "Giulia Di Teodoro",
      "Michele Gentile",
      "Giorgio Grani",
      "Maurizio Lenzerini",
      "Stefano Leonardi",
      "Andrea Mastropietro",
      "Laura Palagi",
      "Massimiliano Pappa",
      "Riccardo Rosati",
      "Riccardo Valentini",
      "Paola Velardi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2206.06182"
  },
  {
    "id": "arXiv:2206.06190",
    "title": "TransRec: Learning Transferable Recommendation from Mixture-of-Modality  Feedback",
    "abstract": "Learning big models and then transfer has become the de facto practice in\ncomputer vision (CV) and natural language processing (NLP). However, such\nunified paradigm is uncommon for recommender systems (RS). A critical issue\nthat hampers this is that standard recommendation models are built on\nunshareable identity data, where both users and their interacted items are\nrepresented by unique IDs. In this paper, we study a novel scenario where\nuser's interaction feedback involves mixture-of-modality (MoM) items. We\npresent TransRec, a straightforward modification done on the popular ID-based\nRS framework. TransRec directly learns from MoM feedback in an end-to-end\nmanner, and thus enables effective transfer learning under various scenarios\nwithout relying on overlapped users or items. We empirically study the\ntransferring ability of TransRec across four different real-world\nrecommendation settings. Besides, we study its effects by scaling the size of\nsource and target data. Our results suggest that learning recommenders from MoM\nfeedback provides a promising way to realize universal recommender systems. Our\ncode and datasets will be made available.",
    "descriptor": "",
    "authors": [
      "Jie Wang",
      "Fajie Yuan",
      "Mingyue Cheng",
      "Joemon M. Jose",
      "Chenyun Yu",
      "Beibei Kong",
      "Zhijin Wang",
      "Bo Hu",
      "Zang Li"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.06190"
  },
  {
    "id": "arXiv:2206.06193",
    "title": "Differentiable Transient Rendering",
    "abstract": "Recent differentiable rendering techniques have become key tools to tackle\nmany inverse problems in graphics and vision. Existing models, however, assume\nsteady-state light transport, i.e., infinite speed of light. While this is a\nsafe assumption for many applications, recent advances in ultrafast imaging\nleverage the wealth of information that can be extracted from the exact time of\nflight of light. In this context, physically-based transient rendering allows\nto efficiently simulate and analyze light transport considering that the speed\nof light is indeed finite. In this paper, we introduce a novel differentiable\ntransient rendering framework, to help bring the potential of differentiable\napproaches into the transient regime. To differentiate the transient path\nintegral we need to take into account that scattering events at path vertices\nare no longer independent; instead, tracking the time of flight of light\nrequires treating such scattering events at path vertices jointly as a\nmultidimensional, evolving manifold. We thus turn to the generalized transport\ntheorem, and introduce a novel correlated importance term, which links the\ntime-integrated contribution of a path to its light throughput, and allows us\nto handle discontinuities in the light and sensor functions. Last, we present\nresults in several challenging scenarios where the time of flight of light\nplays an important role such as optimizing indices of refraction,\nnon-line-of-sight tracking with nonplanar relay walls, and non-line-of-sight\ntracking around two corners.",
    "descriptor": "",
    "authors": [
      "Shinyoung Yi",
      "Donggun Kim",
      "Kiseok Choi",
      "Adrian Jarabo",
      "Diego Gutierrez",
      "Min H. Kim"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2206.06193"
  },
  {
    "id": "arXiv:2206.06194",
    "title": "Predicting conditional probability distributions of redshifts of Active  Galactic Nuclei using Hierarchical Correlation Reconstruction",
    "abstract": "While there is a general focus on prediction of values, real data often only\nallows to predict conditional probability distributions, with capabilities\nbounded by conditional entropy $H(Y|X)$. If additionally estimating\nuncertainty, we can treat a predicted value as the center of Gaussian of\nLaplace distribution - idealization which can be far from complex conditional\ndistributions of real data. This article applies Hierarchical Correlation\nReconstruction (HCR) approach to inexpensively predict quite complex\nconditional probability distributions (e.g. multimodal): by independent MSE\nestimation of multiple moment-like parameters, which allow to reconstruct the\nconditional distribution. Using linear regression for this purpose, we get\ninterpretable models: with coefficients describing contributions of features to\nconditional moments. This article extends on the original approach especially\nby using Canonical Correlation Analysis (CCA) for feature optimization and l1\n\"lasso\" regularization, focusing on practical problem of prediction of redshift\nof Active Galactic Nuclei (AGN) based on Fourth Fermi-LAT Data Release 2 (4LAC)\ndataset.",
    "descriptor": "\nComments: 5 pages, 6 figures\n",
    "authors": [
      "Jarek Duda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Astrophysics of Galaxies (astro-ph.GA)",
      "High Energy Astrophysical Phenomena (astro-ph.HE)"
    ],
    "url": "https://arxiv.org/abs/2206.06194"
  },
  {
    "id": "arXiv:2206.06200",
    "title": "Automatic generation of a large dictionary with  concreteness/abstractness ratings based on a small human dictionary",
    "abstract": "Concrete/abstract words are used in a growing number of psychological and\nneurophysiological research. For a few languages, large dictionaries have been\ncreated manually. This is a very time-consuming and costly process. To generate\nlarge high-quality dictionaries of concrete/abstract words automatically one\nneeds extrapolating the expert assessments obtained on smaller samples. The\nresearch question that arises is how small such samples should be to do a good\nenough extrapolation. In this paper, we present a method for automatic ranking\nconcreteness of words and propose an approach to significantly decrease amount\nof expert assessment. The method has been evaluated on a large test set for\nEnglish. The quality of the constructed dictionaries is comparable to the\nexpert ones. The correlation between predicted and expert ratings is higher\ncomparing to the state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Vladimir Ivanov",
      "Valery Solovyev"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.06200"
  },
  {
    "id": "arXiv:2206.06202",
    "title": "Constraint Guided Gradient Descent: Guided Training with Inequality  Constraints",
    "abstract": "Deep learning is typically performed by learning a neural network solely from\ndata in the form of input-output pairs ignoring available domain knowledge. In\nthis work, the Constraint Guided Gradient Descent (CGGD) framework is proposed\nthat enables the injection of domain knowledge into the training procedure. The\ndomain knowledge is assumed to be described as a conjunction of hard inequality\nconstraints which appears to be a natural choice for several applications.\nCompared to other neuro-symbolic approaches, the proposed method converges to a\nmodel that satisfies any inequality constraint on the training data and does\nnot require to first transform the constraints into some ad-hoc term that is\nadded to the learning (optimisation) objective. Under certain conditions, it is\nshown that CGGD can converges to a model that satisfies the constraints on the\ntraining set, while prior work does not necessarily converge to such a model.\nIt is empirically shown on two independent and small data sets that CGGD makes\ntraining less dependent on the initialisation of the network and improves the\nconstraint satisfiability on all data.",
    "descriptor": "\nComments: 9 pages, 1 figure, 1 table\n",
    "authors": [
      "Quinten Van Baelen Peter Karsmakers"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.06202"
  },
  {
    "id": "arXiv:2206.06210",
    "title": "Sync or Fork: Node-Level Synchronization Analysis of Blockchain",
    "abstract": "As the cornerstone of blockchain, block synchronization plays a vital role in\nmaintaining the security. Without full blockchain synchronization, unexpected\nforks will emerge and thus providing a breeding ground for various malicious\nattacks. The state-of-the-art works mainly study the relationship between the\npropagation time and blockchain security at the systematic level, neglecting\nthe fine-grained impact of peering nodes in blockchain networks. To conduct a\nnode-level synchronization analysis, we take advantage of the large deviation\ntheory and game theory to study the pull-based propagation from a microscopic\nperspective. We examine the blockchain synchronization in a bidirectional\nmanner via investigating the impact of full nodes as responders and that of\npartial nodes as requesters. Based on that, we further reveal the most\nefficient path to speed up synchronization from full nodes and design the best\nsynchronization request scheme based on the concept of correlated equilibrium\nfor partial nodes. Extensive experimental results demonstrate the effectiveness\nof our analysis.",
    "descriptor": "\nComments: published on International Conference on Wireless Algorithms, Systems, and Applications (WASA 2020)\n",
    "authors": [
      "Qin Hu",
      "Minghui Xu",
      "Shengling Wang",
      "Shaoyong Guo"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2206.06210"
  },
  {
    "id": "arXiv:2206.06213",
    "title": "Symbolic Regression for Space Applications: Differentiable Cartesian  Genetic Programming Powered by Multi-objective Memetic Algorithms",
    "abstract": "Interpretable regression models are important for many application domains,\nas they allow experts to understand relations between variables from sparse\ndata. Symbolic regression addresses this issue by searching the space of all\npossible free form equations that can be constructed from elementary algebraic\nfunctions. While explicit mathematical functions can be rediscovered this way,\nthe determination of unknown numerical constants during search has been an\noften neglected issue. We propose a new multi-objective memetic algorithm that\nexploits a differentiable Cartesian Genetic Programming encoding to learn\nconstants during evolutionary loops. We show that this approach is competitive\nor outperforms machine learned black box regression models or hand-engineered\nfits for two applications from space: the Mars express thermal power estimation\nand the determination of the age of stars by gyrochronology.",
    "descriptor": "",
    "authors": [
      "Marcus M\u00e4rtens",
      "Dario Izzo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.06213"
  },
  {
    "id": "arXiv:2206.06214",
    "title": "Learning a Degradation-Adaptive Network for Light Field Image  Super-Resolution",
    "abstract": "Recent years have witnessed the great advances of deep neural networks (DNNs)\nin light field (LF) image super-resolution (SR). However, existing DNN-based LF\nimage SR methods are developed on a single fixed degradation (e.g., bicubic\ndownsampling), and thus cannot be applied to super-resolve real LF images with\ndiverse degradations. In this paper, we propose the first method to handle LF\nimage SR with multiple degradations. In our method, a practical LF degradation\nmodel that considers blur and noise is developed to approximate the degradation\nprocess of real LF images. Then, a degradation-adaptive network (LF-DAnet) is\ndesigned to incorporate the degradation prior into the SR process. By training\non LF images with multiple synthetic degradations, our method can learn to\nadapt to different degradations while incorporating the spatial and angular\ninformation. Extensive experiments on both synthetically degraded and\nreal-world LFs demonstrate the effectiveness of our method. Compared with\nexisting state-of-the-art single and LF image SR methods, our method achieves\nsuperior SR performance under a wide range of degradations, and generalizes\nbetter to real LF images. Codes and models are available at\nhttps://github.com/YingqianWang/LF-DAnet.",
    "descriptor": "\nComments: 13 pages, 9 figures\n",
    "authors": [
      "Yingqian Wang",
      "Zhengyu Liang",
      "Longguang Wang",
      "Jungang Yang",
      "Wei An",
      "Yulan Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.06214"
  },
  {
    "id": "arXiv:2206.06217",
    "title": "Towards an Approximation-Aware Computational Workflow Framework for  Accelerating Large-Scale Discovery Tasks",
    "abstract": "The use of approximation is fundamental in computational science. Almost all\ncomputational methods adopt approximations in some form in order to obtain a\nfavourable cost/accuracy trade-off and there are usually many approximations\nthat could be used. As a result, when a researcher wishes to measure a property\nof a system with a computational technique, they are faced with an array of\noptions. Current computational workflow frameworks focus on helping researchers\nautomate a sequence of steps on a particular platform. The aim is often to\nobtain a computational measurement of a property. However these frameworks are\nunaware that there may be a large number of ways to do so. As such, they cannot\nsupport researchers in making these choices during development or at\nexecution-time.\nWe argue that computational workflow frameworks should be designed to be\n\\textit{approximation-aware} - that is, support the fact that a given workflow\ndescription represents a task that \\textit{could} be performed in different\nways. This is key to unlocking the potential of computational workflows to\naccelerate discovery tasks, particularly those involving searches of large\nentity spaces. It will enable efficiently obtaining measurements of entity\nproperties, given a set of constraints, by directly leveraging the space of\nchoices available. In this paper we describe the basic functions that an\napproximation-aware workflow framework should provide, how those functions can\nbe realized in practice, and illustrate some of the powerful capabilities it\nwould enable, including approximate memoization, surrogate model support, and\nautomated workflow composition.",
    "descriptor": "\nComments: Pre-print of paper in ApPLIED 2022 (part of PODC 2022)\n",
    "authors": [
      "Michael A. Johnston",
      "Vassilis Vassiliadis"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.06217"
  },
  {
    "id": "arXiv:2206.06219",
    "title": "Making Sense of Dependence: Efficient Black-box Explanations Using  Dependence Measure",
    "abstract": "This paper presents a new efficient black-box attribution method based on\nHilbert-Schmidt Independence Criterion (HSIC), a dependence measure based on\nReproducing Kernel Hilbert Spaces (RKHS). HSIC measures the dependence between\nregions of an input image and the output of a model based on kernel embeddings\nof distributions. It thus provides explanations enriched by RKHS representation\ncapabilities. HSIC can be estimated very efficiently, significantly reducing\nthe computational cost compared to other black-box attribution methods. Our\nexperiments show that HSIC is up to 8 times faster than the previous best\nblack-box attribution methods while being as faithful. Indeed, we improve or\nmatch the state-of-the-art of both black-box and white-box attribution methods\nfor several fidelity metrics on Imagenet with various recent model\narchitectures. Importantly, we show that these advances can be transposed to\nefficiently and faithfully explain object detection models such as YOLOv4.\nFinally, we extend the traditional attribution methods by proposing a new\nkernel enabling an orthogonal decomposition of importance scores based on HSIC,\nallowing us to evaluate not only the importance of each image patch but also\nthe importance of their pairwise interactions.",
    "descriptor": "\nComments: Technical report\n",
    "authors": [
      "Paul Novello",
      "Thomas Fel",
      "David Vigouroux"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)",
      "Other Statistics (stat.OT)"
    ],
    "url": "https://arxiv.org/abs/2206.06219"
  },
  {
    "id": "arXiv:2206.06221",
    "title": "A Unified Framework for Dynamic Analysis of Tensegrity Structures with  Arbitrary Rigid Bodies and Rigid Bars",
    "abstract": "In this paper, we develop a unified framework to study the dynamics of\ntensegrity systems that can include any arbitrary rigid bodies and rigid bars.\nThe natural coordinates are adopted as a completely non-minimal modeling\napproach to describe both rigid bodies and rigid bars in terms of different\ncombinations of basic points and base vectors. Various types of coordinates\ncombinations are then unified into polymorphic expressions which succinctly\nencompass Class-1-to-$k$ tensegrities. Then, we employ the Lagrange-d'Alembert\nprinciple to derive the dynamic equation, which has a constant mass matrix and\nis free from trigonometric functions as well as centrifugal and Coriolis terms,\nowing to the non-minimal formulations. For numerical analysis of nonlinear\ndynamics, a modified symplectic integration scheme is derived, accommodating\nnon-conservative forces and prescribed boundary conditions. Additionally,\nformulations for statics and linearized dynamics around static equilibrium\nstates are derived to help determine cable actuations and calculate natural\nfrequencies and mode shapes, which are commonly needed for structural analyses.\nNumerical examples are given to demonstrate the proposed approach's abilities\nin the modeling of tensegrity structures composed of Class-1-to-$k$ modules and\nconducting dynamic simulations with complex conditions, including slack cables,\ngravity loads, seismic grounds, and cable-based deployments. Finally, two novel\ndesigns of tensegrity structures exemplify new ways to create multi-functional\ncomposite structures.",
    "descriptor": "\nComments: 13 pages, 22 figures\n",
    "authors": [
      "Jiahui Luo",
      "Zhigang Wu",
      "Xiaoming Xu"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2206.06221"
  },
  {
    "id": "arXiv:2206.06223",
    "title": "Pursuing More Effective Graph Spectral Sparsifiers via Approximate Trace  Reduction",
    "abstract": "Spectral graph sparsification aims to find ultra-sparse subgraphs which can\npreserve spectral properties of original graphs. In this paper, a new spectral\ncriticality metric based on trace reduction is first introduced for identifying\nspectrally important off-subgraph edges. Then, a physics-inspired truncation\nstrategy and an approach using approximate inverse of Cholesky factor are\nproposed to compute the approximate trace reduction efficiently. Combining them\nwith the iterative densification scheme in \\cite{feng2019grass} and the\nstrategy of excluding spectrally similar off-subgraph edges in \\cite{fegrass},\nwe develop a highly effective graph sparsification algorithm. The proposed\nmethod has been validated with various kinds of graphs. Experimental results\nshow that it always produces sparsifiers with remarkably better quality than\nthe state-of-the-art GRASS \\cite{feng2019grass} in same computational cost,\nenabling more than 40% time reduction for preconditioned iterative equation\nsolver on average. In the applications of power grid transient analysis and\nspectral graph partitioning, the derived iterative solver shows 3.3X or more\nadvantages on runtime and memory cost, over the approach based on direct sparse\nsolver.",
    "descriptor": "\nComments: 7 pages, 2 figures. to appear at DAC'2022\n",
    "authors": [
      "Zhiqiang Liu",
      "Wenjian Yu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Numerical Analysis (math.NA)",
      "Spectral Theory (math.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.06223"
  },
  {
    "id": "arXiv:2206.06226",
    "title": "Parallel Domain Decomposition method for the fully-mixed  Stokes-dual-permeability fluid flow model with Beavers-Joseph interface  conditions",
    "abstract": "In this paper, a parallel domain decomposition method is proposed for solving\nthe fully-mixed Stokes-dual-permeability fluid flow model with Beavers-Joseph\n(BJ) interface conditions. Three Robin-type boundary conditions and a modified\nweak formulation are constructed to completely decouple the original problem,\nnot only for the free flow and dual-permeability regions but also for the\nmatrix and microfractures in the dual-porosity media. We derive the equivalence\nbetween the original problem and the decoupled systems with some suitable\ncompatibility conditions, and also demonstrate the equivalence of two weak\nformulations in different Sobolev spaces. Based on the completely decoupled\nmodified weak formulation, the convergence of the iterative parallel algorithm\nis proved rigorously. To carry out the convergence analysis of our proposed\nalgorithm, we propose an important but general convergence lemma for the\nsteady-state problems. Furthermore, with some suitable choice of parameters,\nthe new algorithm is proved to achieve the geometric convergence rate. Finally,\nseveral numerical experiments are presented to illustrate and validate the\nperformance and exclusive features of our proposed algorithm.",
    "descriptor": "\nComments: 28 pages\n",
    "authors": [
      "Zheng Li",
      "Feng Shi",
      "Yizhong Sun",
      "Haibiao Zheng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.06226"
  },
  {
    "id": "arXiv:2206.06227",
    "title": "Convergence for score-based generative modeling with polynomial  complexity",
    "abstract": "Score-based generative modeling (SGM) is a highly successful approach for\nlearning a probability distribution from data and generating further samples.\nWe prove the first polynomial convergence guarantees for the core mechanic\nbehind SGM: drawing samples from a probability density $p$ given a score\nestimate (an estimate of $\\nabla \\ln p$) that is accurate in $L^2(p)$. Compared\nto previous works, we do not incur error that grows exponentially in time or\nthat suffers from a curse of dimensionality. Our guarantee works for any smooth\ndistribution and depends polynomially on its log-Sobolev constant. Using our\nguarantee, we give a theoretical analysis of score-based generative modeling,\nwhich transforms white-noise input into samples from a learned data\ndistribution given score estimates at different noise scales. Our analysis\ngives theoretical grounding to the observation that an annealed procedure is\nrequired in practice to generate good samples, as our proof depends essentially\non using annealing to obtain a warm start at each step. Moreover, we show that\na predictor-corrector algorithm gives better convergence than using either\nportion alone.",
    "descriptor": "\nComments: 42 pages\n",
    "authors": [
      "Holden Lee",
      "Jianfeng Lu",
      "Yixin Tan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.06227"
  },
  {
    "id": "arXiv:2206.06229",
    "title": "Transition-based Abstract Meaning Representation Parsing with Contextual  Embeddings",
    "abstract": "The ability to understand and generate languages sets human cognition apart\nfrom other known life forms'. We study a way of combing two of the most\nsuccessful routes to meaning of language--statistical language models and\nsymbolic semantics formalisms--in the task of semantic parsing. Building on a\ntransition-based, Abstract Meaning Representation (AMR) parser, AmrEager, we\nexplore the utility of incorporating pretrained context-aware word\nembeddings--such as BERT and RoBERTa--in the problem of AMR parsing,\ncontributing a new parser we dub as AmrBerger. Experiments find these rich\nlexical features alone are not particularly helpful in improving the parser's\noverall performance as measured by the SMATCH score when compared to the\nnon-contextual counterpart, while additional concept information empowers the\nsystem to outperform the baselines. Through lesion study, we found the use of\ncontextual embeddings helps to make the system more robust against the removal\nof explicit syntactical features. These findings expose the strength and\nweakness of the contextual embeddings and the language models in the current\nform, and motivate deeper understanding thereof.",
    "descriptor": "\nComments: Technical report written in 2020\n",
    "authors": [
      "Yichao Liang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06229"
  },
  {
    "id": "arXiv:2206.06232",
    "title": "Towards Understanding Sharpness-Aware Minimization",
    "abstract": "Sharpness-Aware Minimization (SAM) is a recent training method that relies on\nworst-case weight perturbations which significantly improves generalization in\nvarious settings. We argue that the existing justifications for the success of\nSAM which are based on a PAC-Bayes generalization bound and the idea of\nconvergence to flat minima are incomplete. Moreover, there are no explanations\nfor the success of using $m$-sharpness in SAM which has been shown as essential\nfor generalization. To better understand this aspect of SAM, we theoretically\nanalyze its implicit bias for diagonal linear networks. We prove that SAM\nalways chooses a solution that enjoys better generalization properties than\nstandard gradient descent for a certain class of problems, and this effect is\namplified by using $m$-sharpness. We further study the properties of the\nimplicit bias on non-linear networks empirically, where we show that\nfine-tuning a standard model with SAM can lead to significant generalization\nimprovements. Finally, we provide convergence results of SAM for non-convex\nobjectives when used with stochastic gradients. We illustrate these results\nempirically for deep networks and discuss their relation to the generalization\nbehavior of SAM. The code of our experiments is available at\nhttps://github.com/tml-epfl/understanding-sam.",
    "descriptor": "\nComments: The camera-ready version (accepted at ICML 2022)\n",
    "authors": [
      "Maksym Andriushchenko",
      "Nicolas Flammarion"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06232"
  },
  {
    "id": "arXiv:2206.06237",
    "title": "A Versatile Pseudo-Rigid Body Modeling Method",
    "abstract": "A novel semi-analytical method is proposed to develop the\npseudo-rigid-body~(PRB) model of robots made of highly flexible members (HFM),\nsuch as flexures and continuum robots, with no limit on the degrees of freedom\nof the PRB model. The proposed method has a simple formulation yet high\nprecision. Furthermore, it can describe HFMs with variable curvature and\nstiffness along their length. The method offers a semi-analytical solution for\nthe highly coupled nonlinear constrained optimization problem of PRB modeling\nand can be extended to variable-length robots comprised of HFM, such as\ncatheter and concentric tube robots. We also show that this method can obtain a\nPRB model of uniformly stiff HFMs, with only three parameters. The versatility\nof the method is investigated in various applications of HFM in continuum\nrobots. Simulations demonstrate substantial improvement in the precision of the\nPRB model in general and a reduction in the complexity of the formulation.",
    "descriptor": "\nComments: 10 pages and 8 figures\n",
    "authors": [
      "Amir Molaei",
      "Amir G. Aghdam",
      "Javad Dargahi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.06237"
  },
  {
    "id": "arXiv:2206.06238",
    "title": "Indian Legal Text Summarization: A Text Normalisation-based Approach",
    "abstract": "In the Indian court system, pending cases have long been a problem. There are\nmore than 4 crore cases outstanding. Manually summarising hundreds of documents\nis a time-consuming and tedious task for legal stakeholders. Many\nstate-of-the-art models for text summarization have emerged as machine learning\nhas progressed. Domain-independent models don't do well with legal texts, and\nfine-tuning those models for the Indian Legal System is problematic due to a\nlack of publicly available datasets. To improve the performance of\ndomain-independent models, the authors have proposed a methodology for\nnormalising legal texts in the Indian context. The authors experimented with\ntwo state-of-the-art domain-independent models for legal text summarization,\nnamely BART and PEGASUS. BART and PEGASUS are put through their paces in terms\nof extractive and abstractive summarization to understand the effectiveness of\nthe text normalisation approach. Summarised texts are evaluated by domain\nexperts on multiple parameters and using ROUGE metrics. It shows the proposed\ntext normalisation approach is effective in legal texts with domain-independent\nmodels.",
    "descriptor": "\nComments: 4 pages, 3 figures, 4 tables\n",
    "authors": [
      "Satyajit Ghosh",
      "Mousumi Dutta",
      "Tanaya Das"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.06238"
  },
  {
    "id": "arXiv:2206.06241",
    "title": "Optimal routing algorithm for trips involving thousands of ev-charging  stations using Kinetica-Graph",
    "abstract": "This paper discusses a graph based route solving algorithm to find the\noptimal path for an electric vehicle picking the best charging locations among\nthousands to minimize the total cumulative driving distance between the end\npoints of the trip. To this end, we have devised a combinatorial optimization\nalgorithm and a fixed storage graph topology construction for the graph road\nnetwork of the continental USA. We have also re-purposed our existing Dijkstra\nsolver to reduce the computational cost of many shortest path solves involved\nin the algorithm. An adaptive and light weight spatial search structure is also\ndevised for finding a set of prospective stations at each charging location\nusing uniform bins and double link associations. The entire algorithm is\nimplemented as yet another multi-threaded at-scale graph solver within the\nsuite of Kinetica-Graph analytics, exposed as a restful API endpoint and\noperable within SQL. Several example trips are solved and the results are\ndemonstrated within the context.",
    "descriptor": "\nComments: 13 pages, 15 figures, 13 references\n",
    "authors": [
      "B. Kaan Karamete",
      "Eli Glaser"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.06241"
  },
  {
    "id": "arXiv:2206.06243",
    "title": "Contrastive Learning for Unsupervised Domain Adaptation of Time Series",
    "abstract": "Unsupervised domain adaptation (UDA) aims at learning a machine learning\nmodel using a labeled source domain that performs well on a similar yet\ndifferent, unlabeled target domain. UDA is important in many applications such\nas medicine, where it is used to adapt risk scores across different patient\ncohorts. In this paper, we develop a novel framework for UDA of time series\ndata, called CLUDA. Specifically, we propose a contrastive learning framework\nto learn domain-invariant semantics in multivariate time series, so that these\npreserve label information for the prediction task. In our framework, we\nfurther capture semantic variation between source and target domain via\nnearest-neighbor contrastive learning. To the best of our knowledge, ours is\nthe first framework to learn domain-invariant semantic information for UDA of\ntime series data. We evaluate our framework using large-scale, real-world\ndatasets with medical time series (i.e., MIMIC-IV and AmsterdamUMCdb) to\ndemonstrate its effectiveness and show that it achieves state-of-the-art\nperformance for time series UDA.",
    "descriptor": "",
    "authors": [
      "Yilmazcan Ozyurt",
      "Stefan Feuerriegel",
      "Ce Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.06243"
  },
  {
    "id": "arXiv:2206.06246",
    "title": "A Modular Continuum Manipulator for Aerial Manipulation and Perching",
    "abstract": "Most aerial manipulators use serial rigid-link designs, which results in\nlarge forces when initiating contacts during manipulation and could cause\nflight stability difficulty. This limitation could potentially be improved by\nthe compliance of continuum manipulators. To achieve this goal, we present the\nnovel design of a compact, lightweight, and modular cable-driven continuum\nmanipulator for aerial drones. We then derive a complete modeling framework for\nits kinematics, statics, and stiffness (compliance). The framework is essential\nfor integrating the manipulator to aerial drones. Finally, we report\npreliminary experimental validations of the hardware prototype, providing\ninsights on its manipulation feasibility. Future work includes the integration\nand test of the proposed continuum manipulator with aerial drones.",
    "descriptor": "\nComments: 10 pages, accepted for International Design Engineering Technical Conferences & Computers and Information in Engineering Conference (IDETC-CIE 2022). 46th Mechanisms and Robotics Conference (MR)\n",
    "authors": [
      "Qianwen Zhao",
      "Guoqing Zhang",
      "Hamidreza Jafarnejadsani",
      "Long Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.06246"
  },
  {
    "id": "arXiv:2206.06247",
    "title": "Leveraging Structured Pruning of Convolutional Neural Networks",
    "abstract": "Structured pruning is a popular method to reduce the cost of convolutional\nneural networks, that are the state of the art in many computer vision tasks.\nHowever, depending on the architecture, pruning introduces dimensional\ndiscrepancies which prevent the actual reduction of pruned networks. To tackle\nthis problem, we propose a method that is able to take any structured pruning\nmask and generate a network that does not encounter any of these problems and\ncan be leveraged efficiently. We provide an accurate description of our\nsolution and show results of gains, in energy consumption and inference time on\nembedded hardware, of pruned convolutional neural networks.",
    "descriptor": "\nComments: 6 pages, 5 figures, submitted to SiPS 2022\n",
    "authors": [
      "Hugo Tessier",
      "Vincent Gripon",
      "Mathieu L\u00e9onardon",
      "Matthieu Arzel",
      "David Bertrand",
      "Thomas Hannagan"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.06247"
  },
  {
    "id": "arXiv:2206.06251",
    "title": "Explainability-by-Design: A Methodology to Support Explanations in  Decision-Making Systems",
    "abstract": "Algorithms play a key role nowadays in many technological systems that\ncontrol or affect various aspects of our lives. As a result, providing\nexplanations to address the needs of users and organisations is increasingly\nexpected by the laws and regulations, codes of conduct, and the public.\nHowever, as laws and regulations do not prescribe how to meet such\nexpectations, organisations are often left to devise their own approaches to\nexplainability, inevitably increasing the cost of compliance and good\ngovernance. Hence, we put forth \"Explainability by Design\", a holistic\nmethodology characterised by proactive measures to include explanation\ncapability in the design of decision-making systems. This paper describes the\ntechnical steps of the Explainability-by-Design methodology in a software\nengineering workflow to implement explanation capability from requirements\nelicited by domain experts for a specific application context. Outputs of the\nExplainability-by-Design methodology are a set of configurations, allowing a\nreusable service, called the Explanation Assistant, to exploit logs provided by\napplications and create provenance traces that can be queried to extract\nrelevant data points, which in turn can be used in explanation plans to\nconstruct explanations personalised to their consumers. Following those steps,\norganisations will be able to design their decision-making systems to produce\nexplanations that meet the specified requirements, be it from laws,\nregulations, or business needs. We apply the methodology to two applications,\nresulting in a deployment of the Explanation Assistant demonstrating\nexplanations capabilities. Finally, the associated development costs are\nmeasured, showing that the approach to construct explanations is tractable in\nterms of development time, which can be as low as two hours per explanation\nsentence.",
    "descriptor": "",
    "authors": [
      "Trung Dong Huynh",
      "Niko Tsakalakis",
      "Ayah Helal",
      "Sophie Stalla-Bourdillon",
      "Luc Moreau"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.06251"
  },
  {
    "id": "arXiv:2206.06252",
    "title": "Transformer Lesion Tracker",
    "abstract": "Evaluating lesion progression and treatment response via longitudinal lesion\ntracking plays a critical role in clinical practice. Automated approaches for\nthis task are motivated by prohibitive labor costs and time consumption when\nlesion matching is done manually. Previous methods typically lack the\nintegration of local and global information. In this work, we propose a\ntransformer-based approach, termed Transformer Lesion Tracker (TLT).\nSpecifically, we design a Cross Attention-based Transformer (CAT) to capture\nand combine both global and local information to enhance feature extraction. We\nalso develop a Registration-based Anatomical Attention Module (RAAM) to\nintroduce anatomical information to CAT so that it can focus on useful feature\nknowledge. A Sparse Selection Strategy (SSS) is presented for selecting\nfeatures and reducing memory footprint in Transformer training. In addition, we\nuse a global regression to further improve model performance. We conduct\nexperiments on a public dataset to show the superiority of our method and find\nthat our model performance has improved the average Euclidean center error by\nat least 14.3% (6mm vs. 7mm) compared with the state-of-the-art (SOTA). Code is\navailable at https://github.com/TangWen920812/TLT.",
    "descriptor": "\nComments: Accepted MICCAI 2022\n",
    "authors": [
      "Wen Tang",
      "Han Kang",
      "Haoyue Zhang",
      "Pengxin Yu",
      "Corey W. Arnold",
      "Rongguo Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06252"
  },
  {
    "id": "arXiv:2206.06255",
    "title": "Energy Consumption Analysis of pruned Semantic Segmentation Networks on  an Embedded GPU",
    "abstract": "Deep neural networks are the state of the art in many computer vision tasks.\nTheir deployment in the context of autonomous vehicles is of particular\ninterest, since their limitations in terms of energy consumption prohibit the\nuse of very large networks, that typically reach the best performance. A common\nmethod to reduce the complexity of these architectures, without sacrificing\naccuracy, is to rely on pruning, in which the least important portions are\neliminated. There is a large literature on the subject, but interestingly few\nworks have measured the actual impact of pruning on energy. In this work, we\nare interested in measuring it in the specific context of semantic segmentation\nfor autonomous driving, using the Cityscapes dataset. To this end, we analyze\nthe impact of recently proposed structured pruning methods when trained\narchitectures are deployed on a Jetson Xavier embedded GPU.",
    "descriptor": "\nComments: 10 pages, 3 figures, submitted to SysInt 2022\n",
    "authors": [
      "Hugo Tessier",
      "Vincent Gripon",
      "Mathieu L\u00e9onardon",
      "Matthieu Arzel",
      "David Bertrand",
      "Thomas Hannagan"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.06255"
  },
  {
    "id": "arXiv:2206.06256",
    "title": "On the impact of dataset size and class imbalance in evaluating  machine-learning-based windows malware detection techniques",
    "abstract": "The purpose of this project was to collect and analyse data about the\ncomparability and real-life applicability of published results focusing on\nMicrosoft Windows malware, more specifically the impact of dataset size and\ntesting dataset imbalance on measured detector performance. Some researchers\nuse smaller datasets, and if dataset size has a significant impact on\nperformance, that makes comparison of the published results difficult.\nResearchers also tend to use balanced datasets and accuracy as a metric for\ntesting. The former is not a true representation of reality, where benign\nsamples significantly outnumber malware, and the latter is approach is known to\nbe problematic for imbalanced problems. The project identified two key\nobjectives, to understand if dataset size correlates to measured detector\nperformance to an extent that prevents meaningful comparison of published\nresults, and to understand if good performance reported in published research\ncan be expected to perform well in a real-world deployment scenario. The\nresearch's results suggested that dataset size does correlate with measured\ndetector performance to an extent that prevents meaningful comparison of\npublished results, and without understanding the nature of the training set\nsize-accuracy curve for published results conclusions between approaches on\nwhich approach is \"better\" shouldn't be made solely based on accuracy scores.\nResults also suggested that high accuracy scores don't necessarily translate to\nhigh real-world performance.",
    "descriptor": "\nComments: Project report for my MSc project at The Open University originally submitted to obtain an MSc in Cyber Security\n",
    "authors": [
      "David Illes"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06256"
  },
  {
    "id": "arXiv:2206.06257",
    "title": "Distributed Adversarial Training to Robustify Deep Neural Networks at  Scale",
    "abstract": "Current deep neural networks (DNNs) are vulnerable to adversarial attacks,\nwhere adversarial perturbations to the inputs can change or manipulate\nclassification. To defend against such attacks, an effective and popular\napproach, known as adversarial training (AT), has been shown to mitigate the\nnegative impact of adversarial attacks by virtue of a min-max robust training\nmethod. While effective, it remains unclear whether it can successfully be\nadapted to the distributed learning context. The power of distributed\noptimization over multiple machines enables us to scale up robust training over\nlarge models and datasets. Spurred by that, we propose distributed adversarial\ntraining (DAT), a large-batch adversarial training framework implemented over\nmultiple machines. We show that DAT is general, which supports training over\nlabeled and unlabeled data, multiple types of attack generation methods, and\ngradient compression operations favored for distributed optimization.\nTheoretically, we provide, under standard conditions in the optimization\ntheory, the convergence rate of DAT to the first-order stationary points in\ngeneral non-convex settings. Empirically, we demonstrate that DAT either\nmatches or outperforms state-of-the-art robust accuracies and achieves a\ngraceful training speedup (e.g., on ResNet-50 under ImageNet). Codes are\navailable at https://github.com/dat-2022/dat.",
    "descriptor": "",
    "authors": [
      "Gaoyuan Zhang",
      "Songtao Lu",
      "Yihua Zhang",
      "Xiangyi Chen",
      "Pin-Yu Chen",
      "Quanfu Fan",
      "Lee Martie",
      "Lior Horesh",
      "Mingyi Hong",
      "Sijia Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06257"
  },
  {
    "id": "arXiv:2206.06258",
    "title": "Featurized Query R-CNN",
    "abstract": "The query mechanism introduced in the DETR method is changing the paradigm of\nobject detection and recently there are many query-based methods have obtained\nstrong object detection performance. However, the current query-based detection\npipelines suffer from the following two issues. Firstly, multi-stage decoders\nare required to optimize the randomly initialized object queries, incurring a\nlarge computation burden. Secondly, the queries are fixed after training,\nleading to unsatisfying generalization capability. To remedy the above issues,\nwe present featurized object queries predicted by a query generation network in\nthe well-established Faster R-CNN framework and develop a Featurized Query\nR-CNN. Extensive experiments on the COCO dataset show that our Featurized Query\nR-CNN obtains the best speed-accuracy trade-off among all R-CNN detectors,\nincluding the recent state-of-the-art Sparse R-CNN detector. The code is\navailable at \\url{https://github.com/hustvl/Featurized-QueryRCNN}.",
    "descriptor": "\nComments: Tech Report\n",
    "authors": [
      "Wenqiang Zhang",
      "Tianheng Cheng",
      "Xinggang Wang",
      "Qian Zhang",
      "Wenyu Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06258"
  },
  {
    "id": "arXiv:2206.06260",
    "title": "OpenCBS: An Open-Source COBOL Defects Benchmark Suite",
    "abstract": "As the current COBOL workforce retires, entry-level developers are left to\nkeep complex legacy systems maintained and operational. This creates a massive\ngap in knowledge and ability as companies are having their veteran developers\nreplaced with a new, inexperienced workforce. Additionally, the lack of COBOL\nand mainframe technology in the current academic curriculum further increases\nthe learning curve for this new generation of developers. These issues are\nbecoming even more pressing due to the business-critical nature of these\nsystems, which makes migrating or replacing the mainframe and COBOL anytime\nsoon very unlikely. As a result, there is now a huge need for tools and\nresources to increase new developers' code comprehension and ability to perform\nroutine tasks such as debugging and defect location. Extensive work has been\ndone in the software engineering field on the creation of such resources.\nHowever, the proprietary nature of COBOL and mainframe systems has restricted\nthe amount of work and the number of open-source tools available for this\ndomain. To address this issue, our work leverages the publicly available\ntechnical forum data to build an open-source collection of COBOL programs\nembodying issues/defects faced by COBOL developers. These programs were\nreconstructed and organized in a benchmark suite to facilitate the testing of\ndeveloper tools. Our goal is to provide an open-source COBOL benchmark and\ntesting suite that encourage community contribution and serve as a resource for\nresearchers and tool-smiths in this domain.",
    "descriptor": "",
    "authors": [
      "Dylan Lee",
      "Austin Henley",
      "Bill Hinshaw",
      "Rahul Pandita"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.06260"
  },
  {
    "id": "arXiv:2206.06261",
    "title": "An Application of Nodal Curves",
    "abstract": "In this work, we present an efficient method for computing in the generalized\nJacobian of special singular curves, nodal curves. The efficiency of the\noperation is due to the representation of an element in the Jacobian group by a\nsingle polynomial. In addition, we propose a probabilistic public key algorithm\nas an application of nodal curves.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:1904.03978\n",
    "authors": [
      "Selin Caglar",
      "Kubra Nari",
      "Enver Ozdemir"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2206.06261"
  },
  {
    "id": "arXiv:2206.06270",
    "title": "Near-Optimal Sample Complexity Bounds for Constrained MDPs",
    "abstract": "In contrast to the advances in characterizing the sample complexity for\nsolving Markov decision processes (MDPs), the optimal statistical complexity\nfor solving constrained MDPs (CMDPs) remains unknown. We resolve this question\nby providing minimax upper and lower bounds on the sample complexity for\nlearning near-optimal policies in a discounted CMDP with access to a generative\nmodel (simulator). In particular, we design a model-based algorithm that\naddresses two settings: (i) relaxed feasibility, where small constraint\nviolations are allowed, and (ii) strict feasibility, where the output policy is\nrequired to satisfy the constraint. For (i), we prove that our algorithm\nreturns an $\\epsilon$-optimal policy with probability $1 - \\delta$, by making\n$\\tilde{O}\\left(\\frac{S A \\log(1/\\delta)}{(1 - \\gamma)^3 \\epsilon^2}\\right)$\nqueries to the generative model, thus matching the sample-complexity for\nunconstrained MDPs. For (ii), we show that the algorithm's sample complexity is\nupper-bounded by $\\tilde{O} \\left(\\frac{S A \\, \\log(1/\\delta)}{(1 - \\gamma)^5\n\\, \\epsilon^2 \\zeta^2} \\right)$ where $\\zeta$ is the problem-dependent Slater\nconstant that characterizes the size of the feasible region. Finally, we prove\na matching lower-bound for the strict feasibility setting, thus obtaining the\nfirst near minimax optimal bounds for discounted CMDPs. Our results show that\nlearning CMDPs is as easy as MDPs when small constraint violations are allowed,\nbut inherently more difficult when we demand zero constraint violation.",
    "descriptor": "",
    "authors": [
      "Sharan Vaswani",
      "Lin F. Yang",
      "Csaba Szepesv\u00e1ri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.06270"
  },
  {
    "id": "arXiv:2206.06273",
    "title": "Learning Joint Surface Atlases",
    "abstract": "This paper describes new techniques for learning atlas-like representations\nof 3D surfaces, i.e. homeomorphic transformations from a 2D domain to surfaces.\nCompared to prior work, we propose two major contributions. First, instead of\nmapping a fixed 2D domain, such as a set of square patches, to the surface, we\nlearn a continuous 2D domain with arbitrary topology by optimizing a point\nsampling distribution represented as a mixture of Gaussians. Second, we learn\nconsistent mappings in both directions: charts, from the 3D surface to 2D\ndomain, and parametrizations, their inverse. We demonstrate that this improves\nthe quality of the learned surface representation, as well as its consistency\nin a collection of related shapes. It thus leads to improvements for\napplications such as correspondence estimation, texture transfer, and\nconsistent UV mapping. As an additional technical contribution, we outline\nthat, while incorporating normal consistency has clear benefits, it leads to\nissues in the optimization, and that these issues can be mitigated using a\nsimple repulsive regularization. We demonstrate that our contributions provide\nbetter surface representation than existing baselines.",
    "descriptor": "",
    "authors": [
      "Theo Deprelle",
      "Thibault Groueix",
      "Noam Aigerman",
      "Vladimir G. Kim",
      "Mathieu Aubry"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06273"
  },
  {
    "id": "arXiv:2206.06274",
    "title": "Lalaine: Measuring and Characterizing Non-Compliance of Apple Privacy  Labels at Scale",
    "abstract": "As a key supplement to privacy policies that are known to be lengthy and\ndifficult to read, Apple has launched the app privacy labels, which purportedly\nhelp users more easily understand an app's privacy practices. However, false\nand misleading privacy labels can dupe privacy-conscious consumers into\ndownloading data-intensive apps, ultimately eroding the credibility and\nintegrity of the labels. Although Apple releases requirements and guidelines\nfor app developers to create privacy labels, little is known about whether and\nto what extent the privacy labels in the wild are correct and compliant,\nreflecting the actual data practices of iOS apps. This paper presents the first\nsystematic study, based on our new methodology named Lalaine, to evaluate\ndata-flow to privacy-label (flow-to-label) consistency. Lalaine analyzed the\nprivacy labels and binaries of 5,102 iOS apps, shedding light on the prevalence\nand seriousness of privacy-label non-compliance. We provide detailed case\nstudies and analyze root causes for privacy label non-compliance that\ncomplements prior understandings. This has led to new insights for improving\nprivacy-label design and compliance requirements, so app developers, platform\nstakeholders, and policy-makers can better achieve their privacy and\naccountability goals. Lalaine is thoroughly evaluated for its high\neffectiveness and efficiency. We are responsibly reporting the results to\nstakeholders.",
    "descriptor": "",
    "authors": [
      "Yue Xiao",
      "Zhengyi Li",
      "Yue Qin",
      "Jiale Guan",
      "Xiaolong Bai",
      "Xiaojing Liao",
      "Luyi Xing"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.06274"
  },
  {
    "id": "arXiv:2206.06275",
    "title": "Robust Trajectory Tracking for Underactuated Quadrotors with Prescribed  Performance",
    "abstract": "We propose a control protocol based on the prescribed performance control\n(PPC) methodology for a quadrotor unmanned aerial vehicle (UAV). Quadrotor\nsystems belong to the class of underactuated systems for which the original PPC\nmethodology cannot be directly applied. We introduce the necessary design\nmodifications to stabilize the considered system with prescribed performance.\nThe proposed control protocol does not use any information of dynamic model\nparameters or exogenous disturbances. Furthermore, the stability analysis\nguarantees that the tracking errors remain inside of designer-specified\ntime-varying functions, achieving prescribed performance independent from the\ncontrol gains' selection. Finally, simulation results verify the theoretical\nresults.",
    "descriptor": "\nComments: 8 pages, 5 figures, submitted to 61st IEEE Conference on Decision and Control 2022\n",
    "authors": [
      "D\u017eenan Lapandi\u0107",
      "Christos K. Verginis",
      "Dimos V. Dimarogonas",
      "Bo Wahlberg"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.06275"
  },
  {
    "id": "arXiv:2206.06276",
    "title": "On the reusability of samples in active learning",
    "abstract": "An interesting but not extensively studied question in active learning is\nthat of sample reusability: to what extent can samples selected for one learner\nbe reused by another? This paper explains why sample reusability is of\npractical interest, why reusability can be a problem, how reusability could be\nimproved by importance-weighted active learning, and which obstacles to\nuniversal reusability remain. With theoretical arguments and practical\ndemonstrations, this paper argues that universal reusability is impossible.\nBecause every active learning strategy must undersample some areas of the\nsample space, learners that depend on the samples in those areas will learn\nmore from a random sample selection. This paper describes several experiments\nwith importance-weighted active learning that show the impact of the\nreusability problem in practice. The experiments confirmed that universal\nreusability does not exist, although in some cases -- on some datasets and with\nsome pairs of classifiers -- there is sample reusability. Finally, this paper\nexplores the conditions that could guarantee the reusability between two\nclassifiers.",
    "descriptor": "",
    "authors": [
      "Gijs van Tulder",
      "Marco Loog"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06276"
  },
  {
    "id": "arXiv:2206.06279",
    "title": "Mitigating health disparities in hospital readmissions",
    "abstract": "The management of hyperglycemia in hospitalized patients has a significant\nimpact on both morbidity and mortality. This study used a large clinical\ndatabase to predict the need for diabetic patients to be hospitalized, which\ncould lead to improvements in patient safety. These predictions, however, may\nbe vulnerable to health disparities caused by social determinants such as race,\nage, and gender. These biases must be removed early in the data collection\nprocess, before they enter the system and are reinforced by model predictions,\nresulting in biases in the model's decisions. In this paper, we propose a\nmachine learning pipeline capable of making predictions as well as detecting\nand mitigating biases. This pipeline analyses clinical data, determines whether\nbiases exist, removes them, and then make predictions. We demonstrate the\nclassification accuracy and fairness in model predictions using experiments.\nThe results show that when we mitigate biases early in a model, we get fairer\npredictions. We also find that as we get better fairness, we sacrifice a\ncertain level of accuracy, which is also validated in the previous studies. We\ninvite the research community to contribute to identifying additional factors\nthat contribute to health disparities that can be addressed through this\npipeline.",
    "descriptor": "\nComments: report\n",
    "authors": [
      "Shaina Raza"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.06279"
  },
  {
    "id": "arXiv:2206.06282",
    "title": "Analysis of Randomization Effects on Sim2Real Transfer in Reinforcement  Learning for Robotic Manipulation Tasks",
    "abstract": "Randomization is currently a widely used approach in Sim2Real transfer for\ndata-driven learning algorithms in robotics. Still, most Sim2Real studies\nreport results for a specific randomization technique and often on a highly\ncustomized robotic system, making it difficult to evaluate different\nrandomization approaches systematically. To address this problem, we define an\neasy-to-reproduce experimental setup for a robotic reach-and-balance\nmanipulator task, which can serve as a benchmark for comparison. We compare\nfour randomization strategies with three randomized parameters both in\nsimulation and on a real robot. Our results show that more randomization helps\nin Sim2Real transfer, yet it can also harm the ability of the algorithm to find\na good policy in simulation. Fully randomized simulations and fine-tuning show\ndifferentiated results and translate better to the real robot than the other\napproaches tested.",
    "descriptor": "",
    "authors": [
      "Josip Josifovski",
      "Mohammadhossein Malmir",
      "Noah Klarmann",
      "Bare Luka \u017dagar",
      "Nicol\u00e1s Navarro-Guerrero",
      "Alois Knoll"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.06282"
  },
  {
    "id": "arXiv:2206.06289",
    "title": "Silver-Bullet-3D at ManiSkill 2021: Learning-from-Demonstrations and  Heuristic Rule-based Methods for Object Manipulation",
    "abstract": "This paper presents an overview and comparative analysis of our systems\ndesigned for the following two tracks in SAPIEN ManiSkill Challenge 2021:\nNo Interaction Track: The No Interaction track targets for learning policies\nfrom pre-collected demonstration trajectories. We investigate both imitation\nlearning-based approach, i.e., imitating the observed behavior using classical\nsupervised learning techniques, and offline reinforcement learning-based\napproaches, for this track. Moreover, the geometry and texture structures of\nobjects and robotic arms are exploited via Transformer-based networks to\nfacilitate imitation learning.\nNo Restriction Track: In this track, we design a Heuristic Rule-based Method\n(HRM) to trigger high-quality object manipulation by decomposing the task into\na series of sub-tasks. For each sub-task, the simple rule-based controlling\nstrategies are adopted to predict actions that can be applied to robotic arms.\nTo ease the implementations of our systems, all the source codes and\npre-trained models are available at\n\\url{https://github.com/caiqi/Silver-Bullet-3D/}.",
    "descriptor": "\nComments: Accepted by ICLR 2022 Workshop on Generalizable Policy Learning in Physical World. Top-performing systems for both no interaction and no restriction tracks in SAPIEN ManiSkill Challenge 2021. The source code and model are publicly available at: this https URL\n",
    "authors": [
      "Yingwei Pan",
      "Yehao Li",
      "Yiheng Zhang",
      "Qi Cai",
      "Fuchen Long",
      "Zhaofan Qiu",
      "Ting Yao",
      "Tao Mei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.06289"
  },
  {
    "id": "arXiv:2206.06291",
    "title": "Exploring Structure-aware Transformer over Interaction Proposals for  Human-Object Interaction Detection",
    "abstract": "Recent high-performing Human-Object Interaction (HOI) detection techniques\nhave been highly influenced by Transformer-based object detector (i.e., DETR).\nNevertheless, most of them directly map parametric interaction queries into a\nset of HOI predictions through vanilla Transformer in a one-stage manner. This\nleaves rich inter- or intra-interaction structure under-exploited. In this\nwork, we design a novel Transformer-style HOI detector, i.e., Structure-aware\nTransformer over Interaction Proposals (STIP), for HOI detection. Such design\ndecomposes the process of HOI set prediction into two subsequent phases, i.e.,\nan interaction proposal generation is first performed, and then followed by\ntransforming the non-parametric interaction proposals into HOI predictions via\na structure-aware Transformer. The structure-aware Transformer upgrades vanilla\nTransformer by encoding additionally the holistically semantic structure among\ninteraction proposals as well as the locally spatial structure of human/object\nwithin each interaction proposal, so as to strengthen HOI predictions.\nExtensive experiments conducted on V-COCO and HICO-DET benchmarks have\ndemonstrated the effectiveness of STIP, and superior results are reported when\ncomparing with the state-of-the-art HOI detectors. Source code is available at\n\\url{https://github.com/zyong812/STIP}.",
    "descriptor": "\nComments: CVPR 2022; Code is publicly available at: this https URL\n",
    "authors": [
      "Yong Zhang",
      "Yingwei Pan",
      "Ting Yao",
      "Rui Huang",
      "Tao Mei",
      "Chang-Wen Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2206.06291"
  },
  {
    "id": "arXiv:2206.06292",
    "title": "MLP-3D: A MLP-like 3D Architecture with Grouped Time Mixing",
    "abstract": "Convolutional Neural Networks (CNNs) have been regarded as the go-to models\nfor visual recognition. More recently, convolution-free networks, based on\nmulti-head self-attention (MSA) or multi-layer perceptrons (MLPs), become more\nand more popular. Nevertheless, it is not trivial when utilizing these\nnewly-minted networks for video recognition due to the large variations and\ncomplexities in video data. In this paper, we present MLP-3D networks, a novel\nMLP-like 3D architecture for video recognition. Specifically, the architecture\nconsists of MLP-3D blocks, where each block contains one MLP applied across\ntokens (i.e., token-mixing MLP) and one MLP applied independently to each token\n(i.e., channel MLP). By deriving the novel grouped time mixing (GTM)\noperations, we equip the basic token-mixing MLP with the ability of temporal\nmodeling. GTM divides the input tokens into several temporal groups and\nlinearly maps the tokens in each group with the shared projection matrix.\nFurthermore, we devise several variants of GTM with different grouping\nstrategies, and compose each variant in different blocks of MLP-3D network by\ngreedy architecture search. Without the dependence on convolutions or attention\nmechanisms, our MLP-3D networks achieves 68.5\\%/81.4\\% top-1 accuracy on\nSomething-Something V2 and Kinetics-400 datasets, respectively. Despite with\nfewer computations, the results are comparable to state-of-the-art widely-used\n3D CNNs and video transformers. Source code is available at\nhttps://github.com/ZhaofanQiu/MLP-3D.",
    "descriptor": "\nComments: CVPR 2022; Code is publicly available at: this https URL\n",
    "authors": [
      "Zhaofan Qiu",
      "Ting Yao",
      "Chong-Wah Ngo",
      "Tao Mei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2206.06292"
  },
  {
    "id": "arXiv:2206.06293",
    "title": "Learning Domain Adaptive Object Detection with Probabilistic Teacher",
    "abstract": "Self-training for unsupervised domain adaptive object detection is a\nchallenging task, of which the performance depends heavily on the quality of\npseudo boxes. Despite the promising results, prior works have largely\noverlooked the uncertainty of pseudo boxes during self-training. In this paper,\nwe present a simple yet effective framework, termed as Probabilistic Teacher\n(PT), which aims to capture the uncertainty of unlabeled target data from a\ngradually evolving teacher and guides the learning of a student in a mutually\nbeneficial manner. Specifically, we propose to leverage the uncertainty-guided\nconsistency training to promote classification adaptation and localization\nadaptation, rather than filtering pseudo boxes via an elaborate confidence\nthreshold. In addition, we conduct anchor adaptation in parallel with\nlocalization adaptation, since anchor can be regarded as a learnable parameter.\nTogether with this framework, we also present a novel Entropy Focal Loss (EFL)\nto further facilitate the uncertainty-guided self-training. Equipped with EFL,\nPT outperforms all previous baselines by a large margin and achieve new\nstate-of-the-arts.",
    "descriptor": "\nComments: To appear in ICML 2022. Code is coming soon: this https URL\n",
    "authors": [
      "Meilin Chen",
      "Weijie Chen",
      "Shicai Yang",
      "Jie Song",
      "Xinchao Wang",
      "Lei Zhang",
      "Yunfeng Yan",
      "Donglian Qi",
      "Yueting Zhuang",
      "Di Xie",
      "Shiliang Pu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.06293"
  },
  {
    "id": "arXiv:2206.06294",
    "title": "Introducing Proof Tree Automata and Proof Tree Graphs",
    "abstract": "In structural proof theory, designing and working on large calculi make it\ndifficult to get intuitions about each rule individually and as part of a whole\nsystem. We introduce two novel tools to help working on calculi using the\napproach of graph theory and automata theory. The first tool is a Proof Tree\nAutomaton (PTA): a tree automaton which language is the derivation language of\na calculus. The second tool is a graphical representation of a calculus called\nProof Tree Graph (PTG). In this directed hypergraph, vertices are sets of terms\n(e.g. sequents) and hyperarcs are rules. We explore properties of PTA and PTGs\nand how they relate to each other. We show that we can decompose a PTA as a\npartial map from a calculus to a traditional tree automaton. We formulate that\nstatement in the theory of refinement systems. Finally, we compare our\nframework to proof nets and string diagrams.",
    "descriptor": "\nComments: Extended abstract accepted at SLSS 2022\n",
    "authors": [
      "Valentin D. Richard"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.06294"
  },
  {
    "id": "arXiv:2206.06295",
    "title": "Markov Chain Score Ascent: A Unifying Framework of Variational Inference  with Markovian Gradients",
    "abstract": "Minimizing the inclusive Kullback-Leibler (KL) divergence with stochastic\ngradient descent (SGD) is challenging since its gradient is defined as an\nintegral over the posterior. Recently, multiple methods have been proposed to\nrun SGD with biased gradient estimates obtained from a Markov chain. This paper\nprovides the first non-asymptotic convergence analysis of these methods by\nestablishing their mixing rate and gradient variance. To do this, we\ndemonstrate that these methods-which we collectively refer to as Markov chain\nscore ascent (MCSA) methods-can be cast as special cases of the Markov chain\ngradient descent framework. Furthermore, by leveraging this new understanding,\nwe develop a novel MCSA scheme, parallel MCSA (pMCSA), that achieves a tighter\nbound on the gradient variance. We demonstrate that this improved theoretical\nresult translates to superior empirical performance.",
    "descriptor": "",
    "authors": [
      "Kyurae Kim",
      "Jisu Oh",
      "Jacob R. Gardner",
      "Adji Bousso Dieng",
      "Hongseok Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.06295"
  },
  {
    "id": "arXiv:2206.06299",
    "title": "On the Design of Decentralised Data Markets",
    "abstract": "We present an architecture to implement a decentralised data market, whereby\nagents are incentivised to collaborate to crowd-source their data. The\narchitecture is designed to reward data that furthers the market's collective\ngoal, and distributes reward fairly to all those that contribute with their\ndata. This is achieved leveraging the concept of Shapley's value from Game\nTheory. Furthermore, we introduce trust assumptions based on provable honesty,\nas opposed to wealth, or computational power, and we aim to reward agents that\nactively enable the functioning of the market. In order to evaluate the\nresilience of the architecture, we characterise its breakdown points for\nvarious adversarial threat models and we validate our analysis through\nextensive Monte Carlo simulations.",
    "descriptor": "\nComments: 25 pages, 12 figures\n",
    "authors": [
      "Aida Manzano Kharman",
      "Christian Jursitzky",
      "Quan Zhao",
      "Pietro Ferraro",
      "Jakub Marecek",
      "Pierre Pinson",
      "Robert Shorten"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.06299"
  },
  {
    "id": "arXiv:2206.06300",
    "title": "Internet of Things (IoT) based Smart Agriculture Aiming to Achieve  Sustainable Goals",
    "abstract": "Despite the fact, a handful of scholars have endorsed the Internet of Things\n(IoT) as an effective transformative tool for shifting traditional farming to\nsmart farming, relatively little study has addressed the enabling role of smart\nagriculture in achieving sustainable agriculture and green climate. Researchers\nare more focused on technological invention and model introduction rather than\ndiscussing societal or global development goals. Sustainable development goals\n(SDGs) designed by United Nations (UN), therefore demand discussions as SDGs\ntargets have a closer implication of technology. To fill this gap, in this\nstudy a model of smart agriculture is developed and centring the model we\ninvestigated how the model addresses SDGs targets. The investigation suggests\nthat smart agriculture supports targets mentioned in Goal 6, 7, 8, 9, 11 and 12\nof SDG. This research is very important, both for developing and developed\nnations since most of the nations are moving more towards industrialization and\naiming to achieve the SDG goals This research is expected to provide a path to\nthe IT practitioners, governments and developing agencies on how technological\nintervention can provide a more sustainable agricultural world.",
    "descriptor": "\nComments: 18 pages and 9 figures\n",
    "authors": [
      "Dewan Md Nur Anjum Ashir",
      "Md. Taimur Ahad",
      "Manosh Talukder",
      "Tahsinur Rahman"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.06300"
  },
  {
    "id": "arXiv:2206.06301",
    "title": "A Hybrid Artificial Neural Network for Task Offloading in Mobile Edge  Computing",
    "abstract": "Edge Computing (EC) is about remodeling the way data is handled, processed,\nand delivered within a vast heterogeneous network. One of the fundamental\nconcepts of EC is to push the data processing near the edge by exploiting\nfront-end devices with powerful computation capabilities. Thus, limiting the\nuse of centralized architecture, such as cloud computing, to only when it is\nnecessary. This paper proposes a novel edge computer offloading technique that\nassigns computational tasks generated by devices to potential edge computers\nwith enough computational resources. The proposed approach clusters the edge\ncomputers based on their hardware specifications. Afterwards, the tasks\ngenerated by devices will be fed to a hybrid Artificial Neural Network (ANN)\nmodel that predicts, based on these tasks, the profiles, i.e., features, of the\nedge computers with enough computational resources to execute them. The\npredicted edge computers are then assigned to the cluster they belong to so\nthat each task is assigned to a cluster of edge computers. Finally, we choose\nfor each task the edge computer that is expected to provide the fastest\nresponse time. The experiment results show that our proposed approach\noutperforms other state-of-the-art machine learning approaches using real-world\nIoT dataset.",
    "descriptor": "\nComments: 5 pages, 4 figures, conference\n",
    "authors": [
      "Raby Hamadi",
      "Abdullah Khanfor",
      "Hakim Ghazzai",
      "Yehia Massoud"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.06301"
  },
  {
    "id": "arXiv:2206.06302",
    "title": "Closing the Performance Gap with Modern C++",
    "abstract": "On the way to Exascale, programmers face the increasing challenge of having\nto support multiple hardware architectures from the same code base. At the same\ntime, portability of code and performance are increasingly difficult to achieve\nas hardware architectures are becoming more and more diverse. Today's\nheterogeneous systems often include two or more completely distinct and\nincompatible hardware execution models, such as GPGPU's, SIMD vector units, and\ngeneral purpose cores which conventionally have to be programmed using separate\ntool chains representing non-overlapping programming models. The recent revival\nof interest in the industry and the wider community for the C++ language has\nspurred a remarkable amount of standardization proposals and technical\nspecifications in the arena of concurrency and parallelism. This recently\nincludes an increasing amount of discussion around the need for a uniform,\nhigher-level abstraction and programming model for parallelism in the C++\nstandard targeting heterogeneous and distributed computing. Such an abstraction\nshould perfectly blend with existing, already standardized language and library\nfeatures, but should also be generic enough to support future hardware\ndevelopments. In this paper, we present the results from developing such a\nhigher-level programming abstraction for parallelism in C++ which aims at\nenabling code and performance portability over a wide range of architectures\nand for various types of parallelism. We present and compare performance data\nobtained from running the well-known STREAM benchmark ported to our higher\nlevel C++ abstraction with the corresponding results from running it natively.\nWe show that our abstractions enable performance at least as good as the\ncomparable base-line benchmarks while providing a uniform programming API on\nall compared target architectures.",
    "descriptor": "",
    "authors": [
      "Thomas Heller",
      "Hartmut Kaiser",
      "Patrick Diehl",
      "Dietmar Fey",
      "Marc Alexander Schweitzer"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2206.06302"
  },
  {
    "id": "arXiv:2206.06304",
    "title": "Multi-user Co-inference with Batch Processing Capable Edge Server",
    "abstract": "Graphics processing units (GPUs) can improve deep neural network inference\nthroughput via batch processing, where multiple tasks are concurrently\nprocessed. We focus on novel scenarios that the energy-constrained mobile\ndevices offload inference tasks to an edge server with GPU. The inference task\nis partitioned into sub-tasks for a finer granularity of offloading and\nscheduling, and the user energy consumption minimization problem under\ninference latency constraints is investigated. To deal with the coupled\noffloading and scheduling introduced by concurrent batch processing, we first\nconsider an offline problem with a constant edge inference latency and the same\nlatency constraint. It is proven that optimizing the offloading policy of each\nuser independently and aggregating all the same sub-tasks in one batch is\noptimal, and thus the independent partitioning and same sub-task aggregating\n(IP-SSA) algorithm is inspired. Further, the optimal grouping (OG) algorithm is\nproposed to optimally group tasks when the latency constraints are different.\nFinally, when future task arrivals cannot be precisely predicted, a deep\ndeterministic policy gradient (DDPG) agent is trained to call OG. Experiments\nshow that IP-SSA reduces up to 94.9\\% user energy consumption in the offline\nsetting, while DDPG-OG outperforms DDPG-IP-SSA by up to 8.92\\% in the online\nsetting.",
    "descriptor": "",
    "authors": [
      "Wenqi Shi",
      "Sheng Zhou",
      "Zhisheng Niu",
      "Miao Jiang",
      "Lu Geng"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06304"
  },
  {
    "id": "arXiv:2206.06307",
    "title": "Towards Constructing Finer then Homotopy Path Classes",
    "abstract": "This work presents a new path classification criterion to distinguish paths\ngeometrically and topologically from the workspace, which is divided through\ncell decomposition, generating a medial-axis-like skeleton structure. We use\nthis information as well as the topology of the robot to bound and classify\ndifferent paths in the configuration space. We show that the path class found\nby the proposed method is equivalent to and finer than the path class defined\nby the homotopy of paths. The proposed path classes are easy to compute,\ncompare, and can be used for various planning purposes. The classification\nbuilds heavily upon the topology of the robot and the geometry of the\nworkspace, leading to an alternative fiber-bundle-based description of the\nconfiguration space. We introduce a planning framework to overcome obstacles\nand narrow passages using the proposed path classification method and the\nresulting path classes.",
    "descriptor": "",
    "authors": [
      "Weifu Wang",
      "Ping Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.06307"
  },
  {
    "id": "arXiv:2206.06308",
    "title": "Knowledge Graph Construction and Its Application in Automatic Radiology  Report Generation from Radiologist's Dictation",
    "abstract": "Conventionally, the radiologist prepares the diagnosis notes and shares them\nwith the transcriptionist. Then the transcriptionist prepares a preliminary\nformatted report referring to the notes, and finally, the radiologist reviews\nthe report, corrects the errors, and signs off. This workflow causes\nsignificant delays and errors in the report. In current research work, we focus\non applications of NLP techniques like Information Extraction (IE) and\ndomain-specific Knowledge Graph (KG) to automatically generate radiology\nreports from radiologist's dictation. This paper focuses on KG construction for\neach organ by extracting information from an existing large corpus of free-text\nradiology reports. We develop an information extraction pipeline that combines\nrule-based, pattern-based, and dictionary-based techniques with\nlexical-semantic features to extract entities and relations. Missing\ninformation in short dictation can be accessed from the KGs to generate\npathological descriptions and hence the radiology report. Generated\npathological descriptions evaluated using semantic similarity metrics, which\nshows 97% similarity with gold standard pathological descriptions. Also, our\nanalysis shows that our IE module is performing better than the OpenIE tool for\nthe radiology domain. Furthermore, we include a manual qualitative analysis\nfrom radiologists, which shows that 80-85% of the generated reports are\ncorrectly written, and the remaining are partially correct.",
    "descriptor": "",
    "authors": [
      "Kaveri Kale",
      "Pushpak Bhattacharyya",
      "Aditya Shetty",
      "Miling Gune",
      "Kush Shrivastava",
      "Rustom Lawyer",
      "Spriha Biswas"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.06308"
  },
  {
    "id": "arXiv:2206.06315",
    "title": "JiuZhang: A Chinese Pre-trained Language Model for Mathematical Problem  Understanding",
    "abstract": "This paper aims to advance the mathematical intelligence of machines by\npresenting the first Chinese mathematical pre-trained language model~(PLM) for\neffectively understanding and representing mathematical problems. Unlike other\nstandard NLP tasks, mathematical texts are difficult to understand, since they\ninvolve mathematical terminology, symbols and formulas in the problem\nstatement. Typically, it requires complex mathematical logic and background\nknowledge for solving mathematical problems.\nConsidering the complex nature of mathematical texts, we design a novel\ncurriculum pre-training approach for improving the learning of mathematical\nPLMs, consisting of both basic and advanced courses. Specially, we first\nperform token-level pre-training based on a position-biased masking strategy,\nand then design logic-based pre-training tasks that aim to recover the shuffled\nsentences and formulas, respectively. Finally, we introduce a more difficult\npre-training task that enforces the PLM to detect and correct the errors in its\ngenerated solutions. We conduct extensive experiments on offline evaluation\n(including nine math-related tasks) and online $A/B$ test. Experimental results\ndemonstrate the effectiveness of our approach compared with a number of\ncompetitive baselines. Our code is available at:\n\\textcolor{blue}{\\url{https://github.com/RUCAIBox/JiuZhang}}.",
    "descriptor": "\nComments: 11 pages, Accepted by KDD 2022\n",
    "authors": [
      "Wayne Xin Zhao",
      "Kun Zhou",
      "Zheng Gong",
      "Beichen Zhang",
      "Yuanhang Zhou",
      "Jing Sha",
      "Zhigang Chen",
      "Shijin Wang",
      "Cong Liu",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.06315"
  },
  {
    "id": "arXiv:2206.06317",
    "title": "Learning Uncertainty with Artificial Neural Networks for Improved  Predictive Process Monitoring",
    "abstract": "The inability of artificial neural networks to assess the uncertainty of\ntheir predictions is an impediment to their widespread use. We distinguish two\ntypes of learnable uncertainty: model uncertainty due to a lack of training\ndata and noise-induced observational uncertainty. Bayesian neural networks use\nsolid mathematical foundations to learn the model uncertainties of their\npredictions. The observational uncertainty can be calculated by adding one\nlayer to these networks and augmenting their loss functions. Our contribution\nis to apply these uncertainty concepts to predictive process monitoring tasks\nto train uncertainty-based models to predict the remaining time and outcomes.\nOur experiments show that uncertainty estimates allow more and less accurate\npredictions to be differentiated and confidence intervals to be constructed in\nboth regression and classification tasks. These conclusions remain true even in\nearly stages of running processes. Moreover, the deployed techniques are fast\nand produce more accurate predictions. The learned uncertainty could increase\nusers' confidence in their process prediction systems, promote better\ncooperation between humans and these systems, and enable earlier\nimplementations with smaller datasets.",
    "descriptor": "",
    "authors": [
      "Hans Weytjens",
      "Jochen De Weerdt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.06317"
  },
  {
    "id": "arXiv:2206.06318",
    "title": "Diffusion of Innovation over Social Networks under Limited-trust  Equilibrium",
    "abstract": "We consider the diffusion of innovation in social networks using a\ngame-theoretic approach. Each individual plays a coordination game with its\nneighbors and decides what alternative product to adopt to maximize its payoff.\nAs products are used in conjunction with others and through repeated\ninteractions, individuals are more interested in their long-term benefits and\ntend to show trustworthiness to others to maximize their long-term payoffs. To\ncapture such trustworthy behavior, we deviate from the expected utility theory\nand use a new notion of rationality based on limited-trust equilibrium (LTE).\nBy incorporating such notion into the diffusion model, we analyze the\nconvergence of emerging dynamics to their equilibrium points using a mean-field\napproximation. We study the equilibrium state and the convergence rate of the\ndiffusion process using the absorption probability and the expected absorption\ntime of a reduced-size absorbing Markov chain. We also show that the LTE\ndiffusion model under the best-response strategy can be converted to the\nwell-known linear threshold model. Simulations show that when agents behave\ntrustworthily, their long-term payoffs will increase significantly compared to\nthe case when they are solely self-interested. Moreover, the Markov chain\nanalysis provides a good estimation of the convergence property over random\nnetworks.",
    "descriptor": "",
    "authors": [
      "Vincent Leon",
      "S. Rasoul Etesami",
      "Rakesh Nagi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.06318"
  },
  {
    "id": "arXiv:2206.06320",
    "title": "Cryptocurrency Bubble Detection: A New Stock Market Dataset, Financial  Task & Hyperbolic Models",
    "abstract": "The rapid spread of information over social media influences quantitative\ntrading and investments. The growing popularity of speculative trading of\nhighly volatile assets such as cryptocurrencies and meme stocks presents a\nfresh challenge in the financial realm. Investigating such \"bubbles\" - periods\nof sudden anomalous behavior of markets are critical in better understanding\ninvestor behavior and market dynamics. However, high volatility coupled with\nmassive volumes of chaotic social media texts, especially for underexplored\nassets like cryptocoins pose a challenge to existing methods. Taking the first\nstep towards NLP for cryptocoins, we present and publicly release\nCryptoBubbles, a novel multi-span identification task for bubble detection, and\na dataset of more than 400 cryptocoins from 9 exchanges over five years\nspanning over two million tweets. Further, we develop a set of\nsequence-to-sequence hyperbolic models suited to this multi-span identification\ntask based on the power-law dynamics of cryptocurrencies and user behavior on\nsocial media. We further test the effectiveness of our models under zero-shot\nsettings on a test set of Reddit posts pertaining to 29 \"meme stocks\", which\nsee an increase in trade volume due to social media hype. Through quantitative,\nqualitative, and zero-shot analyses on Reddit and Twitter spanning cryptocoins\nand meme-stocks, we show the practical applicability of CryptoBubbles and\nhyperbolic models.",
    "descriptor": "\nComments: Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies\n",
    "authors": [
      "Ramit Sawhney",
      "Shivam Agarwal",
      "Vivek Mittal",
      "Paolo Rosso",
      "Vikram Nanda",
      "Sudheer Chava"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Statistical Finance (q-fin.ST)"
    ],
    "url": "https://arxiv.org/abs/2206.06320"
  },
  {
    "id": "arXiv:2206.06322",
    "title": "Tackling Multiple Tasks with One Single Learning Framework",
    "abstract": "Deep Multi-Task Learning (DMTL) has been widely studied in the machine\nlearning community and applied to a broad range of real-world applications.\nSearching for the optimal knowledge sharing in DMTL is more challenging for\nsequential learning problems, as the task relationship will change in the\ntemporal dimension. In this paper, we propose a flexible and efficient\nframework called HierarchicalTemporal Activation Network (HTAN) to\nsimultaneously explore the optimal sharing of the neural network hierarchy\n(hierarchical axis) and the time-variant task relationship (temporal axis).\nHTAN learns a set of time-variant activation functions to encode the task\nrelation. A functional regularization implemented by a modulated SPDNet and\nadversarial learning is further proposed to enhance the DMTL performance.\nComprehensive experiments on several challenging applications demonstrate that\nour HTAN-SPD framework outperforms SOTA methods significantly in sequential\nDMTL.",
    "descriptor": "\nComments: In submission to NeuroIPS. I changed my name from Xuewen Yang to Michael X. Yang. So I started using this name now\n",
    "authors": [
      "Michael X. Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06322"
  },
  {
    "id": "arXiv:2206.06323",
    "title": "Visual Transformer for Object Detection",
    "abstract": "Convolutional Neural networks (CNN) have been the first choice of paradigm in\nmany computer vision applications. The convolution operation however has a\nsignificant weakness which is it only operates on a local neighborhood of\npixels, thus it misses global information of the surrounding neighbors.\nTransformers, or Self-attention networks to be more specific, on the other\nhand, have emerged as a recent advance to capture long range interactions of\nthe input, but they have mostly been applied to sequence modeling tasks such as\nNeural Machine Translation, Image captioning and other Natural Language\nProcessing tasks. Transformers has been applied to natural language related\ntasks and achieved promising results. However, its applications in visual\nrelated tasks are far from being satisfying. Taking into consideration of both\nthe weaknesses of Convolutional Neural Networks and those of the Transformers,\nin this paper, we consider the use of self-attention for discriminative visual\ntasks, object detection, as an alternative to convolutions. In this paper, we\npropose our model: DetTransNet. Extensive experiments show that our model leads\nto consistent improvements in object detection on COCO across many different\nmodels and scales, including ResNets, while keeping the number of parameters\nsimilar. In particular, our method achieves a 1.2% Average Precision\nimprovement on COCO object detection task over other baseline models.",
    "descriptor": "\nComments: In preparation for short paper of conferences. I am using the name Michael Yang\n",
    "authors": [
      "Michael Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06323"
  },
  {
    "id": "arXiv:2206.06331",
    "title": "Learning Generalized Wireless MAC Communication Protocols via  Abstraction",
    "abstract": "To tackle the heterogeneous requirements of beyond 5G (B5G) and future 6G\nwireless networks, conventional medium access control (MAC) procedures need to\nevolve to enable base stations (BSs) and user equipments (UEs) to automatically\nlearn innovative MAC protocols catering to extremely diverse services. This\ntopic has received significant attention, and several reinforcement learning\n(RL) algorithms, in which BSs and UEs are cast as agents, are available with\nthe aim of learning a communication policy based on agents' local observations.\nHowever, current approaches are typically overfitted to the environment they\nare trained in, and lack robustness against unseen conditions, failing to\ngeneralize in different environments. To overcome this problem, in this work,\ninstead of learning a policy in the high dimensional and redundant observation\nspace, we leverage the concept of observation abstraction (OA) rooted in\nextracting useful information from the environment. This in turn allows\nlearning communication protocols that are more robust and with much better\ngeneralization capabilities than current baselines. To learn the abstracted\ninformation from observations, we propose an architecture based on autoencoder\n(AE) and imbue it into a multi-agent proximal policy optimization (MAPPO)\nframework. Simulation results corroborate the effectiveness of leveraging\nabstraction when learning protocols by generalizing across environments, in\nterms of number of UEs, number of data packets to transmit, and channel\nconditions.",
    "descriptor": "",
    "authors": [
      "Luciano Miuccio",
      "Salvatore Riolo",
      "Sumudu Samarakoony",
      "Daniela Panno",
      "Mehdi Bennis"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06331"
  },
  {
    "id": "arXiv:2206.06336",
    "title": "Language Models are General-Purpose Interfaces",
    "abstract": "Foundation models have received much attention due to their effectiveness\nacross a broad range of downstream applications. Though there is a big\nconvergence in terms of architecture, most pretrained models are typically\nstill developed for specific tasks or modalities. In this work, we propose to\nuse language models as a general-purpose interface to various foundation\nmodels. A collection of pretrained encoders perceive diverse modalities (such\nas vision, and language), and they dock with a language model that plays the\nrole of a universal task layer. We propose a semi-causal language modeling\nobjective to jointly pretrain the interface and the modular encoders. We\nsubsume the advantages and capabilities from both causal and non-causal\nmodeling, thereby combining the best of two worlds. Specifically, the proposed\nmethod not only inherits the capabilities of in-context learning and open-ended\ngeneration from causal language modeling, but also is conducive to finetuning\nbecause of the bidirectional encoders. More importantly, our approach\nseamlessly unlocks the combinations of the above capabilities, e.g., enabling\nin-context learning or instruction following with finetuned encoders.\nExperimental results across various language-only and vision-language\nbenchmarks show that our model outperforms or is competitive with specialized\nmodels on finetuning, zero-shot generalization, and few-shot learning.",
    "descriptor": "\nComments: 32 pages. The first three authors contribute equally\n",
    "authors": [
      "Yaru Hao",
      "Haoyu Song",
      "Li Dong",
      "Shaohan Huang",
      "Zewen Chi",
      "Wenhui Wang",
      "Shuming Ma",
      "Furu Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.06336"
  },
  {
    "id": "arXiv:2206.06340",
    "title": "SNeS: Learning Probably Symmetric Neural Surfaces from Incomplete Data",
    "abstract": "We present a method for the accurate 3D reconstruction of partly-symmetric\nobjects. We build on the strengths of recent advances in neural reconstruction\nand rendering such as Neural Radiance Fields (NeRF). A major shortcoming of\nsuch approaches is that they fail to reconstruct any part of the object which\nis not clearly visible in the training image, which is often the case for\nin-the-wild images and videos. When evidence is lacking, structural priors such\nas symmetry can be used to complete the missing information. However,\nexploiting such priors in neural rendering is highly non-trivial: while\ngeometry and non-reflective materials may be symmetric, shadows and reflections\nfrom the ambient scene are not symmetric in general. To address this, we apply\na soft symmetry constraint to the 3D geometry and material properties, having\nfactored appearance into lighting, albedo colour and reflectivity. We evaluate\nour method on the recently introduced CO3D dataset, focusing on the car\ncategory due to the challenge of reconstructing highly-reflective materials. We\nshow that it can reconstruct unobserved regions with high fidelity and render\nhigh-quality novel view images.",
    "descriptor": "\nComments: First two authors contributed equally\n",
    "authors": [
      "Eldar Insafutdinov",
      "Dylan Campbell",
      "Jo\u00e3o F. Henriques",
      "Andrea Vedaldi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06340"
  },
  {
    "id": "arXiv:2206.06346",
    "title": "Bringing Image Scene Structure to Video via Frame-Clip Consistency of  Object Tokens",
    "abstract": "Recent action recognition models have achieved impressive results by\nintegrating objects, their locations and interactions. However, obtaining dense\nstructured annotations for each frame is tedious and time-consuming, making\nthese methods expensive to train and less scalable. At the same time, if a\nsmall set of annotated images is available, either within or outside the domain\nof interest, how could we leverage these for a video downstream task? We\npropose a learning framework StructureViT (SViT for short), which demonstrates\nhow utilizing the structure of a small number of images only available during\ntraining can improve a video model. SViT relies on two key insights. First, as\nboth images and videos contain structured information, we enrich a transformer\nmodel with a set of \\emph{object tokens} that can be used across images and\nvideos. Second, the scene representations of individual frames in video should\n\"align\" with those of still images. This is achieved via a \\emph{Frame-Clip\nConsistency} loss, which ensures the flow of structured information between\nimages and videos. We explore a particular instantiation of scene structure,\nnamely a \\emph{Hand-Object Graph}, consisting of hands and objects with their\nlocations as nodes, and physical relations of contact/no-contact as edges. SViT\nshows strong performance improvements on multiple video understanding tasks and\ndatasets; and it wins first place in the Ego4D CVPR'22 Object State\nLocalization challenge. For code and pretrained models, visit the project page\nat \\url{https://eladb3.github.io/SViT/}",
    "descriptor": "\nComments: Tech report\n",
    "authors": [
      "Elad Ben-Avraham",
      "Roei Herzig",
      "Karttikeya Mangalam",
      "Amir Bar",
      "Anna Rohrbach",
      "Leonid Karlinsky",
      "Trevor Darrell",
      "Amir Globerson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06346"
  },
  {
    "id": "arXiv:2206.06350",
    "title": "Significant Engagement Community Search on Temporal Networks: Concepts  and Algorithms",
    "abstract": "Community search, retrieving the cohesive subgraph which contains the query\nvertex, has been widely touched over the past decades. The existing studies on\ncommunity search mainly focus on static networks. However, real-world networks\nusually are temporal networks where each edge is associated with timestamps.\nThe previous methods do not work when handling temporal networks. We study the\nproblem of identifying the significant engagement community to which the\nuser-specified query belongs. Specifically, given an integer k and a query\nvertex u, then we search for the subgraph H which satisfies (i) u $\\in$ H; (ii)\nthe de-temporal graph of H is a connected k-core; (iii) In H that u has the\nmaximum engagement level. To address our problem, we first develop a top-down\ngreedy peeling algorithm named TDGP, which iteratively removes the vertices\nwith the maximum temporal degree. To boost the efficiency, we then design a\nbottom-up local search algorithm named BULS and its enhanced versions BULS and\nBULS. Lastly, we empirically show the superiority of our proposed solutions on\nsix real-world temporal graphs.",
    "descriptor": "\nComments: 22 pages, 26 figures\n",
    "authors": [
      "Yifei Zhang",
      "Longlong Lin",
      "Pingpeng Yuan",
      "Hai Jin"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.06350"
  },
  {
    "id": "arXiv:2206.06354",
    "title": "Differentiable and Transportable Structure Learning",
    "abstract": "We are interested in unsupervised structure learning with a particular focus\non directed acyclic graphical (DAG) models. Compute required to infer these\nstructures is typically super-exponential in the amount of variables, as\ninference requires a sweep of a combinatorially large space of potential\nstructures. That is, until recent advances allowed to search this space using a\ndifferentiable metric, drastically reducing search time. While this technique\n-- named NOTEARS -- is widely considered a seminal work in DAG-discovery, it\nconcedes an important property in favour of differentiability:\ntransportability. In our paper we introduce D-Struct which recovers\ntransportability in the found structures through a novel architecture and loss\nfunction, while remaining completely differentiable. As D-Struct remains\ndifferentiable, one can easily adopt our method in differentiable architectures\nas was previously done with NOTEARS. In our experiments we empirically validate\nD-Struct with respect to edge accuracy and the structural Hamming distance.",
    "descriptor": "",
    "authors": [
      "Jeroen Berrevoets",
      "Nabeel Seedat",
      "Fergus Imrie",
      "Mihaela van der Schaar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.06354"
  },
  {
    "id": "arXiv:2206.06355",
    "title": "Anomaly Detection and Inter-Sensor Transfer Learning on Smart  Manufacturing Datasets",
    "abstract": "Smart manufacturing systems are being deployed at a growing rate because of\ntheir ability to interpret a wide variety of sensed information and act on the\nknowledge gleaned from system observations. In many cases, the principal goal\nof the smart manufacturing system is to rapidly detect (or anticipate) failures\nto reduce operational cost and eliminate downtime. This often boils down to\ndetecting anomalies within the sensor date acquired from the system. The smart\nmanufacturing application domain poses certain salient technical challenges. In\nparticular, there are often multiple types of sensors with varying capabilities\nand costs. The sensor data characteristics change with the operating point of\nthe environment or machines, such as, the RPM of the motor. The anomaly\ndetection process therefore has to be calibrated near an operating point. In\nthis paper, we analyze four datasets from sensors deployed from manufacturing\ntestbeds. We evaluate the performance of several traditional and ML-based\nforecasting models for predicting the time series of sensor data. Then,\nconsidering the sparse data from one kind of sensor, we perform transfer\nlearning from a high data rate sensor to perform defect type classification.\nTaken together, we show that predictive failure classification can be achieved,\nthus paving the way for predictive maintenance.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2102.05814\n",
    "authors": [
      "Mustafa Abdallah",
      "Byung-Gun Joung",
      "Wo Jae Lee",
      "Charilaos Mousoulis",
      "John W. Sutherland",
      "Saurabh Bagchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.06355"
  },
  {
    "id": "arXiv:2206.06356",
    "title": "Modern Distributed Data-Parallel Large-Scale Pre-training Strategies For  NLP models",
    "abstract": "Distributed deep learning is becoming increasingly popular due to the\nexpanding demand for computing resources for deep learning models with a larger\namount of parameters. Different from traditional training approaches,\ndata-parallel training allows multiple compute nodes to train large deep\nlearning models simultaneously in order to boost the training efficiency. In\nthis paper, we present and compare six strategies for data-parallel training\nusing PyTorch on the language model GPT-2 with 100M parameters using a\nqualitative approach. These strategies are Single GPU, Single Parameter Server,\nDistributed Parameter Server, Horovod, Distributed Parameter Server with Apex\nmixed-precision strategy, and Horovod with Apex mixed-precision strategy. We\nalso analyze the quantitative experiment results from each strategy. In the\nend, we draw the conclusion that the Distributed Parameter Server with Apex\nmixedprecision strategy has the best performance on single node training, while\nHorovod with Apex is the most robust approach to use when we have single or\nmultiple nodes.",
    "descriptor": "\nComments: Accepted by HP3C'22\n",
    "authors": [
      "Hao Bai"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.06356"
  },
  {
    "id": "arXiv:2206.06357",
    "title": "Federated Bayesian Neural Regression: A Scalable Global Federated  Gaussian Process",
    "abstract": "In typical scenarios where the Federated Learning (FL) framework applies, it\nis common for clients to have insufficient training data to produce an accurate\nmodel. Thus, models that provide not only point estimations, but also some\nnotion of confidence are beneficial. Gaussian Process (GP) is a powerful\nBayesian model that comes with naturally well-calibrated variance estimations.\nHowever, it is challenging to learn a stand-alone global GP since merging local\nkernels leads to privacy leakage. To preserve privacy, previous works that\nconsider federated GPs avoid learning a global model by focusing on the\npersonalized setting or learning an ensemble of local models. We present\nFederated Bayesian Neural Regression (FedBNR), an algorithm that learns a\nscalable stand-alone global federated GP that respects clients' privacy. We\nincorporate deep kernel learning and random features for scalability by\ndefining a unifying random kernel. We show this random kernel can recover any\nstationary kernel and many non-stationary kernels. We then derive a principled\napproach of learning a global predictive model as if all client data is\ncentralized. We also learn global kernels with knowledge distillation methods\nfor non-identically and independently distributed (non-i.i.d.) clients.\nExperiments are conducted on real-world regression datasets and show\nstatistically significant improvements compared to other federated GP models.",
    "descriptor": "\nComments: 10 pages main text, 5 pages appendix, 5 figures\n",
    "authors": [
      "Haolin Yu",
      "Kaiyang Guo",
      "Mahdi Karami",
      "Xi Chen",
      "Guojun Zhang",
      "Pascal Poupart"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06357"
  },
  {
    "id": "arXiv:2206.06359",
    "title": "EnergyMatch: Energy-based Pseudo-Labeling for Semi-Supervised Learning",
    "abstract": "Recent state-of-the-art methods in semi-supervised learning (SSL) combine\nconsistency regularization with confidence-based pseudo-labeling. To obtain\nhigh-quality pseudo-labels, a high confidence threshold is typically adopted.\nHowever, it has been shown that softmax-based confidence scores in deep\nnetworks can be arbitrarily high for samples far from the training data, and\nthus, the pseudo-labels for even high-confidence unlabeled samples may still be\nunreliable. In this work, we present a new perspective of pseudo-labeling:\ninstead of relying on model confidence, we instead measure whether an unlabeled\nsample is likely to be \"in-distribution\"; i.e., close to the current training\ndata. To classify whether an unlabeled sample is \"in-distribution\" or\n\"out-of-distribution\", we adopt the energy score from out-of-distribution\ndetection literature. As training progresses and more unlabeled samples become\nin-distribution and contribute to training, the combined labeled and\npseudo-labeled data can better approximate the true distribution to improve the\nmodel. Experiments demonstrate that our energy-based pseudo-labeling method,\nalbeit conceptually simple, significantly outperforms confidence-based methods\non imbalanced SSL benchmarks, and achieves competitive performance on\nclass-balanced data. For example, it produces a 4-6% absolute accuracy\nimprovement on CIFAR10-LT when the imbalance ratio is higher than 50. When\ncombined with state-of-the-art long-tailed SSL methods, further improvements\nare attained.",
    "descriptor": "",
    "authors": [
      "Zhuoran Yu",
      "Yin Li",
      "Yong Jae Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06359"
  },
  {
    "id": "arXiv:2206.06360",
    "title": "ARF: Artistic Radiance Fields",
    "abstract": "We present a method for transferring the artistic features of an arbitrary\nstyle image to a 3D scene. Previous methods that perform 3D stylization on\npoint clouds or meshes are sensitive to geometric reconstruction errors for\ncomplex real-world scenes. Instead, we propose to stylize the more robust\nradiance field representation. We find that the commonly used Gram matrix-based\nloss tends to produce blurry results without faithful brushstrokes, and\nintroduce a nearest neighbor-based loss that is highly effective at capturing\nstyle details while maintaining multi-view consistency. We also propose a novel\ndeferred back-propagation method to enable optimization of memory-intensive\nradiance fields using style losses defined on full-resolution rendered images.\nOur extensive evaluation demonstrates that our method outperforms baselines by\ngenerating artistic appearance that more closely resembles the style image.\nPlease check our project page for video results and open-source\nimplementations: https://www.cs.cornell.edu/projects/arf/ .",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Kai Zhang",
      "Nick Kolkin",
      "Sai Bi",
      "Fujun Luan",
      "Zexiang Xu",
      "Eli Shechtman",
      "Noah Snavely"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06360"
  },
  {
    "id": "arXiv:2206.06363",
    "title": "Discovering Object Masks with Transformers for Unsupervised Semantic  Segmentation",
    "abstract": "The task of unsupervised semantic segmentation aims to cluster pixels into\nsemantically meaningful groups. Specifically, pixels assigned to the same\ncluster should share high-level semantic properties like their object or part\ncategory. This paper presents MaskDistill: a novel framework for unsupervised\nsemantic segmentation based on three key ideas. First, we advocate a\ndata-driven strategy to generate object masks that serve as a pixel grouping\nprior for semantic segmentation. This approach omits handcrafted priors, which\nare often designed for specific scene compositions and limit the applicability\nof competing frameworks. Second, MaskDistill clusters the object masks to\nobtain pseudo-ground-truth for training an initial object segmentation model.\nThird, we leverage this model to filter out low-quality object masks. This\nstrategy mitigates the noise in our pixel grouping prior and results in a clean\ncollection of masks which we use to train a final segmentation model. By\ncombining these components, we can considerably outperform previous works for\nunsupervised semantic segmentation on PASCAL (+11% mIoU) and COCO (+4% mask\nAP50). Interestingly, as opposed to existing approaches, our framework does not\nlatch onto low-level image cues and is not limited to object-centric datasets.\nThe code and models will be made available.",
    "descriptor": "\nComments: Code: this https URL\n",
    "authors": [
      "Wouter Van Gansbeke",
      "Simon Vandenhende",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06363"
  },
  {
    "id": "arXiv:2206.02166",
    "title": "Error Analysis of Time-Discrete Random Batch Method for Interacting  Particle Systems and Associated Mean-Field Limits",
    "abstract": "The random batch method provides an efficient algorithm for computing\nstatistical properties of a canonical ensemble of interacting particles. In\nthis work, we study the error estimates of the fully discrete random batch\nmethod, especially in terms of approximating the invariant distribution. Using\na triangle inequality framework, we show that the long-time error of the method\nis $O(\\sqrt{\\tau} + e^{-\\beta t})$, where $\\tau$ is the time step and $\\beta$\nis the convergence rate which does not depend on the time step $\\tau$ or the\nnumber of particles $N$. Our results also apply to the McKean-Vlasov process,\nwhich is the mean-field limit of the interacting particle system as the number\nof particles $N\\rightarrow\\infty$.",
    "descriptor": "",
    "authors": [
      "Xuda Ye",
      "Zhennan Zhou"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.02166"
  },
  {
    "id": "arXiv:2206.03864",
    "title": "Discontinuity Computing with Physics-Informed Neural Network",
    "abstract": "How to simulate shock waves and other discontinuities is a long history\ntopic. As a new and booming method, the physics-informed neural network (PINN)\nis still weak in calculating shock waves than traditional shock-capturing\nmethods. In this paper, we propose a `retreat in order to advance' way to\nimprove the shock-capturing ability of PINN by using a weighted equations (WE)\nmethod with PINN. The primary strategy of the method is to weaken the\nexpression of the network in high compressible regions by adding a local\npositive and compression-dependent weight into governing equations at each\ninterior point. With this strategy, the network will focus on training smooth\nparts of the solutions. Then automatically affected by the compressible\nproperty near shock waves, a sharp discontinuity appears with the wrong\ninside-shock-points `compressed' into well-trained smooth regions just like\npassive particles. In this paper, we study one-dimensional and two-dimensional\nEuler equations. As illustrated by the comparisons with the high-order\nclassical WENO-Z method in numerical examples, the proposed method can\nsignificantly improve the discontinuity computing ability.",
    "descriptor": "",
    "authors": [
      "Li Liu",
      "Shengping Liu",
      "Heng Yong",
      "Fansheng Xiong",
      "Tengchao Yu"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.03864"
  },
  {
    "id": "arXiv:2206.04663",
    "title": "Provably efficient variational generative modeling of quantum many-body  systems via quantum-probabilistic information geometry",
    "abstract": "The dual tasks of quantum Hamiltonian learning and quantum Gibbs sampling are\nrelevant to many important problems in physics and chemistry. In the low\ntemperature regime, algorithms for these tasks often suffer from\nintractabilities, for example from poor sample- or time-complexity. With the\naim of addressing such intractabilities, we introduce a generalization of\nquantum natural gradient descent to parameterized mixed states, as well as\nprovide a robust first-order approximating algorithm, Quantum-Probabilistic\nMirror Descent. We prove data sample efficiency for the dual tasks using tools\nfrom information geometry and quantum metrology, thus generalizing the seminal\nresult of classical Fisher efficiency to a variational quantum algorithm for\nthe first time. Our approaches extend previously sample-efficient techniques to\nallow for flexibility in model choice, including to spectrally-decomposed\nmodels like Quantum Hamiltonian-Based Models, which may circumvent intractable\ntime complexities. Our first-order algorithm is derived using a novel quantum\ngeneralization of the classical mirror descent duality. Both results require a\nspecial choice of metric, namely, the Bogoliubov-Kubo-Mori metric. To test our\nproposed algorithms numerically, we compare their performance to existing\nbaselines on the task of quantum Gibbs sampling for the transverse field Ising\nmodel. Finally, we propose an initialization strategy leveraging geometric\nlocality for the modelling of sequences of states such as those arising from\nquantum-stochastic processes. We demonstrate its effectiveness empirically for\nboth real and imaginary time evolution while defining a broader class of\npotential applications.",
    "descriptor": "\nComments: 24 + 49 pages, 5 + 4 figures\n",
    "authors": [
      "Faris M. Sbahi",
      "Antonio J. Martinez",
      "Sahil Patel",
      "Dmitri Saberi",
      "Jae Hyeon Yoo",
      "Geoffrey Roeder",
      "Guillaume Verdon"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.04663"
  },
  {
    "id": "arXiv:2206.05277",
    "title": "Superresolution and Segmentation of OCT scans using Multi-Stage  adversarial Guided Attention Training",
    "abstract": "Optical coherence tomography (OCT) is one of the non-invasive and\neasy-to-acquire biomarkers (the thickness of the retinal layers, which is\ndetectable within OCT scans) being investigated to diagnose Alzheimer's disease\n(AD). This work aims to segment the OCT images automatically; however, it is a\nchallenging task due to various issues such as the speckle noise, small target\nregion, and unfavorable imaging conditions. In our previous work, we have\nproposed the multi-stage & multi-discriminatory generative adversarial network\n(MultiSDGAN) to translate OCT scans in high-resolution segmentation labels. In\nthis investigation, we aim to evaluate and compare various combinations of\nchannel and spatial attention to the MultiSDGAN architecture to extract more\npowerful feature maps by capturing rich contextual relationships to improve\nsegmentation performance. Moreover, we developed and evaluated a guided\nmutli-stage attention framework where we incorporated a guided attention\nmechanism by forcing an L-1 loss between a specifically designed binary mask\nand the generated attention maps. Our ablation study results on the WVU-OCT\ndata-set in five-fold cross-validation (5-CV) suggest that the proposed\nMultiSDGAN with a serial attention module provides the most competitive\nperformance, and guiding the spatial attention feature maps by binary masks\nfurther improves the performance in our proposed network. Comparing the\nbaseline model with adding the guided-attention, our results demonstrated\nrelative improvements of 21.44% and 19.45% on the Dice coefficient and SSIM,\nrespectively.",
    "descriptor": "\nComments: 5 pages,conference\n",
    "authors": [
      "Paria Jeihouni",
      "Omid Dehzangi",
      "Annahita Amireskandari",
      "Ali Dabouei",
      "Ali Rezai",
      "Nasser M. Nasrabadi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.05277"
  },
  {
    "id": "arXiv:2206.05278",
    "title": "Dual-Branch Squeeze-Fusion-Excitation Module for Cross-Modality  Registration of Cardiac SPECT and CT",
    "abstract": "Single-photon emission computed tomography (SPECT) is a widely applied\nimaging approach for diagnosis of coronary artery diseases. Attenuation maps\n(u-maps) derived from computed tomography (CT) are utilized for attenuation\ncorrection (AC) to improve diagnostic accuracy of cardiac SPECT. However, SPECT\nand CT are obtained sequentially in clinical practice, which potentially\ninduces misregistration between the two scans. Convolutional neural networks\n(CNN) are powerful tools for medical image registration. Previous CNN-based\nmethods for cross-modality registration either directly concatenated two input\nmodalities as an early feature fusion or extracted image features using two\nseparate CNN modules for a late fusion. These methods do not fully extract or\nfuse the cross-modality information. Besides, deep-learning-based rigid\nregistration of cardiac SPECT and CT-derived u-maps has not been investigated\nbefore. In this paper, we propose a Dual-Branch Squeeze-Fusion-Excitation\n(DuSFE) module for the registration of cardiac SPECT and CT-derived u-maps.\nDuSFE fuses the knowledge from multiple modalities to recalibrate both\nchannel-wise and spatial features for each modality. DuSFE can be embedded at\nmultiple convolutional layers to enable feature fusion at different spatial\ndimensions. Our studies using clinical data demonstrated that a network\nembedded with DuSFE generated substantial lower registration errors and\ntherefore more accurate AC SPECT images than previous methods.",
    "descriptor": "\nComments: 10 pages, 4 figures, accepted at MICCAI 2022\n",
    "authors": [
      "Xiongchao Chen",
      "Bo Zhou",
      "Huidong Xie",
      "Xueqi Guo",
      "Jiazhen Zhang",
      "Albert J. Sinusas",
      "John A. Onofrey",
      "Chi liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.05278"
  },
  {
    "id": "arXiv:2206.05279",
    "title": "PILC: Practical Image Lossless Compression with an End-to-end GPU  Oriented Neural Framework",
    "abstract": "Generative model based image lossless compression algorithms have seen a\ngreat success in improving compression ratio. However, the throughput for most\nof them is less than 1 MB/s even with the most advanced AI accelerated chips,\npreventing them from most real-world applications, which often require 100\nMB/s. In this paper, we propose PILC, an end-to-end image lossless compression\nframework that achieves 200 MB/s for both compression and decompression with a\nsingle NVIDIA Tesla V100 GPU, 10 times faster than the most efficient one\nbefore. To obtain this result, we first develop an AI codec that combines\nauto-regressive model and VQ-VAE which performs well in lightweight setting,\nthen we design a low complexity entropy coder that works well with our codec.\nExperiments show that our framework compresses better than PNG by a margin of\n30% in multiple datasets. We believe this is an important step to bring AI\ncompression forward to commercial use.",
    "descriptor": "",
    "authors": [
      "Ning Kang",
      "Shanzhao Qiu",
      "Shifeng Zhang",
      "Zhenguo Li",
      "Shutao Xia"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.05279"
  },
  {
    "id": "arXiv:2206.05283",
    "title": "Poissonian Blurred Image Deconvolution by Framelet based Local Minimal  Prior",
    "abstract": "Image production tools do not always create a clear image, noisy and blurry\nimages are sometimes created. Among these cases, Poissonian noise is one of the\nmost famous noises that appear in medical images and images taken in astronomy.\nBlurred image with Poissonian noise obscures important details that are of\ngreat importance in medicine or astronomy. Therefore, studying and increasing\nthe quality of images that are affected by this type of noise is always\nconsidered by researchers. In this paper, in the first step, based on framelet\ntransform, a local minimal prior is introduced, and in the next step, this tool\ntogether with fractional calculation is used for Poissonian blurred image\ndeconvolution. In the following, the model is generalized to the blind case. To\nevaluate the performance of the presented model, several images such as real\nimages have been investigated.",
    "descriptor": "",
    "authors": [
      "Reza Parvaz"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.05283"
  },
  {
    "id": "arXiv:2206.05284",
    "title": "Decoupling Predictions in Distributed Learning for Multi-Center Left  Atrial MRI Segmentation",
    "abstract": "Distributed learning has shown great potential in medical image analysis. It\nallows to use multi-center training data with privacy protection. However, data\ndistributions in local centers can vary from each other due to different\nimaging vendors, and annotation protocols. Such variation degrades the\nperformance of learning-based methods. To mitigate the influence, two groups of\nmethods have been proposed for different aims, i.e., the global methods and the\npersonalized methods. The former are aimed to improve the performance of a\nsingle global model for all test data from unseen centers (known as generic\ndata); while the latter target multiple models for each center (denoted as\nlocal data). However, little has been researched to achieve both goals\nsimultaneously. In this work, we propose a new framework of distributed\nlearning that bridges the gap between two groups, and improves the performance\nfor both generic and local data. Specifically, our method decouples the\npredictions for generic data and local data, via distribution-conditioned\nadaptation matrices. Results on multi-center left atrial (LA) MRI segmentation\nshowed that our method demonstrated superior performance over existing methods\non both generic and local data. Our code is available at\nhttps://github.com/key1589745/decouple_predict",
    "descriptor": "\nComments: Accepted by MICCAI 2022\n",
    "authors": [
      "Zheyao Gao",
      "Lei Li",
      "Fuping Wu",
      "Sihan Wang",
      "Xiahai Zhuang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05284"
  },
  {
    "id": "arXiv:2206.05288",
    "title": "From Labels to Priors in Capsule Endoscopy: A Prior Guided Approach for  Improving Generalization with Few Labels",
    "abstract": "The lack of generalizability of deep learning approaches for the automated\ndiagnosis of pathologies in Wireless Capsule Endoscopy (WCE) has prevented any\nsignificant advantages from trickling down to real clinical practices. As a\nresult, disease management using WCE continues to depend on exhaustive manual\ninvestigations by medical experts. This explains its limited use despite\nseveral advantages. Prior works have considered using higher quality and\nquantity of labels as a way of tackling the lack of generalization, however\nthis is hardly scalable considering pathology diversity not to mention that\nlabeling large datasets encumbers the medical staff additionally. We propose\nusing freely available domain knowledge as priors to learn more robust and\ngeneralizable representations. We experimentally show that domain priors can\nbenefit representations by acting in proxy of labels, thereby significantly\nreducing the labeling requirement while still enabling fully unsupervised yet\npathology-aware learning. We use the contrastive objective along with\nprior-guided views during pretraining, where the view choices inspire\nsensitivity to pathological information. Extensive experiments on three\ndatasets show that our method performs better than (or closes gap with) the\nstate-of-the-art in the domain, establishing a new benchmark in pathology\nclassification and cross-dataset generalization, as well as scaling to unseen\npathology categories.",
    "descriptor": "",
    "authors": [
      "Anuja Vats",
      "Ahmed Mohammed",
      "Marius Pedersen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05288"
  },
  {
    "id": "arXiv:2206.05289",
    "title": "Localized adversarial artifacts for compressed sensing MRI",
    "abstract": "As interest in deep neural networks (DNNs) for image reconstruction tasks\ngrows, their reliability has been called into question (Antun et al., 2020;\nGottschling et al., 2020). However, recent work has shown that compared to\ntotal variation (TV) minimization, they show similar robustness to adversarial\nnoise in terms of $\\ell^2$-reconstruction error (Genzel et al., 2022). We\nconsider a different notion of robustness, using the $\\ell^\\infty$-norm, and\nargue that localized reconstruction artifacts are a more relevant defect than\nthe $\\ell^2$-error. We create adversarial perturbations to undersampled MRI\nmeasurements which induce severe localized artifacts in the TV-regularized\nreconstruction. The same attack method is not as effective against DNN based\nreconstruction. Finally, we show that this phenomenon is inherent to\nreconstruction methods for which exact recovery can be guaranteed, as with\ncompressed sensing reconstructions with $\\ell^1$- or TV-minimization.",
    "descriptor": "\nComments: 14 pages, 7 figures\n",
    "authors": [
      "Rima Alaifari",
      "Giovanni S. Alberti",
      "Tandri Gauksson"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05289"
  },
  {
    "id": "arXiv:2206.05290",
    "title": "IRS for Multi-Access Edge Computing in 6G Networks",
    "abstract": "Computation offloading in multi-access edge computing (MEC) is an effective\nparadigm for enabling resource-intensive smart applications. However, when the\nwireless channel utilized for offloading computing activities is hostile, the\nproper advantages of MEC may not be completely realized. Intelligent reflecting\nsurface (IRS) is a new technology that has recently attracted significant\ninterest can optimize the wireless transmission environment in a programmable\nway and improving the connectivity between user equipment (UE) and base station\n(BS). In this paper, the performance of MEC architecture is analyzed\nconsidering both IRS-assisted and without IRS communication scenarios in the\ncontext of the urban micro cellular scenarios. The research obtained that the\ndeployment of IRS can reduce the spectrum and energy consumption significantly.",
    "descriptor": "",
    "authors": [
      "Mobasshir Mahbub",
      "Raed M. Shubair"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.05290"
  },
  {
    "id": "arXiv:2206.05346",
    "title": "Random Walks, Equidistribution and Graphical Designs",
    "abstract": "Let $G=(V,E)$ be a $d$-regular graph on $n$ vertices and let $\\mu_0$ be a\nprobability measure on $V$. The act of moving to a randomly chosen neighbor\nleads to a sequence of probability measures supported on $V$ given by\n$\\mu_{k+1} = A D^{-1} \\mu_k$, where $A$ is the adjacency matrix and $D$ is the\ndiagonal matrix of vertex degrees of $G$. Ordering the eigenvalues of $ A\nD^{-1}$ as $1 = \\lambda_1 \\geq |\\lambda_2| \\geq \\dots \\geq |\\lambda_n| \\geq 0$,\nit is well-known that the graphs for which $|\\lambda_2|$ is small are those in\nwhich the random walk process converges quickly to the uniform distribution:\nfor all initial probability measures $\\mu_0$ and all $k \\geq 0$, $$ \\sum_{v \\in\nV} \\left| \\mu_k(v) - \\frac{1}{n} \\right|^2 \\leq \\lambda_2^{2k}.$$ One could\nwonder whether this rate can be improved for specific initial probability\nmeasures $\\mu_0$. We show that if $G$ is regular, then for any $1 \\leq \\ell\n\\leq n$, there exists a probability measure $\\mu_0$ supported on at most $\\ell$\nvertices so that $$ \\sum_{v \\in V} \\left| \\mu_k(v) - \\frac{1}{n} \\right|^2 \\leq\n\\lambda_{\\ell+1}^{2k}.$$ The result has applications in the graph sampling\nproblem: we show that these measures have good sampling properties for\nreconstructing global averages.",
    "descriptor": "",
    "authors": [
      "Stefan Steinerberger",
      "Rekha R. Thomas"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.05346"
  },
  {
    "id": "arXiv:2206.05373",
    "title": "An application of neural networks to a problem in knot theory and group  theory (untangling braids)",
    "abstract": "We report on our success on solving the problem of untangling braids up to\nlength 20 and width 4. We use feed-forward neural networks in the framework of\nreinforcement learning to train the agent to choose Reidemeister moves to\nuntangle braids in the minimal number of moves.",
    "descriptor": "",
    "authors": [
      "Alexei Lisitsa",
      "Mateo Salles",
      "Alexei Vernitski"
    ],
    "subjectives": [
      "Geometric Topology (math.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05373"
  },
  {
    "id": "arXiv:2206.05391",
    "title": "Feature Selection using e-values",
    "abstract": "In the context of supervised parametric models, we introduce the concept of\ne-values. An e-value is a scalar quantity that represents the proximity of the\nsampling distribution of parameter estimates in a model trained on a subset of\nfeatures to that of the model trained on all features (i.e. the full model).\nUnder general conditions, a rank ordering of e-values separates models that\ncontain all essential features from those that do not.\nThe e-values are applicable to a wide range of parametric models. We use data\ndepths and a fast resampling-based algorithm to implement a feature selection\nprocedure using e-values, providing consistency results. For a $p$-dimensional\nfeature space, this procedure requires fitting only the full model and\nevaluating $p+1$ models, as opposed to the traditional requirement of fitting\nand evaluating $2^p$ models. Through experiments across several model settings\nand synthetic and real datasets, we establish that the e-values method as a\npromising general alternative to existing model-specific methods of feature\nselection.",
    "descriptor": "\nComments: accepted in ICML-2022\n",
    "authors": [
      "Subhabrata Majumdar",
      "Snigdhansu Chatterjee"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2206.05391"
  },
  {
    "id": "arXiv:2206.05404",
    "title": "Squeeze All: Novel Estimator and Self-Normalized Bound for Linear  Contextual Bandits",
    "abstract": "We propose a novel algorithm for linear contextual bandits with $O(\\sqrt{dT\n\\log T})$ regret bound, where $d$ is the dimension of contexts and $T$ is the\ntime horizon. Our proposed algorithm is equipped with a novel estimator in\nwhich exploration is embedded through explicit randomization. Depending on the\nrandomization, our proposed estimator takes contribution either from contexts\nof all arms or from selected contexts. We establish a self-normalized bound for\nour estimator, which allows a novel decomposition of the cumulative regret into\nadditive dimension-dependent terms instead of multiplicative terms. We also\nprove a novel lower bound of $\\Omega(\\sqrt{dT})$ under our problem setting.\nHence, the regret of our proposed algorithm matches the lower bound up to\nlogarithmic factors. The numerical experiments support the theoretical\nguarantees and show that our proposed method outperforms the existing linear\nbandit algorithms.",
    "descriptor": "\nComments: 27 pages including Appendix\n",
    "authors": [
      "Wonyoung Kim",
      "Min-whan Oh",
      "Myunghee Cho Paik"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05404"
  },
  {
    "id": "arXiv:2206.05433",
    "title": "Gigahertz-rate random speckle projection for high-speed single-pixel  image classification",
    "abstract": "Imaging techniques based on single-pixel detection, such as ghost imaging,\ncan reconstruct or recognize a target scene from multiple measurements using a\nsequence of random mask patterns. However, the processing speed is limited by\nthe low rate of the pattern generation. In this study, we propose an ultrafast\nmethod for random speckle pattern generation, which has the potential to\novercome the limited processing speed. The proposed approach is based on\nmultimode fiber speckles induced by fast optical phase modulation. We\nexperimentally demonstrate dynamic speckle projection with phase modulation at\n10 GHz rates, which is five to six orders of magnitude higher than conventional\nmodulation approaches using spatial light modulators. Moreover, we combine the\nproposed generation approach with a wavelength-division multiplexing technique\nand apply it for image classification. As a proof-of-concept demonstration, we\nshow that 28x28-pixel images of digits acquired at GHz rates can be accurately\nclassified using a simple neural network. The proposed approach opens a novel\npathway for an all-optical image processor.",
    "descriptor": "\nComments: 7 pages, 7 figures\n",
    "authors": [
      "Jinsei Hanawa",
      "Tomoaki Niiyama",
      "Yutaka Endo",
      "Satoshi Sunada"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2206.05433"
  },
  {
    "id": "arXiv:2206.05434",
    "title": "Rewindable Quantum Computation and Its Equivalence to Cloning and  Adaptive Postselection",
    "abstract": "We define rewinding operators that invert quantum measurements. Then, we\ndefine complexity classes ${\\sf RwBQP}$, ${\\sf CBQP}$, and ${\\sf AdPostBQP}$ as\nsets of decision problems solvable by polynomial-size quantum circuits with a\npolynomial number of rewinding operators, cloning operators, and (adaptive)\npostselections, respectively. Our main result is that ${\\sf BPP}^{\\sf\nPP}\\subseteq{\\sf RwBQP}={\\sf CBQP}={\\sf AdPostBQP}\\subseteq{\\sf PSPACE}$. As a\nbyproduct of this result, we show that any problem in ${\\sf PostBQP}$ can be\nsolved with only postselections of outputs whose probabilities are at least\nsome constant. Under the strongly believed assumption that the shortest\nindependent vectors problem cannot be efficiently solved with quantum\ncomputers, we also show that a single rewinding operator is sufficient to\nachieve a task that is intractable for quantum computation. In addition, we\nconsider rewindable Clifford and instantaneous quantum polynomial time\ncircuits.",
    "descriptor": "\nComments: 27 pages, 3 figures\n",
    "authors": [
      "Ryo Hiromasa",
      "Akihiro Mizutani",
      "Yuki Takeuchi",
      "Seiichiro Tani"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2206.05434"
  },
  {
    "id": "arXiv:2206.05443",
    "title": "Islamic economy and capitalism: Comparison using econophysics models of  exchange and redistribution",
    "abstract": "What are the fundamental differences between an Islamic economy and\ncapitalism? The Islamic economy is characterized by the prohibition of Riba\n(interest) and the enforcement of Mudaraba (joint venture) and Waqf (donation).\nWe propose new econophysics models of wealth exchange and redistribution to\nquantitatively compare these characteristics with the differences in\ncapitalism, and evaluate wealth distribution and disparities by simulation.\nSpecifically, we propose a loan interest model representing finance capitalism\nand Riba, a joint venture model representing shareholder capitalism and\nMudaraba with respect to exchange, and a transfer model representing\ninheritance tax and Waqf with respect to redistribution. As exchanges are\nrepeated from an initial uniform distribution of wealth, the distribution of\nwealth approaches a power-law distribution more quickly in the loan than in the\njoint, and the Gini index, which represents disparity, rapidly increases. The\njoint has a slower increase in the Gini index, but eventually the wealth\ndistribution in both models becomes a delta distribution, and the Gini index\ngradually approaches 1. Next, when both models are combined with the transfer\nmodel to redistribute wealth every given period, the loan has a larger Gini\nindex than the joint, but both models converge to a value with a Gini index\nless than 1. These results quantitatively reveal that in the Islamic economy,\ndisparities are restrained by their characteristics. These correspond to the\nthree economic modes Polanyi presented: reciprocity, redistribution, and\nexchange. The insights encourage an economy that embraces the morals of mutual\naid as described in Mauss's theory of gifts, Kropotkin's theory of mutual aid,\nGraeber's theory of debt, Sarthou-Lajus's repayment to third parties, and\nKaratani's mode of exchange D, and provide guidelines for the next alternative\nto capitalism.",
    "descriptor": "\nComments: 35 pages, 7 figures\n",
    "authors": [
      "Takeshi Kato"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Multiagent Systems (cs.MA)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.05443"
  },
  {
    "id": "arXiv:2206.05462",
    "title": "Svadhyaya system for the Second Diagnosing COVID-19 using Acoustics  Challenge 2021",
    "abstract": "This report describes the system used for detecting COVID-19 positives using\nthree different acoustic modalities, namely speech, breathing, and cough in the\nsecond DiCOVA challenge. The proposed system is based on the combination of 4\ndifferent approaches, each focusing more on one aspect of the problem, and\nreaches the blind test AUCs of 86.41, 77.60, and 84.55, in the breathing,\ncough, and speech tracks, respectively, and the AUC of 85.37 in the fusion of\nthese three tracks.",
    "descriptor": "",
    "authors": [
      "Deepak Mittal",
      "Amir H. Poorjam",
      "Debottam Dutta",
      "Debarpan Bhattacharya",
      "Zemin Yu",
      "Sriram Ganapathy",
      "Maneesh Singh"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2206.05462"
  },
  {
    "id": "arXiv:2206.05472",
    "title": "Differentiable Projection from Optical Coherence Tomography B-Scan  without Retinal Layer Segmentation Supervision",
    "abstract": "Projection map (PM) from optical coherence tomography (OCT) B-scan is an\nimportant tool to diagnose retinal diseases, which typically requires retinal\nlayer segmentation. In this study, we present a novel end-to-end framework to\npredict PMs from B-scans. Instead of segmenting retinal layers explicitly, we\nrepresent them implicitly as predicted coordinates. By pixel interpolation on\nuniformly sampled coordinates between retinal layers, the corresponding PMs\ncould be easily obtained with pooling. Notably, all the operators are\ndifferentiable; therefore, this Differentiable Projection Module (DPM) enables\nend-to-end training with the ground truth of PMs rather than retinal layer\nsegmentation. Our framework produces high-quality PMs, significantly\noutperforming baselines, including a vanilla CNN without DPM and an\noptimization-based DPM without a deep prior. Furthermore, the proposed DPM, as\na novel neural representation of areas/volumes between curves/surfaces, could\nbe of independent interest for geometric deep learning.",
    "descriptor": "\nComments: ISBI2022\n",
    "authors": [
      "Dingyi Rong",
      "Jiancheng Yang",
      "Bingbing Ni",
      "Bilian Ke"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.05472"
  },
  {
    "id": "arXiv:2206.05487",
    "title": "Scientific Inference With Interpretable Machine Learning: Analyzing  Models to Learn About Real-World Phenomena",
    "abstract": "Interpretable machine learning (IML) is concerned with the behavior and the\nproperties of machine learning models. Scientists, however, are only interested\nin the model as a gateway to understanding the modeled phenomenon. We show how\nto develop IML methods such that they allow insight into relevant phenomenon\nproperties. We argue that current IML research conflates two goals of\nmodel-analysis -- model audit and scientific inference. Thereby, it remains\nunclear if model interpretations have corresponding phenomenon interpretation.\nBuilding on statistical decision theory, we show that ML model analysis allows\nto describe relevant aspects of the joint data probability distribution. We\nprovide a five-step framework for constructing IML descriptors that can help in\naddressing scientific questions, including a natural way to quantify epistemic\nuncertainty. Our phenomenon-centric approach to IML in science clarifies: the\nopportunities and limitations of IML for inference; that conditional not\nmarginal sampling is required; and, the conditions under which we can trust IML\nmethods.",
    "descriptor": "",
    "authors": [
      "Timo Freiesleben",
      "Gunnar K\u00f6nig",
      "Christoph Molnar",
      "Alvaro Tejero-Cantero"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05487"
  },
  {
    "id": "arXiv:2206.05516",
    "title": "Deep Learning-Based MR Image Re-parameterization",
    "abstract": "Magnetic resonance (MR) image re-parameterization refers to the process of\ngenerating via simulations of an MR image with a new set of MRI scanning\nparameters. Different parameter values generate distinct contrast between\ndifferent tissues, helping identify pathologic tissue. Typically, more than one\nscan is required for diagnosis; however, acquiring repeated scans can be\ncostly, time-consuming, and difficult for patients. Thus, using MR image\nre-parameterization to predict and estimate the contrast in these imaging scans\ncan be an effective alternative. In this work, we propose a novel deep learning\n(DL) based convolutional model for MRI re-parameterization. Based on our\npreliminary results, DL-based techniques hold the potential to learn the\nnon-linearities that govern the re-parameterization.",
    "descriptor": "\nComments: to be published in The 8th International Conference on Biomedical Engineering & Sciences, Luxor (MGM), Las Vegas, USA, 25-28 July 2022\n",
    "authors": [
      "Abhijeet Narang",
      "Abhigyan Raj",
      "Mihaela Pop",
      "Mehran Ebrahimi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.05516"
  },
  {
    "id": "arXiv:2206.05575",
    "title": "MammoDL: Mammographic Breast Density Estimation using Federated Learning",
    "abstract": "Assessing breast cancer risk from imaging remains a subjective process, in\nwhich radiologists employ computer aided detection (CAD) systems or qualitative\nvisual assessment to estimate breast percent density (PD). More advanced\nmachine learning (ML) models have become the most promising way to quantify\nbreast cancer risk for early, accurate, and equitable diagnoses, but training\nsuch models in medical research is often restricted to small,\nsingle-institution data. Since patient demographics and imaging characteristics\nmay vary considerably across imaging sites, models trained on\nsingle-institution data tend not to generalize well. In response to this\nproblem, MammoDL is proposed, an open-source software tool that leverages UNet\narchitecture to accurately estimate breast PD and complexity from digital\nmammography (DM). With the Open Federated Learning (OpenFL) library, this\nsolution enables secure training on datasets across multiple institutions.\nMammoDL is a leaner, more flexible model than its predecessors, boasting\nimproved generalization due to federation-enabled training on larger, more\nrepresentative datasets.",
    "descriptor": "\nComments: Breast Cancer Risk, Digital Mammography, Breast Density, Deep Learning, Machine Learning, Federated Learning, OpenFL\n",
    "authors": [
      "Keshava Katti",
      "Ramya Muthukrishnan",
      "Angelina Heyler",
      "Sarthak Pati",
      "Aprupa Alahari",
      "Michael Sanborn",
      "Emily F. Conant",
      "Christopher Scott",
      "Stacey Winham",
      "Celine Vachon",
      "Pratik Chaudhari",
      "Despina Kontos",
      "Spyridon Bakas"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05575"
  },
  {
    "id": "arXiv:2206.05576",
    "title": "Optimal Solutions for Joint Beamforming and Antenna Selection: From  Branch and Bound to Machine Learning",
    "abstract": "This work revisits the joint beamforming (BF) and antenna selection (AS)\nproblem, as well as its robust beamforming (RBF) version under imperfect\nchannel state information (CSI). Such problems arise in scenarios where the\nnumber of the radio frequency (RF) chains is smaller than that of the antenna\nelements at the transmitter, which has become a critical consideration in the\nera of large-scale arrays. The joint (R)BF\\&AS problem is a mixed integer and\nnonlinear program, and thus finding {\\it optimal solutions} is often costly, if\nnot outright impossible. The vast majority of the prior works tackled these\nproblems using continuous optimization-based approximations -- yet these\napproximations do not ensure optimality or even feasibility of the solutions.\nThe main contribution of this work is threefold. First, an effective {\\it\nbranch and bound} (B\\&B) framework for solving the problems of interest is\nproposed. Leveraging existing BF and RBF solvers, it is shown that the B\\&B\nframework guarantees global optimality of the considered problems. Second, to\nexpedite the potentially costly B\\&B algorithm, a machine learning (ML)-based\nscheme is proposed to help skip intermediate states of the B\\&B search tree.\nThe learning model features a {\\it graph neural network} (GNN)-based design\nthat is resilient to a commonly encountered challenge in wireless\ncommunications, namely, the change of problem size (e.g., the number of users)\nacross the training and test stages. Third, comprehensive performance\ncharacterizations are presented, showing that the GNN-based method retains the\nglobal optimality of B\\&B with provably reduced complexity, under reasonable\nconditions. Numerical simulations also show that the ML-based acceleration can\noften achieve an order-of-magnitude speedup relative to B\\&B.",
    "descriptor": "",
    "authors": [
      "Sagar Shrestha",
      "Xiao Fu",
      "Mingyi Hong"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05576"
  },
  {
    "id": "arXiv:2206.05581",
    "title": "Federated Offline Reinforcement Learning",
    "abstract": "Evidence-based or data-driven dynamic treatment regimes are essential for\npersonalized medicine, which can benefit from offline reinforcement learning\n(RL). Although massive healthcare data are available across medical\ninstitutions, they are prohibited from sharing due to privacy constraints.\nBesides, heterogeneity exists in different sites. As a result, federated\noffline RL algorithms are necessary and promising to deal with the problems. In\nthis paper, we propose a multi-site Markov decision process model which allows\nboth homogeneous and heterogeneous effects across sites. The proposed model\nmakes the analysis of the site-level features possible. We design the first\nfederated policy optimization algorithm for offline RL with sample complexity.\nThe proposed algorithm is communication-efficient and privacy-preserving, which\nrequires only a single round of communication interaction by exchanging summary\nstatistics. We give a theoretical guarantee for the proposed algorithm without\nthe assumption of sufficient action coverage, where the suboptimality for the\nlearned policies is comparable to the rate as if data is not distributed.\nExtensive simulations demonstrate the effectiveness of the proposed algorithm.\nThe method is applied to a sepsis data set in multiple sites to illustrate its\nuse in clinical settings.",
    "descriptor": "",
    "authors": [
      "Doudou Zhou",
      "Yufeng Zhang",
      "Aaron Sonabend-W",
      "Zhaoran Wang",
      "Junwei Lu",
      "Tianxi Cai"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2206.05581"
  },
  {
    "id": "arXiv:2206.05604",
    "title": "A Theoretical Understanding of Neural Network Compression from Sparse  Linear Approximation",
    "abstract": "The goal of model compression is to reduce the size of a large neural network\nwhile retaining a comparable performance. As a result, computation and memory\ncosts in resource-limited applications may be significantly reduced by dropping\nredundant weights, neurons, or layers. There have been many model compression\nalgorithms proposed that provide impressive empirical success. However, a\ntheoretical understanding of model compression is still limited. One problem is\nunderstanding if a network is more compressible than another of the same\nstructure. Another problem is quantifying how much one can prune a network with\ntheoretically guaranteed accuracy degradation. In this work, we propose to use\nthe sparsity-sensitive $\\ell_q$-norm ($0<q<1$) to characterize compressibility\nand provide a relationship between soft sparsity of the weights in the network\nand the degree of compression with a controlled accuracy degradation bound. We\nalso develop adaptive algorithms for pruning each neuron in the network\ninformed by our theory. Numerical studies demonstrate the promising performance\nof the proposed methods compared with standard pruning algorithms.",
    "descriptor": "",
    "authors": [
      "Wenjing Yang",
      "Ganghua Wang",
      "Enmao Diao",
      "Vahid Tarokh",
      "Jie Ding",
      "Yuhong Yang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2206.05604"
  },
  {
    "id": "arXiv:2206.05606",
    "title": "Signal-informed DNN-based DOA Estimation combining an External  Microphone and GCC-PHAT Features",
    "abstract": "Aiming at estimating the direction of arrival (DOA) of a desired speaker in a\nmulti-talker environment using a microphone array, in this paper we propose a\nsignal-informed method exploiting the availability of an external microphone\nattached to the desired speaker. The proposed method applies a binary mask to\nthe GCC-PHAT input features of a convolutional neural network, where the binary\nmask is computed based on the power distribution of the external microphone\nsignal. Experimental results for a reverberant scenario with up to four\ninterfering speakers demonstrate that the signal-informed masking improves the\nlocalization accuracy, without requiring any knowledge about the interfering\nspeakers.",
    "descriptor": "",
    "authors": [
      "Ulrik Kowalk",
      "Simon Doclo",
      "Joerg Bitzer"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2206.05606"
  },
  {
    "id": "arXiv:2206.05614",
    "title": "Information theory of spatial network ensembles",
    "abstract": "This chapter provides a comprehensive and self-contained discussion of the\nmost recent developments of information theory of networks. Maximum entropy\nmodels of networks are the least biased ensembles enforcing a set of\nconstraints and are used in a number of application to produce null model of\nnetworks. Here maximum entropy ensembles of networks are introduced by\ndistinguishing between microcanonical and canonical ensembles revealing the the\nnon-equivalence of these two classes of ensembles in the case in which an\nextensive number of constraints is imposed. It is very common that network data\nincludes also meta-data describing feature of the nodes such as their position\nin a real or in an abstract space. The features of the nodes can be treated as\nlatent variables that determine the cost associated to each link. Maximum\nentropy network ensembles with latent variables include spatial networks and\ntheir generalisation. In this chapter we cover the case of transportation\nnetworks including airport and rail networks. Maximum entropy network ensemble\nsatisfy a given set of constraints. However traditional approaches do not\nprovide any insight on the origin of such constraints. We use information\ntheory principles to find the optimal distribution of latent variables in the\nframework of the classical information theory of networks. This theory explains\nthe \"blessing of non-uniformity\" of data guaranteeing the efficiency of\ninference algorithms.",
    "descriptor": "\nComments: 51 pages, 9 figures\n",
    "authors": [
      "Ginestra Bianconi"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.05614"
  },
  {
    "id": "arXiv:2206.05615",
    "title": "Machine learning approaches for COVID-19 detection from chest X-ray  imaging: A Systematic Review",
    "abstract": "There is a necessity to develop affordable, and reliable diagnostic tools,\nwhich allow containing the COVID-19 spreading. Machine Learning (ML) algorithms\nhave been proposed to design support decision-making systems to assess chest\nX-ray images, which have proven to be useful to detect and evaluate disease\nprogression. Many research articles are published around this subject, which\nmakes it difficult to identify the best approaches for future work. This paper\npresents a systematic review of ML applied to COVID-19 detection using chest\nX-ray images, aiming to offer a baseline for researchers in terms of methods,\narchitectures, databases, and current limitations.",
    "descriptor": "",
    "authors": [
      "Harold Brayan Arteaga-Arteaga",
      "Melissa delaPava",
      "Alejandro Mora-Rubio",
      "Mario Alejandro Bravo-Ort\u00edz",
      "Jesus Alejandro Alzate-Grisales",
      "Daniel Arias-Garz\u00f3n",
      "Luis Humberto L\u00f3pez-Murillo",
      "Felipe Buitrago-Carmona",
      "Juan Pablo Villa-Pulgar\u00edn",
      "Esteban Mercado-Ruiz",
      "Simon Orozco-Arias",
      "M. Hassaballah",
      "Maria de la Iglesia-Vaya",
      "Oscar Cardona-Morales",
      "Reinel Tabares-Soto"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05615"
  },
  {
    "id": "arXiv:2206.05618",
    "title": "Synthetic PET via Domain Translation of 3D MRI",
    "abstract": "Historically, patient datasets have been used to develop and validate various\nreconstruction algorithms for PET/MRI and PET/CT. To enable such algorithm\ndevelopment, without the need for acquiring hundreds of patient exams, in this\npaper we demonstrate a deep learning technique to generate synthetic but\nrealistic whole-body PET sinograms from abundantly-available whole-body MRI.\nSpecifically, we use a dataset of 56 $^{18}$F-FDG-PET/MRI exams to train a 3D\nresidual UNet to predict physiologic PET uptake from whole-body T1-weighted\nMRI. In training we implemented a balanced loss function to generate realistic\nuptake across a large dynamic range and computed losses along tomographic lines\nof response to mimic the PET acquisition. The predicted PET images are forward\nprojected to produce synthetic PET time-of-flight (ToF) sinograms that can be\nused with vendor-provided PET reconstruction algorithms, including using\nCT-based attenuation correction (CTAC) and MR-based attenuation correction\n(MRAC). The resulting synthetic data recapitulates physiologic $^{18}$F-FDG\nuptake, e.g. high uptake localized to the brain and bladder, as well as uptake\nin liver, kidneys, heart and muscle. To simulate abnormalities with high\nuptake, we also insert synthetic lesions. We demonstrate that this synthetic\nPET data can be used interchangeably with real PET data for the PET\nquantification task of comparing CT and MR-based attenuation correction\nmethods, achieving $\\leq 7.6\\%$ error in mean-SUV compared to using real data.\nThese results together show that the proposed synthetic PET data pipeline can\nbe reasonably used for development, evaluation, and validation of PET/MRI\nreconstruction methods.",
    "descriptor": "\nComments: under review\n",
    "authors": [
      "Abhejit Rajagopal",
      "Yutaka Natsuaki",
      "Kristen Wangerin",
      "Mahdjoub Hamdi",
      "Hongyu An",
      "John J. Sunderland",
      "Richard Laforest",
      "Paul E. Kinahan",
      "Peder E.Z. Larson",
      "Thomas A.Hope"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.05618"
  },
  {
    "id": "arXiv:2206.05642",
    "title": "Average-case hardness of estimating probabilities of random quantum  circuits with a linear scaling in the error exponent",
    "abstract": "We consider the hardness of computing additive approximations to output\nprobabilities of random quantum circuits. We consider three random circuit\nfamilies, namely, Haar random, $p=1$ QAOA, and random IQP circuits. Our results\nare as follows. For Haar random circuits with $m$ gates, we improve on prior\nresults by showing $\\mathsf{coC_=P}$ hardness of average-case additive\napproximations to an imprecision of $2^{-O(m)}$. Efficient classical simulation\nof such problems would imply the collapse of the polynomial hierarchy. For\nconstant depth circuits i.e., when $m=O(n)$, this linear scaling in the\nexponent is within a constant of the scaling required to show hardness of\nsampling. Prior to our work, such a result was shown only for Boson Sampling in\nBouland et al (2021). We also use recent results in polynomial interpolation to\nshow $\\mathsf{coC_=P}$ hardness under $\\mathsf{BPP}$ reductions rather than\n$\\mathsf{BPP}^{\\mathsf{NP}}$ reductions. This improves the results of prior\nwork for Haar random circuits both in terms of the error scaling and the power\nof reductions. Next, we consider random $p=1$ QAOA and IQP circuits and show\nthat in the average-case, it is $\\mathsf{coC_=P}$ hard to approximate the\noutput probability to within an additive error of $2^{-O(n)}$. For $p=1$ QAOA\ncircuits, this work constitutes the first average-case hardness result for the\nproblem of approximating output probabilities for random QAOA circuits, which\ninclude Sherrington-Kirkpatrick and Erd\\\"{o}s-Renyi graphs. For IQP circuits, a\nconsequence of our results is that approximating the Ising partition function\nwith imaginary couplings to an additive error of $2^{-O(n)}$ is hard even in\nthe average-case, which extends prior work on worst-case hardness of\nmultiplicative approximation to Ising partition functions.",
    "descriptor": "\nComments: 26 pages\n",
    "authors": [
      "Hari Krovi"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2206.05642"
  },
  {
    "id": "arXiv:2206.05644",
    "title": "Monte Carlo with Soft Constraints: the Surface Augmented Sampler",
    "abstract": "We describe an MCMC method for sampling distributions with soft constraints,\nwhich are constraints that are almost but not exactly satisfied. We sample a\ntotal distribution that is a convex combination of the target soft distribution\nwith the nearby hard distribution supported on the constraint surface. Hard\ndistribution moves lead to performance that is uniform in the softness\nparameter. On and Off moves related to the Holmes-Cerfon Stratification Sampler\nenable sampling the target soft distribution. Computational experiments verify\nthat performance is uniform in the soft constraints limit.",
    "descriptor": "",
    "authors": [
      "Ildebrando Magnani"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2206.05644"
  },
  {
    "id": "arXiv:2206.05647",
    "title": "A Fast Alternating Minimization Algorithm for Coded Aperture Snapshot  Spectral Imaging Based on Sparsity and Deep Image Priors",
    "abstract": "Coded aperture snapshot spectral imaging (CASSI) is a technique used to\nreconstruct three-dimensional hyperspectral images (HSIs) from one or several\ntwo-dimensional projection measurements. However, fewer projection measurements\nor more spectral channels leads to a severly ill-posed problem, in which case\nregularization methods have to be applied. In order to significantly improve\nthe accuracy of reconstruction, this paper proposes a fast alternating\nminimization algorithm based on the sparsity and deep image priors (Fama-SDIP)\nof natural images. By integrating deep image prior (DIP) into the principle of\ncompressive sensing (CS) reconstruction, the proposed algorithm can achieve\nstate-of-the-art results without any training dataset. Extensive experiments\nshow that Fama-SDIP method significantly outperforms prevailing leading methods\non simulation and real HSI datasets.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Qile Zhao",
      "Xianhong Zhao",
      "Xu Ma",
      "Xudong Chen",
      "Gonzalo R. Arce"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2206.05647"
  },
  {
    "id": "arXiv:2206.05650",
    "title": "Preprocessing Enhanced Image Compression for Machine Vision",
    "abstract": "Recently, more and more images are compressed and sent to the back-end\ndevices for the machine analysis tasks~(\\textit{e.g.,} object detection)\ninstead of being purely watched by humans. However, most traditional or learned\nimage codecs are designed to minimize the distortion of the human visual system\nwithout considering the increased demand from machine vision systems. In this\nwork, we propose a preprocessing enhanced image compression method for machine\nvision tasks to address this challenge. Instead of relying on the learned image\ncodecs for end-to-end optimization, our framework is built upon the traditional\nnon-differential codecs, which means it is standard compatible and can be\neasily deployed in practical applications. Specifically, we propose a neural\npreprocessing module before the encoder to maintain the useful semantic\ninformation for the downstream tasks and suppress the irrelevant information\nfor bitrate saving. Furthermore, our neural preprocessing module is\nquantization adaptive and can be used in different compression ratios. More\nimportantly, to jointly optimize the preprocessing module with the downstream\nmachine vision tasks, we introduce the proxy network for the traditional\nnon-differential codecs in the back-propagation stage. We provide extensive\nexperiments by evaluating our compression method for two representative\ndownstream tasks with different backbone networks. Experimental results show\nour method achieves a better trade-off between the coding bitrate and the\nperformance of the downstream machine vision tasks by saving about 20% bitrate.",
    "descriptor": "",
    "authors": [
      "Guo Lu",
      "Xingtong Ge",
      "Tianxiong Zhong",
      "Jing Geng",
      "Qiang Hu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.05650"
  },
  {
    "id": "arXiv:2206.05655",
    "title": "Variational Bayes Deep Operator Network: A data-driven Bayesian solver  for parametric differential equations",
    "abstract": "Neural network based data-driven operator learning schemes have shown\ntremendous potential in computational mechanics. DeepONet is one such neural\nnetwork architecture which has gained widespread appreciation owing to its\nexcellent prediction capabilities. Having said that, being set in a\ndeterministic framework exposes DeepONet architecture to the risk of\noverfitting, poor generalization and in its unaltered form, it is incapable of\nquantifying the uncertainties associated with its predictions. We propose in\nthis paper, a Variational Bayes DeepONet (VB-DeepONet) for operator learning,\nwhich can alleviate these limitations of DeepONet architecture to a great\nextent and give user additional information regarding the associated\nuncertainty at the prediction stage. The key idea behind neural networks set in\nBayesian framework is that, the weights and bias of the neural network are\ntreated as probability distributions instead of point estimates and, Bayesian\ninference is used to update their prior distribution. Now, to manage the\ncomputational cost associated with approximating the posterior distribution,\nthe proposed VB-DeepONet uses \\textit{variational inference}. Unlike Markov\nChain Monte Carlo schemes, variational inference has the capacity to take into\naccount high dimensional posterior distributions while keeping the associated\ncomputational cost low. Different examples covering mechanics problems like\ndiffusion reaction, gravity pendulum, advection diffusion have been shown to\nillustrate the performance of the proposed VB-DeepONet and comparisons have\nalso been drawn against DeepONet set in deterministic framework.",
    "descriptor": "",
    "authors": [
      "Shailesh Garg",
      "Souvik Chakraborty"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05655"
  },
  {
    "id": "arXiv:2206.05695",
    "title": "PD-DWI: Predicting response to neoadjuvant chemotherapy in invasive  breast cancer with Physiologically-Decomposed Diffusion-Weighted MRI  machine-learning model",
    "abstract": "Early prediction of pathological complete response (pCR) following\nneoadjuvant chemotherapy (NAC) for breast cancer plays a critical role in\nsurgical planning and optimizing treatment strategies. Recently, machine and\ndeep-learning based methods were suggested for early pCR prediction from\nmulti-parametric MRI (mp-MRI) data including dynamic contrast-enhanced MRI and\ndiffusion-weighted MRI (DWI) with moderate success. We introduce PD-DWI, a\nphysiologically decomposed DWI machine-learning model to predict pCR from DWI\nand clinical data. Our model first decomposes the raw DWI data into the various\nphysiological cues that are influencing the DWI signal and then uses the\ndecomposed data, in addition to clinical variables, as the input features of a\nradiomics-based XGBoost model. We demonstrated the added-value of our PD-DWI\nmodel over conventional machine-learning approaches for pCR prediction from\nmp-MRI data using the publicly available Breast Multi-parametric MRI for\nprediction of NAC Response (BMMR2) challenge. Our model substantially improves\nthe area under the curve (AUC), compared to the current best result on the\nleaderboard (0.8849 vs. 0.8397) for the challenge test set. PD-DWI has the\npotential to improve prediction of pCR following NAC for breast cancer, reduce\noverall mp-MRI acquisition times and eliminate the need for contrast-agent\ninjection.",
    "descriptor": "\nComments: Accepted to Medical Image Computing and Computer Assisted Intervention - MICCAI 2022 to be held during Sept 18-22 in Singapore\n",
    "authors": [
      "Maya Gilad",
      "Moti Freiman"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.05695"
  },
  {
    "id": "arXiv:2206.05720",
    "title": "Machine learning based surrogate modeling with SVD enabled training for  nonlinear civil structures subject to dynamic loading",
    "abstract": "The computationally expensive estimation of engineering demand parameters\n(EDPs) via finite element (FE) models, while considering earthquake and\nparameter uncertainty limits the use of the Performance Based Earthquake\nEngineering framework. Attempts have been made to substitute FE models with\nsurrogate models, however, most of these models are a function of building\nparameters only. This necessitates re-training for earthquakes not previously\nseen by the surrogate. In this paper, the authors propose a machine learning\nbased surrogate model framework, which considers both these uncertainties in\norder to predict for unseen earthquakes. Accordingly,earthquakes are\ncharacterized by their projections on an orthonormal basis, computed using SVD\nof a representative ground motion suite. This enables one to generate large\nvarieties of earthquakes by randomly sampling these weights and multiplying\nthem with the basis. The weights along with the constitutive parameters serve\nas inputs to a machine learning model with EDPs as the desired output. Four\ncompeting machine learning models were tested and it was observed that a deep\nneural network (DNN) gave the most accurate prediction. The framework is\nvalidated by using it to successfully predict the peak response of one-story\nand three-story buildings represented using stick models, subjected to unseen\nfar-field ground motions.",
    "descriptor": "",
    "authors": [
      "Siddharth S. Parida",
      "Supratik Bose",
      "Megan Butcher",
      "Georgios Apostolakis",
      "Prashant Shekhar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05720"
  },
  {
    "id": "arXiv:2206.05782",
    "title": "Revisiting Whole-Slide Image Pyramids for Cancer Prognosis via  Dual-Stream Networks",
    "abstract": "The cancer prognosis on gigapixel Whole-Slide Images (WSIs) has always been a\nchallenging task. Most existing approaches focus solely on single-resolution\nimages. The multi-resolution schemes, utilizing image pyramids to enhance WSI\nvisual representations, have not yet been paid enough attention to. In order to\nexplore a multi-resolution solution for improving cancer prognosis accuracy,\nthis paper proposes a dual-stream architecture to model WSIs by an image\npyramid strategy. This architecture consists of two sub-streams: one is for\nlow-resolution WSIs, and the other is especially for high-resolution ones.\nCompared to other approaches, our scheme has three highlights: (i) there exists\na one-to-one relation between stream and resolution; (ii) a square pooling\nlayer is added to align the patches from two resolution streams, largely\nreducing computation cost and enabling a natural stream feature fusion; (iii) a\ncross-attention-based method is proposed to pool high-resolution patches\nspatially under the guidance of low-resolution ones. We validate our scheme on\nthree publicly-available datasets, a total number of 3,101 WSIs from 1,911\npatients. Experimental results verify that (1) hierarchical dual-stream\nrepresentation is more effective than single-stream ones for cancer prognosis,\ngaining an average C-Index rise of 5.0% and 1.8% on a single low-resolution and\nhigh-resolution stream, respectively; (2) our dual-stream scheme could\noutperform current state-of-the-art ones, by a 5.1% average improvement of\nC-Index; (3) the cancer diseases with observable survival differences could\nhave different preferences for model complexity. Our scheme could serve as an\nalternative tool for further facilitating WSI prognosis research.",
    "descriptor": "\nComments: Submitted to the IEEE, 10 pages, 5 figures, 4 tables\n",
    "authors": [
      "Pei Liu",
      "Bo Fu",
      "Feng Ye",
      "Rui Yang",
      "Bin Xu",
      "Luping Ji"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05782"
  },
  {
    "id": "arXiv:2206.05824",
    "title": "Science through Machine Learning: Quantification of Poststorm  Thermospheric Cooling",
    "abstract": "Machine learning (ML) is often viewed as a black-box regression technique\nthat is unable to provide considerable scientific insight. ML models are\nuniversal function approximators and - if used correctly - can provide\nscientific information related to the ground-truth dataset used for fitting. A\nbenefit to ML over parametric models is that there are no predefined basis\nfunctions limiting the phenomena that can be modeled. In this work, we develop\nML models on three datasets: the Space Environment Technologies (SET) High\nAccuracy Satellite Drag Model (HASDM) density database, a spatiotemporally\nmatched dataset of outputs from the Jacchia-Bowman 2008 Empirical Thermospheric\nDensity Model (JB2008), and an accelerometer-derived density dataset from\nCHAllenging Minisatellite Payload (CHAMP). These ML models are compared to the\nNaval Research Laboratory Mass Spectrometer and Incoherent Scatter radar\n(NRLMSIS 2.0) model to study the presence of post-storm cooling in the\nmiddle-thermosphere. We find that both NRLMSIS 2.0 and JB2008-ML do not account\nfor post-storm cooling and consequently perform poorly in periods following\nstrong geomagnetic storms (e.g. the 2003 Halloween storms). Conversely,\nHASDM-ML and CHAMP-ML do show evidence of post-storm cooling indicating that\nthis phenomenon is present in the original datasets. Results show that density\nreductions up to 40% can occur 1--3 days post-storm depending on location and\nthe strength of the storm.",
    "descriptor": "",
    "authors": [
      "Richard J. Licata",
      "Piyush M. Mehta",
      "Daniel R. Weimer",
      "Douglas P. Drob",
      "W. Kent Tobiska",
      "Jean Yoshii"
    ],
    "subjectives": [
      "Space Physics (physics.space-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05824"
  },
  {
    "id": "arXiv:2206.05828",
    "title": "Bounding and Approximating Intersectional Fairness through Marginal  Fairness",
    "abstract": "Discrimination in machine learning often arises along multiple dimensions\n(a.k.a. protected attributes); it is then desirable to ensure\n\\emph{intersectional fairness} -- i.e., that no subgroup is discriminated\nagainst. It is known that ensuring \\emph{marginal fairness} for every dimension\nindependently is not sufficient in general. Due to the exponential number of\nsubgroups, however, directly measuring intersectional fairness from data is\nimpossible.\nIn this paper, our primary goal is to understand in detail the relationship\nbetween marginal and intersectional fairness through statistical analysis. We\nfirst identify a set of sufficient conditions under which an exact relationship\ncan be obtained. Then, we prove bounds (easily computable through marginal\nfairness and other meaningful statistical quantities) in high-probability on\nintersectional fairness in the general case. Beyond their descriptive value, we\nshow that these theoretical bounds can be leveraged to derive a heuristic\nimproving the approximation and bounds of intersectional fairness by choosing,\nin a relevant manner, protected attributes for which we describe intersectional\nsubgroups. Finally, we test the performance of our approximations and bounds on\nreal and synthetic data-sets.",
    "descriptor": "\nComments: 42 pages, 7 figures\n",
    "authors": [
      "Mathieu Molina",
      "Patrick Loiseau"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05828"
  },
  {
    "id": "arXiv:2206.05829",
    "title": "A non-graphical representation of conditional independence via the  neighbourhood lattice",
    "abstract": "We introduce and study the neighbourhood lattice decomposition of a\ndistribution, which is a compact, non-graphical representation of conditional\nindependence that is valid in the absence of a faithful graphical\nrepresentation. The idea is to view the set of neighbourhoods of a variable as\na subset lattice, and partition this lattice into convex sublattices, each of\nwhich directly encodes a collection of conditional independence relations. We\nshow that this decomposition exists in any compositional graphoid and can be\ncomputed efficiently and consistently in high-dimensions. {In particular, this\ngives a way to encode all of independence relations implied by a distribution\nthat satisfies the composition axiom, which is strictly weaker than the\nfaithfulness assumption that is typically assumed by graphical approaches.} We\nalso discuss various special cases such as graphical models and projection\nlattices, each of which has intuitive interpretations. Along the way, we see\nhow this problem is closely related to neighbourhood regression, which has been\nextensively studied in the context of graphical models and structural\nequations.",
    "descriptor": "\nComments: 30 pages, 3 figures\n",
    "authors": [
      "Arash A. Amini",
      "Bryon Aragam",
      "Qing Zhou"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.05829"
  },
  {
    "id": "arXiv:2206.05835",
    "title": "Deep Reinforcement Learning for Optimal Investment and Saving Strategy  Selection in Heterogeneous Profiles: Intelligent Agents working towards  retirement",
    "abstract": "The transition from defined benefit to defined contribution pension plans\nshifts the responsibility for saving toward retirement from governments and\ninstitutions to the individuals. Determining optimal saving and investment\nstrategy for individuals is paramount for stable financial stance and for\navoiding poverty during work-life and retirement, and it is a particularly\nchallenging task in a world where form of employment and income trajectory\nexperienced by different occupation groups are highly diversified. We introduce\na model in which agents learn optimal portfolio allocation and saving\nstrategies that are suitable for their heterogeneous profiles. We use deep\nreinforcement learning to train agents. The environment is calibrated with\noccupation and age dependent income evolution dynamics. The research focuses on\nheterogeneous income trajectories dependent on agent profiles and incorporates\nthe behavioural parameterisation of agents. The model provides a flexible\nmethodology to estimate lifetime consumption and investment choices for\nheterogeneous profiles under varying scenarios.",
    "descriptor": "",
    "authors": [
      "Fatih Ozhamaratli",
      "Paolo Barucca"
    ],
    "subjectives": [
      "Portfolio Management (q-fin.PM)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "General Economics (econ.GN)"
    ],
    "url": "https://arxiv.org/abs/2206.05835"
  },
  {
    "id": "arXiv:2206.05858",
    "title": "Curvilinearity and Orthogonality",
    "abstract": "We introduce sequences of functions orthogonal on a finite interval: proper\northogonal rational functions, orthogonal exponential functions, and orthogonal\nlogarithmic functions.",
    "descriptor": "\nComments: 6 pages, 3 figures\n",
    "authors": [
      "Vladimir S. Chelyshkov"
    ],
    "subjectives": [
      "Classical Analysis and ODEs (math.CA)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.05858"
  },
  {
    "id": "arXiv:2206.05907",
    "title": "Computational Models based on Synchronized Oscillators for Solving  Combinatorial Optimization Problems",
    "abstract": "The equivalence between the natural minimization of energy in a dynamical\nsystem and the minimization of an objective function characterizing a\ncombinatorial optimization problem offers a promising approach to designing\ndynamical system-inspired computational models and solvers for such problems.\nFor instance, the ground state energy of coupled electronic oscillators, under\nsecond harmonic injection, can be directly mapped to the optimal solution of\nthe Maximum Cut problem. However, prior work has focused on a limited set of\nsuch problems. Therefore, in this work, we formulate computing models based on\nsynchronized oscillator dynamics for a broad spectrum of combinatorial\noptimization problems ranging from the Max-K-Cut (the general version of the\nMaximum Cut problem) to the Traveling Salesman Problem. We show that\nsynchronized oscillator dynamics can be engineered to solve these different\ncombinatorial optimization problems by appropriately designing the coupling\nfunction and the external injection to the oscillators. Our work marks a step\nforward towards expanding the functionalities of oscillator-based analog\naccelerators and furthers the scope of dynamical system solvers for\ncombinatorial optimization problems.",
    "descriptor": "\nComments: 38 pages, 10 figures\n",
    "authors": [
      "Antik Mallick",
      "Mohammad Khairul Bashar",
      "Zongli Lin",
      "Nikhil Shukla"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2206.05907"
  },
  {
    "id": "arXiv:2206.05910",
    "title": "Safe-FinRL: A Low Bias and Variance Deep Reinforcement Learning  Implementation for High-Freq Stock Trading",
    "abstract": "In recent years, many practitioners in quantitative finance have attempted to\nuse Deep Reinforcement Learning (DRL) to build better quantitative trading (QT)\nstrategies. Nevertheless, many existing studies fail to address several serious\nchallenges, such as the non-stationary financial environment and the bias and\nvariance trade-off when applying DRL in the real financial market. In this\nwork, we proposed Safe-FinRL, a novel DRL-based high-freq stock trading\nstrategy enhanced by the near-stationary financial environment and low bias and\nvariance estimation. Our main contributions are twofold: firstly, we separate\nthe long financial time series into the near-stationary short environment;\nsecondly, we implement Trace-SAC in the near-stationary financial environment\nby incorporating the general retrace operator into the Soft Actor-Critic.\nExtensive experiments on the cryptocurrency market have demonstrated that\nSafe-FinRL has provided a stable value estimation and a steady policy\nimprovement and reduced bias and variance significantly in the near-stationary\nfinancial environment.",
    "descriptor": "",
    "authors": [
      "Zitao Song",
      "Xuyang Jin",
      "Chenliang Li"
    ],
    "subjectives": [
      "Portfolio Management (q-fin.PM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05910"
  },
  {
    "id": "arXiv:2206.05935",
    "title": "Fluorescence angiography classification in colorectal surgery -- A  preliminary report",
    "abstract": "Background: Fluorescence angiography has shown very promising results in\nreducing anastomotic leaks by allowing the surgeon to select optimally perfused\ntissue. However, subjective interpretation of the fluorescent signal still\nhinders broad application of the technique, as significant variation between\ndifferent surgeons exists. Our aim is to develop an artificial intelligence\nalgorithm to classify colonic tissue as 'perfused' or 'not perfused' based on\nintraoperative fluorescence angiography data.\nMethods: A classification model with a Resnet architecture was trained on a\ndataset of fluorescence angiography videos of colorectal resections at a\ntertiary referral centre. Frames corresponding to fluorescent and\nnon-fluorescent segments of colon were used to train a classification\nalgorithm. Validation using frames from patients not used in the training set\nwas performed, including both data collected using the same equipment and data\ncollected using a different camera. Performance metrics were calculated, and\nsaliency maps used to further analyse the output. A decision boundary was\nidentified based on the tissue classification.\nResults: A convolutional neural network was successfully trained on 1790\nframes from 7 patients and validated in 24 frames from 14 patients. The\naccuracy on the training set was 100%, on the validation set was 80%. Recall\nand precision were respectively 100% and 100% on the training set and 68.8% and\n91.7% on the validation set.\nConclusion: Automated classification of intraoperative fluorescence\nangiography with a high degree of accuracy is possible and allows automated\ndecision boundary identification. This will enable surgeons to standardise the\ntechnique of fluorescence angiography. A web based app was made available to\ndeploy the algorithm.",
    "descriptor": "",
    "authors": [
      "Antonio S Soares",
      "Sophia Bano",
      "Neil T Clancy",
      "Laurence B Lovat",
      "Danail Stoyanov",
      "Manish Chand"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.05935"
  },
  {
    "id": "arXiv:2206.05974",
    "title": "Deep Neural Network Based Accelerated Failure Time Models using Rank  Loss",
    "abstract": "An accelerated failure time (AFT) model assumes a log-linear relationship\nbetween failure times and a set of covariates. In contrast to other popular\nsurvival models that work on hazard functions, the effects of covariates are\ndirectly on failure times, whose interpretation is intuitive. The\nsemiparametric AFT model that does not specify the error distribution is\nflexible and robust to departures from the distributional assumption. Owing to\nthe desirable features, this class of models has been considered as a promising\nalternative to the popular Cox model in the analysis of censored failure time\ndata. However, in these AFT models, a linear predictor for the mean is\ntypically assumed. Little research has addressed the nonlinearity of predictors\nwhen modeling the mean. Deep neural networks (DNNs) have received a focal\nattention over the past decades and have achieved remarkable success in a\nvariety of fields. DNNs have a number of notable advantages and have been shown\nto be particularly useful in addressing the nonlinearity. By taking advantage\nof this, we propose to apply DNNs in fitting AFT models using a Gehan-type\nloss, combined with a sub-sampling technique. Finite sample properties of the\nproposed DNN and rank based AFT model (DeepR-AFT) are investigated via an\nextensive stimulation study. DeepR-AFT shows a superior performance over its\nparametric or semiparametric counterparts when the predictor is nonlinear. For\nlinear predictors, DeepR-AFT performs better when the dimensions of covariates\nare large. The proposed DeepR-AFT is illustrated using two real datasets, which\ndemonstrates its superiority.",
    "descriptor": "",
    "authors": [
      "Gwangsu Kim",
      "Sangwook Kang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05974"
  },
  {
    "id": "arXiv:2206.05976",
    "title": "Value Function Based Difference-of-Convex Algorithm for Bilevel  Hyperparameter Selection Problems",
    "abstract": "Gradient-based optimization methods for hyperparameter tuning guarantee\ntheoretical convergence to stationary solutions when for fixed upper-level\nvariable values, the lower level of the bilevel program is strongly convex\n(LLSC) and smooth (LLS). This condition is not satisfied for bilevel programs\narising from tuning hyperparameters in many machine learning algorithms. In\nthis work, we develop a sequentially convergent Value Function based\nDifference-of-Convex Algorithm with inexactness (VF-iDCA). We show that this\nalgorithm achieves stationary solutions without LLSC and LLS assumptions for\nbilevel programs from a broad class of hyperparameter tuning applications. Our\nextensive experiments confirm our theoretical findings and show that the\nproposed VF-iDCA yields superior performance when applied to tune\nhyperparameters.",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Lucy Gao",
      "Jane J. Ye",
      "Haian Yin",
      "Shangzhi Zeng",
      "Jin Zhang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05976"
  },
  {
    "id": "arXiv:2206.05979",
    "title": "Top Two Algorithms Revisited",
    "abstract": "Top Two algorithms arose as an adaptation of Thompson sampling to best arm\nidentification in multi-armed bandit models (Russo, 2016), for parametric\nfamilies of arms. They select the next arm to sample from by randomizing among\ntwo candidate arms, a leader and a challenger. Despite their good empirical\nperformance, theoretical guarantees for fixed-confidence best arm\nidentification have only been obtained when the arms are Gaussian with known\nvariances. In this paper, we provide a general analysis of Top Two methods,\nwhich identifies desirable properties of the leader, the challenger, and the\n(possibly non-parametric) distributions of the arms. As a result, we obtain\ntheoretically supported Top Two algorithms for best arm identification with\nbounded distributions. Our proof method demonstrates in particular that the\nsampling step used to select the leader inherited from Thompson sampling can be\nreplaced by other choices, like selecting the empirical best arm.",
    "descriptor": "\nComments: 75 pages, 8 figures, 3 tables\n",
    "authors": [
      "Marc Jourdan",
      "R\u00e9my Degenne",
      "Dorian Baudry",
      "Rianne de Heide",
      "Emilie Kaufmann"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05979"
  },
  {
    "id": "arXiv:2206.05984",
    "title": "Channel Sounder with Over-the-Air Antenna Synchronization: Absolute  Phase and Timing Calibration Using Known Transmitter Locations",
    "abstract": "Synchronization of transceiver chains is a major challenge in the practical\nrealization of massive MIMO and especially distributed massive MIMO. While\nfrequency synchronization is comparatively easy to achieve, estimating the\ncarrier phase and sampling time offsets of individual transceivers is\nchallenging. However, under the assumption of phase and time offsets that are\nconstant over some duration and knowing the positions of several transmit and\nreceive antennas, it is possible to estimate and compensate for these offsets\neven in scattering environments with multipath propagation components. The\nresulting phase and time calibration is a prerequisite for applying classical\nantenna array processing methods to massive MIMO arrays and for transferring\nmachine learning models either between simulation and deployment or from one\nradio environment to another. Algorithms for phase and time offset estimation\nare presented and several investigations on large datasets generated by an\nover-the-air-synchronized channel sounder are carried out.",
    "descriptor": "",
    "authors": [
      "Florian Euchner",
      "Phillip Stephan",
      "Marc Gauger",
      "Stephan ten Brink"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.05984"
  },
  {
    "id": "arXiv:2206.05998",
    "title": "GPU-Accelerated Machine Learning in Non-Orthogonal Multiple Access",
    "abstract": "Non-orthogonal multiple access (NOMA) is an interesting technology that\nenables massive connectivity as required in future 5G and 6G networks. While\npurely linear processing already achieves good performance in NOMA systems, in\ncertain scenarios, non-linear processing is mandatory to ensure acceptable\nperformance. In this paper, we propose a neural network architecture that\ncombines the advantages of both linear and non-linear processing. Its real-time\ndetection performance is demonstrated by a highly efficient implementation on a\ngraphics processing unit (GPU). Using real measurements in a laboratory\nenvironment, we show the superiority of our approach over conventional methods.",
    "descriptor": "\nComments: 5 pages, 5 figures, Submitted to EUSIPCO 2022\n",
    "authors": [
      "Daniel Sch\u00e4ufele",
      "Guillermo Marcus",
      "Nikolaus Binder",
      "Matthias Mehlhose",
      "Alexander Keller",
      "S\u0142awomir Sta\u0144czak"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05998"
  },
  {
    "id": "arXiv:2206.06004",
    "title": "A Novel Multi-Layer Modular Approach for Real-Time Gravitational-Wave  Detection",
    "abstract": "Advanced LIGO and Advanced Virgo ground-based interferometers are poised to\nprobe an unprecedentedly large volume of space, enhancing the discovery power\nof the observations to even new sources of gravitational wave emitters. In this\nscenario, the development of highly optimized gravitational wave detection\nalgorithms is crucial. We propose a novel layered framework for real-time\ndetection of gravitational waves inspired by speech processing techniques and,\nin the present implementation, based on a state-of-the-art machine learning\napproach involving a hybridization of genetic programming and neural networks.\nThe key aspects of the newly proposed framework are: the well structured,\nlayered approach, and the low computational complexity. The paper describes the\nbasic concepts of the framework and the derivation of the first three layers.\nEven if, in the present implementation, the layers are based on models derived\nusing a machine learning approach, the proposed layered structure has a\nuniversal nature. To train and test the models, we used simulated binary black\nhole gravitational wave waveforms in synthetic Gaussian noise representative of\nAdvanced LIGO sensitivity design. Compared to more complex approaches, such as\nconvolutional neural networks, our framework, even using the simple ground\nmodel described in the paper, has similar performance but with a much lower\ncomputational complexity and a higher degree of modularity. Furthermore, the\nunderlying exploitation of short-term features makes the results of the new\nframework virtually independent against time-position of gravitational wave\nsignals, simplifying its future exploitation in real-time multi-layer pipelines\nfor gravitational-wave detection with second generation interferometers.",
    "descriptor": "",
    "authors": [
      "Francesco Pio Barone",
      "Daniele Dell'Aquila",
      "Marco Russo"
    ],
    "subjectives": [
      "General Relativity and Quantum Cosmology (gr-qc)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.06004"
  },
  {
    "id": "arXiv:2206.06048",
    "title": "Temporal and Spatial Elements in Interactive Epidemiological Maps",
    "abstract": "Maps have played an important role in epidemiology and public health since\nthe beginnings of these disciplines. With the advent of geographical\ninformation systems and advanced information visualization techniques,\ninteractive maps have become essential tools for the analysis of geographical\npatterns of disease incidence and prevalence, as well as communication of\npublic health knowledge, as dramatically illustrated by the proliferation of\nweb-based maps and disease surveillance ``dashboards'' during the COVID-19\npandemic. While such interactive maps are usually effective in supporting\nstatic spatial analysis, support for spatial epidemiological visualization and\nmodelling involving distributed and dynamic data sources, and support for\nanalysis of temporal aspects of disease spread have proved more challenging.\nCombining these two aspects can be crucial in applications of interactive maps\nin epidemiology and public health work. In this paper, we discuss these issues\nin the context of support for disease surveillance in remote regions, including\ntools for distributed data collection, simulation and analysis, and enabling\nmultidisciplinary collaboration.",
    "descriptor": "\nComments: Presented at the Map-based Interfaces and Interactions (MAPII) Workshop, at AVI'22\n",
    "authors": [
      "Saturnino Luz",
      "Masood Masoodian"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Human-Computer Interaction (cs.HC)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2206.06048"
  },
  {
    "id": "arXiv:2206.06058",
    "title": "Energy-Efficient Wake-Up Signalling for Machine-Type Devices Based on  Traffic-Aware Long-Short Term Memory Prediction",
    "abstract": "Reducing energy consumption is a pressing issue in low-power machine-type\ncommunication (MTC) networks. In this regard, the Wake-up Signal (WuS)\ntechnology, which aims to minimize the energy consumed by the radio interface\nof the machine-type devices (MTDs), stands as a promising solution. However,\nstate-of-the-art WuS mechanisms use static operational parameters, so they\ncannot efficiently adapt to the system dynamics. To overcome this, we design a\nsimple but efficient neural network to predict MTC traffic patterns and\nconfigure WuS accordingly. Our proposed forecasting WuS (FWuS) leverages an\naccurate long-short term memory (LSTM)- based traffic prediction that allows\nextending the sleep time of MTDs by avoiding frequent page monitoring occasions\nin idle state. Simulation results show the effectiveness of our approach. The\ntraffic prediction errors are shown to be below 4%, being false alarm and\nmiss-detection probabilities respectively below 8.8% and 1.3%. In terms of\nenergy consumption reduction, FWuS can outperform the best benchmark mechanism\nin up to 32%. Finally, we certify the ability of FWuS to dynamically adapt to\ntraffic density changes, promoting low-power MTC scalability",
    "descriptor": "",
    "authors": [
      "David E. Ru\u00edz-Guirola",
      "Carlos A. Rodr\u00edguez-L\u00f3pez",
      "Samuel Montejo-S\u00e1nchez",
      "Richard Demo Souza",
      "Onel L. A. L\u00f3pez",
      "Hirley Alves"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06058"
  },
  {
    "id": "arXiv:2206.06065",
    "title": "Deep ensemble learning for segmenting tuberculosis-consistent  manifestations in chest radiographs",
    "abstract": "Automated segmentation of tuberculosis (TB)-consistent lesions in chest\nX-rays (CXRs) using deep learning (DL) methods can help reduce radiologist\neffort, supplement clinical decision-making, and potentially result in improved\npatient treatment. The majority of works in the literature discuss training\nautomatic segmentation models using coarse bounding box annotations. However,\nthe granularity of the bounding box annotation could result in the inclusion of\na considerable fraction of false positives and negatives at the pixel level\nthat may adversely impact overall semantic segmentation performance. This study\n(i) evaluates the benefits of using fine-grained annotations of TB-consistent\nlesions and (ii) trains and constructs ensembles of the variants of U-Net\nmodels for semantically segmenting TB-consistent lesions in both original and\nbone-suppressed frontal CXRs. We evaluated segmentation performance using\nseveral ensemble methods such as bitwise AND, bitwise-OR, bitwise-MAX, and\nstacking. We observed that the stacking ensemble demonstrated superior\nsegmentation performance (Dice score: 0.5743, 95% confidence interval:\n(0.4055,0.7431)) compared to the individual constituent models and other\nensemble methods. To the best of our knowledge, this is the first study to\napply ensemble learning to improve fine-grained TB-consistent lesion\nsegmentation performance.",
    "descriptor": "\nComments: 13 pages, 6 figures\n",
    "authors": [
      "Sivaramakrishnan Rajaraman",
      "Feng Yang",
      "Ghada Zamzmi",
      "Peng Guo",
      "Zhiyun Xue",
      "Sameer K Antani"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06065"
  },
  {
    "id": "arXiv:2206.06070",
    "title": "Annular Computational Imaging: Capture Clear Panoramic Images through  Simple Lens",
    "abstract": "Panoramic Annular Lens (PAL), composed of few lenses, has great potential in\npanoramic surrounding sensing tasks for mobile and wearable devices because of\nits tiny size and large Field of View (FoV). However, the image quality of\ntiny-volume PAL confines to optical limit due to the lack of lenses for\naberration correction. In this paper, we propose an Annular Computational\nImaging (ACI) framework to break the optical limit of light-weight PAL design.\nTo facilitate learning-based image restoration, we introduce a wave-based\nsimulation pipeline for panoramic imaging and tackle the synthetic-to-real gap\nthrough multiple data distributions. The proposed pipeline can be easily\nadapted to any PAL with design parameters and is suitable for loose-tolerance\ndesigns. Furthermore, we design the Physics Informed Image Restoration Network\n(PI2RNet), considering the physical priors of panoramic imaging and\nphysics-informed learning. At the dataset level, we create the DIVPano dataset\nand the extensive experiments on it illustrate that our proposed network sets\nthe new state of the art in the panoramic image restoration under\nspatially-variant degradation. In addition, the evaluation of the proposed ACI\non a simple PAL with only 3 spherical lenses reveals the delicate balance\nbetween high-quality panoramic imaging and compact design. To the best of our\nknowledge, we are the first to explore Computational Imaging (CI) in PAL. Code\nand datasets will be made publicly available at\nhttps://github.com/zju-jiangqi/ACI-PI2RNet.",
    "descriptor": "\nComments: Code and datasets will be made publicly available at this https URL\n",
    "authors": [
      "Qi Jiang",
      "Hao Shi",
      "Lei Sun",
      "Shaohua Gao",
      "Kailun Yang",
      "Kaiwei Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2206.06070"
  },
  {
    "id": "arXiv:2206.06086",
    "title": "A Correlation-Ratio Transfer Learning and Variational Stein's Paradox",
    "abstract": "A basic condition for efficient transfer learning is the similarity between a\ntarget model and source models. In practice, however, the similarity condition\nis difficult to meet or is even violated. Instead of the similarity condition,\na brand-new strategy, linear correlation-ratio, is introduced in this paper to\nbuild an accurate relationship between the models. Such a correlation-ratio can\nbe easily estimated by historical data or a part of sample. Then, a\ncorrelation-ratio transfer learning likelihood is established based on the\ncorrelation-ratio combination. On the practical side, the new framework is\napplied to some application scenarios, especially the areas of data streams and\nmedical studies. Methodologically, some techniques are suggested for\ntransferring the information from simple source models to a relatively complex\ntarget model. Theoretically, some favorable properties, including the global\nconvergence rate, are achieved, even for the case where the source models are\nnot similar to the target model. All in all, it can be seen from the theories\nand experimental results that the inference on the target model is\nsignificantly improved by the information from similar or dissimilar source\nmodels. In other words, a variational Stein's paradox is illustrated in the\ncontext of transfer learning.",
    "descriptor": "",
    "authors": [
      "Lu Lin",
      "Weiyu Li"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2206.06086"
  },
  {
    "id": "arXiv:2206.06090",
    "title": "Regret-Aware Black-Box Optimization with Natural Gradients,  Trust-Regions and Entropy Control",
    "abstract": "Most successful stochastic black-box optimizers, such as CMA-ES, use rankings\nof the individual samples to obtain a new search distribution. Yet, the use of\nrankings also introduces several issues such as the underlying optimization\nobjective is often unclear, i.e., we do not optimize the expected fitness.\nFurther, while these algorithms typically produce a high-quality mean estimate\nof the search distribution, the produced samples can have poor quality as these\nalgorithms are ignorant of the regret. Lastly, noisy fitness function\nevaluations may result in solutions that are highly sub-optimal on expectation.\nIn contrast, stochastic optimizers that are motivated by policy gradients, such\nas the Model-based Relative Entropy Stochastic Search (MORE) algorithm,\ndirectly optimize the expected fitness function without the use of rankings.\nMORE can be derived by applying natural policy gradients and compatible\nfunction approximation, and is using information theoretic constraints to\nensure the stability of the policy update. While MORE does not suffer from the\nlisted limitations, it often cannot achieve state of the art performance in\ncomparison to ranking based methods. We improve MORE by decoupling the update\nof the mean and covariance of the search distribution allowing for more\naggressive updates on the mean while keeping the update on the covariance\nconservative, an improved entropy scheduling technique based on an evolution\npath which results in faster convergence and a simplified and more effective\nmodel learning approach in comparison to the original paper. We compare our\nalgorithm to state of the art black-box optimization algorithms on standard\noptimization tasks as well as on episodic RL tasks in robotics where it is also\ncrucial to have small regret. We obtain competitive results on benchmark\nfunctions and clearly outperform ranking-based methods in terms of regret on\nthe RL tasks.",
    "descriptor": "\nComments: 26 pages, 15 figures\n",
    "authors": [
      "Maximilian H\u00fcttenrauch",
      "Gerhard Neumann"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.06090"
  },
  {
    "id": "arXiv:2206.06096",
    "title": "An Enactivist-Inspired Mathematical Model of Cognition",
    "abstract": "We formulate five basic tenets of enactivist cognitive science that we have\ncarefully identified in the relevant literature as the main underlying\nprinciples of that philosophy. We then develop a mathematical framework to talk\nabout cognitive systems (both artificial and natural) which complies with these\nenactivist tenets. In particular we pay attention that our mathematical\nmodeling does not attribute contentful symbolic representations to the agents,\nand that the agent's brain, body and environment are modeled in a way that\nmakes them an inseparable part of a greater totality. The purpose is to create\na mathematical foundation for cognition which is in line with enactivism. We\nsee two main benefits of doing so: (1) It enables enactivist ideas to be more\naccessible for computer scientists, AI researchers, roboticists, cognitive\nscientists, and psychologists, and (2) it gives the philosophers a mathematical\ntool which can be used to clarify their notions and help with their debates.\nOur main notion is that of a sensorimotor system which is a special case of a\nwell studied notion of a transition system. We also consider related notions\nsuch as labeled transition systems and deterministic automata. We analyze a\nnotion called sufficiency and show that it is a very good candidate for a\nfoundational notion in the \"mathematics of cognition from an enactivist\nperspective\". We demonstrate its importance by proving a uniqueness theorem\nabout the minimal sufficient refinements (which correspond in some sense to an\noptimal attunement of an organism to its environment) and by showing that\nsufficiency corresponds to known notions such as sufficient history information\nspaces. We then develop other related notions such as degree of insufficiency,\nuniversal covers, hierarchies, strategic sufficiency. In the end, we tie it all\nback to the enactivist tenets.",
    "descriptor": "",
    "authors": [
      "Vadim Weinstein",
      "Basak Sakcak",
      "Steven M. LaValle"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.06096"
  },
  {
    "id": "arXiv:2206.06109",
    "title": "Markov Decision Processes under Model Uncertainty",
    "abstract": "We introduce a general framework for Markov decision problems under model\nuncertainty in a discrete-time infinite horizon setting. By providing a dynamic\nprogramming principle we obtain a local-to-global paradigm, namely solving a\nlocal, i.e., a one time-step robust optimization problem leads to an optimizer\nof the global (i.e. infinite time-steps) robust stochastic optimal control\nproblem, as well as to a corresponding worst-case measure. Moreover, we apply\nthis framework to portfolio optimization involving data of the S&P 500. We\npresent two different types of ambiguity sets; one is fully data-driven given\nby a Wasserstein-ball around the empirical measure, the second one is described\nby a parametric set of multivariate normal distributions, where the\ncorresponding uncertainty sets of the parameters are estimated from the data.\nIt turns out that in scenarios where the market is volatile or bearish, the\noptimal portfolio strategies from the corresponding robust optimization problem\noutperforms the ones without model uncertainty, showcasing the importance of\ntaking model uncertainty into account.",
    "descriptor": "",
    "authors": [
      "Ariel Neufeld",
      "Julian Sester",
      "Mario \u0160iki\u0107"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Mathematical Finance (q-fin.MF)",
      "Portfolio Management (q-fin.PM)"
    ],
    "url": "https://arxiv.org/abs/2206.06109"
  },
  {
    "id": "arXiv:2206.06127",
    "title": "SyntheX: Scaling Up Learning-based X-ray Image Analysis Through In  Silico Experiments",
    "abstract": "Artificial intelligence (AI) now enables automated interpretation of medical\nimages for clinical use. However, AI's potential use for interventional images\n(versus those involved in triage or diagnosis), such as for guidance during\nsurgery, remains largely untapped. This is because surgical AI systems are\ncurrently trained using post hoc analysis of data collected during live\nsurgeries, which has fundamental and practical limitations, including ethical\nconsiderations, expense, scalability, data integrity, and a lack of ground\ntruth. Here, we demonstrate that creating realistic simulated images from human\nmodels is a viable alternative and complement to large-scale in situ data\ncollection. We show that training AI image analysis models on realistically\nsynthesized data, combined with contemporary domain generalization or\nadaptation techniques, results in models that on real data perform comparably\nto models trained on a precisely matched real data training set. Because\nsynthetic generation of training data from human-based models scales easily, we\nfind that our model transfer paradigm for X-ray image analysis, which we refer\nto as SyntheX, can even outperform real data-trained models due to the\neffectiveness of training on a larger dataset. We demonstrate the potential of\nSyntheX on three clinical tasks: Hip image analysis, surgical robotic tool\ndetection, and COVID-19 lung lesion segmentation. SyntheX provides an\nopportunity to drastically accelerate the conception, design, and evaluation of\nintelligent systems for X-ray-based medicine. In addition, simulated image\nenvironments provide the opportunity to test novel instrumentation, design\ncomplementary surgical approaches, and envision novel techniques that improve\noutcomes, save time, or mitigate human error, freed from the ethical and\npractical considerations of live human data collection.",
    "descriptor": "",
    "authors": [
      "Cong Gao",
      "Benjamin D. Killeen",
      "Yicheng Hu",
      "Robert B. Grupp",
      "Russell H. Taylor",
      "Mehran Armand",
      "Mathias Unberath"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06127"
  },
  {
    "id": "arXiv:2206.06131",
    "title": "Seeing the forest and the tree: Building representations of both  individual and collective dynamics with transformers",
    "abstract": "Complex time-varying systems are often studied by abstracting away from the\ndynamics of individual components to build a model of the population-level\ndynamics from the start. However, when building a population-level description,\nit can be easy to lose sight of each individual and how each contributes to the\nlarger picture. In this paper, we present a novel transformer architecture for\nlearning from time-varying data that builds descriptions of both the individual\nas well as the collective population dynamics. Rather than combining all of our\ndata into our model at the onset, we develop a separable architecture that\noperates on individual time-series first before passing them forward; this\ninduces a permutation-invariance property and can be used to transfer across\nsystems of different size and order. After demonstrating that our model can be\napplied to successfully recover complex interactions and dynamics in many-body\nsystems, we apply our approach to populations of neurons in the nervous system.\nOn neural activity datasets, we show that our multi-scale transformer not only\nyields robust decoding performance, but also provides impressive performance in\ntransfer. Our results show that it is possible to learn from neurons in one\nanimal's brain and transfer the model on neurons in a different animal's brain,\nwith interpretable neuron correspondence across sets and animals. This finding\nopens up a new path to decode from and represent large collections of neurons.",
    "descriptor": "",
    "authors": [
      "Ran Liu",
      "Mehdi Azabou",
      "Max Dabagia",
      "Jingyun Xiao",
      "Eva L. Dyer"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06131"
  },
  {
    "id": "arXiv:2206.06145",
    "title": "Identification of cancer-keeping genes as therapeutic targets by finding  network control hubs",
    "abstract": "Finding cancer driver genes has been a focal theme of cancer research and\nclinical studies. One of the recent approaches is based on network structural\ncontrollability that focuses on finding a control scheme and driver genes that\ncan steer the cell from an arbitrary state to a designated state. While\ntheoretically sound, this approach is impractical for many reasons, e.g., the\ncontrol scheme is often not unique and half of the nodes may be driver genes\nfor the cell. We developed a novel approach that transcends structural\ncontrollability. Instead of considering driver genes for one control scheme, we\nconsidered control hub genes that reside in the middle of a control path of\nevery control scheme. Control hubs are the most vulnerable spots for\ncontrolling the cell and exogenous stimuli on them may render the cell\nuncontrollable. We adopted control hubs as cancer-keep genes (CKGs) and applied\nthem to a gene regulatory network of bladder cancer (BLCA). All the genes on\nthe cell cycle and p53 singling pathways in BLCA are CKGs, confirming the\nimportance of these genes and the two pathways in cancer. A smaller set of 35\nsensitive CKGs (sCKGs) for BLCA was identified by removing network links. Six\nsCKGs (RPS6KA3, FGFR3, N-cadherin (CDH2), EP300, caspase-1, and FN1) were\nsubjected to small-interferencing-RNA knockdown in four cell lines to validate\ntheir effects on the proliferation or migration of cancer cells. Knocking down\nRPS6KA3 in a mouse model of BLCA significantly inhibited the growth of tumor\nxenografts in the mouse model. Combined, our results demonstrated the value of\nCKGs as therapeutic targets for cancer therapy and the potential of CKGs as an\neffective means for studying and characterizing cancer etiology.",
    "descriptor": "\nComments: Contact the corresponding authors for supplementary material\n",
    "authors": [
      "Xizhe Zhang",
      "Chunyu Pan",
      "Xinru Wei",
      "Meng Yu",
      "Shuangjie Liu",
      "Jun An",
      "Jieping Yang",
      "Baojun Wei",
      "Wenjun Hao",
      "Yang Yao",
      "Yuyan Zhu",
      "Weixiong Zhang"
    ],
    "subjectives": [
      "Molecular Networks (q-bio.MN)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.06145"
  },
  {
    "id": "arXiv:2206.06156",
    "title": "Advanced Quantitative Techniques to Solve Center of Gravity Problem in  Supply Chain",
    "abstract": "Activities involving transformation of raw materials, various resources and\ncomponents into final products and also delivering it to the end customer incur\na significant cost during the selection of location of a warehouse that can be\neasily accessed by various actors of the supply chain. To minimize upstream and\ndownstream transportation costs, the center of gravity (CoG) analysis method is\nused to find the potential warehouse locations for a given demand network which\nhave an impact on the entire supply chain network. Mixed Integer Linear\nProgramming (MILP), an open source tool is developed for implementing CoG\nmethod along with certain service level constraints to find optimal potential\nlocations with the least cost. In this paper, an optimization tool has been\ndesigned for a forward logistics network with several novel methods like\nCustomer Location Selection (CLS), Customer Packets along with other business\nheuristics that optimize and enhance the existing MILP to get the optimal\nsolutions with low computational cost and runtime. Finally, recommending an\nalternative network of facilities which reduces overall costs compared to the\nexisting network. An user interface has also been developed to make a user\nfriendly interaction with the model. We can conclude that this model can\nsignificantly help companies reduce costs during the logistics network design.",
    "descriptor": "\nComments: 7 pages, 3 figures, 2 tables\n",
    "authors": [
      "Brian Houck",
      "Chetan Sampat",
      "Srijit Maiti",
      "Shivam S",
      "Anurag Vaishistha",
      "Sumit Banerjee"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2206.06156"
  },
  {
    "id": "arXiv:2206.06172",
    "title": "RIS-ADMM: An ADMM-Based Passive and Sparse Sensing Method with  Interference Removal",
    "abstract": "The reconfigurable intelligent surface (RIS) has been a potential technology\nfor future radar and wireless communication applications. In this letter, the\npassive sensing problem using wireless communications signal and RIS is\naddressed in the scenario with the interference from the wireless access point\n(AP). An atomic norm minimization (ANM) method is formulated to exploit the\ntarget sparsity in the spatial domain and estimate the direction of arrival\n(DOA), but the conventional semidefinite programming (SDP)-based method to\nsolve the ANM problem is complex and cannot be realized efficiently. Therefore,\nwe proposed a RIS-ADMM method as an alternating direction method of multipliers\n(ADMM)-based iterative method. The closed-form expressions are derived, and the\ninterference signal is also suppressed. Simulation results show that the\nproposed RIS-ADMM method outperforms the compared methods in the DOA estimation\nperformance with low computational complexity. The code about the proposed\nmethod is avaliable online \\url{https://github.com/chenpengseu/RIS-ADMM.git}.",
    "descriptor": "",
    "authors": [
      "Peng Chen",
      "Zhimin Chen",
      "Pu Miao",
      "Yun Chen"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.06172"
  },
  {
    "id": "arXiv:2206.06179",
    "title": "Convergence of Simulated Annealing Using Kinetic Langevin Dynamics",
    "abstract": "We study the simulated annealing algorithm based on the kinetic Langevin\ndynamics, in order to find the global minimum of a non-convex potential\nfunction. For both the continuous time formulation and a discrete time\nanalogue, we obtain the convergence rate results under technical conditions on\nthe potential function, together with an appropriate choice of the cooling\nschedule and the time discretization parameters.",
    "descriptor": "\nComments: 33 pages\n",
    "authors": [
      "Xuedong He",
      "Xiaolu Tan",
      "Ruocheng Wu"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.06179"
  },
  {
    "id": "arXiv:2206.06192",
    "title": "Toward Zero Oracle Word Error Rate on the Switchboard Benchmark",
    "abstract": "The \"Switchboard benchmark\" is a very well-known test set in automatic speech\nrecognition (ASR) research, establishing record-setting performance for systems\nthat claim human-level transcription accuracy. This work highlights\nlesser-known practical considerations of this evaluation, demonstrating major\nimprovements in word error rate (WER) by correcting the reference\ntranscriptions and deviating from the official scoring methodology. In this\nmore detailed and reproducible scheme, even commercial ASR systems can score\nbelow 5\\% WER and the established record for a research system is lowered to\n2.3%. An alternative metric of transcript precision is proposed, which does not\npenalize deletions and appears to be more discriminating for human vs. machine\nperformance. While commercial ASR systems are still below this threshold, a\nresearch system is shown to clearly surpass the accuracy of commercial human\nspeech recognition. This work also explores using standardized scoring tools to\ncompute oracle WER by selecting the best among a list of alternatives. A phrase\nalternatives representation is compared to utterance-level N-best lists and\nword-level data structures; using dense lattices and adding out-of-vocabulary\nwords, this achieves an oracle WER of 0.18%.",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Arlo Faria",
      "Adam Janin",
      "Korbinian Riedhammer",
      "Sidhi Adkoli"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2206.06192"
  },
  {
    "id": "arXiv:2206.06208",
    "title": "Automated Evaluation of Standardized Dementia Screening Tests",
    "abstract": "For dementia screening and monitoring, standardized tests play a key role in\nclinical routine since they aim at minimizing subjectivity by measuring\nperformance on a variety of cognitive tasks. In this paper, we report on a\nstudy that consists of a semi-standardized history taking followed by two\nstandardized neuropsychological tests, namely the SKT and the CERAD-NB. The\ntests include basic tasks such as naming objects, learning word lists, but also\nwidely used tools such as the MMSE. Most of the tasks are performed verbally\nand should thus be suitable for automated scoring based on transcripts. For the\nfirst batch of 30 patients, we analyze the correlation between expert manual\nevaluations and automatic evaluations based on manual and automatic\ntranscriptions. For both SKT and CERAD-NB, we observe high to perfect\ncorrelations using manual transcripts; for certain tasks with lower\ncorrelation, the automatic scoring is stricter than the human reference since\nit is limited to the audio. Using automatic transcriptions, correlations drop\nas expected and are related to recognition accuracy; however, we still observe\nhigh correlations of up to 0.98 (SKT) and 0.85 (CERAD-NB). We show that using\nword alternatives helps to mitigate recognition errors and subsequently\nimproves correlation with expert scores.",
    "descriptor": "\nComments: Submitted to Interspeech 2022. arXiv admin note: text overlap with arXiv:2206.05018\n",
    "authors": [
      "Franziska Braun",
      "Markus F\u00f6rstel",
      "Bastian Oppermann",
      "Andreas Erzigkeit",
      "Thomas Hillemacher",
      "Hartmut Lehfeld",
      "Korbinian Riedhammer"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2206.06208"
  },
  {
    "id": "arXiv:2206.06234",
    "title": "Evaluating Graph Generative Models with Contrastively Learned Features",
    "abstract": "A wide range of models have been proposed for Graph Generative Models,\nnecessitating effective methods to evaluate their quality. So far, most\ntechniques use either traditional metrics based on subgraph counting, or the\nrepresentations of randomly initialized Graph Neural Networks (GNNs). We\npropose using representations from contrastively trained GNNs, rather than\nrandom GNNs, and show this gives more reliable evaluation metrics. Neither\ntraditional approaches nor GNN-based approaches dominate the other, however: we\ngive examples of graphs that each approach is unable to distinguish. We\ndemonstrate that Graph Substructure Networks (GSNs), which in a way combine\nboth approaches, are better at distinguishing the distances between graph\ndatasets.",
    "descriptor": "\nComments: GitHub repo:this https URL\n",
    "authors": [
      "Hamed Shirzad",
      "Kaveh Hassani",
      "Danica J. Sutherland"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06234"
  },
  {
    "id": "arXiv:2206.06235",
    "title": "Prostate Cancer Malignancy Detection and localization from mpMRI using  auto-Deep Learning: One Step Closer to Clinical Utilization",
    "abstract": "Automatic diagnosis of malignant prostate cancer patients from mpMRI has been\nstudied heavily in the past years. Model interpretation and domain drift have\nbeen the main road blocks for clinical utilization. As an extension from our\nprevious work where we trained a customized convolutional neural network on a\npublic cohort with 201 patients and the cropped 2D patches around the region of\ninterest were used as the input, the cropped 2.5D slices of the prostate glands\nwere used as the input, and the optimal model were searched in the model space\nusing autoKeras. Something different was peripheral zone (PZ) and central gland\n(CG) were trained and tested separately, the PZ detector and CG detector were\ndemonstrated effectively in highlighting the most suspicious slices out of a\nsequence, hopefully to greatly ease the workload for the physicians.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1903.12331\n",
    "authors": [
      "Weiwei Zong",
      "Eric Carver",
      "Simeng Zhu",
      "Eric Schaff",
      "Daniel Chapman",
      "Joon Lee",
      "Hassan Bagher Ebadian",
      "Indrin Chetty",
      "Benjamin Movsas",
      "Winston Wen",
      "Tarik Alafif",
      "Xiangyun Zong"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06235"
  },
  {
    "id": "arXiv:2206.06253",
    "title": "RPLHR-CT Dataset and Transformer Baseline for Volumetric  Super-Resolution from CT Scans",
    "abstract": "In clinical practice, anisotropic volumetric medical images with low\nthrough-plane resolution are commonly used due to short acquisition time and\nlower storage cost. Nevertheless, the coarse resolution may lead to\ndifficulties in medical diagnosis by either physicians or computer-aided\ndiagnosis algorithms. Deep learning-based volumetric super-resolution (SR)\nmethods are feasible ways to improve resolution, with convolutional neural\nnetworks (CNN) at their core. Despite recent progress, these methods are\nlimited by inherent properties of convolution operators, which ignore content\nrelevance and cannot effectively model long-range dependencies. In addition,\nmost of the existing methods use pseudo-paired volumes for training and\nevaluation, where pseudo low-resolution (LR) volumes are generated by a simple\ndegradation of their high-resolution (HR) counterparts. However, the domain gap\nbetween pseudo- and real-LR volumes leads to the poor performance of these\nmethods in practice. In this paper, we build the first public real-paired\ndataset RPLHR-CT as a benchmark for volumetric SR, and provide baseline results\nby re-implementing four state-of-the-art CNN-based methods. Considering the\ninherent shortcoming of CNN, we also propose a transformer volumetric\nsuper-resolution network (TVSRN) based on attention mechanisms, dispensing with\nconvolutions entirely. This is the first research to use a pure transformer for\nCT volumetric SR. The experimental results show that TVSRN significantly\noutperforms all baselines on both PSNR and SSIM. Moreover, the TVSRN method\nachieves a better trade-off between the image quality, the number of\nparameters, and the running time. Data and code are available at\nhttps://github.com/smilenaxx/RPLHR-CT.",
    "descriptor": "\nComments: Accepted MICCAI 2022\n",
    "authors": [
      "Pengxin Yu",
      "Haoyue Zhang",
      "Han Kang",
      "Wen Tang",
      "Corey W. Arnold",
      "Rongguo Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06253"
  },
  {
    "id": "arXiv:2206.06264",
    "title": "Automatic Polyp Segmentation with Multiple Kernel Dilated Convolution  Network",
    "abstract": "The detection and removal of precancerous polyps through colonoscopy is the\nprimary technique for the prevention of colorectal cancer worldwide. However,\nthe miss rate of colorectal polyp varies significantly among the endoscopists.\nIt is well known that a computer-aided diagnosis (CAD) system can assist\nendoscopists in detecting colon polyps and minimize the variation among\nendoscopists. In this study, we introduce a novel deep learning architecture,\nnamed {\\textbf{MKDCNet}}, for automatic polyp segmentation robust to\nsignificant changes in polyp data distribution. MKDCNet is simply an\nencoder-decoder neural network that uses the pre-trained \\textit{ResNet50} as\nthe encoder and novel \\textit{multiple kernel dilated convolution (MKDC)} block\nthat expands the field of view to learn more robust and heterogeneous\nrepresentation. Extensive experiments on four publicly available polyp datasets\nand cell nuclei dataset show that the proposed MKDCNet outperforms the\nstate-of-the-art methods when trained and tested on the same dataset as well\nwhen tested on unseen polyp datasets from different distributions. With rich\nresults, we demonstrated the robustness of the proposed architecture. From an\nefficiency perspective, our algorithm can process at ($\\approx45$) frames per\nsecond on RTX 3090 GPU. MKDCNet can be a strong benchmark for building\nreal-time systems for clinical colonoscopies. The code of the proposed MKDCNet\nis available at \\url{https://github.com/nikhilroxtomar/MKDCNet}.",
    "descriptor": "",
    "authors": [
      "Nikhil Kumar Tomar",
      "Abhishek Srivastava",
      "Ulas Bagci",
      "Debesh Jha"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06264"
  },
  {
    "id": "arXiv:2206.06266",
    "title": "Enhancement of Rural Connectivity by Recycling TV Towers with Massive  MIMO Techniques",
    "abstract": "Nowadays, the digital divide is one of the major issues facing the global\ncommunity. Around 3 billion people worldwide are still not-connected or\nunder-connected. In this article, we investigate the use of TV towers with\nmulti user (MU) massive multiple input multiple output (mMIMO) techniques to\noffer connectivity in rural areas. Specifically, the coverage range is assessed\nfor a MU mMIMO base station (BS) mounted on a high tower as a TV tower, and\ncompared with a legacy mMIMO BS. The obtained results show that one high tower\nBS can cover an area at least 25 times larger than the area covered by a legacy\nBS. This is of high interest as recycling TV towers can enhance the rural\nconnectivity with low expenditures. We apply the proposed solution to a\nrealistic case study in an Ethiopian rural area, based on population densities\nand locations of current BS and TV towers. Our study shows that a high number\nof people can be covered by existing TV towers. Additional possible solutions\nto enhance rural connectivity are discussed in the last section.",
    "descriptor": "",
    "authors": [
      "Ammar El Falou",
      "Mohamed-Slim Alouini"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.06266"
  },
  {
    "id": "arXiv:2206.06267",
    "title": "MMMNA-Net for Overall Survival Time Prediction of Brain Tumor Patients",
    "abstract": "Overall survival (OS) time is one of the most important evaluation indices\nfor gliomas situations. Multimodal Magnetic Resonance Imaging (MRI) scans play\nan important role in the study of glioma prognosis OS time. Several deep\nlearning-based methods are proposed for the OS time prediction on multi-modal\nMRI problems. However, these methods usually fuse multi-modal information at\nthe beginning or at the end of the deep learning networks and lack the fusion\nof features from different scales. In addition, the fusion at the end of\nnetworks always adapts global with global (eg. fully connected after\nconcatenation of global average pooling output) or local with local (eg.\nbilinear pooling), which loses the information of local with global. In this\npaper, we propose a novel method for multi-modal OS time prediction of brain\ntumor patients, which contains an improved nonlocal features fusion module\nintroduced on different scales. Our method obtains a relative 8.76% improvement\nover the current state-of-art method (0.6989 vs. 0.6426 on accuracy). Extensive\ntesting demonstrates that our method could adapt to situations with missing\nmodalities. The code is available at\nhttps://github.com/TangWen920812/mmmna-net.",
    "descriptor": "\nComments: Accepted EMBC 2022\n",
    "authors": [
      "Wen Tang",
      "Haoyue Zhang",
      "Pengxin Yu",
      "Han Kang",
      "Rongguo Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06267"
  },
  {
    "id": "arXiv:2206.06281",
    "title": "Cumulative culture spontaneously emerges in artificial navigators who  are social and memory-guided",
    "abstract": "While previously thought to be uniquely human, cumulative cultural evolution\ncontinues to be found in non-human animals. It occurs when an adaptive\ninnovation from an individual is repeatedly passed onto consecutive generations\nthrough social learning. For example, pigeons who fly alone or in stable pairs\nshow relatively rigid sub-optimal routes, but gradually improve route\nefficiency over generations of pairs in which experienced members are swapped\nfor naive ones. This raises the question of what the minimally required\ncognitive architecture is for cumulative cultural evolution to emerge. Here, I\naimed to answer this question in artificial agents who employ three main\nfunctions: goal-direction, social proximity, and route memory. At the optima\nfor efficiency and generational efficiency improvement, agents replicated\ncumulative culture observed in pigeons. At each optimum, paths were determined\nprimarily by memory, and to a lesser extent by social proximity and\ngoal-direction. Because of their need for social proximity, each naive agent\nstayed close to their experienced counterpart as that followed its memorised\npath. However, unhindered by route memory, the naive agent's heading was more\nlikely to err towards the goal. This subtly biased pairs' routes, and the\nresulting efficiency improvement is thus regression to the goal. The resulting\nincremental improvements over generations meet all core criteria in current\nframeworks of cumulative cultural evolution, suggesting that rudimentary\ncumulative optimisation is an evolutionary mechanism that emerges even in\nsimple systems that prefer social proximity and have a memory capacity.",
    "descriptor": "",
    "authors": [
      "Edwin S. Dalmaijer"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.06281"
  },
  {
    "id": "arXiv:2206.06290",
    "title": "Constrained Quantum Optimization for Extractive Summarization on a  Trapped-ion Quantum Computer",
    "abstract": "Realizing the potential of near-term quantum computers to solve\nindustry-relevant constrained-optimization problems is a promising path to\nquantum advantage. In this work, we consider the extractive summarization\nconstrained-optimization problem and demonstrate the largest-to-date execution\nof a quantum optimization algorithm that natively preserves constraints on\nquantum hardware. We report results with the Quantum Alternating Operator\nAnsatz algorithm with a Hamming-weight-preserving XY mixer (XY-QAOA) on the\nQuantinuum H1-1 trapped-ion quantum computer. We successfully execute XY-QAOA\ncircuits that restrict the quantum evolution to the in-constraint subspace,\nusing up to 765 two-qubit gates with a two-qubit gate depth of up to 159, and\nall 20 qubits of the H1-1 device. We demonstrate the necessity of directly\nencoding the constraints into the quantum circuit by showing the trade-off\nbetween the in-constraint probability and the quality of the solution that is\nimplicit if unconstrained quantum optimization methods are used. We show that\nthis trade-off makes choosing good parameters difficult in general. We compare\nXY-QAOA to the Layer Variational Quantum Eigensolver algorithm, which has a\nhighly expressive constant-depth circuit, and the Quantum Approximate\nOptimization Algorithm. Our experimental results demonstrate that the rapid\nhardware and algorithmic progress is enabling the solution of\nconstrained-optimization problems on quantum hardware.",
    "descriptor": "\nComments: 16 pages, 7 figure, 1 table\n",
    "authors": [
      "Pradeep Niroula",
      "Ruslan Shaydulin",
      "Romina Yalovetzky",
      "Pierre Minssen",
      "Dylan Herman",
      "Shaohan Hu",
      "Marco Pistoia"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2206.06290"
  },
  {
    "id": "arXiv:2206.06341",
    "title": "Unsupervised inter-frame motion correction for whole-body dynamic PET  using convolutional long short-term memory in a convolutional neural network",
    "abstract": "Subject motion in whole-body dynamic PET introduces inter-frame mismatch and\nseriously impacts parametric imaging. Traditional non-rigid registration\nmethods are generally computationally intense and time-consuming. Deep learning\napproaches are promising in achieving high accuracy with fast speed, but have\nyet been investigated with consideration for tracer distribution changes or in\nthe whole-body scope. In this work, we developed an unsupervised automatic deep\nlearning-based framework to correct inter-frame body motion. The motion\nestimation network is a convolutional neural network with a combined\nconvolutional long short-term memory layer, fully utilizing dynamic temporal\nfeatures and spatial information. Our dataset contains 27 subjects each under a\n90-min FDG whole-body dynamic PET scan. With 9-fold cross-validation, compared\nwith both traditional and deep learning baselines, we demonstrated that the\nproposed network obtained superior performance in enhanced qualitative and\nquantitative spatial alignment between parametric $K_{i}$ and $V_{b}$ images\nand in significantly reduced parametric fitting error. We also showed the\npotential of the proposed motion correction method for impacting downstream\nanalysis of the estimated parametric images, improving the ability to\ndistinguish malignant from benign hypermetabolic regions of interest. Once\ntrained, the motion estimation inference time of our proposed network was\naround 460 times faster than the conventional registration baseline, showing\nits potential to be easily applied in clinical settings.",
    "descriptor": "\nComments: Preprint submitted to Medical Image Analysis\n",
    "authors": [
      "Xueqi Guo",
      "Bo Zhou",
      "David Pigg",
      "Bruce Spottiswoode",
      "Michael E. Casey",
      "Chi Liu",
      "Nicha C. Dvornek"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2206.06341"
  },
  {
    "id": "arXiv:1506.02424",
    "title": "Algorithms for determining transposons in gene sequences",
    "abstract": "Algorithms for determining transposons in gene sequences",
    "descriptor": "",
    "authors": [
      "Yue Wang"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/1506.02424"
  },
  {
    "id": "arXiv:1703.10146",
    "title": "Community Detection and Stochastic Block Models",
    "abstract": "Community Detection and Stochastic Block Models",
    "descriptor": "",
    "authors": [
      "Emmanuel Abbe"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Computational Complexity (cs.CC)",
      "Information Theory (cs.IT)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1703.10146"
  },
  {
    "id": "arXiv:1706.05060",
    "title": "Undecidability of first-order modal and intuitionistic logics with two  variables and one monadic predicate letter",
    "abstract": "Comments: Corrected version of the paper published in Studia Logica, 107(2), 695-717 (2019). doi:10.1007/s11225-018-9815-7.},doi:10.1007/s11225-018-9815-7",
    "descriptor": "\nComments: Corrected version of the paper published in Studia Logica, 107(2), 695-717 (2019). doi:10.1007/s11225-018-9815-7.},doi:10.1007/s11225-018-9815-7\n",
    "authors": [
      "Mikhail Rybakov",
      "Dmitry Shkatov"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/1706.05060"
  },
  {
    "id": "arXiv:1712.03682",
    "title": "Learning to detect an oddball target with observations from an  exponential family",
    "abstract": "Learning to detect an oddball target with observations from an  exponential family",
    "descriptor": "",
    "authors": [
      "Gayathri R Prabhu",
      "Srikrishna Bhashyam",
      "Aditya Gopalan",
      "Rajesh Sundaresan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/1712.03682"
  },
  {
    "id": "arXiv:1802.09377",
    "title": "A Finite-Model-Theoretic View on Propositional Proof Complexity",
    "abstract": "A Finite-Model-Theoretic View on Propositional Proof Complexity",
    "descriptor": "",
    "authors": [
      "Erich Gr\u00e4del",
      "Martin Grohe",
      "Benedikt Pago",
      "Wied Pakusa"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/1802.09377"
  },
  {
    "id": "arXiv:1906.04109",
    "title": "Quantification and Analysis of Layer-wise and Pixel-wise Information  Discarding",
    "abstract": "Quantification and Analysis of Layer-wise and Pixel-wise Information  Discarding",
    "descriptor": "",
    "authors": [
      "Haotian Ma",
      "Hao Zhang",
      "Fan Zhou",
      "Yinqing Zhang",
      "Quanshi Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1906.04109"
  },
  {
    "id": "arXiv:1906.04376",
    "title": "Recognizing License Plates in Real-Time",
    "abstract": "Comments: License Plate Detection and Recognition, Computer Vision, Supervised Learning",
    "descriptor": "\nComments: License Plate Detection and Recognition, Computer Vision, Supervised Learning\n",
    "authors": [
      "Michael Yang",
      "Xin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1906.04376"
  },
  {
    "id": "arXiv:1908.11332",
    "title": "Universal, transferable and targeted adversarial attacks",
    "abstract": "Universal, transferable and targeted adversarial attacks",
    "descriptor": "",
    "authors": [
      "Junde Wu",
      "Rao Fu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1908.11332"
  },
  {
    "id": "arXiv:1911.05136",
    "title": "Fast Computation of Sep$_\u03bb$ via Interpolation-based Globality  Certificates",
    "abstract": "Comments: Revision #3, March 22, 2022",
    "descriptor": "\nComments: Revision #3, March 22, 2022\n",
    "authors": [
      "Tim Mitchell"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1911.05136"
  },
  {
    "id": "arXiv:1912.06845",
    "title": "Empirical and Instance-Dependent Estimation of Markov Chain and Mixing  Time",
    "abstract": "Comments: Extended journal version. A preliminary version of this work was presented at ALT'20",
    "descriptor": "\nComments: Extended journal version. A preliminary version of this work was presented at ALT'20\n",
    "authors": [
      "Geoffrey Wolfer"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1912.06845"
  },
  {
    "id": "arXiv:2001.00088",
    "title": "AI for Social Impact: Learning and Planning in the Data-to-Deployment  Pipeline",
    "abstract": "Comments: AI Magazine, Winter 2020",
    "descriptor": "\nComments: AI Magazine, Winter 2020\n",
    "authors": [
      "Andrew Perrault",
      "Fei Fang",
      "Arunesh Sinha",
      "Milind Tambe"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2001.00088"
  },
  {
    "id": "arXiv:2001.04417",
    "title": "Maximal Closed Set and Half-Space Separations in Finite Closure Systems",
    "abstract": "Comments: An early version of this paper was presented at ECML/PKDD 2019 and has appeared in the Lecture Notes in Computer Science, Machine Learning and Knowledge Discovery in Databases - European Conference, ECML PKDD 2019",
    "descriptor": "\nComments: An early version of this paper was presented at ECML/PKDD 2019 and has appeared in the Lecture Notes in Computer Science, Machine Learning and Knowledge Discovery in Databases - European Conference, ECML PKDD 2019\n",
    "authors": [
      "Florian Seiffarth",
      "Tamas Horvath",
      "Stefan Wrobel"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2001.04417"
  },
  {
    "id": "arXiv:2001.11224",
    "title": "Introducing the diagrammatic semiotic mode",
    "abstract": "Comments: 16 pages; accepted at Diagrams 2022",
    "descriptor": "\nComments: 16 pages; accepted at Diagrams 2022\n",
    "authors": [
      "Tuomo Hiippala",
      "John A. Bateman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2001.11224"
  },
  {
    "id": "arXiv:2002.08461",
    "title": "An Alternating Direction Explicit Method for Time Evolution Equations  with Applications to Fractional Differential Equations",
    "abstract": "Comments: 25 pages, 1 figure, 7 tables",
    "descriptor": "\nComments: 25 pages, 1 figure, 7 tables\n",
    "authors": [
      "Hao Liu",
      "Shingyu Leung"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2002.08461"
  },
  {
    "id": "arXiv:2003.09280",
    "title": "Deep Reinforcement Learning with Weighted Q-Learning",
    "abstract": "Comments: RLDM 2022. For a complete discussion and additional results, check our JMLR paper at this https URL",
    "descriptor": "\nComments: RLDM 2022. For a complete discussion and additional results, check our JMLR paper at this https URL\n",
    "authors": [
      "Andrea Cini",
      "Carlo D'Eramo",
      "Jan Peters",
      "Cesare Alippi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2003.09280"
  },
  {
    "id": "arXiv:2004.01079",
    "title": "Understanding Linearity of Cross-Lingual Word Embedding Mappings",
    "abstract": "Understanding Linearity of Cross-Lingual Word Embedding Mappings",
    "descriptor": "",
    "authors": [
      "Xutan Peng",
      "Mark Stevenson",
      "Chenghua Lin",
      "Chen Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2004.01079"
  },
  {
    "id": "arXiv:2004.05298",
    "title": "Detached Error Feedback for Distributed SGD with Random Sparsification",
    "abstract": "Detached Error Feedback for Distributed SGD with Random Sparsification",
    "descriptor": "",
    "authors": [
      "An Xu",
      "Heng Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2004.05298"
  },
  {
    "id": "arXiv:2004.10863",
    "title": "Dense Embeddings Preserving the Semantic Relationships in WordNet",
    "abstract": "Comments: Accepted at IJCNN 2022. Please ignore the previous version",
    "descriptor": "\nComments: Accepted at IJCNN 2022. Please ignore the previous version\n",
    "authors": [
      "Canlin Zhang",
      "Xiuwen Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2004.10863"
  },
  {
    "id": "arXiv:2005.02061",
    "title": "Privately Connecting Mobility to Infectious Diseases via Applied  Cryptography",
    "abstract": "Comments: Accepted at PoPETs 2022",
    "descriptor": "\nComments: Accepted at PoPETs 2022\n",
    "authors": [
      "Alexandros Bampoulidis",
      "Alessandro Bruni",
      "Lukas Helminger",
      "Daniel Kales",
      "Christian Rechberger",
      "Roman Walch"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2005.02061"
  },
  {
    "id": "arXiv:2005.09436",
    "title": "A cognitive based Intrusion detection system",
    "abstract": "Comments: 17 pages, 6 figures",
    "descriptor": "\nComments: 17 pages, 6 figures\n",
    "authors": [
      "Siamak Parhizkari",
      "Mohammad Bagher Menhaj",
      "Atena Sajedin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2005.09436"
  },
  {
    "id": "arXiv:2005.10190",
    "title": "Feature Purification: How Adversarial Training Performs Robust Deep  Learning",
    "abstract": "Comments: v2 and V3 polish writing and experiments, V4 adds experiments showing that adversarial training can be done through low-rank updates",
    "descriptor": "\nComments: v2 and V3 polish writing and experiments, V4 adds experiments showing that adversarial training can be done through low-rank updates\n",
    "authors": [
      "Zeyuan Allen-Zhu",
      "Yuanzhi Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2005.10190"
  },
  {
    "id": "arXiv:2006.14172",
    "title": "Backward error analysis for variational discretisations of partial  differential equations",
    "abstract": "Backward error analysis for variational discretisations of partial  differential equations",
    "descriptor": "",
    "authors": [
      "Robert I McLachlan",
      "Christian Offen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2006.14172"
  },
  {
    "id": "arXiv:2007.05034",
    "title": "The Mean-Squared Error of Double Q-Learning",
    "abstract": "Comments: An earlier verision of this paper appears in NeurIPS 2020. This verision updated an incorrect equation",
    "descriptor": "\nComments: An earlier verision of this paper appears in NeurIPS 2020. This verision updated an incorrect equation\n",
    "authors": [
      "Wentao Weng",
      "Harsh Gupta",
      "Niao He",
      "Lei Ying",
      "R. Srikant"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.05034"
  },
  {
    "id": "arXiv:2007.09569",
    "title": "Understanding and Mitigating the Limitations of Prioritized Experience  Replay",
    "abstract": "Comments: Accepted to UAI2022",
    "descriptor": "\nComments: Accepted to UAI2022\n",
    "authors": [
      "Yangchen Pan",
      "Jincheng Mei",
      "Amir-massoud Farahmand",
      "Martha White",
      "Hengshuai Yao",
      "Mohsen Rohani",
      "Jun Luo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2007.09569"
  },
  {
    "id": "arXiv:2008.06131",
    "title": "Sequential Monte Carlo for Sampling Balanced and Compact Redistricting  Plans",
    "abstract": "Comments: 18 pages, 7 figures, plus appendices; revised validation section, expanded discussion of practical implementations, and corrected the treatment of labeled versus unlabeled plans",
    "descriptor": "\nComments: 18 pages, 7 figures, plus appendices; revised validation section, expanded discussion of practical implementations, and corrected the treatment of labeled versus unlabeled plans\n",
    "authors": [
      "Cory McCartan",
      "Kosuke Imai"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Computers and Society (cs.CY)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2008.06131"
  },
  {
    "id": "arXiv:2008.11668",
    "title": "DeepVOX: Discovering Features from Raw Audio for Speaker Recognition in  Non-ideal Audio Signals",
    "abstract": "DeepVOX: Discovering Features from Raw Audio for Speaker Recognition in  Non-ideal Audio Signals",
    "descriptor": "",
    "authors": [
      "Anurag Chowdhury",
      "Arun Ross"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2008.11668"
  },
  {
    "id": "arXiv:2009.04003",
    "title": "Bayesian Inverse Reinforcement Learning for Collective Animal Movement",
    "abstract": "Bayesian Inverse Reinforcement Learning for Collective Animal Movement",
    "descriptor": "",
    "authors": [
      "Toryn L. J. Schafer",
      "Christopher K. Wikle",
      "Mevin B. Hooten"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.04003"
  },
  {
    "id": "arXiv:2009.06897",
    "title": "Steady and ranging sets in graph persistence",
    "abstract": "Steady and ranging sets in graph persistence",
    "descriptor": "",
    "authors": [
      "Mattia G. Bergomi",
      "Massimo Ferri",
      "Antonella Tavaglione"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2009.06897"
  },
  {
    "id": "arXiv:2009.08326",
    "title": "LAAT: Locally Aligned Ant Technique for discovering multiple faint low  dimensional structures of varying density",
    "abstract": "Comments: Accepted for publication by IEEE Transactions on Knowledge and Data Engineering",
    "descriptor": "\nComments: Accepted for publication by IEEE Transactions on Knowledge and Data Engineering\n",
    "authors": [
      "Abolfazl Taghribi",
      "Kerstin Bunte",
      "Rory Smith",
      "Jihye Shin",
      "Michele Mastropietro",
      "Reynier F. Peletier",
      "Peter Tino"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.08326"
  },
  {
    "id": "arXiv:2009.11929",
    "title": "Image-Based Sorghum Head Counting When You Only Look Once",
    "abstract": "Image-Based Sorghum Head Counting When You Only Look Once",
    "descriptor": "",
    "authors": [
      "Lawrence Mosley",
      "Hieu Pham",
      "Yogesh Bansal",
      "Eric Hare"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2009.11929"
  },
  {
    "id": "arXiv:2010.08391",
    "title": "Reconstructing A Large Scale 3D Face Dataset for Deep 3D Face  Identification",
    "abstract": "Comments: we want to re-organize this paper",
    "descriptor": "\nComments: we want to re-organize this paper\n",
    "authors": [
      "Cuican Yu",
      "Zihui Zhang",
      "Huibin Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2010.08391"
  },
  {
    "id": "arXiv:2010.10895",
    "title": "Multi-robot Implicit Control of Herds",
    "abstract": "Comments: Accepted at ICRA 2021",
    "descriptor": "\nComments: Accepted at ICRA 2021\n",
    "authors": [
      "Eduardo Sebasti\u00e1n",
      "Eduardo Montijano"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2010.10895"
  },
  {
    "id": "arXiv:2011.00003",
    "title": "Identifying Exoplanets with Deep Learning. IV. Removing Stellar Activity  Signals from Radial Velocity Measurements Using Neural Networks",
    "abstract": "Comments: 28 pages, 14 figures, Accepted for publication in the Astronomical Journal",
    "descriptor": "\nComments: 28 pages, 14 figures, Accepted for publication in the Astronomical Journal\n",
    "authors": [
      "Zoe L. de Beurs",
      "Andrew Vanderburg",
      "Christopher J. Shallue",
      "Xavier Dumusque",
      "Andrew Collier Cameron",
      "Christopher Leet",
      "Lars A. Buchhave",
      "Rosario Cosentino",
      "Adriano Ghedina",
      "Rapha\u00eblle D. Haywood",
      "Nicholas Langellier",
      "David W. Latham",
      "Mercedes L\u00f3pez-Morales",
      "Michel Mayor",
      "Giusi Micela",
      "Timothy W. Milbourne",
      "Annelies Mortier",
      "Emilio Molinari",
      "Francesco Pepe",
      "David F. Phillips",
      "Matteo Pinamonti",
      "Giampaolo Piotto",
      "Ken Rice",
      "Dimitar Sasselov",
      "Alessandro Sozzetti",
      "St\u00e9phane Udry",
      "Christopher A. Watson"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Solar and Stellar Astrophysics (astro-ph.SR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.00003"
  },
  {
    "id": "arXiv:2011.05563",
    "title": "Optimizing Age-of-Information in Adversarial and Stochastic Environments",
    "abstract": "Comments: To appear in the IEEE Transactions on Information Theory",
    "descriptor": "\nComments: To appear in the IEEE Transactions on Information Theory\n",
    "authors": [
      "Abhishek Sinha",
      "Rajarshi Bhattacharjee"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2011.05563"
  },
  {
    "id": "arXiv:2011.08837",
    "title": "Dominant Z-Eigenpairs of Tensor Kronecker Products are Decoupled and  Applications to Higher-Order Graph Matching",
    "abstract": "Comments: Major update to reorganize key results and split off image processing results. 24 pages, 6 pages Supplemental, 9 figures",
    "descriptor": "\nComments: Major update to reorganize key results and split off image processing results. 24 pages, 6 pages Supplemental, 9 figures\n",
    "authors": [
      "Charles Colley",
      "Huda Nassar",
      "David Gleich"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.08837"
  },
  {
    "id": "arXiv:2011.15013",
    "title": "Modularising Verification Of Durable Opacity",
    "abstract": "Modularising Verification Of Durable Opacity",
    "descriptor": "",
    "authors": [
      "Eleni Bila",
      "John Derrick",
      "Simon Doherty",
      "Brijesh Dongol",
      "Gerhard Schellhorn",
      "Heike Wehrheim"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2011.15013"
  },
  {
    "id": "arXiv:2012.04439",
    "title": "SPU-Net: Self-Supervised Point Cloud Upsampling by Coarse-to-Fine  Reconstruction with Self-Projection Optimization",
    "abstract": "Comments: Accepted by IEEE Transactions on Image Processing 2022",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Image Processing 2022\n",
    "authors": [
      "Xinhai Liu",
      "Xinchen Liu",
      "Yu-Shen Liu",
      "Zhizhong Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.04439"
  },
  {
    "id": "arXiv:2101.03258",
    "title": "Fair Sampling Error Analysis on NISQ Devices",
    "abstract": "Fair Sampling Error Analysis on NISQ Devices",
    "descriptor": "",
    "authors": [
      "John Golden",
      "Andreas B\u00e4rtschi",
      "Daniel O'Malley",
      "Stephan Eidenbenz"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2101.03258"
  },
  {
    "id": "arXiv:2101.03805",
    "title": "A Conflict-Based Search Framework for Multi-Objective Multi-Agent Path  Finding",
    "abstract": "Comments: 11 pages, preliminary version published in ICRA 2021, this is the T-ASE journal version",
    "descriptor": "\nComments: 11 pages, preliminary version published in ICRA 2021, this is the T-ASE journal version\n",
    "authors": [
      "Zhongqiang Ren",
      "Sivakumar Rathinam",
      "Howie Choset"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2101.03805"
  },
  {
    "id": "arXiv:2101.07696",
    "title": "Translating Hausdorff is Hard: Fine-Grained Lower Bounds for Hausdorff  Distance Under Translation",
    "abstract": "Comments: to be published at JoCG",
    "descriptor": "\nComments: to be published at JoCG\n",
    "authors": [
      "Karl Bringmann",
      "Andr\u00e9 Nusser"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2101.07696"
  },
  {
    "id": "arXiv:2101.08533",
    "title": "Eliminate Deviation with Deviation for Data Augmentation and a General  Multi-modal Data Learning Method",
    "abstract": "Eliminate Deviation with Deviation for Data Augmentation and a General  Multi-modal Data Learning Method",
    "descriptor": "",
    "authors": [
      "Yunpeng Gong",
      "Liqing Huang",
      "Lifei Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.08533"
  },
  {
    "id": "arXiv:2102.03664",
    "title": "Efficient Learning of a Linear Dynamical System with Stability  Guarantees",
    "abstract": "Comments: Exposition has been updated",
    "descriptor": "\nComments: Exposition has been updated\n",
    "authors": [
      "Wouter Jongeneel",
      "Tobias Sutter",
      "Daniel Kuhn"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2102.03664"
  },
  {
    "id": "arXiv:2102.06384",
    "title": "Uncertainty-of-Information Scheduling: A Restless Multi-armed Bandit  Framework",
    "abstract": "Comments: 28 pages, 5 figures",
    "descriptor": "\nComments: 28 pages, 5 figures\n",
    "authors": [
      "Gongpu Chen",
      "Soung Chang Liew",
      "Yulin Shao"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2102.06384"
  },
  {
    "id": "arXiv:2102.07403",
    "title": "Aperiodic Communication for MPC in Autonomous Cooperative Landing",
    "abstract": "Comments: 6 pages, 6 figures, This work has been presented at 7th IFAC Conference on Nonlinear Model Predictive Control 2021",
    "descriptor": "\nComments: 6 pages, 6 figures, This work has been presented at 7th IFAC Conference on Nonlinear Model Predictive Control 2021\n",
    "authors": [
      "D\u017eenan Lapandi\u0107",
      "Linnea Persson",
      "Dimos V. Dimarogonas",
      "Bo Wahlberg"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2102.07403"
  },
  {
    "id": "arXiv:2102.08352",
    "title": "Stochastic Variance Reduction for Variational Inequality Methods",
    "abstract": "Stochastic Variance Reduction for Variational Inequality Methods",
    "descriptor": "",
    "authors": [
      "Ahmet Alacaoglu",
      "Yura Malitsky"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.08352"
  },
  {
    "id": "arXiv:2103.04233",
    "title": "GANav: Efficient Terrain Segmentation for Robot Navigation in  Unstructured Outdoor Environments",
    "abstract": "GANav: Efficient Terrain Segmentation for Robot Navigation in  Unstructured Outdoor Environments",
    "descriptor": "",
    "authors": [
      "Tianrui Guan",
      "Divya Kothandaraman",
      "Rohan Chandra",
      "Adarsh Jagan Sathyamoorthy",
      "Kasun Weerakoon",
      "Dinesh Manocha"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.04233"
  },
  {
    "id": "arXiv:2103.04931",
    "title": "Monte Carlo Tree Search: A Review of Recent Modifications and  Applications",
    "abstract": "Comments: 99 pages, Accepted to Artificial Intelligence Review journal",
    "descriptor": "\nComments: 99 pages, Accepted to Artificial Intelligence Review journal\n",
    "authors": [
      "Maciej \u015awiechowski",
      "Konrad Godlewski",
      "Bartosz Sawicki",
      "Jacek Ma\u0144dziuk"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2103.04931"
  },
  {
    "id": "arXiv:2103.10005",
    "title": "Neural Network Attribution Methods for Problems in Geoscience: A Novel  Synthetic Benchmark Dataset",
    "abstract": "Comments: This is an updated preprint version of the manuscript. This work has been published (open access) in the journal Environmental Data Science with doi: this https URL Please cite the published version. The dataset of this work is published at: this https URL",
    "descriptor": "\nComments: This is an updated preprint version of the manuscript. This work has been published (open access) in the journal Environmental Data Science with doi: this https URL Please cite the published version. The dataset of this work is published at: this https URL\n",
    "authors": [
      "Antonios Mamalakis",
      "Imme Ebert-Uphoff",
      "Elizabeth A. Barnes"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.10005"
  },
  {
    "id": "arXiv:2104.03468",
    "title": "Semi-implicit Euler--Maruyama scheme for polynomial diffusions on the  unit ball",
    "abstract": "Comments: 19 pages, 10 figures",
    "descriptor": "\nComments: 19 pages, 10 figures\n",
    "authors": [
      "Takuya Nakagawa",
      "Dai Taguchi",
      "Tomooki Yuasa"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2104.03468"
  },
  {
    "id": "arXiv:2104.04883",
    "title": "Graph Representation Learning in Biomedicine",
    "abstract": "Graph Representation Learning in Biomedicine",
    "descriptor": "",
    "authors": [
      "Michelle M. Li",
      "Kexin Huang",
      "Marinka Zitnik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Biomolecules (q-bio.BM)",
      "Genomics (q-bio.GN)",
      "Molecular Networks (q-bio.MN)"
    ],
    "url": "https://arxiv.org/abs/2104.04883"
  },
  {
    "id": "arXiv:2104.07278",
    "title": "Stochastic Processes with Expected Stopping Time",
    "abstract": "Comments: A preliminary version appeared at LICS 2021",
    "descriptor": "\nComments: A preliminary version appeared at LICS 2021\n",
    "authors": [
      "Krishnendu Chatterjee",
      "Laurent Doyen"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2104.07278"
  },
  {
    "id": "arXiv:2104.07921",
    "title": "VGNMN: Video-grounded Neural Module Network to Video-Grounded Language  Tasks",
    "abstract": "Comments: Accepted at NAACL 2022 (Oral)",
    "descriptor": "\nComments: Accepted at NAACL 2022 (Oral)\n",
    "authors": [
      "Hung Le",
      "Nancy F. Chen",
      "Steven C.H. Hoi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.07921"
  },
  {
    "id": "arXiv:2104.11106",
    "title": "Formula RL: Deep Reinforcement Learning for Autonomous Racing using  Telemetry Data",
    "abstract": "Formula RL: Deep Reinforcement Learning for Autonomous Racing using  Telemetry Data",
    "descriptor": "",
    "authors": [
      "Adrian Remonda",
      "Sarah Krebs",
      "Eduardo Veas",
      "Granit Luzhnica",
      "Roman Kern"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.11106"
  },
  {
    "id": "arXiv:2104.14436",
    "title": "Deterministic Algorithms for the Hidden Subgroup Problem",
    "abstract": "Comments: v3: 14 pages. Added some details. Minor edits for clarity. Close to published version. v2: 14 pages. Added references to past and recent related work, added new algorithms partially resolving an open question from the previous version. v1: 7 pages",
    "descriptor": "\nComments: v3: 14 pages. Added some details. Minor edits for clarity. Close to published version. v2: 14 pages. Added references to past and recent related work, added new algorithms partially resolving an open question from the previous version. v1: 7 pages\n",
    "authors": [
      "Ashwin Nayak"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2104.14436"
  },
  {
    "id": "arXiv:2104.14445",
    "title": "Trakhtenbrot's Theorem in Coq: Finite Model Theory through the  Constructive Lens",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2004.07390",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2004.07390\n",
    "authors": [
      "Dominik Kirst",
      "Dominique Larchey-Wendling"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Computation and Language (cs.CL)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2104.14445"
  },
  {
    "id": "arXiv:2105.00613",
    "title": "A C++17 Thread Pool for High-Performance Scientific Computing",
    "abstract": "Comments: 23 pages, source code available at this https URL",
    "descriptor": "\nComments: 23 pages, source code available at this https URL\n",
    "authors": [
      "Barak Shoshany"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.00613"
  },
  {
    "id": "arXiv:2105.03923",
    "title": "CASA: Bridging the Gap between Policy Improvement and Policy Evaluation  with Conflict Averse Policy Iteration",
    "abstract": "CASA: Bridging the Gap between Policy Improvement and Policy Evaluation  with Conflict Averse Policy Iteration",
    "descriptor": "",
    "authors": [
      "Changnan Xiao",
      "Haosen Shi",
      "Jiajun Fan",
      "Shihong Deng",
      "Haiyan Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.03923"
  },
  {
    "id": "arXiv:2105.05687",
    "title": "Bregman algorithms for mixed-strategy generalized Nash equilibrium  seeking in a class of mixed-integer games",
    "abstract": "Bregman algorithms for mixed-strategy generalized Nash equilibrium  seeking in a class of mixed-integer games",
    "descriptor": "",
    "authors": [
      "Wicak Ananduta",
      "Sergio Grammatico"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.05687"
  },
  {
    "id": "arXiv:2105.06827",
    "title": "Profitable Strategy Design for Trades on Cryptocurrency Markets with  Machine Learning Techniques",
    "abstract": "Comments: Manuscript Text Revised, Some Results Added",
    "descriptor": "\nComments: Manuscript Text Revised, Some Results Added\n",
    "authors": [
      "Mohsen Asgari",
      "Hossein Khasteh"
    ],
    "subjectives": [
      "Trading and Market Microstructure (q-fin.TR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.06827"
  },
  {
    "id": "arXiv:2105.07129",
    "title": "Regularized Deep Linear Discriminant Analysis",
    "abstract": "Regularized Deep Linear Discriminant Analysis",
    "descriptor": "",
    "authors": [
      "Wen Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.07129"
  },
  {
    "id": "arXiv:2105.13670",
    "title": "Transferable Deep Reinforcement Learning Framework for Autonomous  Vehicles with Joint Radar-Data Communications",
    "abstract": "Transferable Deep Reinforcement Learning Framework for Autonomous  Vehicles with Joint Radar-Data Communications",
    "descriptor": "",
    "authors": [
      "Nguyen Quang Hieu",
      "Dinh Thai Hoang",
      "Dusit Niyato",
      "Ping Wang",
      "Dong In Kim",
      "Chau Yuen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.13670"
  },
  {
    "id": "arXiv:2105.14278",
    "title": "An Overview of Deep Learning Techniques for Epileptic Seizures Detection  and Prediction Based on Neuroimaging Modalities: Methods, Challenges, and  Future Works",
    "abstract": "An Overview of Deep Learning Techniques for Epileptic Seizures Detection  and Prediction Based on Neuroimaging Modalities: Methods, Challenges, and  Future Works",
    "descriptor": "",
    "authors": [
      "Afshin Shoeibi",
      "Navid Ghassemi",
      "Marjane Khodatars",
      "Mahboobeh Jafari",
      "Parisa Moridian",
      "Roohallah Alizadehsani",
      "Yinan Kong",
      "Juan Manuel Gorriz",
      "Javier Ram\u00edrez",
      "Abbas Khosravi",
      "Saeid Nahavandi",
      "U. Rajendra Acharya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.14278"
  },
  {
    "id": "arXiv:2105.15061",
    "title": "All-in-one: Certifiable Optimal Distributed Kalman Filter under Unknown  Correlations",
    "abstract": "Comments: This paper has been accepted at 60th 2021 IEEE Conference on Decision and Control (CDC)",
    "descriptor": "\nComments: This paper has been accepted at 60th 2021 IEEE Conference on Decision and Control (CDC)\n",
    "authors": [
      "Eduardo Sebasti\u00e1n",
      "Eduardo Montijano",
      "Carlos Sag\u00fc\u00e9s"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.15061"
  },
  {
    "id": "arXiv:2106.00279",
    "title": "$L_0$ Isotonic Regression With Secondary Objectives",
    "abstract": "Comments: Adds references, improves exposition",
    "descriptor": "\nComments: Adds references, improves exposition\n",
    "authors": [
      "Quentin F. Stout"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.00279"
  },
  {
    "id": "arXiv:2106.01100",
    "title": "Prediction of the Position of External Markers Using a Recurrent Neural  Network Trained With Unbiased Online Recurrent Optimization for Safe Lung  Cancer Radiotherapy",
    "abstract": "Comments: 24 pages, 16 figures, minor text improvements (English writing), mistake in footnote 11 corrected",
    "descriptor": "\nComments: 24 pages, 16 figures, minor text improvements (English writing), mistake in footnote 11 corrected\n",
    "authors": [
      "Michel Pohl",
      "Mitsuru Uesaka",
      "Hiroyuki Takahashi",
      "Kazuyuki Demachi",
      "Ritu Bhusal Chhatkuli"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.01100"
  },
  {
    "id": "arXiv:2106.02615",
    "title": "Consensus Multiplicative Weights Update: Learning to Learn using  Projector-based Game Signatures",
    "abstract": "Comments: ICML 2022, the 39th International Conference on Machine Learning",
    "descriptor": "\nComments: ICML 2022, the 39th International Conference on Machine Learning\n",
    "authors": [
      "Nelson Vadori",
      "Rahul Savani",
      "Thomas Spooner",
      "Sumitra Ganesh"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02615"
  },
  {
    "id": "arXiv:2106.02979",
    "title": "Syndicated Bandits: A Framework for Auto Tuning Hyper-parameters in  Contextual Bandit Algorithms",
    "abstract": "Syndicated Bandits: A Framework for Auto Tuning Hyper-parameters in  Contextual Bandit Algorithms",
    "descriptor": "",
    "authors": [
      "Qin Ding",
      "Yue Kang",
      "Yi-Wei Liu",
      "Thomas C.M. Lee",
      "Cho-Jui Hsieh",
      "James Sharpnack"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02979"
  },
  {
    "id": "arXiv:2106.03305",
    "title": "Faster Cut-Equivalent Trees in Simple Graphs",
    "abstract": "Faster Cut-Equivalent Trees in Simple Graphs",
    "descriptor": "",
    "authors": [
      "Tianyi Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.03305"
  },
  {
    "id": "arXiv:2106.05421",
    "title": "Data-Driven Invariant Learning for Probabilistic Programs",
    "abstract": "Comments: 35 pages",
    "descriptor": "\nComments: 35 pages\n",
    "authors": [
      "Jialu Bao",
      "Nitesh Trivedi",
      "Drashti Pathak",
      "Justin Hsu",
      "Subhajit Roy"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2106.05421"
  },
  {
    "id": "arXiv:2106.05527",
    "title": "Soft Truncation: A Universal Training Technique of Score-based Diffusion  Model for High Precision Score Estimation",
    "abstract": "Comments: 28 pages, 16 figures, 15 tables",
    "descriptor": "\nComments: 28 pages, 16 figures, 15 tables\n",
    "authors": [
      "Dongjun Kim",
      "Seungjae Shin",
      "Kyungwoo Song",
      "Wanmo Kang",
      "Il-Chul Moon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.05527"
  },
  {
    "id": "arXiv:2106.06745",
    "title": "Minimization and Canonization of GFG Transition-Based Automata",
    "abstract": "Comments: 33 pages, 12 figures, slight style changes to match LMCS's required style. arXiv admin note: substantial text overlap with arXiv:2009.10885",
    "descriptor": "\nComments: 33 pages, 12 figures, slight style changes to match LMCS's required style. arXiv admin note: substantial text overlap with arXiv:2009.10885\n",
    "authors": [
      "Bader Abu Radi",
      "Orna Kupferman"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2106.06745"
  },
  {
    "id": "arXiv:2106.07767",
    "title": "How does Heterophily Impact Robustness of Graph Neural Networks?  Theoretical Connections and Practical Implications",
    "abstract": "Comments: Accepted to KDD 2022; complete version with full appendix; 21 pages, 2 figures",
    "descriptor": "\nComments: Accepted to KDD 2022; complete version with full appendix; 21 pages, 2 figures\n",
    "authors": [
      "Jiong Zhu",
      "Junchen Jin",
      "Donald Loveland",
      "Michael T. Schaub",
      "Danai Koutra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.07767"
  },
  {
    "id": "arXiv:2106.10271",
    "title": "End-to-end Temporal Action Detection with Transformer",
    "abstract": "Comments: Under review. The complete version of this work was submitted to a journal in July 2021",
    "descriptor": "\nComments: Under review. The complete version of this work was submitted to a journal in July 2021\n",
    "authors": [
      "Xiaolong Liu",
      "Qimeng Wang",
      "Yao Hu",
      "Xu Tang",
      "Shiwei Zhang",
      "Song Bai",
      "Xiang Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10271"
  },
  {
    "id": "arXiv:2106.12284",
    "title": "Bayesian Statistics Guided Label Refurbishment Mechanism: Mitigating  Label Noise in Medical Image Classification",
    "abstract": "Comments: 10 pages, 11 figures",
    "descriptor": "\nComments: 10 pages, 11 figures\n",
    "authors": [
      "Mengdi Gao",
      "Ximeng Feng",
      "Mufeng Geng",
      "Zhe Jiang",
      "Lei Zhu",
      "Xiangxi Meng",
      "Chuanqing Zhou",
      "Qiushi Ren",
      "Yanye Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.12284"
  },
  {
    "id": "arXiv:2106.13871",
    "title": "Transflower: probabilistic autoregressive dance generation with  multimodal attention",
    "abstract": "Comments: Article presented at SIGGRAPH Asia 2021, and published in ACM Transactions on Graphics",
    "descriptor": "\nComments: Article presented at SIGGRAPH Asia 2021, and published in ACM Transactions on Graphics\n",
    "authors": [
      "Guillermo Valle-P\u00e9rez",
      "Gustav Eje Henter",
      "Jonas Beskow",
      "Andr\u00e9 Holzapfel",
      "Pierre-Yves Oudeyer",
      "Simon Alexanderson"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.13871"
  },
  {
    "id": "arXiv:2106.14308",
    "title": "Concentration of Contractive Stochastic Approximation and Reinforcement  Learning",
    "abstract": "Comments: 20 pages, Accepted for publication in Stochastic Systems",
    "descriptor": "\nComments: 20 pages, Accepted for publication in Stochastic Systems\n",
    "authors": [
      "Siddharth Chandak",
      "Vivek S. Borkar",
      "Parth Dodhia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.14308"
  },
  {
    "id": "arXiv:2107.00243",
    "title": "Preconditioning for Scalable Gaussian Process Hyperparameter  Optimization",
    "abstract": "Comments: International Conference on Machine Learning (ICML)",
    "descriptor": "\nComments: International Conference on Machine Learning (ICML)\n",
    "authors": [
      "Jonathan Wenger",
      "Geoff Pleiss",
      "Philipp Hennig",
      "John P. Cunningham",
      "Jacob R. Gardner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.00243"
  },
  {
    "id": "arXiv:2107.01422",
    "title": "Imaging dynamics beneath turbid media via parallelized single-photon  detection",
    "abstract": "Imaging dynamics beneath turbid media via parallelized single-photon  detection",
    "descriptor": "",
    "authors": [
      "Shiqi Xu",
      "Xi Yang",
      "Wenhui Liu",
      "Joakim Jonsson",
      "Ruobing Qian",
      "Pavan Chandra Konda",
      "Kevin C. Zhou",
      "Lucas Kreiss",
      "Qionghai Dai",
      "Haoqian Wang",
      "Edouard Berrocal",
      "Roarke Horstmeyer"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Tissues and Organs (q-bio.TO)"
    ],
    "url": "https://arxiv.org/abs/2107.01422"
  },
  {
    "id": "arXiv:2107.01471",
    "title": "On Tightness of Tsaknakis-Spirakis Descent Methods for Approximate Nash  Equilibria",
    "abstract": "On Tightness of Tsaknakis-Spirakis Descent Methods for Approximate Nash  Equilibria",
    "descriptor": "",
    "authors": [
      "Zhaohua Chen",
      "Xiaotie Deng",
      "Wenhan Huang",
      "Hanyu Li",
      "Yuhao Li"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2107.01471"
  },
  {
    "id": "arXiv:2107.02058",
    "title": "Tight Guarantees for Multi-unit Prophet Inequalities and Online  Stochastic Knapsack",
    "abstract": "Comments: This is the full version of the SODA 2022 paper",
    "descriptor": "\nComments: This is the full version of the SODA 2022 paper\n",
    "authors": [
      "Jiashuo Jiang",
      "Will Ma",
      "Jiawei Zhang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2107.02058"
  },
  {
    "id": "arXiv:2107.02550",
    "title": "Universal approximation and model compression for radial neural networks",
    "abstract": "Comments: 35 pages",
    "descriptor": "\nComments: 35 pages\n",
    "authors": [
      "Iordan Ganev",
      "Twan van Laarhoven",
      "Robin Walters"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Representation Theory (math.RT)"
    ],
    "url": "https://arxiv.org/abs/2107.02550"
  },
  {
    "id": "arXiv:2107.02565",
    "title": "Prioritized training on points that are learnable, worth learning, and  not yet learned (workshop version)",
    "abstract": "Prioritized training on points that are learnable, worth learning, and  not yet learned (workshop version)",
    "descriptor": "",
    "authors": [
      "S\u00f6ren Mindermann",
      "Muhammed Razzak",
      "Winnie Xu",
      "Andreas Kirsch",
      "Mrinank Sharma",
      "Adrien Morisot",
      "Aidan N. Gomez",
      "Sebastian Farquhar",
      "Jan Brauner",
      "Yarin Gal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.02565"
  },
  {
    "id": "arXiv:2107.03721",
    "title": "Demystifying the Draft EU Artificial Intelligence Act",
    "abstract": "Comments: 16 pages, 1 table",
    "descriptor": "\nComments: 16 pages, 1 table\n",
    "authors": [
      "Michael Veale",
      "Frederik Zuiderveen Borgesius"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.03721"
  },
  {
    "id": "arXiv:2107.04986",
    "title": "Theoretical Limit of Radar Parameter Estimation",
    "abstract": "Theoretical Limit of Radar Parameter Estimation",
    "descriptor": "",
    "authors": [
      "Dazhuan Xu",
      "Han Zhang",
      "Weilin Tu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2107.04986"
  },
  {
    "id": "arXiv:2107.06149",
    "title": "MINERVAS: Massive INterior EnviRonments VirtuAl Synthesis",
    "abstract": "Comments: The two first authors contribute equally. Project pape: this https URL",
    "descriptor": "\nComments: The two first authors contribute equally. Project pape: this https URL\n",
    "authors": [
      "Haocheng Ren",
      "Hao Zhang",
      "Jia Zheng",
      "Jiaxiang Zheng",
      "Rui Tang",
      "Rui Wang",
      "and Yuchi Huo",
      "Hujun Bao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.06149"
  },
  {
    "id": "arXiv:2107.07572",
    "title": "Globally Convergent Multilevel Training of Deep Residual Networks",
    "abstract": "Globally Convergent Multilevel Training of Deep Residual Networks",
    "descriptor": "",
    "authors": [
      "Alena Kopani\u010d\u00e1kov\u00e1",
      "Rolf Krause"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2107.07572"
  },
  {
    "id": "arXiv:2107.08096",
    "title": "Learning to Limit Data Collection via Scaling Laws: A Computational  Interpretation for the Legal Principle of Data Minimization",
    "abstract": "Comments: To appear at ACM Conference on Fairness, Accountability, and Transparency, 2022",
    "descriptor": "\nComments: To appear at ACM Conference on Fairness, Accountability, and Transparency, 2022\n",
    "authors": [
      "Divya Shanmugam",
      "Samira Shabanian",
      "Fernando Diaz",
      "Mich\u00e8le Finck",
      "Asia Biega"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2107.08096"
  },
  {
    "id": "arXiv:2107.08295",
    "title": "Communicating via Markov Decision Processes",
    "abstract": "Comments: ICML 2022",
    "descriptor": "\nComments: ICML 2022\n",
    "authors": [
      "Samuel Sokota",
      "Christian Schroeder de Witt",
      "Maximilian Igl",
      "Luisa Zintgraf",
      "Philip Torr",
      "Martin Strohmeier",
      "J. Zico Kolter",
      "Shimon Whiteson",
      "Jakob Foerster"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2107.08295"
  },
  {
    "id": "arXiv:2107.09858",
    "title": "Weighted Intersection over Union (wIoU): A New Evaluation Metric for  Image Segmentation",
    "abstract": "Weighted Intersection over Union (wIoU): A New Evaluation Metric for  Image Segmentation",
    "descriptor": "",
    "authors": [
      "Yeong-Jun Cho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.09858"
  },
  {
    "id": "arXiv:2107.10064",
    "title": "Few Shots Are All You Need: A Progressive Few Shot Learning Approach for  Low Resource Handwritten Text Recognition",
    "abstract": "Comments: Accepted in Pattern Recognition Letters",
    "descriptor": "\nComments: Accepted in Pattern Recognition Letters\n",
    "authors": [
      "Mohamed Ali Souibgui",
      "Alicia Forn\u00e9s",
      "Yousri Kessentini",
      "Be\u00e1ta Megyesi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.10064"
  },
  {
    "id": "arXiv:2107.11272",
    "title": "Graphical Nonlinear System Analysis",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Thomas Chaffey",
      "Fulvio Forni",
      "Rodolphe Sepulchre"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2107.11272"
  },
  {
    "id": "arXiv:2107.11439",
    "title": "What Is The Internet? (Considering Partial Connectivity)",
    "abstract": "What Is The Internet? (Considering Partial Connectivity)",
    "descriptor": "",
    "authors": [
      "Guillermo Baltra",
      "John Heidemann"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2107.11439"
  },
  {
    "id": "arXiv:2107.11972",
    "title": "Trade When Opportunity Comes: Price Movement Forecasting via  Locality-Aware Attention and Iterative Refinement Labeling",
    "abstract": "Trade When Opportunity Comes: Price Movement Forecasting via  Locality-Aware Attention and Iterative Refinement Labeling",
    "descriptor": "",
    "authors": [
      "Liang Zeng",
      "Lei Wang",
      "Hui Niu",
      "Jian Li",
      "Ruchen Zhang",
      "Zhonghao Dai",
      "Dewei Zhu",
      "Ling Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Statistical Finance (q-fin.ST)"
    ],
    "url": "https://arxiv.org/abs/2107.11972"
  },
  {
    "id": "arXiv:2107.13144",
    "title": "Content-aware Directed Propagation Network with Pixel Adaptive Kernel  Attention",
    "abstract": "Comments: submitted to IEEE transactions on Image Processing",
    "descriptor": "\nComments: submitted to IEEE transactions on Image Processing\n",
    "authors": [
      "Min-Cheol Sagong",
      "Yoon-Jae Yeo",
      "Seung-Won Jung",
      "Sung-Jea Ko"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.13144"
  },
  {
    "id": "arXiv:2108.02297",
    "title": "Spartus: A 9.4 TOp/s FPGA-based LSTM Accelerator Exploiting  Spatio-Temporal Sparsity",
    "abstract": "Comments: Accepted for publication in IEEE Transactions on Neural Networks and Learning Systems, 2022",
    "descriptor": "\nComments: Accepted for publication in IEEE Transactions on Neural Networks and Learning Systems, 2022\n",
    "authors": [
      "Chang Gao",
      "Tobi Delbruck",
      "Shih-Chii Liu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.02297"
  },
  {
    "id": "arXiv:2108.02655",
    "title": "Sinkless Orientation Made Simple",
    "abstract": "Comments: Parts of this work appeared in DISC 2021 as a brief announcement, under the title \"Sinkless orientation is hard also in the supported LOCAL model\"",
    "descriptor": "\nComments: Parts of this work appeared in DISC 2021 as a brief announcement, under the title \"Sinkless orientation is hard also in the supported LOCAL model\"\n",
    "authors": [
      "Alkida Balliu",
      "Janne H. Korhonen",
      "Fabian Kuhn",
      "Henrik Lievonen",
      "Dennis Olivetti",
      "Shreyas Pai",
      "Ami Paz",
      "Joel Rybicki",
      "Stefan Schmid",
      "Jan Studen\u00fd",
      "Jukka Suomela",
      "Jara Uitto"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2108.02655"
  },
  {
    "id": "arXiv:2108.04116",
    "title": "Transfer Learning Gaussian Anomaly Detection by Fine-tuning  Representations",
    "abstract": "Comments: Camera ready for IMPROVE22 + additional typo fixes",
    "descriptor": "\nComments: Camera ready for IMPROVE22 + additional typo fixes\n",
    "authors": [
      "Oliver Rippel",
      "Arnav Chavan",
      "Chucai Lei",
      "Dorit Merhof"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.04116"
  },
  {
    "id": "arXiv:2108.04510",
    "title": "A hydraulic model outperforms work-balance models for predicting  recovery kinetics from intermittent exercise",
    "abstract": "Comments: 26 pages, 9 figures, 6 tables, this manuscript has been submitted and is currently under review",
    "descriptor": "\nComments: 26 pages, 9 figures, 6 tables, this manuscript has been submitted and is currently under review\n",
    "authors": [
      "Fabian C. Weigend",
      "David C. Clarke",
      "Oliver Obst",
      "Jason Siegler"
    ],
    "subjectives": [
      "Other Computer Science (cs.OH)"
    ],
    "url": "https://arxiv.org/abs/2108.04510"
  },
  {
    "id": "arXiv:2108.06158",
    "title": "NIAPU: network-informed adaptive positive-unlabelled learning for  disease genes identification",
    "abstract": "Comments: Submitted to peer-reviewed journal, 26 pages",
    "descriptor": "\nComments: Submitted to peer-reviewed journal, 26 pages\n",
    "authors": [
      "Paola Stolfi",
      "Andrea Mastropietro",
      "Giuseppe Pasculli",
      "Paolo Tieri",
      "Davide Vergni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.06158"
  },
  {
    "id": "arXiv:2108.11872",
    "title": "Comparing Classes of Estimators: When does Gradient Descent Beat Ridge  Regression in Linear Models?",
    "abstract": "Comparing Classes of Estimators: When does Gradient Descent Beat Ridge  Regression in Linear Models?",
    "descriptor": "",
    "authors": [
      "Dominic Richards",
      "Edgar Dobriban",
      "Patrick Rebeschini"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2108.11872"
  },
  {
    "id": "arXiv:2108.12314",
    "title": "Multiple Hypothesis Testing Framework for Spatial Signals",
    "abstract": "Comments: Submitted to IEEE Transactions on Signal and Information Processing over Networks",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Signal and Information Processing over Networks\n",
    "authors": [
      "Martin G\u00f6lz",
      "Abdelhak M. Zoubir",
      "Visa Koivunen"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2108.12314"
  },
  {
    "id": "arXiv:2109.00676",
    "title": "Cross-motif Matching and Hierarchical Contrastive Learning for  Recommendation",
    "abstract": "Comments: Rename the paper,the full-text language was polished and part of the experiment content was revised",
    "descriptor": "\nComments: Rename the paper,the full-text language was polished and part of the experiment content was revised\n",
    "authors": [
      "Yundong Sun",
      "Dongjie Zhu",
      "Haiwen Du",
      "Zhaoshuo Tian"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2109.00676"
  },
  {
    "id": "arXiv:2109.01769",
    "title": "SFCDecomp: Multicriteria Optimized Tool Path Planning in 3D Printing  using Space-Filling Curve Based Domain Decomposition",
    "abstract": "Comments: Minor edits to incorporate reviewers' comments. Published in IJCGA",
    "descriptor": "\nComments: Minor edits to incorporate reviewers' comments. Published in IJCGA\n",
    "authors": [
      "Prashant Gupta",
      "Yiran Guo",
      "Narasimha Boddeti",
      "Bala Krishnamoorthy"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computational Geometry (cs.CG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2109.01769"
  },
  {
    "id": "arXiv:2109.04529",
    "title": "Parameterized inapproximability of Morse matching",
    "abstract": "Comments: Corrected a small error in Section 8 and improved the overall exposition in section 8. A few cosmetic changes in the introduction",
    "descriptor": "\nComments: Corrected a small error in Section 8 and improved the overall exposition in section 8. A few cosmetic changes in the introduction\n",
    "authors": [
      "Ulrich Bauer",
      "Abhishek Rathod"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2109.04529"
  },
  {
    "id": "arXiv:2109.12663",
    "title": "WCFS: A new framework for analyzing multiserver systems",
    "abstract": "Comments: 29 pages. Under submission",
    "descriptor": "\nComments: 29 pages. Under submission\n",
    "authors": [
      "Isaac Grosof",
      "Mor Harchol-Balter",
      "Alan Scheller-Wolf"
    ],
    "subjectives": [
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2109.12663"
  },
  {
    "id": "arXiv:2109.15111",
    "title": "SsAG: Summarization and sparsification of Attributed Graphs",
    "abstract": "SsAG: Summarization and sparsification of Attributed Graphs",
    "descriptor": "",
    "authors": [
      "Sarwan Ali",
      "Muhammad Ahmad",
      "Maham Anwer Beg",
      "Imdad Ullah Khan",
      "Safiullah Faizullah",
      "Muhammad Asad Khan"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2109.15111"
  },
  {
    "id": "arXiv:2110.00683",
    "title": "Learning through atypical \"phase transitions\" in overparameterized  neural networks",
    "abstract": "Comments: 28 pages, 14 figures",
    "descriptor": "\nComments: 28 pages, 14 figures\n",
    "authors": [
      "Carlo Baldassi",
      "Clarissa Lauditi",
      "Enrico M. Malatesta",
      "Rosalba Pacelli",
      "Gabriele Perugini",
      "Riccardo Zecchina"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.00683"
  },
  {
    "id": "arXiv:2110.01833",
    "title": "Hierarchical Primitive Composition: Simultaneous Activation of Skills  with Inconsistent Action Dimensions in Multiple Hierarchies",
    "abstract": "Comments: Submitted to RAL-IROS 2022",
    "descriptor": "\nComments: Submitted to RAL-IROS 2022\n",
    "authors": [
      "Jeong-Hoon Lee",
      "Jongeun Choi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.01833"
  },
  {
    "id": "arXiv:2110.02510",
    "title": "Cycle Representation Learning for Inductive Relation Prediction",
    "abstract": "Comments: Accepted in ICML 2022",
    "descriptor": "\nComments: Accepted in ICML 2022\n",
    "authors": [
      "Zuoyu Yan",
      "Tengfei Ma",
      "Liangcai Gao",
      "Zhi Tang",
      "Chao Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02510"
  },
  {
    "id": "arXiv:2110.03681",
    "title": "Neural Tangent Kernel Empowered Federated Learning",
    "abstract": "Comments: Accepted by ICML 2022",
    "descriptor": "\nComments: Accepted by ICML 2022\n",
    "authors": [
      "Kai Yue",
      "Richeng Jin",
      "Ryan Pilgrim",
      "Chau-Wai Wong",
      "Dror Baron",
      "Huaiyu Dai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.03681"
  },
  {
    "id": "arXiv:2110.06172",
    "title": "Complexity of optimizing over the integers",
    "abstract": "Complexity of optimizing over the integers",
    "descriptor": "",
    "authors": [
      "Amitabh Basu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.06172"
  },
  {
    "id": "arXiv:2110.08212",
    "title": "NNK-Means: Data summarization using dictionary learning with  non-negative kernel regression",
    "abstract": "Comments: Preprint. To be published at the 30th European Signal Processing Conference, EUSIPCO 2022",
    "descriptor": "\nComments: Preprint. To be published at the 30th European Signal Processing Conference, EUSIPCO 2022\n",
    "authors": [
      "Sarath Shekkizhar",
      "Antonio Ortega"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08212"
  },
  {
    "id": "arXiv:2110.08355",
    "title": "Clean or Annotate: How to Spend a Limited Data Collection Budget",
    "abstract": "Comments: 17 pages, 3 figures, 6 tables. Accepted to NAACL 2022 workshop",
    "descriptor": "\nComments: 17 pages, 3 figures, 6 tables. Accepted to NAACL 2022 workshop\n",
    "authors": [
      "Derek Chen",
      "Zhou Yu",
      "Samuel R. Bowman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08355"
  },
  {
    "id": "arXiv:2110.08595",
    "title": "A MIMO Radar-based Few-Shot Learning Approach for Human-ID",
    "abstract": "Comments: 5 pages, 6 figures, 2 tables",
    "descriptor": "\nComments: 5 pages, 6 figures, 2 tables\n",
    "authors": [
      "Pascal Weller",
      "Fady Aziz",
      "Sherif Abdulatif",
      "Urs Schneider",
      "Marco F. Huber"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08595"
  },
  {
    "id": "arXiv:2110.08678",
    "title": "Improving Transformers with Probabilistic Attention Keys",
    "abstract": "Comments: 27 pages, 16 figures, 10 tables",
    "descriptor": "\nComments: 27 pages, 16 figures, 10 tables\n",
    "authors": [
      "Tam Nguyen",
      "Tan M. Nguyen",
      "Dung D. Le",
      "Duy Khuong Nguyen",
      "Viet-Anh Tran",
      "Richard G. Baraniuk",
      "Nhat Ho",
      "Stanley J. Osher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.08678"
  },
  {
    "id": "arXiv:2110.10054",
    "title": "Generating Symbolic Reasoning Problems with Transformer GANs",
    "abstract": "Generating Symbolic Reasoning Problems with Transformer GANs",
    "descriptor": "",
    "authors": [
      "Jens U. Kreber",
      "Christopher Hahn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10054"
  },
  {
    "id": "arXiv:2110.11316",
    "title": "CLOOB: Modern Hopfield Networks with InfoLOOB Outperform CLIP",
    "abstract": "Comments: 15 pages (+ appendix); Blog: this https URL GitHub: this https URL",
    "descriptor": "\nComments: 15 pages (+ appendix); Blog: this https URL GitHub: this https URL\n",
    "authors": [
      "Andreas F\u00fcrst",
      "Elisabeth Rumetshofer",
      "Johannes Lehner",
      "Viet Tran",
      "Fei Tang",
      "Hubert Ramsauer",
      "David Kreil",
      "Michael Kopp",
      "G\u00fcnter Klambauer",
      "Angela Bitto-Nemling",
      "Sepp Hochreiter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11316"
  },
  {
    "id": "arXiv:2110.11876",
    "title": "Tight and Robust Private Mean Estimation with Few Users",
    "abstract": "Comments: 41 pages. To appear in the International Conference on Machine Learning (ICML), 2022",
    "descriptor": "\nComments: 41 pages. To appear in the International Conference on Machine Learning (ICML), 2022\n",
    "authors": [
      "Hossein Esfandiari",
      "Vahab Mirrokni",
      "Shyam Narayanan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2110.11876"
  },
  {
    "id": "arXiv:2110.12699",
    "title": "Temporal Team Semantics Revisited",
    "abstract": "Comments: accepted version to LICS conference with additional appendix",
    "descriptor": "\nComments: accepted version to LICS conference with additional appendix\n",
    "authors": [
      "Jens Oliver Gutsfeld",
      "Arne Meier",
      "Christoph Ohrem",
      "Jonni Virtema"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2110.12699"
  },
  {
    "id": "arXiv:2110.13521",
    "title": "Machine learning spectral functions in lattice QCD",
    "abstract": "Comments: 20 pages, 12 figures. error analyses corrected and dependences on hyperparameters of the SVAE added",
    "descriptor": "\nComments: 20 pages, 12 figures. error analyses corrected and dependences on hyperparameters of the SVAE added\n",
    "authors": [
      "S.-Y. Chen",
      "H.-T. Ding",
      "F.-Y. Liu",
      "G. Papp",
      "C.-B. Yang"
    ],
    "subjectives": [
      "High Energy Physics - Lattice (hep-lat)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Phenomenology (hep-ph)",
      "High Energy Physics - Theory (hep-th)",
      "Nuclear Theory (nucl-th)"
    ],
    "url": "https://arxiv.org/abs/2110.13521"
  },
  {
    "id": "arXiv:2110.14495",
    "title": "Convergence of Restricted Additive Schwarz with impedance transmission  conditions for discretised Helmholtz problems",
    "abstract": "Comments: 34 pages, 2 figures",
    "descriptor": "\nComments: 34 pages, 2 figures\n",
    "authors": [
      "Shihua Gong",
      "Ivan G. Graham",
      "Euan A. Spence"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.14495"
  },
  {
    "id": "arXiv:2110.14768",
    "title": "Distributed Asynchronous Games With Causal Memory are Undecidable",
    "abstract": "Distributed Asynchronous Games With Causal Memory are Undecidable",
    "descriptor": "",
    "authors": [
      "Hugo Gimbert"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.14768"
  },
  {
    "id": "arXiv:2111.02644",
    "title": "A Concentration Bound for LSPE($\u03bb$)",
    "abstract": "Comments: 17 pages, submitted to Elsevier System & Control Letters",
    "descriptor": "\nComments: 17 pages, submitted to Elsevier System & Control Letters\n",
    "authors": [
      "Vivek S. Borkar",
      "Siddharth Chandak",
      "Harsh Dolhare"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.02644"
  },
  {
    "id": "arXiv:2111.03169",
    "title": "Hard Negative Sampling via Regularized Optimal Transport for Contrastive  Representation Learning",
    "abstract": "Comments: Minor changes - fixing typos, minor rephrasing in abstract and introduction",
    "descriptor": "\nComments: Minor changes - fixing typos, minor rephrasing in abstract and introduction\n",
    "authors": [
      "Ruijie Jiang",
      "Prakash Ishwar",
      "Shuchin Aeron"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2111.03169"
  },
  {
    "id": "arXiv:2111.03354",
    "title": "Programming with union, intersection, and negation types",
    "abstract": "Programming with union, intersection, and negation types",
    "descriptor": "",
    "authors": [
      "Giuseppe Castagna"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2111.03354"
  },
  {
    "id": "arXiv:2111.03917",
    "title": "Optimal and Efficient Dynamic Regret Algorithms for Non-Stationary  Dueling Bandits",
    "abstract": "Comments: Accepted to International Conference on Machine Learning (ICML), 2022 [both authors contributed equally]",
    "descriptor": "\nComments: Accepted to International Conference on Machine Learning (ICML), 2022 [both authors contributed equally]\n",
    "authors": [
      "Aadirupa Saha",
      "Shubham Gupta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.03917"
  },
  {
    "id": "arXiv:2111.04698",
    "title": "Interactive Inverse Reinforcement Learning for Cooperative Games",
    "abstract": "Comments: ICML 2022",
    "descriptor": "\nComments: ICML 2022\n",
    "authors": [
      "Thomas Kleine Buening",
      "Anne-Marie George",
      "Christos Dimitrakakis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2111.04698"
  },
  {
    "id": "arXiv:2111.06338",
    "title": "On the parameterized complexity of Compact Set Packing",
    "abstract": "Comments: 22 pages",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Ameet Gadekar"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2111.06338"
  },
  {
    "id": "arXiv:2111.07993",
    "title": "CoLLIE: Continual Learning of Language Grounding from Language-Image  Embeddings",
    "abstract": "Comments: Updated version with more details, submitted to Journal of Artificial Intelligence Research (JAIR)",
    "descriptor": "\nComments: Updated version with more details, submitted to Journal of Artificial Intelligence Research (JAIR)\n",
    "authors": [
      "Gabriel Skantze",
      "Bram Willemsen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.07993"
  },
  {
    "id": "arXiv:2111.09571",
    "title": "Robust Person Re-identification with Multi-Modal Joint Defence",
    "abstract": "Comments: Accepted by CVPR2022 Workshops (this https URL)",
    "descriptor": "\nComments: Accepted by CVPR2022 Workshops (this https URL)\n",
    "authors": [
      "Yunpeng Gong",
      "Lifei Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.09571"
  },
  {
    "id": "arXiv:2111.10854",
    "title": "XnODR and XnIDR: Two Accurate and Fast Fully Connected Layers For  Convolutional Neural Networks",
    "abstract": "Comments: 17 pages, 9 figures, 10 tables",
    "descriptor": "\nComments: 17 pages, 9 figures, 10 tables\n",
    "authors": [
      "Jian Sun",
      "Ali Pourramezan Fard",
      "Mohammad H. Mahoor"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2111.10854"
  },
  {
    "id": "arXiv:2111.11178",
    "title": "Anti-Jamming Games in Multi-Band Wireless Ad Hoc Networks",
    "abstract": "Comments: This manuscript was submitted to IEEE Transactions on Information Forensics and Security and a short version was submitted to IEEE GLOBECOM 2022 Figures 3 and 6 are revised from version 2",
    "descriptor": "\nComments: This manuscript was submitted to IEEE Transactions on Information Forensics and Security and a short version was submitted to IEEE GLOBECOM 2022 Figures 3 and 6 are revised from version 2\n",
    "authors": [
      "Hyeon-Seong Im",
      "Si-Hyeon Lee"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.11178"
  },
  {
    "id": "arXiv:2111.11532",
    "title": "The Complexity of Conjunctive Queries with Degree 2",
    "abstract": "The Complexity of Conjunctive Queries with Degree 2",
    "descriptor": "",
    "authors": [
      "Matthias Lanzinger"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2111.11532"
  },
  {
    "id": "arXiv:2111.12316",
    "title": "A note on stabilizing reinforcement learning",
    "abstract": "A note on stabilizing reinforcement learning",
    "descriptor": "",
    "authors": [
      "Pavel Osinenko",
      "Grigory Yaremenko",
      "Ilya Osokin"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.12316"
  },
  {
    "id": "arXiv:2111.12679",
    "title": "On the (In)Tractability of Reinforcement Learning for LTL Objectives",
    "abstract": "On the (In)Tractability of Reinforcement Learning for LTL Objectives",
    "descriptor": "",
    "authors": [
      "Cambridge Yang",
      "Michael Littman",
      "Michael Carbin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12679"
  },
  {
    "id": "arXiv:2111.12996",
    "title": "Generalizing electrocardiogram delineation -- Training convolutional  neural networks with synthetic data augmentation",
    "abstract": "Generalizing electrocardiogram delineation -- Training convolutional  neural networks with synthetic data augmentation",
    "descriptor": "",
    "authors": [
      "Guillermo Jimenez-Perez",
      "Juan Acosta",
      "Alejandro Alcaine",
      "Oscar Camara"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.12996"
  },
  {
    "id": "arXiv:2112.02017",
    "title": "Dynamic Bayesian Network Modelling of User Affect and Perceptions of a  Teleoperated Robot Coach during Longitudinal Mindfulness Training",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Indu P. Bodala",
      "Hatice Gunes"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.02017"
  },
  {
    "id": "arXiv:2112.02456",
    "title": "Theoretically Guaranteed Online Workload Dispatching for Deadline-Aware  Multi-Server Jobs",
    "abstract": "Theoretically Guaranteed Online Workload Dispatching for Deadline-Aware  Multi-Server Jobs",
    "descriptor": "",
    "authors": [
      "Hailiang Zhao",
      "Shuiguang Deng",
      "Jianwei Yin",
      "Schahram Dustdar",
      "Albert Y. Zomaya"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.02456"
  },
  {
    "id": "arXiv:2112.02604",
    "title": "PSI: A Pedestrian Behavior Dataset for Socially Intelligent Autonomous  Car",
    "abstract": "PSI: A Pedestrian Behavior Dataset for Socially Intelligent Autonomous  Car",
    "descriptor": "",
    "authors": [
      "Tina Chen",
      "Taotao Jing",
      "Renran Tian",
      "Yaobin Chen",
      "Joshua Domeyer",
      "Heishiro Toyoda",
      "Rini Sherony",
      "Zhengming Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.02604"
  },
  {
    "id": "arXiv:2112.03358",
    "title": "Associative Memories Using Complex-Valued Hopfield Networks Based on  Spin-Torque Oscillator Arrays",
    "abstract": "Comments: 18 pages, 7 figures",
    "descriptor": "\nComments: 18 pages, 7 figures\n",
    "authors": [
      "Nitin Prasad",
      "Prashansa Mukim",
      "Advait Madhavan",
      "Mark D. Stiles"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.03358"
  },
  {
    "id": "arXiv:2112.03868",
    "title": "EmTract: Investor Emotions and Market Behavior",
    "abstract": "Comments: Substantial changes to the project",
    "descriptor": "\nComments: Substantial changes to the project\n",
    "authors": [
      "Domonkos Vamossy",
      "Rolf Skog"
    ],
    "subjectives": [
      "Pricing of Securities (q-fin.PR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.03868"
  },
  {
    "id": "arXiv:2112.04145",
    "title": "A Review for Deep Reinforcement Learning in Atari:Benchmarks,  Challenges, and Solutions",
    "abstract": "Comments: AAAI-22 Workshop on Reinforcement Learning in Games",
    "descriptor": "\nComments: AAAI-22 Workshop on Reinforcement Learning in Games\n",
    "authors": [
      "Jiajun Fan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.04145"
  },
  {
    "id": "arXiv:2112.04319",
    "title": "SCR: Training Graph Neural Networks with Consistency Regularization",
    "abstract": "SCR: Training Graph Neural Networks with Consistency Regularization",
    "descriptor": "",
    "authors": [
      "Chenhui Zhang",
      "Yufei He",
      "Yukuo Cen",
      "Zhenyu Hou",
      "Wenzheng Feng",
      "Yuxiao Dong",
      "Xu Cheng",
      "Hongyun Cai",
      "Feng He",
      "Jie Tang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.04319"
  },
  {
    "id": "arXiv:2112.07955",
    "title": "Channel Parameter Estimation in the Presence of Phase Noise Based on  Maximum Correntropy Criterion",
    "abstract": "Comments: We will upload a more concise version of the article at a later stage",
    "descriptor": "\nComments: We will upload a more concise version of the article at a later stage\n",
    "authors": [
      "Amir Alizadeh",
      "Ghosheh Abed Hodtani"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.07955"
  },
  {
    "id": "arXiv:2112.08357",
    "title": "Design Challenges for a Multi-Perspective Search Engine",
    "abstract": "Comments: Findings of NAACL 2022 (Theme Track: Human-Centered Natural Language Processing)",
    "descriptor": "\nComments: Findings of NAACL 2022 (Theme Track: Human-Centered Natural Language Processing)\n",
    "authors": [
      "Sihao Chen",
      "Siyi Liu",
      "Xander Uyttendaele",
      "Yi Zhang",
      "William Bruno",
      "Dan Roth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.08357"
  },
  {
    "id": "arXiv:2112.08879",
    "title": "Looking Outside the Box to Ground Language in 3D Scenes",
    "abstract": "Comments: First two authors contributed equally; changelog: reduced pdf size; minor GT eval change",
    "descriptor": "\nComments: First two authors contributed equally; changelog: reduced pdf size; minor GT eval change\n",
    "authors": [
      "Ayush Jain",
      "Nikolaos Gkanatsios",
      "Ishita Mediratta",
      "Katerina Fragkiadaki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08879"
  },
  {
    "id": "arXiv:2112.11313",
    "title": "On the Adversarial Robustness of Causal Algorithmic Recourse",
    "abstract": "Comments: ICML 2022",
    "descriptor": "\nComments: ICML 2022\n",
    "authors": [
      "Ricardo Dominguez-Olmedo",
      "Amir-Hossein Karimi",
      "Bernhard Sch\u00f6lkopf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.11313"
  },
  {
    "id": "arXiv:2112.11329",
    "title": "Multispectral image fusion by super pixel statistics",
    "abstract": "Multispectral image fusion by super pixel statistics",
    "descriptor": "",
    "authors": [
      "Nati Ofir"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.11329"
  },
  {
    "id": "arXiv:2112.12376",
    "title": "Revisiting and Advancing Fast Adversarial Training Through The Lens of  Bi-Level Optimization",
    "abstract": "Revisiting and Advancing Fast Adversarial Training Through The Lens of  Bi-Level Optimization",
    "descriptor": "",
    "authors": [
      "Yihua Zhang",
      "Guanhua Zhang",
      "Prashant Khanduri",
      "Mingyi Hong",
      "Shiyu Chang",
      "Sijia Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12376"
  },
  {
    "id": "arXiv:2112.15089",
    "title": "Causal Attention for Interpretable and Generalizable Graph  Classification",
    "abstract": "Comments: Accepted to KDD 2022",
    "descriptor": "\nComments: Accepted to KDD 2022\n",
    "authors": [
      "Yongduo Sui",
      "Xiang Wang",
      "Jiancan Wu",
      "Min Lin",
      "Xiangnan He",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.15089"
  },
  {
    "id": "arXiv:2112.15280",
    "title": "What is Event Knowledge Graph: A Survey",
    "abstract": "Comments: Accepted to TKDE 2022",
    "descriptor": "\nComments: Accepted to TKDE 2022\n",
    "authors": [
      "Saiping Guan",
      "Xueqi Cheng",
      "Long Bai",
      "Fujun Zhang",
      "Zixuan Li",
      "Yutao Zeng",
      "Xiaolong Jin",
      "Jiafeng Guo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.15280"
  },
  {
    "id": "arXiv:2201.01014",
    "title": "MoCoPnet: Exploring Local Motion and Contrast Priors for Infrared Small  Target Super-Resolution",
    "abstract": "MoCoPnet: Exploring Local Motion and Contrast Priors for Infrared Small  Target Super-Resolution",
    "descriptor": "",
    "authors": [
      "Xinyi Ying",
      "Yingqian Wang",
      "Longguang Wang",
      "Weidong Sheng",
      "Li Liu",
      "Zaiping Lin",
      "Shilin Zhou"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.01014"
  },
  {
    "id": "arXiv:2201.01873",
    "title": "NeuralMLS: Geometry-Aware Control Point Deformation",
    "abstract": "Comments: Eurographics 2022 Short Papers",
    "descriptor": "\nComments: Eurographics 2022 Short Papers\n",
    "authors": [
      "Meitar Shechter",
      "Rana Hanocka",
      "Gal Metzer",
      "Raja Giryes",
      "Daniel Cohen-Or"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.01873"
  },
  {
    "id": "arXiv:2201.02401",
    "title": "Tight Fine-Grained Bounds for Direct Access on Join Queries",
    "abstract": "Tight Fine-Grained Bounds for Direct Access on Join Queries",
    "descriptor": "",
    "authors": [
      "Karl Bringmann",
      "Nofar Carmeli",
      "Stefan Mengel"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2201.02401"
  },
  {
    "id": "arXiv:2201.03494",
    "title": "High-frequency limit of the inverse scattering problem: asymptotic  convergence from inverse Helmholtz to inverse Liouville",
    "abstract": "High-frequency limit of the inverse scattering problem: asymptotic  convergence from inverse Helmholtz to inverse Liouville",
    "descriptor": "",
    "authors": [
      "Shi Chen",
      "Zhiyan Ding",
      "Qin Li",
      "Leonardo Zepeda-N\u00fa\u00f1ez"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2201.03494"
  },
  {
    "id": "arXiv:2201.05812",
    "title": "ChevOpt: Continuous-time State Estimation by Chebyshev Polynomial  Optimization",
    "abstract": "Comments: 12 pages, 16 figures",
    "descriptor": "\nComments: 12 pages, 16 figures\n",
    "authors": [
      "Maoran Zhu",
      "Yuanxin Wu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2201.05812"
  },
  {
    "id": "arXiv:2201.08924",
    "title": "Nearest Class-Center Simplification through Intermediate Layers",
    "abstract": "Nearest Class-Center Simplification through Intermediate Layers",
    "descriptor": "",
    "authors": [
      "Ido Ben-Shaul",
      "Shai Dekel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08924"
  },
  {
    "id": "arXiv:2201.09060",
    "title": "Solvability of orbit-finite systems of linear equations",
    "abstract": "Solvability of orbit-finite systems of linear equations",
    "descriptor": "",
    "authors": [
      "Arka Ghosh",
      "Piotr Hofman",
      "S\u0142awomir Lasota"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.09060"
  },
  {
    "id": "arXiv:2201.09372",
    "title": "Prioritizing municipal lead mitigation projects as a relaxed knapsack  optimization: a method and case study",
    "abstract": "Comments: 16 pages, 6 figures; revise and extend",
    "descriptor": "\nComments: 16 pages, 6 figures; revise and extend\n",
    "authors": [
      "Isaac Slavitt"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Optimization and Control (math.OC)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2201.09372"
  },
  {
    "id": "arXiv:2201.09846",
    "title": "A Novel Mix-normalization Method for Generalizable Multi-source Person  Re-identification",
    "abstract": "Comments: Accepted by IEEE Transactions on Multimedia (TMM)",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Multimedia (TMM)\n",
    "authors": [
      "Lei Qi",
      "Lei Wang",
      "Yinghuan Shi",
      "Xin Geng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.09846"
  },
  {
    "id": "arXiv:2201.11921",
    "title": "Adaptive Best-of-Both-Worlds Algorithm for Heavy-Tailed Multi-Armed  Bandits",
    "abstract": "Adaptive Best-of-Both-Worlds Algorithm for Heavy-Tailed Multi-Armed  Bandits",
    "descriptor": "",
    "authors": [
      "Jiatai Huang",
      "Yan Dai",
      "Longbo Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11921"
  },
  {
    "id": "arXiv:2201.12155",
    "title": "Reducing language context confusion for end-to-end code-switching  automatic speech recognition",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2010.14798,the paper has been submitted to Insterspeech 2022",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2010.14798,the paper has been submitted to Insterspeech 2022\n",
    "authors": [
      "Shuai Zhang",
      "Jiangyan Yi",
      "Zhengkun Tian",
      "Jianhua Tao",
      "Yu Ting Yeung",
      "Liqun Deng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2201.12155"
  },
  {
    "id": "arXiv:2201.12226",
    "title": "Differential Polarization Shift Keying Through Reconfigurable  Intelligent Surfaces",
    "abstract": "Comments: 5 pages, 5 figures, submitted to IEEE Wireless Communication Letters",
    "descriptor": "\nComments: 5 pages, 5 figures, submitted to IEEE Wireless Communication Letters\n",
    "authors": [
      "Emad Ibrahim",
      "Rickard Nilsson",
      "Jaap van de Beek"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2201.12226"
  },
  {
    "id": "arXiv:2201.12518",
    "title": "Zeroth-Order Actor-Critic",
    "abstract": "Zeroth-Order Actor-Critic",
    "descriptor": "",
    "authors": [
      "Yuheng Lei",
      "Jianyu Chen",
      "Shengbo Eben Li",
      "Sifa Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.12518"
  },
  {
    "id": "arXiv:2201.12738",
    "title": "AutoSNN: Towards Energy-Efficient Spiking Neural Networks",
    "abstract": "Comments: Accepted in ICML22",
    "descriptor": "\nComments: Accepted in ICML22\n",
    "authors": [
      "Byunggook Na",
      "Jisoo Mok",
      "Seongsik Park",
      "Dongjin Lee",
      "Hyeokjun Choe",
      "Sungroh Yoon"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12738"
  },
  {
    "id": "arXiv:2201.12771",
    "title": "Self-Supervised Moving Vehicle Detection from Audio-Visual Cues",
    "abstract": "Comments: 8 pages, 6 figures",
    "descriptor": "\nComments: 8 pages, 6 figures\n",
    "authors": [
      "Jannik Z\u00fcrn",
      "Wolfram Burgard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.12771"
  },
  {
    "id": "arXiv:2201.12904",
    "title": "COIN++: Neural Compression Across Modalities",
    "abstract": "Comments: Added audio experiments, additional references and open sourced code",
    "descriptor": "\nComments: Added audio experiments, additional references and open sourced code\n",
    "authors": [
      "Emilien Dupont",
      "Hrushikesh Loya",
      "Milad Alizadeh",
      "Adam Goli\u0144ski",
      "Yee Whye Teh",
      "Arnaud Doucet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.12904"
  },
  {
    "id": "arXiv:2201.12965",
    "title": "Inverse design of photonic devices with strict foundry fabrication  constraints",
    "abstract": "Comments: 16 pages, 17 figures",
    "descriptor": "\nComments: 16 pages, 17 figures\n",
    "authors": [
      "Martin F. Schubert",
      "Alfred K. C. Cheung",
      "Ian A. D. Williamson",
      "Aleksandra Spyra",
      "David H. Alexander"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2201.12965"
  },
  {
    "id": "arXiv:2201.13229",
    "title": "Network-level Safety Metrics for Overall Traffic Safety Assessment: A  Case Study",
    "abstract": "Network-level Safety Metrics for Overall Traffic Safety Assessment: A  Case Study",
    "descriptor": "",
    "authors": [
      "Xiwen Chen",
      "Hao Wang",
      "Abolfazl Razi",
      "Brendan Russo",
      "Jason Pacheco",
      "John Roberts",
      "Jeffrey Wishart",
      "Larry Head",
      "Alonso Granados Baca"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2201.13229"
  },
  {
    "id": "arXiv:2202.00478",
    "title": "NeuraHealth: An Automated Screening Pipeline to Detect Undiagnosed  Cognitive Impairment in Electronic Health Records with Deep Learning and  Natural Language Processing",
    "abstract": "NeuraHealth: An Automated Screening Pipeline to Detect Undiagnosed  Cognitive Impairment in Electronic Health Records with Deep Learning and  Natural Language Processing",
    "descriptor": "",
    "authors": [
      "Tanish Tyagi",
      "Colin G. Magdamo",
      "Ayush Noori",
      "Zhaozhi Li",
      "Xiao Liu",
      "Mayuresh Deodhar",
      "Zhuoqiao Hong",
      "Wendong Ge",
      "Elissa M. Ye",
      "Yi-han Sheu",
      "Haitham Alabsi",
      "Laura Brenner",
      "Gregory K. Robbins",
      "Sahar Zafar",
      "Nicole Benson",
      "Lidia Moura",
      "John Hsu",
      "Alberto Serrano-Pozo",
      "Dimitry Prokopenko",
      "Rudolph E. Tanzi",
      "Bradley T.Hyman",
      "Deborah Blacker",
      "Shibani S. Mukerji",
      "M. Brandon Westover",
      "Sudeshna Das"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.00478"
  },
  {
    "id": "arXiv:2202.00836",
    "title": "On-Sensor Binarized Fully Convolutional Neural Network with A Pixel  Processor Array",
    "abstract": "Comments: lack of experiments for method validation",
    "descriptor": "\nComments: lack of experiments for method validation\n",
    "authors": [
      "Yanan Liu",
      "Laurie Bose",
      "Yao Lu",
      "Piotr Dudek",
      "Walterio Mayol-Cuevas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Emerging Technologies (cs.ET)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.00836"
  },
  {
    "id": "arXiv:2202.01147",
    "title": "Improving Screening Processes via Calibrated Subset Selection",
    "abstract": "Comments: International Conference on Machine Learning (ICML) 2022",
    "descriptor": "\nComments: International Conference on Machine Learning (ICML) 2022\n",
    "authors": [
      "Lequn Wang",
      "Thorsten Joachims",
      "Manuel Gomez Rodriguez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.01147"
  },
  {
    "id": "arXiv:2202.01288",
    "title": "Imitation Learning by Estimating Expertise of Demonstrators",
    "abstract": "Comments: ICML 2022. 17 pages, 4 figures",
    "descriptor": "\nComments: ICML 2022. 17 pages, 4 figures\n",
    "authors": [
      "Mark Beliaev",
      "Andy Shih",
      "Stefano Ermon",
      "Dorsa Sadigh",
      "Ramtin Pedarsani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01288"
  },
  {
    "id": "arXiv:2202.01289",
    "title": "Systems Mining with Heraklit: The Next Step",
    "abstract": "Comments: 16 pages, 18 figures, author prepared version of final manuscript accepted at BPM22 Forum",
    "descriptor": "\nComments: 16 pages, 18 figures, author prepared version of final manuscript accepted at BPM22 Forum\n",
    "authors": [
      "Peter Fettke",
      "Wolfgang Reisig"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2202.01289"
  },
  {
    "id": "arXiv:2202.01563",
    "title": "On the Number of Graphs with a Given Histogram",
    "abstract": "Comments: 34 pages",
    "descriptor": "\nComments: 34 pages\n",
    "authors": [
      "Shahar Stein Ioushua",
      "Ofer Shayevitz"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.01563"
  },
  {
    "id": "arXiv:2202.02396",
    "title": "A Temporal-Difference Approach to Policy Gradient Estimation",
    "abstract": "A Temporal-Difference Approach to Policy Gradient Estimation",
    "descriptor": "",
    "authors": [
      "Samuele Tosatto",
      "Andrew Patterson",
      "Martha White",
      "A. Rupam Mahmood"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02396"
  },
  {
    "id": "arXiv:2202.02549",
    "title": "Solution of a Practical Vehicle Routing Problem for Monitoring Water  Distribution Networks",
    "abstract": "Solution of a Practical Vehicle Routing Problem for Monitoring Water  Distribution Networks",
    "descriptor": "",
    "authors": [
      "Reza Atefi",
      "Manuel Iori",
      "Majid Salari",
      "Dario Vezzali"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2202.02549"
  },
  {
    "id": "arXiv:2202.03036",
    "title": "Structure-Aware Transformer for Graph Representation Learning",
    "abstract": "Comments: To appear in ICML 2022",
    "descriptor": "\nComments: To appear in ICML 2022\n",
    "authors": [
      "Dexiong Chen",
      "Leslie O'Bray",
      "Karsten Borgwardt"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03036"
  },
  {
    "id": "arXiv:2202.03377",
    "title": "Benchmarking and Analyzing Point Cloud Classification under Corruptions",
    "abstract": "Comments: ICML 2022; Code and dataset are available at this https URL",
    "descriptor": "\nComments: ICML 2022; Code and dataset are available at this https URL\n",
    "authors": [
      "Jiawei Ren",
      "Liang Pan",
      "Ziwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03377"
  },
  {
    "id": "arXiv:2202.03525",
    "title": "Nesterov Accelerated Shuffling Gradient Method for Convex Optimization",
    "abstract": "Nesterov Accelerated Shuffling Gradient Method for Convex Optimization",
    "descriptor": "",
    "authors": [
      "Trang H. Tran",
      "Katya Scheinberg",
      "Lam M. Nguyen"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.03525"
  },
  {
    "id": "arXiv:2202.03618",
    "title": "On Unbalanced Optimal Transport: Gradient Methods, Sparsity and  Approximation Error",
    "abstract": "On Unbalanced Optimal Transport: Gradient Methods, Sparsity and  Approximation Error",
    "descriptor": "",
    "authors": [
      "Quang Minh Nguyen",
      "Hoang H. Nguyen",
      "Yi Zhou",
      "Lam M. Nguyen"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03618"
  },
  {
    "id": "arXiv:2202.04010",
    "title": "Multilevel Binary Polar-Coded Modulation Achieving the Capacity of  Asymmetric Channels",
    "abstract": "Comments: 6 pages, 4 figures; to be presented at ISIT 2022",
    "descriptor": "\nComments: 6 pages, 4 figures; to be presented at ISIT 2022\n",
    "authors": [
      "Constantin Runge",
      "Thomas Wiegart",
      "Diego Lentner",
      "Tobias Prinz"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.04010"
  },
  {
    "id": "arXiv:2202.04610",
    "title": "Anti-windup-like Compensator Synthesis for Discrete-Time Quantized  Control Systems",
    "abstract": "Comments: V1 is submitted for presentation at the 10th IFAC Symposium on Robust Control Design ROCOND 2022. V2 and V3 fix some minor oversights",
    "descriptor": "\nComments: V1 is submitted for presentation at the 10th IFAC Symposium on Robust Control Design ROCOND 2022. V2 and V3 fix some minor oversights\n",
    "authors": [
      "Samer AlSamadi",
      "Francesco Ferrante",
      "Sophie Tarbouriech"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.04610"
  },
  {
    "id": "arXiv:2202.05167",
    "title": "Class Distance Weighted Cross-Entropy Loss for Ulcerative Colitis  Severity Estimation",
    "abstract": "Comments: 26th UK Conference on Medical Image Understanding and Analysis. 15 pages, 5 figures",
    "descriptor": "\nComments: 26th UK Conference on Medical Image Understanding and Analysis. 15 pages, 5 figures\n",
    "authors": [
      "Gorkem Polat",
      "Ilkay Ergenc",
      "Haluk Tarik Kani",
      "Yesim Ozen Alahdab",
      "Ozlen Atug",
      "Alptekin Temizel"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.05167"
  },
  {
    "id": "arXiv:2202.05448",
    "title": "Fast Rates in Pool-Based Batch Active Learning",
    "abstract": "Comments: This is an extended version of arXiv:2202.05448v1, which has title \"Achieving Minimax Rates in Pool-Based Batch Active Learning\" and was accepted by ICML 2022 this https URL",
    "descriptor": "\nComments: This is an extended version of arXiv:2202.05448v1, which has title \"Achieving Minimax Rates in Pool-Based Batch Active Learning\" and was accepted by ICML 2022 this https URL\n",
    "authors": [
      "Claudio Gentile",
      "Zhilei Wang",
      "Tong Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.05448"
  },
  {
    "id": "arXiv:2202.05510",
    "title": "Support Vectors and Gradient Dynamics of Single-Neuron ReLU Networks",
    "abstract": "Support Vectors and Gradient Dynamics of Single-Neuron ReLU Networks",
    "descriptor": "",
    "authors": [
      "Sangmin Lee",
      "Byeongsu Sim",
      "Jong Chul Ye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.05510"
  },
  {
    "id": "arXiv:2202.06505",
    "title": "Opinions Vary? Diagnosis First!",
    "abstract": "Opinions Vary? Diagnosis First!",
    "descriptor": "",
    "authors": [
      "Junde Wu",
      "Huihui Fang",
      "Dalu Yang",
      "Zhaowei Wang",
      "Wenshuo Zhou",
      "Fangxin Shang",
      "Yehui Yang",
      "Yanwu Xu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.06505"
  },
  {
    "id": "arXiv:2202.07094",
    "title": "Matching Tweets With Applicable Fact-Checks Across Languages",
    "abstract": "Comments: Accepted to De-Factify Workshop at AAAI 2022",
    "descriptor": "\nComments: Accepted to De-Factify Workshop at AAAI 2022\n",
    "authors": [
      "Ashkan Kazemi",
      "Zehua Li",
      "Ver\u00f3nica P\u00e9rez-Rosas",
      "Scott A. Hale",
      "Rada Mihalcea"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.07094"
  },
  {
    "id": "arXiv:2202.07106",
    "title": "Learning to Mitigate AI Collusion on Economic Platforms",
    "abstract": "Learning to Mitigate AI Collusion on Economic Platforms",
    "descriptor": "",
    "authors": [
      "Gianluca Brero",
      "Nicolas Lepore",
      "Eric Mibuari",
      "David C. Parkes"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.07106"
  },
  {
    "id": "arXiv:2202.07629",
    "title": "Deciding What is Good-for-MDPs",
    "abstract": "Comments: 21 pages (excluding references)",
    "descriptor": "\nComments: 21 pages (excluding references)\n",
    "authors": [
      "Sven Schewe",
      "Qiyi Tang",
      "Tansholpan Zhanabekova"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2202.07629"
  },
  {
    "id": "arXiv:2202.08232",
    "title": "Quantum Lazy Training",
    "abstract": "Comments: 18 pages, 7 figures + 5 page appendix (V2: Added a couple of remarks; V3: Fixed typo, updated figure and added URL of GitHub repository)",
    "descriptor": "\nComments: 18 pages, 7 figures + 5 page appendix (V2: Added a couple of remarks; V3: Fixed typo, updated figure and added URL of GitHub repository)\n",
    "authors": [
      "Erfan Abedi",
      "Salman Beigi",
      "Leila Taghavi"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08232"
  },
  {
    "id": "arXiv:2202.08836",
    "title": "Data-SUITE: Data-centric identification of in-distribution incongruous  examples",
    "abstract": "Comments: Presented at the International Conference on Machine Learning (ICML) 2022",
    "descriptor": "\nComments: Presented at the International Conference on Machine Learning (ICML) 2022\n",
    "authors": [
      "Nabeel Seedat",
      "Jonathan Crabb\u00e9",
      "Mihaela van der Schaar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.08836"
  },
  {
    "id": "arXiv:2202.09036",
    "title": "Adaptivity and Confounding in Multi-Armed Bandit Experiments",
    "abstract": "Adaptivity and Confounding in Multi-Armed Bandit Experiments",
    "descriptor": "",
    "authors": [
      "Chao Qin",
      "Daniel Russo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.09036"
  },
  {
    "id": "arXiv:2202.09989",
    "title": "Learning Low Degree Hypergraphs",
    "abstract": "Learning Low Degree Hypergraphs",
    "descriptor": "",
    "authors": [
      "Eric Balkanski",
      "Oussama Hanguir",
      "Shatian Wang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.09989"
  },
  {
    "id": "arXiv:2202.10603",
    "title": "Disentangling Light Fields for Super-Resolution and Disparity Estimation",
    "abstract": "Comments: Published on IEEE TPAMI. Project page: this https URL",
    "descriptor": "\nComments: Published on IEEE TPAMI. Project page: this https URL\n",
    "authors": [
      "Yingqian Wang",
      "Longguang Wang",
      "Gaochang Wu",
      "Jungang Yang",
      "Wei An",
      "Jingyi Yu",
      "Yulan Guo"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.10603"
  },
  {
    "id": "arXiv:2202.12186",
    "title": "Sequential asset ranking in nonstationary time series",
    "abstract": "Sequential asset ranking in nonstationary time series",
    "descriptor": "",
    "authors": [
      "Gabriel Borrageiro"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)",
      "Trading and Market Microstructure (q-fin.TR)"
    ],
    "url": "https://arxiv.org/abs/2202.12186"
  },
  {
    "id": "arXiv:2202.12394",
    "title": "Evaluation of the Gauss integral",
    "abstract": "Comments: 11 pages, 2 figures",
    "descriptor": "\nComments: 11 pages, 2 figures\n",
    "authors": [
      "Dmitri Martila",
      "Stefan Groote"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2202.12394"
  },
  {
    "id": "arXiv:2202.12598",
    "title": "Bridging the Gap Between Patient-specific and Patient-independent  Seizure Prediction via Knowledge Distillation",
    "abstract": "Bridging the Gap Between Patient-specific and Patient-independent  Seizure Prediction via Knowledge Distillation",
    "descriptor": "",
    "authors": [
      "Di Wu",
      "Jie Yang",
      "Mohamad Sawan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.12598"
  },
  {
    "id": "arXiv:2202.13062",
    "title": "Collision-free Path Planning on Arbitrary Optimization Criteria in the  Latent Space through cGANs",
    "abstract": "Comments: 8 pages, 6 figures. Submitted to RA-L (IEEE Robotics and Automation Letters) with IROS 2022 Option. An accompanying video is available at this https URL arXiv admin note: substantial text overlap with arXiv:2202.07203",
    "descriptor": "\nComments: 8 pages, 6 figures. Submitted to RA-L (IEEE Robotics and Automation Letters) with IROS 2022 Option. An accompanying video is available at this https URL arXiv admin note: substantial text overlap with arXiv:2202.07203\n",
    "authors": [
      "Tomoki Ando",
      "Hiroto Iino",
      "Hiroki Mori",
      "Ryota Torishima",
      "Kuniyuki Takahashi",
      "Shoichiro Yamaguchi",
      "Daisuke Okanohara",
      "Tetsuya Ogata"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.13062"
  },
  {
    "id": "arXiv:2202.13890",
    "title": "Pessimistic Q-Learning for Offline Reinforcement Learning: Towards  Optimal Sample Complexity",
    "abstract": "Comments: International Conference on Machine Learning (ICML), 2022",
    "descriptor": "\nComments: International Conference on Machine Learning (ICML), 2022\n",
    "authors": [
      "Laixi Shi",
      "Gen Li",
      "Yuting Wei",
      "Yuxin Chen",
      "Yuejie Chi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.13890"
  },
  {
    "id": "arXiv:2203.01786",
    "title": "Generative Modeling for Low Dimensional Speech Attributes with Neural  Spline Flows",
    "abstract": "Comments: 22 pages, 11 figures, 3 tables",
    "descriptor": "\nComments: 22 pages, 11 figures, 3 tables\n",
    "authors": [
      "Kevin J. Shih",
      "Rafael Valle",
      "Rohan Badlani",
      "Jo\u00e3o Felipe Santos",
      "Bryan Catanzaro"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.01786"
  },
  {
    "id": "arXiv:2203.02016",
    "title": "Interventions, Where and How? Experimental Design for Causal Models at  Scale",
    "abstract": "Interventions, Where and How? Experimental Design for Causal Models at  Scale",
    "descriptor": "",
    "authors": [
      "Panagiotis Tigas",
      "Yashas Annadani",
      "Andrew Jesson",
      "Bernhard Sch\u00f6lkopf",
      "Yarin Gal",
      "Stefan Bauer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.02016"
  },
  {
    "id": "arXiv:2203.02018",
    "title": "Zero-shot Transfer Learning on Heterogeneous Graphs via Knowledge  Transfer Networks",
    "abstract": "Zero-shot Transfer Learning on Heterogeneous Graphs via Knowledge  Transfer Networks",
    "descriptor": "",
    "authors": [
      "Minji Yoon",
      "John Palowitch",
      "Dustin Zelle",
      "Ziniu Hu",
      "Ruslan Salakhutdinov",
      "Bryan Perozzi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.02018"
  },
  {
    "id": "arXiv:2203.02195",
    "title": "Voice-Face Homogeneity Tells Deepfake",
    "abstract": "Comments: 13 pages for peer review. Code will be released at this https URL",
    "descriptor": "\nComments: 13 pages for peer review. Code will be released at this https URL\n",
    "authors": [
      "Harry Cheng",
      "Yangyang Guo",
      "Tianyi Wang",
      "Qi Li",
      "Xiaojun Chang",
      "Liqiang Nie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2203.02195"
  },
  {
    "id": "arXiv:2203.03054",
    "title": "Verification of Bitcoin Script in Agda using Weakest Preconditions for  Access Control",
    "abstract": "Comments: 27 pages",
    "descriptor": "\nComments: 27 pages\n",
    "authors": [
      "Fahad F. Alhabardi",
      "Arnold Beckmann",
      "Bogdan Lazar",
      "Anton Setzer"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)",
      "Cryptography and Security (cs.CR)",
      "Logic in Computer Science (cs.LO)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2203.03054"
  },
  {
    "id": "arXiv:2203.04860",
    "title": "PET: An Annotated Dataset for Process Extraction from Natural Language  Text",
    "abstract": "PET: An Annotated Dataset for Process Extraction from Natural Language  Text",
    "descriptor": "",
    "authors": [
      "Patrizio Bellan",
      "Han van der Aa",
      "Mauro Dragoni",
      "Chiara Ghidini",
      "Simone Paolo Ponzetto"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.04860"
  },
  {
    "id": "arXiv:2203.06803",
    "title": "Learning Markov Games with Adversarial Opponents: Efficient Algorithms  and Fundamental Limits",
    "abstract": "Comments: fix typos and add additional reference",
    "descriptor": "\nComments: fix typos and add additional reference\n",
    "authors": [
      "Qinghua Liu",
      "Yuanhao Wang",
      "Chi Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.06803"
  },
  {
    "id": "arXiv:2203.06865",
    "title": "Calibration of Derivative Pricing Models: a Multi-Agent Reinforcement  Learning Perspective",
    "abstract": "Calibration of Derivative Pricing Models: a Multi-Agent Reinforcement  Learning Perspective",
    "descriptor": "",
    "authors": [
      "Nelson Vadori"
    ],
    "subjectives": [
      "Mathematical Finance (q-fin.MF)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Computational Finance (q-fin.CP)"
    ],
    "url": "https://arxiv.org/abs/2203.06865"
  },
  {
    "id": "arXiv:2203.06925",
    "title": "WCL-BBCD: A Contrastive Learning and Knowledge Graph Approach to Named  Entity Recognition",
    "abstract": "WCL-BBCD: A Contrastive Learning and Knowledge Graph Approach to Named  Entity Recognition",
    "descriptor": "",
    "authors": [
      "Renjie Zhou",
      "Qiang Hu",
      "Jian Wan",
      "Jilin Zhang",
      "Qiang Liu",
      "Tianxiang Hu",
      "Jianjun Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.06925"
  },
  {
    "id": "arXiv:2203.08089",
    "title": "On Suspicious Coincidences and Pointwise Mutual Information",
    "abstract": "Comments: 8 pages, 1 figure",
    "descriptor": "\nComments: 8 pages, 1 figure\n",
    "authors": [
      "Christopher K. I. Williams"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.08089"
  },
  {
    "id": "arXiv:2203.08115",
    "title": "Analysis of the competition among viral strains using a temporal  interaction-driven contagion model",
    "abstract": "Analysis of the competition among viral strains using a temporal  interaction-driven contagion model",
    "descriptor": "",
    "authors": [
      "Alex Abbey",
      "Yuval Shahar",
      "Osnat Mokryn"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2203.08115"
  },
  {
    "id": "arXiv:2203.08775",
    "title": "Practical Conditional Neural Processes Via Tractable Dependent  Predictions",
    "abstract": "Comments: 23 pages; accepted to the 10th International Conference on Learning Representations (ICLR 2022)",
    "descriptor": "\nComments: 23 pages; accepted to the 10th International Conference on Learning Representations (ICLR 2022)\n",
    "authors": [
      "Stratis Markou",
      "James Requeima",
      "Wessel P. Bruinsma",
      "Anna Vaughan",
      "Richard E. Turner"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08775"
  },
  {
    "id": "arXiv:2203.10844",
    "title": "Data-Lean Evolutionary Reinforcement Learning by Multitasking with  Importance Sampling",
    "abstract": "Data-Lean Evolutionary Reinforcement Learning by Multitasking with  Importance Sampling",
    "descriptor": "",
    "authors": [
      "Nick Zhang",
      "Abhishek Gupta",
      "Zefeng Chen",
      "Yew-Soon Ong"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.10844"
  },
  {
    "id": "arXiv:2203.14009",
    "title": "Combining Evolution and Deep Reinforcement Learning for Policy Search: a  Survey",
    "abstract": "Combining Evolution and Deep Reinforcement Learning for Policy Search: a  Survey",
    "descriptor": "",
    "authors": [
      "Olivier Sigaud"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.14009"
  },
  {
    "id": "arXiv:2203.14822",
    "title": "Row monomial matrices and \u010cerny conjecture, short proof",
    "abstract": "Comments: errors in the proof",
    "descriptor": "\nComments: errors in the proof\n",
    "authors": [
      "A.N. Trahtman"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2203.14822"
  },
  {
    "id": "arXiv:2203.15089",
    "title": "Learning Optical Flow, Depth, and Scene Flow without Real-World Labels",
    "abstract": "Comments: Accepted to RA-L + ICRA 2022 (correct project page)",
    "descriptor": "\nComments: Accepted to RA-L + ICRA 2022 (correct project page)\n",
    "authors": [
      "Vitor Guizilini",
      "Kuan-Hui Lee",
      "Rares Ambrus",
      "Adrien Gaidon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15089"
  },
  {
    "id": "arXiv:2203.16578",
    "title": "Code Switched and Code Mixed Speech Recognition for Indic languages",
    "abstract": "Comments: This paper for submitted to Interspeech 2022",
    "descriptor": "\nComments: This paper for submitted to Interspeech 2022\n",
    "authors": [
      "Harveen Singh Chadha",
      "Priyanshi Shah",
      "Ankur Dhuriya",
      "Neeraj Chhimwal",
      "Anirudh Gupta",
      "Vivek Raghavan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.16578"
  },
  {
    "id": "arXiv:2203.16595",
    "title": "Improving Speech Recognition for Indic Languages using Language Model",
    "abstract": "Comments: This paper was submitted to Interspeech 2022",
    "descriptor": "\nComments: This paper was submitted to Interspeech 2022\n",
    "authors": [
      "Ankur Dhuriya",
      "Harveen Singh Chadha",
      "Anirudh Gupta",
      "Priyanshi Shah",
      "Neeraj Chhimwal",
      "Rishabh Gaur",
      "Vivek Raghavan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.16595"
  },
  {
    "id": "arXiv:2203.16601",
    "title": "Is Word Error Rate a good evaluation metric for Speech Recognition in  Indic Languages?",
    "abstract": "Comments: This paper was submitted to Interspeech 2022",
    "descriptor": "\nComments: This paper was submitted to Interspeech 2022\n",
    "authors": [
      "Priyanshi Shah",
      "Harveen Singh Chadha",
      "Anirudh Gupta",
      "Ankur Dhuriya",
      "Neeraj Chhimwal",
      "Rishabh Gaur",
      "Vivek Raghavan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.16601"
  },
  {
    "id": "arXiv:2203.17259",
    "title": "To ArXiv or not to ArXiv: A Study Quantifying Pros and Cons of Posting  Preprints Online",
    "abstract": "Comments: 17 pages, 3 figures",
    "descriptor": "\nComments: 17 pages, 3 figures\n",
    "authors": [
      "Charvi Rastogi",
      "Ivan Stelmakh",
      "Xinwei Shen",
      "Marina Meila",
      "Federico Echenique",
      "Shuchi Chawla",
      "Nihar B. Shah"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2203.17259"
  },
  {
    "id": "arXiv:2204.00142",
    "title": "Machine Learning Integrated with Model Predictive Control for Imitative  Optimal Control of Compression Ignition Engines",
    "abstract": "Comments: Submitted to Advances in Automotive Control - 10th AAC 2022",
    "descriptor": "\nComments: Submitted to Advances in Automotive Control - 10th AAC 2022\n",
    "authors": [
      "Armin Norouzi",
      "Saeid Shahpouri",
      "David Gordon",
      "Alexander Winkler",
      "Eugen Nuss",
      "and Dirk Abel",
      "Mahdi Shahbakhti",
      "Charles Robert Koch"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.00142"
  },
  {
    "id": "arXiv:2204.01209",
    "title": "EResFD: Rediscovery of the Effectiveness of Standard Convolution for  Lightweight Face Detection",
    "abstract": "EResFD: Rediscovery of the Effectiveness of Standard Convolution for  Lightweight Face Detection",
    "descriptor": "",
    "authors": [
      "Joonhyun Jeong",
      "Beomyoung Kim",
      "Joonsang Yu",
      "Youngjoon Yoo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.01209"
  },
  {
    "id": "arXiv:2204.01601",
    "title": "Towards Privacy-Preserving and Verifiable Federated Matrix Factorization",
    "abstract": "Comments: Accepted by Knowledge-Based Systems",
    "descriptor": "\nComments: Accepted by Knowledge-Based Systems\n",
    "authors": [
      "Xicheng Wan",
      "Yifeng Zheng",
      "Qun Li",
      "Anmin Fu",
      "Mang Su",
      "Yansong Gao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2204.01601"
  },
  {
    "id": "arXiv:2204.01694",
    "title": "\"This is my unicorn, Fluffy\": Personalizing frozen vision-language  representations",
    "abstract": "\"This is my unicorn, Fluffy\": Personalizing frozen vision-language  representations",
    "descriptor": "",
    "authors": [
      "Niv Cohen",
      "Rinon Gal",
      "Eli A. Meirom",
      "Gal Chechik",
      "Yuval Atzmon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.01694"
  },
  {
    "id": "arXiv:2204.01733",
    "title": "Transient motion classification through turbid volumes via parallelized  single-photon detection and deep contrastive embedding",
    "abstract": "Comments: Journal submission",
    "descriptor": "\nComments: Journal submission\n",
    "authors": [
      "Shiqi Xu",
      "Wenhui Liu",
      "Xi Yang",
      "Joakim J\u00f6nsson",
      "Ruobing Qian",
      "Paul McKee",
      "Kanghyun Kim",
      "Pavan Chandra Konda",
      "Kevin C. Zhou",
      "Lucas Krei\u00df",
      "Haoqian Wang",
      "Edouard Berrocal",
      "Scott Huettel",
      "Roarke Horstmeyer"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2204.01733"
  },
  {
    "id": "arXiv:2204.01784",
    "title": "Object Permanence Emerges in a Random Walk along Memory",
    "abstract": "Object Permanence Emerges in a Random Walk along Memory",
    "descriptor": "",
    "authors": [
      "Pavel Tokmakov",
      "Allan Jabri",
      "Jie Li",
      "Adrien Gaidon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.01784"
  },
  {
    "id": "arXiv:2204.02498",
    "title": "On the Sustainability of Lightweight Cryptography Based on PUFs  Implemented on NAND Flash Memories Using Programming Disturbances",
    "abstract": "Comments: This work was accepted for and presented at the Workshop on Sustainability in Security, Security for Sustainability, which took place on 18 March 2022 and was co-located with the 25th Design, Automation and Test in Europe Conference & Exhibition (DATE 2022)",
    "descriptor": "\nComments: This work was accepted for and presented at the Workshop on Sustainability in Security, Security for Sustainability, which took place on 18 March 2022 and was co-located with the 25th Design, Automation and Test in Europe Conference & Exhibition (DATE 2022)\n",
    "authors": [
      "Nikolaos Athanasios Anagnostopoulos",
      "Yufan Fan",
      "Muhammad Umair Saleem",
      "Nico Mexis",
      "Florian Frank",
      "Tolga Arul",
      "Stefan Katzenbeisser"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2204.02498"
  },
  {
    "id": "arXiv:2204.03465",
    "title": "BERTuit: Understanding Spanish language in Twitter through a native  transformer",
    "abstract": "Comments: Support: 1) BBVA FOUNDATION - CIVIC, 2) Spanish Ministry of Science and Innovation - FightDIS (PID2020-117263GB-100) and XAI-Disinfodemics (PLEC2021-007681), 3) Comunidad Autonoma de Madrid - S2018/TCS-4566, 4) European Comission - IBERIFIER (2020-EU-IA-0252), 5) Digital Future Society (Mobile World Capital Barcelona) - DisTrack, 6) UPM - Programa de Excelencia para el Profesorado Universitario",
    "descriptor": "\nComments: Support: 1) BBVA FOUNDATION - CIVIC, 2) Spanish Ministry of Science and Innovation - FightDIS (PID2020-117263GB-100) and XAI-Disinfodemics (PLEC2021-007681), 3) Comunidad Autonoma de Madrid - S2018/TCS-4566, 4) European Comission - IBERIFIER (2020-EU-IA-0252), 5) Digital Future Society (Mobile World Capital Barcelona) - DisTrack, 6) UPM - Programa de Excelencia para el Profesorado Universitario\n",
    "authors": [
      "Javier Huertas-Tato",
      "Alejandro Martin",
      "David Camacho"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.03465"
  },
  {
    "id": "arXiv:2204.05515",
    "title": "CLMLF:A Contrastive Learning and Multi-Layer Fusion Method for  Multimodal Sentiment Detection",
    "abstract": "Comments: Accepted to Findings of NAACL 2022",
    "descriptor": "\nComments: Accepted to Findings of NAACL 2022\n",
    "authors": [
      "Zhen Li",
      "Bing Xu",
      "Conghui Zhu",
      "Tiejun Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.05515"
  },
  {
    "id": "arXiv:2204.07616",
    "title": "Multi-Frame Self-Supervised Depth with Transformers",
    "abstract": "Comments: Accepted to CVPR 2022 (correct project page)",
    "descriptor": "\nComments: Accepted to CVPR 2022 (correct project page)\n",
    "authors": [
      "Vitor Guizilini",
      "Rares Ambrus",
      "Dian Chen",
      "Sergey Zakharov",
      "Adrien Gaidon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07616"
  },
  {
    "id": "arXiv:2204.07916",
    "title": "On representing the degree sequences of sublogarithmic-degree Wheeler  graphs",
    "abstract": "On representing the degree sequences of sublogarithmic-degree Wheeler  graphs",
    "descriptor": "",
    "authors": [
      "Travis Gagie"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.07916"
  },
  {
    "id": "arXiv:2204.08198",
    "title": "UTNLP at SemEval-2022 Task 6: A Comparative Analysis of Sarcasm  Detection using generative-based and mutation-based data augmentation",
    "abstract": "Comments: 6 pages, 2 figures, International Workshop on Semantic Evaluation co-located with NAACL",
    "descriptor": "\nComments: 6 pages, 2 figures, International Workshop on Semantic Evaluation co-located with NAACL\n",
    "authors": [
      "Amirhossein Abaskohi",
      "Arash Rasouli",
      "Tanin Zeraati",
      "Behnam Bahrak"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.08198"
  },
  {
    "id": "arXiv:2204.09664",
    "title": "Deep Learning meets Nonparametric Regression: Are Weight-Decayed DNNs  Locally Adaptive?",
    "abstract": "Comments: 32 pages, 6 figures",
    "descriptor": "\nComments: 32 pages, 6 figures\n",
    "authors": [
      "Kaiqi Zhang",
      "Yu-Xiang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.09664"
  },
  {
    "id": "arXiv:2204.09826",
    "title": "SimMC: Simple Masked Contrastive Learning of Skeleton Representations  for Unsupervised Person Re-Identification",
    "abstract": "Comments: Accepted at IJCAI 2022 Main Track. This version includes main paper (8 pages), Appendix A for Proof (4 pages), and Appendix B for Experiments (9 pages)",
    "descriptor": "\nComments: Accepted at IJCAI 2022 Main Track. This version includes main paper (8 pages), Appendix A for Proof (4 pages), and Appendix B for Experiments (9 pages)\n",
    "authors": [
      "Haocong Rao",
      "Chunyan Miao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.09826"
  },
  {
    "id": "arXiv:2204.09938",
    "title": "Ultra-marginal Feature Importance",
    "abstract": "Ultra-marginal Feature Importance",
    "descriptor": "",
    "authors": [
      "Joseph Janssen",
      "Vincent Guan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2204.09938"
  },
  {
    "id": "arXiv:2204.10962",
    "title": "Visual Attention Emerges from Recurrent Sparse Reconstruction",
    "abstract": "Comments: Released code: this https URL",
    "descriptor": "\nComments: Released code: this https URL\n",
    "authors": [
      "Baifeng Shi",
      "Yale Song",
      "Neel Joshi",
      "Trevor Darrell",
      "Xin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.10962"
  },
  {
    "id": "arXiv:2204.11167",
    "title": "RelViT: Concept-guided Vision Transformer for Visual Relational  Reasoning",
    "abstract": "Comments: ICLR 2022; Code: this https URL",
    "descriptor": "\nComments: ICLR 2022; Code: this https URL\n",
    "authors": [
      "Xiaojian Ma",
      "Weili Nie",
      "Zhiding Yu",
      "Huaizu Jiang",
      "Chaowei Xiao",
      "Yuke Zhu",
      "Song-Chun Zhu",
      "Anima Anandkumar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.11167"
  },
  {
    "id": "arXiv:2204.11832",
    "title": "Machine learning identification of organic compounds using visible light",
    "abstract": "Comments: 18 pages, 7 figures. Open database and python code. Version adds comparison with Raman classifiers (Table 1)",
    "descriptor": "\nComments: 18 pages, 7 figures. Open database and python code. Version adds comparison with Raman classifiers (Table 1)\n",
    "authors": [
      "Thulasi Bikku",
      "Rub\u00e9n A. Fritz",
      "Yamil J. Col\u00f3n",
      "Felipe Herrera"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2204.11832"
  },
  {
    "id": "arXiv:2204.11878",
    "title": "Comeback Kid: Resilience for Mixed-Critical Wireless Network Resource  Management",
    "abstract": "Comments: 16 pages, 13 figures. Submitted to IEEE for possible publication",
    "descriptor": "\nComments: 16 pages, 13 figures. Submitted to IEEE for possible publication\n",
    "authors": [
      "Robert-Jeron Reifert",
      "Stefan Roth",
      "Alaa Alameer Ahmad",
      "Aydin Sezgin"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.11878"
  },
  {
    "id": "arXiv:2205.00165",
    "title": "NeuralEF: Deconstructing Kernels by Deep Neural Networks",
    "abstract": "Comments: International Conference on Machine Learning (ICML), 2022",
    "descriptor": "\nComments: International Conference on Machine Learning (ICML), 2022\n",
    "authors": [
      "Zhijie Deng",
      "Jiaxin Shi",
      "Jun Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.00165"
  },
  {
    "id": "arXiv:2205.00498",
    "title": "CUP: Curriculum Learning based Prompt Tuning for Implicit Event Argument  Extraction",
    "abstract": "Comments: Accpeted by IJCAI 2022",
    "descriptor": "\nComments: Accpeted by IJCAI 2022\n",
    "authors": [
      "Jiaju Lin",
      "Qin Chen",
      "Jie Zhou",
      "Jian Jin",
      "Liang He"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.00498"
  },
  {
    "id": "arXiv:2205.00897",
    "title": "Fast Continuous and Integer L-shaped Heuristics Through Supervised  Learning",
    "abstract": "Comments: 22 pages",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Eric Larsen",
      "Emma Frejinger",
      "Bernard Gendron",
      "Andrea Lodi"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.00897"
  },
  {
    "id": "arXiv:2205.01240",
    "title": "Using Constraint Programming and Graph Representation Learning for  Generating Interpretable Cloud Security Policies",
    "abstract": "Comments: to be published in IJCAI/ECAI'22",
    "descriptor": "\nComments: to be published in IJCAI/ECAI'22\n",
    "authors": [
      "Mikhail Kazdagli",
      "Mohit Tiwari",
      "Akshat Kumar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.01240"
  },
  {
    "id": "arXiv:2205.01287",
    "title": "SemAttack: Natural Textual Attacks via Different Semantic Spaces",
    "abstract": "Comments: Published at Findings of NAACL 2022",
    "descriptor": "\nComments: Published at Findings of NAACL 2022\n",
    "authors": [
      "Boxin Wang",
      "Chejian Xu",
      "Xiangyu Liu",
      "Yu Cheng",
      "Bo Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.01287"
  },
  {
    "id": "arXiv:2205.03517",
    "title": "AdaptiveON: Adaptive Outdoor Navigation Method For Stable and Reliable  Actions",
    "abstract": "Comments: 16 pages",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Jing Liang",
      "Kasun Weerakoon",
      "Tianrui Guan",
      "Nare Karapetyan",
      "Dinesh Manocha"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.03517"
  },
  {
    "id": "arXiv:2205.03860",
    "title": "Zero and R2D2: A Large-scale Chinese Cross-modal Benchmark and A  Vision-Language Framework",
    "abstract": "Zero and R2D2: A Large-scale Chinese Cross-modal Benchmark and A  Vision-Language Framework",
    "descriptor": "",
    "authors": [
      "Chunyu Xie",
      "Heng Cai",
      "Jianfei Song",
      "Jincheng Li",
      "Fanjing Kong",
      "Xiaoyu Wu",
      "Henrique Morimitsu",
      "Lin Yao",
      "Dexin Wang",
      "Dawei Leng",
      "Xiangyang Ji",
      "Yafeng Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.03860"
  },
  {
    "id": "arXiv:2205.04282",
    "title": "Anatomy-aware Self-supervised Learning for Anomaly Detection in Chest  Radiographs",
    "abstract": "Anatomy-aware Self-supervised Learning for Anomaly Detection in Chest  Radiographs",
    "descriptor": "",
    "authors": [
      "Junya Sato",
      "Yuki Suzuki",
      "Tomohiro Wataya",
      "Daiki Nishigaki",
      "Kosuke Kita",
      "Kazuki Yamagata",
      "Noriyuki Tomiyama",
      "Shoji Kido"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.04282"
  },
  {
    "id": "arXiv:2205.04766",
    "title": "Explainable Deep Learning Methods in Medical Imaging Diagnosis: A Survey",
    "abstract": "Comments: Pre-print submitted to ACM CSUR",
    "descriptor": "\nComments: Pre-print submitted to ACM CSUR\n",
    "authors": [
      "Cristiano Patr\u00edcio",
      "Jo\u00e3o C. Neves",
      "Lu\u00eds F. Teixeira"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.04766"
  },
  {
    "id": "arXiv:2205.06116",
    "title": "How are Drivers' Stress Levels and Emotions Associated with the Driving  Context? A Naturalistic Study",
    "abstract": "How are Drivers' Stress Levels and Emotions Associated with the Driving  Context? A Naturalistic Study",
    "descriptor": "",
    "authors": [
      "Arash Tavakoli",
      "Nathan Lai",
      "Vahid Balali",
      "Arsalan Heydarian"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2205.06116"
  },
  {
    "id": "arXiv:2205.06482",
    "title": "Opportunistic Routing Aided Cooperative Communication Network with  Energy-Harvesting",
    "abstract": "Opportunistic Routing Aided Cooperative Communication Network with  Energy-Harvesting",
    "descriptor": "",
    "authors": [
      "Wannian An",
      "Chen Dong",
      "Xiaodong Xu",
      "Chao Xu",
      "Shujun Han",
      "Lei Teng"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.06482"
  },
  {
    "id": "arXiv:2205.07050",
    "title": "Generalization error bounds for DECONET: a deep unfolding network for  analysis Compressive Sensing",
    "abstract": "Generalization error bounds for DECONET: a deep unfolding network for  analysis Compressive Sensing",
    "descriptor": "",
    "authors": [
      "Vasiliki Kouni"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.07050"
  },
  {
    "id": "arXiv:2205.07146",
    "title": "Trajectory Inference via Mean-field Langevin in Path Space",
    "abstract": "Trajectory Inference via Mean-field Langevin in Path Space",
    "descriptor": "",
    "authors": [
      "L\u00e9na\u00efc Chizat",
      "Stephen Zhang",
      "Matthieu Heitz",
      "Geoffrey Schiebinger"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.07146"
  },
  {
    "id": "arXiv:2205.09162",
    "title": "An Invariant Matching Property for Distribution Generalization under  Intervened Response",
    "abstract": "Comments: Accepted to the European Signal Processing Conference (EUSIPCO) 2022",
    "descriptor": "\nComments: Accepted to the European Signal Processing Conference (EUSIPCO) 2022\n",
    "authors": [
      "Kang Du",
      "Yu Xiang"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09162"
  },
  {
    "id": "arXiv:2205.09680",
    "title": "Metrics of calibration for probabilistic predictions",
    "abstract": "Comments: 50 pages, 36 figures",
    "descriptor": "\nComments: 50 pages, 36 figures\n",
    "authors": [
      "Imanol Arrieta-Ibarra",
      "Paman Gujral",
      "Jonathan Tannen",
      "Mark Tygert",
      "Cherie Xu"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2205.09680"
  },
  {
    "id": "arXiv:2205.10362",
    "title": "FIND:Explainable Framework for Meta-learning",
    "abstract": "FIND:Explainable Framework for Meta-learning",
    "descriptor": "",
    "authors": [
      "Xinyue Shao",
      "Hongzhi Wang",
      "Xiao Zhu",
      "Feng Xiong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.10362"
  },
  {
    "id": "arXiv:2205.10456",
    "title": "PSO-Convolutional Neural Networks with Heterogeneous Learning Rate",
    "abstract": "Comments: 19 pages",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Nguyen Huu Phong",
      "Augusto Santos",
      "Bernardete Ribeiro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2205.10456"
  },
  {
    "id": "arXiv:2205.11044",
    "title": "Personalized Federated Learning with Server-Side Information",
    "abstract": "Personalized Federated Learning with Server-Side Information",
    "descriptor": "",
    "authors": [
      "Jaehun Song",
      "Min-hwan Oh",
      "Hyung-Sin Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.11044"
  },
  {
    "id": "arXiv:2205.11331",
    "title": "Networked Sensing with AI-Empowered Environment Estimation: Exploiting  Macro-Diversity and Array Gain in Perceptive Mobile Networks",
    "abstract": "Comments: This paper has been submitted to the IEEE for possible publication",
    "descriptor": "\nComments: This paper has been submitted to the IEEE for possible publication\n",
    "authors": [
      "Lei Xie",
      "S.H. Song"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.11331"
  },
  {
    "id": "arXiv:2205.11506",
    "title": "Orchestra: Unsupervised Federated Learning via Globally Consistent  Clustering",
    "abstract": "Comments: Camera-ready ICML, 2022",
    "descriptor": "\nComments: Camera-ready ICML, 2022\n",
    "authors": [
      "Ekdeep Singh Lubana",
      "Chi Ian Tang",
      "Fahim Kawsar",
      "Robert P. Dick",
      "Akhil Mathur"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.11506"
  },
  {
    "id": "arXiv:2205.11594",
    "title": "A framework for the development of intelligent mechanical systems",
    "abstract": "Comments: References added",
    "descriptor": "\nComments: References added\n",
    "authors": [
      "Wallace M. Bessa"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2205.11594"
  },
  {
    "id": "arXiv:2205.11664",
    "title": "Towards Model Generalization for Monocular 3D Object Detection",
    "abstract": "Comments: Fixed some mistakes",
    "descriptor": "\nComments: Fixed some mistakes\n",
    "authors": [
      "Zhenyu Li",
      "Zehui Chen",
      "Ang Li",
      "Liangji Fang",
      "Qinhong Jiang",
      "Xianming Liu",
      "Junjun Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.11664"
  },
  {
    "id": "arXiv:2205.11784",
    "title": "LOCUS 2.0: Robust and Computationally Efficient Lidar Odometry for  Real-Time Underground 3D Mapping",
    "abstract": "LOCUS 2.0: Robust and Computationally Efficient Lidar Odometry for  Real-Time Underground 3D Mapping",
    "descriptor": "",
    "authors": [
      "Andrzej Reinke",
      "Matteo Palieri",
      "Benjamin Morrell",
      "Yun Chang",
      "Kamak Ebadi",
      "Luca Carlone",
      "Ali-akbar Agha-mohammadi"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.11784"
  },
  {
    "id": "arXiv:2205.11854",
    "title": "Multi-Agent Collaborative Inference via DNN Decoupling: Intermediate  Feature Compression and Edge Learning",
    "abstract": "Multi-Agent Collaborative Inference via DNN Decoupling: Intermediate  Feature Compression and Edge Learning",
    "descriptor": "",
    "authors": [
      "Zhiwei Hao",
      "Guanyu Xu",
      "Yong Luo",
      "Han Hu",
      "Jianping An",
      "Shiwen Mao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11854"
  },
  {
    "id": "arXiv:2205.12746",
    "title": "Machine learning method for return direction forecasting of Exchange  Traded Funds using classification and regression models",
    "abstract": "Comments: Co-author did not agree with publishing here",
    "descriptor": "\nComments: Co-author did not agree with publishing here\n",
    "authors": [
      "Raphael P. B. Piovezan",
      "Pedro Paulo de Andrade Junior"
    ],
    "subjectives": [
      "Computational Finance (q-fin.CP)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Pricing of Securities (q-fin.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.12746"
  },
  {
    "id": "arXiv:2205.13071",
    "title": "Exploring Map-based Features for Efficient Attention-based Vehicle  Motion Prediction",
    "abstract": "Comments: CVPR MABe 2022 - ICRA FFPFAD 2022 Workshops",
    "descriptor": "\nComments: CVPR MABe 2022 - ICRA FFPFAD 2022 Workshops\n",
    "authors": [
      "Carlos G\u00f3mez-Hu\u00e9lamo",
      "Marcos V. Conde",
      "Miguel Ortiz"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.13071"
  },
  {
    "id": "arXiv:2205.13087",
    "title": "New Explicit Good Linear Sum-Rank-Metric Codes",
    "abstract": "Comments: 29 pages, few nonzero or one sum-rank weight linear codes construction included",
    "descriptor": "\nComments: 29 pages, few nonzero or one sum-rank weight linear codes construction included\n",
    "authors": [
      "Hao Chen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.13087"
  },
  {
    "id": "arXiv:2205.14147",
    "title": "FlowNet-PET: Unsupervised Learning to Perform Respiratory Motion  Correction in PET Imaging",
    "abstract": "FlowNet-PET: Unsupervised Learning to Perform Respiratory Motion  Correction in PET Imaging",
    "descriptor": "",
    "authors": [
      "Teaghan O'Briain",
      "Carlos Uribe",
      "Kwang Moo Yi",
      "Jonas Teuwen",
      "Ioannis Sechopoulos",
      "Magdalena Bazalova-Carter"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.14147"
  },
  {
    "id": "arXiv:2205.14334",
    "title": "Teaching Models to Express Their Uncertainty in Words",
    "abstract": "Comments: CalibratedMath tasks and evaluation code are available at this https URL",
    "descriptor": "\nComments: CalibratedMath tasks and evaluation code are available at this https URL\n",
    "authors": [
      "Stephanie Lin",
      "Jacob Hilton",
      "Owain Evans"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.14334"
  },
  {
    "id": "arXiv:2205.14372",
    "title": "On stationary inflection points in step responses",
    "abstract": "Comments: Corrected a typo in Figure 3, and related text on page 2: The flow vector should have been Ax + b",
    "descriptor": "\nComments: Corrected a typo in Figure 3, and related text on page 2: The flow vector should have been Ax + b\n",
    "authors": [
      "Maben Rabi"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.14372"
  },
  {
    "id": "arXiv:2205.14828",
    "title": "Lepton Flavour Violation Identification in Tau Decay ($\u03c4^{-}  \\rightarrow \u03bc^{-}\u03bc^{-}\u03bc^{+}$) Using Artificial Intelligence",
    "abstract": "Comments: 6 pages, 5 figures, 3 tables",
    "descriptor": "\nComments: 6 pages, 5 figures, 3 tables\n",
    "authors": [
      "Reymond Mesuga"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.14828"
  },
  {
    "id": "arXiv:2205.15397",
    "title": "Minimax Optimal Online Imitation Learning via Replay Estimation",
    "abstract": "Minimax Optimal Online Imitation Learning via Replay Estimation",
    "descriptor": "",
    "authors": [
      "Gokul Swamy",
      "Nived Rajaraman",
      "Matthew Peng",
      "Sanjiban Choudhury",
      "J. Andrew Bagnell",
      "Zhiwei Steven Wu",
      "Jiantao Jiao",
      "Kannan Ramchandran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.15397"
  },
  {
    "id": "arXiv:2205.15879",
    "title": "Simplex Neural Population Learning: Any-Mixture Bayes-Optimality in  Symmetric Zero-sum Games",
    "abstract": "Simplex Neural Population Learning: Any-Mixture Bayes-Optimality in  Symmetric Zero-sum Games",
    "descriptor": "",
    "authors": [
      "Siqi Liu",
      "Marc Lanctot",
      "Luke Marris",
      "Nicolas Heess"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15879"
  },
  {
    "id": "arXiv:2206.00171",
    "title": "Learning Sequential Contexts using Transformer for 3D Hand Pose  Estimation",
    "abstract": "Comments: Accepted to ICPR'22",
    "descriptor": "\nComments: Accepted to ICPR'22\n",
    "authors": [
      "Leyla Khaleghi",
      "Joshua Marshall",
      "Ali Etemad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.00171"
  },
  {
    "id": "arXiv:2206.00215",
    "title": "Quantum Error Mitigation by Pauli Check Sandwiching",
    "abstract": "Comments: Preprint. Comments are welcome",
    "descriptor": "\nComments: Preprint. Comments are welcome\n",
    "authors": [
      "Alvin Gonzales",
      "Ruslan Shaydulin",
      "Zain Saleem",
      "Martin Suchara"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2206.00215"
  },
  {
    "id": "arXiv:2206.00516",
    "title": "Feature Selection for Discovering Distributional Treatment Effect  Modifiers",
    "abstract": "Comments: 18 pages, Accepted to UAI2022",
    "descriptor": "\nComments: 18 pages, Accepted to UAI2022\n",
    "authors": [
      "Yoichi Chikahara",
      "Makoto Yamada",
      "Hisashi Kashima"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.00516"
  },
  {
    "id": "arXiv:2206.00934",
    "title": "Deep neural networks can stably solve high-dimensional, noisy,  non-linear inverse problems",
    "abstract": "Deep neural networks can stably solve high-dimensional, noisy,  non-linear inverse problems",
    "descriptor": "",
    "authors": [
      "Andr\u00e9s Felipe Lerma Pineda",
      "Philipp Christian Petersen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.00934"
  },
  {
    "id": "arXiv:2206.01335",
    "title": "Code Generation Tools (Almost) for Free? A Study of Few-Shot,  Pre-Trained Language Models on Code",
    "abstract": "Comments: 12 pages, 5 figures",
    "descriptor": "\nComments: 12 pages, 5 figures\n",
    "authors": [
      "Patrick Barei\u00df",
      "Beatriz Souza",
      "Marcelo d'Amorim",
      "Michael Pradel"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01335"
  },
  {
    "id": "arXiv:2206.01431",
    "title": "Receding Horizon Games with Coupling Constraints for Demand-Side  Management",
    "abstract": "Receding Horizon Games with Coupling Constraints for Demand-Side  Management",
    "descriptor": "",
    "authors": [
      "Sophie Hall",
      "Giuseppe Belgioioso",
      "Dominic Liao-McPherson",
      "Florian D\u00f6rfler"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.01431"
  },
  {
    "id": "arXiv:2206.01451",
    "title": "Learning Distributed and Fair Policies for Network Load Balancing as  Markov Potential Game",
    "abstract": "Learning Distributed and Fair Policies for Network Load Balancing as  Markov Potential Game",
    "descriptor": "",
    "authors": [
      "Zhiyuan Yao",
      "Zihan Ding"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.01451"
  },
  {
    "id": "arXiv:2206.01702",
    "title": "Scalar is Not Enough: Vectorization-based Unbiased Learning to Rank",
    "abstract": "Comments: Accepted by KDD 2022",
    "descriptor": "\nComments: Accepted by KDD 2022\n",
    "authors": [
      "Mouxiang Chen",
      "Chenghao Liu",
      "Zemin Liu",
      "Jianling Sun"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01702"
  },
  {
    "id": "arXiv:2206.01833",
    "title": "Leveraging Heterogeneous Capabilities in Multi-Agent Systems for  Environmental Conflict Resolution",
    "abstract": "Comments: Submitted to The International Symposium on Robotics Research (ISRR) 2022",
    "descriptor": "\nComments: Submitted to The International Symposium on Robotics Research (ISRR) 2022\n",
    "authors": [
      "Michael Enqi Cao",
      "Jonas Warnke",
      "Yunhai Han",
      "Xinpei Ni",
      "Ye Zhao",
      "Samuel Coogan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.01833"
  },
  {
    "id": "arXiv:2206.01872",
    "title": "Affine Symplectic Grassmann codes",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2110.08964",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2110.08964\n",
    "authors": [
      "Fernando Pi\u00f1ero Gonz\u00e1lez",
      "Doel Rivera Laboy"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.01872"
  },
  {
    "id": "arXiv:2206.01888",
    "title": "Reward Poisoning Attacks on Offline Multi-Agent Reinforcement Learning",
    "abstract": "Reward Poisoning Attacks on Offline Multi-Agent Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Young Wu",
      "Jeremey McMahan",
      "Xiaojin Zhu",
      "Qiaomin Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2206.01888"
  },
  {
    "id": "arXiv:2206.01934",
    "title": "Stochastic Multiple Target Sampling Gradient Descent",
    "abstract": "Comments: 25 pages, 9 figures, 5 tables",
    "descriptor": "\nComments: 25 pages, 9 figures, 5 tables\n",
    "authors": [
      "Hoang Phan",
      "Ngoc Tran",
      "Trung Le",
      "Toan Tran",
      "Nhat Ho",
      "Dinh Phung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.01934"
  },
  {
    "id": "arXiv:2206.01984",
    "title": "Geodesic Properties of a Generalized Wasserstein Embedding for Time  Series Analysis",
    "abstract": "Geodesic Properties of a Generalized Wasserstein Embedding for Time  Series Analysis",
    "descriptor": "",
    "authors": [
      "Shiying Li",
      "Abu Hasnat Mohammad Rubaiyat",
      "Gustavo K. Rohde"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Geometric Topology (math.GT)"
    ],
    "url": "https://arxiv.org/abs/2206.01984"
  },
  {
    "id": "arXiv:2206.02225",
    "title": "Physically Inspired Constraint for Unsupervised Regularized Ultrasound  Elastography",
    "abstract": "Comments: Accepted in MICCAI 2022",
    "descriptor": "\nComments: Accepted in MICCAI 2022\n",
    "authors": [
      "Ali K. Z. Tehrani",
      "Hassan Rivaz"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.02225"
  },
  {
    "id": "arXiv:2206.02327",
    "title": "JigsawHSI: a network for Hyperspectral Image classification",
    "abstract": "Comments: 7 pages, 7 figures, not peer reviewed",
    "descriptor": "\nComments: 7 pages, 7 figures, not peer reviewed\n",
    "authors": [
      "Jaime Moraga",
      "H. Sebnem Duzgun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.02327"
  },
  {
    "id": "arXiv:2206.02480",
    "title": "Subspace Phase Retrieval",
    "abstract": "Comments: Four figures",
    "descriptor": "\nComments: Four figures\n",
    "authors": [
      "Mengchu Xu",
      "Dekuan Dong",
      "Jian Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2206.02480"
  },
  {
    "id": "arXiv:2206.02845",
    "title": "On Efficient Approximate Queries over Machine Learning Models",
    "abstract": "Comments: Submitted to VLDB 2023, 16 pages, 10 figures; added formal claims for section 4",
    "descriptor": "\nComments: Submitted to VLDB 2023, 16 pages, 10 figures; added formal claims for section 4\n",
    "authors": [
      "Dujian Ding",
      "Sihem Amer-Yahia",
      "Laks VS Lakshmanan"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02845"
  },
  {
    "id": "arXiv:2206.02852",
    "title": "CompartOS: CHERI Compartmentalization for Embedded Systems",
    "abstract": "CompartOS: CHERI Compartmentalization for Embedded Systems",
    "descriptor": "",
    "authors": [
      "Hesham Almatary",
      "Michael Dodson",
      "Jessica Clarke",
      "Peter Rugg",
      "Ivan Gomes",
      "Michal Podhradsky",
      "Peter G. Neumann",
      "Simon W. Moore",
      "Robert N. M. Watson"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.02852"
  },
  {
    "id": "arXiv:2206.02946",
    "title": "On the Convergence of Optimizing Persistent-Homology-Based Losses",
    "abstract": "On the Convergence of Optimizing Persistent-Homology-Based Losses",
    "descriptor": "",
    "authors": [
      "Yikai Zhang",
      "Jiachen Yao",
      "Yusu Wang",
      "Chao Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Geometry (cs.CG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.02946"
  },
  {
    "id": "arXiv:2206.03221",
    "title": "To incentivize or not: Impact of blockchain-based cryptoeconomic tokens  on human information sharing behavior",
    "abstract": "To incentivize or not: Impact of blockchain-based cryptoeconomic tokens  on human information sharing behavior",
    "descriptor": "",
    "authors": [
      "Mark Christopher Ballandies"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.03221"
  },
  {
    "id": "arXiv:2206.03231",
    "title": "High-performance computing for super-resolution microscopy on a cluster  of computers",
    "abstract": "Comments: The requests I have received from my co-authors",
    "descriptor": "\nComments: The requests I have received from my co-authors\n",
    "authors": [
      "Quan Do",
      "Jon Ivar Kristiansen",
      "Krishna Agarwal",
      "Phuong Hoai Ha"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2206.03231"
  },
  {
    "id": "arXiv:2206.03311",
    "title": "Theorizing Information Sources for Hope: Belief, Desire, Imagination,  and Metacognition",
    "abstract": "Comments: Paper presented at Conceptions of Library & Information Science (CoLIS) 11 on May 30, 2022, in Oslo, Norway",
    "descriptor": "\nComments: Paper presented at Conceptions of Library & Information Science (CoLIS) 11 on May 30, 2022, in Oslo, Norway\n",
    "authors": [
      "Tim Gorichanaz"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.03311"
  },
  {
    "id": "arXiv:2206.03328",
    "title": "Concentration bounds for SSP Q-learning for average cost MDPs",
    "abstract": "Comments: 6 pages, 2 figures",
    "descriptor": "\nComments: 6 pages, 2 figures\n",
    "authors": [
      "Shaan Ul Haque",
      "Vivek Borkar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.03328"
  },
  {
    "id": "arXiv:2206.03440",
    "title": "Enhancing Strong PUF Security with Non-monotonic Response Quantization",
    "abstract": "Enhancing Strong PUF Security with Non-monotonic Response Quantization",
    "descriptor": "",
    "authors": [
      "Kleber Stangherlin",
      "Zhuanhao Wu",
      "Hiren Patel",
      "Manoj Sachdev"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.03440"
  },
  {
    "id": "arXiv:2206.03544",
    "title": "A Penny for Your (visual) Thoughts: Self-Supervised Reconstruction of  Natural Movies from Brain Activity",
    "abstract": "A Penny for Your (visual) Thoughts: Self-Supervised Reconstruction of  Natural Movies from Brain Activity",
    "descriptor": "",
    "authors": [
      "Ganit Kupershmidt",
      "Roman Beliy",
      "Guy Gaziv",
      "Michal Irani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03544"
  },
  {
    "id": "arXiv:2206.03858",
    "title": "Rotation-Equivariant Conditional Spherical Neural Fields for Learning a  Natural Illumination Prior",
    "abstract": "Comments: Corrected columns for SH and SG in Supplementary Material, Figure 1. Updated reference to project page",
    "descriptor": "\nComments: Corrected columns for SH and SG in Supplementary Material, Figure 1. Updated reference to project page\n",
    "authors": [
      "James A. D. Gardner",
      "Bernhard Egger",
      "William A. P. Smith"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.03858"
  },
  {
    "id": "arXiv:2206.04046",
    "title": "Sparse Fusion Mixture-of-Experts are Domain Generalizable Learners",
    "abstract": "Comments: ArXiv preprint, work still in progress",
    "descriptor": "\nComments: ArXiv preprint, work still in progress\n",
    "authors": [
      "Bo Li",
      "Jingkang Yang",
      "Jiawei Ren",
      "Yezhen Wang",
      "Ziwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04046"
  },
  {
    "id": "arXiv:2206.04317",
    "title": "Topic-Aware Evaluation and Transformer Methods for Topic-Controllable  Summarization",
    "abstract": "Topic-Aware Evaluation and Transformer Methods for Topic-Controllable  Summarization",
    "descriptor": "",
    "authors": [
      "Tatiana Passali",
      "Grigorios Tsoumakas"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.04317"
  },
  {
    "id": "arXiv:2206.04367",
    "title": "Distinct Angles in General Position",
    "abstract": "Comments: Former Corollary 4.1 upgraded to Theorem 1.2 with improved bounds",
    "descriptor": "\nComments: Former Corollary 4.1 upgraded to Theorem 1.2 with improved bounds\n",
    "authors": [
      "Henry L. Fleischmann",
      "Sergei V. Konyagin",
      "Steven J. Miller",
      "Eyvindur A. Palsson",
      "Ethan Pesikoff",
      "Charles Wolf"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Combinatorics (math.CO)",
      "Metric Geometry (math.MG)"
    ],
    "url": "https://arxiv.org/abs/2206.04367"
  },
  {
    "id": "arXiv:2206.04510",
    "title": "SsciBERT: A Pre-trained Language Model for Social Science Texts",
    "abstract": "Comments: 19 pages,2 figures",
    "descriptor": "\nComments: 19 pages,2 figures\n",
    "authors": [
      "Si Shen",
      "Jiangfeng Liu",
      "Litao Lin",
      "Ying Huang",
      "Lin Zhang",
      "Chang Liu",
      "Yutong Feng",
      "Dongbo Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.04510"
  },
  {
    "id": "arXiv:2206.04544",
    "title": "Service-Oriented Architecture for Drone-based Multi-Package Delivery",
    "abstract": "Comments: 6 pages, 4 figures. This is an accepted paper and it is going to appear in the Proceedings of the 2022 IEEE International Conference on Web Services (IEEE ICWS 2022)",
    "descriptor": "\nComments: 6 pages, 4 figures. This is an accepted paper and it is going to appear in the Proceedings of the 2022 IEEE International Conference on Web Services (IEEE ICWS 2022)\n",
    "authors": [
      "Babar Shahzaad",
      "Athman Bouguettaya"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.04544"
  },
  {
    "id": "arXiv:2206.04564",
    "title": "TwiBot-22: Towards Graph-Based Twitter Bot Detection",
    "abstract": "TwiBot-22: Towards Graph-Based Twitter Bot Detection",
    "descriptor": "",
    "authors": [
      "Shangbin Feng",
      "Zhaoxuan Tan",
      "Herun Wan",
      "Ningnan Wang",
      "Zilong Chen",
      "Binchi Zhang",
      "Qinghua Zheng",
      "Wenqian Zhang",
      "Zhenyu Lei",
      "Shujie Yang",
      "Xinshun Feng",
      "Qingyue Zhang",
      "Hongrui Wang",
      "Yuhan Liu",
      "Yuyang Bai",
      "Heng Wang",
      "Zijian Cai",
      "Yanbo Wang",
      "Lijing Zheng",
      "Zihan Ma",
      "Jundong Li",
      "Minnan Luo"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.04564"
  },
  {
    "id": "arXiv:2206.04656",
    "title": "Simple Cues Lead to a Strong Multi-Object Tracker",
    "abstract": "Simple Cues Lead to a Strong Multi-Object Tracker",
    "descriptor": "",
    "authors": [
      "Jenny Seidenschwarz",
      "Guillem Bras\u00f3",
      "Ismail Elezi",
      "Laura Leal-Taix\u00e9"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.04656"
  },
  {
    "id": "arXiv:2206.04682",
    "title": "RT-DNAS: Real-time Constrained Differentiable Neural Architecture Search  for 3D Cardiac Cine MRI Segmentation",
    "abstract": "RT-DNAS: Real-time Constrained Differentiable Neural Architecture Search  for 3D Cardiac Cine MRI Segmentation",
    "descriptor": "",
    "authors": [
      "Qing Lu",
      "Xiaowei Xu",
      "Shunjie Dong",
      "Cong Hao",
      "Lei Yang",
      "Cheng Zhuo",
      "Yiyu Shi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04682"
  },
  {
    "id": "arXiv:2206.04713",
    "title": "A Resilient Distributed Boosting Algorithm",
    "abstract": "A Resilient Distributed Boosting Algorithm",
    "descriptor": "",
    "authors": [
      "Yuval Filmus",
      "Idan Mehalel",
      "Shay Moran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.04713"
  },
  {
    "id": "arXiv:2206.04726",
    "title": "COSTA: Covariance-Preserving Feature Augmentation for Graph Contrastive  Learning",
    "abstract": "Comments: This paper is accepted by the ACM KDD 2022",
    "descriptor": "\nComments: This paper is accepted by the ACM KDD 2022\n",
    "authors": [
      "Yifei Zhang",
      "Hao Zhu",
      "Zixing Song",
      "Piotr Koniusz",
      "Irwin King"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.04726"
  },
  {
    "id": "arXiv:2206.04732",
    "title": "AI-MIA: COVID-19 Detection & Severity Analysis through Medical Imaging",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2106.07524",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2106.07524\n",
    "authors": [
      "Dimitrios Kollias",
      "Anastasios Arsenos",
      "Stefanos Kollias"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04732"
  },
  {
    "id": "arXiv:2206.04817",
    "title": "The Slingshot Mechanism: An Empirical Study of Adaptive Optimizers and  the Grokking Phenomenon",
    "abstract": "Comments: Removed Tex formatting commands in title Title and Abstract",
    "descriptor": "\nComments: Removed Tex formatting commands in title Title and Abstract\n",
    "authors": [
      "Vimal Thilak",
      "Etai Littwin",
      "Shuangfei Zhai",
      "Omid Saremi",
      "Roni Paiss",
      "Joshua Susskind"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.04817"
  },
  {
    "id": "arXiv:2206.04838",
    "title": "In Defense of Core-set: A Density-aware Core-set Selection for Active  Learning",
    "abstract": "Comments: Proceedings of the ACM SIGKDD Conference on Knowledge Discovery & Data Mining, 2022 (KDD'22)",
    "descriptor": "\nComments: Proceedings of the ACM SIGKDD Conference on Knowledge Discovery & Data Mining, 2022 (KDD'22)\n",
    "authors": [
      "Yeachan Kim",
      "Bonggun Shin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.04838"
  },
  {
    "id": "arXiv:2206.04843",
    "title": "Neural Laplace: Learning diverse classes of differential equations in  the Laplace domain",
    "abstract": "Comments: Proceedings of the 39th International Conference on Machine Learning, Baltimore, Maryland, USA, PMLR 162, 2022. Copyright 2022 by the author(s)",
    "descriptor": "\nComments: Proceedings of the 39th International Conference on Machine Learning, Baltimore, Maryland, USA, PMLR 162, 2022. Copyright 2022 by the author(s)\n",
    "authors": [
      "Samuel Holt",
      "Zhaozhi Qian",
      "Mihaela van der Schaar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.04843"
  },
  {
    "id": "arXiv:2206.04928",
    "title": "MAREO: Memory- and Attention- based visual REasOning",
    "abstract": "MAREO: Memory- and Attention- based visual REasOning",
    "descriptor": "",
    "authors": [
      "Mohit Vaishnav",
      "Thomas Serre"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2206.04928"
  },
  {
    "id": "arXiv:2206.05010",
    "title": "Highlights of Semantics in Multi-objective Genetic Programming",
    "abstract": "Comments: Accepted in GECCO '22 Companion, July 9--13, 2022, Boston, MA, USA, 2 pages, 1 figure. This Hot-off-the-Press paper summarises \"Semantics in Multi-objective Genetic Programming\" by Edgar Galv\\'an, Leonardo Trujillo and Fergal Stapleton, published in the journal of Applied Soft Computing 2022, this https URL [arXiv:2105.02944]",
    "descriptor": "\nComments: Accepted in GECCO '22 Companion, July 9--13, 2022, Boston, MA, USA, 2 pages, 1 figure. This Hot-off-the-Press paper summarises \"Semantics in Multi-objective Genetic Programming\" by Edgar Galv\\'an, Leonardo Trujillo and Fergal Stapleton, published in the journal of Applied Soft Computing 2022, this https URL [arXiv:2105.02944]\n",
    "authors": [
      "Edgar Galv\u00e1n",
      "Leonardo Trujillo",
      "Fergal Stapleton"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.05010"
  },
  {
    "id": "arXiv:2206.05085",
    "title": "Improved Direct Voxel Grid Optimization for Radiance Fields  Reconstruction",
    "abstract": "Comments: Project page this https URL ; Code this https URL",
    "descriptor": "\nComments: Project page this https URL ; Code this https URL\n",
    "authors": [
      "Cheng Sun",
      "Min Sun",
      "Hwann-Tzong Chen"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2206.05085"
  },
  {
    "id": "arXiv:2206.05136",
    "title": "Fast Deep Autoencoder for Federated learning",
    "abstract": "Fast Deep Autoencoder for Federated learning",
    "descriptor": "",
    "authors": [
      "David Novoa-Paradela",
      "Oscar Romero-Fontenla",
      "Bertha Guijarro-Berdi\u00f1as"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05136"
  },
  {
    "id": "arXiv:2206.05238",
    "title": "Dimensional Modeling of Emotions in Text with Appraisal Theories: Corpus  Creation, Annotation Reliability, and Prediction",
    "abstract": "Comments: 69 pages, 13 figures, 19 tables",
    "descriptor": "\nComments: 69 pages, 13 figures, 19 tables\n",
    "authors": [
      "Enrica Troiano",
      "Laura Oberl\u00e4nder",
      "Roman Klinger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.05238"
  }
]
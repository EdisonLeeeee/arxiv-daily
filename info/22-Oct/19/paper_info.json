[
  {
    "id": "arXiv:2210.09337",
    "title": "Robust Imitation of a Few Demonstrations with a Backwards Model",
    "abstract": "Behavior cloning of expert demonstrations can speed up learning optimal\npolicies in a more sample-efficient way over reinforcement learning. However,\nthe policy cannot extrapolate well to unseen states outside of the\ndemonstration data, creating covariate shift (agent drifting away from\ndemonstrations) and compounding errors. In this work, we tackle this issue by\nextending the region of attraction around the demonstrations so that the agent\ncan learn how to get back onto the demonstrated trajectories if it veers\noff-course. We train a generative backwards dynamics model and generate short\nimagined trajectories from states in the demonstrations. By imitating both\ndemonstrations and these model rollouts, the agent learns the demonstrated\npaths and how to get back onto these paths. With optimal or near-optimal\ndemonstrations, the learned policy will be both optimal and robust to\ndeviations, with a wider region of attraction. On continuous control domains,\nwe evaluate the robustness when starting from different initial states unseen\nin the demonstration data. While both our method and other imitation learning\nbaselines can successfully solve the tasks for initial states in the training\ndistribution, our method exhibits considerably more robustness to different\ninitial states.",
    "descriptor": "\nComments: Conference on Neural Information Processing Systems (NeurIPS) 2022\n",
    "authors": [
      "Jung Yeon Park",
      "Lawson L.S. Wong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.09337"
  },
  {
    "id": "arXiv:2210.09338",
    "title": "Deep Bidirectional Language-Knowledge Graph Pretraining",
    "abstract": "Pretraining a language model (LM) on text has been shown to help various\ndownstream NLP tasks. Recent works show that a knowledge graph (KG) can\ncomplement text data, offering structured background knowledge that provides a\nuseful scaffold for reasoning. However, these works are not pretrained to learn\na deep fusion of the two modalities at scale, limiting the potential to acquire\nfully joint representations of text and KG. Here we propose DRAGON (Deep\nBidirectional Language-Knowledge Graph Pretraining), a self-supervised approach\nto pretraining a deeply joint language-knowledge foundation model from text and\nKG at scale. Specifically, our model takes pairs of text segments and relevant\nKG subgraphs as input and bidirectionally fuses information from both\nmodalities. We pretrain this model by unifying two self-supervised reasoning\ntasks, masked language modeling and KG link prediction. DRAGON outperforms\nexisting LM and LM+KG models on diverse downstream tasks including question\nanswering across general and biomedical domains, with +5% absolute gain on\naverage. In particular, DRAGON achieves notable performance on complex\nreasoning about language and knowledge (+10% on questions involving long\ncontexts or multi-step reasoning) and low-resource QA (+8% on OBQA and\nRiddleSense), and new state-of-the-art results on various BioNLP tasks. Our\ncode and trained models are available at\nhttps://github.com/michiyasunaga/dragon.",
    "descriptor": "\nComments: Published at NeurIPS 2022. Code, data, and trained models are available at this https URL\n",
    "authors": [
      "Michihiro Yasunaga",
      "Antoine Bosselut",
      "Hongyu Ren",
      "Xikun Zhang",
      "Christopher D Manning",
      "Percy Liang",
      "Jure Leskovec"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09338"
  },
  {
    "id": "arXiv:2210.09340",
    "title": "Transferring Knowledge via Neighborhood-Aware Optimal Transport for  Low-Resource Hate Speech Detection",
    "abstract": "The concerning rise of hateful content on online platforms has increased the\nattention towards automatic hate speech detection, commonly formulated as a\nsupervised classification task. State-of-the-art deep learning-based approaches\nusually require a substantial amount of labeled resources for training.\nHowever, annotating hate speech resources is expensive, time-consuming, and\noften harmful to the annotators. This creates a pressing need to transfer\nknowledge from the existing labeled resources to low-resource hate speech\ncorpora with the goal of improving system performance. For this,\nneighborhood-based frameworks have been shown to be effective. However, they\nhave limited flexibility. In our paper, we propose a novel training strategy\nthat allows flexible modeling of the relative proximity of neighbors retrieved\nfrom a resource-rich corpus to learn the amount of transfer. In particular, we\nincorporate neighborhood information with Optimal Transport, which permits\nexploiting the geometry of the data embedding space. By aligning the joint\nembedding and label distributions of neighbors, we demonstrate substantial\nimprovements over strong baselines, in low-resource scenarios, on different\npublicly available hate speech corpora.",
    "descriptor": "\nComments: AACL-IJCNLP 2022 preprint\n",
    "authors": [
      "Tulika Bose",
      "Irina Illina",
      "Dominique Fohr"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.09340"
  },
  {
    "id": "arXiv:2210.09345",
    "title": "CrossRE: A Cross-Domain Dataset for Relation Extraction",
    "abstract": "Relation Extraction (RE) has attracted increasing attention, but current RE\nevaluation is limited to in-domain evaluation setups. Little is known on how\nwell a RE system fares in challenging, but realistic out-of-distribution\nevaluation setups. To address this gap, we propose CrossRE, a new,\nfreely-available cross-domain benchmark for RE, which comprises six distinct\ntext domains and includes multi-label annotations. An additional innovation is\nthat we release meta-data collected during annotation, to include explanations\nand flags of difficult instances. We provide an empirical evaluation with a\nstate-of-the-art model for relation classification. As the meta-data enables us\nto shed new light on the state-of-the-art model, we provide a comprehensive\nanalysis on the impact of difficult cases and find correlations between model\nand human annotations. Overall, our empirical investigation highlights the\ndifficulty of cross-domain RE. We release our dataset, to spur more research in\nthis direction.",
    "descriptor": "\nComments: Accepted in Findings of the Association for Computational Linguistics: EMNLP 2022\n",
    "authors": [
      "Elisa Bassignana",
      "Barbara Plank"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.09345"
  },
  {
    "id": "arXiv:2210.09347",
    "title": "Cloth Funnels: Canonicalized-Alignment for Multi-Purpose Garment  Manipulation",
    "abstract": "Automating garment manipulation is challenging due to extremely high\nvariability in object configurations. To reduce this intrinsic variation, we\nintroduce the task of \"canonicalized-alignment\" that simplifies downstream\napplications by reducing the possible garment configurations. This task can be\nconsidered as \"cloth state funnel\" that manipulates arbitrarily configured\nclothing items into a predefined deformable configuration (i.e.\ncanonicalization) at an appropriate rigid pose (i.e. alignment). In the end,\nthe cloth items will result in a compact set of structured and highly visible\nconfigurations - which are desirable for downstream manipulation skills. To\nenable this task, we propose a novel canonicalized-alignment objective that\neffectively guides learning to avoid adverse local minima during learning.\nUsing this objective, we learn a multi-arm, multi-primitive policy that\nstrategically chooses between dynamic flings and quasi-static pick and place\nactions to achieve efficient canonicalized-alignment. We evaluate this approach\non a real-world ironing and folding system that relies on this learned policy\nas the common first step. Empirically, we demonstrate that our task-agnostic\ncanonicalized-alignment can enable even simple manually-designed policies to\nwork well where they were previously inadequate, thus bridging the gap between\nautomated non-deformable manufacturing and deformable manipulation. Code and\nqualitative visualizations are available at\nhttps://clothfunnels.cs.columbia.edu/. Video can be found at\nhttps://www.youtube.com/watch?v=TkUn0b7mbj0.",
    "descriptor": "\nComments: 8 pages, 8 figures, website at this https URL\n",
    "authors": [
      "Alper Canberk",
      "Cheng Chi",
      "Huy Ha",
      "Benjamin Burchfiel",
      "Eric Cousineau",
      "Siyuan Feng",
      "Shuran Song"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.09347"
  },
  {
    "id": "arXiv:2210.09348",
    "title": "Use of Electronic Resources by Law Academics in India",
    "abstract": "This study investigated e-resources use, storage, the preferred format for\nreading, and difficulties faced while accessing e-resources. Electronic\nresources are playing a crucial role all over the world, and they are\nincreasing widely in all age groups of the academic community. The main aim of\nthe law academics' role is to know the effective use of electronic resources.\nFor this study, we adopted a descriptive survey research design that was used\nto collect feedback from the respondents through the survey and Google form.\nThe study samples are Progressive Education Society's Modern Law College\naffiliated with Savitribai Phule Pune University. BA LLB students are samples\nof the study.",
    "descriptor": "",
    "authors": [
      "Mane Sunita D",
      "Subaveerapandiyan A"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2210.09348"
  },
  {
    "id": "arXiv:2210.09349",
    "title": "Digital Media and Information Literacy: A way to Paperless Society",
    "abstract": "Purpose - The study's main objective was to find out the possibility of a\npaperless library and society with particular reference to Top 60 Universities\nfrom QS world University ranking 2021 and their library professionals. ICT\nknowledge and skills of these LIS professionals and evaluated their digital\nliteracy skills was another aim of this study.\nDesign/methodology/approach - The researchers used the survey method for this\nstudy using a structured questionnaire, distributed through the google form to\nlibrary professionals of world-famous universities, ranked as top 60 in QS\nWorld University Ranking. 206 responses were received. The information\ncollected from the respondents has been analyzed using an Excel sheet and SPSS\nsoftware.\nFindings - Most professionals are interested in digital learning and adopting\npaperless learning to contribute to a paperless society. They go for online\nways to answer reference queries of users and work in a refined atmosphere.\nThey are learning from digital resources and have support from online platforms\nif they suffer. Also, they are actively engaging with the digital environment\nand promoting it too.",
    "descriptor": "",
    "authors": [
      "Subaveerapandiyan A",
      "Anuradha Maurya"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.09349"
  },
  {
    "id": "arXiv:2210.09355",
    "title": "A tensor formalism for multilayer network centrality measures using the  Einstein product",
    "abstract": "Complex systems that consist of different kinds of entities that interact in\ndifferent ways can be modeled by multilayer networks. This paper uses the\ntensor formalism with the Einstein tensor product to model this type of\nnetworks. Several centrality measures, that are well known for single-layer\nnetworks, are extended to multilayer networks using tensors and their\nproperties are investigated. In particular, subgraph centrality based on the\nexponential and resolvent of a tensor are considered. Krylov subspace methods\nare introduced for computing approximations of different measures for large\nmultilayer networks.",
    "descriptor": "\nComments: 23 pages, 3 figures\n",
    "authors": [
      "Smahane El-Halouy",
      "Silvia Noschese",
      "Lothar Reichel"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.09355"
  },
  {
    "id": "arXiv:2210.09358",
    "title": "UMLsec4Edge: Extending UMLsec to model data-protection-compliant edge  computing systems",
    "abstract": "Edge computing enables the processing of data - frequently personal data - at\nthe edge of the network. For personal data, legislation such as the European\nGeneral Data Protection Regulation requires data protection by design. Hence,\ndata protection has to be accounted for in the design of edge computing systems\nwhenever personal data is involved. This leads to specific requirements for\nmodeling the architecture of edge computing systems, e.g., representation of\ndata and network properties.\nTo the best of our knowledge, no existing modeling language fulfils all these\nrequirements. In our previous work we showed that the commonly used UML profile\nUMLsec fulfils some of these requirements, and can thus serve as a starting\npoint.\nThe aim of this paper is to create a modeling language which meets all\nrequirements concerning the design of the architecture of edge computing\nsystems accounting for data protection. Thus, we extend UMLsec to satisfy all\nrequirements. We call the resulting UML profile UMLsec4Edge. We follow a\nsystematic approach to develop UMLsec4Edge. We apply UMLsec4Edge to real-world\nuse cases from different domains, and create appropriate deployment diagrams\nand class diagrams. These diagrams show UMLsec4Edge is capable of meeting the\nrequirements.",
    "descriptor": "\nComments: 8 pages, 4 figures, 2 tables, published at the 48th Euromicro Conference Series on Software Engineering and Advanced Applications (SEAA)\n",
    "authors": [
      "Sven Smolka",
      "Jan Laufer",
      "Zolt\u00e1n \u00c1d\u00e1m Mann",
      "Klaus Pohl"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.09358"
  },
  {
    "id": "arXiv:2210.09364",
    "title": "Probabilistic Categorical Adversarial Attack & Adversarial Training",
    "abstract": "The existence of adversarial examples brings huge concern for people to apply\nDeep Neural Networks (DNNs) in safety-critical tasks. However, how to generate\nadversarial examples with categorical data is an important problem but lack of\nextensive exploration. Previously established methods leverage greedy search\nmethod, which can be very time-consuming to conduct successful attack. This\nalso limits the development of adversarial training and potential defenses for\ncategorical data. To tackle this problem, we propose Probabilistic Categorical\nAdversarial Attack (PCAA), which transfers the discrete optimization problem to\na continuous problem that can be solved efficiently by Projected Gradient\nDescent. In our paper, we theoretically analyze its optimality and time\ncomplexity to demonstrate its significant advantage over current greedy based\nattacks. Moreover, based on our attack, we propose an efficient adversarial\ntraining framework. Through a comprehensive empirical study, we justify the\neffectiveness of our proposed attack and defense algorithms.",
    "descriptor": "",
    "authors": [
      "Penghei He",
      "Han Xu",
      "Jie Ren",
      "Yuxuan Wan",
      "Zitao Liu",
      "Jiliang Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.09364"
  },
  {
    "id": "arXiv:2210.09366",
    "title": "Bridging the Gap between Artificial Intelligence and Artificial General  Intelligence: A Ten Commandment Framework for Human-Like Intelligence",
    "abstract": "The field of artificial intelligence has seen explosive growth and\nexponential success. The last phase of development showcased deep learnings\nability to solve a variety of difficult problems across a multitude of domains.\nMany of these networks met and exceeded human benchmarks by becoming experts in\nthe domains in which they are trained. Though the successes of artificial\nintelligence have begun to overshadow its failures, there is still much that\nseparates current artificial intelligence tools from becoming the exceptional\ngeneral learners that humans are. In this paper, we identify the ten\ncommandments upon which human intelligence is systematically and hierarchically\nbuilt. We believe these commandments work collectively to serve as the\nessential ingredients that lead to the emergence of higher-order cognition and\nintelligence. This paper discusses a computational framework that could house\nthese ten commandments and suggests new architectural modifications that could\nlead to the development of smarter, more explainable, and generalizable\nartificial systems inspired by a neuromorphic approach.",
    "descriptor": "",
    "authors": [
      "Ananta Nair",
      "Farnoush Banaei-Kashani"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2210.09366"
  },
  {
    "id": "arXiv:2210.09367",
    "title": "Task and Motion Informed Trees (TMIT*): Almost-Surely Asymptotically  Optimal Integrated Task and Motion Planning",
    "abstract": "High-level autonomy requires discrete and continuous reasoning to decide both\nwhat actions to take and how to execute them. Integrated Task and Motion\nPlanning (TMP) algorithms solve these hybrid problems jointly to consider\nconstraints between the discrete symbolic actions (i.e., the task plan) and\ntheir continuous geometric realization (i.e., motion plans). This joint\napproach solves more difficult problems than approaches that address the task\nand motion subproblems independently.\nTMP algorithms combine and extend results from both task and motion planning.\nTMP has mainly focused on computational performance and completeness and less\non solution optimality. Optimal TMP is difficult because the independent optima\nof the subproblems may not be the optimal integrated solution, which can only\nbe found by jointly optimizing both plans.\nThis paper presents Task and Motion Informed Trees (TMIT*), an optimal TMP\nalgorithm that combines results from makespan-optimal task planning and\nalmost-surely asymptotically optimal motion planning. TMIT* interleaves\nasymmetric forward and reverse searches to delay computationally expensive\noperations until necessary and perform an efficient informed search directly in\nthe problem's hybrid state space. This allows it to solve problems quickly and\nthen converge towards the optimal solution with additional computational time,\nas demonstrated on the evaluated robotic-manipulation benchmark problems.",
    "descriptor": "\nComments: 9 pages, 5 figures. Accepted to IEEE RA-L and IROS 2022\n",
    "authors": [
      "Wil Thomason",
      "Marlin P. Strub",
      "Jonathan D. Gammell"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.09367"
  },
  {
    "id": "arXiv:2210.09371",
    "title": "On Accelerated Perceptrons and Beyond",
    "abstract": "The classical Perceptron algorithm of Rosenblatt can be used to find a linear\nthreshold function to correctly classify $n$ linearly separable data points,\nassuming the classes are separated by some margin $\\gamma > 0$. A foundational\nresult is that Perceptron converges after $\\Omega(1/\\gamma^{2})$ iterations.\nThere have been several recent works that managed to improve this rate by a\nquadratic factor, to $\\Omega(\\sqrt{\\log n}/\\gamma)$, with more sophisticated\nalgorithms. In this paper, we unify these existing results under one framework\nby showing that they can all be described through the lens of solving min-max\nproblems using modern acceleration techniques, mainly through optimistic online\nlearning. We then show that the proposed framework also lead to improved\nresults for a series of problems beyond the standard Perceptron setting.\nSpecifically, a) For the margin maximization problem, we improve the\nstate-of-the-art result from $O(\\log t/t^2)$ to $O(1/t^2)$, where $t$ is the\nnumber of iterations; b) We provide the first result on identifying the\nimplicit bias property of the classical Nesterov's accelerated gradient descent\n(NAG) algorithm, and show NAG can maximize the margin with an $O(1/t^2)$ rate;\nc) For the classical $p$-norm Perceptron problem, we provide an algorithm with\n$\\Omega(\\sqrt{(p-1)\\log n}/\\gamma)$ convergence rate, while existing algorithms\nsuffer the $\\Omega({(p-1)}/\\gamma^2)$ convergence rate.",
    "descriptor": "",
    "authors": [
      "Guanghui Wang",
      "Rafael Hanashiro",
      "Etash Guha",
      "Jacob Abernethy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.09371"
  },
  {
    "id": "arXiv:2210.09372",
    "title": "Task-Oriented and Semantics-Aware 6G Networks",
    "abstract": "Upon the arrival of emerging devices, including Extended Reality (XR) and\nUnmanned Aerial Vehicles (UAVs), the traditional bit-oriented communication\nframework is approaching Shannon's physical capacity limit and fails to\nguarantee the massive amount of transmission within latency requirements. By\njointly exploiting the context of data and its importance to the task, an\nemerging communication paradigm shift to semantic level and effectiveness level\nis envisioned to be a key revolution in Sixth Generation (6G) networks.\nHowever, an explicit and systematic communication framework incorporating both\nsemantic level and effectiveness level has not been proposed yet. In this\narticle, we propose a generic task-oriented and semantics-aware (TOSA)\ncommunication framework for various tasks with diverse data types, which\nincorporates both semantic level information and effectiveness level\nperformance metrics. We first analyze the unique characteristics of all data\ntypes, and summarise the semantic information, along with corresponding\nextraction methods. We then propose a detailed TOSA communication framework for\ndifferent time critical and non-critical tasks. In the TOSA framework, we\npresent the TOSA information, extraction methods, recovery methods, and\neffectiveness level performance metrics. Last but not least, we present a TOSA\nframework tailored for Virtual Reality (VR) data with interactive VR tasks to\nvalidate the effectiveness of the proposed TOSA communication framework.",
    "descriptor": "",
    "authors": [
      "Hui Zhou",
      "Xiaonan Liu",
      "Yansha Deng",
      "Nikolaos Pappas",
      "Arumugam Nallanathan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.09372"
  },
  {
    "id": "arXiv:2210.09373",
    "title": "A Systematic Study of the Consistency of Two-Factor Authentication User  Journeys on Top-Ranked Websites (Extended Version)",
    "abstract": "Heuristics for user experience state that users will transfer their\nexpectations from one product to another. A lack of consistency between\nproducts can increase users' cognitive friction, leading to frustration and\nrejection. This paper presents the first systematic study of the external,\nfunctional consistency of two-factor authentication user journeys on top-ranked\nwebsites. We find that these websites implement only a minimal number of design\naspects consistently (e.g., naming and location of settings) but exhibit mixed\ndesign patterns for setup and usage of a second factor. Moreover, we find that\nsome of the more consistently realized aspects, such as descriptions of\ntwo-factor authentication, have been described in the literature as problematic\nand adverse to user experience. Our results advocate for more general UX\nguidelines for 2FA implementers and raise new research questions about the 2FA\nuser journeys.",
    "descriptor": "",
    "authors": [
      "Sanam Ghorbani Lyastani",
      "Michael Backes",
      "Sven Bugiel"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.09373"
  },
  {
    "id": "arXiv:2210.09375",
    "title": "Reconstruction Attack on Differential Private Trajectory Protection  Mechanisms",
    "abstract": "Location trajectories collected by smartphones and other devices represent a\nvaluable data source for applications such as location-based services.\nLikewise, trajectories have the potential to reveal sensitive information about\nindividuals, e.g., religious beliefs or sexual orientations. Accordingly,\ntrajectory datasets require appropriate sanitization. Due to their strong\ntheoretical privacy guarantees, differential private publication mechanisms\nreceive much attention. However, the large amount of noise required to achieve\ndifferential privacy yields structural differences, e.g., ship trajectories\npassing over land. We propose a deep learning-based Reconstruction Attack on\nProtected Trajectories (RAoPT), that leverages the mentioned differences to\npartly reconstruct the original trajectory from a differential private release.\nThe evaluation shows that our RAoPT model can reduce the Euclidean and\nHausdorff distances between the released and original trajectories by over 68%\non two real-world datasets under protection with $\\varepsilon \\leq 1$. In this\nsetting, the attack increases the average Jaccard index of the trajectories'\nconvex hulls, representing a user's activity space, by over 180%. Trained on\nthe GeoLife dataset, the model still reduces the Euclidean and Hausdorff\ndistances by over 60% for T-Drive trajectories protected with a\nstate-of-the-art mechanism ($\\varepsilon = 0.1$). This work highlights\nshortcomings of current trajectory publication mechanisms, and thus motivates\nfurther research on privacy-preserving publication schemes.",
    "descriptor": "\nComments: To be published in the proceedings of the 38th Annual Computer Security Applications Conference (ACSAC '22)\n",
    "authors": [
      "Erik Buchholz",
      "Alsharif Abuadbba",
      "Shuo Wang",
      "Surya Nepal",
      "Salil S. Kanhere"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.09375"
  },
  {
    "id": "arXiv:2210.09377",
    "title": "6th Place Solution to Google Universal Image Embedding",
    "abstract": "This paper presents the 6th place solution to the Google Universal Image\nEmbedding competition on Kaggle. Our approach is based on the CLIP\narchitecture, a powerful pre-trained model used to learn visual representation\nfrom natural language supervision. We also utilized the SubCenter ArcFace loss\nwith dynamic margins to improve the distinctive power of class separability and\nembeddings. Finally, a diverse dataset has been created based on the test's set\ncategories and the leaderboard's feedback. By carefully crafting a training\nscheme to enhance transfer learning, our submission scored 0.685 on the private\nleaderboard.",
    "descriptor": "\nComments: Competition URL: this https URL\n",
    "authors": [
      "S. Gkelios",
      "A. Kastellos",
      "S. Chatzichristofis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.09377"
  },
  {
    "id": "arXiv:2210.09378",
    "title": "Learning Control Admissibility Models with Graph Neural Networks for  Multi-Agent Navigation",
    "abstract": "Deep reinforcement learning in continuous domains focuses on learning control\npolicies that map states to distributions over actions that ideally concentrate\non the optimal choices in each step. In multi-agent navigation problems, the\noptimal actions depend heavily on the agents' density. Their interaction\npatterns grow exponentially with respect to such density, making it hard for\nlearning-based methods to generalize. We propose to switch the learning\nobjectives from predicting the optimal actions to predicting sets of admissible\nactions, which we call control admissibility models (CAMs), such that they can\nbe easily composed and used for online inference for an arbitrary number of\nagents. We design CAMs using graph neural networks and develop training methods\nthat optimize the CAMs in the standard model-free setting, with the additional\nbenefit of eliminating the need for reward engineering typically required to\nbalance collision avoidance and goal-reaching requirements. We evaluate the\nproposed approach in multi-agent navigation environments. We show that the CAM\nmodels can be trained in environments with only a few agents and be easily\ncomposed for deployment in dense environments with hundreds of agents,\nachieving better performance than state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Chenning Yu",
      "Hongzhan Yu",
      "Sicun Gao"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.09378"
  },
  {
    "id": "arXiv:2210.09381",
    "title": "Learning Diversified Feature Representations for Facial Expression  Recognition in the Wild",
    "abstract": "Diversity of the features extracted by deep neural networks is important for\nenhancing the model generalization ability and accordingly its performance in\ndifferent learning tasks. Facial expression recognition in the wild has\nattracted interest in recent years due to the challenges existing in this area\nfor extracting discriminative and informative features from occluded images in\nreal-world scenarios. In this paper, we propose a mechanism to diversify the\nfeatures extracted by CNN layers of state-of-the-art facial expression\nrecognition architectures for enhancing the model capacity in learning\ndiscriminative features. To evaluate the effectiveness of the proposed\napproach, we incorporate this mechanism in two state-of-the-art models to (i)\ndiversify local/global features in an attention-based model and (ii) diversify\nfeatures extracted by different learners in an ensemble-based model.\nExperimental results on three well-known facial expression recognition\nin-the-wild datasets, AffectNet, FER+, and RAF-DB, show the effectiveness of\nour method, achieving the state-of-the-art performance of 89.99% on RAF-DB,\n89.34% on FER+ and the competitive accuracy of 60.02% on AffectNet dataset.",
    "descriptor": "\nComments: 5 pages, 3 figures, submitted to a conference\n",
    "authors": [
      "Negar Heidari",
      "Alexandros Iosifidis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09381"
  },
  {
    "id": "arXiv:2210.09382",
    "title": "Tight Analysis of Extra-gradient and Optimistic Gradient Methods For  Nonconvex Minimax Problems",
    "abstract": "Despite the established convergence theory of Optimistic Gradient Descent\nAscent (OGDA) and Extragradient (EG) methods for the convex-concave minimax\nproblems, little is known about the theoretical guarantees of these methods in\nnonconvex settings. To bridge this gap, for the first time, this paper\nestablishes the convergence of OGDA and EG methods under the\nnonconvex-strongly-concave (NC-SC) and nonconvex-concave (NC-C) settings by\nproviding a unified analysis through the lens of single-call extra-gradient\nmethods. We further establish lower bounds on the convergence of GDA/OGDA/EG,\nshedding light on the tightness of our analysis. We also conduct experiments\nsupporting our theoretical results. We believe our results will advance the\ntheoretical understanding of OGDA and EG methods for solving complicated\nnonconvex minimax real-world problems, e.g., Generative Adversarial Networks\n(GANs) or robust neural networks training.",
    "descriptor": "",
    "authors": [
      "Pouria Mahdavinia",
      "Yuyang Deng",
      "Haochuan Li",
      "Mehrdad Mahdavi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.09382"
  },
  {
    "id": "arXiv:2210.09385",
    "title": "Adaptive Oracle-Efficient Online Learning",
    "abstract": "The classical algorithms for online learning and decision-making have the\nbenefit of achieving the optimal performance guarantees, but suffer from\ncomputational complexity limitations when implemented at scale. More recent\nsophisticated techniques, which we refer to as oracle-efficient methods,\naddress this problem by dispatching to an offline optimization oracle that can\nsearch through an exponentially-large (or even infinite) space of decisions and\nselect that which performed the best on any dataset. But despite the benefits\nof computational feasibility, oracle-efficient algorithms exhibit one major\nlimitation: while performing well in worst-case settings, they do not adapt\nwell to friendly environments. In this paper we consider two such friendly\nscenarios, (a) \"small-loss\" problems and (b) IID data. We provide a new\nframework for designing follow-the-perturbed-leader algorithms that are\noracle-efficient and adapt well to the small-loss environment, under a\nparticular condition which we call approximability (which is spiritually\nrelated to sufficient conditions provided by Dud\\'{i}k et al., [2020]). We\nidentify a series of real-world settings, including online auctions and\ntransductive online classification, for which approximability holds. We also\nextend the algorithm to an IID data setting and establish a\n\"best-of-both-worlds\" bound in the oracle-efficient setting.",
    "descriptor": "",
    "authors": [
      "Guanghui Wang",
      "Zihao Hu",
      "Vidya Muthukumar",
      "Jacob Abernethy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.09385"
  },
  {
    "id": "arXiv:2210.09389",
    "title": "Potrika: Raw and Balanced Newspaper Datasets in the Bangla Language with  Eight Topics and Five Attributes",
    "abstract": "Knowledge is central to human and scientific developments. Natural Language\nProcessing (NLP) allows automated analysis and creation of knowledge. Data is a\ncrucial NLP and machine learning ingredient. The scarcity of open datasets is a\nwell-known problem in machine and deep learning research. This is very much the\ncase for textual NLP datasets in English and other major world languages. For\nthe Bangla language, the situation is even more challenging and the number of\nlarge datasets for NLP research is practically nil. We hereby present Potrika,\na large single-label Bangla news article textual dataset curated for NLP\nresearch from six popular online news portals in Bangladesh (Jugantor,\nJaijaidin, Ittefaq, Kaler Kontho, Inqilab, and Somoyer Alo) for the period\n2014-2020. The articles are classified into eight distinct categories\n(National, Sports, International, Entertainment, Economy, Education, Politics,\nand Science \\& Technology) providing five attributes (News Article, Category,\nHeadline, Publication Date, and Newspaper Source). The raw dataset contains\n185.51 million words and 12.57 million sentences contained in 664,880 news\narticles. Moreover, using NLP augmentation techniques, we create from the raw\n(unbalanced) dataset another (balanced) dataset comprising 320,000 news\narticles with 40,000 articles in each of the eight news categories. Potrika\ncontains both the datasets (raw and balanced) to suit a wide range of NLP\nresearch. By far, to the best of our knowledge, Potrika is the largest and the\nmost extensive dataset for news classification.",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Istiak Ahmad",
      "Fahad AlQurashi",
      "Rashid Mehmood"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.09389"
  },
  {
    "id": "arXiv:2210.09394",
    "title": "Review Learning: Alleviating Catastrophic Forgetting with Generative  Replay without Generator",
    "abstract": "When a deep learning model is sequentially trained on different datasets, it\nforgets the knowledge acquired from previous data, a phenomenon known as\ncatastrophic forgetting. It deteriorates performance of the deep learning model\non diverse datasets, which is critical in privacy-preserving deep learning\n(PPDL) applications based on transfer learning (TL). To overcome this, we\npropose review learning (RL), a generative-replay-based continual learning\ntechnique that does not require a separate generator. Data samples are\ngenerated from the memory stored within the synaptic weights of the deep\nlearning model which are used to review knowledge acquired from previous\ndatasets. The performance of RL was validated through PPDL experiments.\nSimulations and real-world medical multi-institutional experiments were\nconducted using three types of binary classification electronic health record\ndata. In the real-world experiments, the global area under the receiver\noperating curve was 0.710 for RL and 0.655 for TL. Thus, RL was highly\neffective in retaining previously learned knowledge.",
    "descriptor": "",
    "authors": [
      "Jaesung Yoo",
      "Sunghyuk Choi",
      "Ye Seul Yang",
      "Suhyeon Kim",
      "Jieun Choi",
      "Dongkyeong Lim",
      "Yaeji Lim",
      "Hyung Joon Joo",
      "Dae Jung Kim",
      "Rae Woong Park",
      "Hyeong-Jin Yoon",
      "Kwangsoo Kim"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09394"
  },
  {
    "id": "arXiv:2210.09396",
    "title": "Affective Idiosyncratic Responses to Music",
    "abstract": "Affective responses to music are highly personal. Despite consensus that\nidiosyncratic factors play a key role in regulating how listeners emotionally\nrespond to music, precisely measuring the marginal effects of these variables\nhas proved challenging. To address this gap, we develop computational methods\nto measure affective responses to music from over 403M listener comments on a\nChinese social music platform. Building on studies from music psychology in\nsystematic and quasi-causal analyses, we test for musical, lyrical, contextual,\ndemographic, and mental health effects that drive listener affective responses.\nFinally, motivated by the social phenomenon known as w\\v{a}ng-y\\`i-y\\'un, we\nidentify influencing factors of platform user self-disclosures, the social\nsupport they receive, and notable differences in discloser user activity.",
    "descriptor": "\nComments: EMNLP 2022 Main Conference; see Github this https URL\n",
    "authors": [
      "Sky CH-Wang",
      "Evan Li",
      "Oliver Li",
      "Smaranda Muresan",
      "Zhou Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.09396"
  },
  {
    "id": "arXiv:2210.09399",
    "title": "Probabilistic Forecasting Methods for System-Level Electricity Load  Forecasting",
    "abstract": "Load forecasts have become an integral part of energy security. Due to the\nvarious influencing factors that can be considered in such a forecast, there is\nalso a wide range of models that attempt to integrate these parameters into a\nsystem in various ways. Due to the growing importance of probabilistic load\nforecast models, different approaches are presented in this analysis. The focus\nis on different models from the short-term sector. After that, another model\nfrom the long-term sector is presented. Then, the presented models are put in\nrelation to each other and examined with reference to advantages and\ndisadvantages. Afterwards, the presented papers are analyzed with focus on\ntheir comparability to each other. Finally, an outlook on further areas of\ndevelopment in the literature will be discussed.",
    "descriptor": "",
    "authors": [
      "Philipp Giese"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.09399"
  },
  {
    "id": "arXiv:2210.09401",
    "title": "Link and Network-wide Study of Incoherent GN/EGN Models",
    "abstract": "An unprecedented comparison of closed-form incoherent GN (InGN) models is\npresented with heterogeneous spans and partially loaded links in elastic\noptical networks. Results reveal that with accumulated dispersion correction\nand modulation format terms, the InGN shows higher accuracy.",
    "descriptor": "",
    "authors": [
      "Farhad Arpanaei",
      "M.Ranjbar Zefreh",
      "Jose A.Hernandez",
      "Andrea Carena",
      "David Larrabeiti"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.09401"
  },
  {
    "id": "arXiv:2210.09404",
    "title": "Measures of Information Reflect Memorization",
    "abstract": "Neural networks are known to exploit spurious artifacts (or shortcuts) that\nco-occur with a target label, exhibiting heuristic memorization. On the other\nhand, networks have been shown to memorize training examples, resulting in\nexample-level memorization. These kinds of memorization impede generalization\nof networks beyond their training distributions. Detecting such memorization\ncould be challenging, often requiring researchers to curate tailored test sets.\nIn this work, we hypothesize -- and subsequently show -- that the diversity in\nthe activation patterns of different neurons is reflective of model\ngeneralization and memorization. We quantify the diversity in the neural\nactivations through information-theoretic measures and find support for our\nhypothesis on experiments spanning several natural language and vision tasks.\nImportantly, we discover that information organization points to the two forms\nof memorization, even for neural activations computed on unlabeled\nin-distribution examples. Lastly, we demonstrate the utility of our findings\nfor the problem of model selection. The associated code and other resources for\nthis work are available at https://linktr.ee/InformationMeasures .",
    "descriptor": "",
    "authors": [
      "Rachit Bansal",
      "Danish Pruthi",
      "Yonatan Belinkov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.09404"
  },
  {
    "id": "arXiv:2210.09405",
    "title": "Towards Generating Adversarial Examples on Mixed-type Data",
    "abstract": "The existence of adversarial attacks (or adversarial examples) brings huge\nconcern about the machine learning (ML) model's safety issues. For many\nsafety-critical ML tasks, such as financial forecasting, fraudulent detection,\nand anomaly detection, the data samples are usually mixed-type, which contain\nplenty of numerical and categorical features at the same time. However, how to\ngenerate adversarial examples with mixed-type data is still seldom studied. In\nthis paper, we propose a novel attack algorithm M-Attack, which can effectively\ngenerate adversarial examples in mixed-type data. Based on M-Attack, attackers\ncan attempt to mislead the targeted classification model's prediction, by only\nslightly perturbing both the numerical and categorical features in the given\ndata samples. More importantly, by adding designed regularizations, our\ngenerated adversarial examples can evade potential detection models, which\nmakes the attack indeed insidious. Through extensive empirical studies, we\nvalidate the effectiveness and efficiency of our attack method and evaluate the\nrobustness of existing classification models against our proposed attack. The\nexperimental results highlight the feasibility of generating adversarial\nexamples toward machine learning models in real-world applications.",
    "descriptor": "",
    "authors": [
      "Han Xu",
      "Menghai Pan",
      "Zhimeng Jiang",
      "Huiyuan Chen",
      "Xiaoting Li",
      "Mahashweta Das",
      "Hao Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.09405"
  },
  {
    "id": "arXiv:2210.09411",
    "title": "Multimodal Shared Autonomy for Social Navigation Assistance of  Telepresence Robots",
    "abstract": "Mobile telepresence robots (MTRs) have become increasingly popular in the\nexpanding world of remote work, providing new avenues for people to actively\nparticipate in activities at a distance. However, humans operating MTRs often\nhave difficulty navigating in densely populated environments due to limited\nsituation awareness and narrow field-of-view, which reduces user acceptance and\nsatisfaction. Shared autonomy in navigation has been studied primarily in\nstatic environments or in situations where only one pedestrian interacts with\nthe robot. We present a multimodal shared autonomy approach, leveraging visual\nand haptic guidance, to provide navigation assistance for remote operators in\ndensely-populated environments. It uses a modified form of reciprocal velocity\nobstacles for generating safe control inputs while taking social proxemics\nconstraints into account. Two different visual guidance designs, as well as\nhaptic force rendering, were proposed to convey safe control input. We\nconducted a user study to compare the merits and limitations of multimodal\nnavigation assistance to haptic or visual assistance alone on a shared\nnavigation task. The study involved 15 participants operating a virtual\ntelepresence robot in a virtual hall with moving pedestrians, using the\ndifferent assistance modalities. We evaluated navigation performance,\ntransparency and cooperation, as well as user preferences. Our results showed\nthat participants preferred multimodal assistance with a visual guidance\ntrajectory over haptic or visual modalities alone, although it had no impact on\nnavigation performance. Additionally, we found that visual guidance\ntrajectories conveyed a higher degree of understanding and cooperation than\nequivalent haptic cues in a navigation task.",
    "descriptor": "\nComments: 10 pages, 4 figures\n",
    "authors": [
      "Kenechukwu C. Mbanisi",
      "Michael A. Gennert"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.09411"
  },
  {
    "id": "arXiv:2210.09414",
    "title": "A Data-Driven Method for Locating Sensors and Selecting Alarm Thresholds  to Identify Violations of Voltage Limits in Distribution Systems",
    "abstract": "Stochastic fluctuations in power injections from distributed energy resources\n(DERs) combined with load variability can cause constraint violations (e.g.,\nexceeded voltage limits) in electric distribution systems. To monitor grid\noperations, sensors are placed to measure important quantities such as the\nvoltage magnitudes. In this paper, we consider a sensor placement problem which\nseeks to identify locations for installing sensors that can capture all\npossible violations of voltage magnitude limits. We formulate a bilevel\noptimization problem that minimizes the number of sensors and avoids false\nsensor alarms in the upper level while ensuring detection of any voltage\nviolations in the lower level. This problem is challenging due to the\nnonlinearity of the power flow equations and the presence of binary variables.\nAccordingly, we employ recently developed conservative linear approximations of\nthe power flow equations that overestimate or underestimate the voltage\nmagnitudes. By replacing the nonlinear power flow equations with conservative\nlinear approximations, we can ensure that the resulting sensor locations and\nthresholds are sufficient to identify any constraint violations. Additionally,\nwe apply various problem reformulations to significantly improve computational\ntractability while simultaneously ensuring an appropriate placement of sensors.\nLastly, we improve the quality of the results via an approximate gradient\ndescent method that adjusts the sensor thresholds. We demonstrate the\neffectiveness of our proposed method for several test cases, including a system\nwith multiple switching configurations.",
    "descriptor": "",
    "authors": [
      "Paprapee Buason",
      "Sidhant Misra",
      "Daniel K. Molzahn"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.09414"
  },
  {
    "id": "arXiv:2210.09420",
    "title": "Differentiable Physics Simulation of Dynamics-Augmented Neural Objects",
    "abstract": "We present a differentiable pipeline for simulating the motion of objects\nthat represent their geometry as a continuous density field parameterized as a\ndeep network. This includes Neural Radiance Fields (NeRFs), and other related\nmodels. From the density field, we estimate the dynamical properties of the\nobject, including its mass, center of mass, and inertia matrix. We then\nintroduce a differentiable contact model based on the density field for\ncomputing normal and friction forces resulting from collisions. This allows a\nrobot to autonomously build object models that are visually and dynamically\naccurate from still images and videos of objects in motion. The resulting\nDynamics-Augmented Neural Objects (DANOs) are simulated with an existing\ndifferentiable simulation engine, Dojo, interacting with other standard\nsimulation objects, such as spheres, planes, and robots specified as URDFs. A\nrobot can use this simulation to optimize grasps and manipulation trajectories\nof neural objects, or to improve the neural object models through\ngradient-based real-to-simulation transfer. We demonstrate the pipeline to\nlearn the coefficient of friction of a bar of soap from a real video of the\nsoap sliding on a table. We also learn the coefficient of friction and mass of\na Stanford bunny through interactions with a Panda robot arm from synthetic\ndata, and we optimize trajectories in simulation for the Panda arm to push the\nbunny to a goal location.",
    "descriptor": "",
    "authors": [
      "Simon Le Cleac'h",
      "Hong-Xing Yu",
      "Michelle Guo",
      "Taylor A. Howell",
      "Ruohan Gao",
      "Jiajun Wu",
      "Zachary Manchester",
      "Mac Schwager"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.09420"
  },
  {
    "id": "arXiv:2210.09421",
    "title": "Deepfake Text Detection: Limitations and Opportunities",
    "abstract": "Recent advances in generative models for language have enabled the creation\nof convincing synthetic text or deepfake text. Prior work has demonstrated the\npotential for misuse of deepfake text to mislead content consumers. Therefore,\ndeepfake text detection, the task of discriminating between human and\nmachine-generated text, is becoming increasingly critical. Several defenses\nhave been proposed for deepfake text detection. However, we lack a thorough\nunderstanding of their real-world applicability. In this paper, we collect\ndeepfake text from 4 online services powered by Transformer-based tools to\nevaluate the generalization ability of the defenses on content in the wild. We\ndevelop several low-cost adversarial attacks, and investigate the robustness of\nexisting defenses against an adaptive attacker. We find that many defenses show\nsignificant degradation in performance under our evaluation scenarios compared\nto their original claimed performance. Our evaluation shows that tapping into\nthe semantic information in the text content is a promising approach for\nimproving the robustness and generalization performance of deepfake text\ndetection schemes.",
    "descriptor": "\nComments: Accepted to IEEE S&P 2023; First two authors contributed equally to this work; 18 pages, 7 figures\n",
    "authors": [
      "Jiameng Pu",
      "Zain Sarwar",
      "Sifat Muhammad Abdullah",
      "Abdullah Rehman",
      "Yoonjin Kim",
      "Parantapa Bhattacharya",
      "Mobin Javed",
      "Bimal Viswanath"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09421"
  },
  {
    "id": "arXiv:2210.09427",
    "title": "A Pilot Study on Teacher-Facing Real-Time Classroom Game Dashboards",
    "abstract": "Educational games are an increasingly popular teaching tool in modern\nclassrooms. However, the development of complementary tools for teachers\nfacilitating classroom gameplay is lacking. We present the results of a\nparticipatory design process for a teacher-facing, real-time game data\ndashboard. This two-phase process included a workshop to elicit teachers'\nrequirements for such a tool, and a pilot study of our dashboard prototype. We\nanalyze post-gameplay survey and interview data to understand teachers'\nexperiences with the tool in terms of evidence of co-design, feasibility, and\neffectiveness. Our results indicate the participatory design yielded a tool\nboth useful for and usable by teachers within the context of a real class\ngameplay session. We advocate for the continued development of data-driven\nteacher tools to improve the effectiveness of games deployed in the classroom.",
    "descriptor": "\nComments: Presented at Meaningful Play 2022. East Lansing, MI\n",
    "authors": [
      "Luke Swanson",
      "David Gagnon",
      "Jennifer Scianna"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.09427"
  },
  {
    "id": "arXiv:2210.09428",
    "title": "Improving Low-Resource Cross-lingual Parsing with Expected Statistic  Regularization",
    "abstract": "We present Expected Statistic Regularization (ESR), a novel regularization\ntechnique that utilizes low-order multi-task structural statistics to shape\nmodel distributions for semi-supervised learning on low-resource datasets. We\nstudy ESR in the context of cross-lingual transfer for syntactic analysis (POS\ntagging and labeled dependency parsing) and present several classes of\nlow-order statistic functions that bear on model behavior. Experimentally, we\nevaluate the proposed statistics with ESR for unsupervised transfer on 5\ndiverse target languages and show that all statistics, when estimated\naccurately, yield improvements to both POS and LAS, with the best statistic\nimproving POS by +7.0 and LAS by +8.5 on average. We also present\nsemi-supervised transfer and learning curve experiments that show ESR provides\nsignificant gains over strong cross-lingual-transfer-plus-fine-tuning baselines\nfor modest amounts of label data. These results indicate that ESR is a\npromising and complementary approach to model-transfer approaches for\ncross-lingual parsing.",
    "descriptor": "\nComments: Accepted in TACL 2022, pre-MIT Press publication version\n",
    "authors": [
      "Thomas Effland",
      "Michael Collins"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.09428"
  },
  {
    "id": "arXiv:2210.09430",
    "title": "Evaluating Search Explainability with Psychometrics and Crowdsourcing",
    "abstract": "Information retrieval (IR) systems have become an integral part of our\neveryday lives. As search engines, recommender systems, and conversational\nagents are employed across various domains from recreational search to clinical\ndecision support, there is an increasing need for transparent and explainable\nsystems to guarantee accountable, fair, and unbiased results. Despite many\nrecent advances towards explainable AI and IR techniques, there is no consensus\non what it means for a system to be explainable. Although a growing body of\nliterature suggests that explainability is comprised of multiple subfactors,\nvirtually all existing approaches treat it as a singular notion. In this paper,\nwe examine explainability in Web search systems, leveraging psychometrics and\ncrowdsourcing to identify human-centered factors of explainability. Based on\nthese factors, we establish a continuous-scale evaluation instrument for\nexplainable search systems that allows researchers and practitioners to\ntrade-off performance in a more flexible manner than what was previously\npossible.",
    "descriptor": "",
    "authors": [
      "Catherine Chen",
      "Carsten Eickhoff"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.09430"
  },
  {
    "id": "arXiv:2210.09432",
    "title": "Deep Decarbonization of Multi-Energy Systems: A Carbon-Oriented  Framework with Cross Disciplinary Technologies",
    "abstract": "The retirement of unabated coal power plants, the plummeting cost of\nrenewable energy technologies, along with more aggressive public policies and\nregulatory reforms, are occurring at an unprecedented speed to decarbonize the\npower and energy systems towards the 2030 and 2050 climate goals. This article\naims to establish a carbon-oriented framework to examine the role carbon\nemission is playing within a power grid that is rapidly transitioning to an\nintegrated multi-energy system. We divide the carbon flows in the multi-energy\nsystems into three stages: carbon allowances initialization/allocation,\nexchanging/pricing, and circulation. Then, we discuss how cross-disciplinary\ntechnologies, such as game theory, optimization, and machine learning can\nfacilitate the modeling and analysis of the proposed framework.",
    "descriptor": "",
    "authors": [
      "Jian Shi",
      "Dan Wang",
      "Chenye Wu",
      "Zhu Han"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.09432"
  },
  {
    "id": "arXiv:2210.09433",
    "title": "Jo Wilder and the Capitol Case: A taxonomy of uses for a historical  inquiry game in 4th grade Classrooms in Wisconsin",
    "abstract": "In this paper, we study the various ways 3rd-5th grade educators in Wisconsin\nutilized Jo Wilder and the Capitol Case, a historical inquiry game, as part of\ntheir classroom instruction. The 15 educators involved in the study were all\ngrade school teachers in Wisconsin who took part in the \"Doing History\nFellowship\" program, a professional development opportunity offered by the\nauthors, designed to increase their understanding of historical inquiry\ninstruction and game-based learning. As part of the program, the educators\nplanned and implemented the game within their own classroom context and\nreported their results back to the authors and other educators. Through their\nreports, surveys and semi-structured interviews we discovered the educators\nwere motivated by five distinct instructional purposes, which influenced how\nthe game was integrated into their curriculum. In this paper, we name and\ndescribe these five purposes. We see these findings as useful insights into how\neducators think about games and how educational video games and corresponding\nprofessional development activities may be designed in the future.",
    "descriptor": "\nComments: Paper presented at Meaningful Play 2022. East Lansing, MI\n",
    "authors": [
      "Peter Wardrip",
      "David Gagnon",
      "James Mathews",
      "Jen Scianna"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.09433"
  },
  {
    "id": "arXiv:2210.09434",
    "title": "Modelling Emotion Dynamics in Song Lyrics with State Space Models",
    "abstract": "Most previous work in music emotion recognition assumes a single or a few\nsong-level labels for the whole song. While it is known that different emotions\ncan vary in intensity within a song, annotated data for this setup is scarce\nand difficult to obtain. In this work, we propose a method to predict emotion\ndynamics in song lyrics without song-level supervision. We frame each song as a\ntime series and employ a State Space Model (SSM), combining a sentence-level\nemotion predictor with an Expectation-Maximization (EM) procedure to generate\nthe full emotion dynamics. Our experiments show that applying our method\nconsistently improves the performance of sentence-level baselines without\nrequiring any annotated songs, making it ideal for limited training data\nscenarios. Further analysis through case studies shows the benefits of our\nmethod while also indicating the limitations and pointing to future directions.",
    "descriptor": "\nComments: To appear in Transactions of the Association for Computational Linguistics (TACL); 17 pages, 4 figures\n",
    "authors": [
      "Yingjin Song",
      "Daniel Beck"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.09434"
  },
  {
    "id": "arXiv:2210.09435",
    "title": "Robot Learning Theory of Mind through Self-Observation: Exploiting the  Intentions-Beliefs Synergy",
    "abstract": "In complex environments, where the human sensory system reaches its limits,\nour behaviour is strongly driven by our beliefs about the state of the world\naround us. Accessing others' beliefs, intentions, or mental states in general,\ncould thus allow for more effective social interactions in natural contexts.\nYet these variables are not directly observable. Theory of Mind (TOM), the\nability to attribute to other agents' beliefs, intentions, or mental states in\ngeneral,\nis a crucial feature of human social interaction and has become of interest\nto the robotics community. Recently, new models that are able to learn TOM have\nbeen introduced. In this paper, we show the synergy between learning to predict\nlow-level mental states, such as intentions and goals, and attributing\nhigh-level ones, such as beliefs. Assuming that learning of beliefs can take\nplace by observing own decision and beliefs estimation processes in partially\nobservable environments and using a simple feed-forward deep learning model, we\nshow that when learning to predict others' intentions and actions, faster and\nmore accurate predictions can be acquired if beliefs attribution is learnt\nsimultaneously with action and intentions prediction. We show that the learning\nperformance improves even when observing agents with a different decision\nprocess and is higher when observing beliefs-driven chunks of behaviour. We\npropose that our architectural approach can be relevant for the design of\nfuture adaptive social robots that should be able to autonomously understand\nand assist human partners in novel natural environments and tasks.",
    "descriptor": "",
    "authors": [
      "Francesca Bianco",
      "Dimitri Ognibene"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09435"
  },
  {
    "id": "arXiv:2210.09439",
    "title": "CAN-BERT do it? Controller Area Network Intrusion Detection System based  on BERT Language Model",
    "abstract": "Due to the rising number of sophisticated customer functionalities,\nelectronic control units (ECUs) are increasingly integrated into modern\nautomotive systems. However, the high connectivity between the in-vehicle and\nthe external networks paves the way for hackers who could exploit in-vehicle\nnetwork protocols' vulnerabilities. Among these protocols, the Controller Area\nNetwork (CAN), known as the most widely used in-vehicle networking technology,\nlacks encryption and authentication mechanisms, making the communications\ndelivered by distributed ECUs insecure. Inspired by the outstanding performance\nof bidirectional encoder representations from transformers (BERT) for improving\nmany natural language processing tasks, we propose in this paper ``CAN-BERT\", a\ndeep learning based network intrusion detection system, to detect cyber attacks\non CAN bus protocol. We show that the BERT model can learn the sequence of\narbitration identifiers (IDs) in the CAN bus for anomaly detection using the\n``masked language model\" unsupervised training objective. The experimental\nresults on the ``Car Hacking: Attack \\& Defense Challenge 2020\" dataset show\nthat ``CAN-BERT\" outperforms state-of-the-art approaches. In addition to being\nable to identify in-vehicle intrusions in real-time within 0.8 ms to 3 ms w.r.t\nCAN ID sequence length, it can also detect a wide variety of cyberattacks with\nan F1-score of between 0.81 and 0.99.",
    "descriptor": "",
    "authors": [
      "Natasha Alkhatib",
      "Maria Mushtaq",
      "Hadi Ghauch",
      "Jean-Luc Danger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.09439"
  },
  {
    "id": "arXiv:2210.09440",
    "title": "Using Bottleneck Adapters to Identify Cancer in Clinical Notes under  Low-Resource Constraints",
    "abstract": "Processing information locked within clinical health records is a challenging\ntask that remains an active area of research in biomedical NLP. In this work,\nwe evaluate a broad set of machine learning techniques ranging from simple RNNs\nto specialised transformers such as BioBERT on a dataset containing clinical\nnotes along with a set of annotations indicating whether a sample is\ncancer-related or not.\nFurthermore, we specifically employ efficient fine-tuning methods from NLP,\nnamely, bottleneck adapters and prompt tuning, to adapt the models to our\nspecialised task. Our evaluations suggest that fine-tuning a frozen BERT model\npre-trained on natural language and with bottleneck adapters outperforms all\nother strategies, including full fine-tuning of the specialised BioBERT model.\nBased on our findings, we suggest that using bottleneck adapters in\nlow-resource situations with limited access to labelled data or processing\ncapacity could be a viable strategy in biomedical text mining. The code used in\nthe experiments are going to be made available at\nhttps://github.com/omidrohanian/bottleneck-adapters.",
    "descriptor": "",
    "authors": [
      "Omid Rohanian",
      "Hannah Jauncey",
      "Mohammadmahdi Nouriborji",
      "Bronner P. Gon\u00e7alves",
      "Christiana Kartsonaki",
      "ISARIC Clinical Characterisation Group",
      "Laura Merson",
      "David Clifton"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.09440"
  },
  {
    "id": "arXiv:2210.09441",
    "title": "Real-Time Driver Monitoring Systems through Modality and View Analysis",
    "abstract": "Driver distractions are known to be the dominant cause of road accidents.\nWhile monitoring systems can detect non-driving-related activities and\nfacilitate reducing the risks, they must be accurate and efficient to be\napplicable. Unfortunately, state-of-the-art methods prioritize accuracy while\nignoring latency because they leverage cross-view and multimodal videos in\nwhich consecutive frames are highly similar. Thus, in this paper, we pursue\ntime-effective detection models by neglecting the temporal relation between\nvideo frames and investigate the importance of each sensing modality in\ndetecting drives' activities. Experiments demonstrate that 1) our proposed\nalgorithms are real-time and can achieve similar performances (97.5\\% AUC-PR)\nwith significantly reduced computation compared with video-based models; 2) the\ntop view with the infrared channel is more informative than any other single\nmodality. Furthermore, we enhance the DAD dataset by manually annotating its\ntest set to enable multiclassification. We also thoroughly analyze the\ninfluence of visual sensor types and their placements on the prediction of each\nclass. The code and the new labels will be released.",
    "descriptor": "\nComments: Paper summaries that our work on the DAD dataset\n",
    "authors": [
      "Yiming Ma",
      "Victor Sanchez",
      "Soodeh Nikan",
      "Devesh Upadhyay",
      "Bhushan Atote",
      "Tanaya Guha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.09441"
  },
  {
    "id": "arXiv:2210.09446",
    "title": "Deformably-Scaled Transposed Convolution",
    "abstract": "Transposed convolution is crucial for generating high-resolution outputs, yet\nhas received little attention compared to convolution layers. In this work we\nrevisit transposed convolution and introduce a novel layer that allows us to\nplace information in the image selectively and choose the `stroke breadth' at\nwhich the image is synthesized, whilst incurring a small additional parameter\ncost. For this we introduce three ideas: firstly, we regress offsets to the\npositions where the transpose convolution results are placed; secondly we\nbroadcast the offset weight locations over a learnable neighborhood; and\nthirdly we use a compact parametrization to share weights and restrict offsets.\nWe show that simply substituting upsampling operators with our novel layer\nproduces substantial improvements across tasks as diverse as instance\nsegmentation, object detection, semantic segmentation, generative image\nmodeling, and 3D magnetic resonance image enhancement, while outperforming all\nexisting variants of transposed convolutions. Our novel layer can be used as a\ndrop-in replacement for 2D and 3D upsampling operators and the code will be\npublicly available.",
    "descriptor": "",
    "authors": [
      "Stefano B. Blumberg",
      "Daniele Rav\u00ed",
      "Mou-Cheng Xu",
      "Matteo Figini",
      "Iasonas Kokkinos",
      "Daniel C. Alexander"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2210.09446"
  },
  {
    "id": "arXiv:2210.09452",
    "title": "Multiple Instance Learning via Iterative Self-Paced Supervised  Contrastive Learning",
    "abstract": "Learning representations for individual instances when only bag-level labels\nare available is a fundamental challenge in multiple instance learning (MIL).\nRecent works have shown promising results using contrastive self-supervised\nlearning (CSSL), which learns to push apart representations corresponding to\ntwo different randomly-selected instances. Unfortunately, in real-world\napplications such as medical image classification, there is often class\nimbalance, so randomly-selected instances mostly belong to the same majority\nclass, which precludes CSSL from learning inter-class differences. To address\nthis issue, we propose a novel framework, Iterative Self-paced Supervised\nContrastive Learning for MIL Representations (ItS2CLR), which improves the\nlearned representation by exploiting instance-level pseudo labels derived from\nthe bag-level labels. The framework employs a novel self-paced sampling\nstrategy to ensure the accuracy of pseudo labels. We evaluate ItS2CLR on three\nmedical datasets, showing that it improves the quality of instance-level pseudo\nlabels and representations, and outperforms existing MIL methods in terms of\nboth bag and instance level accuracy.",
    "descriptor": "\nComments: The first two authors contribute equally. The last two authors are joint last authors\n",
    "authors": [
      "Kangning Liu",
      "Weicheng Zhu",
      "Yiqiu Shen",
      "Sheng Liu",
      "Narges Razavian",
      "Krzysztof J. Geras",
      "Carlos Fernandez-Granda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09452"
  },
  {
    "id": "arXiv:2210.09455",
    "title": "Track Targets by Dense Spatio-Temporal Position Encoding",
    "abstract": "In this work, we propose a novel paradigm to encode the position of targets\nfor target tracking in videos using transformers. The proposed paradigm, Dense\nSpatio-Temporal (DST) position encoding, encodes spatio-temporal position\ninformation in a pixel-wise dense fashion. The provided position encoding\nprovides location information to associate targets across frames beyond\nappearance matching by comparing objects in two bounding boxes. Compared to the\ntypical transformer positional encoding, our proposed encoding is applied to\nthe 2D CNN features instead of the projected feature vectors to avoid losing\npositional information. Moreover, the designed DST encoding can represent the\nlocation of a single-frame object and the evolution of the location of the\ntrajectory among frames uniformly. Integrated with the DST encoding, we build a\ntransformer-based multi-object tracking model. The model takes a video clip as\ninput and conducts the target association in the clip. It can also perform\nonline inference by associating existing trajectories with objects from the\nnew-coming frames. Experiments on video multi-object tracking (MOT) and\nmulti-object tracking and segmentation (MOTS) datasets demonstrate the\neffectiveness of the proposed DST position encoding.",
    "descriptor": "\nComments: 10 pages, 3 figures, accepted by BMVC 2022 (oral)\n",
    "authors": [
      "Jinkun Cao",
      "Hao Wu",
      "Kris Kitani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.09455"
  },
  {
    "id": "arXiv:2210.09459",
    "title": "Extensible Proxy for Efficient NAS",
    "abstract": "Neural Architecture Search (NAS) has become a de facto approach in the recent\ntrend of AutoML to design deep neural networks (DNNs). Efficient or\nnear-zero-cost NAS proxies are further proposed to address the demanding\ncomputational issues of NAS, where each candidate architecture network only\nrequires one iteration of backpropagation. The values obtained from the proxies\nare considered the predictions of architecture performance on downstream tasks.\nHowever, two significant drawbacks hinder the extended usage of Efficient NAS\nproxies. (1) Efficient proxies are not adaptive to various search spaces. (2)\nEfficient proxies are not extensible to multi-modality downstream tasks. Based\non the observations, we design a Extensible proxy (Eproxy) that utilizes\nself-supervised, few-shot training (i.e., 10 iterations of backpropagation)\nwhich yields near-zero costs. The key component that makes Eproxy efficient is\nan untrainable convolution layer termed barrier layer that add the\nnon-linearities to the optimization spaces so that the Eproxy can discriminate\nthe performance of architectures in the early stage. Furthermore, to make\nEproxy adaptive to different downstream tasks/search spaces, we propose a\nDiscrete Proxy Search (DPS) to find the optimized training settings for Eproxy\nwith only handful of benchmarked architectures on the target tasks. Our\nextensive experiments confirm the effectiveness of both Eproxy and Eproxy+DPS.\nCode is available at https://github.com/leeyeehoo/GenNAS-Zero.",
    "descriptor": "",
    "authors": [
      "Yuhong Li",
      "Jiajie Li",
      "Cong Han",
      "Pan Li",
      "Jinjun Xiong",
      "Deming Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09459"
  },
  {
    "id": "arXiv:2210.09460",
    "title": "System-Specific Interpreters Make Megasystems Friendlier",
    "abstract": "Modern operating systems, browsers, and office suites have become megasystems\nbuilt on millions of lines of code. Their sheer size can intimidate even\nexperienced users and programmers away from attempting to understand and modify\nthe software running on their machines. This paper introduces system-specific\ninterpreters (SSIs) as a tool to help users regain knowledge of and control\nover megasystems. SSIs directly execute individual modules of a megasystem in a\ngdb-like environment without forcing the user to build, run, and trace the\nentire system. A prototype framework to help write SSIs is described in this\npaper and available for download at https://github.com/matthewsot/ssi-live22.",
    "descriptor": "\nComments: To appear at the Eight Workshop on Live Programming (LIVE 2022)\n",
    "authors": [
      "Matthew Sotoudeh"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.09460"
  },
  {
    "id": "arXiv:2210.09461",
    "title": "Token Merging: Your ViT But Faster",
    "abstract": "We introduce Token Merging (ToMe), a simple method to increase the throughput\nof existing ViT models without needing to train. ToMe gradually combines\nsimilar tokens in a transformer using a general and light-weight matching\nalgorithm that is as fast as pruning while being more accurate. Off-the-shelf,\nToMe can 2x the throughput of state-of-the-art ViT-L @ 512 and ViT-H @ 518\nmodels on images and 2.2x the throughput of ViT-L on video with only a 0.2-0.3%\naccuracy drop in each case. ToMe can also easily be applied during training,\nimproving in practice training speed up to 2x for MAE fine-tuning on video.\nTraining with ToMe further minimizes accuracy drop, leading to 2x the\nthroughput of ViT-B on audio for only a 0.4% mAP drop. Qualitatively, we find\nthat ToMe merges object parts into one token, even over multiple frames of\nvideo. Overall, ToMe's accuracy and speed are competitive with state-of-the-art\non images, video, and audio.",
    "descriptor": "\nComments: Preprint. Code will be available here: this https URL\n",
    "authors": [
      "Daniel Bolya",
      "Cheng-Yang Fu",
      "Xiaoliang Dai",
      "Peizhao Zhang",
      "Christoph Feichtenhofer",
      "Judy Hoffman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09461"
  },
  {
    "id": "arXiv:2210.09463",
    "title": "Morig: Motion-aware rigging of character meshes from point clouds",
    "abstract": "We present MoRig, a method that automatically rigs character meshes driven by\nsingle-view point cloud streams capturing the motion of performing characters.\nOur method is also able to animate the 3D meshes according to the captured\npoint cloud motion. MoRig's neural network encodes motion cues from the point\nclouds into features that are informative about the articulated parts of the\nperforming character. These motion-aware features guide the inference of an\nappropriate skeletal rig for the input mesh, which is then animated based on\nthe point cloud motion. Our method can rig and animate diverse characters,\nincluding humanoids, quadrupeds, and toys with varying articulation. It\naccounts for occluded regions in the point clouds and mismatches in the part\nproportions between the input mesh and captured character. Compared to other\nrigging approaches that ignore motion cues, MoRig produces more accurate rigs,\nwell-suited for re-targeting motion from captured characters.",
    "descriptor": "\nComments: SIGGRAPH ASIA 2022\n",
    "authors": [
      "Zhan Xu",
      "Yang Zhou",
      "Li Yi",
      "Evangelos Kalogerakis"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09463"
  },
  {
    "id": "arXiv:2210.09465",
    "title": "Understanding CNN Fragility When Learning With Imbalanced Data",
    "abstract": "Convolutional neural networks (CNNs) have achieved impressive results on\nimbalanced image data, but they still have difficulty generalizing to minority\nclasses and their decisions are difficult to interpret. These problems are\nrelated because the method by which CNNs generalize to minority classes, which\nrequires improvement, is wrapped in a blackbox. To demystify CNN decisions on\nimbalanced data, we focus on their latent features. Although CNNs embed the\npattern knowledge learned from a training set in model parameters, the effect\nof this knowledge is contained in feature and classification embeddings (FE and\nCE). These embeddings can be extracted from a trained model and their global,\nclass properties (e.g., frequency, magnitude and identity) can be analyzed. We\nfind that important information regarding the ability of a neural network to\ngeneralize to minority classes resides in the class top-K CE and FE. We show\nthat a CNN learns a limited number of class top-K CE per category, and that\ntheir number and magnitudes vary based on whether the same class is balanced or\nimbalanced. This calls into question whether a CNN has learned intrinsic class\nfeatures, or merely frequently occurring ones that happen to exist in the\nsampled class distribution. We also hypothesize that latent class diversity is\nas important as the number of class examples, which has important implications\nfor re-sampling and cost-sensitive methods. These methods generally focus on\nrebalancing model weights, class numbers and margins; instead of diversifying\nclass latent features through augmentation. We also demonstrate that a CNN has\ndifficulty generalizing to test data if the magnitude of its top-K latent\nfeatures do not match the training set. We use three popular image datasets and\ntwo cost-sensitive algorithms commonly employed in imbalanced learning for our\nexperiments.",
    "descriptor": "",
    "authors": [
      "Damien Dablain",
      "Kristen N. Jacobson",
      "Colin Bellinger",
      "Mark Roberts",
      "Nitesh Chawla"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09465"
  },
  {
    "id": "arXiv:2210.09466",
    "title": "Anisotropic Multi-Scale Graph Convolutional Network for Dense Shape  Correspondence",
    "abstract": "This paper studies 3D dense shape correspondence, a key shape analysis\napplication in computer vision and graphics. We introduce a novel hybrid\ngeometric deep learning-based model that learns geometrically meaningful and\ndiscretization-independent features with a U-Net model as the primary node\nfeature extraction module, followed by a successive spectral-based graph\nconvolutional network. To create a diverse set of filters, we use anisotropic\nwavelet basis filters, being sensitive to both different directions and\nband-passes. This filter set overcomes the over-smoothing behavior of\nconventional graph neural networks. To further improve the model's performance,\nwe add a function that perturbs the feature maps in the last layer ahead of\nfully connected layers, forcing the network to learn more discriminative\nfeatures overall. The resulting correspondence maps show state-of-the-art\nperformance on the benchmark datasets based on average geodesic errors and\nsuperior robustness to discretization in 3D meshes. Our approach provides new\ninsights and practical solutions to the dense shape correspondence research.",
    "descriptor": "\nComments: 10 pages, 8 figures, 2 tables. Accepted as a conference paper to WACV2023\n",
    "authors": [
      "Mohammad Farazi",
      "Wenhui Zhu",
      "Zhangsihao Yang",
      "Yalin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09466"
  },
  {
    "id": "arXiv:2210.09467",
    "title": "Adversarial and Safely Scaled Question Generation",
    "abstract": "Question generation has recently gained a lot of research interest,\nespecially with the advent of large language models. In and of itself, question\ngeneration can be considered 'AI-hard', as there is a lack of unanimously\nagreed sense of what makes a question 'good' or 'bad'. In this paper, we tackle\ntwo fundamental problems in parallel: on one hand, we try to solve the scaling\nproblem, where question-generation and answering applications have to be\napplied to a massive amount of text without ground truth labeling. The usual\napproach to solve this problem is to either downsample or summarize. However,\nthere are critical risks of misinformation with these approaches. On the other\nhand, and related to the misinformation problem, we try to solve the 'safety'\nproblem, as many public institutions rely on a much higher level of accuracy\nfor the content they provide. We introduce an adversarial approach to tackle\nthe question generation safety problem with scale. Specifically, we designed a\nquestion-answering system that specifically prunes out unanswerable questions\nthat may be generated, and further increases the quality of the answers that\nare generated. We build a production-ready, easily-plugged pipeline that can be\nused on any given body of text, that is scalable and immune from generating any\nhate speech, profanity, or misinformation. Based on the results, we are able to\ngenerate more than six times the number of quality questions generated by the\nabstractive approach, with a perceived quality being 44% higher, according to a\nsurvey of 168 participants.",
    "descriptor": "\nComments: 15 pages, 8 figures, 2 tables\n",
    "authors": [
      "Sreehari Sankar",
      "Zhihang Dong"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.09467"
  },
  {
    "id": "arXiv:2210.09468",
    "title": "Optimal Control Strategy for Linear Systems with Time Varying Random  Plant Parameters",
    "abstract": "We propose an open loop control scheme for linear systems with time-varying\nrandom elements in the plant's state matrix. This paper focuses on joint chance\nconstraints for potentially time-varying target sets. Under assumption of\nfinite and known expectation and variance, we use the one-sided\nVysochanskij-Petunin inequality to reformulate joint chance constraints into a\ntractable form. We demonstrate our methodology on two resource allocation\nproblems. One involving a two-bus power system with stochastic load and wind\npower generation and the second allocation of labor hours to control an\ninvasive plant population. We compare our method with situation approach and\nparticle control. We show that in both situations the proposed method had\nsuperior solve times and favorable optimally considerations.",
    "descriptor": "\nComments: Initial submission for ACC 2023\n",
    "authors": [
      "Shawn Priore",
      "Ali Bidram",
      "Meeko Oishi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.09468"
  },
  {
    "id": "arXiv:2210.09472",
    "title": "Multi-granularity Argument Mining in Legal Texts",
    "abstract": "In this paper, we explore legal argument mining using multiple levels of\ngranularity. Argument mining has usually been conceptualized as a sentence\nclassification problem. In this work, we conceptualize argument mining as a\ntoken-level (i.e., word-level) classification problem. We use a Longformer\nmodel to classify the tokens. Results show that token-level text classification\nidentifies certain legal argument elements more accurately than sentence-level\ntext classification. Token-level classification also provides greater\nflexibility to analyze legal texts and to gain more insight into what the model\nfocuses on when processing a large amount of input data.",
    "descriptor": "",
    "authors": [
      "Huihui Xu",
      "Kevin Ashley"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.09472"
  },
  {
    "id": "arXiv:2210.09474",
    "title": "Leveraging Non-dialogue Summaries for Dialogue Summarization",
    "abstract": "To mitigate the lack of diverse dialogue summarization datasets in academia,\nwe present methods to utilize non-dialogue summarization data for enhancing\ndialogue summarization systems. We apply transformations to document\nsummarization data pairs to create training data that better befit dialogue\nsummarization. The suggested transformations also retain desirable properties\nof non-dialogue datasets, such as improved faithfulness to the source text. We\nconduct extensive experiments across both English and Korean to verify our\napproach. Although absolute gains in ROUGE naturally plateau as more dialogue\nsummarization samples are introduced, utilizing non-dialogue data for training\nsignificantly improves summarization performance in zero- and few-shot settings\nand enhances faithfulness across all training regimes.",
    "descriptor": "\nComments: Transcript Understanding Workshop at COLING 2022\n",
    "authors": [
      "Seongmin Park",
      "Dongchan Shin",
      "Jihwa Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.09474"
  },
  {
    "id": "arXiv:2210.09475",
    "title": "AMPNet: Attention as Message Passing for Graph Neural Networks",
    "abstract": "Feature-level interactions between nodes can carry crucial information for\nunderstanding complex interactions in graph-structured data. Current\ninterpretability techniques, however, are limited in their ability to capture\nfeature-level interactions between different nodes. In this work, we propose\nAMPNet, a general Graph Neural Network (GNN) architecture for uncovering\nfeature-level interactions between different spatial locations within\ngraph-structured data. Our framework applies a multiheaded attention operation\nduring message-passing to contextualize messages based on the feature\ninteractions between different nodes. We evaluate AMPNet on several benchmark\nand real-world datasets, and develop a synthetic benchmark based on cyclic\ncellular automata to test the ability of our framework to recover cyclic\npatterns in node states based on feature-interactions. We also propose several\nmethods for addressing the scalability of our architecture to large graphs,\nincluding subgraph sampling during training and node feature downsampling.",
    "descriptor": "\nComments: 9 pages, 3 figures\n",
    "authors": [
      "S. A. Rizvi",
      "N. Nguyen",
      "H. Lyu",
      "B. Christensen",
      "J. O. Caro",
      "E. Zappala",
      "M. Brbic",
      "R. M. Dhodapkar",
      "D. V. Dijk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09475"
  },
  {
    "id": "arXiv:2210.09476",
    "title": "Contextuality in distributed systems",
    "abstract": "We present a lattice of distributed program specifications, whose ordering\nrepresents implementability/refinement. Specifications are modelled by families\nof subsets of relative execution traces, which encode the local orderings of\nstate transitions, rather than their absolute timing according to a global\nclock. This is to overcome fundamental physical difficulties with\nsynchronisation. The lattice of specifications is assembled and analysed with\nseveral established mathematical tools. Sets of nondegenerate cells of a\nsimplicial set model relative traces, presheaves model the parametrisation of\nthese traces by a topological space of variables, and information algebras\nreveal novel constraints on program correctness. The latter aspect brings the\nenterprise of program specification under the widening umbrella of contextual\nsemantics introduced by Abramsky et al. In this model of program\nspecifications, contextuality manifests as a failure of a consistency criterion\ncomparable to Lamport's definition of sequential consistency. The theory of\ninformation algebras also suggests efficient local computation algorithms for\nthe verification of this criterion. The novel constructions in this paper have\nbeen verified in the proof assistant Isabelle/HOL.",
    "descriptor": "\nComments: 23 pages\n",
    "authors": [
      "Nasos Evangelou-Oost",
      "Callum Bannister",
      "Ian J. Hayes"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.09476"
  },
  {
    "id": "arXiv:2210.09477",
    "title": "UniTune: Text-Driven Image Editing by Fine Tuning an Image Generation  Model on a Single Image",
    "abstract": "We present UniTune, a simple and novel method for general text-driven image\nediting. UniTune gets as input an arbitrary image and a textual edit\ndescription, and carries out the edit while maintaining high semantic and\nvisual fidelity to the input image. UniTune uses text, an intuitive interface\nfor art-direction, and does not require additional inputs, like masks or\nsketches. At the core of our method is the observation that with the right\nchoice of parameters, we can fine-tune a large text-to-image diffusion model on\na single image, encouraging the model to maintain fidelity to the input image\nwhile still allowing expressive manipulations. We used Imagen as our\ntext-to-image model, but we expect UniTune to work with other large-scale\nmodels as well. We test our method in a range of different use cases, and\ndemonstrate its wide applicability.",
    "descriptor": "",
    "authors": [
      "Dani Valevski",
      "Matan Kalman",
      "Yossi Matias",
      "Yaniv Leviathan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09477"
  },
  {
    "id": "arXiv:2210.09479",
    "title": "Approximate Stochastic Optimal Control for Linear Time Invariant Systems  with Heavy-tailed Disturbances",
    "abstract": "We propose an open loop control scheme for linear time invariant systems\nperturbed by multivariate $t$ disturbances through the use of quantile\nreformulations. The multivariate $t$ disturbance is motivated by heavy tailed\nphenomena that arise in multi-vehicle planning planning problems through\nunmodeled perturbation forces, linearization effects, or faulty actuators. Our\napproach relies on convex quantile reformulations of the polytopic target sets\nand norm based collision avoidance constraints to enable fast computation. We\nembed quantile approximations of the Student's $t$ distribution and the beta\nprime distribution in a difference-of-convex function framework to compute\nprovably safe but likely suboptimal controllers. We demonstrate our method with\nthree satellite rendezvous examples and provide a comparison with particle\ncontrol.",
    "descriptor": "\nComments: Initial submission to AIAA Journal of Guidance, Control, and Dynamics\n",
    "authors": [
      "Shawn Priore",
      "Christopher Petersen",
      "Meeko Oishi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.09479"
  },
  {
    "id": "arXiv:2210.09481",
    "title": "FPGA Hardware Acceleration for Feature-Based Relative Navigation  Applications",
    "abstract": "Estimation of rigid transformation between two point clouds is a\ncomputationally challenging problem in vision-based relative navigation.\nTargeting a real-time navigation solution utilizing point-cloud and image\nregistration algorithms, this paper develops high-performance avionics for\npower and resource constrained pose estimation framework. A Field-Programmable\nGate Array (FPGA) based embedded architecture is developed to accelerate\nestimation of relative pose between the point-clouds, aided by image features\nthat correspond to the individual point sets. At algorithmic level, the pose\nestimation method is an adaptation of Optimal Linear Attitude and Translation\nEstimator (OLTAE) for relative attitude and translation estimation. At the\narchitecture level, the proposed embedded solution is a hardware/software\nco-design that evaluates the OLTAE computations on the bare-metal hardware for\nhigh-speed state estimation. The finite precision FPGA evaluation of the OLTAE\nalgorithm is compared with a double-precision evaluation on MATLAB for\nperformance analysis and error quantification. Implementation results of the\nproposed finite-precision OLTAE accelerator demonstrate the high-performance\ncompute capabilities of the FPGA-based pose estimation while offering relative\nnumerical errors below 7%.",
    "descriptor": "\nComments: Proceedings of 2022 Astrodynamics Specialist Conference, Charlotte, USA\n",
    "authors": [
      "Ramchander Rao Bhaskara",
      "Manoranjan Majji"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Hardware Architecture (cs.AR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.09481"
  },
  {
    "id": "arXiv:2210.09482",
    "title": "You Can't See Me: Physical Removal Attacks on LiDAR-based Autonomous  Vehicles Driving Frameworks",
    "abstract": "Autonomous Vehicles (AVs) increasingly use LiDAR-based object detection\nsystems to perceive other vehicles and pedestrians on the road. While existing\nattacks on LiDAR-based autonomous driving architectures focus on lowering the\nconfidence score of AV object detection models to induce obstacle misdetection,\nour research discovers how to leverage laser-based spoofing techniques to\nselectively remove the LiDAR point cloud data of genuine obstacles at the\nsensor level before being used as input to the AV perception. The ablation of\nthis critical LiDAR information causes autonomous driving obstacle detectors to\nfail to identify and locate obstacles and, consequently, induces AVs to make\ndangerous automatic driving decisions. In this paper, we present a method\ninvisible to the human eye that hides objects and deceives autonomous vehicles'\nobstacle detectors by exploiting inherent automatic transformation and\nfiltering processes of LiDAR sensor data integrated with autonomous driving\nframeworks. We call such attacks Physical Removal Attacks (PRA), and we\ndemonstrate their effectiveness against three popular AV obstacle detectors\n(Apollo, Autoware, PointPillars), and we achieve 45{\\deg} attack capability. We\nevaluate the attack impact on three fusion models (Frustum-ConvNet, AVOD, and\nIntegrated-Semantic Level Fusion) and the consequences on the driving decision\nusing LGSVL, an industry-grade simulator. In our moving vehicle scenarios, we\nachieve a 92.7% success rate removing 90% of a target obstacle's cloud points.\nFinally, we demonstrate the attack's success against two popular defenses\nagainst spoofing and object hiding attacks and discuss two enhanced defense\nstrategies to mitigate our attack.",
    "descriptor": "",
    "authors": [
      "Yulong Cao",
      "S. Hrushikesh Bhupathiraju",
      "Pirouz Naghavi",
      "Takeshi Sugawara",
      "Z. Morley Mao",
      "Sara Rampazzi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.09482"
  },
  {
    "id": "arXiv:2210.09484",
    "title": "PaST-NoC: A Packet-Switched Superconducting Temporal NoC",
    "abstract": "Temporal computing promises to mitigate the stringent area constraints and\nclock distribution overheads of traditional superconducting digital computing.\nTo design a scalable, area- and power-efficient superconducting network on chip\n(NoC), we propose packet-switched superconducting temporal NoC (PaST-NoC).\nPaST-NoC operates its control path in the temporal domain using race logic\n(RL), combined with bufferless deflection flow control to minimize area.\nPackets encode their destination using RL and carry a collection of data pulses\nthat the receiver can interpret as pulse trains, RL, serialized binary, or\nother formats. We demonstrate how to scale up PaST-NoC to arbitrary topologies\nbased on 2x2 routers and 4x4 butterflies as building blocks. As we show, if\ndata pulses are interpreted using RL, PaST-NoC outperforms state-of-the-art\nsuperconducting binary NoCs in throughput per area by as much as 5X for long\npackets.",
    "descriptor": "\nComments: 22 pages, 17 figures, 2 tables. Preprint for future publication\n",
    "authors": [
      "Darren Lyles",
      "Patricia Gonzalez-Guerrero",
      "Meriam Gay Bautista",
      "George Michelogiannakis"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Hardware Architecture (cs.AR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.09484"
  },
  {
    "id": "arXiv:2210.09486",
    "title": "Semi-Supervised Domain Adaptation with Auto-Encoder via Simultaneous  Learning",
    "abstract": "We present a new semi-supervised domain adaptation framework that combines a\nnovel auto-encoder-based domain adaptation model with a simultaneous learning\nscheme providing stable improvements over state-of-the-art domain adaptation\nmodels. Our framework holds strong distribution matching property by training\nboth source and target auto-encoders using a novel simultaneous learning scheme\non a single graph with an optimally modified MMD loss objective function.\nAdditionally, we design a semi-supervised classification approach by\ntransferring the aligned domain invariant feature spaces from source domain to\nthe target domain. We evaluate on three datasets and show proof that our\nframework can effectively solve both fragile convergence (adversarial) and weak\ndistribution matching problems between source and target feature space\n(discrepancy) with a high `speed' of adaptation requiring a very low number of\niterations.",
    "descriptor": "",
    "authors": [
      "Md Mahmudur Rahman",
      "Rameswar Panda",
      "Mohammad Arif Ul Alam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09486"
  },
  {
    "id": "arXiv:2210.09492",
    "title": "Systematicity in GPT-3's Interpretation of Novel English Noun Compounds",
    "abstract": "Levin et al. (2019) show experimentally that the interpretations of novel\nEnglish noun compounds (e.g., stew skillet), while not fully compositional, are\nhighly predictable based on whether the modifier and head refer to artifacts or\nnatural kinds. Is the large language model GPT-3 governed by the same\ninterpretive principles? To address this question, we first compare Levin et\nal.'s experimental data with GPT-3 generations, finding a high degree of\nsimilarity. However, this evidence is consistent with GPT3 reasoning only about\nspecific lexical items rather than the more abstract conceptual categories of\nLevin et al.'s theory. To probe more deeply, we construct prompts that require\nthe relevant kind of conceptual reasoning. Here, we fail to find convincing\nevidence that GPT-3 is reasoning about more than just individual lexical items.\nThese results highlight the importance of controlling for low-level\ndistributional regularities when assessing whether a large language model\nlatently encodes a deeper theory.",
    "descriptor": "\nComments: Findings of EMNLP 2022\n",
    "authors": [
      "Siyan Li",
      "Riley Carlson",
      "Christopher Potts"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.09492"
  },
  {
    "id": "arXiv:2210.09495",
    "title": "5th Place Solution to Kaggle Google Universal Image Embedding  Competition",
    "abstract": "In this paper, we present our solution, which placed 5th in the kaggle Google\nUniversal Image Embedding Competition in 2022. We use the ViT-H visual encoder\nof CLIP from the openclip repository as a backbone and train a head model\ncomposed of BatchNormalization and Linear layers using ArcFace. The dataset\nused was a subset of products10K, GLDv2, GPR1200, and Food101. And applying TTA\nfor part of images also improves the score. With this method, we achieve a\nscore of 0.684 on the public and 0.688 on the private leaderboard. Our code is\navailable.\nhttps://github.com/riron1206/kaggle-Google-Universal-Image-Embedding-Competition-5th-Place-Solution",
    "descriptor": "\nComments: 3 pages, 1 figures\n",
    "authors": [
      "Noriaki Ota",
      "Shingo Yokoi",
      "Shinsuke Yamaoka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09495"
  },
  {
    "id": "arXiv:2210.09496",
    "title": "CEIP: Combining Explicit and Implicit Priors for Reinforcement Learning  with Demonstrations",
    "abstract": "Although reinforcement learning has found widespread use in dense reward\nsettings, training autonomous agents with sparse rewards remains challenging.\nTo address this difficulty, prior work has shown promising results when using\nnot only task-specific demonstrations but also task-agnostic albeit somewhat\nrelated demonstrations. In most cases, the available demonstrations are\ndistilled into an implicit prior, commonly represented via a single deep net.\nExplicit priors in the form of a database that can be queried have also been\nshown to lead to encouraging results. To better benefit from available\ndemonstrations, we develop a method to Combine Explicit and Implicit Priors\n(CEIP). CEIP exploits multiple implicit priors in the form of normalizing flows\nin parallel to form a single complex prior. Moreover, CEIP uses an effective\nexplicit retrieval and push-forward mechanism to condition the implicit priors.\nIn three challenging environments, we find the proposed CEIP method to improve\nupon sophisticated state-of-the-art techniques.",
    "descriptor": "\nComments: 27 pages; published as NeurIPS 2022 poster paper\n",
    "authors": [
      "Kai Yan",
      "Alexander G. Schwing",
      "Yu-Xiong Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.09496"
  },
  {
    "id": "arXiv:2210.09499",
    "title": "Enabling Heterogeneous Domain Adaptation in Multi-inhabitants Smart Home  Activity Learning",
    "abstract": "Domain adaptation for sensor-based activity learning is of utmost importance\nin remote health monitoring research. However, many domain adaptation\nalgorithms suffer with failure to operate adaptation in presence of target\ndomain heterogeneity (which is always present in reality) and presence of\nmultiple inhabitants dramatically hinders their generalizability producing\nunsatisfactory results for semi-supervised and unseen activity learning tasks.\nWe propose \\emph{AEDA}, a novel deep auto-encoder-based model to enable\nsemi-supervised domain adaptation in the existence of target domain\nheterogeneity and how to incorporate it to empower heterogeneity to any\nhomogeneous deep domain adaptation architecture for cross-domain activity\nlearning. Experimental evaluation on 18 different heterogeneous and\nmulti-inhabitants use-cases of 8 different domains created from 2 publicly\navailable human activity datasets (wearable and ambient smart homes) shows that\n\\emph{AEDA} outperforms (max. 12.8\\% and 8.9\\% improvements for ambient smart\nhome and wearables) over existing domain adaptation techniques for both seen\nand unseen activity learning in a heterogeneous setting.",
    "descriptor": "",
    "authors": [
      "Md Mahmudur Rahman",
      "Mahta Mousavi",
      "Peri Tarr",
      "Mohammad Arif Ul Alam"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09499"
  },
  {
    "id": "arXiv:2210.09500",
    "title": "A Human-ML Collaboration Framework for Improving Video Content Reviews",
    "abstract": "We deal with the problem of localized in-video taxonomic human annotation in\nthe video content moderation domain, where the goal is to identify video\nsegments that violate granular policies, e.g., community guidelines on an\nonline video platform. High quality human labeling is critical for enforcement\nin content moderation. This is challenging due to the problem of information\noverload - raters need to apply a large taxonomy of granular policy violations\nwith ambiguous definitions, within a limited review duration to relatively long\nvideos. Our key contribution is a novel human-machine learning (ML)\ncollaboration framework aimed at maximizing the quality and efficiency of human\ndecisions in this setting - human labels are used to train segment-level\nmodels, the predictions of which are displayed as \"hints\" to human raters,\nindicating probable regions of the video with specific policy violations. The\nhuman verified/corrected segment labels can help refine the model further,\nhence creating a human-ML positive feedback loop. Experiments show improved\nhuman video moderation decision quality, and efficiency through more granular\nannotations submitted within a similar review duration, which enable a 5-8% AUC\nimprovement in the hint generation models.",
    "descriptor": "\nComments: 5 pages, Human-in-the-Loop Data Curation Workshop CIKM'22\n",
    "authors": [
      "Meghana Deodhar",
      "Xiao Ma",
      "Yixin Cai",
      "Alex Koes",
      "Alex Beutel",
      "Jilin Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09500"
  },
  {
    "id": "arXiv:2210.09503",
    "title": "Towards Fair Classification against Poisoning Attacks",
    "abstract": "Fair classification aims to stress the classification models to achieve the\nequality (treatment or prediction quality) among different sensitive groups.\nHowever, fair classification can be under the risk of poisoning attacks that\ndeliberately insert malicious training samples to manipulate the trained\nclassifiers' performance. In this work, we study the poisoning scenario where\nthe attacker can insert a small fraction of samples into training data, with\narbitrary sensitive attributes as well as other predictive features. We\ndemonstrate that the fairly trained classifiers can be greatly vulnerable to\nsuch poisoning attacks, with much worse accuracy & fairness trade-off, even\nwhen we apply some of the most effective defenses (originally proposed to\ndefend traditional classification tasks). As countermeasures to defend fair\nclassification tasks, we propose a general and theoretically guaranteed\nframework which accommodates traditional defense methods to fair classification\nagainst poisoning attacks. Through extensive experiments, the results validate\nthat the proposed defense framework obtains better robustness in terms of\naccuracy and fairness than representative baseline methods.",
    "descriptor": "",
    "authors": [
      "Han Xu",
      "Xiaorui Liu",
      "Yuxuan Wan",
      "Jiliang Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.09503"
  },
  {
    "id": "arXiv:2210.09505",
    "title": "CNT (Conditioning on Noisy Targets): A new Algorithm for Leveraging  Top-Down Feedback",
    "abstract": "We propose a novel regularizer for supervised learning called Conditioning on\nNoisy Targets (CNT). This approach consists in conditioning the model on a\nnoisy version of the target(s) (e.g., actions in imitation learning or labels\nin classification) at a random noise level (from small to large noise). At\ninference time, since we do not know the target, we run the network with only\nnoise in place of the noisy target. CNT provides hints through the noisy label\n(with less noise, we can more easily infer the true target). This give two main\nbenefits: 1) the top-down feedback allows the model to focus on simpler and\nmore digestible sub-problems and 2) rather than learning to solve the task from\nscratch, the model will first learn to master easy examples (with less noise),\nwhile slowly progressing toward harder examples (with more noise).",
    "descriptor": "",
    "authors": [
      "Alexia Jolicoeur-Martineau",
      "Alex Lamb",
      "Vikas Verma",
      "Aniket Didolkar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.09505"
  },
  {
    "id": "arXiv:2210.09506",
    "title": "No Pairs Left Behind: Improving Metric Learning with Regularized Triplet  Objective",
    "abstract": "We propose a novel formulation of the triplet objective function that\nimproves metric learning without additional sample mining or overhead costs.\nOur approach aims to explicitly regularize the distance between the positive\nand negative samples in a triplet with respect to the anchor-negative distance.\nAs an initial validation, we show that our method (called No Pairs Left Behind\n[NPLB]) improves upon the traditional and current state-of-the-art triplet\nobjective formulations on standard benchmark datasets. To show the\neffectiveness and potentials of NPLB on real-world complex data, we evaluate\nour approach on a large-scale healthcare dataset (UK Biobank), demonstrating\nthat the embeddings learned by our model significantly outperform all other\ncurrent representations on tested downstream tasks. Additionally, we provide a\nnew model-agnostic single-time health risk definition that, when used in tandem\nwith the learned representations, achieves the most accurate prediction of\nsubjects' future health complications. Our results indicate that NPLB is a\nsimple, yet effective framework for improving existing deep metric learning\nmodels, showcasing the potential implications of metric learning in more\ncomplex applications, especially in the biological and healthcare domains.",
    "descriptor": "\nComments: Main manuscript and supplementary material are all as one PDF\n",
    "authors": [
      "A. Ali Heydari",
      "Naghmeh Rezaei",
      "Daniel J. McDuff",
      "Javier L. Prieto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.09506"
  },
  {
    "id": "arXiv:2210.09507",
    "title": "An enhanced method of initial cluster center selection for K-means  algorithm",
    "abstract": "Clustering is one of the widely used techniques to find out patterns from a\ndataset that can be applied in different applications or analyses. K-means, the\nmost popular and simple clustering algorithm, might get trapped into local\nminima if not properly initialized and the initialization of this algorithm is\ndone randomly. In this paper, we propose a novel approach to improve initial\ncluster selection for K-means algorithm. This algorithm is based on the fact\nthat the initial centroids must be well separated from each other since the\nfinal clusters are separated groups in feature space. The Convex Hull algorithm\nfacilitates the computing of the first two centroids and the remaining ones are\nselected according to the distance from previously selected centers. To ensure\nthe selection of one center per cluster, we use the nearest neighbor technique.\nTo check the robustness of our proposed algorithm, we consider several\nreal-world datasets. We obtained only 7.33%, 7.90%, and 0% clustering error in\nIris, Letter, and Ruspini data respectively which proves better performance\nthan other existing systems. The results indicate that our proposed method\noutperforms the conventional K means approach by accelerating the computation\nwhen the number of clusters is greater than 2.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Zillur Rahman",
      "Md. Sabir Hossain",
      "Mohammad Hasan",
      "Ahmed Imteaj"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09507"
  },
  {
    "id": "arXiv:2210.09509",
    "title": "Deep Data Augmentation for Weed Recognition Enhancement: A Diffusion  Probabilistic Model and Transfer Learning Based Approach",
    "abstract": "Weed management plays an important role in many modern agricultural\napplications. Conventional weed control methods mainly rely on chemical\nherbicides or hand weeding, which are often cost-ineffective, environmentally\nunfriendly, or even posing a threat to food safety and human health. Recently,\nautomated/robotic weeding using machine vision systems has seen increased\nresearch attention with its potential for precise and individualized weed\ntreatment. However, dedicated, large-scale, and labeled weed image datasets are\nrequired to develop robust and effective weed identification systems but they\nare often difficult and expensive to obtain. To address this issue, data\naugmentation approaches, such as generative adversarial networks (GANs), have\nbeen explored to generate highly realistic images for agricultural\napplications. Yet, despite some progress, those approaches are often\ncomplicated to train or have difficulties preserving fine details in images. In\nthis paper, we present the first work of applying diffusion probabilistic\nmodels (also known as diffusion models) to generate high-quality synthetic weed\nimages based on transfer learning. Comprehensive experimental results show that\nthe developed approach consistently outperforms several state-of-the-art GAN\nmodels, representing the best trade-off between sample fidelity and diversity\nand highest FID score on a common weed dataset, CottonWeedID15. In addition,\nthe expanding dataset with synthetic weed images can apparently boost model\nperformance on four deep learning (DL) models for the weed classification\ntasks. Furthermore, the DL models trained on CottonWeedID15 dataset with only\n10% of real images and 90% of synthetic weed images achieve a testing accuracy\nof over 94%, showing high-quality of the generated weed samples. The codes of\nthis study are made publicly available at\nhttps://github.com/DongChen06/DMWeeds.",
    "descriptor": "\nComments: 15 pages, 9 figures\n",
    "authors": [
      "Dong Chen",
      "Xinda Qi",
      "Yu Zheng",
      "Yuzhen Lu",
      "Zhaojian Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09509"
  },
  {
    "id": "arXiv:2210.09510",
    "title": "Personalization of CTC Speech Recognition Models",
    "abstract": "End-to-end speech recognition models trained using joint Connectionist\nTemporal Classification (CTC)-Attention loss have gained popularity recently.\nIn these models, a non-autoregressive CTC decoder is often used at inference\ntime due to its speed and simplicity. However, such models are hard to\npersonalize because of their conditional independence assumption that prevents\noutput tokens from previous time steps to influence future predictions. To\ntackle this, we propose a novel two-way approach that first biases the encoder\nwith attention over a predefined list of rare long-tail and out-of-vocabulary\n(OOV) words and then uses dynamic boosting and phone alignment network during\ndecoding to further bias the subword predictions. We evaluate our approach on\nopen-source VoxPopuli and in-house medical datasets to showcase a 60%\nimprovement in F1 score on domain-specific rare words over a strong CTC\nbaseline.",
    "descriptor": "\nComments: To appear in SLT 2022\n",
    "authors": [
      "Saket Dingliwal",
      "Monica Sunkara",
      "Srikanth Ronanki",
      "Jeff Farris",
      "Katrin Kirchhoff",
      "Sravan Bodapati"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.09510"
  },
  {
    "id": "arXiv:2210.09512",
    "title": "Off-policy evaluation for learning-to-rank via interpolating the  item-position model and the position-based model",
    "abstract": "A critical need for industrial recommender systems is the ability to evaluate\nrecommendation policies offline, before deploying them to production.\nUnfortunately, widely used off-policy evaluation methods either make strong\nassumptions about how users behave that can lead to excessive bias, or they\nmake fewer assumptions and suffer from large variance. We tackle this problem\nby developing a new estimator that mitigates the problems of the two most\npopular off-policy estimators for rankings, namely the position-based model and\nthe item-position model. In particular, the new estimator, called INTERPOL,\naddresses the bias of a potentially misspecified position-based model, while\nproviding an adaptable bias-variance trade-off compared to the item-position\nmodel. We provide theoretical arguments as well as empirical results that\nhighlight the performance of our novel estimation approach.",
    "descriptor": "\nComments: Presented at CONSEQUENCES workshop (Recsys '22) this https URL\n",
    "authors": [
      "Alexander Buchholz",
      "Ben London",
      "Giuseppe di Benedetto",
      "Thorsten Joachims"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2210.09512"
  },
  {
    "id": "arXiv:2210.09515",
    "title": "Artificial intelligence and renegotiation of commercial lease contracts  affected by pandemic-related contingencies from Covid-19. The project  A.I.A.Co",
    "abstract": "This paper aims to investigate the possibility of using artificial\nintelligence (AI) to resolve the legal issues raised by the Covid-19 emergency\nabout the fate of continuing execution contracts, or those with deferred or\nperiodic execution, as well as, more generally, to deal with exceptional events\nand contingencies. We first study whether the Italian legal system allows for\n''maintenance'' remedies to cope with contingencies and to avoid the\ntermination of the contract, while ensuring effective protection of the\ninterests of both parties. We then give a complete and technical description of\nan AI-based predictive framework, aimed at assisting both the Magistrate (in\nthe course of litigation) and the parties themselves (in out-of-court\nproceedings) in the redetermination of the rent of commercial lease contracts.\nThis framework, called A.I.A.Co. for Artificial Intelligence for contract law\nAgainst Covid-19, has been developed under the Italian grant ''Fondo\nIntegrativo Speciale per la Ricerca''.",
    "descriptor": "\nComments: Accepted at CRCL 2022: Computational 'law' on edge, this https URL\n",
    "authors": [
      "Maurizio Parton",
      "Marco Angelone",
      "Carlo Metta",
      "Stefania D'Ovidio",
      "Roberta Massarelli",
      "Luca Moscardelli",
      "Gianluca Amato"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.09515"
  },
  {
    "id": "arXiv:2210.09517",
    "title": "Graph neural networks to learn joint representations of disjoint  molecular graphs",
    "abstract": "Graph neural networks are widely used to learn global representations of\ngraphs, which are then used for regression or classification tasks. Typically,\nthe graphs in such data sets are connected, i.e. each training sample consists\nof a single internally connected graph associated with a global label. However,\nthere is a wide variety of yet unconsidered but application-relevant tasks,\nwhere labels are assigned to sets of disjoint graphs, which requires the\ngeneration of global representations of disjoint graphs. In this paper, we\npresent a new data set with chemical reactions, which is illustrating this\ntask. Each sample consists of a pair of disjoint molecular graphs and a joint\nlabel representing a scalar measure associated with the chemical reaction of\nthe molecules. We show the initial results of graph neural networks that are\nable to solve the task within a combinatorial subset of the dataset but do not\ngeneralize well to the full data set and unseen (sub)graphs.",
    "descriptor": "\nComments: 5 pages, 4 figures\n",
    "authors": [
      "C.Shao",
      "C. Chen",
      "P.Friederich"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2210.09517"
  },
  {
    "id": "arXiv:2210.09518",
    "title": "Team Flow at DRC2022: Pipeline System for Travel Destination  Recommendation Task in Spoken Dialogue",
    "abstract": "To improve the interactive capabilities of a dialogue system, e.g., to adapt\nto different customers, the Dialogue Robot Competition (DRC2022) was held. As\none of the teams, we built a dialogue system with a pipeline structure\ncontaining four modules. The natural language understanding (NLU) and natural\nlanguage generation (NLG) modules were GPT-2 based models, and the dialogue\nstate tracking (DST) and policy modules were designed on the basis of\nhand-crafted rules. After the preliminary round of the competition, we found\nthat the low variation in training examples for the NLU and failed\nrecommendation due to the policy used were probably the main reasons for the\nlimited performance of the system.",
    "descriptor": "\nComments: This paper is part of the proceedings of the Dialogue Robot Competition 2022\n",
    "authors": [
      "Ryu Hirai",
      "Atsumoto Ohashi",
      "Ao Guo",
      "Hideki Shiroma",
      "Xulin Zhou",
      "Yukihiko Tone",
      "Shinya Iizuka",
      "Ryuichiro Higashinaka"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.09518"
  },
  {
    "id": "arXiv:2210.09520",
    "title": "Using Language to Extend to Unseen Domains",
    "abstract": "It is expensive to collect training data for every possible domain that a\nvision model may encounter when deployed. We instead consider how simply\nverbalizing the training domain (e.g. \"photos of birds\") as well as domains we\nwant to extend to but do not have data for (e.g. \"paintings of birds\") can\nimprove robustness. Using a multimodal model with a joint image and language\nembedding space, our method LADS learns a transformation of the image\nembeddings from the training domain to each unseen test domain, while\npreserving task relevant information. Without using any images from the unseen\ntest domain, we show that over the extended domain containing both training and\nunseen test domains, LADS outperforms standard fine-tuning and ensemble\napproaches over a suite of four benchmarks targeting domain adaptation and\ndataset bias",
    "descriptor": "",
    "authors": [
      "Lisa Dunlap",
      "Clara Mohri",
      "Devin Guillory",
      "Han Zhang",
      "Trevor Darrell",
      "Joseph E. Gonzalez",
      "Aditi Raghunanthan",
      "Anja Rohrbach"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09520"
  },
  {
    "id": "arXiv:2210.09521",
    "title": "A Practical, Progressively-Expressive GNN",
    "abstract": "Message passing neural networks (MPNNs) have become a dominant flavor of\ngraph neural networks (GNNs) in recent years. Yet, MPNNs come with notable\nlimitations; namely, they are at most as powerful as the 1-dimensional\nWeisfeiler-Leman (1-WL) test in distinguishing graphs in a graph isomorphism\ntesting frame-work. To this end, researchers have drawn inspiration from the\nk-WL hierarchy to develop more expressive GNNs. However, current\nk-WL-equivalent GNNs are not practical for even small values of k, as k-WL\nbecomes combinatorially more complex as k grows. At the same time, several\nworks have found great empirical success in graph learning tasks without highly\nexpressive models, implying that chasing expressiveness with a coarse-grained\nruler of expressivity like k-WL is often unneeded in practical tasks. To truly\nunderstand the expressiveness-complexity tradeoff, one desires a more\nfine-grained ruler, which can more gradually increase expressiveness. Our work\nputs forth such a proposal: Namely, we first propose the (k, c)(<=)-SETWL\nhierarchy with greatly reduced complexity from k-WL, achieved by moving from\nk-tuples of nodes to sets with <=k nodes defined over <=c connected components\nin the induced original graph. We show favorable theoretical results for this\nmodel in relation to k-WL, and concretize it via (k, c)(<=)-SETGNN, which is as\nexpressive as (k, c)(<=)-SETWL. Our model is practical and\nprogressively-expressive, increasing in power with k and c. We demonstrate\neffectiveness on several benchmark datasets, achieving several state-of-the-art\nresults with runtime and memory usage applicable to practical graphs. We open\nsource our implementation at https://github.com/LingxiaoShawn/KCSetGNN.",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Lingxiao Zhao",
      "Louis H\u00e4rtel",
      "Neil Shah",
      "Leman Akoglu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09521"
  },
  {
    "id": "arXiv:2210.09523",
    "title": "Agglomerative Hierarchical Clustering with Dynamic Time Warping for  Household Load Curve Clustering",
    "abstract": "Energy companies often implement various demand response (DR) programs to\nbetter match electricity demand and supply by offering the consumers incentives\nto reduce their demand during critical periods. Classifying clients according\nto their consumption patterns enables targeting specific groups of consumers\nfor DR. Traditional clustering algorithms use standard distance measurement to\nfind the distance between two points. The results produced by clustering\nalgorithms such as K-means, K-medoids, and Gaussian Mixture Models depend on\nthe clustering parameters or initial clusters. In contrast, our methodology\nuses a shape-based approach that combines Agglomerative Hierarchical Clustering\n(AHC) with Dynamic Time Warping (DTW) to classify residential households' daily\nload curves based on their consumption patterns. While DTW seeks the optimal\nalignment between two load curves, AHC provides a realistic initial clusters\ncenter. In this paper, we compare the results with other clustering algorithms\nsuch as K-means, K-medoids, and GMM using different distance measures, and we\nshow that AHC using DTW outperformed other clustering algorithms and needed\nfewer clusters.",
    "descriptor": "",
    "authors": [
      "Fadi AlMahamid",
      "Katarina Grolinger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09523"
  },
  {
    "id": "arXiv:2210.09524",
    "title": "SVLDL: Improved Speaker Age Estimation Using Selective Variance Label  Distribution Learning",
    "abstract": "Estimating age from a single speech is a classic and challenging topic.\nAlthough Label Distribution Learning (LDL) can represent adjacent\nindistinguishable ages well, the uncertainty of the age estimate for each\nutterance varies from person to person, i.e., the variance of the age\ndistribution is different. To address this issue, we propose selective variance\nlabel distribution learning (SVLDL) method to adapt the variance of different\nage distributions. Furthermore, the model uses WavLM as the speech feature\nextractor and adds the auxiliary task of gender recognition to further improve\nthe performance. Two tricks are applied on the loss function to enhance the\nrobustness of the age estimation and improve the quality of the fitted age\ndistribution. Extensive experiments show that the model achieves\nstate-of-the-art performance on all aspects of the NIST SRE08-10 and a\nreal-world datasets.",
    "descriptor": "\nComments: Accepted by SLT 2022. The 2022 IEEE Spoken Language Technology Workshop (SLT 2022)\n",
    "authors": [
      "Zuheng Kang",
      "Jianzong Wang",
      "Junqing Peng",
      "Jing Xiao"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.09524"
  },
  {
    "id": "arXiv:2210.09529",
    "title": "A Hybrid System of Sound Event Detection Transformer and Frame-wise  Model for DCASE 2022 Task 4",
    "abstract": "In this paper, we describe in detail our system for DCASE 2022 Task4. The\nsystem combines two considerably different models: an end-to-end Sound Event\nDetection Transformer (SEDT) and a frame-wise model, Metric Learning and Focal\nLoss CNN (MLFL-CNN). The former is an event-wise model which learns event-level\nrepresentations and predicts sound event categories and boundaries directly,\nwhile the latter is based on the widely adopted frame-classification scheme,\nunder which each frame is classified into event categories and event boundaries\nare obtained by post-processing such as thresholding and smoothing. For SEDT,\nself-supervised pre-training using unlabeled data is applied, and\nsemi-supervised learning is adopted by using an online teacher, which is\nupdated from the student model using the Exponential Moving Average (EMA)\nstrategy and generates reliable pseudo labels for weakly-labeled and unlabeled\ndata. For the frame-wise model, the ICT-TOSHIBA system of DCASE 2021 Task 4 is\nused. Experimental results show that the hybrid system considerably outperforms\neither individual model and achieves psds1 of 0.420 and psds2 of 0.783 on the\nvalidation set without external data. The code is available at\nhttps://github.com/965694547/Hybrid-system-of-frame-wise-model-and-SEDT.",
    "descriptor": "\nComments: 5 pages, 2 figures, accepted for publication in DCASE2022 Workshop\n",
    "authors": [
      "Yiming Li",
      "Zhifang Guo",
      "Zhirong Ye",
      "Xiangdong Wang",
      "Hong Liu",
      "Yueliang Qian",
      "Rui Tao",
      "Long Yan",
      "Kazushige Ouchi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.09529"
  },
  {
    "id": "arXiv:2210.09531",
    "title": "The Brain-Inspired Cooperative Shared Control for Brain-Machine  Interface",
    "abstract": "In the practical application of brain-machine interface technology, the\nproblem often faced is the low information content and high noise of the neural\nsignals collected by the electrode and the difficulty of decoding by the\ndecoder, which makes it difficult for the robotic to obtain stable instructions\nto complete the task. The idea based on the principle of cooperative shared\ncontrol can be achieved by extracting general motor commands from brain\nactivity, while the fine details of the movement can be hosted to the robot for\ncompletion, or the brain can have complete control. This study proposes a\nbrain-machine interface shared control system based on spiking neural networks\nfor robotic arm movement control and wheeled robots wheel speed control and\nsteering, respectively. The former can reliably control the robotic arm to move\nto the destination position, while the latter controls the wheeled robots for\nobject tracking and map generation. The results show that the shared control\nbased on brain-inspired intelligence can perform some typical tasks in complex\nenvironments and positively improve the fluency and ease of use of\nbrain-machine interaction, and also demonstrate the potential of this control\nmethod in clinical applications of brain-machine interfaces.",
    "descriptor": "\nComments: 16 pages, 16 figures\n",
    "authors": [
      "Shengjie Zheng",
      "Ling Liu",
      "Junjie Yang",
      "Lang Qian",
      "Gang Gao",
      "Xin Chen",
      "Wenqi Jin",
      "Chunshan Deng",
      "Xiaojian Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.09531"
  },
  {
    "id": "arXiv:2210.09535",
    "title": "Graph Anomaly Detection with Unsupervised GNNs",
    "abstract": "Graph-based anomaly detection finds numerous applications in the real-world.\nThus, there exists extensive literature on the topic that has recently shifted\ntoward deep detection models due to advances in deep learning and graph neural\nnetworks (GNNs). A vast majority of prior work focuses on detecting\nnode/edge/subgraph anomalies within a single graph, with much less work on\ngraph-level anomaly detection in a graph database. This work aims to fill two\ngaps in the literature: We (1) design GLAM, an end-to-end graph-level anomaly\ndetection model based on GNNs, and (2) focus on unsupervised model selection,\nwhich is notoriously hard due to lack of any labels, yet especially critical\nfor deep NN based models with a long list of hyper-parameters. Further, we\npropose a new pooling strategy for graph-level embedding, called MMD-pooling,\nthat is geared toward detecting distribution anomalies which has not been\nconsidered before. Through extensive experiments on 15 real-world datasets, we\nshow that (i) GLAM outperforms node-level and two-stage (i.e. not end-to-end)\nbaselines, and (ii) model selection picks a significantly more effective model\nthan expectation (i.e. average) -- without using any labels -- among candidates\nwith otherwise large variation in performance.",
    "descriptor": "\nComments: ICDM 2022 Short Paper Extension\n",
    "authors": [
      "Lingxiao Zhao",
      "Saurabh Sawlani",
      "Arvind Srinivasan",
      "Leman Akoglu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.09535"
  },
  {
    "id": "arXiv:2210.09537",
    "title": "Less is More: Simplifying Feature Extractors Prevents Overfitting for  Neural Discourse Parsing Models",
    "abstract": "Complex feature extractors are widely employed for text representation\nbuilding. However, these complex feature extractors can lead to severe\noverfitting problems especially when the training datasets are small, which is\nespecially the case for several discourse parsing tasks. Thus, we propose to\nremove additional feature extractors and only utilize self-attention mechanism\nto exploit pretrained neural language models in order to mitigate the\noverfitting problem. Experiments on three common discourse parsing tasks (News\nDiscourse Profiling, Rhetorical Structure Theory based Discourse Parsing and\nPenn Discourse Treebank based Discourse Parsing) show that powered by recent\npretrained language models, our simplied feature extractors obtain better\ngeneralizabilities and meanwhile achieve comparable or even better system\nperformance. The simplified feature extractors have fewer learnable parameters\nand less processing time. Codes will be released and this simple yet effective\nmodel can serve as a better baseline for future research.",
    "descriptor": "",
    "authors": [
      "Ming Li",
      "Sijing Yu",
      "Ruihong Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.09537"
  },
  {
    "id": "arXiv:2210.09539",
    "title": "Hierarchical Model-Based Imitation Learning for Planning in Autonomous  Driving",
    "abstract": "We demonstrate the first large-scale application of model-based generative\nadversarial imitation learning (MGAIL) to the task of dense urban self-driving.\nWe augment standard MGAIL using a hierarchical model to enable generalization\nto arbitrary goal routes, and measure performance using a closed-loop\nevaluation framework with simulated interactive agents. We train policies from\nexpert trajectories collected from real vehicles driving over 100,000 miles in\nSan Francisco, and demonstrate a steerable policy that can navigate robustly\neven in a zero-shot setting, generalizing to synthetic scenarios with novel\ngoals that never occurred in real-world driving. We also demonstrate the\nimportance of mixing closed-loop MGAIL losses with open-loop behavior cloning\nlosses, and show our best policy approaches the performance of the expert. We\nevaluate our imitative model in both average and challenging scenarios, and\nshow how it can serve as a useful prior to plan successful trajectories.",
    "descriptor": "\nComments: IROS 2022\n",
    "authors": [
      "Eli Bronstein",
      "Mark Palatucci",
      "Dominik Notz",
      "Brandyn White",
      "Alex Kuefler",
      "Yiren Lu",
      "Supratik Paul",
      "Payam Nikdel",
      "Paul Mougin",
      "Hongge Chen",
      "Justin Fu",
      "Austin Abrams",
      "Punit Shah",
      "Evan Racah",
      "Benjamin Frenkel",
      "Shimon Whiteson",
      "Dragomir Anguelov"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09539"
  },
  {
    "id": "arXiv:2210.09540",
    "title": "Contact-Implicit Planning and Control for Non-Prehensile Manipulation  Using State-Triggered Constraints",
    "abstract": "We present a contact-implicit planning approach that can generate\ncontact-interaction trajectories for non-prehensile manipulation problems\nwithout tuning or a tailored initial guess and with high success rates. This is\nachieved by leveraging the concept of state-triggered constraints (STCs) to\ncapture the hybrid dynamics induced by discrete contact modes without\nexplicitly reasoning about the combinatorics. STCs enable triggering arbitrary\nconstraints by a strict inequality condition in a continuous way. We first use\nSTCs to develop an automatic contact constraint activation method to minimize\nthe effective constraint space based on the utility of contact candidates for a\ngiven task. Then, we introduce a re-formulation of the Coulomb friction model\nbased on STCs that is more efficient for the discovery of tangential forces\nthan the well-studied complementarity constraints-based approach. Last, we\ninclude the proposed friction model in the planning and control of quasi-static\nplanar pushing. The performance of the STC-based contact activation and\nfriction methods is evaluated by extensive simulation experiments in a dynamic\npushing scenario. The results demonstrate that our methods outperform the\nbaselines based on complementarity constraints with a significant decrease in\nthe planning time and a higher success rate. We then compare the proposed\nquasi-static pushing controller against a mixed-integer programming-based\napproach in simulation and find that our method is computationally more\nefficient and provides a better tracking accuracy, with the added benefit of\nnot requiring an initial control trajectory. Finally, we present hardware\nexperiments demonstrating the usability of our framework in executing complex\ntrajectories in real-time even with a low-accuracy tracking system.",
    "descriptor": "\nComments: 16 pages, The International Symposium on Robotics Research 2022\n",
    "authors": [
      "Maozhen Wang",
      "Aykut Ozgun Onol",
      "Philip Long",
      "Taskin Padir"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.09540"
  },
  {
    "id": "arXiv:2210.09545",
    "title": "Fine-mixing: Mitigating Backdoors in Fine-tuned Language Models",
    "abstract": "Deep Neural Networks (DNNs) are known to be vulnerable to backdoor attacks.\nIn Natural Language Processing (NLP), DNNs are often backdoored during the\nfine-tuning process of a large-scale Pre-trained Language Model (PLM) with\npoisoned samples. Although the clean weights of PLMs are readily available,\nexisting methods have ignored this information in defending NLP models against\nbackdoor attacks. In this work, we take the first step to exploit the\npre-trained (unfine-tuned) weights to mitigate backdoors in fine-tuned language\nmodels. Specifically, we leverage the clean pre-trained weights via two\ncomplementary techniques: (1) a two-step Fine-mixing technique, which first\nmixes the backdoored weights (fine-tuned on poisoned data) with the pre-trained\nweights, then fine-tunes the mixed weights on a small subset of clean data; (2)\nan Embedding Purification (E-PUR) technique, which mitigates potential\nbackdoors existing in the word embeddings. We compare Fine-mixing with typical\nbackdoor mitigation methods on three single-sentence sentiment classification\ntasks and two sentence-pair classification tasks and show that it outperforms\nthe baselines by a considerable margin in all scenarios. We also show that our\nE-PUR method can benefit existing mitigation methods. Our work establishes a\nsimple but strong baseline defense for secure fine-tuned NLP models against\nbackdoor attacks.",
    "descriptor": "\nComments: Accepted by Findings of EMNLP 2022\n",
    "authors": [
      "Zhiyuan Zhang",
      "Lingjuan Lyu",
      "Xingjun Ma",
      "Chenguang Wang",
      "Xu Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09545"
  },
  {
    "id": "arXiv:2210.09546",
    "title": "An Improved Structured Mesh Generation Method Based on Physics-informed  Neural Networks",
    "abstract": "Mesh generation remains a key technology in many areas where numerical\nsimulations are required. As numerical algorithms become more efficient and\ncomputers become more powerful, the percentage of time devoted to mesh\ngeneration becomes higher. In this paper, we present an improved structured\nmesh generation method. The method formulates the meshing problem as a global\noptimization problem related to a physics-informed neural network. The mesh is\nobtained by intelligently solving the physical boundary-constrained partial\ndifferential equations. To improve the prediction accuracy of the neural\nnetwork, we also introduce a novel auxiliary line strategy and an efficient\nnetwork model during meshing. The strategy first employs a priori auxiliary\nlines to provide ground truth data and then uses these data to construct a loss\nterm to better constrain the convergence of the subsequent training. The\nexperimental results indicate that the proposed method is effective and robust.\nIt can accurately approximate the mapping (transformation) from the\ncomputational domain to the physical domain and enable fast high-quality\nstructured mesh generation.",
    "descriptor": "",
    "authors": [
      "Xinhai Chen",
      "Jie Liu",
      "Junjun Yan",
      "Zhichao Wang",
      "Chunye Gong"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2210.09546"
  },
  {
    "id": "arXiv:2210.09549",
    "title": "Swinv2-Imagen: Hierarchical Vision Transformer Diffusion Models for  Text-to-Image Generation",
    "abstract": "Recently, diffusion models have been proven to perform remarkably well in\ntext-to-image synthesis tasks in a number of studies, immediately presenting\nnew study opportunities for image generation. Google's Imagen follows this\nresearch trend and outperforms DALLE2 as the best model for text-to-image\ngeneration. However, Imagen merely uses a T5 language model for text\nprocessing, which cannot ensure learning the semantic information of the text.\nFurthermore, the Efficient UNet leveraged by Imagen is not the best choice in\nimage processing. To address these issues, we propose the Swinv2-Imagen, a\nnovel text-to-image diffusion model based on a Hierarchical Visual Transformer\nand a Scene Graph incorporating a semantic layout. In the proposed model, the\nfeature vectors of entities and relationships are extracted and involved in the\ndiffusion model, effectively improving the quality of generated images. On top\nof that, we also introduce a Swin-Transformer-based UNet architecture, called\nSwinv2-Unet, which can address the problems stemming from the CNN convolution\noperations. Extensive experiments are conducted to evaluate the performance of\nthe proposed model by using three real-world datasets, i.e., MSCOCO, CUB and\nMM-CelebA-HQ. The experimental results show that the proposed Swinv2-Imagen\nmodel outperforms several popular state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Ruijun Li",
      "Weihua Li",
      "Yi Yang",
      "Hanyu Wei",
      "Jianhua Jiang",
      "Quan Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09549"
  },
  {
    "id": "arXiv:2210.09550",
    "title": "Probing Cross-modal Semantics Alignment Capability from the Textual  Perspective",
    "abstract": "In recent years, vision and language pre-training (VLP) models have advanced\nthe state-of-the-art results in a variety of cross-modal downstream tasks.\nAligning cross-modal semantics is claimed to be one of the essential\ncapabilities of VLP models. However, it still remains unclear about the inner\nworking mechanism of alignment in VLP models. In this paper, we propose a new\nprobing method that is based on image captioning to first empirically study the\ncross-modal semantics alignment of VLP models. Our probing method is built upon\nthe fact that given an image-caption pair, the VLP models will give a score,\nindicating how well two modalities are aligned; maximizing such scores will\ngenerate sentences that VLP models believe are of good alignment. Analyzing\nthese sentences thus will reveal in what way different modalities are aligned\nand how well these alignments are in VLP models. We apply our probing method to\nfive popular VLP models, including UNITER, ROSITA, ViLBERT, CLIP, and LXMERT,\nand provide a comprehensive analysis of the generated captions guided by these\nmodels. Our results show that VLP models (1) focus more on just aligning\nobjects with visual words, while neglecting global semantics; (2) prefer fixed\nsentence patterns, thus ignoring more important textual information including\nfluency and grammar; and (3) deem the captions with more visual words are\nbetter aligned with images. These findings indicate that VLP models still have\nweaknesses in cross-modal semantics alignment and we hope this work will draw\nresearchers' attention to such problems when designing a new VLP model.",
    "descriptor": "\nComments: Findings of EMNLP2022\n",
    "authors": [
      "Zheng Ma",
      "Shi Zong",
      "Mianzhi Pan",
      "Jianbing Zhang",
      "Shujian Huang",
      "Xinyu Dai",
      "Jiajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.09550"
  },
  {
    "id": "arXiv:2210.09551",
    "title": "DisCup: Discriminator Cooperative Unlikelihood Prompt-tuning for  Controllable Text Generation",
    "abstract": "Prompt learning with immensely large Casual Language Models (CLMs) has been\nshown promising for attribute-controllable text generation (CTG). However,\nvanilla prompt tuning tends to imitate training corpus characteristics beyond\nthe control attributes, resulting in a poor generalization ability. Moreover,\nit is less able to capture the relationship between different attributes,\nfurther limiting the control performance. In this paper, we propose a new CTG\napproach, namely DisCup, which incorporates the attribute knowledge of\ndiscriminator to optimize the control-prompts, steering a frozen CLM to produce\nattribute-specific texts. Specifically, the frozen CLM model, capable of\nproducing multitudinous texts, is first used to generate the next-token\ncandidates based on the context, so as to ensure the diversity of tokens to be\npredicted. Then, we leverage an attribute-discriminator to select\ndesired/undesired tokens from those candidates, providing the inter-attribute\nknowledge. Finally, we bridge the above two traits by an unlikelihood objective\nfor prompt-tuning. Extensive experimental results show that DisCup can achieve\na new state-of-the-art control performance while maintaining an efficient and\nhigh-quality text generation, only relying on around 10 virtual tokens.",
    "descriptor": "\nComments: Accepted at EMNLP2022\n",
    "authors": [
      "Hanqing Zhang",
      "Dawei Song"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.09551"
  },
  {
    "id": "arXiv:2210.09552",
    "title": "A double-parameter robust lower order mixed element method for a strain  gradient elastic model",
    "abstract": "A double-parameter robust nonconforming mixed finite element method is\ndeveloped for a strain gradient elastic (SGE) model. A lower order\n$C^0$-continuous $H^2$-nonconforming finite element in arbitrary dimension is\nconstructed for the displacement field through enriching the quadratic Lagrange\nelement with bubble functions. This together with the linear Lagrange element\nis exploited to discretize a mixed formulation of the SGE model. The robust\ndiscrete inf-sup condition is established. The sharp and uniform error\nestimates with respect to both the small size parameter and the Lam\\'{e}\ncoefficient are achieved, which is also verified by numerical results. In\naddition, the uniform regularity of the SGE model is derived under two\nreasonable assumptions.",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Mingqing Chen",
      "Jianguo Huang",
      "Xuehai Huang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.09552"
  },
  {
    "id": "arXiv:2210.09553",
    "title": "Title detection: a novel approach to automatically finding retractions  and other editorial notices in the scholarly literature",
    "abstract": "Despite being a key element in the process of disseminating scientific\nknowledge, editorial notices are often obscured and not clearly linked to the\npapers to which they refer. In the present paper, we describe established\nmethods of aggregating notice data, and introduce a novel method of finding\neditorial notices in the scientific literature. Specifically, we describe how\narticle titles denote notices to existing publications, and how this\ninformation can be used to tie notices to papers in an automated fashion.\nFinally, as part of a broader movement to make science more transparent, we\nmake notices detected through this and other methods publicly available and\ndescribe this dataset and how it can be accessed.",
    "descriptor": "",
    "authors": [
      "Ashish Uppala",
      "Domenic Rosati",
      "Josh M. Nicholson",
      "Milo Mordaunt",
      "Peter Grabitz",
      "Sean C. Rife"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2210.09553"
  },
  {
    "id": "arXiv:2210.09556",
    "title": "Discrete Cross-Modal Alignment Enables Zero-Shot Speech Translation",
    "abstract": "End-to-end Speech Translation (ST) aims at translating the source language\nspeech into target language text without generating the intermediate\ntranscriptions. However, the training of end-to-end methods relies on parallel\nST data, which are difficult and expensive to obtain. Fortunately, the\nsupervised data for automatic speech recognition (ASR) and machine translation\n(MT) are usually more accessible, making zero-shot speech translation a\npotential direction. Existing zero-shot methods fail to align the two\nmodalities of speech and text into a shared semantic space, resulting in much\nworse performance compared to the supervised ST methods. In order to enable\nzero-shot ST, we propose a novel Discrete Cross-Modal Alignment (DCMA) method\nthat employs a shared discrete vocabulary space to accommodate and match both\nmodalities of speech and text. Specifically, we introduce a vector quantization\nmodule to discretize the continuous representations of speech and text into a\nfinite set of virtual tokens, and use ASR data to map corresponding speech and\ntext to the same virtual token in a shared codebook. This way, source language\nspeech can be embedded in the same semantic space as the source language text,\nwhich can be then transformed into target language text with an MT module.\nExperiments on multiple language pairs demonstrate that our zero-shot ST method\nsignificantly improves the SOTA, and even performers on par with the strong\nsupervised ST baselines.",
    "descriptor": "\nComments: Accepted by the main conference of EMNLP 2022\n",
    "authors": [
      "Chen Wang",
      "Yuchen Liu",
      "Boxing Chen",
      "Jiajun Zhang",
      "Wei Luo",
      "Zhongqiang Huang",
      "Chengqing Zong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.09556"
  },
  {
    "id": "arXiv:2210.09559",
    "title": "Unsupervised Inference of Data-Driven Discourse Structures using a Tree  Auto-Encoder",
    "abstract": "With a growing need for robust and general discourse structures in many\ndownstream tasks and real-world applications, the current lack of high-quality,\nhigh-quantity discourse trees poses a severe shortcoming. In order the\nalleviate this limitation, we propose a new strategy to generate tree\nstructures in a task-agnostic, unsupervised fashion by extending a latent tree\ninduction framework with an auto-encoding objective. The proposed approach can\nbe applied to any tree-structured objective, such as syntactic parsing,\ndiscourse parsing and others. However, due to the especially difficult\nannotation process to generate discourse trees, we initially develop such\nmethod to complement task-specific models in generating much larger and more\ndiverse discourse treebanks.",
    "descriptor": "\nComments: Extended Abstract. Non-Archival. 2 pages\n",
    "authors": [
      "Patrick Huber",
      "Giuseppe Carenini"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.09559"
  },
  {
    "id": "arXiv:2210.09563",
    "title": "FedForgery: Generalized Face Forgery Detection with Residual Federated  Learning",
    "abstract": "With the continuous development of deep learning in the field of image\ngeneration models, a large number of vivid forged faces have been generated and\nspread on the Internet. These high-authenticity artifacts could grow into a\nthreat to society security. Existing face forgery detection methods directly\nutilize the obtained public shared or centralized data for training but ignore\nthe personal privacy and security issues when personal data couldn't be\ncentralizedly shared in real-world scenarios. Additionally, different\ndistributions caused by diverse artifact types would further bring adverse\ninfluences on the forgery detection task. To solve the mentioned problems, the\npaper proposes a novel generalized residual Federated learning for face Forgery\ndetection (FedForgery). The designed variational autoencoder aims to learn\nrobust discriminative residual feature maps to detect forgery faces (with\ndiverse or even unknown artifact types). Furthermore, the general federated\nlearning strategy is introduced to construct distributed detection model\ntrained collaboratively with multiple local decentralized devices, which could\nfurther boost the representation generalization. Experiments conducted on\npublicly available face forgery detection datasets prove the superior\nperformance of the proposed FedForgery. The designed novel generalized face\nforgery detection protocols and source code would be publicly available.",
    "descriptor": "\nComments: The code is available at this https URL\n",
    "authors": [
      "Decheng Liu",
      "Zhan Dang",
      "Chunlei Peng",
      "Yu Zheng",
      "Shuang Li",
      "Nannan Wang",
      "Xinbo Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09563"
  },
  {
    "id": "arXiv:2210.09565",
    "title": "Towards Domain-Independent Supervised Discourse Parsing Through Gradient  Boosting",
    "abstract": "Discourse analysis and discourse parsing have shown great impact on many\nimportant problems in the field of Natural Language Processing (NLP). Given the\ndirect impact of discourse annotations on model performance and\ninterpretability, robustly extracting discourse structures from arbitrary\ndocuments is a key task to further improve computational models in NLP. To this\nend, we present a new, supervised paradigm directly tackling the domain\nadaptation issue in discourse parsing. Specifically, we introduce the first\nfully supervised discourse parser designed to alleviate the domain dependency\nthrough a staged model of weak classifiers by introducing the gradient boosting\nframework.",
    "descriptor": "\nComments: Extended Abstract. Non Archival. 3 pages\n",
    "authors": [
      "Patrick Huber",
      "Giuseppe Carenini"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.09565"
  },
  {
    "id": "arXiv:2210.09566",
    "title": "Simple Emergent Action Representations from Multi-Task Policy Training",
    "abstract": "Low-level sensory and motor signals in the high-dimensional spaces (e.g.,\nimage observations or motor torques) in deep reinforcement learning are\ncomplicated to understand or harness for downstream tasks directly. While\nsensory representations have been widely studied, the representations of\nactions that form motor skills are yet under exploration. In this work, we find\nthat when a multi-task policy network takes as input states and task\nembeddings, a space based on the task embeddings emerges to contain meaningful\naction representations with moderate constraints. Within this space,\ninterpolated or composed embeddings can serve as a high-level interface to\ninstruct the agent to perform meaningful action sequences. Empirical results\nnot only show that the proposed action representations have efficacy for\nintra-action interpolation and inter-action composition with limited or no\nlearning, but also demonstrate their superior ability in task adaptation to\nstrong baselines in Mujoco locomotion tasks. The evidence elucidates that\nlearning action representations is a promising direction toward efficient,\nadaptable, and composable RL, forming the basis of abstract action planning and\nthe understanding of motor signal space. Anonymous project page:\nhttps://sites.google.com/view/emergent-action-representation/",
    "descriptor": "\nComments: 17 pages, 8 figures\n",
    "authors": [
      "Pu Hua",
      "Yubei Chen",
      "Huazhe Xu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.09566"
  },
  {
    "id": "arXiv:2210.09569",
    "title": "ModSandbox: Facilitating Online Community Moderation Through Error  Prediction and Improvement of Automated Rules",
    "abstract": "Despite the common use of rule-based tools for online content moderation,\nhuman moderators still spend a lot of time monitoring them to ensure that they\nwork as intended. Based on surveys and interviews with Reddit moderators who\nuse AutoModerator, we identified the main challenges in reducing false\npositives and false negatives of automated rules: not being able to estimate\nthe actual effect of a rule in advance and having difficulty figuring out how\nthe rules should be updated. To address these issues, we built ModSandbox, a\nnovel virtual sandbox system that detects possible false positives and false\nnegatives of a rule to be improved and visualizes which part of the rule is\ncausing issues. We conducted a user study with online content moderators,\nfinding that ModSandbox can support quickly finding possible false positives\nand false negatives of automated rules and guide moderators to update those to\nreduce future errors.",
    "descriptor": "\nComments: 24 pages, 10 figures\n",
    "authors": [
      "Jean Y. Song",
      "Sangwook Lee",
      "Jisoo Lee",
      "Mina Kim",
      "Juho Kim"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.09569"
  },
  {
    "id": "arXiv:2210.09571",
    "title": "On Relations Between Tight Bounds for Symmetric $f$-Divergences and  Binary Divergences",
    "abstract": "Minimizing divergence measures under a constraint is an important problem. We\nderive a sufficient condition that binary divergence measures provide lower\nbounds for symmetric divergence measures under a given triangular\ndiscrimination or given means and variances. Assuming this sufficient\ncondition, the former bounds are always tight, and the latter bounds are tight\nwhen two probability measures have the same variance. An application of these\nresults for nonequilibrium physics is provided.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Tomohiro Nishiyama"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2210.09571"
  },
  {
    "id": "arXiv:2210.09572",
    "title": "Spatio-Temporal-based Context Fusion for Video Anomaly Detection",
    "abstract": "Video anomaly detection aims to discover abnormal events in videos, and the\nprincipal objects are target objects such as people and vehicles. Each target\nin the video data has rich spatio-temporal context information. Most existing\nmethods only focus on the temporal context, ignoring the role of the spatial\ncontext in anomaly detection. The spatial context information represents the\nrelationship between the detection target and surrounding targets. Anomaly\ndetection makes a lot of sense. To this end, a video anomaly detection\nalgorithm based on target spatio-temporal context fusion is proposed. Firstly,\nthe target in the video frame is extracted through the target detection network\nto reduce background interference. Then the optical flow map of two adjacent\nframes is calculated. Motion features are used multiple targets in the video\nframe to construct spatial context simultaneously, re-encoding the target\nappearance and motion features, and finally reconstructing the above features\nthrough the spatio-temporal dual-stream network, and using the reconstruction\nerror to represent the abnormal score. The algorithm achieves frame-level AUCs\nof 98.5% and 86.3% on the UCSDped2 and Avenue datasets, respectively. On the\nUCSDped2 dataset, the spatio-temporal dual-stream network improves frames by\n5.1% and 0.3%, respectively, compared to the temporal and spatial stream\nnetworks. After using spatial context encoding, the frame-level AUC is enhanced\nby 1%, which verifies the method's effectiveness.",
    "descriptor": "",
    "authors": [
      "Chao Hu",
      "Weibin Qiu",
      "Weijie Wu",
      "Liqiang Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.09572"
  },
  {
    "id": "arXiv:2210.09573",
    "title": "ViTCoD: Vision Transformer Acceleration via Dedicated Algorithm and  Accelerator Co-Design",
    "abstract": "Vision Transformers (ViTs) have achieved state-of-the-art performance on\nvarious vision tasks. However, ViTs' self-attention module is still arguably a\nmajor bottleneck, limiting their achievable hardware efficiency. Meanwhile,\nexisting accelerators dedicated to NLP Transformers are not optimal for ViTs.\nThis is because there is a large difference between ViTs and NLP Transformers:\nViTs have a relatively fixed number of input tokens, whose attention maps can\nbe pruned by up to 90% even with fixed sparse patterns; while NLP Transformers\nneed to handle input sequences of varying numbers of tokens and rely on\non-the-fly predictions of dynamic sparse attention patterns for each input to\nachieve a decent sparsity (e.g., >=50%). To this end, we propose a dedicated\nalgorithm and accelerator co-design framework dubbed ViTCoD for accelerating\nViTs. Specifically, on the algorithm level, ViTCoD prunes and polarizes the\nattention maps to have either denser or sparser fixed patterns for regularizing\ntwo levels of workloads without hurting the accuracy, largely reducing the\nattention computations while leaving room for alleviating the remaining\ndominant data movements; on top of that, we further integrate a lightweight and\nlearnable auto-encoder module to enable trading the dominant high-cost data\nmovements for lower-cost computations. On the hardware level, we develop a\ndedicated accelerator to simultaneously coordinate the enforced denser/sparser\nworkloads and encoder/decoder engines for boosted hardware utilization.\nExtensive experiments and ablation studies validate that ViTCoD largely reduces\nthe dominant data movement costs, achieving speedups of up to 235.3x, 142.9x,\n86.0x, 10.1x, and 6.8x over general computing platforms CPUs, EdgeGPUs, GPUs,\nand prior-art Transformer accelerators SpAtten and Sanger under an attention\nsparsity of 90%, respectively.",
    "descriptor": "\nComments: Accepted to HPCA 2023\n",
    "authors": [
      "Haoran You",
      "Zhanyi Sun",
      "Huihong Shi",
      "Zhongzhi Yu",
      "Yang Zhao",
      "Yongan Zhang",
      "Chaojian Li",
      "Baopu Li",
      "Yingyan Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09573"
  },
  {
    "id": "arXiv:2210.09579",
    "title": "Unpacking Reward Shaping: Understanding the Benefits of Reward  Engineering on Sample Complexity",
    "abstract": "Reinforcement learning provides an automated framework for learning behaviors\nfrom high-level reward specifications, but in practice the choice of reward\nfunction can be crucial for good results -- while in principle the reward only\nneeds to specify what the task is, in reality practitioners often need to\ndesign more detailed rewards that provide the agent with some hints about how\nthe task should be completed. The idea of this type of ``reward-shaping'' has\nbeen often discussed in the literature, and is often a critical part of\npractical applications, but there is relatively little formal characterization\nof how the choice of reward shaping can yield benefits in sample complexity. In\nthis work, we build on the framework of novelty-based exploration to provide a\nsimple scheme for incorporating shaped rewards into RL along with an analysis\ntool to show that particular choices of reward shaping provably improve sample\nefficiency. We characterize the class of problems where these gains are\nexpected to be significant and show how this can be connected to practical\nalgorithms in the literature. We confirm that these results hold in practice in\nan experimental evaluation, providing an insight into the mechanisms through\nwhich reward shaping can significantly improve the complexity of reinforcement\nlearning while retaining asymptotic performance.",
    "descriptor": "",
    "authors": [
      "Abhishek Gupta",
      "Aldo Pacchiano",
      "Yuexiang Zhai",
      "Sham M. Kakade",
      "Sergey Levine"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.09579"
  },
  {
    "id": "arXiv:2210.09580",
    "title": "A Novel Feature Representation for Malware Classification",
    "abstract": "In this study we have presented a novel feature representation for malicious\nprograms that can be used for malware classification. We have shown how to\nconstruct the features in a bottom-up approach, and analyzed the overlap of\nmalicious and benign programs in terms of their components. We have shown that\nour method of analysis offers an increase in feature resolution that is\ndescriptive of data movement in comparison to tf-idf features.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2210.08034\n",
    "authors": [
      "John Musgrave",
      "Temesguen Messay-Kebede",
      "David Kapp",
      "Anca Ralescu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09580"
  },
  {
    "id": "arXiv:2210.09582",
    "title": "NADI 2022: The Third Nuanced Arabic Dialect Identification Shared Task",
    "abstract": "We describe findings of the third Nuanced Arabic Dialect Identification\nShared Task (NADI 2022). NADI aims at advancing state of the art Arabic NLP,\nincluding on Arabic dialects. It does so by affording diverse datasets and\nmodeling opportunities in a standardized context where meaningful comparisons\nbetween models and approaches are possible. NADI 2022 targeted both dialect\nidentification (Subtask 1) and dialectal sentiment analysis (Subtask 2) at the\ncountry level. A total of 41 unique teams registered for the shared task, of\nwhom 21 teams have actually participated (with 105 valid submissions). Among\nthese, 19 teams participated in Subtask 1 and 10 participated in Subtask 2. The\nwinning team achieved 27.06 F1 on Subtask 1 and F1=75.16 on Subtask 2,\nreflecting that the two subtasks remain challenging and motivating future work\nin this area. We describe methods employed by participating teams and offer an\noutlook for NADI.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2103.08466\n",
    "authors": [
      "Muhammad Abdul-Mageed",
      "Chiyu Zhang",
      "AbdelRahim Elmadany",
      "Houda Bouamor",
      "Nizar Habash"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.09582"
  },
  {
    "id": "arXiv:2210.09586",
    "title": "Deep Deterministic Policy Gradient to Minimize the Age of Information in  Cellular V2X Communications",
    "abstract": "This paper studies the problem of minimizing the age of information (AoI) in\ncellular vehicle-to-everything communications. To provide minimal AoI and high\nreliability for vehicles' safety information, NOMA is exploited. We reformulate\na resource allocation problem that involves half-duplex transceiver selection,\nbroadcast coverage optimization, power allocation, and resource block\nscheduling. First, to obtain the optimal solution, we formulate the problem as\na mixed-integer nonlinear programming problem and then study its NP-hardness.\nThe NP-hardness result motivates us to design simple solutions. Consequently,\nwe model the problem as a single-agent Markov decision process to solve the\nproblem efficiently using fingerprint deep reinforcement learning techniques\nsuch as deep-Q-network (DQN) methods. Nevertheless, applying DQN is not\nstraightforward due to the curse of dimensionality implied by the large and\nmixed action space that contains discrete and continuous optimization\ndecisions. Therefore, to solve this mixed discrete/continuous problem\nefficiently, simply and elegantly, we propose a decomposition technique that\nconsists of first solving the discrete subproblem using a matching algorithm\nbased on state-of-the-art stable roommate matching and then solving the\ncontinuous subproblem using DRL algorithm that is based on deep deterministic\npolicy gradient DDPG. We validate our proposed method through Monte Carlo\nsimulations where we show that the decomposed matching and DRL algorithm\nsuccessfully minimizes the AoI and achieves almost 66% performance gain\ncompared to the best benchmarks for various vehicles' speeds, transmission\npower, or packet sizes. Further, we prove the existence of an optimal value of\nbroadcast coverage at which the learning algorithm provides the optimal AoI.",
    "descriptor": "\nComments: 16 pages, 11 figures, 2 tables, 2 algorithms\n",
    "authors": [
      "Zoubeir Mlika",
      "Soumaya Cherkaoui"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.09586"
  },
  {
    "id": "arXiv:2210.09587",
    "title": "Summary Workbench: Unifying Application and Evaluation of Text  Summarization Models",
    "abstract": "This paper presents Summary Workbench, a new tool for developing and\nevaluating text summarization models. New models and evaluation measures can be\neasily integrated as Docker-based plugins, allowing to examine the quality of\ntheir summaries against any input and to evaluate them using various evaluation\nmeasures. Visual analyses combining multiple measures provide insights into the\nmodels' strengths and weaknesses. The tool is hosted at\n\\url{https://tldr.demo.webis.de} and also supports local deployment for private\nresources.",
    "descriptor": "\nComments: Accepted as system demonstration at EMNLP 2022\n",
    "authors": [
      "Shahbaz Syed",
      "Dominik Schwabe",
      "Martin Potthast"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.09587"
  },
  {
    "id": "arXiv:2210.09588",
    "title": "Synergy with Translation Artifacts for Training and Inference in  Multilingual Tasks",
    "abstract": "Translation has played a crucial role in improving the performance on\nmultilingual tasks: (1) to generate the target language data from the source\nlanguage data for training and (2) to generate the source language data from\nthe target language data for inference. However, prior works have not\nconsidered the use of both translations simultaneously. This paper shows that\ncombining them can synergize the results on various multilingual sentence\nclassification tasks. We empirically find that translation artifacts stylized\nby translators are the main factor of the performance gain. Based on this\nanalysis, we adopt two training methods, SupCon and MixUp, considering\ntranslation artifacts. Furthermore, we propose a cross-lingual fine-tuning\nalgorithm called MUSC, which uses SupCon and MixUp jointly and improves the\nperformance. Our code is available at https://github.com/jongwooko/MUSC.",
    "descriptor": "\nComments: The 2022 Conference on Empirical Methods in Natural Language Processing (EMNLP)\n",
    "authors": [
      "Jaehoon Oh",
      "Jongwoo Ko",
      "Se-Young Yun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.09588"
  },
  {
    "id": "arXiv:2210.09594",
    "title": "Analyses of the contour integral method for time fractional  subdiffusion-normal transport equation",
    "abstract": "In this work, we theoretically and numerically discuss the time fractional\nsubdiffusion-normal transport equation, which depicts a crossover from\nsub-diffusion (as $t\\rightarrow 0$) to normal diffusion (as $t\\rightarrow\n\\infty$). Firstly, the well-posedness and regularities of the model are studied\nby using the bivariate Mittag-Leffler function. Theoretical results show that\nafter introducing the first-order derivative operator, the regularity of the\nsolution can be improved in substance. Then, a numerical scheme with\nhigh-precision is developed no matter the initial value is smooth or\nnon-smooth. More specifically, we use the contour integral method (CIM) with\nparameterized hyperbolic contour to approximate the temporal local and\nnon-local operators, and employ the standard Galerkin finite element method for\nspacial discretization. Rigorous error estimates show that the proposed\nnumerical scheme has spectral accuracy in time and optimal convergence order in\nspace. Besides, we further improve the algorithm and reduce the computational\ncost by using the barycentric Lagrange interpolation. Finally, the obtained\ntheoretical results as well as the acceleration algorithm are verified by\nseveral 1-D and 2-D numerical experiments, which also show that the numerical\nscheme developed in this paper is effective and robust.",
    "descriptor": "\nComments: 34 pages,4 figures, 12 tables\n",
    "authors": [
      "Fugui Ma",
      "Lijing Zhao",
      "Weihua Deng",
      "Yejuan Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.09594"
  },
  {
    "id": "arXiv:2210.09597",
    "title": "Soft-Labeled Contrastive Pre-training for Function-level Code  Representation",
    "abstract": "Code contrastive pre-training has recently achieved significant progress on\ncode-related tasks. In this paper, we present \\textbf{SCodeR}, a\n\\textbf{S}oft-labeled contrastive pre-training framework with two positive\nsample construction methods to learn functional-level \\textbf{Code}\n\\textbf{R}epresentation. Considering the relevance between codes in a\nlarge-scale code corpus, the soft-labeled contrastive pre-training can obtain\nfine-grained soft-labels through an iterative adversarial manner and use them\nto learn better code representation. The positive sample construction is\nanother key for contrastive pre-training. Previous works use\ntransformation-based methods like variable renaming to generate semantically\nequal positive codes. However, they usually result in the generated code with a\nhighly similar surface form, and thus mislead the model to focus on superficial\ncode structure instead of code semantics. To encourage SCodeR to capture\nsemantic information from the code, we utilize code comments and abstract\nsyntax sub-trees of the code to build positive samples. We conduct experiments\non four code-related tasks over seven datasets. Extensive experimental results\nshow that SCodeR achieves new state-of-the-art performance on all of them,\nwhich illustrates the effectiveness of the proposed pre-training method.",
    "descriptor": "\nComments: Accepted to EMNLP 2022 (findings)\n",
    "authors": [
      "Xiaonan Li",
      "Daya Guo",
      "Yeyun Gong",
      "Yun Lin",
      "Yelong Shen",
      "Xipeng Qiu",
      "Daxin Jiang",
      "Weizhu Chen",
      "Nan Duan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.09597"
  },
  {
    "id": "arXiv:2210.09598",
    "title": "Planning for Sample Efficient Imitation Learning",
    "abstract": "Imitation learning is a class of promising policy learning algorithms that is\nfree from many practical issues with reinforcement learning, such as the reward\ndesign issue and the exploration hardness. However, the current imitation\nalgorithm struggles to achieve both high performance and high in-environment\nsample efficiency simultaneously. Behavioral Cloning (BC) does not need\nin-environment interactions, but it suffers from the covariate shift problem\nwhich harms its performance. Adversarial Imitation Learning (AIL) turns\nimitation learning into a distribution matching problem. It can achieve better\nperformance on some tasks but it requires a large number of in-environment\ninteractions. Inspired by the recent success of EfficientZero in RL, we propose\nEfficientImitate (EI), a planning-based imitation learning method that can\nachieve high in-environment sample efficiency and performance simultaneously.\nOur algorithmic contribution in this paper is two-fold. First, we extend AIL\ninto the MCTS-based RL. Second, we show the seemingly incompatible two classes\nof imitation algorithms (BC and AIL) can be naturally unified under our\nframework, enjoying the benefits of both. We benchmark our method not only on\nthe state-based DeepMind Control Suite, but also on the image version which\nmany previous works find highly challenging. Experimental results show that EI\nachieves state-of-the-art results in performance and sample efficiency. EI\nshows over 4x gain in performance in the limited sample setting on state-based\nand image-based tasks and can solve challenging problems like Humanoid, where\nprevious methods fail with small amount of interactions. Our code is available\nat https://github.com/zhaohengyin/EfficientImitate.",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Zhao-Heng Yin",
      "Weirui Ye",
      "Qifeng Chen",
      "Yang Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.09598"
  },
  {
    "id": "arXiv:2210.09599",
    "title": "Denoising Enhanced Distantly Supervised Ultrafine Entity Typing",
    "abstract": "Recently, the task of distantly supervised (DS) ultra-fine entity typing has\nreceived significant attention. However, DS data is noisy and often suffers\nfrom missing or wrong labeling issues resulting in low precision and low\nrecall. This paper proposes a novel ultra-fine entity typing model with\ndenoising capability. Specifically, we build a noise model to estimate the\nunknown labeling noise distribution over input contexts and noisy type labels.\nWith the noise model, more trustworthy labels can be recovered by subtracting\nthe estimated noise from the input. Furthermore, we propose an entity typing\nmodel, which adopts a bi-encoder architecture, is trained on the denoised data.\nFinally, the noise model and entity typing model are trained iteratively to\nenhance each other. We conduct extensive experiments on the Ultra-Fine entity\ntyping dataset as well as OntoNotes dataset and demonstrate that our approach\nsignificantly outperforms other baseline methods.",
    "descriptor": "",
    "authors": [
      "Yue Zhang",
      "Hongliang Fei",
      "Ping Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.09599"
  },
  {
    "id": "arXiv:2210.09602",
    "title": "ODEs learn to walk: ODE-Net based data-driven modeling for crowd  dynamics",
    "abstract": "Predicting the behaviors of pedestrian crowds is of critical importance for a\nvariety of real-world problems. Data driven modeling, which aims to learn the\nmathematical models from observed data, is a promising tool to construct models\nthat can make accurate predictions of such systems. In this work, we present a\ndata-driven modeling approach based on the ODE-Net framework, for constructing\ncontinuous-time models of crowd dynamics. We discuss some challenging issues in\napplying the ODE-Net method to such problems, which are primarily associated\nwith the dimensionality of the underlying crowd system, and we propose to\naddress these issues by incorporating the social-force concept in the ODE-Net\nframework. Finally application examples are provided to demonstrate the\nperformance of the proposed method.",
    "descriptor": "",
    "authors": [
      "Chen Cheng",
      "Jinglai Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.09602"
  },
  {
    "id": "arXiv:2210.09603",
    "title": "Hidet: Task Mapping Programming Paradigm for Deep Learning Tensor  Programs",
    "abstract": "As deep learning models nowadays are widely adopted by both cloud services\nand edge devices, the latency of deep learning model inferences becomes crucial\nto provide efficient model serving. However, it is challenging to develop\nefficient tensor programs for deep learning operators due to the high\ncomplexity of modern accelerators (e.g., NVIDIA GPUs and Google TPUs) and the\nrapidly growing number of operators. Deep learning compilers, such as Apache\nTVM, adopt declarative scheduling primitives to lower the bar of developing\ntensor programs. However, we show that this approach is insufficient to cover\nstate-of-the-art tensor program optimizations (e.g., double buffering). In this\npaper, we propose to embed the scheduling process into tensor programs and use\ndedicated mappings, called task mappings, to define the computation assignment\nand ordering directly in the tensor programs. This new approach greatly\nenriches the expressible optimizations by allowing developers to manipulate\ntensor programs at a much finer granularity (e.g., allowing program\nstatement-level optimizations). We call the proposed method the\ntask-mapping-oriented programming paradigm. With the proposed paradigm, we\nimplement a deep learning compiler - Hidet. Extensive experiments on modern\nconvolution and transformer models show that Hidet outperforms state-of-the-art\nDNN inference framework, ONNX Runtime, and compiler, TVM equipped with\nscheduler AutoTVM and Ansor, by up to 1.48x (1.22x on average) with enriched\noptimizations. It also reduces the tuning time by 20x and 11x compared with\nAutoTVM and Ansor, respectively.",
    "descriptor": "",
    "authors": [
      "Yaoyao Ding",
      "Cody Hao Yu",
      "Bojian Zheng",
      "Yizhi Liu",
      "Yida Wang",
      "Gennady Pekhimenko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2210.09603"
  },
  {
    "id": "arXiv:2210.09604",
    "title": "Perceptual Multi-Exposure Fusion",
    "abstract": "As an ever-increasing demand for high dynamic range (HDR) scene shooting,\nmulti-exposure image fusion (MEF) technology has abounded. In recent years,\nmulti-scale exposure fusion approaches based on detail-enhancement have led the\nway for improvement in highlight and shadow details. Most of such methods,\nhowever, are too computationally expensive to be deployed on mobile devices.\nThis paper presents a perceptual multi-exposure fusion method that not just\nensures fine shadow/highlight details but with lower complexity than\ndetailenhanced methods. We analyze the potential defects of three classical\nexposure measures in lieu of using detail-enhancement component and improve two\nof them, namely adaptive Wellexposedness (AWE) and the gradient of color images\n(3-D gradient). AWE designed in YCbCr color space considers the difference\nbetween varying exposure images. 3-D gradient is employed to extract fine\ndetails. We build a large-scale multiexposure benchmark dataset suitable for\nstatic scenes, which contains 167 image sequences all told. Experiments on the\nconstructed dataset demonstrate that the proposed method exceeds existing eight\nstate-of-the-art approaches in terms of visually and MEF-SSIM value. Moreover,\nour approach can achieve a better improvement for current image enhancement\ntechniques, ensuring fine detail in bright light.",
    "descriptor": "",
    "authors": [
      "Xiaoning Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.09604"
  },
  {
    "id": "arXiv:2210.09605",
    "title": "Optimal Phase Design for RIS Channel Estimation",
    "abstract": "We develop an optimal version of a prior two-stage channel estimation\nprotocol for RIS-assisted channels. The new design uses a modified DFT matrix\n(MDFT) for the training phases at the RIS and is shown to minimize the total\nchannel estimation error variance. In conjunction with interpolation\n(estimating fewer RIS channels), the MDFT approach accelerates channel\nestimation even when the channel from base station to RIS is line-of-sight. In\ncontrast, prior two-stage techniques required a full-rank channel for efficient\nestimation. We investigate the resulting channel estimation errors by comparing\ndifferent training phase designs for a variety of propagation conditions using\na ray-based channel model. To examine the overall performance, we simulate the\nspectral efficiency with MRC processing for a single-user RIS-assisted system\nusing an existing optimal design for the RIS transmission phases. Results\nverify the optimality of MDFT while simulations and analysis show that the\nperformance is more dependent on the user-to-RIS channel correlation and the\ncoarseness of the interpolation used, rather than the training phase design.\nFor example, under a scenario with more highly correlated channels, the\nprocedure accelerates channel estimation by a factor of 16, while the\nimprovement is a factor of 5 in a less correlated case. The overall procedure\nis extremely robust, with a maximum performance loss of 1.5bits/sec/Hz compared\nto that with perfect channel state information for the considered channel\nconditions.",
    "descriptor": "",
    "authors": [
      "Chelsea L. Miller",
      "Peter J. Smith",
      "Pawel A. Dmochowski"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.09605"
  },
  {
    "id": "arXiv:2210.09609",
    "title": "SA-MLP: Distilling Graph Knowledge from GNNs into Structure-Aware MLP",
    "abstract": "The message-passing mechanism helps Graph Neural Networks (GNNs) achieve\nremarkable results on various node classification tasks. Nevertheless, the\nrecursive nodes fetching and aggregation in message-passing cause inference\nlatency when deploying GNNs to large-scale graphs. One promising inference\nacceleration direction is to distill the GNNs into message-passing-free student\nmulti-layer perceptrons (MLPs). However, the MLP student cannot fully learn the\nstructure knowledge due to the lack of structure inputs, which causes inferior\nperformance in the heterophily and inductive scenarios. To address this, we\nintend to inject structure information into MLP-like students in low-latency\nand interpretable ways. Specifically, we first design a Structure-Aware MLP\n(SA-MLP) student that encodes both features and structures without\nmessage-passing. Then, we introduce a novel structure-mixing knowledge\ndistillation strategy to enhance the learning ability of MLPs for structure\ninformation. Furthermore, we design a latent structure embedding approximation\ntechnique with two-stage distillation for inductive scenarios. Extensive\nexperiments on eight benchmark datasets under both transductive and inductive\nsettings show that our SA-MLP can consistently outperform the teacher GNNs,\nwhile maintaining faster inference as MLPs. The source code of our work can be\nfound in https://github.com/JC-202/SA-MLP.",
    "descriptor": "",
    "authors": [
      "Jie Chen",
      "Shouzhen Chen",
      "Mingyuan Bai",
      "Junbin Gao",
      "Junping Zhang",
      "Jian Pu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.09609"
  },
  {
    "id": "arXiv:2210.09615",
    "title": "Homogeneous Multi-modal Feature Fusion and Interaction for 3D Object  Detection",
    "abstract": "Multi-modal 3D object detection has been an active research topic in\nautonomous driving. Nevertheless, it is non-trivial to explore the cross-modal\nfeature fusion between sparse 3D points and dense 2D pixels. Recent approaches\neither fuse the image features with the point cloud features that are projected\nonto the 2D image plane or combine the sparse point cloud with dense image\npixels. These fusion approaches often suffer from severe information loss, thus\ncausing sub-optimal performance. To address these problems, we construct the\nhomogeneous structure between the point cloud and images to avoid projective\ninformation loss by transforming the camera features into the LiDAR 3D space.\nIn this paper, we propose a homogeneous multi-modal feature fusion and\ninteraction method (HMFI) for 3D object detection. Specifically, we first\ndesign an image voxel lifter module (IVLM) to lift 2D image features into the\n3D space and generate homogeneous image voxel features. Then, we fuse the\nvoxelized point cloud features with the image features from different regions\nby introducing the self-attention based query fusion mechanism (QFM). Next, we\npropose a voxel feature interaction module (VFIM) to enforce the consistency of\nsemantic information from identical objects in the homogeneous point cloud and\nimage voxel representations, which can provide object-level alignment guidance\nfor cross-modal feature fusion and strengthen the discriminative ability in\ncomplex backgrounds. We conduct extensive experiments on the KITTI and Waymo\nOpen Dataset, and the proposed HMFI achieves better performance compared with\nthe state-of-the-art multi-modal methods. Particularly, for the 3D detection of\ncyclist on the KITTI benchmark, HMFI surpasses all the published algorithms by\na large margin.",
    "descriptor": "\nComments: Accepted by ECCV 2022\n",
    "authors": [
      "Xin Li",
      "Botian Shi",
      "Yuenan Hou",
      "Xingjiao Wu",
      "Tianlong Ma",
      "Yikang Li",
      "Liang He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09615"
  },
  {
    "id": "arXiv:2210.09617",
    "title": "Making Split Learning Resilient to Label Leakage by Potential Energy  Loss",
    "abstract": "As a practical privacy-preserving learning method, split learning has drawn\nmuch attention in academia and industry. However, its security is constantly\nbeing questioned since the intermediate results are shared during training and\ninference. In this paper, we focus on the privacy leakage problem caused by the\ntrained split model, i.e., the attacker can use a few labeled samples to\nfine-tune the bottom model, and gets quite good performance. To prevent such\nkind of privacy leakage, we propose the potential energy loss to make the\noutput of the bottom model become a more `complicated' distribution, by pushing\noutputs of the same class towards the decision boundary. Therefore, the\nadversary suffers a large generalization error when fine-tuning the bottom\nmodel with only a few leaked labeled samples. Experiment results show that our\nmethod significantly lowers the attacker's fine-tuning accuracy, making the\nsplit model more resilient to label leakage.",
    "descriptor": "",
    "authors": [
      "Fei Zheng",
      "Chaochao Chen",
      "Binhui Yao",
      "Xiaolin Zheng"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09617"
  },
  {
    "id": "arXiv:2210.09618",
    "title": "Object Recognition in Different Lighting Conditions at Various Angles by  Deep Learning Method",
    "abstract": "Existing computer vision and object detection methods strongly rely on neural\nnetworks and deep learning. This active research area is used for applications\nsuch as autonomous driving, aerial photography, protection, and monitoring.\nFuturistic object detection methods rely on rectangular, boundary boxes drawn\nover an object to accurately locate its location. The modern object recognition\nalgorithms, however, are vulnerable to multiple factors, such as illumination,\nocclusion, viewing angle, or camera rotation as well as cost. Therefore, deep\nlearning-based object recognition will significantly increase the recognition\nspeed and compatible external interference. In this study, we use convolutional\nneural networks (CNN) to recognize items, the neural networks have the\nadvantages of end-to-end, sparse relation, and sharing weights. This article\naims to classify the name of the various object based on the position of an\nobject's detected box. Instead, under different distances, we can get\nrecognition results with different confidence. Through this study, we find that\nthis model's accuracy through recognition is mainly influenced by the\nproportion of objects and the number of samples. When we have a small\nproportion of an object on camera, then we get higher recognition accuracy; if\nwe have a much small number of samples, we can get greater accuracy in\nrecognition. The epidemic has a great impact on the world economy where\ndesigning a cheaper object recognition system is the need of time.",
    "descriptor": "",
    "authors": [
      "Imran Khan Mirani",
      "Chen Tianhua",
      "Malak Abid Ali Khan",
      "Syed Muhammad Aamir",
      "Waseef Menhaj"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09618"
  },
  {
    "id": "arXiv:2210.09622",
    "title": "Deep Black-Box Reinforcement Learning with Movement Primitives",
    "abstract": "\\Episode-based reinforcement learning (ERL) algorithms treat reinforcement\nlearning (RL) as a black-box optimization problem where we learn to select a\nparameter vector of a controller, often represented as a movement primitive,\nfor a given task descriptor called a context. ERL offers several distinct\nbenefits in comparison to step-based RL. It generates smooth control\ntrajectories, can handle non-Markovian reward definitions, and the resulting\nexploration in parameter space is well suited for solving sparse reward\nsettings. Yet, the high dimensionality of the movement primitive parameters has\nso far hampered the effective use of deep RL methods. In this paper, we present\na new algorithm for deep ERL. It is based on differentiable trust region\nlayers, a successful on-policy deep RL algorithm. These layers allow us to\nspecify trust regions for the policy update that are solved exactly for each\nstate using convex optimization, which enables policies learning with the high\nprecision required for the ERL. We compare our ERL algorithm to\nstate-of-the-art step-based algorithms in many complex simulated robotic\ncontrol tasks. In doing so, we investigate different reward formulations -\ndense, sparse, and non-Markovian. While step-based algorithms perform well only\non dense rewards, ERL performs favorably on sparse and non-Markovian rewards.\nMoreover, our results show that the sparse and the non-Markovian rewards are\nalso often better suited to define the desired behavior, allowing us to obtain\nconsiderably higher quality policies compared to step-based RL.",
    "descriptor": "\nComments: Accepted at CoRL 2022\n",
    "authors": [
      "Fabian Otto",
      "Onur Celik",
      "Hongyi Zhou",
      "Hanna Ziesche",
      "Ngo Anh Vien",
      "Gerhard Neumann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.09622"
  },
  {
    "id": "arXiv:2210.09626",
    "title": "FLECS-CGD: A Federated Learning Second-Order Framework via Compression  and Sketching with Compressed Gradient Differences",
    "abstract": "In the recent paper FLECS (Agafonov et al, FLECS: A Federated Learning\nSecond-Order Framework via Compression and Sketching), the second-order\nframework FLECS was proposed for the Federated Learning problem. This method\nutilize compression of sketched Hessians to make communication costs low.\nHowever, the main bottleneck of FLECS is gradient communication without\ncompression. In this paper, we propose the modification of FLECS with\ncompressed gradient differences, which we call FLECS-CGD (FLECS with Compressed\nGradient Differences) and make it applicable for stochastic optimization.\nConvergence guarantees are provided in strongly convex and nonconvex cases.\nExperiments show the practical benefit of proposed approach.",
    "descriptor": "",
    "authors": [
      "Artem Agafonov",
      "Brahim Erraji",
      "Martin Tak\u00e1\u010d"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.09626"
  },
  {
    "id": "arXiv:2210.09628",
    "title": "Review of Persuasive User Interface as Strategy for Technology Addiction  in Virtual Environments",
    "abstract": "In the era of virtuality, the increasingly ubiquitous technology bears the\nchallenge of excessive user dependency, also known as user addiction. Augmented\nreality (AR) and virtual reality (VR) have become increasingly integrated into\ndaily life. Although discussions about the drawbacks of these technologies are\nabundant, their exploration for solutions is still rare. Thus, using the PRISMA\nmethodology, this paper reviewed the literature on technology addiction and\npersuasive technology. After describing the key research trends, the paper\nsummed up nine persuasive elements of user interfaces (UIs) that AR and VR\ndevelopers could add to their apps to make them less addictive. Furthermore,\nthis review paper encourages more research into a persuasive strategy for\ncontrolling user dependency in virtual-physical blended cyberspace.",
    "descriptor": "",
    "authors": [
      "Fachrina Dewi Puspitasari",
      "Lik-Hang Lee"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.09628"
  },
  {
    "id": "arXiv:2210.09629",
    "title": "1st Place Solutions for the UVO Challenge 2022",
    "abstract": "This paper describes the approach we have taken in the challenge. We still\nadopted the two-stage scheme same as the last champion, that is, detection\nfirst and segmentation followed. We trained more powerful detector and\nsegmentor separately. Besides, we also perform pseudo-label training on the\ntest set, based on student-teacher framework and end-to-end transformer based\nobject detection. The method ranks first on the 2nd Unidentified Video Objects\n(UVO) challenge, achieving AR@100 of 46.8, 64.7 and 32.2 in the limited data\nframe track, unlimited data frame track and video track respectively.",
    "descriptor": "",
    "authors": [
      "Jiajun Zhang",
      "Boyu Chen",
      "Zhilong Ji",
      "Jinfeng Bai",
      "Zonghai Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09629"
  },
  {
    "id": "arXiv:2210.09634",
    "title": "DPIS: An Enhanced Mechanism for Differentially Private SGD with  Importance Sampling",
    "abstract": "Nowadays, differential privacy (DP) has become a well-accepted standard for\nprivacy protection, and deep neural networks (DNN) have been immensely\nsuccessful in machine learning. The combination of these two techniques, i.e.,\ndeep learning with differential privacy, promises the privacy-preserving\nrelease of high-utility models trained with sensitive data such as medical\nrecords. A classic mechanism for this purpose is DP-SGD, which is a\ndifferentially private version of the stochastic gradient descent (SGD)\noptimizer commonly used for DNN training. Subsequent approaches have improved\nvarious aspects of the model training process, including noise decay schedule,\nmodel architecture, feature engineering, and hyperparameter tuning. However,\nthe core mechanism for enforcing DP in the SGD optimizer remains unchanged ever\nsince the original DP-SGD algorithm, which has increasingly become a\nfundamental barrier limiting the performance of DP-compliant machine learning\nsolutions.\nMotivated by this, we propose DPIS, a novel mechanism for differentially\nprivate SGD training that can be used as a drop-in replacement of the core\noptimizer of DP-SGD, with consistent and significant accuracy gains over the\nlatter. The main idea is to employ importance sampling (IS) in each SGD\niteration for mini-batch selection, which reduces both sampling variance and\nthe amount of random noise injected to the gradients that is required to\nsatisfy DP. Integrating IS into the complex mathematical machinery of DP-SGD is\nhighly non-trivial. DPIS addresses the challenge through novel mechanism\ndesigns, fine-grained privacy analysis, efficiency enhancements, and an\nadaptive gradient clipping optimization. Extensive experiments on four\nbenchmark datasets, namely MNIST, FMNIST, CIFAR-10 and IMDb, demonstrate the\nsuperior effectiveness of DPIS over existing solutions for deep learning with\ndifferential privacy.",
    "descriptor": "",
    "authors": [
      "Jianxin Wei",
      "Ergute Bao",
      "Xiaokui Xiao",
      "Yin Yang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09634"
  },
  {
    "id": "arXiv:2210.09638",
    "title": "IF-GAN: A Novel Generator Architecture with Information Feedback",
    "abstract": "This paper presents an alternative generator architecture for image\ngeneration, having a novel information feedback system. Contrary to\nconventional methods in which the latent space unilaterally affects the feature\nspace in the generator, the proposed method trains not only the feature space\nbut also the latent one by interchanging their information. To this end, we\nintroduce a novel module, called information feedback (IF) block, which jointly\nupdates the latent and feature spaces. To show the superiority of the proposed\nmethod, we present extensive experiments on various datasets including subsets\nof LSUN and FFHQ. Experimental results reveal that the proposed method can\ndramatically improve the image generation performance, in terms of Frechet\ninception distance (FID), kernel inception distance (KID), and Precision and\nRecall (P & R).",
    "descriptor": "",
    "authors": [
      "Seung Park",
      "Yong-Goo Shin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.09638"
  },
  {
    "id": "arXiv:2210.09640",
    "title": "Clustering Categorical Data: Soft Rounding k-modes",
    "abstract": "Over the last three decades, researchers have intensively explored various\nclustering tools for categorical data analysis. Despite the proposal of various\nclustering algorithms, the classical k-modes algorithm remains a popular choice\nfor unsupervised learning of categorical data. Surprisingly, our first insight\nis that in a natural generative block model, the k-modes algorithm performs\npoorly for a large range of parameters. We remedy this issue by proposing a\nsoft rounding variant of the k-modes algorithm (SoftModes) and theoretically\nprove that our variant addresses the drawbacks of the k-modes algorithm in the\ngenerative model. Finally, we empirically verify that SoftModes performs well\non both synthetic and real-world datasets.",
    "descriptor": "",
    "authors": [
      "Surya Teja Gavva",
      "Karthik C. S.",
      "Sharath Punna"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.09640"
  },
  {
    "id": "arXiv:2210.09643",
    "title": "Improving Adversarial Robustness by Contrastive Guided Diffusion Process",
    "abstract": "Synthetic data generation has become an emerging tool to help improve the\nadversarial robustness in classification tasks since robust learning requires a\nsignificantly larger amount of training samples compared with standard\nclassification tasks. Among various deep generative models, the diffusion model\nhas been shown to produce high-quality synthetic images and has achieved good\nperformance in improving the adversarial robustness. However, diffusion-type\nmethods are typically slow in data generation as compared with other generative\nmodels. Although different acceleration techniques have been proposed recently,\nit is also of great importance to study how to improve the sample efficiency of\ngenerated data for the downstream task. In this paper, we first analyze the\noptimality condition of synthetic distribution for achieving non-trivial robust\naccuracy. We show that enhancing the distinguishability among the generated\ndata is critical for improving adversarial robustness. Thus, we propose the\nContrastive-Guided Diffusion Process (Contrastive-DP), which adopts the\ncontrastive loss to guide the diffusion model in data generation. We verify our\ntheoretical results using simulations and demonstrate the good performance of\nContrastive-DP on image datasets.",
    "descriptor": "",
    "authors": [
      "Yidong Ouyang",
      "Liyan Xie",
      "Guang Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09643"
  },
  {
    "id": "arXiv:2210.09644",
    "title": "Tencent's Multilingual Machine Translation System for WMT22 Large-Scale  African Languages",
    "abstract": "This paper describes Tencent's multilingual machine translation systems for\nthe WMT22 shared task on Large-Scale Machine Translation Evaluation for African\nLanguages. We participated in the $\\mathbf{constrained}$ translation track in\nwhich only the data and pretrained models provided by the organizer are\nallowed. The task is challenging due to three problems, including the absence\nof training data for some to-be-evaluated language pairs, the uneven\noptimization of language pairs caused by data imbalance, and the curse of\nmultilinguality. To address these problems, we adopt data augmentation,\ndistributionally robust optimization, and language family grouping,\nrespectively, to develop our multilingual neural machine translation (MNMT)\nmodels. Our submissions won the $\\mathbf{1st\\ place}$ on the blind test sets in\nterms of the automatic evaluation metrics. Codes, models, and detailed\ncompetition results are available at\nhttps://github.com/wxjiao/WMT2022-Large-Scale-African.",
    "descriptor": "\nComments: WMT 2022, 8 pages\n",
    "authors": [
      "Wenxiang Jiao",
      "Zhaopeng Tu",
      "Jiarui Li",
      "Wenxuan Wang",
      "Jen-tse Huang",
      "Shuming Shi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.09644"
  },
  {
    "id": "arXiv:2210.09646",
    "title": "RPM: Generalizable Behaviors for Multi-Agent Reinforcement Learning",
    "abstract": "Despite the recent advancement in multi-agent reinforcement learning (MARL),\nthe MARL agents easily overfit the training environment and perform poorly in\nthe evaluation scenarios where other agents behave differently. Obtaining\ngeneralizable policies for MARL agents is thus necessary but challenging mainly\ndue to complex multi-agent interactions. In this work, we model the problem\nwith Markov Games and propose a simple yet effective method, ranked policy\nmemory (RPM), to collect diverse multi-agent trajectories for training MARL\npolicies with good generalizability. The main idea of RPM is to maintain a\nlook-up memory of policies. In particular, we try to acquire various levels of\nbehaviors by saving policies via ranking the training episode return, i.e., the\nepisode return of agents in the training environment; when an episode starts,\nthe learning agent can then choose a policy from the RPM as the behavior\npolicy. This innovative self-play training framework leverages agents' past\npolicies and guarantees the diversity of multi-agent interaction in the\ntraining data. We implement RPM on top of MARL algorithms and conduct extensive\nexperiments on Melting Pot. It has been demonstrated that RPM enables MARL\nagents to interact with unseen agents in multi-agent generalization evaluation\nscenarios and complete given tasks, and it significantly boosts the performance\nup to 402% on average.",
    "descriptor": "",
    "authors": [
      "Wei Qiu",
      "Xiao Ma",
      "Bo An",
      "Svetlana Obraztsova",
      "Shuicheng Yan",
      "Zhongwen Xu"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09646"
  },
  {
    "id": "arXiv:2210.09651",
    "title": "Comparison of Popular Video Conferencing Apps Using Client-side  Measurements on Different Backhaul Networks",
    "abstract": "Video conferencing platforms have been appropriated during the COVID-19\npandemic for different purposes, including classroom teaching. However, the\nplatforms are not designed for many of these objectives. When users, like\neducationists, select a platform, it is unclear which platform will perform\nbetter given the same network and hardware resources to meet the required\nQuality of Experience (QoE). Similarly, when developers design a new video\nconferencing platform, they do not have clear guidelines for making design\nchoices given the QoE requirements.\nIn this paper, we provide a set of networks and systems measurements, and\nquantitative user studies to measure the performance of video conferencing apps\nin terms of both, Quality of Service (QoS) and QoE. Using those metrics, we\nmeasure the performance of Google Meet, Microsoft Teams, and Zoom, which are\nthree popular platforms in education and business. We find a substantial\ndifference in how the three apps treat video and audio streams. We see that\ntheir choice of treatment affects their consumption of hardware resources. Our\nquantitative user studies confirm the findings of our quantitative\nmeasurements. While each platform has its benefits, we find that no app is\nideal. A user can choose a suitable platform depending on which of the\nfollowing, audio, video, or network bandwidth, CPU, or memory are more\nimportant.",
    "descriptor": "",
    "authors": [
      "Rohan Kumar",
      "Dhruv Nagpal",
      "Vinayak Naik",
      "Dipanjan Chakraborty"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.09651"
  },
  {
    "id": "arXiv:2210.09654",
    "title": "Convergence Analysis of Volumetric Stretch Energy Minimization and its  Associated Optimal Mass Transport",
    "abstract": "The volumetric stretch energy has been widely applied to the computation of\nvolume-/mass-preserving parameterizations of simply connected tetrahedral mesh\nmodels. However, this approach still lacks theoretical support. In this paper,\nwe provide the theoretical foundation for volumetric stretch energy\nminimization (VSEM) to compute volume-/mass-preserving parameterizations. In\naddition, we develop an associated efficient VSEM algorithm with guaranteed\nasymptotic R-linear convergence. Furthermore, based on the VSEM algorithm, we\npropose a projected gradient method for the computation of the\nvolume/mass-preserving optimal mass transport map with a guaranteed convergence\nrate of $\\mathcal{O}(1/m)$, and combined with Nesterov-based acceleration, the\nguaranteed convergence rate becomes $\\mathcal{O}(1/m^2)$. Numerical experiments\nare presented to justify the theoretical convergence behavior for various\nexamples drawn from known benchmark models. Moreover, these numerical\nexperiments show the effectiveness and accuracy of the proposed algorithm,\nparticularly in the processing of 3D medical MRI brain images.",
    "descriptor": "\nComments: 26 pages\n",
    "authors": [
      "Tsung-Ming Huang",
      "Wei-Hung Liao",
      "Wen-Wei Lin",
      "Mei-Heng Yueh",
      "Shing-Tung Yau"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.09654"
  },
  {
    "id": "arXiv:2210.09655",
    "title": "WaGI : Wavelet-based GAN Inversion for Preserving High-frequency Image  Details",
    "abstract": "Recent GAN inversion models focus on preserving image-specific details\nthrough various methods, e.g., generator tuning or feature mixing. While those\nare helpful for preserving details compared to a naiive low-rate latent\ninversion, they still fail to maintain high-frequency features precisely. In\nthis paper, we point out that the existing GAN inversion models have inherent\nlimitations in both structural and training aspects, which preclude the\ndelicate reconstruction of high-frequency features. Especially, we prove that\nthe widely-used loss term in GAN inversion, i.e., L2, is biased to reconstruct\nlow-frequency features mainly. To overcome this problem, we propose a novel GAN\ninversion model, coined WaGI, which enables to handle high-frequency features\nexplicitly, by using a novel wavelet-based loss term and a newly proposed\nwavelet fusion scheme. To the best of our knowledge, WaGI is the first attempt\nto interpret GAN inversion in the frequency domain. We demonstrate that WaGI\nshows outstanding results on both inversion and editing, compared to the\nexisting state-of-the-art GAN inversion models. Especially, WaGI robustly\npreserves high-frequency features of images even in the editing scenario. We\nwill release our code with the pre-trained model after the review.",
    "descriptor": "",
    "authors": [
      "Seung-Jun Moon",
      "Chaewon Kim",
      "Gyeong-Moon Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.09655"
  },
  {
    "id": "arXiv:2210.09658",
    "title": "ROSE: Robust Selective Fine-tuning for Pre-trained Language Models",
    "abstract": "Even though the large-scale language models have achieved excellent\nperformances, they suffer from various adversarial attacks. A large body of\ndefense methods has been proposed. However, they are still limited due to\nredundant attack search spaces and the inability to defend against various\ntypes of attacks. In this work, we present a novel fine-tuning approach called\n\\textbf{RO}bust \\textbf{SE}letive fine-tuning (\\textbf{ROSE}) to address this\nissue. ROSE conducts selective updates when adapting pre-trained models to\ndownstream tasks, filtering out invaluable and unrobust updates of parameters.\nSpecifically, we propose two strategies: the first-order and second-order ROSE\nfor selecting target robust parameters. The experimental results show that ROSE\nachieves significant improvements in adversarial robustness on various\ndownstream NLP tasks, and the ensemble method even surpasses both variants\nabove. Furthermore, ROSE can be easily incorporated into existing fine-tuning\nmethods to improve their adversarial robustness further. The empirical analysis\nconfirms that ROSE eliminates unrobust spurious updates during fine-tuning,\nleading to solutions corresponding to flatter and wider optima than the\nconventional method. Code is available at\n\\url{https://github.com/jiangllan/ROSE}.",
    "descriptor": "\nComments: Accepted to EMNLP 2022. Code is available at this https URL\n",
    "authors": [
      "Lan Jiang",
      "Hao Zhou",
      "Yankai Lin",
      "Peng Li",
      "Jie Zhou",
      "Rui Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.09658"
  },
  {
    "id": "arXiv:2210.09668",
    "title": "On effects of Knowledge Distillation on Transfer Learning",
    "abstract": "Knowledge distillation is a popular machine learning technique that aims to\ntransfer knowledge from a large 'teacher' network to a smaller 'student'\nnetwork and improve the student's performance by training it to emulate the\nteacher. In recent years, there has been significant progress in novel\ndistillation techniques that push performance frontiers across multiple\nproblems and benchmarks. Most of the reported work focuses on achieving\nstate-of-the-art results on the specific problem. However, there has been a\nsignificant gap in understanding the process and how it behaves under certain\ntraining scenarios. Similarly, transfer learning (TL) is an effective technique\nin training neural networks on a limited dataset faster by reusing\nrepresentations learned from a different but related problem. Despite its\neffectiveness and popularity, there has not been much exploration of knowledge\ndistillation on transfer learning. In this thesis, we propose a machine\nlearning architecture we call TL+KD that combines knowledge distillation with\ntransfer learning; we then present a quantitative and qualitative comparison of\nTL+KD with TL in the domain of image classification. Through this work, we show\nthat using guidance and knowledge from a larger teacher network during\nfine-tuning, we can improve the student network to achieve better validation\nperformances like accuracy. We characterize the improvement in the validation\nperformance of the model using a variety of metrics beyond just accuracy\nscores, and study its performance in scenarios such as input degradation.",
    "descriptor": "",
    "authors": [
      "Sushil Thapa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.09668"
  },
  {
    "id": "arXiv:2210.09670",
    "title": "Hierarchical Normalization for Robust Monocular Depth Estimation",
    "abstract": "In this paper, we address monocular depth estimation with deep neural\nnetworks. To enable training of deep monocular estimation models with various\nsources of datasets, state-of-the-art methods adopt image-level normalization\nstrategies to generate affine-invariant depth representations. However,\nlearning with image-level normalization mainly emphasizes the relations of\npixel representations with the global statistic in the images, such as the\nstructure of the scene, while the fine-grained depth difference may be\noverlooked. In this paper, we propose a novel multi-scale depth normalization\nmethod that hierarchically normalizes the depth representations based on\nspatial information and depth distributions. Compared with previous\nnormalization strategies applied only at the holistic image level, the proposed\nhierarchical normalization can effectively preserve the fine-grained details\nand improve accuracy. We present two strategies that define the hierarchical\nnormalization contexts in the depth domain and the spatial domain,\nrespectively. Our extensive experiments show that the proposed normalization\nstrategy remarkably outperforms previous normalization methods, and we set new\nstate-of-the-art on five zero-shot transfer benchmark datasets.",
    "descriptor": "\nComments: Accepted to NeurIPS 2022\n",
    "authors": [
      "Chi Zhang",
      "Wei Yin",
      "Zhibin Wang",
      "Gang Yu",
      "Bin Fu",
      "Chunhua Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09670"
  },
  {
    "id": "arXiv:2210.09671",
    "title": "Not All Poisons are Created Equal: Robust Training against Data  Poisoning",
    "abstract": "Data poisoning causes misclassification of test time target examples by\ninjecting maliciously crafted samples in the training data. Existing defenses\nare often effective only against a specific type of targeted attack,\nsignificantly degrade the generalization performance, or are prohibitive for\nstandard deep learning pipelines.\nIn this work, we propose an efficient defense mechanism that significantly\nreduces the success rate of various data poisoning attacks, and provides\ntheoretical guarantees for the performance of the model. Targeted attacks work\nby adding bounded perturbations to a randomly selected subset of training data\nto match the targets' gradient or representation. We show that: (i) under\nbounded perturbations, only a number of poisons can be optimized to have a\ngradient that is close enough to that of the target and make the attack\nsuccessful; (ii) such effective poisons move away from their original class and\nget isolated in the gradient space; (iii) dropping examples in low-density\ngradient regions during training can successfully eliminate the effective\npoisons, and guarantees similar training dynamics to that of training on full\ndata. Our extensive experiments show that our method significantly decreases\nthe success rate of state-of-the-art targeted attacks, including Gradient\nMatching and Bullseye Polytope, and easily scales to large datasets.",
    "descriptor": "",
    "authors": [
      "Yu Yang",
      "Tian Yu Liu",
      "Baharan Mirzasoleiman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.09671"
  },
  {
    "id": "arXiv:2210.09672",
    "title": "Addressing the Extreme Cold-Start Problem in Group Recommendation",
    "abstract": "The task of recommending items to a group of users, a.k.a. group\nrecommendation, is receiving increasing attention. However, the cold-start\nproblem inherent in recommender systems is amplified in group recommendation\nbecause interaction data between groups and items are extremely scarce in\npractice. Most existing work exploits associations between groups and items to\nmitigate the data scarcity problem. However, existing approaches inevitably\nfail in extreme cold-start scenarios where associations between groups and\nitems are lacking. For this reason, we design a group recommendation model for\nEXreme cold-star} in group REcommendation (EXTRE) suitable for the extreme cold\nstart scenario. The basic idea behind EXTRE is to use the limit theory of graph\nconvolutional neural networks to establish implicit associations between groups\nand items, and the derivation of these associations does not require explicit\ninteraction data, making it suitable for cold start scenarios. The training\nprocess of EXTRE depends on the newly defined and interpretable concepts of\nconsistency and discrepancy, other than commonly used negative sampling with\npairwise ranking, which can improve the performance of the group\nrecommendation. Extensive experiments validate the efficacy of the proposed\nmodel EXTRE.",
    "descriptor": "",
    "authors": [
      "Guo linxin",
      "Tao yinghui",
      "Gao Min",
      "Yu Junliang",
      "Zhao liang",
      "Li Wentao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.09672"
  },
  {
    "id": "arXiv:2210.09678",
    "title": "Virtual Reality via Object Poses and Active Learning: Realizing  Telepresence Robots with Aerial Manipulation Capabilities",
    "abstract": "This article presents a novel telepresence system for advancing aerial\nmanipulation in dynamic and unstructured environments. The proposed system not\nonly features a haptic device, but also a virtual reality (VR) interface that\nprovides real-time 3D displays of the robot's workspace as well as a haptic\nguidance to its remotely located operator. To realize this, multiple sensors\nnamely a LiDAR, cameras and IMUs are utilized. For processing of the acquired\nsensory data, pose estimation pipelines are devised for industrial objects of\nboth known and unknown geometries. We further propose an active learning\npipeline in order to increase the sample efficiency of a pipeline component\nthat relies on Deep Neural Networks (DNNs) based object detection. All these\nalgorithms jointly address various challenges encountered during the execution\nof perception tasks in industrial scenarios. In the experiments, exhaustive\nablation studies are provided to validate the proposed pipelines.\nMethodologically, these results commonly suggest how an awareness of the\nalgorithms' own failures and uncertainty (\"introspection\") can be used tackle\nthe encountered problems. Moreover, outdoor experiments are conducted to\nevaluate the effectiveness of the overall system in enhancing aerial\nmanipulation capabilities. In particular, with flight campaigns over days and\nnights, from spring to winter, and with different users and locations, we\ndemonstrate over 70 robust executions of pick-and-place, force application and\npeg-in-hole tasks with the DLR cable-Suspended Aerial Manipulator (SAM). As a\nresult, we show the viability of the proposed system in future industrial\napplications.",
    "descriptor": "\nComments: Released as part of IROS 2022 late breaking results; the paper is under review at a journal\n",
    "authors": [
      "Jongseok Lee",
      "Ribin Balachandran",
      "Konstantin Kondak",
      "Andre Coelho",
      "Marco De Stefano",
      "Matthias Humt",
      "Jianxiang Feng",
      "Tamim Asfour",
      "Rudolph Triebel"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09678"
  },
  {
    "id": "arXiv:2210.09681",
    "title": "Minimizing the Age of Incorrect Information for Unknown Markovian Source",
    "abstract": "The age of information minimization problems has been extensively studied in\nReal-time monitoring applications frameworks. In this paper, we consider the\nproblem of monitoring the states of unknown remote source that evolves\naccording to a Markovian Process. A central scheduler decides at each time slot\nwhether to schedule the source or not in order to receive the new status\nupdates in such a way as to minimize the Mean Age of Incorrect Information\n(MAoII). When the scheduler knows the source parameters, we formulate the\nminimization problem as an MDP problem. Then, we prove that the optimal\nsolution is a threshold-based policy. When the source's parameters are unknown,\nthe problem's difficulty lies in finding a strategy with a good trade-off\nbetween exploitation and exploration. Indeed, we need to provide an algorithm\nimplemented by the scheduler that jointly estimates the unknown parameters\n(exploration) and minimizes the MAoII (exploitation). However, considering our\nsystem model, we can only explore the source if the monitor decides to schedule\nit. Then, applying the greedy approach, we risk definitively stopping the\nexploration process in the case where at a specific time, we end up with an\nestimation of the Markovian source's parameters to which the corresponding\noptimal solution is never to transmit. In this case, we can no longer improve\nthe estimation of our unknown parameters, which may significantly detract from\nthe performance of the algorithm. For that, we develop a new learning algorithm\nthat gives a good balance between exploration and exploitation to avoid this\nmain problem. Then, we theoretically analyze the performance of our algorithm\ncompared to a genie solution by proving that the regret bound at time T is\nlog(T). Finally, we provide some numerical results to highlight the performance\nof our derived policy compared to the greedy approach.",
    "descriptor": "",
    "authors": [
      "Saad Kriouile",
      "Mohamad Assaad"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.09681"
  },
  {
    "id": "arXiv:2210.09683",
    "title": "Alibaba-Translate China's Submission for WMT 2022 Metrics Shared Task",
    "abstract": "In this report, we present our submission to the WMT 2022 Metrics Shared\nTask. We build our system based on the core idea of UNITE (Unified Translation\nEvaluation), which unifies source-only, reference-only, and\nsource-reference-combined evaluation scenarios into one single model.\nSpecifically, during the model pre-training phase, we first apply the\npseudo-labeled data examples to continuously pre-train UNITE. Notably, to\nreduce the gap between pre-training and fine-tuning, we use data cropping and a\nranking-based score normalization strategy. During the fine-tuning phase, we\nuse both Direct Assessment (DA) and Multidimensional Quality Metrics (MQM) data\nfrom past years' WMT competitions. Specially, we collect the results from\nmodels with different pre-trained language model backbones, and use different\nensembling strategies for involved translation directions.",
    "descriptor": "\nComments: WMT 2022 Metrics Shared Task\n",
    "authors": [
      "Yu Wan",
      "Keqin Bao",
      "Dayiheng Liu",
      "Baosong Yang",
      "Derek F. Wong",
      "Lidia S. Chao",
      "Wenqiang Lei",
      "Jun Xie"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.09683"
  },
  {
    "id": "arXiv:2210.09688",
    "title": "Nirdizati: an Advanced Predictive Process Monitoring Toolkit",
    "abstract": "Predictive Process Monitoring is a field of Process Mining that aims at\npredicting how an ongoing execution of a business process will develop in the\nfuture using past process executions recorded in event logs. The recent stream\nof publications in this field shows the need for tools able to support\nresearchers and users in analyzing, comparing and selecting the techniques that\nare the most suitable for them. Nirdizati is a dedicated tool for supporting\nusers in building, comparing, analyzing, and explaining predictive models that\ncan then be used to perform predictions on the future of an ongoing case. By\nproviding a rich set of different state-of-the-art approaches, Nirdizati offers\nBPM researchers and practitioners a useful and flexible instrument for\ninvestigating and comparing Predictive Process Monitoring techniques. In this\npaper, we present the current version of Nirdizati, together with its\narchitecture which has been developed to improve its modularity and\nscalability. The features of Nirdizati enrich its capability to support\nresearchers and practitioners within the entire pipeline for constructing\nreliable Predictive Process Monitoring models.",
    "descriptor": "",
    "authors": [
      "Williams Rizzi",
      "Chiara Di Francescomarino",
      "Chiara Ghidini",
      "Fabrizio Maria Maggi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.09688"
  },
  {
    "id": "arXiv:2210.09691",
    "title": "OpenStack and Google Cloud performance comparison in Infrastructure as a  Service model",
    "abstract": "Cloud computing is becoming common, and the choice of proper infrastructure\nis essential. One of main issues is choosing between private and public clound,\nbetween commercial and non-commercial solutions. This paper aims to compare the\nparameters of OpenStack and Google Cloud systems. Both systems deliver a\ncomputing cloud service, enabling the user to use the infrastructure as a\nservice (IaaS) model. We developed the pipeline using the Python programming\nlanguage and its libraries, which enable communication with the aforementioned\nclouds. We measured various parameters of instances and task execution:\ninstance launch and deletion times, and their dependence on the number of\nlaunched instances. Moreover, we used benchmark algorithms to check the\ninstance performance. We analysed the results and the factors that contributed\nto them and provided conclusions, recommendations, and suggestions for further\nresearch based on the gathered data.",
    "descriptor": "\nComments: 22 pages, 10 figures\n",
    "authors": [
      "Micha\u0142 \u0141\u0105tkowski",
      "Robert Nowak"
    ],
    "subjectives": [
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2210.09691"
  },
  {
    "id": "arXiv:2210.09693",
    "title": "TFAD: A Decomposition Time Series Anomaly Detection Architecture with  Time-Frequency Analysis",
    "abstract": "Time series anomaly detection is a challenging problem due to the complex\ntemporal dependencies and the limited label data. Although some algorithms\nincluding both traditional and deep models have been proposed, most of them\nmainly focus on time-domain modeling, and do not fully utilize the information\nin the frequency domain of the time series data. In this paper, we propose a\nTime-Frequency analysis based time series Anomaly Detection model, or TFAD for\nshort, to exploit both time and frequency domains for performance improvement.\nBesides, we incorporate time series decomposition and data augmentation\nmechanisms in the designed time-frequency architecture to further boost the\nabilities of performance and interpretability. Empirical studies on widely used\nbenchmark datasets show that our approach obtains state-of-the-art performance\nin univariate and multivariate time series anomaly detection tasks. Code is\nprovided at https://github.com/DAMO-DI-ML/CIKM22-TFAD.",
    "descriptor": "",
    "authors": [
      "Chaoli Zhang",
      "Tian Zhou",
      "Qingsong Wen",
      "Liang Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.09693"
  },
  {
    "id": "arXiv:2210.09698",
    "title": "Transfer learning with weak labels from radiology reports: application  to glioma change detection",
    "abstract": "Creating large annotated datasets represents a major bottleneck for the\ndevelopment of deep learning models in radiology. To overcome this, we propose\na combined use of weak labels (imprecise, but fast-to-create annotations) and\nTransfer Learning (TL). Specifically, we explore inductive TL, where source and\ntarget domains are identical, but tasks are different due to a label shift: our\ntarget labels are created manually by three radiologists, whereas the source\nweak labels are generated automatically from textual radiology reports. We\nframe knowledge transfer as hyperparameter optimization, thus avoiding\nheuristic choices that are frequent in related works. We investigate the\nrelationship between model size and TL, comparing a low-capacity VGG with a\nhigher-capacity SEResNeXt. The task that we address is change detection in\nfollow-up glioma imaging: we extracted 1693 T2-weighted magnetic resonance\nimaging difference maps from 183 patients, and classified them into stable or\nunstable according to tumor evolution. Weak labeling allowed us to increase\ndataset size more than 3-fold, and improve VGG classification results from 75%\nto 82% Area Under the ROC Curve (AUC) (p=0.04). Mixed training from scratch led\nto higher performance than fine-tuning or feature extraction. To assess\ngeneralizability, we also ran inference on an open dataset (BraTS-2015: 15\npatients, 51 difference maps), reaching up to 76% AUC. Overall, results suggest\nthat medical imaging problems may benefit from smaller models and different TL\nstrategies with respect to computer vision problems, and that report-generated\nweak labels are effective in improving model performances. Code, in-house\ndataset and BraTS labels are released.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Tommaso Di Noto",
      "Meritxell Bach Cuadra",
      "Chirine Atat",
      "Eduardo Gamito Teiga",
      "Monika Hegi",
      "Andreas Hottinger",
      "Patric Hagmann",
      "Jonas Richiardi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09698"
  },
  {
    "id": "arXiv:2210.09701",
    "title": "A stable local commuting projector and optimal $hp$ approximation  estimates in ${\\boldsymbol H}(\\mathrm{curl})$",
    "abstract": "We design an operator from the infinite-dimensional Sobolev space\n${\\boldsymbol H}(\\mathrm{curl})$ to its finite-dimensional subspace formed by\nthe N\\'ed\\'elec piecewise polynomials on a tetrahedral mesh that has the\nfollowing properties: 1) it is defined over the entire ${\\boldsymbol\nH}(\\mathrm{curl})$, including boundary conditions imposed on a part of the\nboundary; 2) it is defined locally in a neighborhood of each mesh element; 3)\nit is based on simple piecewise polynomial projections; 4) it is stable in the\n${\\boldsymbol L}^2$-norm, up to data oscillation; 5) it has optimal\n(local-best) approximation properties; 6) it satisfies the commuting property\nwith its sibling operator on ${\\boldsymbol H}(\\mathrm{div})$; 7) it is a\nprojector, i.e., it leaves intact objects that are already in the N\\'ed\\'elec\npiecewise polynomial space. This operator can be used in various parts of\nnumerical analysis related to the ${\\boldsymbol H}(\\mathrm{curl})$ space. We in\nparticular employ it here to establish the two following results: i)\nequivalence of global-best, tangential-trace-and curl-constrained, and\nlocal-best, unconstrained approximations in ${\\boldsymbol H}(\\mathrm{curl})$\nincluding data oscillation terms; and ii) fully $h$- and $p$- (mesh-size- and\npolynomial-degree-) optimal approximation bounds valid under the minimal\nSobolev regularity only requested elementwise. As a result of independent\ninterest, we also prove a $p$-robust equivalence of curl-constrained and\nunconstrained best-approximations on a single tetrahedron in the ${\\boldsymbol\nH}(\\mathrm{curl})$-setting, including $hp$ data oscillation terms.",
    "descriptor": "",
    "authors": [
      "Th\u00e9ophile Chaumont-Frelet",
      "Martin Vohral\u00edk"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.09701"
  },
  {
    "id": "arXiv:2210.09703",
    "title": "How to Play Optimally for Regular Objectives?",
    "abstract": "This paper studies two-player zero-sum games played on graphs and makes\ncontributions toward the following question: given an objective, how much\nmemory is required to play optimally for that objective? We study regular\nobjectives, where the goal of the first player is that eventually the sequence\nof colors along the play belongs to some regular language over finite words. We\nobtain different characterizations of the chromatic memory requirements for\nsuch objectives for both players, from which we derive complexity-theoretic\nstatements: deciding whether there exist small memory structures sufficient to\nplay optimally is NP-complete for both players. Some of our characterization\nresults apply to a more general class of objectives: topologically closed and\ntopologically open sets.",
    "descriptor": "\nComments: 26 pages, 8 figures\n",
    "authors": [
      "Patricia Bouyer",
      "Nathana\u00ebl Fijalkow",
      "Mickael Randour",
      "Pierre Vandenhove"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.09703"
  },
  {
    "id": "arXiv:2210.09704",
    "title": "Electromagnetic Effective-Degree-of-Freedom Limit of a MIMO System in  2-D Inhomogeneous Environment",
    "abstract": "Compared with a single-input-single-output (SISO) wireless communication\nsystem, the benefit of multiple-input-multiple-output (MIMO) technology\noriginates from its extra degree of freedom (DOF), also referred as scattering\nchannels or spatial electromagnetic (EM) modes, brought by spatial\nmultiplexing. When the physical sizes of transmitting and receiving arrays are\nfixed, and there are sufficient antennas (typically with half-wavelength\nspacings), the DOF limit is only dependent on the propagating environment.\nAnalytical methods can be used to estimate this limit in free space, and some\napproximate models are adopted in stochastic environments, such as Clarke's\nmodel and Ray-tracing methods. However, this DOF limit in an certain\ninhomogeneous environment has not been well discussed with rigorous full-wave\nnumerical methods. In this work, volume integral equation (VIE) is implemented\nfor investigating the limit of MIMO effective degree of freedom (EDOF) in three\nrepresentative two-dimensional (2-D) inhomogeneous environments. Moreover, we\nclarify the relation between the performance of a MIMO system and the\nscattering characteristics of its propagating environment.",
    "descriptor": "",
    "authors": [
      "Shuai S. A. Yuan",
      "Zi He",
      "Sheng Sun",
      "Xiaoming Chen",
      "Chongwen Huang",
      "Wei E. I. Sha"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.09704"
  },
  {
    "id": "arXiv:2210.09705",
    "title": "ATCON: Attention Consistency for Vision Models",
    "abstract": "Attention--or attribution--maps methods are methods designed to highlight\nregions of the model's input that were discriminative for its predictions.\nHowever, different attention maps methods can highlight different regions of\nthe input, with sometimes contradictory explanations for a prediction. This\neffect is exacerbated when the training set is small. This indicates that\neither the model learned incorrect representations or that the attention maps\nmethods did not accurately estimate the model's representations. We propose an\nunsupervised fine-tuning method that optimizes the consistency of attention\nmaps and show that it improves both classification performance and the quality\nof attention maps. We propose an implementation for two state-of-the-art\nattention computation methods, Grad-CAM and Guided Backpropagation, which\nrelies on an input masking technique. We also show results on Grad-CAM and\nIntegrated Gradients in an ablation study. We evaluate this method on our own\ndataset of event detection in continuous video recordings of hospital patients\naggregated and curated for this work. As a sanity check, we also evaluate the\nproposed method on PASCAL VOC and SVHN. With the proposed method, with small\ntraining sets, we achieve a 6.6 points lift of F1 score over the baselines on\nour video dataset, a 2.9 point lift of F1 score on PASCAL, and a 1.8 points\nlift of mean Intersection over Union over Grad-CAM for weakly supervised\ndetection on PASCAL. Those improved attention maps may help clinicians better\nunderstand vision model predictions and ease the deployment of machine learning\nsystems into clinical care. We share part of the code for this article at the\nfollowing repository: https://github.com/alimirzazadeh/SemisupervisedAttention.",
    "descriptor": "\nComments: WACV 2023\n",
    "authors": [
      "Ali Mirzazadeh",
      "Florian Dubost",
      "Maxwell Pike",
      "Krish Maniar",
      "Max Zuo",
      "Christopher Lee-Messer",
      "Daniel Rubin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09705"
  },
  {
    "id": "arXiv:2210.09706",
    "title": "Privacy Explanations -- A Means to End-User Trust",
    "abstract": "Software systems are ubiquitous, and their use is ingrained in our everyday\nlives. They enable us to get in touch with people quickly and easily, support\nus in gathering information, and help us perform our daily tasks. In return, we\nprovide these systems with a large amount of personal information, often\nunaware that this is jeopardizing our privacy. End users are typically unaware\nof what data is collected, for what purpose, who has access to it, and where\nand how it is stored. To address this issue, we looked into how explainability\nmight help to tackle this problem. We created privacy explanations that aim to\nhelp to clarify to end users why and for what purposes specific data is\nrequired. We asked end users about privacy explanations in a survey and found\nthat the majority of respondents (91.6 \\%) are generally interested in\nreceiving privacy explanations. Our findings reveal that privacy explanations\ncan be an important step towards increasing trust in software systems and can\nincrease the privacy awareness of end users. These findings are a significant\nstep in developing privacy-aware systems and incorporating usable privacy\nfeatures into them, assisting users in protecting their privacy.",
    "descriptor": "",
    "authors": [
      "Wasja Brunottea",
      "Alexander Specht",
      "Larissa Chazette",
      "Kurt Schneider"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.09706"
  },
  {
    "id": "arXiv:2210.09708",
    "title": "HiSMatch: Historical Structure Matching based Temporal Knowledge Graph  Reasoning",
    "abstract": "A Temporal Knowledge Graph (TKG) is a sequence of KGs with respective\ntimestamps, which adopts quadruples in the form of (\\emph{subject},\n\\emph{relation}, \\emph{object}, \\emph{timestamp}) to describe dynamic facts.\nTKG reasoning has facilitated many real-world applications via answering such\nqueries as (\\emph{query entity}, \\emph{query relation}, \\emph{?}, \\emph{future\ntimestamp}) about future. This is actually a matching task between a query and\ncandidate entities based on their historical structures, which reflect\nbehavioral trends of the entities at different timestamps. In addition, recent\nKGs provide background knowledge of all the entities, which is also helpful for\nthe matching. Thus, in this paper, we propose the \\textbf{Hi}storical\n\\textbf{S}tructure \\textbf{Match}ing (\\textbf{HiSMatch}) model. It applies two\nstructure encoders to capture the semantic information contained in the\nhistorical structures of the query and candidate entities. Besides, it adopts\nanother encoder to integrate the background knowledge into the model. TKG\nreasoning experiments on six benchmark datasets demonstrate the significant\nimprovement of the proposed HiSMatch model, with up to 5.6\\% performance\nimprovement in MRR, compared to the state-of-the-art baselines.",
    "descriptor": "\nComments: Full paper of EMNLP 2022 Findings\n",
    "authors": [
      "Zixuan Li",
      "Zhongni Hou",
      "Saiping Guan",
      "Xiaolong Jin",
      "Weihua Peng",
      "Long Bai",
      "Yajuan Lyu",
      "Wei Li",
      "Jiafeng Guo",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.09708"
  },
  {
    "id": "arXiv:2210.09715",
    "title": "Fine-tune your Classifier: Finding Correlations With Temperature",
    "abstract": "Temperature is a widely used hyperparameter in various tasks involving neural\nnetworks, such as classification or metric learning, whose choice can have a\ndirect impact on the model performance. Most of existing works select its value\nusing hyperparameter optimization methods requiring several runs to find the\noptimal value. We propose to analyze the impact of temperature on\nclassification tasks by describing a dataset as a set of statistics computed on\nrepresentations on which we can build a heuristic giving us a default value of\ntemperature. We study the correlation between these extracted statistics and\nthe observed optimal temperatures. This preliminary study on more than a\nhundred combinations of different datasets and features extractors highlights\npromising results towards the construction of a general heuristic for\ntemperature.",
    "descriptor": "",
    "authors": [
      "Benjamin Chamand",
      "Olivier Risser-Maroix",
      "Camille Kurtz",
      "Philippe Joly",
      "Nicolas Lom\u00e9nie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09715"
  },
  {
    "id": "arXiv:2210.09716",
    "title": "A Comprehensive Analysis of Acknowledgement Texts in Web of Science: a  case study on four scientific domains",
    "abstract": "Analysis of acknowledgments is particularly interesting as acknowledgments\nmay give information not only about funding, but they are also able to reveal\nhidden contributions to authorship and the researcher's collaboration patterns,\ncontext in which research was conducted, and specific aspects of the academic\nwork. The focus of the present research is the analysis of a large sample of\nacknowledgement texts indexed in the Web of Science (WoS) Core Collection.\nRecord types 'article' and 'review' from four different scientific domains,\nnamely social sciences, economics, oceanography and computer science, published\nfrom 2014 to 2019 in a scientific journal in English were considered. Six types\nof acknowledged entities, i.e., funding agency, grant number, individuals,\nuniversity, corporation and miscellaneous, were extracted from the\nacknowledgement texts using a Named Entity Recognition (NER) tagger and\nsubsequently examined. A general analysis of the acknowledgement texts showed\nthat indexing of funding information in WoS is incomplete. The analysis of the\nautomatically extracted entities revealed differences and distinct patterns in\nthe distribution of acknowledged entities of different types between different\nscientific domains. A strong association was found between acknowledged entity\nand scientific domain and acknowledged entity and entity type. Only negligible\ncorrelation was found between the number of citations and the number of\nacknowledged entities. Generally, the number of words in the acknowledgement\ntexts positively correlates with the number of acknowledged funding\norganizations, universities, individuals and miscellaneous entities. At the\nsame time, acknowledgement texts with the larger number of sentences have more\nacknowledged individuals and miscellaneous categories.",
    "descriptor": "\nComments: 30 pages, 14 figures, accepted in Scientometrics\n",
    "authors": [
      "Nina Smirnova",
      "Philipp Mayr"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.09716"
  },
  {
    "id": "arXiv:2210.09721",
    "title": "An incremental input-to-state stability condition for a generic class of  recurrent neural networks",
    "abstract": "This paper proposes a novel sufficient condition for the incremental\ninput-to-state stability of a generic class of recurrent neural networks\n(RNNs). The established condition is compared with others available in the\nliterature, showing to be less conservative. Moreover, it can be applied for\nthe design of incremental input-to-state stable RNN-based control systems,\nresulting in a linear matrix inequality constraint for some specific RNN\narchitectures. The formulation of nonlinear observers for the considered system\nclass, as well as the design of control schemes with explicit integral action,\nare also investigated. The theoretical results are validated through simulation\non a referenced nonlinear system.",
    "descriptor": "",
    "authors": [
      "William D'Amico",
      "Alessio La Bella",
      "Marcello Farina"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.09721"
  },
  {
    "id": "arXiv:2210.09723",
    "title": "Textual Entailment Recognition with Semantic Features from Empirical  Text Representation",
    "abstract": "Textual entailment recognition is one of the basic natural language\nunderstanding(NLU) tasks. Understanding the meaning of sentences is a\nprerequisite before applying any natural language processing(NLP) techniques to\nautomatically recognize the textual entailment. A text entails a hypothesis if\nand only if the true value of the hypothesis follows the text. Classical\napproaches generally utilize the feature value of each word from word embedding\nto represent the sentences. In this paper, we propose a novel approach to\nidentifying the textual entailment relationship between text and hypothesis,\nthereby introducing a new semantic feature focusing on empirical\nthreshold-based semantic text representation. We employ an element-wise\nManhattan distance vector-based feature that can identify the semantic\nentailment relationship between the text-hypothesis pair. We carried out\nseveral experiments on a benchmark entailment classification(SICK-RTE) dataset.\nWe train several machine learning(ML) algorithms applying both semantic and\nlexical features to classify the text-hypothesis pair as entailment, neutral,\nor contradiction. Our empirical sentence representation technique enriches the\nsemantic information of the texts and hypotheses found to be more efficient\nthan the classical ones. In the end, our approach significantly outperforms\nknown methods in understanding the meaning of the sentences for the textual\nentailment classification task.",
    "descriptor": "",
    "authors": [
      "Md Atabuzzaman",
      "Md Shajalal",
      "Maksuda Bilkis Baby",
      "Md Rezaul Karim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.09723"
  },
  {
    "id": "arXiv:2210.09727",
    "title": "Vision-based GNSS-Free Localization for UAVs in the Wild",
    "abstract": "Considering the accelerated development of Unmanned Aerial Vehicles (UAVs)\napplications in both industrial and research scenarios, there is an increasing\nneed for localizing these aerial systems in non-urban environments, using\nGNSS-Free, vision-based methods. Our paper proposes a vision-based localization\nalgorithm that utilizes deep features to compute geographical coordinates of a\nUAV flying in the wild. The method is based on matching salient features of RGB\nphotographs captured by the drone camera and sections of a pre-built map\nconsisting of georeferenced open-source satellite images. Experimental results\nprove that vision-based localization has comparable accuracy with traditional\nGNSS-based methods, which serve as ground truth. Compared to state-of-the-art\nVisual Odometry (VO) approaches, our solution is designed for long-distance,\nhigh-altitude UAV flights. Code and datasets are available at\nhttps://github.com/TIERS/wildnav.",
    "descriptor": "\nComments: 6 pages, 6 figures, submitted to the International Conference on Mechanical Engineering and Robotics Research 2022\n",
    "authors": [
      "Marius-Mihail Gurgu",
      "Jorge Pe\u00f1a Queralta",
      "Tomi Westerlund"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.09727"
  },
  {
    "id": "arXiv:2210.09729",
    "title": "HUMANISE: Language-conditioned Human Motion Generation in 3D Scenes",
    "abstract": "Learning to generate diverse scene-aware and goal-oriented human motions in\n3D scenes remains challenging due to the mediocre characteristics of the\nexisting datasets on Human-Scene Interaction (HSI); they only have limited\nscale/quality and lack semantics. To fill in the gap, we propose a large-scale\nand semantic-rich synthetic HSI dataset, denoted as HUMANISE, by aligning the\ncaptured human motion sequences with various 3D indoor scenes. We automatically\nannotate the aligned motions with language descriptions that depict the action\nand the unique interacting objects in the scene; e.g., sit on the armchair near\nthe desk. HUMANISE thus enables a new generation task, language-conditioned\nhuman motion generation in 3D scenes. The proposed task is challenging as it\nrequires joint modeling of the 3D scene, human motion, and natural language. To\ntackle this task, we present a novel scene-and-language conditioned generative\nmodel that can produce 3D human motions of the desirable action interacting\nwith the specified objects. Our experiments demonstrate that our model\ngenerates diverse and semantically consistent human motions in 3D scenes.",
    "descriptor": "\nComments: Accepted by NeurIPS 2022\n",
    "authors": [
      "Zan Wang",
      "Yixin Chen",
      "Tengyu Liu",
      "Yixin Zhu",
      "Wei Liang",
      "Siyuan Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.09729"
  },
  {
    "id": "arXiv:2210.09730",
    "title": "Efficient Machine-Learning-based decoder for Heavy Hexagonal QECC",
    "abstract": "Errors in heavy hexagonal code and other topological codes like surface code\nwere usually decoded using the Minimum Weight Perfect Matching (MWPM) based\ndecoders. Recent advances have shown that topological codes can be efficiently\ndecoded by deploying machine learning (ML) techniques, for example, neural\nnetworks. In this work, we first propose an ML based decoder and show that this\ndecoder can decode heavy hexagonal code efficiently, in terms of the values of\nthreshold and pseudo-threshold, for various noise models. We show that the\nproposed ML based decoding method achieves $\\sim 5$ times higher values of\nthreshold than that by MWPM. Next, exploiting the property of subsystem codes,\nwe define gauge equivalence in heavy hexagonal code, by which two different\nerrors can belong to the same error class. We obtain a quadratic reduction in\nthe number of error classes for both bit flip and phase flip errors, thus\nachieving a further improvement of $\\sim 14\\%$ in the threshold o ver the basic\nML decoder. A novel technique of rank based gauge equivalence minimization to\nminimize the number of classes is further proposed, which is empirically faster\nthan the previously mentioned gauge equivalence minimization.",
    "descriptor": "",
    "authors": [
      "Debasmita Bhoumik",
      "Ritajit Majumdar",
      "Dhiraj Madan",
      "Dhinakaran Vinayagamurthy",
      "Shesha Raghunathan",
      "Susmita Sur-Kolay"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.09730"
  },
  {
    "id": "arXiv:2210.09735",
    "title": "Policy Gradient Methods for Designing Dynamic Output Feedback  Controllers",
    "abstract": "This paper proposes model-based and model-free policy gradient methods (PGMs)\nfor designing dynamic output feedback controllers for discrete-time partially\nobservable systems. To fulfill this objective, we first show that any dynamic\noutput feedback controller design is equivalent to a state-feedback controller\ndesign for a newly introduced system whose internal state is a finite-length\ninput-output history (IOH). Next, based on this equivalency, we propose a\nmodel-based PGM and show its global linear convergence by proving that the\nPolyak-Lojasiewicz inequality holds for a reachability-based lossless\nprojection of the IOH dynamics. Moreover, we propose two model-free\nimplementations of the PGM: the multi- and single-episodic PGM. The former is a\nMonte Carlo approximation of the model-based PGM, whereas the latter is a\nsimplified version of the former for ease of use in real systems. A sample\ncomplexity analysis of both methods is also presented. Finally, the\neffectiveness of the model-based/model-free PGMs is investigated through a\nnumerical simulation.",
    "descriptor": "",
    "authors": [
      "Takumi Hirai",
      "Tomonori Sadamoto"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.09735"
  },
  {
    "id": "arXiv:2210.09738",
    "title": "Clustering-based Aggregations for Prediction in Event Streams",
    "abstract": "Predicting the behaviour of shoppers provides valuable information for\nretailers, such as the expected spend of a shopper or the total turnover of a\nsupermarket. The ability to make predictions on an individual level is useful,\nas it allows supermarkets to accurately perform targeted marketing. However,\ngiven the expected number of shoppers and their diverse behaviours, making\naccurate predictions on an individual level is difficult. This problem does not\nonly arise in shopper behaviour, but also in various business processes, such\nas predicting when an invoice will be paid. In this paper we present CAPiES, a\nframework that focuses on this trade-off in an online setting. By making\npredictions on a larger number of entities at a time, we improve the predictive\naccuracy but at the potential cost of usefulness since we can say less about\nthe individual entities. CAPiES is developed in an online setting, where we\ncontinuously update the prediction model and make new predictions over time. We\nshow the existence of the trade-off in an experimental evaluation in two\nreal-world scenarios: a supermarket with over 160 000 shoppers and a paint\nfactory with over 171 000 invoices.",
    "descriptor": "",
    "authors": [
      "Yorick Spenrath",
      "Marwan Hassani",
      "Boudewijn F. Van Dongen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09738"
  },
  {
    "id": "arXiv:2210.09739",
    "title": "Real-Time Multi-Modal Semantic Fusion on Unmanned Aerial Vehicles with  Label Propagation for Cross-Domain Adaptation",
    "abstract": "Unmanned aerial vehicles (UAVs) equipped with multiple complementary sensors\nhave tremendous potential for fast autonomous or remote-controlled semantic\nscene analysis, e.g., for disaster examination. Here, we propose a UAV system\nfor real-time semantic inference and fusion of multiple sensor modalities.\nSemantic segmentation of LiDAR scans and RGB images, as well as object\ndetection on RGB and thermal images, run online onboard the UAV computer using\nlightweight CNN architectures and embedded inference accelerators. We follow a\nlate fusion approach where semantic information from multiple sensor modalities\naugments 3D point clouds and image segmentation masks while also generating an\nallocentric semantic map. Label propagation on the semantic map allows for\nsensor-specific adaptation with cross-modality and cross-domain supervision.\nOur system provides augmented semantic images and point clouds with $\\approx$ 9\nHz. We evaluate the integrated system in real-world experiments in an urban\nenvironment and at a disaster test site.",
    "descriptor": "\nComments: 35 pages, 18 figures, Accepted for Robotics and Autonomous Systems, Elsevier. arXiv admin note: substantial text overlap with arXiv:2108.06608\n",
    "authors": [
      "Simon Bultmann",
      "Jan Quenzel",
      "Sven Behnke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.09739"
  },
  {
    "id": "arXiv:2210.09743",
    "title": "A Dashboard to Analysis and Synthesis of Dimensionality Reduction  Methods in Remote Sensing",
    "abstract": "Hyperspectral images (HSI) classification is a high technical remote sensing\nsoftware. The purpose is to reproduce a thematic map . The HSI contains more\nthan a hundred hyperspectral measures, as bands (or simply images), of the\nconcerned region. They are taken at neighbors frequencies. Unfortunately, some\nbands are redundant features, others are noisily measured, and the high\ndimensionality of features made classification accuracy poor. The problematic\nis how to find the good bands to classify the regions items. Some methods use\nMutual Information (MI) and thresholding, to select relevant images, without\nprocessing redundancy. Others control and avoid redundancy. But they process\nthe dimensionality reduction, some times as selection, other times as wrapper\nmethods without any relationship . Here , we introduce a survey on all scheme\nused, and after critics and improvement, we synthesize a dashboard, that helps\nuser to analyze an hypothesize features selection and extraction softwares.",
    "descriptor": "\nComments: Journal Paper On Concepts Of Selection\n",
    "authors": [
      "Elkebir Sarhrouni",
      "Ahmed Hammouch",
      "Driss Aboutajdine"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09743"
  },
  {
    "id": "arXiv:2210.09746",
    "title": "Improving User's Sense of Participation in Robot-Driven Dialogue",
    "abstract": "In task-oriented dialogues with symbiotic robots, the robot usually takes the\ninitiative in dialogue progression and topic selection. In such robot-driven\ndialogue, the user's sense of participation in the dialogue is reduced because\nthe degree of freedom in timing and content of speech is limited, and as a\nresult, the user's familiarity with and trust in the robot as a dialogue\npartner and the level of dialogue satisfaction decrease. In this study, we\nconstructed a travel agent dialogue system focusing on improving the sense of\ndialogue participation. At the beginning of the dialogue, the robot tells the\nuser the purpose of the upcoming dialogue and indicates that it is responsible\nfor assisting the user in making decisions. In addition, in situations where\nusers were asked to state their preferences, the robot encourages them to\nexpress their intentions with actions, as well as spoken language responses. In\naddition, we attempted to reduce the sense of discomfort felt toward the\nandroid robot by devising a timing control for the robot's detailed movements\nand facial expressions.",
    "descriptor": "\nComments: This paper is part of the proceedings of the Dialogue Robot Competition 2022\n",
    "authors": [
      "Makoto Kawamoto",
      "Masaki Shuzo",
      "Eisaku Maeda"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.09746"
  },
  {
    "id": "arXiv:2210.09748",
    "title": "Spoken Dialogue Strategy Focusing on Asymmetric Communication with  Android Robots",
    "abstract": "Humans are easily conscious of small differences in an android robot's (AR's)\nbehaviors and utterances, resulting in treating the AR as not-human, while ARs\ntreat us as humans. Thus, there exists asymmetric communication between ARs and\nhumans. In our system at Dialogue Robot Competition 2022, this asymmetry was a\nconsiderable research target in our dialogue strategy. For example, tricky\nphrases such as questions related to personal matters and forceful requests for\nagreement were experimentally used in AR's utterances. We assumed that these AR\nphrases would have a reasonable chance of success, although humans would likely\nhesitate to use the phrases. Additionally, during a five-minute dialogue, our\nAR's character, such as its voice tones and sentence expressions, changed from\nmechanical to human-like type in order to pretend to tailor to customers. The\ncharacteristics of the AR developed by our team, DSML-TDU, are introduced in\nthis paper.",
    "descriptor": "\nComments: This paper is part of the proceedings of the Dialogue Robot Competition 2022\n",
    "authors": [
      "Daisuke Kawakubo",
      "Hitoshi Ishii",
      "Riku Okazawa",
      "Shunta Nishizawa",
      "Haruki Hatakeyama",
      "Hiroaki Sugiyama",
      "Masaki Shuzo",
      "Eisaku Maeda"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.09748"
  },
  {
    "id": "arXiv:2210.09750",
    "title": "A Signal Temporal Logic Motion Planner for Bird Diverter Installation  Tasks with Multi-Robot Aerial Systems",
    "abstract": "This paper investigates the problem of task assignment and trajectory\ngeneration for the installation of bird diverters with a fleet of multirotors\nleveraging on Signal Temporal Logic (STL) specifications. We extend our\nprevious motion planner to compute feasible and constrained trajectories,\ntaking into account payload capacity limitations and recharging constraints.\nThe proposed planner ensures the continuity of the operation, while\nguaranteeing compliance with safety requirements and mission fulfillment.\nAdditionally, an event-based replanning strategy is proposed to react to\nunforeseen failures. An energy minimization term is also considered to\nimplicitly save multirotor flight time during installation operations.\nNumerical simulations in MATLAB, Gazebo, and field experiments demonstrate the\nperformance of the approach and its validity in mock-up scenarios.",
    "descriptor": "\nComments: 18 pages, 14 figures, journal preprint\n",
    "authors": [
      "Alvaro Caballero",
      "Giuseppe Silano"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.09750"
  },
  {
    "id": "arXiv:2210.09753",
    "title": "A Socially Assistive Robot using Automated Planning in a Paediatric  Clinical Setting",
    "abstract": "We present an ongoing project that aims to develop a social robot to help\nchildren cope with painful and distressing medical procedures in a clinical\nsetting. Our approach uses automated planning as a core component for action\nselection in order to generate plans that include physical, sensory, and social\nactions for the robot to use when interacting with humans. A key capability of\nour system is that the robot's behaviour adapts based on the affective state of\nthe child patient. The robot must operate in a challenging physical and social\nenvironment where appropriate and safe interaction with children,\nparents/caregivers, and healthcare professionals is crucial. In this paper, we\npresent our system, examine some of the key challenges of the scenario, and\ndescribe how they are addressed by our system.",
    "descriptor": "\nComments: Presented at the AI-HRI Symposium at AAAI Fall Symposium Series (FSS) 2022\n",
    "authors": [
      "Alan Lindsay",
      "Andres Ramirez-Duque",
      "Ronald P.A. Petrick",
      "Mary Ellen Foster"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.09753"
  },
  {
    "id": "arXiv:2210.09754",
    "title": "Simultaneous Translation for Unsegmented Input: A Sliding Window  Approach",
    "abstract": "In the cascaded approach to spoken language translation (SLT), the ASR output\nis typically punctuated and segmented into sentences before being passed to MT,\nsince the latter is typically trained on written text. However, erroneous\nsegmentation, due to poor sentence-final punctuation by the ASR system, leads\nto degradation in translation quality, especially in the simultaneous (online)\nsetting where the input is continuously updated. To reduce the influence of\nautomatic segmentation, we present a sliding window approach to translate raw\nASR outputs (online or offline) without needing to rely on an automatic\nsegmenter. We train translation models using parallel windows (instead of\nparallel sentences) extracted from the original training data. At test time, we\ntranslate at the window level and join the translated windows using a simple\napproach to generate the final translation. Experiments on English-to-German\nand English-to-Czech show that our approach improves 1.3--2.0 BLEU points over\nthe usual ASR-segmenter pipeline, and the fixed-length window considerably\nreduces flicker compared to a baseline retranslation-based online SLT system.",
    "descriptor": "",
    "authors": [
      "Sukanta Sen",
      "Ond\u0159ej Bojar",
      "Barry Haddow"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.09754"
  },
  {
    "id": "arXiv:2210.09757",
    "title": "A Real-Time Fusion Framework for Long-term Visual Localization",
    "abstract": "Visual localization is a fundamental task that regresses the 6 Degree Of\nFreedom (6DoF) poses with image features in order to serve the high precision\nlocalization requests in many robotics applications. Degenerate conditions like\nmotion blur, illumination changes and environment variations place great\nchallenges in this task. Fusion with additional information, such as sequential\ninformation and Inertial Measurement Unit (IMU) inputs, would greatly assist\nsuch problems. In this paper, we present an efficient client-server visual\nlocalization architecture that fuses global and local pose estimations to\nrealize promising precision and efficiency. We include additional geometry\nhints in mapping and global pose regressing modules to improve the measurement\nquality. A loosely coupled fusion policy is adopted to leverage the computation\ncomplexity and accuracy. We conduct the evaluations on two typical open-source\nbenchmarks, 4Seasons and OpenLORIS. Quantitative results prove that our\nframework has competitive performance with respect to other state-of-the-art\nvisual localization solutions.",
    "descriptor": "\nComments: Submitted to ICRA 2023\n",
    "authors": [
      "Yuchen Yang",
      "Xudong Zhang",
      "Shuang Gao",
      "Jixiang Wan",
      "Yishan Ping",
      "Yuyue Liu",
      "Jijunnan Li",
      "Yandong Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.09757"
  },
  {
    "id": "arXiv:2210.09759",
    "title": "Pareto Manifold Learning: Tackling multiple tasks via ensembles of  single-task models",
    "abstract": "In Multi-Task Learning, tasks may compete and limit the performance achieved\non each other rather than guiding the optimization trajectory to a common\nsolution, superior to its single-task counterparts. There is often not a single\nsolution that is optimal for all tasks, leading practitioners to balance\ntradeoffs between tasks' performance, and to resort to optimality in the Pareto\nsense. Current Multi-Task Learning methodologies either completely neglect this\naspect of functional diversity, and produce one solution in the Pareto Front\npredefined by their optimization schemes, or produce diverse but discrete\nsolutions, each requiring a separate training run. In this paper, we conjecture\nthat there exist Pareto Subspaces, i.e., weight subspaces where multiple\noptimal functional solutions lie. We propose Pareto Manifold Learning, an\nensembling method in weight space that is able to discover such a\nparameterization and produces a continuous Pareto Front in a single training\nrun, allowing practitioners to modulate the performance on each task during\ninference on the fly. We validate the proposed method on a diverse set of\nmulti-task learning benchmarks, ranging from image classification to tabular\ndatasets and scene understanding, and show that Pareto Manifold Learning\noutperforms state-of-the-art algorithms.",
    "descriptor": "\nComments: 33 pages, 23 figures\n",
    "authors": [
      "Nikolaos Dimitriadis",
      "Pascal Frossard",
      "Fran\u00e7ois Fleuret"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09759"
  },
  {
    "id": "arXiv:2210.09761",
    "title": "Personality-adapted multimodal dialogue system",
    "abstract": "This paper describes a personality-adaptive multimodal dialogue system\ndeveloped for the Dialogue Robot Competition 2022. To realize a dialogue system\nthat adapts the dialogue strategy to individual users, it is necessary to\nconsider the user's nonverbal information and personality. In this competition,\nwe built a prototype of a user-adaptive dialogue system that estimates user\npersonality during dialogue. Pretrained DNN models are used to estimate user\npersonalities annotated as Big Five scores. This model is embedded in a\ndialogue system to estimate user personality from face images during the\ndialogue. We proposed a method for dialogue management that changed the\ndialogue flow based on the estimated personality characteristics and confirmed\nthat the system works in a real environment in the preliminary round of this\ncompetition. Furthermore, we implemented specific modules to enhance the\nmultimodal dialogue experience of the user, including personality assessment,\ncontrolling facial expressions and movements of the android, and dialogue\nmanagement to explain the attractiveness of sightseeing spots. The aim of\ndialogue based on personality assessment is to reduce the nervousness of users,\nand it acts as an ice breaker. The android's facial expressions and movements\nare necessary for a more natural android conversation. Since the task of this\ncompetition was to promote the appeal of sightseeing spots and to recommend an\nappropriate sightseeing spot, the dialogue process for how to explain the\nattractiveness of the spot is important. All results of the subjective\nevaluation by users were better than those of the baseline and other systems\ndeveloped for this competition. The proposed dialogue system ranked first in\nboth \"Impression Rating\" and \"Effectiveness of Android Recommendations\".\nAccording to the total evaluation in the competition, the proposed system was\nranked first overall.",
    "descriptor": "\nComments: This paper is part of the proceedings of the Dialogue Robot Competition 2022\n",
    "authors": [
      "Tamotsu Miyama",
      "Shogo Okada"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.09761"
  },
  {
    "id": "arXiv:2210.09765",
    "title": "Very Low-Resolution Iris Recognition Via Eigen-Patch Super-Resolution  and Matcher Fusion",
    "abstract": "Current research in iris recognition is moving towards enabling more relaxed\nacquisition conditions. This has effects on the quality of acquired images,\nwith low resolution being a predominant issue. Here, we evaluate a\nsuper-resolution algorithm used to reconstruct iris images based on\nEigen-transformation of local image patches. Each patch is reconstructed\nseparately, allowing better quality of enhanced images by preserving local\ninformation. Contrast enhancement is used to improve the reconstruction\nquality, while matcher fusion has been adopted to improve iris recognition\nperformance. We validate the system using a database of 1,872 near-infrared\niris images. The presented approach is superior to bilinear or bicubic\ninterpolation, especially at lower resolutions, and the fusion of the two\nsystems pushes the EER to below 5% for down-sampling factors up to a image size\nof only 13x13.",
    "descriptor": "\nComments: Published at Intl Conf on Biometrics: Theory, Apps and Systems, BTAS 2016\n",
    "authors": [
      "Fernando Alonso-Fernandez",
      "Reuben A. Farrugia",
      "Josef Bigun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09765"
  },
  {
    "id": "arXiv:2210.09766",
    "title": "DAGAD: Data Augmentation for Graph Anomaly Detection",
    "abstract": "Graph anomaly detection in this paper aims to distinguish abnormal nodes that\nbehave differently from the benign ones accounting for the majority of\ngraph-structured instances. Receiving increasing attention from both academia\nand industry, yet existing research on this task still suffers from two\ncritical issues when learning informative anomalous behavior from graph data.\nFor one thing, anomalies are usually hard to capture because of their subtle\nabnormal behavior and the shortage of background knowledge about them, which\ncauses severe anomalous sample scarcity. Meanwhile, the overwhelming majority\nof objects in real-world graphs are normal, bringing the class imbalance\nproblem as well. To bridge the gaps, this paper devises a novel Data\nAugmentation-based Graph Anomaly Detection (DAGAD) framework for attributed\ngraphs, equipped with three specially designed modules: 1) an information\nfusion module employing graph neural network encoders to learn representations,\n2) a graph data augmentation module that fertilizes the training set with\ngenerated samples, and 3) an imbalance-tailored learning module to discriminate\nthe distributions of the minority (anomalous) and majority (normal) classes. A\nseries of experiments on three datasets prove that DAGAD outperforms ten\nstate-of-the-art baseline detectors concerning various mostly-used metrics,\ntogether with an extensive ablation study validating the strength of our\nproposed modules.",
    "descriptor": "\nComments: Regular paper accepted by the 22nd IEEE International Conference on Data Mining (ICDM 2022)\n",
    "authors": [
      "Fanzhen Liu",
      "Xiaoxiao Ma",
      "Jia Wu",
      "Jian Yang",
      "Shan Xue",
      "Amin Beheshti",
      "Chuan Zhou",
      "Hao Peng",
      "Quan Z. Sheng",
      "Charu C. Aggarwal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09766"
  },
  {
    "id": "arXiv:2210.09767",
    "title": "Generative models uncertainty estimation",
    "abstract": "In recent years fully-parametric fast simulation methods based on generative\nmodels have been proposed for a variety of high-energy physics detectors. By\ntheir nature, the quality of data-driven models degrades in the regions of the\nphase space where the data are sparse. Since machine-learning models are hard\nto analyse from the physical principles, the commonly used testing procedures\nare performed in a data-driven way and can't be reliably used in such regions.\nIn our work we propose three methods to estimate the uncertainty of generative\nmodels inside and outside of the training phase space region, along with\ndata-driven calibration techniques. A test of the proposed methods on the LHCb\nRICH fast simulation is also presented.",
    "descriptor": "\nComments: Under review in Journal Of Physics: Conference Series (ACAT-2021)\n",
    "authors": [
      "Lucio Anderlini",
      "Constantine Chimpoesh",
      "Nikita Kazeev",
      "Agata Shishigina"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)",
      "High Energy Physics - Phenomenology (hep-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.09767"
  },
  {
    "id": "arXiv:2210.09769",
    "title": "STay-ON-the-Ridge: Guaranteed Convergence to Local Minimax Equilibrium  in Nonconvex-Nonconcave Games",
    "abstract": "Min-max optimization problems involving nonconvex-nonconcave objectives have\nfound important applications in adversarial training and other multi-agent\nlearning settings. Yet, no known gradient descent-based method is guaranteed to\nconverge to (even local notions of) min-max equilibrium in the\nnonconvex-nonconcave setting. For all known methods, there exist relatively\nsimple objectives for which they cycle or exhibit other undesirable behavior\ndifferent from converging to a point, let alone to some game-theoretically\nmeaningful one~\\cite{flokas2019poincare,hsieh2021limits}. The only known\nconvergence guarantees hold under the strong assumption that the initialization\nis very close to a local min-max equilibrium~\\cite{wang2019solving}. Moreover,\nthe afore-described challenges are not just theoretical curiosities. All known\nmethods are unstable in practice, even in simple settings.\nWe propose the first method that is guaranteed to converge to a local min-max\nequilibrium for smooth nonconvex-nonconcave objectives. Our method is\nsecond-order and provably escapes limit cycles as long as it is initialized at\nan easy-to-find initial point. Both the definition of our method and its\nconvergence analysis are motivated by the topological nature of the problem. In\nparticular, our method is not designed to decrease some potential function,\nsuch as the distance of its iterate from the set of local min-max equilibria or\nthe projected gradient of the objective, but is designed to satisfy a\ntopological property that guarantees the avoidance of cycles and implies its\nconvergence.",
    "descriptor": "",
    "authors": [
      "Constantinos Daskalakis",
      "Noah Golowich",
      "Stratis Skoulakis",
      "Manolis Zampetakis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.09769"
  },
  {
    "id": "arXiv:2210.09770",
    "title": "EventGraph at CASE 2021 Task 1: A General Graph-based Approach to  Protest Event Extraction",
    "abstract": "This paper presents our submission to the 2022 edition of the CASE 2021\nshared task 1, subtask 4. The EventGraph system adapts an end-to-end,\ngraph-based semantic parser to the task of Protest Event Extraction and more\nspecifically subtask 4 on event trigger and argument extraction. We experiment\nwith various graphs, encoding the events as either \"labeled-edge\" or\n\"node-centric\" graphs. We show that the \"node-centric\" approach yields best\nresults overall, performing well across the three languages of the task, namely\nEnglish, Spanish, and Portuguese. EventGraph is ranked 3rd for English and\nPortuguese, and 4th for Spanish. Our code is available at:\nhttps://github.com/huiling-y/eventgraph_at_case",
    "descriptor": "",
    "authors": [
      "Huiling You",
      "David Samuel",
      "Samia Touileb",
      "Lilja \u00d8vrelid"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.09770"
  },
  {
    "id": "arXiv:2210.09773",
    "title": "Retrofitting Multilingual Sentence Embeddings with Abstract Meaning  Representation",
    "abstract": "We introduce a new method to improve existing multilingual sentence\nembeddings with Abstract Meaning Representation (AMR). Compared with the\noriginal textual input, AMR is a structured semantic representation that\npresents the core concepts and relations in a sentence explicitly and\nunambiguously. It also helps reduce surface variations across different\nexpressions and languages. Unlike most prior work that only evaluates the\nability to measure semantic similarity, we present a thorough evaluation of\nexisting multilingual sentence embeddings and our improved versions, which\ninclude a collection of five transfer tasks in different downstream\napplications. Experiment results show that retrofitting multilingual sentence\nembeddings with AMR leads to better state-of-the-art performance on both\nsemantic textual similarity and transfer tasks. Our codebase and evaluation\nscripts can be found at \\url{https://github.com/jcyk/MSE-AMR}.",
    "descriptor": "\nComments: EMNLP2022\n",
    "authors": [
      "Deng Cai",
      "Xin Li",
      "Jackie Chun-Sing Ho",
      "Lidong Bing",
      "Wai Lam"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.09773"
  },
  {
    "id": "arXiv:2210.09778",
    "title": "Compact multi-scale periocular recognition using SAFE features",
    "abstract": "In this paper, we present a new approach for periocular recognition based on\nthe Symmetry Assessment by Feature Expansion (SAFE) descriptor, which encodes\nthe presence of various symmetric curve families around image key points. We\nuse the sclera center as single key point for feature extraction, highlighting\nthe object-like identity properties that concentrates to this unique point of\nthe eye. As it is demonstrated, such discriminative properties can be encoded\nwith a reduced set of symmetric curves. Experiments are done with a database of\nperiocular images captured with a digital camera. We test our system against\nreference periocular features, achieving top performance with a considerably\nsmaller feature vector (given by the use of a single key point). All the\nsystems tested also show a nearly steady correlation between acquisition\ndistance and performance, and they are also able to cope well when enrolment\nand test images are not captured at the same distance. Fusion experiments among\nthe available systems are also provided.",
    "descriptor": "\nComments: Published at IEEE/IAPR Intl Conf on Pattern Recognition, ICPR 2016\n",
    "authors": [
      "Fernando Alonso-Fernandez",
      "Anna Mikaelyan",
      "Josef Bigun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09778"
  },
  {
    "id": "arXiv:2210.09782",
    "title": "Decoupling Features in Hierarchical Propagation for Video Object  Segmentation",
    "abstract": "This paper focuses on developing a more effective method of hierarchical\npropagation for semi-supervised Video Object Segmentation (VOS). Based on\nvision transformers, the recently-developed Associating Objects with\nTransformers (AOT) approach introduces hierarchical propagation into VOS and\nhas shown promising results. The hierarchical propagation can gradually\npropagate information from past frames to the current frame and transfer the\ncurrent frame feature from object-agnostic to object-specific. However, the\nincrease of object-specific information will inevitably lead to the loss of\nobject-agnostic visual information in deep propagation layers. To solve such a\nproblem and further facilitate the learning of visual embeddings, this paper\nproposes a Decoupling Features in Hierarchical Propagation (DeAOT) approach.\nFirstly, DeAOT decouples the hierarchical propagation of object-agnostic and\nobject-specific embeddings by handling them in two independent branches.\nSecondly, to compensate for the additional computation from dual-branch\npropagation, we propose an efficient module for constructing hierarchical\npropagation, i.e., Gated Propagation Module, which is carefully designed with\nsingle-head attention. Extensive experiments show that DeAOT significantly\noutperforms AOT in both accuracy and efficiency. On YouTube-VOS, DeAOT can\nachieve 86.0% at 22.4fps and 82.0% at 53.4fps. Without test-time augmentations,\nwe achieve new state-of-the-art performance on four benchmarks, i.e.,\nYouTube-VOS (86.2%), DAVIS 2017 (86.2%), DAVIS 2016 (92.9%), and VOT 2020\n(0.622). Project page: https://github.com/z-x-yang/AOT.",
    "descriptor": "\nComments: Accepted by NeurIPS 2022\n",
    "authors": [
      "Zongxin Yang",
      "Yi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09782"
  },
  {
    "id": "arXiv:2210.09787",
    "title": "CPS-MEBR: Click Feedback-Aware Web Page Summarization for  Multi-Embedding-Based Retrieval",
    "abstract": "Embedding-based retrieval (EBR) is a technique to use embeddings to represent\nquery and document, and then convert the retrieval problem into a nearest\nneighbor search problem in the embedding space. Some previous works have mainly\nfocused on representing the web page with a single embedding, but in real web\nsearch scenarios, it is difficult to represent all the information of a long\nand complex structured web page as a single embedding. To address this issue,\nwe design a click feedback-aware web page summarization for\nmulti-embedding-based retrieval (CPS-MEBR) framework which is able to generate\nmultiple embeddings for web pages to match different potential queries.\nSpecifically, we use the click data of users in search logs to train a summary\nmodel to extract those sentences in web pages that are frequently clicked by\nusers, which are more likely to answer those potential queries. Meanwhile, we\nintroduce sentence-level semantic interaction to design a multi-embedding-based\nretrieval (MEBR) model, which can generate multiple embeddings to deal with\ndifferent potential queries by using frequently clicked sentences in web pages.\nOffline experiments show that it can perform high quality candidate retrieval\ncompared to single-embedding-based retrieval (SEBR) model.",
    "descriptor": "",
    "authors": [
      "Wenbiao Li",
      "Pan Tang",
      "Zhengfan Wu",
      "Weixue Lu",
      "Minghua Zhang",
      "Zhenlei Tian",
      "Daiting Shi",
      "Yu Sun",
      "Simiu Gu",
      "Dawei Yin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.09787"
  },
  {
    "id": "arXiv:2210.09789",
    "title": "Anti-Symmetric DGN: a stable architecture for Deep Graph Networks",
    "abstract": "Deep Graph Networks (DGNs) currently dominate the research landscape of\nlearning from graphs, due to their efficiency and ability to implement an\nadaptive message-passing scheme between the nodes. However, DGNs are typically\nlimited in their ability to propagate and preserve long-term dependencies\nbetween nodes, \\ie they suffer from the over-squashing phenomena. This reduces\ntheir effectiveness, since predictive problems may require to capture\ninteractions at different, and possibly large, radii in order to be effectively\nsolved. In this work, we present Anti-Symmetric Deep Graph Networks (A-DGNs), a\nframework for stable and non-dissipative DGN design, conceived through the lens\nof ordinary differential equations. We give theoretical proof that our method\nis stable and non-dissipative, leading to two key results: long-range\ninformation between nodes is preserved, and no gradient vanishing or explosion\noccurs in training. We empirically validate the proposed approach on several\ngraph benchmarks, showing that A-DGN yields to improved performance and enables\nto learn effectively even when dozens of layers are used.",
    "descriptor": "",
    "authors": [
      "Alessio Gravina",
      "Davide Bacciu",
      "Claudio Gallicchio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09789"
  },
  {
    "id": "arXiv:2210.09790",
    "title": "Hospitable Travel Agent Dialogue Robot: Team Irisapu Project Description  for DRC2022",
    "abstract": "This paper describes the dialog robot system designed by Team Irisapu for the\npreliminary round of the Dialogue Robot Competition 2022 (DRC2022). Our\nobjective was to design a hospitable travel agent robot. The system we\ndeveloped was ranked 8th out of 13 systems in the preliminary round of the\ncompetition, but our robot received high marks for its naturalness and\nlikeability.Our next challenge is to create a system that can provide more\nuseful information to users.",
    "descriptor": "\nComments: 5 pages, 5 figures, This paper is part of the proceedings of the Dialogue Robot Competition 2022\n",
    "authors": [
      "Kazuya Tsubokura",
      "Fumiya Kishi",
      "Kotomi Narita",
      "Takuya Takeda",
      "Yurie Iribe"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.09790"
  },
  {
    "id": "arXiv:2210.09791",
    "title": "Enabling Autonomous Electron Microscopy for Networked Computation and  Steering",
    "abstract": "Advanced electron microscopy workflows require an ecosystem of microscope\ninstruments and computing systems possibly located at different sites to\nconduct remotely steered and automated experiments. Current workflow executions\ninvolve manual operations for steering and measurement tasks, which are\ntypically performed from control workstations co-located with microscopes;\nconsequently, their operational tempo and effectiveness are limited. We propose\nan approach based on separate data and control channels for such an ecosystem\nof Scanning Transmission Electron Microscopes (STEM) and computing systems, for\nwhich no general solutions presently exist, unlike the neutron and light source\ninstruments. We demonstrate automated measurement transfers and remote steering\nof Nion STEM physical instruments over site networks. We propose a Virtual\nInfrastructure Twin (VIT) of this ecosystem, which is used to develop and test\nour steering software modules without requiring access to the physical\ninstrument infrastructure. Additionally, we develop a VIT for a multiple\nlaboratory scenario, which illustrates the applicability of this approach to\necosystems connected over wide-area networks, for the development and testing\nof software modules and their later field deployment.",
    "descriptor": "\nComments: 11 pages, 16 figures, accepted at IEEE eScience 2022 conference\n",
    "authors": [
      "Anees Al-Najjar",
      "Nageswara S. V. Rao",
      "Ramanan Sankaran",
      "Maxim Ziatdinov",
      "Debangshu Mukherjee",
      "Olga Ovchinnikova",
      "Kevin Roccapriore",
      "Andrew R. Lupini",
      "Sergei V. Kalinin"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.09791"
  },
  {
    "id": "arXiv:2210.09796",
    "title": "Inception-Based Crowd Counting -- Being Fast while Remaining Accurate",
    "abstract": "Recent sophisticated CNN-based algorithms have demonstrated their\nextraordinary ability to automate counting crowds from images, thanks to their\nstructures which are designed to address the issue of various head scales.\nHowever, these complicated architectures also increase computational complexity\nenormously, making real-time estimation implausible. Thus, in this paper, a new\nmethod, based on Inception-V3, is proposed to reduce the amount of computation.\nThis proposed approach (ICC), exploits the first five inception blocks and the\ncontextual module designed in CAN to extract features at different receptive\nfields, thereby being context-aware. The employment of these two different\nstrategies can also increase the model's robustness. Experiments show that ICC\ncan at best reduce 85.3 percent calculations with 24.4 percent performance\nloss. This high efficiency contributes significantly to the deployment of crowd\ncounting models in surveillance systems to guard the public safety. The code\nwill be available at https://github.com/YIMINGMA/CrowdCounting-ICC,and its\npre-trained weights on the Crowd Counting dataset, which comprises a large\nvariety of scenes from surveillance perspectives, will also open-sourced.",
    "descriptor": "\nComments: This is the paper that summarises my MSc's research project. Not plan to publish it. Share it on arXiv as a beginner-friendly paper for new researchers into crowd counting\n",
    "authors": [
      "Yiming Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09796"
  },
  {
    "id": "arXiv:2210.09798",
    "title": "HistoStarGAN: A Unified Approach to Stain Normalisation, Stain Transfer  and Stain Invariant Segmentation in Renal Histopathology",
    "abstract": "Virtual stain transfer is a promising area of research in Computational\nPathology, which has a great potential to alleviate important limitations when\napplying deeplearningbased solutions such as lack of annotations and\nsensitivity to a domain shift. However, in the literature, the majority of\nvirtual staining approaches are trained for a specific staining or stain\ncombination, and their extension to unseen stainings requires the acquisition\nof additional data and training. In this paper, we propose HistoStarGAN, a\nunified framework that performs stain transfer between multiple stainings,\nstain normalisation and stain invariant segmentation, all in one inference of\nthe model. We demonstrate the generalisation abilities of the proposed solution\nto perform diverse stain transfer and accurate stain invariant segmentation\nover numerous unseen stainings, which is the first such demonstration in the\nfield. Moreover, the pre-trained HistoStar-GAN model can serve as a synthetic\ndata generator, which paves the way for the use of fully annotated synthetic\nimage data to improve the training of deep learning-based algorithms. To\nillustrate the capabilities of our approach, as well as the potential risks in\nthe microscopy domain, inspired by applications in natural images, we generated\nKidneyArtPathology, a fully annotated artificial image dataset for renal\npathology.",
    "descriptor": "",
    "authors": [
      "Jelica Vasiljevi\u0107",
      "Friedrich Feuerhake",
      "C\u00e9dric Wemmert",
      "Thomas Lampert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.09798"
  },
  {
    "id": "arXiv:2210.09802",
    "title": "NFGen: Automatic Non-linear Function Evaluation Code Generator for  General-purpose MPC Platforms",
    "abstract": "Due to the absence of a library for non-linear function evaluation, so-called\ngeneral-purpose secure multi-party computation (MPC) are not as ''general'' as\nMPC programmers expect. Prior arts either naively reuse plaintext methods,\nresulting in suboptimal performance and even incorrect results, or handcraft ad\nhoc approximations for specific functions or platforms. We propose a general\ntechnique, NFGen, that utilizes pre-computed discrete piecewise polynomials to\naccurately approximate generic functions using fixed-point numbers. We\nimplement it using a performance-prediction-based code generator to support\ndifferent platforms. Conducting extensive evaluations of 23 non-linear\nfunctions against six MPC protocols on two platforms, we demonstrate\nsignificant performance, accuracy, and generality improvements over existing\nmethods.",
    "descriptor": "\nComments: 20 pages, full version of CCS22 paper\n",
    "authors": [
      "Xiaoyu Fan",
      "Kun Chen",
      "Guosai Wang",
      "Mingchun Zhuang",
      "Yi Li",
      "Wei Xu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.09802"
  },
  {
    "id": "arXiv:2210.09803",
    "title": "Sentiment-Aware Word and Sentence Level Pre-training for Sentiment  Analysis",
    "abstract": "Most existing pre-trained language representation models (PLMs) are\nsub-optimal in sentiment analysis tasks, as they capture the sentiment\ninformation from word-level while under-considering sentence-level information.\nIn this paper, we propose SentiWSP, a novel Sentiment-aware pre-trained\nlanguage model with combined Word-level and Sentence-level Pre-training tasks.\nThe word level pre-training task detects replaced sentiment words, via a\ngenerator-discriminator framework, to enhance the PLM's knowledge about\nsentiment words. The sentence level pre-training task further strengthens the\ndiscriminator via a contrastive learning framework, with similar sentences as\nnegative samples, to encode sentiments in a sentence. Extensive experimental\nresults show that SentiWSP achieves new state-of-the-art performance on various\nsentence-level and aspect-level sentiment classification benchmarks. We have\nmade our code and model publicly available at\nhttps://github.com/XMUDM/SentiWSP.",
    "descriptor": "",
    "authors": [
      "Shuai Fan",
      "Chen Lin",
      "Haonan Li",
      "Zhenghao Lin",
      "Jinsong Su",
      "Hang Zhang",
      "Yeyun Gong",
      "Jian Guo",
      "Nan Duan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.09803"
  },
  {
    "id": "arXiv:2210.09805",
    "title": "Domain Specific Sub-network for Multi-Domain Neural Machine Translation",
    "abstract": "This paper presents Domain-Specific Sub-network (DoSS). It uses a set of\nmasks obtained through pruning to define a sub-network for each domain and\nfinetunes the sub-network parameters on domain data. This performs very closely\nand drastically reduces the number of parameters compared to finetuning the\nwhole network on each domain. Also a method to make masks unique per domain is\nproposed and shown to greatly improve the generalization to unseen domains. In\nour experiments on German to English machine translation the proposed method\noutperforms the strong baseline of continue training on multi-domain (medical,\ntech and religion) data by 1.47 BLEU points. Also continue training DoSS on new\ndomain (legal) outperforms the multi-domain (medical, tech, religion, legal)\nbaseline by 1.52 BLEU points.",
    "descriptor": "\nComments: 6 pages, 1 figure, 5 tables, AACL-IJCNLP 2022 conference\n",
    "authors": [
      "Amr Hendy",
      "Mohamed Abdelghaffar",
      "Mohamed Afify",
      "Ahmed Y. Tawfik"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.09805"
  },
  {
    "id": "arXiv:2210.09806",
    "title": "Capacitated Vehicle Routing in Graphic Metrics",
    "abstract": "We study the capacitated vehicle routing problem in graphic metrics (graphic\nCVRP). Our main contribution is a new lower bound on the cost of an optimal\nsolution. For graphic metrics, this lower bound is tight and significantly\nstronger than the well-known bound for general metrics. The proof of the new\nlower bound is simple and combinatorial. Using this lower bound, we analyze the\napproximation ratio of the classical iterated tour partitioning algorithm\ncombined with the TSP algorithms for graphic metrics of Christofides [1976], of\nM\\\"omke-Svensson [JACM 2016], and of Seb\\H{o}-Vygen [Combinatorica 2014]. In\nparticular, we obtain a 1.95-approximation for the graphic CVRP.",
    "descriptor": "",
    "authors": [
      "Tobias M\u00f6mke",
      "Hang Zhou"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.09806"
  },
  {
    "id": "arXiv:2210.09808",
    "title": "Distributed Inference over Linear Models using Alternating Gaussian  Belief Propagation",
    "abstract": "We consider the problem of maximum likelihood estimation in linear models\nrepresented by factor graphs and solved via the Gaussian belief propagation\nalgorithm. Motivated by massive internet of things (IoT) networks and edge\ncomputing, we set the above problem in a clustered scenario, where the factor\ngraph is divided into clusters and assigned for processing in a distributed\nfashion across a number of edge computing nodes. For these scenarios, we show\nthat an alternating Gaussian belief propagation (AGBP) algorithm that\nalternates between inter- and intra-cluster iterations, demonstrates superior\nperformance in terms of convergence properties compared to the existing\nsolutions in the literature. We present a comprehensive framework and introduce\nappropriate metrics to analyse AGBP algorithm across a wide range of linear\nmodels characterised by symmetric and non-symmetric, square, and rectangular\nmatrices. We extend the analysis to the case of dynamic linear models by\nintroducing dynamic arrival of new data over time. Using a combination of\nanalytical and extensive numerical results, we show the efficiency and\nscalability of AGBP algorithm, making it a suitable solution for large-scale\ninference in massive IoT networks.",
    "descriptor": "\nComments: 12 pages, 12 figures\n",
    "authors": [
      "Mirsad Cosovic",
      "Dragisa Miskovic",
      "Muhamed Delalic",
      "Darijo Raca",
      "Dejan Vukobratovic"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.09808"
  },
  {
    "id": "arXiv:2210.09809",
    "title": "Representation Power of Graph Convolutions : Neural Tangent Kernel  Analysis",
    "abstract": "The fundamental principle of Graph Neural Networks (GNNs) is to exploit the\nstructural information of the data by aggregating the neighboring nodes using a\ngraph convolution. Therefore, understanding its influence on the network\nperformance is crucial. Convolutions based on graph Laplacian have emerged as\nthe dominant choice with the symmetric normalization of the adjacency matrix\n$A$, defined as $D^{-1/2}AD^{-1/2}$, being the most widely adopted one, where\n$D$ is the degree matrix. However, some empirical studies show that row\nnormalization $D^{-1}A$ outperforms it in node classification. Despite the\nwidespread use of GNNs, there is no rigorous theoretical study on the\nrepresentation power of these convolution operators, that could explain this\nbehavior. In this work, we analyze the influence of the graph convolutions\ntheoretically using Graph Neural Tangent Kernel in a semi-supervised node\nclassification setting. Under a Degree Corrected Stochastic Block Model, we\nprove that: (i) row normalization preserves the underlying class structure\nbetter than other convolutions; (ii) performance degrades with network depth\ndue to over-smoothing, but the loss in class information is the slowest in row\nnormalization; (iii) skip connections retain the class information even at\ninfinite depth, thereby eliminating over-smoothing. We finally validate our\ntheoretical findings on real datasets.",
    "descriptor": "",
    "authors": [
      "Mahalakshmi Sabanayagam",
      "Pascal Esser",
      "Debarghya Ghoshdastidar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09809"
  },
  {
    "id": "arXiv:2210.09813",
    "title": "Identifying Operation Equilibrium in Integrated Electricity, Natural  Gas, and Carbon-Emission Markets",
    "abstract": "The decarbonization of the power sector plays a pivotal role in economy-wide\ndecarbonization to set the world on track to limit warming to 1.5{\\deg}C by\n2050. Carbon emission markets can play a significant role in this transition by\nputting a price on carbon and giving electricity producers an incentive to\nreduce their emissions. In this paper, we study the operational equilibrium of\nan integrated regional/jurisdictional energy system that comprises an\nelectricity market, a natural gas market, and a carbon emission market. We\nfirst propose the novel role of a regional carbon market operator (CMO).\nDifferent than the conventional cap-and-trade carbon trading mechanism, the\nproposed CMO manages carbon allowance trading in a centralized jurisdictional\ncarbon emission market. We then develop the formulation to identify the\noperational equilibrium of the electricity, natural gas, and carbon emission\nmarkets based on their interactions. The proposed equilibrium can be obtained\nby solving the Karush-Kuhn-Tucker (KKT) conditions of all three operational\nmodels simultaneously. Simulation results demonstrate that the proposed\napproach is more flexible, consistent, and effective in mitigating carbon\nemissions compared with the cap-and-trade mechanism.",
    "descriptor": "",
    "authors": [
      "Yijie Yang",
      "Jian Shi",
      "Dan Wang",
      "Chenye Wu",
      "Zhu Han"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.09813"
  },
  {
    "id": "arXiv:2210.09814",
    "title": "Scrape, Cut, Paste and Learn: Automated Dataset Generation Applied to  Parcel Logistics",
    "abstract": "State-of-the-art approaches in computer vision heavily rely on sufficiently\nlarge training datasets. For real-world applications, obtaining such a dataset\nis usually a tedious task. In this paper, we present a fully automated pipeline\nto generate a synthetic dataset for instance segmentation in four steps. In\ncontrast to existing work, our pipeline covers every step from data acquisition\nto the final dataset. We first scrape images for the objects of interest from\npopular image search engines and since we rely only on text-based queries the\nresulting data comprises a wide variety of images. Hence, image selection is\nnecessary as a second step. This approach of image scraping and selection\nrelaxes the need for a real-world domain-specific dataset that must be either\npublicly available or created for this purpose. We employ an object-agnostic\nbackground removal model and compare three different methods for image\nselection: Object-agnostic pre-processing, manual image selection and CNN-based\nimage selection. In the third step, we generate random arrangements of the\nobject of interest and distractors on arbitrary backgrounds. Finally, the\ncomposition of the images is done by pasting the objects using four different\nblending methods. We present a case study for our dataset generation approach\nby considering parcel segmentation. For the evaluation we created a dataset of\nparcel photos that were annotated automatically. We find that (1) our dataset\ngeneration pipeline allows a successful transfer to real test images (Mask AP\n86.2), (2) a very accurate image selection process - in contrast to human\nintuition - is not crucial and a broader category definition can help to bridge\nthe domain gap, (3) the usage of blending methods is beneficial compared to\nsimple copy-and-paste. We made our full code for scraping, image composition\nand training publicly available at https://a-nau.github.io/parcel2d.",
    "descriptor": "\nComments: Accepted at ICMLA 2022\n",
    "authors": [
      "Alexander Naumann",
      "Felix Hertlein",
      "Benchun Zhou",
      "Laura D\u00f6rr",
      "Kai Furmans"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09814"
  },
  {
    "id": "arXiv:2210.09815",
    "title": "Spontaneous speech synthesis with linguistic-speech consistency training  using pseudo-filled pauses",
    "abstract": "We propose a training method for spontaneous speech synthesis models that\nguarantees the consistency of linguistic parts of synthesized speech.\nPersonalized spontaneous speech synthesis aims to reproduce the individuality\nof disfluency, such as filled pauses. Our prior model includes a filled-pause\nprediction model and synthesizes filled-pause-included speech from text without\nfilled pauses. However, inserting the filled pauses degrades the quality of the\nlinguistic parts of the synthesized speech. This might be because filled-pause\ninsertion tendencies differ between training and inference, and the synthesis\nmodel cannot represent connections between filled pauses and surrounding\nphonemes in inference. We, therefore, developed a linguistic-speech consistency\ntraining that guarantees the consistency of linguistic parts of synthetic\nspeech with and without filled pauses. The proposed consistency training\nutilizes not only ground-truth-filled pauses but also pseudo ones. Our\nexperiments demonstrate that this method improves the naturalness of the\nsynthetic linguistic speech and the entire predicted-filled-pause-included\nsynthetic speech.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Yuta Matsunaga",
      "Takaaki Saeki",
      "Shinnosuke Takamichi",
      "Hiroshi Saruwatari"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.09815"
  },
  {
    "id": "arXiv:2210.09817",
    "title": "Universal hidden monotonic trend estimation with contrastive learning",
    "abstract": "In this paper, we describe a universal method for extracting the underlying\nmonotonic trend factor from time series data. We propose an approach related to\nthe Mann-Kendall test, a standard monotonic trend detection method and call it\ncontrastive trend estimation (CTE). We show that the CTE method identifies any\nhidden trend underlying temporal data while avoiding the standard assumptions\nused for monotonic trend identification. In particular, CTE can take any type\nof temporal data (vector, images, graphs, time series, etc.) as input. We\nfinally illustrate the interest of our CTE method through several experiments\non different types of data and problems.",
    "descriptor": "",
    "authors": [
      "Edouard Pineau",
      "S\u00e9bastien Razakarivony",
      "Mauricio Gonzalez",
      "Anthony Schrapffer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09817"
  },
  {
    "id": "arXiv:2210.09818",
    "title": "Disentangling the Predictive Variance of Deep Ensembles through the  Neural Tangent Kernel",
    "abstract": "Identifying unfamiliar inputs, also known as out-of-distribution (OOD)\ndetection, is a crucial property of any decision making process. A simple and\nempirically validated technique is based on deep ensembles where the variance\nof predictions over different neural networks acts as a substitute for input\nuncertainty. Nevertheless, a theoretical understanding of the inductive biases\nleading to the performance of deep ensemble's uncertainty estimation is\nmissing. To improve our description of their behavior, we study deep ensembles\nwith large layer widths operating in simplified linear training regimes, in\nwhich the functions trained with gradient descent can be described by the\nneural tangent kernel. We identify two sources of noise, each inducing a\ndistinct inductive bias in the predictive variance at initialization. We\nfurther show theoretically and empirically that both noise sources affect the\npredictive variance of non-linear deep ensembles in toy models and realistic\nsettings after training. Finally, we propose practical ways to eliminate part\nof these noise sources leading to significant changes and improved OOD\ndetection in trained deep ensembles.",
    "descriptor": "",
    "authors": [
      "Seijin Kobayashi",
      "Pau Vilimelis Aceituno",
      "Johannes von Oswald"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09818"
  },
  {
    "id": "arXiv:2210.09819",
    "title": "Eye-tracking based classification of Mandarin Chinese readers with and  without dyslexia using neural sequence models",
    "abstract": "Eye movements are known to reflect cognitive processes in reading, and\npsychological reading research has shown that eye gaze patterns differ between\nreaders with and without dyslexia. In recent years, researchers have attempted\nto classify readers with dyslexia based on their eye movements using Support\nVector Machines (SVMs). However, these approaches (i) are based on highly\naggregated features averaged over all words read by a participant, thus\ndisregarding the sequential nature of the eye movements, and (ii) do not\nconsider the linguistic stimulus and its interaction with the reader's eye\nmovements. In the present work, we propose two simple sequence models that\nprocess eye movements on the entire stimulus without the need of aggregating\nfeatures across the sentence. Additionally, we incorporate the linguistic\nstimulus into the model in two ways -- contextualized word embeddings and\nmanually extracted linguistic features. The models are evaluated on a Mandarin\nChinese dataset containing eye movements from children with and without\ndyslexia. Our results show that (i) even for a logographic script such as\nChinese, sequence models are able to classify dyslexia on eye gaze sequences,\nreaching state-of-the-art performance, and (ii) incorporating the linguistic\nstimulus does not help to improve classification performance.",
    "descriptor": "",
    "authors": [
      "Patrick Haller",
      "Andreas S\u00e4uberli",
      "Sarah Elisabeth Kiener",
      "Jinger Pan",
      "Ming Yan",
      "Lena J\u00e4ger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09819"
  },
  {
    "id": "arXiv:2210.09821",
    "title": "On-the-go Reflectance Transformation Imaging with Ordinary Smartphones",
    "abstract": "Reflectance Transformation Imaging (RTI) is a popular technique that allows\nthe recovery of per-pixel reflectance information by capturing an object under\ndifferent light conditions. This can be later used to reveal surface details\nand interactively relight the subject. Such process, however, typically\nrequires dedicated hardware setups to recover the light direction from multiple\nlocations, making the process tedious when performed outside the lab.\nWe propose a novel RTI method that can be carried out by recording videos\nwith two ordinary smartphones. The flash led-light of one device is used to\nilluminate the subject while the other captures the reflectance. Since the led\nis mounted close to the camera lenses, we can infer the light direction for\nthousands of images by freely moving the illuminating device while observing a\nfiducial marker surrounding the subject. To deal with such amount of data, we\npropose a neural relighting model that reconstructs object appearance for\narbitrary light directions from extremely compact reflectance distribution data\ncompressed via Principal Components Analysis (PCA). Experiments shows that the\nproposed technique can be easily performed on the field with a resulting RTI\nmodel that can outperform state-of-the-art approaches involving dedicated\nhardware setups.",
    "descriptor": "\nComments: VISART VI - Workshop at the European Conference of Computer Vision (ECCV)\n",
    "authors": [
      "Mara Pistellato",
      "Filippo Bergamasco"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2210.09821"
  },
  {
    "id": "arXiv:2210.09822",
    "title": "Two low differentially uniform power permutations over odd  characteristic finite fields: APN and differentially $4$-uniform functions",
    "abstract": "Permutation polynomials over finite fields are fundamental objects as they\nare used in various theoretical and practical applications in cryptography,\ncoding theory, combinatorial design, and related topics. This family of\npolynomials constitutes an active research area in which advances are being\nmade constantly. In particular, constructing infinite classes of permutation\npolynomials over finite fields with good differential properties (namely, low)\nremains an exciting problem despite much research in this direction for many\nyears.\nThis article exhibits low differentially uniform power permutations over\nfinite fields of odd characteristic. Specifically, its objective is twofold\nconcerning the power functions $F(x)=x^{\\frac{p^n+3}{2}}$ defined over the\nfinite field $F_{p^n}$ of order $p^n$, where $p$ is an odd prime, and $n$ is a\npositive integer. The first is to complement some former results initiated by\nHelleseth and Sandberg in \\cite{HS} by solving the open problem left open for\nmore than twenty years concerning the determination of the differential\nspectrum of $F$ when $p^n\\equiv3\\pmod 4$ and $p\\neq 3$. The second is to\ndetermine the exact value of its differential uniformity. Our achievements are\nobtained firstly by evaluating some exponential sums over $F_{p^n}$ (which\namounts to evaluating the number of $F_{p^n}$-rational points on some related\ncurves and secondly by computing the number of solutions in $(F_{p^n})^4$ of a\nsystem of equations presented by Helleseth, Rong, and Sandberg in [``New\nfamilies of almost perfect nonlinear power mappings,\" IEEE Trans. Inform.\nTheory, vol. 45. no. 2, 1999], naturally appears while determining the\ndifferential spectrum of $F$. We show that in the considered case\n($p^n\\equiv3\\pmod 4$ and $p\\neq 3$), $F$ is an APN power permutation when\n$p^n=11$, and a differentially $4$-uniform power permutation otherwise.",
    "descriptor": "",
    "authors": [
      "Yan Haode",
      "Sihem Mesnager",
      "Tan Xiantong"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.09822"
  },
  {
    "id": "arXiv:2210.09825",
    "title": "Agile Practices for Quantum Software Development: Practitioners  Perspectives",
    "abstract": "Quantum software systems are emerging software engineering (SE) genre that\nexploit principles of quantum bits (Qubit) and quantum gates (Qgates) to solve\ncomplex computing problems that today classic computers can not effectively do\nin a reasonable time. According to its proponents, agile software development\npractices have the potential to address many of the problems endemic to the\ndevelopment of quantum software. However, there is a dearth of evidence\nconfirming if agile practices suit and can be adopted by software teams as they\nare in the context of quantum software development. To address this lack, we\nconducted an empirical study to investigate the needs and challenges of using\nagile practices to develop quantum software. While our semi-structured\ninterviews with 26 practitioners across 10 countries highlighted the\napplicability of agile practices in this domain, the interview findings also\nrevealed new challenges impeding the effective incorporation of these\npractices. Our research findings provide a springboard for further\ncontextualization and seamless integration of agile practices with developing\nthe next generation of quantum software.",
    "descriptor": "\nComments: 12 pages, 5 figures\n",
    "authors": [
      "Arif Ali Khan",
      "Muhammad Azeem Akbar",
      "Aakash Ahmad",
      "Mahdi Fahmideh",
      "Mohammad Shameem",
      "Valtteri Lahtinen",
      "Muhammad Waseem",
      "Tommi Mikkonen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.09825"
  },
  {
    "id": "arXiv:2210.09831",
    "title": "Simplex space-time meshes in engineering applications with moving  domains",
    "abstract": "This paper highlights how unstructured space-time meshes can be used in\nproduction engineering applications with moving domains. Unstructured\nspace-time elements can connect different spatial meshes at the bottom and top\nlevel of the space-time domain and deal with complicated domain\nmovements/rotations that the standard arbitrary Lagrangian-Eulerian techniques\ncan not resolve without remeshing. We use a space-time finite element\ndiscretization, by means of 4D simplex space-time elements, referred to as\npentatopes by Behr [2008], which leads to entirely unstructured grids with\nvarying levels of refinement both in space and in time. Furthermore, we use\nstabilization techniques, and the stabilization parameter is defined based on\nthe contravariant metric tensor, as shown in the work of Pauli and Behr [2017].\nIts definition was extended in 4D by von Danwitz et al. [2019], allowing us to\ndeal with complex anisotropic simplex meshes in the space-time domain.",
    "descriptor": "",
    "authors": [
      "Violeta Karyofylli",
      "Marek Behr"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2210.09831"
  },
  {
    "id": "arXiv:2210.09834",
    "title": "Learning Less Generalizable Patterns with an Asymmetrically Trained  Double Classifier for Better Test-Time Adaptation",
    "abstract": "Deep neural networks often fail to generalize outside of their training\ndistribution, in particular when only a single data domain is available during\ntraining. While test-time adaptation has yielded encouraging results in this\nsetting, we argue that, to reach further improvements, these approaches should\nbe combined with training procedure modifications aiming to learn a more\ndiverse set of patterns. Indeed, test-time adaptation methods usually have to\nrely on a limited representation because of the shortcut learning phenomenon:\nonly a subset of the available predictive patterns is learned with standard\ntraining. In this paper, we first show that the combined use of existing\ntraining-time strategies, and test-time batch normalization, a simple\nadaptation method, does not always improve upon the test-time adaptation alone\non the PACS benchmark. Furthermore, experiments on Office-Home show that very\nfew training-time methods improve upon standard training, with or without\ntest-time batch normalization. We therefore propose a novel approach using a\npair of classifiers and a shortcut patterns avoidance loss that mitigates the\nshortcut learning behavior by reducing the generalization ability of the\nsecondary classifier, using the additional shortcut patterns avoidance loss\nthat encourages the learning of samples specific patterns. The primary\nclassifier is trained normally, resulting in the learning of both the natural\nand the more complex, less generalizable, features. Our experiments show that\nour method improves upon the state-of-the-art results on both benchmarks and\nbenefits the most to test-time batch normalization.",
    "descriptor": "",
    "authors": [
      "Thomas Duboudin",
      "Emmanuel Dellandr\u00e9a",
      "Corentin Abgrall",
      "Gilles H\u00e9naff",
      "Liming Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.09834"
  },
  {
    "id": "arXiv:2210.09835",
    "title": "When Age-Invariant Face Recognition Meets Face Age Synthesis: A  Multi-Task Learning Framework and A New Benchmark",
    "abstract": "To minimize the impact of age variation on face recognition, age-invariant\nface recognition (AIFR) extracts identity-related discriminative features by\nminimizing the correlation between identity- and age-related features while\nface age synthesis (FAS) eliminates age variation by converting the faces in\ndifferent age groups to the same group. However, AIFR lacks visual results for\nmodel interpretation and FAS compromises downstream recognition due to\nartifacts. Therefore, we propose a unified, multi-task framework to jointly\nhandle these two tasks, termed MTLFace, which can learn the age-invariant\nidentity-related representation for face recognition while achieving pleasing\nface synthesis for model interpretation. Specifically, we propose an\nattention-based feature decomposition to decompose the mixed face features into\ntwo uncorrelated components -- identity- and age-related features -- in a\nspatially constrained way. Unlike the conventional one-hot encoding that\nachieves group-level FAS, we propose a novel identity conditional module to\nachieve identity-level FAS, which can improve the age smoothness of synthesized\nfaces through a weight-sharing strategy. Benefiting from the proposed\nmulti-task framework, we then leverage those high-quality synthesized faces\nfrom FAS to further boost AIFR via a novel selective fine-tuning strategy.\nFurthermore, to advance both AIFR and FAS, we collect and release a large\ncross-age face dataset with age and gender annotations, and a new benchmark\nspecifically designed for tracing long-missing children. Extensive experimental\nresults on five benchmark cross-age datasets demonstrate that MTLFace yields\nsuperior performance for both AIFR and FAS. We further validate MTLFace on two\npopular general face recognition datasets, obtaining competitive performance on\nface recognition in the wild. Code is available at\nthis http URL",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2103.01520\n",
    "authors": [
      "Zhizhong Huang",
      "Junping Zhang",
      "Hongming Shan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09835"
  },
  {
    "id": "arXiv:2210.09836",
    "title": "Overlap-guided Gaussian Mixture Models for Point Cloud Registration",
    "abstract": "Probabilistic 3D point cloud registration methods have shown competitive\nperformance in overcoming noise, outliers, and density variations. However,\nregistering point cloud pairs in the case of partial overlap is still a\nchallenge. This paper proposes a novel overlap-guided probabilistic\nregistration approach that computes the optimal transformation from matched\nGaussian Mixture Model (GMM) parameters. We reformulate the registration\nproblem as the problem of aligning two Gaussian mixtures such that a\nstatistical discrepancy measure between the two corresponding mixtures is\nminimized. We introduce a Transformer-based detection module to detect\noverlapping regions, and represent the input point clouds using GMMs by guiding\ntheir alignment through overlap scores computed by this detection module.\nExperiments show that our method achieves superior registration accuracy and\nefficiency than state-of-the-art methods when handling point clouds with\npartial overlap and different densities on synthetic and real-world datasets.\nhttps://github.com/gfmei/ogmm",
    "descriptor": "\nComments: Accepted in WACV 2023\n",
    "authors": [
      "Guofeng Mei",
      "Fabio Poiesi",
      "Cristiano Saltori",
      "Jian Zhang",
      "Elisa Ricci",
      "Nicu Sebe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09836"
  },
  {
    "id": "arXiv:2210.09840",
    "title": "Graph-Based Multilingual Label Propagation for Low-Resource  Part-of-Speech Tagging",
    "abstract": "Part-of-Speech (POS) tagging is an important component of the NLP pipeline,\nbut many low-resource languages lack labeled data for training. An established\nmethod for training a POS tagger in such a scenario is to create a labeled\ntraining set by transferring from high-resource languages. In this paper, we\npropose a novel method for transferring labels from multiple high-resource\nsource to low-resource target languages. We formalize POS tag projection as\ngraph-based label propagation. Given translations of a sentence in multiple\nlanguages, we create a graph with words as nodes and alignment links as edges\nby aligning words for all language pairs. We then propagate node labels from\nsource to target using a Graph Neural Network augmented with transformer\nlayers. We show that our propagation creates training sets that allow us to\ntrain POS taggers for a diverse set of languages. When combined with enhanced\ncontextualized embeddings, our method achieves a new state-of-the-art for\nunsupervised POS tagging of low-resource languages.",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Ayyoob Imani",
      "Silvia Severini",
      "Masoud Jalili Sabet",
      "Fran\u00e7ois Yvon",
      "Hinrich Sch\u00fctze"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.09840"
  },
  {
    "id": "arXiv:2210.09843",
    "title": "BIOWISH: Biometric Recognition using Wearable Inertial Sensors detecting  Heart Activity",
    "abstract": "Wearable devices are increasingly used, thanks to the wide set of\napplications that can be deployed exploiting their ability to monitor physical\nactivity and health-related parameters. Their usage has been recently proposed\nto perform biometric recognition, leveraging on the uniqueness of the recorded\ntraits to generate discriminative identifiers. Most of the studies conducted on\nthis topic have considered signals derived from cardiac activity, detecting it\nmainly using electrical measurements thorugh electrocardiography, or optical\nrecordings employing photoplethysmography. In this paper we instead propose a\nBIOmetric recognition approach using Wearable Inertial Sensors detecting Heart\nactivity (BIOWISH). In more detail, we investigate the feasibility of\nexploiting mechanical measurements obtained through seismocardiography and\ngyrocardiography to recognize a person. Several feature extractors and\nclassifiers, including deep learning techniques relying on transfer learning\nand siamese training, are employed to derive distinctive characteristics from\nthe considered signals, and differentiate between legitimate and impostor\nsubjects. An multi-session database, comprising acquisitions taken from\nsubjects performing different activities, is employed to perform experimental\ntests simulating a verification system. The obtained results testify that\nidentifiers derived from measurements of chest vibrations, collected by\nwearable inertial sensors, could be employed to guarantee high recognition\nperformance, even when considering short-time recordings.",
    "descriptor": "",
    "authors": [
      "Emanuele Maiorana",
      "Chiara Romano",
      "Emiliano Schena",
      "Carlo Massaroni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.09843"
  },
  {
    "id": "arXiv:2210.09844",
    "title": "Performance evaluation of approximation algorithms for the minimum size  2-vertex strongly connected subgraph problem",
    "abstract": "Jaberi [7] presented approximation algorithms for the problem of computing a\nminimum size 2-vertex strongly biconnected subgraph in directed graphs. We have\nimplemented approximation algorithms presented in [7] and we have tested the\nimplementation on some graphs. The experimental results show that these\nalgorithms work well in practice.",
    "descriptor": "\nComments: 4 pages\n",
    "authors": [
      "Azzam Habib"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.09844"
  },
  {
    "id": "arXiv:2210.09846",
    "title": "Analyzing the Robustness of PECNet",
    "abstract": "Comprehensive robustness analysis of PECNet, a pedestrian trajectory\nprediction system for autonomous vehicles. A novel metric is introduced for\ndataset analysis and classification. Synthetic data augmentation techniques\nranging from Newtonian mechanics to Deep Reinforcement Learning based\nsimulations are used to improve and test the system. An improvement of 9.5%\nover state-of-the-art results is seen on the FDE while compromising ADE. We\nintroduce novel architectural changes using SIRENs for higher precision results\nto validate our robustness hypotheses. Additionally, we diagrammatically\npropose a novel multi-modal system for the same task.",
    "descriptor": "\nComments: 13 pages, 17 figures\n",
    "authors": [
      "Aryan Garg",
      "Renu M. Rameshan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.09846"
  },
  {
    "id": "arXiv:2210.09847",
    "title": "Multimodal Image Fusion based on Hybrid CNN-Transformer and Non-local  Cross-modal Attention",
    "abstract": "The fusion of images taken by heterogeneous sensors helps to enrich the\ninformation and improve the quality of imaging. In this article, we present a\nhybrid model consisting of a convolutional encoder and a Transformer-based\ndecoder to fuse multimodal images. In the encoder, a non-local cross-modal\nattention block is proposed to capture both local and global dependencies of\nmultiple source images. A branch fusion module is designed to adaptively fuse\nthe features of the two branches. We embed a Transformer module with linear\ncomplexity in the decoder to enhance the reconstruction capability of the\nproposed network. Qualitative and quantitative experiments demonstrate the\neffectiveness of the proposed method by comparing it with existing\nstate-of-the-art fusion models. The source code of our work is available at\nhttps://github.com/pandayuanyu/HCFusion.",
    "descriptor": "",
    "authors": [
      "Yu Yuan",
      "Jiaqi Wu",
      "Zhongliang Jing",
      "Henry Leung",
      "Han Pan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09847"
  },
  {
    "id": "arXiv:2210.09852",
    "title": "Scaling Adversarial Training to Large Perturbation Bounds",
    "abstract": "The vulnerability of Deep Neural Networks to Adversarial Attacks has fuelled\nresearch towards building robust models. While most Adversarial Training\nalgorithms aim at defending attacks constrained within low magnitude Lp norm\nbounds, real-world adversaries are not limited by such constraints. In this\nwork, we aim to achieve adversarial robustness within larger bounds, against\nperturbations that may be perceptible, but do not change human (or Oracle)\nprediction. The presence of images that flip Oracle predictions and those that\ndo not makes this a challenging setting for adversarial robustness. We discuss\nthe ideal goals of an adversarial defense algorithm beyond perceptual limits,\nand further highlight the shortcomings of naively extending existing training\nalgorithms to higher perturbation bounds. In order to overcome these\nshortcomings, we propose a novel defense, Oracle-Aligned Adversarial Training\n(OA-AT), to align the predictions of the network with that of an Oracle during\nadversarial training. The proposed approach achieves state-of-the-art\nperformance at large epsilon bounds (such as an L-inf bound of 16/255 on\nCIFAR-10) while outperforming existing defenses (AWP, TRADES, PGD-AT) at\nstandard bounds (8/255) as well.",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Sravanti Addepalli",
      "Samyak Jain",
      "Gaurang Sriramanan",
      "R.Venkatesh Babu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.09852"
  },
  {
    "id": "arXiv:2210.09857",
    "title": "Compositional Reasoning for Side-effectful Iterators and Iterator  Adapters",
    "abstract": "Iteration is a programming operation that traditionally refers to visiting\nthe elements of a data structure in sequence. However, modern programming\nsystems such as Rust, Java, and C# generalise iteration far beyond the\ntraditional use case. They allow iterators to be parameterised with\n(potentially side-effectful) closures and support the composition of iterators\nto form iterator chains, where each iterator in the chain consumes values from\nits predecessor and produces values for its successor. Such generalisations\npose three major challenges for modular specification and verification of\niterators and the client code using them: (1) How can parameterised iterators\nbe specified modularly and their (accumulated) side effects reasoned about? (2)\nHow can the behaviour of an iterator chain be derived from the specifications\nof its component iterators? (3) How can proofs about such iterators be\nautomated?\nWe present the first methodology for the modular specification and\nverification of advanced iteration idioms with side-effectful computations. It\naddresses the three challenges above using a combination of inductive two-state\ninvariants, higher-order closure contracts, and separation logic-like\nownership. We implement and our methodology in a state-of-the-art SMT-based\nRust verifier. Our evaluation shows that our methodology is sufficiently\nexpressive to handle advanced and idiomatic iteration idioms and requires\nmodest annotation overhead.",
    "descriptor": "",
    "authors": [
      "Aurel B\u00edl\u00fd",
      "Jonas Hansen",
      "Peter M\u00fcller",
      "Alexander J. Summers"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.09857"
  },
  {
    "id": "arXiv:2210.09864",
    "title": "Information-theoretic Characterizations of Generalization Error for the  Gibbs Algorithm",
    "abstract": "Various approaches have been developed to upper bound the generalization\nerror of a supervised learning algorithm. However, existing bounds are often\nloose and even vacuous when evaluated in practice. As a result, they may fail\nto characterize the exact generalization ability of a learning algorithm. Our\nmain contributions are exact characterizations of the expected generalization\nerror of the well-known Gibbs algorithm (a.k.a. Gibbs posterior) using\ndifferent information measures, in particular, the symmetrized KL information\nbetween the input training samples and the output hypothesis. Our result can be\napplied to tighten existing expected generalization error and PAC-Bayesian\nbounds. Our information-theoretic approach is versatile, as it also\ncharacterizes the generalization error of the Gibbs algorithm with a\ndata-dependent regularizer and that of the Gibbs algorithm in the asymptotic\nregime, where it converges to the standard empirical risk minimization\nalgorithm. Of particular relevance, our results highlight the role the\nsymmetrized KL information plays in controlling the generalization error of the\nGibbs algorithm.",
    "descriptor": "\nComments: under review. arXiv admin note: text overlap with arXiv:2107.13656, arXiv:2111.01635\n",
    "authors": [
      "Gholamali Aminian",
      "Yuheng Bu",
      "Laura Toni",
      "Miguel R. D. Rodrigues",
      "Gregory W. Wornell"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.09864"
  },
  {
    "id": "arXiv:2210.09866",
    "title": "Towards Efficient and Effective Self-Supervised Learning of Visual  Representations",
    "abstract": "Self-supervision has emerged as a propitious method for visual representation\nlearning after the recent paradigm shift from handcrafted pretext tasks to\ninstance-similarity based approaches. Most state-of-the-art methods enforce\nsimilarity between various augmentations of a given image, while some methods\nadditionally use contrastive approaches to explicitly ensure diverse\nrepresentations. While these approaches have indeed shown promising direction,\nthey require a significantly larger number of training iterations when compared\nto the supervised counterparts. In this work, we explore reasons for the slow\nconvergence of these methods, and further propose to strengthen them using\nwell-posed auxiliary tasks that converge significantly faster, and are also\nuseful for representation learning. The proposed method utilizes the task of\nrotation prediction to improve the efficiency of existing state-of-the-art\nmethods. We demonstrate significant gains in performance using the proposed\nmethod on multiple datasets, specifically for lower training epochs.",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Sravanti Addepalli",
      "Kaushal Bhogale",
      "Priyam Dey",
      "R.Venkatesh Babu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09866"
  },
  {
    "id": "arXiv:2210.09868",
    "title": "Non-Submodular Maximization via the Greedy Algorithm and the Effects of  Limited Information in Multi-Agent Execution",
    "abstract": "We provide theoretical bounds on the worst case performance of the greedy\nalgorithm in seeking to maximize a normalized, monotone, but not necessarily\nsubmodular objective function under a simple partition matroid constraint. We\nalso provide worst case bounds on the performance of the greedy algorithm in\nthe case that limited information is available at each planning step. We\nspecifically consider limited information as a result of unreliable\ncommunications during distributed execution of the greedy algorithm. We utilize\nnotions of curvature for normalized, monotone set functions to develop the\nbounds provided in this work. To demonstrate the value of the bounds provided\nin this work, we analyze a variant of the benefit of search objective function\nand show, using real-world data collected by an autonomous underwater vehicle,\nthat theoretical approximation guarantees are achieved despite\nnon-submodularity of the objective function.",
    "descriptor": "\nComments: 8 pages, 1 figure, 1 table\n",
    "authors": [
      "Benjamin Biggs",
      "James McMahon",
      "Philip Baldoni",
      "Daniel J. Stilwell"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.09868"
  },
  {
    "id": "arXiv:2210.09871",
    "title": "Sequence and Circle: Exploring the Relationship Between Patches",
    "abstract": "The vision transformer (ViT) has achieved state-of-the-art results in various\nvision tasks. It utilizes a learnable position embedding (PE) mechanism to\nencode the location of each image patch. However, it is presently unclear if\nthis learnable PE is really necessary and what its benefits are. This paper\nexplores two alternative ways of encoding the location of individual patches\nthat exploit prior knowledge about their spatial arrangement. One is called the\nsequence relationship embedding (SRE), and the other is called the circle\nrelationship embedding(CRE). Among them, the SRE considers all patches to be in\norder, and adjacent patches have the same interval distance. The CRE considers\nthe central patch as the center of the circle and measures the distance of the\nremaining patches from the center based on the four neighborhoods principle.\nMultiple concentric circles with different radii combine different patches.\nFinally, we implemented these two relations on three classic ViTs and tested\nthem on four popular datasets. Experiments show that SRE and CRE can replace PE\nto reduce the random learnable parameters while achieving the same performance.\nCombining SRE or CRE with PE gets better performance than only using PE.",
    "descriptor": "\nComments: 7 pages, 1 figure\n",
    "authors": [
      "Zhengyang Yu",
      "Jochen Triesch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09871"
  },
  {
    "id": "arXiv:2210.09873",
    "title": "Energy Efficient Train-Ground mmWave Mobile Relay System for High Speed  Railways",
    "abstract": "The rapid development of high-speed railways (HSRs) puts forward high\nrequirements on the corresponding communication system. Millimeter wave\n(mmWave) can be a promising solution due to its wide bandwidth, narrow beams,\nand rich spectrum resources. However, with the large number of antenna elements\nemployed, energy-efficient solutions at mmWave frequencies are in great demand.\nBased on a mmWave HSR communication system with multiple mobile relays (MRs) on\ntop of the train, a dynamic power-control scheme for train-ground\ncommunications is proposed. The scheme follows the regular movement\ncharacteristics of high-speed trains and considers three phases of train\nmovement: the train enters the cell, all MRs are covered in the cell, and the\ntrain leaves the cell. The transmit power is further refined according to the\nnumber of MRs in the cell and the distance between the train and the remote\nradio head. By minimizing energy consumption under the constraints of the\ntransmitted data and transmit power budget, the transmit power is allocated to\nmultiple MRs through the multiplier punitive function-based algorithm.\nComprehensive simulation results, where the velocity estimation error is taken\ninto account, are provided to demonstrate the effectiveness of the proposed\nscheme over several baseline schemes.",
    "descriptor": "\nComments: 13 pages, 12 figures, IEEE TGCN\n",
    "authors": [
      "Lei Wang",
      "Bo Ai",
      "Yong Niu",
      "Zhangdui Zhong",
      "Shiwen Mao",
      "Ning Wang",
      "Zhu Han"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.09873"
  },
  {
    "id": "arXiv:2210.09877",
    "title": "Towards Proactive Information Retrieval in Noisy Text with Wikipedia  Concepts",
    "abstract": "Extracting useful information from the user history to clearly understand\ninformational needs is a crucial feature of a proactive information retrieval\nsystem. Regarding understanding information and relevance, Wikipedia can\nprovide the background knowledge that an intelligent system needs. This work\nexplores how exploiting the context of a query using Wikipedia concepts can\nimprove proactive information retrieval on noisy text. We formulate two models\nthat use entity linking to associate Wikipedia topics with the relevance model.\nOur experiments around a podcast segment retrieval task demonstrate that there\nis a clear signal of relevance in Wikipedia concepts while a ranking model can\nimprove precision by incorporating them. We also find Wikifying the background\ncontext of a query can help disambiguate the meaning of the query, further\nhelping proactive information retrieval.",
    "descriptor": "\nComments: To be published at the First Workshop on Proactive and Agent-Supported Information Retrieval at CIKM 2022\n",
    "authors": [
      "Tabish Ahmed",
      "Sahan Bulathwela"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2210.09877"
  },
  {
    "id": "arXiv:2210.09879",
    "title": "Unsupervised visualization of image datasets using contrastive learning",
    "abstract": "Visualization methods based on the nearest neighbor graph, such as t-SNE or\nUMAP, are widely used for visualizing high-dimensional data. Yet, these\napproaches only produce meaningful results if the nearest neighbors themselves\nare meaningful. For images represented in pixel space this is not the case, as\ndistances in pixel space are often not capturing our sense of similarity and\ntherefore neighbors are not semantically close. This problem can be\ncircumvented by self-supervised approaches based on contrastive learning, such\nas SimCLR, relying on data augmentation to generate implicit neighbors, but\nthese methods do not produce two-dimensional embeddings suitable for\nvisualization. Here, we present a new method, called t-SimCNE, for unsupervised\nvisualization of image data. T-SimCNE combines ideas from contrastive learning\nand neighbor embeddings, and trains a parametric mapping from the\nhigh-dimensional pixel space into two dimensions. We show that the resulting 2D\nembeddings achieve classification accuracy comparable to the state-of-the-art\nhigh-dimensional SimCLR representations, thus faithfully capturing semantic\nrelationships. Using t-SimCNE, we obtain informative visualizations of the\nCIFAR-10 and CIFAR-100 datasets, showing rich cluster structure and\nhighlighting artifacts and outliers.",
    "descriptor": "",
    "authors": [
      "Jan Niklas B\u00f6hm",
      "Philipp Berens",
      "Dmitry Kobak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.09879"
  },
  {
    "id": "arXiv:2210.09880",
    "title": "Graphs, Constraints, and Search for the Abstraction and Reasoning Corpus",
    "abstract": "The Abstraction and Reasoning Corpus (ARC) aims at benchmarking the\nperformance of general artificial intelligence algorithms. The ARC's focus on\nbroad generalization and few-shot learning has made it impossible to solve\nusing pure machine learning. A more promising approach has been to perform\nprogram synthesis within an appropriately designed Domain Specific Language\n(DSL). However, these too have seen limited success. We propose Abstract\nReasoning with Graph Abstractions (ARGA), a new object-centric framework that\nfirst represents images using graphs and then performs a search for a correct\nprogram in a DSL that is based on the abstracted graph space. The complexity of\nthis combinatorial search is tamed through the use of constraint acquisition,\nstate hashing, and Tabu search. An extensive set of experiments demonstrates\nthe promise of ARGA in tackling some of the complicated tasks of the ARC rather\nefficiently, producing programs that are correct and easy to understand.",
    "descriptor": "\nComments: 9 pages, 5 figures\n",
    "authors": [
      "Yudong Xu",
      "Elias B. Khalil",
      "Scott Sanner"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.09880"
  },
  {
    "id": "arXiv:2210.09881",
    "title": "Random Orthogonalization for Federated Learning in Massive MIMO Systems",
    "abstract": "We propose a novel communication design, termed random orthogonalization, for\nfederated learning (FL) in a massive multiple-input and multiple-output (MIMO)\nwireless system. The key novelty of random orthogonalization comes from the\ntight coupling of FL and two unique characteristics of massive MIMO -- channel\nhardening and favorable propagation. As a result, random orthogonalization can\nachieve natural over-the-air model aggregation without requiring transmitter\nside channel state information (CSI) for the uplink phase of FL, while\nsignificantly reducing the channel estimation overhead at the receiver. We\nextend this principle to the downlink communication phase and develop a simple\nbut highly effective model broadcast method for FL. We also relax the massive\nMIMO assumption by proposing an enhanced random orthogonalization design for\nboth uplink and downlink FL communications, that does not rely on channel\nhardening or favorable propagation. Theoretical analyses with respect to both\ncommunication and machine learning performance are carried out. In particular,\nan explicit relationship among the convergence rate, the number of clients, and\nthe number of antennas is established. Experimental results validate the\neffectiveness and efficiency of random orthogonalization for FL in massive\nMIMO.",
    "descriptor": "\nComments: 31 pages, 7 figures, submitted for possible journal publication\n",
    "authors": [
      "Xizixiang Wei",
      "Cong Shen",
      "Jing Yang",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.09881"
  },
  {
    "id": "arXiv:2210.09887",
    "title": "MotionDeltaCNN: Sparse CNN Inference of Frame Differences in Moving  Camera Videos",
    "abstract": "Convolutional neural network inference on video input is computationally\nexpensive and has high memory bandwidth requirements. Recently, researchers\nmanaged to reduce the cost of processing upcoming frames by only processing\npixels that changed significantly. Using sparse convolutions, the sparsity of\nframe differences can be translated to speedups on current inference devices.\nHowever, previous work was relying on static cameras. Moving cameras add new\nchallenges in how to fuse newly unveiled image regions with already processed\nregions efficiently to minimize the update rate - without increasing memory\noverhead and without knowing the camera extrinsics of future frames. In this\nwork, we propose MotionDeltaCNN, a CNN framework that supports moving cameras\nand variable resolution input. We propose a spherical buffer which enables\nseamless fusion of newly unveiled regions and previously processed regions -\nwithout increasing the memory footprint. Our evaluations show that we\noutperform previous work significantly by explicitly adding support for moving\ncamera input.",
    "descriptor": "",
    "authors": [
      "Mathias Parger",
      "Chengcheng Tang",
      "Christopher D. Twigg",
      "Cem Keskin",
      "Robert Wang",
      "Markus Steinberger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09887"
  },
  {
    "id": "arXiv:2210.09890",
    "title": "IntTower: the Next Generation of Two-Tower Model for Pre-Ranking System",
    "abstract": "Scoring a large number of candidates precisely in several milliseconds is\nvital for industrial pre-ranking systems. Existing pre-ranking systems\nprimarily adopt the \\textbf{two-tower} model since the ``user-item decoupling\narchitecture'' paradigm is able to balance the \\textit{efficiency} and\n\\textit{effectiveness}. However, the cost of high efficiency is the neglect of\nthe potential information interaction between user and item towers, hindering\nthe prediction accuracy critically. In this paper, we show it is possible to\ndesign a two-tower model that emphasizes both information interactions and\ninference efficiency. The proposed model, IntTower (short for\n\\textit{Interaction enhanced Two-Tower}), consists of Light-SE, FE-Block and\nCIR modules. Specifically, lightweight Light-SE module is used to identify the\nimportance of different features and obtain refined feature representations in\neach tower. FE-Block module performs fine-grained and early feature\ninteractions to capture the interactive signals between user and item towers\nexplicitly and CIR module leverages a contrastive interaction regularization to\nfurther enhance the interactions implicitly. Experimental results on three\npublic datasets show that IntTower outperforms the SOTA pre-ranking models\nsignificantly and even achieves comparable performance in comparison with the\nranking models. Moreover, we further verify the effectiveness of IntTower on a\nlarge-scale advertisement pre-ranking system. The code of IntTower is publicly\navailable\\footnote{https://github.com/archersama/IntTower}",
    "descriptor": "\nComments: Accept by CIKM 2022 & DLP-KDD best paper\n",
    "authors": [
      "Xiangyang Li",
      "Bo Chen",
      "HuiFeng Guo",
      "Jingjie Li",
      "Chenxu Zhu",
      "Xiang Long",
      "Sujian Li",
      "Yichao Wang",
      "Wei Guo",
      "Longxia Mao",
      "Jinxing Liu",
      "Zhenhua Dong",
      "Ruiming Tang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.09890"
  },
  {
    "id": "arXiv:2210.09894",
    "title": "Taxonomy of Abstractive Dialogue Summarization: Scenarios, Approaches  and Future Directions",
    "abstract": "Abstractive dialogue summarization is to generate a concise and fluent\nsummary covering the salient information in a dialogue among two or more\ninterlocutors. It has attracted great attention in recent years based on the\nmassive emergence of social communication platforms and an urgent requirement\nfor efficient dialogue information understanding and digestion. Different from\nnews or articles in traditional document summarization, dialogues bring unique\ncharacteristics and additional challenges, including different language styles\nand formats, scattered information, flexible discourse structures and unclear\ntopic boundaries. This survey provides a comprehensive investigation on\nexisting work for abstractive dialogue summarization from scenarios, approaches\nto evaluations. It categorizes the task into two broad categories according to\nthe type of input dialogues, i.e., open-domain and task-oriented, and presents\na taxonomy of existing techniques in three directions, namely, injecting\ndialogue features, designing auxiliary training tasks and using additional\ndata.A list of datasets under different scenarios and widely-accepted\nevaluation metrics are summarized for completeness. After that, the trends of\nscenarios and techniques are summarized, together with deep insights on\ncorrelations between extensively exploited features and different scenarios.\nBased on these analyses, we recommend future directions including more\ncontrolled and complicated scenarios, technical innovations and comparisons,\npublicly available datasets in special domains, etc.",
    "descriptor": "\nComments: Under review at ACM Computing Surveys (CSUR), submitted in January 2022\n",
    "authors": [
      "Qi Jia",
      "Siyu Ren",
      "Yizhu Liu",
      "Kenny Q. Zhu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.09894"
  },
  {
    "id": "arXiv:2210.09899",
    "title": "First Order Logic on Pathwidth Revisited Again",
    "abstract": "Courcelle's celebrated theorem states that all MSO-expressible properties can\nbe decided in linear time on graphs of bounded treewidth. Unfortunately, the\nhidden constant implied by this theorem is a tower of exponentials whose height\nincreases with each quantifier alternation in the formula. More devastatingly,\nthis cannot be improved, under standard assumptions, even if we consider the\nmuch more restricted problem of deciding FO-expressible properties on trees.\nIn this paper we revisit this well-studied topic and identify a natural\nspecial case where the dependence of Courcelle's theorem can, in fact, be\nimproved. Specifically, we show that all FO-expressible properties can be\ndecided with an elementary dependence on the input formula, if the input graph\nhas bounded pathwidth (rather than treewidth). This is a rare example of\ntreewidth and pathwidth having different complexity behaviors. Our result is\nalso in sharp contrast with MSO logic on graphs of bounded pathwidth, where it\nis known that the dependence has to be non-elementary, under standard\nassumptions. Our work builds upon, and generalizes, a corresponding\nmeta-theorem by Gajarsk{\\'{y}} and Hlin{\\v{e}}n{\\'{y}} for the more restricted\nclass of graphs of bounded tree-depth.",
    "descriptor": "",
    "authors": [
      "Michael Lampis"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.09899"
  },
  {
    "id": "arXiv:2210.09900",
    "title": "SA-DNet: A on-demand semantic object registration network adapting to  non-rigid deformation",
    "abstract": "As an essential processing step before the fusing of infrared and visible\nimages, the performance of image registration determines whether the two images\ncan be fused at correct spatial position. In the actual scenario, the varied\nimaging devices may lead to a change in perspective or time gap between shots,\nmaking significant non-rigid spatial relationship in infrared and visible\nimages. Even if a large number of feature points are matched, the registration\naccuracy may still be inadequate, affecting the result of image fusion and\nother vision tasks. To alleviate this problem, we propose a Semantic-Aware\non-Demand registration network (SA-DNet), which mainly purpose is to confine\nthe feature matching process to the semantic region of interest (sROI) by\ndesigning semantic-aware module (SAM) and HOL-Deep hybrid matching module\n(HDM). After utilizing TPS to transform infrared and visible images based on\nthe corresponding feature points in sROI, the registered images are fused using\nimage fusion module (IFM) to achieve a fully functional registration and fusion\nnetwork. Moreover, we point out that for different demands, this type of\napproach allows us to select semantic objects for feature matching as needed\nand accomplishes task-specific registration based on specific requirements. To\ndemonstrate the robustness of SA-DNet for non-rigid distortions, we conduct\nextensive experiments by comparing SA-DNet with five state-of-the-art infrared\nand visible image feature matching methods, and the experimental results show\nthat our method adapts better to the presence of non-rigid distortions in the\nimages and provides semantically well-registered images.",
    "descriptor": "\nComments: 15 pages, 12 figures\n",
    "authors": [
      "Housheng Xie",
      "Junhui Qiu",
      "Yang Yang",
      "Yukuan Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09900"
  },
  {
    "id": "arXiv:2210.09902",
    "title": "Successor Sets of Discrete-time Nonlinear Systems Using Hybrid Zonotopes",
    "abstract": "This paper presents identities for calculating over-approximated successor\nsets of discrete-time nonlinear systems using hybrid zonotopes. The proposed\ntechnique extends the state-update set construct, previously developed for\nlinear hybrid systems, to nonlinear systems. Forward reachability of nonlinear\nsystems can then be performed using only projection, intersection, and\nCartesian product set operations with the state-update set. It is shown that\nuse of an over-approximation of the state-update set yields over-approximations\nof successor sets. A technique to over-approximate a nonlinear function using a\nspecial ordered set approximation, equivalently represented as a hybrid\nzonotope, is then presented. A numerical example of a nonlinear system\ncontrolled by a piecewise-affine control law demonstrates that the approach\nprovides a computationally-efficient and tight over-approximation of the\nclosed-loop reachable set dynamics.",
    "descriptor": "",
    "authors": [
      "Jacob A. Siefert",
      "Trevor J. Bird",
      "Justin P. Koeln",
      "Neera Jain",
      "Herschel C. Pangborn"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.09902"
  },
  {
    "id": "arXiv:2210.09903",
    "title": "Online Convex Optimization with Unbounded Memory",
    "abstract": "Online convex optimization (OCO) is a widely used framework in online\nlearning. In each round, the learner chooses a decision in some convex set and\nan adversary chooses a convex loss function, and then the learner suffers the\nloss associated with their chosen decision. However, in many of the motivating\napplications the loss of the learner depends not only on the current decision\nbut on the entire history of decisions until that point. The OCO framework and\nexisting generalizations thereof fail to capture this. In this work we\nintroduce a generalization of the OCO framework, ``Online Convex Optimization\nwith Unbounded Memory'', that captures long-term dependence on past decisions.\nWe introduce the notion of $p$-effective memory capacity, $H_p$, that\nquantifies the maximum influence of past decisions on current losses. We prove\na $O(\\sqrt{H_1 T})$ policy regret bound and a stronger $O(\\sqrt{H_p T})$ policy\nregret bound under mild additional assumptions. These bounds are optimal in\nterms of their dependence on the time horizon $T$. We show the broad\napplicability of our framework by using it to derive regret bounds, and to\nsimplify existing regret bound derivations, for a variety of online learning\nproblems including an online variant of performative prediction and online\nlinear control.",
    "descriptor": "",
    "authors": [
      "Raunak Kumar",
      "Sarah Dean",
      "Robert D. Kleinberg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.09903"
  },
  {
    "id": "arXiv:2210.09904",
    "title": "MaSS: Multi-attribute Selective Suppression",
    "abstract": "The recent rapid advances in machine learning technologies largely depend on\nthe vast richness of data available today, in terms of both the quantity and\nthe rich content contained within. For example, biometric data such as images\nand voices could reveal people's attributes like age, gender, sentiment, and\norigin, whereas location/motion data could be used to infer people's activity\nlevels, transportation modes, and life habits. Along with the new services and\napplications enabled by such technological advances, various governmental\npolicies are put in place to regulate such data usage and protect people's\nprivacy and rights. As a result, data owners often opt for simple data\nobfuscation (e.g., blur people's faces in images) or withholding data\naltogether, which leads to severe data quality degradation and greatly limits\nthe data's potential utility.\nAiming for a sophisticated mechanism which gives data owners fine-grained\ncontrol while retaining the maximal degree of data utility, we propose\nMulti-attribute Selective Suppression, or MaSS, a general framework for\nperforming precisely targeted data surgery to simultaneously suppress any\nselected set of attributes while preserving the rest for downstream machine\nlearning tasks. MaSS learns a data modifier through adversarial games between\ntwo sets of networks, where one is aimed at suppressing selected attributes,\nand the other ensures the retention of the rest of the attributes via general\ncontrastive loss as well as explicit classification metrics. We carried out an\nextensive evaluation of our proposed method using multiple datasets from\ndifferent domains including facial images, voice audio, and video clips, and\nobtained promising results in MaSS' generalizability and capability of\nsuppressing targeted attributes without negatively affecting the data's\nusability in other downstream ML tasks.",
    "descriptor": "",
    "authors": [
      "Chun-Fu Chen",
      "Shaohan Hu",
      "Zhonghao Shi",
      "Prateek Gulati",
      "Bill Moriarty",
      "Marco Pistoia",
      "Vincenzo Piuri",
      "Pierangela Samarati"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.09904"
  },
  {
    "id": "arXiv:2210.09906",
    "title": "Exploring players' experience of humor and snark in a grade 3-6 history  practices game",
    "abstract": "In this paper we use an existing history learning game with an active\naudience as a research platform for exploring how humor and \"snarkiness\" in the\ndialog script affect students' progression and attitudes about the game. We\nconducted a 2x2 randomized experiment with 11,804 anonymous 3rd-6th grade\nstudents. Using one-way ANOVA and Kruskall-Wallis tests, we find that changes\nto the script produced measurable results in the self-reported perceived humor\nof the game and the likeability of the player character. Different scripts did\nnot produce significant differences in player completion of the game, or how\nmuch of the game was played. Perceived humor and enjoyment of the game and its\nmain character contributed significantly to progress in the game, as did\nself-perceived reading skill.",
    "descriptor": "\nComments: Presented at Games, Learning & Society (GLS) 2022 conference. Irvine, CA\n",
    "authors": [
      "David J. Gagnon",
      "Ryan S. Baker",
      "Sarah Gagnon",
      "Luke Swanson",
      "Nick Spevacek",
      "Juliana Andres",
      "Erik Harpstead",
      "Jennifer Scianna",
      "Stefan Slater",
      "Maria O.C.Z. San Pedro"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.09906"
  },
  {
    "id": "arXiv:2210.09909",
    "title": "Uncertainty estimation for out-of-distribution detection in  computational histopathology",
    "abstract": "In computational histopathology algorithms now outperform humans on a range\nof tasks, but to date none are employed for automated diagnoses in the clinic.\nBefore algorithms can be involved in such high-stakes decisions they need to\n\"know when they don't know\", i.e., they need to estimate their predictive\nuncertainty. This allows them to defer potentially erroneous predictions to a\nhuman pathologist, thus increasing their safety. Here, we evaluate the\npredictive performance and calibration of several uncertainty estimation\nmethods on clinical histopathology data. We show that a distance-aware\nuncertainty estimation method outperforms commonly used approaches, such as\nMonte Carlo dropout and deep ensembles. However, we observe a drop in\npredictive performance and calibration on novel samples across all uncertainty\nestimation methods tested. We also investigate the use of uncertainty\nthresholding to reject out-of-distribution samples for selective prediction. We\ndemonstrate the limitations of this approach and suggest areas for future\nresearch.",
    "descriptor": "\nComments: 8 pages, 3 figures\n",
    "authors": [
      "Lea Goetz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09909"
  },
  {
    "id": "arXiv:2210.09911",
    "title": "Leveraging Cluster Analysis to Understand Educational Game Player  Experiences and Support Design",
    "abstract": "The ability for an educational game designer to understand their audience's\nplay styles and resulting experience is an essential tool for improving their\ngame's design. As a game is subjected to large-scale player testing, the\ndesigners require inexpensive, automated methods for categorizing patterns of\nplayer-game interactions. In this paper we present a simple, reusable process\nusing best practices for data clustering, feasible for use within a small\neducational game studio. We utilize the method to analyze a real-time strategy\ngame, processing game telemetry data to determine categories of players based\non their in-game actions, the feedback they received, and their progress\nthrough the game. An interpretive analysis of these clusters results in\nactionable insights for the game's designers.",
    "descriptor": "\nComments: Presented at Games, Learning & Society (GLS) 2022 Conference. Irving, CA\n",
    "authors": [
      "Luke Swanson",
      "David Gagnon",
      "Jennifer Scianna",
      "John McCloskey",
      "Nicholas Spevacek",
      "Stefan Slater",
      "Erik Harpstead"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2210.09911"
  },
  {
    "id": "arXiv:2210.09914",
    "title": "Computing MEMs on Repetitive Text Collections",
    "abstract": "We consider the problem of computing the Maximal Exact Matches (MEMs) of a\ngiven pattern $P[1..m]$ on a large repetitive text collection $T[1..n]$, which\nis represented as a (hopefully much smaller) run-length context-free grammar of\nsize $g_{rl}$. We show that the problem can be solved in time $O(m^2\n\\log^\\epsilon n)$, for any constant $\\epsilon > 0$, on a data structure of size\n$O(g_{rl})$. Further, on a locally consistent grammar of size\n$O(\\delta\\log\\frac{n}{\\delta})$, the time decreases to $O(m\\log m(\\log m +\n\\log^\\epsilon n))$. The value $\\delta$ is a function of the substring\ncomplexity of $T$ and $\\Omega(\\delta\\log\\frac{n}{\\delta})$ is a tight lower\nbound on the compressibility of repetitive texts $T$, so our structure has\noptimal size in terms of $n$ and $\\delta$.",
    "descriptor": "",
    "authors": [
      "Gonzalo Navarro"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.09914"
  },
  {
    "id": "arXiv:2210.09916",
    "title": "Mid-attribute speaker generation using optimal-transport-based  interpolation of Gaussian mixture models",
    "abstract": "In this paper, we propose a method for intermediating multiple speakers'\nattributes and diversifying their voice characteristics in ``speaker\ngeneration,'' an emerging task that aims to synthesize a nonexistent speaker's\nnaturally sounding voice. The conventional TacoSpawn-based speaker generation\nmethod represents the distributions of speaker embeddings by Gaussian mixture\nmodels (GMMs) conditioned with speaker attributes. Although this method enables\nthe sampling of various speakers from the speaker-attribute-aware GMMs, it is\nnot yet clear whether the learned distributions can represent speakers with an\nintermediate attribute (i.e., mid-attribute). To this end, we propose an\noptimal-transport-based method that interpolates the learned GMMs to generate\nnonexistent speakers with mid-attribute (e.g., gender-neutral) voices. We\nempirically validate our method and evaluate the naturalness of synthetic\nspeech and the controllability of two speaker attributes: gender and language\nfluency. The evaluation results show that our method can control the generated\nspeakers' attributes by a continuous scalar value without statistically\nsignificant degradation of speech naturalness.",
    "descriptor": "\nComments: Submitted to ICASSP 2023. Demo: this https URL\n",
    "authors": [
      "Aya Watanabe",
      "Shinnosuke Takamichi",
      "Yuki Saito",
      "Detai Xin",
      "Hiroshi Saruwatari"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.09916"
  },
  {
    "id": "arXiv:2210.09917",
    "title": "Controllable Fake Document Infilling for Cyber Deception",
    "abstract": "Recent works in cyber deception study how to deter malicious intrusion by\ngenerating multiple fake versions of a critical document to impose costs on\nadversaries who need to identify the correct information. However, existing\napproaches are context-agnostic, resulting in sub-optimal and unvaried outputs.\nWe propose a novel context-aware model, Fake Document Infilling (FDI), by\nconverting the problem to a controllable mask-then-infill procedure. FDI masks\nimportant concepts of varied lengths in the document, then infills a realistic\nbut fake alternative considering both the previous and future contexts. We\nconduct comprehensive evaluations on technical documents and news stories.\nResults show that FDI outperforms the baselines in generating highly believable\nfakes with moderate modification to protect critical information and deceive\nadversaries.",
    "descriptor": "\nComments: Accepted to Findings of EMNLP 2022\n",
    "authors": [
      "Yibo Hu",
      "Yu Lin",
      "Erick Skorupa Parolin",
      "Latifur Khan",
      "Kevin Hamlen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.09917"
  },
  {
    "id": "arXiv:2210.09918",
    "title": "Online Damage Recovery for Physical Robots with Hierarchical  Quality-Diversity",
    "abstract": "In real-world environments, robots need to be resilient to damages and robust\nto unforeseen scenarios. Quality-Diversity (QD) algorithms have been\nsuccessfully used to make robots adapt to damages in seconds by leveraging a\ndiverse set of learned skills. A high diversity of skills increases the chances\nof a robot to succeed at overcoming new situations since there are more\npotential alternatives to solve a new task.However, finding and storing a large\nbehavioural diversity of multiple skills often leads to an increase in\ncomputational complexity. Furthermore, robot planning in a large skill space is\nan additional challenge that arises with an increased number of skills.\nHierarchical structures can help reducing this search and storage complexity by\nbreaking down skills into primitive skills. In this paper, we introduce the\nHierarchical Trial and Error algorithm, which uses a hierarchical behavioural\nrepertoire to learn diverse skills and leverages them to make the robot adapt\nquickly in the physical world. We show that the hierarchical decomposition of\nskills enables the robot to learn more complex behaviours while keeping the\nlearning of the repertoire tractable. Experiments with a hexapod robot show\nthat our method solves a maze navigation tasks with 20% less actions in\nsimulation, and 43% less actions in the physical world, for the most\nchallenging scenarios than the best baselines while having 78% less complete\nfailures.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2204.05726\n",
    "authors": [
      "Maxime Allard",
      "Sim\u00f3n C. Smith",
      "Konstantinos Chatzilygeroudis",
      "Bryan Lim",
      "Antoine Cully"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2210.09918"
  },
  {
    "id": "arXiv:2210.09919",
    "title": "Dense FixMatch: a simple semi-supervised learning method for pixel-wise  prediction tasks",
    "abstract": "We propose Dense FixMatch, a simple method for online semi-supervised\nlearning of dense and structured prediction tasks combining pseudo-labeling and\nconsistency regularization via strong data augmentation. We enable the\napplication of FixMatch in semi-supervised learning problems beyond image\nclassification by adding a matching operation on the pseudo-labels. This allows\nus to still use the full strength of data augmentation pipelines, including\ngeometric transformations. We evaluate it on semi-supervised semantic\nsegmentation on Cityscapes and Pascal VOC with different percentages of labeled\ndata and ablate design choices and hyper-parameters. Dense FixMatch\nsignificantly improves results compared to supervised learning using only\nlabeled data, approaching its performance with 1/4 of the labeled samples.",
    "descriptor": "",
    "authors": [
      "Miquel Mart\u00ed i Rabad\u00e1n",
      "Alessandro Pieropan",
      "Hossein Azizpour",
      "Atsuto Maki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09919"
  },
  {
    "id": "arXiv:2210.09921",
    "title": "Finite-time analysis of single-timescale actor-critic",
    "abstract": "Despite the great empirical success of actor-critic methods, its finite-time\nconvergence is still poorly understood in its most practical form. In\nparticular, the analysis of single-timescale actor-critic presents significant\nchallenges due to the highly inaccurate critic estimation and the complex error\npropagation dynamics over iterations. Existing works on analyzing\nsingle-timescale actor-critic only focus on the i.i.d. sampling or tabular\nsetting for simplicity, which is rarely the case in practical applications. We\nconsider the more practical online single-timescale actor-critic algorithm on\ncontinuous state space, where the critic is updated with a single Markovian\nsample per actor step. We prove that the online single-timescale actor-critic\nmethod is guaranteed to find an $\\epsilon$-approximate stationary point with\n$\\widetilde{\\mathcal{O}}(\\epsilon^{-2})$ sample complexity under standard\nassumptions, which can be further improved to $\\mathcal{O}(\\epsilon^{-2})$\nunder i.i.d. sampling. Our analysis develops a novel framework that evaluates\nand controls the error propagation between actor and critic in a systematic\nway. To our knowledge, this is the first finite-time analysis for online\nsingle-timescale actor-critic method. Overall, our results compare favorably to\nthe existing literature on analyzing actor-critic in terms of considering the\nmost practical settings and requiring weaker assumptions.",
    "descriptor": "",
    "authors": [
      "Xuyang Chen",
      "Lin Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.09921"
  },
  {
    "id": "arXiv:2210.09922",
    "title": "Few-Shot Learning of Compact Models via Task-Specific Meta Distillation",
    "abstract": "We consider a new problem of few-shot learning of compact models.\nMeta-learning is a popular approach for few-shot learning. Previous work in\nmeta-learning typically assumes that the model architecture during\nmeta-training is the same as the model architecture used for final deployment.\nIn this paper, we challenge this basic assumption. For final deployment, we\noften need the model to be small. But small models usually do not have enough\ncapacity to effectively adapt to new tasks. In the mean time, we often have\naccess to the large dataset and extensive computing power during meta-training\nsince meta-training is typically performed on a server. In this paper, we\npropose task-specific meta distillation that simultaneously learns two models\nin meta-learning: a large teacher model and a small student model. These two\nmodels are jointly learned during meta-training. Given a new task during\nmeta-testing, the teacher model is first adapted to this task, then the adapted\nteacher model is used to guide the adaptation of the student model. The adapted\nstudent model is used for final deployment. We demonstrate the effectiveness of\nour approach in few-shot image classification using model-agnostic\nmeta-learning (MAML). Our proposed method outperforms other alternatives on\nseveral benchmark datasets.",
    "descriptor": "\nComments: This paper has been accepted by WACV'2023\n",
    "authors": [
      "Yong Wu",
      "Shekhor Chanda",
      "Mehrdad Hosseinzadeh",
      "Zhi Liu",
      "Yang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09922"
  },
  {
    "id": "arXiv:2210.09923",
    "title": "Zero-shot Point Cloud Segmentation by Transferring Geometric Primitives",
    "abstract": "We investigate transductive zero-shot point cloud semantic segmentation in\nthis paper, where unseen class labels are unavailable during training.\nActually, the 3D geometric elements are essential cues to reason the 3D object\ntype. If two categories share similar geometric primitives, they also have\nsimilar semantic representations. Based on this consideration, we propose a\nnovel framework to learn the geometric primitives shared in seen and unseen\ncategories' objects, where the learned geometric primitives are served for\ntransferring knowledge from seen to unseen categories. Specifically, a group of\nlearnable prototypes automatically encode geometric primitives via\nback-propagation. Then, the point visual representation is formulated as the\nsimilarity vector of its feature to the prototypes, which implies semantic cues\nfor both seen and unseen categories. Besides, considering a 3D object composed\nof multiple geometric primitives, we formulate the semantic representation as a\nmixture-distributed embedding for the fine-grained match of visual\nrepresentation. In the end, to effectively learn the geometric primitives and\nalleviate the misclassification issue, we propose a novel unknown-aware infoNCE\nloss to align the visual and semantic representation. As a result, guided by\nsemantic representations, the network recognizes the novel object represented\nwith geometric primitives. Extensive experiments show that our method\nsignificantly outperforms other state-of-the-art methods in the harmonic\nmean-intersection-over-union (hIoU), with the improvement of 17.8%, 30.4% and\n9.2% on S3DIS, ScanNet and SemanticKITTI datasets, respectively. Codes will be\nreleased.",
    "descriptor": "",
    "authors": [
      "Runnan Chen",
      "Xinge Zhu",
      "Nenglun Chen",
      "Wei Li",
      "Yuexin Ma",
      "Ruigang Yang",
      "Wenping Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09923"
  },
  {
    "id": "arXiv:2210.09924",
    "title": "Predicting Winning Regions in Parity Games via Graph Neural Networks  (Extended Abstract)",
    "abstract": "Solving parity games is a major building block for numerous applications in\nreactive program verification and synthesis. While there exist efficient\napproaches to solving parity games in practice, none of these have a polynomial\nworst-case runtime complexity. We present a incomplete approach to determining\nthe winning regions of parity games via graph neural networks. Our evaluation\non 900 randomly generated parity games shows that this approach is efficient in\npractice. It moreover correctly determines the winning regions of ~60% of the\ngames in our data set and only incurs minor errors in the remaining ones.",
    "descriptor": "\nComments: 4 pages, extended abstract\n",
    "authors": [
      "Tobias Hecking",
      "Alexander Weinert"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09924"
  },
  {
    "id": "arXiv:2210.09925",
    "title": "Generalizing in the Real World with Representation Learning",
    "abstract": "Machine learning (ML) formalizes the problem of getting computers to learn\nfrom experience as optimization of performance according to some metric(s) on a\nset of data examples. This is in contrast to requiring behaviour specified in\nadvance (e.g. by hard-coded rules). Formalization of this problem has enabled\ngreat progress in many applications with large real-world impact, including\ntranslation, speech recognition, self-driving cars, and drug discovery. But\npractical instantiations of this formalism make many assumptions - for example,\nthat data are i.i.d.: independent and identically distributed - whose soundness\nis seldom investigated. And in making great progress in such a short time, the\nfield has developed many norms and ad-hoc standards, focused on a relatively\nsmall range of problem settings. As applications of ML, particularly in\nartificial intelligence (AI) systems, become more pervasive in the real world,\nwe need to critically examine these assumptions, norms, and problem settings,\nas well as the methods that have become de-facto standards. There is much we\nstill do not understand about how and why deep networks trained with stochastic\ngradient descent are able to generalize as well as they do, why they fail when\nthey do, and how they will perform on out-of-distribution data. In this thesis\nI cover some of my work towards better understanding deep net generalization,\nidentify several ways assumptions and problem settings fail to generalize to\nthe real world, and propose ways to address those failures in practice.",
    "descriptor": "\nComments: PhD Thesis, Montreal Polytechnic\n",
    "authors": [
      "Tegan Maharaj"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.09925"
  },
  {
    "id": "arXiv:2210.09926",
    "title": "RAPO: An Adaptive Ranking Paradigm for Bilingual Lexicon Induction",
    "abstract": "Bilingual lexicon induction induces the word translations by aligning\nindependently trained word embeddings in two languages. Existing approaches\ngenerally focus on minimizing the distances between words in the aligned pairs,\nwhile suffering from low discriminative capability to distinguish the relative\norders between positive and negative candidates. In addition, the mapping\nfunction is globally shared by all words, whose performance might be hindered\nby the deviations in the distributions of different languages. In this work, we\npropose a novel ranking-oriented induction model RAPO to learn personalized\nmapping function for each word. RAPO is capable of enjoying the merits from the\nunique characteristics of a single word and the cross-language isomorphism\nsimultaneously. Extensive experimental results on public datasets including\nboth rich-resource and low-resource languages demonstrate the superiority of\nour proposal. Our code is publicly available in\n\\url{https://github.com/Jlfj345wf/RAPO}.",
    "descriptor": "\nComments: 9 pages, accepted by EMNLP 2022\n",
    "authors": [
      "Zhoujin Tian",
      "Chaozhuo Li",
      "Shuo Ren",
      "Zhiqiang Zuo",
      "Zengxuan Wen",
      "Xinyue Hu",
      "Xiao Han",
      "Haizhen Huang",
      "Denvy Deng",
      "Qi Zhang",
      "Xing Xie"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09926"
  },
  {
    "id": "arXiv:2210.09927",
    "title": "Research of an optimization model for servicing a network of ATMs and  information payment terminals",
    "abstract": "The steadily high demand for cash contributes to the expansion of the network\nof Bank payment terminals. To optimize the amount of cash in payment terminals,\nit is necessary to minimize the cost of servicing them and ensure that there\nare no excess funds in the network. The purpose of this work is to create a\ncash management system in the network of payment terminals. The article\ndiscusses the solution to the problem of determining the optimal amount of\nfunds to be loaded into the terminals, and the effective frequency of\ncollection, which allows to get additional income by investing the released\nfunds. The paper presents the results of predicting daily cash withdrawals at\nATMs using a triple exponential smoothing model, a recurrent neural network\nwith long short-term memory, and a model of singular spectrum analysis. These\nforecasting models allowed us to obtain a sufficient level of correct forecasts\nwith good accuracy and completeness. The results of forecasting cash\nwithdrawals were used to build a discrete optimal control model, which was used\nto develop an optimal schedule for adding funds to the payment terminal. It is\nproved that the efficiency and reliability of the proposed model is higher than\nthat of the classical Baumol-Tobin inventory management model: when tested on\nthe time series of three ATMs, the discrete optimal control model did not allow\nexhaustion of funds and allowed to earn on average 30% more than the classical\nmodel.",
    "descriptor": "\nComments: Convergent Cognitive Information Technologies. Convergent 2020. Communications in Computer and Information Science, in press, Springer, Cham. this http URL (12 pages, 12 figures)\n",
    "authors": [
      "G.A. Nigmatulin",
      "O.B. Chaganova"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Trading and Market Microstructure (q-fin.TR)"
    ],
    "url": "https://arxiv.org/abs/2210.09927"
  },
  {
    "id": "arXiv:2210.09928",
    "title": "Team OS's System for Dialogue Robot Competition 2022",
    "abstract": "This paper describes our dialogue robot system, OSbot, developed for Dialogue\nRobot Competition 2022. The dialogue flow is based on state transitions\ndescribed manually and the transition conditions use the results of keyword\nextraction and sentiment analysis. The transitions can be easily viewed and\nedited by managing them on a spreadsheet. The keyword extraction is based on\nnamed entity extraction and our predefined keyword set. The sentiment analysis\nis text-based and uses SVM, which was trained with the multimodal dialogue\ncorpus Hazumi. We quickly checked and edited a dialogue flow by using a logging\nfunction. In the competition's preliminary round, our system ended up in third\nplace.",
    "descriptor": "\nComments: This paper is part of the proceedings of the Dialogue Robot Competition 2022\n",
    "authors": [
      "Yuki Kubo",
      "Ryo Yanagimoto",
      "Hayato Futase",
      "Mikio Nakano",
      "Zhaojie Luo",
      "Kazunori Komatani"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.09928"
  },
  {
    "id": "arXiv:2210.09931",
    "title": "Compiling Petri Net Mutual Reachability in Presburger",
    "abstract": "Petri nets are a classical model of concurrency widely used and studied in\nformal verification with many applications in modeling and analyzing hardware\nand software, data bases, and reactive systems. The reachability problem is\ncentral since many other problems reduce to reachability questions. The\nreachability problem is known to be decidable but its complexity is extremely\nhigh (non primitive recursive). In 2011, a variant of the reachability problem,\ncalled the mutual reachability problem, that consists in deciding if two\nconfigurations are mutually reachable was proved to be exponential-space\ncomplete. Recently, this problem found several unexpected applications in\nparticular in the theory of population protocols. While the mutual reachability\nproblem is known to be definable in the Preburger arithmetic, the best known\nupper bound of such a formula was recently proved to be non-elementary (tower).\nIn this paper we provide a way to compile the mutual reachability relation of a\nPetri net with $d$ counters into a quantifier-free Presburger formula given as\na doubly exponential disjunction of $O(d)$ linear constraints of exponential\nsize. We also provide some first results about Presburger formulas encoding\nbottom configurations.",
    "descriptor": "",
    "authors": [
      "J\u00e9r\u00f4me Leroux"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.09931"
  },
  {
    "id": "arXiv:2210.09932",
    "title": "Making Science Simple: Corpora for the Lay Summarisation of Scientific  Literature",
    "abstract": "Lay summarisation aims to jointly summarise and simplify a given text, thus\nmaking its content more comprehensible to non-experts. Automatic approaches for\nlay summarisation can provide significant value in broadening access to\nscientific literature, enabling a greater degree of both interdisciplinary\nknowledge sharing and public understanding when it comes to research findings.\nHowever, current corpora for this task are limited in their size and scope,\nhindering the development of broadly applicable data-driven approaches. Aiming\nto rectify these issues, we present two novel lay summarisation datasets, PLOS\n(large-scale) and eLife (medium-scale), each of which contains biomedical\njournal articles alongside expert-written lay summaries. We provide a thorough\ncharacterisation of our lay summaries, highlighting differing levels of\nreadability and abstractiveness between datasets that can be leveraged to\nsupport the needs of different applications. Finally, we benchmark our datasets\nusing mainstream summarisation approaches and perform a manual evaluation with\ndomain experts, demonstrating their utility and casting light on the key\nchallenges of this task.",
    "descriptor": "\nComments: 16 pages, 9 figures. Accepted to EMNLP 2022\n",
    "authors": [
      "Tomas Goldsack",
      "Zhihao Zhang",
      "Chenghua Lin",
      "Carolina Scarton"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.09932"
  },
  {
    "id": "arXiv:2210.09933",
    "title": "Global Explanation of Tree-Ensembles Models Based on Item Response  Theory",
    "abstract": "Explainable Artificial Intelligence - XAI is aimed at studying and developing\ntechniques to explain black box models, that is, models that provide limited\nself-explanation of their predictions. In recent years, XAI researchers have\nbeen formalizing proposals and developing new measures to explain how these\nmodels make specific predictions. In previous studies, evidence has been found\non how model (dataset and algorithm) complexity affects global explanations\ngenerated by XAI measures Ciu, Dalex, Eli5, Lofo, Shap and Skater, suggesting\nthat there is room for the development of a new XAI measure that builds on the\ncomplexity of the model. Thus, this research proposes a measure called\nExplainable based on Item Response Theory - eXirt, which is capable of\nexplaining tree-ensemble models by using the properties of Item Response Theory\n(IRT). For this purpose, a benchmark was created using 40 different datasets\nand 2 different algorithms (Random Forest and Gradient Boosting), thus\ngenerating 6 different explainability ranks using known XAI measures along with\n1 data purity rank and 1 rank of the measure eXirt, amounting to 8 global ranks\nfor each model, i.e., 640 ranks altogether. The results show that eXirt\ndisplayed different ranks than those of the other measures, which demonstrates\nthat the advocated methodology generates global explanations of tree-ensemble\nmodels that have not yet been explored, either for the more difficult models to\nexplain or even the easier ones.",
    "descriptor": "\nComments: 31 pages, 11 Figures, 3 Equations, 1 table\n",
    "authors": [
      "Jos\u00e9 Ribeiro",
      "Lucas Cardoso",
      "Ra\u00edssa Silva",
      "Vitor Cirilo",
      "N\u00edkolas Carneiro",
      "Ronnie Alves"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09933"
  },
  {
    "id": "arXiv:2210.09934",
    "title": "A Simple and Effective Method to Improve Zero-Shot Cross-Lingual  Transfer Learning",
    "abstract": "Existing zero-shot cross-lingual transfer methods rely on parallel corpora or\nbilingual dictionaries, which are expensive and impractical for low-resource\nlanguages. To disengage from these dependencies, researchers have explored\ntraining multilingual models on English-only resources and transferring them to\nlow-resource languages. However, its effect is limited by the gap between\nembedding clusters of different languages. To address this issue, we propose\nEmbedding-Push, Attention-Pull, and Robust targets to transfer English\nembeddings to virtual multilingual embeddings without semantic loss, thereby\nimproving cross-lingual transferability. Experimental results on mBERT and\nXLM-R demonstrate that our method significantly outperforms previous works on\nthe zero-shot cross-lingual text classification task and can obtain a better\nmultilingual alignment.",
    "descriptor": "\nComments: Published at COLING2022\n",
    "authors": [
      "Kunbo Ding",
      "Weijie Liu",
      "Yuejian Fang",
      "Weiquan Mao",
      "Zhe Zhao",
      "Tao Zhu",
      "Haoyan Liu",
      "Rong Tian",
      "Yiren Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.09934"
  },
  {
    "id": "arXiv:2210.09936",
    "title": "The smallest 5-chromatic tournament",
    "abstract": "A coloring of a digraph is a partition of its vertex set such that each class\ninduces a digraph with no directed cycles. A digraph is $k$-chromatic if $k$ is\nthe minimum number of classes in such partition, and a digraph is oriented if\nthere is at most one arc between each pair of vertices. Clearly, the smallest\n$k$-chromatic digraph is the complete digraph on $k$ vertices, but determining\nthe order of the smallest $k$-chromatic oriented graphs is a challenging\nproblem. It is known that the smallest $2$-, $3$- and $4$-chromatic oriented\ngraphs have $3$, $7$ and $11$ vertices, respectively. In 1994, Neumann-Lara\nconjectured that a smallest $5$-chromatic oriented graph has $17$ vertices. We\nsolve this conjecture and show that the correct order is $19$.",
    "descriptor": "",
    "authors": [
      "Thomas Bellitto",
      "Nicolas Bousquet",
      "Adam Kabela",
      "Th\u00e9o Pierron"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2210.09936"
  },
  {
    "id": "arXiv:2210.09940",
    "title": "Automatic Detection of Fake Key Attacks in Secure Messaging",
    "abstract": "Popular instant messaging applications such as WhatsApp and Signal provide\nend-to-end encryption for billions of users. They rely on a centralized,\napplication-specific server to distribute public keys and relay encrypted\nmessages between the users. Therefore, they prevent passive attacks but are\nvulnerable to some active attacks. A malicious or hacked server can distribute\nfake keys to users to perform man-in-the-middle or impersonation attacks. While\ntypical secure messaging applications provide a manual method for users to\ndetect these attacks, this burdens users, and studies show it is ineffective in\npractice. This paper presents KTACA, a completely automated approach for key\nverification that is oblivious to users and easy to deploy. We motivate KTACA\nby designing two approaches to automatic key verification. One approach uses\nclient auditing (KTCA) and the second uses anonymous key monitoring (AKM). Both\nhave relatively inferior security properties, leading to KTACA, which combines\nthese approaches to provide the best of both worlds. We provide a security\nanalysis of each defense, identifying which attacks they can automatically\ndetect. We implement the active attacks to demonstrate they are possible, and\nwe also create a prototype implementation of all the defenses to measure their\nperformance and confirm their feasibility. Finally, we discuss the strengths\nand weaknesses of each defense, the overhead on clients and service providers,\nand deployment considerations.",
    "descriptor": "\nComments: An extended version of our paper published at ACM CCS 2022\n",
    "authors": [
      "Tarun Kumar Yadav",
      "Devashish Gosain",
      "Amir Herzberg",
      "Daniel Zappala",
      "Kent Seamons"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.09940"
  },
  {
    "id": "arXiv:2210.09943",
    "title": "On the Importance of Architectures and Hyperparameters for Fairness in  Face Recognition",
    "abstract": "Face recognition systems are deployed across the world by government agencies\nand contractors for sensitive and impactful tasks, such as surveillance and\ndatabase matching. Despite their widespread use, these systems are known to\nexhibit bias across a range of sociodemographic dimensions, such as gender and\nrace. Nonetheless, an array of works proposing pre-processing, training, and\npost-processing methods have failed to close these gaps. Here, we take a very\ndifferent approach to this problem, identifying that both architectures and\nhyperparameters of neural networks are instrumental in reducing bias. We first\nrun a large-scale analysis of the impact of architectures and training\nhyperparameters on several common fairness metrics and show that the implicit\nconvention of choosing high-accuracy architectures may be suboptimal for\nfairness. Motivated by our findings, we run the first neural architecture\nsearch for fairness, jointly with a search for hyperparameters. We output a\nsuite of models which Pareto-dominate all other competitive architectures in\nterms of accuracy and fairness. Furthermore, we show that these models transfer\nwell to other face recognition datasets with similar and distinct protected\nattributes. We release our code and raw result files so that researchers and\npractitioners can replace our fairness metrics with a bias measure of their\nchoice.",
    "descriptor": "",
    "authors": [
      "Rhea Sukthanker",
      "Samuel Dooley",
      "John P. Dickerson",
      "Colin White",
      "Frank Hutter",
      "Micah Goldblum"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09943"
  },
  {
    "id": "arXiv:2210.09946",
    "title": "MMGA: Multimodal Learning with Graph Alignment",
    "abstract": "Multimodal pre-training breaks down the modality barriers and allows the\nindividual modalities to be mutually augmented with information, resulting in\nsignificant advances in representation learning. However, graph modality, as a\nvery general and important form of data, cannot be easily interacted with other\nmodalities because of its non-regular nature. In this paper, we propose MMGA\n(Multimodal learning with Graph Alignment), a novel multimodal pre-training\nframework to incorporate information from graph (social network), image and\ntext modalities on social media to enhance user representation learning. In\nMMGA, a multi-step graph alignment mechanism is proposed to add the\nself-supervision from graph modality to optimize the image and text encoders,\nwhile using the information from the image and text modalities to guide the\ngraph encoder learning. We conduct experiments on the dataset crawled from\nInstagram. The experimental results show that MMGA works well on the dataset\nand improves the fans prediction task's performance. We release our dataset,\nthe first social media multimodal dataset with graph, of 60,000 users labeled\nwith specific topics based on 2 million posts to facilitate future research.",
    "descriptor": "",
    "authors": [
      "Xuan Yang",
      "Yang Yang"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09946"
  },
  {
    "id": "arXiv:2210.09947",
    "title": "Finding the Needle in a Haystack: On the Automatic Identification of  Accessibility User Reviews",
    "abstract": "In recent years, mobile accessibility has become an important trend with the\ngoal of allowing all users the possibility of using any app without many\nlimitations. User reviews include insights that are useful for app evolution.\nHowever, with the increase in the amount of received reviews, manually\nanalyzing them is tedious and time-consuming, especially when searching for\naccessibility reviews. The goal of this paper is to support the automated\nidentification of accessibility in user reviews, to help technology\nprofessionals in prioritizing their handling, and thus, creating more inclusive\napps. Particularly, we design a model that takes as input accessibility user\nreviews, learns their keyword-based features, in order to make a binary\ndecision, for a given review, on whether it is about accessibility or not. The\nmodel is evaluated using a total of 5,326 mobile app reviews. The findings show\nthat (1) our model can accurately identify accessibility reviews, outperforming\ntwo baselines, namely keyword-based detector and a random classifier; (2) our\nmodel achieves an accuracy of 85% with relatively small training dataset;\nhowever, the accuracy improves as we increase the size of the training dataset.",
    "descriptor": "",
    "authors": [
      "Eman Abdullah AlOmar",
      "Wajdi Aljedaani",
      "Murtaza Tamjeed",
      "Mohamed Wiem Mkaouer",
      "Yasmine N. Elglaly"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.09947"
  },
  {
    "id": "arXiv:2210.09948",
    "title": "Number-Adaptive Prototype Learning for 3D Point Cloud Semantic  Segmentation",
    "abstract": "3D point cloud semantic segmentation is one of the fundamental tasks for 3D\nscene understanding and has been widely used in the metaverse applications.\nMany recent 3D semantic segmentation methods learn a single prototype\n(classifier weights) for each semantic class, and classify 3D points according\nto their nearest prototype. However, learning only one prototype for each class\nlimits the model's ability to describe the high variance patterns within a\nclass. Instead of learning a single prototype for each class, in this paper, we\npropose to use an adaptive number of prototypes to dynamically describe the\ndifferent point patterns within a semantic class. With the powerful capability\nof vision transformer, we design a Number-Adaptive Prototype Learning (NAPL)\nmodel for point cloud semantic segmentation. To train our NAPL model, we\npropose a simple yet effective prototype dropout training strategy, which\nenables our model to adaptively produce prototypes for each class. The\nexperimental results on SemanticKITTI dataset demonstrate that our method\nachieves 2.3% mIoU improvement over the baseline model based on the point-wise\nclassification paradigm.",
    "descriptor": "",
    "authors": [
      "Yangheng Zhao",
      "Jun Wang",
      "Xiaolong Li",
      "Yue Hu",
      "Ce Zhang",
      "Yanfeng Wang",
      "Siheng Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09948"
  },
  {
    "id": "arXiv:2210.09949",
    "title": "SQ Lower Bounds for Learning Single Neurons with Massart Noise",
    "abstract": "We study the problem of PAC learning a single neuron in the presence of\nMassart noise. Specifically, for a known activation function $f: \\mathbb{R} \\to\n\\mathbb{R}$, the learner is given access to labeled examples $(\\mathbf{x}, y)\n\\in \\mathbb{R}^d \\times \\mathbb{R}$, where the marginal distribution of\n$\\mathbf{x}$ is arbitrary and the corresponding label $y$ is a Massart\ncorruption of $f(\\langle \\mathbf{w}, \\mathbf{x} \\rangle)$. The goal of the\nlearner is to output a hypothesis $h: \\mathbb{R}^d \\to \\mathbb{R}$ with small\nsquared loss. For a range of activation functions, including ReLUs, we\nestablish super-polynomial Statistical Query (SQ) lower bounds for this\nlearning problem. In more detail, we prove that no efficient SQ algorithm can\napproximate the optimal error within any constant factor. Our main technical\ncontribution is a novel SQ-hard construction for learning $\\{ \\pm 1\\}$-weight\nMassart halfspaces on the Boolean hypercube that is interesting on its own\nright.",
    "descriptor": "\nComments: To appear in NeurIPS 2022\n",
    "authors": [
      "Ilias Diakonikolas",
      "Daniel M. Kane",
      "Lisheng Ren",
      "Yuxin Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.09949"
  },
  {
    "id": "arXiv:2210.09950",
    "title": "Deconstructing the Calculus of Relations with Tape Diagrams",
    "abstract": "Rig categories with finite biproducts are categories with two monoidal\nproducts, where one is a biproduct and the other distributes over it. In this\nwork we present tape diagrams, a sound and complete diagrammatic language for\nthese categories, that can be intuitively thought as string diagrams of string\ndiagrams. We test the effectiveness of our approach against the positive\nfragment of Tarski's calculus of relations.",
    "descriptor": "",
    "authors": [
      "Filippo Bonchi",
      "Alessandro Di Giorgio",
      "Alessio Santamaria"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.09950"
  },
  {
    "id": "arXiv:2210.09951",
    "title": "HMM vs. CTC for Automatic Speech Recognition: Comparison Based on  Full-Sum Training from Scratch",
    "abstract": "In this work, we compare from-scratch sequence-level cross-entropy (full-sum)\ntraining of Hidden Markov Model (HMM) and Connectionist Temporal Classification\n(CTC) topologies for automatic speech recognition (ASR). Besides accuracy, we\nfurther analyze their capability for generating high-quality time alignment\nbetween the speech signal and the transcription, which can be crucial for many\nsubsequent applications. Moreover, we propose several methods to improve\nconvergence of from-scratch full-sum training by addressing the alignment\nmodeling issue. Systematic comparison is conducted on both Switchboard and\nLibriSpeech corpora across CTC, posterior HMM with and w/o transition\nprobabilities, and standard hybrid HMM. We also provide a detailed analysis of\nboth Viterbi forced-alignment and Baum-Welch full-sum occupation probabilities.",
    "descriptor": "\nComments: Accepted for Presentation at IEEE SLT 2022\n",
    "authors": [
      "Tina Raissi",
      "Wei Zhou",
      "Simon Berger",
      "Ralf Schl\u00fcter",
      "Hermann Ney"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.09951"
  },
  {
    "id": "arXiv:2210.09953",
    "title": "Randomized Cholesky QR factorizations",
    "abstract": "This article proposes and analyzes several variants of the randomized\nCholesky QR factorization of a matrix $X$. Instead of computing the R factor\nfrom $X^T X$, as is done by standard methods, we obtain it from a small,\nefficiently computable random sketch of $X$, thus saving computational cost and\nimproving numerical stability. The proposed direct variant of the randomized\nCholesky QR requires only half the flops and data passes, and the same\ncommunication cost as the classical Cholesky QR. At the same time, it is more\nrobust since it is guaranteed to be stable whenever the input matrix is\nnumerically full-rank. The rank-revealing randomized Cholesky QR variant has\nthe ability to sort out the linearly dependent columns of $X$, which allows to\nhave an unconditional numerical stability and reduce the computational cost\nwhen $X$ is rank-deficient. We also depict a column-oriented randomized\nCholesky QR that establishes the connection with the randomized Gram-Schmidt\nprocess, and a reduced variant that outputs a low-dimensional projection of the\nQ factor rather than the full factor and therefore yields drastic computational\nsavings. It is shown that performing minor operations in higher precision in\nthe proposed algorithms can allow stability with working unit roundoff\nindependent of the dominant matrix dimension. This feature may be of particular\ninterest for a QR factorization of tall-and-skinny matrices on low-precision\narchitectures.",
    "descriptor": "",
    "authors": [
      "Oleg Balabanov"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.09953"
  },
  {
    "id": "arXiv:2210.09954",
    "title": "Decomposition and conformal mapping techniques for the quadrature of  nearly singular integrals",
    "abstract": "Gauss-Legendre quadrature and the trapezoidal rule are powerful tools for\nnumerical integration of analytic functions. For nearly singular problems,\nhowever, these standard methods become unacceptably slow. We discuss and\ngeneralize some existing methods for improving on these schemes when the\nlocation of the nearby singularity is known. We conclude with an application to\nsome nearly singular surface integrals of viscous flow.",
    "descriptor": "",
    "authors": [
      "William Mitchell",
      "Abbie Natkin",
      "Paige Robertson",
      "Marika Sullivan",
      "Xuechen Yu",
      "Chenxin Zhu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.09954"
  },
  {
    "id": "arXiv:2210.09956",
    "title": "Double Attention-based Lightweight Network for Plant Pest Recognition",
    "abstract": "Timely recognition of plant pests from field images is significant to avoid\npotential losses of crop yields. Traditional convolutional neural network-based\ndeep learning models demand high computational capability and require large\nlabelled samples for each pest type for training. On the other hand, the\nexisting lightweight network-based approaches suffer in correctly classifying\nthe pests because of common characteristics and high similarity between\nmultiple plant pests. In this work, a novel double attention-based lightweight\ndeep learning architecture is proposed to automatically recognize different\nplant pests. The lightweight network facilitates faster and small data training\nwhile the double attention module increases performance by focusing on the most\npertinent information. The proposed approach achieves 96.61%, 99.08% and 91.60%\non three variants of two publicly available datasets with 5869, 545 and 500\nsamples, respectively. Moreover, the comparison results reveal that the\nproposed approach outperforms existing approaches on both small and large\ndatasets consistently.",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Sivasubramaniam Janarthan",
      "Selvarajah Thuseethan",
      "Sutharshan Rajasegarar",
      "John Yearwood"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.09956"
  },
  {
    "id": "arXiv:2210.09957",
    "title": "Contextual bandits with concave rewards, and an application to fair  ranking",
    "abstract": "We consider Contextual Bandits with Concave Rewards (CBCR), a multi-objective\nbandit problem where the desired trade-off between the rewards is defined by a\nknown concave objective function, and the reward vector depends on an observed\nstochastic context. We present the first algorithm with provably vanishing\nregret for CBCR without restrictions on the policy space, whereas prior works\nwere restricted to finite policy spaces or tabular representations. Our\nsolution is based on a geometric interpretation of CBCR algorithms as\noptimization algorithms over the convex set of expected rewards spanned by all\nstochastic policies. Building on Frank-Wolfe analyses in constrained convex\noptimization, we derive a novel reduction from the CBCR regret to the regret of\na scalar-reward bandit problem. We illustrate how to apply the reduction\noff-the-shelf to obtain algorithms for CBCR with both linear and general reward\nfunctions, in the case of non-combinatorial actions. Motivated by fairness in\nrecommendation, we describe a special case of CBCR with rankings and\nfairness-aware objectives, leading to the first algorithm with regret\nguarantees for contextual combinatorial bandits with fairness of exposure.",
    "descriptor": "",
    "authors": [
      "Virginie Do",
      "Elvis Dohmatob",
      "Matteo Pirotta",
      "Alessandro Lazaric",
      "Nicolas Usunier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.09957"
  },
  {
    "id": "arXiv:2210.09958",
    "title": "It's a long way! Layer-wise Relevance Propagation for Echo State  Networks applied to Earth System Variability",
    "abstract": "Artificial neural networks (ANNs) are known to be powerful methods for many\nhard problems (e.g. image classification, speech recognition or time series\nprediction). However, these models tend to produce black-box results and are\noften difficult to interpret. Layer-wise relevance propagation (LRP) is a\nwidely used technique to understand how ANN models come to their conclusion and\nto understand what a model has learned. Here, we focus on Echo State Networks\n(ESNs) as a certain type of recurrent neural networks, also known as reservoir\ncomputing. ESNs are easy to train and only require a small number of trainable\nparameters, but are still black-box models. We show how LRP can be applied to\nESNs in order to open the black-box. We also show how ESNs can be used not only\nfor time series prediction but also for image classification: Our ESN model\nserves as a detector for El Nino Southern Oscillation (ENSO) from sea surface\ntemperature anomalies. ENSO is actually a well-known problem and has been\nextensively discussed before. But here we use this simple problem to\ndemonstrate how LRP can significantly enhance the explainablility of ESNs.",
    "descriptor": "",
    "authors": [
      "Marco Landt-Hayen",
      "Peer Kr\u00f6ger",
      "Martin Claus",
      "Willi Rath"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.09958"
  },
  {
    "id": "arXiv:2210.09959",
    "title": "Out of Distribution Reasoning by Weakly-Supervised Disentangled Logic  Variational Autoencoder",
    "abstract": "Out-of-distribution (OOD) detection, i.e., finding test samples derived from\na different distribution than the training set, as well as reasoning about such\nsamples (OOD reasoning), are necessary to ensure the safety of results\ngenerated by machine learning models. Recently there have been promising\nresults for OOD detection in the latent space of variational autoencoders\n(VAEs). However, without disentanglement, VAEs cannot perform OOD reasoning.\nDisentanglement ensures a one- to-many mapping between generative factors of\nOOD (e.g., rain in image data) and the latent variables to which they are\nencoded. Although previous literature has focused on weakly-supervised\ndisentanglement on simple datasets with known and independent generative\nfactors. In practice, achieving full disentanglement through weak supervision\nis impossible for complex datasets, such as Carla, with unknown and abstract\ngenerative factors. As a result, we propose an OOD reasoning framework that\nlearns a partially disentangled VAE to reason about complex datasets. Our\nframework consists of three steps: partitioning data based on observed\ngenerative factors, training a VAE as a logic tensor network that satisfies\ndisentanglement rules, and run-time OOD reasoning. We evaluate our approach on\nthe Carla dataset and compare the results against three state-of-the-art\nmethods. We found that our framework outperformed these methods in terms of\ndisentanglement and end-to-end OOD reasoning.",
    "descriptor": "\nComments: Accepted in The 6th International Conference on System Reliability and Safety (ICSRS) 2022\n",
    "authors": [
      "Zahra Rahiminasab",
      "Michael Yuhas",
      "Arvind Easwaran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09959"
  },
  {
    "id": "arXiv:2210.09960",
    "title": "Rethinking Value Function Learning for Generalization in Reinforcement  Learning",
    "abstract": "We focus on the problem of training RL agents on multiple training\nenvironments to improve observational generalization performance. In prior\nmethods, policy and value networks are separately optimized using a disjoint\nnetwork architecture to avoid interference and obtain a more accurate value\nfunction. We identify that the value network in the multiple-environment\nsetting is more challenging to optimize and prone to overfitting training data\nthan in the conventional single-environment setting. In addition, we find that\nappropriate regularization of the value network is required for better training\nand test performance. To this end, we propose Delayed-Critic Policy Gradient\n(DCPG), which implicitly penalizes the value estimates by optimizing the value\nnetwork less frequently with more training data than the policy network, which\ncan be implemented using a shared network architecture. Furthermore, we\nintroduce a simple self-supervised task that learns the forward and inverse\ndynamics of environments using a single discriminator, which can be jointly\noptimized with the value network. Our proposed algorithms significantly improve\nobservational generalization performance and sample efficiency in the Procgen\nBenchmark.",
    "descriptor": "\nComments: Accepted and to appear at NeurIPS 2022\n",
    "authors": [
      "Seungyong Moon",
      "JunYeong Lee",
      "Hyun Oh Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.09960"
  },
  {
    "id": "arXiv:2210.09962",
    "title": "Nighttime Dehaze-Enhancement",
    "abstract": "In this paper, we introduce a new computer vision task called nighttime\ndehaze-enhancement. This task aims to jointly perform dehazing and lightness\nenhancement. Our task fundamentally differs from nighttime dehazing -- our goal\nis to jointly dehaze and enhance scenes, while nighttime dehazing aims to\ndehaze scenes under a nighttime setting. In order to facilitate further\nresearch on this task, we release a new benchmark dataset called Reside-$\\beta$\nNight dataset, consisting of 4122 nighttime hazed images from 2061 scenes and\n2061 ground truth images. Moreover, we also propose a new network called NDENet\n(Nighttime Dehaze-Enhancement Network), which jointly performs dehazing and\nlow-light enhancement in an end-to-end manner. We evaluate our method on the\nproposed benchmark and achieve SSIM of 0.8962 and PSNR of 26.25. We also\ncompare our network with other baseline networks on our benchmark to\ndemonstrate the effectiveness of our approach. We believe that nighttime\ndehaze-enhancement is an essential task particularly for autonomous navigation\napplications, and hope that our work will open up new frontiers in research.\nOur dataset and code will be made publicly available upon acceptance of our\npaper.",
    "descriptor": "",
    "authors": [
      "Harshan Baskar",
      "Anirudh S Chakravarthy",
      "Prateek Garg",
      "Divyam Goel",
      "Abhijith S Raj",
      "Kshitij Kumar",
      "Lakshya",
      "Ravichandra Parvatham",
      "V Sushant",
      "Bijay Kumar Rout"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09962"
  },
  {
    "id": "arXiv:2210.09963",
    "title": "Methods To Ensure Privacy Regarding Medical Data -- Including an  examination of the differential privacy algorithm RAPPOR and its  implementation in \"Cryptool 2\"",
    "abstract": "This document examines several applicable methods to ensure privacy of data\ngathered in the health care sector. To ensure a common understanding of the\ntopic, the introduction explains the need for anonymization methods based on an\nexample. Next, reasons for data collection are introduced in connection to the\npurpose to protect mentioned data, as well as currently applicable privacy laws\nto enforce this privacy. The question \"What kind of privacy we are talking\nabout and what conditions have to be fulfilled?\" is dealt with in the\nsubsequent chapter \"Differential Privacy\". Thus being established, common\nanonymization methods are explained and reviewed for their use in the\nhealthcare sector. The RAPPOR algorithm and its differential privacy is dealt\nwith in more detail before coming to a conclusion.",
    "descriptor": "\nComments: 10 pages, 1 figure, 9 tables\n",
    "authors": [
      "Christina M. W\u00f6lk"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.09963"
  },
  {
    "id": "arXiv:2210.09964",
    "title": "Efficient Evaluation of Arbitrary Relational Calculus Queries",
    "abstract": "The relational calculus (RC) is a concise, declarative query language.\nHowever, existing RC query evaluation approaches are inefficient and often\ndeviate from established algorithms based on finite tables used in database\nmanagement systems. We devise a new translation of an arbitrary RC query into\ntwo safe-range queries, for which the finiteness of the query's evaluation\nresult is guaranteed. Assuming an infinite domain, the two queries have the\nfollowing meaning: The first is closed and characterizes the original query's\nrelative safety, i.e., whether given a fixed database, the original query\nevaluates to a finite relation. The second safe-range query is equivalent to\nthe original query, if the latter is relatively safe. We compose our\ntranslation with other, more standard ones to ultimately obtain two SQL\nqueries. This allows us to use standard database management systems to evaluate\narbitrary RC queries. We show that our translation improves the time complexity\nover existing approaches, which we also empirically confirm in both realistic\nand synthetic experiments.",
    "descriptor": "",
    "authors": [
      "Martin Raszyk",
      "David Basin",
      "Sr\u0111an Krsti\u0107",
      "Dmitriy Traytel"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.09964"
  },
  {
    "id": "arXiv:2210.09969",
    "title": "Transfer-learning for video classification: Video Swin Transformer on  multiple domains",
    "abstract": "The computer vision community has seen a shift from convolutional-based to\npure transformer architectures for both image and video tasks. Training a\ntransformer from zero for these tasks usually requires a lot of data and\ncomputational resources. Video Swin Transformer (VST) is a pure-transformer\nmodel developed for video classification which achieves state-of-the-art\nresults in accuracy and efficiency on several datasets. In this paper, we aim\nto understand if VST generalizes well enough to be used in an out-of-domain\nsetting. We study the performance of VST on two large-scale datasets, namely\nFCVID and Something-Something using a transfer learning approach from\nKinetics-400, which requires around 4x less memory than training from scratch.\nWe then break down the results to understand where VST fails the most and in\nwhich scenarios the transfer-learning approach is viable. Our experiments show\nan 85\\% top-1 accuracy on FCVID without retraining the whole model which is\nequal to the state-of-the-art for the dataset and a 21\\% accuracy on\nSomething-Something. The experiments also suggest that the performance of the\nVST decreases on average when the video duration increases which seems to be a\nconsequence of a design choice of the model. From the results, we conclude that\nVST generalizes well enough to classify out-of-domain videos without retraining\nwhen the target classes are from the same type as the classes used to train the\nmodel. We observed this effect when we performed transfer-learning from\nKinetics-400 to FCVID, where most datasets target mostly objects. On the other\nhand, if the classes are not from the same type, then the accuracy after the\ntransfer-learning approach is expected to be poor. We observed this effect when\nwe performed transfer-learning from Kinetics-400, where the classes represent\nmostly objects, to Something-Something, where the classes represent mostly\nactions.",
    "descriptor": "\nComments: 7 pages, 11 figures\n",
    "authors": [
      "Daniel Oliveira",
      "David Martins de Matos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.09969"
  },
  {
    "id": "arXiv:2210.09972",
    "title": "On the Information Content of Predictions in Word Analogy Tests",
    "abstract": "An approach is proposed to quantify, in bits of information, the actual\nrelevance of analogies in analogy tests. The main component of this approach is\na softaccuracy estimator that also yields entropy estimates with compensated\nbiases. Experimental results obtained with pre-trained GloVe 300-D vectors and\ntwo public analogy test sets show that proximity hints are much more relevant\nthan analogies in analogy tests, from an information content perspective.\nAccordingly, a simple word embedding model is used to predict that analogies\ncarry about one bit of information, which is experimentally corroborated.",
    "descriptor": "",
    "authors": [
      "Jugurta Montalv\u00e3o"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09972"
  },
  {
    "id": "arXiv:2210.09976",
    "title": "Phenomenological Model of Superconducting Optoelectronic Loop Neurons",
    "abstract": "Superconducting optoelectronic loop neurons are a class of circuits\npotentially conducive to networks for large-scale artificial cognition. These\ncircuits employ superconducting components including single-photon detectors,\nJosephson junctions, and transformers to achieve neuromorphic functions. To\ndate, all simulations of loop neurons have used first-principles circuit\nanalysis to model the behavior of synapses, dendrites, and neurons. These\ncircuit models are computationally inefficient and leave opaque the\nrelationship between loop neurons and other complex systems. Here we introduce\na modeling framework that captures the behavior of the relevant synaptic,\ndendritic, and neuronal circuits at a phenomenological level without resorting\nto full circuit equations. Within this compact model, each dendrite is\ndiscovered to obey a single nonlinear leaky-integrator ordinary differential\nequation, while a neuron is modeled as a dendrite with a thresholding element\nand an additional feedback mechanism for establishing a refractory period. A\nsynapse is modeled as a single-photon detector coupled to a dendrite, where the\nresponse of the single-photon detector follows a closed-form expression. We\nquantify the accuracy of the phenomenological model relative to circuit\nsimulations and find that the approach reduces computational time by a factor\nof ten thousand while maintaining accuracy of one part in ten thousand. We\ndemonstrate the use of the model with several basic examples. The net increase\nin computational efficiency enables future simulation of large networks, while\nthe formulation provides a connection to a large body of work in applied\nmathematics, computational neuroscience, and physical systems such as spin\nglasses.",
    "descriptor": "\nComments: 34 total pages, 21 pages before the appendices, 31 figures, 24 figures before the appendices\n",
    "authors": [
      "Jeffrey M. Shainline",
      "Bryce A. Primavera",
      "Saeed Khan"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ],
    "url": "https://arxiv.org/abs/2210.09976"
  },
  {
    "id": "arXiv:2210.09984",
    "title": "Making a MIRACL: Multilingual Information Retrieval Across a Continuum  of Languages",
    "abstract": "MIRACL (Multilingual Information Retrieval Across a Continuum of Languages)\nis a multilingual dataset we have built for the WSDM 2023 Cup challenge that\nfocuses on ad hoc retrieval across 18 different languages, which collectively\nencompass over three billion native speakers around the world. These languages\nhave diverse typologies, originate from many different language families, and\nare associated with varying amounts of available resources -- including what\nresearchers typically characterize as high-resource as well as low-resource\nlanguages. Our dataset is designed to support the creation and evaluation of\nmodels for monolingual retrieval, where the queries and the corpora are in the\nsame language. In total, we have gathered over 700k high-quality relevance\njudgments for around 77k queries over Wikipedia in these 18 languages, where\nall assessments have been performed by native speakers hired by our team. Our\ngoal is to spur research that will improve retrieval across a continuum of\nlanguages, thus enhancing information access capabilities for diverse\npopulations around the world, particularly those that have been traditionally\nunderserved. This overview paper describes the dataset and baselines that we\nshare with the community. The MIRACL website is live at this http URL",
    "descriptor": "",
    "authors": [
      "Xinyu Zhang",
      "Nandan Thakur",
      "Odunayo Ogundepo",
      "Ehsan Kamalloo",
      "David Alfonso-Hermelo",
      "Xiaoguang Li",
      "Qun Liu",
      "Mehdi Rezagholizadeh",
      "Jimmy Lin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.09984"
  },
  {
    "id": "arXiv:2210.09990",
    "title": "Post-hoc analysis of Arabic transformer models",
    "abstract": "Arabic is a Semitic language which is widely spoken with many dialects. Given\nthe success of pre-trained language models, many transformer models trained on\nArabic and its dialects have surfaced. While there have been an extrinsic\nevaluation of these models with respect to downstream NLP tasks, no work has\nbeen carried out to analyze and compare their internal representations. We\nprobe how linguistic information is encoded in the transformer models, trained\non different Arabic dialects. We perform a layer and neuron analysis on the\nmodels using morphological tagging tasks for different dialects of Arabic and a\ndialectal identification task. Our analysis enlightens interesting findings\nsuch as: i) word morphology is learned at the lower and middle layers, ii)\nwhile syntactic dependencies are predominantly captured at the higher layers,\niii) despite a large overlap in their vocabulary, the MSA-based models fail to\ncapture the nuances of Arabic dialects, iv) we found that neurons in embedding\nlayers are polysemous in nature, while the neurons in middle layers are\nexclusive to specific properties",
    "descriptor": "\nComments: BlackboxNLP 2022. arXiv admin note: substantial text overlap with arXiv:2201.07434\n",
    "authors": [
      "Ahmed Abdelali",
      "Nadir Durrani",
      "Fahim Dalvi",
      "Hassan Sajjad"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.09990"
  },
  {
    "id": "arXiv:2210.09992",
    "title": "Optimal Event Monitoring through Internet Mashup over Multivariate Time  Series",
    "abstract": "We propose a Web-Mashup Application Service Framework for Multivariate Time\nSeries Analytics (MTSA) that supports the services of model definitions,\nquerying, parameter learning, model evaluations, data monitoring, decision\nrecommendations, and web portals. This framework maintains the advantage of\ncombining the strengths of both the domain-knowledge-based and the\nformal-learning-based approaches and is designed for a more general class of\nproblems over multivariate time series. More specifically, we identify a\ngeneral-hybrid-based model, MTSA-Parameter Estimation, to solve this class of\nproblems in which the objective function is maximized or minimized from the\noptimal decision parameters regardless of particular time points. This model\nalso allows domain experts to include multiple types of constraints, e.g.,\nglobal constraints and monitoring constraints. We further extend the MTSA data\nmodel and query language to support this class of problems for the services of\nlearning, monitoring, and recommendation. At the end, we conduct an\nexperimental case study for a university campus microgrid as a practical\nexample to demonstrate our proposed framework, models, and language.",
    "descriptor": "",
    "authors": [
      "Chun-Kit Ngan",
      "Alexander Brodsky"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.09992"
  },
  {
    "id": "arXiv:2210.09996",
    "title": "Perceptual Grouping in Vision-Language Models",
    "abstract": "Recent advances in zero-shot image recognition suggest that vision-language\nmodels learn generic visual representations with a high degree of semantic\ninformation that may be arbitrarily probed with natural language phrases.\nUnderstanding an image, however, is not just about understanding what content\nresides within an image, but importantly, where that content resides. In this\nwork we examine how well vision-language models are able to understand where\nobjects reside within an image and group together visually related parts of the\nimagery. We demonstrate how contemporary vision and language representation\nlearning models based on contrastive losses and large web-based data capture\nlimited object localization information. We propose a minimal set of\nmodifications that results in models that uniquely learn both semantic and\nspatial information. We measure this performance in terms of zero-shot image\nrecognition, unsupervised bottom-up and top-down semantic segmentations, as\nwell as robustness analyses. We find that the resulting model achieves\nstate-of-the-art results in terms of unsupervised segmentation, and demonstrate\nthat the learned representations are uniquely robust to spurious correlations\nin datasets designed to probe the causal behavior of vision models.",
    "descriptor": "",
    "authors": [
      "Kanchana Ranasinghe",
      "Brandon McKinzie",
      "Sachin Ravi",
      "Yinfei Yang",
      "Alexander Toshev",
      "Jonathon Shlens"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09996"
  },
  {
    "id": "arXiv:2210.09997",
    "title": "Bag All You Need: Learning a Generalizable Bagging Strategy for  Heterogeneous Objects",
    "abstract": "We introduce a practical robotics solution for the task of heterogeneous\nbagging, requiring the placement of multiple rigid and deformable objects into\na deformable bag. This is a difficult task as it features complex interactions\nbetween multiple highly deformable objects under limited observability. To\ntackle these challenges, we propose a robotic system consisting of two learned\npolicies: a rearrangement policy that learns to place multiple rigid objects\nand fold deformable objects in order to achieve desirable pre-bagging\nconditions, and a lifting policy to infer suitable grasp points for bi-manual\nbag lifting. We evaluate these learned policies on a real-world three-arm robot\nplatform that achieves a 70% heterogeneous bagging success rate with novel\nobjects. To facilitate future research and comparison, we also develop a novel\nheterogeneous bagging simulation benchmark that will be made publicly\navailable.",
    "descriptor": "\nComments: 8 pages, 5 figures, project website: this https URL\n",
    "authors": [
      "Arpit Bahety",
      "Shreeya Jain",
      "Huy Ha",
      "Nathalie Hager",
      "Benjamin Burchfiel",
      "Eric Cousineau",
      "Siyuan Feng",
      "Shuran Song"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.09997"
  },
  {
    "id": "arXiv:2210.10005",
    "title": "Otsu based Differential Evolution Method for Image Segmentation",
    "abstract": "This paper proposes an OTSU based differential evolution method for satellite\nimage segmentation and compares it with four other methods such as Modified\nArtificial Bee Colony Optimizer (MABC), Artificial Bee Colony (ABC), Genetic\nAlgorithm (GA), and Particle Swarm Optimization (PSO) using the objective\nfunction proposed by Otsu for optimal multilevel thresholding. The experiments\nconducted and their results illustrate that our proposed DE and OTSU algorithm\nsegmentation can effectively and precisely segment the input image, close to\nresults obtained by the other methods. In the proposed DE and OTSU algorithm,\ninstead of passing the fitness function variables, the entire image is passed\nas an input to the DE algorithm after obtaining the threshold values for the\ninput number of levels in the OTSU algorithm. The image segmentation results\nare obtained after learning about the image instead of learning about the\nfitness variables. In comparison to other segmentation methods examined, the\nproposed DE and OTSU algorithm yields promising results with minimized\ncomputational time compared to some algorithms.",
    "descriptor": "",
    "authors": [
      "Afreen Shaikh",
      "Sharmila Botcha",
      "Murali Krishna"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10005"
  },
  {
    "id": "arXiv:2210.10010",
    "title": "Vision Paper: Causal Inference for Interpretable and Robust Machine  Learning in Mobility Analysis",
    "abstract": "Artificial intelligence (AI) is revolutionizing many areas of our lives,\nleading a new era of technological advancement. Particularly, the\ntransportation sector would benefit from the progress in AI and advance the\ndevelopment of intelligent transportation systems. Building intelligent\ntransportation systems requires an intricate combination of artificial\nintelligence and mobility analysis. The past few years have seen rapid\ndevelopment in transportation applications using advanced deep neural networks.\nHowever, such deep neural networks are difficult to interpret and lack\nrobustness, which slows the deployment of these AI-powered algorithms in\npractice. To improve their usability, increasing research efforts have been\ndevoted to developing interpretable and robust machine learning methods, among\nwhich the causal inference approach recently gained traction as it provides\ninterpretable and actionable information. Moreover, most of these methods are\ndeveloped for image or sequential data which do not satisfy specific\nrequirements of mobility data analysis. This vision paper emphasizes research\nchallenges in deep learning-based mobility analysis that require\ninterpretability and robustness, summarizes recent developments in using causal\ninference for improving the interpretability and robustness of machine learning\nmethods, and highlights opportunities in developing causally-enabled machine\nlearning models tailored for mobility analysis. This research direction will\nmake AI in the transportation sector more interpretable and reliable, thus\ncontributing to safer, more efficient, and more sustainable future\ntransportation systems.",
    "descriptor": "\nComments: accepted by ACM SIGSPATIAL 2022 Conference\n",
    "authors": [
      "Yanan Xin",
      "Natasa Tagasovska",
      "Fernando Perez-Cruz",
      "Martin Raubal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10010"
  },
  {
    "id": "arXiv:2210.10012",
    "title": "Linear Guardedness and its Implications",
    "abstract": "Previous work on concept identification in neural representations has focused\non linear concept subspaces and their neutralization. In this work, we\nformulate the notion of linear guardedness -- the inability to directly predict\na given concept from the representation -- and study its implications. We show\nthat, in the binary case, the neutralized concept cannot be recovered by an\nadditional linear layer. However, we point out that -- contrary to what was\nimplicitly argued in previous works -- multiclass softmax classifiers can be\nconstructed that indirectly recover the concept. Thus, linear guardedness does\nnot guarantee that linear classifiers do not utilize the neutralized concepts,\nshedding light on theoretical limitations of linear information removal\nmethods.",
    "descriptor": "\nComments: A preprint\n",
    "authors": [
      "Shauli Ravfogel",
      "Yoav Goldberg",
      "Ryan Cotterell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.10012"
  },
  {
    "id": "arXiv:2210.10014",
    "title": "On Classification Thresholds for Graph Attention with Edge Features",
    "abstract": "The recent years we have seen the rise of graph neural networks for\nprediction tasks on graphs. One of the dominant architectures is graph\nattention due to its ability to make predictions using weighted edge features\nand not only node features. In this paper we analyze, theoretically and\nempirically, graph attention networks and their ability of correctly labelling\nnodes in a classic classification task. More specifically, we study the\nperformance of graph attention on the classic contextual stochastic block model\n(CSBM). In CSBM the nodes and edge features are obtained from a mixture of\nGaussians and the edges from a stochastic block model. We consider a general\ngraph attention mechanism that takes random edge features as input to determine\nthe attention coefficients. We study two cases, in the first one, when the edge\nfeatures are noisy, we prove that the majority of the attention coefficients\nare up to a constant uniform. This allows us to prove that graph attention with\nedge features is not better than simple graph convolution for achieving perfect\nnode classification. Second, we prove that when the edge features are clean\ngraph attention can distinguish intra- from inter-edges and this makes graph\nattention better than classic graph convolution.",
    "descriptor": "\nComments: 37 pages, 5 figures, 5 Tables\n",
    "authors": [
      "Kimon Fountoulakis",
      "Dake He",
      "Silvio Lattanzi",
      "Bryan Perozzi",
      "Anton Tsitsulin",
      "Shenghao Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10014"
  },
  {
    "id": "arXiv:2210.10015",
    "title": "Towards Task-Specific Modular Gripper Fingers: Automatic Production of  Fingertip Mechanics",
    "abstract": "The number of sequential tasks a single gripper can perform is significantly\nlimited by its design. In many cases, changing the gripper fingers is required\nto successfully conduct multiple consecutive tasks. For this reason, several\nrobotic tool change systems have been introduced that allow an automatic\nchanging of the entire end-effector. However, many situations require only the\nmodification or the change of the fingertip, making the exchange of the entire\ngripper uneconomic. In this paper, we introduce a paradigm for automatic\ntask-specific fingertip production. The setup used in the proposed framework\nconsists of a production and task execution unit, containing a robotic\nmanipulator, and two 3D printers - autonomously producing the gripper fingers.\nIt also consists of a second manipulator that uses a quick-exchange mechanism\nto pick up the printed fingertips and evaluates gripping performance. The setup\nis experimentally validated by conducting automatic production of three\ndifferent fingertips and executing graspstability tests as well as multiple\npick- and insertion tasks, with and without position offsets - using these\nfingertips. The proposed paradigm, indeed, goes beyond fingertip production and\nserves as a foundation for a fully automatic fingertip design, production and\napplication pipeline - potentially improving manufacturing flexibility and\nrepresenting a new production paradigm: tactile 3D manufacturing.",
    "descriptor": "\nComments: 8 pages, 9 figures\n",
    "authors": [
      "Johannes Ringwald",
      "Samuel Schneider",
      "Lingyun Chen",
      "Dennis Knobbe",
      "Lars Johannsmeier",
      "Abdalla Swikir",
      "Sami Haddadin"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.10015"
  },
  {
    "id": "arXiv:2210.10019",
    "title": "Towards Understanding GD with Hard and Conjugate Pseudo-labels for  Test-Time Adaptation",
    "abstract": "We consider a setting that a model needs to adapt to a new domain under\ndistribution shifts, given that only unlabeled test samples from the new domain\nare accessible at test time. A common idea in most of the related works is\nconstructing pseudo-labels for the unlabeled test samples and applying gradient\ndescent (GD) to a loss function with the pseudo-labels. Recently, Goyal et al.\n(2022) propose conjugate labels, which is a new kind of pseudo-labels for\nself-training at test time. They empirically show that the conjugate label\noutperforms other ways of pseudo-labeling on many domain adaptation benchmarks.\nHowever, provably showing that GD with conjugate labels learns a good\nclassifier for test-time adaptation remains open. In this work, we aim at\ntheoretically understanding GD with hard and conjugate labels for a binary\nclassification problem. We show that for square loss, GD with conjugate labels\nconverges to a solution that minimizes the testing 0-1 loss under a Gaussian\nmodel, while GD with hard pseudo-labels fails in this task. We also analyze\nthem under different loss functions for the update. Our results shed lights on\nunderstanding when and why GD with hard labels or conjugate labels works in\ntest-time adaptation.",
    "descriptor": "",
    "authors": [
      "Jun-Kun Wang",
      "Andre Wibisono"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10019"
  },
  {
    "id": "arXiv:2210.10020",
    "title": "ULN: Towards Underspecified Vision-and-Language Navigation",
    "abstract": "Vision-and-Language Navigation (VLN) is a task to guide an embodied agent\nmoving to a target position using language instructions. Despite the\nsignificant performance improvement, the wide use of fine-grained instructions\nfails to characterize more practical linguistic variations in reality. To fill\nin this gap, we introduce a new setting, namely Underspecified\nvision-and-Language Navigation (ULN), and associated evaluation datasets. ULN\nevaluates agents using multi-level underspecified instructions instead of\npurely fine-grained or coarse-grained, which is a more realistic and general\nsetting. As a primary step toward ULN, we propose a VLN framework that consists\nof a classification module, a navigation agent, and an\nExploitation-to-Exploration (E2E) module. Specifically, we propose to learn\nGranularity Specific Sub-networks (GSS) for the agent to ground multi-level\ninstructions with minimal additional parameters. Then, our E2E module estimates\ngrounding uncertainty and conducts multi-step lookahead exploration to improve\nthe success rate further. Experimental results show that existing VLN models\nare still brittle to multi-level language underspecification. Our framework is\nmore robust and outperforms the baselines on ULN by ~10% relative success rate\nacross all levels.",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Weixi Feng",
      "Tsu-Jui Fu",
      "Yujie Lu",
      "William Yang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.10020"
  },
  {
    "id": "arXiv:2210.10026",
    "title": "Diverse Misinformation: Impacts of Human Biases on Detection of  Deepfakes on Networks",
    "abstract": "Social media users are not equally susceptible to all misinformation. We call\n``diverse misinformation'' the complex relationships between human biases and\ndemographics represented in misinformation, and its impact on our\nsusceptibility to misinformation is currently unknown. To investigate how\nusers' biases impact susceptibility, we explore computer-generated videos\ncalled deepfakes as a type of diverse misinformation. We chose deepfakes as a\ncase study for three reasons: 1.) their classification as misinformation is\nmore objective; 2.) we can control the demographics of the persona presented;\nand 3.) deepfakes are a real-world concern with associated harms that need to\nbe better understood. Our paper presents a survey (N=2,000) where U.S.-based\nparticipants are exposed to videos and asked questions about their attributes,\nnot knowing they might be a deepfake. Our analysis investigates the extent to\nwhich different users are duped and by what perceived demographics of deepfake\npersonas. First, if users not explicitly looking for deepfakes are not\nparticularly accurate classifiers. Importantly, accuracy varies significantly\nby demographics, and participants are generally better at classifying videos\nthat match them (especially male, white, and young participants). We\nextrapolate from these results to understand the population-level impacts of\nthese biases using an idealized mathematical model of the interplay between\ndiverse misinformation and crowd correction. Our model suggests that a diverse\nset of contacts might provide ``herd correction'' where friends can protect\neach other's blind spots. Altogether, human biases and the attributes of\nmisinformation matter greatly, but having a diverse social group may help\nreduce susceptibility to misinformation.",
    "descriptor": "\nComments: Supplementary appendix available upon request for the time being\n",
    "authors": [
      "Juniper Lovato",
      "Laurent H\u00e9bert-Dufresne",
      "Jonathan St-Onge",
      "Randall Harp",
      "Gabriela Salazar Lopez",
      "Sean P. Rogers",
      "Ijaz Ul Haq",
      "Jeremiah Onaolapo"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.10026"
  },
  {
    "id": "arXiv:2210.10027",
    "title": "Maestro-U: Leveraging joint speech-text representation learning for zero  supervised speech ASR",
    "abstract": "Training state-of-the-art Automated Speech Recognition (ASR) models typically\nrequires a substantial amount of transcribed speech. In this work, we\ndemonstrate that a modality-matched joint speech and text model can be\nleveraged to train a massively multilingual ASR model without any supervised\n(manually transcribed) speech for some languages. This paper explores the use\nof jointly learnt speech and text representations in a massively multilingual,\nzero supervised speech, real-world setting to expand the set of languages\ncovered by ASR with only unlabeled speech and text in the target languages.\nUsing the FLEURS dataset, we define the task to cover $102$ languages, where\ntranscribed speech is available in $52$ of these languages and can be used to\nimprove end-to-end ASR quality on the remaining $50$. First, we show that by\ncombining speech representations with byte-level text representations and use\nof language embeddings, we can dramatically reduce the Character Error Rate\n(CER) on languages with no supervised speech from 64.8\\% to 30.8\\%, a relative\nreduction of 53\\%. Second, using a subset of South Asian languages we show that\nMaestro-U can promote knowledge transfer from languages with supervised speech\neven when there is limited to no graphemic overlap. Overall, Maestro-U closes\nthe gap to oracle performance by 68.5\\% relative and reduces the CER of 19\nlanguages below 15\\%.",
    "descriptor": "\nComments: Accepted by SLT 2022\n",
    "authors": [
      "Zhehuai Chen",
      "Ankur Bapna",
      "Andrew Rosenberg",
      "Yu Zhang",
      "Bhuvana Ramabhadran",
      "Pedro Moreno",
      "Nanxin Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.10027"
  },
  {
    "id": "arXiv:2210.10031",
    "title": "Understanding COVID-19 Vaccine Campaign on Facebook using Minimal  Supervision",
    "abstract": "In the age of social media, where billions of internet users share\ninformation and opinions, the negative impact of pandemics is not limited to\nthe physical world. It provokes a surge of incomplete, biased, and incorrect\ninformation, also known as an infodemic. This global infodemic jeopardizes\nmeasures to control the pandemic by creating panic, vaccine hesitancy, and\nfragmented social response. Platforms like Facebook allow advertisers to adapt\ntheir messaging to target different demographics and help alleviate or\nexacerbate the infodemic problem depending on their content. In this paper, we\npropose a minimally supervised multi-task learning framework for understanding\nmessaging on Facebook related to the covid vaccine by identifying ad themes and\nmoral foundations. Furthermore, we perform a more nuanced thematic analysis of\nmessaging tactics of vaccine campaigns on social media so that policymakers can\nmake better decisions on pandemic control.",
    "descriptor": "",
    "authors": [
      "Tunazzina Islam",
      "Dan Goldwasser"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.10031"
  },
  {
    "id": "arXiv:2210.10033",
    "title": "Edge-based Monocular Thermal-Inertial Odometry in Visually Degraded  Environments",
    "abstract": "State estimation in complex illumination environments based on conventional\nvisual-inertial odometry is a challenging task due to the severe visual\ndegradation of the visual camera. The thermal infrared camera is capable of\nall-day time and is less affected by illumination variation. However, most\nexisting visual data association algorithms are incompatible because the\nthermal infrared data contains large noise and low contrast. Motivated by the\nphenomenon that thermal radiation varies most significantly at the edges of\nobjects, the study proposes an ETIO, which is the first edge-based monocular\nthermal-inertial odometry for robust localization in visually degraded\nenvironments. Instead of the raw image, we utilize the binarized image from\nedge extraction for pose estimation to overcome the poor thermal infrared image\nquality. Then, an adaptive feature tracking strategy ADT-KLT is developed for\nrobust data association based on limited edge information and its distance\ndistribution. Finally, a pose graph optimization performs real-time estimation\nover a sliding window of recent states by combining IMU pre-integration with\nreprojection error of all edge feature observations. We evaluated the\nperformance of the proposed system on public datasets and real-world\nexperiments and compared it against state-of-the-art methods. The proposed ETIO\nwas verified with the ability to enable accurate and robust localization\nall-day time.",
    "descriptor": "\nComments: 8 pages, 10 figures,\n",
    "authors": [
      "Yu Wang",
      "Haoyao Chen",
      "Yufeng Liu",
      "Shiwu Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.10033"
  },
  {
    "id": "arXiv:2210.10036",
    "title": "ARAH: Animatable Volume Rendering of Articulated Human SDFs",
    "abstract": "Combining human body models with differentiable rendering has recently\nenabled animatable avatars of clothed humans from sparse sets of multi-view RGB\nvideos. While state-of-the-art approaches achieve realistic appearance with\nneural radiance fields (NeRF), the inferred geometry often lacks detail due to\nmissing geometric constraints. Further, animating avatars in\nout-of-distribution poses is not yet possible because the mapping from\nobservation space to canonical space does not generalize faithfully to unseen\nposes. In this work, we address these shortcomings and propose a model to\ncreate animatable clothed human avatars with detailed geometry that generalize\nwell to out-of-distribution poses. To achieve detailed geometry, we combine an\narticulated implicit surface representation with volume rendering. For\ngeneralization, we propose a novel joint root-finding algorithm for\nsimultaneous ray-surface intersection search and correspondence search. Our\nalgorithm enables efficient point sampling and accurate point canonicalization\nwhile generalizing well to unseen poses. We demonstrate that our proposed\npipeline can generate clothed avatars with high-quality pose-dependent geometry\nand appearance from a sparse set of multi-view RGB videos. Our method achieves\nstate-of-the-art performance on geometry and appearance reconstruction while\ncreating animatable avatars that generalize well to out-of-distribution poses\nbeyond the small number of training poses.",
    "descriptor": "\nComments: Accepted to ECCV 2022. Project page: this https URL\n",
    "authors": [
      "Shaofei Wang",
      "Katja Schwarz",
      "Andreas Geiger",
      "Siyu Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10036"
  },
  {
    "id": "arXiv:2210.10039",
    "title": "How Would The Viewer Feel? Estimating Wellbeing From Video Scenarios",
    "abstract": "In recent years, deep neural networks have demonstrated increasingly strong\nabilities to recognize objects and activities in videos. However, as video\nunderstanding becomes widely used in real-world applications, a key\nconsideration is developing human-centric systems that understand not only the\ncontent of the video but also how it would affect the wellbeing and emotional\nstate of viewers. To facilitate research in this setting, we introduce two\nlarge-scale datasets with over 60,000 videos manually annotated for emotional\nresponse and subjective wellbeing. The Video Cognitive Empathy (VCE) dataset\ncontains annotations for distributions of fine-grained emotional responses,\nallowing models to gain a detailed understanding of affective states. The Video\nto Valence (V2V) dataset contains annotations of relative pleasantness between\nvideos, which enables predicting a continuous spectrum of wellbeing. In\nexperiments, we show how video models that are primarily trained to recognize\nactions and find contours of objects can be repurposed to understand human\npreferences and the emotional content of videos. Although there is room for\nimprovement, predicting wellbeing and emotional response is on the horizon for\nstate-of-the-art models. We hope our datasets can help foster further advances\nat the intersection of commonsense video understanding and human preference\nlearning.",
    "descriptor": "\nComments: NeurIPS 2022; datasets available at this https URL\n",
    "authors": [
      "Mantas Mazeika",
      "Eric Tang",
      "Andy Zou",
      "Steven Basart",
      "Jun Shern Chan",
      "Dawn Song",
      "David Forsyth",
      "Jacob Steinhardt",
      "Dan Hendrycks"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10039"
  },
  {
    "id": "arXiv:2210.10040",
    "title": "The Tail Wagging the Dog: Dataset Construction Biases of Social Bias  Benchmarks",
    "abstract": "How reliably can we trust the scores obtained from social bias benchmarks as\nfaithful indicators of problematic social biases in a given language model? In\nthis work, we study this question by contrasting social biases with non-social\nbiases stemming from choices made during dataset construction that might not\neven be discernible to the human eye. To do so, we empirically simulate various\nalternative constructions for a given benchmark based on innocuous\nmodifications (such as paraphrasing or random-sampling) that maintain the\nessence of their social bias. On two well-known social bias benchmarks\n(Winogender and BiasNLI) we observe that these shallow modifications have a\nsurprising effect on the resulting degree of bias across various models. We\nhope these troubling observations motivate more robust measures of social\nbiases.",
    "descriptor": "",
    "authors": [
      "Nikil Roashan Selvam",
      "Sunipa Dev",
      "Daniel Khashabi",
      "Tushar Khot",
      "Kai-Wei Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.10040"
  },
  {
    "id": "arXiv:2210.10041",
    "title": "Hidden State Variability of Pretrained Language Models Can Guide  Computation Reduction for Transfer Learning",
    "abstract": "While transferring a pretrained language model, common approaches\nconventionally attach their task-specific classifiers to the top layer and\nadapt all the pretrained layers. We investigate whether one could make a\ntask-specific selection on which subset of the layers to adapt and where to\nplace the classifier. The goal is to reduce the computation cost of transfer\nlearning methods (e.g. fine-tuning or adapter-tuning) without sacrificing its\nperformance.\nWe propose to select layers based on the variability of their hidden states\ngiven a task-specific corpus. We say a layer is already ``well-specialized'' in\na task if the within-class variability of its hidden states is low relative to\nthe between-class variability. Our variability metric is cheap to compute and\ndoesn't need any training or hyperparameter tuning. It is robust to data\nimbalance and data scarcity. Extensive experiments on the GLUE benchmark\ndemonstrate that selecting layers based on our metric can yield significantly\nstronger performance than using the same number of top layers and often match\nthe performance of fine-tuning or adapter-tuning the entire language model.",
    "descriptor": "",
    "authors": [
      "Shuo Xie",
      "Jiahao Qiu",
      "Ankita Pasad",
      "Li Du",
      "Qing Qu",
      "Hongyuan Mei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10041"
  },
  {
    "id": "arXiv:2210.10044",
    "title": "Deep Whole-Body Control: Learning a Unified Policy for Manipulation and  Locomotion",
    "abstract": "An attached arm can significantly increase the applicability of legged robots\nto several mobile manipulation tasks that are not possible for the wheeled or\ntracked counterparts. The standard hierarchical control pipeline for such\nlegged manipulators is to decouple the controller into that of manipulation and\nlocomotion. However, this is ineffective. It requires immense engineering to\nsupport coordination between the arm and legs, and error can propagate across\nmodules causing non-smooth unnatural motions. It is also biological implausible\ngiven evidence for strong motor synergies across limbs. In this work, we\npropose to learn a unified policy for whole-body control of a legged\nmanipulator using reinforcement learning. We propose Regularized Online\nAdaptation to bridge the Sim2Real gap for high-DoF control, and Advantage\nMixing exploiting the causal dependency in the action space to overcome local\nminima during training the whole-body system. We also present a simple design\nfor a low-cost legged manipulator, and find that our unified policy can\ndemonstrate dynamic and agile behaviors across several task setups. Videos are\nat https://maniploco.github.io",
    "descriptor": "\nComments: CoRL 2022 (Oral). Project website at this https URL\n",
    "authors": [
      "Zipeng Fu",
      "Xuxin Cheng",
      "Deepak Pathak"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.10044"
  },
  {
    "id": "arXiv:2210.10045",
    "title": "SafeText: A Benchmark for Exploring Physical Safety in Language Models",
    "abstract": "Understanding what constitutes safe text is an important issue in natural\nlanguage processing and can often prevent the deployment of models deemed\nharmful and unsafe. One such type of safety that has been scarcely studied is\ncommonsense physical safety, i.e. text that is not explicitly violent and\nrequires additional commonsense knowledge to comprehend that it leads to\nphysical harm. We create the first benchmark dataset, SafeText, comprising\nreal-life scenarios with paired safe and physically unsafe pieces of advice. We\nutilize SafeText to empirically study commonsense physical safety across\nvarious models designed for text generation and commonsense reasoning tasks. We\nfind that state-of-the-art large language models are susceptible to the\ngeneration of unsafe text and have difficulty rejecting unsafe advice. As a\nresult, we argue for further studies of safety and the assessment of\ncommonsense physical safety in models before release.",
    "descriptor": "\nComments: Accepted to EMNLP 2022\n",
    "authors": [
      "Sharon Levy",
      "Emily Allaway",
      "Melanie Subbiah",
      "Lydia Chilton",
      "Desmond Patton",
      "Kathleen McKeown",
      "William Yang Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10045"
  },
  {
    "id": "arXiv:2210.10046",
    "title": "A Tri-Layer Plugin to Improve Occluded Detection",
    "abstract": "Detecting occluded objects still remains a challenge for state-of-the-art\nobject detectors. The objective of this work is to improve the detection for\nsuch objects, and thereby improve the overall performance of a modern object\ndetector.\nTo this end we make the following four contributions: (1) We propose a simple\n'plugin' module for the detection head of two-stage object detectors to improve\nthe recall of partially occluded objects. The module predicts a tri-layer of\nsegmentation masks for the target object, the occluder and the occludee, and by\ndoing so is able to better predict the mask of the target object. (2) We\npropose a scalable pipeline for generating training data for the module by\nusing amodal completion of existing object detection and instance segmentation\ntraining datasets to establish occlusion relationships. (3) We also establish a\nCOCO evaluation dataset to measure the recall performance of partially occluded\nand separated objects. (4) We show that the plugin module inserted into a\ntwo-stage detector can boost the performance significantly, by only fine-tuning\nthe detection head, and with additional improvements if the entire architecture\nis fine-tuned. COCO results are reported for Mask R-CNN with Swin-T or Swin-S\nbackbones, and Cascade Mask R-CNN with a Swin-B backbone.",
    "descriptor": "\nComments: BMVC 2022\n",
    "authors": [
      "Guanqi Zhan",
      "Weidi Xie",
      "Andrew Zisserman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10046"
  },
  {
    "id": "arXiv:2210.10047",
    "title": "From Play to Policy: Conditional Behavior Generation from Uncurated  Robot Data",
    "abstract": "While large-scale sequence modeling from offline data has led to impressive\nperformance gains in natural language and image generation, directly\ntranslating such ideas to robotics has been challenging. One critical reason\nfor this is that uncurated robot demonstration data, i.e. play data, collected\nfrom non-expert human demonstrators are often noisy, diverse, and\ndistributionally multi-modal. This makes extracting useful, task-centric\nbehaviors from such data a difficult generative modeling problem. In this work,\nwe present Conditional Behavior Transformers (C-BeT), a method that combines\nthe multi-modal generation ability of Behavior Transformer with\nfuture-conditioned goal specification. On a suite of simulated benchmark tasks,\nwe find that C-BeT improves upon prior state-of-the-art work in learning from\nplay data by an average of 45.7%. Further, we demonstrate for the first time\nthat useful task-centric behaviors can be learned on a real-world robot purely\nfrom play data without any task labels or reward information. Robot videos are\nbest viewed on our project website: https://play-to-policy.github.io",
    "descriptor": "\nComments: Code and data available at: this https URL\n",
    "authors": [
      "Zichen Jeff Cui",
      "Yibin Wang",
      "Nur Muhammad",
      "Shafiullah",
      "Lerrel Pinto"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10047"
  },
  {
    "id": "arXiv:2210.08224",
    "title": "Struggling with change: The fragile resilience of collectives",
    "abstract": "Collectives form non-equilibrium social structures characterised by a\nvolatile dynamics. Individuals join or leave. Social relations change quickly.\nTherefore, differently from engineered or ecological systems, a resilient\nreference state cannot be defined. We propose a novel resilience measure\ncombining two dimensions: robustness and adaptivity. We demonstrate how they\ncan be quantified using data from a software developer collective. Our analysis\nreveals a resilience life cycle, i.e., stages of increasing resilience are\nfollowed by stages of decreasing resilience. We explain the reasons for these\nobserved dynamics and provide a formal model to reproduce them. The resilience\nlife cycle allows distinguishing between short-term resilience, given by a\nsequence of resilient states, and long-term resilience, which requires\ncollectives to survive through different cycles.",
    "descriptor": "",
    "authors": [
      "Frank Schweitzer",
      "Christian Zingg",
      "Giona Casiraghi"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ],
    "url": "https://arxiv.org/abs/2210.08224"
  },
  {
    "id": "arXiv:2210.08549",
    "title": "Automatic Emergency Dust-Free solution on-board International Space  Station with Bi-GRU (AED-ISS)",
    "abstract": "With a rising attention for the issue of PM2.5 or PM0.3, particulate matters\nhave become not only a potential threat to both the environment and human, but\nalso a harming existence to instruments onboard International Space Station\n(ISS). Our team is aiming to relate various concentration of particulate\nmatters to magnetic fields, humidity, acceleration, temperature, pressure and\nCO2 concentration. Our goal is to establish an early warning system (EWS),\nwhich is able to forecast the levels of particulate matters and provides ample\nreaction time for astronauts to protect their instruments in some experiments\nor increase the accuracy of the measurements; In addition, the constructed\nmodel can be further developed into a prototype of a remote-sensing smoke alarm\nfor applications related to fires. In this article, we will implement the\nBi-GRU (Bidirectional Gated Recurrent Unit) algorithms that collect data for\npast 90 minutes and predict the levels of particulates which over 2.5\nmicrometer per 0.1 liter for the next 1 minute, which is classified as an early\nwarning",
    "descriptor": "\nComments: 10 pages, 5 figures, and 1 table\n",
    "authors": [
      "Po-Han Hou",
      "Hong-Chun Hou",
      "Wei-Chih Lin",
      "Yu-Hao Huang",
      "Jih-Hong Shue"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.08549"
  },
  {
    "id": "arXiv:2210.09308",
    "title": "ProtoFold Neighborhood Inspector",
    "abstract": "Post-translational modifications (PTMs) affecting a protein's residues (amino\nacids) can disturb its function, leading to illness. Whether or not a PTM is\npathogenic depends on its type and the status of neighboring residues. In this\npaper, we present the ProtoFold Neighborhood Inspector (PFNI), a visualization\nsystem for analyzing residues neighborhoods. The main contribution is a\nvisualization idiom, the Residue Constellation (RC), for identifying and\ncomparing three-dimensional neighborhoods based on per-residue features and\nspatial characteristics. The RC leverages two-dimensional representations of\nthe protein's three-dimensional structure to overcome problems like occlusion,\neasing the analysis of neighborhoods that often have complicated spatial\narrangements. Using the PFNI, we explored proteins' structural PTM data, which\nallowed us to identify patterns in the distribution and quantity of\nper-neighborhood PTMs that might be related to their pathogenic status. In the\nfollowing, we define the tasks that guided the development of the PFNI and\ndescribe the data sources we derived and used. Then, we introduce the PFNI and\nillustrate its usage through an example of an analysis workflow. We conclude by\nreflecting on preliminary findings obtained while using the tool on the\nprovided data and future directions concerning the development of the PFNI.",
    "descriptor": "\nComments: Accepted submission for the Bio+MedVis challenge @ IEEE VIS 2022\n",
    "authors": [
      "Nicolas F. Chaves-de-Plaza",
      "Klaus Hildebrandt",
      "Anna Vilanova"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2210.09308"
  },
  {
    "id": "arXiv:2210.09309",
    "title": "RibSeg v2: A Large-scale Benchmark for Rib Labeling and Anatomical  Centerline Extraction",
    "abstract": "Automatic rib labeling and anatomical centerline extraction are common\nprerequisites for various clinical applications. Prior studies either use\nin-house datasets that are inaccessible to communities, or focus on rib\nsegmentation that neglects the clinical significance of rib labeling. To\naddress these issues, we extend our prior dataset (RibSeg) on the binary rib\nsegmentation task to a comprehensive benchmark, named RibSeg v2, with 660 CT\nscans (15,466 individual ribs in total) and annotations manually inspected by\nexperts for rib labeling and anatomical centerline extraction. Based on the\nRibSeg v2, we develop a pipeline including deep learning-based methods for rib\nlabeling, and a skeletonization-based method for centerline extraction. To\nimprove computational efficiency, we propose a sparse point cloud\nrepresentation of CT scans and compare it with standard dense voxel grids.\nMoreover, we design and analyze evaluation metrics to address the key\nchallenges of each task. Our dataset, code, and model are available online to\nfacilitate open research at https://github.com/M3DV/RibSeg",
    "descriptor": "\nComments: 10 pages, 6 figures, journal\n",
    "authors": [
      "Liang Jin",
      "Shixuan Gu",
      "Donglai Wei",
      "Kaiming Kuang",
      "Hanspeter Pfister",
      "Bingbing Ni",
      "Jiancheng Yang",
      "Ming Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09309"
  },
  {
    "id": "arXiv:2210.09321",
    "title": "On Optimal Subarchitectures for Quantum Circuit Mapping",
    "abstract": "Compiling a high-level quantum circuit down to a low-level description that\ncan be executed on state-of-the-art quantum computers is a crucial part of the\nsoftware stack for quantum computing. One step in compiling a quantum circuit\nto some device is quantum circuit mapping, where the circuit is transformed\nsuch that it complies with the architecture's limited qubit connectivity.\nBecause the search space in quantum circuit mapping grows exponentially in the\nnumber of qubits, it is desirable to consider as few of the device's physical\nqubits as possible in the process. Previous work conjectured that it suffices\nto consider only subarchitectures of a quantum computer composed of as many\nqubits as used in the circuit. In this work, we refute this conjecture and\nestablish criteria for judging whether considering larger parts of the\narchitecture might yield better solutions to the mapping problem. Through\nrigorous analysis, we show that determining subarchitectures that are of\nminimal size, i.e., of which no physical qubit can be removed without losing\nthe optimal mapping solution for some quantum circuit, is a very hard problem.\nBased on a relaxation of the criteria for optimality, we introduce a relaxed\nconsideration that still maintains optimality for practically relevant quantum\ncircuits. Eventually, this results in two methods for computing near-optimal\nsets of subarchitectures$\\unicode{x2014}$providing the basis for efficient\nquantum circuit mapping solutions. We demonstrate the benefits of this novel\nmethod for state-of-the-art quantum computers by IBM, Google and Rigetti.",
    "descriptor": "\nComments: 17 pages, 8 figures, 1 table\n",
    "authors": [
      "Tom Peham",
      "Lukas Burgholzer",
      "Robert Wille"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2210.09321"
  },
  {
    "id": "arXiv:2210.09334",
    "title": "TorchDIVA: An Extensible Computational Model of Speech Production built  on an Open-Source Machine Learning Library",
    "abstract": "The DIVA model is a computational model of speech motor control that combines\na simulation of the brain regions responsible for speech production with a\nmodel of the human vocal tract. The model is currently implemented in Matlab\nSimulink; however, this is less than ideal as most of the development in speech\ntechnology research is done in Python. This means there is a wealth of machine\nlearning tools which are freely available in the Python ecosystem that cannot\nbe easily integrated with DIVA. We present TorchDIVA, a full rebuild of DIVA in\nPython using PyTorch tensors. DIVA source code was directly translated from\nMatlab to Python, and built-in Simulink signal blocks were implemented from\nscratch. After implementation, the accuracy of each module was evaluated via\nsystematic block-by-block validation. The TorchDIVA model is shown to produce\noutputs that closely match those of the original DIVA model, with a negligible\ndifference between the two. We additionally present an example of the\nextensibility of TorchDIVA as a research platform. Speech quality enhancement\nin TorchDIVA is achieved through an integration with an existing PyTorch\ngenerative vocoder called DiffWave. A modified DiffWave mel-spectrum upsampler\nwas trained on human speech waveforms and conditioned on the TorchDIVA speech\nproduction. The results indicate improved speech quality metrics in the\nDiffWave-enhanced output as compared to the baseline. This enhancement would\nhave been difficult or impossible to accomplish in the original Matlab\nimplementation. This proof-of-concept demonstrates the value TorchDIVA will\nbring to the research community. Researchers can download the new\nimplementation at: https://github.com/skinahan/DIVA_PyTorch",
    "descriptor": "",
    "authors": [
      "Sean Kinahan",
      "Julie Liss",
      "Visar Berisha"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.09334"
  },
  {
    "id": "arXiv:2210.09343",
    "title": "Data-Driven Observability Decomposition with Koopman Operators for  Optimization of Output Functions of Nonlinear Systems",
    "abstract": "When complex systems with nonlinear dynamics achieve an output performance\nobjective, only a fraction of the state dynamics significantly impacts that\noutput. Those minimal state dynamics can be identified using the differential\ngeometric approach to the observability of nonlinear systems, but the theory is\nlimited to only analytical systems. In this paper, we extend the notion of\nnonlinear observable decomposition to the more general class of data-informed\nsystems. We employ Koopman operator theory, which encapsulates nonlinear\ndynamics in linear models, allowing us to bridge the gap between linear and\nnonlinear observability notions. We propose a new algorithm to learn Koopman\noperator representations that capture the system dynamics while ensuring that\nthe output performance measure is in the span of its observables. We show that\na transformation of this linear, output-inclusive Koopman model renders a new\nminimum Koopman representation. This representation embodies only the\nobservable portion of the nonlinear observable decomposition of the original\nsystem. A prime application of this theory is to identify genes in biological\nsystems that correspond to specific phenotypes, the performance measure. We\nsimulate two biological gene networks and demonstrate that the observability of\nKoopman operators can successfully identify genes that drive each phenotype. We\nanticipate our novel system identification tool will effectively discover\nreduced gene networks that drive complex behaviors in biological systems.",
    "descriptor": "\nComments: 17 pages, 4 figures, submission to Automatica\n",
    "authors": [
      "Shara Balakrishnan",
      "Aqib Hasnain",
      "Robert Egbert",
      "Enoch Yeung"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)",
      "Differential Geometry (math.DG)",
      "Molecular Networks (q-bio.MN)"
    ],
    "url": "https://arxiv.org/abs/2210.09343"
  },
  {
    "id": "arXiv:2210.09352",
    "title": "A Mixing Time Lower Bound for a Simplified Version of BART",
    "abstract": "Bayesian Additive Regression Trees (BART) is a popular Bayesian\nnon-parametric regression algorithm. The posterior is a distribution over sums\nof decision trees, and predictions are made by averaging approximate samples\nfrom the posterior.\nThe combination of strong predictive performance and the ability to provide\nuncertainty measures has led BART to be commonly used in the social sciences,\nbiostatistics, and causal inference.\nBART uses Markov Chain Monte Carlo (MCMC) to obtain approximate posterior\nsamples over a parameterized space of sums of trees, but it has often been\nobserved that the chains are slow to mix.\nIn this paper, we provide the first lower bound on the mixing time for a\nsimplified version of BART in which we reduce the sum to a single tree and use\na subset of the possible moves for the MCMC proposal distribution. Our lower\nbound for the mixing time grows exponentially with the number of data points.\nInspired by this new connection between the mixing time and the number of\ndata points, we perform rigorous simulations on BART. We show qualitatively\nthat BART's mixing time increases with the number of data points.\nThe slow mixing time of the simplified BART suggests a large variation\nbetween different runs of the simplified BART algorithm and a similar large\nvariation is known for BART in the literature. This large variation could\nresult in a lack of stability in the models, predictions, and posterior\nintervals obtained from the BART MCMC samples.\nOur lower bound and simulations suggest increasing the number of chains with\nthe number of data points.",
    "descriptor": "",
    "authors": [
      "Omer Ronen",
      "Theo Saarinen",
      "Yan Shuo Tan",
      "James Duncan",
      "Bin Yu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2210.09352"
  },
  {
    "id": "arXiv:2210.09403",
    "title": "A Transfer Learning Based Approach for Classification of COVID-19 and  Pneumonia in CT Scan Imaging",
    "abstract": "The world is still overwhelmed by the spread of the COVID-19 virus. With over\n250 Million infected cases as of November 2021 and affecting 219 countries and\nterritories, the world remains in the pandemic period. Detecting COVID-19 using\nthe deep learning method on CT scan images can play a vital role in assisting\nmedical professionals and decision authorities in controlling the spread of the\ndisease and providing essential support for patients. The convolution neural\nnetwork is widely used in the field of large-scale image recognition. The\ncurrent method of RT-PCR to diagnose COVID-19 is time-consuming and universally\nlimited. This research aims to propose a deep learning-based approach to\nclassify COVID-19 pneumonia patients, bacterial pneumonia, viral pneumonia, and\nhealthy (normal cases). This paper used deep transfer learning to classify the\ndata via Inception-ResNet-V2 neural network architecture. The proposed model\nhas been intentionally simplified to reduce the implementation cost so that it\ncan be easily implemented and used in different geographical areas, especially\nrural and developing regions.",
    "descriptor": "\nComments: 8 pages, 8 figures, under reviewing process\n",
    "authors": [
      "Gargi Desai",
      "Nelly Elsayed",
      "Zag Elsayed",
      "Murat Ozer"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09403"
  },
  {
    "id": "arXiv:2210.09409",
    "title": "Sufficient Exploration for Convex Q-learning",
    "abstract": "In recent years there has been a collective research effort to find new\nformulations of reinforcement learning that are simultaneously more efficient\nand more amenable to analysis. This paper concerns one approach that builds on\nthe linear programming (LP) formulation of optimal control of Manne. A primal\nversion is called logistic Q-learning, and a dual variant is convex Q-learning.\nThis paper focuses on the latter, while building bridges with the former. The\nmain contributions follow: (i) The dual of convex Q-learning is not precisely\nManne's LP or a version of logistic Q-learning, but has similar structure that\nreveals the need for regularization to avoid over-fitting. (ii) A sufficient\ncondition is obtained for a bounded solution to the Q-learning LP. (iii)\nSimulation studies reveal numerical challenges when addressing sampled-data\nsystems based on a continuous time model. The challenge is addressed using\nstate-dependent sampling. The theory is illustrated with applications to\nexamples from OpenAI gym. It is shown that convex Q-learning is successful in\ncases where standard Q-learning diverges, such as the LQR problem.",
    "descriptor": "",
    "authors": [
      "Fan Lu",
      "Prashant Mehta",
      "Sean Meyn",
      "Gergely Neu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09409"
  },
  {
    "id": "arXiv:2210.09444",
    "title": "A tradeoff between universality of equivariant models and learnability  of symmetries",
    "abstract": "We prove an impossibility result, which in the context of function learning\nsays the following: under certain conditions, it is impossible to\nsimultaneously learn symmetries and functions equivariant under them using an\nansatz consisting of equivariant functions. To formalize this statement, we\ncarefully study notions of approximation for groups and semigroups. We analyze\ncertain families of neural networks for whether they satisfy the conditions of\nthe impossibility result: what we call ``linearly equivariant'' networks, and\ngroup-convolutional networks. A lot can be said precisely about linearly\nequivariant networks, making them theoretically useful. On the practical side,\nour analysis of group-convolutional neural networks allows us generalize the\nwell-known ``convolution is all you need'' theorem to non-homogeneous spaces.\nWe additionally find an important difference between group convolution and\nsemigroup convolution.",
    "descriptor": "\nComments: 54 pages, 0 figures. Comments welcome\n",
    "authors": [
      "Vasco Portilheiro"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09444"
  },
  {
    "id": "arXiv:2210.09449",
    "title": "Early Diagnosis of Retinal Blood Vessel Damage via Deep Learning-Powered  Collective Intelligence Models",
    "abstract": "Early diagnosis of retinal diseases such as diabetic retinopathy has had the\nattention of many researchers. Deep learning through the introduction of\nconvolutional neural networks has become a prominent solution for image-related\ntasks such as classification and segmentation. Most tasks in image\nclassification are handled by deep CNNs pretrained and evaluated on imagenet\ndataset. However, these models do not always translate to the best result on\nother datasets. Devising a neural network manually from scratch based on\nheuristics may not lead to an optimal model as there are numerous\nhyperparameters in play. In this paper, we use two nature-inspired swarm\nalgorithms: particle swarm optimization (PSO) and ant colony optimization (ACO)\nto obtain TDCN models to perform classification of fundus images into severity\nclasses. The power of swarm algorithms is used to search for various\ncombinations of convolutional, pooling, and normalization layers to provide the\nbest model for the task. It is observed that TDCN-PSO outperforms imagenet\nmodels and existing literature, while TDCN-ACO achieves faster architecture\nsearch. The best TDCN model achieves an accuracy of 90.3%, AUC ROC of 0.956,\nand a Cohen kappa score of 0.967. The results were compared with the previous\nstudies to show that the proposed TDCN models exhibit superior performance.",
    "descriptor": "",
    "authors": [
      "Pranjal Bhardwaj",
      "Prajjwal Gupta",
      "Thejineaswar Guhan",
      "Kathiravan Srinivasan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2210.09449"
  },
  {
    "id": "arXiv:2210.09498",
    "title": "Double Upconversion for Superconducting Qubit Control realised using  Microstrip Filters",
    "abstract": "Superconducting qubits provide a promising platform for physically realising\nquantum computers at scale. Such devices require precision control at microwave\nfrequencies. Common practice is to synthesise such control signals using IQ\nmodulation, requiring calibration of a in-phase (I) and quadrature (Q) signals\nalongside two DC offsets to generate pure tones. This paper presents an\neconomic physical implementation of an alternative method referred to as double\nupconversion which requires considerably less hardware calibration and physical\nresources to operate a qubit. A physical circuit was created using standard PCB\ndesign techniques for microstrip filters and two common RF mixers. This circuit\nwas then utilised to successfully control a superconducting transmon qubit.\nWhen using proper RF shielding, qubit tones were demonstrated with over 70dB of\nspurious-free dynamic range across the entire operational spectrum of a\ntransmon qubit.",
    "descriptor": "",
    "authors": [
      "Jonathan Dearlove",
      "Prasanna Pakkiam",
      "Arkady Fedorov"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.09498"
  },
  {
    "id": "arXiv:2210.09513",
    "title": "Extracting speaker and emotion information from self-supervised speech  models via channel-wise correlations",
    "abstract": "Self-supervised learning of speech representations from large amounts of\nunlabeled data has enabled state-of-the-art results in several speech\nprocessing tasks. Aggregating these speech representations across time is\ntypically approached by using descriptive statistics, and in particular, using\nthe first- and second-order statistics of representation coefficients. In this\npaper, we examine an alternative way of extracting speaker and emotion\ninformation from self-supervised trained models, based on the correlations\nbetween the coefficients of the representations - correlation pooling. We show\nimprovements over mean pooling and further gains when the pooling methods are\ncombined via fusion. The code is available at\ngithub.com/Lamomal/s3prl_correlation.",
    "descriptor": "\nComments: Accepted at IEEE-SLT 2022\n",
    "authors": [
      "Themos Stafylakis",
      "Ladislav Mosner",
      "Sofoklis Kakouros",
      "Oldrich Plchot",
      "Lukas Burget",
      "Jan Cernocky"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.09513"
  },
  {
    "id": "arXiv:2210.09534",
    "title": "A Note on Robust Subsets of Transversal Matroids",
    "abstract": "Robust subsets of matroids were introduced by Huang and Sellier to propose\napproximate kernels for the matroid-constrained maximum vertex cover problem.\nIn this paper, we prove that the bound for robust subsets of transversal\nmatroids given by Huang and Sellier can be improved.",
    "descriptor": "",
    "authors": [
      "Naoyuki Kamiyama"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2210.09534"
  },
  {
    "id": "arXiv:2210.09554",
    "title": "A novel statistical methodology for quantifying the spatial arrangements  of axons in peripheral nerves",
    "abstract": "A thorough understanding of the neuroanatomy of peripheral nerves is required\nfor a better insight into their function and the development of neuromodulation\ntools and strategies. In biophysical modeling, it is commonly assumed that the\ncomplex spatial arrangement of myelinated and unmyelinated axons in peripheral\nnerves is random, however, in reality the axonal organization is inhomogeneous\nand anisotropic. Present quantitative neuroanatomy methods analyze peripheral\nnerves in terms of the number of axons and the morphometric characteristics of\nthe axons, such as area and diameter. In this study, we employed spatial\nstatistics and point process models to describe the spatial arrangement of\naxons and Sinkhorn distances to compute the similarities between these\narrangements (in terms of first- and second-order statistics) in various vagus\nand pelvic nerve cross-sections. We utilized high-resolution TEM images that\nhave been segmented using a custom-built high-throughput deep learning system\nbased on a highly modified U-Net architecture. Our findings show a novel and\ninnovative approach to quantifying similarities between spatial point patterns\nusing metrics derived from the solution to the optimal transport problem. We\nalso present a generalizable pipeline for quantitative analysis of peripheral\nnerve architecture. Our data demonstrate differences between male- and\nfemale-originating samples and similarities between the pelvic and abdominal\nvagus nerves.",
    "descriptor": "\nComments: 10 figures\n",
    "authors": [
      "Abida Sanjana Shemonti",
      "Emanuele Plebani",
      "Natalia P. Biscola",
      "Deborah M. Jaffey",
      "Leif A. Havton",
      "Janet R. Keast",
      "Alex Pothen",
      "M. Murat Dundar",
      "Terry L. Powley",
      "Bartek Rajwa"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2210.09554"
  },
  {
    "id": "arXiv:2210.09558",
    "title": "Bag of Tricks for Developing Diabetic Retinopathy Analysis Framework to  Overcome Data Scarcity",
    "abstract": "Recently, diabetic retinopathy (DR) screening utilizing ultra-wide optical\ncoherence tomography angiography (UW-OCTA) has been used in clinical practices\nto detect signs of early DR. However, developing a deep learning-based DR\nanalysis system using UW-OCTA images is not trivial due to the difficulty of\ndata collection and the absence of public datasets. By realistic constraints, a\nmodel trained on small datasets may obtain sub-par performance. Therefore, to\nhelp ophthalmologists be less confused about models' incorrect decisions, the\nmodels should be robust even in data scarcity settings. To address the above\npractical challenging, we present a comprehensive empirical study for DR\nanalysis tasks, including lesion segmentation, image quality assessment, and DR\ngrading. For each task, we introduce a robust training scheme by leveraging\nensemble learning, data augmentation, and semi-supervised learning.\nFurthermore, we propose reliable pseudo labeling that excludes uncertain\npseudo-labels based on the model's confidence scores to reduce the negative\neffect of noisy pseudo-labels. By exploiting the proposed approaches, we\nachieved 1st place in the Diabetic Retinopathy Analysis Challenge.",
    "descriptor": "",
    "authors": [
      "Gitaek Kwon",
      "Eunjin Kim",
      "Sunho Kim",
      "Seongwon Bak",
      "Minsung Kim",
      "Jaeyoung Kim"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09558"
  },
  {
    "id": "arXiv:2210.09606",
    "title": "Degradation-invariant Enhancement of Fundus Images via Pyramid  Constraint Network",
    "abstract": "As an economical and efficient fundus imaging modality, retinal fundus images\nhave been widely adopted in clinical fundus examination. Unfortunately, fundus\nimages often suffer from quality degradation caused by imaging interferences,\nleading to misdiagnosis. Despite impressive enhancement performances that\nstate-of-the-art methods have achieved, challenges remain in clinical\nscenarios. For boosting the clinical deployment of fundus image enhancement,\nthis paper proposes the pyramid constraint to develop a degradation-invariant\nenhancement network (PCE-Net), which mitigates the demand for clinical data and\nstably enhances unknown data. Firstly, high-quality images are randomly\ndegraded to form sequences of low-quality ones sharing the same content\n(SeqLCs). Then individual low-quality images are decomposed to Laplacian\npyramid features (LPF) as the multi-level input for the enhancement.\nSubsequently, a feature pyramid constraint (FPC) for the sequence is introduced\nto enforce the PCE-Net to learn a degradation-invariant model. Extensive\nexperiments have been conducted under the evaluation metrics of enhancement and\nsegmentation. The effectiveness of the PCE-Net was demonstrated in comparison\nwith state-of-the-art methods and the ablation study. The source code of this\nstudy is publicly available at\nhttps://github.com/HeverLaw/PCENet-Image-Enhancement.",
    "descriptor": "",
    "authors": [
      "Haofeng Liu",
      "Heng Li",
      "Huazhu Fu",
      "Ruoxiu Xiao",
      "Yunshu Gao",
      "Yan Hu",
      "Jiang Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09606"
  },
  {
    "id": "arXiv:2210.09611",
    "title": "Relationships between patenting trends and research activity for green  energy technologies",
    "abstract": "Green technology is viewed as a means of creating a sustainable society and a\ncatalyst for sustainable development by the global community. It is responsible\nfor both the potential reduction of production waste and the reduction of\ncarbon footprint and CO2 emissions. However, alongside with the growing\npopularity of green technologies, there is an emerging skepticism about their\ncontribution to solving environmental challenges. This article focuses on three\nareas of eco-innovation in green technology: renewable energy, hydrogen power,\nand decarbonization. Our main goal is to analyze the relationship between\npublication activity and the number of patented research results, thus shedding\nlight on the real-world applicability of scientific outcomes. We used several\nbibliometric methods for analyzing global publication and patent activity,\napplied to the Scopus citation database and the European Patent Office's patent\ndatabase. Our results show that the advancement of research in all three areas\nof eco-innovation does not automatically lead to the increase in the number of\npatents. We offer possible reasons for such dependency based on the\nobservations of the worldwide tendencies in green innovation sphere.",
    "descriptor": "\nComments: 11 pages, 3 figures\n",
    "authors": [
      "Regina Tuganova",
      "Anna Permyakova",
      "Anna Kuznetsova",
      "Karina Rakhmanova",
      "Natalia Monzul",
      "Roman Uvarov",
      "Elizaveta Kovtun",
      "Semen Budennyy"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Digital Libraries (cs.DL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.09611"
  },
  {
    "id": "arXiv:2210.09630",
    "title": "Completeness of Tableau Calculi for Two-Dimensional Hybrid Logics",
    "abstract": "Hybrid logic is one of the extensions of modal logic. The many-dimensional\nproduct of hybrid logic is called hybrid product logic (HPL). We construct a\nsound and complete tableau calculus for two-dimensional HPL. Also, we made a\ntableau calculus for Hybrid dependent Product Logic (HdPL), where one dimension\ndepends on the other. In addition, we add the special rule to the tableau\ncalculus for HdPL and show that it is still sound and complete. All of them\nlack termination, however.",
    "descriptor": "\nComments: 27 pages. 5 figures\n",
    "authors": [
      "Yuki Nishimura"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.09630"
  },
  {
    "id": "arXiv:2210.09636",
    "title": "Split-KalmanNet: A Robust Model-Based Deep Learning Approach for SLAM",
    "abstract": "Simultaneous localization and mapping (SLAM) is a method that constructs a\nmap of an unknown environment and localizes the position of a moving agent on\nthe map simultaneously. Extended Kalman filter (EKF) has been widely adopted as\na low complexity solution for online SLAM, which relies on a motion and\nmeasurement model of the moving agent. In practice, however, acquiring precise\ninformation about these models is very challenging, and the model mismatch\neffect causes severe performance loss in SLAM. In this paper, inspired by the\nrecently proposed KalmanNet, we present a robust EKF algorithm using the power\nof deep learning for online SLAM, referred to as Split-KalmanNet. The key idea\nof Split-KalmanNet is to compute the Kalman gain using the Jacobian matrix of a\nmeasurement function and two recurrent neural networks (RNNs). The two RNNs\nindependently learn the covariance matrices for a prior state estimate and the\ninnovation from data. The proposed split structure in the computation of the\nKalman gain allows to compensate for state and measurement model mismatch\neffects independently. Numerical simulation results verify that Split-KalmanNet\noutperforms the traditional EKF and the state-of-the-art KalmanNet algorithm in\nvarious model mismatch scenarios.",
    "descriptor": "\nComments: 6 pages, 6 figures\n",
    "authors": [
      "Geon Choi",
      "Jeonghun Park",
      "Nir Shlezinger",
      "Yonina C. Eldar",
      "Namyoon Lee"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.09636"
  },
  {
    "id": "arXiv:2210.09659",
    "title": "Large-Scale Bandwidth and Power Optimization for Multi-Modal Edge  Intelligence Autonomous Driving",
    "abstract": "Edge intelligence autonomous driving (EIAD) offers computing resources in\nautonomous vehicles for training deep neural networks. However, wireless\nchannels between the edge server and autonomous vehicles are time-varying due\nto the high-mobility of vehicles. Moreover, the required number of training\nsamples for different data modalities (e.g., images, point-clouds) is diverse.\nConsequently, when collecting these datasets from vehicles to the edge server,\nthe associated bandwidth and power allocation across all data frames is a\nlarge-scale multi-modal optimization problem. This article proposes a highly\ncomputationally efficient algorithm that directly maximizes the quality of\ntraining (QoT). The key ingredients include a data-driven model for quantifying\nthe priority of data modality and two first-order methods termed accelerated\ngradient projection and dual decomposition for low-complexity resource\nallocation. High-fidelity simulations in Car Learning to Act (CARLA) show that\nthe proposed algorithm reduces the perception error by $3\\%$ and the\ncomputation time by $98\\%$.",
    "descriptor": "\nComments: Submitted to IEEE\n",
    "authors": [
      "Xinrao Li",
      "Tong Zhang",
      "Shuai Wang",
      "Guangxu Zhu",
      "Rui Wang",
      "Tsung-Hui Chang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.09659"
  },
  {
    "id": "arXiv:2210.09695",
    "title": "Consistent Multiclass Algorithms for Complex Metrics and Constraints",
    "abstract": "We present consistent algorithms for multiclass learning with complex\nperformance metrics and constraints, where the objective and constraint are\ndefined by arbitrary functions of the confusion matrix. This setting includes\nmany common performance metrics such as the multiclass G-mean and micro\nF1-measure, and constraints such as those on the classifier's precision and\nrecall and more recent measures of fairness discrepancy. We give a general\nframework for designing consistent algorithms for such complex design goals by\nviewing the learning problem as an optimization problem over the set of\nfeasible confusion matrices. We provide multiple instantiations of our\nframework under different assumptions on the performance metrics and\nconstraints, and in each case show rates of convergence to the optimal\n(feasible) classifier (and this asymptotic consistency). Experiments on a\nvariety of multiclass classification and fairness-constrained problems show\nthat our algorithms compare favorably to the state-of-the-art baselines.",
    "descriptor": "",
    "authors": [
      "Harikrishna Narasimhan",
      "Harish G. Ramaswamy",
      "Shiv Kumar Tavker",
      "Drona Khurana",
      "Praneeth Netrapalli",
      "Shivani Agarwal"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09695"
  },
  {
    "id": "arXiv:2210.09709",
    "title": "Importance Weighting Correction of Regularized Least-Squares for  Covariate and Target Shifts",
    "abstract": "In many real world problems, the training data and test data have different\ndistributions. This situation is commonly referred as a dataset shift. The most\ncommon settings for dataset shift often considered in the literature are {\\em\ncovariate shift } and {\\em target shift}. Importance weighting (IW) correction\nis a universal method for correcting the bias present in learning scenarios\nunder dataset shift. The question one may ask is: does IW correction work\nequally well for different dataset shift scenarios? By investigating the\ngeneralization properties of the weighted kernel ridge regression (W-KRR) under\ncovariate and target shifts we show that the answer is negative, except when IW\nis bounded and the model is wellspecified. In the latter cases, a minimax\noptimal rates are achieved by importance weighted kernel ridge regression\n(IW-KRR) in both, covariate and target shift scenarios. Slightly relaxing the\nboundedness condition of the IW we show that the IW-KRR still achieves the\noptimal rates under target shift while leading to slower rates for covariate\nshift. In the case of the model misspecification we show that the performance\nof the W-KRR under covariate shift could be substantially increased by\ndesigning an alternative reweighting function. The distinction between\nmisspecified and wellspecified scenarios does not seem to be crucial in the\nlearning problems under target shift.",
    "descriptor": "",
    "authors": [
      "Davit Gogolashvili"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2210.09709"
  },
  {
    "id": "arXiv:2210.09728",
    "title": "3D Scalable Quantum Convolutional Neural Networks for Point Cloud Data  Processing in Classification Applications",
    "abstract": "With the beginning of the noisy intermediate-scale quantum (NISQ) era, a\nquantum neural network (QNN) has recently emerged as a solution for several\nspecific problems that classical neural networks cannot solve. Moreover, a\nquantum convolutional neural network (QCNN) is the quantum-version of CNN\nbecause it can process high-dimensional vector inputs in contrast to QNN.\nHowever, due to the nature of quantum computing, it is difficult to scale up\nthe QCNN to extract a sufficient number of features due to barren plateaus.\nMotivated by this, a novel 3D scalable QCNN (sQCNN-3D) is proposed for point\ncloud data processing in classification applications. Furthermore, reverse\nfidelity training (RF-Train) is additionally considered on top of sQCNN-3D for\ndiversifying features with a limited number of qubits using the fidelity of\nquantum computing. Our data-intensive performance evaluation verifies that the\nproposed algorithm achieves desired performance.",
    "descriptor": "",
    "authors": [
      "Hankyul Baek",
      "Won Joon Yun",
      "Joongheon Kim"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09728"
  },
  {
    "id": "arXiv:2210.09736",
    "title": "Spectral solver for Cauchy problems in polar coordinates using discrete  Hankel transforms",
    "abstract": "We introduce a Fourier-Bessel-based spectral solver for Cauchy problems\nfeaturing Laplacians in polar coordinates under homogeneous Dirichlet boundary\nconditions. We use FFTs in the azimuthal direction to isolate angular modes,\nthen perform discrete Hankel transform (DHT) on each mode along the radial\ndirection to obtain spectral coefficients. The two transforms are connected via\nnumerical and cardinal interpolations. We analyze the boundary-dependent error\nbound of DHT; the worst case is $\\sim N^{-3/2}$, which governs the method, and\nthe best $\\sim e^{-N}$, which then the numerical interpolation governs. The\ncomplexity is $O[N^3]$. Taking advantage of Bessel functions being the\neigenfunctions of the Laplacian operator, we solve linear equations for all\ntimes. For non-linear equations, we use a time-splitting method to integrate\nthe solutions. We show examples and validate the method on the two-dimensional\nwave equation, which is linear, and on two non-linear problems: a\ntime-dependent Poiseuille flow and the flow of a Bose-Einstein condensate on a\ndisk.",
    "descriptor": "",
    "authors": [
      "Rundong Zhou",
      "Nicolas Grisouard"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Quantum Gases (cond-mat.quant-gas)",
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2210.09736"
  },
  {
    "id": "arXiv:2210.09745",
    "title": "Transfer learning with affine model transformation",
    "abstract": "Supervised transfer learning (TL) has received considerable attention because\nof its potential to boost the predictive power of machine learning in cases\nwith limited data. In a conventional scenario, cross-domain differences are\nmodeled and estimated using a given set of source models and samples from a\ntarget domain. For example, if there is a functional relationship between\nsource and target domains, only domain-specific factors are additionally\nlearned using target samples to shift the source models to the target. However,\nthe general methodology for modeling and estimating such cross-domain shifts\nhas been less studied. This study presents a TL framework that simultaneously\nand separately estimates domain shifts and domain-specific factors using given\ntarget samples. Assuming consistency and invertibility of the domain\ntransformation functions, we derive an optimal family of functions to represent\nthe cross-domain shift. The newly derived class of transformation functions\ntakes the same form as invertible neural networks using affine coupling layers,\nwhich are widely used in generative deep learning. We show that the proposed\nmethod encompasses a wide range of existing methods, including the most common\nTL procedure based on feature extraction using neural networks. We also clarify\nthe theoretical properties of the proposed method, such as the convergence rate\nof the generalization error, and demonstrate the practical benefits of\nseparately modeling and estimating domain-specific factors through several case\nstudies.",
    "descriptor": "\nComments: 32 pages\n",
    "authors": [
      "Shunya Minami",
      "Kenji Fukumizu",
      "Yoshihiro Hayashi",
      "Ryo Yoshida"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09745"
  },
  {
    "id": "arXiv:2210.09783",
    "title": "Machine-Learning-Optimized Perovskite Nanoplatelet Synthesis",
    "abstract": "With the demand for renewable energy and efficient devices rapidly\nincreasing, a need arises to find and optimize novel (nano)materials. This can\nbe an extremely tedious process, often relying significantly on trial and\nerror. Machine learning has emerged recently as a powerful alternative;\nhowever, most approaches require a substantial amount of data points, i.e.,\nsyntheses. Here, we merge three machine-learning models with Bayesian\nOptimization and are able to dramatically improve the quality of CsPbBr3\nnanoplatelets (NPLs) using only approximately 200 total syntheses. The\nalgorithm can predict the resulting PL emission maxima of the NPL dispersions\nbased on the precursor ratios, which lead to previously unobtainable 7 and 8 ML\nNPLs. Aided by heuristic knowledge, the algorithm should be easily applicable\nto other nanocrystal syntheses and significantly help to identify interesting\ncompositions and rapidly improve their quality.",
    "descriptor": "",
    "authors": [
      "Carola Lampe",
      "Ioannis Kouroudis",
      "Milan Harth",
      "Stefan Martin",
      "Alessio Gagliardi",
      "Alexander S. Urban"
    ],
    "subjectives": [
      "Applied Physics (physics.app-ph)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09783"
  },
  {
    "id": "arXiv:2210.09784",
    "title": "Generalized Many-Body Dispersion Correction through Random-phase  Approximation for Chemically Accurate Density Functional Theory",
    "abstract": "We extend our recently proposed Deep Learning-aided many-body dispersion\n(DNN-MBD) model to quadrupole polarizability (Q) terms using a generalized\nRandom Phase Approximation (RPA) formalism enabling to include van der Waals\ncontributions beyond dipole. The resulting DNN-MBDQ model only relies on ab\ninitio-derived quantities as the introduced quadrupole polarizabilities are\nrecursively retrieved from dipole ones, in turn modelled via the\nTkatchenko-Scheffler method. A transferable and efficient deep-neuronal network\n(DNN) provides atom in molecule volumes, while a single range-separation\nparameter is used to couple the model to Density Functional Theory (DFT). Since\nit can be computed at negligible cost, the DNN-MBDQ approach can be coupled\nwith DFT functionals such as as PBE/PBE0 or B86bPBE(dispersionless).\nDNN-MBQ-PBE/PBE0 reaches chemical accuracy exhibiting superior accuracy\ncompared to other dispersion-corrected models, especially at near-equilibrium\nranges where errors are lowered by nearly 25% compared to our dipole-only\napproach while gains reach nearly 50% compared to other corrected schemes.",
    "descriptor": "",
    "authors": [
      "Pier Paolo Poier",
      "Louis Lagard\u00e8re",
      "Jean-Philip Piquemal"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09784"
  },
  {
    "id": "arXiv:2210.09786",
    "title": "Bagged $k$-Distance for Mode-Based Clustering Using the Probability of  Localized Level Sets",
    "abstract": "In this paper, we propose an ensemble learning algorithm named \\textit{bagged\n$k$-distance for mode-based clustering} (\\textit{BDMBC}) by putting forward a\nnew measurement called the \\textit{probability of localized level sets}\n(\\textit{PLLS}), which enables us to find all clusters for varying densities\nwith a global threshold. On the theoretical side, we show that with a properly\nchosen number of nearest neighbors $k_D$ in the bagged $k$-distance, the\nsub-sample size $s$, the bagging rounds $B$, and the number of nearest\nneighbors $k_L$ for the localized level sets, BDMBC can achieve optimal\nconvergence rates for mode estimation. It turns out that with a relatively\nsmall $B$, the sub-sample size $s$ can be much smaller than the number of\ntraining data $n$ at each bagging round, and the number of nearest neighbors\n$k_D$ can be reduced simultaneously. Moreover, we establish optimal convergence\nresults for the level set estimation of the PLLS in terms of Hausdorff\ndistance, which reveals that BDMBC can find localized level sets for varying\ndensities and thus enjoys local adaptivity. On the practical side, we conduct\nnumerical experiments to empirically verify the effectiveness of BDMBC for mode\nestimation and level set estimation, which demonstrates the promising accuracy\nand efficiency of our proposed algorithm.",
    "descriptor": "",
    "authors": [
      "Hanyuan Hang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09786"
  },
  {
    "id": "arXiv:2210.09837",
    "title": "Deep Scattering Spectrum germaneness to Fault Detection and Diagnosis  for Component-level Prognostics and Health Management (PHM)",
    "abstract": "In fault detection and diagnosis of prognostics and health management (PHM)\nsystems, most of the methodologies utilize machine learning (ML) or deep\nlearning (DL) through which either some features are extracted beforehand (in\nthe case of ML) or filters are used to extract features autonomously (in case\nof DL) to perform the critical classification task. Particularly in the fault\ndetection and diagnosis of industrial robots where electric current, vibration\nor acoustic emissions signals are the primary sources of information, a feature\ndomain that can map the signals into their constituent components with\ncompressed information at different levels can reduce the complexities and size\nof typical ML and DL-based frameworks. The Deep Scattering Spectrum (DSS) is\none of the strategies that use the Wavelet Transform (WT) analogy to separate\nand extract the information encoded in a signal's various temporal and\nfrequency domains. As a result, the focus of this work is on the study of the\nDSS's relevance to fault detection and daignosis for mechanical components of\nindustrail robots. We used multiple industrial robots and distinct mechanical\nfaults to build an approach for classifying the faults using low-variance\nfeatures extracted from the input signals. The presented approach was\nimplemented on the practical test benches and demonstrated satisfactory\nperformance in fault detection and diagnosis for simple and complex\nclassification problems with a classification accuracy of 99.7% and 88.1%,\nrespectively.",
    "descriptor": "",
    "authors": [
      "Ali Rohan"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.09837"
  },
  {
    "id": "arXiv:2210.09850",
    "title": "Near Real-time CO$_2$ Emissions Based on Carbon Satellite And Artificial  Intelligence",
    "abstract": "To limit global warming to pre-industrial levels, global governments,\nindustry and academia are taking aggressive efforts to reduce carbon emissions.\nThe evaluation of anthropogenic carbon dioxide (CO$_2$) emissions, however,\ndepends on the self-reporting information that is not always reliable. Society\nneed to develop an objective, independent, and generalized system to meter\nCO$_2$ emissions. Satellite CO$_2$ observation from space that reports\ncolumn-average regional CO$_2$ dry-air mole fractions has gradually indicated\nits potential to build such a system. Nevertheless, estimating anthropogenic\nCO$_2$ emissions from CO$_2$ observing satellite is bottlenecked by the\ninfluence of the highly complicated physical characteristics of atmospheric\nactivities. Here we provide the first method that combines the advanced\nartificial intelligence (AI) techniques and the carbon satellite monitor to\nquantify anthropogenic CO$_2$ emissions. We propose an integral AI based\npipeline that contains both a data retrieval algorithm and a two-step\ndata-driven solution. First, the data retrieval algorithm can generate\neffective datasets from multi-modal data including carbon satellite, the\ninformation of carbon sources, and several environmental factors. Second, the\ntwo-step data-driven solution that applies the powerful representation of deep\nlearning techniques to learn to quantify anthropogenic CO$_2$ emissions from\nsatellite CO$_2$ observation with other factors. Our work unmasks the potential\nof quantifying CO$_2$ emissions based on the combination of deep learning\nalgorithms and the carbon satellite monitor.",
    "descriptor": "",
    "authors": [
      "Zhengwen Zhang",
      "Jingjin Gu",
      "Junhua Zhao",
      "Jianwei Huang",
      "Haifeng Wu"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09850"
  },
  {
    "id": "arXiv:2210.09884",
    "title": "Is Dogecoin a Viable Investment? Insights from Network and Bubble  Effects",
    "abstract": "We find that three factors: Dogecoin network externalities, momentum, and\ntweet sentiment that capture the time-series expected Dogecoin returns.\nDogecoin returns are exposed to Dogecoin network factors. We construct the\nnetwork factors to capture the user adoption of Dogecoin. Moreover, there is a\nstrong time-series momentum effect, and proxies for investor attention strongly\nforecast future Dogecoin returns. Lastly, we examine potential underlying\nmechanisms of the Dogecoin price bubble.",
    "descriptor": "",
    "authors": [
      "Ruoxin Xiao",
      "Xinyu Ying",
      "Hengxu Li",
      "Kexin Liu"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.09884"
  },
  {
    "id": "arXiv:2210.09897",
    "title": "Learning to simulate realistic limit order book markets from data as a  World Agent",
    "abstract": "Multi-agent market simulators usually require careful calibration to emulate\nreal markets, which includes the number and the type of agents. Poorly\ncalibrated simulators can lead to misleading conclusions, potentially causing\nsevere loss when employed by investment banks, hedge funds, and traders to\nstudy and evaluate trading strategies. In this paper, we propose a world model\nsimulator that accurately emulates a limit order book market -- it requires no\nagent calibration but rather learns the simulated market behavior directly from\nhistorical data. Traditional approaches fail short to learn and calibrate\ntrader population, as historical labeled data with details on each individual\ntrader strategy is not publicly available. Our approach proposes to learn a\nunique \"world\" agent from historical data. It is intended to emulate the\noverall trader population, without the need of making assumptions about\nindividual market agent strategies. We implement our world agent simulator\nmodels as a Conditional Generative Adversarial Network (CGAN), as well as a\nmixture of parametric distributions, and we compare our models against previous\nwork. Qualitatively and quantitatively, we show that the proposed approaches\nconsistently outperform previous work, providing more realism and\nresponsiveness.",
    "descriptor": "",
    "authors": [
      "Andrea Coletta",
      "Aymeric Moulin",
      "Svitlana Vyetrenko",
      "Tucker Balch"
    ],
    "subjectives": [
      "Trading and Market Microstructure (q-fin.TR)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Computational Finance (q-fin.CP)"
    ],
    "url": "https://arxiv.org/abs/2210.09897"
  },
  {
    "id": "arXiv:2210.09913",
    "title": "Measure-Theoretic Probability of Complex Co-occurrence and E-Integral",
    "abstract": "Complex high-dimensional co-occurrence data are increasingly popular from a\ncomplex system of interacting physical, biological and social processes in\ndiscretely indexed modifiable areal units or continuously indexed locations of\na study region for landscape-based mechanism. Modeling, predicting and\ninterpreting complex co-occurrences are very general and fundamental problems\nof statistical and machine learning in a broad variety of real-world modern\napplications. Probability and conditional probability of co-occurrence are\nintroduced by being defined in a general setting with set functions to develop\na rigorous measure-theoretic foundation for the inherent challenge of data\nsparseness. The data sparseness is a main challenge inherent to probabilistic\nmodeling and reasoning of co-occurrence in statistical inference. The behavior\nof a class of natural integrals called E-integrals is investigated based on the\ndefined conditional probability of co-occurrence. The results on the properties\nof E-integral are presented. The paper offers a novel measure-theoretic\nframework where E-integral as a basic measure-theoretic concept can be the\nstarting point for the expectation functional approach preferred by Whittle\n(1992) and Pollard (2001) to the development of probability theory for the\ninherent challenge of co-occurrences emerging in modern high-dimensional\nco-occurrence data problems and opens the doors to more sophisticated and\ninteresting research in complex high-dimensional co-occurrence data science.",
    "descriptor": "",
    "authors": [
      "Jian-Yong Wang",
      "Han Yu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09913"
  },
  {
    "id": "arXiv:2210.09920",
    "title": "An Efficient Ratio Detector for Ambient Backscatter Communication",
    "abstract": "Ambient backscatter communication (AmBC) leverages the existing ambient radio\nfrequency (RF) environment to implement communication with battery-free\ndevices. One critical challenge of AmBC systems is signal recovery because the\ntransmitted information bits are embedded in the ambient RF signals and these\nare unknown and uncontrollable. To address this problem, most existing\napproaches use averaging-based energy detectors and consequently the data rate\nis low and there is an error floor. Here we propose a new detection strategy\nbased on the ratio between signals received from a multiple-antenna Reader. The\nadvantage of using the ratio is that ambient RF signals are removed directly\nfrom the embedded signals without averaging and hence it can increase data\nrates and avoid the error floor. Different from original ratio detectors that\nuse the magnitude ratio of the signals between two Reader antennas, in our\nproposed approach, we utilize the complex ratio so that phase information is\npreserved and propose an accurate linear channel model approximation. This\nallows the application of existing linear detection techniques from which we\ncan obtain a minimum distance detector and closed-form expressions for bit\nerror rate (BER). In addition, averaging, coding and interleaving can also be\nincluded to further enhance the BER. The results are also general, allowing any\nnumber of Reader antennas to be utilized in the approach. Numerical results\ndemonstrate that the proposed approach performs better than approaches based on\nenergy detection and original ratio detectors.",
    "descriptor": "",
    "authors": [
      "Wenjing Liu",
      "Shanpu Shen",
      "Danny H. K. Tsang",
      "Ranjan K. Mallik",
      "Ross Murch"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.09920"
  },
  {
    "id": "arXiv:2210.09929",
    "title": "Differentially Private Diffusion Models",
    "abstract": "While modern machine learning models rely on increasingly large training\ndatasets, data is often limited in privacy-sensitive domains. Generative models\ntrained with differential privacy (DP) on sensitive data can sidestep this\nchallenge, providing access to synthetic data instead. However, training DP\ngenerative models is highly challenging due to the noise injected into training\nto enforce DP. We propose to leverage diffusion models (DMs), an emerging class\nof deep generative models, and introduce Differentially Private Diffusion\nModels (DPDMs), which enforce privacy using differentially private stochastic\ngradient descent (DP-SGD). We motivate why DP-SGD is well suited for training\nDPDMs, and thoroughly investigate the DM parameterization and the sampling\nalgorithm, which turn out to be crucial ingredients in DPDMs. Furthermore, we\npropose noise multiplicity, a simple yet powerful modification of the DM\ntraining objective tailored to the DP setting to boost performance. We validate\nour novel DPDMs on widely-used image generation benchmarks and achieve\nstate-of-the-art (SOTA) performance by large margins. For example, on MNIST we\nimprove the SOTA FID from 48.4 to 5.01 and downstream classification accuracy\nfrom 83.2% to 98.1% for the privacy setting DP-$(\\varepsilon{=}10,\n\\delta{=}10^{-5})$. Moreover, on standard benchmarks, classifiers trained on\nDPDM-generated synthetic data perform on par with task-specific DP-SGD-trained\nclassifiers, which has not been demonstrated before for DP generative models.\nProject page and code: https://nv-tlabs.github.io/DPDM.",
    "descriptor": "",
    "authors": [
      "Tim Dockhorn",
      "Tianshi Cao",
      "Arash Vahdat",
      "Karsten Kreis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09929"
  },
  {
    "id": "arXiv:2210.09937",
    "title": "Wijesekera-style constructive modal logics",
    "abstract": "We define a family of propositional constructive modal logics corresponding\neach to a different classical modal system. The logics are defined in the style\nof Wijesekera's constructive modal logic, and are both proof-theoretically and\nsemantically motivated. On the one hand, they correspond to the\nsingle-succedent restriction of standard sequent calculi for classical modal\nlogics. On the other hand, they are obtained by incorporating the\nhereditariness of intuitionistic Kripke models into the classical satisfaction\nclauses for modal formulas. We show that, for the considered classical logics,\nthe proof-theoretical and the semantical approach return the same constructive\nsystems.",
    "descriptor": "\nComments: To appear in: David Fern\\'andez-Duque, Alessandra Palmigiano and Sophie Pinchinat (eds), Advances in Modal Logic 14, College Publications, 2022\n",
    "authors": [
      "Tiziano Dalmonte"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.09937"
  },
  {
    "id": "arXiv:2210.09974",
    "title": "Theoretical Guarantees for Permutation-Equivariant Quantum Neural  Networks",
    "abstract": "Despite the great promise of quantum machine learning models, there are\nseveral challenges one must overcome before unlocking their full potential. For\ninstance, models based on quantum neural networks (QNNs) can suffer from\nexcessive local minima and barren plateaus in their training landscapes.\nRecently, the nascent field of geometric quantum machine learning (GQML) has\nemerged as a potential solution to some of those issues. The key insight of\nGQML is that one should design architectures, such as equivariant QNNs,\nencoding the symmetries of the problem at hand. Here, we focus on problems with\npermutation symmetry (i.e., the group of symmetry $S_n$), and show how to build\n$S_n$-equivariant QNNs. We provide an analytical study of their performance,\nproving that they do not suffer from barren plateaus, quickly reach\noverparametrization, and can generalize well from small amounts of data. To\nverify our results, we perform numerical simulations for a graph state\nclassification task. Our work provides the first theoretical guarantees for\nequivariant QNNs, thus indicating the extreme power and potential of GQML.",
    "descriptor": "\nComments: 14+22 pages, 5 + 5 figures\n",
    "authors": [
      "Louis Schatzki",
      "Martin Larocca",
      "Frederic Sauvage",
      "M. Cerezo"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.09974"
  },
  {
    "id": "arXiv:2210.09975",
    "title": "Risk of re-identification for shared clinical speech recordings",
    "abstract": "Large, curated datasets are required to leverage speech-based tools in\nhealthcare. These are costly to produce, resulting in increased interest in\ndata sharing. As speech can potentially identify speakers (i.e., voiceprints),\nsharing recordings raises privacy concerns. We examine the re-identification\nrisk for speech recordings, without reference to demographic or metadata, using\na state-of-the-art speaker recognition system. We demonstrate that the risk is\ninversely related to the number of comparisons an adversary must consider,\ni.e., the search space. Risk is high for a small search space but drops as the\nsearch space grows ($precision >0.85$ for $<1*10^{6}$ comparisons, $precision\n<0.5$ for $>3*10^{6}$ comparisons). Next, we show that the nature of a speech\nrecording influences re-identification risk, with non-connected speech (e.g.,\nvowel prolongation) being harder to identify. Our findings suggest that speaker\nrecognition systems can be used to re-identify participants in specific\ncircumstances, but in practice, the re-identification risk appears low.",
    "descriptor": "\nComments: 24 pages, 6 figures\n",
    "authors": [
      "Daniela A. Wiepert",
      "Bradley A. Malin",
      "Joseph R. Duffy",
      "Rene L. Utianski",
      "John L. Stricker",
      "David T. Jones",
      "Hugo Botha"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.09975"
  },
  {
    "id": "arXiv:2210.09979",
    "title": "Multivariate Super-Resolution without Separation",
    "abstract": "In this paper we study the high-dimensional super-resolution imaging problem.\nHere we are given an image of a number of point sources of light whose\nlocations and intensities are unknown. The image is pixelized and is blurred by\na known point-spread function arising from the imaging device. We encode the\nunknown point sources and their intensities via a nonnegative measure and we\npropose a convex optimization program to find it. Assuming the device's\npoint-spread function is component-wise decomposable, we show that the optimal\nsolution is the true measure in the noiseless case, and it approximates the\ntrue measure well in the noisy case with respect to the generalized Wasserstein\ndistance. Our main assumption is that the components of the point-spread\nfunction form a Tchebychev system ($T$-system) in the noiseless case and a\n$T^*$-system in the noisy case, mild conditions that are satisfied by Gaussian\npoint-spread functions. Our work is a generalization to all dimensions of the\nwork (Eftekhari, Bendory, & Tang, 2021) where the same analysis is carried out\nin 2 dimensions. We resolve an open problem posed in (Schiebinger, Robeva, &\nRecht, 2018) in the case when the point-spread function decomposes.",
    "descriptor": "",
    "authors": [
      "Bakytzhan Kurmanbek",
      "Elina Robeva"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.09979"
  },
  {
    "id": "arXiv:2210.09986",
    "title": "Phase transition in the computational complexity of the shortest common  superstring and genome assembly",
    "abstract": "Genome assembly, the process of reconstructing a long genetic sequence by\naligning and merging short fragments, or reads, is known to be NP-hard, either\nas a version of the shortest common superstring problem or in a\nHamiltonian-cycle formulation. That is, the computing time is believed to grow\nexponentially with the the problem size in the worst case. Despite this fact,\nhigh-throughput technologies and modern algorithms currently allow\nbioinformaticians to produce and assemble datasets of billions of reads. Using\nmethods from statistical mechanics, we address this conundrum by demonstrating\nthe existence of a phase transition in the computational complexity of the\nproblem and showing that practical instances always fall in the `easy' phase\n(solvable by polynomial-time algorithms). In addition, we propose a\nMarkov-chain Monte Carlo method that outperforms common deterministic\nalgorithms in the hard regime.",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "L. A. Fernandez",
      "V. Martin-Mayor",
      "D. Yllanes"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Computational Complexity (cs.CC)",
      "Biological Physics (physics.bio-ph)",
      "Genomics (q-bio.GN)"
    ],
    "url": "https://arxiv.org/abs/2210.09986"
  },
  {
    "id": "arXiv:2210.09998",
    "title": "Locally Smoothed Gaussian Process Regression",
    "abstract": "We develop a novel framework to accelerate Gaussian process regression (GPR).\nIn particular, we consider localization kernels at each data point to\ndown-weigh the contributions from other data points that are far away, and we\nderive the GPR model stemming from the application of such localization\noperation. Through a set of experiments, we demonstrate the competitive\nperformance of the proposed approach compared to full GPR, other localized\nmodels, and deep Gaussian processes. Crucially, these performances are obtained\nwith considerable speedups compared to standard global GPR due to the\nsparsification effect of the Gram matrix induced by the localization operation.",
    "descriptor": "",
    "authors": [
      "Davit Gogolashvili",
      "Bogdan Kozyrskiy",
      "Maurizio Filippone"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09998"
  },
  {
    "id": "arXiv:2210.10001",
    "title": "Algebraic and context-free subsets of subgroups",
    "abstract": "We study the relation between the structure of algebraic and context-free\nsubsets of a group G and that of a finite index subgroup H. Using these\nresults, we prove that a kind of Fatou property, previously studied by Berstel\nand Sakarovitch in the context of rational subsets and by Herbst in the context\nof algebraic subsets, holds for context-free subsets if and only if the group\nis virtually free. We also exhibit a counterexample to a question of Herbst\nconcerning this property for algebraic subsets.",
    "descriptor": "\nComments: 13 pages. Comments are welcome\n",
    "authors": [
      "Andr\u00e9 Carvalho"
    ],
    "subjectives": [
      "Group Theory (math.GR)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2210.10001"
  },
  {
    "id": "arXiv:2210.10016",
    "title": "Contribution to the initialization of linear non-commensurate  fractional-order systems for the joint estimation of parameters and  fractional differentiation orders",
    "abstract": "It has been recognized that using time-varying initialization functions to\nsolve the initial value problem of fractional-order systems (FOS) is both\ncomplex and essential in defining the dynamical behavior of the states of FOSs.\nIn this paper, we investigate the use of the initialization functions for the\npurpose of estimating unknown parameters of linear non-commensurate FOSs. In\nparticular, we propose a novel \"pre-initial\" process that describes the dynamic\ncharacteristic of FOSs before the initial state and consists of designing an\nappropriate time-varying initialization function that ensures accurate\nconvergence of the estimates of the unknown parameters. To do so, we propose an\nestimation technique that consists of two steps: (i) to design of practical\ninitialization function that is output-dependent and which is employed; (ii) to\nsolve the joint estimation problem of both parameters and fractional\ndifferentiation orders (FDOs). A convergence proof has been presented. The\nperformance of the proposed method is illustrated through different numerical\nexamples. Potential applications of the algorithm to joint estimation of\nparameters and FDOs of the fractional arterial Windkessel and neurovascular\nmodels are also presented using both synthetic and real data. The added value\nof the proposed \"pre-initial\" process to solve the studied estimation problem\nis shown through different simulation tests that investigate the sensitivity of\nestimation results using different time-varying initialization functions.",
    "descriptor": "",
    "authors": [
      "Mohamed A. Bahloul",
      "Zehor Belkhatir",
      "Taous-Meriem laleg-Kirati"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.10016"
  },
  {
    "id": "arXiv:1702.02133",
    "title": "A New Graph Parameter To Measure Linearity",
    "abstract": "A New Graph Parameter To Measure Linearity",
    "descriptor": "",
    "authors": [
      "Pierre Charbit",
      "Michel Habib",
      "Lalla Mouatadid",
      "Reza Naserasr"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/1702.02133"
  },
  {
    "id": "arXiv:1812.11194",
    "title": "Error estimates for a tree structure algorithm solving finite horizon  control problems",
    "abstract": "Error estimates for a tree structure algorithm solving finite horizon  control problems",
    "descriptor": "",
    "authors": [
      "Luca Saluzzi",
      "Alessandro Alla",
      "Maurizio Falcone"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/1812.11194"
  },
  {
    "id": "arXiv:1905.06635",
    "title": "Parsimonious Black-Box Adversarial Attacks via Efficient Combinatorial  Optimization",
    "abstract": "Comments: Accepted and to appear at ICML 2019",
    "descriptor": "\nComments: Accepted and to appear at ICML 2019\n",
    "authors": [
      "Seungyong Moon",
      "Gaon An",
      "Hyun Oh Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1905.06635"
  },
  {
    "id": "arXiv:1907.06987",
    "title": "A Short Note on the Kinetics-700 Human Action Dataset",
    "abstract": "Comments: added note about dangers of training on k700 and evaluating on k400/k600. arXiv admin note: text overlap with arXiv:1808.01340",
    "descriptor": "\nComments: added note about dangers of training on k700 and evaluating on k400/k600. arXiv admin note: text overlap with arXiv:1808.01340\n",
    "authors": [
      "Joao Carreira",
      "Eric Noland",
      "Chloe Hillier",
      "Andrew Zisserman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1907.06987"
  },
  {
    "id": "arXiv:1908.06936",
    "title": "Large-scale Environmental Data Science with ExaGeoStatR",
    "abstract": "Large-scale Environmental Data Science with ExaGeoStatR",
    "descriptor": "",
    "authors": [
      "Sameh Abdulah",
      "Yuxiao Li",
      "Jian Cao",
      "Hatem Ltaief",
      "David E. Keyes",
      "Marc G. Genton",
      "Ying Sun"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/1908.06936"
  },
  {
    "id": "arXiv:2002.05545",
    "title": "Sampling and Update Frequencies in Proximal Variance-Reduced Stochastic  Gradient Methods",
    "abstract": "Sampling and Update Frequencies in Proximal Variance-Reduced Stochastic  Gradient Methods",
    "descriptor": "",
    "authors": [
      "Martin Morin",
      "Pontus Giselsson"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2002.05545"
  },
  {
    "id": "arXiv:2003.06658",
    "title": "Revisit Systematic Generalization via Meaningful Learning",
    "abstract": "Comments: Accepted to the Fifth BlackboxNLP in EMNLP 2022",
    "descriptor": "\nComments: Accepted to the Fifth BlackboxNLP in EMNLP 2022\n",
    "authors": [
      "Ning Shi",
      "Boxin Wang",
      "Wei Wang",
      "Xiangyu Liu",
      "Zhouhan Lin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2003.06658"
  },
  {
    "id": "arXiv:2006.14082",
    "title": "Discontinuous Galerkin for the wave equation: a simplified a priori  error analysis",
    "abstract": "Comments: 26 pages, 4 figure",
    "descriptor": "\nComments: 26 pages, 4 figure\n",
    "authors": [
      "Neda Rezaei",
      "Fardin Saedpanah"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2006.14082"
  },
  {
    "id": "arXiv:2007.08902",
    "title": "Attraction-Repulsion Spectrum in Neighbor Embeddings",
    "abstract": "Attraction-Repulsion Spectrum in Neighbor Embeddings",
    "descriptor": "",
    "authors": [
      "Jan Niklas B\u00f6hm",
      "Philipp Berens",
      "Dmitry Kobak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.08902"
  },
  {
    "id": "arXiv:2012.04866",
    "title": "LQG Mean Field Games with a Major Agent: Nash Certainty Equivalence  versus Probabilistic Approach",
    "abstract": "Comments: To appear in Automatica",
    "descriptor": "\nComments: To appear in Automatica\n",
    "authors": [
      "Dena Firoozi"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2012.04866"
  },
  {
    "id": "arXiv:2101.02808",
    "title": "Average-Reward Off-Policy Policy Evaluation with Function Approximation",
    "abstract": "Comments: ICML 2021",
    "descriptor": "\nComments: ICML 2021\n",
    "authors": [
      "Shangtong Zhang",
      "Yi Wan",
      "Richard S. Sutton",
      "Shimon Whiteson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2101.02808"
  },
  {
    "id": "arXiv:2104.07021",
    "title": "Dressing in Order: Recurrent Person Image Generation for Pose Transfer,  Virtual Try-on and Outfit Editing",
    "abstract": "Comments: ICCV 2021",
    "descriptor": "\nComments: ICCV 2021\n",
    "authors": [
      "Aiyu Cui",
      "Daniel McKee",
      "Svetlana Lazebnik"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.07021"
  },
  {
    "id": "arXiv:2104.08462",
    "title": "Syntactic structures and the general Markov models",
    "abstract": "Comments: Added tables summarizing the comparisons",
    "descriptor": "\nComments: Added tables summarizing the comparisons\n",
    "authors": [
      "Sitanshu Gakkhar",
      "Matilde Marcolli"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.08462"
  },
  {
    "id": "arXiv:2105.08372",
    "title": "Analysis of Low-Density Parity-Check Codes over Finite Integer Rings for  the Lee Channel",
    "abstract": "Analysis of Low-Density Parity-Check Codes over Finite Integer Rings for  the Lee Channel",
    "descriptor": "",
    "authors": [
      "Jessica Bariffi",
      "Hannes Bartz",
      "Gianluigi Liva",
      "Joachim Rosenthal"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.08372"
  },
  {
    "id": "arXiv:2106.04001",
    "title": "Optimized Data Rate Allocation for Dynamic Sensor Fusion over Resource  Constrained Communication Networks",
    "abstract": "Optimized Data Rate Allocation for Dynamic Sensor Fusion over Resource  Constrained Communication Networks",
    "descriptor": "",
    "authors": [
      "Hyunho Jung",
      "Ali Reza Pedram",
      "Travis Craig Cuvelier",
      "Takashi Tanaka"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.04001"
  },
  {
    "id": "arXiv:2106.04260",
    "title": "Provably Robust Detection of Out-of-distribution Data (almost) for free",
    "abstract": "Provably Robust Detection of Out-of-distribution Data (almost) for free",
    "descriptor": "",
    "authors": [
      "Alexander Meinke",
      "Julian Bitterwolf",
      "Matthias Hein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.04260"
  },
  {
    "id": "arXiv:2107.08271",
    "title": "Fair Equilibria in Sponsored Search Auctions: The Advertisers'  Perspective",
    "abstract": "Fair Equilibria in Sponsored Search Auctions: The Advertisers'  Perspective",
    "descriptor": "",
    "authors": [
      "Georgios Birmpas",
      "Andrea Celli",
      "Riccardo Colini-Baldeschi",
      "Stefano Leonardi"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2107.08271"
  },
  {
    "id": "arXiv:2107.10450",
    "title": "Learning Sparse Fixed-Structure Gaussian Bayesian Networks",
    "abstract": "Comments: 30 pages, 11 figures, acknowledgement added",
    "descriptor": "\nComments: 30 pages, 11 figures, acknowledgement added\n",
    "authors": [
      "Arnab Bhattacharyya",
      "Davin Choo",
      "Rishikesh Gajjala",
      "Sutanu Gayen",
      "Yuhao Wang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.10450"
  },
  {
    "id": "arXiv:2109.03560",
    "title": "X-GOAL: Multiplex Heterogeneous Graph Prototypical Contrastive Learning",
    "abstract": "Comments: Accepted by CIKM'2022",
    "descriptor": "\nComments: Accepted by CIKM'2022\n",
    "authors": [
      "Baoyu Jing",
      "Shengyu Feng",
      "Yuejia Xiang",
      "Xi Chen",
      "Yu Chen",
      "Hanghang Tong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.03560"
  },
  {
    "id": "arXiv:2109.03564",
    "title": "NSP-BERT: A Prompt-based Few-Shot Learner Through an Original  Pre-training Task--Next Sentence Prediction",
    "abstract": "Comments: Published at COLING2022, long paper",
    "descriptor": "\nComments: Published at COLING2022, long paper\n",
    "authors": [
      "Yi Sun",
      "Yu Zheng",
      "Chao Hao",
      "Hangping Qiu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.03564"
  },
  {
    "id": "arXiv:2109.13392",
    "title": "The Tensor Brain: A Unified Theory of Perception, Memory and Semantic  Decoding",
    "abstract": "Comments: Accepted for publication at Neural Computation",
    "descriptor": "\nComments: Accepted for publication at Neural Computation\n",
    "authors": [
      "Volker Tresp",
      "Sahand Sharifzadeh",
      "Hang Li",
      "Dario Konopatzki",
      "Yunpu Ma"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.13392"
  },
  {
    "id": "arXiv:2109.14081",
    "title": "Efficient Fourier representations of families of Gaussian processes",
    "abstract": "Efficient Fourier representations of families of Gaussian processes",
    "descriptor": "",
    "authors": [
      "Philip Greengard"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.14081"
  },
  {
    "id": "arXiv:2110.13638",
    "title": "EDLaaS: Fully Homomorphic Encryption Over Neural Network Graphs for  Vision and Private Strawberry Yield Forecasting",
    "abstract": "Comments: 13 pages, 6 figures, journal",
    "descriptor": "\nComments: 13 pages, 6 figures, journal\n",
    "authors": [
      "George Onoufriou",
      "Marc Hanheide",
      "Georgios Leontidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13638"
  },
  {
    "id": "arXiv:2110.14160",
    "title": "Identifying the key components in ResNet-50 for diabetic retinopathy  grading from fundus images: a systematic investigation",
    "abstract": "Identifying the key components in ResNet-50 for diabetic retinopathy  grading from fundus images: a systematic investigation",
    "descriptor": "",
    "authors": [
      "Yijin Huang",
      "Li Lin",
      "Pujin Cheng",
      "Junyan Lyu",
      "Roger Tam",
      "Xiaoying Tang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.14160"
  },
  {
    "id": "arXiv:2111.01355",
    "title": "Real-Time Forecasting of Dockless Scooter-Sharing Demand: A  Spatio-Temporal Multi-Graph Transformer Approach",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Yiming Xu",
      "Xilei Zhao",
      "Xiaojian Zhang",
      "Mudit Paliwal"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2111.01355"
  },
  {
    "id": "arXiv:2111.02997",
    "title": "Global Optimality and Finite Sample Analysis of Softmax Off-Policy Actor  Critic under State Distribution Mismatch",
    "abstract": "Comments: Journal of Machine Learning Research 2022",
    "descriptor": "\nComments: Journal of Machine Learning Research 2022\n",
    "authors": [
      "Shangtong Zhang",
      "Remi Tachet",
      "Romain Laroche"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02997"
  },
  {
    "id": "arXiv:2111.12447",
    "title": "Revisiting Contextual Toxicity Detection in Conversations",
    "abstract": "Revisiting Contextual Toxicity Detection in Conversations",
    "descriptor": "",
    "authors": [
      "Atijit Anuchitanukul",
      "Julia Ive",
      "Lucia Specia"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.12447"
  },
  {
    "id": "arXiv:2112.00885",
    "title": "DOPE: Doubly Optimistic and Pessimistic Exploration for Safe  Reinforcement Learning",
    "abstract": "Comments: Accepted to NeurIPS 2022",
    "descriptor": "\nComments: Accepted to NeurIPS 2022\n",
    "authors": [
      "Archana Bura",
      "Aria HasanzadeZonuzy",
      "Dileep Kalathil",
      "Srinivas Shakkottai",
      "Jean-Francois Chamberland"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.00885"
  },
  {
    "id": "arXiv:2112.03232",
    "title": "A Risk-Averse Preview-based $Q$-Learning Algorithm: Application to  Highway Driving of Autonomous Vehicles",
    "abstract": "A Risk-Averse Preview-based $Q$-Learning Algorithm: Application to  Highway Driving of Autonomous Vehicles",
    "descriptor": "",
    "authors": [
      "Majid Mazouchi",
      "Subramanya Nageshrao",
      "Hamidreza Modares"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.03232"
  },
  {
    "id": "arXiv:2112.04629",
    "title": "Transferability Properties of Graph Neural Networks",
    "abstract": "Comments: Submitted to IEEE TSP",
    "descriptor": "\nComments: Submitted to IEEE TSP\n",
    "authors": [
      "Luana Ruiz",
      "Luiz F. O. Chamon",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.04629"
  },
  {
    "id": "arXiv:2112.08826",
    "title": "A case study on parametric verification of failure detectors",
    "abstract": "Comments: We recalled LTL in the Appendix. We clarified a symmetric algorithm on page 5. We clarified our intended definition and described the connection between a correct process, a crashed process, and predicate Correct(p). We clarified what can happen in a system step",
    "descriptor": "\nComments: We recalled LTL in the Appendix. We clarified a symmetric algorithm on page 5. We clarified our intended definition and described the connection between a correct process, a crashed process, and predicate Correct(p). We clarified what can happen in a system step\n",
    "authors": [
      "Thanh-Hai Tran",
      "Igor Konnov",
      "Josef Widder"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2112.08826"
  },
  {
    "id": "arXiv:2112.09767",
    "title": "Know Your Customer: Balancing Innovation and Regulation for Financial  Inclusion",
    "abstract": "Comments: Published in the Journal Data & Policy",
    "descriptor": "\nComments: Published in the Journal Data & Policy\n",
    "authors": [
      "Karen Elliott",
      "Kovila Coopamootoo",
      "Edward Curran",
      "Paul Ezhilchelvan",
      "Samantha Finnigan",
      "Dave Horsfall",
      "Zhichao Ma",
      "Magdalene Ng",
      "Tasos Spiliotopoulos",
      "Han Wu",
      "Aad van Moorsel"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Cryptography and Security (cs.CR)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2112.09767"
  },
  {
    "id": "arXiv:2112.10574",
    "title": "Hybrid Bayesian network discovery with latent variables by scoring  multiple interventions",
    "abstract": "Hybrid Bayesian network discovery with latent variables by scoring  multiple interventions",
    "descriptor": "",
    "authors": [
      "Kiattikun Chobtham",
      "Anthony C. Constantinou",
      "Neville K. Kitson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.10574"
  },
  {
    "id": "arXiv:2112.10601",
    "title": "Error estimates for a splitting integrator for abstract semilinear  boundary coupled systems",
    "abstract": "Error estimates for a splitting integrator for abstract semilinear  boundary coupled systems",
    "descriptor": "",
    "authors": [
      "Petra Csom\u00f3s",
      "B\u00e1lint Farkas",
      "Bal\u00e1zs Kov\u00e1cs"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.10601"
  },
  {
    "id": "arXiv:2112.10955",
    "title": "Joint Learning of Linear Time-Invariant Dynamical Systems",
    "abstract": "Joint Learning of Linear Time-Invariant Dynamical Systems",
    "descriptor": "",
    "authors": [
      "Aditya Modi",
      "Mohamad Kazem Shirani Faradonbeh",
      "Ambuj Tewari",
      "George Michailidis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.10955"
  },
  {
    "id": "arXiv:2201.00732",
    "title": "Classifying Turbulent Environments via Machine Learning",
    "abstract": "Classifying Turbulent Environments via Machine Learning",
    "descriptor": "",
    "authors": [
      "Michele Buzzicotti",
      "Fabio Bonaccorso"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)",
      "Chaotic Dynamics (nlin.CD)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2201.00732"
  },
  {
    "id": "arXiv:2201.02151",
    "title": "Dynamic Task Space Control Enables Soft Manipulators to Perform  Real-World Tasks",
    "abstract": "Dynamic Task Space Control Enables Soft Manipulators to Perform  Real-World Tasks",
    "descriptor": "",
    "authors": [
      "Oliver Fischer",
      "Yasunori Toshimitsu",
      "Amirhossein Kazemipour",
      "Robert K. Katzschmann"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2201.02151"
  },
  {
    "id": "arXiv:2201.05314",
    "title": "A Novel Skeleton-Based Human Activity Discovery Using Particle Swarm  Optimization with Gaussian Mutation",
    "abstract": "A Novel Skeleton-Based Human Activity Discovery Using Particle Swarm  Optimization with Gaussian Mutation",
    "descriptor": "",
    "authors": [
      "Parham Hadikhani",
      "Daphne Teck Ching Lai",
      "Wee-Hong Ong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2201.05314"
  },
  {
    "id": "arXiv:2201.05966",
    "title": "UnifiedSKG: Unifying and Multi-Tasking Structured Knowledge Grounding  with Text-to-Text Language Models",
    "abstract": "Comments: EMNLP 2022",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Tianbao Xie",
      "Chen Henry Wu",
      "Peng Shi",
      "Ruiqi Zhong",
      "Torsten Scholak",
      "Michihiro Yasunaga",
      "Chien-Sheng Wu",
      "Ming Zhong",
      "Pengcheng Yin",
      "Sida I. Wang",
      "Victor Zhong",
      "Bailin Wang",
      "Chengzu Li",
      "Connor Boyle",
      "Ansong Ni",
      "Ziyu Yao",
      "Dragomir Radev",
      "Caiming Xiong",
      "Lingpeng Kong",
      "Rui Zhang",
      "Noah A. Smith",
      "Luke Zettlemoyer",
      "Tao Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.05966"
  },
  {
    "id": "arXiv:2201.07395",
    "title": "Overview frequency principle/spectral bias in deep learning",
    "abstract": "Overview frequency principle/spectral bias in deep learning",
    "descriptor": "",
    "authors": [
      "Zhi-Qin John Xu",
      "Yaoyu Zhang",
      "Tao Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.07395"
  },
  {
    "id": "arXiv:2202.01181",
    "title": "Make Some Noise: Reliable and Efficient Single-Step Adversarial Training",
    "abstract": "Comments: Published in NeurIPS 2022",
    "descriptor": "\nComments: Published in NeurIPS 2022\n",
    "authors": [
      "Pau de Jorge",
      "Adel Bibi",
      "Riccardo Volpi",
      "Amartya Sanyal",
      "Philip H. S. Torr",
      "Gr\u00e9gory Rogez",
      "Puneet K. Dokania"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.01181"
  },
  {
    "id": "arXiv:2202.01525",
    "title": "Reliable Community Search in Dynamic Networks",
    "abstract": "Reliable Community Search in Dynamic Networks",
    "descriptor": "",
    "authors": [
      "Yifu Tang",
      "Jianxin Li",
      "Nur Al Hasan Haldar",
      "Ziyu Guan",
      "Jiajie Xu",
      "Chengfei Liu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2202.01525"
  },
  {
    "id": "arXiv:2202.03593",
    "title": "Nonmyopic Multiclass Active Search with Diminishing Returns for Diverse  Discovery",
    "abstract": "Nonmyopic Multiclass Active Search with Diminishing Returns for Diverse  Discovery",
    "descriptor": "",
    "authors": [
      "Quan Nguyen",
      "Roman Garnett"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03593"
  },
  {
    "id": "arXiv:2202.06387",
    "title": "Scaling Laws Under the Microscope: Predicting Transformer Performance  from Small Scale Experiments",
    "abstract": "Comments: Findings of EMNLP 2022",
    "descriptor": "\nComments: Findings of EMNLP 2022\n",
    "authors": [
      "Maor Ivgi",
      "Yair Carmon",
      "Jonathan Berant"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.06387"
  },
  {
    "id": "arXiv:2202.11645",
    "title": "Cyclical Variational Bayes Monte Carlo for Efficient Multi-Modal  Posterior Distributions Evaluation",
    "abstract": "Comments: Accepted version in MSSP",
    "descriptor": "\nComments: Accepted version in MSSP\n",
    "authors": [
      "Felipe Igea",
      "Alice Cicirello"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.11645"
  },
  {
    "id": "arXiv:2202.13536",
    "title": "LobsDICE: Offline Learning from Observation via Stationary Distribution  Correction Estimation",
    "abstract": "Comments: 33 pages, Accepted at NeurIPS 2022",
    "descriptor": "\nComments: 33 pages, Accepted at NeurIPS 2022\n",
    "authors": [
      "Geon-Hyeong Kim",
      "Jongmin Lee",
      "Youngsoo Jang",
      "Hongseok Yang",
      "Kee-Eung Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.13536"
  },
  {
    "id": "arXiv:2203.00158",
    "title": "GROW: A Row-Stationary Sparse-Dense GEMM Accelerator for  Memory-Efficient Graph Convolutional Neural Networks",
    "abstract": "Comments: First authors Ranggi Hwang and Minhoo Kang have made equal contributions to this work",
    "descriptor": "\nComments: First authors Ranggi Hwang and Minhoo Kang have made equal contributions to this work\n",
    "authors": [
      "Ranggi Hwang",
      "Minhoo Kang",
      "Jiwon Lee",
      "Dongyun Kam",
      "Youngjoo Lee",
      "Minsoo Rhu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.00158"
  },
  {
    "id": "arXiv:2203.02094",
    "title": "LiteTransformerSearch: Training-free Neural Architecture Search for  Efficient Language Models",
    "abstract": "LiteTransformerSearch: Training-free Neural Architecture Search for  Efficient Language Models",
    "descriptor": "",
    "authors": [
      "Mojan Javaheripi",
      "Gustavo H. de Rosa",
      "Subhabrata Mukherjee",
      "Shital Shah",
      "Tomasz L. Religa",
      "Caio C. T. Mendes",
      "Sebastien Bubeck",
      "Farinaz Koushanfar",
      "Debadeepta Dey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.02094"
  },
  {
    "id": "arXiv:2203.02557",
    "title": "UVCGAN: UNet Vision Transformer cycle-consistent GAN for unpaired  image-to-image translation",
    "abstract": "Comments: Accepted by WACV2023, contains 5 pages, 2 figures, 2 tables",
    "descriptor": "\nComments: Accepted by WACV2023, contains 5 pages, 2 figures, 2 tables\n",
    "authors": [
      "Dmitrii Torbunov",
      "Yi Huang",
      "Haiwang Yu",
      "Jin Huang",
      "Shinjae Yoo",
      "Meifeng Lin",
      "Brett Viren",
      "Yihui Ren"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.02557"
  },
  {
    "id": "arXiv:2203.02882",
    "title": "RGB-D SLAM in Indoor Planar Environments with Multiple Large Dynamic  Objects",
    "abstract": "Comments: 8 papges, 9 figures",
    "descriptor": "\nComments: 8 papges, 9 figures\n",
    "authors": [
      "Ran Long",
      "Christian Rauch",
      "Tianwei Zhang",
      "Vladimir Ivan",
      "Tin Lun Lam",
      "Sethu Vijayakumar"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.02882"
  },
  {
    "id": "arXiv:2203.04179",
    "title": "Understanding Person Identification through Gait",
    "abstract": "Understanding Person Identification through Gait",
    "descriptor": "",
    "authors": [
      "Simon Hanisch",
      "Evelyn Muschter",
      "Admantini Hatzipanayioti",
      "Shu-Chen Li",
      "Thorsten Strufe"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04179"
  },
  {
    "id": "arXiv:2203.04923",
    "title": "On-Robot Learning With Equivariant Models",
    "abstract": "Comments: Published at CoRL 2022",
    "descriptor": "\nComments: Published at CoRL 2022\n",
    "authors": [
      "Dian Wang",
      "Mingxi Jia",
      "Xupeng Zhu",
      "Robin Walters",
      "Robert Platt"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.04923"
  },
  {
    "id": "arXiv:2203.05822",
    "title": "aiWave: Volumetric Image Compression with 3-D Trained Affine  Wavelet-like Transform",
    "abstract": "aiWave: Volumetric Image Compression with 3-D Trained Affine  Wavelet-like Transform",
    "descriptor": "",
    "authors": [
      "Dongmei Xue",
      "Haichuan Ma",
      "Li Li",
      "Dong Liu",
      "Zhiwei Xiong"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05822"
  },
  {
    "id": "arXiv:2203.06649",
    "title": "Joint rotational invariance and adversarial training of a dual-stream  Transformer yields state of the art Brain-Score for Area V4",
    "abstract": "Comments: Under review",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "William Berrios",
      "Arturo Deza"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2203.06649"
  },
  {
    "id": "arXiv:2203.06735",
    "title": "Private Non-Convex Federated Learning Without a Trusted Server",
    "abstract": "Private Non-Convex Federated Learning Without a Trusted Server",
    "descriptor": "",
    "authors": [
      "Andrew Lowy",
      "Ali Ghafelebashi",
      "Meisam Razaviyayn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.06735"
  },
  {
    "id": "arXiv:2203.07259",
    "title": "The Optimal BERT Surgeon: Scalable and Accurate Second-Order Pruning for  Large Language Models",
    "abstract": "Comments: Accepted to EMNLP 2022",
    "descriptor": "\nComments: Accepted to EMNLP 2022\n",
    "authors": [
      "Eldar Kurtic",
      "Daniel Campos",
      "Tuan Nguyen",
      "Elias Frantar",
      "Mark Kurtz",
      "Benjamin Fineran",
      "Michael Goin",
      "Dan Alistarh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.07259"
  },
  {
    "id": "arXiv:2203.08304",
    "title": "Hyperdecoders: Instance-specific decoders for multi-task NLP",
    "abstract": "Comments: Accepted to Findings of EMNLP 2022",
    "descriptor": "\nComments: Accepted to Findings of EMNLP 2022\n",
    "authors": [
      "Hamish Ivison",
      "Matthew E. Peters"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.08304"
  },
  {
    "id": "arXiv:2203.08906",
    "title": "ORCA: A Network and Architecture Co-design for Offloading us-scale  Datacenter Applications",
    "abstract": "Comments: This paper has been accepted by HPCA'23. This arxiv paper is not the final camera-ready version",
    "descriptor": "\nComments: This paper has been accepted by HPCA'23. This arxiv paper is not the final camera-ready version\n",
    "authors": [
      "Yifan Yuan",
      "Jinghan Huang",
      "Yan Sun",
      "Tianchen Wang",
      "Jacob Nelson",
      "Dan R. K. Ports",
      "Yipeng Wang",
      "Ren Wang",
      "Charlie Tai",
      "Nam Sung Kim"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.08906"
  },
  {
    "id": "arXiv:2203.10730",
    "title": "Semantic Segmentation with Active Semi-Supervised Learning",
    "abstract": "Comments: To appear in the Winter Conference on Applications of Computer Vision (WACV-2023)",
    "descriptor": "\nComments: To appear in the Winter Conference on Applications of Computer Vision (WACV-2023)\n",
    "authors": [
      "Aneesh Rangnekar",
      "Christopher Kanan",
      "Matthew Hoffman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.10730"
  },
  {
    "id": "arXiv:2203.11442",
    "title": "Scalable Multi-object Identification for Video Object Segmentation",
    "abstract": "Comments: Extension of arXiv:2106.02638 (NeurIPS 2021)",
    "descriptor": "\nComments: Extension of arXiv:2106.02638 (NeurIPS 2021)\n",
    "authors": [
      "Zongxin Yang",
      "Jiaxu Miao",
      "Xiaohan Wang",
      "Yunchao Wei",
      "Yi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11442"
  },
  {
    "id": "arXiv:2203.12602",
    "title": "VideoMAE: Masked Autoencoders are Data-Efficient Learners for  Self-Supervised Video Pre-Training",
    "abstract": "Comments: NeurIPS 2022 camera-ready version",
    "descriptor": "\nComments: NeurIPS 2022 camera-ready version\n",
    "authors": [
      "Zhan Tong",
      "Yibing Song",
      "Jue Wang",
      "Limin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.12602"
  },
  {
    "id": "arXiv:2203.13048",
    "title": "Benchmarking Visual Localization for Autonomous Navigation",
    "abstract": "Comments: WACV2023 camera ready",
    "descriptor": "\nComments: WACV2023 camera ready\n",
    "authors": [
      "Lauri Suomela",
      "Jussi Kalliola",
      "Atakan Dag",
      "Harry Edelman",
      "Joni-Kristian K\u00e4m\u00e4r\u00e4inen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13048"
  },
  {
    "id": "arXiv:2203.16582",
    "title": "Factored Adaptation for Non-Stationary Reinforcement Learning",
    "abstract": "Comments: Accepted at the NeurIPS 2022",
    "descriptor": "\nComments: Accepted at the NeurIPS 2022\n",
    "authors": [
      "Fan Feng",
      "Biwei Huang",
      "Kun Zhang",
      "Sara Magliacane"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.16582"
  },
  {
    "id": "arXiv:2203.16944",
    "title": "A data-driven approach for the closure of RANS models by the divergence  of the Reynolds Stress Tensor",
    "abstract": "Comments: 26 pages, 13 figures",
    "descriptor": "\nComments: 26 pages, 13 figures\n",
    "authors": [
      "Stefano Berrone",
      "Davide Oberto"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.16944"
  },
  {
    "id": "arXiv:2204.01880",
    "title": "Models and Mechanisms for Spatial Data Fairness",
    "abstract": "Models and Mechanisms for Spatial Data Fairness",
    "descriptor": "",
    "authors": [
      "Sina Shaham",
      "Gabriel Ghinita",
      "Cyrus Shahabi"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.01880"
  },
  {
    "id": "arXiv:2204.03230",
    "title": "What You See is What You Get: Principled Deep Learning via  Distributional Generalization",
    "abstract": "Comments: First two authors contributed equally. To appear in NeurIPS 2022",
    "descriptor": "\nComments: First two authors contributed equally. To appear in NeurIPS 2022\n",
    "authors": [
      "Bogdan Kulynych",
      "Yao-Yuan Yang",
      "Yaodong Yu",
      "Jaros\u0142aw B\u0142asiok",
      "Preetum Nakkiran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.03230"
  },
  {
    "id": "arXiv:2204.03248",
    "title": "Composite Spatial Monte Carlo Integration Based on Generalized Least  Squares",
    "abstract": "Composite Spatial Monte Carlo Integration Based on Generalized Least  Squares",
    "descriptor": "",
    "authors": [
      "Kaiji Sekimoto",
      "Muneki Yasuda"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.03248"
  },
  {
    "id": "arXiv:2204.04260",
    "title": "Towards Cognitive Robots That People Accept in Their Home",
    "abstract": "Comments: 2022 AAAI Fall Symposium on Artificial Intelligence for Human-Robot Interaction (AI-HRI 2022) workshop paper",
    "descriptor": "\nComments: 2022 AAAI Fall Symposium on Artificial Intelligence for Human-Robot Interaction (AI-HRI 2022) workshop paper\n",
    "authors": [
      "Nina Moorman",
      "Erin Hedlund-Botti",
      "Matthew Gombolay"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2204.04260"
  },
  {
    "id": "arXiv:2204.05955",
    "title": "Ground state preparation and energy estimation on early fault-tolerant  quantum computers via quantum eigenvalue transformation of unitary matrices",
    "abstract": "Ground state preparation and energy estimation on early fault-tolerant  quantum computers via quantum eigenvalue transformation of unitary matrices",
    "descriptor": "",
    "authors": [
      "Yulong Dong",
      "Lin Lin",
      "Yu Tong"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2204.05955"
  },
  {
    "id": "arXiv:2204.06487",
    "title": "Adapting Pre-trained Language Models to African Languages via  Multilingual Adaptive Fine-Tuning",
    "abstract": "Comments: Accepted to COLING 2022",
    "descriptor": "\nComments: Accepted to COLING 2022\n",
    "authors": [
      "Jesujoba O. Alabi",
      "David Ifeoluwa Adelani",
      "Marius Mosbach",
      "Dietrich Klakow"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.06487"
  },
  {
    "id": "arXiv:2204.07937",
    "title": "Unsupervised Cross-Task Generalization via Retrieval Augmentation",
    "abstract": "Comments: Accepted to NeurIPS 2022. Website: this https URL",
    "descriptor": "\nComments: Accepted to NeurIPS 2022. Website: this https URL\n",
    "authors": [
      "Bill Yuchen Lin",
      "Kangmin Tan",
      "Chris Miller",
      "Beiwen Tian",
      "Xiang Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07937"
  },
  {
    "id": "arXiv:2204.14154",
    "title": "Outage Performance of Uplink Rate Splitting Multiple Access with  Randomly Deployed Users",
    "abstract": "Comments: 37 pages,8 figures",
    "descriptor": "\nComments: 37 pages,8 figures\n",
    "authors": [
      "Huabing Lu",
      "Xianzhong Xie",
      "Zhaoyuan Shi",
      "Hongjian Lei",
      "Nan Zhao",
      "Jun Cai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2204.14154"
  },
  {
    "id": "arXiv:2205.00271",
    "title": "Deep Learning-Enabled Semantic Communication Systems with Task-Unaware  Transmitter and Dynamic Data",
    "abstract": "Deep Learning-Enabled Semantic Communication Systems with Task-Unaware  Transmitter and Dynamic Data",
    "descriptor": "",
    "authors": [
      "Hongwei Zhang",
      "Shuo Shao",
      "Meixia Tao",
      "Xiaoyan Bi",
      "Khaled B. Letaief"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2205.00271"
  },
  {
    "id": "arXiv:2205.00971",
    "title": "Complex moment-based methods for differential eigenvalue problems",
    "abstract": "Comments: 26 pages, 9 figures",
    "descriptor": "\nComments: 26 pages, 9 figures\n",
    "authors": [
      "Akira Imakura",
      "Keiichi Morikuni",
      "Akitoshi Takayasu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.00971"
  },
  {
    "id": "arXiv:2205.05071",
    "title": "Towards Climate Awareness in NLP Research",
    "abstract": "Comments: Accepted to EMNLP 2022",
    "descriptor": "\nComments: Accepted to EMNLP 2022\n",
    "authors": [
      "Daniel Hershcovich",
      "Nicolas Webersinke",
      "Mathias Kraus",
      "Julia Anna Bingler",
      "Markus Leippold"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2205.05071"
  },
  {
    "id": "arXiv:2205.07617",
    "title": "Analysis of Distributed Ledger Technologies for Industrial Manufacturing",
    "abstract": "Comments: Accepted for publication at Nature Scientific Reports",
    "descriptor": "\nComments: Accepted for publication at Nature Scientific Reports\n",
    "authors": [
      "Lam Duc Nguyen",
      "Arne Broering",
      "Massimo Pizzol",
      "Petar Popovski"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.07617"
  },
  {
    "id": "arXiv:2205.08121",
    "title": "Design of Joint Source-Channel Codes Based on a Generic Protograph",
    "abstract": "Comments: 26 pages, 15 figures, 5 tables",
    "descriptor": "\nComments: 26 pages, 15 figures, 5 tables\n",
    "authors": [
      "Jia Zhan",
      "Francis C.M. Lau"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.08121"
  },
  {
    "id": "arXiv:2205.08514",
    "title": "Recovering Private Text in Federated Learning of Language Models",
    "abstract": "Comments: NeurIPS 2022. Code is publicly available at this https URL v2 added discussion and evaluation of defenses",
    "descriptor": "\nComments: NeurIPS 2022. Code is publicly available at this https URL v2 added discussion and evaluation of defenses\n",
    "authors": [
      "Samyak Gupta",
      "Yangsibo Huang",
      "Zexuan Zhong",
      "Tianyu Gao",
      "Kai Li",
      "Danqi Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.08514"
  },
  {
    "id": "arXiv:2205.09833",
    "title": "Learning Interface Conditions in Domain Decomposition Solvers",
    "abstract": "Learning Interface Conditions in Domain Decomposition Solvers",
    "descriptor": "",
    "authors": [
      "Ali Taghibakhshi",
      "Nicolas Nytko",
      "Tareq Zaman",
      "Scott MacLachlan",
      "Luke Olson",
      "Matthew West"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Discrete Mathematics (cs.DM)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.09833"
  },
  {
    "id": "arXiv:2205.09860",
    "title": "Mean-Field Analysis of Two-Layer Neural Networks: Global Optimality with  Linear Convergence Rates",
    "abstract": "Comments: revision on presentation; add experiments; more discussions on previous independent works of chizat2022mean and nitanda2022convex",
    "descriptor": "\nComments: revision on presentation; add experiments; more discussions on previous independent works of chizat2022mean and nitanda2022convex\n",
    "authors": [
      "Jingwei Zhang",
      "Xunpeng Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Analysis of PDEs (math.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.09860"
  },
  {
    "id": "arXiv:2205.10689",
    "title": "Diversity Preference-Aware Link Recommendation for Online Social  Networks",
    "abstract": "Comments: 50 pages, 3 figures",
    "descriptor": "\nComments: 50 pages, 3 figures\n",
    "authors": [
      "Kexin Yin",
      "Xiao Fang",
      "Bintong Chen",
      "Olivia Sheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.10689"
  },
  {
    "id": "arXiv:2205.11998",
    "title": "Multi-Level Modeling Units for End-to-End Mandarin Speech Recognition",
    "abstract": "Multi-Level Modeling Units for End-to-End Mandarin Speech Recognition",
    "descriptor": "",
    "authors": [
      "Yuting Yang",
      "Binbin Du",
      "Yuke Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2205.11998"
  },
  {
    "id": "arXiv:2205.12215",
    "title": "DivEMT: Neural Machine Translation Post-Editing Effort Across  Typologically Diverse Languages",
    "abstract": "Comments: EMNLP 2022, materials: this https URL",
    "descriptor": "\nComments: EMNLP 2022, materials: this https URL\n",
    "authors": [
      "Gabriele Sarti",
      "Arianna Bisazza",
      "Ana Guerberof Arenas",
      "Antonio Toral"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.12215"
  },
  {
    "id": "arXiv:2205.12443",
    "title": "Generating Natural Language Proofs with Verifier-Guided Search",
    "abstract": "Comments: EMNLP 2022. Code and models are available at this https URL",
    "descriptor": "\nComments: EMNLP 2022. Code and models are available at this https URL\n",
    "authors": [
      "Kaiyu Yang",
      "Jia Deng",
      "Danqi Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2205.12443"
  },
  {
    "id": "arXiv:2205.12934",
    "title": "Amortized Inference for Causal Structure Learning",
    "abstract": "Comments: To appear in NeurIPS 2022",
    "descriptor": "\nComments: To appear in NeurIPS 2022\n",
    "authors": [
      "Lars Lorch",
      "Scott Sussex",
      "Jonas Rothfuss",
      "Andreas Krause",
      "Bernhard Sch\u00f6lkopf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.12934"
  },
  {
    "id": "arXiv:2205.13571",
    "title": "Low-rank lottery tickets: finding efficient low-rank neural networks via  matrix differential equations",
    "abstract": "Low-rank lottery tickets: finding efficient low-rank neural networks via  matrix differential equations",
    "descriptor": "",
    "authors": [
      "Steffen Schotth\u00f6fer",
      "Emanuele Zangrando",
      "Jonas Kusch",
      "Gianluca Ceruti",
      "Francesco Tudisco"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.13571"
  },
  {
    "id": "arXiv:2205.13914",
    "title": "3DILG: Irregular Latent Grids for 3D Generative Modeling",
    "abstract": "Comments: Accepted at NeurIPS 2022. Project page: this https URL",
    "descriptor": "\nComments: Accepted at NeurIPS 2022. Project page: this https URL\n",
    "authors": [
      "Biao Zhang",
      "Matthias Nie\u00dfner",
      "Peter Wonka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.13914"
  },
  {
    "id": "arXiv:2205.14292",
    "title": "BulletArm: An Open-Source Robotic Manipulation Benchmark and Learning  Framework",
    "abstract": "Comments: Published at ISRR 2022",
    "descriptor": "\nComments: Published at ISRR 2022\n",
    "authors": [
      "Dian Wang",
      "Colin Kohler",
      "Xupeng Zhu",
      "Mingxi Jia",
      "Robert Platt"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.14292"
  },
  {
    "id": "arXiv:2205.14415",
    "title": "Non-stationary Transformers: Exploring the Stationarity in Time Series  Forecasting",
    "abstract": "Non-stationary Transformers: Exploring the Stationarity in Time Series  Forecasting",
    "descriptor": "",
    "authors": [
      "Yong Liu",
      "Haixu Wu",
      "Jianmin Wang",
      "Mingsheng Long"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.14415"
  },
  {
    "id": "arXiv:2205.14421",
    "title": "Approximation of Functionals by Neural Network without Curse of  Dimensionality",
    "abstract": "Approximation of Functionals by Neural Network without Curse of  Dimensionality",
    "descriptor": "",
    "authors": [
      "Yahong Yang",
      "Yang Xiang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2205.14421"
  },
  {
    "id": "arXiv:2205.15113",
    "title": "Online Agnostic Multiclass Boosting",
    "abstract": "Comments: Camera-Ready Version",
    "descriptor": "\nComments: Camera-Ready Version\n",
    "authors": [
      "Vinod Raman",
      "Ambuj Tewari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.15113"
  },
  {
    "id": "arXiv:2205.15612",
    "title": "GlanceNets: Interpretabile, Leak-proof Concept-based Models",
    "abstract": "Comments: 36th Conference on Neural Information Processing Systems (NeurIPS 2022)",
    "descriptor": "\nComments: 36th Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Emanuele Marconato",
      "Andrea Passerini",
      "Stefano Teso"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15612"
  },
  {
    "id": "arXiv:2206.00375",
    "title": "Watch Your Back: Identifying Cybercrime Financial Relationships in  Bitcoin through Back-and-Forth Exploration",
    "abstract": "Watch Your Back: Identifying Cybercrime Financial Relationships in  Bitcoin through Back-and-Forth Exploration",
    "descriptor": "",
    "authors": [
      "Gibran Gomez",
      "Pedro Moreno-Sanchez",
      "Juan Caballero"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.00375"
  },
  {
    "id": "arXiv:2206.00629",
    "title": "CLIP4IDC: CLIP for Image Difference Captioning",
    "abstract": "Comments: Accepted to AACL-IJCNLP 2022",
    "descriptor": "\nComments: Accepted to AACL-IJCNLP 2022\n",
    "authors": [
      "Zixin Guo",
      "Tzu-Jui Julius Wang",
      "Jorma Laaksonen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.00629"
  },
  {
    "id": "arXiv:2206.01041",
    "title": "End-to-End Security for Distributed Event-Driven Enclave Applications on  Heterogeneous TEEs",
    "abstract": "Comments: 40 pages, submitted to ACM Transactions on Privacy and Security, first co-authorship between Gianluca Scopelliti and Sepideh Pouyanrad, source code available at this https URL",
    "descriptor": "\nComments: 40 pages, submitted to ACM Transactions on Privacy and Security, first co-authorship between Gianluca Scopelliti and Sepideh Pouyanrad, source code available at this https URL\n",
    "authors": [
      "Gianluca Scopelliti",
      "Sepideh Pouyanrad",
      "Job Noorman",
      "Fritz Alder",
      "Christoph Baumann",
      "Frank Piessens",
      "Jan Tobias M\u00fchlberg"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.01041"
  },
  {
    "id": "arXiv:2206.03467",
    "title": "Discrete State-Action Abstraction via the Successor Representation",
    "abstract": "Discrete State-Action Abstraction via the Successor Representation",
    "descriptor": "",
    "authors": [
      "Amnon Attali",
      "Pedro Cisneros-Velarde",
      "Marco Morales",
      "Nancy M. Amato"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.03467"
  },
  {
    "id": "arXiv:2206.04172",
    "title": "On Gradient Descent Convergence beyond the Edge of Stability",
    "abstract": "On Gradient Descent Convergence beyond the Edge of Stability",
    "descriptor": "",
    "authors": [
      "Lei Chen",
      "Joan Bruna"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.04172"
  },
  {
    "id": "arXiv:2206.05357",
    "title": "Anchor-Changing Regularized Natural Policy Gradient for Multi-Objective  Reinforcement Learning",
    "abstract": "Comments: 36th Conference on Neural Information Processing Systems (NeurIPS 2022)",
    "descriptor": "\nComments: 36th Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Ruida Zhou",
      "Tao Liu",
      "Dileep Kalathil",
      "P. R. Kumar",
      "Chao Tian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.05357"
  },
  {
    "id": "arXiv:2206.07303",
    "title": "Energetic Variational Neural Network Discretizations to Gradient Flows",
    "abstract": "Comments: 26 pages, 8 figures",
    "descriptor": "\nComments: 26 pages, 8 figures\n",
    "authors": [
      "Ziqing Hu",
      "Chun Liu",
      "Yiwei Wang",
      "Zhiliang Xu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.07303"
  },
  {
    "id": "arXiv:2206.08569",
    "title": "Bootstrapped Transformer for Offline Reinforcement Learning",
    "abstract": "Comments: Accepted in NeurIPS 2022",
    "descriptor": "\nComments: Accepted in NeurIPS 2022\n",
    "authors": [
      "Kerong Wang",
      "Hanye Zhao",
      "Xufang Luo",
      "Kan Ren",
      "Weinan Zhang",
      "Dongsheng Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.08569"
  },
  {
    "id": "arXiv:2206.08972",
    "title": "Shallow and Deep Nonparametric Convolutions for Gaussian Processes",
    "abstract": "Comments: 19 pages, 7 figures. NP-DGP results and discussion updated",
    "descriptor": "\nComments: 19 pages, 7 figures. NP-DGP results and discussion updated\n",
    "authors": [
      "Thomas M. McDonald",
      "Magnus Ross",
      "Michael T. Smith",
      "Mauricio A. \u00c1lvarez"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.08972"
  },
  {
    "id": "arXiv:2206.11108",
    "title": "M/G/1-FIFO Queue with Uniform Service Times",
    "abstract": "Comments: 14 pages; 3 figures",
    "descriptor": "\nComments: 14 pages; 3 figures\n",
    "authors": [
      "Steven Finch"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Discrete Mathematics (cs.DM)",
      "History and Overview (math.HO)"
    ],
    "url": "https://arxiv.org/abs/2206.11108"
  },
  {
    "id": "arXiv:2206.11177",
    "title": "Frugal Splitting Operators: Representation, Minimal Lifting and  Convergence",
    "abstract": "Frugal Splitting Operators: Representation, Minimal Lifting and  Convergence",
    "descriptor": "",
    "authors": [
      "Martin Morin",
      "Sebastian Banert",
      "Pontus Giselsson"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.11177"
  },
  {
    "id": "arXiv:2206.12469",
    "title": "Burst2Vec: An Adversarial Multi-Task Approach for Predicting Emotion,  Age, and Origin from Vocal Bursts",
    "abstract": "Burst2Vec: An Adversarial Multi-Task Approach for Predicting Emotion,  Age, and Origin from Vocal Bursts",
    "descriptor": "",
    "authors": [
      "Atijit Anuchitanukul",
      "Lucia Specia"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.12469"
  },
  {
    "id": "arXiv:2206.14534",
    "title": "When Does Group Invariant Learning Survive Spurious Correlations?",
    "abstract": "Comments: 25 pages, 3 figures. Accepted by NeurIPS 2022",
    "descriptor": "\nComments: 25 pages, 3 figures. Accepted by NeurIPS 2022\n",
    "authors": [
      "Yimeng Chen",
      "Ruibin Xiong",
      "Zhiming Ma",
      "Yanyan Lan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.14534"
  },
  {
    "id": "arXiv:2206.14797",
    "title": "3D-Aware Video Generation",
    "abstract": "Comments: Project page: this https URL",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Sherwin Bahmani",
      "Jeong Joon Park",
      "Despoina Paschalidou",
      "Hao Tang",
      "Gordon Wetzstein",
      "Leonidas Guibas",
      "Luc Van Gool",
      "Radu Timofte"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14797"
  },
  {
    "id": "arXiv:2207.03578",
    "title": "Code Translation with Compiler Representations",
    "abstract": "Comments: 9 pages",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Marc Szafraniec",
      "Baptiste Roziere",
      "Hugh Leather",
      "Francois Charton",
      "Patrick Labatut",
      "Gabriel Synnaeve"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.03578"
  },
  {
    "id": "arXiv:2207.04649",
    "title": "Fast Density-Peaks Clustering: Multicore-based Parallelization Approach",
    "abstract": "Fast Density-Peaks Clustering: Multicore-based Parallelization Approach",
    "descriptor": "",
    "authors": [
      "Daichi Amagata",
      "Takahiro Hara"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2207.04649"
  },
  {
    "id": "arXiv:2207.06080",
    "title": "Efficient Augmentation for Imbalanced Deep Learning",
    "abstract": "Efficient Augmentation for Imbalanced Deep Learning",
    "descriptor": "",
    "authors": [
      "Damien Dablain",
      "Colin Bellinger",
      "Bartosz Krawczyk",
      "Nitesh Chawla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.06080"
  },
  {
    "id": "arXiv:2207.08980",
    "title": "DeformIrisNet: An Identity-Preserving Model of Iris Texture Deformation",
    "abstract": "Comments: Accepted to the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2023",
    "descriptor": "\nComments: Accepted to the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2023\n",
    "authors": [
      "Siamul Karim Khan",
      "Patrick Tinsley",
      "Adam Czajka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.08980"
  },
  {
    "id": "arXiv:2207.10643",
    "title": "STOP: A dataset for Spoken Task Oriented Semantic Parsing",
    "abstract": "STOP: A dataset for Spoken Task Oriented Semantic Parsing",
    "descriptor": "",
    "authors": [
      "Paden Tomasello",
      "Akshat Shrivastava",
      "Daniel Lazar",
      "Po-Chun Hsu",
      "Duc Le",
      "Adithya Sagar",
      "Ali Elkahky",
      "Jade Copet",
      "Wei-Ning Hsu",
      "Yossi Adi",
      "Robin Algayres",
      "Tu Ahn Nguyen",
      "Emmanuel Dupoux",
      "Luke Zettlemoyer",
      "Abdelrahman Mohamed"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2207.10643"
  },
  {
    "id": "arXiv:2207.10897",
    "title": "Efficient Modeling of Future Context for Image Captioning",
    "abstract": "Comments: ACM Multimedia 2022",
    "descriptor": "\nComments: ACM Multimedia 2022\n",
    "authors": [
      "Zhengcong Fei",
      "Junshi Huang",
      "Xiaoming Wei",
      "Xiaolin Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10897"
  },
  {
    "id": "arXiv:2207.11512",
    "title": "Combining Self-Training and Hybrid Architecture for Semi-supervised  Abdominal Organ Segmentation",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2203.04568",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2203.04568\n",
    "authors": [
      "Wentao Liu",
      "Weijin Xu",
      "Songlin Yan",
      "Lemeng Wang",
      "Haoyuan Li",
      "Huihua Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.11512"
  },
  {
    "id": "arXiv:2207.11812",
    "title": "Federated Graph Machine Learning: A Survey of Concepts, Techniques, and  Applications",
    "abstract": "Comments: Accepted by SIGKDD Explorations",
    "descriptor": "\nComments: Accepted by SIGKDD Explorations\n",
    "authors": [
      "Xingbo Fu",
      "Binchi Zhang",
      "Yushun Dong",
      "Chen Chen",
      "Jundong Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.11812"
  },
  {
    "id": "arXiv:2207.13298",
    "title": "Is Attention All That NeRF Needs?",
    "abstract": "Comments: Preprint",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Mukund Varma T",
      "Peihao Wang",
      "Xuxi Chen",
      "Tianlong Chen",
      "Subhashini Venugopalan",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.13298"
  },
  {
    "id": "arXiv:2207.14219",
    "title": "A general framework for multi-step ahead adaptive conformal  heteroscedastic time series forecasting",
    "abstract": "Comments: 13 pages, 8 figures",
    "descriptor": "\nComments: 13 pages, 8 figures\n",
    "authors": [
      "Martim Sousa",
      "Ana Maria Tom\u00e9",
      "Jos\u00e9 Moreira"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.14219"
  },
  {
    "id": "arXiv:2207.14668",
    "title": "lifex: a flexible, high performance library for the numerical solution  of complex finite element problems",
    "abstract": "lifex: a flexible, high performance library for the numerical solution  of complex finite element problems",
    "descriptor": "",
    "authors": [
      "Pasquale Claudio Africa"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.14668"
  },
  {
    "id": "arXiv:2208.01147",
    "title": "Short-term Load Forecasting with Distributed Long Short-Term Memory",
    "abstract": "Comments: 5 pages, 4 figures, 2023 ISGT-NA",
    "descriptor": "\nComments: 5 pages, 4 figures, 2023 ISGT-NA\n",
    "authors": [
      "Yi Dong",
      "Yang Chen",
      "Xingyu Zhao",
      "Xiaowei Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2208.01147"
  },
  {
    "id": "arXiv:2208.02645",
    "title": "Neural network accelerator for quantum control",
    "abstract": "Comments: 7 pages, 10 figures. To appear in IEEE Conference Proceedings, International Workshop on Quantum Computing Software (SC22)",
    "descriptor": "\nComments: 7 pages, 10 figures. To appear in IEEE Conference Proceedings, International Workshop on Quantum Computing Software (SC22)\n",
    "authors": [
      "David Xu",
      "A. Bar\u0131\u015f \u00d6zg\u00fcler",
      "Giuseppe Di Guglielmo",
      "Nhan Tran",
      "Gabriel N. Perdue",
      "Luca Carloni",
      "Farah Fahim"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.02645"
  },
  {
    "id": "arXiv:2208.04749",
    "title": "Where's the Learning in Representation Learning for Compositional  Semantics and the Case of Thematic Fit",
    "abstract": "Comments: Published in Blackbox NLP workshop, EMNLP 2022. 12 pages including Appendices, 1 figure (with 6 sub-figures)",
    "descriptor": "\nComments: Published in Blackbox NLP workshop, EMNLP 2022. 12 pages including Appendices, 1 figure (with 6 sub-figures)\n",
    "authors": [
      "Mughilan Muthupari",
      "Samrat Halder",
      "Asad Sayeed",
      "Yuval Marton"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.04749"
  },
  {
    "id": "arXiv:2208.05129",
    "title": "Robust Reinforcement Learning using Offline Data",
    "abstract": "Comments: Appeared in Neural Information Processing Systems (NeurIPS) 2022",
    "descriptor": "\nComments: Appeared in Neural Information Processing Systems (NeurIPS) 2022\n",
    "authors": [
      "Kishan Panaganti",
      "Zaiyan Xu",
      "Dileep Kalathil",
      "Mohammad Ghavamzadeh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2208.05129"
  },
  {
    "id": "arXiv:2208.06063",
    "title": "ICIP 2022 Challenge on Parasitic Egg Detection and Classification in  Microscopic Images: Dataset, Methods and Results",
    "abstract": "Comments: The 29th IEEE International Conference on Image Processing",
    "descriptor": "\nComments: The 29th IEEE International Conference on Image Processing\n",
    "authors": [
      "Nantheera Anantrasirichai",
      "Thanarat H. Chalidabhongse",
      "Duangdao Palasuwan",
      "Korranat Naruenatthanaset",
      "Thananop Kobchaisawat",
      "Nuntiporn Nunthanasup",
      "Kanyarat Boonpeng",
      "Xudong Ma",
      "Alin Achim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.06063"
  },
  {
    "id": "arXiv:2208.06677",
    "title": "Adan: Adaptive Nesterov Momentum Algorithm for Faster Optimizing Deep  Models",
    "abstract": "Adan: Adaptive Nesterov Momentum Algorithm for Faster Optimizing Deep  Models",
    "descriptor": "",
    "authors": [
      "Xingyu Xie",
      "Pan Zhou",
      "Huan Li",
      "Zhouchen Lin",
      "Shuicheng Yan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2208.06677"
  },
  {
    "id": "arXiv:2208.07331",
    "title": "Anticipating Performativity by Predicting from Predictions",
    "abstract": "Comments: to appear at NeurIPS 2022, revision corresponds to camera ready version",
    "descriptor": "\nComments: to appear at NeurIPS 2022, revision corresponds to camera ready version\n",
    "authors": [
      "Celestine Mendler-D\u00fcnner",
      "Frances Ding",
      "Yixin Wang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2208.07331"
  },
  {
    "id": "arXiv:2208.08661",
    "title": "Domain-Specific Risk Minimization for Out-of-Distribution Generalization",
    "abstract": "Comments: ECCV 2022 Workshop on Out-of-Distribution Generalization in Computer Vision",
    "descriptor": "\nComments: ECCV 2022 Workshop on Out-of-Distribution Generalization in Computer Vision\n",
    "authors": [
      "Yi-Fan Zhang",
      "Jindong Wang",
      "Jian Liang",
      "Zhang Zhang",
      "Baosheng Yu",
      "Liang Wang",
      "Dacheng Tao",
      "Xing Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.08661"
  },
  {
    "id": "arXiv:2208.09023",
    "title": "Single-Stage Open-world Instance Segmentation with Cross-task  Consistency Regularization",
    "abstract": "Single-Stage Open-world Instance Segmentation with Cross-task  Consistency Regularization",
    "descriptor": "",
    "authors": [
      "Xizhe Xue",
      "Dongdong Yu",
      "Lingqiao Liu",
      "Yu Liu",
      "Satoshi Tsutsui",
      "Ying Li",
      "Zehuan Yuan",
      "Ping Song",
      "Mike Zheng Shou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.09023"
  },
  {
    "id": "arXiv:2208.09980",
    "title": "M/D/1 Queues with LIFO and SIRO Policies",
    "abstract": "Comments: 12 pages; 2 figures; typo fixed in third equation on second page",
    "descriptor": "\nComments: 12 pages; 2 figures; typo fixed in third equation on second page\n",
    "authors": [
      "Steven Finch"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Discrete Mathematics (cs.DM)",
      "History and Overview (math.HO)"
    ],
    "url": "https://arxiv.org/abs/2208.09980"
  },
  {
    "id": "arXiv:2208.10224",
    "title": "Friendly Noise against Adversarial Noise: A Powerful Defense against  Data Poisoning Attacks",
    "abstract": "Friendly Noise against Adversarial Noise: A Powerful Defense against  Data Poisoning Attacks",
    "descriptor": "",
    "authors": [
      "Tian Yu Liu",
      "Yu Yang",
      "Baharan Mirzasoleiman"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.10224"
  },
  {
    "id": "arXiv:2208.10859",
    "title": "Wavelet-Based Fast Decoding of 360-Degree Videos",
    "abstract": "Wavelet-Based Fast Decoding of 360-Degree Videos",
    "descriptor": "",
    "authors": [
      "Colin Groth",
      "Sascha Fricke",
      "Susana Castillo",
      "Marcus Magnor"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2208.10859"
  },
  {
    "id": "arXiv:2209.00213",
    "title": "Public Parking Spot Detection And Geo-localization Using Transfer  Learning",
    "abstract": "Comments: Accepted for presentation at SACAIR 2022. 11 pages,5 figures",
    "descriptor": "\nComments: Accepted for presentation at SACAIR 2022. 11 pages,5 figures\n",
    "authors": [
      "Moseli Mots'oehli",
      "Yao Chao Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.00213"
  },
  {
    "id": "arXiv:2209.01760",
    "title": "REQA: Coarse-to-fine Assessment of Image Quality to Alleviate the Range  Effect",
    "abstract": "REQA: Coarse-to-fine Assessment of Image Quality to Alleviate the Range  Effect",
    "descriptor": "",
    "authors": [
      "Bingheng Li",
      "Fushuo Huo"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.01760"
  },
  {
    "id": "arXiv:2209.03299",
    "title": "Multimodal Representation Learning on Graphs",
    "abstract": "Comments: 28 pages, 5 figures, 2 boxes",
    "descriptor": "\nComments: 28 pages, 5 figures, 2 boxes\n",
    "authors": [
      "Yasha Ektefaie",
      "George Dasoulas",
      "Ayush Noori",
      "Maha Farhat",
      "Marinka Zitnik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.03299"
  },
  {
    "id": "arXiv:2209.03316",
    "title": "On the Complementarity between Pre-Training and Random-Initialization  for Resource-Rich Machine Translation",
    "abstract": "Comments: COLING 2022",
    "descriptor": "\nComments: COLING 2022\n",
    "authors": [
      "Changtong Zan",
      "Liang Ding",
      "Li Shen",
      "Yu Cao",
      "Weifeng Liu",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.03316"
  },
  {
    "id": "arXiv:2209.03695",
    "title": "Training Scale-Invariant Neural Networks on the Sphere Can Happen in  Three Regimes",
    "abstract": "Comments: Published in NeurIPS 2022. First three authors contributed equally",
    "descriptor": "\nComments: Published in NeurIPS 2022. First three authors contributed equally\n",
    "authors": [
      "Maxim Kodryan",
      "Ekaterina Lobacheva",
      "Maksim Nakhodnov",
      "Dmitry Vetrov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.03695"
  },
  {
    "id": "arXiv:2209.06788",
    "title": "Small Transformers Compute Universal Metric Embeddings",
    "abstract": "Comments: 42 pages, 10 Figures, 3 Tables",
    "descriptor": "\nComments: 42 pages, 10 Figures, 3 Tables\n",
    "authors": [
      "Anastasis Kratsios",
      "Valentin Debarnot",
      "Ivan Dokmani\u0107"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Combinatorics (math.CO)",
      "Metric Geometry (math.MG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.06788"
  },
  {
    "id": "arXiv:2209.07403",
    "title": "Private Stochastic Optimization in the Presence of Outliers: Optimal  Rates for (Non-Smooth) Convex Losses and Extension to Non-Convex Losses",
    "abstract": "Private Stochastic Optimization in the Presence of Outliers: Optimal  Rates for (Non-Smooth) Convex Losses and Extension to Non-Convex Losses",
    "descriptor": "",
    "authors": [
      "Andrew Lowy",
      "Meisam Razaviyayn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.07403"
  },
  {
    "id": "arXiv:2209.07587",
    "title": "Theoretical Insight into Batch Normalization: Data Dependant Auto-Tuning  of Regularization Rate",
    "abstract": "Theoretical Insight into Batch Normalization: Data Dependant Auto-Tuning  of Regularization Rate",
    "descriptor": "",
    "authors": [
      "Lakshmi Annamalai",
      "Chetan Singh Thakur"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07587"
  },
  {
    "id": "arXiv:2209.08483",
    "title": "Honor of Kings Arena: an Environment for Generalization in Competitive  Reinforcement Learning",
    "abstract": "Comments: Accepted by NeurIPS 2022",
    "descriptor": "\nComments: Accepted by NeurIPS 2022\n",
    "authors": [
      "Hua Wei",
      "Jingxiao Chen",
      "Xiyang Ji",
      "Hongyang Qin",
      "Minwen Deng",
      "Siqin Li",
      "Liang Wang",
      "Weinan Zhang",
      "Yong Yu",
      "Lin Liu",
      "Lanxiao Huang",
      "Deheng Ye",
      "Qiang Fu",
      "Wei Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.08483"
  },
  {
    "id": "arXiv:2209.11134",
    "title": "Neural Networks Base on Power Method and Inverse Power Method for  Solving Linear Eigenvalue Problems",
    "abstract": "Neural Networks Base on Power Method and Inverse Power Method for  Solving Linear Eigenvalue Problems",
    "descriptor": "",
    "authors": [
      "Qihong Yang",
      "Yangtao Deng",
      "Yu Yang",
      "Qiaolin He",
      "Shiquan Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.11134"
  },
  {
    "id": "arXiv:2209.11904",
    "title": "CryptoGCN: Fast and Scalable Homomorphically Encrypted Graph  Convolutional Network Inference",
    "abstract": "Comments: Accepted in Conference on Neural Information Processing Systems (NeurIPS 2022)",
    "descriptor": "\nComments: Accepted in Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Ran Ran",
      "Nuo Xu",
      "Wei Wang",
      "Quan Gang",
      "Jieming Yin",
      "Wujie Wen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.11904"
  },
  {
    "id": "arXiv:2209.12221",
    "title": "Hand Hygiene Assessment via Joint Step Segmentation and Key Action  Scorer",
    "abstract": "Comments: In the introduction, we mention that the framework of the proposed method is different from other methods in that the action is segmented, assessed and then integrated. We've recently learned that such processing is not novel. And we have some other words that are not appropriate, so we need to update our work",
    "descriptor": "\nComments: In the introduction, we mention that the framework of the proposed method is different from other methods in that the action is segmented, assessed and then integrated. We've recently learned that such processing is not novel. And we have some other words that are not appropriate, so we need to update our work\n",
    "authors": [
      "Chenglong Li",
      "Qiwen Zhu",
      "Tubiao Liu",
      "Jin Tang",
      "Yu Su"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.12221"
  },
  {
    "id": "arXiv:2209.12340",
    "title": "Solving Seismic Wave Equations on Variable Velocity Models with Fourier  Neural Operator",
    "abstract": "Comments: 24 pages, 13 figures",
    "descriptor": "\nComments: 24 pages, 13 figures\n",
    "authors": [
      "Bian Li",
      "Hanchen Wang",
      "Xiu Yang",
      "Youzuo Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2209.12340"
  },
  {
    "id": "arXiv:2209.12413",
    "title": "CAMEL: Learning Cost-maps Made Easy for Off-road Driving",
    "abstract": "CAMEL: Learning Cost-maps Made Easy for Off-road Driving",
    "descriptor": "",
    "authors": [
      "Kasi Vishwanath",
      "P.B. Sujit",
      "Srikanth Saripalli"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.12413"
  },
  {
    "id": "arXiv:2209.13464",
    "title": "Information Extraction and Human-Robot Dialogue towards Real-life Tasks:  A Baseline Study with the MobileCS Dataset",
    "abstract": "Comments: Accepted by EMNLP 2022 SereTOD Workshop",
    "descriptor": "\nComments: Accepted by EMNLP 2022 SereTOD Workshop\n",
    "authors": [
      "Hong Liu",
      "Hao Peng",
      "Zhijian Ou",
      "Juanzi Li",
      "Yi Huang",
      "Junlan Feng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.13464"
  },
  {
    "id": "arXiv:2209.13603",
    "title": "Scalable and Equivariant Spherical CNNs by Discrete-Continuous (DISCO)  Convolutions",
    "abstract": "Comments: 17 pages, 6 figures",
    "descriptor": "\nComments: 17 pages, 6 figures\n",
    "authors": [
      "Jeremy Ocampo",
      "Matthew A. Price",
      "Jason D. McEwen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.13603"
  },
  {
    "id": "arXiv:2209.13684",
    "title": "Online Search-based Collision-inclusive Motion Planning and Control for  Impact-resilient Mobile Robots",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2108.01802",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2108.01802\n",
    "authors": [
      "Zhouyu Lu",
      "Zhichao Liu",
      "Merrick Campbell",
      "Konstantinos Karydis"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2209.13684"
  },
  {
    "id": "arXiv:2210.00215",
    "title": "Differentiable Parsing and Visual Grounding of Verbal Instructions for  Object Placement",
    "abstract": "Comments: Submitted to ICRA 2023",
    "descriptor": "\nComments: Submitted to ICRA 2023\n",
    "authors": [
      "Zirui Zhao",
      "Wee Sun Lee",
      "David Hsu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00215"
  },
  {
    "id": "arXiv:2210.01478",
    "title": "When to Make Exceptions: Exploring Language Models as Accounts of Human  Moral Judgment",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Zhijing Jin",
      "Sydney Levine",
      "Fernando Gonzalez",
      "Ojasv Kamal",
      "Maarten Sap",
      "Mrinmaya Sachan",
      "Rada Mihalcea",
      "Josh Tenenbaum",
      "Bernhard Sch\u00f6lkopf"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.01478"
  },
  {
    "id": "arXiv:2210.01917",
    "title": "Differentiable Raycasting for Self-supervised Occupancy Forecasting",
    "abstract": "Comments: ECCV 2022. Code available at this https URL",
    "descriptor": "\nComments: ECCV 2022. Code available at this https URL\n",
    "authors": [
      "Tarasha Khurana",
      "Peiyun Hu",
      "Achal Dave",
      "Jason Ziglar",
      "David Held",
      "Deva Ramanan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.01917"
  },
  {
    "id": "arXiv:2210.02097",
    "title": "Teaching Yourself:Graph Self-Distillation on Neighborhood for Node  Classification",
    "abstract": "Teaching Yourself:Graph Self-Distillation on Neighborhood for Node  Classification",
    "descriptor": "",
    "authors": [
      "Lirong Wu",
      "Jun Xia",
      "Haitao Lin",
      "Zhangyang Gao",
      "Zicheng Liu",
      "Guojiang Zhao",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02097"
  },
  {
    "id": "arXiv:2210.02914",
    "title": "Generative Entity Typing with Curriculum Learning",
    "abstract": "Comments: Accepted to EMNLP 2022",
    "descriptor": "\nComments: Accepted to EMNLP 2022\n",
    "authors": [
      "Siyu Yuan",
      "Deqing Yang",
      "Jiaqing Liang",
      "Zhixu Li",
      "Jinxi Liu",
      "Jingyue Huang",
      "Yanghua Xiao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.02914"
  },
  {
    "id": "arXiv:2210.03165",
    "title": "A Theory of Dynamic Benchmarks",
    "abstract": "Comments: Corrected typos",
    "descriptor": "\nComments: Corrected typos\n",
    "authors": [
      "Ali Shirali",
      "Rediet Abebe",
      "Moritz Hardt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.03165"
  },
  {
    "id": "arXiv:2210.03221",
    "title": "PQLM -- Multilingual Decentralized Portable Quantum Language Model for  Privacy Protection",
    "abstract": "Comments: 5 pages, 3 figures, 3 tables",
    "descriptor": "\nComments: 5 pages, 3 figures, 3 tables\n",
    "authors": [
      "Shuyue Stella Li",
      "Xiangyu Zhang",
      "Shu Zhou",
      "Hongchao Shu",
      "Ruixing Liang",
      "Hexin Liu",
      "Leibny Paola Garcia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.03221"
  },
  {
    "id": "arXiv:2210.03329",
    "title": "Calibrating Factual Knowledge in Pretrained Language Models",
    "abstract": "Comments: Accepted by Findings of EMNLP 2022",
    "descriptor": "\nComments: Accepted by Findings of EMNLP 2022\n",
    "authors": [
      "Qingxiu Dong",
      "Damai Dai",
      "Yifan Song",
      "Jingjing Xu",
      "Zhifang Sui",
      "Lei Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.03329"
  },
  {
    "id": "arXiv:2210.04204",
    "title": "Lasso trigonometric polynomial approximation for periodic function  recovery in equidistant points",
    "abstract": "Comments: 18 pages, 5 figures",
    "descriptor": "\nComments: 18 pages, 5 figures\n",
    "authors": [
      "Congpei An",
      "Mou Cai"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.04204"
  },
  {
    "id": "arXiv:2210.04284",
    "title": "SparseAdapter: An Easy Approach for Improving the Parameter-Efficiency  of Adapters",
    "abstract": "Comments: Findings of EMNLP 2022",
    "descriptor": "\nComments: Findings of EMNLP 2022\n",
    "authors": [
      "Shwai He",
      "Liang Ding",
      "Daize Dong",
      "Miao Zhang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.04284"
  },
  {
    "id": "arXiv:2210.04474",
    "title": "Rethinking Wireless Communication Security in Semantic Internet of  Things",
    "abstract": "Rethinking Wireless Communication Security in Semantic Internet of  Things",
    "descriptor": "",
    "authors": [
      "Hongyang Du",
      "Jiacheng Wang",
      "Dusit Niyato",
      "Jiawen Kang",
      "Zehui Xiong",
      "Mohsen Guizani",
      "Dong In Kim"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.04474"
  },
  {
    "id": "arXiv:2210.04475",
    "title": "Optimal Hybrid Multiplexed AC-DC-AC converters",
    "abstract": "Comments: Submitted to ACDC conference 2023 (Glasgow, UK)",
    "descriptor": "\nComments: Submitted to ACDC conference 2023 (Glasgow, UK)\n",
    "authors": [
      "Matthew Deakin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.04475"
  },
  {
    "id": "arXiv:2210.04834",
    "title": "Knowledge Distillation Transfer Sets and their Impact on Downstream NLU  Tasks",
    "abstract": "Comments: 7 pages, 2 figures, 2 tables (+ 4 tables in Appendix), Accepted to EMNLP 2022 (industry track)",
    "descriptor": "\nComments: 7 pages, 2 figures, 2 tables (+ 4 tables in Appendix), Accepted to EMNLP 2022 (industry track)\n",
    "authors": [
      "Charith Peris",
      "Lizhen Tan",
      "Thomas Gueudre",
      "Turan Gojayev",
      "Pan Wei",
      "Gokmen Oz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.04834"
  },
  {
    "id": "arXiv:2210.04909",
    "title": "Meta-Principled Family of Hyperparameter Scaling Strategies",
    "abstract": "Comments: 24 pages; v2: an addendum added",
    "descriptor": "\nComments: 24 pages; v2: an addendum added\n",
    "authors": [
      "Sho Yaida"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "High Energy Physics - Theory (hep-th)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.04909"
  },
  {
    "id": "arXiv:2210.05438",
    "title": "Parallel Augmentation and Dual Enhancement for Occluded Person  Re-identification",
    "abstract": "Comments: 9 pages, 5 figures",
    "descriptor": "\nComments: 9 pages, 5 figures\n",
    "authors": [
      "Zi wang",
      "Huaibo Huang",
      "Aihua Zheng",
      "Chenglong Li",
      "Ran He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.05438"
  },
  {
    "id": "arXiv:2210.06361",
    "title": "MFFN: Multi-view Feature Fusion Network for Camouflaged Object Detection",
    "abstract": "Comments: In Proceedings of the 2023 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)",
    "descriptor": "\nComments: In Proceedings of the 2023 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)\n",
    "authors": [
      "Dehua Zheng",
      "Xiaochen Zheng",
      "Laurence T. Yang",
      "Yuan Gao",
      "Chenlu Zhu",
      "Yiheng Ruan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.06361"
  },
  {
    "id": "arXiv:2210.06789",
    "title": "Large-Scale Open-Set Classification Protocols for ImageNet",
    "abstract": "Comments: This is a pre-print of the original paper accepted at the Winter Conference on Applications of Computer Vision (WACV) 2023",
    "descriptor": "\nComments: This is a pre-print of the original paper accepted at the Winter Conference on Applications of Computer Vision (WACV) 2023\n",
    "authors": [
      "Andres Palechor",
      "Annesha Bhoumik",
      "Manuel G\u00fcnther"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.06789"
  },
  {
    "id": "arXiv:2210.06849",
    "title": "Retrospectives on the Embodied AI Workshop",
    "abstract": "Retrospectives on the Embodied AI Workshop",
    "descriptor": "",
    "authors": [
      "Matt Deitke",
      "Dhruv Batra",
      "Yonatan Bisk",
      "Tommaso Campari",
      "Angel X. Chang",
      "Devendra Singh Chaplot",
      "Changan Chen",
      "Claudia P\u00e9rez D'Arpino",
      "Kiana Ehsani",
      "Ali Farhadi",
      "Li Fei-Fei",
      "Anthony Francis",
      "Chuang Gan",
      "Kristen Grauman",
      "David Hall",
      "Winson Han",
      "Unnat Jain",
      "Aniruddha Kembhavi",
      "Jacob Krantz",
      "Stefan Lee",
      "Chengshu Li",
      "Sagnik Majumder",
      "Oleksandr Maksymets",
      "Roberto Mart\u00edn-Mart\u00edn",
      "Roozbeh Mottaghi",
      "Sonia Raychaudhuri",
      "Mike Roberts",
      "Silvio Savarese",
      "Manolis Savva",
      "Mohit Shridhar",
      "Niko S\u00fcnderhauf",
      "Andrew Szot",
      "Ben Talbot",
      "Joshua B. Tenenbaum",
      "Jesse Thomason",
      "Alexander Toshev",
      "Joanne Truong",
      "Luca Weihs",
      "Jiajun Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.06849"
  },
  {
    "id": "arXiv:2210.07024",
    "title": "Self-explaining deep models with logic rule reasoning",
    "abstract": "Comments: 26 pages including reference, checklist, and appendix. Accepted in NeurIPS 2022",
    "descriptor": "\nComments: 26 pages including reference, checklist, and appendix. Accepted in NeurIPS 2022\n",
    "authors": [
      "Seungeon Lee",
      "Xiting Wang",
      "Sungwon Han",
      "Xiaoyuan Yi",
      "Xing Xie",
      "Meeyoung Cha"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.07024"
  },
  {
    "id": "arXiv:2210.07122",
    "title": "Deep Idempotent Network for Efficient Single Image Blind Deblurring",
    "abstract": "Comments: The first two authors contributed equally, accepted by IEEE TCSVT(this https URL), Project page(this https URL)",
    "descriptor": "\nComments: The first two authors contributed equally, accepted by IEEE TCSVT(this https URL), Project page(this https URL)\n",
    "authors": [
      "Yuxin Mao",
      "Zhexiong Wan",
      "Yuchao Dai",
      "Xin Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07122"
  },
  {
    "id": "arXiv:2210.07374",
    "title": "A Relational Macrostate Theory Guides Artificial Intelligence to Learn  Macro and Design Micro",
    "abstract": "Comments: 12 pages, 6 figures",
    "descriptor": "\nComments: 12 pages, 6 figures\n",
    "authors": [
      "Yanbo Zhang",
      "Sara Imari Walker"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Statistical Mechanics (cond-mat.stat-mech)"
    ],
    "url": "https://arxiv.org/abs/2210.07374"
  },
  {
    "id": "arXiv:2210.07435",
    "title": "NOCaL: Calibration-Free Semi-Supervised Learning of Odometry and Camera  Intrinsics",
    "abstract": "Comments: 7 pages, 4 figures, 2 tables, for associated project page, see this https URL",
    "descriptor": "\nComments: 7 pages, 4 figures, 2 tables, for associated project page, see this https URL\n",
    "authors": [
      "Ryan Griffiths",
      "Jack Naylor",
      "Donald G. Dansereau"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07435"
  },
  {
    "id": "arXiv:2210.07500",
    "title": "ToupleGDD: A Fine-Designed Solution of Influence Maximization by Deep  Reinforcement Learning",
    "abstract": "Comments: 12 pages, 7 figures",
    "descriptor": "\nComments: 12 pages, 7 figures\n",
    "authors": [
      "Tiantian Chen",
      "Siwen Yan",
      "Jianxiong Guo",
      "Weili Wu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07500"
  },
  {
    "id": "arXiv:2210.07508",
    "title": "Hierarchical Diffusion Models for Singing Voice Neural Vocoder",
    "abstract": "Hierarchical Diffusion Models for Singing Voice Neural Vocoder",
    "descriptor": "",
    "authors": [
      "Naoya Takahashi",
      "Mayank Kumar",
      "Singh",
      "Yuki Mitsufuji"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.07508"
  },
  {
    "id": "arXiv:2210.07646",
    "title": "Vision Transformer Visualization: What Neurons Tell and How Neurons  Behave?",
    "abstract": "Comments: The first two authors contributed equally to this work. Our code is available at this https URL",
    "descriptor": "\nComments: The first two authors contributed equally to this work. Our code is available at this https URL\n",
    "authors": [
      "Van-Anh Nguyen",
      "Khanh Pham Dinh",
      "Long Tung Vuong",
      "Thanh-Toan Do",
      "Quan Hung Tran",
      "Dinh Phung",
      "Trung Le"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07646"
  },
  {
    "id": "arXiv:2210.07651",
    "title": "Decentralized Policy Gradient for Nash Equilibria Learning of  General-sum Stochastic Games",
    "abstract": "Decentralized Policy Gradient for Nash Equilibria Learning of  General-sum Stochastic Games",
    "descriptor": "",
    "authors": [
      "Yan Chen",
      "Tao Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2210.07651"
  },
  {
    "id": "arXiv:2210.07745",
    "title": "Confidence estimation of classification based on the distribution of the  neural network output layer",
    "abstract": "Comments: Draft",
    "descriptor": "\nComments: Draft\n",
    "authors": [
      "Abdel Aziz Taha",
      "Leonhard Hennig",
      "Petr Knoth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.07745"
  },
  {
    "id": "arXiv:2210.07808",
    "title": "Optimal AdaBoost Converges",
    "abstract": "Optimal AdaBoost Converges",
    "descriptor": "",
    "authors": [
      "Conor Snedeker"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.07808"
  },
  {
    "id": "arXiv:2210.07829",
    "title": "Asymmetric Student-Teacher Networks for Industrial Anomaly Detection",
    "abstract": "Comments: accepted to WACV 2023",
    "descriptor": "\nComments: accepted to WACV 2023\n",
    "authors": [
      "Marco Rudolph",
      "Tom Wehrbein",
      "Bodo Rosenhahn",
      "Bastian Wandt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07829"
  },
  {
    "id": "arXiv:2210.07857",
    "title": "Commutativity and Disentanglement from the Manifold Perspective",
    "abstract": "Commutativity and Disentanglement from the Manifold Perspective",
    "descriptor": "",
    "authors": [
      "Frank Qiu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07857"
  },
  {
    "id": "arXiv:2210.07873",
    "title": "A Second Wave of UD Hebrew Treebanking and Cross-Domain Parsing",
    "abstract": "Comments: Proceedings of EMNLP 2022",
    "descriptor": "\nComments: Proceedings of EMNLP 2022\n",
    "authors": [
      "Amir Zeldes",
      "Nick Howell",
      "Noam Ordan",
      "Yifat Ben Moshe"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.07873"
  },
  {
    "id": "arXiv:2210.08016",
    "title": "Prediction of drug effectiveness in rheumatoid arthritis patients based  on machine learning algorithms",
    "abstract": "Comments: 13 pages, 5 figures, to be published in ICBBE 2022",
    "descriptor": "\nComments: 13 pages, 5 figures, to be published in ICBBE 2022\n",
    "authors": [
      "Shengjia Chen",
      "Nikunj Gupta",
      "Woodward B. Galbraith",
      "Valay Shah",
      "Jacopo Cirrone"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2210.08016"
  },
  {
    "id": "arXiv:2210.08305",
    "title": "PointNeuron: 3D Neuron Reconstruction via Geometry and Topology Learning  of Point Clouds",
    "abstract": "Comments: WACV 2023",
    "descriptor": "\nComments: WACV 2023\n",
    "authors": [
      "Runkai Zhao",
      "Heng Wang",
      "Chaoyi Zhang",
      "Weidong Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08305"
  },
  {
    "id": "arXiv:2210.08312",
    "title": "Disordered Systems Insights on Computational Hardness",
    "abstract": "Comments: 42 pages",
    "descriptor": "\nComments: 42 pages\n",
    "authors": [
      "David Gamarnik",
      "Cristopher Moore",
      "Lenka Zdeborov\u00e1"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Computational Complexity (cs.CC)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2210.08312"
  },
  {
    "id": "arXiv:2210.08363",
    "title": "Data-Efficient Augmentation for Training Neural Networks",
    "abstract": "Data-Efficient Augmentation for Training Neural Networks",
    "descriptor": "",
    "authors": [
      "Tian Yu Liu",
      "Baharan Mirzasoleiman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08363"
  },
  {
    "id": "arXiv:2210.08391",
    "title": "Video in 10 Bits: Few-Bit VideoQA for Efficiency and Privacy",
    "abstract": "Comments: ECCV Workshop 2022",
    "descriptor": "\nComments: ECCV Workshop 2022\n",
    "authors": [
      "Shiyuan Huang",
      "Robinson Piramuthu",
      "Shih-Fu Chang",
      "Gunnar A. Sigurdsson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08391"
  },
  {
    "id": "arXiv:2210.08572",
    "title": "Automatic Differentiation of Programs with Discrete Randomness",
    "abstract": "Comments: NeurIPS 2022 camera-ready. 10 pages in the main text, 27 pages total, 5 figures",
    "descriptor": "\nComments: NeurIPS 2022 camera-ready. 10 pages in the main text, 27 pages total, 5 figures\n",
    "authors": [
      "Gaurav Arya",
      "Moritz Schauer",
      "Frank Sch\u00e4fer",
      "Chris Rackauckas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Mathematical Software (cs.MS)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2210.08572"
  },
  {
    "id": "arXiv:2210.08578",
    "title": "Data-Model-Circuit Tri-Design for Ultra-Light Video Intelligence on Edge  Devices",
    "abstract": "Comments: Accepted to ASP-DAC'23",
    "descriptor": "\nComments: Accepted to ASP-DAC'23\n",
    "authors": [
      "Yimeng Zhang",
      "Akshay Karkal Kamath",
      "Qiucheng Wu",
      "Zhiwen Fan",
      "Wuyang Chen",
      "Zhangyang Wang",
      "Shiyu Chang",
      "Sijia Liu",
      "Cong Hao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2210.08578"
  },
  {
    "id": "arXiv:2210.08590",
    "title": "Zero-Shot Learners for Natural Language Understanding via a Unified  Multiple Choice Perspective",
    "abstract": "Comments: EMNLP 2022",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Ping Yang",
      "Junjie Wang",
      "Ruyi Gan",
      "Xinyu Zhu",
      "Lin Zhang",
      "Ziwei Wu",
      "Xinyu Gao",
      "Jiaxing Zhang",
      "Tetsuya Sakai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08590"
  },
  {
    "id": "arXiv:2210.08676",
    "title": "Scale-Agnostic Super-Resolution in MRI using Feature-Based Coordinate  Networks",
    "abstract": "Scale-Agnostic Super-Resolution in MRI using Feature-Based Coordinate  Networks",
    "descriptor": "",
    "authors": [
      "Dave Van Veen",
      "Rogier van der Sluijs",
      "Batu Ozturkler",
      "Arjun Desai",
      "Christian Bluethgen",
      "Robert D. Boutin",
      "Marc H. Willis",
      "Gordon Wetzstein",
      "David Lindell",
      "Shreyas Vasanawala",
      "John Pauly",
      "Akshay S. Chaudhari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08676"
  },
  {
    "id": "arXiv:2210.08692",
    "title": "A Generative User Simulator with GPT-based Architecture and Goal State  Tracking for Reinforced Multi-Domain Dialog Systems",
    "abstract": "Comments: Accepted by EMNLP 2022 SereTOD Workshop",
    "descriptor": "\nComments: Accepted by EMNLP 2022 SereTOD Workshop\n",
    "authors": [
      "Hong Liu",
      "Yucheng Cai",
      "Zhijian Ou",
      "Yi Huang",
      "Junlan Feng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08692"
  },
  {
    "id": "arXiv:2210.08710",
    "title": "Joint Plasticity Learning for Camera Incremental Person  Re-Identification",
    "abstract": "Joint Plasticity Learning for Camera Incremental Person  Re-Identification",
    "descriptor": "",
    "authors": [
      "Zexian Yang",
      "Dayan Wu",
      "Bo Li",
      "Weiping Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08710"
  },
  {
    "id": "arXiv:2210.08727",
    "title": "Can Quadruped Navigation Robots be Used as Guide Dogs?",
    "abstract": "Can Quadruped Navigation Robots be Used as Guide Dogs?",
    "descriptor": "",
    "authors": [
      "Qihe Chen",
      "Luyao Wang",
      "Yan Zhang",
      "Ziang Li",
      "Tingmin Yan",
      "Fan Wang",
      "Guyue Zhou",
      "Jiangtao Gong"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.08727"
  },
  {
    "id": "arXiv:2210.08731",
    "title": "A High Fidelity Simulation Framework for Potential Safety Benefits  Estimation of Cooperative Pedestrian Perception",
    "abstract": "A High Fidelity Simulation Framework for Potential Safety Benefits  Estimation of Cooperative Pedestrian Perception",
    "descriptor": "",
    "authors": [
      "Longrui Chen",
      "Yan Zhang",
      "Wenjie Jiang",
      "Jiangtao Gong",
      "Jiahao Shen",
      "Mengdi Chu",
      "Chuxuan Li",
      "Yifeng Pan",
      "Yifeng Shi",
      "Nairui Luo",
      "Xu Gao",
      "Jirui Yuan",
      "Guyue Zhou",
      "Yaqin Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.08731"
  },
  {
    "id": "arXiv:2210.08788",
    "title": "EISeg: An Efficient Interactive Segmentation Tool based on PaddlePaddle",
    "abstract": "Comments: 8 pages",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Yuying Hao",
      "Yi Liu",
      "Yizhou Chen",
      "Lin Han",
      "Juncai Peng",
      "Shiyu Tang",
      "Guowei Chen",
      "Zewu Wu",
      "Zeyu Chen",
      "Baohua Lai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08788"
  },
  {
    "id": "arXiv:2210.08884",
    "title": "HyperDomainNet: Universal Domain Adaptation for Generative Adversarial  Networks",
    "abstract": "Comments: Accepted to NeurIPS 2022",
    "descriptor": "\nComments: Accepted to NeurIPS 2022\n",
    "authors": [
      "Aibek Alanov",
      "Vadim Titov",
      "Dmitry Vetrov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08884"
  },
  {
    "id": "arXiv:2210.08922",
    "title": "Joint Multilingual Knowledge Graph Completion and Alignment",
    "abstract": "Comments: EMNLP 2022 (Findings), to appear",
    "descriptor": "\nComments: EMNLP 2022 (Findings), to appear\n",
    "authors": [
      "Vinh Tong",
      "Dat Quoc Nguyen",
      "Trung Thanh Huynh",
      "Tam Thanh Nguyen",
      "Quoc Viet Hung Nguyen",
      "Mathias Niepert"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08922"
  },
  {
    "id": "arXiv:2210.08955",
    "title": "Monitoring edge-geodetic sets: hardness and graph products",
    "abstract": "Comments: 8 pages, 2 figures",
    "descriptor": "\nComments: 8 pages, 2 figures\n",
    "authors": [
      "John Haslegrave"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2210.08955"
  },
  {
    "id": "arXiv:2210.09186",
    "title": "Implicit models, latent compression, intrinsic biases, and cheap lunches  in community detection",
    "abstract": "Comments: 24 pages, 18 figures",
    "descriptor": "\nComments: 24 pages, 18 figures\n",
    "authors": [
      "Tiago P. Peixoto",
      "Alec Kirkley"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Physics and Society (physics.soc-ph)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.09186"
  },
  {
    "id": "arXiv:2210.09267",
    "title": "CramNet: Camera-Radar Fusion with Ray-Constrained Cross-Attention for  Robust 3D Object Detection",
    "abstract": "Comments: ECCV 2022",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Jyh-Jing Hwang",
      "Henrik Kretzschmar",
      "Joshua Manela",
      "Sean Rafferty",
      "Nicholas Armstrong-Crews",
      "Tiffany Chen",
      "Dragomir Anguelov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.09267"
  }
]